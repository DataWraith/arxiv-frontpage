{"created":"2025-04-17","title":"Exploring the Role of Knowledge Graph-Based RAG in Japanese Medical Question Answering with Small-Scale LLMs","abstract":"Large language models (LLMs) perform well in medical QA, but their effectiveness in Japanese contexts is limited due to privacy constraints that prevent the use of commercial models like GPT-4 in clinical settings. As a result, recent efforts focus on instruction-tuning open-source LLMs, though the potential of combining them with retrieval-augmented generation (RAG) remains underexplored. To bridge this gap, we are the first to explore a knowledge graph-based (KG) RAG framework for Japanese medical QA small-scale open-source LLMs. Experimental results show that KG-based RAG has only a limited impact on Japanese medical QA using small-scale open-source LLMs. Further case studies reveal that the effectiveness of the RAG is sensitive to the quality and relevance of the external retrieved content. These findings offer valuable insights into the challenges and potential of applying RAG in Japanese medical QA, while also serving as a reference for other low-resource languages.","authors":["Yingjian Chen","Feiyang Li","Xingyu Song","Tianxiao Li","Issey Sukeda","Irene Li"],"url":"https://arxiv.org/abs/2504.10982"}
{"created":"2025-04-17","title":"EthosGPT: Mapping Human Value Diversity to Advance Sustainable Development Goals (SDGs)","abstract":"Large language models (LLMs) are transforming global decision-making and societal systems by processing diverse data at unprecedented scales. However, their potential to homogenize human values poses critical risks, similar to biodiversity loss undermining ecological resilience. Rooted in the ancient Greek concept of ethos, meaning both individual character and the shared moral fabric of communities, EthosGPT draws on a tradition that spans from Aristotle's virtue ethics to Adam Smith's moral sentiments as the ethical foundation of economic cooperation. These traditions underscore the vital role of value diversity in fostering social trust, institutional legitimacy, and long-term prosperity. EthosGPT addresses the challenge of value homogenization by introducing an open-source framework for mapping and evaluating LLMs within a global scale of human values. Using international survey data on cultural indices, prompt-based assessments, and comparative statistical analyses, EthosGPT reveals both the adaptability and biases of LLMs across regions and cultures. It offers actionable insights for developing inclusive LLMs, such as diversifying training data and preserving endangered cultural heritage to ensure representation in AI systems. These contributions align with the United Nations Sustainable Development Goals (SDGs), especially SDG 10 (Reduced Inequalities), SDG 11.4 (Cultural Heritage Preservation), and SDG 16 (Peace, Justice and Strong Institutions). Through interdisciplinary collaboration, EthosGPT promotes AI systems that are both technically robust and ethically inclusive, advancing value plurality as a cornerstone for sustainable and equitable futures.","authors":["Luyao Zhang"],"url":"https://arxiv.org/abs/2504.09861"}
{"created":"2025-04-17","title":"Wasserstein Distributionally Robust Regret Optimization","abstract":"Distributionally Robust Optimization (DRO) is a popular framework for decision-making under uncertainty, but its adversarial nature can lead to overly conservative solutions. To address this, we study ex-ante Distributionally Robust Regret Optimization (DRRO), focusing on Wasserstein-based ambiguity sets which are popular due to their links to regularization and machine learning. We provide a systematic analysis of Wasserstein DRRO, paralleling known results for Wasserstein DRO. Under smoothness and regularity conditions, we show that Wasserstein DRRO coincides with Empirical Risk Minimization (ERM) up to first-order terms, and exactly so in convex quadratic settings. We revisit the Wasserstein DRRO newsvendor problem, where the loss is the maximum of two linear functions of demand and decision. Extending [25], we show that the regret can be computed by maximizing two one-dimensional concave functions. For more general loss functions involving the maximum of multiple linear terms in multivariate random variables and decision vectors, we prove that computing the regret and thus also the DRRO policy is NP-hard. We then propose a convex relaxation for these more general Wasserstein DRRO problems and demonstrate its strong empirical performance. Finally, we provide an upper bound on the optimality gap of our relaxation and show it improves over recent alternatives.","authors":["Lukas-Benedikt Fiechtner","Jose Blanchet"],"url":"https://arxiv.org/abs/2504.10796"}
{"created":"2025-04-17","title":"On the performance of downlink NOMA in underlay spectrum sharing","abstract":"Non-orthogonal multiple access (NOMA) and spectrum sharing are two potential technologies for providing massive connectivity in beyond fifth-generation (B5G) networks. In this paper, we present the performance analysis of a multi-antenna-assisted two-user downlink NOMA system in an underlay spectrum sharing system. We derive closed-form expressions for the average achievable sum-rate and outage probability of the secondary network under a peak interference constraint and/or peak power constraint, depending on the availability of channel state information (CSI) of the interference link between secondary transmitter (ST) and primary receiver (PR). For the case where the ST has a fixed power budget, we show that performance can be divided into two specific regimes, where either the interference constraint or the power constraint primarily dictates the performance. Our results confirm that the NOMA-based underlay spectrum sharing system significantly outperforms its orthogonal multiple access (OMA) based counterpart, by achieving higher average sum-rate and lower outage probability. We also show the effect of information loss at the ST in terms of CSI of the link between the ST and PR on the system performance. Moreover, we also present closed-form expressions for the optimal power allocation coefficient that minimizes the outage probability of the NOMA system for the special case where the secondary users are each equipped with a single antenna. A close agreement between the simulation and analytical results confirms the correctness of the presented analysis.","authors":["Vaibhav Kumar","Zhiguo Ding","Mark F. Flanagan"],"url":"https://arxiv.org/abs/2011.08159"}
{"created":"2025-04-17","title":"Nonlinear Expectation Inference for Efficient Uncertainty Quantification and History Matching of Transient Darcy Flows in Porous Media with Random Parameters Under Distribution Uncertainty","abstract":"The uncertainty quantification of Darcy flows using history matching is important for the evaluation and prediction of subsurface reservoir performance. Conventional methods aim to obtain the maximum a posterior or maximum likelihood estimate (MLE) using gradient-based, heuristic or ensemble-based methods. These methods can be computationally expensive for high-dimensional problems since forward simulation needs to be run iteratively as physical parameters are updated. In the current study, we propose a nonlinear expectation inference (NEI) method for efficient history matching and uncertainty quantification accounting for distribution or Knightian uncertainty. Forward simulation runs are conducted on prior realisations once, and then a range of expectations are computed in the data space based on subsets of prior realisations with no repetitive forward runs required. In NEI, no prior probability distribution for data is assumed. Instead, the probability distribution is assumed to be uncertain with prior and posterior uncertainty quantified by nonlinear expectations. The inferred result of NEI is the posterior subsets on which the expected flow rates are consistent with observation. The accuracy and efficiency of the new method are validated using single- and two-phase Darcy flows in 2D and 3D heterogeneous reservoirs.","authors":["Zhao Zhang","Xinpeng Li","Menghan Li","Jiayu Zhai","Piyang Liu","Xia Yan","Kai Zhang"],"url":"https://arxiv.org/abs/2312.06923"}
{"created":"2025-04-17","title":"UniForm: A Unified Multi-Task Diffusion Transformer for Audio-Video Generation","abstract":"With the rise of diffusion models, audio-video generation has been revolutionized. However, most existing methods rely on separate modules for each modality, with limited exploration of unified generative architectures. In addition, many are confined to a single task and small-scale datasets. To address these limitations, we first propose UniForm, a unified multi-task diffusion transformer that jointly generates audio and visual modalities in a shared latent space. A single diffusion process models both audio and video, capturing the inherent correlations between sound and vision. Second, we introduce task-specific noise schemes and task tokens, enabling a single model to support multiple tasks, including text-to-audio-video, audio-to-video, and video-to-audio generation. Furthermore, by leveraging large language models and a large-scale text-audio-video combined dataset, UniForm achieves greater generative diversity than prior approaches. Extensive experiments show that UniForm achieves the state-of-the-art performance across audio-video generation tasks, producing content that is both well-aligned and close to real-world data distributions. Our demos are available at https://uniform-t2av.github.io/.","authors":["Lei Zhao","Linfeng Feng","Dongxu Ge","Rujin Chen","Fangqiu Yi","Chi Zhang","Xiao-Lei Zhang","Xuelong Li"],"url":"https://arxiv.org/abs/2502.03897"}
{"created":"2025-04-17","title":"AppAgentX: Evolving GUI Agents as Proficient Smartphone Users","abstract":"Recent advancements in Large Language Models (LLMs) have led to the development of intelligent LLM-based agents capable of interacting with graphical user interfaces (GUIs). These agents demonstrate strong reasoning and adaptability, enabling them to perform complex tasks that traditionally required predefined rules. However, the reliance on step-by-step reasoning in LLM-based agents often results in inefficiencies, particularly for routine tasks. In contrast, traditional rule-based systems excel in efficiency but lack the intelligence and flexibility to adapt to novel scenarios. To address this challenge, we propose a novel evolutionary framework for GUI agents that enhances operational efficiency while retaining intelligence and flexibility. Our approach incorporates a memory mechanism that records the agent's task execution history. By analyzing this history, the agent identifies repetitive action sequences and evolves high-level actions that act as shortcuts, replacing these low-level operations and improving efficiency. This allows the agent to focus on tasks requiring more complex reasoning, while simplifying routine actions. Experimental results on multiple benchmark tasks demonstrate that our approach significantly outperforms existing methods in both efficiency and accuracy. The code will be open-sourced to support further research.","authors":["Wenjia Jiang","Yangyang Zhuang","Chenxi Song","Xu Yang","Joey Tianyi Zhou","Chi Zhang"],"url":"https://arxiv.org/abs/2503.02268"}
{"created":"2025-04-17","title":"Opinion: Revisiting synthetic data classifications from a privacy perspective","abstract":"Synthetic data is emerging as a cost-effective solution necessary to meet the increasing data demands of AI development, created either from existing knowledge or derived from real data. The traditional classification of synthetic data types into hybrid, partial or fully synthetic datasets has limited value and does not reflect the ever-increasing methods to generate synthetic data. The generation method and their source jointly shape the characteristics of synthetic data, which in turn determines its practical applications. We make a case for an alternative approach to grouping synthetic data types that better reflect privacy perspectives in order to facilitate regulatory guidance in the generation and processing of synthetic data. This approach to classification provides flexibility to new advancements like deep generative methods and offers a more practical framework for future applications.","authors":["Vibeke Binz Vallevik","Serena Elizabeth Marshall","Aleksandar Babic","Jan Franz Nygaard"],"url":"https://arxiv.org/abs/2503.03506"}
{"created":"2025-04-17","title":"Bounded Exhaustive Random Program Generation for Testing Solidity Compilers and Analyzers","abstract":"Random program generators often exhibit opportunism: they generate programs without a specific focus within the vast search space defined by the programming language. This opportunistic behavior hinders the effective generation of programs that trigger bugs in compilers and analyzers, even when such programs closely resemble those generated. To address this limitation, we propose bounded exhaustive random program generation, a novel method that focuses the search space of program generation with the aim of more quickly identifying bug-triggering programs. Our approach comprises two stages: 1) generating random program templates, which are incomplete test programs containing bug-related placeholders, and 2) conducting a bounded exhaustive enumeration of valid values for each placeholder within these templates. To ensure efficiency, we maintain a solvable constraint set during the template generation phase and then methodically explore all possible values of placeholders within these constraints during the exhaustive enumeration phase. We have implemented this approach for Solidity, a popular smart contract language for the Ethereum blockchain, in a tool named Erwin. Based on a recent study of Solidity compiler bugs, the placeholders used by Erwin relate to language features commonly associated with compiler bugs. Erwin has successfully identified 23 previously unknown bugs across two Solidity compilers, solc and solang, and one Solidity static analyzer, slither. Evaluation results demonstrate that Erwin outperforms state-of-the-art Solidity fuzzers in bug detection and complements developer-written test suites by covering 4,582 edges and 14,737 lines of the solc compiler that were missed by solc unit tests.","authors":["Haoyang Ma","Alastair F. Donaldson","Qingchao Shen","Yongqiang Tian","Junjie Chen","Shing-Chi Cheung"],"url":"https://arxiv.org/abs/2503.20332"}
{"created":"2025-04-17","title":"Frequency-Aware Attention-LSTM for PM$_{2.5}$ Time Series Forecasting","abstract":"To enhance the accuracy and robustness of PM$_{2.5}$ concentration forecasting, this paper introduces FALNet, a Frequency-Aware LSTM Network that integrates frequency-domain decomposition, temporal modeling, and attention-based refinement. The model first applies STL and FFT to extract trend, seasonal, and denoised residual components, effectively filtering out high-frequency noise. The filtered residuals are then fed into a stacked LSTM to capture long-term dependencies, followed by a multi-head attention mechanism that dynamically focuses on key time steps. Experiments conducted on real-world urban air quality datasets demonstrate that FALNet consistently outperforms conventional models across standard metrics such as MAE, RMSE, and $R^2$. The model shows strong adaptability in capturing sharp fluctuations during pollution peaks and non-stationary conditions. These results validate the effectiveness and generalizability of FALNet for real-time air pollution prediction, environmental risk assessment, and decision-making support.","authors":["Jiahui Lu","Shuang Wu","Zhenkai Qin","Guifang Yang"],"url":"https://arxiv.org/abs/2503.24043"}
{"created":"2025-04-17","title":"Do \"New Snow Tablets\" Contain Snow? Large Language Models Over-Rely on Names to Identify Ingredients of Chinese Drugs","abstract":"Traditional Chinese Medicine (TCM) has seen increasing adoption in healthcare, with specialized Large Language Models (LLMs) emerging to support clinical applications. A fundamental requirement for these models is accurate identification of TCM drug ingredients. In this paper, we evaluate how general and TCM-specialized LLMs perform when identifying ingredients of Chinese drugs. Our systematic analysis reveals consistent failure patterns: models often interpret drug names literally, overuse common herbs regardless of relevance, and exhibit erratic behaviors when faced with unfamiliar formulations. LLMs also fail to understand the verification task. These findings demonstrate that current LLMs rely primarily on drug names rather than possessing systematic pharmacological knowledge. To address these limitations, we propose a Retrieval Augmented Generation (RAG) approach focused on ingredient names. Experiments across 220 TCM formulations show our method significantly improves accuracy from approximately 50% to 82% in ingredient verification tasks. Our work highlights critical weaknesses in current TCM-specific LLMs and offers a practical solution for enhancing their clinical reliability.","authors":["Sifan Li","Yujun Cai","Bryan Hooi","Nanyun Peng","Yiwei Wang"],"url":"https://arxiv.org/abs/2504.03786"}
{"created":"2025-04-17","title":"How Relevance Emerges: Interpreting LoRA Fine-Tuning in Reranking LLMs","abstract":"We conduct a behavioral exploration of LoRA fine-tuned LLMs for Passage Reranking to understand how relevance signals are learned and deployed by Large Language Models. By fine-tuning Mistral-7B, LLaMA3.1-8B, and Pythia-6.9B on MS MARCO under diverse LoRA configurations, we investigate how relevance modeling evolves across checkpoints, the impact of LoRA rank (1, 2, 8, 32), and the relative importance of updated MHA vs. MLP components. Our ablations reveal which layers and projections within LoRA transformations are most critical for reranking accuracy. These findings offer fresh explanations into LoRA's adaptation mechanisms, setting the stage for deeper mechanistic studies in Information Retrieval. All models used in this study have been shared.","authors":["Atharva Nijasure","Tanya Chowdhury","James Allan"],"url":"https://arxiv.org/abs/2504.08780"}
{"created":"2025-04-17","title":"Can Large Language Models Become Policy Refinement Partners? Evidence from China's Social Security Studies","abstract":"The rapid development of large language models (LLMs) is reshaping operational paradigms across multidisciplinary domains. LLMs' emergent capability to synthesize policy-relevant insights across disciplinary boundaries suggests potential as decision-support tools. However, their actual performance and suitability as policy refinement partners still require verification through rigorous and systematic evaluations. Our study employs the context-embedded generation-adaptation framework to conduct a tripartite comparison among the American GPT-4o, the Chinese DeepSeek-R1 and human researchers, investigating the capability boundaries and performance characteristics of LLMs in generating policy recommendations for China's social security issues. This study demonstrates that while LLMs exhibit distinct advantages in systematic policy design, they face significant limitations in addressing complex social dynamics, balancing stakeholder interests, and controlling fiscal risks within the social security domain. Furthermore, DeepSeek-R1 demonstrates superior performance to GPT-4o across all evaluation dimensions in policy recommendation generation, illustrating the potential of localized training to improve contextual alignment. These findings suggest that regionally-adapted LLMs can function as supplementary tools for generating diverse policy alternatives informed by domain-specific social insights. Nevertheless, the formulation of policy refinement requires integration with human researchers' expertise, which remains critical for interpreting institutional frameworks, cultural norms, and value systems.","authors":["Ke Jinghan","Zhou Zheng","Zhao Yuxuan"],"url":"https://arxiv.org/abs/2504.09137"}
{"created":"2025-04-17","title":"EchoMask: Speech-Queried Attention-based Mask Modeling for Holistic Co-Speech Motion Generation","abstract":"Masked modeling framework has shown promise in co-speech motion generation. However, it struggles to identify semantically significant frames for effective motion masking. In this work, we propose a speech-queried attention-based mask modeling framework for co-speech motion generation. Our key insight is to leverage motion-aligned speech features to guide the masked motion modeling process, selectively masking rhythm-related and semantically expressive motion frames. Specifically, we first propose a motion-audio alignment module (MAM) to construct a latent motion-audio joint space. In this space, both low-level and high-level speech features are projected, enabling motion-aligned speech representation using learnable speech queries. Then, a speech-queried attention mechanism (SQA) is introduced to compute frame-level attention scores through interactions between motion keys and speech queries, guiding selective masking toward motion frames with high attention scores. Finally, the motion-aligned speech features are also injected into the generation network to facilitate co-speech motion generation. Qualitative and quantitative evaluations confirm that our method outperforms existing state-of-the-art approaches, successfully producing high-quality co-speech motion.","authors":["Xiangyue Zhang","Jianfang Li","Jiaxu Zhang","Jianqiang Ren","Liefeng Bo","Zhigang Tu"],"url":"https://arxiv.org/abs/2504.09209"}
{"created":"2025-04-17","title":"FairACE: Achieving Degree Fairness in Graph Neural Networks via Contrastive and Adversarial Group-Balanced Training","abstract":"Fairness has been a significant challenge in graph neural networks (GNNs) since degree biases often result in un-equal prediction performance among nodes with varying degrees. Existing GNN models focus on prediction accuracy, frequently overlooking fairness across different degree groups. To addressthis issue, we propose a novel GNN framework, namely Fairness- Aware Asymmetric Contrastive Ensemble (FairACE), which inte-grates asymmetric contrastive learning with adversarial training to improve degree fairness. FairACE captures one-hop local neighborhood information and two-hop monophily similarity to create fairer node representations and employs a degree fairness regulator to balance performance between high-degree and low-degree nodes. During model training, a novel group-balanced fairness loss is proposed to minimize classification disparities across degree groups. In addition, we also propose a novel fairness metric, the Accuracy Distribution Gap (ADG), which can quantitatively assess and ensure equitable performance across different degree-based node groups. Experimental results on both synthetic and real-world datasets demonstrate that FairACE significantly improves degree fairness metrics while maintaining competitive accuracy in comparison to the state-of-the-art GNN models.","authors":["Jiaxin Liu","Xiaoqian Jiang","Xiang Li","Bohan Zhang","Jing Zhang"],"url":"https://arxiv.org/abs/2504.09210"}
{"created":"2025-04-17","title":"Can you map it to English? The Role of Cross-Lingual Alignment in Multilingual Performance of LLMs","abstract":"Large language models (LLMs) pre-trained predominantly on English text exhibit surprising multilingual capabilities, yet the mechanisms driving cross-lingual generalization remain poorly understood. This work investigates how the alignment of representations for text written in different languages correlates with LLM performance on natural language understanding tasks and translation tasks, both at the language and the instance level. For this purpose, we introduce cross-lingual alignment metrics such as the Discriminative Alignment Index (DALI) to quantify the alignment at an instance level for discriminative tasks. Through experiments on three natural language understanding tasks (Belebele, XStoryCloze, XCOPA), and machine translation, we find that while cross-lingual alignment metrics strongly correlate with task accuracy at the language level, the sample-level alignment often fails to distinguish correct from incorrect predictions, exposing alignment as a necessary but insufficient condition for success.","authors":["Kartik Ravisankar","Hyojung Han","Marine Carpuat"],"url":"https://arxiv.org/abs/2504.09378"}
{"created":"2025-04-17","title":"ClinicalGPT-R1: Pushing reasoning capability of generalist disease diagnosis with large language model","abstract":"Recent advances in reasoning with large language models (LLMs)has shown remarkable reasoning capabilities in domains such as mathematics and coding, yet their application to clinical diagnosis remains underexplored. Here, we introduce ClinicalGPT-R1, a reasoning enhanced generalist large language model for disease diagnosis. Trained on a dataset of 20,000 real-world clinical records, ClinicalGPT-R1 leverages diverse training strategies to enhance diagnostic reasoning. To benchmark performance, we curated MedBench-Hard, a challenging dataset spanning seven major medical specialties and representative diseases. Experimental results demonstrate that ClinicalGPT-R1 outperforms GPT-4o in Chinese diagnostic tasks and achieves comparable performance to GPT-4 in English settings. This comparative study effectively validates the superior performance of ClinicalGPT-R1 in disease diagnosis tasks. Resources are available at https://github.com/medfound/medfound.","authors":["Wuyang Lan","Wenzheng Wang","Changwei Ji","Guoxing Yang","Yongbo Zhang","Xiaohong Liu","Song Wu","Guangyu Wang"],"url":"https://arxiv.org/abs/2504.09421"}
{"created":"2025-04-17","title":"Cartographers in Cubicles: How Training and Preferences of Mapmakers Interplay with Structures and Norms in Not-for-Profit Organizations","abstract":"Choropleth maps are a common and effective way to visualize geographic thematic data. Although cartographers have established many principles about map design, data binning and color usage, less is known about how mapmakers make individual decisions in practice. We interview 16 cartographers and geographic information systems (GIS) experts from 13 government organizations, NGOs, and federal agencies about their choropleth mapmaking decisions and workflows. We categorize our findings and report on how mapmakers follow cartographic guidelines and personal rules of thumb, collaborate with other stakeholders within and outside their organization, and how organizational structures and norms are tied to decision-making during data preparation, data analysis, data binning, map styling, and map post-processing. We find several points of variation as well as regularity across mapmakers and organizations and present takeaways to inform cartographic education and practice, including broader implications and opportunities for CSCW, HCI, and information visualization researchers and practitioners.","authors":["Arpit Narechania","Alex Endert","Clio Andris"],"url":"https://arxiv.org/abs/2504.09438"}
{"created":"2025-04-17","title":"RoboComm: A DID-based scalable and privacy-preserving Robot-to-Robot interaction over state channels","abstract":"In a multi robot system establishing trust amongst untrusted robots from different organisations while preserving a robot's privacy is a challenge. Recently decentralized technologies such as smart contract and blockchain are being explored for applications in robotics. However, the limited transaction processing and high maintenance cost hinder the widespread adoption of such approaches. Moreover, blockchain transactions be they on public or private permissioned blockchain are publically readable which further fails to preserve the confidentiality of the robot's data and privacy of the robot.","authors":["Roshan Singh","Sushant Pandey"],"url":"https://arxiv.org/abs/2504.09517"}
{"created":"2025-04-17","title":"A Systematic Literature Review of Infrastructure Studies in SIGCHI","abstract":"Infrastructure is an indispensable part of human life. Over the past decades, the Human-Computer Interaction (HCI) community has paid increasing attention to human interactions with infrastructure. In this paper, we conducted a systematic literature review on infrastructure studies in SIGCHI, one of the most influential communities in HCI. We collected a total of 190 primary studies, covering works published between 2006 and 2024. Most of these studies are inspired by Susan Leigh Star's notion of infrastructure. We identify three major themes in infrastructure studies: growing infrastructure, appropriating infrastructure, and coping with infrastructure. Our review highlights a prevailing trend in SIGCHI's infrastructure research: a focus on informal infrastructural activities across various sociotechnical contexts. In particular, we examine studies that problematize infrastructure and alert the HCI community to its potentially harmful aspects.","authors":["Yao Lyu","Jie Cai","John M. Carroll"],"url":"https://arxiv.org/abs/2504.09612"}
{"created":"2025-04-17","title":"Redesign of Online Design Communities: Facilitating Personalized Visual Design Learning with Structured Comments","abstract":"Online Design Communities (ODCs) offer various artworks with members' comments for beginners to learn visual design. However, as identified by our Formative Study (N = 10), current ODCs lack features customized for personal learning purposes, e.g., searching artworks and digesting useful comments to learn design principles about buttons. In this paper, we present DesignLearner, a redesigned interface of ODCs to facilitate personalized visual design learning with comments structured based on UI components (e.g., button, text) and visual elements (e.g., color, contrast). In DesignLearner, learners can specify the UI components and visual elements that they wish to learn to filter artworks and associated comments. They can interactively read comments on an artwork, take notes, and get suggestions for the next artworks to explore. Our between-subjects study (N = 24) indicates that compared to a traditional ODC interface, DesignLearner can improve the user learning outcome and is deemed significantly more useful. We conclude with design considerations for customizing the interface of online communities to satisfy users' learning needs.","authors":["Xia Chen","Xinyue Chen","Weixian Hu","Haojia Zheng","YuJun Qian","Zhenhui Peng"],"url":"https://arxiv.org/abs/2504.09827"}
{"created":"2025-04-17","title":"TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models","abstract":"Multimodal Large Language Models (MLLMs) have shown remarkable versatility in understanding diverse multimodal data and tasks. However, these capabilities come with an increased model scale. While post-training pruning reduces model size in unimodal models, its application to MLLMs often yields limited success. Our analysis discovers that conventional methods fail to account for the unique token attributes across layers and modalities inherent to MLLMs. Inspired by this observation, we propose TAMP, a simple yet effective pruning framework tailored for MLLMs, featuring two key components: (1) Diversity-Aware Sparsity, which adjusts sparsity ratio per layer based on diversities among multimodal output tokens, preserving more parameters in high-diversity layers; and (2) Adaptive Multimodal Input Activation, which identifies representative multimodal input tokens using attention scores to guide unstructured weight pruning. We validate our method on two state-of-the-art MLLMs: LLaVA-NeXT, designed for vision-language tasks, and VideoLLaMA2, capable of processing audio, visual, and language modalities. Empirical experiments across various multimodal evaluation benchmarks demonstrate that each component of our approach substantially outperforms existing pruning techniques.","authors":["Jaewoo Lee","Keyang Xuan","Chanakya Ekbote","Sandeep Polisetty","Yi R. Fung","Paul Pu Liang"],"url":"https://arxiv.org/abs/2504.09897"}
{"created":"2025-04-17","title":"OctGPT: Octree-based Multiscale Autoregressive Models for 3D Shape Generation","abstract":"Autoregressive models have achieved remarkable success across various domains, yet their performance in 3D shape generation lags significantly behind that of diffusion models. In this paper, we introduce OctGPT, a novel multiscale autoregressive model for 3D shape generation that dramatically improves the efficiency and performance of prior 3D autoregressive approaches, while rivaling or surpassing state-of-the-art diffusion models. Our method employs a serialized octree representation to efficiently capture the hierarchical and spatial structures of 3D shapes. Coarse geometry is encoded via octree structures, while fine-grained details are represented by binary tokens generated using a vector quantized variational autoencoder (VQVAE), transforming 3D shapes into compact multiscale binary sequences suitable for autoregressive prediction. To address the computational challenges of handling long sequences, we incorporate octree-based transformers enhanced with 3D rotary positional encodings, scale-specific embeddings, and token-parallel generation schemes. These innovations reduce training time by 13 folds and generation time by 69 folds, enabling the efficient training of high-resolution 3D shapes, e.g.,$1024^3$, on just four NVIDIA 4090 GPUs only within days. OctGPT showcases exceptional versatility across various tasks, including text-, sketch-, and image-conditioned generation, as well as scene-level synthesis involving multiple objects. Extensive experiments demonstrate that OctGPT accelerates convergence and improves generation quality over prior autoregressive methods, offering a new paradigm for high-quality, scalable 3D content creation. Our code and trained models are available at https://github.com/octree-nn/octgpt.","authors":["Si-Tong Wei","Rui-Huan Wang","Chuan-Zhi Zhou","Baoquan Chen","Peng-Shuai Wang"],"url":"https://arxiv.org/abs/2504.09975"}
{"created":"2025-04-17","title":"GaussVideoDreamer: 3D Scene Generation with Video Diffusion and Inconsistency-Aware Gaussian Splatting","abstract":"Single-image 3D scene reconstruction presents significant challenges due to its inherently ill-posed nature and limited input constraints. Recent advances have explored two promising directions: multiview generative models that train on 3D consistent datasets but struggle with out-of-distribution generalization, and 3D scene inpainting and completion frameworks that suffer from cross-view inconsistency and suboptimal error handling, as they depend exclusively on depth data or 3D smoothness, which ultimately degrades output quality and computational performance. Building upon these approaches, we present GaussVideoDreamer, which advances generative multimedia approaches by bridging the gap between image, video, and 3D generation, integrating their strengths through two key innovations: (1) A progressive video inpainting strategy that harnesses temporal coherence for improved multiview consistency and faster convergence. (2) A 3D Gaussian Splatting consistency mask to guide the video diffusion with 3D consistent multiview evidence. Our pipeline combines three core components: a geometry-aware initialization protocol, Inconsistency-Aware Gaussian Splatting, and a progressive video inpainting strategy. Experimental results demonstrate that our approach achieves 32% higher LLaVA-IQA scores and at least 2x speedup compared to existing methods while maintaining robust performance across diverse scenes.","authors":["Junlin Hao","Peiheng Wang","Haoyang Wang","Xinggong Zhang","Zongming Guo"],"url":"https://arxiv.org/abs/2504.10001"}
{"created":"2025-04-17","title":"Emotional Strain and Frustration in LLM Interactions in Software Engineering","abstract":"Large Language Models (LLMs) are increasingly integrated into various daily tasks in Software Engineering such as coding and requirement elicitation. Despite their various capabilities and constant use, some interactions can lead to unexpected challenges (e.g. hallucinations or verbose answers) and, in turn, cause emotions that develop into frustration. Frustration can negatively impact engineers' productivity and well-being if they escalate into stress and burnout. In this paper, we assess the impact of LLM interactions on software engineers' emotional responses, specifically strains, and identify common causes of frustration when interacting with LLMs at work. Based on 62 survey responses from software engineers in industry and academia across various companies and universities, we found that a majority of our respondents experience frustrations or other related emotions regardless of the nature of their work. Additionally, our results showed that frustration mainly stemmed from issues with correctness and less critical issues such as adaptability to context or specific format. While such issues may not cause frustration in general, artefacts that do not follow certain preferences, standards, or best practices can make the output unusable without extensive modification, causing frustration over time. In addition to the frustration triggers, our study offers guidelines to improve the software engineers' experience, aiming to minimise long-term consequences on mental health.","authors":["Cristina Martinez Montes","Ranim Khojah"],"url":"https://arxiv.org/abs/2504.10050"}
{"created":"2025-04-17","title":"MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation Framework","abstract":"Recent advancements in large language models (LLMs) and multi-modal LLMs have been remarkable. However, these models still rely solely on their parametric knowledge, which limits their ability to generate up-to-date information and increases the risk of producing erroneous content. Retrieval-Augmented Generation (RAG) partially mitigates these challenges by incorporating external data sources, yet the reliance on databases and retrieval systems can introduce irrelevant or inaccurate documents, ultimately undermining both performance and reasoning quality. In this paper, we propose Multi-Modal Knowledge-Based Retrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework that leverages the inherent knowledge boundaries of models to dynamically generate semantic tags for the retrieval process. This strategy enables the joint filtering of retrieved documents, retaining only the most relevant and accurate references. Extensive experiments on knowledge-based visual question-answering tasks demonstrate the efficacy of our approach: on the E-VQA dataset, our method improves performance by +4.2% on the Single-Hop subset and +0.4% on the full dataset, while on the InfoSeek dataset, it achieves gains of +7.8% on the Unseen-Q subset, +8.2% on the Unseen-E subset, and +8.1% on the full dataset. These results highlight significant enhancements in both accuracy and robustness over the current state-of-the-art MLLM and RAG frameworks.","authors":["Zihan Ling","Zhiyao Guo","Yixuan Huang","Yi An","Shuai Xiao","Jinsong Lan","Xiaoyong Zhu","Bo Zheng"],"url":"https://arxiv.org/abs/2504.10074"}
{"created":"2025-04-17","title":"Breaking the Data Barrier -- Building GUI Agents Through Task Generalization","abstract":"Graphical User Interface (GUI) agents offer cross-platform solutions for automating complex digital tasks, with significant potential to transform productivity workflows. However, their performance is often constrained by the scarcity of high-quality trajectory data. To address this limitation, we propose training Vision Language Models (VLMs) on data-rich, reasoning-intensive tasks during a dedicated mid-training stage, and then examine how incorporating these tasks facilitates generalization to GUI planning scenarios. Specifically, we explore a range of tasks with readily available instruction-tuning data, including GUI perception, multimodal reasoning, and textual reasoning. Through extensive experiments across 11 mid-training tasks, we demonstrate that: (1) Task generalization proves highly effective, yielding substantial improvements across most settings. For instance, multimodal mathematical reasoning enhances performance on AndroidWorld by an absolute 6.3%. Remarkably, text-only mathematical data significantly boosts GUI web agent performance, achieving a 5.6% improvement on WebArena and 5.4% improvement on AndroidWorld, underscoring notable cross-modal generalization from text-based to visual domains; (2) Contrary to prior assumptions, GUI perception data - previously considered closely aligned with GUI agent tasks and widely utilized for training - has a comparatively limited impact on final performance; (3) Building on these insights, we identify the most effective mid-training tasks and curate optimized mixture datasets, resulting in absolute performance gains of 8.0% on WebArena and 12.2% on AndroidWorld. Our work provides valuable insights into cross-domain knowledge transfer for GUI agents and offers a practical approach to addressing data scarcity challenges in this emerging field. The code, data and models will be available at https://github.com/hkust-nlp/GUIMid.","authors":["Junlei Zhang","Zichen Ding","Chang Ma","Zijie Chen","Qiushi Sun","Zhenzhong Lan","Junxian He"],"url":"https://arxiv.org/abs/2504.10127"}
{"created":"2025-04-17","title":"WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs","abstract":"Live tracking of wildlife via high-resolution video processing directly onboard drones is widely unexplored and most existing solutions rely on streaming video to ground stations to support navigation. Yet, both autonomous animal-reactive flight control beyond visual line of sight and/or mission-specific individual and behaviour recognition tasks rely to some degree on this capability. In response, we introduce WildLive -- a near real-time animal detection and tracking framework for high-resolution imagery running directly onboard uncrewed aerial vehicles (UAVs). The system performs multi-animal detection and tracking at 17fps+ for HD and 7fps+ on 4K video streams suitable for operation during higher altitude flights to minimise animal disturbance. Our system is optimised for Jetson Orin AGX onboard hardware. It integrates the efficiency of sparse optical flow tracking and mission-specific sampling with device-optimised and proven YOLO-driven object detection and segmentation techniques. Essentially, computational resource is focused onto spatio-temporal regions of high uncertainty to significantly improve UAV processing speeds without domain-specific loss of accuracy. Alongside, we introduce our WildLive dataset, which comprises 200k+ annotated animal instances across 19k+ frames from 4K UAV videos collected at the Ol Pejeta Conservancy in Kenya. All frames contain ground truth bounding boxes, segmentation masks, as well as individual tracklets and tracking point trajectories. We compare our system against current object tracking approaches including OC-SORT, ByteTrack, and SORT. Our materials are available at: https://dat-nguyenvn.github.io/WildLive/","authors":["Nguyen Ngoc Dat","Tom Richardson","Matthew Watson","Kilian Meier","Jenna Kline","Sid Reid","Guy Maalouf","Duncan Hine","Majid Mirmehdi","Tilo Burghardt"],"url":"https://arxiv.org/abs/2504.10165"}
{"created":"2025-04-17","title":"LLaVA-ReID: Selective Multi-image Questioner for Interactive Person Re-Identification","abstract":"Traditional text-based person ReID assumes that person descriptions from witnesses are complete and provided at once. However, in real-world scenarios, such descriptions are often partial or vague. To address this limitation, we introduce a new task called interactive person re-identification (Inter-ReID). Inter-ReID is a dialogue-based retrieval task that iteratively refines initial descriptions through ongoing interactions with the witnesses. To facilitate the study of this new task, we construct a dialogue dataset that incorporates multiple types of questions by decomposing fine-grained attributes of individuals. We further propose LLaVA-ReID, a question model that generates targeted questions based on visual and textual contexts to elicit additional details about the target person. Leveraging a looking-forward strategy, we prioritize the most informative questions as supervision during training. Experimental results on both Inter-ReID and text-based ReID benchmarks demonstrate that LLaVA-ReID significantly outperforms baselines.","authors":["Yiding Lu","Mouxing Yang","Dezhong Peng","Peng Hu","Yijie Lin","Xi Peng"],"url":"https://arxiv.org/abs/2504.10174"}
{"created":"2025-04-17","title":"Differentially Private 2D Human Pose Estimation","abstract":"Human pose estimation (HPE) has become essential in numerous applications including healthcare, activity recognition, and human-computer interaction. However, the privacy implications of processing sensitive visual data present significant deployment barriers in critical domains. While traditional anonymization techniques offer limited protection and often compromise data utility for broader motion analysis, Differential Privacy (DP) provides formal privacy guarantees but typically degrades model performance when applied naively. In this work, we present the first differentially private 2D human pose estimation (2D-HPE) by applying Differentially Private Stochastic Gradient Descent (DP-SGD) to this task. To effectively balance privacy with performance, we adopt Projected DP-SGD (PDP-SGD), which projects the noisy gradients to a low-dimensional subspace. Additionally, we adapt TinyViT, a compact and efficient vision transformer for coordinate classification in HPE, providing a lightweight yet powerful backbone that enhances privacy-preserving deployment feasibility on resource-limited devices. Our approach is particularly valuable for multimedia interpretation tasks, enabling privacy-safe analysis and understanding of human motion across diverse visual media while preserving the semantic meaning required for downstream applications. Comprehensive experiments on the MPII Human Pose Dataset demonstrate significant performance enhancement with PDP-SGD achieving 78.48% PCKh@0.5 at a strict privacy budget ($\\epsilon=0.2$), compared to 63.85% for standard DP-SGD. This work lays foundation for privacy-preserving human pose estimation in real-world, sensitive applications.","authors":["Kaushik Bhargav Sivangi","Idris Zakariyya","Paul Henderson","Fani Deligianni"],"url":"https://arxiv.org/abs/2504.10190"}
{"created":"2025-04-17","title":"A moving horizon estimator for aquifer thermal energy storages","abstract":"Aquifer thermal energy storages (ATES) represent groundwater saturated aquifers that store thermal energy in the form of heated or cooled groundwater. Combining two ATES, one can harness excess thermal energy from summer (heat) and winter (cold) to support the building's heating, ventilation, and air conditioning (HVAC) technology. In general, a dynamic operation of ATES throughout the year is beneficial to avoid using fossil fuel-based HVAC technology and maximize the ``green use'' of ATES. Model predictive control (MPC) with an appropriate system model may become a crucial control approach for ATES systems. Consequently, the MPC model should reflect spatial temperature profiles around ATES' boreholes to predict extracted groundwater temperatures accurately. However, meaningful predictions require the estimation of the current state of the system, as measurements are usually only at the borehole of the ATES. In control, this is often realized by model-based observers. Still, observing the state of an ATES system is non-trivial, since the model is typically hybrid. We show how to exploit the specific structure of the hybrid ATES model and design an easy-to-solve moving horizon estimator based on a quadratic program.","authors":["Johannes van Randenborgh","Moritz Schulze Darup"],"url":"https://arxiv.org/abs/2504.10203"}
{"created":"2025-04-17","title":"Trade-offs in Privacy-Preserving Eye Tracking through Iris Obfuscation: A Benchmarking Study","abstract":"Recent developments in hardware, computer graphics, and AI may soon enable AR/VR head-mounted displays (HMDs) to become everyday devices like smartphones and tablets. Eye trackers within HMDs provide a special opportunity for such setups as it is possible to facilitate gaze-based research and interaction. However, estimating users' gaze information often requires raw eye images and videos that contain iris textures, which are considered a gold standard biometric for user authentication, and this raises privacy concerns. Previous research in the eye-tracking community focused on obfuscating iris textures while keeping utility tasks such as gaze estimation accurate. Despite these attempts, there is no comprehensive benchmark that evaluates state-of-the-art approaches. Considering all, in this paper, we benchmark blurring, noising, downsampling, rubber sheet model, and iris style transfer to obfuscate user identity, and compare their impact on image quality, privacy, utility, and risk of imposter attack on two datasets. We use eye segmentation and gaze estimation as utility tasks, and reduction in iris recognition accuracy as a measure of privacy protection, and false acceptance rate to estimate risk of attack. Our experiments show that canonical image processing methods like blurring and noising cause a marginal impact on deep learning-based tasks. While downsampling, rubber sheet model, and iris style transfer are effective in hiding user identifiers, iris style transfer, with higher computation cost, outperforms others in both utility tasks, and is more resilient against spoof attacks. Our analyses indicate that there is no universal optimal approach to balance privacy, utility, and computation burden. Therefore, we recommend practitioners consider the strengths and weaknesses of each approach, and possible combinations of those to reach an optimal privacy-utility trade-off.","authors":["Mengdi Wang","Efe Bozkir","Enkelejda Kasneci"],"url":"https://arxiv.org/abs/2504.10267"}
{"created":"2025-04-17","title":"Efficient Prompt Tuning for Hierarchical Ingredient Recognition","abstract":"Fine-grained ingredient recognition presents a significant challenge due to the diverse appearances of ingredients, resulting from different cutting and cooking methods. While existing approaches have shown promising results, they still require extensive training costs and focus solely on fine-grained ingredient recognition. In this paper, we address these limitations by introducing an efficient prompt-tuning framework that adapts pretrained visual-language models (VLMs), such as CLIP, to the ingredient recognition task without requiring full model finetuning. Additionally, we introduce three-level ingredient hierarchies to enhance both training performance and evaluation robustness. Specifically, we propose a hierarchical ingredient recognition task, designed to evaluate model performance across different hierarchical levels (e.g., chicken chunks, chicken, meat), capturing recognition capabilities from coarse- to fine-grained categories. Our method leverages hierarchical labels, training prompt-tuned models with both fine-grained and corresponding coarse-grained labels. Experimental results on the VireoFood172 dataset demonstrate the effectiveness of prompt-tuning with hierarchical labels, achieving superior performance. Moreover, the hierarchical ingredient recognition task provides valuable insights into the model's ability to generalize across different levels of ingredient granularity.","authors":["Yinxuan Gui","Bin Zhu","Jingjing Chen","Chong-Wah Ngo"],"url":"https://arxiv.org/abs/2504.10322"}
{"created":"2025-04-17","title":"LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian Splatting for Novel View Synthesis","abstract":"Novel view synthesis (NVS) in low-light scenes remains a significant challenge due to degraded inputs characterized by severe noise, low dynamic range (LDR) and unreliable initialization. While recent NeRF-based approaches have shown promising results, most suffer from high computational costs, and some rely on carefully captured or pre-processed data--such as RAW sensor inputs or multi-exposure sequences--which severely limits their practicality. In contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering with competitive visual fidelity; however, existing 3DGS-based methods struggle with low-light sRGB inputs, resulting in unstable Gaussian initialization and ineffective noise suppression. To address these challenges, we propose LL-Gaussian, a novel framework for 3D reconstruction and enhancement from low-light sRGB images, enabling pseudo normal-light novel view synthesis. Our method introduces three key innovations: 1) an end-to-end Low-Light Gaussian Initialization Module (LLGIM) that leverages dense priors from learning-based MVS approach to generate high-quality initial point clouds; 2) a dual-branch Gaussian decomposition model that disentangles intrinsic scene properties (reflectance and illumination) from transient interference, enabling stable and interpretable optimization; 3) an unsupervised optimization strategy guided by both physical constrains and diffusion prior to jointly steer decomposition and enhancement. Additionally, we contribute a challenging dataset collected in extreme low-light environments and demonstrate the effectiveness of LL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussian achieves up to 2,000 times faster inference and reduces training time to just 2%, while delivering superior reconstruction and rendering quality.","authors":["Hao Sun","Fenggen Yu","Huiyao Xu","Tao Zhang","Changqing Zou"],"url":"https://arxiv.org/abs/2504.10331"}
{"created":"2025-04-17","title":"VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain Knowledge","abstract":"Current multimodal benchmarks often conflate reasoning with domain-specific knowledge, making it difficult to isolate and evaluate general reasoning abilities in non-expert settings. To address this, we introduce VisualPuzzles, a benchmark that targets visual reasoning while deliberately minimizing reliance on specialized knowledge. VisualPuzzles consists of diverse questions spanning five categories: algorithmic, analogical, deductive, inductive, and spatial reasoning. One major source of our questions is manually translated logical reasoning questions from the Chinese Civil Service Examination. Experiments show that VisualPuzzles requires significantly less intensive domain-specific knowledge and more complex reasoning compared to benchmarks like MMMU, enabling us to better evaluate genuine multimodal reasoning. Evaluations show that state-of-the-art multimodal large language models consistently lag behind human performance on VisualPuzzles, and that strong performance on knowledge-intensive benchmarks does not necessarily translate to success on reasoning-focused, knowledge-light tasks. Additionally, reasoning enhancements such as scaling up inference compute (with \"thinking\" modes) yield inconsistent gains across models and task types, and we observe no clear correlation between model size and performance. We also found that models exhibit different reasoning and answering patterns on VisualPuzzles compared to benchmarks with heavier emphasis on knowledge. VisualPuzzles offers a clearer lens through which to evaluate reasoning capabilities beyond factual recall and domain knowledge.","authors":["Yueqi Song","Tianyue Ou","Yibo Kong","Zecheng Li","Graham Neubig","Xiang Yue"],"url":"https://arxiv.org/abs/2504.10342"}
{"created":"2025-04-17","title":"MultiLoKo: a multilingual local knowledge benchmark for LLMs spanning 31 languages","abstract":"We present MultiLoKo, a new benchmark for evaluating multilinguality in LLMs covering 31 languages. MultiLoKo consists of three partitions: a main partition consisting of 500 questions per language, separately sourced to be locally relevant to the specific language, and two translated partitions, containing human-authored translations from 30 non-English languages to English and vice versa. For comparison, we also release corresponding machine-authored translations. The data is equally distributed over two splits: a dev split and a blind, out-of-distribution test split. MultiLoKo can be used to study a variety of questions regarding the multilinguality of LLMs as well as meta-questions about multilingual benchmark creation. We compute MultiLoKo scores for 11 base and chat models marketed to be multilingual and study their average performance, their performance parity across languages, how much their ability to answer questions depends on the question language, and which languages are most difficult. None of the models we studied performs well on MultiLoKo, as indicated by low average scores as well as large differences between the best and worst scoring languages. Furthermore, we find a substantial effect of the question language, indicating sub-optimal knowledge transfer between languages. Lastly, we find that using local vs English-translated data can result in differences more than 20 points for the best performing models, drastically change the estimated difficulty of some languages. For using machines instead of human translations, we find a weaker effect on ordering of language difficulty, a larger difference in model rankings, and a substantial drop in estimated performance for all models.","authors":["Dieuwke Hupkes","Nikolay Bogoychev"],"url":"https://arxiv.org/abs/2504.10356"}
{"created":"2025-04-17","title":"GPS: Distilling Compact Memories via Grid-based Patch Sampling for Efficient Online Class-Incremental Learning","abstract":"Online class-incremental learning aims to enable models to continuously adapt to new classes with limited access to past data, while mitigating catastrophic forgetting. Replay-based methods address this by maintaining a small memory buffer of previous samples, achieving competitive performance. For effective replay under constrained storage, recent approaches leverage distilled data to enhance the informativeness of memory. However, such approaches often involve significant computational overhead due to the use of bi-level optimization. Motivated by these limitations, we introduce Grid-based Patch Sampling (GPS), a lightweight and effective strategy for distilling informative memory samples without relying on a trainable model. GPS generates informative samples by sampling a subset of pixels from the original image, yielding compact low-resolution representations that preserve both semantic content and structural information. During replay, these representations are reassembled to support training and evaluation. Experiments on extensive benchmarks demonstrate that GRS can be seamlessly integrated into existing replay frameworks, leading to 3%-4% improvements in average end accuracy under memory-constrained settings, with limited computational overhead.","authors":["Mingchuan Ma","Yuhao Zhou","Jindi Lv","Yuxin Tian","Dan Si","Shujian Li","Qing Ye","Jiancheng Lv"],"url":"https://arxiv.org/abs/2504.10409"}
{"created":"2025-04-17","title":"Unchecked and Overlooked: Addressing the Checkbox Blind Spot in Large Language Models with CheckboxQA","abstract":"Checkboxes are critical in real-world document processing where the presence or absence of ticks directly informs data extraction and decision-making processes. Yet, despite the strong performance of Large Vision and Language Models across a wide range of tasks, they struggle with interpreting checkable content. This challenge becomes particularly pressing in industries where a single overlooked checkbox may lead to costly regulatory or contractual oversights. To address this gap, we introduce the CheckboxQA dataset, a targeted resource designed to evaluate and improve model performance on checkbox-related tasks. It reveals the limitations of current models and serves as a valuable tool for advancing document comprehension systems, with significant implications for applications in sectors such as legal tech and finance.","authors":["Micha{\\l} Turski","Mateusz Chili\\'nski","{\\L}ukasz Borchmann"],"url":"https://arxiv.org/abs/2504.10419"}
{"created":"2025-04-17","title":"What metric to optimize for suppressing instability in a Vlasov-Poisson system?","abstract":"Stabilizing plasma dynamics is an important task in green energy generation via nuclear fusion. One common strategy is to introduce an external field to prevent the plasma distribution from developing turbulence. However, finding such external fields efficiently remains an open question, even for simplified models such as the Vlasov-Poisson (VP) system. In this work, we leverage two different approaches to build such fields: for the first approach, we use an analytical derivation of the dispersion relation of the VP system to find a range of reasonable fields that can potentially suppress instability, providing a qualitative suggestion. For the second approach, we leverage PDE-constrained optimization to obtain a locally optimal field using different loss functions. As the stability of the system can be characterized in several different ways, the objective functions need to be tailored accordingly. We show, through extensive numerical tests, that objective functions such as the relative entropy (KL divergence) and the $L^{2}$ norm result in a highly non-convex problem, rendering the global minimum difficult to find. However, we show that using the electric energy of the system as a loss function is advantageous, as it has a large convex basin close to the global minimum. Unfortunately, outside the basin, the electric energy landscape consists of unphysical flat local minima, thus rendering a good initial guess key for the overall convergence of the optimization problem, particularly for solvers with adaptive steps.","authors":["Martin Guerra","Qin Li","Yukun Yue"],"url":"https://arxiv.org/abs/2504.10435"}
{"created":"2025-04-17","title":"GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents","abstract":"Existing efforts in building Graphical User Interface (GUI) agents largely rely on the training paradigm of supervised fine-tuning on Large Vision-Language Models (LVLMs). However, this approach not only demands extensive amounts of training data but also struggles to effectively understand GUI screenshots and generalize to unseen interfaces. The issue significantly limits its application in real-world scenarios, especially for high-level tasks. Inspired by Reinforcement Fine-Tuning (RFT) in large reasoning models (e.g., DeepSeek-R1), which efficiently enhances the problem-solving capabilities of large language models in real-world settings, we propose \\name, the first reinforcement learning framework designed to enhance the GUI capabilities of LVLMs in high-level real-world task scenarios, through unified action space rule modeling. By leveraging a small amount of carefully curated high-quality data across multiple platforms (including Windows, Linux, MacOS, Android, and Web) and employing policy optimization algorithms such as Group Relative Policy Optimization (GRPO) to update the model, \\name achieves superior performance using only 0.02\\% of the data (3K vs. 13M) compared to previous state-of-the-art methods like OS-Atlas across eight benchmarks spanning three different platforms (mobile, desktop, and web). These results demonstrate the immense potential of reinforcement learning based on unified action space rule modeling in improving the execution capabilities of LVLMs for real-world GUI agent tasks.","authors":["Xiaobo Xia","Run Luo"],"url":"https://arxiv.org/abs/2504.10458"}
{"created":"2025-04-17","title":"Weight Ensembling Improves Reasoning in Language Models","abstract":"We investigate a failure mode that arises during the training of reasoning models, where the diversity of generations begins to collapse, leading to suboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during supervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a simple intervention of interpolating the weights of the latest SFT checkpoint with an early checkpoint, otherwise known as WiSE-FT, almost completely recovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves better test-time scaling (Best@k, majority vote) and achieves superior results with less data when tuned further by reinforcement learning. Finally, we find that WiSE-FT provides complementary performance gains that cannot be achieved only through diversity-inducing decoding strategies, like temperature scaling. We formalize a bias-variance tradeoff of Pass@k with respect to the expectation and variance of Pass@1 over the test distribution. We find that WiSE-FT can reduce bias and variance simultaneously, while temperature scaling inherently trades-off between bias and variance.","authors":["Xingyu Dang","Christina Baek","Kaiyue Wen","Zico Kolter","Aditi Raghunathan"],"url":"https://arxiv.org/abs/2504.10478"}
{"created":"2025-04-17","title":"InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models","abstract":"We introduce InternVL3, a significant advancement in the InternVL series featuring a native multimodal pre-training paradigm. Rather than adapting a text-only large language model (LLM) into a multimodal large language model (MLLM) that supports visual inputs, InternVL3 jointly acquires multimodal and linguistic capabilities from both diverse multimodal data and pure-text corpora during a single pre-training stage. This unified training paradigm effectively addresses the complexities and alignment challenges commonly encountered in conventional post-hoc training pipelines for MLLMs. To further improve performance and scalability, InternVL3 incorporates variable visual position encoding (V2PE) to support extended multimodal contexts, employs advanced post-training techniques such as supervised fine-tuning (SFT) and mixed preference optimization (MPO), and adopts test-time scaling strategies alongside an optimized training infrastructure. Extensive empirical evaluations demonstrate that InternVL3 delivers superior performance across a wide range of multi-modal tasks. In particular, InternVL3-78B achieves a score of 72.2 on the MMMU benchmark, setting a new state-of-the-art among open-source MLLMs. Its capabilities remain highly competitive with leading proprietary models, including ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro, while also maintaining strong pure-language proficiency. In pursuit of open-science principles, we will publicly release both the training data and model weights to foster further research and development in next-generation MLLMs.","authors":["Jinguo Zhu","Weiyun Wang","Zhe Chen","Zhaoyang Liu","Shenglong Ye","Lixin Gu","Yuchen Duan","Hao Tian","Weijie Su","Jie Shao","Zhangwei Gao","Erfei Cui","Yue Cao","Yangzhou Liu","Xingguang Wei","Hongjie Zhang","Haomin Wang","Weiye Xu","Hao Li","Jiahao Wang","Dengnian Chen","Songze Li","Yinan He","Tan Jiang","Jiapeng Luo","Yi Wang","Conghui He","Botian Shi","Xingcheng Zhang","Wenqi Shao","Junjun He","Yingtong Xiong","Wenwen Qu","Peng Sun","Penglong Jiao","Han Lv","Lijun Wu","Kaipeng Zhang","Huipeng Deng","Jiaye Ge","Kai Chen","Limin Wang","Min Dou","Lewei Lu","Xizhou Zhu","Tong Lu","Dahua Lin","Yu Qiao","Jifeng Dai","Wenhai Wang"],"url":"https://arxiv.org/abs/2504.10479"}
{"created":"2025-04-17","title":"Membership problems in nilpotent groups","abstract":"We study both the Submonoid Membership problem and the Rational Subset Membership problem in finitely generated nilpotent groups. We give two reductions with important applications. First, Submonoid Membership in any nilpotent group can be reduced to Rational Subset Membership in smaller groups. As a corollary, we prove the existence of a group with decidable Submonoid Membership and undecidable Rational Subset Membership, confirming a conjecture of Lohrey and Steinberg. Second, the Rational Subset Membership problem in $H_3(\\mathbb Z)$ can be reduced to the Knapsack problem in the same group, and is therefore decidable. Combining both results, we deduce that the filiform $3$-step nilpotent group has decidable Submonoid Membership.","authors":["Corentin Bodart"],"url":"https://arxiv.org/abs/2401.15504"}
{"created":"2025-04-17","title":"A Piecewise Lyapunov Analysis of Sub-quadratic SGD: Applications to Robust and Quantile Regression","abstract":"Motivated by robust and quantile regression problems, we investigate the stochastic gradient descent (SGD) algorithm for minimizing an objective function $f$ that is locally strongly convex with a sub--quadratic tail. This setting covers many widely used online statistical methods. We introduce a novel piecewise Lyapunov function that enables us to handle functions $f$ with only first-order differentiability, which includes a wide range of popular loss functions such as Huber loss. Leveraging our proposed Lyapunov function, we derive finite-time moment bounds under general diminishing stepsizes, as well as constant stepsizes. We further establish the weak convergence, central limit theorem and bias characterization under constant stepsize, providing the first geometrical convergence result for sub--quadratic SGD. Our results have wide applications, especially in online statistical methods. In particular, we discuss two applications of our results. 1) Online robust regression: We consider a corrupted linear model with sub--exponential covariates and heavy--tailed noise. Our analysis provides convergence rates comparable to those for corrupted models with Gaussian covariates and noise. 2) Online quantile regression: Importantly, our results relax the common assumption in prior work that the conditional density is continuous and provide a more fine-grained analysis for the moment bounds.","authors":["Yixuan Zhang","Dongyan Huo","Yudong Chen","Qiaomin Xie"],"url":"https://arxiv.org/abs/2504.08178"}
{"created":"2025-04-17","title":"Inferring Outcome Means of Exponential Family Distributions Estimated by Deep Neural Networks","abstract":"While deep neural networks (DNNs) are widely used for prediction, inference on DNN-estimated subject-specific means for categorical or exponential family outcomes remains underexplored. We address this by proposing a DNN estimator under generalized nonparametric regression models (GNRMs) and developing a rigorous inference framework. Unlike existing approaches that assume independence between prediction errors and inputs to establish the error bound, a condition often violated in GNRMs, we allow for dependence and our theoretical analysis demonstrates the feasibility of drawing inference under GNRMs. To implement inference, we consider an Ensemble Subsampling Method (ESM) that leverages U-statistics and the Hoeffding decomposition to construct reliable confidence intervals for DNN estimates. We show that, under GNRM settings, ESM enables model-free variance estimation and accounts for heterogeneity among individuals in the population. Through simulations under nonparametric logistic, Poisson, and binomial regression models, we demonstrate the effectiveness and efficiency of our method. We further apply the method to the electronic Intensive Care Unit (eICU) dataset, a large-scale collection of anonymized health records from ICU patients, to predict ICU readmission risk and offer patient-centric insights for clinical decision-making.","authors":["Xuran Meng","Yi Li"],"url":"https://arxiv.org/abs/2504.09347"}
{"created":"2025-04-17","title":"Diversity-Fair Online Selection","abstract":"Online selection problems frequently arise in applications such as crowdsourcing and employee recruitment. Existing research typically focuses on candidates with a single attribute. However, crowdsourcing tasks often require contributions from individuals across various demographics. Further motivated by the dynamic nature of crowdsourcing and hiring, we study the diversity-fair online selection problem, in which a recruiter must make real-time decisions to foster workforce diversity across many dimensions. We propose two scenarios for this problem. The fixed-capacity scenario, suited for short-term hiring for crowdsourced workers, provides the recruiter with a fixed capacity to fill temporary job vacancies. In contrast, in the unknown-capacity scenario, recruiters optimize diversity across recruitment seasons with increasing capacities, reflecting that the firm honors diversity consideration in a long-term employee acquisition strategy. By modeling the diversity over $d$ dimensions as a max-min fairness objective, we show that no policy can surpass a competitive ratio of $O(1/d^{1/3})$ for either scenario, indicating that any achievable result inevitably decays by some polynomial factor in $d$. To this end, we develop bilevel hierarchical randomized policies that ensure compliance with the capacity constraint. For the fixed-capacity scenario, leveraging marginal information about the arriving population allows us to achieve a competitive ratio of $1/(4\\sqrt{d} \\lceil \\log_2 d \\rceil)$. For the unknown-capacity scenario, we establish a competitive ratio of $\\Omega(1/d^{3/4})$ under mild boundedness conditions. In both bilevel hierarchical policies, the higher level determines ex-ante selection probabilities and then informs the lower level's randomized selection that ensures no loss in efficiency. Both policies prioritize core diversity and then adjust for underrepresented dimensions.","authors":["Ming Hu","Yanzhi Li","Tongwen Wu"],"url":"https://arxiv.org/abs/2504.10389"}
