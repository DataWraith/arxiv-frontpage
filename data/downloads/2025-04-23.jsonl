{"created":"2025-04-23","title":"EditLord: Learning Code Transformation Rules for Code Editing","abstract":"Code editing is a foundational task in software development, where its effectiveness depends on whether it introduces desired code property changes without changing the original code's intended functionality. Existing approaches often formulate code editing as an implicit end-to-end task, omitting the fact that code-editing procedures inherently consist of discrete and explicit steps. Thus, they suffer from suboptimal performance and lack of robustness and generalization. We introduce EditLord, a code editing framework that makes the code transformation steps explicit. Our key insight is to employ a language model (LM) as an inductive learner to extract code editing rules from the training code pairs as concise meta-rule sets. Such rule sets will be manifested for each training sample to augment them for finetuning or assist in prompting- and iterative-based code editing. EditLordoutperforms the state-of-the-art by an average of 22.7% in editing performance and 58.1% in robustness while achieving 20.2% higher functional correctness across critical software engineering and security applications, LM models, and editing modes.","authors":["Weichen Li","Albert Jan","Baishakhi Ray","Chengzhi Mao","Junfeng Yang","Kexin Pei"],"url":"https://arxiv.org/abs/2504.15284"}
{"created":"2025-04-23","title":"CUBETESTERAI: Automated JUnit Test Generation using the LLaMA Model","abstract":"This paper presents an approach to automating JUnit test generation for Java applications using the Spring Boot framework, leveraging the LLaMA (Large Language Model Architecture) model to enhance the efficiency and accuracy of the testing process. The resulting tool, called CUBETESTERAI, includes a user-friendly web interface and the integration of a CI/CD pipeline using GitLab and Docker. These components streamline the automated test generation process, allowing developers to generate JUnit tests directly from their code snippets with minimal manual intervention. The final implementation executes the LLaMA models through RunPod, an online GPU service, which also enhances the privacy of our tool. Using the advanced natural language processing capabilities of the LLaMA model, CUBETESTERAI is able to generate test cases that provide high code coverage and accurate validation of software functionalities in Java-based Spring Boot applications. Furthermore, it efficiently manages resource-intensive operations and refines the generated tests to address common issues like missing imports and handling of private methods. By comparing CUBETESTERAI with some state-of-the-art tools, we show that our proposal consistently demonstrates competitive and, in many cases, better performance in terms of code coverage in different real-life Java programs.","authors":["Daniele Gorla","Shivam Kumar","Pietro Nicolaus Roselli Lorenzini","Alireza Alipourfaz"],"url":"https://arxiv.org/abs/2504.15286"}
{"created":"2025-04-23","title":"Range Counting Oracles for Geometric Problems","abstract":"In this paper, we study estimators for geometric optimization problems in the sublinear geometric model. In this model, we have oracle access to a point set with size $n$ in a discrete space $[\\Delta]^d$, where queries can be made to an oracle that responds to orthogonal range counting requests. The query complexity of an optimization problem is measured by the number of oracle queries required to compute an estimator for the problem. We investigate two problems in this framework, the Euclidean Minimum Spanning Tree (MST) and Earth Mover Distance (EMD). For EMD, we show the existence of an estimator that approximates the cost of EMD with $O(\\log \\Delta)$-relative error and $O(\\frac{n\\Delta}{s^{1+1/d}})$-additive error using $O(s\\polylog \\Delta)$ range counting queries for any parameter $s$ with $1\\leq s \\leq n$. Moreover, we prove that this bound is tight. For MST, we demonstrate that the weight of MST can be estimated within a factor of $(1 \\pm \\eps)$ using $\\tilde{O}(\\sqrt{n})$ range counting queries.","authors":["Anne Driemel","Morteza Monemizadeh","Eunjin Oh","Frank Staals","David P. Woodruff"],"url":"https://arxiv.org/abs/2504.15292"}
{"created":"2025-04-23","title":"Revisiting Computational Storage for Data Integrity and Security","abstract":"The idea of computational storage device (CSD) has come a long way since at least 1990s [1], [2]. By embedding computing resources within storage devices, CSDs could potentially offload computational tasks from CPUs and enable near-data processing (NDP), reducing data movements and/or energy consumption significantly. While the initial hard-disk-based CSDs suffer from severe limitations in terms of on-drive resources, programmability, etc., the storage market has witnessed the commercialization of solid-state-drive (SSD) based CSDs (e.g., Samsung SmartSSD [3], ScaleFlux CSDs [4]) recently, which has enabled CSD-based optimizations for avariety of application scenarios (e.g., [5], [6], [7]).","authors":["Chao Shi","Anthony Manschula","Tabassum Mahmud","Zeren Yang","Mai Zheng","Yong Chen","Jim Wayda","Matthew Wolf","Byungwoo Bang"],"url":"https://arxiv.org/abs/2504.15293"}
{"created":"2025-04-23","title":"Determining Implication of Fixed Matrix Prenex Normal Forms Can Be Decided in Linear Time","abstract":"For a fixed arbitrary matrix depending on $n$ variables, one may ask whether a Prenex Normal Form (PNF) implies another. A RAM algorithm running in linear time is presented and shown to be asymptotically optimal.","authors":["Adam Wang"],"url":"https://arxiv.org/abs/2504.15294"}
{"created":"2025-04-23","title":"High-Efficiency Split Computing for Cooperative Edge Systems: A Novel Compressed Sensing Bottleneck","abstract":"The advent of big data and AI has precipitated a demand for computational frameworks that ensure real-time performance, accuracy, and privacy. While edge computing mitigates latency and privacy concerns, its scalability is constrained by the resources of edge devices, thus prompting the adoption of split computing (SC) addresses these limitations. However, SC faces challenges in (1) efficient data transmission under bandwidth constraints and (2) balancing accuracy with real-time performance. To tackle these challenges, we propose a novel split computing architecture inspired by compressed sensing (CS) theory. At its core is the High-Efficiency Compressed Sensing Bottleneck (HECS-B), which incorporates an efficient compressed sensing autoencoder into the shallow layer of a deep neural network (DNN) to create a bottleneck layer using the knowledge distillation method. This bottleneck splits the DNN into a distributed model while efficiently compressing intermediate feature data, preserving critical information for seamless reconstruction in the cloud.","authors":["Hailin Zhong","Donglong Chen"],"url":"https://arxiv.org/abs/2504.15295"}
{"created":"2025-04-23","title":"Scalability Optimization in Cloud-Based AI Inference Services: Strategies for Real-Time Load Balancing and Automated Scaling","abstract":"The rapid expansion of AI inference services in the cloud necessitates a robust scalability solution to manage dynamic workloads and maintain high performance. This study proposes a comprehensive scalability optimization framework for cloud AI inference services, focusing on real-time load balancing and autoscaling strategies. The proposed model is a hybrid approach that combines reinforcement learning for adaptive load distribution and deep neural networks for accurate demand forecasting. This multi-layered approach enables the system to anticipate workload fluctuations and proactively adjust resources, ensuring maximum resource utilisation and minimising latency. Furthermore, the incorporation of a decentralised decision-making process within the model serves to enhance fault tolerance and reduce response time in scaling operations. Experimental results demonstrate that the proposed model enhances load balancing efficiency by 35\\ and reduces response delay by 28\\, thereby exhibiting a substantial optimization effect in comparison with conventional scalability solutions.","authors":["Yihong Jin","Ze Yang"],"url":"https://arxiv.org/abs/2504.15296"}
{"created":"2025-04-23","title":"Diffusion Models on the Edge: Challenges, Optimizations, and Applications","abstract":"Diffusion models have shown remarkable capabilities in generating high-fidelity data across modalities such as images, audio, and video. However, their computational intensity makes deployment on edge devices a significant challenge. This survey explores the foundational concepts of diffusion models, identifies key constraints of edge platforms, and synthesizes recent advancements in model compression, sampling efficiency, and hardware-software co-design to make diffusion models viable on edge devices. We also review promising applications and suggest future research directions.","authors":["Dongqi Zheng"],"url":"https://arxiv.org/abs/2504.15298"}
{"created":"2025-04-23","title":"D$^{2}$MoE: Dual Routing and Dynamic Scheduling for Efficient On-Device MoE-based LLM Serving","abstract":"The mixture of experts (MoE) model is a sparse variant of large language models (LLMs), designed to hold a better balance between intelligent capability and computational overhead. Despite its benefits, MoE is still too expensive to deploy on resource-constrained edge devices, especially with the demands of on-device inference services. Recent research efforts often apply model compression techniques, such as quantization, pruning and merging, to restrict MoE complexity. Unfortunately, due to their predefined static model optimization strategies, they cannot always achieve the desired quality-overhead trade-off when handling multiple requests, finally degrading the on-device quality of service. These limitations motivate us to propose the D$^2$MoE, an algorithm-system co-design framework that matches diverse task requirements by dynamically allocating the most proper bit-width to each expert. Specifically, inspired by the nested structure of matryoshka dolls, we propose the matryoshka weight quantization (MWQ) to progressively compress expert weights in a bit-nested manner and reduce the required runtime memory. On top of it, we further optimize the I/O-computation pipeline and design a heuristic scheduling algorithm following our hottest-expert-bit-first (HEBF) principle, which maximizes the expert parallelism between I/O and computation queue under constrained memory budgets, thus significantly reducing the idle temporal bubbles waiting for the experts to load. Evaluations on real edge devices show that D$^2$MoE improves the overall inference throughput by up to 1.39$\\times$ and reduces the peak memory footprint by up to 53% over the latest on-device inference frameworks, while still preserving comparable serving accuracy as its INT8 counterparts.","authors":["Haodong Wang","Qihua Zhou","Zicong Hong","Song Guo"],"url":"https://arxiv.org/abs/2504.15299"}
{"created":"2025-04-23","title":"Collaborative Learning of On-Device Small Model and Cloud-Based Large Model: Advances and Future Directions","abstract":"The conventional cloud-based large model learning framework is increasingly constrained by latency, cost, personalization, and privacy concerns. In this survey, we explore an emerging paradigm: collaborative learning between on-device small model and cloud-based large model, which promises low-latency, cost-efficient, and personalized intelligent services while preserving user privacy. We provide a comprehensive review across hardware, system, algorithm, and application layers. At each layer, we summarize key problems and recent advances from both academia and industry. In particular, we categorize collaboration algorithms into data-based, feature-based, and parameter-based frameworks. We also review publicly available datasets and evaluation metrics with user-level or device-level consideration tailored to collaborative learning settings. We further highlight real-world deployments, ranging from recommender systems and mobile livestreaming to personal intelligent assistants. We finally point out open research directions to guide future development in this rapidly evolving field.","authors":["Chaoyue Niu","Yucheng Ding","Junhui Lu","Zhengxiang Huang","Hang Zeng","Yutong Dai","Xuezhen Tu","Chengfei Lv","Fan Wu","Guihai Chen"],"url":"https://arxiv.org/abs/2504.15300"}
{"created":"2025-04-23","title":"A biologically Inspired Trust Model for Open Multi-Agent Systems that is Resilient to Rapid Performance Fluctuations","abstract":"Trust management provides an alternative solution for securing open, dynamic, and distributed multi-agent systems, where conventional cryptographic methods prove to be impractical. However, existing trust models face challenges related to agent mobility, changing behaviors, and the cold start problem. To address these issues we introduced a biologically inspired trust model in which trustees assess their own capabilities and store trust data locally. This design improves mobility support, reduces communication overhead, resists disinformation, and preserves privacy. Despite these advantages, prior evaluations revealed limitations of our model in adapting to provider population changes and continuous performance fluctuations. This study proposes a novel algorithm, incorporating a self-classification mechanism for providers to detect performance drops potentially harmful for the service consumers. Simulation results demonstrate that the new algorithm outperforms its original version and FIRE, a well-known trust and reputation model, particularly in handling dynamic trustee behavior. While FIRE remains competitive under extreme environmental changes, the proposed algorithm demonstrates greater adaptability across various conditions. In contrast to existing trust modeling research, this study conducts a comprehensive evaluation of our model using widely recognized trust model criteria, assessing its resilience against common trust-related attacks while identifying strengths, weaknesses, and potential countermeasures. Finally, several key directions for future research are proposed.","authors":["Zoi Lygizou","Dimitris Kalles"],"url":"https://arxiv.org/abs/2504.15301"}
{"created":"2025-04-23","title":"RAGDoll: Efficient Offloading-based Online RAG System on a Single GPU","abstract":"Retrieval-Augmented Generation (RAG) enhances large language model (LLM) generation quality by incorporating relevant external knowledge. However, deploying RAG on consumer-grade platforms is challenging due to limited memory and the increasing scale of both models and knowledge bases. In this work, we introduce RAGDoll, a resource-efficient, self-adaptive RAG serving system integrated with LLMs, specifically designed for resource-constrained platforms. RAGDoll exploits the insight that RAG retrieval and LLM generation impose different computational and memory demands, which in a traditional serial workflow result in substantial idle times and poor resource utilization. Based on this insight, RAGDoll decouples retrieval and generation into parallel pipelines, incorporating joint memory placement and dynamic batch scheduling strategies to optimize resource usage across diverse hardware devices and workloads. Extensive experiments demonstrate that RAGDoll adapts effectively to various hardware configurations and LLM scales, achieving up to 3.6 times speedup in average latency compared to serial RAG systems based on vLLM.","authors":["Weiping Yu","Ningyi Liao","Siqiang Luo","Junfeng Liu"],"url":"https://arxiv.org/abs/2504.15302"}
{"created":"2025-04-23","title":"High-Throughput LLM inference on Heterogeneous Clusters","abstract":"Nowadays, many companies possess various types of AI accelerators, forming heterogeneous clusters. Efficiently leveraging these clusters for high-throughput large language model (LLM) inference services can significantly reduce costs and expedite task processing. However, LLM inference on heterogeneous clusters presents two main challenges. Firstly, different deployment configurations can result in vastly different performance. The number of possible configurations is large, and evaluating the effectiveness of a specific setup is complex. Thus, finding an optimal configuration is not an easy task. Secondly, LLM inference instances within a heterogeneous cluster possess varying processing capacities, leading to different processing speeds for handling inference requests. Evaluating these capacities and designing a request scheduling algorithm that fully maximizes the potential of each instance is challenging. In this paper, we propose a high-throughput inference service system on heterogeneous clusters. First, the deployment configuration is optimized by modeling the resource amount and expected throughput and using the exhaustive search method. Second, a novel mechanism is proposed to schedule requests among instances, which fully considers the different processing capabilities of various instances. Extensive experiments show that the proposed scheduler improves throughput by 122.5% and 33.6% on two heterogeneous clusters, respectively.","authors":["Yi Xiong","Jinqi Huang","Wenjie Huang","Xuebing Yu","Entong Li","Zhixiong Ning","Jinhua Zhou","Li Zeng","Xin Chen"],"url":"https://arxiv.org/abs/2504.15303"}
{"created":"2025-04-23","title":"Can Machine Learning Agents Deal with Hard Choices?","abstract":"Machine Learning ML agents have been increasingly used in decision-making across a wide range of tasks and environments. These ML agents are typically designed to balance multiple objectives when making choices. Understanding how their decision-making processes align with or diverge from human reasoning is essential. Human agents often encounter hard choices, that is, situations where options are incommensurable; neither option is preferred, yet the agent is not indifferent between them. In such cases, human agents can identify hard choices and resolve them through deliberation. In contrast, current ML agents, due to fundamental limitations in Multi-Objective Optimisation or MOO methods, cannot identify hard choices, let alone resolve them. Neither Scalarised Optimisation nor Pareto Optimisation, the two principal MOO approaches, can capture incommensurability. This limitation generates three distinct alignment problems: the alienness of ML decision-making behaviour from a human perspective; the unreliability of preference-based alignment strategies for hard choices; and the blockage of alignment strategies pursuing multiple objectives. Evaluating two potential technical solutions, I recommend an ensemble solution that appears most promising for enabling ML agents to identify hard choices and mitigate alignment problems. However, no known technique allows ML agents to resolve hard choices through deliberation, as they cannot autonomously change their goals. This underscores the distinctiveness of human agency and urges ML researchers to reconceptualise machine autonomy and develop frameworks and methods that can better address this fundamental gap.","authors":["Kangyu Wang"],"url":"https://arxiv.org/abs/2504.15304"}
{"created":"2025-04-23","title":"SLAM-Based Navigation and Fault Resilience in a Surveillance Quadcopter with Embedded Vision Systems","abstract":"We present an autonomous aerial surveillance platform, Veg, designed as a fault-tolerant quadcopter system that integrates visual SLAM for GPS-independent navigation, advanced control architecture for dynamic stability, and embedded vision modules for real-time object and face recognition. The platform features a cascaded control design with an LQR inner-loop and PD outer-loop trajectory control. It leverages ORB-SLAM3 for 6-DoF localization and loop closure, and supports waypoint-based navigation through Dijkstra path planning over SLAM-derived maps. A real-time Failure Detection and Identification (FDI) system detects rotor faults and executes emergency landing through re-routing. The embedded vision system, based on a lightweight CNN and PCA, enables onboard object detection and face recognition with high precision. The drone operates fully onboard using a Raspberry Pi 4 and Arduino Nano, validated through simulations and real-world testing. This work consolidates real-time localization, fault recovery, and embedded AI on a single platform suitable for constrained environments.","authors":["Abhishek Tyagi","Charu Gaur"],"url":"https://arxiv.org/abs/2504.15305"}
{"created":"2025-04-23","title":"LLM-Enabled Style and Content Regularization for Personalized Text-to-Image Generation","abstract":"The personalized text-to-image generation has rapidly advanced with the emergence of Stable Diffusion. Existing methods, which typically fine-tune models using embedded identifiers, often struggle with insufficient stylization and inaccurate image content due to reduced textual controllability. In this paper, we propose style refinement and content preservation strategies. The style refinement strategy leverages the semantic information of visual reasoning prompts and reference images to optimize style embeddings, allowing a more precise and consistent representation of style information. The content preservation strategy addresses the content bias problem by preserving the model's generalization capabilities, ensuring enhanced textual controllability without compromising stylization. Experimental results verify that our approach achieves superior performance in generating consistent and personalized text-to-image outputs.","authors":["Anran Yu","Wei Feng","Yaochen Zhang","Xiang Li","Lei Meng","Lei Wu","Xiangxu Meng"],"url":"https://arxiv.org/abs/2504.15309"}
{"created":"2025-04-23","title":"Power Transformer Health Index and Life Span Assessment: A Comprehensive Review of Conventional and Machine Learning based Approaches","abstract":"Power transformers play a critical role within the electrical power system, making their health assessment and the prediction of their remaining lifespan paramount for the purpose of ensuring efficient operation and facilitating effective maintenance planning. This paper undertakes a comprehensive examination of existent literature, with a primary focus on both conventional and cutting-edge techniques employed within this domain. The merits and demerits of recent methodologies and techniques are subjected to meticulous scrutiny and explication. Furthermore, this paper expounds upon intelligent fault diagnosis methodologies and delves into the most widely utilized intelligent algorithms for the assessment of transformer conditions. Diverse Artificial Intelligence (AI) approaches, including Artificial Neural Networks (ANN) and Convolutional Neural Network (CNN), Support Vector Machine (SVM), Random Forest (RF), Genetic Algorithm (GA), and Particle Swarm Optimization (PSO), are elucidated offering pragmatic solutions for enhancing the performance of transformer fault diagnosis. The amalgamation of multiple AI methodologies and the exploration of timeseries analysis further contribute to the augmentation of diagnostic precision and the early detection of faults in transformers. By furnishing a comprehensive panorama of AI applications in the field of transformer fault diagnosis, this study lays the groundwork for future research endeavors and the progression of this critical area of study.","authors":["Syeda Tahreem Zahra","Syed Kashif Imdad","Sohail Khan","Sohail Khalid","Nauman Anwar Baig"],"url":"https://arxiv.org/abs/2504.15310"}
{"created":"2025-04-23","title":"M-TabNet: A Multi-Encoder Transformer Model for Predicting Neonatal Birth Weight from Multimodal Data","abstract":"Birth weight (BW) is a key indicator of neonatal health, with low birth weight (LBW) linked to increased mortality and morbidity. Early prediction of BW enables timely interventions; however, current methods like ultrasonography have limitations, including reduced accuracy before 20 weeks and operator dependent variability. Existing models often neglect nutritional and genetic influences, focusing mainly on physiological and lifestyle factors. This study presents an attention-based transformer model with a multi-encoder architecture for early (less than 12 weeks of gestation) BW prediction. Our model effectively integrates diverse maternal data such as physiological, lifestyle, nutritional, and genetic, addressing limitations seen in prior attention-based models such as TabNet. The model achieves a Mean Absolute Error (MAE) of 122 grams and an R-squared value of 0.94, demonstrating high predictive accuracy and interoperability with our in-house private dataset. Independent validation confirms generalizability (MAE: 105 grams, R-squared: 0.95) with the IEEE children dataset. To enhance clinical utility, predicted BW is classified into low and normal categories, achieving a sensitivity of 97.55% and a specificity of 94.48%, facilitating early risk stratification. Model interpretability is reinforced through feature importance and SHAP analyses, highlighting significant influences of maternal age, tobacco exposure, and vitamin B12 status, with genetic factors playing a secondary role. Our results emphasize the potential of advanced deep-learning models to improve early BW prediction, offering clinicians a robust, interpretable, and personalized tool for identifying pregnancies at risk and optimizing neonatal outcomes.","authors":["Muhammad Mursil","Hatem A. Rashwan","Luis Santos-Calderon","Pere Cavalle-Busquets","Michelle M. Murphy","Domenec Puig"],"url":"https://arxiv.org/abs/2504.15312"}
{"created":"2025-04-23","title":"PolicyEvol-Agent: Evolving Policy via Environment Perception and Self-Awareness with Theory of Mind","abstract":"Multi-agents has exhibited significant intelligence in real-word simulations with Large language models (LLMs) due to the capabilities of social cognition and knowledge retrieval. However, existing research on agents equipped with effective cognition chains including reasoning, planning, decision-making and reflecting remains limited, especially in the dynamically interactive scenarios. In addition, unlike human, prompt-based responses face challenges in psychological state perception and empirical calibration during uncertain gaming process, which can inevitably lead to cognition bias. In light of above, we introduce PolicyEvol-Agent, a comprehensive LLM-empowered framework characterized by systematically acquiring intentions of others and adaptively optimizing irrational strategies for continual enhancement. Specifically, PolicyEvol-Agent first obtains reflective expertise patterns and then integrates a range of cognitive operations with Theory of Mind alongside internal and external perspectives. Simulation results, outperforming RL-based models and agent-based methods, demonstrate the superiority of PolicyEvol-Agent for final gaming victory. Moreover, the policy evolution mechanism reveals the effectiveness of dynamic guideline adjustments in both automatic and human evaluation.","authors":["Yajie Yu","Yue Feng"],"url":"https://arxiv.org/abs/2504.15313"}
{"created":"2025-04-23","title":"Diffusion-Driven Inertial Generated Data for Smartphone Location Classification","abstract":"Despite the crucial role of inertial measurements in motion tracking and navigation systems, the time-consuming and resource-intensive nature of collecting extensive inertial data has hindered the development of robust machine learning models in this field. In recent years, diffusion models have emerged as a revolutionary class of generative models, reshaping the landscape of artificial data generation. These models surpass generative adversarial networks and other state-of-the-art approaches to complex tasks. In this work, we propose diffusion-driven specific force-generated data for smartphone location recognition. We provide a comprehensive evaluation methodology by comparing synthetic and real recorded specific force data across multiple metrics. Our results demonstrate that our diffusion-based generative model successfully captures the distinctive characteristics of specific force signals across different smartphone placement conditions. Thus, by creating diverse, realistic synthetic data, we can reduce the burden of extensive data collection while providing high-quality training data for machine learning models.","authors":["Noa Cohen","Rotem Dror","Itzik Klein"],"url":"https://arxiv.org/abs/2504.15315"}
{"created":"2025-04-23","title":"Efficient and Safe Planner for Automated Driving on Ramps Considering Unsatisfication","abstract":"Automated driving on ramps presents significant challenges due to the need to balance both safety and efficiency during lane changes. This paper proposes an integrated planner for automated vehicles (AVs) on ramps, utilizing an unsatisfactory level metric for efficiency and arrow-cluster-based sampling for safety. The planner identifies optimal times for the AV to change lanes, taking into account the vehicle's velocity as a key factor in efficiency. Additionally, the integrated planner employs arrow-cluster-based sampling to evaluate collision risks and select an optimal lane-changing curve. Extensive simulations were conducted in a ramp scenario to verify the planner's efficient and safe performance. The results demonstrate that the proposed planner can effectively select an appropriate lane-changing time point and a safe lane-changing curve for AVs, without incurring any collisions during the maneuver.","authors":["Qinghao Li","Zhen Tian","Xiaodan Wang","Jinming Yang","Zhihao Lin"],"url":"https://arxiv.org/abs/2504.15320"}
{"created":"2025-04-23","title":"How to systematically develop an effective AI-based bias correction model?","abstract":"This study introduces ReSA-ConvLSTM, an artificial intelligence (AI) framework for systematic bias correction in numerical weather prediction (NWP). We propose three innovations by integrating dynamic climatological normalization, ConvLSTM with temporal causality constraints, and residual self-attention mechanisms. The model establishes a physics-aware nonlinear mapping between ECMWF forecasts and ERA5 reanalysis data. Using 41 years (1981-2021) of global atmospheric data, the framework reduces systematic biases in 2-m air temperature (T2m), 10-m winds (U10/V10), and sea-level pressure (SLP), achieving up to 20% RMSE reduction over 1-7 day forecasts compared to operational ECMWF outputs. The lightweight architecture (10.6M parameters) enables efficient generalization to multiple variables and downstream applications, reducing retraining time by 85% for cross-variable correction while improving ocean model skill through bias-corrected boundary conditions. The ablation experiments demonstrate that our innovations significantly improve the model's correction performance, suggesting that incorporating variable characteristics into the model helps enhance forecasting skills.","authors":["Xiao Zhou","Yuze Sun","Jie Wu","Xiaomeng Huang"],"url":"https://arxiv.org/abs/2504.15322"}
{"created":"2025-04-23","title":"HyperFlow: Gradient-Free Emulation of Few-Shot Fine-Tuning","abstract":"While test-time fine-tuning is beneficial in few-shot learning, the need for multiple backpropagation steps can be prohibitively expensive in real-time or low-resource scenarios. To address this limitation, we propose an approach that emulates gradient descent without computing gradients, enabling efficient test-time adaptation. Specifically, we formulate gradient descent as an Euler discretization of an ordinary differential equation (ODE) and train an auxiliary network to predict the task-conditional drift using only the few-shot support set. The adaptation then reduces to a simple numerical integration (e.g., via the Euler method), which requires only a few forward passes of the auxiliary network -- no gradients or forward passes of the target model are needed. In experiments on cross-domain few-shot classification using the Meta-Dataset and CDFSL benchmarks, our method significantly improves out-of-domain performance over the non-fine-tuned baseline while incurring only 6\\% of the memory cost and 0.02\\% of the computation time of standard fine-tuning, thus establishing a practical middle ground between direct transfer and fully fine-tuned approaches.","authors":["Donggyun Kim","Chanwoo Kim","Seunghoon Hong"],"url":"https://arxiv.org/abs/2504.15323"}
{"created":"2025-04-23","title":"Significativity Indices for Agreement Values","abstract":"Agreement measures, such as Cohen's kappa or intraclass correlation, gauge the matching between two or more classifiers. They are used in a wide range of contexts from medicine, where they evaluate the effectiveness of medical treatments and clinical trials, to artificial intelligence, where they can quantify the approximation due to the reduction of a classifier. The consistency of different classifiers to a golden standard can be compared simply by using the order induced by their agreement measure with respect to the golden standard itself. Nevertheless, labelling an approach as good or bad exclusively by using the value of an agreement measure requires a scale or a significativity index. Some quality scales have been proposed in the literature for Cohen's kappa, but they are mainly naive, and their boundaries are arbitrary. This work proposes a general approach to evaluate the significativity of any agreement value between two classifiers and introduces two significativity indices: one dealing with finite data sets, the other one handling classification probability distributions. Moreover, this manuscript considers the computational issues of evaluating such indices and identifies some efficient algorithms to evaluate them.","authors":["Alberto Casagrande","Francesco Fabris","Rossano Girometti","Roberto Pagliarini"],"url":"https://arxiv.org/abs/2504.15325"}
{"created":"2025-04-23","title":"Advancing Embodied Intelligence in Robotic-Assisted Endovascular Procedures: A Systematic Review of AI Solutions","abstract":"Endovascular procedures have revolutionized the treatment of vascular diseases thanks to minimally invasive solutions that significantly reduce patient recovery time and enhance clinical outcomes. However, the precision and dexterity required during these procedures poses considerable challenges for interventionists. Robotic systems have emerged offering transformative solutions, addressing issues such as operator fatigue, radiation exposure, and the inherent limitations of human precision. The integration of Embodied Intelligence (EI) into these systems signifies a paradigm shift, enabling robots to navigate complex vascular networks and adapt to dynamic physiological conditions. Data-driven approaches, advanced computer vision, medical image analysis, and machine learning techniques, are at the forefront of this evolution. These methods augment procedural intelligence by facilitating real-time vessel segmentation, device tracking, and anatomical landmark detection. Reinforcement learning and imitation learning further refine navigation strategies and replicate experts' techniques. This review systematically examines the integration of EI principles into robotic technologies, in relation to endovascular procedures. We discuss recent advancements in intelligent perception and data-driven control, and their practical applications in robot-assisted endovascular procedures. By critically evaluating current limitations and emerging opportunities, this review establishes a framework for future developments, emphasizing the potential for greater autonomy and improved clinical outcomes. Emerging trends and specific areas of research, such as federated learning for medical data sharing, explainable AI for clinical decision support, and advanced human-robot collaboration paradigms, are also explored, offering insights into the future direction of this rapidly evolving field.","authors":["Tianliang Yao","Bo Lu","Markus Kowarschik","Yixuan Yuan","Hubin Zhao","Sebastien Ourselin","Kaspar Althoefer","Junbo Ge","Peng Qi"],"url":"https://arxiv.org/abs/2504.15327"}
{"created":"2025-04-23","title":"Bayesian Federated Learning for Continual Training","abstract":"Bayesian Federated Learning (BFL) enables uncertainty quantification and robust adaptation in distributed learning. In contrast to the frequentist approach, it estimates the posterior distribution of a global model, offering insights into model reliability. However, current BFL methods neglect continual learning challenges in dynamic environments where data distributions shift over time. We propose a continual BFL framework applied to human sensing with radar data collected over several days. Using Stochastic Gradient Langevin Dynamics (SGLD), our approach sequentially updates the model, leveraging past posteriors to construct the prior for the new tasks. We assess the accuracy, the expected calibration error (ECE) and the convergence speed of our approach against several baselines. Results highlight the effectiveness of continual Bayesian updates in preserving knowledge and adapting to evolving data.","authors":["Usevalad Milasheuski","Luca Barbieri","Sanaz Kianoush","Monica Nicoli","Stefano Savazzi"],"url":"https://arxiv.org/abs/2504.15328"}
{"created":"2025-04-23","title":"Vision6D: 3D-to-2D Interactive Visualization and Annotation Tool for 6D Pose Estimation","abstract":"Accurate 6D pose estimation has gained more attention over the years for robotics-assisted tasks that require precise interaction with physical objects. This paper presents an interactive 3D-to-2D visualization and annotation tool to support the 6D pose estimation research community. To the best of our knowledge, the proposed work is the first tool that allows users to visualize and manipulate 3D objects interactively on a 2D real-world scene, along with a comprehensive user study. This system supports robust 6D camera pose annotation by providing both visual cues and spatial relationships to determine object position and orientation in various environments. The annotation feature in Vision6D is particularly helpful in scenarios where the transformation matrix between the camera and world objects is unknown, as it enables accurate annotation of these objects' poses using only the camera intrinsic matrix. This capability serves as a foundational step in developing and training advanced pose estimation models across various domains. We evaluate Vision6D's effectiveness by utilizing widely-used open-source pose estimation datasets Linemod and HANDAL through comparisons between the default ground-truth camera poses with manual annotations. A user study was performed to show that Vision6D generates accurate pose annotations via visual cues in an intuitive 3D user interface. This approach aims to bridge the gap between 2D scene projections and 3D scenes, offering an effective way for researchers and developers to solve 6D pose annotation related problems. The software is open-source and publicly available at https://github.com/InteractiveGL/vision6D.","authors":["Yike Zhang","Eduardo Davalos","Jack Noble"],"url":"https://arxiv.org/abs/2504.15329"}
{"created":"2025-04-23","title":"Med-CoDE: Medical Critique based Disagreement Evaluation Framework","abstract":"The emergence of large language models (LLMs) has significantly influenced numerous fields, including healthcare, by enhancing the capabilities of automated systems to process and generate human-like text. However, despite their advancements, the reliability and accuracy of LLMs in medical contexts remain critical concerns. Current evaluation methods often lack robustness and fail to provide a comprehensive assessment of LLM performance, leading to potential risks in clinical settings. In this work, we propose Med-CoDE, a specifically designed evaluation framework for medical LLMs to address these challenges. The framework leverages a critique-based approach to quantitatively measure the degree of disagreement between model-generated responses and established medical ground truths. This framework captures both accuracy and reliability in medical settings. The proposed evaluation framework aims to fill the existing gap in LLM assessment by offering a systematic method to evaluate the quality and trustworthiness of medical LLMs. Through extensive experiments and case studies, we illustrate the practicality of our framework in providing a comprehensive and reliable evaluation of medical LLMs.","authors":["Mohit Gupta","Akiko Aizawa","Rajiv Ratn Shah"],"url":"https://arxiv.org/abs/2504.15330"}
{"created":"2025-04-23","title":"Measuring Interest Group Positions on Legislation: An AI-Driven Analysis of Lobbying Reports","abstract":"Special interest groups (SIGs) in the U.S. participate in a range of political activities, such as lobbying and making campaign donations, to influence policy decisions in the legislative and executive branches. The competing interests of these SIGs have profound implications for global issues such as international trade policies, immigration, climate change, and global health challenges. Despite the significance of understanding SIGs' policy positions, empirical challenges in observing them have often led researchers to rely on indirect measurements or focus on a select few SIGs that publicly support or oppose a limited range of legislation. This study introduces the first large-scale effort to directly measure and predict a wide range of bill positions-Support, Oppose, Engage (Amend and Monitor)- across all legislative bills introduced from the 111th to the 117th Congresses. We leverage an advanced AI framework, including large language models (LLMs) and graph neural networks (GNNs), to develop a scalable pipeline that automatically extracts these positions from lobbying activities, resulting in a dataset of 42k bills annotated with 279k bill positions of 12k SIGs. With this large-scale dataset, we reveal (i) a strong correlation between a bill's progression through legislative process stages and the positions taken by interest groups, (ii) a significant relationship between firm size and lobbying positions, (iii) notable distinctions in lobbying position distribution based on bill subject, and (iv) heterogeneity in the distribution of policy preferences across industries. We introduce a novel framework for examining lobbying strategies and offer opportunities to explore how interest groups shape the political landscape.","authors":["Jiseon Kim","Dongkwan Kim","Joohye Jeong","Alice Oh","In Song Kim"],"url":"https://arxiv.org/abs/2504.15333"}
{"created":"2025-04-23","title":"Exploring Compositional Generalization (in ReCOGS_pos) by Transformers using Restricted Access Sequence Processing (RASP)","abstract":"Humans understand new combinations of words encountered if they are combinations of words recognized from different contexts, an ability called Compositional Generalization. The COGS benchmark (Kim and Linzen, 2020) arXiv:2010.05465 reports 0% accuracy for Transformer models on some structural generalizations. We use (Weiss et al., 2021) arXiv:2106.06981's Restricted Access Sequence Processing (RASP), a Transformer-equivalent programming language, to prove by construction that a Transformer encoder-decoder can perform the semantically equivalent ReCOGS_pos (Wu et al., 2024) arXiv:2303.13716 variant of COGS systematically and compositionally: Our RASP model attains 100% semantic exact match on the ReCOGS test set and 100% SEM on all generalization splits except obj_pp_to_subj_pp which gets 92%. Furthermore, our RASP model shows the ReCOGS_pos task does not require a hierarchical or tree-structured solution: we use word-level tokens with an \"embedding\" layer that tags with possible parts of speech, applying just once per encoder pass 19 attention-head compatible flat pattern-matching rules, shown using grammar coverage (Zeller et al., 2023) to be learnable from the training data, plus general prepositional phrase (pp) handling and sentential complement (cp) handling logic, and output the next logical form (LF) token (repeating until the LF is complete). The model does not apply recursive, tree-structured rules like 'np_det pp np -> np_pp -> np', but scores 100% semantic and string exact match on pp recursion, cp recursion using the decoder loop.","authors":["William Bruns"],"url":"https://arxiv.org/abs/2504.15349"}
{"created":"2025-04-23","title":"Randomized Proper Orthogonal Decomposition for data-driven reduced order modeling of a two-layer quasi-geostrophic ocean model","abstract":"The two-layer quasi-geostrophic equations (2QGE) serve as a simplified model for simulating wind-driven, stratified ocean flows. However, their numerical simulation remains computationally expensive due to the need for high-resolution meshes to capture a wide range of turbulent scales. This becomes especially problematic when several simulations need to be run because of, e.g., uncertainty in the parameter settings. To address this challenge, we propose a data-driven reduced order model (ROM) for the 2QGE that leverages randomized proper orthogonal decomposition (rPOD) and long short-term memory (LSTM) networks. To efficiently generate the snapshot data required for model construction, we apply a nonlinear filtering stabilization technique that allows for the use of larger mesh sizes compared to a direct numerical simulations (DNS). Thanks to the use of rPOD to extract the dominant modes from the snapshot matrices, we achieve up to 700 times speedup over the use of deterministic POD. LSTM networks are trained with the modal coefficients associated with the snapshots to enable the prediction of the time- and parameter-dependent modal coefficients during the online phase, which is hundreds of thousands of time faster than a DNS. We assess the accuracy and efficiency of our rPOD-LSTM ROM through an extension of a well-known benchmark called double-gyre wind forcing test. The dimension of the parameter space in this test is increased from two to four.","authors":["Lander Besabe","Michele Girfoglio","Annalisa Quaini","Gianluigi Rozza"],"url":"https://arxiv.org/abs/2504.15350"}
{"created":"2025-04-23","title":"Reliable Classification with Conformal Learning and Interval-Type 2 Fuzzy Sets","abstract":"Classical machine learning classifiers tend to be overconfident can be unreliable outside of the laboratory benchmarks. Properly assessing the reliability of the output of the model per sample is instrumental for real-life scenarios where these systems are deployed. Because of this, different techniques have been employed to properly quantify the quality of prediction for a given model. These are most commonly Bayesian statistics and, more recently, conformal learning. Given a calibration set, conformal learning can produce outputs that are guaranteed to cover the target class with a desired significance level, and are more reliable than the standard confidence intervals used by Bayesian methods. In this work, we propose to use conformal learning with fuzzy rule-based systems in classification and show some metrics of their performance. Then, we discuss how the use of type 2 fuzzy sets can improve the quality of the output of the system compared to both fuzzy and crisp rules. Finally, we also discuss how the fine-tuning of the system can be adapted to improve the quality of the conformal prediction.","authors":["Javier Fumanal-Idocin","Javier Andreu-Perez"],"url":"https://arxiv.org/abs/2504.15360"}
{"created":"2025-04-23","title":"LongPerceptualThoughts: Distilling System-2 Reasoning for System-1 Perception","abstract":"Recent reasoning models through test-time scaling have demonstrated that long chain-of-thoughts can unlock substantial performance boosts in hard reasoning tasks such as math and code. However, the benefit of such long thoughts for system-2 reasoning is relatively less explored in other domains such as perceptual tasks where shallower, system-1 reasoning seems sufficient. In this paper, we introduce LongPerceptualThoughts, a new synthetic dataset with 30K long-thought traces for perceptual tasks. The key challenges in synthesizing elaborate reasoning thoughts for perceptual tasks are that off-the-shelf models are not yet equipped with such thinking behavior and that it is not straightforward to build a reliable process verifier for perceptual tasks. Thus, we propose a novel three-stage data synthesis framework that first synthesizes verifiable multiple-choice questions from dense image descriptions, then extracts simple CoTs from VLMs for those verifiable problems, and finally expands those simple thoughts to elaborate long thoughts via frontier reasoning models. In controlled experiments with a strong instruction-tuned 7B model, we demonstrate notable improvements over existing visual reasoning data-generation methods. Our model, trained on the generated dataset, achieves an average +3.4 points improvement over 5 vision-centric benchmarks, including +11.8 points on V$^*$ Bench. Notably, despite being tuned for vision tasks, it also improves performance on the text reasoning benchmark, MMLU-Pro, by +2 points.","authors":["Yuan-Hong Liao","Sven Elflein","Liu He","Laura Leal-Taix\\'e","Yejin Choi","Sanja Fidler","David Acuna"],"url":"https://arxiv.org/abs/2504.15362"}
{"created":"2025-04-23","title":"KeDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments","abstract":"In this work, we demonstrate that distinctive keys during LLM inference tend to have high attention scores. We explore this phenomenon and propose KeyDiff, a training-free KV cache eviction method based on key similarity. This method facilitates the deployment of LLM-based application requiring long input prompts in resource-constrained environments with limited memory and compute budgets. Unlike other KV cache eviction methods, KeyDiff can process arbitrarily long prompts within strict resource constraints and efficiently generate responses. We demonstrate that KeyDiff computes the optimal solution to a KV cache selection problem that maximizes key diversity, providing a theoretical understanding of KeyDiff. Notably,KeyDiff does not rely on attention scores, allowing the use of optimized attention mechanisms like FlashAttention. We demonstrate the effectiveness of KeyDiff across diverse tasks and models, illustrating a performance gap of less than 0.04\\% with 8K cache budget ($\\sim$ 23\\% KV cache reduction) from the non-evicting baseline on the LongBench benchmark for Llama 3.1-8B and Llama 3.2-3B.","authors":["Junyoung Park","Dalton Jones","Matt Morse","Raghavv Goel","Mingu Lee","Chris Lott"],"url":"https://arxiv.org/abs/2504.15364"}
{"created":"2025-04-23","title":"Convergence-rate and error analysis of sectional-volume average method for the collisional breakage equation with multi-dimensional modelling","abstract":"Recent literature reports two sectional techniques, the finite volume method [Das et al., 2020, SIAM J. Sci. Comput., 42(6): B1570-B1598] and the fixed pivot technique [Kushwah et al., 2023, Commun. Nonlinear Sci. Numer. Simul., 121(37): 107244] to solve one-dimensional collision-induced nonlinear particle breakage equation. It is observed that both the methods become inconsistent over random grids. Therefore, we propose a new birth modification strategy, where the newly born particles are proportionately allocated in three adjacent cells, depending upon the average volume in each cell. This modification technique improves the numerical model by making it consistent over random grids. A detailed convergence and error analysis for this new scheme is studied over different possible choices of grids such as uniform, nonuniform, locally-uniform, random and oscillatory grids. In addition, we have also identified the conditions upon kernels for which the convergence rate increases significantly and the scheme achieves second order of convergence over uniform, nonuniform and locally-uniform grids. The enhanced order of accuracy will enable the new model to be easily coupled with CFD-modules. Another significant advancement in the literature is done by extending the discrete model for two-dimensional equation over rectangular grids.","authors":["Prakrati Kushwah","Anupama Ghorai","Jitraj Saha"],"url":"https://arxiv.org/abs/2504.15365"}
{"created":"2025-04-23","title":"FedFetch: Faster Federated Learning with Adaptive Downstream Prefetching","abstract":"Federated learning (FL) is a machine learning paradigm that facilitates massively distributed model training with end-user data on edge devices directed by a central server. However, the large number of heterogeneous clients in FL deployments leads to a communication bottleneck between the server and the clients. This bottleneck is made worse by straggling clients, any one of which will further slow down training. To tackle these challenges, researchers have proposed techniques like client sampling and update compression. These techniques work well in isolation but combine poorly in the downstream, server-to-client direction. This is because unselected clients have outdated local model states and need to synchronize these states with the server first.","authors":["Qifan Yan","Andrew Liu","Shiqi He","Mathias L\\'ecuyer","Ivan Beschastnikh"],"url":"https://arxiv.org/abs/2504.15366"}
{"created":"2025-04-23","title":"Solving New Tasks by Adapting Internet Video Knowledge","abstract":"Video generative models demonstrate great promise in robotics by serving as visual planners or as policy supervisors. When pretrained on internet-scale data, such video models intimately understand alignment with natural language, and can thus facilitate generalization to novel downstream behavior through text-conditioning. However, they may not be sensitive to the specificities of the particular environment the agent inhabits. On the other hand, training video models on in-domain examples of robotic behavior naturally encodes environment-specific intricacies, but the scale of available demonstrations may not be sufficient to support generalization to unseen tasks via natural language specification. In this work, we investigate different adaptation techniques that integrate in-domain information with large-scale pretrained video models, and explore the extent to which they enable novel text-conditioned generalization for robotic tasks, while also considering their independent data and resource considerations. We successfully demonstrate across robotic environments that adapting powerful video models with small scales of example data can successfully facilitate generalization to novel behaviors. In particular, we present a novel adaptation strategy, termed Inverse Probabilistic Adaptation, that not only consistently achieves strong generalization performance across robotic tasks and settings, but also exhibits robustness to the quality of adaptation data, successfully solving novel tasks even when only suboptimal in-domain demonstrations are available.","authors":["Calvin Luo","Zilai Zeng","Yilun Du","Chen Sun"],"url":"https://arxiv.org/abs/2504.15369"}
{"created":"2025-04-23","title":"Event2Vec: Processing neuromorphic events directly by representations in vector space","abstract":"The neuromorphic event cameras have overwhelming advantages in temporal resolution, power efficiency, and dynamic range compared to traditional cameras. However, the event cameras output asynchronous, sparse, and irregular events, which are not compatible with mainstream computer vision and deep learning methods. Various methods have been proposed to solve this issue but at the cost of long preprocessing procedures, losing temporal resolutions, or being incompatible with massively parallel computation. Inspired by the great success of the word to vector, we summarize the similarities between words and events, then propose the first event to vector (event2vec) representation. We validate event2vec on classifying the ASL-DVS dataset, showing impressive parameter efficiency, accuracy, and speed than previous graph/image/voxel-based representations. Beyond task performance, the most attractive advantage of event2vec is that it aligns events to the domain of natural language processing, showing the promising prospect of integrating events into large language and multimodal models. Our codes, models, and training logs are available at https://github.com/fangwei123456/event2vec.","authors":["Wei Fang","Priyadarshini Panda"],"url":"https://arxiv.org/abs/2504.15371"}
{"created":"2025-04-23","title":"FLARE: Feature-based Lightweight Aggregation for Robust Evaluation of IoT Intrusion Detection","abstract":"The proliferation of Internet of Things (IoT) devices has expanded the attack surface, necessitating efficient intrusion detection systems (IDSs) for network protection. This paper presents FLARE, a feature-based lightweight aggregation for robust evaluation of IoT intrusion detection to address the challenges of securing IoT environments through feature aggregation techniques. FLARE utilizes a multilayered processing approach, incorporating session, flow, and time-based sliding-window data aggregation to analyze network behavior and capture vital features from IoT network traffic data. We perform extensive evaluations on IoT data generated from our laboratory experimental setup to assess the effectiveness of the proposed aggregation technique. To classify attacks in IoT IDS, we employ four supervised learning models and two deep learning models. We validate the performance of these models in terms of accuracy, precision, recall, and F1-score. Our results reveal that incorporating the FLARE aggregation technique as a foundational step in feature engineering, helps lay a structured representation, and enhances the performance of complex end-to-end models, making it a crucial step in IoT IDS pipeline. Our findings highlight the potential of FLARE as a valuable technique to improve performance and reduce computational costs of end-to-end IDS implementations, thereby fostering more robust IoT intrusion detection systems.","authors":["Bradley Boswell","Seth Barrett","Swarnamugi Rajaganapathy","Gokila Dorai"],"url":"https://arxiv.org/abs/2504.15375"}
{"created":"2025-04-23","title":"Towards Understanding Camera Motions in Any Video","abstract":"We introduce CameraBench, a large-scale dataset and benchmark designed to assess and improve camera motion understanding. CameraBench consists of ~3,000 diverse internet videos, annotated by experts through a rigorous multi-stage quality control process. One of our contributions is a taxonomy of camera motion primitives, designed in collaboration with cinematographers. We find, for example, that some motions like \"follow\" (or tracking) require understanding scene content like moving subjects. We conduct a large-scale human study to quantify human annotation performance, revealing that domain expertise and tutorial-based training can significantly enhance accuracy. For example, a novice may confuse zoom-in (a change of intrinsics) with translating forward (a change of extrinsics), but can be trained to differentiate the two. Using CameraBench, we evaluate Structure-from-Motion (SfM) and Video-Language Models (VLMs), finding that SfM models struggle to capture semantic primitives that depend on scene content, while VLMs struggle to capture geometric primitives that require precise estimation of trajectories. We then fine-tune a generative VLM on CameraBench to achieve the best of both worlds and showcase its applications, including motion-augmented captioning, video question answering, and video-text retrieval. We hope our taxonomy, benchmark, and tutorials will drive future efforts towards the ultimate goal of understanding camera motions in any video.","authors":["Zhiqiu Lin","Siyuan Cen","Daniel Jiang","Jay Karhade","Hewei Wang","Chancharik Mitra","Tiffany Ling","Yuhan Huang","Sifan Liu","Mingyu Chen","Rushikesh Zawar","Xue Bai","Yilun Du","Chuang Gan","Deva Ramanan"],"url":"https://arxiv.org/abs/2504.15376"}
{"created":"2025-04-23","title":"SCALE-Sim v3: A modular cycle-accurate systolic accelerator simulator for end-to-end system analysis","abstract":"The rapid advancements in AI, scientific computing, and high-performance computing (HPC) have driven the need for versatile and efficient hardware accelerators. Existing tools like SCALE-Sim v2 provide valuable cycle-accurate simulations for systolic-array-based architectures but fall short in supporting key modern features such as sparsity, multi-core scalability, and comprehensive memory analysis. To address these limitations, we present SCALE-Sim v3, a modular, cycle-accurate simulator that extends the capabilities of its predecessor. SCALE-Sim v3 introduces five significant enhancements: multi-core simulation with spatio-temporal partitioning and hierarchical memory structures, support for sparse matrix multiplications (SpMM) with layer-wise and row-wise sparsity, integration with Ramulator for detailed DRAM analysis, precise data layout modeling to minimize memory stalls, and energy and power estimation via Accelergy. These improvements enable deeper end-to-end system analysis for modern AI accelerators, accommodating a wide variety of systems and workloads and providing detailed full-system insights into latency, bandwidth, and power efficiency.","authors":["Ritik Raj","Sarbartha Banerjee","Nikhil Chandra","Zishen Wan","Jianming Tong","Ananda Samajdhar","Tushar Krishna"],"url":"https://arxiv.org/abs/2504.15377"}
{"created":"2025-04-23","title":"Physics Driven Image Simulation from Commercial Satellite Imagery","abstract":"Physics driven image simulation allows for the modeling and creation of realistic imagery beyond what is afforded by typical rendering pipelines. We aim to automatically generate a physically realistic scene for simulation of a given region using satellite imagery to model the scene geometry, drive material estimates, and populate the scene with dynamic elements. We present automated techniques to utilize satellite imagery throughout the simulated scene to expedite scene construction and decrease manual overhead. Our technique does not use lidar, enabling simulations that could not be constructed previously. To develop a 3D scene, we model the various components of the real location, addressing the terrain, modelling man-made structures, and populating the scene with smaller elements such as vegetation and vehicles. To create the scene we begin with a Digital Surface Model, which serves as the basis for scene geometry, and allows us to reason about the real location in a common 3D frame of reference. These simulated scenes can provide increased fidelity with less manual intervention for novel locations on earth, and can facilitate algorithm development, and processing pipelines for imagery ranging from UV to LWIR $(200nm-20\\mu m)$.","authors":["Scott Sorensen","Wayne Treible","Robert Wagner","Andrew D. Gilliam","Todd Rovito","Joseph L. Mundy"],"url":"https://arxiv.org/abs/2504.15378"}
{"created":"2025-04-23","title":"Plug-and-Play Versatile Compressed Video Enhancement","abstract":"As a widely adopted technique in data transmission, video compression effectively reduces the size of files, making it possible for real-time cloud computing. However, it comes at the cost of visual quality, posing challenges to the robustness of downstream vision models. In this work, we present a versatile codec-aware enhancement framework that reuses codec information to adaptively enhance videos under different compression settings, assisting various downstream vision tasks without introducing computation bottleneck. Specifically, the proposed codec-aware framework consists of a compression-aware adaptation (CAA) network that employs a hierarchical adaptation mechanism to estimate parameters of the frame-wise enhancement network, namely the bitstream-aware enhancement (BAE) network. The BAE network further leverages temporal and spatial priors embedded in the bitstream to effectively improve the quality of compressed input frames. Extensive experimental results demonstrate the superior quality enhancement performance of our framework over existing enhancement methods, as well as its versatility in assisting multiple downstream tasks on compressed videos as a plug-and-play module. Code and models are available at https://huimin-zeng.github.io/PnP-VCVE/.","authors":["Huimin Zeng","Jiacheng Li","Zhiwei Xiong"],"url":"https://arxiv.org/abs/2504.15380"}
{"created":"2025-04-23","title":"ICGM-FRAX: Iterative Cross Graph Matching for Hip Fracture Risk Assessment using Dual-energy X-ray Absorptiometry Images","abstract":"Hip fractures represent a major health concern, particularly among the elderly, often leading decreased mobility and increased mortality. Early and accurate detection of at risk individuals is crucial for effective intervention. In this study, we propose Iterative Cross Graph Matching for Hip Fracture Risk Assessment (ICGM-FRAX), a novel approach for predicting hip fractures using Dual-energy X-ray Absorptiometry (DXA) images. ICGM-FRAX involves iteratively comparing a test (subject) graph with multiple template graphs representing the characteristics of hip fracture subjects to assess the similarity and accurately to predict hip fracture risk. These graphs are obtained as follows. The DXA images are separated into multiple regions of interest (RoIs), such as the femoral head, shaft, and lesser trochanter. Radiomic features are then calculated for each RoI, with the central coordinates used as nodes in a graph. The connectivity between nodes is established according to the Euclidean distance between these coordinates. This process transforms each DXA image into a graph, where each node represents a RoI, and edges derived by the centroids of RoIs capture the spatial relationships between them. If the test graph closely matches a set of template graphs representing subjects with incident hip fractures, it is classified as indicating high hip fracture risk. We evaluated our method using 547 subjects from the UK Biobank dataset, and experimental results show that ICGM-FRAX achieved a sensitivity of 0.9869, demonstrating high accuracy in predicting hip fractures.","authors":["Chen Zhao","Anjum Shaik","Joyce H. Keyak","Nancy E. Lane","Jeffrey D. Deng","Kuan-Jui Su","Qiuying Sha","Hui Shen","Hong-Wen Deng","Weihua Zhou"],"url":"https://arxiv.org/abs/2504.15384"}
{"created":"2025-04-23","title":"MST3 Encryption improvement with three-parameter group of Hermitian function field","abstract":"This scholarly work presents an advanced cryptographic framework utilizing automorphism groups as the foundational structure for encryption scheme implementation. The proposed methodology employs a three-parameter group construction, distinguished by its application of logarithmic signatures positioned outside the group's center, a significant departure from conventional approaches. A key innovation in this implementation is utilizing the Hermitian function field as the underlying mathematical framework. This particular function field provides enhanced structural properties that strengthen the cryptographic protocol when integrated with the three-parameter group architecture. The encryption mechanism features phased key de-encapsulation from ciphertext, representing a substantial advantage over alternative implementations. This sequential extraction process introduces additional computational complexity for potential adversaries while maintaining efficient legitimate decryption. A notable characteristic of this cryptosystem is the direct correlation between the underlying group's mathematical strength and both the attack complexity and message size parameters. This relationship enables precise security-efficiency calibration based on specific implementation requirements and threat models. The application of automorphism groups with logarithmic signatures positioned outside the center represents a significant advancement in non-traditional cryptographic designs, particularly relevant in the context of post-quantum cryptographic resilience.","authors":["Gennady Khalimov","Yevgen Kotukh"],"url":"https://arxiv.org/abs/2504.15391"}
{"created":"2025-04-23","title":"Tell Me What You Know About Sexism: Expert-LLM Interaction Strategies and Co-Created Definitions for Zero-Shot Sexism Detection","abstract":"This paper investigates hybrid intelligence and collaboration between researchers of sexism and Large Language Models (LLMs), with a four-component pipeline. First, nine sexism researchers answer questions about their knowledge of sexism and of LLMs. They then participate in two interactive experiments involving an LLM (GPT3.5). The first experiment has experts assessing the model's knowledge about sexism and suitability for use in research. The second experiment tasks them with creating three different definitions of sexism: an expert-written definition, an LLM-written one, and a co-created definition. Lastly, zero-shot classification experiments use the three definitions from each expert in a prompt template for sexism detection, evaluating GPT4o on 2.500 texts sampled from five sexism benchmarks. We then analyze the resulting 67.500 classification decisions. The LLM interactions lead to longer and more complex definitions of sexism. Expert-written definitions on average perform poorly compared to LLM-generated definitions. However, some experts do improve classification performance with their co-created definitions of sexism, also experts who are inexperienced in using LLMs.","authors":["Myrthe Reuver","Indira Sen","Matteo Melis","Gabriella Lapesa"],"url":"https://arxiv.org/abs/2504.15392"}
{"created":"2025-04-23","title":"Capacity on BMS Channels via Code Symmetry and Nesting","abstract":"The past decade has seen notable advances in our understanding of structured error-correcting codes, particularly binary Reed--Muller (RM) codes. While initial breakthroughs were for erasure channels based on symmetry, extending these results to the binary symmetric channel (BSC) and other binary memoryless symmetric (BMS) channels required new tools and conditions. Recent work uses nesting to obtain multiple weakly correlated \"looks\" that imply capacity-achieving performance under bit-MAP and block-MAP decoding. This paper revisits and extends past approaches, aiming to simplify proofs, unify insights, and remove unnecessary conditions. By leveraging powerful results from the analysis of boolean functions, we derive recursive bounds using two or three looks at each stage. This gives bounds on the bit error probability that decay exponentially in the number of stages. For the BSC, we incorporate level-k inequalities and hypercontractive techniques to achieve the faster decay rate required for vanishing block error probability. The results are presented in a semitutorial style, providing both theoretical insights and practical implications for future research on structured codes.","authors":["Henry D. Pfister","Galen Reeves"],"url":"https://arxiv.org/abs/2504.15394"}
{"created":"2025-04-23","title":"Measuring likelihood in cybersecurity","abstract":"In cybersecurity risk is commonly measured by impact and probability, the former is objectively measured based on the consequences from the use of technology to obtain business gains, or by achieving business objectives. The latter has been measured, in sectors such as financial or insurance, based on historical data because there is vast information, and many other fields have applied the same approach. Although in cybersecurity, as a new discipline, there is not always historical data to support an objective measure of probability, the data available is not public and there is no consistent formatting to store and share it, so a new approach is required to measure cybersecurity events incidence. Through a comprehensive analysis of the state of the art, including current methodologies, frameworks, and incident data, considering tactics, techniques, and procedures (TTP) used by attackers, indicators of compromise (IOC), and defence controls, this work proposes a data model that describes a cyber exposure profile that provides an indirect but objective measure for likelihood, including different sources and metrics to update the model if needed. We further propose a set of practical, quantifiable metrics for risk assessment, enabling cybersecurity practitioners to measure likelihood without relying solely on historical incident data. By combining these metrics with our data model, organizations gain an actionable framework for continuously refining their cybersecurity strategies.","authors":["Pablo Corona-Fraga","Vanessa Diaz-Rodriguez","Jesus Manuel Niebla-Zatarain","Gabriel Sanchez-Perez"],"url":"https://arxiv.org/abs/2504.15395"}
{"created":"2025-04-23","title":"A Quadratic Control Framework for Dynamic Systems","abstract":"This article presents a unified approach to quadratic optimal control for both linear and nonlinear discrete-time systems, with a focus on trajectory tracking. The control strategy is based on minimizing a quadratic cost function that penalizes deviations of system states and control inputs from their desired trajectories.","authors":["Igor Ladnik"],"url":"https://arxiv.org/abs/2504.15396"}
{"created":"2025-04-23","title":"MirrorVerse: Pushing Diffusion Models to Realistically Reflect the World","abstract":"Diffusion models have become central to various image editing tasks, yet they often fail to fully adhere to physical laws, particularly with effects like shadows, reflections, and occlusions. In this work, we address the challenge of generating photorealistic mirror reflections using diffusion-based generative models. Despite extensive training data, existing diffusion models frequently overlook the nuanced details crucial to authentic mirror reflections. Recent approaches have attempted to resolve this by creating synhetic datasets and framing reflection generation as an inpainting task; however, they struggle to generalize across different object orientations and positions relative to the mirror. Our method overcomes these limitations by introducing key augmentations into the synthetic data pipeline: (1) random object positioning, (2) randomized rotations, and (3) grounding of objects, significantly enhancing generalization across poses and placements. To further address spatial relationships and occlusions in scenes with multiple objects, we implement a strategy to pair objects during dataset generation, resulting in a dataset robust enough to handle these complex scenarios. Achieving generalization to real-world scenes remains a challenge, so we introduce a three-stage training curriculum to develop the MirrorFusion 2.0 model to improve real-world performance. We provide extensive qualitative and quantitative evaluations to support our approach. The project page is available at: https://mirror-verse.github.io/.","authors":["Ankit Dhiman","Manan Shah","R Venkatesh Babu"],"url":"https://arxiv.org/abs/2504.15397"}
{"created":"2025-04-23","title":"Improving Learning to Optimize Using Parameter Symmetries","abstract":"We analyze a learning-to-optimize (L2O) algorithm that exploits parameter space symmetry to enhance optimization efficiency. Prior work has shown that jointly learning symmetry transformations and local updates improves meta-optimizer performance. Supporting this, our theoretical analysis demonstrates that even without identifying the optimal group element, the method locally resembles Newton's method. We further provide an example where the algorithm provably learns the correct symmetry transformation during training. To empirically evaluate L2O with teleportation, we introduce a benchmark, analyze its success and failure cases, and show that enhancements like momentum further improve performance. Our results highlight the potential of leveraging neural network parameter space symmetry to advance meta-optimization.","authors":["Guy Zamir","Aryan Dokania","Bo Zhao","Rose Yu"],"url":"https://arxiv.org/abs/2504.15399"}
{"created":"2025-04-23","title":"Context Aware Grounded Teacher for Source Free Object Detection","abstract":"We focus on the Source Free Object Detection (SFOD) problem, when source data is unavailable during adaptation, and the model must adapt to the unlabeled target domain. In medical imaging, several approaches have leveraged a semi-supervised student-teacher architecture to bridge domain discrepancy. Context imbalance in labeled training data and significant domain shifts between domains can lead to biased teacher models that produce inaccurate pseudolabels, degrading the student model's performance and causing a mode collapse. Class imbalance, particularly when one class significantly outnumbers another, leads to contextual bias. To tackle the problem of context bias and the significant performance drop of the student model in the SFOD setting, we introduce Grounded Teacher (GT) as a standard framework. In this study, we model contextual relationships using a dedicated relational context module and leverage it to mitigate inherent biases in the model. This approach enables us to apply augmentations to closely related classes, across and within domains, enhancing the performance of underrepresented classes while keeping the effect on dominant classes minimal. We further improve the quality of predictions by implementing an expert foundational branch to supervise the student model. We validate the effectiveness of our approach in mitigating context bias under the SFOD setting through experiments on three medical datasets supported by comprehensive ablation studies. All relevant resources, including preprocessed data, trained model weights, and code, are publicly available at this https://github.com/Tajamul21/Grounded_Teacher.","authors":["Tajamul Ashraf","Rajes Manna","Partha Sarathi Purkayastha","Tavaheed Tariq","Janibul Bashir"],"url":"https://arxiv.org/abs/2504.15404"}
{"created":"2025-04-23","title":"On optimality and bounds for internal solutions generated from boundary data-driven Gramians","abstract":"We consider the computation of internal solutions for a time domain plasma wave equation with unknown coefficients from the data obtained by sampling its transfer function at the boundary. The computation is performed by transforming known background snapshots using the Cholesky decomposition of the data-driven Gramian. We show that this approximation is asymptotically close to the projection of the true internal solution onto the subspace of background snapshots. This allows us to derive a generally applicable bound for the error in the approximation of internal fields from boundary data for a time domain plasma wave equation with an unknown potential $q$. For general $q\\in L^\\infty$, we prove convergence of these data generated internal fields in one dimension for two examples. The first is for piecewise constant initial data and sampling $\\tau$ equal to the pulse width. The second is piecewise linear initial data and sampling at half the pulse width. We show that in both cases the data generated solutions converge in $L^2$ at order $\\sqrt{\\tau}$. We present numerical experiments validating the result and the sharpness of this convergence rate.","authors":["V. Druskin","S. Moskow","M. Zaslavsky"],"url":"https://arxiv.org/abs/2504.15407"}
{"created":"2025-04-23","title":"Players' Perception of Bugs and Glitches in Video Games: An Exploratory Study","abstract":"The goal of this exploratory research is to investigate how glitches and bugs within video games affect a players overall experience. The severity or frequency of bugs, as well as the nature of the bugs present, could influence how the players perceive these interactions. Another factor is the players personality because this will affect their motivations for playing certain games as well as how they react to bugs within these games. Glitches and bugs are framed as a negative aspect within games, but create the potential for enjoyable experiences, despite being unexpected. To explore this hypothesis, I observed some glitches within recorded gameplay via YouTube and Twitch livestream VODs and analyzed the streamers reaction, as well as the audiences. I also conducted semi-structured interviews with gamers with the goal of learning more about that players personality and attitudes towards bugs in the games they play. I concluded that the types of bugs matter less to the players than how frequently they occur, the context they occur, and the outcome of them.","authors":["Jessica Backus"],"url":"https://arxiv.org/abs/2504.15408"}
{"created":"2025-04-23","title":"Post-Convergence Sim-to-Real Policy Transfer: A Principled Alternative to Cherry-Picking","abstract":"Learning-based approaches, particularly reinforcement learning (RL), have become widely used for developing control policies for autonomous agents, such as locomotion policies for legged robots. RL training typically maximizes a predefined reward (or minimizes a corresponding cost/loss) by iteratively optimizing policies within a simulator. Starting from a randomly initialized policy, the empirical expected reward follows a trajectory with an overall increasing trend. While some policies become temporarily stuck in local optima, a well-defined training process generally converges to a reward level with noisy oscillations. However, selecting a policy for real-world deployment is rarely an analytical decision (i.e., simply choosing the one with the highest reward) and is instead often performed through trial and error. To improve sim-to-real transfer, most research focuses on the pre-convergence stage, employing techniques such as domain randomization, multi-fidelity training, adversarial training, and architectural innovations. However, these methods do not eliminate the inevitable convergence trajectory and noisy oscillations of rewards, leading to heuristic policy selection or cherry-picking. This paper addresses the post-convergence sim-to-real transfer problem by introducing a worst-case performance transference optimization approach, formulated as a convex quadratic-constrained linear programming problem. Extensive experiments demonstrate its effectiveness in transferring RL-based locomotion policies from simulation to real-world laboratory tests.","authors":["Dylan Khor","Bowen Weng"],"url":"https://arxiv.org/abs/2504.15414"}
{"created":"2025-04-23","title":"IV-Bench: A Benchmark for Image-Grounded Video Perception and Reasoning in Multimodal LLMs","abstract":"Existing evaluation frameworks for Multimodal Large Language Models (MLLMs) primarily focus on image reasoning or general video understanding tasks, largely overlooking the significant role of image context in video comprehension. To bridge this gap, we propose IV-Bench, the first comprehensive benchmark for evaluating Image-Grounded Video Perception and Reasoning. IV-Bench consists of 967 videos paired with 2,585 meticulously annotated image-text queries across 13 tasks (7 perception and 6 reasoning tasks) and 5 representative categories. Extensive evaluations of state-of-the-art open-source (e.g., InternVL2.5, Qwen2.5-VL) and closed-source (e.g., GPT-4o, Gemini2-Flash and Gemini2-Pro) MLLMs demonstrate that current models substantially underperform in image-grounded video Perception and Reasoning, merely achieving at most 28.9% accuracy. Further analysis reveals key factors influencing model performance on IV-Bench, including inference pattern, frame number, and resolution. Additionally, through a simple data synthesis approach, we demonstratethe challenges of IV- Bench extend beyond merely aligning the data format in the training proecss. These findings collectively provide valuable insights for future research. Our codes and data are released in https://github.com/multimodal-art-projection/IV-Bench.","authors":["David Ma","Yuanxing Zhang","Jincheng Ren","Jarvis Guo","Yifan Yao","Zhenlin Wei","Zhenzhu Yang","Zhongyuan Peng","Boyu Feng","Jun Ma","Xiao Gu","Zhoufutu Wen","King Zhu","Yancheng He","Meng Cao","Shiwen Ni","Jiaheng Liu","Wenhao Huang","Ge Zhang","Xiaojie Jin"],"url":"https://arxiv.org/abs/2504.15415"}
{"created":"2025-04-23","title":"Bare Minimum Mitigations for Autonomous AI Development","abstract":"Artificial intelligence (AI) is advancing rapidly, with the potential for significantly automating AI research and development itself in the near future. In 2024, international scientists, including Turing Award recipients, warned of risks from autonomous AI research and development (R&amp;D), suggesting a red line such that no AI system should be able to improve itself or other AI systems without explicit human approval and assistance. However, the criteria for meaningful human approval remain unclear, and there is limited analysis on the specific risks of autonomous AI R&amp;D, how they arise, and how to mitigate them. In this brief paper, we outline how these risks may emerge and propose four minimum safeguard recommendations applicable when AI agents significantly automate or accelerate AI development.","authors":["Joshua Clymer","Isabella Duan","Chris Cundy","Yawen Duan","Fynn Heide","Chaochao Lu","S\\\"oren Mindermann","Conor McGurk","Xudong Pan","Saad Siddiqui","Jingren Wang","Min Yang","Xianyuan Zhan"],"url":"https://arxiv.org/abs/2504.15416"}
{"created":"2025-04-23","title":"On the Boolean Network Theory of Datalog$^\\neg$","abstract":"Datalog$^\\neg$ is a central formalism used in a variety of domains ranging from deductive databases and abstract argumentation frameworks to answer set programming. Its model theory is the finite counterpart of the logical semantics developed for normal logic programs, mainly based on the notions of Clark's completion and two-valued or three-valued canonical models including supported, stable, regular and well-founded models. In this paper we establish a formal link between Datalog$^\\neg$ and Boolean network theory, which was initially introduced by Stuart Kaufman and Ren\\'e Thomas to reason about gene regulatory networks. We use previous results from Boolean network theory to prove that in the absence of odd cycles in a Datalog$^\\neg$ program, the regular models coincide with the stable models, which entails the existence of stable models, and in the absence of even cycles, we show the uniqueness of stable partial models, which entails the uniqueness of regular models. These results on regular models have been claimed by You and Yuan in 1994 for normal logic programs but we show problems in their definition of well-founded stratification and in their proofs that we can fix for negative normal logic programs only. We also give upper bounds on the numbers of stable partial, regular, and stable models of a Datalog$^\\neg$ program using the cardinality of a feedback vertex set in its atom dependency graph. Interestingly, our connection to Boolean network theory also points us to the notion of trap spaces for Datalog$^\\neg$ programs. We relate the notions of supported or stable trap spaces to the other semantics of Datalog$^\\neg$, and show the equivalence between subset-minimal stable trap spaces and regular models.","authors":["Van-Giang Trinh","Belaid Benhamou","Sylvain Soliman","Fran\\c{c}ois Fages"],"url":"https://arxiv.org/abs/2504.15417"}
{"created":"2025-04-23","title":"MRTA-Sim: A Modular Simulator for Multi-Robot Allocation, Planning, and Control in Open-World Environments","abstract":"This paper introduces MRTA-Sim, a Python/ROS2/Gazebo simulator for testing approaches to Multi-Robot Task Allocation (MRTA) problems on simulated robots in complex, indoor environments. Grid-based approaches to MRTA problems can be too restrictive for use in complex, dynamic environments such in warehouses, department stores, hospitals, etc. However, approaches that operate in free-space often operate at a layer of abstraction above the control and planning layers of a robot and make an assumption on approximate travel time between points of interest in the system. These abstractions can neglect the impact of the tight space and multi-agent interactions on the quality of the solution. Therefore, MRTA solutions should be tested with the navigation stacks of the robots in mind, taking into account robot planning, conflict avoidance between robots, and human interaction and avoidance. This tool connects the allocation output of MRTA solvers to individual robot planning using the NAV2 stack and local, centralized multi-robot deconfliction using Control Barrier Function-Quadrtic Programs (CBF-QPs), creating a platform closer to real-world operation for more comprehensive testing of these approaches. The simulation architecture is modular so that users can swap out methods at different levels of the stack. We show the use of our system with a Satisfiability Modulo Theories (SMT)-based approach to dynamic MRTA on a fleet of indoor delivery robots.","authors":["Victoria Marie Tuck","Hardik Parwana","Pei-Wei Chen","Georgios Fainekos","Bardh Hoxha","Hideki Okamoto","S. Shankar Sastry","Sanjit A. Seshia"],"url":"https://arxiv.org/abs/2504.15418"}
{"created":"2025-04-23","title":"Safety Embedded Adaptive Control Using Barrier States","abstract":"In this work, we explore the application of barrier states (BaS) in the realm of safe nonlinear adaptive control. Our proposed framework derives barrier states for systems with parametric uncertainty, which are augmented into the uncertain dynamical model. We employ an adaptive nonlinear control strategy based on a control Lyapunov functions approach to design a stabilizing controller for the augmented system. The developed theory shows that the controller ensures safe control actions for the original system while meeting specified performance objectives. We validate the effectiveness of our approach through simulations on diverse systems, including a planar quadrotor subject to unknown drag forces and an adaptive cruise control system, for which we provide comparisons with existing methodologies.","authors":["Maitham F. AL-Sunni","Hassan Almubarak","John M. Dolan"],"url":"https://arxiv.org/abs/2504.15423"}
{"created":"2025-04-23","title":"LLM-Assisted Translation of Legacy FORTRAN Codes to C++: A Cross-Platform Study","abstract":"Large Language Models (LLMs) are increasingly being leveraged for generating and translating scientific computer codes by both domain-experts and non-domain experts. Fortran has served as one of the go to programming languages in legacy high-performance computing (HPC) for scientific discoveries. Despite growing adoption, LLM-based code translation of legacy code-bases has not been thoroughly assessed or quantified for its usability. Here, we studied the applicability of LLM-based translation of Fortran to C++ as a step towards building an agentic-workflow using open-weight LLMs on two different computational platforms. We statistically quantified the compilation accuracy of the translated C++ codes, measured the similarity of the LLM translated code to the human translated C++ code, and statistically quantified the output similarity of the Fortran to C++ translation.","authors":["Nishath Rajiv Ranasinghe","Shawn M. Jones","Michal Kucer","Ayan Biswas","Daniel O'Malley","Alexander Buschmann Most","Selma Liliane Wanna","Ajay Sreekumar"],"url":"https://arxiv.org/abs/2504.15424"}
{"created":"2025-04-23","title":"Solving Multi-Agent Safe Optimal Control with Distributed Epigraph Form MARL","abstract":"Tasks for multi-robot systems often require the robots to collaborate and complete a team goal while maintaining safety. This problem is usually formalized as a constrained Markov decision process (CMDP), which targets minimizing a global cost and bringing the mean of constraint violation below a user-defined threshold. Inspired by real-world robotic applications, we define safety as zero constraint violation. While many safe multi-agent reinforcement learning (MARL) algorithms have been proposed to solve CMDPs, these algorithms suffer from unstable training in this setting. To tackle this, we use the epigraph form for constrained optimization to improve training stability and prove that the centralized epigraph form problem can be solved in a distributed fashion by each agent. This results in a novel centralized training distributed execution MARL algorithm named Def-MARL. Simulation experiments on 8 different tasks across 2 different simulators show that Def-MARL achieves the best overall performance, satisfies safety constraints, and maintains stable training. Real-world hardware experiments on Crazyflie quadcopters demonstrate the ability of Def-MARL to safely coordinate agents to complete complex collaborative tasks compared to other methods.","authors":["Songyuan Zhang","Oswin So","Mitchell Black","Zachary Serlin","Chuchu Fan"],"url":"https://arxiv.org/abs/2504.15425"}
{"created":"2025-04-23","title":"TVR: Automotive System Requirement Traceability Validation and Recovery Through Retrieval-Augmented Generation","abstract":"In automotive software development, as well as other domains, traceability between stakeholder requirements and system requirements is crucial to ensure consistency, correctness, and regulatory compliance. However, erroneous or missing traceability relationships often arise due to improper propagation of requirement changes or human errors in requirement mapping, leading to inconsistencies and increased maintenance costs. Existing approaches do not address traceability between stakeholder and system requirements, rely on open-source data -- as opposed to automotive (or any industry) data -- and do not address the validation of manual links established by engineers. Additionally, automotive requirements often exhibit variations in the way they are expressed, posing challenges for supervised models requiring training. The recent advancements in large language models (LLMs) provide new opportunities to address these challenges. In this paper, we introduce TVR, a requirement Traceability Validation and Recovery approach primarily targeting automotive systems, leveraging LLMs enhanced with retrieval-augmented generation (RAG). TVR is designed to validate existing traceability links and recover missing ones with high accuracy. We empirically evaluate TVR on automotive requirements, achieving 98.87% accuracy in traceability validation and 85.50% correctness in traceability recovery. Additionally, TVR demonstrates strong robustness, achieving 97.13% in accuracy when handling unseen requirements variations. The results highlight the practical effectiveness of RAG-based LLM approaches in industrial settings, offering a promising solution for improving requirements traceability in complex automotive systems.","authors":["Feifei Niu","Rongqi Pan","Lionel C. Briand","Hanyang Hu","Krishna Koravadi"],"url":"https://arxiv.org/abs/2504.15427"}
{"created":"2025-04-23","title":"Understanding the Perceptions of Trigger Warning and Content Warning on Social Media Platforms in the U.S","abstract":"The prevalence of distressing content on social media raises concerns about users' mental well-being, prompting the use of trigger warnings (TW) and content warnings (CW). However, inconsistent implementation of TW/CW across platforms and the lack of standardized practices confuse users regarding these warnings. To better understand how users experienced and utilized these warnings, we conducted a semi-structured interview study with 15 general social media users. Our findings reveal challenges across three key stakeholders: viewers, who need to decide whether to engage with warning-labeled content; posters, who struggle with whether and how to apply TW/CW to the content; and platforms, whose design features shape the visibility and usability of warnings. While users generally expressed positive attitudes toward warnings, their understanding of TW/CW usage was limited. Based on these insights, we proposed a conceptual framework of the TW/CW mechanisms from multiple stakeholders' perspectives. Lastly, we further reflected on our findings and discussed the opportunities for social media platforms to enhance users' TW/CW experiences, fostering a more trauma-informed social media environment.","authors":["Xinyi Zhang","Muskan Gupta","Emily Altland","Sang Won Lee"],"url":"https://arxiv.org/abs/2504.15429"}
{"created":"2025-04-23","title":"Trillion 7B Technical Report","abstract":"We introduce Trillion-7B, the most token-efficient Korean-centric multilingual LLM available. Our novel Cross-lingual Document Attention (XLDA) mechanism enables highly efficient and effective knowledge transfer from English to target languages like Korean and Japanese. Combined with optimized data mixtures, language-specific filtering, and tailored tokenizer construction, Trillion-7B achieves competitive performance while dedicating only 10\\% of its 2T training tokens to multilingual data and requiring just 59.4K H100 GPU hours (\\$148K) for full training. Comprehensive evaluations across 27 benchmarks in four languages demonstrate Trillion-7B's robust multilingual performance and exceptional cross-lingual consistency.","authors":["Sungjun Han (Trillion Labs)","Juyoung Suk (Trillion Labs)","Suyeong An (Trillion Labs)","Hyungguk Kim (Trillion Labs)","Kyuseok Kim (Trillion Labs)","Wonsuk Yang (Trillion Labs)","Seungtaek Choi (Trillion Labs)","Jamin Shin (Trillion Labs)"],"url":"https://arxiv.org/abs/2504.15431"}
{"created":"2025-04-23","title":"Feeding LLM Annotations to BERT Classifiers at Your Own Risk","abstract":"Using LLM-generated labels to fine-tune smaller encoder-only models for text classification has gained popularity in various settings. While this approach may be justified in simple and low-stakes applications, we conduct empirical analysis to demonstrate how the perennial curse of training on synthetic data manifests itself in this specific setup. Compared to models trained on gold labels, we observe not only the expected performance degradation in accuracy and F1 score, but also increased instability across training runs and premature performance plateaus. These findings cast doubts on the reliability of such approaches in real-world applications. We contextualize the observed phenomena through the lens of error propagation and offer several practical mitigation strategies, including entropy-based filtering and ensemble techniques. Although these heuristics offer partial relief, they do not fully resolve the inherent risks of propagating non-random errors from LLM annotations to smaller classifiers, underscoring the need for caution when applying this workflow in high-stakes text classification tasks.","authors":["Yucheng Lu","Kazimier Smith"],"url":"https://arxiv.org/abs/2504.15432"}
{"created":"2025-04-23","title":"AGI Is Coming... Right After AI Learns to Play Wordle","abstract":"This paper investigates multimodal agents, in particular, OpenAI's Computer-User Agent (CUA), trained to control and complete tasks through a standard computer interface, similar to humans. We evaluated the agent's performance on the New York Times Wordle game to elicit model behaviors and identify shortcomings. Our findings revealed a significant discrepancy in the model's ability to recognize colors correctly depending on the context. The model had a $5.36\\%$ success rate over several hundred runs across a week of Wordle. Despite the immense enthusiasm surrounding AI agents and their potential to usher in Artificial General Intelligence (AGI), our findings reinforce the fact that even simple tasks present substantial challenges for today's frontier AI models. We conclude with a discussion of the potential underlying causes, implications for future development, and research directions to improve these AI systems.","authors":["Sarath Shekkizhar","Romain Cosentino"],"url":"https://arxiv.org/abs/2504.15434"}
{"created":"2025-04-23","title":"Iris: A Next Generation Digital Pathology Rendering Engine","abstract":"Digital pathology is a tool of rapidly evolving importance within the discipline of pathology.Whole slide imaging promises numerous advantages; however, adoption is limited by challenges in ease of use and speed of high-quality image rendering relative to the simplicity and visual quality of glass slides. We introduce Iris, a new high-performance digital pathology rendering system. Specifically, we outline and detail the performance metrics of Iris Core, the core rendering engine technology. Iris Core comprises machine code modules written from the ground up in C++ and using Vulkan, a low-level and low-overhead cross-platform graphical processing unit application program interface, and our novel rapid tile buffering algorithms. We provide a detailed explanation of Iris Core's system architecture, including the stateless isolation of core processes, interprocess communication paradigms, and explicit synchronization paradigms that provide powerful control over the graphical processing unit. Iris Core achieves slide rendering at the sustained maximum frame rate on all tested platforms and buffers an entire new slide field of, view without overlapping pixels, in 10 ms with enhanced detail in 30 ms. It is able to buffer and compute high-fidelity reduction-enhancements for viewing low-power cytology with increased visual quality at a rate of 100-160 {\\mu}s per slide tile, and with a cumulative median buffering rate of 1.36 GB of decompressed image data per second. This buffering rate allows for an entirely new field of view to be fully buffered and rendered in less than a single monitor refresh on a standard display, and high detail features within 2-3 monitor refresh frames. These metrics far exceed previously published specifications, beyond an order of magnitude in some contexts. The system shows no slowing with high use loads, but rather increases performance due to cache mechanisms.","authors":["Ryan Erik Landvater","Ulysses Balis"],"url":"https://arxiv.org/abs/2504.15437"}
{"created":"2025-04-23","title":"Does Your Blockchain Need Multidimensional Transaction Fees?","abstract":"Blockchains have block-size limits to ensure the entire cluster can keep up with the tip of the chain. These block-size limits are usually single-dimensional, but richer multidimensional constraints allow for greater throughput. The potential for performance improvements from multidimensional resource pricing has been discussed in the literature, but exactly how big those performance improvements are remains unclear. In order to identify the magnitude of additional throughput that multi-dimensional transaction fees can unlock, we introduce the concept of an $\\alpha$-approximation. A constraint set $C_1$ is $\\alpha$-approximated by $C_2$ if every block feasible under $C_1$ is also feasible under $C_2$ once all resource capacities are scaled by a factor of $\\alpha$ (e.g., $\\alpha =2$ corresponds to doubling all available resources). We show that the $\\alpha$-approximation of the optimal single-dimensional gas measure corresponds to the value of a specific zero-sum game. However, the more general problem of finding the optimal $k$-dimensional approximation is NP-complete. Quantifying the additional throughput that multi-dimensional fees can provide allows blockchain designers to make informed decisions about whether the additional capacity unlocked by multidimensional constraints is worth the additional complexity they add to the protocol.","authors":["Nir Lavee","Noam Nisan","Mallesh Pai","Max Resnick"],"url":"https://arxiv.org/abs/2504.15438"}
{"created":"2025-04-23","title":"Combating Toxic Language: A Review of LLM-Based Strategies for Software Engineering","abstract":"Large Language Models (LLMs) have become integral to software engineering (SE), where they are increasingly used in development workflows. However, their widespread use raises concerns about the presence and propagation of toxic language--harmful or offensive content that can foster exclusionary environments. This paper provides a comprehensive review of recent research on toxicity detection and mitigation, focusing on both SE-specific and general-purpose datasets. We examine annotation and preprocessing techniques, assess detection methodologies, and evaluate mitigation strategies, particularly those leveraging LLMs. Additionally, we conduct an ablation study demonstrating the effectiveness of LLM-based rewriting for reducing toxicity. By synthesizing existing work and identifying open challenges, this review highlights key areas for future research to ensure the responsible deployment of LLMs in SE and beyond.","authors":["Hao Zhuo","Yicheng Yang","Kewen Peng"],"url":"https://arxiv.org/abs/2504.15439"}
{"created":"2025-04-23","title":"Demand for LLMs: Descriptive Evidence on Substitution, Market Expansion, and Multihoming","abstract":"This paper documents three stylized facts about the demand for Large Language Models (LLMs) using data from OpenRouter, a prominent LLM marketplace. First, new models experience rapid initial adoption that stabilizes within weeks. Second, model releases differ substantially in whether they primarily attract new users or substitute demand from competing models. Third, multihoming, using multiple models simultaneously, is common among apps. These findings suggest significant horizontal and vertical differentiation in the LLM market, implying opportunities for providers to maintain demand and pricing power despite rapid technological advances.","authors":["Andrey Fradkin"],"url":"https://arxiv.org/abs/2504.15440"}
{"created":"2025-04-23","title":"Prize-Collecting Forest with Submodular Penalties: Improved Approximation","abstract":"Constrained forest problems form a class of graph problems where specific connectivity requirements for certain cuts within the graph must be satisfied by selecting the minimum-cost set of edges. The prize-collecting version of these problems introduces flexibility by allowing penalties to be paid to ignore some connectivity requirements.","authors":["Ali Ahmadi","Iman Gholami","MohammadTaghi Hajiaghayi","Peyman Jabbarzade","Mohammad Mahdavi"],"url":"https://arxiv.org/abs/2504.15445"}
{"created":"2025-04-23","title":"Valkyrie: A Response Framework to Augment Runtime Detection of Time-Progressive Attacks","abstract":"A popular approach to detect cyberattacks is to monitor systems in real-time to identify malicious activities as they occur. While these solutions aim to detect threats early, minimizing damage, they suffer from a significant challenge due to the presence of false positives. False positives have a detrimental impact on computer systems, which can lead to interruptions of legitimate operations and reduced productivity. Most contemporary works tend to use advanced Machine Learning and AI solutions to address this challenge. Unfortunately, false positives can, at best, be reduced but not eliminated.","authors":["Nikhilesh Singh","Chester Rebeiro"],"url":"https://arxiv.org/abs/2504.15447"}
{"created":"2025-04-23","title":"Tracing Cross-chain Transactions between EVM-based Blockchains: An Analysis of Ethereum-Polygon Bridges","abstract":"Ethereum's scalability has been a major concern due to its limited transaction throughput and high fees. To address these limitations, Polygon has emerged as a sidechain solution that facilitates asset transfers between Ethereum and Polygon, thereby improving scalability and reducing costs. However, current cross-chain transactions, particularly those between Ethereum and Polygon, lack transparency and traceability. This paper proposes a method to track cross-chain transactions across EVM-compatible blockchains. It leverages the unique feature that user addresses are consistent across EVM-compatible blockchains. We develop a matching heuristic algorithm that links transactions between the source and target chains by combining transaction time, value, and token identification. Applying our methodology to over 2 million cross-chain transactions (August 2020-August 2023) between Ethereum and Polygon, we achieve matching rates of up to 99.65% for deposits and 92.78% for withdrawals, across different asset types including Ether, ERC-20 tokens, and NFTs. In addition, we provide a comprehensive analysis of various properties and characteristics of cross-chain transactions. Our methodology and findings contribute to a better understanding of cross-chain transaction dynamics and bridge performance, with implications for improving bridge efficiency and security in cross-chain operations.","authors":["Tao Yan","Chuanshan Huang","Claudio J. Tessone"],"url":"https://arxiv.org/abs/2504.15449"}
{"created":"2025-04-23","title":"Nearly Optimal Nonlinear Safe Control with BaS-SDRE","abstract":"The State-Dependent Riccati Equation (SDRE) approach has emerged as a systematic and effective means of designing nearly optimal nonlinear controllers. The Barrier States (BaS) embedding methodology was developed recently for safe multi-objective controls in which the safety condition is manifested as a state to be controlled along with other states of the system. The overall system, termed the safety embedded system, is highly nonlinear even if the original system is linear. This paper develops a nonlinear nearly optimal safe feedback control technique by combining the two strategies effectively. First, the BaS is derived in an extended linearization formulation to be subsequently used to form an extended safety embedded system. A new optimal control problem is formed thereafter, which is used to construct a safety embedded State-Dependent Riccati Equation, termed BaS-SDRE, whose solution approximates the solution of the optimal control problem's associated Hamilton-Jacobi-Bellman (HJB) equation. The BaS-SDRE is then solved online to synthesize the nearly optimal safe control. The proposed technique's efficacy is demonstrated on an unstable, constrained linear system that shows how the synthesized control reacts to nonlinearities near the unsafe region, a nonlinear flight control system with limited path angular velocity that exists due to structural and dynamic concerns, and a planar quadrotor system that navigates safely in a crowded environment.","authors":["Hassan Almubarak","Maitham F. AL-Sunni","Justin T. Dubbin","Nader Sadegh","John M. Dolan","Evangelos A. Theodorou"],"url":"https://arxiv.org/abs/2504.15453"}
{"created":"2025-04-23","title":"Field Report on Ground Penetrating Radar for Localization at the Mars Desert Research Station","abstract":"In this field report, we detail the lessons learned from our field expedition to collect Ground Penetrating Radar (GPR) data in a Mars analog environment for the purpose of validating GPR localization techniques in rugged environments. Planetary rovers are already equipped with GPR for geologic subsurface characterization. GPR has been successfully used to localize vehicles on Earth, but it has not yet been explored as another modality for localization on a planetary rover. Leveraging GPR for localization can aid in efficient and robust rover pose estimation. In order to demonstrate localizing GPR in a Mars analog environment, we collected over 50 individual survey trajectories during a two-week period at the Mars Desert Research Station (MDRS). In this report, we discuss our methodology, lessons learned, and opportunities for future work.","authors":["Anja Sheppard","Katherine A. Skinner"],"url":"https://arxiv.org/abs/2504.15455"}
{"created":"2025-04-23","title":"Improving Human-AI Coordination through Adversarial Training and Generative Models","abstract":"Being able to cooperate with new people is an important component of many economically valuable AI tasks, from household robotics to autonomous driving. However, generalizing to novel humans requires training on data that captures the diversity of human behaviors. Adversarial training is one avenue for searching for such data and ensuring that agents are robust. However, it is difficult to apply in the cooperative setting because adversarial policies intentionally learn to sabotage the task instead of simulating valid cooperation partners. To address this challenge, we propose a novel strategy for overcoming self-sabotage that combines a pre-trained generative model to simulate valid cooperative agent policies with adversarial training to maximize regret. We call our method GOAT: Generative Online Adversarial Training. In this framework, the GOAT dynamically searches for and generates coordination strategies where the learning policy -- the Cooperator agent -- underperforms. GOAT enables better generalization by exposing the Cooperator to various challenging interaction scenarios. We maintain realistic coordination strategies by updating only the generative model's embedding while keeping its parameters frozen, thus avoiding adversarial exploitation. We evaluate GOAT with real human partners, and the results demonstrate state-of-the-art performance on the Overcooked benchmark, highlighting its effectiveness in generalizing to diverse human behaviors.","authors":["Paresh Chaudhary","Yancheng Liang","Daphne Chen","Simon S. Du","Natasha Jaques"],"url":"https://arxiv.org/abs/2504.15457"}
{"created":"2025-04-23","title":"Compton Form Factor Extraction using Quantum Deep Neural Networks","abstract":"Extraction tests of Compton Form Factors are performed using pseudodata based on experimental data from Deeply Virtual Compton Scattering experiments conducted at Jefferson Lab. The standard Belitsky, Kirchner, and Muller formalism at twist-two is employed, along with a fitting procedure designed to reduce model dependency similar to traditional local fits. The extraction of the Compton Form Factors is performed using both Classical Deep Neural Networks (CDNNs) and Quantum Deep Neural Networks (QDNNs). Comparative studies reveal that QDNNs outperform CDNNs for this application, demonstrating improved predictive accuracy and precision even for limited model complexity. The results demonstrate the potential of QDNNs for future studies in which quantum algorithms can be fully optimized.","authors":["Brandon Le","Dustin Keller"],"url":"https://arxiv.org/abs/2504.15458"}
{"created":"2025-04-23","title":"LithOS: An Operating System for Efficient Machine Learning on GPUs","abstract":"The surging demand for GPUs in datacenters for machine learning (ML) has made efficient GPU utilization crucial. However, meeting the diverse needs of ML models while optimizing resource usage is challenging. To enable transparent, fine-grained GPU management that maximizes utilization and energy efficiency while maintaining strong isolation, an operating system (OS) approach is needed. This paper introduces LithOS, a first step toward a GPU OS. LithOS includes the following new abstractions and mechanisms for efficient GPU resource management: (i) a novel TPC Scheduler that supports spatial scheduling at the granularity of individual TPCs, unlocking efficient TPC stealing between workloads; (ii) transparent kernel atomization to reduce head-of-line blocking and enable dynamic resource reallocation mid-execution; (iii) a lightweight hardware right-sizing mechanism that determines the minimal TPC resources needed per atom; and (iv) a transparent power management mechanism that reduces power consumption based on in-flight work behavior. We implement LithOS in Rust and evaluate its performance across extensive ML environments, comparing it to state-of-the-art solutions from NVIDIA and prior research. For inference stacking, LithOS reduces tail latencies by 13x compared to MPS; compared to the best SotA, it reduces tail latencies by 3x while improving aggregate throughput by 1.6x. In hybrid inference-training stacking, LithOS reduces tail latencies by 4.7x compared to MPS; compared to the best SotA, it reduces tail latencies 1.18x while improving aggregate throughput by 1.35x. Finally, for a modest performance hit under 4%, LithOS's right-sizing provides a quarter of GPU capacity savings on average, while for a 7% hit, its power management yields a quarter of a GPU's energy savings. Overall, LithOS increases GPU efficiency, establishing a foundation for future OS research on GPUs.","authors":["Patrick H. Coppock","Brian Zhang","Eliot H. Solomon","Vasilis Kypriotis","Leon Yang","Bikash Sharma","Dan Schatzberg","Todd C. Mowry","Dimitrios Skarlatos"],"url":"https://arxiv.org/abs/2504.15465"}
{"created":"2025-04-23","title":"Learning Adaptive Parallel Reasoning with Language Models","abstract":"Scaling inference-time computation has substantially improved the reasoning capabilities of language models. However, existing methods have significant limitations: serialized chain-of-thought approaches generate overly long outputs, leading to increased latency and exhausted context windows, while parallel methods such as self-consistency suffer from insufficient coordination, resulting in redundant computations and limited performance gains. To address these shortcomings, we propose Adaptive Parallel Reasoning (APR), a novel reasoning framework that enables language models to orchestrate both serialized and parallel computations end-to-end. APR generalizes existing reasoning methods by enabling adaptive multi-threaded inference using spawn() and join() operations. A key innovation is our end-to-end reinforcement learning strategy, optimizing both parent and child inference threads to enhance task success rate without requiring predefined reasoning structures. Experiments on the Countdown reasoning task demonstrate significant benefits of APR: (1) higher performance within the same context window (83.4% vs. 60.0% at 4k context); (2) superior scalability with increased computation (80.1% vs. 66.6% at 20k total tokens); (3) improved accuracy at equivalent latency (75.2% vs. 57.3% at approximately 5,000ms). APR represents a step towards enabling language models to autonomously optimize their reasoning processes through adaptive allocation of computation.","authors":["Jiayi Pan","Xiuyu Li","Long Lian","Charlie Snell","Yifei Zhou","Adam Yala","Trevor Darrell","Kurt Keutzer","Alane Suhr"],"url":"https://arxiv.org/abs/2504.15466"}
{"created":"2025-04-23","title":"Aspirational Affordances of AI","abstract":"As artificial intelligence systems increasingly permeate processes of cultural and epistemic production, there are growing concerns about how their outputs may confine individuals and groups to static or restricted narratives about who or what they could be. In this paper, we advance the discourse surrounding these concerns by making three contributions. First, we introduce the concept of aspirational affordance to describe how culturally shared interpretive resources can shape individual cognition, and in particular exercises practical imagination. We show how this concept can ground productive evaluations of the risks of AI-enabled representations and narratives. Second, we provide three reasons for scrutinizing of AI's influence on aspirational affordances: AI's influence is potentially more potent, but less public than traditional sources; AI's influence is not simply incremental, but ecological, transforming the entire landscape of cultural and epistemic practices that traditionally shaped aspirational affordances; and AI's influence is highly concentrated, with a few corporate-controlled systems mediating a growing portion of aspirational possibilities. Third, to advance such a scrutiny, we introduce the concept of aspirational harm, which, in the context of AI systems, arises when AI-enabled aspirational affordances distort or diminish available interpretive resources in ways that undermine individuals' ability to imagine relevant practical possibilities and alternative futures. Through three case studies, we illustrate how aspirational harms extend the existing discourse on AI-inflicted harms beyond representational and allocative harms, warranting separate attention. Through these conceptual resources and analyses, this paper advances understanding of the psychological and societal stakes of AI's role in shaping individual and collective aspirations.","authors":["Sina Fazelpour","Meica Magnani"],"url":"https://arxiv.org/abs/2504.15469"}
{"created":"2025-04-23","title":"Manifold Induced Biases for Zero-shot and Few-shot Detection of Generated Images","abstract":"Distinguishing between real and AI-generated images, commonly referred to as 'image detection', presents a timely and significant challenge. Despite extensive research in the (semi-)supervised regime, zero-shot and few-shot solutions have only recently emerged as promising alternatives. Their main advantage is in alleviating the ongoing data maintenance, which quickly becomes outdated due to advances in generative technologies. We identify two main gaps: (1) a lack of theoretical grounding for the methods, and (2) significant room for performance improvements in zero-shot and few-shot regimes. Our approach is founded on understanding and quantifying the biases inherent in generated content, where we use these quantities as criteria for characterizing generated images. Specifically, we explore the biases of the implicit probability manifold, captured by a pre-trained diffusion model. Through score-function analysis, we approximate the curvature, gradient, and bias towards points on the probability manifold, establishing criteria for detection in the zero-shot regime. We further extend our contribution to the few-shot setting by employing a mixture-of-experts methodology. Empirical results across 20 generative models demonstrate that our method outperforms current approaches in both zero-shot and few-shot settings. This work advances the theoretical understanding and practical usage of generated content biases through the lens of manifold analysis.","authors":["Jonathan Brokman","Amit Giloni","Omer Hofman","Roman Vainshtein","Hisashi Kojima","Guy Gilboa"],"url":"https://arxiv.org/abs/2504.15470"}
{"created":"2025-04-23","title":"Bigram Subnetworks: Mapping to Next Tokens in Transformer Language Models","abstract":"In Transformer language models, activation vectors transform from current token embeddings to next token predictions as they pass through the model. To isolate a minimal form of this transformation, we identify language model subnetworks that make bigram predictions, naive next token predictions based only on the current token. We find that bigram subnetworks can be found in fully trained language models up to 1B parameters, and these subnetworks are critical for model performance even when they consist of less than 0.2% of model parameters. Bigram subnetworks are concentrated in the first Transformer MLP layer, and they overlap significantly with subnetworks trained to optimally prune a given model. Mechanistically, the bigram subnetworks often recreate a pattern from the full models where the first layer induces a sharp change that aligns activations with next token predictions rather than current token representations. Our results demonstrate that bigram subnetworks comprise a minimal subset of parameters that are both necessary and sufficient for basic next token predictions in language models, and they help drive the transformation from current to next token activations in the residual stream. These subnetworks can lay a foundation for studying language model circuits by building up from a minimal circuit rather than the traditional approach of ablating circuits from a full model.","authors":["Tyler A. Chang","Benjamin K. Bergen"],"url":"https://arxiv.org/abs/2504.15471"}
{"created":"2025-04-23","title":"LAPP: Large Language Model Feedback for Preference-Driven Reinforcement Learning","abstract":"We introduce Large Language Model-Assisted Preference Prediction (LAPP), a novel framework for robot learning that enables efficient, customizable, and expressive behavior acquisition with minimum human effort. Unlike prior approaches that rely heavily on reward engineering, human demonstrations, motion capture, or expensive pairwise preference labels, LAPP leverages large language models (LLMs) to automatically generate preference labels from raw state-action trajectories collected during reinforcement learning (RL). These labels are used to train an online preference predictor, which in turn guides the policy optimization process toward satisfying high-level behavioral specifications provided by humans. Our key technical contribution is the integration of LLMs into the RL feedback loop through trajectory-level preference prediction, enabling robots to acquire complex skills including subtle control over gait patterns and rhythmic timing. We evaluate LAPP on a diverse set of quadruped locomotion and dexterous manipulation tasks and show that it achieves efficient learning, higher final performance, faster adaptation, and precise control of high-level behaviors. Notably, LAPP enables robots to master highly dynamic and expressive tasks such as quadruped backflips, which remain out of reach for standard LLM-generated or handcrafted rewards. Our results highlight LAPP as a promising direction for scalable preference-driven robot learning.","authors":["Pingcheng Jian","Xiao Wei","Yanbaihui Liu","Samuel A. Moore","Michael M. Zavlanos","Boyuan Chen"],"url":"https://arxiv.org/abs/2504.15472"}
{"created":"2025-04-23","title":"Emergence and Evolution of Interpretable Concepts in Diffusion Models","abstract":"Diffusion models have become the go-to method for text-to-image generation, producing high-quality images from noise through a process called reverse diffusion. Understanding the dynamics of the reverse diffusion process is crucial in steering the generation and achieving high sample quality. However, the inner workings of diffusion models is still largely a mystery due to their black-box nature and complex, multi-step generation process. Mechanistic Interpretability (MI) techniques, such as Sparse Autoencoders (SAEs), aim at uncovering the operating principles of models through granular analysis of their internal representations. These MI techniques have been successful in understanding and steering the behavior of large language models at scale. However, the great potential of SAEs has not yet been applied toward gaining insight into the intricate generative process of diffusion models. In this work, we leverage the SAE framework to probe the inner workings of a popular text-to-image diffusion model, and uncover a variety of human-interpretable concepts in its activations. Interestingly, we find that even before the first reverse diffusion step is completed, the final composition of the scene can be predicted surprisingly well by looking at the spatial distribution of activated concepts. Moreover, going beyond correlational analysis, we show that the discovered concepts have a causal effect on the model output and can be leveraged to steer the generative process. We design intervention techniques aimed at manipulating image composition and style, and demonstrate that (1) in early stages of diffusion image composition can be effectively controlled, (2) in the middle stages of diffusion image composition is finalized, however stylistic interventions are effective, and (3) in the final stages of diffusion only minor textural details are subject to change.","authors":["Berk Tinaz","Zalan Fabian","Mahdi Soltanolkotabi"],"url":"https://arxiv.org/abs/2504.15473"}
{"created":"2025-04-23","title":"Agent for User: Testing Multi-User Interactive Features in TikTok","abstract":"TikTok, a widely-used social media app boasting over a billion monthly active users, requires effective app quality assurance for its intricate features. Feature testing is crucial in achieving this goal. However, the multi-user interactive features within the app, such as live streaming, voice calls, etc., pose significant challenges for developers, who must handle simultaneous device management and user interaction coordination. To address this, we introduce a novel multi-agent approach, powered by the Large Language Models (LLMs), to automate the testing of multi-user interactive app features. In detail, we build a virtual device farm that allocates the necessary number of devices for a given multi-user interactive task. For each device, we deploy an LLM-based agent that simulates a user, thereby mimicking user interactions to collaboratively automate the testing process. The evaluations on 24 multi-user interactive tasks within the TikTok app, showcase its capability to cover 75% of tasks with 85.9% action similarity and offer 87% time savings for developers. Additionally, we have also integrated our approach into the real-world TikTok testing platform, aiding in the detection of 26 multi-user interactive bugs.","authors":["Sidong Feng","Changhao Du","Huaxiao Liu","Qingnan Wang","Zhengwei Lv","Gang Huo","Xu Yang","Chunyang Chen"],"url":"https://arxiv.org/abs/2504.15474"}
{"created":"2025-04-23","title":"Speculative Sampling via Exponential Races","abstract":"Speculative decoding accelerates large language model inference using a smaller draft model. In this paper, we establish a surprising connection between speculative decoding and channel simulation, which aims at simulating a noisy channel using as few bits as possible. This connection allows us to provide an information-theoretic analysis of the speed up that can be achieved by speculative decoding. Leveraging this link, we derive an explicit relation between generation speed-up and the number of tokens $k$ generated by the draft model for large $k$, which serves as an upper bound for all $k$. We also propose a novel speculative decoding method via exponential race ERSD that matches state-of-the-art performance.","authors":["Szymon Kobus","Deniz G\\\"und\\\"uz"],"url":"https://arxiv.org/abs/2504.15475"}
{"created":"2025-04-23","title":"From Reviews to Dialogues: Active Synthesis for Zero-Shot LLM-based Conversational Recommender System","abstract":"Conversational recommender systems (CRS) typically require extensive domain-specific conversational datasets, yet high costs, privacy concerns, and data-collection challenges severely limit their availability. Although Large Language Models (LLMs) demonstrate strong zero-shot recommendation capabilities, practical applications often favor smaller, internally managed recommender models due to scalability, interpretability, and data privacy constraints, especially in sensitive or rapidly evolving domains. However, training these smaller models effectively still demands substantial domain-specific conversational data, which remains challenging to obtain. To address these limitations, we propose an active data augmentation framework that synthesizes conversational training data by leveraging black-box LLMs guided by active learning techniques. Specifically, our method utilizes publicly available non-conversational domain data, including item metadata, user reviews, and collaborative signals, as seed inputs. By employing active learning strategies to select the most informative seed samples, our approach efficiently guides LLMs to generate synthetic, semantically coherent conversational interactions tailored explicitly to the target domain. Extensive experiments validate that conversational data generated by our proposed framework significantly improves the performance of LLM-based CRS models, effectively addressing the challenges of building CRS in no- or low-resource scenarios.","authors":["Rohan Surana","Junda Wu","Zhouhang Xie","Yu Xia","Harald Steck","Dawen Liang","Nathan Kallus","Julian McAuley"],"url":"https://arxiv.org/abs/2504.15476"}
{"created":"2025-04-23","title":"In-context Ranking Preference Optimization","abstract":"Recent developments in Direct Preference Optimization (DPO) allow large language models (LLMs) to function as implicit ranking models by maximizing the margin between preferred and non-preferred responses. In practice, user feedback on such lists typically involves identifying a few relevant items in context rather than providing detailed pairwise comparisons for every possible item pair. Moreover, many complex information retrieval tasks, such as conversational agents and summarization systems, critically depend on ranking the highest-quality outputs at the top, emphasizing the need to support natural and flexible forms of user feedback. To address the challenge of limited and sparse pairwise feedback in the in-context setting, we propose an In-context Ranking Preference Optimization (IRPO) framework that directly optimizes LLMs based on ranking lists constructed during inference. To further capture flexible forms of feedback, IRPO extends the DPO objective by incorporating both the relevance of items and their positions in the list. Modeling these aspects jointly is non-trivial, as ranking metrics are inherently discrete and non-differentiable, making direct optimization difficult. To overcome this, IRPO introduces a differentiable objective based on positional aggregation of pairwise item preferences, enabling effective gradient-based optimization of discrete ranking metrics. We further provide theoretical insights showing that IRPO (i) automatically emphasizes items with greater disagreement between the model and the reference ranking, and (ii) links its gradient to an importance sampling estimator, yielding an unbiased estimator with reduced variance. Empirical results show IRPO outperforms standard DPO approaches in ranking performance, highlighting its effectiveness in aligning LLMs with direct in-context ranking preferences.","authors":["Junda Wu","Rohan Surana","Zhouhang Xie","Yiran Shen","Yu Xia","Tong Yu","Ryan A. Rossi","Prithviraj Ammanabrolu","Julian McAuley"],"url":"https://arxiv.org/abs/2504.15477"}
{"created":"2025-04-23","title":"Unifying Image Counterfactuals and Feature Attributions with Latent-Space Adversarial Attacks","abstract":"Counterfactuals are a popular framework for interpreting machine learning predictions. These what if explanations are notoriously challenging to create for computer vision models: standard gradient-based methods are prone to produce adversarial examples, in which imperceptible modifications to image pixels provoke large changes in predictions. We introduce a new, easy-to-implement framework for counterfactual images that can flexibly adapt to contemporary advances in generative modeling. Our method, Counterfactual Attacks, resembles an adversarial attack on the representation of the image along a low-dimensional manifold. In addition, given an auxiliary dataset of image descriptors, we show how to accompany counterfactuals with feature attribution that quantify the changes between the original and counterfactual images. These importance scores can be aggregated into global counterfactual explanations that highlight the overall features driving model predictions. While this unification is possible for any counterfactual method, it has particular computational efficiency for ours. We demonstrate the efficacy of our approach with the MNIST and CelebA datasets.","authors":["Jeremy Goldwasser","Giles Hooker"],"url":"https://arxiv.org/abs/2504.15479"}
{"created":"2025-04-23","title":"Under Pressure: Contextualizing Workplace Stress Towards User-Centered Interventions","abstract":"Stress is a pervasive challenge that significantly impacts worker health and well-being. Workplace stress is driven by various factors, ranging from organizational changes to poor workplace design. Although individual stress management strategies have been shown to be effective, current interventions often overlook personal and contextual factors shaping stress experiences. In this study, we conducted semi-structured interviews with eight office workers to gain a deeper understanding of their personal experiences with workplace stress. Our analysis reveals key stress triggers, coping mechanisms, and reflections on past stressful events. We highlight the multifaceted and individualized nature of workplace stress, emphasizing the importance of intervention timing, modality, and recognizing that stress is not solely a negative experience but can also have positive effects. Our findings provide actionable insights for the design of user-centered stress management solutions more attuned to the needs of office workers.","authors":["Antonin Brun","Gales Lucas","Bur\\c{c}in Becerik-Gerber"],"url":"https://arxiv.org/abs/2504.15480"}
{"created":"2025-04-23","title":"From Overload to Insight: Scaffolding Creative Ideation through Structuring Inspiration","abstract":"Creative ideation relies on exploring diverse stimuli, but the overwhelming abundance of information often makes it difficult to identify valuable insights or reach the `aha' moment. Traditional methods for accessing design stimuli lack organization and fail to support users in discovering promising opportunities within large idea spaces. In this position paper, we explore how AI can be leveraged to structure, organize, and surface relevant stimuli, guiding users in both exploring idea spaces and mapping insights back to their design challenges.","authors":["Yaqing Yang","Vikram Mohanty","Nikolas Martelaro","Aniket Kittur","Yan-Ying Chen","Matthew K. Hong"],"url":"https://arxiv.org/abs/2504.15482"}
{"created":"2025-04-23","title":"CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting","abstract":"Recognizing and reasoning about occluded (partially or fully hidden) objects is vital to understanding visual scenes, as occlusions frequently occur in real-world environments and act as obstacles for spatial comprehension. To test models' ability to reason about multiple occluded objects, we introduce a novel task, Counting Amodally for Patterns Through Unseen REgions (CAPTURe), which requires a model to count objects arranged in a pattern by inferring how the pattern continues behind an occluder (an object which blocks parts of the scene). CAPTURe requires both recognizing visual patterns and reasoning, making it a useful testbed for evaluating vision-language models (VLMs) on whether they understand occluded patterns and possess spatial understanding skills. By requiring models to reason about occluded objects, CAPTURe also tests VLMs' ability to form world models that would allow them to fill in missing information. CAPTURe consists of two parts: (1) CAPTURe-real, with manually filtered images of real objects in patterns and (2) CAPTURe-synthetic, a controlled diagnostic with generated patterned images. We evaluate four strong VLMs (GPT-4o, Intern-VL2, Molmo, and Qwen2-VL) on CAPTURe, finding that models struggle to count on both occluded and unoccluded patterns. Crucially, we find that models perform worse with occlusion, suggesting that VLMs are also deficient in inferring unseen spatial relationships: even the strongest VLMs like GPT-4o fail to count with occlusion. In contrast, we find that humans achieve very little error on CAPTURe. We also find that providing auxiliary information of occluded object locations increases performance, underscoring that the model error comes both from an inability to handle occlusion as well as difficulty counting in images.","authors":["Atin Pothiraj","Elias Stengel-Eskin","Jaemin Cho","Mohit Bansal"],"url":"https://arxiv.org/abs/2504.15485"}
{"created":"2025-04-23","title":"Fourier analysis of the physics of transfer learning for data-driven subgrid-scale models of ocean turbulence","abstract":"Transfer learning (TL) is a powerful tool for enhancing the performance of neural networks (NNs) in applications such as weather and climate prediction and turbulence modeling. TL enables models to generalize to out-of-distribution data with minimal training data from the new system. In this study, we employ a 9-layer convolutional NN to predict the subgrid forcing in a two-layer ocean quasi-geostrophic system and examine which metrics best describe its performance and generalizability to unseen dynamical regimes. Fourier analysis of the NN kernels reveals that they learn low-pass, Gabor, and high-pass filters, regardless of whether the training data are isotropic or anisotropic. By analyzing the activation spectra, we identify why NNs fail to generalize without TL and how TL can overcome these limitations: the learned weights and biases from one dataset underestimate the out-of-distribution sample spectra as they pass through the network, leading to an underestimation of output spectra. By re-training only one layer with data from the target system, this underestimation is corrected, enabling the NN to produce predictions that match the target spectra. These findings are broadly applicable to data-driven parameterization of dynamical systems.","authors":["Moein Darman","Pedram Hassanzadeh","Laure Zanna","Ashesh Chattopadhyay"],"url":"https://arxiv.org/abs/2504.15487"}
{"created":"2025-04-23","title":"Application of Deep Generative Models for Anomaly Detection in Complex Financial Transactions","abstract":"This study proposes an algorithm for detecting suspicious behaviors in large payment flows based on deep generative models. By combining Generative Adversarial Networks (GAN) and Variational Autoencoders (VAE), the algorithm is designed to detect abnormal behaviors in financial transactions. First, the GAN is used to generate simulated data that approximates normal payment flows. The discriminator identifies anomalous patterns in transactions, enabling the detection of potential fraud and money laundering behaviors. Second, a VAE is introduced to model the latent distribution of payment flows, ensuring that the generated data more closely resembles real transaction features, thus improving the model's detection accuracy. The method optimizes the generative capabilities of both GAN and VAE, ensuring that the model can effectively capture suspicious behaviors even in sparse data conditions. Experimental results show that the proposed method significantly outperforms traditional machine learning algorithms and other deep learning models across various evaluation metrics, especially in detecting rare fraudulent behaviors. Furthermore, this study provides a detailed comparison of performance in recognizing different transaction patterns (such as normal, money laundering, and fraud) in large payment flows, validating the advantages of generative models in handling complex financial data.","authors":["Tengda Tang","Jianhua Yao","Yixian Wang","Qiuwu Sha","Hanrui Feng","Zhen Xu"],"url":"https://arxiv.org/abs/2504.15491"}
{"created":"2025-04-23","title":"A dual-stage constitutive modeling framework based on finite strain data-driven identification and physics-augmented neural networks","abstract":"In this contribution, we present a novel consistent dual-stage approach for the automated generation of hyperelastic constitutive models which only requires experimentally measurable data. To generate input data for our approach, an experiment with full-field measurement has to be conducted to gather testing force and corresponding displacement field of the sample. Then, in the first step of the dual-stage framework, a new finite strain Data-Driven Identification (DDI) formulation is applied. This method enables to identify tuples consisting of stresses and strains by only prescribing the applied boundary conditions and the measured displacement field. In the second step, the data set is used to calibrate a Physics-Augmented Neural Network (PANN), which fulfills all common conditions of hyperelasticity by construction and is very flexible at the same time. We demonstrate the applicability of our approach by several descriptive examples. Two-dimensional synthetic data are exemplarily generated in virtual experiments by using a reference constitutive model. The calibrated PANN is then applied in 3D Finite Element simulations. In addition, a real experiment including noisy data is mimicked.","authors":["Lennart Linden","Karl A. Kalina","J\\\"org Brummund","Brain Riemer","Markus K\\\"astner"],"url":"https://arxiv.org/abs/2504.15492"}
{"created":"2025-04-23","title":"\"Ohhh, He's the Boss!\": Unpacking Power Dynamics Among Developers, Designers, and End-Users in FLOSS Usability","abstract":"Addressing usability in free, libre, and open-source software (FLOSS) is a challenging issue, particularly due to a long-existing \"by developer, for developer\" mentality. Engaging designers and end-users to work with developers can help improve its usability, but unequal power dynamics among those stakeholder roles must be mitigated. To explore how the power of different FLOSS stakeholders manifests and can be mediated during collaboration, we conducted eight design workshops with different combinations of key FLOSS stakeholders (i.e., developers, designers, and end-users). Leveraging existing theories on Dimensions of Power, we revealed how participants navigate existing role-based power structures through resource utilization, knowledge gap management, and experience referencing. We also observed that participants exhibited diverse behaviors confirming and challenging the status quo of FLOSS usability. Overall, our results contribute to a comprehensive understanding of the power dynamics among FLOSS stakeholders, providing valuable insights into ways to balance their power to improve FLOSS usability. Our work also serves as an exemplar of using design workshops as a research method to study power dynamics during collaboration that are usually hidden in the field.","authors":["Jazlyn Hellman","Itai Epstein","Jinghui Cheng","Jin L. C. Guo"],"url":"https://arxiv.org/abs/2504.15494"}
{"created":"2025-04-23","title":"Scalable APT Malware Classification via Parallel Feature Extraction and GPU-Accelerated Learning","abstract":"This paper presents an underlying framework for both automating and accelerating malware classification, more specifically, mapping malicious executables to known Advanced Persistent Threat (APT) groups. The main feature of this analysis is the assembly-level instructions present in executables which are also known as opcodes. The collection of such opcodes on many malicious samples is a lengthy process; hence, open-source reverse engineering tools are used in tandem with scripts that leverage parallel computing to analyze multiple files at once. Traditional and deep learning models are applied to create models capable of classifying malware samples. One-gram and two-gram datasets are constructed and used to train models such as SVM, KNN, and Decision Tree; however, they struggle to provide adequate results without relying on metadata to support n-gram sequences. The computational limitations of such models are overcome with convolutional neural networks (CNNs) and heavily accelerated using graphical compute unit (GPU) resources.","authors":["Noah Subedar","Taeui Kim","Saathwick Venkataramalingam"],"url":"https://arxiv.org/abs/2504.15497"}
{"created":"2025-04-23","title":"Guillotine: Hypervisors for Isolating Malicious AIs","abstract":"As AI models become more embedded in critical sectors like finance, healthcare, and the military, their inscrutable behavior poses ever-greater risks to society. To mitigate this risk, we propose Guillotine, a hypervisor architecture for sandboxing powerful AI models -- models that, by accident or malice, can generate existential threats to humanity. Although Guillotine borrows some well-known virtualization techniques, Guillotine must also introduce fundamentally new isolation mechanisms to handle the unique threat model posed by existential-risk AIs. For example, a rogue AI may try to introspect upon hypervisor software or the underlying hardware substrate to enable later subversion of that control plane; thus, a Guillotine hypervisor requires careful co-design of the hypervisor software and the CPUs, RAM, NIC, and storage devices that support the hypervisor software, to thwart side channel leakage and more generally eliminate mechanisms for AI to exploit reflection-based vulnerabilities. Beyond such isolation at the software, network, and microarchitectural layers, a Guillotine hypervisor must also provide physical fail-safes more commonly associated with nuclear power plants, avionic platforms, and other types of mission critical systems. Physical fail-safes, e.g., involving electromechanical disconnection of network cables, or the flooding of a datacenter which holds a rogue AI, provide defense in depth if software, network, and microarchitectural isolation is compromised and a rogue AI must be temporarily shut down or permanently destroyed.","authors":["James Mickens","Sarah Radway","Ravi Netravali"],"url":"https://arxiv.org/abs/2504.15499"}
{"created":"2025-04-23","title":"Are Widely Known Findings Easier to Retract?","abstract":"Failures of retraction are common in science. Why do these failures occur? And, relatedly, what makes findings harder or easier to retract? We use data from Microsoft Academic Graph, Retraction Watch, and Altmetric -- including retracted papers, citation records, and Altmetric scores and mentions -- to test recently proposed answers to these questions. A recent previous study by LaCroix et al. employ simple network models to argue that the social spread of scientific information helps explain failures of retraction. One prediction of their models is that widely known or well established results, surprisingly, should be easier to retract, since their retraction is more relevant to more scientists. Our results support this conclusion. We find that highly cited papers show more significant reductions in citation after retraction and garner more attention to their retractions as they occur.","authors":["Shahan Ali Memon","Jevin D. West","Cailin O'Connor"],"url":"https://arxiv.org/abs/2504.15504"}
{"created":"2025-04-23","title":"Automatically Detecting Numerical Instability in Machine Learning Applications via Soft Assertions","abstract":"Machine learning (ML) applications have become an integral part of our lives. ML applications extensively use floating-point computation and involve very large/small numbers; thus, maintaining the numerical stability of such complex computations remains an important challenge. Numerical bugs can lead to system crashes, incorrect output, and wasted computing resources. In this paper, we introduce a novel idea, namely soft assertions (SA), to encode safety/error conditions for the places where numerical instability can occur. A soft assertion is an ML model automatically trained using the dataset obtained during unit testing of unstable functions. Given the values at the unstable function in an ML application, a soft assertion reports how to change these values in order to trigger the instability. We then use the output of soft assertions as signals to effectively mutate inputs to trigger numerical instability in ML applications. In the evaluation, we used the GRIST benchmark, a total of 79 programs, as well as 15 real-world ML applications from GitHub. We compared our tool with 5 state-of-the-art (SOTA) fuzzers. We found all the GRIST bugs and outperformed the baselines. We found 13 numerical bugs in real-world code, one of which had already been confirmed by the GitHub developers. While the baselines mostly found the bugs that report NaN and INF, our tool \\tool found numerical bugs with incorrect output. We showed one case where the Tumor Detection Model, trained on Brain MRI images, should have predicted \"tumor\", but instead, it incorrectly predicted \"no tumor\" due to the numerical bugs. Our replication package is located at https://figshare.com/s/6528d21ccd28bea94c32.","authors":["Shaila Sharmin","Anwar Hossain Zahid","Subhankar Bhattacharjee","Chiamaka Igwilo","Miryung Kim","Wei Le"],"url":"https://arxiv.org/abs/2504.15507"}
{"created":"2025-04-23","title":"Scaling Neural-Network-Based Molecular Dynamics with Long-Range Electrostatic Interactions to 51 Nanoseconds per Day","abstract":"Neural network-based molecular dynamics (NNMD) simulations incorporating long-range electrostatic interactions have significantly extended the applicability to heterogeneous and ionic systems, enabling effective modeling critical physical phenomena such as protein folding and dipolar surface and maintaining ab initio accuracy. However, neural network inference and long-range force computation remain the major bottlenecks, severely limiting simulation speed. In this paper, we target DPLR, a state-of-the-art NNMD package that supports long-range electrostatics, and propose a set of comprehensive optimizations to enhance computational efficiency. We introduce (1) a hardware-offloaded FFT method to reduce the communication overhead; (2) an overlapping strategy that hides long-range force computations using a single core per node, and (3) a ring-based load balancing method that enables atom-level task evenly redistribution with minimal communication overhead. Experimental results on the Fugaku supercomputer show that our work achieves a 37x performance improvement, reaching a maximum simulation speed of 51 ns/day.","authors":["Jianxiong Li","Beining Zhang","Mingzhen Li","Siyu Hu","Jinzhe Zeng","Lijun Liu","Guojun Yuan","Zhan Wang","Guangming Tan","Weile Jia"],"url":"https://arxiv.org/abs/2504.15508"}
{"created":"2025-04-23","title":"SimulS2S-LLM: Unlocking Simultaneous Inference of Speech LLMs for Speech-to-Speech Translation","abstract":"Simultaneous speech translation (SST) outputs translations in parallel with streaming speech input, balancing translation quality and latency. While large language models (LLMs) have been extended to handle the speech modality, streaming remains challenging as speech is prepended as a prompt for the entire generation process. To unlock LLM streaming capability, this paper proposes SimulS2S-LLM, which trains speech LLMs offline and employs a test-time policy to guide simultaneous inference. SimulS2S-LLM alleviates the mismatch between training and inference by extracting boundary-aware speech prompts that allows it to be better matched with text input data. SimulS2S-LLM achieves simultaneous speech-to-speech translation (Simul-S2ST) by predicting discrete output speech tokens and then synthesising output speech using a pre-trained vocoder. An incremental beam search is designed to expand the search space of speech token prediction without increasing latency. Experiments on the CVSS speech data show that SimulS2S-LLM offers a better translation quality-latency trade-off than existing methods that use the same training data, such as improving ASR-BLEU scores by 3 points at similar latency.","authors":["Keqi Deng","Wenxi Chen","Xie Chen","Philip C. Woodland"],"url":"https://arxiv.org/abs/2504.15509"}
{"created":"2025-04-23","title":"T2VShield: Model-Agnostic Jailbreak Defense for Text-to-Video Models","abstract":"The rapid development of generative artificial intelligence has made text to video models essential for building future multimodal world simulators. However, these models remain vulnerable to jailbreak attacks, where specially crafted prompts bypass safety mechanisms and lead to the generation of harmful or unsafe content. Such vulnerabilities undermine the reliability and security of simulation based applications. In this paper, we propose T2VShield, a comprehensive and model agnostic defense framework designed to protect text to video models from jailbreak threats. Our method systematically analyzes the input, model, and output stages to identify the limitations of existing defenses, including semantic ambiguities in prompts, difficulties in detecting malicious content in dynamic video outputs, and inflexible model centric mitigation strategies. T2VShield introduces a prompt rewriting mechanism based on reasoning and multimodal retrieval to sanitize malicious inputs, along with a multi scope detection module that captures local and global inconsistencies across time and modalities. The framework does not require access to internal model parameters and works with both open and closed source systems. Extensive experiments on five platforms show that T2VShield can reduce jailbreak success rates by up to 35 percent compared to strong baselines. We further develop a human centered audiovisual evaluation protocol to assess perceptual safety, emphasizing the importance of visual level defense in enhancing the trustworthiness of next generation multimodal simulators.","authors":["Siyuan Liang","Jiayang Liu","Jiecheng Zhai","Tianmeng Fang","Rongcheng Tu","Aishan Liu","Xiaochun Cao","Dacheng Tao"],"url":"https://arxiv.org/abs/2504.15512"}
{"created":"2025-04-23","title":"InstaRevive: One-Step Image Enhancement via Dynamic Score Matching","abstract":"Image enhancement finds wide-ranging applications in real-world scenarios due to complex environments and the inherent limitations of imaging devices. Recent diffusion-based methods yield promising outcomes but necessitate prolonged and computationally intensive iterative sampling. In response, we propose InstaRevive, a straightforward yet powerful image enhancement framework that employs score-based diffusion distillation to harness potent generative capability and minimize the sampling steps. To fully exploit the potential of the pre-trained diffusion model, we devise a practical and effective diffusion distillation pipeline using dynamic control to address inaccuracies in updating direction during score matching. Our control strategy enables a dynamic diffusing scope, facilitating precise learning of denoising trajectories within the diffusion model and ensuring accurate distribution matching gradients during training. Additionally, to enrich guidance for the generative power, we incorporate textual prompts via image captioning as auxiliary conditions, fostering further exploration of the diffusion model. Extensive experiments substantiate the efficacy of our framework across a diverse array of challenging tasks and datasets, unveiling the compelling efficacy and efficiency of InstaRevive in delivering high-quality and visually appealing results. Code is available at https://github.com/EternalEvan/InstaRevive.","authors":["Yixuan Zhu","Haolin Wang","Ao Li","Wenliang Zhao","Yansong Tang","Jingxuan Niu","Lei Chen","Jie Zhou","Jiwen Lu"],"url":"https://arxiv.org/abs/2504.15513"}
{"created":"2025-04-23","title":"Derivatives of tree tensor networks and its applications in Runge--Kutta methods","abstract":"Tree tensor networks (TTNs) provide a compact and structured representation of high-dimensional data, making them valuable in various areas of computational mathematics and physics. In this paper, we present a rigorous mathematical framework for expressing high-order derivatives of functional TTNs, both with or without constraints. Our framework decomposes the total derivative of a given TTN into a summation of TTNs, each corresponding to the partial derivatives of the original TTN. Using this decomposition, we derive the Taylor expansion of vector-valued functions subject to ordinary differential equation constraints or algebraic constraints imposed by Runge--Kutta (RK) methods. As a concrete application, we employ this framework to construct order conditions for RK methods. Due to the intrinsic tensor properties of partial derivatives and the separable tensor structure in RK methods, the Taylor expansion of numerical solutions can be obtained in a manner analogous to that of exact solutions using tensor operators. This enables the order conditions of RK methods to be established by directly comparing the Taylor expansions of the exact and numerical solutions, eliminating the need for mathematical induction. For a given function $\\vector{f}$, we derive sharper order conditions that go beyond the classical ones, enabling the identification of situations where a standard RK scheme of order {\\it p} achieves unexpectedly higher convergence order for the particular function. These results establish new connections between tensor network theory and classical numerical methods, potentially opening new avenues for both analytical exploration and practical computation.","authors":["Junyuan He","Zhonghao Sun","Jizu Huang"],"url":"https://arxiv.org/abs/2504.15516"}
{"created":"2025-04-23","title":"Few-Shot Vision-Language Action-Incremental Policy Learning","abstract":"Recently, Transformer-based robotic manipulation methods utilize multi-view spatial representations and language instructions to learn robot motion trajectories by leveraging numerous robot demonstrations. However, the collection of robot data is extremely challenging, and existing methods lack the capability for continuous learning on new tasks with only a few demonstrations. In this paper, we formulate these challenges as the Few-Shot Action-Incremental Learning (FSAIL) task, and accordingly design a Task-prOmpt graPh evolutIon poliCy (TOPIC) to address these issues. Specifically, to address the data scarcity issue in robotic imitation learning, TOPIC learns Task-Specific Prompts (TSP) through the deep interaction of multi-modal information within few-shot demonstrations, thereby effectively extracting the task-specific discriminative information. On the other hand, to enhance the capability for continual learning on new tasks and mitigate the issue of catastrophic forgetting, TOPIC adopts a Continuous Evolution Strategy (CES). CES leverages the intrinsic relationships between tasks to construct a task relation graph, which effectively facilitates the adaptation of new tasks by reusing skills learned from previous tasks. TOPIC pioneers few-shot continual learning in the robotic manipulation task, and extensive experimental results demonstrate that TOPIC outperforms state-of-the-art baselines by over 26$\\%$ in success rate, significantly enhancing the continual learning capabilities of existing Transformer-based policies.","authors":["Mingchen Song","Xiang Deng","Guoqiang Zhong","Qi Lv","Jia Wan","Yinchuan Li","Jianye Hao","Weili Guan"],"url":"https://arxiv.org/abs/2504.15517"}
{"created":"2025-04-23","title":"The Bitter Lesson Learned from 2,000+ Multilingual Benchmarks","abstract":"As large language models (LLMs) continue to advance in linguistic capabilities, robust multilingual evaluation has become essential for promoting equitable technological progress. This position paper examines over 2,000 multilingual (non-English) benchmarks from 148 countries, published between 2021 and 2024, to evaluate past, present, and future practices in multilingual benchmarking. Our findings reveal that, despite significant investments amounting to tens of millions of dollars, English remains significantly overrepresented in these benchmarks. Additionally, most benchmarks rely on original language content rather than translations, with the majority sourced from high-resource countries such as China, India, Germany, the UK, and the USA. Furthermore, a comparison of benchmark performance with human judgments highlights notable disparities. STEM-related tasks exhibit strong correlations with human evaluations (0.70 to 0.85), while traditional NLP tasks like question answering (e.g., XQuAD) show much weaker correlations (0.11 to 0.30). Moreover, translating English benchmarks into other languages proves insufficient, as localized benchmarks demonstrate significantly higher alignment with local human judgments (0.68) than their translated counterparts (0.47). This underscores the importance of creating culturally and linguistically tailored benchmarks rather than relying solely on translations. Through this comprehensive analysis, we highlight six key limitations in current multilingual evaluation practices, propose the guiding principles accordingly for effective multilingual benchmarking, and outline five critical research directions to drive progress in the field. Finally, we call for a global collaborative effort to develop human-aligned benchmarks that prioritize real-world applications.","authors":["Minghao Wu","Weixuan Wang","Sinuo Liu","Huifeng Yin","Xintong Wang","Yu Zhao","Chenyang Lyu","Longyue Wang","Weihua Luo","Kaifu Zhang"],"url":"https://arxiv.org/abs/2504.15521"}
{"created":"2025-04-23","title":"IPBench: Benchmarking the Knowledge of Large Language Models in Intellectual Property","abstract":"Intellectual Property (IP) is a unique domain that integrates technical and legal knowledge, making it inherently complex and knowledge-intensive. As large language models (LLMs) continue to advance, they show great potential for processing IP tasks, enabling more efficient analysis, understanding, and generation of IP-related content. However, existing datasets and benchmarks either focus narrowly on patents or cover limited aspects of the IP field, lacking alignment with real-world scenarios. To bridge this gap, we introduce the first comprehensive IP task taxonomy and a large, diverse bilingual benchmark, IPBench, covering 8 IP mechanisms and 20 tasks. This benchmark is designed to evaluate LLMs in real-world intellectual property applications, encompassing both understanding and generation. We benchmark 16 LLMs, ranging from general-purpose to domain-specific models, and find that even the best-performing model achieves only 75.8% accuracy, revealing substantial room for improvement. Notably, open-source IP and law-oriented models lag behind closed-source general-purpose models. We publicly release all data and code of IPBench and will continue to update it with additional IP-related tasks to better reflect real-world challenges in the intellectual property domain.","authors":["Qiyao Wang","Guhong Chen","Hongbo Wang","Huaren Liu","Minghui Zhu","Zhifei Qin","Linwei Li","Yilin Yue","Shiqiang Wang","Jiayan Li","Yihang Wu","Ziqiang Liu","Longze Chen","Run Luo","Liyang Fan","Jiaming Li","Lei Zhang","Kan Xu","Hongfei Lin","Hamid Alinejad-Rokny","Shiwen Ni","Yuan Lin","Min Yang"],"url":"https://arxiv.org/abs/2504.15524"}
{"created":"2025-04-23","title":"Federated Latent Factor Learning for Recovering Wireless Sensor Networks Signal with Privacy-Preserving","abstract":"Wireless Sensor Networks (WSNs) are a cutting-edge domain in the field of intelligent sensing. Due to sensor failures and energy-saving strategies, the collected data often have massive missing data, hindering subsequent analysis and decision-making. Although Latent Factor Learning (LFL) has been proven effective in recovering missing data, it fails to sufficiently consider data privacy protection. To address this issue, this paper innovatively proposes a federated latent factor learning (FLFL) based spatial signal recovery (SSR) model, named FLFL-SSR. Its main idea is two-fold: 1) it designs a sensor-level federated learning framework, where each sensor uploads only gradient updates instead of raw data to optimize the global model, and 2) it proposes a local spatial sharing strategy, allowing sensors within the same spatial region to share their latent feature vectors, capturing spatial correlations and enhancing recovery accuracy. Experimental results on two real-world WSNs datasets demonstrate that the proposed model outperforms existing federated methods in terms of recovery performance.","authors":["Chengjun Yu","Yixin Ran","Yangyi Xia","Jia Wu","Xiaojing Liu"],"url":"https://arxiv.org/abs/2504.15525"}
{"created":"2025-04-23","title":"Compass-V2 Technical Report","abstract":"Predominant LLMs focus on high-resource languages while leaving low-resource languages, particularly those in Southeast Asia (SEA), underrepresented. In addition, those models are general-purpose and pay limited attention to the e-commerce domain. To overcome these limitations, we introduce Compass-v2, a lightweight Mixture-of-Experts (MoE) model specifically designed for Southeast Asian languages and e-commerce applications. To balance model performance and inference cost, the model is designed with 30B total parameters and 5B active parameters, incorporating both fine-grained and shared expert modules. To enhance multilingual performance, we curated and constructed a high-quality, industry-leading SEA dataset, to the best of our knowledge. To boost performance in the e-commerce domain, we built a dataset comprising hundreds of billions of tokens, sourced through external data mining and internal platform collection. Besides, we pioneered a hybrid reasoning model that supports both fast thinking and deep thinking within a unified framework to enhance the reasoning capabilities, diverging from the conventional industry practice of deploying two separate models. Through extensive experimental evaluations, our model demonstrates state-of-the-art SEA multilingual and e-commerce performance among sub-30B models, while maintaining significantly lower inference cost.","authors":["Sophia Maria"],"url":"https://arxiv.org/abs/2504.15527"}
{"created":"2025-04-23","title":"Quantum-Related Methods for Solving Set Constraint Problems","abstract":"In this paper, we propose two new methods for solving Set Constraint Problems. While current methods focus on classical techniques, we offer both a quantum-inspired matrix method and a quantum matrix method that neutralizes common contradictions and inconsistencies that appear in these types of problems. We start by formally defining a Set Constraint Problem. We then explain current, classical methods that are used to solve these problems and the drawbacks of such methods. After this, we explain a new quantum-inspired matrix method that allows us to solve these problems, with classical limitations. Finally, we explain a new quantum matrix method that solves these problems using quantum information science.","authors":["Neema Rustin Badihian"],"url":"https://arxiv.org/abs/2504.15529"}
{"created":"2025-04-23","title":"Towards Resilience and Autonomy-based Approaches for Adolescents Online Safety","abstract":"In this position paper, we discuss the paradigm shift that has emerged in the literature, suggesting to move away from restrictive and authoritarian parental mediation approaches to move toward resilient-based and privacy-preserving solutions to promote adolescents' online safety. We highlight the limitations of restrictive mediation strategies, which often induce a trade-off between teens' privacy and online safety, and call for more teen-centric frameworks that can empower teens to self-regulate while using the technology in meaningful ways. We also present an overview of empirical studies that conceptualized and examined resilience-based approaches to promoting the digital well-being of teens in a way to empower teens to be more resilient.","authors":["Jinkyung Park","Mamtaj Akter","Naima Samreen Ali","Zainab Agha","Ashwaq Alsoubai","Pamela Wisniewski"],"url":"https://arxiv.org/abs/2504.15533"}
{"created":"2025-04-23","title":"VibeCheck: Using Active Acoustic Tactile Sensing for Contact-Rich Manipulation","abstract":"The acoustic response of an object can reveal a lot about its global state, for example its material properties or the extrinsic contacts it is making with the world. In this work, we build an active acoustic sensing gripper equipped with two piezoelectric fingers: one for generating signals, the other for receiving them. By sending an acoustic vibration from one finger to the other through an object, we gain insight into an object's acoustic properties and contact state. We use this system to classify objects, estimate grasping position, estimate poses of internal structures, and classify the types of extrinsic contacts an object is making with the environment. Using our contact type classification model, we tackle a standard long-horizon manipulation problem: peg insertion. We use a simple simulated transition model based on the performance of our sensor to train an imitation learning policy that is robust to imperfect predictions from the classifier. We finally demonstrate the policy on a UR5 robot with active acoustic sensing as the only feedback.","authors":["Kaidi Zhang","Do-Gon Kim","Eric T. Chang","Hua-Hsuan Liang","Zhanpeng He","Kathryn Lampo","Philippe Wu","Ioannis Kymissis","Matei Ciocarlie"],"url":"https://arxiv.org/abs/2504.15535"}
{"created":"2025-04-23","title":"Interpretable Deep Learning for Polar Mechanistic Reaction Prediction","abstract":"Accurately predicting chemical reactions is essential for driving innovation in synthetic chemistry, with broad applications in medicine, manufacturing, and agriculture. At the same time, reaction prediction is a complex problem which can be both time-consuming and resource-intensive for chemists to solve. Deep learning methods offer an appealing solution by enabling high-throughput reaction prediction. However, many existing models are trained on the US Patent Office dataset and treat reactions as overall transformations: mapping reactants directly to products with limited interpretability or mechanistic insight. To address this, we introduce PMechRP (Polar Mechanistic Reaction Predictor), a system that trains machine learning models on the PMechDB dataset, which represents reactions as polar elementary steps that capture electron flow and mechanistic detail. To further expand model coverage and improve generalization, we augment PMechDB with a diverse set of combinatorially generated reactions. We train and compare a range of machine learning models, including transformer-based, graph-based, and two-step siamese architectures. Our best-performing approach was a hybrid model, which combines a 5-ensemble of Chemformer models with a two-step Siamese framework to leverage the accuracy of transformer architectures, while filtering away \"alchemical\" products using the two-step network predictions. For evaluation, we use a test split of the PMechDB dataset and additionally curate a human benchmark dataset consisting of complete mechanistic pathways extracted from an organic chemistry textbook. Our hybrid model achieves a top-10 accuracy of 94.9% on the PMechDB test set and a target recovery rate of 84.9% on the pathway dataset.","authors":["Ryan J. Miller","Alexander E. Dashuta","Brayden Rudisill","David Van Vranken","Pierre Baldi"],"url":"https://arxiv.org/abs/2504.15539"}
{"created":"2025-04-23","title":"Explicit Ensemble Mean Clock Synchronization for Optimal Atomic Time Scale Generation","abstract":"This paper presents a novel theoretical framework for atomic time scale generation, called explicit ensemble mean synchronization, which unifies clock synchronization and time scale generation within a control-theoretic paradigm. By exploiting an observable canonical decomposition of a standard atomic clock ensemble model, the system is decomposed into two complementary components: the observable part, which represents the synchronization deviation, and the unobservable part, which captures the synchronization destination. Within this structure, we mathematically prove that standard Kalman filtering, widely used in current time scale generation, can be interpreted as a special case of the proposed framework that optimizes long-term frequency stability in terms of the Allan variance. Furthermore, by applying appropriate state feedback control to each component based on the Kalman filtering, both clock synchronization and optimal time scale generation are achieved within a unified framework. This framework provides a principled basis for robust timekeeping systems that goes beyond conventional approaches in both scope and performance.","authors":["Takayuki Ishizaki","Takahiro Kawaguchi","Yuichiro Yano","Yuko Hanado"],"url":"https://arxiv.org/abs/2504.15540"}
{"created":"2025-04-23","title":"RiskNet: Interaction-Aware Risk Forecasting for Autonomous Driving in Long-Tail Scenarios","abstract":"Ensuring the safety of autonomous vehicles (AVs) in long-tail scenarios remains a critical challenge, particularly under high uncertainty and complex multi-agent interactions. To address this, we propose RiskNet, an interaction-aware risk forecasting framework, which integrates deterministic risk modeling with probabilistic behavior prediction for comprehensive risk assessment. At its core, RiskNet employs a field-theoretic model that captures interactions among ego vehicle, surrounding agents, and infrastructure via interaction fields and force. This model supports multidimensional risk evaluation across diverse scenarios (highways, intersections, and roundabouts), and shows robustness under high-risk and long-tail settings. To capture the behavioral uncertainty, we incorporate a graph neural network (GNN)-based trajectory prediction module, which learns multi-modal future motion distributions. Coupled with the deterministic risk field, it enables dynamic, probabilistic risk inference across time, enabling proactive safety assessment under uncertainty. Evaluations on the highD, inD, and rounD datasets, spanning lane changes, turns, and complex merges, demonstrate that our method significantly outperforms traditional approaches (e.g., TTC, THW, RSS, NC Field) in terms of accuracy, responsiveness, and directional sensitivity, while maintaining strong generalization across scenarios. This framework supports real-time, scenario-adaptive risk forecasting and demonstrates strong generalization across uncertain driving environments. It offers a unified foundation for safety-critical decision-making in long-tail scenarios.","authors":["Qichao Liu","Heye Huang","Shiyue Zhao","Lei Shi","Soyoung Ahn","Xiaopeng Li"],"url":"https://arxiv.org/abs/2504.15541"}
{"created":"2025-04-23","title":"llm-jp-modernbert: A ModernBERT Model Trained on a Large-Scale Japanese Corpus with Long Context Length","abstract":"Encoder-only transformer models like BERT are widely adopted as a pre-trained backbone for tasks like sentence classification and retrieval. However, pretraining of encoder models with large-scale corpora and long contexts has been relatively underexplored compared to decoder-only transformers. In this work, we present llm-jp-modernbert, a ModernBERT model trained on a publicly available, massive Japanese corpus with a context length of 8192 tokens. While our model does not surpass existing baselines on downstream tasks, it achieves good results on fill-mask test evaluations. We also analyze the effect of context length expansion through pseudo-perplexity experiments. Furthermore, we investigate sentence embeddings in detail, analyzing their transitions during training and comparing them with those from other existing models, confirming similar trends with models sharing the same architecture. To support reproducibility and foster the development of long-context BERT, we release our model, along with the training and evaluation code.","authors":["Issa Sugiura","Kouta Nakayama","Yusuke Oda"],"url":"https://arxiv.org/abs/2504.15544"}
{"created":"2025-04-23","title":"A Framework for Testing and Adapting REST APIs as LLM Tools","abstract":"Large Language Models (LLMs) are enabling autonomous agents to perform complex workflows using external tools or functions, often provided via REST APIs in enterprise systems. However, directly utilizing these APIs as tools poses challenges due to their complex input schemas, elaborate responses, and often ambiguous documentation. Current benchmarks for tool testing do not adequately address these complexities, leading to a critical gap in evaluating API readiness for agent-driven automation. In this work, we present a novel testing framework aimed at evaluating and enhancing the readiness of REST APIs to function as tools for LLM-based agents. Our framework transforms apis as tools, generates comprehensive test cases for the APIs, translates tests cases into natural language instructions suitable for agents, enriches tool definitions and evaluates the agent's ability t correctly invoke the API and process its inputs and responses. To provide actionable insights, we analyze the outcomes of 750 test cases, presenting a detailed taxonomy of errors, including input misinterpretation, output handling inconsistencies, and schema mismatches. Additionally, we classify these test cases to streamline debugging and refinement of tool integrations. This work offers a foundational step toward enabling enterprise APIs as tools, improving their usability in agent-based applications.","authors":["Jayachandu Bandlamudi","Ritwik Chaudhuri","Neelamadhav Gantayat","Kushal Mukherjee","Prerna Agarwal","Renuka Sindhgatta","Sameep Mehta"],"url":"https://arxiv.org/abs/2504.15546"}
{"created":"2025-04-23","title":"Adaptivity Gaps for Stochastic Probing with Subadditive Functions","abstract":"In this paper, we study the stochastic probing problem under a general monotone norm objective. Given a ground set $U = [n]$, each element $i \\in U$ has an independent nonnegative random variable $X_i$ with known distribution. Probing an element reveals its value, and the sequence of probed elements must satisfy a prefix-closed feasibility constraint $\\mathcal{F}$. A monotone norm $f: \\mathbb{R}_{\\geq 0}^n \\to \\mathbb{R}_{\\geq 0}$ determines the reward $f(X_P)$, where $P$ is the set of probed elements and $X_P$ is the vector with $X_i$ for $i \\in P$ and 0 otherwise. The goal is to design a probing strategy maximizing the expected reward $\\mathbb{E}[f(X_P)]$. We focus on the adaptivity gap: the ratio between the expected rewards of optimal adaptive and optimal non-adaptive strategies. We resolve an open question posed in [GNS17, KMS24], showing that for general monotone norms, the adaptivity gap is $O(\\log^2 n)$. A refined analysis yields an improved bound of $O(\\log r \\log n / \\log\\log n)$, where $r$ is the maximum size of a feasible probing sequence. As a by-product, we derive an asymptotically tight adaptivity gap $\\Theta(\\log n / \\log\\log n)$ for Bernoulli probing with binary-XOS objectives, matching the known lower bound. Additionally, we show an $O(\\log^3 n)$ upper bound for Bernoulli probing with general subadditive objectives. For monotone symmetric norms, we prove the adaptivity gap is $O(1)$, improving the previous $O(\\log n)$ bound from [PRS23].","authors":["Jian Li","Yinchen Liu","Yiran Zhang"],"url":"https://arxiv.org/abs/2504.15547"}
{"created":"2025-04-23","title":"LLM-based Semantic Augmentation for Harmful Content Detection","abstract":"Recent advances in large language models (LLMs) have demonstrated strong performance on simple text classification tasks, frequently under zero-shot settings. However, their efficacy declines when tackling complex social media challenges such as propaganda detection, hateful meme classification, and toxicity identification. Much of the existing work has focused on using LLMs to generate synthetic training data, overlooking the potential of LLM-based text preprocessing and semantic augmentation. In this paper, we introduce an approach that prompts LLMs to clean noisy text and provide context-rich explanations, thereby enhancing training sets without substantial increases in data volume. We systematically evaluate on the SemEval 2024 multi-label Persuasive Meme dataset and further validate on the Google Jigsaw toxic comments and Facebook hateful memes datasets to assess generalizability. Our results reveal that zero-shot LLM classification underperforms on these high-context tasks compared to supervised models. In contrast, integrating LLM-based semantic augmentation yields performance on par with approaches that rely on human-annotated data, at a fraction of the cost. These findings underscore the importance of strategically incorporating LLMs into machine learning (ML) pipeline for social media classification tasks, offering broad implications for combating harmful content online.","authors":["Elyas Meguellati","Assaad Zeghina","Shazia Sadiq","Gianluca Demartini"],"url":"https://arxiv.org/abs/2504.15548"}
{"created":"2025-04-23","title":"Do It For Me vs. Do It With Me: Investigating User Perceptions of Different Paradigms of Automation in Copilots for Feature-Rich Software","abstract":"Large Language Model (LLM)-based in-application assistants, or copilots, can automate software tasks, but users often prefer learning by doing, raising questions about the optimal level of automation for an effective user experience. We investigated two automation paradigms by designing and implementing a fully automated copilot (AutoCopilot) and a semi-automated copilot (GuidedCopilot) that automates trivial steps while offering step-by-step visual guidance. In a user study (N=20) across data analysis and visual design tasks, GuidedCopilot outperformed AutoCopilot in user control, software utility, and learnability, especially for exploratory and creative tasks, while AutoCopilot saved time for simpler visual tasks. A follow-up design exploration (N=10) enhanced GuidedCopilot with task-and state-aware features, including in-context preview clips and adaptive instructions. Our findings highlight the critical role of user control and tailored guidance in designing the next generation of copilots that enhance productivity, support diverse skill levels, and foster deeper software engagement.","authors":["Anjali Khurana","Xiaotian Su","April Yi Wang","Parmit K Chilana"],"url":"https://arxiv.org/abs/2504.15549"}
{"created":"2025-04-23","title":"Smooth, Integrated Proofs of Cryptographic Constant Time for Nondeterministic Programs and Compilers","abstract":"Formal verification of software and compilers has been used to rule out large classes of security-critical issues, but risk of unintentional information leakage has received much less consideration. It is a key requirement for formal specifications to leave some details of a system's behavior unspecified so that future implementation changes can be accommodated, and yet it is nonetheless expected that these choices would not be made based on confidential information the system handles. This paper formalizes that notion using omnisemantics and plain single-copy assertions, giving for the first time a specification of what it means for a nondeterministic program to be constant-time or more generally to avoid leaking (a part of) its inputs. We use this theory to prove data-leak-free execution of core cryptographic routines compiled from Bedrock2 C to RISC-V machine code, showing that the smooth specification and proof experience omnisemantics provides for nondeterminism extends to constant-time properties in the same setting. We also study variants of the key program-compiler contract, highlighting pitfalls of tempting simplifications and subtle consequences of how inputs to nondeterministic choices are constrained. Our results are backed by modular program-logic and compiler-correctness theorems, and they integrate into a neat end-to-end theorem in the Coq proof assistant.","authors":["Owen Conoly","Andres Erbsen","Adam Chlipala"],"url":"https://arxiv.org/abs/2504.15550"}
{"created":"2025-04-23","title":"A Multi-Agent Framework for Automated Qinqiang Opera Script Generation Using Large Language Models","abstract":"This paper introduces a novel multi-Agent framework that automates the end to end production of Qinqiang opera by integrating Large Language Models , visual generation, and Text to Speech synthesis. Three specialized agents collaborate in sequence: Agent1 uses an LLM to craft coherent, culturally grounded scripts;Agent2 employs visual generation models to render contextually accurate stage scenes; and Agent3 leverages TTS to produce synchronized, emotionally expressive vocal performances. In a case study on Dou E Yuan, the system achieved expert ratings of 3.8 for script fidelity, 3.5 for visual coherence, and 3.8 for speech accuracy-culminating in an overall score of 3.6, a 0.3 point improvement over a Single Agent baseline. Ablation experiments demonstrate that removing Agent2 or Agent3 leads to drops of 0.4 and 0.5 points, respectively, underscoring the value of modular collaboration. This work showcases how AI driven pipelines can streamline and scale the preservation of traditional performing arts, and points toward future enhancements in cross modal alignment, richer emotional nuance, and support for additional opera genres.","authors":["Gengxian Cao","Fengyuan Li","Hong Duan","Ye Yang","Bofeng Wang","Donghe Li"],"url":"https://arxiv.org/abs/2504.15552"}
{"created":"2025-04-23","title":"SPECI: Skill Prompts based Hierarchical Continual Imitation Learning for Robot Manipulation","abstract":"Real-world robot manipulation in dynamic unstructured environments requires lifelong adaptability to evolving objects, scenes and tasks. Traditional imitation learning relies on static training paradigms, which are ill-suited for lifelong adaptation. Although Continual Imitation Learnin (CIL) enables incremental task adaptation while preserving learned knowledge, current CIL methods primarily overlook the intrinsic skill characteristics of robot manipulation or depend on manually defined and rigid skills, leading to suboptimal cross-task knowledge transfer. To address these issues, we propose Skill Prompts-based HiErarchical Continual Imitation Learning (SPECI), a novel end-to-end hierarchical CIL policy architecture for robot manipulation. The SPECI framework consists of a multimodal perception and fusion module for heterogeneous sensory information encoding, a high-level skill inference module for dynamic skill extraction and selection, and a low-level action execution module for precise action generation. To enable efficient knowledge transfer on both skill and task levels, SPECI performs continual implicit skill acquisition and reuse via an expandable skill codebook and an attention-driven skill selection mechanism. Furthermore, we introduce mode approximation to augment the last two modules with task-specific and task-sharing parameters, thereby enhancing task-level knowledge transfer. Extensive experiments on diverse manipulation task suites demonstrate that SPECI consistently outperforms state-of-the-art CIL methods across all evaluated metrics, revealing exceptional bidirectional knowledge transfer and superior overall performance.","authors":["Jingkai Xu","Xiangli Nie"],"url":"https://arxiv.org/abs/2504.15561"}
{"created":"2025-04-23","title":"Bayesian Autoencoder for Medical Anomaly Detection: Uncertainty-Aware Approach for Brain 2 MRI Analysis","abstract":"In medical imaging, anomaly detection is a vital element of healthcare diagnostics, especially for neurological conditions which can be life-threatening. Conventional deterministic methods often fall short when it comes to capturing the inherent uncertainty of anomaly detection tasks. This paper introduces a Bayesian Variational Autoencoder (VAE) equipped with multi-head attention mechanisms for detecting anomalies in brain magnetic resonance imaging (MRI). For the purpose of improving anomaly detection performance, we incorporate both epistemic and aleatoric uncertainty estimation through Bayesian inference. The model was tested on the BraTS2020 dataset, and the findings were a 0.83 ROC AUC and a 0.83 PR AUC. The data in our paper suggests that modeling uncertainty is an essential component of anomaly detection, enhancing both performance and interpretability and providing confidence estimates, as well as anomaly predictions, for clinicians to leverage in making medical decisions.","authors":["Dip Roy"],"url":"https://arxiv.org/abs/2504.15562"}
{"created":"2025-04-23","title":"A Large-scale Class-level Benchmark Dataset for Code Generation with LLMs","abstract":"Recent advancements in large language models (LLMs) have demonstrated promising capabilities in code generation tasks. However, most existing benchmarks focus on isolated functions and fail to capture the complexity of real-world, class-level software structures. To address this gap, we introduce a large-scale, Python class-level dataset curated from $13{,}174$ real-world open-source projects. The dataset contains over 842,000 class skeletons, each including class and method signatures, along with associated docstrings when available. We preserve structural and contextual dependencies critical to realistic software development scenarios and enrich the dataset with static code metrics to support downstream analysis. To evaluate the usefulness of this dataset, we use extracted class skeletons as prompts for GPT-4 to generate full class implementations. Results show that the LLM-generated classes exhibit strong lexical and structural similarity to human-written counterparts, with average ROUGE@L, BLEU, and TSED scores of 0.80, 0.59, and 0.73, respectively. These findings confirm that well-structured prompts derived from real-world class skeletons significantly enhance LLM performance in class-level code generation. This dataset offers a valuable resource for benchmarking, training, and improving LLMs in realistic software engineering contexts.","authors":["Musfiqur Rahman","SayedHassan Khatoonabadi","Emad Shihab"],"url":"https://arxiv.org/abs/2504.15564"}
{"created":"2025-04-23","title":"DecETT: Accurate App Fingerprinting Under Encrypted Tunnels via Dual Decouple-based Semantic Enhancement","abstract":"Due to the growing demand for privacy protection, encrypted tunnels have become increasingly popular among mobile app users, which brings new challenges to app fingerprinting (AF)-based network management. Existing methods primarily transfer traditional AF methods to encrypted tunnels directly, ignoring the core obfuscation and re-encapsulation mechanism of encrypted tunnels, thus resulting in unsatisfactory performance. In this paper, we propose DecETT, a dual decouple-based semantic enhancement method for accurate AF under encrypted tunnels. Specifically, DecETT improves AF under encrypted tunnels from two perspectives: app-specific feature enhancement and irrelevant tunnel feature decoupling.Considering the obfuscated app-specific information in encrypted tunnel traffic, DecETT introduces TLS traffic with stronger app-specific information as a semantic anchor to guide and enhance the fingerprint generation for tunnel traffic. Furthermore, to address the app-irrelevant tunnel feature introduced by the re-encapsulation mechanism, DecETT is designed with a dual decouple-based fingerprint enhancement module, which decouples the tunnel feature and app semantic feature from tunnel traffic separately, thereby minimizing the impact of tunnel features on accurate app fingerprint extraction. Evaluation under five prevalent encrypted tunnels indicates that DecETT outperforms state-of-the-art methods in accurate AF under encrypted tunnels, and further demonstrates its superiority under tunnels with more complicated obfuscation. \\textit{Project page: \\href{https://github.com/DecETT/DecETT}{https://github.com/DecETT/DecETT}}","authors":["Zheyuan Gu","Chang Liu","Xiyuan Zhang","Chen Yang","Gaopeng Gou","Gang Xiong","Zhen Li","Sijia Li"],"url":"https://arxiv.org/abs/2504.15565"}
{"created":"2025-04-23","title":"Minimization of Curve Length through Energy Minimization using Finite Difference and Numerical Integration in Real Coordinate Space","abstract":"The problem of determining the minimal length is garnering attention in various fields such as computer vision, robotics, and machine learning. One solution to this problem involves linearly interpolating the solution of a nonlinear optimization problem that approximates the curve's energy minimization problem using finite differences and numerical integration. This method tends to be easier to implement compared to others. However, it was previously unknown whether this approach successfully minimizes the curve's length under the Riemannian metric in real coordinate spaces. In this paper, we prove that the length of a curve obtained by linear interpolation of the solution to an optimization problem, where the energy of the curve is approximated using finite differences and the trapezoidal rule, converges to the minimal curve length at a rate of $1/2$ in terms of the number of points used in the numerical integration. Similarly, we prove that when using the left-point rule, the approximated curve's length likewise converges to the minimal curve length at a rate of $1/2$ in terms of the number of points used in the numerical integration.","authors":["Akira Kitaoka"],"url":"https://arxiv.org/abs/2504.15566"}
{"created":"2025-04-23","title":"Is Learning Effective in Dynamic Strategic Interactions? Evidence from Stackelberg Games","abstract":"In many settings of interest, a policy is set by one party, the leader, in order to influence the action of another party, the follower, where the follower's response is determined by some private information. A natural question to ask is, can the leader improve their strategy by learning about the unknown follower through repeated interactions? A well known folk theorem from dynamic pricing, a special case of this leader-follower setting, would suggest that the leader cannot learn effectively from the follower when the follower is fully strategic, leading to a large literature on learning in strategic settings that relies on limiting the strategic space of the follower in order to provide positive results. In this paper, we study dynamic Bayesian Stackelberg games, where a leader and a \\emph{fully strategic} follower interact repeatedly, with the follower's type unknown. Contrary to existing results, we show that the leader can improve their utility through learning in repeated play. Using a novel average-case analysis, we demonstrate that learning is effective in these settings, without needing to weaken the follower's strategic space. Importantly, this improvement is not solely due to the leader's ability to commit, nor does learning simply substitute for communication between the parties. We provide an algorithm, based on a mixed-integer linear program, to compute the optimal leader policy in these games and develop heuristic algorithms to approximate the optimal dynamic policy more efficiently. Through simulations, we compare the efficiency and runtime of these algorithms against static policies.","authors":["Michael Albert","Quinlan Dawkins","Minbiao Han","Haifeng Xu"],"url":"https://arxiv.org/abs/2504.15568"}
{"created":"2025-04-23","title":"Instruction-Tuning Data Synthesis from Scratch via Web Reconstruction","abstract":"The improvement of LLMs' instruction-following capabilities depends critically on the availability of high-quality instruction-response pairs. While existing automatic data synthetic methods alleviate the burden of manual curation, they often rely heavily on either the quality of seed data or strong assumptions about the structure and content of web documents. To tackle these challenges, we propose Web Reconstruction (WebR), a fully automated framework for synthesizing high-quality instruction-tuning (IT) data directly from raw web documents with minimal assumptions. Leveraging the inherent diversity of raw web content, we conceptualize web reconstruction as an instruction-tuning data synthesis task via a novel dual-perspective paradigm--Web as Instruction and Web as Response--where each web document is designated as either an instruction or a response to trigger the reconstruction process. Comprehensive experiments show that datasets generated by WebR outperform state-of-the-art baselines by up to 16.65% across four instruction-following benchmarks. Notably, WebR demonstrates superior compatibility, data efficiency, and scalability, enabling enhanced domain adaptation with minimal effort. The data and code are publicly available at https://github.com/YJiangcm/WebR.","authors":["Yuxin Jiang","Yufei Wang","Chuhan Wu","Xinyi Dai","Yan Xu","Weinan Gan","Yasheng Wang","Xin Jiang","Lifeng Shang","Ruiming Tang","Wei Wang"],"url":"https://arxiv.org/abs/2504.15573"}
{"created":"2025-04-23","title":"State-Aware IoT Scheduling Using Deep Q-Networks and Edge-Based Coordination","abstract":"This paper addresses the challenge of energy efficiency management faced by intelligent IoT devices in complex application environments. A novel optimization method is proposed, combining Deep Q-Network (DQN) with an edge collaboration mechanism. The method builds a state-action-reward interaction model and introduces edge nodes as intermediaries for state aggregation and policy scheduling. This enables dynamic resource coordination and task allocation among multiple devices. During the modeling process, device status, task load, and network resources are jointly incorporated into the state space. The DQN is used to approximate and learn the optimal scheduling strategy. To enhance the model's ability to perceive inter-device relationships, a collaborative graph structure is introduced to model the multi-device environment and assist in decision optimization. Experiments are conducted using real-world IoT data collected from the FastBee platform. Several comparative and validation tests are performed, including energy efficiency comparisons across different scheduling strategies, robustness analysis under varying task loads, and evaluation of state dimension impacts on policy convergence speed. The results show that the proposed method outperforms existing baseline approaches in terms of average energy consumption, processing latency, and resource utilization. This confirms its effectiveness and practicality in intelligent IoT scenarios.","authors":["Qingyuan He","Chang Liu","Juecen Zhan","Weiqiang Huang","Ran Hao"],"url":"https://arxiv.org/abs/2504.15577"}
{"created":"2025-04-23","title":"Real-Time Optimal Design of Experiment for Parameter Identification of Li-Ion Cell Electrochemical Model","abstract":"Accurately identifying the parameters of electrochemical models of li-ion battery (LiB) cells is a critical task for enhancing the fidelity and predictive ability. Traditional parameter identification methods often require extensive data collection experiments and lack adaptability in dynamic environments. This paper describes a Reinforcement Learning (RL) based approach that dynamically tailors the current profile applied to a LiB cell to optimize the parameters identifiability of the electrochemical model. The proposed framework is implemented in real-time using a Hardware-in-the-Loop (HIL) setup, which serves as a reliable testbed for evaluating the RL-based design strategy. The HIL validation confirms that the RL-based experimental design outperforms conventional test protocols used for parameter identification in terms of both reducing the modeling errors on a verification test and minimizing the duration of the experiment used for parameter identification.","authors":["Ian Mikesell","Samuel Filgueira da Silva","Mehmet Fatih Ozkan","Faissal El Idrissi","Prashanth Ramesh","Marcello Canova"],"url":"https://arxiv.org/abs/2504.15578"}
{"created":"2025-04-23","title":"On the Price of Differential Privacy for Hierarchical Clustering","abstract":"Hierarchical clustering is a fundamental unsupervised machine learning task with the aim of organizing data into a hierarchy of clusters. Many applications of hierarchical clustering involve sensitive user information, therefore motivating recent studies on differentially private hierarchical clustering under the rigorous framework of Dasgupta's objective. However, it has been shown that any privacy-preserving algorithm under edge-level differential privacy necessarily suffers a large error. To capture practical applications of this problem, we focus on the weight privacy model, where each edge of the input graph is at least unit weight. We present a novel algorithm in the weight privacy model that shows significantly better approximation than known impossibility results in the edge-level DP setting. In particular, our algorithm achieves $O(\\log^{1.5}n/\\varepsilon)$ multiplicative error for $\\varepsilon$-DP and runs in polynomial time, where $n$ is the size of the input graph, and the cost is never worse than the optimal additive error in existing work. We complement our algorithm by showing if the unit-weight constraint does not apply, the lower bound for weight-level DP hierarchical clustering is essentially the same as the edge-level DP, i.e. $\\Omega(n^2/\\varepsilon)$ additive error. As a result, we also obtain a new lower bound of $\\tilde{\\Omega}(1/\\varepsilon)$ additive error for balanced sparsest cuts in the weight-level DP model, which may be of independent interest. Finally, we evaluate our algorithm on synthetic and real-world datasets. Our experimental results show that our algorithm performs well in terms of extra cost and has good scalability to large graphs.","authors":["Chengyuan Deng","Jie Gao","Jalaj Upadhyay","Chen Wang","Samson Zhou"],"url":"https://arxiv.org/abs/2504.15580"}
{"created":"2025-04-23","title":"Smooth Calibration and Decision Making","abstract":"Calibration requires predictor outputs to be consistent with their Bayesian posteriors. For machine learning predictors that do not distinguish between small perturbations, calibration errors are continuous in predictions, e.g., smooth calibration error (Foster and Hart, 2018), Distance to Calibration (Blasiok et al., 2023a). On the contrary, decision-makers who use predictions make optimal decisions discontinuously in probabilistic space, experiencing loss from miscalibration discontinuously. Calibration errors for decision-making are thus discontinuous, e.g., Expected Calibration Error (Foster and Vohra, 1997), and Calibration Decision Loss (Hu and Wu, 2024). Thus, predictors with a low calibration error for machine learning may suffer a high calibration error for decision-making, i.e., they may not be trustworthy for decision-makers optimizing assuming their predictions are correct. It is natural to ask if post-processing a predictor with a low calibration error for machine learning is without loss to achieve a low calibration error for decision-making. In our paper, we show that post-processing an online predictor with $\\epsilon$ distance to calibration achieves $O(\\sqrt{\\epsilon})$ ECE and CDL, which is asymptotically optimal. The post-processing algorithm adds noise to make predictions differentially private. The optimal bound from low distance to calibration predictors from post-processing is non-optimal compared with existing online calibration algorithms that directly optimize for ECE and CDL.","authors":["Jason Hartline","Yifan Wu","Yunran Yang"],"url":"https://arxiv.org/abs/2504.15582"}
{"created":"2025-04-23","title":"A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment","abstract":"The remarkable success of Large Language Models (LLMs) has illuminated a promising pathway toward achieving Artificial General Intelligence for both academic and industrial communities, owing to their unprecedented performance across various applications. As LLMs continue to gain prominence in both research and commercial domains, their security and safety implications have become a growing concern, not only for researchers and corporations but also for every nation. Currently, existing surveys on LLM safety primarily focus on specific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning phase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs. To address this gap, this paper introduces, for the first time, the concept of \"full-stack\" safety to systematically consider safety issues throughout the entire process of LLM training, deployment, and eventual commercialization. Compared to the off-the-shelf LLM safety surveys, our work demonstrates several distinctive advantages: (I) Comprehensive Perspective. We define the complete LLM lifecycle as encompassing data preparation, pre-training, post-training, deployment and final commercialization. To our knowledge, this represents the first safety survey to encompass the entire lifecycle of LLMs. (II) Extensive Literature Support. Our research is grounded in an exhaustive review of over 800+ papers, ensuring comprehensive coverage and systematic organization of security issues within a more holistic understanding. (III) Unique Insights. Through systematic literature analysis, we have developed reliable roadmaps and perspectives for each chapter. Our work identifies promising research directions, including safety in data generation, alignment techniques, model editing, and LLM-based agent systems. These insights provide valuable guidance for researchers pursuing future work in this field.","authors":["Kun Wang","Guibin Zhang","Zhenhong Zhou","Jiahao Wu","Miao Yu","Shiqian Zhao","Chenlong Yin","Jinhu Fu","Yibo Yan","Hanjun Luo","Liang Lin","Zhihao Xu","Haolang Lu","Xinye Cao","Xinyun Zhou","Weifei Jin","Fanci Meng","Junyuan Mao","Hao Wu","Minghe Wang","Fan Zhang","Junfeng Fang","Chengwei Liu","Yifan Zhang","Qiankun Li","Chongye Guo","Yalan Qin","Yi Ding","Donghai Hong","Jiaming Ji","Xinfeng Li","Yifan Jiang","Dongxia Wang","Yihao Huang","Yufei Guo","Jen-tse Huang","Yanwei Yue","Wenke Huang","Guancheng Wan","Tianlin Li","Lei Bai","Jie Zhang","Qing Guo","Jingyi Wang","Tianlong Chen","Joey Tianyi Zhou","Xiaojun Jia","Weisong Sun","Cong Wu","Jing Chen","Xuming Hu","Yiming Li","Xiao Wang","Ningyu Zhang","Luu Anh Tuan","Guowen Xu","Tianwei Zhang","Xingjun Ma","Xiang Wang","Bo An","Jun Sun","Mohit Bansal","Shirui Pan","Yuval Elovici","Bhavya Kailkhura","Bo Li","Yaodong Yang","Hongwei Li","Wenyuan Xu","Yizhou Sun","Wei Wang","Qing Li","Ke Tang","Yu-Gang Jiang","Felix Juefei-Xu","Hui Xiong","Xiaofeng Wang","Shuicheng Yan","Dacheng Tao","Philip S. Yu","Qingsong Wen","Yang Liu"],"url":"https://arxiv.org/abs/2504.15585"}
{"created":"2025-04-23","title":"MetaMolGen: A Neural Graph Motif Generation Model for De Novo Molecular Design","abstract":"Molecular generation plays an important role in drug discovery and materials science, especially in data-scarce scenarios where traditional generative models often struggle to achieve satisfactory conditional generalization. To address this challenge, we propose MetaMolGen, a first-order meta-learning-based molecular generator designed for few-shot and property-conditioned molecular generation. MetaMolGen standardizes the distribution of graph motifs by mapping them to a normalized latent space, and employs a lightweight autoregressive sequence model to generate SMILES sequences that faithfully reflect the underlying molecular structure. In addition, it supports conditional generation of molecules with target properties through a learnable property projector integrated into the generative process.Experimental results demonstrate that MetaMolGen consistently generates valid and diverse SMILES sequences under low-data regimes, outperforming conventional baselines. This highlights its advantage in fast adaptation and efficient conditional generation for practical molecular design.","authors":["Zimo Yan","Jie Zhang","Zheng Xie","Chang Liu","Yizhen Liu","Yiping Song"],"url":"https://arxiv.org/abs/2504.15587"}
{"created":"2025-04-23","title":"Validation of 3GPP TR 38.901 Indoor Hotspot Path Loss Model Based on Measurements Conducted at 6.75, 16.95, 28, and 73 GHz for 6G and Beyond","abstract":"This paper presents a thorough validation of the Third Generation Partnership Project (3GPP) Technical Report (TR) 38.901 indoor hotspot (InH) path loss model, as part of the 3GPP Release 19 study on \"Channel model validation of TR 38.901 for 7-24 GHz,\" for 6G standardization. Specifically, we validate the 3GPP TR 38.901 path loss model for the InH scenario in both line of sight (LOS) and non line of sight (NLOS) channel conditions, using the floating intercept (FI) and alpha-beta-gamma (ABG) path loss models. The validation focuses on specific frequencies, including 6.75 GHz and 16.95 GHz, as well as the broader 7-24 GHz and 0.5-100 GHz frequency ranges. The validation is based on real-world measurements conducted at 6.75 GHz, 16.95 GHz, 28 GHz, and 73 GHz by NYU WIRELESS using a 1 GHz wideband time domain based sliding correlation channel sounder in the InH scenario for both LOS and NLOS channel conditions. Our results confirm that the 3GPP TR 38.901 path loss model for the InH scenario remains valid for the 7-24 GHz range in both LOS and NLOS conditions and provide valuable input for 6G standardization efforts.","authors":["Hitesh Poddar","Tomoki Yoshimura","Art Ishii"],"url":"https://arxiv.org/abs/2504.15589"}
{"created":"2025-04-23","title":"Yet Another Diminishing Spark: Low-level Cyberattacks in the Israel-Gaza Conflict","abstract":"We report empirical evidence of web defacement and DDoS attacks carried out by low-level cybercrime actors in the Israel-Gaza conflict. Our quantitative measurements indicate an immediate increase in such cyberattacks following the Hamas-led assault and the subsequent declaration of war. However, the surges waned quickly after a few weeks, with patterns resembling those observed in the aftermath of the Russian invasion of Ukraine. The scale of attacks and discussions within the hacking community this time was both significantly lower than those during the early days of the Russia-Ukraine war, and attacks have been prominently one-sided: many pro-Palestinian supporters have targeted Israel, while attacks on Palestine have been much less significant. Beyond targeting these two, attackers also defaced sites of other countries to express their war support. Their broader opinions are also largely disparate, with far more support for Palestine and many objections expressed toward Israel.","authors":["Anh V. Vu","Alice Hutchings","Ross Anderson"],"url":"https://arxiv.org/abs/2504.15592"}
{"created":"2025-04-23","title":"Analytical Softmax Temperature Setting from Feature Dimensions for Model- and Domain-Robust Classification","abstract":"In deep learning-based classification tasks, the softmax function's temperature parameter $T$ critically influences the output distribution and overall performance. This study presents a novel theoretical insight that the optimal temperature $T^*$ is uniquely determined by the dimensionality of the feature representations, thereby enabling training-free determination of $T^*$. Despite this theoretical grounding, empirical evidence reveals that $T^*$ fluctuates under practical conditions owing to variations in models, datasets, and other confounding factors. To address these influences, we propose and optimize a set of temperature determination coefficients that specify how $T^*$ should be adjusted based on the theoretical relationship to feature dimensionality. Additionally, we insert a batch normalization layer immediately before the output layer, effectively stabilizing the feature space. Building on these coefficients and a suite of large-scale experiments, we develop an empirical formula to estimate $T^*$ without additional training while also introducing a corrective scheme to refine $T^*$ based on the number of classes and task complexity. Our findings confirm that the derived temperature not only aligns with the proposed theoretical perspective but also generalizes effectively across diverse tasks, consistently enhancing classification performance and offering a practical, training-free solution for determining $T^*$.","authors":["Tatsuhito Hasegawa","Shunsuke Sakai"],"url":"https://arxiv.org/abs/2504.15594"}
{"created":"2025-04-23","title":"Grasping Deformable Objects via Reinforcement Learning with Cross-Modal Attention to Visuo-Tactile Inputs","abstract":"We consider the problem of grasping deformable objects with soft shells using a robotic gripper. Such objects have a center-of-mass that changes dynamically and are fragile so prone to burst. Thus, it is difficult for robots to generate appropriate control inputs not to drop or break the object while performing manipulation tasks. Multi-modal sensing data could help understand the grasping state through global information (e.g., shapes, pose) from visual data and local information around the contact (e.g., pressure) from tactile data. Although they have complementary information that can be beneficial to use together, fusing them is difficult owing to their different properties.","authors":["Yonghyun Lee","Sungeun Hong","Min-gu Kim","Gyeonghwan Kim","Changjoo Nam"],"url":"https://arxiv.org/abs/2504.15595"}
{"created":"2025-04-23","title":"Multi-Modal Fusion of In-Situ Video Data and Process Parameters for Online Forecasting of Cookie Drying Readiness","abstract":"Food drying is essential for food production, extending shelf life, and reducing transportation costs. Accurate real-time forecasting of drying readiness is crucial for minimizing energy consumption, improving productivity, and ensuring product quality. However, this remains challenging due to the dynamic nature of drying, limited data availability, and the lack of effective predictive analytical methods. To address this gap, we propose an end-to-end multi-modal data fusion framework that integrates in-situ video data with process parameters for real-time food drying readiness forecasting. Our approach leverages a new encoder-decoder architecture with modality-specific encoders and a transformer-based decoder to effectively extract features while preserving the unique structure of each modality. We apply our approach to sugar cookie drying, where time-to-ready is predicted at each timestamp. Experimental results demonstrate that our model achieves an average prediction error of only 15 seconds, outperforming state-of-the-art data fusion methods by 65.69% and a video-only model by 11.30%. Additionally, our model balances prediction accuracy, model size, and computational efficiency, making it well-suited for heterogenous industrial datasets. The proposed model is extensible to various other industrial modality fusion tasks for online decision-making.","authors":["Shichen Li","Chenhui Shao"],"url":"https://arxiv.org/abs/2504.15599"}
{"created":"2025-04-23","title":"Research on Navigation Methods Based on LLMs","abstract":"In recent years, the field of indoor navigation has witnessed groundbreaking advancements through the integration of Large Language Models (LLMs). Traditional navigation approaches relying on pre-built maps or reinforcement learning exhibit limitations such as poor generalization and limited adaptability to dynamic environments. In contrast, LLMs offer a novel paradigm for complex indoor navigation tasks by leveraging their exceptional semantic comprehension, reasoning capabilities, and zero-shot generalization properties. We propose an LLM-based navigation framework that leverages function calling capabilities, positioning the LLM as the central controller. Our methodology involves modular decomposition of conventional navigation functions into reusable LLM tools with expandable configurations. This is complemented by a systematically designed, transferable system prompt template and interaction workflow that can be easily adapted across different implementations. Experimental validation in PyBullet simulation environments across diverse scenarios demonstrates the substantial potential and effectiveness of our approach, particularly in achieving context-aware navigation through dynamic tool composition.","authors":["Anlong Zhang","Jianmin Ji"],"url":"https://arxiv.org/abs/2504.15600"}
{"created":"2025-04-23","title":"Exploring Next Token Prediction in Theory of Mind (ToM) Tasks: Comparative Experiments with GPT-2 and LLaMA-2 AI Models","abstract":"Language models have made significant progress in generating coherent text and predicting next tokens based on input prompts. This study compares the next-token prediction performance of two well-known models: OpenAI's GPT-2 and Meta's Llama-2-7b-chat-hf on Theory of Mind (ToM) tasks. To evaluate their capabilities, we built a dataset from 10 short stories sourced from the Explore ToM Dataset. We enhanced these stories by programmatically inserting additional sentences (infills) using GPT-4, creating variations that introduce different levels of contextual complexity. This setup enables analysis of how increasing context affects model performance. We tested both models under four temperature settings (0.01, 0.5, 1.0, 2.0) and evaluated their ability to predict the next token across three reasoning levels. Zero-order reasoning involves tracking the state, either current (ground truth) or past (memory). First-order reasoning concerns understanding another's mental state (e.g., \"Does Anne know the apple is salted?\"). Second-order reasoning adds recursion (e.g., \"Does Anne think that Charles knows the apple is salted?\").","authors":["Pavan Yadav","Nikhil Khandalkar","Krishna Shinde","Lokesh B. Ramegowda","Rajarshi Das"],"url":"https://arxiv.org/abs/2504.15604"}
{"created":"2025-04-23","title":"SonarT165: A Large-scale Benchmark and STFTrack Framework for Acoustic Object Tracking","abstract":"Underwater observation systems typically integrate optical cameras and imaging sonar systems. When underwater visibility is insufficient, only sonar systems can provide stable data, which necessitates exploration of the underwater acoustic object tracking (UAOT) task. Previous studies have explored traditional methods and Siamese networks for UAOT. However, the absence of a unified evaluation benchmark has significantly constrained the value of these methods. To alleviate this limitation, we propose the first large-scale UAOT benchmark, SonarT165, comprising 165 square sequences, 165 fan sequences, and 205K high-quality annotations. Experimental results demonstrate that SonarT165 reveals limitations in current state-of-the-art SOT trackers. To address these limitations, we propose STFTrack, an efficient framework for acoustic object tracking. It includes two novel modules, a multi-view template fusion module (MTFM) and an optimal trajectory correction module (OTCM). The MTFM module integrates multi-view feature of both the original image and the binary image of the dynamic template, and introduces a cross-attention-like layer to fuse the spatio-temporal target representations. The OTCM module introduces the acoustic-response-equivalent pixel property and proposes normalized pixel brightness response scores, thereby suppressing suboptimal matches caused by inaccurate Kalman filter prediction boxes. To further improve the model feature, STFTrack introduces a acoustic image enhancement method and a Frequency Enhancement Module (FEM) into its tracking pipeline. Comprehensive experiments show the proposed STFTrack achieves state-of-the-art performance on the proposed benchmark. The code is available at https://github.com/LiYunfengLYF/SonarT165.","authors":["Yunfeng Li","Bo Wang","Jiahao Wan","Xueyi Wu","Ye Li"],"url":"https://arxiv.org/abs/2504.15609"}
{"created":"2025-04-23","title":"A LoRA-Based Approach to Fine-Tuning LLMs for Educational Guidance in Resource-Constrained Settings","abstract":"The current study describes a cost-effective method for adapting large language models (LLMs) for academic advising with study-abroad contexts in mind and for application in low-resource methods for acculturation. With the Mistral-7B-Instruct model applied with a Low-Rank Adaptation (LoRA) method and a 4-bit quantization method, the model underwent training in two distinct stages related to this study's purpose to enhance domain specificity while maintaining computational efficiency. In Phase 1, the model was conditioned with a synthetic dataset via the Gemini Pro API, and in Phase 2, it was trained with manually curated datasets from the StudyAbroadGPT project to achieve enhanced, contextualized responses. Technical innovations entailed memory-efficient quantization, parameter-efficient adaptation, and continuous training analytics via Weights & Biases. After training, this study demonstrated a reduction in training loss by 52.7%, 92% accuracy in domain-specific recommendations, achieved 95% markdown-based formatting support, and a median run-rate of 100 samples per second on off-the-shelf GPU equipment. These findings support the effective application of instruction-tuned LLMs within educational advisers, especially in low-resource institutional scenarios. Limitations included decreased generalizability and the application of a synthetically generated dataset, but this framework is scalable for adding new multilingual-augmented and real-time academic advising processes. Future directions may include plans for the integration of retrieval-augmented generation, applying dynamic quantization routines, and connecting to real-time academic databases to increase adaptability and accuracy.","authors":["Md Millat","Md Motiur"],"url":"https://arxiv.org/abs/2504.15610"}
{"created":"2025-04-23","title":"An ACO-MPC Framework for Energy-Efficient and Collision-Free Path Planning in Autonomous Maritime Navigation","abstract":"Automated driving on ramps presents significant challenges due to the need to balance both safety and efficiency during lane changes. This paper proposes an integrated planner for automated vehicles (AVs) on ramps, utilizing an unsatisfactory level metric for efficiency and arrow-cluster-based sampling for safety. The planner identifies optimal times for the AV to change lanes, taking into account the vehicle's velocity as a key factor in efficiency. Additionally, the integrated planner employs arrow-cluster-based sampling to evaluate collision risks and select an optimal lane-changing curve. Extensive simulations were conducted in a ramp scenario to verify the planner's efficient and safe performance. The results demonstrate that the proposed planner can effectively select an appropriate lane-changing time point and a safe lane-changing curve for AVs, without incurring any collisions during the maneuver.","authors":["Yaoze Liu","Zhen Tian","Qifan Zhou","Zixuan Huang","Hongyu Sun"],"url":"https://arxiv.org/abs/2504.15611"}
{"created":"2025-04-23","title":"HS-Mamba: Full-Field Interaction Multi-Groups Mamba for Hyperspectral Image Classification","abstract":"Hyperspectral image (HSI) classification has been one of the hot topics in remote sensing fields. Recently, the Mamba architecture based on selective state-space models (S6) has demonstrated great advantages in long sequence modeling. However, the unique properties of hyperspectral data, such as high dimensionality and feature inlining, pose challenges to the application of Mamba to HSI classification. To compensate for these shortcomings, we propose an full-field interaction multi-groups Mamba framework (HS-Mamba), which adopts a strategy different from pixel-patch based or whole-image based, but combines the advantages of both. The patches cut from the whole image are sent to multi-groups Mamba, combined with positional information to perceive local inline features in the spatial and spectral domains, and the whole image is sent to a lightweight attention module to enhance the global feature representation ability. Specifically, HS-Mamba consists of a dual-channel spatial-spectral encoder (DCSS-encoder) module and a lightweight global inline attention (LGI-Att) branch. The DCSS-encoder module uses multiple groups of Mamba to decouple and model the local features of dual-channel sequences with non-overlapping patches. The LGI-Att branch uses a lightweight compressed and extended attention module to perceive the global features of the spatial and spectral domains of the unsegmented whole image. By fusing local and global features, high-precision classification of hyperspectral images is achieved. Extensive experiments demonstrate the superiority of the proposed HS-Mamba, outperforming state-of-the-art methods on four benchmark HSI datasets.","authors":["Hongxing Peng","Kang Lin","Huanai Liu"],"url":"https://arxiv.org/abs/2504.15612"}
{"created":"2025-04-23","title":"Learning Dynamic Graphs via Tensorized and Lightweight Graph Convolutional Networks","abstract":"A dynamic graph (DG) is frequently encountered in numerous real-world scenarios. Consequently, A dynamic graph convolutional network (DGCN) has been successfully applied to perform precise representation learning on a DG. However, conventional DGCNs typically consist of a static GCN coupled with a sequence neural network (SNN) to model spatial and temporal patterns separately. This decoupled modeling mechanism inherently disrupts the intricate spatio-temporal dependencies. To address the issue, this study proposes a novel Tensorized Lightweight Graph Convolutional Network (TLGCN) for accurate dynamic graph learning. It mainly contains the following two key concepts: a) designing a novel spatio-temporal information propagation method for joint propagation of spatio-temporal information based on the tensor M-product framework; b) proposing a tensorized lightweight graph convolutional network based on the above method, which significantly reduces the memory occupation of the model by omitting complex feature transformation and nonlinear activation. Numerical experiments on four real-world datasets demonstrate that the proposed TLGCN outperforms the state-of-the-art models in the weight estimation task on DGs.","authors":["Minglian Han"],"url":"https://arxiv.org/abs/2504.15613"}
{"created":"2025-04-23","title":"Dimension-Free Decision Calibration for Nonlinear Loss Functions","abstract":"When model predictions inform downstream decision making, a natural question is under what conditions can the decision-makers simply respond to the predictions as if they were the true outcomes. Calibration suffices to guarantee that simple best-response to predictions is optimal. However, calibration for high-dimensional prediction outcome spaces requires exponential computational and statistical complexity. The recent relaxation known as decision calibration ensures the optimality of the simple best-response rule while requiring only polynomial sample complexity in the dimension of outcomes. However, known results on calibration and decision calibration crucially rely on linear loss functions for establishing best-response optimality. A natural approach to handle nonlinear losses is to map outcomes $y$ into a feature space $\\phi(y)$ of dimension $m$, then approximate losses with linear functions of $\\phi(y)$. Unfortunately, even simple classes of nonlinear functions can demand exponentially large or infinite feature dimensions $m$. A key open problem is whether it is possible to achieve decision calibration with sample complexity independent of~$m$. We begin with a negative result: even verifying decision calibration under standard deterministic best response inherently requires sample complexity polynomial in~$m$. Motivated by this lower bound, we investigate a smooth version of decision calibration in which decision-makers follow a smooth best-response. This smooth relaxation enables dimension-free decision calibration algorithms. We introduce algorithms that, given $\\mathrm{poly}(|A|,1/\\epsilon)$ samples and any initial predictor~$p$, can efficiently post-process it to satisfy decision calibration without worsening accuracy. Our algorithms apply broadly to function classes that can be well-approximated by bounded-norm functions in (possibly infinite-dimensional) separable RKHS.","authors":["Jingwu Tang","Jiayun Wu","Zhiwei Steven Wu","Jiahao Zhang"],"url":"https://arxiv.org/abs/2504.15615"}
{"created":"2025-04-23","title":"SocialMOIF: Multi-Order Intention Fusion for Pedestrian Trajectory Prediction","abstract":"The analysis and prediction of agent trajectories are crucial for decision-making processes in intelligent systems, with precise short-term trajectory forecasting being highly significant across a range of applications. Agents and their social interactions have been quantified and modeled by researchers from various perspectives; however, substantial limitations exist in the current work due to the inherent high uncertainty of agent intentions and the complex higher-order influences among neighboring groups. SocialMOIF is proposed to tackle these challenges, concentrating on the higher-order intention interactions among neighboring groups while reinforcing the primary role of first-order intention interactions between neighbors and the target agent. This method develops a multi-order intention fusion model to achieve a more comprehensive understanding of both direct and indirect intention information. Within SocialMOIF, a trajectory distribution approximator is designed to guide the trajectories toward values that align more closely with the actual data, thereby enhancing model interpretability. Furthermore, a global trajectory optimizer is introduced to enable more accurate and efficient parallel predictions. By incorporating a novel loss function that accounts for distance and direction during training, experimental results demonstrate that the model outperforms previous state-of-the-art baselines across multiple metrics in both dynamic and static datasets.","authors":["Kai Chen","Xiaodong Zhao","Yujie Huang","Guoyu Fang","Xiao Song","Ruiping Wang","Ziyuan Wang"],"url":"https://arxiv.org/abs/2504.15616"}
{"created":"2025-04-23","title":"AdaViP: Aligning Multi-modal LLMs via Adaptive Vision-enhanced Preference Optimization","abstract":"Preference alignment through Direct Preference Optimization (DPO) has demonstrated significant effectiveness in aligning multimodal large language models (MLLMs) with human preferences. However, existing methods focus primarily on language preferences while neglecting the critical visual context. In this paper, we propose an Adaptive Vision-enhanced Preference optimization (AdaViP) that addresses these limitations through two key innovations: (1) vision-based preference pair construction, which integrates multiple visual foundation models to strategically remove key visual elements from the image, enhancing MLLMs' sensitivity to visual details; and (2) adaptive preference optimization that dynamically balances vision- and language-based preferences for more accurate alignment. Extensive evaluations across different benchmarks demonstrate our effectiveness. Notably, our AdaViP-7B achieves 93.7% and 96.4% reductions in response-level and mentioned-level hallucination respectively on the Object HalBench, significantly outperforming current state-of-the-art methods.","authors":["Jinda Lu","Jinghan Li","Yuan Gao","Junkang Wu","Jiancan Wu","Xiang Wang","Xiangnan He"],"url":"https://arxiv.org/abs/2504.15619"}
{"created":"2025-04-23","title":"Exploring the Role of Large Language Models in Cybersecurity: A Systematic Survey","abstract":"With the rapid development of technology and the acceleration of digitalisation, the frequency and complexity of cyber security threats are increasing. Traditional cybersecurity approaches, often based on static rules and predefined scenarios, are struggling to adapt to the rapidly evolving nature of modern cyberattacks. There is an urgent need for more adaptive and intelligent defence strategies. The emergence of Large Language Model (LLM) provides an innovative solution to cope with the increasingly severe cyber threats, and its potential in analysing complex attack patterns, predicting threats and assisting real-time response has attracted a lot of attention in the field of cybersecurity, and exploring how to effectively use LLM to defend against cyberattacks has become a hot topic in the current research field. This survey examines the applications of LLM from the perspective of the cyber attack lifecycle, focusing on the three phases of defense reconnaissance, foothold establishment, and lateral movement, and it analyzes the potential of LLMs in Cyber Threat Intelligence (CTI) tasks. Meanwhile, we investigate how LLM-based security solutions are deployed and applied in different network scenarios. It also summarizes the internal and external risk issues faced by LLM during its application. Finally, this survey also points out the facing risk issues and possible future research directions in this domain.","authors":["Shuang Tian","Tao Zhang","Jiqiang Liu","Jiacheng Wang","Xuangou Wu","Xiaoqiang Zhu","Ruichen Zhang","Weiting Zhang","Zhenhui Yuan","Shiwen Mao","Dong In Kim"],"url":"https://arxiv.org/abs/2504.15622"}
{"created":"2025-04-23","title":"RadioDiff-$k^2$: Helmholtz Equation Informed Generative Diffusion Model for Multi-Path Aware Radio Map Construction","abstract":"In this paper, we propose a novel physics-informed generative learning approach, termed RadioDiff-$\\bm{k^2}$, for accurate and efficient multipath-aware radio map (RM) construction. As wireless communication evolves towards environment-aware paradigms, driven by the increasing demand for intelligent and proactive optimization in sixth-generation (6G) networks, accurate construction of RMs becomes crucial yet highly challenging. Conventional electromagnetic (EM)-based methods, such as full-wave solvers and ray-tracing approaches, exhibit substantial computational overhead and limited adaptability to dynamic scenarios. Although, existing neural network (NN) approaches have efficient inferencing speed, they lack sufficient consideration of the underlying physics of EM wave propagation, limiting their effectiveness in accurately modeling critical EM singularities induced by complex multipath environments. To address these fundamental limitations, we propose a novel physics-inspired RM construction method guided explicitly by the Helmholtz equation, which inherently governs EM wave propagation. Specifically, we theoretically establish a direct correspondence between EM singularities, which correspond to the critical spatial features influencing wireless propagation, and regions defined by negative wave numbers in the Helmholtz equation. Based on this insight, we design an innovative dual generative diffusion model (DM) framework comprising one DM dedicated to accurately inferring EM singularities and another DM responsible for reconstructing the complete RM using these singularities along with environmental contextual information. Our physics-informed approach uniquely combines the efficiency advantages of data-driven methods with rigorous physics-based EM modeling, significantly enhancing RM accuracy, particularly in complex propagation environments dominated by multipath effects.","authors":["Xiucheng Wang","Qiming Zhang","Nan Cheng","Ruijin Sun","Zan Li","Shuguang Cui","Xuemin Shen"],"url":"https://arxiv.org/abs/2504.15623"}
{"created":"2025-04-23","title":"FaceInsight: A Multimodal Large Language Model for Face Perception","abstract":"Recent advances in multimodal large language models (MLLMs) have demonstrated strong capabilities in understanding general visual content. However, these general-domain MLLMs perform poorly in face perception tasks, often producing inaccurate or misleading responses to face-specific queries. To address this gap, we propose FaceInsight, the versatile face perception MLLM that provides fine-grained facial information. Our approach introduces visual-textual alignment of facial knowledge to model both uncertain dependencies and deterministic relationships among facial information, mitigating the limitations of language-driven reasoning. Additionally, we incorporate face segmentation maps as an auxiliary perceptual modality, enriching the visual input with localized structural cues to enhance semantic understanding. Comprehensive experiments and analyses across three face perception tasks demonstrate that FaceInsight consistently outperforms nine compared MLLMs under both training-free and fine-tuned settings.","authors":["Jingzhi Li","Changjiang Luo","Ruoyu Chen","Hua Zhang","Wenqi Ren","Jianhou Gan","Xiaochun Cao"],"url":"https://arxiv.org/abs/2504.15624"}
{"created":"2025-04-23","title":"Comprehensive List Generation for Multi-Generator Reranking","abstract":"Reranking models solve the final recommendation lists that best fulfill users' demands. While existing solutions focus on finding parametric models that approximate optimal policies, recent approaches find that it is better to generate multiple lists to compete for a ``pass'' ticket from an evaluator, where the evaluator serves as the supervisor who accurately estimates the performance of the candidate lists. In this work, we show that we can achieve a more efficient and effective list proposal with a multi-generator framework and provide empirical evidence on two public datasets and online A/B tests. More importantly, we verify that the effectiveness of a generator is closely related to how much it complements the views of other generators with sufficiently different rerankings, which derives the metric of list comprehensiveness. With this intuition, we design an automatic complementary generator-finding framework that learns a policy that simultaneously aligns the users' preferences and maximizes the list comprehensiveness metric. The experimental results indicate that the proposed framework can further improve the multi-generator reranking performance.","authors":["Hailan Yang","Zhenyu Qi","Shuchang Liu","Xiaoyu Yang","Xiaobei Wang","Xiang Li","Lantao Hu","Han Li","Kun Gai"],"url":"https://arxiv.org/abs/2504.15625"}
{"created":"2025-04-23","title":"ZeroSlide: Is Zero-Shot Classification Adequate for Lifelong Learning in Whole-Slide Image Analysis in the Era of Pathology Vision-Language Foundation Models?","abstract":"Lifelong learning for whole slide images (WSIs) poses the challenge of training a unified model to perform multiple WSI-related tasks, such as cancer subtyping and tumor classification, in a distributed, continual fashion. This is a practical and applicable problem in clinics and hospitals, as WSIs are large, require storage, processing, and transfer time. Training new models whenever new tasks are defined is time-consuming. Recent work has applied regularization- and rehearsal-based methods to this setting. However, the rise of vision-language foundation models that align diagnostic text with pathology images raises the question: are these models alone sufficient for lifelong WSI learning using zero-shot classification, or is further investigation into continual learning strategies needed to improve performance? To our knowledge, this is the first study to compare conventional continual-learning approaches with vision-language zero-shot classification for WSIs. Our source code and experimental results will be available soon.","authors":["Doanh C. Bui","Hoai Luan Pham","Vu Trung Duong Le","Tuan Hai Vu","Van Duy Tran","Yasuhiko Nakashima"],"url":"https://arxiv.org/abs/2504.15627"}
{"created":"2025-04-23","title":"CiteFix: Enhancing RAG Accuracy Through Post-Processing Citation Correction","abstract":"Retrieval Augmented Generation (RAG) has emerged as a powerful application of Large Language Models (LLMs), revolutionizing information search and consumption. RAG systems combine traditional search capabilities with LLMs to generate comprehensive answers to user queries, ideally with accurate citations. However, in our experience of developing a RAG product, LLMs often struggle with source attribution, aligning with other industry studies reporting citation accuracy rates of only about 74% for popular generative search engines. To address this, we present efficient post-processing algorithms to improve citation accuracy in LLM-generated responses, with minimal impact on latency and cost. Our approaches cross-check generated citations against retrieved articles using methods including keyword + semantic matching, fine tuned model with BERTScore, and a lightweight LLM-based technique. Our experimental results demonstrate a relative improvement of 15.46% in the overall accuracy metrics of our RAG system. This significant enhancement potentially enables a shift from our current larger language model to a relatively smaller model that is approximately 12x more cost-effective and 3x faster in inference time, while maintaining comparable performance. This research contributes to enhancing the reliability and trustworthiness of AI-generated content in information retrieval and summarization tasks which is critical to gain customer trust especially in commercial products.","authors":["Harsh Maheshwari","Srikanth Tenneti","Alwarappan Nakkiran"],"url":"https://arxiv.org/abs/2504.15629"}
{"created":"2025-04-23","title":"Exploiting Contextual Knowledge in LLMs through V-usable Information based Layer Enhancement","abstract":"Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks, yet they often struggle with context-faithfulness generations that properly reflect contextual knowledge. While existing approaches focus on enhancing the decoding strategies, they ignore the fundamental mechanism of how contextual information is processed within LLMs' internal states. As a result, LLMs remain limited in their ability to fully leverage contextual knowledge. In this paper, we propose Context-aware Layer Enhancement (CaLE), a novel intervention method that enhances the utilization of contextual knowledge within LLMs' internal representations. By employing V-usable information analysis, CaLE strategically amplifies the growth of contextual information at an optimal layer, thereby enriching representations in the final layer. Our experiments demonstrate that CaLE effectively improves context-faithful generation in Question-Answering tasks, particularly in scenarios involving unknown or conflicting contextual knowledge.","authors":["Xiaowei Yuan","Zhao Yang","Ziyang Huang","Yequan Wang","Siqi Fan","Yiming Ju","Jun Zhao","Kang Liu"],"url":"https://arxiv.org/abs/2504.15630"}
{"created":"2025-04-23","title":"A Study On Mixup-inspired Augmentation Methods For Software Vulnerability Detection","abstract":"Various Deep Learning (DL) methods have recently been utilized to detect software vulnerabilities. Real-world software vulnerability datasets are rare and hard to acquire as there's no simple metric for classifying vulnerability. Such datasets are heavily imbalanced, and none of the current datasets are considered huge for DL models. To tackle these problems a recent work has tried to augment the dataset using the source code and generate realistic single-statement vulnerabilities which is not quite practical and requires manual checking of the generated vulnerabilities. In this regard, we aim to explore the augmentation of vulnerabilities at the representation level to help current models learn better which has never been done before to the best of our knowledge. We implement and evaluate the 5 augmentation techniques that augment the embedding of the data and recently have been used for code search which is a completely different software engineering task. We also introduced a conditioned version of those augmentation methods, which ensures the augmentation does not change the vulnerable section of the vector representation. We show that such augmentation methods can be helpful and increase the f1-score by up to 9.67%, yet they cannot beat Random Oversampling when balancing datasets which increases the f1-score by 10.82%!","authors":["Seyed Shayan Daneshvar","Da Tan","Shaowei Wang","Carson Leung"],"url":"https://arxiv.org/abs/2504.15632"}
{"created":"2025-04-23","title":"Enhancing Reinforcement learning in 3-Dimensional Hydrophobic-Polar Protein Folding Model with Attention-based layers","abstract":"Transformer-based architectures have recently propelled advances in sequence modeling across domains, but their application to the hydrophobic-hydrophilic (H-P) model for protein folding remains relatively unexplored. In this work, we adapt a Deep Q-Network (DQN) integrated with attention mechanisms (Transformers) to address the 3D H-P protein folding problem. Our system formulates folding decisions as a self-avoiding walk in a reinforced environment, and employs a specialized reward function based on favorable hydrophobic interactions. To improve performance, the method incorporates validity check including symmetry-breaking constraints, dueling and double Q-learning, and prioritized replay to focus learning on critical transitions. Experimental evaluations on standard benchmark sequences demonstrate that our approach achieves several known best solutions for shorter sequences, and obtains near-optimal results for longer chains. This study underscores the promise of attention-based reinforcement learning for protein folding, and created a prototype of Transformer-based Q-network structure for 3-dimensional lattice models.","authors":["Peizheng Liu","Hitoshi Iba"],"url":"https://arxiv.org/abs/2504.15634"}
{"created":"2025-04-23","title":"DR.FIX: Automatically Fixing Data Races at Industry Scale","abstract":"Data races are a prevalent class of concurrency bugs in shared-memory parallel programs, posing significant challenges to software reliability and reproducibility. While there is an extensive body of research on detecting data races and a wealth of practical detection tools across various programming languages, considerably less effort has been directed toward automatically fixing data races at an industrial scale. In large codebases, data races are continuously introduced and exhibit myriad patterns, making automated fixing particularly challenging.","authors":["Farnaz Behrang","Zhizhou Zhang","Georgian-Vlad Saioc","Peng Liu","Milind Chabbi"],"url":"https://arxiv.org/abs/2504.15637"}
{"created":"2025-04-23","title":"Cost-Effective Text Clustering with Large Language Models","abstract":"Text clustering aims to automatically partition a collection of text documents into distinct clusters based on linguistic features. In the literature, this task is usually framed as metric clustering based on text embeddings from pre-trained encoders or a graph clustering problem upon pairwise similarities from an oracle, e.g., a large ML model. Recently, large language models (LLMs) bring significant advancement in this field by offering contextualized text embeddings and highly accurate similarity scores, but meanwhile, present grand challenges to cope with substantial computational and/or financial overhead caused by numerous API-based queries or inference calls to the models.","authors":["Hongtao Wang","Taiyan Zhang","Renchi Yang","Jianliang Xu"],"url":"https://arxiv.org/abs/2504.15640"}
{"created":"2025-04-23","title":"Computational Typology","abstract":"Typology is a subfield of linguistics that focuses on the study and classification of languages based on their structural features. Unlike genealogical classification, which examines the historical relationships between languages, typology seeks to understand the diversity of human languages by identifying common properties and patterns, known as universals. In recent years, computational methods have played an increasingly important role in typological research, enabling the analysis of large-scale linguistic data and the testing of hypotheses about language structure and evolution. This article provides an illustration of the benefits of computational statistical modeling in typology.","authors":["Gerhard J\\\"ager"],"url":"https://arxiv.org/abs/2504.15642"}
{"created":"2025-04-23","title":"Multimodal Perception for Goal-oriented Navigation: A Survey","abstract":"Goal-oriented navigation presents a fundamental challenge for autonomous systems, requiring agents to navigate complex environments to reach designated targets. This survey offers a comprehensive analysis of multimodal navigation approaches through the unifying perspective of inference domains, exploring how agents perceive, reason about, and navigate environments using visual, linguistic, and acoustic information. Our key contributions include organizing navigation methods based on their primary environmental reasoning mechanisms across inference domains; systematically analyzing how shared computational foundations support seemingly disparate approaches across different navigation tasks; identifying recurring patterns and distinctive strengths across various navigation paradigms; and examining the integration challenges and opportunities of multimodal perception to enhance navigation capabilities. In addition, we review approximately 200 relevant articles to provide an in-depth understanding of the current landscape.","authors":["I-Tak Ieong","Hao Tang"],"url":"https://arxiv.org/abs/2504.15643"}
{"created":"2025-04-23","title":"SMT and Functional Equation Solving over the Reals: Challenges from the IMO","abstract":"We use SMT technology to address a class of problems involving uninterpreted functions and nonlinear real arithmetic. In particular, we focus on problems commonly found in mathematical competitions, such as the International Mathematical Olympiad (IMO), where the task is to determine all solutions to constraints on an uninterpreted function. Although these problems require only high-school-level mathematics, state-of-the-art SMT solvers often struggle with them. We propose several techniques to improve SMT performance in this setting.","authors":["Chad E. Brown","Karel Chvalovsk\\'y","Mikol\\'a\\v{s} Janota","Mirek Ol\\v{s}\\'ak","Stefan Ratschan"],"url":"https://arxiv.org/abs/2504.15645"}
{"created":"2025-04-23","title":"Promoting Real-Time Reflection in Synchronous Communication with Generative AI","abstract":"Real-time reflection plays a vital role in synchronous communication. It enables users to adjust their communication strategies dynamically, thereby improving the effectiveness of their communication. Generative AI holds significant potential to enhance real-time reflection due to its ability to comprehensively understand the current context and generate personalized and nuanced content. However, it is challenging to design the way of interaction and information presentation to support the real-time workflow rather than disrupt it. In this position paper, we present a review of research on systems designed for real-time reflection in different synchronous communication scenarios. Based on that, we discuss how to design human-AI interaction to support real-time reflection in synchronous communication scenarios.","authors":["Yi Wen","Meng Xia"],"url":"https://arxiv.org/abs/2504.15647"}
{"created":"2025-04-23","title":"AffordanceSAM: Segment Anything Once More in Affordance Grounding","abstract":"Improving the generalization ability of an affordance grounding model to recognize regions for unseen objects and affordance functions is crucial for real-world application. However, current models are still far away from such standards. To address this problem, we introduce AffordanceSAM, an effective approach that extends SAM's generalization capacity to the domain of affordance grounding. For the purpose of thoroughly transferring SAM's robust performance in segmentation to affordance, we initially propose an affordance-adaption module in order to help modify SAM's segmentation output to be adapted to the specific functional regions required for affordance grounding. We concurrently make a coarse-to-fine training recipe to make SAM first be aware of affordance objects and actions coarsely, and then be able to generate affordance heatmaps finely. Both quantitative and qualitative experiments show the strong generalization capacity of our AffordanceSAM, which not only surpasses previous methods under AGD20K benchmark but also shows evidence to handle the task with novel objects and affordance functions.","authors":["Dengyang Jiang","Mengmeng Wang","Teli Ma","Hengzhuang Li","Yong liu","Guang Dai","Lei Zhang"],"url":"https://arxiv.org/abs/2504.15650"}
{"created":"2025-04-23","title":"A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities","abstract":"This paper introduces a novel AI vision-enabled pediatric prosthetic hand designed to assist children aged 10-12 with upper limb disabilities. The prosthesis features an anthropomorphic appearance, multi-articulating functionality, and a lightweight design that mimics a natural hand, making it both accessible and affordable for low-income families. Using 3D printing technology and integrating advanced machine vision, sensing, and embedded computing, the prosthetic hand offers a low-cost, customizable solution that addresses the limitations of current myoelectric prostheses. A micro camera is interfaced with a low-power FPGA for real-time object detection and assists with precise grasping. The onboard DL-based object detection and grasp classification models achieved accuracies of 96% and 100% respectively. In the force prediction, the mean absolute error was found to be 0.018. The features of the proposed prosthetic hand can thus be summarized as: a) a wrist-mounted micro camera for artificial sensing, enabling a wide range of hand-based tasks; b) real-time object detection and distance estimation for precise grasping; and c) ultra-low-power operation that delivers high performance within constrained power and resource limits.","authors":["Md Abdul Baset Sarker","Art Nguyen","Sigmond Kukla","Kevin Fite","Masudul H. Imtiaz"],"url":"https://arxiv.org/abs/2504.15654"}
{"created":"2025-04-23","title":"Neural Kinematic Bases for Fluids","abstract":"We propose mesh-free fluid simulations that exploit a kinematic neural basis for velocity fields represented by an MLP. We design a set of losses that ensures that these neural bases satisfy fundamental physical properties such as orthogonality, divergence-free, boundary alignment, and smoothness. Our neural bases can then be used to fit an input sketch of a flow, which will inherit the same fundamental properties from the bases. We then can animate such flow in real-time using standard time integrators. Our neural bases can accommodate different domains and naturally extend to three dimensions.","authors":["Yibo Liu","Paul Kry","Kenny Erleben","Noam Aigerman","Sune Darkner","Teseo Schneider"],"url":"https://arxiv.org/abs/2504.15657"}
{"created":"2025-04-23","title":"VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional Correctness Validation","abstract":"Recent advances in Large Language Models (LLMs) have sparked growing interest in applying them to Electronic Design Automation (EDA) tasks, particularly Register Transfer Level (RTL) code generation. While several RTL datasets have been introduced, most focus on syntactic validity rather than functional validation with tests, leading to training examples that compile but may not implement the intended behavior. We present VERICODER, a model for RTL code generation fine-tuned on a dataset validated for functional correctness. This fine-tuning dataset is constructed using a novel methodology that combines unit test generation with feedback-directed refinement. Given a natural language specification and an initial RTL design, we prompt a teacher model (GPT-4o-mini) to generate unit tests and iteratively revise the RTL design based on its simulation results using the generated tests. If necessary, the teacher model also updates the tests to ensure they comply with the natural language specification. As a result of this process, every example in our dataset is functionally validated, consisting of a natural language description, an RTL implementation, and passing tests. Fine-tuned on this dataset of over 125,000 examples, VERICODER achieves state-of-the-art metrics in functional correctness on VerilogEval and RTLLM, with relative gains of up to 71.7% and 27.4% respectively. An ablation study further shows that models trained on our functionally validated dataset outperform those trained on functionally non-validated datasets, underscoring the importance of high-quality datasets in RTL code generation.","authors":["Anjiang Wei","Huanmi Tan","Tarun Suresh","Daniel Mendoza","Thiago S. F. X. Teixeira","Ke Wang","Caroline Trippel","Alex Aiken"],"url":"https://arxiv.org/abs/2504.15659"}
{"created":"2025-04-23","title":"DiTPainter: Efficient Video Inpainting with Diffusion Transformers","abstract":"Many existing video inpainting algorithms utilize optical flows to construct the corresponding maps and then propagate pixels from adjacent frames to missing areas by mapping. Despite the effectiveness of the propagation mechanism, they might encounter blurry and inconsistencies when dealing with inaccurate optical flows or large masks. Recently, Diffusion Transformer (DiT) has emerged as a revolutionary technique for video generation tasks. However, pretrained DiT models for video generation all contain a large amount of parameters, which makes it very time consuming to apply to video inpainting tasks. In this paper, we present DiTPainter, an end-to-end video inpainting model based on Diffusion Transformer (DiT). DiTPainter uses an efficient transformer network designed for video inpainting, which is trained from scratch instead of initializing from any large pretrained models. DiTPainter can address videos with arbitrary lengths and can be applied to video decaptioning and video completion tasks with an acceptable time cost. Experiments show that DiTPainter outperforms existing video inpainting algorithms with higher quality and better spatial-temporal consistency.","authors":["Xian Wu","Chang Liu"],"url":"https://arxiv.org/abs/2504.15661"}
{"created":"2025-04-23","title":"An XAI-based Analysis of Shortcut Learning in Neural Networks","abstract":"Machine learning models tend to learn spurious features - features that strongly correlate with target labels but are not causal. Existing approaches to mitigate models' dependence on spurious features work in some cases, but fail in others. In this paper, we systematically analyze how and where neural networks encode spurious correlations. We introduce the neuron spurious score, an XAI-based diagnostic measure to quantify a neuron's dependence on spurious features. We analyze both convolutional neural networks (CNNs) and vision transformers (ViTs) using architecture-specific methods. Our results show that spurious features are partially disentangled, but the degree of disentanglement varies across model architectures. Furthermore, we find that the assumptions behind existing mitigation methods are incomplete. Our results lay the groundwork for the development of novel methods to mitigate spurious correlations and make AI models safer to use in practice.","authors":["Phuong Quynh Le","J\\\"org Schl\\\"otterer","Christin Seifert"],"url":"https://arxiv.org/abs/2504.15664"}
{"created":"2025-04-23","title":"Motion-Enhanced Nonlocal Similarity Implicit Neural Representation for Infrared Dim and Small Target Detection","abstract":"Infrared dim and small target detection presents a significant challenge due to dynamic multi-frame scenarios and weak target signatures in the infrared modality. Traditional low-rank plus sparse models often fail to capture dynamic backgrounds and global spatial-temporal correlations, which results in background leakage or target loss. In this paper, we propose a novel motion-enhanced nonlocal similarity implicit neural representation (INR) framework to address these challenges. We first integrate motion estimation via optical flow to capture subtle target movements, and propose multi-frame fusion to enhance motion saliency. Second, we leverage nonlocal similarity to construct patch tensors with strong low-rank properties, and propose an innovative tensor decomposition-based INR model to represent the nonlocal patch tensor, effectively encoding both the nonlocal low-rankness and spatial-temporal correlations of background through continuous neural representations. An alternating direction method of multipliers is developed for the nonlocal INR model, which enjoys theoretical fixed-point convergence. Experimental results show that our approach robustly separates dim targets from complex infrared backgrounds, outperforming state-of-the-art methods in detection accuracy and robustness.","authors":["Pei Liu","Yisi Luo","Wenzhen Wang","Xiangyong Cao"],"url":"https://arxiv.org/abs/2504.15665"}
{"created":"2025-04-23","title":"Symbolic Runtime Verification and Adaptive Decision-Making for Robot-Assisted Dressing","abstract":"We present a control framework for robot-assisted dressing that augments low-level hazard response with runtime monitoring and formal verification. A parametric discrete-time Markov chain (pDTMC) models the dressing process, while Bayesian inference dynamically updates this pDTMC's transition probabilities based on sensory and user feedback. Safety constraints from hazard analysis are expressed in probabilistic computation tree logic, and symbolically verified using a probabilistic model checker. We evaluate reachability, cost, and reward trade-offs for garment-snag mitigation and escalation, enabling real-time adaptation. Our approach provides a formal yet lightweight foundation for safety-aware, explainable robotic assistance.","authors":["Yasmin Rafiq","Gricel V\\'azquez","Radu Calinescu","Sanja Dogramadzi","Robert M Hierons"],"url":"https://arxiv.org/abs/2504.15666"}
{"created":"2025-04-23","title":"Exploring Inevitable Waypoints for Unsolvability Explanation in Hybrid Planning Problems","abstract":"Explaining unsolvability of planning problems is of significant research interest in Explainable AI Planning. AI planning literature has reported several research efforts on generating explanations of solutions to planning problems. However, explaining the unsolvability of planning problems remains a largely open and understudied problem. A widely practiced approach to plan generation and automated problem solving, in general, is to decompose tasks into sub-problems that help progressively converge towards the goal. In this paper, we propose to adopt the same philosophy of sub-problem identification as a mechanism for analyzing and explaining unsolvability of planning problems in hybrid systems. In particular, for a given unsolvable planning problem, we propose to identify common waypoints, which are universal obstacles to plan existence; in other words, they appear on every plan from the source to the planning goal. This work envisions such waypoints as sub-problems of the planning problem and the unreachability of any of these waypoints as an explanation for the unsolvability of the original planning problem. We propose a novel method of waypoint identification by casting the problem as an instance of the longest common subsequence problem, a widely popular problem in computer science, typically considered as an illustrative example for the dynamic programming paradigm. Once the waypoints are identified, we perform symbolic reachability analysis on them to identify the earliest unreachable waypoint and report it as the explanation of unsolvability. We present experimental results on unsolvable planning problems in hybrid domains.","authors":["Mir Md Sajid Sarwar","Rajarshi Ray"],"url":"https://arxiv.org/abs/2504.15668"}
{"created":"2025-04-23","title":"DINOv2-powered Few-Shot Semantic Segmentation: A Unified Framework via Cross-Model Distillation and 4D Correlation Mining","abstract":"Few-shot semantic segmentation has gained increasing interest due to its generalization capability, i.e., segmenting pixels of novel classes requiring only a few annotated images. Prior work has focused on meta-learning for support-query matching, with extensive development in both prototype-based and aggregation-based methods. To address data scarcity, recent approaches have turned to foundation models to enhance representation transferability for novel class segmentation. Among them, a hybrid dual-modal framework including both DINOv2 and SAM has garnered attention due to their complementary capabilities. We wonder \"can we build a unified model with knowledge from both foundation models?\" To this end, we propose FS-DINO, with only DINOv2's encoder and a lightweight segmenter. The segmenter features a bottleneck adapter, a meta-visual prompt generator based on dense similarities and semantic embeddings, and a decoder. Through coarse-to-fine cross-model distillation, we effectively integrate SAM's knowledge into our lightweight segmenter, which can be further enhanced by 4D correlation mining on support-query pairs. Extensive experiments on COCO-20i, PASCAL-5i, and FSS-1000 demonstrate the effectiveness and superiority of our method.","authors":["Wei Zhuo","Zhiyue Tang","Wufeng Xue","Hao Ding","Linlin Shen"],"url":"https://arxiv.org/abs/2504.15669"}
{"created":"2025-04-23","title":"Comparative Analysis of Evolutionary Algorithms for Energy-Aware Production Scheduling","abstract":"The energy transition is driving rapid growth in renewable energy generation, creating the need to balance energy supply and demand with energy price awareness. One such approach for manufacturers to balance their energy demand with available energy is energyaware production planning. Through energy-aware production planning, manufacturers can align their energy demand with dynamic grid conditions, supporting renewable energy integration while benefiting from lower prices and reduced emissions. Energy-aware production planning can be modeled as a multi-criteria scheduling problem, where the objectives extend beyond traditional metrics like makespan or required workers to also include minimizing energy costs and emissions. Due to market dynamics and the NP-hard multi-objective nature of the problem, evolutionary algorithms are widely used for energy-aware scheduling. However, existing research focuses on the design and analysis of single algorithms, with limited comparisons between different approaches. In this study, we adapt NSGA-III, HypE, and $\\theta$-DEA as memetic metaheuristics for energy-aware scheduling to minimize makespan, energy costs, emissions, and the number of workers, within a real-time energy market context. These adapted metaheuristics present different approaches for environmental selection. In a comparative analysis, we explore differences in solution efficiency and quality across various scenarios which are based on benchmark instances from the literature and real-world energy market data. Additionally, we estimate upper bounds on the distance between objective values obtained with our memetic metaheuristics and reference sets obtained via an exact solver.","authors":["Sascha C Burmeister","Till N Rogalski","Guido Schryen"],"url":"https://arxiv.org/abs/2504.15672"}
{"created":"2025-04-23","title":"TrojanDam: Detection-Free Backdoor Defense in Federated Learning through Proactive Model Robustification utilizing OOD Data","abstract":"Federated learning (FL) systems allow decentralized data-owning clients to jointly train a global model through uploading their locally trained updates to a centralized server. The property of decentralization enables adversaries to craft carefully designed backdoor updates to make the global model misclassify only when encountering adversary-chosen triggers. Existing defense mechanisms mainly rely on post-training detection after receiving updates. These methods either fail to identify updates which are deliberately fabricated statistically close to benign ones, or show inconsistent performance in different FL training stages. The effect of unfiltered backdoor updates will accumulate in the global model, and eventually become functional. Given the difficulty of ruling out every backdoor update, we propose a backdoor defense paradigm, which focuses on proactive robustification on the global model against potential backdoor attacks. We first reveal that the successful launching of backdoor attacks in FL stems from the lack of conflict between malicious and benign updates on redundant neurons of ML models. We proceed to prove the feasibility of activating redundant neurons utilizing out-of-distribution (OOD) samples in centralized settings, and migrating to FL settings to propose a novel backdoor defense mechanism, TrojanDam. The proposed mechanism has the FL server continuously inject fresh OOD mappings into the global model to activate redundant neurons, canceling the effect of backdoor updates during aggregation. We conduct systematic and extensive experiments to illustrate the superior performance of TrojanDam, over several SOTA backdoor defense methods across a wide range of FL settings.","authors":["Yanbo Dai","Songze Li","Zihan Gan","Xueluan Gong"],"url":"https://arxiv.org/abs/2504.15674"}
{"created":"2025-04-23","title":"Trustworthy Decentralized Autonomous Machines: A New Paradigm in Automation Economy","abstract":"Decentralized Autonomous Machines (DAMs) represent a transformative paradigm in automation economy, integrating artificial intelligence (AI), blockchain technology, and Internet of Things (IoT) devices to create self-governing economic agents participating in Decentralized Physical Infrastructure Networks (DePIN). Capable of managing both digital and physical assets and unlike traditional Decentralized Autonomous Organizations (DAOs), DAMs extend autonomy into the physical world, enabling trustless systems for Real and Digital World Assets (RDWAs). In this paper, we explore the technological foundations, and challenges of DAMs and argue that DAMs are pivotal in transitioning from trust-based to trustless economic models, offering scalable, transparent, and equitable solutions for asset management. The integration of AI-driven decision-making, IoT-enabled operational autonomy, and blockchain-based governance allows DAMs to decentralize ownership, optimize resource allocation, and democratize access to economic opportunities. Therefore, in this research, we highlight the potential of DAMs to address inefficiencies in centralized systems, reduce wealth disparities, and foster a post-labor economy.","authors":["Fernando Castillo","Oscar Castillo","Eduardo Brito","Simon Espinola"],"url":"https://arxiv.org/abs/2504.15676"}
{"created":"2025-04-23","title":"Zoozve: A Strip-Mining-Free RISC-V Vector Extension with Arbitrary Register Grouping Compilation Support (WIP)","abstract":"Vector processing is crucial for boosting processor performance and efficiency, particularly with data-parallel tasks. The RISC-V \"V\" Vector Extension (RVV) enhances algorithm efficiency by supporting vector registers of dynamic sizes and their grouping. Nevertheless, for very long vectors, the static number of RVV vector registers and its power-of-two grouping can lead to performance restrictions. To counteract this limitation, this work introduces Zoozve, a RISC-V vector instruction extension that eliminates the need for strip-mining. Zoozve allows for flexible vector register length and count configurations to boost data computation parallelism. With a data-adaptive register allocation approach, Zoozve permits any register groupings and accurately aligns vector lengths, cutting down register overhead and alleviating performance declines from strip-mining. Additionally, the paper details Zoozve's compiler and hardware implementations using LLVM and SystemVerilog. Initial results indicate Zoozve yields a minimum 10.10$\\times$ reduction in dynamic instruction count for fast Fourier transform (FFT), with a mere 5.2\\% increase in overall silicon area.","authors":["Siyi Xu","Limin Jiang","Yintao Liu","Yihao Shen","Yi Shi","Shan Cao","Zhiyuan Jiang"],"url":"https://arxiv.org/abs/2504.15678"}
{"created":"2025-04-23","title":"Vidi: Large Multimodal Models for Video Understanding and Editing","abstract":"Humans naturally share information with those they are connected to, and video has become one of the dominant mediums for communication and expression on the Internet. To support the creation of high-quality large-scale video content, a modern pipeline requires a comprehensive understanding of both the raw input materials (e.g., the unedited footage captured by cameras) and the editing components (e.g., visual effects). In video editing scenarios, models must process multiple modalities (e.g., vision, audio, text) with strong background knowledge and handle flexible input lengths (e.g., hour-long raw videos), which poses significant challenges for traditional models. In this report, we introduce Vidi, a family of Large Multimodal Models (LMMs) for a wide range of video understand editing scenarios. The first release focuses on temporal retrieval, i.e., identifying the time ranges within the input videos corresponding to a given text query, which plays a critical role in intelligent editing. The model is capable of processing hour-long videos with strong temporal understanding capability, e.g., retrieve time ranges for certain queries. To support a comprehensive evaluation in real-world scenarios, we also present the VUE-TR benchmark, which introduces five key advancements. 1) Video duration: significantly longer than existing temporal retrival datasets, 2) Audio support: includes audio-based queries, 3) Query format: diverse query lengths/formats, 4) Annotation quality: ground-truth time ranges are manually annotated. 5) Evaluation metric: a refined IoU metric to support evaluation over multiple time ranges. Remarkably, Vidi significantly outperforms leading proprietary models, e.g., GPT-4o and Gemini, on the temporal retrieval task, indicating its superiority in video editing scenarios.","authors":["Vidi Team","Celong Liu","Chia-Wen Kuo","Dawei Du","Fan Chen","Guang Chen","Jiamin Yuan","Lingxi Zhang","Lu Guo","Lusha Li","Longyin Wen","Qingyu Chen","Rachel Deng","Sijie Zhu","Stuart Siew","Tong Jin","Wei Lu","Wen Zhong","Xiaohui Shen","Xin Gu","Xing Mei","Xueqiong Qu"],"url":"https://arxiv.org/abs/2504.15681"}
{"created":"2025-04-23","title":"FinTextSim: Enhancing Financial Text Analysis with BERTopic","abstract":"Recent advancements in information availability and computational capabilities have transformed the analysis of annual reports, integrating traditional financial metrics with insights from textual data. To extract valuable insights from this wealth of textual data, automated review processes, such as topic modeling, are crucial. This study examines the effectiveness of BERTopic, a state-of-the-art topic model relying on contextual embeddings, for analyzing Item 7 and Item 7A of 10-K filings from S&amp;P 500 companies (2016-2022). Moreover, we introduce FinTextSim, a finetuned sentence-transformer model optimized for clustering and semantic search in financial contexts. Compared to all-MiniLM-L6-v2, the most widely used sentence-transformer, FinTextSim increases intratopic similarity by 81% and reduces intertopic similarity by 100%, significantly enhancing organizational clarity. We assess BERTopic's performance using embeddings from both FinTextSim and all-MiniLM-L6-v2. Our findings reveal that BERTopic only forms clear and distinct economic topic clusters when paired with FinTextSim's embeddings. Without FinTextSim, BERTopic struggles with misclassification and overlapping topics. Thus, FinTextSim is pivotal for advancing financial text analysis. FinTextSim's enhanced contextual embeddings, tailored for the financial domain, elevate the quality of future research and financial information. This improved quality of financial information will enable stakeholders to gain a competitive advantage, streamlining resource allocation and decision-making processes. Moreover, the improved insights have the potential to leverage business valuation and stock price prediction models.","authors":["Simon Jehnen","Joaqu\\'in Ordieres-Mer\\'e","Javier Villalba-D\\'iez"],"url":"https://arxiv.org/abs/2504.15683"}
{"created":"2025-04-23","title":"Invariant Learning with Annotation-free Environments","abstract":"Invariant learning is a promising approach to improve domain generalization compared to Empirical Risk Minimization (ERM). However, most invariant learning methods rely on the assumption that training examples are pre-partitioned into different known environments. We instead infer environments without the need for additional annotations, motivated by observations of the properties within the representation space of a trained ERM model. We show the preliminary effectiveness of our approach on the ColoredMNIST benchmark, achieving performance comparable to methods requiring explicit environment labels and on par with an annotation-free method that poses strong restrictions on the ERM reference model.","authors":["Phuong Quynh Le","Christin Seifert","J\\\"org Schl\\\"otterer"],"url":"https://arxiv.org/abs/2504.15686"}
{"created":"2025-04-23","title":"Subject islands do not reduce to construction-specific discourse function","abstract":"The term islands in linguistics refers to phrases from which extracting an element results in ungrammaticality (Ross, 1967). Grammatical subjects are considered islands because extracting a sub-part of a subject results in an ill-formed sentence, despite having a clear intended meaning (e.g., \"Which topic did the article about inspire you?\"). The generative tradition, which views syntax as autonomous of meaning and function, attributes this ungrammaticality to the abstract movement dependency between the wh-phrase and the subject-internal position with which it is associated for interpretation. However, research on language that emphasizes its communicative function suggests instead that syntactic constraints, including islands, can be explained based on the way different constructions package information. Accordingly, Abeill\\'e et al. (2020) suggest that the islandhood of subjects is specific to the information structure of wh-questions, and propose that subjects are not islands for movement, but for focusing, due to their discourse-backgroundedness. This predicts that other constructions that differ in their information structure from wh-questions, but still involve movement, should not create a subject island effect. We test this prediction in three large-scale acceptability studies, using a super-additive design that singles out subject island violations, in three different constructions: wh-questions, relative clauses, and topicalization. We report evidence for a subject island effect in each construction type, despite only wh-questions introducing what Abeill\\'e et al. (2020) call \"a clash in information structure.\" We argue that this motivates an account of islands in terms of abstract, syntactic representations, independent of the communicative function associated with the constructions.","authors":["Mandy Cartner","Matthew Kogan","Nikolas Webster","Matthew Wagers","Ivy Sichel"],"url":"https://arxiv.org/abs/2504.15688"}
{"created":"2025-04-23","title":"The Viability of Crowdsourcing for RAG Evaluation","abstract":"How good are humans at writing and judging responses in retrieval-augmented generation (RAG) scenarios? To answer this question, we investigate the efficacy of crowdsourcing for RAG through two complementary studies: response writing and response utility judgment. We present the Crowd RAG Corpus 2025 (CrowdRAG-25), which consists of 903 human-written and 903 LLM-generated responses for the 301 topics of the TREC RAG'24 track, across the three discourse styles 'bulleted list', 'essay', and 'news'. For a selection of 65 topics, the corpus further contains 47,320 pairwise human judgments and 10,556 pairwise LLM judgments across seven utility dimensions (e.g., coverage and coherence). Our analyses give insights into human writing behavior for RAG and the viability of crowdsourcing for RAG evaluation. Human pairwise judgments provide reliable and cost-effective results compared to LLM-based pairwise or human/LLM-based pointwise judgments, as well as automated comparisons with human-written reference responses. All our data and tools are freely available.","authors":["Lukas Gienapp","Tim Hagen","Maik Fr\\\"obe","Matthias Hagen","Benno Stein","Martin Potthast","Harrisen Scells"],"url":"https://arxiv.org/abs/2504.15689"}
{"created":"2025-04-23","title":"A Data Literacy Competence Model for Higher Education and Research","abstract":"In an increasingly data-driven world, the ability to understand, interpret, and use data - data literacy - is emerging as a critical competence across all academic disciplines. The Data Literacy Initiative (DaLI) at TH K\\\"oln addresses this need by developing a comprehensive competence model for promoting data literacy in higher education. Based on interdisciplinary collaboration and empirical research, the DaLI model defines seven overarching competence areas: \"Establish Data Culture\", \"Provide Data\", \"Manage Data\", \"Analyze Data\", \"Evaluate Data\", \"Interpret Data\", and \"Publish Data\". Each area is further detailed by specific competence dimensions and progression levels, providing a structured framework for curriculum design, teaching, and assessment. Intended for use across disciplines, the model supports the strategic integration of data literacy into university programs. By providing a common language and orientation for educators and institutions, the DaLI model contributes to the broader goal of preparing students to navigate and shape a data-informed society.","authors":["Martina M. Echtenbruck","Simone F\\\"uhles-Ubach","Boris Naujoks","Elisabeth Kaliva"],"url":"https://arxiv.org/abs/2504.15690"}
{"created":"2025-04-23","title":"You Sense Only Once Beneath: Ultra-Light Real-Time Underwater Object Detection","abstract":"Despite the remarkable achievements in object detection, the model's accuracy and efficiency still require further improvement under challenging underwater conditions, such as low image quality and limited computational resources. To address this, we propose an Ultra-Light Real-Time Underwater Object Detection framework, You Sense Only Once Beneath (YSOOB). Specifically, we utilize a Multi-Spectrum Wavelet Encoder (MSWE) to perform frequency-domain encoding on the input image, minimizing the semantic loss caused by underwater optical color distortion. Furthermore, we revisit the unique characteristics of even-sized and transposed convolutions, allowing the model to dynamically select and enhance key information during the resampling process, thereby improving its generalization ability. Finally, we eliminate model redundancy through a simple yet effective channel compression and reconstructed large kernel convolution (RLKC) to achieve model lightweight. As a result, forms a high-performance underwater object detector YSOOB with only 1.2 million parameters. Extensive experimental results demonstrate that, with the fewest parameters, YSOOB achieves mAP50 of 83.1% and 82.9% on the URPC2020 and DUO datasets, respectively, comparable to the current SOTA detectors. The inference speed reaches 781.3 FPS and 57.8 FPS on the T4 GPU (TensorRT FP16) and the edge computing device Jetson Xavier NX (TensorRT FP16), surpassing YOLOv12-N by 28.1% and 22.5%, respectively.","authors":["Jun Dong","Wenli Wu","Jintao Cheng","Xiaoyu Tang"],"url":"https://arxiv.org/abs/2504.15694"}
{"created":"2025-04-23","title":"A Time Series Analysis of Malware Uploads to Programming Language Ecosystems","abstract":"Software ecosystems built around programming languages have greatly facilitated software development. At the same time, their security has increasingly been acknowledged as a problem. To this end, the paper examines the previously overlooked longitudinal aspects of software ecosystem security, focusing on malware uploaded to six popular programming language ecosystems. The dataset examined is based on the new Open Source Vulnerabilities (OSV) database. According to the results, records about detected malware uploads in the database have recently surpassed those addressing vulnerabilities in packages distributed in the ecosystems. In the early 2025 even up to 80% of all entries in the OSV have been about malware. Regarding time series analysis of malware frequencies and their shares to all database entries, good predictions are available already by relatively simple autoregressive models using the numbers of ecosystems, security advisories, and media and other articles as predictors. With these results and the accompanying discussion, the paper improves and advances the understanding of the thus far overlooked longitudinal aspects of ecosystems and malware.","authors":["Jukka Ruohonen","Mubashrah Saddiqa"],"url":"https://arxiv.org/abs/2504.15695"}
{"created":"2025-04-23","title":"Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation","abstract":"Embodied agents exhibit immense potential across a multitude of domains, making the assurance of their behavioral safety a fundamental prerequisite for their widespread deployment. However, existing research predominantly concentrates on the security of general large language models, lacking specialized methodologies for establishing safety benchmarks and input moderation tailored to embodied agents. To bridge this gap, this paper introduces a novel input moderation framework, meticulously designed to safeguard embodied agents. This framework encompasses the entire pipeline, including taxonomy definition, dataset curation, moderator architecture, model training, and rigorous evaluation. Notably, we introduce EAsafetyBench, a meticulously crafted safety benchmark engineered to facilitate both the training and stringent assessment of moderators specifically designed for embodied agents. Furthermore, we propose Pinpoint, an innovative prompt-decoupled input moderation scheme that harnesses a masked attention mechanism to effectively isolate and mitigate the influence of functional prompts on moderation tasks. Extensive experiments conducted on diverse benchmark datasets and models validate the feasibility and efficacy of the proposed approach. The results demonstrate that our methodologies achieve an impressive average detection accuracy of 94.58%, surpassing the performance of existing state-of-the-art techniques, alongside an exceptional moderation processing time of merely 0.002 seconds per instance.","authors":["Ning Wang","Zihan Yan","Weiyang Li","Chuan Ma","He Chen","Tao Xiang"],"url":"https://arxiv.org/abs/2504.15699"}
{"created":"2025-04-23","title":"Towards True Work-Efficiency in Parallel Derandomization: MIS, Maximal Matching, and Hitting Set","abstract":"Derandomization is one of the classic topics studied in the theory of parallel computations, dating back to the early 1980s. Despite much work, all known techniques lead to deterministic algorithms that are not work-efficient. For instance, for the well-studied problem of maximal independent set -- e.g., [Karp, Wigderson STOC'84; Luby STOC' 85; Luby FOCS'88] -- state-of-the-art deterministic algorithms require at least $m \\cdot poly(\\log n)$ work, where $m$ and $n$ denote the number of edges and vertices. Hence, these deterministic algorithms will remain slower than their trivial sequential counterparts unless we have at least $poly(\\log n)$ processors.","authors":["Mohsen Ghaffari","Christoph Grunau"],"url":"https://arxiv.org/abs/2504.15700"}
{"created":"2025-04-23","title":"On relaxing the N-Reachability Implicit Requirement in NMPC Design","abstract":"This paper proposes a proof of stability for Model Predictive Control formulations involving a prediction horizon that might be too short to meet the reachability condition generally invoked as a sufficient condition for closed-loop stability. This condition is replaced by a contraction condition on the stage cost. But unlike the contraction based existing formulations where the prediction horizon becomes a decision variable, the formulation proposed in this paper remains standard in that it uses constant and short prediction horizon. An illustrative example is provided to assess the relevance of the proposed formulation.","authors":["Mazen Alamir"],"url":"https://arxiv.org/abs/2504.15704"}
{"created":"2025-04-23","title":"Distributed Compression for Computation and Bounds on the Optimal Rate","abstract":"We address the problem of distributed computation of arbitrary functions of two correlated sources $X_1$ and $X_2$, residing in two distributed source nodes, respectively. We exploit the structure of a computation task by coding source characteristic graphs (and multiple instances using the $n$-fold OR product of this graph with itself). For regular graphs and general graphs, we establish bounds on the optimal rate -- characterized by the chromatic entropy for the $n$-fold graph products -- that allows a receiver for asymptotically lossless computation of arbitrary functions over finite fields. For the special class of cycle graphs (i.e., $2$-regular graphs), we establish an exact characterization of chromatic numbers and derive bounds on the required rates. Next, focusing on the more general class of $d$-regular graphs, we establish connections between $d$-regular graphs and expansion rates for $n$-fold graph powers using graph spectra. Finally, for general graphs, we leverage the Gershgorin Circle Theorem (GCT) to provide a characterization of the spectra, which allows us to build new bounds on the optimal rate. Our codes leverage the spectra of the computation and provide a graph expansion-based characterization to efficiently/succinctly capture the computation structure, providing new insights into the problem of distributed computation of arbitrary functions.","authors":["Mohammad Reza Deylam Salehi","Derya Malak"],"url":"https://arxiv.org/abs/2504.15706"}
{"created":"2025-04-23","title":"RePOPE: Impact of Annotation Errors on the POPE Benchmark","abstract":"Since data annotation is costly, benchmark datasets often incorporate labels from established image datasets. In this work, we assess the impact of label errors in MSCOCO on the frequently used object hallucination benchmark POPE. We re-annotate the benchmark images and identify an imbalance in annotation errors across different subsets. Evaluating multiple models on the revised labels, which we denote as RePOPE, we observe notable shifts in model rankings, highlighting the impact of label quality. Code and data are available at https://github.com/YanNeu/RePOPE .","authors":["Yannic Neuhaus","Matthias Hein"],"url":"https://arxiv.org/abs/2504.15707"}
{"created":"2025-04-23","title":"Autonomous Control of Redundant Hydraulic Manipulator Using Reinforcement Learning with Action Feedback","abstract":"This article presents an entirely data-driven approach for autonomous control of redundant manipulators with hydraulic actuation. The approach only requires minimal system information, which is inherited from a simulation model. The non-linear hydraulic actuation dynamics are modeled using actuator networks from the data gathered during the manual operation of the manipulator to effectively emulate the real system in a simulation environment. A neural network control policy for autonomous control, based on end-effector (EE) position tracking is then learned using Reinforcement Learning (RL) with Ornstein-Uhlenbeck process noise (OUNoise) for efficient exploration. The RL agent also receives feedback based on supervised learning of the forward kinematics which facilitates selecting the best suitable action from exploration. The control policy directly provides the joint variables as outputs based on provided target EE position while taking into account the system dynamics. The joint variables are then mapped to the hydraulic valve commands, which are then fed to the system without further modifications. The proposed approach is implemented on a scaled hydraulic forwarder crane with three revolute and one prismatic joint to track the desired position of the EE in 3-Dimensional (3D) space. With the emulated dynamics and extensive learning in simulation, the results demonstrate the feasibility of deploying the learned controller directly on the real system.","authors":["Rohit Dhakate","Christian Brommer","Christoph B\\\"ohm","Stephan Weiss","Jan Steinbrener"],"url":"https://arxiv.org/abs/2504.15714"}
{"created":"2025-04-23","title":"Assessing FAIRness of the Digital Shadow Reference Model","abstract":"Models play a critical role in managing the vast amounts of data and increasing complexity found in the IoT, IIoT, and IoP domains. The Digital Shadow Reference Model, which serves as a foundational metadata schema for linking data and metadata in these environments, is an example of such a model. Ensuring FAIRness (adherence to the FAIR Principles) is critical because it improves data findability, accessibility, interoperability, and reusability, facilitating efficient data management and integration across systems.","authors":["Johannes Theissen-Lipp"],"url":"https://arxiv.org/abs/2504.15715"}
{"created":"2025-04-23","title":"DianJin-R1: Evaluating and Enhancing Financial Reasoning in Large Language Models","abstract":"Effective reasoning remains a core challenge for large language models (LLMs) in the financial domain, where tasks often require domain-specific knowledge, precise numerical calculations, and strict adherence to compliance rules. We propose DianJin-R1, a reasoning-enhanced framework designed to address these challenges through reasoning-augmented supervision and reinforcement learning. Central to our approach is DianJin-R1-Data, a high-quality dataset constructed from CFLUE, FinQA, and a proprietary compliance corpus (Chinese Compliance Check, CCC), combining diverse financial reasoning scenarios with verified annotations. Our models, DianJin-R1-7B and DianJin-R1-32B, are fine-tuned from Qwen2.5-7B-Instruct and Qwen2.5-32B-Instruct using a structured format that generates both reasoning steps and final answers. To further refine reasoning quality, we apply Group Relative Policy Optimization (GRPO), a reinforcement learning method that incorporates dual reward signals: one encouraging structured outputs and another rewarding answer correctness. We evaluate our models on five benchmarks: three financial datasets (CFLUE, FinQA, and CCC) and two general reasoning benchmarks (MATH-500 and GPQA-Diamond). Experimental results show that DianJin-R1 models consistently outperform their non-reasoning counterparts, especially on complex financial tasks. Moreover, on the real-world CCC dataset, our single-call reasoning models match or even surpass the performance of multi-agent systems that require significantly more computational cost. These findings demonstrate the effectiveness of DianJin-R1 in enhancing financial reasoning through structured supervision and reward-aligned learning, offering a scalable and practical solution for real-world applications.","authors":["Jie Zhu","Qian Chen","Huaixia Dou","Junhui Li","Lifan Guo","Feng Chen","Chi Zhang"],"url":"https://arxiv.org/abs/2504.15716"}
{"created":"2025-04-23","title":"Trusted Compute Units: A Framework for Chained Verifiable Computations","abstract":"Blockchain and distributed ledger technologies (DLTs) facilitate decentralized computations across trust boundaries. However, ensuring complex computations with low gas fees and confidentiality remains challenging. Recent advances in Confidential Computing -- leveraging hardware-based Trusted Execution Environments (TEEs) -- and Proof-carrying Data -- employing cryptographic Zero-Knowledge Virtual Machines (zkVMs) -- hold promise for secure, privacy-preserving off-chain and layer-2 computations.On the other side, a homogeneous reliance on a single technology, such as TEEs or zkVMs, is impractical for decentralized environments with heterogeneous computational requirements. This paper introduces the Trusted Compute Unit (TCU), a unifying framework that enables composable and interoperable verifiable computations across heterogeneous technologies. Our approach allows decentralized applications (dApps) to flexibly offload complex computations to TCUs, obtaining proof of correctness. These proofs can be anchored on-chain for automated dApp interactions, while ensuring confidentiality of input data, and integrity of output data. We demonstrate how TCUs can support a prominent blockchain use case, such as federated learning. By enabling secure off-chain interactions without incurring on-chain confirmation delays or gas fees, TCUs significantly improve system performance and scalability. Experimental insights and performance evaluations confirm the feasibility and practicality of this unified approach, advancing the state of the art in verifiable off-chain services for the blockchain ecosystem.","authors":["Fernando Castillo","Jonathan Heiss","Sebastian Werner","Stefan Tai"],"url":"https://arxiv.org/abs/2504.15717"}
{"created":"2025-04-23","title":"Implementing Rational Choice Functions with LLMs and Measuring their Alignment with User Preferences","abstract":"As large language models (LLMs) become integral to intelligent user interfaces (IUIs), their role as decision-making agents raises critical concerns about alignment. Although extensive research has addressed issues such as factuality, bias, and toxicity, comparatively little attention has been paid to measuring alignment to preferences, i.e., the relative desirability of different alternatives, a concept used in decision making, economics, and social choice theory. However, a reliable decision-making agent makes choices that align well with user preferences.","authors":["Anna Karnysheva","Christian Drescher","Dietrich Klakow"],"url":"https://arxiv.org/abs/2504.15719"}
{"created":"2025-04-23","title":"SeaLLM: Service-Aware and Latency-Optimized Resource Sharing for Large Language Model Inference","abstract":"Large language models (LLMs) with different architectures and sizes have been developed. Serving each LLM with dedicated GPUs leads to resource waste and service inefficiency due to the varying demand of LLM requests. A common practice is to share multiple LLMs. However, existing sharing systems either do not consider the autoregressive pattern of LLM services, or only focus on improving the throughput, which impairs the sharing performance, especially the serving latency. We present SeaLLM, which enables service-aware and latency-optimized LLM sharing. SeaLLM improves the overall sharing performance by (1) a latency-optimized scheduling algorithm utilizing the characteristics of LLM services, (2) a placement algorithm to determine the placement plan and an adaptive replacement algorithm to decide the replacement interval, and (3) a unified key-value cache to share GPU memory among LLM services efficiently. Our evaluation under real-world traces and LLM services demonstrates that SeaLLM improves the normalized latency by up to $13.60\\times$, the tail latency by up to $18.69\\times$, and the SLO attainment by up to $3.64\\times$ compared to existing solutions.","authors":["Yihao Zhao","Jiadun Chen","Peng Sun","Lei Li","Xuanzhe Liu","Xin Jin"],"url":"https://arxiv.org/abs/2504.15720"}
{"created":"2025-04-23","title":"BBAL: A Bidirectional Block Floating Point-Based Quantisation Accelerator for Large Language Models","abstract":"Large language models (LLMs), with their billions of parameters, pose substantial challenges for deployment on edge devices, straining both memory capacity and computational resources. Block Floating Point (BFP) quantisation reduces memory and computational overhead by converting high-overhead floating point operations into low-bit fixed point operations. However, BFP requires aligning all data to the maximum exponent, which causes loss of small and moderate values, resulting in quantisation error and degradation in the accuracy of LLMs. To address this issue, we propose a Bidirectional Block Floating Point (BBFP) data format, which reduces the probability of selecting the maximum as shared exponent, thereby reducing quantisation error. By utilizing the features in BBFP, we present a full-stack Bidirectional Block Floating Point-Based Quantisation Accelerator for LLMs (BBAL), primarily comprising a processing element array based on BBFP, paired with proposed cost-effective nonlinear computation unit. Experimental results show BBAL achieves a 22% improvement in accuracy compared to an outlier-aware accelerator at similar efficiency, and a 40% efficiency improvement over a BFP-based accelerator at similar accuracy.","authors":["Xiaomeng Han","Yuan Cheng","Jing Wang","Junyang Lu","Hui Wang","X. x. Zhang","Ning Xu","Dawei Yang","Zhe Jiang"],"url":"https://arxiv.org/abs/2504.15721"}
{"created":"2025-04-23","title":"Structure-Preserving Zero-Shot Image Editing via Stage-Wise Latent Injection in Diffusion Models","abstract":"We propose a diffusion-based framework for zero-shot image editing that unifies text-guided and reference-guided approaches without requiring fine-tuning. Our method leverages diffusion inversion and timestep-specific null-text embeddings to preserve the structural integrity of the source image. By introducing a stage-wise latent injection strategy-shape injection in early steps and attribute injection in later steps-we enable precise, fine-grained modifications while maintaining global consistency. Cross-attention with reference latents facilitates semantic alignment between the source and reference. Extensive experiments across expression transfer, texture transformation, and style infusion demonstrate state-of-the-art performance, confirming the method's scalability and adaptability to diverse image editing scenarios.","authors":["Dasol Jeong","Donggoo Kang","Jiwon Park","Hyebean Lee","Joonki Paik"],"url":"https://arxiv.org/abs/2504.15723"}
{"created":"2025-04-23","title":"Collaborative Split Federated Learning with Parallel Training and Aggregation","abstract":"Federated learning (FL) operates based on model exchanges between the server and the clients, and it suffers from significant client-side computation and communication burden. Split federated learning (SFL) arises a promising solution by splitting the model into two parts, that are trained sequentially: the clients train the first part of the model (client-side model) and transmit it to the server that trains the second (server-side model). Existing SFL schemes though still exhibit long training delays and significant communication overhead, especially when clients of different computing capability participate. Thus, we propose Collaborative-Split Federated Learning~(C-SFL), a novel scheme that splits the model into three parts, namely the model parts trained at the computationally weak clients, the ones trained at the computationally strong clients, and the ones at the server. Unlike existing works, C-SFL enables parallel training and aggregation of model's parts at the clients and at the server, resulting in reduced training delays and commmunication overhead while improving the model's accuracy. Experiments verify the multiple gains of C-SFL against the existing schemes.","authors":["Yiannis Papageorgiou","Yannis Thomas","Alexios Filippakopoulos","Ramin Khalili","Iordanis Koutsopoulos"],"url":"https://arxiv.org/abs/2504.15724"}
{"created":"2025-04-23","title":"SAGA: Semantic-Aware Gray color Augmentation for Visible-to-Thermal Domain Adaptation across Multi-View Drone and Ground-Based Vision Systems","abstract":"Domain-adaptive thermal object detection plays a key role in facilitating visible (RGB)-to-thermal (IR) adaptation by reducing the need for co-registered image pairs and minimizing reliance on large annotated IR datasets. However, inherent limitations of IR images, such as the lack of color and texture cues, pose challenges for RGB-trained models, leading to increased false positives and poor-quality pseudo-labels. To address this, we propose Semantic-Aware Gray color Augmentation (SAGA), a novel strategy for mitigating color bias and bridging the domain gap by extracting object-level features relevant to IR images. Additionally, to validate the proposed SAGA for drone imagery, we introduce the IndraEye, a multi-sensor (RGB-IR) dataset designed for diverse applications. The dataset contains 5,612 images with 145,666 instances, captured from diverse angles, altitudes, backgrounds, and times of day, offering valuable opportunities for multimodal learning, domain adaptation for object detection and segmentation, and exploration of sensor-specific strengths and weaknesses. IndraEye aims to enhance the development of more robust and accurate aerial perception systems, especially in challenging environments. Experimental results show that SAGA significantly improves RGB-to-IR adaptation for autonomous driving and IndraEye dataset, achieving consistent performance gains of +0.4% to +7.6% (mAP) when integrated with state-of-the-art domain adaptation techniques. The dataset and codes are available at https://github.com/airliisc/IndraEye.","authors":["Manjunath D","Aniruddh Sikdar","Prajwal Gurunath","Sumanth Udupa","Suresh Sundaram"],"url":"https://arxiv.org/abs/2504.15728"}
{"created":"2025-04-23","title":"Operator Inference for Elliptic Eigenvalue Problems","abstract":"Eigenvalue problems for elliptic operators play an important role in science and engineering applications, where efficient and accurate numerical computation is essential. In this work, we propose a novel operator inference approach for elliptic eigenvalue problems based on neural network approximations that directly maps computational domains to their associated eigenvalues and eigenfunctions. Motivated by existing neural network architectures and the mathematical characteristics of eigenvalue problems, we represent computational domains as pixelated images and decompose the task into two subtasks: eigenvalue prediction and eigenfunction prediction. For the eigenvalue prediction, we design a convolutional neural network (CNN), while for the eigenfunction prediction, we employ a Fourier Neural Operator (FNO). Additionally, we introduce a critical preprocessing module that integrates domain scaling, detailed boundary pixelization, and main-axis alignment. This preprocessing step not only simplifies the learning task but also enhances the performance of the neural networks. Finally, we present numerical results to demonstrate the effectiveness of the proposed method.","authors":["Haoqian Li","Jiguang Sun","Zhiwen Zhang"],"url":"https://arxiv.org/abs/2504.15733"}
{"created":"2025-04-23","title":"Riemannian Neural Geodesic Interpolant","abstract":"Stochastic interpolants are efficient generative models that bridge two arbitrary probability density functions in finite time, enabling flexible generation from the source to the target distribution or vice versa. These models are primarily developed in Euclidean space, and are therefore limited in their application to many distribution learning problems defined on Riemannian manifolds in real-world scenarios. In this work, we introduce the Riemannian Neural Geodesic Interpolant (RNGI) model, which interpolates between two probability densities on a Riemannian manifold along the stochastic geodesics, and then samples from one endpoint as the final state using the continuous flow originating from the other endpoint. We prove that the temporal marginal density of RNGI solves a transport equation on the Riemannian manifold. After training the model's the neural velocity and score fields, we propose the Embedding Stochastic Differential Equation (E-SDE) algorithm for stochastic sampling of RNGI. E-SDE significantly improves the sampling quality by reducing the accumulated error caused by the excessive intrinsic discretization of Riemannian Brownian motion in the classical Geodesic Random Walk (GRW) algorithm. We also provide theoretical bounds on the generative bias measured in terms of KL-divergence. Finally, we demonstrate the effectiveness of the proposed RNGI and E-SDE through experiments conducted on both collected and synthetic distributions on S2 and SO(3).","authors":["Jiawen Wu","Bingguang Chen","Yuyi Zhou","Qi Meng","Rongchan Zhu","Zhi-Ming Ma"],"url":"https://arxiv.org/abs/2504.15736"}
{"created":"2025-04-23","title":"Energy-Efficient SIM-assisted Communications: How Many Layers Do We Need?","abstract":"The stacked intelligent metasurface (SIM), comprising multiple layers of reconfigurable transmissive metasurfaces, is becoming an increasingly viable solution for future wireless communication systems. In this paper, we explore the integration of SIM in a multi-antenna base station for application to downlink multi-user communications, and a realistic power consumption model for SIM-assisted systems is presented. Specifically, we focus on maximizing the energy efficiency (EE) for hybrid precoding design, i.e., the base station digital precoding and SIM wave-based beamforming. Due to the non-convexity and high complexity of the formulated problem, we employ the quadratic transformation method to reformulate the optimization problem and propose an alternating optimization (AO)-based joint precoding framework. Specifically, a successive convex approximation (SCA) algorithm is adopted for the base station precoding design. For the SIM wave-based beamforming, two algorithms are employed: the high-performance semidefinite programming (SDP) method and the low-complexity projected gradient ascent (PGA) algorithm. In particular, the results indicate that while the optimal number of SIM layers for maximizing the EE and spectral efficiency differs, a design of 2 to 5 layers can achieve satisfactory performance for both. Finally, numerical results are illustrated to evaluate the effectiveness of the proposed hybrid precoding framework and to showcase the performance enhancement achieved by the algorithm in comparison to benchmark schemes.","authors":["Enyu Shi","Jiayi Zhang","Jiancheng An","Marco Di Renzo","Bo Ai","Chau Yuen"],"url":"https://arxiv.org/abs/2504.15737"}
{"created":"2025-04-23","title":"RRC Signaling Storm Detection in O-RAN","abstract":"The Open Radio Access Network (O-RAN) marks a significant shift in the mobile network industry. By transforming a traditionally vertically integrated architecture into an open, data-driven one, O-RAN promises to enhance operational flexibility and drive innovation. In this paper, we harness O-RAN's openness to address one critical threat to 5G availability: signaling storms caused by abuse of the Radio Resource Control (RRC) protocol. Such attacks occur when a flood of RRC messages from one or multiple User Equipments (UEs) deplete resources at a 5G base station (gNB), leading to service degradation. We provide a reference implementation of an RRC signaling storm attack, using the OpenAirInterface (OAI) platform to evaluate its impact on a gNB. We supplement the experimental results with a theoretical model to extend the findings for different load conditions. To mitigate RRC signaling storms, we develop a threshold-based detection technique that relies on RRC layer features to distinguish between malicious activity and legitimate high network load conditions. Leveraging O-RAN capabilities, our detection method is deployed as an external Application (xApp). Performance evaluation shows attacks can be detected within 90ms, providing a mitigation window of 60ms before gNB unavailability, with an overhead of 1.2% and 0% CPU and memory consumption, respectively.","authors":["Dang Kien Nguyen","Rim El Malki","Filippo Rebecchi"],"url":"https://arxiv.org/abs/2504.15738"}
{"created":"2025-04-23","title":"CaRoSaC: A Reinforcement Learning-Based Kinematic Control of Cable-Driven Parallel Robots by Addressing Cable Sag through Simulation","abstract":"This paper introduces the Cable Robot Simulation and Control (CaRoSaC) Framework, which integrates a simulation environment with a model-free reinforcement learning control methodology for suspended Cable-Driven Parallel Robots (CDPRs), accounting for cable sag. Our approach seeks to bridge the knowledge gap of the intricacies of CDPRs due to aspects such as cable sag and precision control necessities by establishing a simulation platform that captures the real-world behaviors of CDPRs, including the impacts of cable sag. The framework offers researchers and developers a tool to further develop estimation and control strategies within the simulation for understanding and predicting the performance nuances, especially in complex operations where cable sag can be significant. Using this simulation framework, we train a model-free control policy in Reinforcement Learning (RL). This approach is chosen for its capability to adaptively learn from the complex dynamics of CDPRs. The policy is trained to discern optimal cable control inputs, ensuring precise end-effector positioning. Unlike traditional feedback-based control methods, our RL control policy focuses on kinematic control and addresses the cable sag issues without being tethered to predefined mathematical models. We also demonstrate that our RL-based controller, coupled with the flexible cable simulation, significantly outperforms the classical kinematics approach, particularly in dynamic conditions and near the boundary regions of the workspace. The combined strength of the described simulation and control approach offers an effective solution in manipulating suspended CDPRs even at workspace boundary conditions where traditional approach fails, as proven from our experiments, ensuring that CDPRs function optimally in various applications while accounting for the often neglected but critical factor of cable sag.","authors":["Rohit Dhakate","Thomas Jantos","Eren Allak","Stephan Weiss","Jan Steinbrener"],"url":"https://arxiv.org/abs/2504.15740"}
{"created":"2025-04-23","title":"Proving Cypher Query Equivalence","abstract":"Graph database systems store graph data as nodes and relationships, and utilize graph query languages (e.g., Cypher) for efficiently querying graph data. Proving the equivalence of graph queries is an important foundation for optimizing graph query performance, ensuring graph query reliability, etc. Although researchers have proposed many SQL query equivalence provers for relational database systems, these provers cannot be directly applied to prove the equivalence of graph queries. The difficulty lies in the fact that graph query languages (e.g., Cypher) adopt significantly different data models (property graph model vs. relational model) and query patterns (graph pattern matching vs. tabular tuple calculus) from SQL.","authors":["Lei Tang","Wensheng Dou","Yingying Zheng","Lijie Xu","Wei Wang","Jun Wei","Tao Huang"],"url":"https://arxiv.org/abs/2504.15742"}
{"created":"2025-04-23","title":"iMedic: Towards Smartphone-based Self-Auscultation Tool for AI-Powered Pediatric Respiratory Assessment","abstract":"Respiratory auscultation is crucial for early detection of pediatric pneumonia, a condition that can quickly worsen without timely intervention. In areas with limited physician access, effective auscultation is challenging. We present a smartphone-based system that leverages built-in microphones and advanced deep learning algorithms to detect abnormal respiratory sounds indicative of pneumonia risk. Our end-to-end deep learning framework employs domain generalization to integrate a large electronic stethoscope dataset with a smaller smartphone-derived dataset, enabling robust feature learning for accurate respiratory assessments without expensive equipment. The accompanying mobile application guides caregivers in collecting high-quality lung sound samples and provides immediate feedback on potential pneumonia risks. User studies show strong classification performance and high acceptance, demonstrating the system's ability to facilitate proactive interventions and reduce preventable childhood pneumonia deaths. By seamlessly integrating into ubiquitous smartphones, this approach offers a promising avenue for more equitable and comprehensive remote pediatric care.","authors":["Seung Gyu Jeong","Sung Woo Nam","Seong Kwan Jung","Seong-Eun Kim"],"url":"https://arxiv.org/abs/2504.15743"}
{"created":"2025-04-23","title":"Enhancing Tennis Training with Real-Time Swing Data Visualisation in Immersive Virtual Reality","abstract":"Recent advances in immersive technology have opened new possibilities in sports training, especially for activities requiring precise motor skills, such as tennis. In this paper, we present a virtual reality (VR) tennis training system integrating real-time performance feedback through a wearable sensor device. Ten participants wore the sensor on their dominant hand to capture motion data, including swing speed and swing power, while engaging in a VR tennis environment. Initially, participants performed baseline tests without access to performance metrics. In subsequent tests, participants executed similar routines with their swing data displayed in real-time via a VR overlay. Qualitative and quantitative results indicated that real-time visual feedback led to improved performance behaviors and enhanced situational awareness. Some participants exhibited increased swing consistency and strategic decision-making, though improvements in accuracy varied individually. Additionally, subjective feedback highlighted that the immersive experience, combined with instantaneous performance metrics, enhanced player engagement and motivation. These findings illustrate the effectiveness of VR-based data visualisation in sports training, suggesting broader applicability in performance enhancement.","authors":["Ryan Najami","Rami Ghannam"],"url":"https://arxiv.org/abs/2504.15746"}
{"created":"2025-04-23","title":"GADS: A Super Lightweight Model for Head Pose Estimation","abstract":"In human-computer interaction, head pose estimation profoundly influences application functionality. Although utilizing facial landmarks is valuable for this purpose, existing landmark-based methods prioritize precision over simplicity and model size, limiting their deployment on edge devices and in compute-poor environments. To bridge this gap, we propose \\textbf{Grouped Attention Deep Sets (GADS)}, a novel architecture based on the Deep Set framework. By grouping landmarks into regions and employing small Deep Set layers, we reduce computational complexity. Our multihead attention mechanism extracts and combines inter-group information, resulting in a model that is $7.5\\times$ smaller and executes $25\\times$ faster than the current lightest state-of-the-art model. Notably, our method achieves an impressive reduction, being $4321\\times$ smaller than the best-performing model. We introduce vanilla GADS and Hybrid-GADS (landmarks + RGB) and evaluate our models on three benchmark datasets -- AFLW2000, BIWI, and 300W-LP. We envision our architecture as a robust baseline for resource-constrained head pose estimation methods.","authors":["Menan Velayuthan","Asiri Gawesha","Purushoth Velayuthan","Nuwan Kodagoda","Dharshana Kasthurirathna","Pradeepa Samarasinghe"],"url":"https://arxiv.org/abs/2504.15751"}
{"created":"2025-04-23","title":"DSDNet: Raw Domain Demoir\\'eing via Dual Color-Space Synergy","abstract":"With the rapid advancement of mobile imaging, capturing screens using smartphones has become a prevalent practice in distance learning and conference recording. However, moir\\'e artifacts, caused by frequency aliasing between display screens and camera sensors, are further amplified by the image signal processing pipeline, leading to severe visual degradation. Existing sRGB domain demoir\\'eing methods struggle with irreversible information loss, while recent two-stage raw domain approaches suffer from information bottlenecks and inference inefficiency. To address these limitations, we propose a single-stage raw domain demoir\\'eing framework, Dual-Stream Demoir\\'eing Network (DSDNet), which leverages the synergy of raw and YCbCr images to remove moir\\'e while preserving luminance and color fidelity. Specifically, to guide luminance correction and moir\\'e removal, we design a raw-to-YCbCr mapping pipeline and introduce the Synergic Attention with Dynamic Modulation (SADM) module. This module enriches the raw-to-sRGB conversion with cross-domain contextual features. Furthermore, to better guide color fidelity, we develop a Luminance-Chrominance Adaptive Transformer (LCAT), which decouples luminance and chrominance representations. Extensive experiments demonstrate that DSDNet outperforms state-of-the-art methods in both visual quality and quantitative evaluation, and achieves an inference speed $\\mathrm{\\textbf{2.4x}}$ faster than the second-best method, highlighting its practical advantages. We provide an anonymous online demo at https://xxxxxxxxdsdnet.github.io/DSDNet/.","authors":["Qirui Yang","Fangpu Zhang","Yeying Jin","Qihua Cheng","Pengtao Jiang","Huanjing Yue","Jingyu Yang"],"url":"https://arxiv.org/abs/2504.15756"}
{"created":"2025-04-23","title":"Observability conditions for neural state-space models with eigenvalues and their roots of unity","abstract":"We operate through the lens of ordinary differential equations and control theory to study the concept of observability in the context of neural state-space models and the Mamba architecture. We develop strategies to enforce observability, which are tailored to a learning context, specifically where the hidden states are learnable at initial time, in conjunction to over its continuum, and high-dimensional. We also highlight our methods emphasize eigenvalues, roots of unity, or both. Our methods effectuate computational efficiency when enforcing observability, sometimes at great scale. We formulate observability conditions in machine learning based on classical control theory and discuss their computational complexity. Our nontrivial results are fivefold. We discuss observability through the use of permutations in neural applications with learnable matrices without high precision. We present two results built upon the Fourier transform that effect observability with high probability up to the randomness in the learning. These results are worked with the interplay of representations in Fourier space and their eigenstructure, nonlinear mappings, and the observability matrix. We present a result for Mamba that is similar to a Hautus-type condition, but instead employs an argument using a Vandermonde matrix instead of eigenvectors. Our final result is a shared-parameter construction of the Mamba system, which is computationally efficient in high exponentiation. We develop a training algorithm with this coupling, showing it satisfies a Robbins-Monro condition under certain orthogonality, while a more classical training procedure fails to satisfy a contraction with high Lipschitz constant.","authors":["Andrew Gracyk"],"url":"https://arxiv.org/abs/2504.15758"}
{"created":"2025-04-23","title":"Dynamic Intent Queries for Motion Transformer-based Trajectory Prediction","abstract":"In autonomous driving, accurately predicting the movements of other traffic participants is crucial, as it significantly influences a vehicle's planning processes. Modern trajectory prediction models strive to interpret complex patterns and dependencies from agent and map data. The Motion Transformer (MTR) architecture and subsequent work define the most accurate methods in common benchmarks such as the Waymo Open Motion Benchmark. The MTR model employs pre-generated static intention points as initial goal points for trajectory prediction. However, the static nature of these points frequently leads to misalignment with map data in specific traffic scenarios, resulting in unfeasible or unrealistic goal points. Our research addresses this limitation by integrating scene-specific dynamic intention points into the MTR model. This adaptation of the MTR model was trained and evaluated on the Waymo Open Motion Dataset. Our findings demonstrate that incorporating dynamic intention points has a significant positive impact on trajectory prediction accuracy, especially for predictions over long time horizons. Furthermore, we analyze the impact on ground truth trajectories which are not compliant with the map data or are illegal maneuvers.","authors":["Tobias Demmler","Lennart Hartung","Andreas Tamke","Thao Dang","Alexander Hegai","Karsten Haug","Lars Mikelsons"],"url":"https://arxiv.org/abs/2504.15766"}
{"created":"2025-04-23","title":"Distributed model predictive control without terminal cost under inexact distributed optimization","abstract":"This paper presents a novel distributed model predictive control (MPC) formulation without terminal cost and a corresponding distributed synthesis approach for distributed linear discrete-time systems with coupled constraints. The proposed control scheme introduces an explicit stability condition as an additional constraint based on relaxed dynamic programming. As a result, contrary to other related approaches, system stability with the developed controller does not rely on designing a terminal cost. A distributed synthesis approach is then introduced to handle the stability constraint locally within each local agent. To solve the underlying optimization problem for distributed MPC, a violation-free distributed optimization approach is developed, using constraint tightening to ensure feasibility throughout iterations. A numerical example demonstrates that the proposed distributed MPC approach ensures closed-loop stability for each feasible control sequence, with each agent computing its control input in parallel.","authors":["Xiaoyu Liu","Dimos V. Dimarogonas","Changxin Liu","Azita Dabiri","Bart De Schutter"],"url":"https://arxiv.org/abs/2504.15768"}
{"created":"2025-04-23","title":"Multi-Scale Tensorial Summation and Dimensional Reduction Guided Neural Network for Edge Detection","abstract":"Edge detection has attracted considerable attention thanks to its exceptional ability to enhance performance in downstream computer vision tasks. In recent years, various deep learning methods have been explored for edge detection tasks resulting in a significant performance improvement compared to conventional computer vision algorithms. In neural networks, edge detection tasks require considerably large receptive fields to provide satisfactory performance. In a typical convolutional operation, such a large receptive field can be achieved by utilizing a significant number of consecutive layers, which yields deep network structures. Recently, a Multi-scale Tensorial Summation (MTS) factorization operator was presented, which can achieve very large receptive fields even from the initial layers. In this paper, we propose a novel MTS Dimensional Reduction (MTS-DR) module guided neural network, MTS-DR-Net, for the edge detection task. The MTS-DR-Net uses MTS layers, and corresponding MTS-DR blocks as a new backbone to remove redundant information initially. Such a dimensional reduction module enables the neural network to focus specifically on relevant information (i.e., necessary subspaces). Finally, a weight U-shaped refinement module follows MTS-DR blocks in the MTS-DR-Net. We conducted extensive experiments on two benchmark edge detection datasets: BSDS500 and BIPEDv2 to verify the effectiveness of our model. The implementation of the proposed MTS-DR-Net can be found at https://github.com/LeiXuAI/MTS-DR-Net.git.","authors":["Lei Xu","Mehmet Yamac","Mete Ahishali","Moncef Gabbouj"],"url":"https://arxiv.org/abs/2504.15770"}
{"created":"2025-04-23","title":"Grounded in Context: Retrieval-Based Method for Hallucination Detection","abstract":"Despite advancements in grounded content generation, production Large Language Models (LLMs) based applications still suffer from hallucinated answers. We present \"Grounded in Context\" - Deepchecks' hallucination detection framework, designed for production-scale long-context data and tailored to diverse use cases, including summarization, data extraction, and RAG. Inspired by RAG architecture, our method integrates retrieval and Natural Language Inference (NLI) models to predict factual consistency between premises and hypotheses using an encoder-based model with only a 512-token context window. Our framework identifies unsupported claims with an F1 score of 0.83 in RAGTruth's response-level classification task, matching methods that trained on the dataset, and outperforming all comparable frameworks using similar-sized models.","authors":["Assaf Gerner","Netta Madvil","Nadav Barak","Alex Zaikman","Jonatan Liberman","Liron Hamra","Rotem Brazilay","Shay Tsadok","Yaron Friedman","Neal Harow","Noam Bresler","Shir Chorev","Philip Tannor"],"url":"https://arxiv.org/abs/2504.15771"}
{"created":"2025-04-23","title":"Clifford Group Equivariant Diffusion Models for 3D Molecular Generation","abstract":"This paper explores leveraging the Clifford algebra's expressive power for $\\E(n)$-equivariant diffusion models. We utilize the geometric products between Clifford multivectors and the rich geometric information encoded in Clifford subspaces in \\emph{Clifford Diffusion Models} (CDMs). We extend the diffusion process beyond just Clifford one-vectors to incorporate all higher-grade multivector subspaces. The data is embedded in grade-$k$ subspaces, allowing us to apply latent diffusion across complete multivectors. This enables CDMs to capture the joint distribution across different subspaces of the algebra, incorporating richer geometric information through higher-order features. We provide empirical results for unconditional molecular generation on the QM9 dataset, showing that CDMs provide a promising avenue for generative modeling.","authors":["Cong Liu","Sharvaree Vadgama","David Ruhe","Erik Bekkers","Patrick Forr\\`e"],"url":"https://arxiv.org/abs/2504.15773"}
{"created":"2025-04-23","title":"Performance Analysis of IEEE 802.11bn Non-Primary Channel Access","abstract":"This paper presents a performance analysis of the Non-Primary Channel Access (NPCA) mechanism, a new feature introduced in IEEE 802.11bn to enhance spectrum utilization in Wi-Fi networks. NPCA enables devices to contend for and transmit on the secondary channel when the primary channel is occupied by transmissions from an Overlapping Basic Service Set (OBSS). We develop a Continuous-Time Markov Chain (CTMC) model that captures the interactions among OBSSs in dense WLAN environments when NPCA is enabled, incorporating new NPCA-specific states and transitions. In addition to the analytical insights offered by the model, we conduct numerical evaluations and simulations to quantify NPCA's impact on throughput and channel access delay across various scenarios. Our results show that NPCA can significantly improve throughput and reduce access delays in favorable conditions for BSSs that support the mechanism. Moreover, NPCA helps mitigate the OBSS performance anomaly, where low-rate OBSS transmissions degrade network performance for all nearby devices. However, we also observe trade-offs: NPCA may increase contention on secondary channels, potentially reducing transmission opportunities for BSSs operating there.","authors":["Boris Bellalta","Francesc Wilhelmi","Lorenzo Galati-Giordano","Giovanni Geraci"],"url":"https://arxiv.org/abs/2504.15774"}
{"created":"2025-04-23","title":"Pose Optimization for Autonomous Driving Datasets using Neural Rendering Models","abstract":"Autonomous driving systems rely on accurate perception and localization of the ego car to ensure safety and reliability in challenging real-world driving scenarios. Public datasets play a vital role in benchmarking and guiding advancement in research by providing standardized resources for model development and evaluation. However, potential inaccuracies in sensor calibration and vehicle poses within these datasets can lead to erroneous evaluations of downstream tasks, adversely impacting the reliability and performance of the autonomous systems. To address this challenge, we propose a robust optimization method based on Neural Radiance Fields (NeRF) to refine sensor poses and calibration parameters, enhancing the integrity of dataset benchmarks. To validate improvement in accuracy of our optimized poses without ground truth, we present a thorough evaluation process, relying on reprojection metrics, Novel View Synthesis rendering quality, and geometric alignment. We demonstrate that our method achieves significant improvements in sensor pose accuracy. By optimizing these critical parameters, our approach not only improves the utility of existing datasets but also paves the way for more reliable autonomous driving models. To foster continued progress in this field, we make the optimized sensor poses publicly available, providing a valuable resource for the research community.","authors":["Quentin Herau","Nathan Piasco","Moussab Bennehar","Luis Rolado","Dzmitry Tsishkou","Bingbing Liu","Cyrille Migniot","Pascal Vasseur","C\\'edric Demonceaux"],"url":"https://arxiv.org/abs/2504.15776"}
{"created":"2025-04-23","title":"Tina: Tiny Reasoning Models via LoRA","abstract":"How cost-effectively can strong reasoning abilities be achieved in language models? Driven by this fundamental question, we present Tina, a family of tiny reasoning models achieved with high cost-efficiency. Notably, Tina demonstrates that substantial reasoning performance can be developed using only minimal resources, by applying parameter-efficient updates during reinforcement learning (RL), using low-rank adaptation (LoRA), to an already tiny 1.5B parameter base model. This minimalist approach produces models that achieve reasoning performance which is competitive with, and sometimes surpasses, SOTA RL reasoning models built upon the same base model. Crucially, this is achieved at a tiny fraction of the computational post-training cost employed by existing SOTA models. In fact, the best Tina model achieves a >20\\% reasoning performance increase and 43.33\\% Pass@1 accuracy on AIME24, at only \\$9 USD post-training and evaluation cost (i.e., an estimated 260x cost reduction). Our work reveals the surprising effectiveness of efficient RL reasoning via LoRA. We validate this across multiple open-source reasoning datasets and various ablation settings starting with a single, fixed set of hyperparameters. Furthermore, we hypothesize that this effectiveness and efficiency stem from LoRA rapidly adapting the model to the structural format of reasoning rewarded by RL, while largely preserving the base model's underlying knowledge. In service of accessibility and open research, we fully open-source all code, training logs, and model weights \\& checkpoints.","authors":["Shangshang Wang","Julian Asilis","\\\"Omer Faruk Akg\\\"ul","Enes Burak Bilgin","Ollie Liu","Willie Neiswanger"],"url":"https://arxiv.org/abs/2504.15777"}
{"created":"2025-04-23","title":"Shannon invariants: A scalable approach to information decomposition","abstract":"Distributed systems, such as biological and artificial neural networks, process information via complex interactions engaging multiple subsystems, resulting in high-order patterns with distinct properties across scales. Investigating how these systems process information remains challenging due to difficulties in defining appropriate multivariate metrics and ensuring their scalability to large systems. To address these challenges, we introduce a novel framework based on what we call \"Shannon invariants\" -- quantities that capture essential properties of high-order information processing in a way that depends only on the definition of entropy and can be efficiently calculated for large systems. Our theoretical results demonstrate how Shannon invariants can be used to resolve long-standing ambiguities regarding the interpretation of widely used multivariate information-theoretic measures. Moreover, our practical results reveal distinctive information-processing signatures of various deep learning architectures across layers, which lead to new insights into how these systems process information and how this evolves during training. Overall, our framework resolves fundamental limitations in analyzing high-order phenomena and offers broad opportunities for theoretical developments and empirical analyses.","authors":["Aaron J. Gutknecht","Fernando E. Rosas","David A. Ehrlich","Abdullah Makkeh","Pedro A. M. Mediano","Michael Wibral"],"url":"https://arxiv.org/abs/2504.15779"}
{"created":"2025-04-23","title":"TrustGeoGen: Scalable and Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving","abstract":"Mathematical geometric problem solving (GPS) often requires effective integration of multimodal information and verifiable logical coherence. Despite the fast development of large language models in general problem solving, it remains unresolved regarding with both methodology and benchmarks, especially given the fact that exiting synthetic GPS benchmarks are often not self-verified and contain noise and self-contradicted information due to the illusion of LLMs. In this paper, we propose a scalable data engine called TrustGeoGen for problem generation, with formal verification to provide a principled benchmark, which we believe lays the foundation for the further development of methods for GPS. The engine synthesizes geometric data through four key innovations: 1) multimodal-aligned generation of diagrams, textual descriptions, and stepwise solutions; 2) formal verification ensuring rule-compliant reasoning paths; 3) a bootstrapping mechanism enabling complexity escalation via recursive state generation and 4) our devised GeoExplore series algorithms simultaneously produce multi-solution variants and self-reflective backtracking traces. By formal logical verification, TrustGeoGen produces GeoTrust-200K dataset with guaranteed modality integrity, along with GeoTrust-test testset. Experiments reveal the state-of-the-art models achieve only 49.17\\% accuracy on GeoTrust-test, demonstrating its evaluation stringency. Crucially, models trained on GeoTrust achieve OOD generalization on GeoQA, significantly reducing logical inconsistencies relative to pseudo-label annotated by OpenAI-o1. Our code is available at https://github.com/Alpha-Innovator/TrustGeoGen","authors":["Daocheng Fu","Zijun Chen","Renqiu Xia","Qi Liu","Yuan Feng","Hongbin Zhou","Renrui Zhang","Shiyang Feng","Peng Gao","Junchi Yan","Botian Shi","Bo Zhang","Yu Qiao"],"url":"https://arxiv.org/abs/2504.15780"}
{"created":"2025-04-23","title":"Model-based Metric 3D Shape and Motion Reconstruction of Wild Bottlenose Dolphins in Drone-Shot Videos","abstract":"We address the problem of estimating the metric 3D shape and motion of wild dolphins from monocular video, with the aim of assessing their body condition. While considerable progress has been made in reconstructing 3D models of terrestrial quadrupeds, aquatic animals remain unexplored due to the difficulty of observing them in their natural underwater environment. To address this, we propose a model-based approach that incorporates a transmission model to account for water-induced occlusion. We apply our method to video captured under different sea conditions. We estimate mass and volume, and compare our results to a manual 2D measurements-based method.","authors":["Daniele Baieri","Riccardo Cicciarella","Michael Kr\\\"utzen","Emanuele Rodol\\`a","Silvia Zuffi"],"url":"https://arxiv.org/abs/2504.15782"}
{"created":"2025-04-23","title":"Towards prediction of morphological heart age from computed tomography angiography","abstract":"Age prediction from medical images or other health-related non-imaging data is an important approach to data-driven aging research, providing knowledge of how much information a specific tissue or organ carries about the chronological age of the individual. In this work, we studied the prediction of age from computed tomography angiography (CTA) images, which provide detailed representations of the heart morphology, with the goals of (i) studying the relationship between morphology and aging, and (ii) developing a novel \\emph{morphological heart age} biomarker. We applied an image registration-based method that standardizes the images from the whole cohort into a single space. We then extracted supervoxels (using unsupervised segmentation), and corresponding robust features of density and local volume, which provide a detailed representation of the heart morphology while being robust to registration errors. Machine learning models are then trained to fit regression models from these features to the chronological age. We applied the method to a subset of the images from the Swedish CArdioPulomonary bioImage Study (SCAPIS) dataset, consisting of 721 females and 666 males. We observe a mean absolute error of $2.74$ years for females and $2.77$ years for males. The predictions from different sub-regions of interest were observed to be more highly correlated with the predictions from the whole heart, compared to the chronological age, revealing a high consistency in the predictions from morphology. Saliency analysis was also performed on the prediction models to study what regions are associated positively and negatively with the predicted age. This resulted in detailed association maps where the density and volume of known, as well as some novel sub-regions of interest, are determined to be important. The saliency analysis aids in the interpretability of the models and their predictions.","authors":["Johan \\\"Ofverstedt","Elin Lundstr\\\"om","H{\\aa}kan Ahlstr\\\"om","Joel Kullberg"],"url":"https://arxiv.org/abs/2504.15783"}
{"created":"2025-04-23","title":"Automated Creativity Evaluation for Large Language Models: A Reference-Based Approach","abstract":"Creative writing is a key capability of Large Language Models (LLMs), with potential applications in literature, storytelling, and various creative domains. However, evaluating the creativity of machine-generated texts remains a significant challenge, as existing methods either rely on costly manual annotations or fail to align closely with human assessments. In this paper, we propose an effective automated evaluation method based on the Torrance Test of Creative Writing (TTCW), which evaluates creativity as product. Our method employs a reference-based Likert-style approach, scoring generated creative texts relative to high-quality reference texts across various tests. Experimental results demonstrate that our method significantly improves the alignment between LLM evaluations and human assessments, achieving a pairwise accuracy of 0.75 (+15\\%).","authors":["Ruizhe Li","Chiwei Zhu","Benfeng Xu","Xiaorui Wang","Zhendong Mao"],"url":"https://arxiv.org/abs/2504.15784"}
{"created":"2025-04-23","title":"WALL-E 2.0: World Alignment by NeuroSymbolic Learning improves World Model-based LLM Agents","abstract":"Can we build accurate world models out of large language models (LLMs)? How can world models benefit LLM agents? The gap between the prior knowledge of LLMs and the specified environment's dynamics usually bottlenecks LLMs' performance as world models. To bridge the gap, we propose a training-free \"world alignment\" that learns an environment's symbolic knowledge complementary to LLMs. The symbolic knowledge covers action rules, knowledge graphs, and scene graphs, which are extracted by LLMs from exploration trajectories and encoded into executable codes to regulate LLM agents' policies. We further propose an RL-free, model-based agent \"WALL-E 2.0\" through the model-predictive control (MPC) framework. Unlike classical MPC requiring costly optimization on the fly, we adopt an LLM agent as an efficient look-ahead optimizer of future steps' actions by interacting with the neurosymbolic world model. While the LLM agent's strong heuristics make it an efficient planner in MPC, the quality of its planned actions is also secured by the accurate predictions of the aligned world model. They together considerably improve learning efficiency in a new environment. On open-world challenges in Mars (Minecraft like) and ALFWorld (embodied indoor environments), WALL-E 2.0 significantly outperforms existing methods, e.g., surpassing baselines in Mars by 16.1%-51.6% of success rate and by at least 61.7% in score. In ALFWorld, it achieves a new record 98% success rate after only 4 iterations.","authors":["Siyu Zhou","Tianyi Zhou","Yijun Yang","Guodong Long","Deheng Ye","Jing Jiang","Chengqi Zhang"],"url":"https://arxiv.org/abs/2504.15785"}
{"created":"2025-04-23","title":"Satellite to GroundScape -- Large-scale Consistent Ground View Generation from Satellite Views","abstract":"Generating consistent ground-view images from satellite imagery is challenging, primarily due to the large discrepancies in viewing angles and resolution between satellite and ground-level domains. Previous efforts mainly concentrated on single-view generation, often resulting in inconsistencies across neighboring ground views. In this work, we propose a novel cross-view synthesis approach designed to overcome these challenges by ensuring consistency across ground-view images generated from satellite views. Our method, based on a fixed latent diffusion model, introduces two conditioning modules: satellite-guided denoising, which extracts high-level scene layout to guide the denoising process, and satellite-temporal denoising, which captures camera motion to maintain consistency across multiple generated views. We further contribute a large-scale satellite-ground dataset containing over 100,000 perspective pairs to facilitate extensive ground scene or video generation. Experimental results demonstrate that our approach outperforms existing methods on perceptual and temporal metrics, achieving high photorealism and consistency in multi-view outputs.","authors":["Ningli Xu","Rongjun Qin"],"url":"https://arxiv.org/abs/2504.15786"}
{"created":"2025-04-23","title":"Crisp complexity of fuzzy classifiers","abstract":"Rule-based systems are a very popular form of explainable AI, particularly in the fuzzy community, where fuzzy rules are widely used for control and classification problems. However, fuzzy rule-based classifiers struggle to reach bigger traction outside of fuzzy venues, because users sometimes do not know about fuzzy and because fuzzy partitions are not so easy to interpret in some situations. In this work, we propose a methodology to reduce fuzzy rule-based classifiers to crisp rule-based classifiers. We study different possible crisp descriptions and implement an algorithm to obtain them. Also, we analyze the complexity of the resulting crisp classifiers. We believe that our results can help both fuzzy and non-fuzzy practitioners understand better the way in which fuzzy rule bases partition the feature space and how easily one system can be translated to another and vice versa. Our complexity metric can also help to choose between different fuzzy classifiers based on what the equivalent crisp partitions look like.","authors":["Raquel Fernandez-Peralta","Javier Fumanal-Idocin","Javier Andreu-Perez"],"url":"https://arxiv.org/abs/2504.15791"}
{"created":"2025-04-23","title":"Development and evaluation of a deep learning algorithm for German word recognition from lip movements","abstract":"When reading lips, many people benefit from additional visual information from the lip movements of the speaker, which is, however, very error prone. Algorithms for lip reading with artificial intelligence based on artificial neural networks significantly improve word recognition but are not available for the German language. A total of 1806 video clips with only one German-speaking person each were selected, split into word segments, and assigned to word classes using speech-recognition software. In 38,391 video segments with 32 speakers, 18 polysyllabic, visually distinguishable words were used to train and validate a neural network. The 3D Convolutional Neural Network and Gated Recurrent Units models and a combination of both models (GRUConv) were compared, as were different image sections and color spaces of the videos. The accuracy was determined in 5000 training epochs. Comparison of the color spaces did not reveal any relevant different correct classification rates in the range from 69% to 72%. With a cut to the lips, a significantly higher accuracy of 70% was achieved than when cut to the entire speaker's face (34%). With the GRUConv model, the maximum accuracies were 87% with known speakers and 63% in the validation with unknown speakers. The neural network for lip reading, which was first developed for the German language, shows a very high level of accuracy, comparable to English-language algorithms. It works with unknown speakers as well and can be generalized with more word classes.","authors":["Dinh Nam Pham","Torsten Rahne"],"url":"https://arxiv.org/abs/2504.15792"}
{"created":"2025-04-23","title":"A Point-Hyperplane Geometry Method for Operational Security Region of Renewable Energy Generation in Power Systems","abstract":"The rapid growth of renewable energy generation challenges the secure operation of power systems. It becomes crucial to quantify the critical security boundaries and hosting capability of renewable generation at the system operation level. This paper proposes a novel point-hyperplane geometry (PHG) method to accurately obtain the geometric expression of the operational security region of renewable energy generation for power systems. Firstly, the geometric expression of the operational security region is defined as a polytope of boundary hyperplanes in the form of inequalities satisfying the system operation constraints. Then, an orthogonal basis generation method is proposed to solve a single boundary hyperplane of the polytope based on intersecting and orthogonal geometric principles. Next, a point-hyperplane iteration algorithm is developed to progressively obtain the overall geometric polytope of the operational security region of renewable energy generation in power systems. Besides, the flexible performance trade-off can be achieved by modifying the proposed maximum tolerated angle between adjacent hyperplanes. Finally, comprehensive case studies verify the effectiveness and superiority of the PHG method.","authors":["Can Wan","Biao Li","Xuejun Hu","Yunyi Li","Ping Ju"],"url":"https://arxiv.org/abs/2504.15793"}
{"created":"2025-04-23","title":"Locating and Mitigating Gradient Conflicts in Point Cloud Domain Adaptation via Saliency Map Skewness","abstract":"Object classification models utilizing point cloud data are fundamental for 3D media understanding, yet they often struggle with unseen or out-of-distribution (OOD) scenarios. Existing point cloud unsupervised domain adaptation (UDA) methods typically employ a multi-task learning (MTL) framework that combines primary classification tasks with auxiliary self-supervision tasks to bridge the gap between cross-domain feature distributions. However, our further experiments demonstrate that not all gradients from self-supervision tasks are beneficial and some may negatively impact the classification performance. In this paper, we propose a novel solution, termed Saliency Map-based Data Sampling Block (SM-DSB), to mitigate these gradient conflicts. Specifically, our method designs a new scoring mechanism based on the skewness of 3D saliency maps to estimate gradient conflicts without requiring target labels. Leveraging this, we develop a sample selection strategy that dynamically filters out samples whose self-supervision gradients are not beneficial for the classification. Our approach is scalable, introducing modest computational overhead, and can be integrated into all the point cloud UDA MTL frameworks. Extensive evaluations demonstrate that our method outperforms state-of-the-art approaches. In addition, we provide a new perspective on understanding the UDA problem through back-propagation analysis.","authors":["Jiaqi Tang","Yinsong Xu","Qingchao Chen"],"url":"https://arxiv.org/abs/2504.15796"}
{"created":"2025-04-23","title":"Bridging Bond Beyond Life: Designing VR Memorial Space with Stakeholder Collaboration via Research through Design","abstract":"The integration of digital technologies into memorialization practices offers opportunities to transcend physical and temporal limitations. However, designing personalized memorial spaces that address the diverse needs of the dying and the bereaved remains underexplored. Using a Research through Design (RtD) approach, we conducted a three-phase study: participatory design, VR memorial space development, and user testing. This study highlights three key aspects: 1) the value of VR memorial spaces as bonding mediums, 2) the role of a design process that engages users through co-design, development, and user testing in addressing the needs of the dying and the bereaved, and 3) design elements that enhance the VR memorial experience. This research lays the foundation for personalized VR memorialization practices, providing insights into how technology can enrich remembrance and relational experiences.","authors":["Heejae Bae","Nayeong Kim","Sehee Lee","Tak Yeon Lee"],"url":"https://arxiv.org/abs/2504.15797"}
{"created":"2025-04-23","title":"FinDER: Financial Dataset for Question Answering and Evaluating Retrieval-Augmented Generation","abstract":"In the fast-paced financial domain, accurate and up-to-date information is critical to addressing ever-evolving market conditions. Retrieving this information correctly is essential in financial Question-Answering (QA), since many language models struggle with factual accuracy in this domain. We present FinDER, an expert-generated dataset tailored for Retrieval-Augmented Generation (RAG) in finance. Unlike existing QA datasets that provide predefined contexts and rely on relatively clear and straightforward queries, FinDER focuses on annotating search-relevant evidence by domain experts, offering 5,703 query-evidence-answer triplets derived from real-world financial inquiries. These queries frequently include abbreviations, acronyms, and concise expressions, capturing the brevity and ambiguity common in the realistic search behavior of professionals. By challenging models to retrieve relevant information from large corpora rather than relying on readily determined contexts, FinDER offers a more realistic benchmark for evaluating RAG systems. We further present a comprehensive evaluation of multiple state-of-the-art retrieval models and Large Language Models, showcasing challenges derived from a realistic benchmark to drive future research on truthful and precise RAG in the financial domain.","authors":["Chanyeol Choi","Jihoon Kwon","Jaeseon Ha","Hojun Choi","Chaewoon Kim","Yongjae Lee","Jy-yong Sohn","Alejandro Lopez-Lira"],"url":"https://arxiv.org/abs/2504.15800"}
{"created":"2025-04-23","title":"A closer look at how large language models trust humans: patterns and biases","abstract":"As large language models (LLMs) and LLM-based agents increasingly interact with humans in decision-making contexts, understanding the trust dynamics between humans and AI agents becomes a central concern. While considerable literature studies how humans trust AI agents, it is much less understood how LLM-based agents develop effective trust in humans. LLM-based agents likely rely on some sort of implicit effective trust in trust-related contexts (e.g., evaluating individual loan applications) to assist and affect decision making. Using established behavioral theories, we develop an approach that studies whether LLMs trust depends on the three major trustworthiness dimensions: competence, benevolence and integrity of the human subject. We also study how demographic variables affect effective trust. Across 43,200 simulated experiments, for five popular language models, across five different scenarios we find that LLM trust development shows an overall similarity to human trust development. We find that in most, but not all cases, LLM trust is strongly predicted by trustworthiness, and in some cases also biased by age, religion and gender, especially in financial scenarios. This is particularly true for scenarios common in the literature and for newer models. While the overall patterns align with human-like mechanisms of effective trust formation, different models exhibit variation in how they estimate trust; in some cases, trustworthiness and demographic factors are weak predictors of effective trust. These findings call for a better understanding of AI-to-human trust dynamics and monitoring of biases and trust development patterns to prevent unintended and potentially harmful outcomes in trust-sensitive applications of AI.","authors":["Valeria Lerman","Yaniv Dover"],"url":"https://arxiv.org/abs/2504.15801"}
{"created":"2025-04-23","title":"Finite time max-consensus for simultaneous target interception in switching graph topologies","abstract":"In this paper, we propose a distributed guidance law for the simultaneous interception of a stationary target. For a group of `n' heterogeneous pursuers, the proposed guidance law establishes the necessary conditions on static graphs that ensure simultaneous target interception, regardless of the initial conditions of the pursuers. Building on these results, we also establish the necessary conditions for achieving simultaneous interception in switching graph topologies as well. The major highlight of the work is that the target interception occurs in finite time for both static and switching graph topologies. We demonstrate all of these results through numerical simulations.","authors":["Kushal P. Singh","Aditya K. Rao","Twinkle Tripathy"],"url":"https://arxiv.org/abs/2504.15803"}
{"created":"2025-04-23","title":"Insights from Verification: Training a Verilog Generation LLM with Reinforcement Learning with Testbench Feedback","abstract":"Large language models (LLMs) have shown strong performance in Verilog generation from natural language description. However, ensuring the functional correctness of the generated code remains a significant challenge. This paper introduces a method that integrates verification insights from testbench into the training of Verilog generation LLMs, aligning the training with the fundamental goal of hardware design: functional correctness. The main obstacle in using LLMs for Verilog code generation is the lack of sufficient functional verification data, particularly testbenches paired with design specifications and code. To address this problem, we introduce an automatic testbench generation pipeline that decomposes the process and uses feedback from the Verilog compiler simulator (VCS) to reduce hallucination and ensure correctness. We then use the testbench to evaluate the generated codes and collect them for further training, where verification insights are introduced. Our method applies reinforcement learning (RL), specifically direct preference optimization (DPO), to align Verilog code generation with functional correctness by training preference pairs based on testbench outcomes. In evaluations on VerilogEval-Machine, VerilogEval-Human, RTLLM v1.1, RTLLM v2, and VerilogEval v2, our approach consistently outperforms state-of-the-art baselines in generating functionally correct Verilog code. We open source all training code, data, and models at https://anonymous.4open.science/r/VeriPrefer-E88B.","authors":["Ning Wang","Bingkun Yao","Jie Zhou","Yuchen Hu","Xi Wang","Nan Guan","Zhe Jiang"],"url":"https://arxiv.org/abs/2504.15804"}
{"created":"2025-04-23","title":"No-Regret Model Predictive Control with Online Learning of Koopman Operators","abstract":"We study a problem of simultaneous system identification and model predictive control of nonlinear systems. Particularly, we provide an algorithm for systems with unknown residual dynamics that can be expressed by Koopman operators. Such residual dynamics can model external disturbances and modeling errors, such as wind and wave disturbances to aerial and marine vehicles, or inaccurate model parameters. The algorithm has finite-time near-optimality guarantees and asymptotically converges to the optimal non-causal controller. Specifically, the algorithm enjoys sublinear \\textit{dynamic regret}, defined herein as the suboptimality against an optimal clairvoyant controller that knows how the unknown dynamics will adapt to its states and actions. To this end, we assume the algorithm is given Koopman observable functions such that the unknown dynamics can be approximated by a linear dynamical system. Then, it employs model predictive control based on the current learned model of the unknown residual dynamics. This model is updated online using least squares in a self-supervised manner based on the data collected while controlling the system. We validate our algorithm in physics-based simulations of a cart-pole system aiming to maintain the pole upright despite inaccurate model parameters.","authors":["Hongyu Zhou","Vasileios Tzoumas"],"url":"https://arxiv.org/abs/2504.15805"}
{"created":"2025-04-23","title":"DAE-KAN: A Kolmogorov-Arnold Network Model for High-Index Differential-Algebraic Equations","abstract":"Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to Multi-Layer Perceptrons (MLPs) due to their superior function-fitting abilities in data-driven modeling. In this paper, we propose a novel framework, DAE-KAN, for solving high-index differential-algebraic equations (DAEs) by integrating KANs with Physics-Informed Neural Networks (PINNs). This framework not only preserves the ability of traditional PINNs to model complex systems governed by physical laws but also enhances their performance by leveraging the function-fitting strengths of KANs. Numerical experiments demonstrate that for DAE systems ranging from index-1 to index-3, DAE-KAN reduces the absolute errors of both differential and algebraic variables by 1 to 2 orders of magnitude compared to traditional PINNs. To assess the effectiveness of this approach, we analyze the drift-off error and find that both PINNs and DAE-KAN outperform classical numerical methods in controlling this phenomenon. Our results highlight the potential of neural network methods, particularly DAE-KAN, in solving high-index DAEs with substantial computational accuracy and generalization, offering a promising solution for challenging partial differential-algebraic equations.","authors":["Kai Luo","Juan Tang","Mingchao Cai","Xiaoqing Zeng","Manqi Xie","Ming Yan"],"url":"https://arxiv.org/abs/2504.15806"}
{"created":"2025-04-23","title":"Multilevel lattice-based kernel approximation for elliptic PDEs with random coefficients","abstract":"This paper introduces a multilevel kernel-based approximation method to estimate efficiently solutions to elliptic partial differential equations (PDEs) with periodic random coefficients. Building upon the work of Kaarnioja, Kazashi, Kuo, Nobile, Sloan (Numer. Math., 2022) on kernel interpolation with quasi-Monte Carlo (QMC) lattice point sets, we leverage multilevel techniques to enhance computational efficiency while maintaining a given level of accuracy. In the function space setting with product-type weight parameters, the single-level approximation can achieve an accuracy of $\\varepsilon>0$ with cost $\\mathcal{O}(\\varepsilon^{-\\eta-\\nu-\\theta})$ for positive constants $\\eta, \\nu, \\theta $ depending on the rates of convergence associated with dimension truncation, kernel approximation, and finite element approximation, respectively. Our multilevel approximation can achieve the same $\\varepsilon$ accuracy at a reduced cost $\\mathcal{O}(\\varepsilon^{-\\eta-\\max(\\nu,\\theta)})$. Full regularity theory and error analysis are provided, followed by numerical experiments that validate the efficacy of the proposed multilevel approximation in comparison to the single-level approach.","authors":["Alexander D. Gilbert","Michael B. Giles","Frances Y. Kuo","Ian H. Sloan","Abirami Srikumar"],"url":"https://arxiv.org/abs/2504.15810"}
{"created":"2025-04-23","title":"Fusing Reward and Dueling Feedback in Stochastic Bandits","abstract":"This paper investigates the fusion of absolute (reward) and relative (dueling) feedback in stochastic bandits, where both feedback types are gathered in each decision round. We derive a regret lower bound, demonstrating that an efficient algorithm may incur only the smaller among the reward and dueling-based regret for each individual arm. We propose two fusion approaches: (1) a simple elimination fusion algorithm that leverages both feedback types to explore all arms and unifies collected information by sharing a common candidate arm set, and (2) a decomposition fusion algorithm that selects the more effective feedback to explore the corresponding arms and randomly assigns one feedback type for exploration and the other for exploitation in each round. The elimination fusion experiences a suboptimal multiplicative term of the number of arms in regret due to the intrinsic suboptimality of dueling elimination. In contrast, the decomposition fusion achieves regret matching the lower bound up to a constant under a common assumption. Extensive experiments confirm the efficacy of our algorithms and theoretical results.","authors":["Xuchuang Wang","Qirun Zeng","Jinhang Zuo","Xutong Liu","Mohammad Hajiesmaili","John C. S. Lui","Adam Wierman"],"url":"https://arxiv.org/abs/2504.15812"}
{"created":"2025-04-23","title":"Fast Higher-Order Interpolation and Restriction in ExaHyPE Avoiding Non-physical Reflections","abstract":"Wave equations help us to understand phenomena ranging from earthquakes to tsunamis. These phenomena materialise over very large scales. It would be computationally infeasible to track them over a regular mesh. Yet, since the phenomena are localised, adaptive mesh refinement (AMR) can be used to construct meshes with a higher resolution close to the regions of interest. ExaHyPE is a software engine created to solve wave problems using AMR, and we use it as baseline to construct our numerical relativity application called ExaGRyPE. To advance the mesh in time, we have to interpolate and restrict along resolution transitions in each and every time step. ExaHyPE's vanilla code version uses a d-linear tensor-product approach. In benchmarks of a stationary black hole this performs slowly and leads to errors in conserved quantities near AMR boundaries. We therefore introduce a set of higher-order interpolation schemes where the derivatives are calculated at each coarse grid cell to approximate the enclosed fine cells. The resulting methods run faster than the tensor-product approach. Most importantly, when running the stationary black hole simulation using the higher order methods the errors near the AMR boundaries are removed.","authors":["Timothy Stokes","Tobias Weinzierl","Han Zhang","Baojiu Li"],"url":"https://arxiv.org/abs/2504.15814"}
{"created":"2025-04-23","title":"What's the Difference? Supporting Users in Identifying the Effects of Prompt and Model Changes Through Token Patterns","abstract":"Prompt engineering for large language models is challenging, as even small prompt perturbations or model changes can significantly impact the generated output texts. Existing evaluation methods, either automated metrics or human evaluation, have limitations, such as providing limited insights or being labor-intensive. We propose Spotlight, a new approach that combines both automation and human analysis. Based on data mining techniques, we automatically distinguish between random (decoding) variations and systematic differences in language model outputs. This process provides token patterns that describe the systematic differences and guide the user in manually analyzing the effects of their prompt and model changes efficiently. We create three benchmarks to quantitatively test the reliability of token pattern extraction methods and demonstrate that our approach provides new insights into established prompt data. From a human-centric perspective, through demonstration studies and a user study, we show that our token pattern approach helps users understand the systematic differences of language model outputs, and we are able to discover relevant differences caused by prompt and model changes (e.g. related to gender or culture), thus supporting the prompt engineering process and human-centric model behavior research.","authors":["Michael A. Hedderich","Anyi Wang","Raoyuan Zhao","Florian Eichin","Barbara Plank"],"url":"https://arxiv.org/abs/2504.15815"}
{"created":"2025-04-23","title":"Toward optimal-scaling DFT: stochastic Hartree theory in the thermodynamic and complete basis set limits at arbitrary temperature","abstract":"We present the first mathematical analysis of stochastic density functional theory (DFT) in the context of the Hartree approximation. We motivate our analysis via the notion of nearly-optimal or $\\tilde{O}(n)$ scaling with respect to the number $n$ of computational degrees of freedom, independent of the number of electrons, in both the thermodynamic and complete basis set limits. Indeed, the promise of such scaling is the primary motivation for stochastic DFT relative to conventional orbital-based approaches, as well as deterministic orbital-free alternatives. We highlight three key targets for mathematical attention, which are synthesized in our algorithm and analysis. First, we identify a particular stochastic estimator for the Hartree potential whose sample complexity is essentially independent of the discretization size. Second, we reformulate the self-consistent field iteration as a stochastic mirror descent method where the Fermi-Dirac entropy plays the role of the Bregman potential, and we prove a nearly discretization-independent bound on the number of iterations needed to reach fixed accuracy. Third, motivated by the estimator, we introduce a novel pole expansion scheme for the square-root Fermi-Dirac operator, preserving $\\tilde{O}(n)$ cost per mirror descent iteration even in the complete basis set limit. Combining these ingredients, we establish nearly-optimal scaling in both limits of interest under reasonable assumptions on the basis sets chosen for discretization. Extensive numerical experiments on problems with as many as $10^{6}$ degrees of freedom validate our algorithm and support the theory of nearly-optimal scaling.","authors":["Yuhang Cai","Michael Lindsey"],"url":"https://arxiv.org/abs/2504.15816"}
{"created":"2025-04-23","title":"EFFACT: A Highly Efficient Full-Stack FHE Acceleration Platform","abstract":"Fully Homomorphic Encryption (FHE) is a set of powerful cryptographic schemes that allows computation to be performed directly on encrypted data with an unlimited depth. Despite FHE's promising in privacy-preserving computing, yet in most FHE schemes, ciphertext generally blows up thousands of times compared to the original message, and the massive amount of data load from off-chip memory for bootstrapping and privacy-preserving machine learning applications (such as HELR, ResNet-20), both degrade the performance of FHE-based computation. Several hardware designs have been proposed to address this issue, however, most of them require enormous resources and power. An acceleration platform with easy programmability, high efficiency, and low overhead is a prerequisite for practical application.","authors":["Yi Huang","Xinsheng Gong","Xiangyu Kong","Dibei Chen","Jianfeng Zhu","Wenping Zhu","Liangwei Li","Mingyu Gao","Shaojun Wei","Aoyang Zhang","Leibo Liu"],"url":"https://arxiv.org/abs/2504.15817"}
{"created":"2025-04-23","title":"Quantifying Source Speaker Leakage in One-to-One Voice Conversion","abstract":"Using a multi-accented corpus of parallel utterances for use with commercial speech devices, we present a case study to show that it is possible to quantify a degree of confidence about a source speaker's identity in the case of one-to-one voice conversion. Following voice conversion using a HiFi-GAN vocoder, we compare information leakage for a range speaker characteristics; assuming a \"worst-case\" white-box scenario, we quantify our confidence to perform inference and narrow the pool of likely source speakers, reinforcing the regulatory obligation and moral duty that providers of synthetic voices have to ensure the privacy of their speakers' data.","authors":["Scott Wellington","Xuechen Liu","Junichi Yamagishi"],"url":"https://arxiv.org/abs/2504.15822"}
{"created":"2025-04-23","title":"Human-Imperceptible Physical Adversarial Attack for NIR Face Recognition Models","abstract":"Near-infrared (NIR) face recognition systems, which can operate effectively in low-light conditions or in the presence of makeup, exhibit vulnerabilities when subjected to physical adversarial attacks. To further demonstrate the potential risks in real-world applications, we design a novel, stealthy, and practical adversarial patch to attack NIR face recognition systems in a black-box setting. We achieved this by utilizing human-imperceptible infrared-absorbing ink to generate multiple patches with digitally optimized shapes and positions for infrared images. To address the optimization mismatch between digital and real-world NIR imaging, we develop a light reflection model for human skin to minimize pixel-level discrepancies by simulating NIR light reflection.","authors":["Songyan Xie","Jinghang Wen","Encheng Su","Qiucheng Yu"],"url":"https://arxiv.org/abs/2504.15823"}
{"created":"2025-04-23","title":"DualOptim: Enhancing Efficacy and Stability in Machine Unlearning with Dual Optimizers","abstract":"Existing machine unlearning (MU) approaches exhibit significant sensitivity to hyperparameters, requiring meticulous tuning that limits practical deployment. In this work, we first empirically demonstrate the instability and suboptimal performance of existing popular MU methods when deployed in different scenarios. To address this issue, we propose Dual Optimizer (DualOptim), which incorporates adaptive learning rate and decoupled momentum factors. Empirical and theoretical evidence demonstrates that DualOptim contributes to effective and stable unlearning. Through extensive experiments, we show that DualOptim can significantly boost MU efficacy and stability across diverse tasks, including image classification, image generation, and large language models, making it a versatile approach to empower existing MU algorithms.","authors":["Xuyang Zhong","Haochen Luo","Chen Liu"],"url":"https://arxiv.org/abs/2504.15827"}
{"created":"2025-04-23","title":"Circularity and repetitiveness in non-injective DF0L systems","abstract":"We study circularity in DF0L systems, a generalization of D0L systems. We focus on two different types of circularity, called weak and strong circularity. When the morphism is injective on the language of the system, the two notions are equivalent, but they may differ otherwise. Our main result shows that failure of weak circularity implies unbounded repetitiveness, and that unbounded repetitiveness implies failure of strong circularity. This extends previous work by the second and third authors for injective systems. To help motivate this work, we also give examples of non-injective but strongly circular systems.","authors":["Herman Goulet-Ouellet","Karel Klouda","\\v{S}t\\v{e}p\\'an Starosta"],"url":"https://arxiv.org/abs/2504.15828"}
{"created":"2025-04-23","title":"Generative AI for Research Data Processing: Lessons Learnt From Three Use Cases","abstract":"There has been enormous interest in generative AI since ChatGPT was launched in 2022. However, there are concerns about the accuracy and consistency of the outputs of generative AI. We have carried out an exploratory study on the application of this new technology in research data processing. We identified tasks for which rule-based or traditional machine learning approaches were difficult to apply, and then performed these tasks using generative AI.","authors":["Modhurita Mitra","Martine G. de Vos","Nicola Cortinovis","Dawa Ometto"],"url":"https://arxiv.org/abs/2504.15829"}
{"created":"2025-04-23","title":"Predictive Synthesis of Control Barrier Functions and its Application to Time-Varying Constraints","abstract":"This paper presents a systematic method for synthesizing a Control Barrier Function (CBF) that encodes predictive information into a CBF. Unlike other methods, the synthesized CBF can account for changes and time-variations in the constraints even when constructed for time-invariant constraints. This avoids recomputing the CBF when the constraint specifications change. The method provides an explicit characterization of the extended class K function {\\alpha} that determines the dynamic properties of the CBF, and {\\alpha} can even be explicitly chosen as a design parameter in the controller synthesis. The resulting CBF further accounts for input constraints, and its values can be determined at any point without having to compute the CBF over the entire domain. The synthesis method is based on a finite horizon optimal control problem inspired by Hamilton-Jacobi reachability analysis and does not rely on a nominal control law. The synthesized CBF is time-invariant if the constraints are. The method poses mild assumptions on the controllability of the dynamic system and assumes the knowledge of at least a subset of some control invariant set. The paper provides a detailed analysis of the properties of the synthesized CBF, including its application to time-varying constraints. A simulation study applies the proposed approach to various dynamic systems in the presence of time-varying constraints. The paper is accompanied by an online available parallelized implementation of the proposed synthesis method.","authors":["Adrian Wiltz","Dimos V. Dimarogonas"],"url":"https://arxiv.org/abs/2504.15830"}
{"created":"2025-04-23","title":"Text-based Animatable 3D Avatars with Morphable Model Alignment","abstract":"The generation of high-quality, animatable 3D head avatars from text has enormous potential in content creation applications such as games, movies, and embodied virtual assistants. Current text-to-3D generation methods typically combine parametric head models with 2D diffusion models using score distillation sampling to produce 3D-consistent results. However, they struggle to synthesize realistic details and suffer from misalignments between the appearance and the driving parametric model, resulting in unnatural animation results. We discovered that these limitations stem from ambiguities in the 2D diffusion predictions during 3D avatar distillation, specifically: i) the avatar's appearance and geometry is underconstrained by the text input, and ii) the semantic alignment between the predictions and the parametric head model is insufficient because the diffusion model alone cannot incorporate information from the parametric model. In this work, we propose a novel framework, AnimPortrait3D, for text-based realistic animatable 3DGS avatar generation with morphable model alignment, and introduce two key strategies to address these challenges. First, we tackle appearance and geometry ambiguities by utilizing prior information from a pretrained text-to-3D model to initialize a 3D avatar with robust appearance, geometry, and rigging relationships to the morphable model. Second, we refine the initial 3D avatar for dynamic expressions using a ControlNet that is conditioned on semantic and normal maps of the morphable model to ensure accurate alignment. As a result, our method outperforms existing approaches in terms of synthesis quality, alignment, and animation fidelity. Our experiments show that the proposed method advances the state of the art in text-based, animatable 3D head avatar generation.","authors":["Yiqian Wu","Malte Prinzler","Xiaogang Jin","Siyu Tang"],"url":"https://arxiv.org/abs/2504.15835"}
{"created":"2025-04-23","title":"Gaussian behaviors: representations and data-driven control","abstract":"We propose a modeling framework for stochastic systems based on Gaussian processes. Finite-length trajectories of the system are modeled as random vectors from a Gaussian distribution, which we call a Gaussian behavior. The proposed model naturally quantifies the uncertainty in the trajectories, yet it is simple enough to allow for tractable formulations. We relate the proposed model to existing descriptions of dynamical systems including deterministic and stochastic behaviors, and linear time-invariant (LTI) state-space models with Gaussian process and measurement noise. Gaussian behaviors can be estimated directly from observed data as the empirical sample covariance under the assumption that the measured trajectories are from independent experiments. The distribution of future outputs conditioned on inputs and past outputs provides a predictive model that can be incorporated in predictive control frameworks. We show that subspace predictive control (SPC) is a certainty-equivalence control formulation with the estimated Gaussian behavior. Furthermore, the regularized data-enabled predictive control (DeePC) method is shown to be a distributionally optimistic formulation that optimistically accounts for uncertainty in the Gaussian behavior. To mitigate the excessive optimism of DeePC, we propose a novel distributionally robust control formulation, and provide a convex reformulation allowing for efficient implementation.","authors":["Andr\\'as Sasfi","Ivan Markovsky","Alberto Padoan","Florian D\\\"orfler"],"url":"https://arxiv.org/abs/2504.15838"}
{"created":"2025-04-23","title":"Pre-DPO: Improving Data Utilization in Direct Preference Optimization Using a Guiding Reference Model","abstract":"Direct Preference Optimization (DPO) simplifies reinforcement learning from human feedback (RLHF) for large language models (LLMs) by directly optimizing human preferences without an explicit reward model. We find that during DPO training, the reference model plays the role of a data weight adjuster. However, the common practice of initializing the policy and reference models identically in DPO can lead to inefficient data utilization and impose a performance ceiling. Meanwhile, the lack of a reference model in Simple Preference Optimization (SimPO) reduces training robustness and necessitates stricter conditions to prevent catastrophic forgetting. In this work, we propose Pre-DPO, a simple yet effective DPO-based training paradigm that enhances preference optimization performance by leveraging a guiding reference model. This reference model provides foresight into the optimal policy state achievable through the training preference data, serving as a guiding mechanism that adaptively assigns higher weights to samples more suitable for the model and lower weights to those less suitable. Extensive experiments on AlpacaEval 2.0 and Arena-Hard v0.1 benchmarks demonstrate that Pre-DPO consistently improves the performance of both DPO and SimPO, without relying on external models or additional data.","authors":["Junshu Pan","Wei Shen","Shulin Huang","Qiji Zhou","Yue Zhang"],"url":"https://arxiv.org/abs/2504.15843"}
{"created":"2025-04-23","title":"Sound and Complete Invariant-Based Heap Encodings (Technical Report)","abstract":"Verification of programs operating on mutable, heap-allocated data structures poses significant challenges due to potentially unbounded structures like linked lists and trees. In this paper, we present a novel relational heap encoding leveraging uninterpreted predicates and prophecy variables, reducing heap verification tasks to satisfiability checks over integers in constrained Horn clauses (CHCs). To the best of our knowledge, our approach is the first invariant-based method that achieves both soundness and completeness for heap-manipulating programs. We provide formal proofs establishing the correctness of our encodings. Through an experimental evaluation we demonstrate that our method significantly extends the capability of existing CHC-based verification tools, allowing automatic verification of programs with heap previously unreachable by state-of-the-art tools.","authors":["Zafer Esen","Philipp R\\\"ummer","Tjark Weber"],"url":"https://arxiv.org/abs/2504.15844"}
{"created":"2025-04-23","title":"Contrasting Deadlock-Free Session Processes (Extended Version)","abstract":"Deadlock freedom is a crucial property for message-passing programs. Over the years, several different type systems for concurrent processes that ensure deadlock freedom have been proposed; this diversity raises the question of how they compare. This paper addresses this question, considering two type systems not covered in prior work: Kokke et al.'s HCP, a type system based on a linear logic with hypersequents, and Padovani's priority-based type system for asynchronous processes, dubbed P. Their distinctive features make formal comparisons relevant and challenging. Our findings are two-fold: (1) the hypersequent setting does not drastically change the class of deadlock-free processes induced by linear logic, and (2) we precisely relate the classes of deadlock-free processes induced by HCP and P. We also prove that our results hold in an asynchronous setting. Our results provide new insights into the essential mechanisms involved in statically avoiding deadlocks in concurrency.","authors":["Juan C. Jaramillo","Jorge A. P\\'erez"],"url":"https://arxiv.org/abs/2504.15845"}
{"created":"2025-04-23","title":"Adaptive PCA-Based Outlier Detection for Multi-Feature Time Series in Space Missions","abstract":"Analyzing multi-featured time series data is critical for space missions making efficient event detection, potentially onboard, essential for automatic analysis. However, limited onboard computational resources and data downlink constraints necessitate robust methods for identifying regions of interest in real time. This work presents an adaptive outlier detection algorithm based on the reconstruction error of Principal Component Analysis (PCA) for feature reduction, designed explicitly for space mission applications. The algorithm adapts dynamically to evolving data distributions by using Incremental PCA, enabling deployment without a predefined model for all possible conditions. A pre-scaling process normalizes each feature's magnitude while preserving relative variance within feature types. We demonstrate the algorithm's effectiveness in detecting space plasma events, such as distinct space environments, dayside and nightside transients phenomena, and transition layers through NASA's MMS mission observations. Additionally, we apply the method to NASA's THEMIS data, successfully identifying a dayside transient using onboard-available measurements.","authors":["Jonah Ekelund","Savvas Raptis","Vicki Toy-Edens","Wenli Mo","Drew L. Turner","Ian J. Cohen","Stefano Markidis"],"url":"https://arxiv.org/abs/2504.15846"}
{"created":"2025-04-23","title":"CARE: Compatibility-Aware Incentive Mechanisms for Federated Learning with Budgeted Requesters","abstract":"Federated learning (FL) is a promising approach that allows requesters (\\eg, servers) to obtain local training models from workers (e.g., clients). Since workers are typically unwilling to provide training services/models freely and voluntarily, many incentive mechanisms in FL are designed to incentivize participation by offering monetary rewards from requesters. However, existing studies neglect two crucial aspects of real-world FL scenarios. First, workers can possess inherent incompatibility characteristics (e.g., communication channels and data sources), which can lead to degradation of FL efficiency (e.g., low communication efficiency and poor model generalization). Second, the requesters are budgeted, which limits the amount of workers they can hire for their tasks. In this paper, we investigate the scenario in FL where multiple budgeted requesters seek training services from incompatible workers with private training costs. We consider two settings: the cooperative budget setting where requesters cooperate to pool their budgets to improve their overall utility and the non-cooperative budget setting where each requester optimizes their utility within their own budgets. To address efficiency degradation caused by worker incompatibility, we develop novel compatibility-aware incentive mechanisms, CARE-CO and CARE-NO, for both settings to elicit true private costs and determine workers to hire for requesters and their rewards while satisfying requester budget constraints. Our mechanisms guarantee individual rationality, truthfulness, budget feasibility, and approximation performance. We conduct extensive experiments using real-world datasets to show that the proposed mechanisms significantly outperform existing baselines.","authors":["Xiang Liu","Hau Chan","Minming Li","Xianlong Zeng","Chenchen Fu","Weiwei Wu"],"url":"https://arxiv.org/abs/2504.15847"}
{"created":"2025-04-23","title":"Exploring Cognitive and Aesthetic Causality for Multimodal Aspect-Based Sentiment Analysis","abstract":"Multimodal aspect-based sentiment classification (MASC) is an emerging task due to an increase in user-generated multimodal content on social platforms, aimed at predicting sentiment polarity toward specific aspect targets (i.e., entities or attributes explicitly mentioned in text-image pairs). Despite extensive efforts and significant achievements in existing MASC, substantial gaps remain in understanding fine-grained visual content and the cognitive rationales derived from semantic content and impressions (cognitive interpretations of emotions evoked by image content). In this study, we present Chimera: a cognitive and aesthetic sentiment causality understanding framework to derive fine-grained holistic features of aspects and infer the fundamental drivers of sentiment expression from both semantic perspectives and affective-cognitive resonance (the synergistic effect between emotional responses and cognitive interpretations). Specifically, this framework first incorporates visual patch features for patch-word alignment. Meanwhile, it extracts coarse-grained visual features (e.g., overall image representation) and fine-grained visual regions (e.g., aspect-related regions) and translates them into corresponding textual descriptions (e.g., facial, aesthetic). Finally, we leverage the sentimental causes and impressions generated by a large language model (LLM) to enhance the model's awareness of sentimental cues evoked by semantic content and affective-cognitive resonance. Experimental results on standard MASC datasets demonstrate the effectiveness of the proposed model, which also exhibits greater flexibility to MASC compared to LLMs such as GPT-4o. We have publicly released the complete implementation and dataset at https://github.com/Xillv/Chimera","authors":["Luwei Xiao","Rui Mao","Shuai Zhao","Qika Lin","Yanhao Jia","Liang He","Erik Cambria"],"url":"https://arxiv.org/abs/2504.15848"}
{"created":"2025-04-23","title":"NLCTables: A Dataset for Marrying Natural Language Conditions with Table Discovery","abstract":"With the growing abundance of repositories containing tabular data, discovering relevant tables for in-depth analysis remains a challenging task. Existing table discovery methods primarily retrieve desired tables based on a query table or several vague keywords, leaving users to manually filter large result sets. To address this limitation, we propose a new task: NL-conditional table discovery (nlcTD), where users combine a query table with natural language (NL) requirements to refine search results. To advance research in this area, we present nlcTables, a comprehensive benchmark dataset comprising 627 diverse queries spanning NL-only, union, join, and fuzzy conditions, 22,080 candidate tables, and 21,200 relevance annotations. Our evaluation of six state-of-the-art table discovery methods on nlcTables reveals substantial performance gaps, highlighting the need for advanced techniques to tackle this challenging nlcTD scenario. The dataset, construction framework, and baseline implementations are publicly available at https://github.com/SuDIS-ZJU/nlcTables to foster future research.","authors":["Lingxi Cui","Huan Li","Ke Chen","Lidan Shou","Gang Chen"],"url":"https://arxiv.org/abs/2504.15849"}
{"created":"2025-04-23","title":"Embedded Safe Reactive Navigation for Multirotors Systems using Control Barrier Functions","abstract":"Aiming to promote the wide adoption of safety filters for autonomous aerial robots, this paper presents a safe control architecture designed for seamless integration into widely used open-source autopilots. Departing from methods that require consistent localization and mapping, we formalize the obstacle avoidance problem as a composite control barrier function constructed only from the online onboard range measurements. The proposed framework acts as a safety filter, modifying the acceleration references derived by the nominal position/velocity control loops, and is integrated into the PX4 autopilot stack. Experimental studies using a small multirotor aerial robot demonstrate the effectiveness and performance of the solution within dynamic maneuvering and unknown environments.","authors":["Nazar Misyats","Marvin Harms","Morten Nissov","Martin Jacquet","Kostas Alexis"],"url":"https://arxiv.org/abs/2504.15850"}
{"created":"2025-04-23","title":"Consistent Causal Inference of Group Effects in Non-Targeted Trials with Finitely Many Effect Levels","abstract":"A treatment may be appropriate for some group (the ``sick\" group) on whom it has a positive effect, but it can also have a detrimental effect on subjects from another group (the ``healthy\" group). In a non-targeted trial both sick and healthy subjects may be treated, producing heterogeneous effects within the treated group. Inferring the correct treatment effect on the sick population is then difficult, because the effects on the different groups get tangled. We propose an efficient nonparametric approach to estimating the group effects, called {\\bf PCM} (pre-cluster and merge). We prove its asymptotic consistency in a general setting and show, on synthetic data, more than a 10x improvement in accuracy over existing state-of-the-art. Our approach applies more generally to consistent estimation of functions with a finite range.","authors":["Georgios Mavroudeas","Malik Magdon-Ismail","Kristin P. Bennett","Jason Kuruzovich"],"url":"https://arxiv.org/abs/2504.15854"}
{"created":"2025-04-23","title":"FailLite: Failure-Resilient Model Serving for Resource-Constrained Edge Environments","abstract":"Model serving systems have become popular for deploying deep learning models for various latency-sensitive inference tasks. While traditional replication-based methods have been used for failure-resilient model serving in the cloud, such methods are often infeasible in edge environments due to significant resource constraints that preclude full replication. To address this problem, this paper presents FailLite, a failure-resilient model serving system that employs (i) a heterogeneous replication where failover models are smaller variants of the original model, (ii) an intelligent approach that uses warm replicas to ensure quick failover for critical applications while using cold replicas, and (iii) progressive failover to provide low mean time to recovery (MTTR) for the remaining applications. We implement a full prototype of our system and demonstrate its efficacy on an experimental edge testbed. Our results using 27 models show that FailLite can recover all failed applications with 175.5ms MTTR and only a 0.6% reduction in accuracy.","authors":["Li Wu","Walid A. Hanafy","Tarek Abdelzaher","David Irwin","Jesse Milzman","Prashant Shenoy"],"url":"https://arxiv.org/abs/2504.15856"}
{"created":"2025-04-23","title":"The 2nd MERCADO Workshop at IEEE VIS 2025: Multimodal Experiences for Remote Communication Around Data Online","abstract":"We propose a half-day workshop at IEEE VIS 2025 on addressing the emerging challenges in data-rich multimodal remote collaboration. We focus on synchronous, remote, and hybrid settings where people take part in tasks such as data analysis, decision-making, and presentation. With this workshop, we continue successful prior work from the first MERCADO workshop at VIS 2023 and a 2024 Shonan Seminar that followed. Based on the findings of the earlier events, we invite research and ideas related to four themes of challenges: Tools & Technologies, Individual Differences & Interpersonal Dynamics, AI-assisted Collaboration, and Evaluation. With this workshop, we aim to broaden the community, foster new collaborations, and develop a research agenda to address these challenges in future research. Our planned workshop format is comprised of a keynote, short presentations, a breakout group session, and discussions organized around the identified challenges.","authors":["Wolfgang B\\\"uschel","Gabriela Molina Le\\'on","Arnaud Prouzeau","Mahmood Jasim","Christophe Hurter","Maxime Cordeil","Matthew Brehmer"],"url":"https://arxiv.org/abs/2504.15859"}
{"created":"2025-04-23","title":"DERD-Net: Learning Depth from Event-based Ray Densities","abstract":"Event cameras offer a promising avenue for multi-view stereo depth estimation and Simultaneous Localization And Mapping (SLAM) due to their ability to detect blur-free 3D edges at high-speed and over broad illumination conditions. However, traditional deep learning frameworks designed for conventional cameras struggle with the asynchronous, stream-like nature of event data, as their architectures are optimized for discrete, image-like inputs. We propose a scalable, flexible and adaptable framework for pixel-wise depth estimation with event cameras in both monocular and stereo setups. The 3D scene structure is encoded into disparity space images (DSIs), representing spatial densities of rays obtained by back-projecting events into space via known camera poses. Our neural network processes local subregions of the DSIs combining 3D convolutions and a recurrent structure to recognize valuable patterns for depth prediction. Local processing enables fast inference with full parallelization and ensures constant ultra-low model complexity and memory costs, regardless of camera resolution. Experiments on standard benchmarks (MVSEC and DSEC datasets) demonstrate unprecedented effectiveness: (i) using purely monocular data, our method achieves comparable results to existing stereo methods; (ii) when applied to stereo data, it strongly outperforms all state-of-the-art (SOTA) approaches, reducing the mean absolute error by at least 42%; (iii) our method also allows for increases in depth completeness by more than 3-fold while still yielding a reduction in median absolute error of at least 30%. Given its remarkable performance and effective processing of event-data, our framework holds strong potential to become a standard approach for using deep learning for event-based depth estimation and SLAM. Project page: https://github.com/tub-rip/DERD-Net","authors":["Diego de Oliveira Hitzges","Suman Ghosh","Guillermo Gallego"],"url":"https://arxiv.org/abs/2504.15863"}
{"created":"2025-04-23","title":"MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search","abstract":"Deep learning (DL) has achieved remarkable progress in the field of medical imaging. However, adapting DL models to medical tasks remains a significant challenge, primarily due to two key factors: (1) architecture selection, as different tasks necessitate specialized model designs, and (2) weight initialization, which directly impacts the convergence speed and final performance of the models. Although transfer learning from ImageNet is a widely adopted strategy, its effectiveness is constrained by the substantial differences between natural and medical images. To address these challenges, we introduce Medical Neural Network Search (MedNNS), the first Neural Network Search framework for medical imaging applications. MedNNS jointly optimizes architecture selection and weight initialization by constructing a meta-space that encodes datasets and models based on how well they perform together. We build this space using a Supernetwork-based approach, expanding the model zoo size by 51x times over previous state-of-the-art (SOTA) methods. Moreover, we introduce rank loss and Fr\\'echet Inception Distance (FID) loss into the construction of the space to capture inter-model and inter-dataset relationships, thereby achieving more accurate alignment in the meta-space. Experimental results across multiple datasets demonstrate that MedNNS significantly outperforms both ImageNet pre-trained DL models and SOTA Neural Architecture Search (NAS) methods, achieving an average accuracy improvement of 1.7% across datasets while converging substantially faster. The code and the processed meta-space is available at https://github.com/BioMedIA-MBZUAI/MedNNS.","authors":["Lotfi Abdelkrim Mecharbat","Ibrahim Elmakky","Martin Takac","Mohammed Yaqub"],"url":"https://arxiv.org/abs/2504.15865"}
{"created":"2025-04-23","title":"Inducing Vulnerable Code Generation in LLM Coding Assistants","abstract":"Due to insufficient domain knowledge, LLM coding assistants often reference related solutions from the Internet to address programming problems. However, incorporating external information into LLMs' code generation process introduces new security risks. In this paper, we reveal a real-world threat, named HACKODE, where attackers exploit referenced external information to embed attack sequences, causing LLMs to produce code with vulnerabilities such as buffer overflows and incomplete validations. We designed a prototype of the attack, which generates effective attack sequences for potential diverse inputs with various user queries and prompt templates. Through the evaluation on two general LLMs and two code LLMs, we demonstrate that the attack is effective, achieving an 84.29% success rate. Additionally, on a real-world application, HACKODE achieves 75.92% ASR, demonstrating its real-world impact.","authors":["Binqi Zeng","Quan Zhang","Chijin Zhou","Gwihwan Go","Yu Jiang","Heyuan Shi"],"url":"https://arxiv.org/abs/2504.15867"}
{"created":"2025-04-23","title":"An Extended Horizon Tactical Decision-Making for Automated Driving Based on Monte Carlo Tree Search","abstract":"This paper introduces COR-MCTS (Conservation of Resources - Monte Carlo Tree Search), a novel tactical decision-making approach for automated driving focusing on maneuver planning over extended horizons. Traditional decision-making algorithms are often constrained by fixed planning horizons, typically up to 6 seconds for classical approaches and 3 seconds for learning-based methods limiting their adaptability in particular dynamic driving scenarios. However, planning must be done well in advance in environments such as highways, roundabouts, and exits to ensure safe and efficient maneuvers. To address this challenge, we propose a hybrid method integrating Monte Carlo Tree Search (MCTS) with our prior utility-based framework, COR-MP (Conservation of Resources Model for Maneuver Planning). This combination enables long-term, real-time decision-making, significantly enhancing the ability to plan a sequence of maneuvers over extended horizons. Through simulations across diverse driving scenarios, we demonstrate that COR-MCTS effectively improves planning robustness and decision efficiency over extended horizons.","authors":["Karim Essalmi","Fernando Garrido","Fawzi Nashashibi"],"url":"https://arxiv.org/abs/2504.15869"}
{"created":"2025-04-23","title":"A new method for erasure decoding of convolutional codes","abstract":"In this paper, we propose a new erasure decoding algorithm for convolutional codes using the generator matrix. This implies that our decoding method also applies to catastrophic convolutional codes in opposite to the classic approach using the parity-check matrix. We compare the performance of both decoding algorithms. Moreover, we enlarge the family of optimal convolutional codes (complete-MDP) based on the generator matrix.","authors":["Julia Lieb","Raquel Pinto","Carlos Vela"],"url":"https://arxiv.org/abs/2504.15873"}
{"created":"2025-04-23","title":"Bidirectional Task-Motion Planning Based on Hierarchical Reinforcement Learning for Strategic Confrontation","abstract":"In swarm robotics, confrontation scenarios, including strategic confrontations, require efficient decision-making that integrates discrete commands and continuous actions. Traditional task and motion planning methods separate decision-making into two layers, but their unidirectional structure fails to capture the interdependence between these layers, limiting adaptability in dynamic environments. Here, we propose a novel bidirectional approach based on hierarchical reinforcement learning, enabling dynamic interaction between the layers. This method effectively maps commands to task allocation and actions to path planning, while leveraging cross-training techniques to enhance learning across the hierarchical framework. Furthermore, we introduce a trajectory prediction model that bridges abstract task representations with actionable planning goals. In our experiments, it achieves over 80\\% in confrontation win rate and under 0.01 seconds in decision time, outperforming existing approaches. Demonstrations through large-scale tests and real-world robot experiments further emphasize the generalization capabilities and practical applicability of our method.","authors":["Qizhen Wu Lei Chen","Kexin Liu","Jinhu L\\\"u"],"url":"https://arxiv.org/abs/2504.15876"}
{"created":"2025-04-23","title":"Cryptoanalysis of a public key exchange based on circulant matrix over digital semiring","abstract":"We present a cryptanalysis of a key exchange protocol based on the digital semiring. For this purpose, we find the maximal solution of a linear system over such semiring, and use the properties of circulant matrix to demonstrate that the protocol is vulnerable. Specifically, we provide an efficient attack that recovers the shared secret key from publicly exchanged information for any instance of the digital semiring in polynomial time.","authors":["Alvaro Otero Sanchez"],"url":"https://arxiv.org/abs/2504.15880"}
{"created":"2025-04-23","title":"Integrating Non-Linear Radon Transformation for Diabetic Retinopathy Grading","abstract":"Diabetic retinopathy is a serious ocular complication that poses a significant threat to patients' vision and overall health. Early detection and accurate grading are essential to prevent vision loss. Current automatic grading methods rely heavily on deep learning applied to retinal fundus images, but the complex, irregular patterns of lesions in these images, which vary in shape and distribution, make it difficult to capture subtle changes. This study introduces RadFuse, a multi-representation deep learning framework that integrates non-linear RadEx-transformed sinogram images with traditional fundus images to enhance diabetic retinopathy detection and grading. Our RadEx transformation, an optimized non-linear extension of the Radon transform, generates sinogram representations to capture complex retinal lesion patterns. By leveraging both spatial and transformed domain information, RadFuse enriches the feature set available to deep learning models, improving the differentiation of severity levels. We conducted extensive experiments on two benchmark datasets, APTOS-2019 and DDR, using three convolutional neural networks (CNNs): ResNeXt-50, MobileNetV2, and VGG19. RadFuse showed significant improvements over fundus-image-only models across all three CNN architectures and outperformed state-of-the-art methods on both datasets. For severity grading across five stages, RadFuse achieved a quadratic weighted kappa of 93.24%, an accuracy of 87.07%, and an F1-score of 87.17%. In binary classification between healthy and diabetic retinopathy cases, the method reached an accuracy of 99.09%, precision of 98.58%, and recall of 99.6%, surpassing previously established models. These results demonstrate RadFuse's capacity to capture complex non-linear features, advancing diabetic retinopathy classification and promoting the integration of advanced mathematical transforms in medical image analysis.","authors":["Farida Mohsen","Samir Belhaouari","Zubair Shah"],"url":"https://arxiv.org/abs/2504.15883"}
{"created":"2025-04-23","title":"Branch-and-Bound Algorithms as Polynomial-time Approximation Schemes","abstract":"Branch-and-bound algorithms (B&amp;B) and polynomial-time approximation schemes (PTAS) are two seemingly distant areas of combinatorial optimization. We intend to (partially) bridge the gap between them while expanding the boundary of theoretical knowledge on the B&amp;B framework. Branch-and-bound algorithms typically guarantee that an optimal solution is eventually found. However, we show that the standard implementation of branch-and-bound for certain knapsack and scheduling problems also exhibits PTAS-like behavior, yielding increasingly better solutions within polynomial time. Our findings are supported by computational experiments and comparisons with benchmark methods. This paper is an extended version of a paper accepted at ICALP 2025.","authors":["Kopp\\'any Istv\\'an Encz","Monaldo Mastrolilli","Eleonora Vercesi"],"url":"https://arxiv.org/abs/2504.15885"}
{"created":"2025-04-23","title":"Beyond Attention: Investigating the Threshold Where Objective Robot Exclusion Becomes Subjective","abstract":"As robots become increasingly involved in decision-making processes (e.g., personnel selection), concerns about fairness and social inclusion arise. This study examines social exclusion in robot-led group interviews by robot Ameca, exploring the relationship between objective exclusion (robot's attention allocation), subjective exclusion (perceived exclusion), mood change, and need fulfillment. In a controlled lab study (N = 35), higher objective exclusion significantly predicted subjective exclusion. In turn, subjective exclusion negatively impacted mood and need fulfillment but only mediated the relationship between objective exclusion and need fulfillment. A piecewise regression analysis identified a critical threshold at which objective exclusion begins to be perceived as subjective exclusion. Additionally, the standing position was the primary predictor of exclusion, whereas demographic factors (e.g., gender, height) had no significant effect. These findings underscore the need to consider both objective and subjective exclusion in human-robot interactions and have implications for fairness in robot-assisted hiring processes.","authors":["Clarissa Sabrina Arlinghaus","Ashita Ashok","Ashim Mandal","Karsten Berns","G\\\"unter W. Maier"],"url":"https://arxiv.org/abs/2504.15886"}
{"created":"2025-04-23","title":"MS-Occ: Multi-Stage LiDAR-Camera Fusion for 3D Semantic Occupancy Prediction","abstract":"Accurate 3D semantic occupancy perception is essential for autonomous driving in complex environments with diverse and irregular objects. While vision-centric methods suffer from geometric inaccuracies, LiDAR-based approaches often lack rich semantic information. To address these limitations, MS-Occ, a novel multi-stage LiDAR-camera fusion framework which includes middle-stage fusion and late-stage fusion, is proposed, integrating LiDAR's geometric fidelity with camera-based semantic richness via hierarchical cross-modal fusion. The framework introduces innovations at two critical stages: (1) In the middle-stage feature fusion, the Gaussian-Geo module leverages Gaussian kernel rendering on sparse LiDAR depth maps to enhance 2D image features with dense geometric priors, and the Semantic-Aware module enriches LiDAR voxels with semantic context via deformable cross-attention; (2) In the late-stage voxel fusion, the Adaptive Fusion (AF) module dynamically balances voxel features across modalities, while the High Classification Confidence Voxel Fusion (HCCVF) module resolves semantic inconsistencies using self-attention-based refinement. Experiments on the nuScenes-OpenOccupancy benchmark show that MS-Occ achieves an Intersection over Union (IoU) of 32.1% and a mean IoU (mIoU) of 25.3%, surpassing the state-of-the-art by +0.7% IoU and +2.4% mIoU. Ablation studies further validate the contribution of each module, with substantial improvements in small-object perception, demonstrating the practical value of MS-Occ for safety-critical autonomous driving scenarios.","authors":["Zhiqiang Wei","Lianqing Zheng","Jianan Liu","Tao Huang","Qing-Long Han","Wenwen Zhang","Fengdeng Zhang"],"url":"https://arxiv.org/abs/2504.15888"}
{"created":"2025-04-23","title":"Supporting Data-Frame Dynamics in AI-assisted Decision Making","abstract":"High stakes decision-making often requires a continuous interplay between evolving evidence and shifting hypotheses, a dynamic that is not well supported by current AI decision support systems. In this paper, we introduce a mixed-initiative framework for AI assisted decision making that is grounded in the data-frame theory of sensemaking and the evaluative AI paradigm. Our approach enables both humans and AI to collaboratively construct, validate, and adapt hypotheses. We demonstrate our framework with an AI-assisted skin cancer diagnosis prototype that leverages a concept bottleneck model to facilitate interpretable interactions and dynamic updates to diagnostic hypotheses.","authors":["Chengbo Zheng","Tim Miller","Alina Bialkowski","H Peter Soyer","Monika Janda"],"url":"https://arxiv.org/abs/2504.15894"}
{"created":"2025-04-23","title":"Dynamic Early Exit in Reasoning Models","abstract":"Recent advances in large reasoning language models (LRLMs) rely on test-time scaling, which extends long chain-of-thought (CoT) generation to solve complex tasks. However, overthinking in long CoT not only slows down the efficiency of problem solving, but also risks accuracy loss due to the extremely detailed or redundant reasoning steps. We propose a simple yet effective method that allows LLMs to self-truncate CoT sequences by early exit during generation. Instead of relying on fixed heuristics, the proposed method monitors model behavior at potential reasoning transition points (e.g.,\"Wait\" tokens) and dynamically terminates the next reasoning chain's generation when the model exhibits high confidence in a trial answer. Our method requires no additional training and can be seamlessly integrated into existing o1-like reasoning LLMs. Experiments on multiple reasoning benchmarks MATH-500, AMC 2023, GPQA Diamond and AIME 2024 show that the proposed method is consistently effective on deepseek-series reasoning LLMs, reducing the length of CoT sequences by an average of 31% to 43% while improving accuracy by 1.7% to 5.7%.","authors":["Chenxu Yang","Qingyi Si","Yongjie Duan","Zheliang Zhu","Chenyu Zhu","Zheng Lin","Li Cao","Weiping Wang"],"url":"https://arxiv.org/abs/2504.15895"}
{"created":"2025-04-23","title":"SUPRA: Subspace Parameterized Attention for Neural Operator on General Domains","abstract":"Neural operators are efficient surrogate models for solving partial differential equations (PDEs), but their key components face challenges: (1) in order to improve accuracy, attention mechanisms suffer from computational inefficiency on large-scale meshes, and (2) spectral convolutions rely on the Fast Fourier Transform (FFT) on regular grids and assume a flat geometry, which causes accuracy degradation on irregular domains. To tackle these problems, we regard the matrix-vector operations in the standard attention mechanism on vectors in Euclidean space as bilinear forms and linear operators in vector spaces and generalize the attention mechanism to function spaces. This new attention mechanism is fully equivalent to the standard attention but impossible to compute due to the infinite dimensionality of function spaces. To address this, inspired by model reduction techniques, we propose a Subspace Parameterized Attention (SUPRA) neural operator, which approximates the attention mechanism within a finite-dimensional subspace. To construct a subspace on irregular domains for SUPRA, we propose using the Laplacian eigenfunctions, which naturally adapt to domains' geometry and guarantee the optimal approximation for smooth functions. Experiments show that the SUPRA neural operator reduces error rates by up to 33% on various PDE datasets while maintaining state-of-the-art computational efficiency.","authors":["Zherui Yang","Zhengyang Xue","Ligang Liu"],"url":"https://arxiv.org/abs/2504.15897"}
{"created":"2025-04-23","title":"RaSCL: Radar to Satellite Crossview Localization","abstract":"GNSS is unreliable, inaccurate, and insufficient in many real-time autonomous field applications. In this work, we present a GNSS-free global localization solution that contains a method of registering imaging radar on the ground with overhead RGB imagery, with joint optimization of relative poses from odometry and global poses from our overhead registration. Previous works have used various combinations of ground sensors and overhead imagery, and different feature extraction and matching methods. These include various handcrafted and deep-learning-based methods for extracting features from overhead imagery. Our work presents insights on extracting essential features from RGB overhead images for effective global localization against overhead imagery using only ground radar and a single georeferenced initial guess. We motivate our method by evaluating it on datasets in diverse geographic conditions and robotic platforms, including on an Unmanned Surface Vessel (USV) as well as urban and suburban driving datasets.","authors":["Blerim Abdullai","Tony Wang","Xinyuan Qiao","Florian Shkurti","Timothy D. Barfoot"],"url":"https://arxiv.org/abs/2504.15899"}
{"created":"2025-04-23","title":"SARI: Structured Audio Reasoning via Curriculum-Guided Reinforcement Learning","abstract":"Recent work shows that reinforcement learning(RL) can markedly sharpen the reasoning ability of large language models (LLMs) by prompting them to \"think before answering.\" Yet whether and how these gains transfer to audio-language reasoning remains largely unexplored. We extend the Group-Relative Policy Optimization (GRPO) framework from DeepSeek-R1 to a Large Audio-Language Model (LALM), and construct a 32k sample multiple-choice corpus. Using a two-stage regimen supervised fine-tuning on structured and unstructured chains-of-thought, followed by curriculum-guided GRPO, we systematically compare implicit vs. explicit, and structured vs. free form reasoning under identical architectures. Our structured audio reasoning model, SARI (Structured Audio Reasoning via Curriculum-Guided Reinforcement Learning), achieves a 16.35% improvement in average accuracy over the base model Qwen2-Audio-7B-Instruct. Furthermore, the variant built upon Qwen2.5-Omni reaches state-of-the-art performance of 67.08% on the MMAU test-mini benchmark. Ablation experiments show that on the base model we use: (i) SFT warm-up is important for stable RL training, (ii) structured chains yield more robust generalization than unstructured ones, and (iii) easy-to-hard curricula accelerate convergence and improve final performance. These findings demonstrate that explicit, structured reasoning and curriculum learning substantially enhances audio-language understanding.","authors":["Cheng Wen","Tingwei Guo","Shuaijiang Zhao","Wei Zou","Xiangang Li"],"url":"https://arxiv.org/abs/2504.15900"}
{"created":"2025-04-23","title":"Impact of Noise on LLM-Models Performance in Abstraction and Reasoning Corpus (ARC) Tasks with Model Temperature Considerations","abstract":"Recent advancements in Large Language Models (LLMs) have generated growing interest in their structured reasoning capabilities, particularly in tasks involving abstraction and pattern recognition. The Abstraction and Reasoning Corpus (ARC) benchmark plays a crucial role in evaluating these capabilities by testing how well AI models generalize to novel problems. While GPT-4o demonstrates strong performance by solving all ARC tasks under zero-noise conditions, other models like DeepSeek R1 and LLaMA 3.2 fail to solve any, suggesting limitations in their ability to reason beyond simple pattern matching. To explore this gap, we systematically evaluate these models across different noise levels and temperature settings. Our results reveal that the introduction of noise consistently impairs model performance, regardless of architecture. This decline highlights a shared vulnerability: current LLMs, despite showing signs of abstract reasoning, remain highly sensitive to input perturbations. Such fragility raises concerns about their real-world applicability, where noise and uncertainty are common. By comparing how different model architectures respond to these challenges, we offer insights into the structural weaknesses of modern LLMs in reasoning tasks. This work underscores the need for developing more robust and adaptable AI systems capable of handling the ambiguity and variability inherent in real-world scenarios. Our findings aim to guide future research toward enhancing model generalization, robustness, and alignment with human-like cognitive flexibility.","authors":["Nikhil Khandalkar","Pavan Yadav","Krishna Shinde","Lokesh B. Ramegowda","Rajarshi Das"],"url":"https://arxiv.org/abs/2504.15903"}
{"created":"2025-04-23","title":"GraphEdge: Dynamic Graph Partition and Task Scheduling for GNNs Computing in Edge Network","abstract":"With the exponential growth of Internet of Things (IoT) devices, edge computing (EC) is gradually playing an important role in providing cost-effective services. However, existing approaches struggle to perform well in graph-structured scenarios where user data is correlated, such as traffic flow prediction and social relationship recommender systems. In particular, graph neural network (GNN)-based approaches lead to expensive server communication cost. To address this problem, we propose GraphEdge, an efficient GNN-based EC architecture. It considers the EC system of GNN tasks, where there are associations between users and it needs to take into account the task data of its neighbors when processing the tasks of a user. Specifically, the architecture first perceives the user topology and represents their data associations as a graph layout at each time step. Then the graph layout is optimized by calling our proposed hierarchical traversal graph cut algorithm (HiCut), which cuts the graph layout into multiple weakly associated subgraphs based on the aggregation characteristics of GNN, and the communication cost between different subgraphs during GNN inference is minimized. Finally, based on the optimized graph layout, our proposed deep reinforcement learning (DRL) based graph offloading algorithm (DRLGO) is executed to obtain the optimal offloading strategy for the tasks of users, the offloading strategy is subgraph-based, it tries to offload user tasks in a subgraph to the same edge server as possible while minimizing the task processing time and energy consumption of the EC system. Experimental results show the good effectiveness and dynamic adaptation of our proposed architecture and it also performs well even in dynamic scenarios.","authors":["Wenjing Xiao","Chenglong Shi","Miaojiang Chen","Zhiquan Liu","Min Chen","H. Herbert Song"],"url":"https://arxiv.org/abs/2504.15905"}
{"created":"2025-04-23","title":"Synergizing RAG and Reasoning: A Systematic Review","abstract":"Recent breakthroughs in large language models (LLMs), particularly in reasoning capabilities, have propelled Retrieval-Augmented Generation (RAG) to unprecedented levels. By synergizing retrieval mechanisms with advanced reasoning, LLMs can now tackle increasingly complex problems. This paper presents a systematic review of the collaborative interplay between RAG and reasoning, clearly defining \"reasoning\" within the RAG context. It construct a comprehensive taxonomy encompassing multi-dimensional collaborative objectives, representative paradigms, and technical implementations, and analyze the bidirectional synergy methods. Additionally, we critically evaluate current limitations in RAG assessment, including the absence of intermediate supervision for multi-step reasoning and practical challenges related to cost-risk trade-offs. To bridge theory and practice, we provide practical guidelines tailored to diverse real-world applications. Finally, we identify promising research directions, such as graph-based knowledge integration, hybrid model collaboration, and RL-driven optimization. Overall, this work presents a theoretical framework and practical foundation to advance RAG systems in academia and industry, fostering the next generation of RAG solutions.","authors":["Yunfan Gao","Yun Xiong","Yijie Zhong","Yuxi Bi","Ming Xue","Haofen Wang"],"url":"https://arxiv.org/abs/2504.15909"}
{"created":"2025-04-23","title":"Automated Bug Report Prioritization in Large Open-Source Projects","abstract":"Large open-source projects receive a large number of issues (known as bugs), including software defect (i.e., bug) reports and new feature requests from their user and developer communities at a fast rate. The often limited project resources do not allow them to deal with all issues. Instead, they have to prioritize them according to the project's priorities and the issues' severities. In this paper, we propose a novel approach to automated bug prioritization based on the natural language text of the bug reports that are stored in the open bug repositories of the issue-tracking systems. We conduct topic modeling using a variant of LDA called TopicMiner-MTM and text classification with the BERT large language model to achieve a higher performance level compared to the state-of-the-art. Experimental results using an existing reference dataset containing 85,156 bug reports of the Eclipse Platform project indicate that we outperform existing approaches in terms of Accuracy, Precision, Recall, and F1-measure of the bug report priority prediction.","authors":["Riley Pierson","Armin Moin"],"url":"https://arxiv.org/abs/2504.15912"}
{"created":"2025-04-23","title":"Towards Test Generation from Task Description for Mobile Testing with Multi-modal Reasoning","abstract":"In Android GUI testing, generating an action sequence for a task that can be replayed as a test script is common. Generating sequences of actions and respective test scripts from task goals described in natural language can eliminate the need for manually writing test scripts. However, existing approaches based on large language models (LLM) often struggle with identifying the final action, and either end prematurely or continue past the final screen. In this paper, we introduce VisiDroid, a multi-modal, LLM-based, multi-agent framework that iteratively determines the next action and leverages visual images of screens to detect the task's completeness. The multi-modal approach enhances our model in two significant ways. First, this approach enables it to avoid prematurely terminating a task when textual content alone provides misleading indications of task completion. Additionally, visual input helps the tool avoid errors when changes in the GUI do not directly affect functionality toward task completion, such as adjustments to font sizes or colors. Second, the multi-modal approach also ensures the tool not progress beyond the final screen, which might lack explicit textual indicators of task completion but could display a visual element indicating task completion, which is common in GUI apps. Our evaluation shows that VisiDroid achieves an accuracy of 87.3%, outperforming the best baseline relatively by 23.5%. We also demonstrate that our multi-modal framework with images and texts enables the LLM to better determine when a task is completed.","authors":["Hieu Huynh","Hai Phung","Hao Pham","Tien N. Nguyen","Vu Nguyen"],"url":"https://arxiv.org/abs/2504.15917"}
{"created":"2025-04-23","title":"Ask2Loc: Learning to Locate Instructional Visual Answers by Asking Questions","abstract":"Locating specific segments within an instructional video is an efficient way to acquire guiding knowledge. Generally, the task of obtaining video segments for both verbal explanations and visual demonstrations is known as visual answer localization (VAL). However, users often need multiple interactions to obtain answers that align with their expectations when using the system. During these interactions, humans deepen their understanding of the video content by asking themselves questions, thereby accurately identifying the location. Therefore, we propose a new task, named In-VAL, to simulate the multiple interactions between humans and videos in the procedure of obtaining visual answers. The In-VAL task requires interactively addressing several semantic gap issues, including 1) the ambiguity of user intent in the input questions, 2) the incompleteness of language in video subtitles, and 3) the fragmentation of content in video segments. To address these issues, we propose Ask2Loc, a framework for resolving In-VAL by asking questions. It includes three key modules: 1) a chatting module to refine initial questions and uncover clear intentions, 2) a rewriting module to generate fluent language and create complete descriptions, and 3) a searching module to broaden local context and provide integrated content. We conduct extensive experiments on three reconstructed In-VAL datasets. Compared to traditional end-to-end and two-stage methods, our proposed Ask2Loc can improve performance by up to 14.91 (mIoU) on the In-VAL task. Our code and datasets can be accessed at https://github.com/changzong/Ask2Loc.","authors":["Chang Zong","Bin Li","Shoujun Zhou","Jian Wan","Lei Zhang"],"url":"https://arxiv.org/abs/2504.15918"}
{"created":"2025-04-23","title":"ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order Neighboring Feature Fusion","abstract":"Graph Neural Networks (GNNs) have demonstrated strong performance across various graph-based tasks by effectively capturing relational information between nodes. These models rely on iterative message passing to propagate node features, enabling nodes to aggregate information from their neighbors. Recent research has significantly improved the message-passing mechanism, enhancing GNN scalability on large-scale graphs. However, GNNs still face two main challenges: over-smoothing, where excessive message passing results in indistinguishable node representations, especially in deep networks incorporating high-order neighbors; and scalability issues, as traditional architectures suffer from high model complexity and increased inference time due to redundant information aggregation. This paper proposes a novel framework for large-scale graphs named ScaleGNN that simultaneously addresses both challenges by adaptively fusing multi-level graph features. We first construct neighbor matrices for each order, learning their relative information through trainable weights through an adaptive high-order feature fusion module. This allows the model to selectively emphasize informative high-order neighbors while reducing unnecessary computational costs. Additionally, we introduce a High-order redundant feature masking mechanism based on a Local Contribution Score (LCS), which enables the model to retain only the most relevant neighbors at each order, preventing redundant information propagation. Furthermore, low-order enhanced feature aggregation adaptively integrates low-order and high-order features based on task relevance, ensuring effective capture of both local and global structural information without excessive complexity. Extensive experiments on real-world datasets demonstrate that our approach consistently outperforms state-of-the-art GNN models in both accuracy and computational efficiency.","authors":["Xiang Li","Haobing Liu","Jianpeng Qi","Yuan Cao","Guoqing Chao","Yanwei Yu"],"url":"https://arxiv.org/abs/2504.15920"}
{"created":"2025-04-23","title":"ViSMaP: Unsupervised Hour-long Video Summarisation by Meta-Prompting","abstract":"We introduce ViSMap: Unsupervised Video Summarisation by Meta Prompting, a system to summarise hour long videos with no-supervision. Most existing video understanding models work well on short videos of pre-segmented events, yet they struggle to summarise longer videos where relevant events are sparsely distributed and not pre-segmented. Moreover, long-form video understanding often relies on supervised hierarchical training that needs extensive annotations which are costly, slow and prone to inconsistency. With ViSMaP we bridge the gap between short videos (where annotated data is plentiful) and long ones (where it's not). We rely on LLMs to create optimised pseudo-summaries of long videos using segment descriptions from short ones. These pseudo-summaries are used as training data for a model that generates long-form video summaries, bypassing the need for expensive annotations of long videos. Specifically, we adopt a meta-prompting strategy to iteratively generate and refine creating pseudo-summaries of long videos. The strategy leverages short clip descriptions obtained from a supervised short video model to guide the summary. Each iteration uses three LLMs working in sequence: one to generate the pseudo-summary from clip descriptions, another to evaluate it, and a third to optimise the prompt of the generator. This iteration is necessary because the quality of the pseudo-summaries is highly dependent on the generator prompt, and varies widely among videos. We evaluate our summaries extensively on multiple datasets; our results show that ViSMaP achieves performance comparable to fully supervised state-of-the-art models while generalising across domains without sacrificing performance. Code will be released upon publication.","authors":["Jian Hu","Dimitrios Korkinof","Shaogang Gong","Mariano Beguerisse-Diaz"],"url":"https://arxiv.org/abs/2504.15921"}
{"created":"2025-04-23","title":"Language Models to Support Multi-Label Classification of Industrial Data","abstract":"Multi-label requirements classification is a challenging task, especially when dealing with numerous classes at varying levels of abstraction. The difficulties increases when a limited number of requirements is available to train a supervised classifier. Zero-shot learning (ZSL) does not require training data and can potentially address this problem. This paper investigates the performance of zero-shot classifiers (ZSCs) on a multi-label industrial dataset. We focuse on classifying requirements according to a taxonomy designed to support requirements tracing. We compare multiple variants of ZSCs using different embeddings, including 9 language models (LMs) with a reduced number of parameters (up to 3B), e.g., BERT, and 5 large LMs (LLMs) with a large number of parameters (up to 70B), e.g., Llama. Our ground truth includes 377 requirements and 1968 labels from 6 output spaces. For the evaluation, we adopt traditional metrics, i.e., precision, recall, F1, and $F_\\beta$, as well as a novel label distance metric Dn. This aims to better capture the classification's hierarchical nature and provides a more nuanced evaluation of how far the results are from the ground truth. 1) The top-performing model on 5 out of 6 output spaces is T5-xl, with maximum $F_\\beta$ = 0.78 and Dn = 0.04, while BERT base outperformed the other models in one case, with maximum $F_\\beta$ = 0.83 and Dn = 0.04. 2) LMs with smaller parameter size produce the best classification results compared to LLMs. Thus, addressing the problem in practice is feasible as limited computing power is needed. 3) The model architecture (autoencoding, autoregression, and sentence-to-sentence) significantly affects the classifier's performance. We conclude that using ZSL for multi-label requirements classification offers promising results. We also present a novel metric that can be used to select the top-performing model for this problem","authors":["Waleed Abdeen","Michael Unterkalmsteiner","Krzysztof Wnuk","Alessio Ferrari","Panagiota Chatzipetrou"],"url":"https://arxiv.org/abs/2504.15922"}
{"created":"2025-04-23","title":"Achieving Distributive Justice in Federated Learning via Uncertainty Quantification","abstract":"Client-level fairness metrics for federated learning are used to ensure that all clients in a federation either: a) have similar final performance on their local data distributions (i.e., client parity), or b) obtain final performance on their local data distributions relative to their contribution to the federated learning process (i.e., contribution fairness). While a handful of works that propose either client-parity or contribution-based fairness metrics ground their definitions and decisions in social theories of equality -- such as distributive justice -- most works arbitrarily choose what notion of fairness to align with which makes it difficult for practitioners to choose which fairness metric aligns best with their fairness ethics. In this work, we propose UDJ-FL (Uncertainty-based Distributive Justice for Federated Learning), a flexible federated learning framework that can achieve multiple distributive justice-based client-level fairness metrics. Namely, by utilizing techniques inspired by fair resource allocation, in conjunction with performing aleatoric uncertainty-based client weighing, our UDJ-FL framework is able to achieve egalitarian, utilitarian, Rawls' difference principle, or desert-based client-level fairness. We empirically show the ability of UDJ-FL to achieve all four defined distributive justice-based client-level fairness metrics in addition to providing fairness equivalent to (or surpassing) other popular fair federated learning works. Further, we provide justification for why aleatoric uncertainty weighing is necessary to the construction of our UDJ-FL framework as well as derive theoretical guarantees for the generalization bounds of UDJ-FL. Our code is publicly available at https://github.com/alycia-noel/UDJ-FL.","authors":["Alycia Carey","Xintao Wu"],"url":"https://arxiv.org/abs/2504.15924"}
{"created":"2025-04-23","title":"New Recipe for Semi-supervised Community Detection: Clique Annealing under Crystallization Kinetics","abstract":"Semi-supervised community detection methods are widely used for identifying specific communities due to the label scarcity. Existing semi-supervised community detection methods typically involve two learning stages learning in both initial identification and subsequent adjustment, which often starts from an unreasonable community core candidate. Moreover, these methods encounter scalability issues because they depend on reinforcement learning and generative adversarial networks, leading to higher computational costs and restricting the selection of candidates. To address these limitations, we draw a parallel between crystallization kinetics and community detection to integrate the spontaneity of the annealing process into community detection. Specifically, we liken community detection to identifying a crystal subgrain (core) that expands into a complete grain (community) through a process similar to annealing. Based on this finding, we propose CLique ANNealing (CLANN), which applies kinetics concepts to community detection by integrating these principles into the optimization process to strengthen the consistency of the community core. Subsequently, a learning-free Transitive Annealer was employed to refine the first-stage candidates by merging neighboring cliques and repositioning the community core, enabling a spontaneous growth process that enhances scalability. Extensive experiments on \\textbf{43} different network settings demonstrate that CLANN outperforms state-of-the-art methods across multiple real-world datasets, showcasing its exceptional efficacy and efficiency in community detection.","authors":["Ling Cheng","Jiashu Pu","Ruicheng Liang","Qian Shao","Hezhe Qiao","Feida Zhu"],"url":"https://arxiv.org/abs/2504.15927"}
{"created":"2025-04-23","title":"A Clinician-Friendly Platform for Ophthalmic Image Analysis Without Technical Barriers","abstract":"Artificial intelligence (AI) shows remarkable potential in medical imaging diagnostics, but current models typically require retraining when deployed across different clinical centers, limiting their widespread adoption. We introduce GlobeReady, a clinician-friendly AI platform that enables ocular disease diagnosis without retraining/fine-tuning or technical expertise. GlobeReady achieves high accuracy across imaging modalities: 93.9-98.5% for an 11-category fundus photo dataset and 87.2-92.7% for a 15-category OCT dataset. Through training-free local feature augmentation, it addresses domain shifts across centers and populations, reaching an average accuracy of 88.9% across five centers in China, 86.3% in Vietnam, and 90.2% in the UK. The built-in confidence-quantifiable diagnostic approach further boosted accuracy to 94.9-99.4% (fundus) and 88.2-96.2% (OCT), while identifying out-of-distribution cases at 86.3% (49 CFP categories) and 90.6% (13 OCT categories). Clinicians from multiple countries rated GlobeReady highly (average 4.6 out of 5) for its usability and clinical relevance. These results demonstrate GlobeReady's robust, scalable diagnostic capability and potential to support ophthalmic care without technical barriers.","authors":["Meng Wang","Tian Lin","Qingshan Hou","Aidi Lin","Jingcheng Wang","Qingsheng Peng","Truong X. Nguyen","Danqi Fang","Ke Zou","Ting Xu","Cancan Xue","Ten Cheer Quek","Qinkai Yu","Minxin Liu","Hui Zhou","Zixuan Xiao","Guiqin He","Huiyu Liang","Tingkun Shi","Man Chen","Linna Liu","Yuanyuan Peng","Lianyu Wang","Qiuming Hu","Junhong Chen","Zhenhua Zhang","Cheng Chen","Yitian Zhao","Dianbo Liu","Jianhua Wu","Xinjian Chen","Changqing Zhang","Triet Thanh Nguyen","Yanda Meng","Yalin Zheng","Yih Chung Tham","Carol Y. Cheung","Huazhu Fu","Haoyu Chen","Ching-Yu Cheng"],"url":"https://arxiv.org/abs/2504.15928"}
{"created":"2025-04-23","title":"Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models","abstract":"Diagnostic imaging relies on interpreting both images and radiology reports, but the growing data volumes place significant pressure on medical experts, yielding increased errors and workflow backlogs. Medical vision-language models (med-VLMs) have emerged as a powerful framework to efficiently process multimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeit their performance hinges on how well image and text representations are aligned. Existing alignment methods, predominantly based on contrastive learning, prioritize separation between disease classes over segregation of fine-grained pathology attributes like location, size or severity, leading to suboptimal representations. Here, we propose MedTrim (Meta-entity-driven Triplet mining), a novel method that enhances image-text alignment through multimodal triplet learning synergistically guided by disease class as well as adjectival and directional pathology descriptors. Unlike common alignment methods that separate broad disease classes, MedTrim leverages structured meta-entity information to preserve subtle but clinically significant intra-class variations. For this purpose, we first introduce an ontology-based entity recognition module that extracts pathology-specific meta-entities from CXR reports, as annotations on pathology attributes are rare in public datasets. For refined sample selection in triplet mining, we then introduce a novel score function that captures an aggregate measure of inter-sample similarity based on disease classes and adjectival/directional descriptors. Lastly, we introduce a multimodal triplet alignment objective for explicit within- and cross-modal alignment between samples sharing detailed pathology characteristics. Our demonstrations indicate that MedTrim improves performance in downstream retrieval and classification tasks compared to state-of-the-art alignment methods.","authors":["Saban Ozturk","Melih B. Yilmaz","Muti Kara","M. Talat Yavuz","Aykut Ko\\c{c}","Tolga \\c{C}ukur"],"url":"https://arxiv.org/abs/2504.15929"}
{"created":"2025-04-23","title":"StreamRL: Scalable, Heterogeneous, and Elastic RL for LLMs with Disaggregated Stream Generation","abstract":"Reinforcement learning (RL) has become the core post-training technique for large language models (LLMs). RL for LLMs involves two stages: generation and training. The LLM first generates samples online, which are then used to derive rewards for training. The conventional view holds that the colocated architecture, where the two stages share resources via temporal multiplexing, outperforms the disaggregated architecture, in which dedicated resources are assigned to each stage. However, in real-world deployments, we observe that the colocated architecture suffers from resource coupling, where the two stages are constrained to use the same resources. This coupling compromises the scalability and cost-efficiency of colocated RL in large-scale training. In contrast, the disaggregated architecture allows for flexible resource allocation, supports heterogeneous training setups, and facilitates cross-datacenter deployment.","authors":["Yinmin Zhong","Zili Zhang","Xiaoniu Song","Hanpeng Hu","Chao Jin","Bingyang Wu","Nuo Chen","Yukun Chen","Yu Zhou","Changyi Wan","Hongyu Zhou","Yimin Jiang","Yibo Zhu","Daxin Jiang"],"url":"https://arxiv.org/abs/2504.15930"}
{"created":"2025-04-23","title":"Benchmarking the Reproducibility of Brain MRI Segmentation Across Scanners and Time","abstract":"Accurate and reproducible brain morphometry from structural MRI is critical for monitoring neuroanatomical changes across time and across imaging domains. Although deep learning has accelerated segmentation workflows, scanner-induced variability and reproducibility limitations remain-especially in longitudinal and multi-site settings. In this study, we benchmark two modern segmentation pipelines, FastSurfer and SynthSeg, both integrated into FreeSurfer, one of the most widely adopted tools in neuroimaging.","authors":["Ekaterina Kondrateva","Sandzhi Barg","Mikhail Vasiliev"],"url":"https://arxiv.org/abs/2504.15931"}
{"created":"2025-04-23","title":"Reasoning Physical Video Generation with Diffusion Timestep Tokens via Reinforcement Learning","abstract":"Despite recent progress in video generation, producing videos that adhere to physical laws remains a significant challenge. Traditional diffusion-based methods struggle to extrapolate to unseen physical conditions (eg, velocity) due to their reliance on data-driven approximations. To address this, we propose to integrate symbolic reasoning and reinforcement learning to enforce physical consistency in video generation. We first introduce the Diffusion Timestep Tokenizer (DDT), which learns discrete, recursive visual tokens by recovering visual attributes lost during the diffusion process. The recursive visual tokens enable symbolic reasoning by a large language model. Based on it, we propose the Phys-AR framework, which consists of two stages: The first stage uses supervised fine-tuning to transfer symbolic knowledge, while the second stage applies reinforcement learning to optimize the model's reasoning abilities through reward functions based on physical conditions. Our approach allows the model to dynamically adjust and improve the physical properties of generated videos, ensuring adherence to physical laws. Experimental results demonstrate that PhysAR can generate videos that are physically consistent.","authors":["Wang Lin","Liyu Jia","Wentao Hu","Kaihang Pan","Zhongqi Yue","Wei Zhao","Jingyuan Chen","Fei Wu","Hanwang Zhang"],"url":"https://arxiv.org/abs/2504.15932"}
{"created":"2025-04-23","title":"Low-Rank Adaptation of Neural Fields","abstract":"Processing visual data often involves small adjustments or sequences of changes, such as in image filtering, surface smoothing, and video storage. While established graphics techniques like normal mapping and video compression exploit redundancy to encode such small changes efficiently, the problem of encoding small changes to neural fields (NF) -- neural network parameterizations of visual or physical functions -- has received less attention.","authors":["Anh Truong","Ahmed H. Mahmoud","Mina Konakovi\\'c Lukovi\\'c","Justin Solomon"],"url":"https://arxiv.org/abs/2504.15933"}
{"created":"2025-04-23","title":"Real-time raw signal genomic analysis using fully integrated memristor hardware","abstract":"Advances in third-generation sequencing have enabled portable and real-time genomic sequencing, but real-time data processing remains a bottleneck, hampering on-site genomic analysis due to prohibitive time and energy costs. These technologies generate a massive amount of noisy analog signals that traditionally require basecalling and digital mapping, both demanding frequent and costly data movement on von Neumann hardware. To overcome these challenges, we present a memristor-based hardware-software co-design that processes raw sequencer signals directly in analog memory, effectively combining the separated basecalling and read mapping steps. Here we demonstrate, for the first time, end-to-end memristor-based genomic analysis in a fully integrated memristor chip. By exploiting intrinsic device noise for locality-sensitive hashing and implementing parallel approximate searches in content-addressable memory, we experimentally showcase on-site applications including infectious disease detection and metagenomic classification. Our experimentally-validated analysis confirms the effectiveness of this approach on real-world tasks, achieving a state-of-the-art 97.15% F1 score in virus raw signal mapping, with 51x speed up and 477x energy saving compared to implementation on a state-of-the-art ASIC. These results demonstrate that memristor-based in-memory computing provides a viable solution for integration with portable sequencers, enabling truly real-time on-site genomic analysis for applications ranging from pathogen surveillance to microbial community profiling.","authors":["Peiyi He","Shengbo Wang","Ruibin Mao","Sebastian Siegel","Giacomo Pedretti","Jim Ignowski","John Paul Strachan","Ruibang Luo","Can Li"],"url":"https://arxiv.org/abs/2504.15934"}
{"created":"2025-04-23","title":"An effectful object calculus","abstract":"We show how to smoothly incorporate in the object-oriented paradigm constructs to raise, compose, and handle effects in an arbitrary monad. The underlying pure calculus is meant to be a representative of the last generation of OO languages, and the effectful extension is manageable enough for ordinary programmers; notably, constructs to raise effects are just special methods. We equip the calculus with an expressive type-and-effect system, which, again by relying on standard features such as inheritance and generic types, allows a simple form of effect polymorphism. The soundness of the type-and-effect system is expressed and proved by a recently introduced technique, where the semantics is formalized by a one-step reduction relation from language expressions into monadic ones, so that it is enough to prove progress and subject reduction properties on this relation.","authors":["Francesco Dagnino","Paola Giannini","Elena Zucca"],"url":"https://arxiv.org/abs/2504.15936"}
{"created":"2025-04-23","title":"FairTranslate: An English-French Dataset for Gender Bias Evaluation in Machine Translation by Overcoming Gender Binarity","abstract":"Large Language Models (LLMs) are increasingly leveraged for translation tasks but often fall short when translating inclusive language -- such as texts containing the singular 'they' pronoun or otherwise reflecting fair linguistic protocols. Because these challenges span both computational and societal domains, it is imperative to critically evaluate how well LLMs handle inclusive translation with a well-founded framework.","authors":["Fanny Jourdan","Yannick Chevalier","C\\'ecile Favre"],"url":"https://arxiv.org/abs/2504.15941"}
{"created":"2025-04-23","title":"Adversarial Observations in Weather Forecasting","abstract":"AI-based systems, such as Google's GenCast, have recently redefined the state of the art in weather forecasting, offering more accurate and timely predictions of both everyday weather and extreme events. While these systems are on the verge of replacing traditional meteorological methods, they also introduce new vulnerabilities into the forecasting process. In this paper, we investigate this threat and present a novel attack on autoregressive diffusion models, such as those used in GenCast, capable of manipulating weather forecasts and fabricating extreme events, including hurricanes, heat waves, and intense rainfall. The attack introduces subtle perturbations into weather observations that are statistically indistinguishable from natural noise and change less than 0.1% of the measurements - comparable to tampering with data from a single meteorological satellite. As modern forecasting integrates data from nearly a hundred satellites and many other sources operated by different countries, our findings highlight a critical security risk with the potential to cause large-scale disruptions and undermine public trust in weather prediction.","authors":["Erik Imgrund","Thorsten Eisenhofer","Konrad Rieck"],"url":"https://arxiv.org/abs/2504.15942"}
{"created":"2025-04-23","title":"Automated Vulnerability Injection in Solidity Smart Contracts: A Mutation-Based Approach for Benchmark Development","abstract":"The security of smart contracts is critical in blockchain systems, where even minor vulnerabilities can lead to substantial financial losses. Researchers proposed several vulnerability detection tools evaluated using existing benchmarks. However, most benchmarks are outdated and focus on a narrow set of vulnerabilities. This work evaluates whether mutation seeding can effectively inject vulnerabilities into Solidity-based smart contracts and whether state-of-the-art static analysis tools can detect the injected flaws. We aim to automatically inject vulnerabilities into smart contracts to generate large and wide benchmarks. We propose MuSe, a tool to generate vulnerable smart contracts by leveraging pattern-based mutation operators to inject six vulnerability types into real-world smart contracts. We analyzed these vulnerable smart contracts using Slither, a static analysis tool, to determine its capacity to identify them and assess their validity. The results show that each vulnerability has a different injection rate. Not all smart contracts can exhibit some vulnerabilities because they lack the prerequisites for injection. Furthermore, static analysis tools fail to detect all vulnerabilities injected using pattern-based mutations, underscoring the need for enhancements in static analyzers and demonstrating that benchmarks generated by mutation seeding tools can improve the evaluation of detection tools.","authors":["Gerardo Iuliano","Luigi Allocca","Matteo Cicalese","Dario Di Nucci"],"url":"https://arxiv.org/abs/2504.15948"}
{"created":"2025-04-23","title":"Structural Properties of Non-Linear Cellular Automata: Permutivity, Surjectivity and Reversibility","abstract":"This paper explores the algebraic conditions under which a cellular automaton with a non-linear local rule exhibits surjectivity and reversibility. We also analyze the role of permutivity as a key factor influencing these properties and provide conditions that determine whether a non-linear CA is (bi)permutive. Through theoretical results and illustrative examples, we characterize the relationships between these fundamental properties, offering new insights into the dynamical behavior of non-linear CA.","authors":["Firas Ben Ramdhane","Alberto Dennunzio","Luciano Margara","Giuliamaria Menara"],"url":"https://arxiv.org/abs/2504.15949"}
{"created":"2025-04-23","title":"Understanding the Role of Covariates in Numerical Reconstructions of Real-World Vehicle-to-Pedestrian Collisions","abstract":"Traumatic Brain Injuries (TBIs) are a pressing global public health issue, impacting tens of millions of individuals annually. Vulnerable road users (VRUs), such as pedestrians, are vastly overrepresented in the worldwide TBI statistics. To evaluate the effectiveness of injury prevention measures, researchers often employ Finite Element (FE) models of the human body to virtually simulate the human response to impact in real-world road traffic accident scenarios. However, VRU accidents occur in a highly uncontrolled environment and, in consequence, there is a large amount of variables (covariates), e.g. the vehicle impact speed and VRU body posture, that together dictate the injurious outcome of the collision. At the same time, since FE analysis is a computationally heavy task, researchers often need to apply extensive simplifications to FE models when attempting to predict real-world VRU head trauma. To help researchers make informed decisions when conducting FE accident reconstructions, this literature review aims to create an overarching summary of covariates that have been reported influential in literature. The review provides researchers with an overview of variables proven to have an influence on head injury predictions. The material could potentially be useful as a basis for choosing parameters to include when performing sensitivity analyses of car-to-pedestrian impact simulations.","authors":["Natalia Lindgren","Svein Kleiven","Xiaogai Li"],"url":"https://arxiv.org/abs/2504.15951"}
{"created":"2025-04-23","title":"Visual Place Cell Encoding: A Computational Model for Spatial Representation and Cognitive Mapping","abstract":"This paper presents the Visual Place Cell Encoding (VPCE) model, a biologically inspired computational framework for simulating place cell-like activation using visual input. Drawing on evidence that visual landmarks play a central role in spatial encoding, the proposed VPCE model activates visual place cells by clustering high-dimensional appearance features extracted from images captured by a robot-mounted camera. Each cluster center defines a receptive field, and activation is computed based on visual similarity using a radial basis function. We evaluate whether the resulting activation patterns correlate with key properties of biological place cells, including spatial proximity, orientation alignment, and boundary differentiation. Experiments demonstrate that the VPCE can distinguish between visually similar yet spatially distinct locations and adapt to environment changes such as the insertion or removal of walls. These results suggest that structured visual input, even in the absence of motion cues or reward-driven learning, is sufficient to generate place-cell-like spatial representations and support biologically inspired cognitive mapping.","authors":["Chance J. Hamilton","Alfredo Weitzenfeld"],"url":"https://arxiv.org/abs/2504.15953"}
{"created":"2025-04-23","title":"Monocular inspection of spacecraft under illumination constraints and avoidance regions","abstract":"This paper presents an adaptive control approach to information-based guidance and control of a spacecraft carrying out on-orbit inspection by actively computing optimal policies for the spacecraft to achieve the best possible representation of objects within its orbital environment. Due to the complexity of navigating the space environment, it may be impossible to carry out on-orbit servicing to maintain space systems like satellites using a spacecraft equipped with controllers that cannot adapt to changing conditions. In particular, the presence of constraints such as illumination, field-of-view (FOV), minimal fuel, the use of visual-inertial navigation for improved localization, and the need for real-time computation of control policies render the spacecraft motion planning problem challenging. The control framework developed in this paper addresses these challenges by formulating the inspection task as a constrained optimization problem where the goal is to maximize information gained from the cameras, while navigating to the next best view, subject to illumination and FOV constraints. The developed architecture is analyzed using a Lyapunov-based stability analysis and the effectiveness of the planning algorithm is verified in simulation.","authors":["Tochukwu Elijah Ogri","Muzaffar Qureshi","Zachary I. Bell","Matthew Longmire","Rushikesh Kamalapurkar"],"url":"https://arxiv.org/abs/2504.15954"}
{"created":"2025-04-23","title":"Universal Approximation with Softmax Attention","abstract":"We prove that with linear transformations, both (i) two-layer self-attention and (ii) one-layer self-attention followed by a softmax function are universal approximators for continuous sequence-to-sequence functions on compact domains. Our main technique is a new interpolation-based method for analyzing attention's internal mechanism. This leads to our key insight: self-attention is able to approximate a generalized version of ReLU to arbitrary precision, and hence subsumes many known universal approximators. Building on these, we show that two-layer multi-head attention alone suffices as a sequence-to-sequence universal approximator. In contrast, prior works rely on feed-forward networks to establish universal approximation in Transformers. Furthermore, we extend our techniques to show that, (softmax-)attention-only layers are capable of approximating various statistical models in-context. We believe these techniques hold independent interest.","authors":["Jerry Yao-Chieh Hu","Hude Liu","Hong-Yu Chen","Weimin Wu","Han Liu"],"url":"https://arxiv.org/abs/2504.15956"}
{"created":"2025-04-23","title":"FreeGraftor: Training-Free Cross-Image Feature Grafting for Subject-Driven Text-to-Image Generation","abstract":"Subject-driven image generation aims to synthesize novel scenes that faithfully preserve subject identity from reference images while adhering to textual guidance, yet existing methods struggle with a critical trade-off between fidelity and efficiency. Tuning-based approaches rely on time-consuming and resource-intensive subject-specific optimization, while zero-shot methods fail to maintain adequate subject consistency. In this work, we propose FreeGraftor, a training-free framework that addresses these limitations through cross-image feature grafting. Specifically, FreeGraftor employs semantic matching and position-constrained attention fusion to transfer visual details from reference subjects to the generated image. Additionally, our framework incorporates a novel noise initialization strategy to preserve geometry priors of reference subjects for robust feature matching. Extensive qualitative and quantitative experiments demonstrate that our method enables precise subject identity transfer while maintaining text-aligned scene synthesis. Without requiring model fine-tuning or additional training, FreeGraftor significantly outperforms existing zero-shot and training-free approaches in both subject fidelity and text alignment. Furthermore, our framework can seamlessly extend to multi-subject generation, making it practical for real-world deployment. Our code is available at https://github.com/Nihukat/FreeGraftor.","authors":["Zebin Yao","Lei Ren","Huixing Jiang","Chen Wei","Xiaojie Wang","Ruifan Li","Fangxiang Feng"],"url":"https://arxiv.org/abs/2504.15958"}
{"created":"2025-04-23","title":"The Value Problem for Multiple-Environment MDPs with Parity Objective","abstract":"We consider multiple-environment Markov decision processes (MEMDP), which consist of a finite set of MDPs over the same state space, representing different scenarios of transition structure and probability. The value of a strategy is the probability to satisfy the objective, here a parity objective, in the worst-case scenario, and the value of an MEMDP is the supremum of the values achievable by a strategy.","authors":["Krishnendu Chatterjee","Laurent Doyen","Jean-Fran\\c{c}ois Raskin","Ocan Sankur"],"url":"https://arxiv.org/abs/2504.15960"}
{"created":"2025-04-23","title":"Active Reconfigurable Intelligent Surface Assisted MIMO: Electromagnetic-Compliant Modeling with Mutual Coupling","abstract":"Reconfigurable Intelligent Surfaces (RIS) represent a transformative technology for sixth-generation (6G) wireless communications, but it suffers from a significant limitation, namely the double-fading attenuation. Active RIS has emerged as a promising solution, effectively mitigating the attenuation issues associated with conventional RIS-assisted systems. However, the current academic work on active RIS focuses on the system-level optimization of active RIS, often overlooking the development of models that are compatible with its electromagnetic (EM) and physical properties. The challenge of constructing realistic, EM-compliant models for active RIS-assisted communication, as well as understanding their implications on system-level optimization, remains an open research area. To tackle these problems, in this paper we develop a novel EM-compliant model with mutual coupling (MC) for active RIS-assisted wireless systems by integrating the developed scattering-parameter ($S$-parameter) based active RIS framework with multiport network theory, which facilitates system-level analysis and optimization. To evaluate the performance of the EM-compliant active RIS model, we design the joint optimization scheme based on the transmit beamforming at the transmitter and the reflection coefficient at the active RIS to maximize the achievable rate of EM-compliant active RIS-assisted MIMO system. To tackle the inherent non-convexity of this problem, we employ the Sherman-Morrison inversion and Neumann series (SMaN)-based alternating optimization (AO) algorithm. Simulation results verified that EM property (i.e., MC effect) is an indispensable factor in the optimization process of MIMO systems. Neglecting this effect introduces a substantial performance gap, highlighting its significance in the more pronounced the MC effect is, the greater the gap in achievable rates.","authors":["Yang Cao","Wenchi Cheng","Jingqing Wang","Wei Zhang"],"url":"https://arxiv.org/abs/2504.15961"}
{"created":"2025-04-23","title":"Blimp-based Crime Scene Analysis","abstract":"To tackle the crucial problem of crime, evidence at indoor crime scenes must be analyzed before it becomes contaminated or degraded. Here, as an application of artificial intelligence (AI), computer vision, and robotics, we explore how a blimp could be designed as a kind of \"floating camera\" to drift over and record evidence with minimal disturbance. In particular, rapid prototyping is used to develop a proof-of-concept to gain insight into what such blimps could do, manually piloted or semi-autonomously. As a result, we show the feasibility of attaching various components to an indoor blimp, and confirm our basic premise, that blimps can sense evidence without producing much wind. Some additional suggestions--regarding mapping, sensing, and path-finding--aim to stimulate the flow of ideas for further exploration.","authors":["Martin Cooney","Fernando Alonso-Fernandez"],"url":"https://arxiv.org/abs/2504.15962"}
{"created":"2025-04-23","title":"High order treatment of moving curved boundaries: Arbitrary-Lagrangian-Eulerian methods with a shifted boundary polynomials correction","abstract":"In this paper we present a novel approach for the prescription of high order boundary conditions when approximating the solution of the Euler equations for compressible gas dynamics on curved moving domains. When dealing with curved boundaries, the consistency of boundary conditions is a real challenge, and it becomes even more challenging in the context of moving domains discretized with high order Arbitrary-Lagrangian-Eulerian (ALE) schemes. The ALE formulation is particularly well-suited for handling moving and deforming domains, thus allowing for the simulation of complex fluid-structure interaction problems. However, if not properly treated, the imposition of boundary conditions can lead to significant errors in the numerical solution, which can spoil the high order discretization of the underlying mathematical model. In order to tackle this issue, we propose a new method based on the recently developed shifted boundary polynomial correction, which was originally proposed on fixed meshes. The new method is integrated into the space-time corrector step of a direct ALE finite volume method to account for the local curvature of the moving boundary by only exploiting the high order reconstruction polynomial of the finite volume control volume. It relies on a correction based on the extrapolated value of the cell polynomial evaluated at the true geometry, thus not requiring the explicit evaluation of high order Taylor series. This greatly simplifies the treatment of moving curved boundaries, as it allows for the use of standard simplicial meshes, which are much easier to generate and move than curvilinear ones, especially for 3D time-dependent problems. Several numerical experiments are presented demonstrating the high order convergence properties of the new method in the context of compressible flows in moving curved domains, which remain approximated by piecewise linear elements.","authors":["Walter Boscheri","Mirco Ciallella"],"url":"https://arxiv.org/abs/2504.15963"}
{"created":"2025-04-23","title":"From Human Memory to AI Memory: A Survey on Memory Mechanisms in the Era of LLMs","abstract":"Memory is the process of encoding, storing, and retrieving information, allowing humans to retain experiences, knowledge, skills, and facts over time, and serving as the foundation for growth and effective interaction with the world. It plays a crucial role in shaping our identity, making decisions, learning from past experiences, building relationships, and adapting to changes. In the era of large language models (LLMs), memory refers to the ability of an AI system to retain, recall, and use information from past interactions to improve future responses and interactions. Although previous research and reviews have provided detailed descriptions of memory mechanisms, there is still a lack of a systematic review that summarizes and analyzes the relationship between the memory of LLM-driven AI systems and human memory, as well as how we can be inspired by human memory to construct more powerful memory systems. To achieve this, in this paper, we propose a comprehensive survey on the memory of LLM-driven AI systems. In particular, we first conduct a detailed analysis of the categories of human memory and relate them to the memory of AI systems. Second, we systematically organize existing memory-related work and propose a categorization method based on three dimensions (object, form, and time) and eight quadrants. Finally, we illustrate some open problems regarding the memory of current AI systems and outline possible future directions for memory in the era of large language models.","authors":["Yaxiong Wu","Sheng Liang","Chen Zhang","Yichao Wang","Yongyue Zhang","Huifeng Guo","Ruiming Tang","Yong Liu"],"url":"https://arxiv.org/abs/2504.15965"}
{"created":"2025-04-23","title":"A UAV-Aided Digital Twin Framework for IoT Networks with High Accuracy and Synchronization","abstract":"With the continued growth of its core technologies, including the Internet of Things (IoT), artificial intelligence (AI), Big Data and data analytics, and edge computing, digital twin (DT) technology has witnessed a significant increase in industrial applications, helping the industry become more sustainable, smart, and adaptable. Hence, DT technology has emerged as a promising link between the physical and virtual worlds, enabling simulation, prediction, and real-time performance optimization. This work aims to explore the development of a high-fidelity digital twin framework, focusing on synchronization and accuracy between physical and digital systems to enhance data-driven decision making. To achieve this, we deploy several stationary UAVs in optimized locations to collect data from industrial IoT devices, which were used to monitor multiple physical entities and perform computations to evaluate their status. We consider a practical setup in which multiple IoT devices may monitor a single physical entity, and as a result, the measurements are combined and processed together to determine the status of the physical entity. The resulting status updates are subsequently uploaded from the UAVs to the base station, where the DT resides. In this work, we consider a novel metric based on the Age of Information (AoI), coined as the Age of Digital Twin (AoDT), to reflect the status freshness of the digital twin. Factoring AoDT in the problem formulation ensures that the DT reliably mirrors the physical system with high accuracy and synchronization. We formulate a mixed-integer non-convex program to maximize the total amount of data collected from all IoT devices while ensuring a constrained AoDT. Using successive convex approximations, we solve the problem, conduct extensive simulations and compare the results with baseline approaches to demonstrate the effectiveness of the proposed solution.","authors":["Ghofran Khalaf","May Itani","Sanaa Sharafeddine"],"url":"https://arxiv.org/abs/2504.15967"}
{"created":"2025-04-23","title":"Recent Advances and Future Directions in Extended Reality (XR): Exploring AI-Powered Spatial Intelligence","abstract":"Extended Reality (XR), encompassing Augmented Reality (AR), Virtual Reality (VR) and Mixed Reality (MR), is a transformative technology bridging the physical and virtual world and it has diverse potential which will be ubiquitous in the future. This review examines XR's evolution through foundational framework - hardware ranging from monitors to sensors and software ranging from visual tasks to user interface; highlights state of the art (SOTA) XR products with the comparison and analysis of performance based on their foundational framework; discusses how commercial XR devices can support the demand of high-quality performance focusing on spatial intelligence. For future directions, attention should be given to the integration of multi-modal AI and IoT-driven digital twins to enable adaptive XR systems. With the concept of spatial intelligence, future XR should establish a new digital space with realistic experience that benefits humanity. This review underscores the pivotal role of AI in unlocking XR as the next frontier in human-computer interaction.","authors":["Baichuan Zeng"],"url":"https://arxiv.org/abs/2504.15970"}
{"created":"2025-04-23","title":"Bug Destiny Prediction in Large Open-Source Software Repositories through Sentiment Analysis and BERT Topic Modeling","abstract":"This study explores a novel approach to predicting key bug-related outcomes, including the time to resolution, time to fix, and ultimate status of a bug, using data from the Bugzilla Eclipse Project. Specifically, we leverage features available before a bug is resolved to enhance predictive accuracy. Our methodology incorporates sentiment analysis to derive both an emotionality score and a sentiment classification (positive or negative). Additionally, we integrate the bug's priority level and its topic, extracted using a BERTopic model, as features for a Convolutional Neural Network (CNN) and a Multilayer Perceptron (MLP). Our findings indicate that the combination of BERTopic and sentiment analysis can improve certain model performance metrics. Furthermore, we observe that balancing model inputs enhances practical applicability, albeit at the cost of a significant reduction in accuracy in most cases. To address our primary objectives, predicting time-to-resolution, time-to-fix, and bug destiny, we employ both binary classification and exact time value predictions, allowing for a comparative evaluation of their predictive effectiveness. Results demonstrate that sentiment analysis serves as a valuable predictor of a bug's eventual outcome, particularly in determining whether it will be fixed. However, its utility is less pronounced when classifying bugs into more complex or unconventional outcome categories.","authors":["Sophie C. Pope","Andrew Barovic","Armin Moin"],"url":"https://arxiv.org/abs/2504.15972"}
{"created":"2025-04-23","title":"A New Graph Grammar Formalism for Robust Syntactic Pattern Recognition","abstract":"I introduce a formalism for representing the syntax of recursively structured graph-like patterns. It does not use production rules, like a conventional graph grammar, but represents the syntactic structure in a more direct and declarative way. The grammar and the pattern are both represented as networks, and parsing is seen as the construction of a homomorphism from the pattern to the grammar. The grammars can represent iterative, hierarchical and nested recursive structure in more than one dimension.","authors":["Peter Fletcher"],"url":"https://arxiv.org/abs/2504.15975"}
{"created":"2025-04-23","title":"ad-trait: A Fast and Flexible Automatic Differentiation Library in Rust","abstract":"The Rust programming language is an attractive choice for robotics and related fields, offering highly efficient and memory-safe code. However, a key limitation preventing its broader adoption in these domains is the lack of high-quality, well-supported Automatic Differentiation (AD)-a fundamental technique that enables convenient derivative computation by systematically accumulating data during function evaluation. In this work, we introduce ad-trait, a new Rust-based AD library. Our implementation overloads Rust's standard floating-point type with a flexible trait that can efficiently accumulate necessary information for derivative computation. The library supports both forward-mode and reverse-mode automatic differentiation, making it the first operator-overloading AD implementation in Rust to offer both options. Additionally, ad-trait leverages Rust's performance-oriented features, such as Single Instruction, Multiple Data acceleration in forward-mode AD, to enhance efficiency. Through benchmarking experiments, we show that our library is among the fastest AD implementations across several programming languages for computing derivatives. Moreover, it is already integrated into a Rust-based robotics library, where we showcase its ability to facilitate fast optimization procedures. We conclude with a discussion of the limitations and broader implications of our work.","authors":["Chen Liang","Qian Wang","Andy Xu","Daniel Rakita"],"url":"https://arxiv.org/abs/2504.15976"}
{"created":"2025-04-23","title":"Efficient Discovery of Motif Transition Process for Large-Scale Temporal Graphs","abstract":"Understanding the dynamic transition of motifs in temporal graphs is essential for revealing how graph structures evolve over time, identifying critical patterns, and predicting future behaviors, yet existing methods often focus on predefined motifs, limiting their ability to comprehensively capture transitions and interrelationships. We propose a parallel motif transition process discovery algorithm, PTMT, a novel parallel method for discovering motif transition processes in large-scale temporal graphs. PTMT integrates a tree-based framework with the temporal zone partitioning (TZP) strategy, which partitions temporal graphs by time and structure while preserving lossless motif transitions and enabling massive parallelism. PTMT comprises three phases: growth zone parallel expansion, overlap-aware result aggregation, and deterministic encoding of motif transitions, ensuring accurate tracking of dynamic transitions and interactions. Results on 10 real-world datasets demonstrate that PTMT achieves speedups ranging from 12.0$\\times$ to 50.3$\\times$ compared to the SOTA method.","authors":["Zhiyuan Zheng","Jianpeng Qi","Jiantao Li","Guoqing Chao","Junyu Dong","Yanwei Yu"],"url":"https://arxiv.org/abs/2504.15979"}
{"created":"2025-04-23","title":"W-PCA Based Gradient-Free Proxy for Efficient Search of Lightweight Language Models","abstract":"The demand for efficient natural language processing (NLP) systems has led to the development of lightweight language models. Previous work in this area has primarily focused on manual design or training-based neural architecture search (NAS) methods. Recently, zero-shot NAS methods have been proposed for evaluating language models without the need for training. However, prevailing approaches to zero-shot NAS often face challenges such as biased evaluation metrics and computational inefficiencies. In this paper, we introduce weight-weighted PCA (W-PCA), a novel zero-shot NAS method specifically tailored for lightweight language models. Our approach utilizes two evaluation proxies: the parameter count and the number of principal components with cumulative contribution exceeding $\\eta$ in the feed-forward neural (FFN) layer. Additionally, by eliminating the need for gradient computations, we optimize the evaluation time, thus enhancing the efficiency of designing and evaluating lightweight language models. We conduct a comparative analysis on the GLUE and SQuAD datasets to evaluate our approach. The results demonstrate that our method significantly reduces training time compared to one-shot NAS methods and achieves higher scores in the testing phase compared to previous state-of-the-art training-based methods. Furthermore, we perform ranking evaluations on a dataset sampled from the FlexiBERT search space. Our approach exhibits superior ranking correlation and further reduces solving time compared to other zero-shot NAS methods that require gradient computation.","authors":["Shang Wang"],"url":"https://arxiv.org/abs/2504.15983"}
{"created":"2025-04-23","title":"Neuroadaptive Haptics: Comparing Reinforcement Learning from Explicit Ratings and Neural Signals for Adaptive XR Systems","abstract":"Neuroadaptive haptics offers a path to more immersive extended reality (XR) experiences by dynamically tuning multisensory feedback to user preferences. We present a neuroadaptive haptics system that adapts XR feedback through reinforcement learning (RL) from explicit user ratings and brain-decoded neural signals. In a user study, participants interacted with virtual objects in VR while Electroencephalography (EEG) data were recorded. An RL agent adjusted haptic feedback based either on explicit ratings or on outputs from a neural decoder. Results show that the RL agent's performance was comparable across feedback sources, suggesting that implicit neural feedback can effectively guide personalization without requiring active user input. The EEG-based neural decoder achieved a mean F1 score of 0.8, supporting reliable classification of user experience. These findings demonstrate the feasibility of combining brain-computer interfaces (BCI) and RL to autonomously adapt XR interactions, reducing cognitive load and enhancing immersion.","authors":["Lukas Gehrke","Aleksandrs Koselevsk","Marius Klug","Klaus Gramann"],"url":"https://arxiv.org/abs/2504.15984"}
{"created":"2025-04-23","title":"Charting the Uncharted: The Landscape of Monero Peer-to-Peer Network","abstract":"The Monero blockchain enables anonymous transactions through advanced cryptography in its peer-to-peer network, which underpins decentralization, security, and trustless interactions. However, privacy measures obscure peer connections, complicating network analysis. This study proposes a method to infer peer connections in Monero's latest protocol version, where timestamp data is unavailable. We collect peerlist data from TCP flows, validate our inference algorithm, and map the network structure. Our results show high accuracy, improving with longer observation periods. This work is the first to reveal connectivity patterns in Monero's updated protocol, providing visualizations and insights into its topology. Our findings enhance the understanding of Monero's P2P network, including the role of supernodes, and highlight potential protocol and security improvements.","authors":["Yu Gao","Matija Pi\\v{s}korec","Yu Zhang","Nicol\\`o Vallarano","Claudio J. Tessone"],"url":"https://arxiv.org/abs/2504.15986"}
{"created":"2025-04-23","title":"Few-shot Hate Speech Detection Based on the MindSpore Framework","abstract":"The proliferation of hate speech on social media poses a significant threat to online communities, requiring effective detection systems. While deep learning models have shown promise, their performance often deteriorates in few-shot or low-resource settings due to reliance on large annotated corpora. To address this, we propose MS-FSLHate, a prompt-enhanced neural framework for few-shot hate speech detection implemented on the MindSpore deep learning platform. The model integrates learnable prompt embeddings, a CNN-BiLSTM backbone with attention pooling, and synonym-based adversarial data augmentation to improve generalization. Experimental results on two benchmark datasets-HateXplain and HSOL-demonstrate that our approach outperforms competitive baselines in precision, recall, and F1-score. Additionally, the framework shows high efficiency and scalability, suggesting its suitability for deployment in resource-constrained environments. These findings highlight the potential of combining prompt-based learning with adversarial augmentation for robust and adaptable hate speech detection in few-shot scenarios.","authors":["Zhenkai Qin","Dongze Wu","Yuxin Liu","Guifang Yang"],"url":"https://arxiv.org/abs/2504.15987"}
{"created":"2025-04-23","title":"Token-Aware Coding Flow: A Study with Nano Surge in Reasoning Model","abstract":"With the widespread application of large-scale language models (LLMs) in software engineering, the Chain of Thought (CoT) approach has emerged as a crucial tool for driving automated code generation and optimization. However, despite the significant success of CoT methods in generating high-quality code, the issue of token inflation during the reasoning process remains a formidable challenge to model performance and efficiency, particularly when dealing with complex code smells. Code smells not only affect the maintainability and scalability of code but also significantly increase the computational burden during LLM inference, leading to excessive token consumption and, consequently, reduced reasoning efficiency. This paper introduces an innovative Token-Aware Coding Flow method, aimed at addressing the token inflation problem caused by smelly code in the CoT process. Through experimentation, we validate the synergistic effect of code refactoring and prompt engineering strategies, demonstrating that after eliminating code smells, token consumption during model inference is significantly reduced. The experimental results show that refactored code, while maintaining functional consistency, can reduce token consumption by up to 50\\%. Additionally, by explicitly prompting the type of code smells in the prompt and incorporating strategies such as context awareness and role constraints, we further optimize the reasoning process, achieving a 24.5\\% to 30\\% reduction in token consumption. These optimizations not only significantly enhance the model's reasoning efficiency and improve code generation quality but also provide new insights for addressing performance bottlenecks in complex code generation tasks.","authors":["Junwei Hu","Weicheng Zheng","Yan Liu","Yihan Liu"],"url":"https://arxiv.org/abs/2504.15989"}
{"created":"2025-04-23","title":"Efficient Adaptation of Deep Neural Networks for Semantic Segmentation in Space Applications","abstract":"In recent years, the application of Deep Learning techniques has shown remarkable success in various computer vision tasks, paving the way for their deployment in extraterrestrial exploration. Transfer learning has emerged as a powerful strategy for addressing the scarcity of labeled data in these novel environments. This paper represents one of the first efforts in evaluating the feasibility of employing adapters toward efficient transfer learning for rock segmentation in extraterrestrial landscapes, mainly focusing on lunar and martian terrains. Our work suggests that the use of adapters, strategically integrated into a pre-trained backbone model, can be successful in reducing both bandwidth and memory requirements for the target extraterrestrial device. In this study, we considered two memory-saving strategies: layer fusion (to reduce to zero the inference overhead) and an ``adapter ranking'' (to also reduce the transmission cost). Finally, we evaluate these results in terms of task performance, memory, and computation on embedded devices, evidencing trade-offs that open the road to more research in the field.","authors":["Leonardo Olivi","Edoardo Santero Mormile","Enzo Tartaglione"],"url":"https://arxiv.org/abs/2504.15991"}
{"created":"2025-04-23","title":"OPUS-VFL: Incentivizing Optimal Privacy-Utility Tradeoffs in Vertical Federated Learning","abstract":"Vertical Federated Learning (VFL) enables organizations with disjoint feature spaces but shared user bases to collaboratively train models without sharing raw data. However, existing VFL systems face critical limitations: they often lack effective incentive mechanisms, struggle to balance privacy-utility tradeoffs, and fail to accommodate clients with heterogeneous resource capabilities. These challenges hinder meaningful participation, degrade model performance, and limit practical deployment. To address these issues, we propose OPUS-VFL, an Optimal Privacy-Utility tradeoff Strategy for VFL. OPUS-VFL introduces a novel, privacy-aware incentive mechanism that rewards clients based on a principled combination of model contribution, privacy preservation, and resource investment. It employs a lightweight leave-one-out (LOO) strategy to quantify feature importance per client, and integrates an adaptive differential privacy mechanism that enables clients to dynamically calibrate noise levels to optimize their individual utility. Our framework is designed to be scalable, budget-balanced, and robust to inference and poisoning attacks. Extensive experiments on benchmark datasets (MNIST, CIFAR-10, and CIFAR-100) demonstrate that OPUS-VFL significantly outperforms state-of-the-art VFL baselines in both efficiency and robustness. It reduces label inference attack success rates by up to 20%, increases feature inference reconstruction error (MSE) by over 30%, and achieves up to 25% higher incentives for clients that contribute meaningfully while respecting privacy and cost constraints. These results highlight the practicality and innovation of OPUS-VFL as a secure, fair, and performance-driven solution for real-world VFL.","authors":["Sindhuja Madabushi","Ahmad Faraz Khan","Haider Ali","Jin-Hee Cho"],"url":"https://arxiv.org/abs/2504.15995"}
{"created":"2025-04-23","title":"MVQA: Mamba with Unified Sampling for Efficient Video Quality Assessment","abstract":"The rapid growth of long-duration, high-definition videos has made efficient video quality assessment (VQA) a critical challenge. Existing research typically tackles this problem through two main strategies: reducing model parameters and resampling inputs. However, light-weight Convolution Neural Networks (CNN) and Transformers often struggle to balance efficiency with high performance due to the requirement of long-range modeling capabilities. Recently, the state-space model, particularly Mamba, has emerged as a promising alternative, offering linear complexity with respect to sequence length. Meanwhile, efficient VQA heavily depends on resampling long sequences to minimize computational costs, yet current resampling methods are often weak in preserving essential semantic information. In this work, we present MVQA, a Mamba-based model designed for efficient VQA along with a novel Unified Semantic and Distortion Sampling (USDS) approach. USDS combines semantic patch sampling from low-resolution videos and distortion patch sampling from original-resolution videos. The former captures semantically dense regions, while the latter retains critical distortion details. To prevent computation increase from dual inputs, we propose a fusion mechanism using pre-defined masks, enabling a unified sampling strategy that captures both semantic and quality information without additional computational burden. Experiments show that the proposed MVQA, equipped with USDS, achieve comparable performance to state-of-the-art methods while being $2\\times$ as fast and requiring only $1/5$ GPU memory.","authors":["Yachun Mi","Yu Li","Weicheng Meng","Chaofeng Chen","Chen Hui","Shaohui Liu"],"url":"https://arxiv.org/abs/2504.16003"}
{"created":"2025-04-23","title":"CAPO: Cost-Aware Prompt Optimization","abstract":"Large language models (LLMs) have revolutionized natural language processing by solving a wide range of tasks simply guided by a prompt. Yet their performance is highly sensitive to prompt formulation. While automated prompt optimization addresses this challenge by finding optimal prompts, current methods require a substantial number of LLM calls and input tokens, making prompt optimization expensive. We introduce CAPO (Cost-Aware Prompt Optimization), an algorithm that enhances prompt optimization efficiency by integrating AutoML techniques. CAPO is an evolutionary approach with LLMs as operators, incorporating racing to save evaluations and multi-objective optimization to balance performance with prompt length. It jointly optimizes instructions and few-shot examples while leveraging task descriptions for improved robustness. Our extensive experiments across diverse datasets and LLMs demonstrate that CAPO outperforms state-of-the-art discrete prompt optimization methods in 11/15 cases with improvements up to 21%p. Our algorithm achieves better performances already with smaller budgets, saves evaluations through racing, and decreases average prompt length via a length penalty, making it both cost-efficient and cost-aware. Even without few-shot examples, CAPO outperforms its competitors and generally remains robust to initial prompts. CAPO represents an important step toward making prompt optimization more powerful and accessible by improving cost-efficiency.","authors":["Tom Zehle","Moritz Schlager","Timo Hei{\\ss}","Matthias Feurer"],"url":"https://arxiv.org/abs/2504.16005"}
{"created":"2025-04-23","title":"Methods for Recognizing Nested Terms","abstract":"In this paper, we describe our participation in the RuTermEval competition devoted to extracting nested terms. We apply the Binder model, which was previously successfully applied to the recognition of nested named entities, to extract nested terms. We obtained the best results of term recognition in all three tracks of the RuTermEval competition. In addition, we study the new task of recognition of nested terms from flat training data annotated with terms without nestedness. We can conclude that several approaches we proposed in this work are viable enough to retrieve nested terms effectively without nested labeling of them.","authors":["Igor Rozhkov","Natalia Loukachevitch"],"url":"https://arxiv.org/abs/2504.16007"}
{"created":"2025-04-23","title":"The Formation of Production Networks: How Supply Chains Arise from Simple Learning with Minimal Information","abstract":"We develop a model where firms determine the price at which they sell their differentiable goods, the volume that they produce, and the inputs (types and amounts) that they purchase from other firms. A steady-state production network emerges endogenously without resorting to assumptions such as equilibrium or perfect knowledge about production technologies. Through a simple version of reinforcement learning, firms with heterogeneous technologies cope with uncertainty and maximize profits. Due to this learning process, firms can adapt to shocks such as demand shifts, suppliers/clients closure, productivity changes, and production technology modifications; effectively reshaping the production network. To demonstrate the potential of this model, we analyze the upstream and downstream impact of demand and productivity shocks.","authors":["Tuong Manh Vu","Ernesto Carrella","Robert Axtell","Omar A. Guerrero"],"url":"https://arxiv.org/abs/2504.16010"}
{"created":"2025-04-23","title":"Interpolation error analysis using a new geometric parameter","abstract":"This article presents novel proof methods for estimating interpolation errors, predicated on the understanding that one has already studied foundational error analysis using the finite element method.","authors":["Hiroki Ishizaka"],"url":"https://arxiv.org/abs/2504.16012"}
{"created":"2025-04-23","title":"Efficient Temporal Consistency in Diffusion-Based Video Editing with Adaptor Modules: A Theoretical Framework","abstract":"Adapter-based methods are commonly used to enhance model performance with minimal additional complexity, especially in video editing tasks that require frame-to-frame consistency. By inserting small, learnable modules into pretrained diffusion models, these adapters can maintain temporal coherence without extensive retraining. Approaches that incorporate prompt learning with both shared and frame-specific tokens are particularly effective in preserving continuity across frames at low training cost. In this work, we want to provide a general theoretical framework for adapters that maintain frame consistency in DDIM-based models under a temporal consistency loss. First, we prove that the temporal consistency objective is differentiable under bounded feature norms, and we establish a Lipschitz bound on its gradient. Second, we show that gradient descent on this objective decreases the loss monotonically and converges to a local minimum if the learning rate is within an appropriate range. Finally, we analyze the stability of modules in the DDIM inversion procedure, showing that the associated error remains controlled. These theoretical findings will reinforce the reliability of diffusion-based video editing methods that rely on adapter strategies and provide theoretical insights in video generation tasks.","authors":["Xinyuan Song","Yangfan He","Sida Li","Jianhui Wang","Hongyang He","Xinhang Yuan","Ruoyu Wang","Jiaqi Chen","Keqin Li","Kuan Lu","Menghao Huo","Binxu Li","Pei Liu"],"url":"https://arxiv.org/abs/2504.16016"}
{"created":"2025-04-23","title":"AlphaGrad: Non-Linear Gradient Normalization Optimizer","abstract":"We introduce AlphaGrad, a memory-efficient, conditionally stateless optimizer addressing the memory overhead and hyperparameter complexity of adaptive methods like Adam. AlphaGrad enforces scale invariance via tensor-wise L2 gradient normalization followed by a smooth hyperbolic tangent transformation, $g' = \\tanh(\\alpha \\cdot \\tilde{g})$, controlled by a single steepness parameter $\\alpha$. Our contributions include: (1) the AlphaGrad algorithm formulation; (2) a formal non-convex convergence analysis guaranteeing stationarity; (3) extensive empirical evaluation on diverse RL benchmarks (DQN, TD3, PPO). Compared to Adam, AlphaGrad demonstrates a highly context-dependent performance profile. While exhibiting instability in off-policy DQN, it provides enhanced training stability with competitive results in TD3 (requiring careful $\\alpha$ tuning) and achieves substantially superior performance in on-policy PPO. These results underscore the critical importance of empirical $\\alpha$ selection, revealing strong interactions between the optimizer's dynamics and the underlying RL algorithm. AlphaGrad presents a compelling alternative optimizer for memory-constrained scenarios and shows significant promise for on-policy learning regimes where its stability and efficiency advantages can be particularly impactful.","authors":["Soham Sane"],"url":"https://arxiv.org/abs/2504.16020"}
{"created":"2025-04-23","title":"Navigating the State of Cognitive Flow: Context-Aware AI Interventions for Effective Reasoning Support","abstract":"Flow theory describes an optimal cognitive state where individuals experience deep focus and intrinsic motivation when a task's difficulty aligns with their skill level. In AI-augmented reasoning, interventions that disrupt the state of cognitive flow can hinder rather than enhance decision-making. This paper proposes a context-aware cognitive augmentation framework that adapts interventions based on three key contextual factors: type, timing, and scale. By leveraging multimodal behavioral cues (e.g., gaze behavior, typing hesitation, interaction speed), AI can dynamically adjust cognitive support to maintain or restore flow. We introduce the concept of cognitive flow, an extension of flow theory in AI-augmented reasoning, where interventions are personalized, adaptive, and minimally intrusive. By shifting from static interventions to context-aware augmentation, our approach ensures that AI systems support deep engagement in complex decision-making and reasoning without disrupting cognitive immersion.","authors":["Dinithi Dissanayake","Suranga Nanayakkara"],"url":"https://arxiv.org/abs/2504.16021"}
{"created":"2025-04-23","title":"PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud Learning","abstract":"Self-supervised representation learning for point cloud has demonstrated effectiveness in improving pre-trained model performance across diverse tasks. However, as pre-trained models grow in complexity, fully fine-tuning them for downstream applications demands substantial computational and storage resources. Parameter-efficient fine-tuning (PEFT) methods offer a promising solution to mitigate these resource requirements, yet most current approaches rely on complex adapter and prompt mechanisms that increase tunable parameters. In this paper, we propose PointLoRA, a simple yet effective method that combines low-rank adaptation (LoRA) with multi-scale token selection to efficiently fine-tune point cloud models. Our approach embeds LoRA layers within the most parameter-intensive components of point cloud transformers, reducing the need for tunable parameters while enhancing global feature capture. Additionally, multi-scale token selection extracts critical local information to serve as prompts for downstream fine-tuning, effectively complementing the global context captured by LoRA. The experimental results across various pre-trained models and three challenging public datasets demonstrate that our approach achieves competitive performance with only 3.43% of the trainable parameters, making it highly effective for resource-constrained applications. Source code is available at: https://github.com/songw-zju/PointLoRA.","authors":["Song Wang","Xiaolu Liu","Lingdong Kong","Jianyun Xu","Chunyong Hu","Gongfan Fang","Wentong Li","Jianke Zhu","Xinchao Wang"],"url":"https://arxiv.org/abs/2504.16023"}
{"created":"2025-04-23","title":"Trends in AI Supercomputers","abstract":"Frontier AI development relies on powerful AI supercomputers, yet analysis of these systems is limited. We create a dataset of 500 AI supercomputers from 2019 to 2025 and analyze key trends in performance, power needs, hardware cost, ownership, and global distribution. We find that the computational performance of AI supercomputers has doubled every nine months, while hardware acquisition cost and power needs both doubled every year. The leading system in March 2025, xAI's Colossus, used 200,000 AI chips, had a hardware cost of \\$7B, and required 300 MW of power, as much as 250,000 households. As AI supercomputers evolved from tools for science to industrial machines, companies rapidly expanded their share of total AI supercomputer performance, while the share of governments and academia diminished. Globally, the United States accounts for about 75% of total performance in our dataset, with China in second place at 15%. If the observed trends continue, the leading AI supercomputer in 2030 will achieve $2\\times10^{22}$ 16-bit FLOP/s, use two million AI chips, have a hardware cost of \\$200 billion, and require 9 GW of power. Our analysis provides visibility into the AI supercomputer landscape, allowing policymakers to assess key AI trends like resource needs, ownership, and national competitiveness.","authors":["Konstantin F. Pilz","James Sanders","Robi Rahman","Lennart Heim"],"url":"https://arxiv.org/abs/2504.16026"}
{"created":"2025-04-23","title":"Benchmarking LLM for Code Smells Detection: OpenAI GPT-4.0 vs DeepSeek-V3","abstract":"Determining the most effective Large Language Model for code smell detection presents a complex challenge. This study introduces a structured methodology and evaluation matrix to tackle this issue, leveraging a curated dataset of code samples consistently annotated with known smells. The dataset spans four prominent programming languages Java, Python, JavaScript, and C++; allowing for cross language comparison. We benchmark two state of the art LLMs, OpenAI GPT 4.0 and DeepSeek-V3, using precision, recall, and F1 score as evaluation metrics. Our analysis covers three levels of detail: overall performance, category level performance, and individual code smell type performance. Additionally, we explore cost effectiveness by comparing the token based detection approach of GPT 4.0 with the pattern-matching techniques employed by DeepSeek V3. The study also includes a cost analysis relative to traditional static analysis tools such as SonarQube. The findings offer valuable guidance for practitioners in selecting an efficient, cost effective solution for automated code smell detection","authors":["Ahmed R. Sadik","Siddhata Govind"],"url":"https://arxiv.org/abs/2504.16027"}
{"created":"2025-04-23","title":"Hessian Riemannian Flow For Multi-Population Wardrop Equilibrium","abstract":"In this paper, we address the problem of optimizing flows on generalized graphs that feature multiple entry points and multiple populations, each with varying cost structures. We tackle this problem by considering the multi-population Wardrop equilibrium, defined through variational inequalities. We rigorously analyze the existence and uniqueness of the Wardrop equilibrium. Furthermore, we introduce an efficient numerical method to find the solution. In particular, we reformulate the equilibrium problem as a distributed optimization problem over subgraphs and introduce a novel Hessian Riemannian flow method, a Riemannian-manifold-projected Hessian flow, to efficiently compute a solution. Finally, we demonstrate the effectiveness of our approach through examples in urban traffic management, including routing for diverse vehicle types and strategies for minimizing emissions in congested environments.","authors":["Tigran Bakaryan","Christoph Aoun","Ricardo de Lima Ribeiro","Naira Hovakimyan","Diogo Gomes"],"url":"https://arxiv.org/abs/2504.16028"}
{"created":"2025-04-23","title":"Bayesian Parameter Identification in the Landau-de Gennes Theory for Nematic Liquid Crystals","abstract":"This manuscript establishes a pathway to reconstruct material parameters from measurements within the Landau-de Gennes model for nematic liquid crystals. We present a Bayesian approach to this inverse problem and analyse its properties using given, simulated data for benchmark problems of a planar bistable nematic device. In particular, we discuss the accuracy of the Markov chain Monte Carlo approximations, confidence intervals and the limits of identifiability.","authors":["Heiko Gimperlein","Ruma R. Maity","Apala Majumdar","Michael Oberguggenberger"],"url":"https://arxiv.org/abs/2504.16029"}
{"created":"2025-04-23","title":"LiveCC: Learning Video LLM with Streaming Speech Transcription at Scale","abstract":"Recent video large language models (Video LLMs) often depend on costly human annotations or proprietary model APIs (e.g., GPT-4o) to produce training data, which limits their training at scale. In this paper, we explore large-scale training for Video LLM with cheap automatic speech recognition (ASR) transcripts. Specifically, we propose a novel streaming training approach that densely interleaves the ASR words and video frames according to their timestamps. Compared to previous studies in vision-language representation with ASR, our method naturally fits the streaming characteristics of ASR, thus enabling the model to learn temporally-aligned, fine-grained vision-language modeling. To support the training algorithm, we introduce a data production pipeline to process YouTube videos and their closed captions (CC, same as ASR), resulting in Live-CC-5M dataset for pre-training and Live-WhisperX-526K dataset for high-quality supervised fine-tuning (SFT). Remarkably, even without SFT, the ASR-only pre-trained LiveCC-7B-Base model demonstrates competitive general video QA performance and exhibits a new capability in real-time video commentary. To evaluate this, we carefully design a new LiveSports-3K benchmark, using LLM-as-a-judge to measure the free-form commentary. Experiments show our final LiveCC-7B-Instruct model can surpass advanced 72B models (Qwen2.5-VL-72B-Instruct, LLaVA-Video-72B) in commentary quality even working in a real-time mode. Meanwhile, it achieves state-of-the-art results at the 7B/8B scale on popular video QA benchmarks such as VideoMME and OVOBench, demonstrating the broad generalizability of our approach. All resources of this paper have been released at https://showlab.github.io/livecc.","authors":["Joya Chen","Ziyun Zeng","Yiqi Lin","Wei Li","Zejun Ma","Mike Zheng Shou"],"url":"https://arxiv.org/abs/2504.16030"}
{"created":"2025-04-23","title":"VR-based Intervention for Perspective Change: A Case to Investigate Virtual Materiality","abstract":"This paper addresses the concept of materiality in virtual environments, which we define as being composed of objects that can influence user experience actively. Such virtual materiality is closely related to its physical counterpart, which is discussed in theoretical frameworks such as sociomateriality and actor-network theory. They define phenomena in terms of the entanglement of human and non-human elements. We report on an early investigation of virtual materiality within the context of reflection and perspective change in nature-based virtual environments. We considered the case of university students reflecting on the planning and management of their theses and major projects. Inspired by nature's known positive cognitive and affective effects and repeated questioning processes, we established a virtual reflection intervention to demonstrate the environmental mechanisms and material characteristics relevant to virtual materiality. Our work is a preliminary step toward understanding virtual materiality and its implications for research and the design of virtual environments.","authors":["Ali Arya","Anthony Scavarelli","Dan Hawes","Luciara Nardon"],"url":"https://arxiv.org/abs/2504.16031"}
{"created":"2025-04-23","title":"LLMs meet Federated Learning for Scalable and Secure IoT Management","abstract":"The rapid expansion of IoT ecosystems introduces severe challenges in scalability, security, and real-time decision-making. Traditional centralized architectures struggle with latency, privacy concerns, and excessive resource consumption, making them unsuitable for modern large-scale IoT deployments. This paper presents a novel Federated Learning-driven Large Language Model (FL-LLM) framework, designed to enhance IoT system intelligence while ensuring data privacy and computational efficiency. The framework integrates Generative IoT (GIoT) models with a Gradient Sensing Federated Strategy (GSFS), dynamically optimizing model updates based on real-time network conditions. By leveraging a hybrid edge-cloud processing architecture, our approach balances intelligence, scalability, and security in distributed IoT environments. Evaluations on the IoT-23 dataset demonstrate that our framework improves model accuracy, reduces response latency, and enhances energy efficiency, outperforming traditional FL techniques (i.e., FedAvg, FedOpt). These findings highlight the potential of integrating LLM-powered federated learning into large-scale IoT ecosystems, paving the way for more secure, scalable, and adaptive IoT management solutions.","authors":["Yazan Otoum","Arghavan Asad","Amiya Nayak"],"url":"https://arxiv.org/abs/2504.16032"}
{"created":"2025-04-23","title":"Adaptive Fault-tolerant Control of Underwater Vehicles with Thruster Failures","abstract":"This paper presents a fault-tolerant control for the trajectory tracking of autonomous underwater vehicles (AUVs) against thruster failures. We formulate faults in AUV thrusters as discrete switching events during a UAV mission, and develop a soft-switching approach in facilitating shift of control strategies across fault scenarios. We mathematically define AUV thruster fault scenarios, and develop the fault-tolerant control that captures the fault scenario via Bayesian approach. Particularly, when the AUV fault type switches from one to another, the developed control captures the fault states and maintains the control by a linear quadratic tracking controller. With the captured fault states by Bayesian approach, we derive the control law by aggregating the control outputs for individual fault scenarios weighted by their Bayesian posterior probability. The developed fault-tolerant control works in an adaptive way and guarantees soft-switching across fault scenarios, and requires no complicated fault detection dedicated to different type of faults. The entailed soft-switching ensures stable AUV trajectory tracking when fault type shifts, which otherwise leads to reduced control under hard-switching control strategies. We conduct numerical simulations with diverse AUV thruster fault settings. The results demonstrate that the proposed control can provide smooth transition across thruster failures, and effectively sustain AUV trajectory tracking control in case of thruster failures and failure shifts.","authors":["Haolin Liu","Shiliang Zhang","Shangbin Jiao","Xiaohui Zhang","Xuehui Ma","Yan Yan","Wenchuan Cui","Youmin Zhang"],"url":"https://arxiv.org/abs/2504.16037"}
{"created":"2025-04-23","title":"A Comparative and Measurement-Based Study on Real-Time Network KPI Extraction Methods for 5G and Beyond Applications","abstract":"Key performance indicators (KPIs), which can be extracted from the standardized interfaces of network equipment defined by current standards, constitute a primary data source that can be leveraged in the development of non-standardized new equipment, architectures, and computational tools. In next-generation technologies, the demand for data has evolved beyond the conventional log generation or export capabilities provided by existing licensed network monitoring tools. There is now a growing need to collect such data at specific time intervals and with defined granularities. At this stage, the development of real-time KPI extraction methods and enabling their exchange between both standardized/commercialized and non-standardized components or tools has become increasingly critical. This study presents a comprehensive evaluation of three distinct KPI extraction methodologies applied to two commercially available devices. The analysis aims to uncover the strengths, weaknesses, and overall efficacy of these approaches under varying conditions, and highlights the critical insights into the practical capabilities and limitations. The findings serve as a foundational guide for the seamless integration and robust testing of novel technologies and approaches within commercial telecommunication networks. This work aspires to bridge the gap between technological innovation and real-world applicability, fostering enhanced decision-making in network deployment and optimization.","authors":["Batuhan Kaplan","Samed Ke\\c{s}\\.ir","Ahmet Faruk Co\\c{s}kun"],"url":"https://arxiv.org/abs/2504.16039"}
{"created":"2025-04-23","title":"Muon Optimizer Accelerates Grokking","abstract":"This paper investigates the impact of different optimizers on the grokking phenomenon, where models exhibit delayed generalization. We conducted experiments across seven numerical tasks (primarily modular arithmetic) using a modern Transformer architecture. The experimental configuration systematically varied the optimizer (Muon vs. AdamW) and the softmax activation function (standard softmax, stablemax, and sparsemax) to assess their combined effect on learning dynamics. Our empirical evaluation reveals that the Muon optimizer, characterized by its use of spectral norm constraints and second-order information, significantly accelerates the onset of grokking compared to the widely used AdamW optimizer. Specifically, Muon reduced the mean grokking epoch from 153.09 to 102.89 across all configurations, a statistically significant difference (t = 5.0175, p = 6.33e-08). This suggests that the optimizer choice plays a crucial role in facilitating the transition from memorization to generalization.","authors":["Amund Tveit","Bj{\\o}rn Remseth","Arve Skogvold"],"url":"https://arxiv.org/abs/2504.16041"}
{"created":"2025-04-23","title":"Approximate matrices of systems of max-min fuzzy relational equations","abstract":"In this article, we address the inconsistency of a system of max-min fuzzy relational equations by minimally modifying the matrix governing the system in order to achieve consistency. Our method yields consistent systems that approximate the original inconsistent system in the following sense: the right-hand side vector of each consistent system is that of the inconsistent system, and the coefficients of the matrix governing each consistent system are obtained by modifying, exactly and minimally, the entries of the original matrix that must be corrected to achieve consistency, while leaving all other entries unchanged.","authors":["Isma\\\"il Baaj"],"url":"https://arxiv.org/abs/2504.16042"}
{"created":"2025-04-23","title":"Certified Mitigation of Worst-Case LLM Copyright Infringement","abstract":"The exposure of large language models (LLMs) to copyrighted material during pre-training raises concerns about unintentional copyright infringement post deployment. This has driven the development of \"copyright takedown\" methods, post-training approaches aimed at preventing models from generating content substantially similar to copyrighted ones. While current mitigation approaches are somewhat effective for average-case risks, we demonstrate that they overlook worst-case copyright risks exhibits by the existence of long, verbatim quotes from copyrighted sources. We propose BloomScrub, a remarkably simple yet highly effective inference-time approach that provides certified copyright takedown. Our method repeatedly interleaves quote detection with rewriting techniques to transform potentially infringing segments. By leveraging efficient data sketches (Bloom filters), our approach enables scalable copyright screening even for large-scale real-world corpora. When quotes beyond a length threshold cannot be removed, the system can abstain from responding, offering certified risk reduction. Experimental results show that BloomScrub reduces infringement risk, preserves utility, and accommodates different levels of enforcement stringency with adaptive abstention. Our results suggest that lightweight, inference-time methods can be surprisingly effective for copyright prevention.","authors":["Jingyu Zhang","Jiacan Yu","Marc Marone","Benjamin Van Durme","Daniel Khashabi"],"url":"https://arxiv.org/abs/2504.16046"}
{"created":"2025-04-23","title":"Evaluating Vision Language Models (VLMs) for Radiology: A Comprehensive Analysis","abstract":"Foundation models, trained on vast amounts of data using self-supervised techniques, have emerged as a promising frontier for advancing artificial intelligence (AI) applications in medicine. This study evaluates three different vision-language foundation models (RAD-DINO, CheXagent, and BiomedCLIP) on their ability to capture fine-grained imaging features for radiology tasks. The models were assessed across classification, segmentation, and regression tasks for pneumothorax and cardiomegaly on chest radiographs. Self-supervised RAD-DINO consistently excelled in segmentation tasks, while text-supervised CheXagent demonstrated superior classification performance. BiomedCLIP showed inconsistent performance across tasks. A custom segmentation model that integrates global and local features substantially improved performance for all foundation models, particularly for challenging pneumothorax segmentation. The findings highlight that pre-training methodology significantly influences model performance on specific downstream tasks. For fine-grained segmentation tasks, models trained without text supervision performed better, while text-supervised models offered advantages in classification and interpretability. These insights provide guidance for selecting foundation models based on specific clinical applications in radiology.","authors":["Frank Li","Hari Trivedi","Bardia Khosravi","Theo Dapamede","Mohammadreza Chavoshi","Abdulhameed Dere","Rohan Satya Isaac","Aawez Mansuri","Janice Newsome","Saptarshi Purkayastha","Judy Gichoya"],"url":"https://arxiv.org/abs/2504.16047"}
{"created":"2025-04-23","title":"PRIME: Fast Primal-Dual Feedback Optimization for Markets with Application to Optimal Power Flow","abstract":"Online Feedback Optimization (OFO) controllers iteratively drive a plant to an optimal operating point that satisfies input and output constraints, relying solely on the input-output sensitivity as model information. This paper introduces PRIME (PRoximal Iterative MarkEts), a novel OFO approach based on proximal-point iterations. Unlike existing OFO solutions, PRIME admits a market-based implementation, where self-interested actors are incentivized to make choices that result in a safe and efficient operation, without communicating private costs or constraints. Furthermore, PRIME can cope with non-smooth objective functions, achieve fast convergence rates and rapid constraint satisfaction, and reject measurement noise. We demonstrate PRIME on an AC optimal power flow problem, obtaining an efficient real-time nonlinear local marginal pricing scheme.","authors":["Nicholas Julian Behr","Mattia Bianchi","Keith Moffat","Saverio Bolognani","Florian D\\\"orfler"],"url":"https://arxiv.org/abs/2504.16048"}
{"created":"2025-04-23","title":"LongMamba: Enhancing Mamba's Long Context Capabilities via Training-Free Receptive Field Enlargement","abstract":"State space models (SSMs) have emerged as an efficient alternative to Transformer models for language modeling, offering linear computational complexity and constant memory usage as context length increases. However, despite their efficiency in handling long contexts, recent studies have shown that SSMs, such as Mamba models, generally underperform compared to Transformers in long-context understanding tasks. To address this significant shortfall and achieve both efficient and accurate long-context understanding, we propose LongMamba, a training-free technique that significantly enhances the long-context capabilities of Mamba models. LongMamba builds on our discovery that the hidden channels in Mamba can be categorized into local and global channels based on their receptive field lengths, with global channels primarily responsible for long-context capability. These global channels can become the key bottleneck as the input context lengthens. Specifically, when input lengths largely exceed the training sequence length, global channels exhibit limitations in adaptively extend their receptive fields, leading to Mamba's poor long-context performance. The key idea of LongMamba is to mitigate the hidden state memory decay in these global channels by preventing the accumulation of unimportant tokens in their memory. This is achieved by first identifying critical tokens in the global channels and then applying token filtering to accumulate only those critical tokens. Through extensive benchmarking across synthetic and real-world long-context scenarios, LongMamba sets a new standard for Mamba's long-context performance, significantly extending its operational range without requiring additional training. Our code is available at https://github.com/GATECH-EIC/LongMamba.","authors":["Zhifan Ye","Kejing Xia","Yonggan Fu","Xin Dong","Jihoon Hong","Xiangchi Yuan","Shizhe Diao","Jan Kautz","Pavlo Molchanov","Yingyan Celine Lin"],"url":"https://arxiv.org/abs/2504.16053"}
{"created":"2025-04-23","title":"$\\pi_{0.5}$: a Vision-Language-Action Model with Open-World Generalization","abstract":"In order for robots to be useful, they must perform practically relevant tasks in the real world, outside of the lab. While vision-language-action (VLA) models have demonstrated impressive results for end-to-end robot control, it remains an open question how far such models can generalize in the wild. We describe $\\pi_{0.5}$, a new model based on $\\pi_{0}$ that uses co-training on heterogeneous tasks to enable broad generalization. $\\pi_{0.5}$\\ uses data from multiple robots, high-level semantic prediction, web data, and other sources to enable broadly generalizable real-world robotic manipulation. Our system uses a combination of co-training and hybrid multi-modal examples that combine image observations, language commands, object detections, semantic subtask prediction, and low-level actions. Our experiments show that this kind of knowledge transfer is essential for effective generalization, and we demonstrate for the first time that an end-to-end learning-enabled robotic system can perform long-horizon and dexterous manipulation skills, such as cleaning a kitchen or bedroom, in entirely new homes.","authors":["Physical Intelligence","Kevin Black","Noah Brown","James Darpinian","Karan Dhabalia","Danny Driess","Adnan Esmail","Michael Equi","Chelsea Finn","Niccolo Fusai","Manuel Y. Galliker","Dibya Ghosh","Lachy Groom","Karol Hausman","Brian Ichter","Szymon Jakubczak","Tim Jones","Liyiming Ke","Devin LeBlanc","Sergey Levine","Adrian Li-Bell","Mohith Mothukuri","Suraj Nair","Karl Pertsch","Allen Z. Ren","Lucy Xiaoyang Shi","Laura Smith","Jost Tobias Springenberg","Kyle Stachowicz","James Tanner","Quan Vuong","Homer Walke","Anna Walling","Haohuan Wang","Lili Yu","Ury Zhilinsky"],"url":"https://arxiv.org/abs/2504.16054"}
{"created":"2025-04-23","title":"SAR4SLPs: An Asynchronous Survey of Speech-Language Pathologists' Perspectives on Socially Assistive Robots","abstract":"Socially Assistive Robots (SARs) offer unique opportunities within speech language pathology (SLP) education and practice by supporting interactive interventions for children with communication disorders. This paper explores the implementation of SAR4SLPs (Socially Assistive Robots for Speech-Language Pathologists) to investigate aspects such as engagement, therapeutic strategy discipline, and consistent intervention support. We assessed the current application of technology to clinical and educational settings, especially with respect to how SLPs might use SAR in their therapeutic work. An asynchronous remote community (ARC) collaborated with a cohort of practicing SLPs to consider the feasibility, potential effectiveness, and anticipated challenges with implementing SARs in day-to-day interventions and as practice facilitators. We focus in particular on the expressive functionality of SARs, modeling a foundational strategy that SLPs employ across various intervention targets. This paper highlights clinician-driven insights and design implications for developing SARs that support specific treatment goals through collaborative and iterative design.","authors":["Denielle Oliva","Abbie Olszewski","David Feil-Seifer"],"url":"https://arxiv.org/abs/2504.16055"}
{"created":"2025-04-23","title":"Honey, I Shrunk the Language Model: Impact of Knowledge Distillation Methods on Performance and Explainability","abstract":"Artificial Intelligence (AI) has increasingly influenced modern society, recently in particular through significant advancements in Large Language Models (LLMs). However, high computational and storage demands of LLMs still limit their deployment in resource-constrained environments. Knowledge distillation addresses this challenge by training a small student model from a larger teacher model. Previous research has introduced several distillation methods for both generating training data and for training the student model. Despite their relevance, the effects of state-of-the-art distillation methods on model performance and explainability have not been thoroughly investigated and compared. In this work, we enlarge the set of available methods by applying critique-revision prompting to distillation for data generation and by synthesizing existing methods for training. For these methods, we provide a systematic comparison based on the widely used Commonsense Question-Answering (CQA) dataset. While we measure performance via student model accuracy, we employ a human-grounded study to evaluate explainability. We contribute new distillation methods and their comparison in terms of both performance and explainability. This should further advance the distillation of small language models and, thus, contribute to broader applicability and faster diffusion of LLM technology.","authors":["Daniel Hendriks","Philipp Spitzer","Niklas K\\\"uhl","Gerhard Satzger"],"url":"https://arxiv.org/abs/2504.16056"}
{"created":"2025-04-23","title":"Automated Static Vulnerability Detection via a Holistic Neuro-symbolic Approach","abstract":"Static vulnerability detection is still a challenging problem and demands excessive human efforts, e.g., manual curation of good vulnerability patterns. None of prior works, including classic program analysis or Large Language Model (LLM)-based approaches, have fully automated such vulnerability pattern generations with reasonable detection accuracy. In this paper, we design and implement, MoCQ, a novel holistic neuro-symbolic framework that combines the complementary strengths of LLMs and classical static analysis to enable scalable vulnerability detection. The key insight is that MoCQ leverages an LLM to automatically extract vulnerability patterns and translate them into detection queries, and then on static analysis to refine such queries in a feedback loop and eventually execute them for analyzing large codebases and mining vulnerabilities. We evaluate MoCQ on seven types of vulnerabilities spanning two programming languages. We found MoCQ-generated queries uncovered at least 12 patterns that were missed by experts. On a ground truth dataset, MoCQ achieved comparable precision and recall compared to expert-crafted queries. Moreover, MoCQ has identified seven previously unknown vulnerabilities in real-world applications, demonstrating its practical effectiveness. We have responsibly disclosed them to the corresponding developers.","authors":["Penghui Li","Songchen Yao","Josef Sarfati Korich","Changhua Luo","Jianjia Yu","Yinzhi Cao","Junfeng Yang"],"url":"https://arxiv.org/abs/2504.16057"}
{"created":"2025-04-23","title":"Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation","abstract":"Referring Expression Generation (REG) is a core task for evaluating the pragmatic competence of vision-language systems, requiring not only accurate semantic grounding but also adherence to principles of cooperative communication (Grice, 1975). However, current evaluations of vision-language models (VLMs) often overlook the pragmatic dimension, reducing REG to a region-based captioning task and neglecting Gricean maxims. In this work, we revisit REG from a pragmatic perspective, introducing a new dataset (RefOI) of 1.5k images annotated with both written and spoken referring expressions. Through a systematic evaluation of state-of-the-art VLMs, we identify three key failures of pragmatic competence: (1) failure to uniquely identify the referent, (2) inclusion of excessive or irrelevant information, and (3) misalignment with human pragmatic preference, such as the underuse of minimal spatial cues. We also show that standard automatic evaluations fail to capture these pragmatic violations, reinforcing superficial cues rather than genuine referential success. Our findings call for a renewed focus on pragmatically informed models and evaluation frameworks that align with real human communication.","authors":["Ziqiao Ma","Jing Ding","Xuejun Zhang","Dezhi Luo","Jiahe Ding","Sihan Xu","Yuchen Huang","Run Peng","Joyce Chai"],"url":"https://arxiv.org/abs/2504.16060"}
{"created":"2025-04-23","title":"Vision language models are unreliable at trivial spatial cognition","abstract":"Vision language models (VLMs) are designed to extract relevant visuospatial information from images. Some research suggests that VLMs can exhibit humanlike scene understanding, while other investigations reveal difficulties in their ability to process relational information. To achieve widespread applicability, VLMs must perform reliably, yielding comparable competence across a wide variety of related tasks. We sought to test how reliable these architectures are at engaging in trivial spatial cognition, e.g., recognizing whether one object is left of another in an uncluttered scene. We developed a benchmark dataset -- TableTest -- whose images depict 3D scenes of objects arranged on a table, and used it to evaluate state-of-the-art VLMs. Results show that performance could be degraded by minor variations of prompts that use logically equivalent descriptions. These analyses suggest limitations in how VLMs may reason about spatial relations in real-world applications. They also reveal novel opportunities for bolstering image caption corpora for more efficient training and testing.","authors":["Sangeet Khemlani","Tyler Tran","Nathaniel Gyory","Anthony M. Harrison","Wallace E. Lawson","Ravenna Thielstrom","Hunter Thompson","Taaren Singh","J. Gregory Trafton"],"url":"https://arxiv.org/abs/2504.16061"}
{"created":"2025-04-23","title":"ForesightNav: Learning Scene Imagination for Efficient Exploration","abstract":"Understanding how humans leverage prior knowledge to navigate unseen environments while making exploratory decisions is essential for developing autonomous robots with similar abilities. In this work, we propose ForesightNav, a novel exploration strategy inspired by human imagination and reasoning. Our approach equips robotic agents with the capability to predict contextual information, such as occupancy and semantic details, for unexplored regions. These predictions enable the robot to efficiently select meaningful long-term navigation goals, significantly enhancing exploration in unseen environments. We validate our imagination-based approach using the Structured3D dataset, demonstrating accurate occupancy prediction and superior performance in anticipating unseen scene geometry. Our experiments show that the imagination module improves exploration efficiency in unseen environments, achieving a 100% completion rate for PointNav and an SPL of 67% for ObjectNav on the Structured3D Validation split. These contributions demonstrate the power of imagination-driven reasoning for autonomous systems to enhance generalizable and efficient exploration.","authors":["Hardik Shah","Jiaxu Xing","Nico Messikommer","Boyang Sun","Marc Pollefeys","Davide Scaramuzza"],"url":"https://arxiv.org/abs/2504.16062"}
{"created":"2025-04-23","title":"A Python Tool for Reconstructing Full News Text from GDELT","abstract":"News data have become an essential resource across various disciplines, including economics, finance, management, social sciences, and computer science. Researchers leverage newspaper articles to study economic trends, market dynamics, corporate strategies, public perception, political discourse, and the evolution of public opinion. Additionally, news datasets have been instrumental in training large-scale language models, with applications in sentiment analysis, fake news detection, and automated news summarization. Despite their significance, access to comprehensive news corpora remains a key challenge. Many full-text news providers, such as Factiva and LexisNexis, require costly subscriptions, while free alternatives often suffer from incomplete data and transparency issues. This paper presents a novel approach to obtaining full-text newspaper articles at near-zero cost by leveraging data from the Global Database of Events, Language, and Tone (GDELT). Specifically, we focus on the GDELT Web News NGrams 3.0 dataset, which provides high-frequency updates of n-grams extracted from global online news sources. We provide Python code to reconstruct full-text articles from these n-grams by identifying overlapping textual fragments and intelligently merging them. Our method enables researchers to access structured, large-scale newspaper data for text analysis while overcoming the limitations of existing proprietary datasets. The proposed approach enhances the accessibility of news data for empirical research, facilitating applications in economic forecasting, computational social science, and natural language processing.","authors":["A. Fronzetti Colladon","R. Vestrelli"],"url":"https://arxiv.org/abs/2504.16063"}
{"created":"2025-04-23","title":"Boosting Generative Image Modeling via Joint Image-Feature Synthesis","abstract":"Latent diffusion models (LDMs) dominate high-quality image generation, yet integrating representation learning with generative modeling remains a challenge. We introduce a novel generative image modeling framework that seamlessly bridges this gap by leveraging a diffusion model to jointly model low-level image latents (from a variational autoencoder) and high-level semantic features (from a pretrained self-supervised encoder like DINO). Our latent-semantic diffusion approach learns to generate coherent image-feature pairs from pure noise, significantly enhancing both generative quality and training efficiency, all while requiring only minimal modifications to standard Diffusion Transformer architectures. By eliminating the need for complex distillation objectives, our unified design simplifies training and unlocks a powerful new inference strategy: Representation Guidance, which leverages learned semantics to steer and refine image generation. Evaluated in both conditional and unconditional settings, our method delivers substantial improvements in image quality and training convergence speed, establishing a new direction for representation-aware generative modeling.","authors":["Theodoros Kouzelis","Efstathios Karypidis","Ioannis Kakogeorgiou","Spyros Gidaris","Nikos Komodakis"],"url":"https://arxiv.org/abs/2504.16064"}
{"created":"2025-04-23","title":"A Mysterious Connection Between Tolerant Junta Testing and Agnostically Learning Conjunctions","abstract":"The main conceptual contribution of this paper is identifying a previously unnoticed connection between two central problems in computational learning theory and property testing: agnostically learning conjunctions and tolerantly testing juntas. Inspired by this connection, the main technical contribution is a pair of improved algorithms for these two problems.","authors":["Xi Chen","Shyamal Patel","Rocco A. Servedio"],"url":"https://arxiv.org/abs/2504.16065"}
{"created":"2025-04-23","title":"Reconstruction of source function in a parabolic equation using partial boundary measurements","abstract":"In this paper, we present the analytical and numerical study of the optimization approach for determining the space-dependent source function in the parabolic inverse source problem using partial boundary measurements. The Lagrangian approach for the solution of the optimization problem is presented, and optimality conditions are derived. The proof of the Fr\\'echet differentiability of the regularized Tikhonov functional and the existence result for the solution of the inverse source problem are established. A local stability estimate for the unknown source term is also presented. The numerical examples justify the theoretical investigations using the conjugate gradient method (CGM) in 2D and 3D tests with noisy data.","authors":["T. Sharma","L. Beilina","K. Sakthivel"],"url":"https://arxiv.org/abs/2504.16070"}
{"created":"2025-04-23","title":"A Markov Chain Monte Carlo Method for Efficient Finite-Length LDPC Code Design","abstract":"Low-density parity-check (LDPC) codes are among the most prominent error-correction schemes. They find application to fortify various modern storage, communication, and computing systems. Protograph-based (PB) LDPC codes offer many degrees of freedom in the code design and enable fast encoding and decoding. In particular, spatially-coupled (SC) and multi-dimensional (MD) circulant-based codes are PB-LDPC codes with excellent performance. Efficient finite-length (FL) algorithms are required in order to effectively exploit the available degrees of freedom offered by SC partitioning, lifting, and MD relocations. In this paper, we propose a novel Markov chain Monte Carlo (MCMC or MC$^2$) method to perform this FL optimization, addressing the removal of short cycles. While iterating, we draw samples from a defined distribution where the probability decreases as the number of short cycles from the previous iteration increases. We analyze our MC$^2$ method theoretically as we prove the invariance of the Markov chain where each state represents a possible partitioning or lifting arrangement. Via our simulations, we then fit the distribution of the number of cycles resulting from a given arrangement on a Gaussian distribution. We derive estimates for cycle counts that are close to the actual counts. Furthermore, we derive the order of the expected number of iterations required by our approach to reach a local minimum as well as the size of the Markov chain recurrent class. Our approach is compatible with code design techniques based on gradient-descent. Numerical results show that our MC$^2$ method generates SC codes with remarkably less number of short cycles compared with the current state-of-the-art. Moreover, to reach the same number of cycles, our method requires orders of magnitude less overall time compared with the available literature methods.","authors":["Ata Tanr{\\i}kulu","Mete Y{\\i}ld{\\i}r{\\i}m","Ahmed Hareedy"],"url":"https://arxiv.org/abs/2504.16071"}
{"created":"2025-04-23","title":"Describe Anything: Detailed Localized Image and Video Captioning","abstract":"Generating detailed and accurate descriptions for specific regions in images and videos remains a fundamental challenge for vision-language models. We introduce the Describe Anything Model (DAM), a model designed for detailed localized captioning (DLC). DAM preserves both local details and global context through two key innovations: a focal prompt, which ensures high-resolution encoding of targeted regions, and a localized vision backbone, which integrates precise localization with its broader context. To tackle the scarcity of high-quality DLC data, we propose a Semi-supervised learning (SSL)-based Data Pipeline (DLC-SDP). DLC-SDP starts with existing segmentation datasets and expands to unlabeled web images using SSL. We introduce DLC-Bench, a benchmark designed to evaluate DLC without relying on reference captions. DAM sets new state-of-the-art on 7 benchmarks spanning keyword-level, phrase-level, and detailed multi-sentence localized image and video captioning.","authors":["Long Lian","Yifan Ding","Yunhao Ge","Sifei Liu","Hanzi Mao","Boyi Li","Marco Pavone","Ming-Yu Liu","Trevor Darrell","Adam Yala","Yin Cui"],"url":"https://arxiv.org/abs/2504.16072"}
{"created":"2025-04-23","title":"Guiding VLM Agents with Process Rewards at Inference Time for GUI Navigation","abstract":"Recent advancements in visual language models (VLMs) have notably enhanced their capabilities in handling complex Graphical User Interface (GUI) interaction tasks. Despite these improvements, current frameworks often struggle to generate correct actions in challenging GUI environments. State-of-the-art commercial VLMs are black-boxes, and fine-tuning open-source VLMs for GUI tasks requires significant resources. Additionally, existing trajectory-level evaluation and refinement techniques frequently fall short due to delayed feedback and local optimization issues. To address these challenges, we propose an approach that guides VLM agents with process supervision by a reward model during GUI navigation and control at inference time. This guidance allows the VLM agent to optimize actions at each inference step, thereby improving performance in both static and dynamic environments. In particular, our method demonstrates significant performance gains in three GUI navigation tasks, achieving a 3.4% improvement in single step action accuracy for static environments, along with a around 33% increase in task success rate in one dynamic environment. With further integration of trajectory reflection and retry mechanisms, we also demonstrate even greater enhancement in task success.","authors":["Zhiyuan Hu","Shiyun Xiong","Yifan Zhang","See-Kiong Ng","Anh Tuan Luu","Bo An","Shuicheng Yan","Bryan Hooi"],"url":"https://arxiv.org/abs/2504.16073"}
{"created":"2025-04-23","title":"PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models","abstract":"We introduce PHYBench, a novel, high-quality benchmark designed for evaluating reasoning capabilities of large language models (LLMs) in physical contexts. PHYBench consists of 500 meticulously curated physics problems based on real-world physical scenarios, designed to assess the ability of models to understand and reason about realistic physical processes. Covering mechanics, electromagnetism, thermodynamics, optics, modern physics, and advanced physics, the benchmark spans difficulty levels from high school exercises to undergraduate problems and Physics Olympiad challenges. Additionally, we propose the Expression Edit Distance (EED) Score, a novel evaluation metric based on the edit distance between mathematical expressions, which effectively captures differences in model reasoning processes and results beyond traditional binary scoring methods. We evaluate various LLMs on PHYBench and compare their performance with human experts. Our results reveal that even state-of-the-art reasoning models significantly lag behind human experts, highlighting their limitations and the need for improvement in complex physical reasoning scenarios. Our benchmark results and dataset are publicly available at https://phybench-official.github.io/phybench-demo/.","authors":["Shi Qiu","Shaoyang Guo","Zhuo-Yang Song","Yunbo Sun","Zeyu Cai","Jiashen Wei","Tianyu Luo","Yixuan Yin","Haoxu Zhang","Yi Hu","Chenyang Wang","Chencheng Tang","Haoling Chang","Qi Liu","Ziheng Zhou","Tianyu Zhang","Jingtian Zhang","Zhangyi Liu","Minghao Li","Yuku Zhang","Boxuan Jing","Xianqi Yin","Yutong Ren","Zizhuo Fu","Weike Wang","Xudong Tian","Anqi Lv","Laifu Man","Jianxiang Li","Feiyu Tao","Qihua Sun","Zhou Liang","Yushu Mu","Zhongxuan Li","Jing-Jun Zhang","Shutao Zhang","Xiaotian Li","Xingqi Xia","Jiawei Lin","Zheyu Shen","Jiahang Chen","Qiuhao Xiong","Binran Wang","Fengyuan Wang","Ziyang Ni","Bohan Zhang","Fan Cui","Changkun Shao","Qing-Hong Cao","Ming-xing Luo","Muhan Zhang","Hua Xing Zhu"],"url":"https://arxiv.org/abs/2504.16074"}
{"created":"2025-04-23","title":"Intent-aware Diffusion with Contrastive Learning for Sequential Recommendation","abstract":"Contrastive learning has proven effective in training sequential recommendation models by incorporating self-supervised signals from augmented views. Most existing methods generate multiple views from the same interaction sequence through stochastic data augmentation, aiming to align their representations in the embedding space. However, users typically have specific intents when purchasing items (e.g., buying clothes as gifts or cosmetics for beauty). Random data augmentation used in existing methods may introduce noise, disrupting the latent intent information implicit in the original interaction sequence. Moreover, using noisy augmented sequences in contrastive learning may mislead the model to focus on irrelevant features, distorting the embedding space and failing to capture users' true behavior patterns and intents. To address these issues, we propose Intent-aware Diffusion with contrastive learning for sequential Recommendation (InDiRec). The core idea is to generate item sequences aligned with users' purchasing intents, thus providing more reliable augmented views for contrastive learning. Specifically, InDiRec first performs intent clustering on sequence representations using K-means to build intent-guided signals. Next, it retrieves the intent representation of the target interaction sequence to guide a conditional diffusion model, generating positive views that share the same underlying intent. Finally, contrastive learning is applied to maximize representation consistency between these intent-aligned views and the original sequence. Extensive experiments on five public datasets demonstrate that InDiRec achieves superior performance compared to existing baselines, learning more robust representations even under noisy and sparse data conditions.","authors":["Yuanpeng Qu","Hajime Nobuhara"],"url":"https://arxiv.org/abs/2504.16077"}
{"created":"2025-04-23","title":"LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities","abstract":"The success of Large Language Models (LLMs) has sparked interest in various agentic applications. A key hypothesis is that LLMs, leveraging common sense and Chain-of-Thought (CoT) reasoning, can effectively explore and efficiently solve complex domains. However, LLM agents have been found to suffer from sub-optimal exploration and the knowing-doing gap, the inability to effectively act on knowledge present in the model. In this work, we systematically study why LLMs perform sub-optimally in decision-making scenarios. In particular, we closely examine three prevalent failure modes: greediness, frequency bias, and the knowing-doing gap. We propose mitigation of these shortcomings by fine-tuning via Reinforcement Learning (RL) on self-generated CoT rationales. Our experiments across multi-armed bandits, contextual bandits, and Tic-tac-toe, demonstrate that RL fine-tuning enhances the decision-making abilities of LLMs by increasing exploration and narrowing the knowing-doing gap. Finally, we study both classic exploration mechanisms, such as $\\epsilon$-greedy, and LLM-specific approaches, such as self-correction and self-consistency, to enable more effective fine-tuning of LLMs for decision-making.","authors":["Thomas Schmied","J\\\"org Bornschein","Jordi Grau-Moya","Markus Wulfmeier","Razvan Pascanu"],"url":"https://arxiv.org/abs/2504.16078"}
{"created":"2025-04-23","title":"From Reflection to Perfection: Scaling Inference-Time Optimization for Text-to-Image Diffusion Models via Reflection Tuning","abstract":"Recent text-to-image diffusion models achieve impressive visual quality through extensive scaling of training data and model parameters, yet they often struggle with complex scenes and fine-grained details. Inspired by the self-reflection capabilities emergent in large language models, we propose ReflectionFlow, an inference-time framework enabling diffusion models to iteratively reflect upon and refine their outputs. ReflectionFlow introduces three complementary inference-time scaling axes: (1) noise-level scaling to optimize latent initialization; (2) prompt-level scaling for precise semantic guidance; and most notably, (3) reflection-level scaling, which explicitly provides actionable reflections to iteratively assess and correct previous generations. To facilitate reflection-level scaling, we construct GenRef, a large-scale dataset comprising 1 million triplets, each containing a reflection, a flawed image, and an enhanced image. Leveraging this dataset, we efficiently perform reflection tuning on state-of-the-art diffusion transformer, FLUX.1-dev, by jointly modeling multimodal inputs within a unified framework. Experimental results show that ReflectionFlow significantly outperforms naive noise-level scaling methods, offering a scalable and compute-efficient solution toward higher-quality image synthesis on challenging tasks.","authors":["Le Zhuo","Liangbing Zhao","Sayak Paul","Yue Liao","Renrui Zhang","Yi Xin","Peng Gao","Mohamed Elhoseiny","Hongsheng Li"],"url":"https://arxiv.org/abs/2504.16080"}
{"created":"2025-04-23","title":"Survey of Video Diffusion Models: Foundations, Implementations, and Applications","abstract":"Recent advances in diffusion models have revolutionized video generation, offering superior temporal consistency and visual quality compared to traditional generative adversarial networks-based approaches. While this emerging field shows tremendous promise in applications, it faces significant challenges in motion consistency, computational efficiency, and ethical considerations. This survey provides a comprehensive review of diffusion-based video generation, examining its evolution, technical foundations, and practical applications. We present a systematic taxonomy of current methodologies, analyze architectural innovations and optimization strategies, and investigate applications across low-level vision tasks such as denoising and super-resolution. Additionally, we explore the synergies between diffusionbased video generation and related domains, including video representation learning, question answering, and retrieval. Compared to the existing surveys (Lei et al., 2024a;b; Melnik et al., 2024; Cao et al., 2023; Xing et al., 2024c) which focus on specific aspects of video generation, such as human video synthesis (Lei et al., 2024a) or long-form content generation (Lei et al., 2024b), our work provides a broader, more updated, and more fine-grained perspective on diffusion-based approaches with a special section for evaluation metrics, industry solutions, and training engineering techniques in video generation. This survey serves as a foundational resource for researchers and practitioners working at the intersection of diffusion models and video generation, providing insights into both the theoretical frameworks and practical implementations that drive this rapidly evolving field. A structured list of related works involved in this survey is also available on https://github.com/Eyeline-Research/Survey-Video-Diffusion.","authors":["Yimu Wang","Xuye Liu","Wei Pang","Li Ma","Shuai Yuan","Paul Debevec","Ning Yu"],"url":"https://arxiv.org/abs/2504.16081"}
{"created":"2025-04-23","title":"MR. Video: \"MapReduce\" is the Principle for Long Video Understanding","abstract":"We propose MR. Video, an agentic long video understanding framework that demonstrates the simple yet effective MapReduce principle for processing long videos: (1) Map: independently and densely perceiving short video clips, and (2) Reduce: jointly aggregating information from all clips. Compared with sequence-to-sequence vision-language models (VLMs), MR. Video performs detailed short video perception without being limited by context length. Compared with existing video agents that typically rely on sequential key segment selection, the Map operation enables simpler and more scalable sequence parallel perception of short video segments. Its Reduce step allows for more comprehensive context aggregation and reasoning, surpassing explicit key segment retrieval. This MapReduce principle is applicable to both VLMs and video agents, and we use LLM agents to validate its effectiveness.","authors":["Ziqi Pang","Yu-Xiong Wang"],"url":"https://arxiv.org/abs/2504.16082"}
{"created":"2025-04-23","title":"MMInference: Accelerating Pre-filling for Long-Context VLMs via Modality-Aware Permutation Sparse Attention","abstract":"The integration of long-context capabilities with visual understanding unlocks unprecedented potential for Vision Language Models (VLMs). However, the quadratic attention complexity during the pre-filling phase remains a significant obstacle to real-world deployment. To overcome this limitation, we introduce MMInference (Multimodality Million tokens Inference), a dynamic sparse attention method that accelerates the prefilling stage for long-context multi-modal inputs. First, our analysis reveals that the temporal and spatial locality of video input leads to a unique sparse pattern, the Grid pattern. Simultaneously, VLMs exhibit markedly different sparse distributions across different modalities. We introduce a permutation-based method to leverage the unique Grid pattern and handle modality boundary issues. By offline search the optimal sparse patterns for each head, MMInference constructs the sparse distribution dynamically based on the input. We also provide optimized GPU kernels for efficient sparse computations. Notably, MMInference integrates seamlessly into existing VLM pipelines without any model modifications or fine-tuning. Experiments on multi-modal benchmarks-including Video QA, Captioning, VisionNIAH, and Mixed-Modality NIAH-with state-of-the-art long-context VLMs (LongVila, LlavaVideo, VideoChat-Flash, Qwen2.5-VL) show that MMInference accelerates the pre-filling stage by up to 8.3x at 1M tokens while maintaining accuracy. Our code is available at https://aka.ms/MMInference.","authors":["Yucheng Li","Huiqiang Jiang","Chengruidong Zhang","Qianhui Wu","Xufang Luo","Surin Ahn","Amir H. Abdi","Dongsheng Li","Jianfeng Gao","Yuqing Yang","Lili Qiu"],"url":"https://arxiv.org/abs/2504.16083"}
{"created":"2025-04-23","title":"TTRL: Test-Time Reinforcement Learning","abstract":"This paper investigates Reinforcement Learning (RL) on data without explicit labels for reasoning tasks in Large Language Models (LLMs). The core challenge of the problem is reward estimation during inference while not having access to ground-truth information. While this setting appears elusive, we find that common practices in Test-Time Scaling (TTS), such as majority voting, yield surprisingly effective rewards suitable for driving RL training. In this work, we introduce Test-Time Reinforcement Learning (TTRL), a novel method for training LLMs using RL on unlabeled data. TTRL enables self-evolution of LLMs by utilizing the priors in the pre-trained models. Our experiments demonstrate that TTRL consistently improves performance across a variety of tasks and models. Notably, TTRL boosts the pass@1 performance of Qwen-2.5-Math-7B by approximately 159% on the AIME 2024 with only unlabeled test data. Furthermore, although TTRL is only supervised by the Maj@N metric, TTRL has demonstrated performance to consistently surpass the upper limit of the initial model, and approach the performance of models trained directly on test data with ground-truth labels. Our experimental findings validate the general effectiveness of TTRL across various tasks, and highlight TTRL's potential for broader tasks and domains. GitHub: https://github.com/PRIME-RL/TTRL","authors":["Yuxin Zuo","Kaiyan Zhang","Shang Qu","Li Sheng","Xuekai Zhu","Biqing Qi","Youbang Sun","Ganqu Cui","Ning Ding","Bowen Zhou"],"url":"https://arxiv.org/abs/2504.16084"}
{"created":"2025-04-23","title":"Evidence of conceptual mastery in the application of rules by Large Language Models","abstract":"In this paper we leverage psychological methods to investigate LLMs' conceptual mastery in applying rules. We introduce a novel procedure to match the diversity of thought generated by LLMs to that observed in a human sample. We then conducted two experiments comparing rule-based decision-making in humans and LLMs. Study 1 found that all investigated LLMs replicated human patterns regardless of whether they are prompted with scenarios created before or after their training cut-off. Moreover, we found unanticipated differences between the two sets of scenarios among humans. Surprisingly, even these differences were replicated in LLM responses. Study 2 turned to a contextual feature of human rule application: under forced time delay, human samples rely more heavily on a rule's text than on other considerations such as a rule's purpose.. Our results revealed that some models (Gemini Pro and Claude 3) responded in a human-like manner to a prompt describing either forced delay or time pressure, while others (GPT-4o and Llama 3.2 90b) did not. We argue that the evidence gathered suggests that LLMs have mastery over the concept of rule, with implications for both legal decision making and philosophical inquiry.","authors":["Jos\\'e Luiz Nunes","Guilherme FCF Almeida","Brian Flanagan"],"url":"https://arxiv.org/abs/2503.00992"}
{"created":"2025-04-23","title":"SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow","abstract":"Recent prompt-based image editing models have demonstrated impressive prompt-following capability at structural editing tasks. However, existing models still fail to perform local edits, follow detailed editing prompts, or maintain global image quality beyond a single editing step. To address these challenges, we introduce SPICE, a training-free workflow that accepts arbitrary resolutions and aspect ratios, accurately follows user requirements, and improves image quality consistently during more than 100 editing steps. By synergizing the strengths of a base diffusion model and a Canny edge ControlNet model, SPICE robustly handles free-form editing instructions from the user. SPICE outperforms state-of-the-art baselines on a challenging realistic image-editing dataset consisting of semantic editing (object addition, removal, replacement, and background change), stylistic editing (texture changes), and structural editing (action change) tasks. Not only does SPICE achieve the highest quantitative performance according to standard evaluation metrics, but it is also consistently preferred by users over existing image-editing methods. We release the workflow implementation for popular diffusion model Web UIs to support further research and artistic exploration.","authors":["Kenan Tang","Yanhong Li","Yao Qin"],"url":"https://arxiv.org/abs/2504.09697"}
{"created":"2025-04-23","title":"Algorithmic Advances Towards a Realizable Quantum Lattice Boltzmann Method","abstract":"The Quantum Lattice Boltzmann Method (QLBM) is one of the most promising approaches for realizing the potential of quantum computing in simulating computational fluid dynamics. Many recent works mostly focus on classical simulation, and rely on full state tomography. Several key algorithmic issues like observable readout, data encoding, and impractical circuit depth remain unsolved. As a result, these are not directly realizable on any quantum hardware. We present a series of novel algorithmic advances which allow us to implement the QLBM algorithm, for the first time, on a quantum computer. Hardware results for the time evolution of a 2D Gaussian initial density distribution subject to a uniform advection-diffusion field are presented. Furthermore, 3D simulation results are presented for particular non-uniform advection fields, devised so as to avoid the problem of diminishing probability of success due to repeated post-selection operations required for multiple timesteps. We demonstrate the evolution of an initial quantum state governed by the advection-diffusion equation, accounting for the iterative nature of the explicit QLBM algorithm. A tensor network encoding scheme is used to represent the initial condition supplied to the advection-diffusion equation, significantly reducing the two-qubit gate count affording a shorter circuit depth. Further reductions are made in the collision and streaming operators. Collectively, these advances give a path to realizing more practical, 2D and 3D QLBM applications with non-trivial velocity fields on quantum hardware.","authors":["Apurva Tiwari","Jason Iaconis","Jezer Jojo","Sayonee Ray","Martin Roetteler","Chris Hill","Jay Pathak"],"url":"https://arxiv.org/abs/2504.10870"}
{"created":"2025-04-23","title":"AneuPy: An open source Python tool for creating simulation-ready geometries of abdominal aortic aneurysms","abstract":"Abdominal aortic aneurysms (AAAs) are localized dilations of the abdominal aorta that can lead to life-threatening rupture if left untreated. AAAs predominantly affect older individuals, with a high mortality rate upon rupture, making early diagnosis and risk assessment critical. The geometric characteristics of an AAA, such as its maximum diameter, asymmetry, and wall thickness, play a crucial role in biomechanical models used to assess rupture risk. Despite the growing use of computational modeling to study AAAs, there is a lack of open source software that facilitates the generation of simulation-ready geometries tailored for biomechanical and hemodynamic analyses. To address this need, we introduce AneuPy, an open-source Python-based tool designed to generate idealized and patient-specific AAA geometrical models. AneuPy provides an efficient and automated approach to aneurysm geometry generation, requiring minimal input data while allowing for flexible parameterization. By streamlining the creation of simulation-ready geometries for finite element analysis (FEA), computational fluid dynamics (CFD), or fluid-structure interaction (FSI) models, AneuPy aims to facilitate research in AAAs and enhance patient-specific risk assessment.","authors":["Mario de Lucio","Jacobo Diaz","Alberto de Castro","Luis E. Romera"],"url":"https://arxiv.org/abs/2504.15285"}
{"created":"2025-04-23","title":"RINN: One Sample Radio Frequency Imaging based on Physics Informed Neural Network","abstract":"Due to its ability to work in non-line-of-sight and low-light environments, radio frequency (RF) imaging technology is expected to bring new possibilities for embodied intelligence and multimodal sensing. However, widely used RF devices (such as Wi-Fi) often struggle to provide high-precision electromagnetic measurements and large-scale datasets, hindering the application of RF imaging technology. In this paper, we combine the ideas of PINN to design the RINN network, using physical constraints instead of true value comparison constraints and adapting it with the characteristics of ubiquitous RF signals, allowing the RINN network to achieve RF imaging using only one sample without phase and with amplitude noise. Our numerical evaluation results show that compared with 5 classic algorithms based on phase data for imaging results, RINN's imaging results based on phaseless data are good, with indicators such as RRMSE (0.11) performing similarly well. RINN provides new possibilities for the universal development of radio frequency imaging technology.","authors":["Fei Shang","Haohua Du","Dawei Yan","Panlong Yang","Xiang-Yang Li"],"url":"https://arxiv.org/abs/2504.15311"}
{"created":"2025-04-23","title":"Enhancing DR Classification with Swin Transformer and Shifted Window Attention","abstract":"Diabetic retinopathy (DR) is a leading cause of blindness worldwide, underscoring the importance of early detection for effective treatment. However, automated DR classification remains challenging due to variations in image quality, class imbalance, and pixel-level similarities that hinder model training. To address these issues, we propose a robust preprocessing pipeline incorporating image cropping, Contrast-Limited Adaptive Histogram Equalization (CLAHE), and targeted data augmentation to improve model generalization and resilience. Our approach leverages the Swin Transformer, which utilizes hierarchical token processing and shifted window attention to efficiently capture fine-grained features while maintaining linear computational complexity. We validate our method on the Aptos and IDRiD datasets for multi-class DR classification, achieving accuracy rates of 89.65% and 97.40%, respectively. These results demonstrate the effectiveness of our model, particularly in detecting early-stage DR, highlighting its potential for improving automated retinal screening in clinical settings.","authors":["Meher Boulaabi","Takwa Ben A\\\"icha Gader","Afef Kacem Echi","Zied Bouraoui"],"url":"https://arxiv.org/abs/2504.15317"}
{"created":"2025-04-23","title":"A Graph Based Raman Spectral Processing Technique for Exosome Classification","abstract":"Exosomes are small vesicles crucial for cell signaling and disease biomarkers. Due to their complexity, an \"omics\" approach is preferable to individual biomarkers. While Raman spectroscopy is effective for exosome analysis, it requires high sample concentrations and has limited sensitivity to lipids and proteins. Surface-enhanced Raman spectroscopy helps overcome these challenges. In this study, we leverage Neo4j graph databases to organize 3,045 Raman spectra of exosomes, enhancing data generalization. To further refine spectral analysis, we introduce a novel spectral filtering process that integrates the PageRank Filter with optimal Dimensionality Reduction. This method improves feature selection, resulting in superior classification performance. Specifically, the Extra Trees model, using our spectral processing approach, achieves 0.76 and 0.857 accuracy in classifying hyperglycemic, hypoglycemic, and normal exosome samples based on Raman spectra and surface, respectively, with group 10-fold cross-validation. Our results show that graph-based spectral filtering combined with optimal dimensionality reduction significantly improves classification accuracy by reducing noise while preserving key biomarker signals. This novel framework enhances Raman-based exosome analysis, expanding its potential for biomedical applications, disease diagnostics, and biomarker discovery.","authors":["Vuong M. Ngo","Edward Bolger","Stan Goodwin","John O'Sullivan","Dinh Viet Cuong","Mark Roantree"],"url":"https://arxiv.org/abs/2504.15324"}
{"created":"2025-04-23","title":"The Hardness of Learning Quantum Circuits and its Cryptographic Applications","abstract":"We show that concrete hardness assumptions about learning or cloning the output state of a random quantum circuit can be used as the foundation for secure quantum cryptography. In particular, under these assumptions we construct secure one-way state generators (OWSGs), digital signature schemes, quantum bit commitments, and private key encryption schemes. We also discuss evidence for these hardness assumptions by analyzing the best-known quantum learning algorithms, as well as proving black-box lower bounds for cloning and learning given state preparation oracles.","authors":["Bill Fefferman","Soumik Ghosh","Makrand Sinha","Henry Yuen"],"url":"https://arxiv.org/abs/2504.15343"}
{"created":"2025-04-23","title":"Transferable Learning of Reaction Pathways from Geometric Priors","abstract":"Identifying minimum-energy paths (MEPs) is crucial for understanding chemical reaction mechanisms but remains computationally demanding. We introduce MEPIN, a scalable machine-learning method for efficiently predicting MEPs from reactant and product configurations, without relying on transition-state geometries or pre-optimized reaction paths during training. The task is defined as predicting deviations from geometric interpolations along reaction coordinates. We address this task with a continuous reaction path model based on a symmetry-broken equivariant neural network that generates a flexible number of intermediate structures. The model is trained using an energy-based objective, with efficiency enhanced by incorporating geometric priors from geodesic interpolation as initial interpolations or pre-training objectives. Our approach generalizes across diverse chemical reactions and achieves accurate alignment with reference intrinsic reaction coordinates, as demonstrated on various small molecule reactions and [3+2] cycloadditions. Our method enables the exploration of large chemical reaction spaces with efficient, data-driven predictions of reaction pathways.","authors":["Juno Nam","Miguel Steiner","Max Misterka","Soojung Yang","Avni Singhal","Rafael G\\'omez-Bombarelli"],"url":"https://arxiv.org/abs/2504.15370"}
{"created":"2025-04-23","title":"Assessing Surrogate Heterogeneity in Real World Data Using Meta-Learners","abstract":"Surrogate markers are most commonly studied within the context of randomized clinical trials. However, the need for alternative outcomes extends beyond these settings and may be more pronounced in real-world public health and social science research, where randomized trials are often impractical. Research on identifying surrogates in real-world non-randomized data is scarce, as available statistical approaches for evaluating surrogate markers tend to rely on the assumption that treatment is randomized. While the few methods that allow for non-randomized treatment/exposure appropriately handle confounding individual characteristics, they do not offer a way to examine surrogate heterogeneity with respect to patient characteristics. In this paper, we propose a framework to assess surrogate heterogeneity in real-world, i.e., non-randomized, data and implement this framework using various meta-learners. Our approach allows us to quantify heterogeneity in surrogate strength with respect to patient characteristics while accommodating confounders through the use of flexible, off-the-shelf machine learning methods. In addition, we use our framework to identify individuals for whom the surrogate is a valid replacement of the primary outcome. We examine the performance of our methods via a simulation study and application to examine heterogeneity in the surrogacy of hemoglobin A1c as a surrogate for fasting plasma glucose.","authors":["Rebecca Knowlton","Layla Parast"],"url":"https://arxiv.org/abs/2504.15386"}
{"created":"2025-04-23","title":"Deep learning with missing data","abstract":"In the context of multivariate nonparametric regression with missing covariates, we propose Pattern Embedded Neural Networks (PENNs), which can be applied in conjunction with any existing imputation technique. In addition to a neural network trained on the imputed data, PENNs pass the vectors of observation indicators through a second neural network to provide a compact representation. The outputs are then combined in a third neural network to produce final predictions. Our main theoretical result exploits an assumption that the observation patterns can be partitioned into cells on which the Bayes regression function behaves similarly, and belongs to a compositional H\\\"older class. It provides a finite-sample excess risk bound that holds for an arbitrary missingness mechanism, and in combination with a complementary minimax lower bound, demonstrates that our PENN estimator attains in typical cases the minimax rate of convergence as if the cells of the partition were known in advance, up to a poly-logarithmic factor in the sample size. Numerical experiments on simulated, semi-synthetic and real data confirm that the PENN estimator consistently improves, often dramatically, on standard neural networks without pattern embedding. Code to reproduce our experiments, as well as a tutorial on how to apply our method, is publicly available.","authors":["Tianyi Ma","Tengyao Wang","Richard J. Samworth"],"url":"https://arxiv.org/abs/2504.15388"}
{"created":"2025-04-23","title":"$k$-Inductive and Interpolation-Inspired Barrier Certificates for Stochastic Dynamical Systems","abstract":"We introduce two notions of barrier certificates that use multiple functions to provide a lower bound on the probabilistic satisfaction of safety for stochastic dynamical systems. A barrier certificate for a stochastic dynamical system acts as a nonnegative supermartingale, and provides a lower bound on the probability that the system is safe. The promise of such certificates is that their search can be effectively automated. Typically, one may use optimization or SMT solvers to find such barrier certificates of a given fixed template. When such approaches fail, a typical approach is to instead change the template. We propose an alternative approach that we dub interpolation-inspired barrier certificates. An interpolation-inspired barrier certificate consists of a set of functions that jointly provide a lower bound on the probability of satisfying safety. We show how one may find such certificates of a fixed template, even when we fail to find standard barrier certificates of the same template. However, we note that such certificates still need to ensure a supermartingale guarantee for one function in the set. To address this challenge, we consider the use of $k$-induction with these interpolation-inspired certificates. The recent use of $k$-induction in barrier certificates allows one to relax the supermartingale requirement at every time step to a combination of a supermartingale requirement every $k$ steps and a $c$-martingale requirement for the intermediate steps. We provide a generic formulation of a barrier certificate that we dub $k$-inductive interpolation-inspired barrier certificate. The formulation allows for several combinations of interpolation and $k$-induction for barrier certificate. We present two examples among the possible combinations. We finally present sum-of-squares programming to synthesize this set of functions and demonstrate their utility in case studies.","authors":["Mohammed Adib Oumer","Vishnu Murali","Majid Zamani"],"url":"https://arxiv.org/abs/2504.15412"}
{"created":"2025-04-23","title":"Real-Time Sentiment Insights from X Using VADER, DistilBERT, and Web-Scraped Data","abstract":"In the age of social media, understanding public sentiment toward major corporations is crucial for investors, policymakers, and researchers. This paper presents a comprehensive sentiment analysis system tailored for corporate reputation monitoring, combining Natural Language Processing (NLP) and machine learning techniques to accurately interpret public opinion in real time. The methodology integrates a hybrid sentiment detection framework leveraging both rule-based models (VADER) and transformer-based deep learning models (DistilBERT), applied to social media data from multiple platforms. The system begins with robust preprocessing involving noise removal and text normalization, followed by sentiment classification using an ensemble approach to ensure both interpretability and contextual accuracy. Results are visualized through sentiment distribution plots, comparative analyses, and temporal sentiment trends for enhanced interpretability. Our analysis reveals significant disparities in public sentiment across major corporations, with companies like Amazon (81.2) and Samsung (45.8) receiving excellent sentiment scores, while Microsoft (21.7) and Walmart (21.9) exhibit poor sentiment profiles. These findings demonstrate the utility of our multi-source sentiment framework in providing actionable insights regarding corporate public perception, enabling stakeholders to make informed strategic decisions based on comprehensive sentiment analysis.","authors":["Yanampally Abhiram Reddy","Siddhi Agarwal","Vikram Parashar","Arshiya Arora"],"url":"https://arxiv.org/abs/2504.15448"}
{"created":"2025-04-23","title":"Split-quaternions for perceptual white balance","abstract":"We propose a perceptual chromatic adaptation transform for white balance that makes use of split-quaternions. The novelty of the present work, which is motivated by a recently developed quantum-like model of color perception, consists at stressing the link between the algebraic structures appearing in this model and a certain sub-algebra of the split-quaternions. We show the potentiality of this approach for color image processing applications by proposing a chromatic adaptation transform, implemented via an appropriate use of the split-quaternion multiplication. Moreover, quantitative comparisons with the widely used state-of-the art von Kries chromatic adaptation transform are provided.","authors":["Michel Berthier","Nicoletta Prencipe","Edoardo Provenzi"],"url":"https://arxiv.org/abs/2504.15481"}
{"created":"2025-04-23","title":"A Sensor-Driven Optimization Framework for Asset Management in Energy Systems: Implications for Full and Partial Digital Transformation in Hydro Fleets","abstract":"This paper proposes a novel prognostics-driven approach to optimize operations and maintenance (O&amp;M) decisions in hydropower systems. Our approach harnesses the insights from sensor data to accurately predict the remaining lifetime distribution of critical generation assets in hydropower systems, i.e., thrust bearings, and use these predictions to optimally schedule O&amp;M actions for a fleet of hydro generators. We consider complex interdependencies across hydro generator failure risks, reservoir, production, and demand management decisions. We propose a stochastic joint O&amp;M scheduling model to tackle the unique challenges of hydropower O&amp;M including the interdependency of generation capacities, the nonlinear nature of power production, operational requirements, and uncertainties. We develop a two-level decomposition-based solution algorithm to effectively handle large-scale cases. The algorithm incorporates a combination of Benders optimality cuts and integer cuts to solve the problem in an efficient manner. We design an experimental framework to evaluate the proposed prognostics-driven O&amp;M scheduling framework, using real-world condition monitoring data from hydropower systems, historical market prices, and water inflow data. The developed framework can be partially implemented for a phased-in approach. Our experiments demonstrate the significant benefits of the sensor-driven O&amp;M framework in improving reliability, availability, effective usage of resources, and system profitability, especially when gradually shifting from traditional time-based maintenance policies to condition-based prognostics-driven maintenance policies.","authors":["Farnaz Fallahi","Murat Yildirim","Shijia Zhao","Feng Qiu"],"url":"https://arxiv.org/abs/2504.15483"}
{"created":"2025-04-23","title":"Fluorescence Reference Target Quantitative Analysis Library","abstract":"Standardized performance evaluation of fluorescence imaging systems remains a critical unmet need in the field of fluorescence-guided surgery (FGS). While the American Association of Physicists in Medicine (AAPM) TG311 report and recent FDA draft guidance provide recommended metrics for system characterization, practical tools for extracting these metrics remain limited, inconsistent, and often inaccessible. We present QUEL-QAL, an open-source Python library designed to streamline and standardize the quantitative analysis of fluorescence images using solid reference targets. The library provides a modular, reproducible workflow that includes region of interest (ROI) detection, statistical analysis, and visualization capabilities. QUEL-QAL supports key metrics such as response linearity, limit of detection, depth sensitivity, and spatial resolution, in alignment with regulatory and academic guidance. Built on widely adopted Python packages, the library is designed to be extensible, enabling users to adapt it to novel target designs and analysis protocols. By promoting transparency, reproducibility, and regulatory alignment, QUEL-QAL offers a foundational tool to support standardized benchmarking and accelerate the development and evaluation of fluorescence imaging systems.","authors":["Eammon A. Littler","Emmanuel A. Mannoh","Ethan P. M. LaRochelle"],"url":"https://arxiv.org/abs/2504.15496"}
{"created":"2025-04-23","title":"Transport f divergences","abstract":"We define a class of divergences to measure differences between probability density functions in one-dimensional sample space. The construction is based on the convex function with the Jacobi operator of mapping function that pushforwards one density to the other. We call these information measures {\\em transport $f$-divergences}. We present several properties of transport $f$-divergences, including invariances, convexities, variational formulations, and Taylor expansions in terms of mapping functions. Examples of transport $f$-divergences in generative models are provided.","authors":["Wuchen Li"],"url":"https://arxiv.org/abs/2504.15515"}
{"created":"2025-04-23","title":"Bayesian information theoretic model-averaging stochastic item selection for computer adaptive testing: compromise-free item exposure","abstract":"The goal of Computer Adaptive Testing (CAT) is to reliably estimate an individual's ability as modeled by an item response theory (IRT) instrument using only a subset of the instrument's items. A secondary goal is to vary the items presented across different testing sessions so that the sequence of items does not become overly stereotypical -- we want all items to have an exposure rate sufficiently far from zero. We formulate the optimization problem for CAT in terms of Bayesian information theory, where one chooses the item at each step based on the criterion of the ability model discrepancy -- the statistical distance between the ability estimate at the next step and the full-test ability estimate. This viewpoint of CAT naturally motivates a stochastic selection procedure that equates choosing the next item to sampling from a model-averaging ensemble ability model. Using the NIH Work Disability Functional Assessment Battery (WD-FAB), we evaluate our new methods in comparison to pre-existing methods found in the literature. We find that our stochastic selector has superior properties in terms of both item exposure and test accuracy/efficiency.","authors":["Joshua C. Chang","Edison Choe"],"url":"https://arxiv.org/abs/2504.15543"}
{"created":"2025-04-23","title":"VLM-based Prompts as the Optimal Assistant for Unpaired Histopathology Virtual Staining","abstract":"In histopathology, tissue sections are typically stained using common H&amp;E staining or special stains (MAS, PAS, PASM, etc.) to clearly visualize specific tissue structures. The rapid advancement of deep learning offers an effective solution for generating virtually stained images, significantly reducing the time and labor costs associated with traditional histochemical staining. However, a new challenge arises in separating the fundamental visual characteristics of tissue sections from the visual differences induced by staining agents. Additionally, virtual staining often overlooks essential pathological knowledge and the physical properties of staining, resulting in only style-level transfer. To address these issues, we introduce, for the first time in virtual staining tasks, a pathological vision-language large model (VLM) as an auxiliary tool. We integrate contrastive learnable prompts, foundational concept anchors for tissue sections, and staining-specific concept anchors to leverage the extensive knowledge of the pathological VLM. This approach is designed to describe, frame, and enhance the direction of virtual staining. Furthermore, we have developed a data augmentation method based on the constraints of the VLM. This method utilizes the VLM's powerful image interpretation capabilities to further integrate image style and structural information, proving beneficial in high-precision pathological diagnostics. Extensive evaluations on publicly available multi-domain unpaired staining datasets demonstrate that our method can generate highly realistic images and enhance the accuracy of downstream tasks, such as glomerular detection and segmentation. Our code is available at: https://github.com/CZZZZZZZZZZZZZZZZZ/VPGAN-HARBOR","authors":["Zizhi Chen","Xinyu Zhang","Minghao Han","Yizhou Liu","Ziyun Qian","Weifeng Zhang","Xukun Zhang","Jingwei Wei","Lihua Zhang"],"url":"https://arxiv.org/abs/2504.15545"}
{"created":"2025-04-23","title":"Exploring the User Experience of AI-Assisted Sound Searching Systems for Creative Workflows","abstract":"Locating the right sound effect efficiently is an important yet challenging topic for audio production. Most current sound-searching systems rely on pre-annotated audio labels created by humans, which can be time-consuming to produce and prone to inaccuracies, limiting the efficiency of audio production. Following the recent advancement of contrastive language-audio pre-training (CLAP) models, we explore an alternative CLAP-based sound-searching system (CLAP-UI) that does not rely on human annotations. To evaluate the effectiveness of CLAP-UI, we conducted comparative experiments with a widely used sound effect searching platform, the BBC Sound Effect Library. Our study evaluates user performance, cognitive load, and satisfaction through ecologically valid tasks based on professional sound-searching workflows. Our result shows that CLAP-UI demonstrated significantly enhanced productivity and reduced frustration while maintaining comparable cognitive demands. We also qualitatively analyzed the participants' feedback, which offered valuable perspectives on the design of future AI-assisted sound search systems.","authors":["Haohe Liu","Thomas Deacon","Wenwu Wang","Matt Paradis","Mark D. Plumbley"],"url":"https://arxiv.org/abs/2504.15575"}
{"created":"2025-04-23","title":"Bayesian Parameter Estimation for Partially Observed McKean-Vlasov Diffusions Using Multilevel Markov chain Monte Carlo","abstract":"In this article we consider Bayesian estimation of static parameters for a class of partially observed McKean-Vlasov diffusion processes with discrete-time observations over a fixed time interval. This problem features several obstacles to its solution, which include that the posterior density is numerically intractable in continuous-time, even if the transition probabilities are available and even when one uses a time-discretization, the posterior still cannot be used by adopting well-known computational methods such as Markov chain Monte Carlo (MCMC). In this paper we provide a solution to this problem by using new MCMC algorithms which can solve the afore-mentioned issues. This MCMC algorithm is extended to use multilevel Monte Carlo (MLMC) methods. We prove convergence bounds on our parameter estimators and show that the MLMC-based MCMC algorithm reduces the computational cost to achieve a mean square error versus ordinary MCMC by an order of magnitude. We numerically illustrate our results on two models.","authors":["Ajay Jasra","Amin Wu"],"url":"https://arxiv.org/abs/2504.15588"}
{"created":"2025-04-23","title":"Quantum Speedup for Sampling Random Spanning Trees","abstract":"We present a quantum algorithm for sampling random spanning trees from a weighted graph in $\\widetilde{O}(\\sqrt{mn})$ time, where $n$ and $m$ denote the number of vertices and edges, respectively. Our algorithm has sublinear runtime for dense graphs and achieves a quantum speedup over the best-known classical algorithm, which runs in $\\widetilde{O}(m)$ time. The approach carefully combines, on one hand, a classical method based on ``large-step'' random walks for reduced mixing time and, on the other hand, quantum algorithmic techniques, including quantum graph sparsification and a sampling-without-replacement variant of Hamoudi's multiple-state preparation. We also establish a matching lower bound, proving the optimality of our algorithm up to polylogarithmic factors. These results highlight the potential of quantum computing in accelerating fundamental graph sampling problems.","authors":["Chenghua Liu","Minbo Gao","Zhengfeng Ji","Simon Apers"],"url":"https://arxiv.org/abs/2504.15603"}
{"created":"2025-04-23","title":"RepNet-VSR: Reparameterizable Architecture for High-Fidelity Video Super-Resolution","abstract":"As a fundamental challenge in visual computing, video super-resolution (VSR) focuses on reconstructing highdefinition video sequences from their degraded lowresolution counterparts. While deep convolutional neural networks have demonstrated state-of-the-art performance in spatial-temporal super-resolution tasks, their computationally intensive nature poses significant deployment challenges for resource-constrained edge devices, particularly in real-time mobile video processing scenarios where power efficiency and latency constraints coexist. In this work, we propose a Reparameterizable Architecture for High Fidelity Video Super Resolution method, named RepNet-VSR, for real-time 4x video super-resolution. On the REDS validation set, the proposed model achieves 27.79 dB PSNR when processing 180p to 720p frames in 103 ms per 10 frames on a MediaTek Dimensity NPU. The competition results demonstrate an excellent balance between restoration quality and deployment efficiency. The proposed method scores higher than the previous champion algorithm of MAI video super-resolution challenge.","authors":["Biao Wu","Diankai Zhang","Shaoli Liu","Si Gao","Chengjian Zheng","Ning Wang"],"url":"https://arxiv.org/abs/2504.15649"}
{"created":"2025-04-23","title":"FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep Learning","abstract":"Recently, fake audio detection has gained significant attention, as advancements in speech synthesis and voice conversion have increased the vulnerability of automatic speaker verification (ASV) systems to spoofing attacks. A key challenge in this task is generalizing models to detect unseen, out-of-distribution (OOD) attacks. Although existing approaches have shown promising results, they inherently suffer from overconfidence issues due to the usage of softmax for classification, which can produce unreliable predictions when encountering unpredictable spoofing attempts. To deal with this limitation, we propose a novel framework called fake audio detection with evidential learning (FADEL). By modeling class probabilities with a Dirichlet distribution, FADEL incorporates model uncertainty into its predictions, thereby leading to more robust performance in OOD scenarios. Experimental results on the ASVspoof2019 Logical Access (LA) and ASVspoof2021 LA datasets indicate that the proposed method significantly improves the performance of baseline models. Furthermore, we demonstrate the validity of uncertainty estimation by analyzing a strong correlation between average uncertainty and equal error rate (EER) across different spoofing algorithms.","authors":["Ju Yeon Kang","Ji Won Yoon","Semin Kim","Min Hyun Han","Nam Soo Kim"],"url":"https://arxiv.org/abs/2504.15663"}
{"created":"2025-04-23","title":"Performance Estimation for Supervised Medical Image Segmentation Models on Unlabeled Data Using UniverSeg","abstract":"The performance of medical image segmentation models is usually evaluated using metrics like the Dice score and Hausdorff distance, which compare predicted masks to ground truth annotations. However, when applying the model to unseen data, such as in clinical settings, it is often impractical to annotate all the data, making the model's performance uncertain. To address this challenge, we propose the Segmentation Performance Evaluator (SPE), a framework for estimating segmentation models' performance on unlabeled data. This framework is adaptable to various evaluation metrics and model architectures. Experiments on six publicly available datasets across six evaluation metrics including pixel-based metrics such as Dice score and distance-based metrics like HD95, demonstrated the versatility and effectiveness of our approach, achieving a high correlation (0.956$\\pm$0.046) and low MAE (0.025$\\pm$0.019) compare with real Dice score on the independent test set. These results highlight its ability to reliably estimate model performance without requiring annotations. The SPE framework integrates seamlessly into any model training process without adding training overhead, enabling performance estimation and facilitating the real-world application of medical image segmentation algorithms. The source code is publicly available","authors":["Jingchen Zou","Jianqiang Li","Gabriel Jimenez","Qing Zhao","Daniel Racoceanu","Matias Cosarinsky","Enzo Ferrante","Guanghui Fu"],"url":"https://arxiv.org/abs/2504.15667"}
{"created":"2025-04-23","title":"Policy-Based Radiative Transfer: Solving the $2$-Level Atom Non-LTE Problem using Soft Actor-Critic Reinforcement Learning","abstract":"We present a novel reinforcement learning (RL) approach for solving the classical 2-level atom non-LTE radiative transfer problem by framing it as a control task in which an RL agent learns a depth-dependent source function $S(\\tau)$ that self-consistently satisfies the equation of statistical equilibrium (SE). The agent's policy is optimized entirely via reward-based interactions with a radiative transfer engine, without explicit knowledge of the ground truth. This method bypasses the need for constructing approximate lambda operators ($\\Lambda^*$) common in accelerated iterative schemes. Additionally, it requires no extensive precomputed labeled datasets to extract a supervisory signal, and avoids backpropagating gradients through the complex RT solver itself. Finally, we show through experiment that a simple feedforward neural network trained greedily cannot solve for SE, possibly due to the moving target nature of the problem. Our $\\Lambda^*-\\text{Free}$ method offers potential advantages for complex scenarios (e.g., atmospheres with enhanced velocity fields, multi-dimensional geometries, or complex microphysics) where $\\Lambda^*$ construction or solver differentiability is challenging. Additionally, the agent can be incentivized to find more efficient policies by manipulating the discount factor, leading to a reprioritization of immediate rewards. If demonstrated to generalize past its training data, this RL framework could serve as an alternative or accelerated formalism to achieve SE. To the best of our knowledge, this study represents the first application of reinforcement learning in solar physics that directly solves for a fundamental physical constraint.","authors":["Brandon Panos","Ivan Milic"],"url":"https://arxiv.org/abs/2504.15679"}
{"created":"2025-04-23","title":"Transfer Learning for High-dimensional Reduced Rank Time Series Models","abstract":"The objective of transfer learning is to enhance estimation and inference in a target data by leveraging knowledge gained from additional sources. Recent studies have explored transfer learning for independent observations in complex, high-dimensional models assuming sparsity, yet research on time series models remains limited. Our focus is on transfer learning for sequences of observations with temporal dependencies and a more intricate model parameter structure. Specifically, we investigate the vector autoregressive model (VAR), a widely recognized model for time series data, where the transition matrix can be deconstructed into a combination of a sparse matrix and a low-rank one. We propose a new transfer learning algorithm tailored for estimating high-dimensional VAR models characterized by low-rank and sparse structures. Additionally, we present a novel approach for selecting informative observations from auxiliary datasets. Theoretical guarantees are established, encompassing model parameter consistency, informative set selection, and the asymptotic distribution of estimators under mild conditions. The latter facilitates the construction of entry-wise confidence intervals for model parameters. Finally, we demonstrate the empirical efficacy of our methodologies through both simulated and real-world datasets.","authors":["Mingliang Ma Abolfazl Safikhani"],"url":"https://arxiv.org/abs/2504.15691"}
{"created":"2025-04-23","title":"From predictions to confidence intervals: an empirical study of conformal prediction methods for in-context learning","abstract":"Transformers have become a standard architecture in machine learning, demonstrating strong in-context learning (ICL) abilities that allow them to learn from the prompt at inference time. However, uncertainty quantification for ICL remains an open challenge, particularly in noisy regression tasks. This paper investigates whether ICL can be leveraged for distribution-free uncertainty estimation, proposing a method based on conformal prediction to construct prediction intervals with guaranteed coverage. While traditional conformal methods are computationally expensive due to repeated model fitting, we exploit ICL to efficiently generate confidence intervals in a single forward pass. Our empirical analysis compares this approach against ridge regression-based conformal methods, showing that conformal prediction with in-context learning (CP with ICL) achieves robust and scalable uncertainty estimates. Additionally, we evaluate its performance under distribution shifts and establish scaling laws to guide model training. These findings bridge ICL and conformal prediction, providing a theoretically grounded and new framework for uncertainty quantification in transformer-based models.","authors":["Zhe Huang","Simone Rossi","Rui Yuan","Thomas Hannagan"],"url":"https://arxiv.org/abs/2504.15722"}
{"created":"2025-04-23","title":"Markov Kernels, Distances and Optimal Control: A Parable of Linear Quadratic Non-Gaussian Distribution Steering","abstract":"For a controllable linear time-varying (LTV) pair $(\\boldsymbol{A}_t,\\boldsymbol{B}_t)$ and $\\boldsymbol{Q}_{t}$ positive semidefinite, we derive the Markov kernel for the It\\^{o} diffusion ${\\mathrm{d}}\\boldsymbol{x}_{t}=\\boldsymbol{A}_{t}\\boldsymbol{x}_t {\\mathrm{d}} t + \\sqrt{2}\\boldsymbol{B}_{t}{\\mathrm{d}}\\boldsymbol{w}_{t}$ with an accompanying killing of probability mass at rate $\\frac{1}{2}\\boldsymbol{x}^{\\top}\\boldsymbol{Q}_{t}\\boldsymbol{x}$. This Markov kernel is the Green's function for an associated linear reaction-advection-diffusion partial differential equation. Our result generalizes the recently derived kernel for the special case $\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t\\right)=\\left(\\boldsymbol{0},\\boldsymbol{I}\\right)$, and depends on the solution of an associated Riccati matrix ODE. A consequence of this result is that the linear quadratic non-Gaussian Schr\\\"{o}dinger bridge is exactly solvable. This means that the problem of steering a controlled LTV diffusion from a given non-Gaussian distribution to another over a fixed deadline while minimizing an expected quadratic cost can be solved using dynamic Sinkhorn recursions performed with the derived kernel. Our derivation for the $\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t,\\boldsymbol{Q}_t\\right)$-parametrized kernel pursues a new idea that relies on finding a state-time dependent distance-like functional given by the solution of a deterministic optimal control problem. This technique breaks away from existing methods, such as generalizing Hermite polynomials or Weyl calculus, which have seen limited success in the reaction-diffusion context. Our technique uncovers a new connection between Markov kernels, distances, and optimal control. This connection is of interest beyond its immediate application in solving the linear quadratic Schr\\\"{o}dinger bridge problem.","authors":["Alexis M. H. Teter","Wenqing Wang","Sachin Shivakumar","Abhishek Halder"],"url":"https://arxiv.org/abs/2504.15753"}
{"created":"2025-04-23","title":"A Line Graph-Based Framework for Identifying Optimal Routing Paths in Decentralized Exchanges","abstract":"Decentralized exchanges, such as those employing constant product market makers (CPMMs) like Uniswap V2, play a crucial role in the blockchain ecosystem by enabling peer-to-peer token swaps without intermediaries. Despite the increasing volume of transactions, there remains limited research on identifying optimal trading paths across multiple DEXs. This paper presents a novel line-graph-based algorithm (LG) designed to efficiently discover profitable trading routes within DEX environments. We benchmark LG against the widely adopted Depth-First Search (DFS) algorithm under a linear routing scenario, encompassing platforms such as Uniswap, SushiSwap, and PancakeSwap. Experimental results demonstrate that LG consistently identifies trading paths that are as profitable as, or more profitable than, those found by DFS, while incurring comparable gas costs. Evaluations on Uniswap V2 token graphs across two temporal snapshots further validate LG's performance. Although LG exhibits exponential runtime growth with respect to graph size in empirical tests, it remains viable for practical, real-world use cases. Our findings underscore the potential of the LG algorithm for industrial adoption, offering tangible benefits to traders and market participants in the DeFi space.","authors":["Yu Zhang","Yafei Li","Claudio Tessone"],"url":"https://arxiv.org/abs/2504.15809"}
{"created":"2025-04-23","title":"Full waveform inversion with CNN-based velocity representation extension","abstract":"Full waveform inversion (FWI) updates the velocity model by minimizing the discrepancy between observed and simulated data. However, discretization errors in numerical modeling and incomplete seismic data acquisition can introduce noise, which propagates through the adjoint operator and affects the accuracy of the velocity gradient, thereby impacting the FWI inversion accuracy. To mitigate the influence of noise on the gradient, we employ a convolutional neural network (CNN) to refine the velocity model before performing the forward simulation, aiming to reduce noise and provide a more accurate velocity update direction. We use the same data misfit loss to update both the velocity and network parameters, thereby forming a self-supervised learning procedure. We propose two implementation schemes, which differ in whether the velocity update passes through the CNN. In both methodologies, the velocity representation is extended (VRE) by using a neural network in addition to the grid-based velocities. Thus, we refer to this general approach as VRE-FWI. Synthetic and real data tests demonstrate that the proposed VRE-FWI achieves higher velocity inversion accuracy compared to traditional FWI, at a marginal additional computational cost of approximately 1%.","authors":["Xinru Mu","Omar M. Saad","Tariq Alkhalifah"],"url":"https://arxiv.org/abs/2504.15826"}
{"created":"2025-04-23","title":"Continuity Conditions for Piecewise Quadratic Functions on Simplicial Conic Partitions are Equivalent","abstract":"Analysis of continuous-time piecewise linear (PWL) systems based on piecewise quadratic (PWQ) Lyapunov functions typically requires continuity of these functions over a partition of the state space. Several conditions for guaranteeing continuity of PWQ functions over state space partitions can be found in the literature. In this technical note, we show that these continuity conditions are equivalent over so-called simplicial conic partitions. A key element in our proof is a technical lemma, which, in addition to being of independent interest, plays a crucial role in demonstrating the equivalence of these conditions. As a consequence, the choice of which condition to impose can be based solely on practical considerations such as specific application or numerical aspects, without introducing additional conservatism in the analysis.","authors":["Magne Erlandsen","Tomas Meijer","Maurice Heemels","Sebastiaan van den Eijnden"],"url":"https://arxiv.org/abs/2504.15914"}
{"created":"2025-04-23","title":"Over-the-Air Transmission of Zak-OTFS with Spread Pilots on Sub-THz Communications Testbed","abstract":"Looking towards 6G wireless systems, frequency bands like the sub-terahertz (sub-THz) band (100 GHz - 300 GHz) are gaining traction for their promises of large available swaths of bandwidth to support the ever-growing data demands. However, challenges with harsh channel conditions and hardware nonlinearities in the sub-THz band require robust communication techniques with favorable properties, such as good spectral efficiency and low peak-to-average power ratio (PAPR). Recently, OTFS and its variants have garnered significant attention for their performance in severe conditions (like high delay and Doppler), making it a promising candidate for future communications. In this work, we implement Zak-OTFS for the over-the-air experiments with traditional point pilots and the new spread pilots. Notably, we design our spread-pilot waveforms with communications and sensing coexisting in the same radio resources. We define the system model and the signal design for integration onto our state-of-the-art sub-THz wireless testbed. We show successful data transmission over-the-air at 140 GHz and 240 GHz in a variety of signal-to-noise ratio (SNR) conditions. In addition, we demonstrate integrated sensing and communications (ISAC) capabilities and show PAPR improvement of over 5 dB with spread pilots compared to point pilots.","authors":["Claire Parisi","Venkatesh Khammammetti","Robert Calderbank","Lauren Huie"],"url":"https://arxiv.org/abs/2504.15947"}
{"created":"2025-04-23","title":"Benchmarking machine learning models for predicting aerofoil performance","abstract":"This paper investigates the capability of Neural Networks (NNs) as alternatives to the traditional methods to analyse the performance of aerofoils used in the wind and tidal energy industry. The current methods used to assess the characteristic lift and drag coefficients include Computational Fluid Dynamics (CFD), thin aerofoil and panel methods, all face trade-offs between computational speed and the accuracy of the results and as such NNs have been investigated as an alternative with the aim that it would perform both quickly and accurately. As such, this paper provides a benchmark for the windAI_bench dataset published by the National Renewable Energy Laboratory (NREL) in the USA. In order to validate the methodology of the benchmarking, the AirfRANS {\\tt arXiv:2212.07564v3} dataset is used as both a starting point and a point of comparison. This study evaluates four neural networks (MLP, PointNet, GraphSAGE, GUNet) trained on a range aerofoils at 25 angles of attack (4$^\\circ$ to 20$^\\circ$). to predict fluid flow and calculate lift coefficients ($C_L$) via the panel method. GraphSAGE and GUNet performed well during the testing phase, but underperformed during validation. Accordingly, this paper has identified PointNet and MLP as the two strongest models tested, however whilst the results from MLP are more commonly correct for predicting the behaviour of the fluid, the results from PointNet provide the more accurate results for calculating $C_L$.","authors":["Oliver Summerell","Gerardo Aragon-Camarasa","Stephanie Ordonez Sanchez"],"url":"https://arxiv.org/abs/2504.15993"}
{"created":"2025-04-23","title":"How Private is Your Attention? Bridging Privacy with In-Context Learning","abstract":"In-context learning (ICL)-the ability of transformer-based models to perform new tasks from examples provided at inference time-has emerged as a hallmark of modern language models. While recent works have investigated the mechanisms underlying ICL, its feasibility under formal privacy constraints remains largely unexplored. In this paper, we propose a differentially private pretraining algorithm for linear attention heads and present the first theoretical analysis of the privacy-accuracy trade-off for ICL in linear regression. Our results characterize the fundamental tension between optimization and privacy-induced noise, formally capturing behaviors observed in private training via iterative methods. Additionally, we show that our method is robust to adversarial perturbations of training prompts, unlike standard ridge regression. All theoretical findings are supported by extensive simulations across diverse settings.","authors":["Soham Bonnerjee (Kingsley)","Zhen Wei (Kingsley)","Yeon","Anna Asch","Sagnik Nandy","Promit Ghosal"],"url":"https://arxiv.org/abs/2504.16000"}
{"created":"2025-04-23","title":"High-performance training and inference for deep equivariant interatomic potentials","abstract":"Machine learning interatomic potentials, particularly those based on deep equivariant neural networks, have demonstrated state-of-the-art accuracy and computational efficiency in atomistic modeling tasks like molecular dynamics and high-throughput screening. The size of datasets and demands of downstream workflows are growing rapidly, making robust and scalable software essential. This work presents a major overhaul of the NequIP framework focusing on multi-node parallelism, computational performance, and extensibility. The redesigned framework supports distributed training on large datasets and removes barriers preventing full utilization of the PyTorch 2.0 compiler at train time. We demonstrate this acceleration in a case study by training Allegro models on the SPICE 2 dataset of organic molecular systems. For inference, we introduce the first end-to-end infrastructure that uses the PyTorch Ahead-of-Time Inductor compiler for machine learning interatomic potentials. Additionally, we implement a custom kernel for the Allegro model's most expensive operation, the tensor product. Together, these advancements speed up molecular dynamics calculations on system sizes of practical relevance by up to a factor of 18.","authors":["Chuin Wei Tan","Marc L. Descoteaux","Mit Kotak","Gabriel de Miranda Nascimento","Se\\'an R. Kavanagh","Laura Zichi","Menghang Wang","Aadit Saluja","Yizhong R. Hu","Tess Smidt","Anders Johansson","William C. Witt","Boris Kozinsky","Albert Musaelian"],"url":"https://arxiv.org/abs/2504.16068"}
{"created":"2025-04-23","title":"Explainable Unsupervised Anomaly Detection with Random Forest","abstract":"We describe the use of an unsupervised Random Forest for similarity learning and improved unsupervised anomaly detection. By training a Random Forest to discriminate between real data and synthetic data sampled from a uniform distribution over the real data bounds, a distance measure is obtained that anisometrically transforms the data, expanding distances at the boundary of the data manifold. We show that using distances recovered from this transformation improves the accuracy of unsupervised anomaly detection, compared to other commonly used detectors, demonstrated over a large number of benchmark datasets. As well as improved performance, this method has advantages over other unsupervised anomaly detection methods, including minimal requirements for data preprocessing, native handling of missing data, and potential for visualizations. By relating outlier scores to partitions of the Random Forest, we develop a method for locally explainable anomaly predictions in terms of feature importance.","authors":["Joshua S. Harvey","Joshua Rosaler","Mingshu Li","Dhruv Desai","Dhagash Mehta"],"url":"https://arxiv.org/abs/2504.16075"}
{"created":"2025-04-23","title":"Decisiveness for countable MDPs and insights for NPLCSs and POMDPs","abstract":"Markov chains and Markov decision processes (MDPs) are well-established probabilistic models. While finite Markov models are well-understood, analysing their infinite counterparts remains a significant challenge. Decisiveness has proven to be an elegant property for countable Markov chains: it is general enough to be satisfied by several natural classes of countable Markov chains, and it is a sufficient condition for simple qualitative and approximate quantitative model-checking algorithms to exist.","authors":["Nathalie Bertrand","Patricia Bouyer","Thomas Brihaye","Paulin Fournier","Pierre Vandenhove"],"url":"https://arxiv.org/abs/2008.10426"}
{"created":"2025-04-23","title":"An Operator Splitting View of Federated Learning","abstract":"Over the past few years, the federated learning ($\\texttt{FL}$) community has witnessed a proliferation of new $\\texttt{FL}$ algorithms. However, our understating of the theory of $\\texttt{FL}$ is still fragmented, and a thorough, formal comparison of these algorithms remains elusive. Motivated by this gap, we show that many of the existing $\\texttt{FL}$ algorithms can be understood from an operator splitting point of view. This unification allows us to compare different algorithms with ease, to refine previous convergence results and to uncover new algorithmic variants. In particular, our analysis reveals the vital role played by the step size in $\\texttt{FL}$ algorithms. The unification also leads to a streamlined and economic way to accelerate $\\texttt{FL}$ algorithms, without incurring any communication overhead. We perform numerical experiments on both convex and nonconvex models to validate our findings.","authors":["Saber Malekmohammadi","Kiarash Shaloudegi","Zeou Hu","Yaoliang Yu"],"url":"https://arxiv.org/abs/2108.05974"}
{"created":"2025-04-23","title":"Computing well-balanced spanning trees of unweighted networks","abstract":"A spanning tree of a network or graph is a subgraph that connects all nodes with the least number or weight of edges. The spanning tree is one of the most straightforward techniques for network simplification and sampling, and for discovering its backbone or skeleton. Prim's algorithm and Kruskal's algorithm are well-known algorithms for computing a spanning tree of a weighted network, and are therefore also the default procedure for unweighted networks in the most popular network libraries. In this paper, we empirically study the performance of these algorithms on unweighted networks and compare them with different priority-first search algorithms. We show that the structure of a network, such as the distances between the nodes, is better preserved by a simpler algorithm based on breadth-first search. The spanning trees are also most compact and well-balanced as measured by classical graph indices. We support our findings with experiments on synthetic graphs and more than a thousand real networks, and demonstrate practical applications of the computed spanning trees. We conclude that if a spanning tree is to maintain the structure of an unweighted network, the breadth-first search algorithm should be the preferred choice.","authors":["Lovro \\v{S}ubelj"],"url":"https://arxiv.org/abs/2205.06628"}
{"created":"2025-04-23","title":"Flow-augmentation III: Complexity dichotomy for Boolean CSPs parameterized by the number of unsatisfied constraints","abstract":"We study the parameterized problem of satisfying ``almost all'' constraints of a given formula $F$ over a fixed, finite Boolean constraint language $\\Gamma$, with or without weights. More precisely, for each finite Boolean constraint language $\\Gamma$, we consider the following two problems. In Min SAT$(\\Gamma)$, the input is a formula $F$ over $\\Gamma$ and an integer $k$, and the task is to find an assignment $\\alpha \\colon V(F) \\to \\{0,1\\}$ that satisfies all but at most $k$ constraints of $F$, or determine that no such assignment exists. In Weighted Min SAT$(\\Gamma$), the input additionally contains a weight function $w \\colon F \\to \\mathbb{Z}_+$ and an integer $W$, and the task is to find an assignment $\\alpha$ such that (1) $\\alpha$ satisfies all but at most $k$ constraints of $F$, and (2) the total weight of the violated constraints is at most $W$. We give a complete dichotomy for the fixed-parameter tractability of these problems: We show that for every Boolean constraint language $\\Gamma$, either Weighted Min SAT$(\\Gamma)$ is FPT; or Weighted Min SAT$(\\Gamma)$ is W[1]-hard but Min SAT$(\\Gamma)$ is FPT; or Min SAT$(\\Gamma)$ is W[1]-hard. This generalizes recent work of Kim et al. (SODA 2021) which did not consider weighted problems, and only considered languages $\\Gamma$ that cannot express implications $(u \\to v)$ (as is used to, e.g., model digraph cut problems). Our result generalizes and subsumes multiple previous results, including the FPT algorithms for Weighted Almost 2-SAT, weighted and unweighted $\\ell$-Chain SAT, and Coupled Min-Cut, as well as weighted and directed versions of the latter. The main tool used in our algorithms is the recently developed method of directed flow-augmentation (Kim et al., STOC 2022).","authors":["Eun Jung Kim","Stefan Kratsch","Marcin Pilipczuk","Magnus Wahlstr\\\"om"],"url":"https://arxiv.org/abs/2207.07422"}
{"created":"2025-04-23","title":"A Primer on Zadoff Chu Sequences","abstract":"Zadoff-Chu (ZC) sequences are an important manifestation of spread spectrum in modern cellular systems, including LTE and 5G NR. They have to some extent displaced PN and Walsh sequences which were the mainstays of 3G cellular (WCDMA and cdma2000) and the 2G-era IS-95. ZC sequences are complex sequences with unit amplitude and particular phase shifts, as opposed to Walsh and PN codes which are real and binary valued, most commonly $\\pm1$.","authors":["Jeffrey G. Andrews"],"url":"https://arxiv.org/abs/2211.05702"}
{"created":"2025-04-23","title":"Aggregating Soft Labels from Crowd Annotations Improves Uncertainty Estimation Under Distribution Shift","abstract":"Selecting an effective training signal for machine learning tasks is difficult: expert annotations are expensive, and crowd-sourced annotations may not be reliable. Recent work has demonstrated that learning from a distribution over labels acquired from crowd annotations can be effective both for performance and uncertainty estimation. However, this has mainly been studied using a limited set of soft-labeling methods in an in-domain setting. Additionally, no one method has been shown to consistently perform well across tasks, making it difficult to know a priori which to choose. To fill these gaps, this paper provides the first large-scale empirical study on learning from crowd labels in the out-of-domain setting, systematically analyzing 8 soft-labeling methods on 4 language and vision tasks. Additionally, we propose to aggregate soft-labels via a simple average in order to achieve consistent performance across tasks. We demonstrate that this yields classifiers with improved predictive uncertainty estimation in most settings while maintaining consistent raw performance compared to learning from individual soft-labeling methods or taking a majority vote of the annotations. We additionally highlight that in regimes with abundant or minimal training data, the selection of soft labeling method is less important, while for highly subjective labels and moderate amounts of training data, aggregation yields significant improvements in uncertainty estimation over individual methods. Code can be found at https://github.com/copenlu/aggregating-crowd-annotations-ood.","authors":["Dustin Wright","Isabelle Augenstein"],"url":"https://arxiv.org/abs/2212.09409"}
{"created":"2025-04-23","title":"LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene Graphs with Weak Supervision","abstract":"Supervised approaches for learning spatio-temporal scene graphs (STSG) from video are greatly hindered due to their reliance on STSG-annotated videos, which are labor-intensive to construct at scale. Is it feasible to instead use readily available video captions as weak supervision? To address this question, we propose LASER, a neuro-symbolic framework to enable training STSG generators using only video captions. LASER employs large language models to first extract logical specifications with rich spatio-temporal semantic information from video captions. LASER then trains the underlying STSG generator to align the predicted STSG with the specification. The alignment algorithm overcomes the challenges of weak supervision by leveraging a differentiable symbolic reasoner and using a combination of contrastive, temporal, and semantics losses. The overall approach efficiently trains low-level perception models to extract a fine-grained STSG that conforms to the video caption. In doing so, it enables a novel methodology for learning STSGs without tedious annotations. We evaluate our method on three video datasets: OpenPVSG, 20BN, and MUGEN. Our approach demonstrates substantial improvements over fully-supervised baselines, achieving a unary predicate prediction accuracy of 27.78% (+12.65%) and a binary recall@5 of 0.42 (+0.22) on OpenPVSG. Additionally, LASER exceeds baselines by 7% on 20BN and 5.2% on MUGEN in terms of overall predicate prediction accuracy.","authors":["Jiani Huang","Ziyang Li","Mayur Naik","Ser-Nam Lim"],"url":"https://arxiv.org/abs/2304.07647"}
{"created":"2025-04-23","title":"Sharp inverse statements for kernel interpolation","abstract":"While direct statements for kernel based interpolation on regions $\\Omega \\subset \\mathbb{R}^d$ are well researched, far less is known about corresponding inverse statements. The available inverse statements for kernel based interpolation so far are not sharp. In this paper, we derive sharp inverse statements for interpolation using finitely smooth kernels, such as popular radial basis function (RBF) kernels like the class of Mat\\'ern or Wendland kernels. In particular, the results show that there is a one-to-one correspondence between the smoothness of a function and its approximation rate via kernel interpolation: If a function can be approximated with a given rate, it has a corresponding smoothness and vice versa.","authors":["Tizian Wenzel"],"url":"https://arxiv.org/abs/2306.14618"}
{"created":"2025-04-23","title":"Revolutionizing Wireless Networks with Federated Learning: A Comprehensive Review","abstract":"These days with the rising computational capabilities of wireless user equipment such as smart phones, tablets, and vehicles, along with growing concerns about sharing private data, a novel machine learning model called federated learning (FL) has emerged. FL enables the separation of data acquisition and computation at the central unit, which is different from centralized learning that occurs in a data center. FL is typically used in a wireless edge network where communication resources are limited and unreliable. Bandwidth constraints necessitate scheduling only a subset of UEs for updates in each iteration, and because the wireless medium is shared, transmissions are susceptible to interference and are not assured. The article discusses the significance of Machine Learning in wireless communication and highlights Federated Learning (FL) as a novel approach that could play a vital role in future mobile networks, particularly 6G and beyond.","authors":["Sajjad Emdadi Mahdimahalleh"],"url":"https://arxiv.org/abs/2308.04404"}
{"created":"2025-04-23","title":"Language Models for Business Optimisation with a Real World Case Study in Production Scheduling","abstract":"Business optimisation has been used extensively to determine optimal solutions for challenging business operations. Problem formulation is an important part of business optimisation as it influences both the validity of solutions and the efficiency of the optimisation process. While different optimisation modelling languages have been developed, problem formulation is still not a trivial task and usually requires optimisation expertise and problem-domain knowledge. Recently, Large Language Models (LLMs) have demonstrated outstanding performance across different language-related tasks. Since problem formulation can be viewed as a translation task, there is a potential to leverage LLMs to automate problem formulation. However, developing an LLM for problem formulation is challenging, due to limited training data, and the complexity of real-world optimisation problems. Several prompt engineering methods have been proposed in the literature to automate problem formulation with LLMs. While the initial results are encouraging, the accuracy of formulations generated by these methods can still be significantly improved. In this paper, we present an LLM-based framework for automating problem formulation in business optimization. Our approach introduces a method for fine-tuning cost-efficient LLMs specifically tailored to specialized business optimization challenges. The experiment results demonstrate that our framework can generate accurate formulations for conventional and real-world business optimisation problems in production scheduling. Extensive analyses show the effectiveness and the convergence of the proposed fine-tuning method. The proposed method also shows very competitive performance when compared with the state-of-the-art prompt engineering methods in the literature when tested on general linear programming problems.","authors":["Pivithuru Thejan Amarasinghe","Su Nguyen","Yuan Sun","Damminda Alahakoon"],"url":"https://arxiv.org/abs/2309.13218"}
{"created":"2025-04-23","title":"EMelodyGen: Emotion-Conditioned Melody Generation in ABC Notation with the Musical Feature Template","abstract":"The EMelodyGen system focuses on emotional melody generation in ABC notation controlled by the musical feature template. Owing to the scarcity of well-structured and emotionally labeled sheet music, we designed a template for controlling emotional melody generation by statistical correlations between musical features and emotion labels derived from small-scale emotional symbolic music datasets and music psychology conclusions. We then automatically annotated a large, well-structured sheet music collection with rough emotional labels by the template, converted them into ABC notation, and reduced label imbalance by data augmentation, resulting in a dataset named Rough4Q. Our system backbone pre-trained on Rough4Q can achieve up to 99% music21 parsing rate and melodies generated by our template can lead to a 91% alignment on emotional expressions in blind listening tests. Ablation studies further validated the effectiveness of the feature controls in the template. Available code and demos are at https://github.com/monetjoe/EMelodyGen.","authors":["Monan Zhou","Xiaobing Li","Feng Yu","Wei Li"],"url":"https://arxiv.org/abs/2309.13259"}
{"created":"2025-04-23","title":"DaPPA: A Data-Parallel Programming Framework for Processing-in-Memory Architectures","abstract":"The growing volume of data in modern applications has led to significant computational costs in conventional processor-centric systems. Processing-in-memory (PIM) architectures alleviate these costs by moving computation closer to memory, reducing data movement overheads. UPMEM is the first commercially available PIM system, featuring thousands of in-order processors (DPUs) integrated within DRAM modules. However, a programming UPMEM-based system remains challenging due to the need for explicit data management and workload partitioning across DPUs.","authors":["Geraldo F. Oliveira","Alain Kohli","David Novo","Ataberk Olgun","A. Giray Yaglikci","Saugata Ghose","Juan G\\'omez-Luna","Onur Mutlu"],"url":"https://arxiv.org/abs/2310.10168"}
{"created":"2025-04-23","title":"Mission-driven Exploration for Accelerated Deep Reinforcement Learning with Temporal Logic Task Specifications","abstract":"This paper addresses the problem of designing control policies for agents with unknown stochastic dynamics and control objectives specified using Linear Temporal Logic (LTL). Recent Deep Reinforcement Learning (DRL) algorithms have aimed to compute policies that maximize the satisfaction probability of LTL formulas, but they often suffer from slow learning performance. To address this, we introduce a novel Deep Q-learning algorithm that significantly improves learning speed. The enhanced sample efficiency stems from a mission-driven exploration strategy that prioritizes exploration towards directions likely to contribute to mission success. Identifying these directions relies on an automaton representation of the LTL task as well as a learned neural network that partially models the agent-environment interaction. We provide comparative experiments demonstrating the efficiency of our algorithm on robot navigation tasks in unseen environments.","authors":["Jun Wang","Hosein Hasanbeig","Kaiyuan Tan","Zihe Sun","Yiannis Kantaros"],"url":"https://arxiv.org/abs/2311.17059"}
{"created":"2025-04-23","title":"Building symmetries into data-driven manifold dynamics models for complex flows: application to two-dimensional Kolmogorov flow","abstract":"Data-driven reduced-order models of the dynamics of complex flows are important for tasks related to design, understanding, prediction, and control. Many flows obey symmetries, and the present work illustrates how these can be exploited to yield highly efficient low-dimensional data-driven models for chaotic flows. In particular, incorporating symmetries both guarantees that the reduced order model automatically respects them and dramatically increases the effective density of data sampling. Given data for the long-time dynamics of a system, and knowing the set of continuous and discrete symmetries it obeys, the first step in the methodology is to identify a \"fundamental chart\", a region in the state space of the flow to which all other regions can be mapped by a symmetry operation, and a set of criteria indicating what mapping takes each point in state space into that chart. We then find a low-dimensional coordinate representation of the data in the fundamental chart with the use of an autoencoder architecture that also provides an estimate of the dimension of the invariant manifold where data lie. Finally, we learn dynamics on this manifold with the use of neural ordinary differential equations. We apply this method, denoted \"symmetry charting\" to simulation data from two-dimensional Kolmogorov flow in a chaotic bursting regime. This system has a continuous translation symmetry, and discrete rotation and shift-reflect symmetries. With this framework we observe that less data is needed to learn accurate data-driven models, more robust estimates of the manifold dimension are obtained, equivariance of the NSE is satisfied, better short-time tracking with respect to the true data is observed, and long-time statistics are correctly captured.","authors":["Carlos E. P\\'erez De Jes\\'us","Alec J. Linot","Michael D. Graham"],"url":"https://arxiv.org/abs/2312.10235"}
{"created":"2025-04-23","title":"Some convergence analysis for multicontinuum homogenization","abstract":"In this paper, we provide an analysis of a recently proposed multicontinuum homogenization technique. The analysis differs from those used in classical homogenization methods for several reasons. First, the cell problems in multicontinuum homogenization use constraint problems and can not be directly substituted into the differential operator. Secondly, the problem contains high contrast that remains in the homogenized problem. The homogenized problem averages the microstructure while containing the small parameter. In this analysis, we first based on our previous techniques, CEM-GMsFEM, to define a CEM-downscaling operator that maps the multicontinuum quantities to an approximated microscopic solution. Following the regularity assumption of the multicontinuum quantities, we construct a downscaling operator and the homogenized multicontinuum equations using the information of linear approximation of the multicontinuum quantities. The error analysis is given by the residual estimate of the homogenized equations and the well-posedness assumption of the homogenized equations.","authors":["Wing Tat Leung"],"url":"https://arxiv.org/abs/2401.12799"}
{"created":"2025-04-23","title":"Tight Approximation and Kernelization Bounds for Vertex-Disjoint Shortest Paths","abstract":"We examine the possibility of approximating Maximum Vertex-Disjoint Shortest Paths. In this problem, the input is an edge-weighted (directed or undirected) $n$-vertex graph $G$ along with $k$ terminal pairs $(s_1,t_1),(s_2,t_2),\\ldots,(s_k,t_k)$. The task is to connect as many terminal pairs as possible by pairwise vertex-disjoint paths such that each path is a shortest path between the respective terminals. Our work is anchored in the recent breakthrough by Lochet [SODA '21], which demonstrates the polynomial-time solvability of the problem for a fixed value of $k$.","authors":["Matthias Bentert","Fedor V. Fomin","Petr A. Golovach"],"url":"https://arxiv.org/abs/2402.15348"}
{"created":"2025-04-23","title":"Certifying Knowledge Comprehension in LLMs","abstract":"Large Language Models (LLMs) are increasingly deployed in safety-critical systems where they provide answers based on in-context information derived from knowledge bases. As LLMs are increasingly envisioned as superhuman agents, their proficiency in knowledge comprehension-extracting relevant information and reasoning over it to answer questions, a key facet of human intelligence-becomes crucial. However, existing evaluations of LLMs on knowledge comprehension are typically conducted on small test sets, but these datasets represent only a tiny fraction of the vast number of possible queries. Simple empirical evaluations on these limited test sets raises concerns about the reliability and generalizability of the results. In this work, we introduce the first specification and certification framework for knowledge comprehension in LLMs, providing formal probabilistic guarantees for reliability. Instead of a fixed dataset, we design novel specifications that mathematically represent prohibitively large probability distributions of knowledge comprehension prompts with natural noise, using knowledge graphs. From these specifications, we generate quantitative certificates that offer high-confidence, tight bounds on the probability that a given LLM correctly answers any question drawn from the specification distribution. We apply our framework to certify SOTA LLMs in two domains: precision medicine and general question-answering. Our results reveal previously unrecognized vulnerabilities in SOTA LLMs due to natural noise in the prompts. Additionally, we establish performance hierarchies with formal guarantees among the SOTA LLMs, particularly in the context of precision medicine question-answering.","authors":["Isha Chaudhary","Vedaant V. Jain","Gagandeep Singh"],"url":"https://arxiv.org/abs/2402.15929"}
{"created":"2025-04-23","title":"Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models Trained on Corrupted Data","abstract":"We provide a framework for solving inverse problems with diffusion models learned from linearly corrupted data. Firstly, we extend the Ambient Diffusion framework to enable training directly from measurements corrupted in the Fourier domain. Subsequently, we train diffusion models for MRI with access only to Fourier subsampled multi-coil measurements at acceleration factors R= 2,4,6,8. Secondly, we propose Ambient Diffusion Posterior Sampling (A-DPS), a reconstruction algorithm that leverages generative models pre-trained on one type of corruption (e.g. image inpainting) to perform posterior sampling on measurements from a different forward process (e.g. image blurring). For MRI reconstruction in high acceleration regimes, we observe that A-DPS models trained on subsampled data are better suited to solving inverse problems than models trained on fully sampled data. We also test the efficacy of A-DPS on natural image datasets (CelebA, FFHQ, and AFHQ) and show that A-DPS can sometimes outperform models trained on clean data for several image restoration tasks in both speed and performance.","authors":["Asad Aali","Giannis Daras","Brett Levac","Sidharth Kumar","Alexandros G. Dimakis","Jonathan I. Tamir"],"url":"https://arxiv.org/abs/2403.08728"}
{"created":"2025-04-23","title":"DROID: A Large-Scale In-The-Wild Robot Manipulation Dataset","abstract":"The creation of large, diverse, high-quality robot manipulation datasets is an important stepping stone on the path toward more capable and robust robotic manipulation policies. However, creating such datasets is challenging: collecting robot manipulation data in diverse environments poses logistical and safety challenges and requires substantial investments in hardware and human labour. As a result, even the most general robot manipulation policies today are mostly trained on data collected in a small number of environments with limited scene and task diversity. In this work, we introduce DROID (Distributed Robot Interaction Dataset), a diverse robot manipulation dataset with 76k demonstration trajectories or 350 hours of interaction data, collected across 564 scenes and 84 tasks by 50 data collectors in North America, Asia, and Europe over the course of 12 months. We demonstrate that training with DROID leads to policies with higher performance and improved generalization ability. We open source the full dataset, policy learning code, and a detailed guide for reproducing our robot hardware setup.","authors":["Alexander Khazatsky","Karl Pertsch","Suraj Nair","Ashwin Balakrishna","Sudeep Dasari","Siddharth Karamcheti","Soroush Nasiriany","Mohan Kumar Srirama","Lawrence Yunliang Chen","Kirsty Ellis","Peter David Fagan","Joey Hejna","Masha Itkina","Marion Lepert","Yecheng Jason Ma","Patrick Tree Miller","Jimmy Wu","Suneel Belkhale","Shivin Dass","Huy Ha","Arhan Jain","Abraham Lee","Youngwoon Lee","Marius Memmel","Sungjae Park","Ilija Radosavovic","Kaiyuan Wang","Albert Zhan","Kevin Black","Cheng Chi","Kyle Beltran Hatch","Shan Lin","Jingpei Lu","Jean Mercat","Abdul Rehman","Pannag R Sanketi","Archit Sharma","Cody Simpson","Quan Vuong","Homer Rich Walke","Blake Wulfe","Ted Xiao","Jonathan Heewon Yang","Arefeh Yavary","Tony Z. Zhao","Christopher Agia","Rohan Baijal","Mateo Guaman Castro","Daphne Chen","Qiuyu Chen","Trinity Chung","Jaimyn Drake","Ethan Paul Foster","Jensen Gao","Vitor Guizilini","David Antonio Herrera","Minho Heo","Kyle Hsu","Jiaheng Hu","Muhammad Zubair Irshad","Donovon Jackson","Charlotte Le","Yunshuang Li","Kevin Lin","Roy Lin","Zehan Ma","Abhiram Maddukuri","Suvir Mirchandani","Daniel Morton","Tony Nguyen","Abigail O'Neill","Rosario Scalise","Derick Seale","Victor Son","Stephen Tian","Emi Tran","Andrew E. Wang","Yilin Wu","Annie Xie","Jingyun Yang","Patrick Yin","Yunchu Zhang","Osbert Bastani","Glen Berseth","Jeannette Bohg","Ken Goldberg","Abhinav Gupta","Abhishek Gupta","Dinesh Jayaraman","Joseph J Lim","Jitendra Malik","Roberto Mart\\'in-Mart\\'in","Subramanian Ramamoorthy","Dorsa Sadigh","Shuran Song","Jiajun Wu","Michael C. Yip","Yuke Zhu","Thomas Kollar","Sergey Levine","Chelsea Finn"],"url":"https://arxiv.org/abs/2403.12945"}
{"created":"2025-04-23","title":"Cross-domain Fiber Cluster Shape Analysis for Language Performance Cognitive Score Prediction","abstract":"Shape plays an important role in computer graphics, offering informative features to convey an object's morphology and functionality. Shape analysis in brain imaging can help interpret structural and functionality correlations of the human brain. In this work, we investigate the shape of the brain's 3D white matter connections and its potential predictive relationship to human cognitive function. We reconstruct brain connections as sequences of 3D points using diffusion magnetic resonance imaging (dMRI) tractography. To describe each connection, we extract 12 shape descriptors in addition to traditional dMRI connectivity and tissue microstructure features. We introduce a novel framework, Shape--fused Fiber Cluster Transformer (SFFormer), that leverages a multi-head cross-attention feature fusion module to predict subject-specific language performance based on dMRI tractography. We assess the performance of the method on a large dataset including 1065 healthy young adults. The results demonstrate that both the transformer-based SFFormer model and its inter/intra feature fusion with shape, microstructure, and connectivity are informative, and together, they improve the prediction of subject-specific language performance scores. Overall, our results indicate that the shape of the brain's connections is predictive of human language function.","authors":["Yui Lo","Yuqian Chen","Dongnan Liu","Wan Liu","Leo Zekelman","Fan Zhang","Yogesh Rathi","Nikos Makris","Alexandra J. Golby","Weidong Cai","Lauren J. O'Donnell"],"url":"https://arxiv.org/abs/2403.19001"}
{"created":"2025-04-23","title":"Facilitating Reinforcement Learning for Process Control Using Transfer Learning: Overview and Perspectives","abstract":"In the context of Industry 4.0 and smart manufacturing, the field of process industry optimization and control is also undergoing a digital transformation. With the rise of Deep Reinforcement Learning (DRL), its application in process control has attracted widespread attention. However, the extremely low sample efficiency and the safety concerns caused by exploration in DRL hinder its practical implementation in industrial settings. Transfer learning offers an effective solution for DRL, enhancing its generalization and adaptability in multi-mode control scenarios. This paper provides insights into the use of DRL for process control from the perspective of transfer learning. We analyze the challenges of applying DRL in the process industry and the necessity of introducing transfer learning. Furthermore, recommendations and prospects are provided for future research directions on how transfer learning can be integrated with DRL to enhance process control. This paper aims to offer a set of promising, user-friendly, easy-to-implement, and scalable approaches to artificial intelligence-facilitated industrial control for scholars and engineers in the process industry.","authors":["Runze Lin","Junghui Chen","Lei Xie","Hongye Su"],"url":"https://arxiv.org/abs/2404.00247"}
{"created":"2025-04-23","title":"TextSquare: Scaling up Text-Centric Visual Instruction Tuning","abstract":"Text-centric visual question answering (VQA) has made great strides with the development of Multimodal Large Language Models (MLLMs), yet open-source models still fall short of leading models like GPT4V and Gemini, partly due to a lack of extensive, high-quality instruction tuning data. To this end, we introduce a new approach for creating a massive, high-quality instruction-tuning dataset, Square-10M, which is generated using closed-source MLLMs. The data construction process, termed Square, consists of four steps: Self-Questioning, Answering, Reasoning, and Evaluation. Our experiments with Square-10M led to three key findings: 1) Our model, TextSquare, considerably surpasses open-source previous state-of-the-art Text-centric MLLMs and sets a new standard on OCRBench(62.2%). It even outperforms top-tier models like GPT4V and Gemini in 6 of 10 text-centric benchmarks. 2) Additionally, we demonstrate the critical role of VQA reasoning data in offering comprehensive contextual insights for specific questions. This not only improves accuracy but also significantly mitigates hallucinations. Specifically, TextSquare scores an average of 75.1% across four general VQA and hallucination evaluation datasets, outperforming previous state-of-the-art models. 3) Notably, the phenomenon observed in scaling text-centric VQA datasets reveals a vivid pattern: the exponential increase of instruction tuning data volume is directly proportional to the improvement in model performance, thereby validating the necessity of the dataset scale and the high quality of Square-10M.","authors":["Jingqun Tang","Chunhui Lin","Zhen Zhao","Shu Wei","Binghong Wu","Qi Liu","Hao Feng","Yang Li","Siqi Wang","Lei Liao","Wei Shi","Yuliang Liu","Hao Liu","Yuan Xie","Xiang Bai","Can Huang"],"url":"https://arxiv.org/abs/2404.12803"}
{"created":"2025-04-23","title":"TF4CTR: Twin Focus Framework for CTR Prediction via Adaptive Sample Differentiation","abstract":"Effective feature interaction modeling is critical for enhancing the accuracy of click-through rate (CTR) prediction in industrial recommender systems. Most of the current deep CTR models resort to building complex network architectures to better capture intricate feature interactions or user behaviors. However, we identify two limitations in these models: (1) the samples given to the model are undifferentiated, which may lead the model to learn a larger number of easy samples in a single-minded manner while ignoring a smaller number of hard samples, thus reducing the model's generalization ability; (2) differentiated feature interaction encoders are designed to capture different interactions information but receive consistent supervision signals, thereby limiting the effectiveness of the encoder. To bridge the identified gaps, this paper introduces a novel CTR prediction framework by integrating the plug-and-play Twin Focus (TF) Loss, Sample Selection Embedding Module (SSEM), and Dynamic Fusion Module (DFM), named the Twin Focus Framework for CTR (TF4CTR). Specifically, the framework employs the SSEM at the bottom of the model to differentiate between samples, thereby assigning a more suitable encoder for each sample. Meanwhile, the TF Loss provides tailored supervision signals to both simple and complex encoders. Moreover, the DFM dynamically fuses the feature interaction information captured by the encoders, resulting in more accurate predictions. Experiments on five real-world datasets confirm the effectiveness and compatibility of the framework, demonstrating its capacity to enhance various representative baselines in a model-agnostic manner. To facilitate reproducible research, our open-sourced code and detailed running logs will be made available at: https://github.com/salmon1802/TF4CTR.","authors":["Honghao Li","Yiwen Zhang","Yi Zhang","Lei Sang","Yun Yang"],"url":"https://arxiv.org/abs/2405.03167"}
{"created":"2025-04-23","title":"GoalGrasp: Grasping Goals in Partially Occluded Scenarios without Grasp Training","abstract":"Grasping user-specified objects is crucial for robotic assistants; however, most current 6-DoF grasp detection methods are object-agnostic, making it challenging to grasp specific targets from a scene. To achieve that, we present GoalGrasp, a simple yet effective 6-DoF robot grasp pose detection method that does not rely on grasp pose annotations and grasp training. By combining 3D bounding boxes and simple human grasp priors, our method introduces a novel paradigm for robot grasp pose detection. GoalGrasp's novelty is its swift grasping of user-specified objects and partial mitigation of occlusion issues. The experimental evaluation involves 18 common objects categorized into 7 classes. Our method generates dense grasp poses for 1000 scenes. We compare our method's grasp poses to existing approaches using a novel stability metric, demonstrating significantly higher grasp pose stability. In user-specified robot grasping tests, our method achieves a 94% success rate, and 92% under partial occlusion.","authors":["Shun Gui","Kai Gui","Yan Luximon"],"url":"https://arxiv.org/abs/2405.04783"}
{"created":"2025-04-23","title":"Listenable Maps for Zero-Shot Audio Classifiers","abstract":"Interpreting the decisions of deep learning models, including audio classifiers, is crucial for ensuring the transparency and trustworthiness of this technology. In this paper, we introduce LMAC-ZS (Listenable Maps for Audio Classifiers in the Zero-Shot context), which, to the best of our knowledge, is the first decoder-based post-hoc interpretation method for explaining the decisions of zero-shot audio classifiers. The proposed method utilizes a novel loss function that maximizes the faithfulness to the original similarity between a given text-and-audio pair. We provide an extensive evaluation using the Contrastive Language-Audio Pretraining (CLAP) model to showcase that our interpreter remains faithful to the decisions in a zero-shot classification context. Moreover, we qualitatively show that our method produces meaningful explanations that correlate well with different text prompts.","authors":["Francesco Paissan","Luca Della Libera","Mirco Ravanelli","Cem Subakan"],"url":"https://arxiv.org/abs/2405.17615"}
{"created":"2025-04-23","title":"A Pontryagin Perspective on Reinforcement Learning","abstract":"Reinforcement learning has traditionally focused on learning state-dependent policies to solve optimal control problems in a closed-loop fashion. In this work, we introduce the paradigm of open-loop reinforcement learning where a fixed action sequence is learned instead. We present three new algorithms: one robust model-based method and two sample-efficient model-free methods. Rather than basing our algorithms on Bellman's equation from dynamic programming, our work builds on Pontryagin's principle from the theory of open-loop optimal control. We provide convergence guarantees and evaluate all methods empirically on a pendulum swing-up task, as well as on two high-dimensional MuJoCo tasks, significantly outperforming existing baselines.","authors":["Onno Eberhard","Claire Vernade","Michael Muehlebach"],"url":"https://arxiv.org/abs/2405.18100"}
{"created":"2025-04-23","title":"Certifying Counterfactual Bias in LLMs","abstract":"Large Language Models (LLMs) can produce biased responses that can cause representational harms. However, conventional studies are insufficient to thoroughly evaluate biases across LLM responses for different demographic groups (a.k.a. counterfactual bias), as they do not scale to large number of inputs and do not provide guarantees. Therefore, we propose the first framework, LLMCert-B that certifies LLMs for counterfactual bias on distributions of prompts. A certificate consists of high-confidence bounds on the probability of unbiased LLM responses for any set of counterfactual prompts - prompts differing by demographic groups, sampled from a distribution. We illustrate counterfactual bias certification for distributions of counterfactual prompts created by applying prefixes sampled from prefix distributions, to a given set of prompts. We consider prefix distributions consisting random token sequences, mixtures of manual jailbreaks, and perturbations of jailbreaks in LLM's embedding space. We generate non-trivial certificates for SOTA LLMs, exposing their vulnerabilities over distributions of prompts generated from computationally inexpensive prefix distributions.","authors":["Isha Chaudhary","Qian Hu","Manoj Kumar","Morteza Ziyadi","Rahul Gupta","Gagandeep Singh"],"url":"https://arxiv.org/abs/2405.18780"}
{"created":"2025-04-23","title":"A Scoping Review of Earth Observation and Machine Learning for Causal Inference: Implications for the Geography of Poverty","abstract":"Earth observation (EO) data such as satellite imagery can have far-reaching impacts on our understanding of the geography of poverty, especially when coupled with machine learning (ML) and computer vision. Early research used computer vision to predict living conditions in areas with limited data, but recent studies increasingly focus on causal analysis. Despite this shift, the use of EO-ML methods for causal inference lacks thorough documentation, and best practices are still developing. Through a comprehensive scoping review, we catalog the current literature on EO-ML methods in causal analysis. We synthesize five principal approaches to incorporating EO data in causal workflows: (1) outcome imputation for downstream causal analysis, (2) EO image deconfounding, (3) EO-based treatment effect heterogeneity, (4) EO-based transportability analysis, and (5) image-informed causal discovery. Building on these findings, we provide a detailed protocol guiding researchers in integrating EO data into causal analysis -- covering data requirements, computer vision model selection, and evaluation metrics. While our focus centers on health and living conditions outcomes, our protocol is adaptable to other sustainable development domains utilizing EO data.","authors":["Kazuki Sakamoto","Connor T. Jerzak","Adel Daoud"],"url":"https://arxiv.org/abs/2406.02584"}
{"created":"2025-04-23","title":"Normal-guided Detail-Preserving Neural Implicit Function for High-Fidelity 3D Surface Reconstruction","abstract":"Neural implicit representations have emerged as a powerful paradigm for 3D reconstruction. However, despite their success, existing methods fail to capture fine geometric details and thin structures, especially in scenarios where only sparse multi-view RGB images of the objects of interest are available. This paper shows that training neural representations with first-order differential properties (surface normals) leads to highly accurate 3D surface reconstruction, even with as few as two RGB images. Using input RGB images, we compute approximate ground-truth surface normals from depth maps produced by an off-the-shelf monocular depth estimator. During training, we directly locate the surface point of the SDF network and supervise its normal with the one estimated from the depth map. Extensive experiments demonstrate that our method achieves state-of-the-art reconstruction accuracy with a minimal number of views, capturing intricate geometric details and thin structures that were previously challenging to capture.","authors":["Aarya Patel","Hamid Laga","Ojaswa Sharma"],"url":"https://arxiv.org/abs/2406.04861"}
{"created":"2025-04-23","title":"Robust, positive and exact model reduction via monotone matrices","abstract":"This work focuses on the problem of exact model reduction of positive linear systems, by leveraging minimal realization theory. While determining the existence of a positive reachable realization remains in general an open problem, we are able to fully characterize the cases in which the new model is obtained with non-negative reduction matrices, and hence positivity of the reduced model is robust with respect to small perturbations of the original system. The characterization is obtained by specializing monotone matrix theory to positive matrices. In addition, we provide a systematic method to construct positive reductions also when minimal ones are not available, by exploiting algebraic techniques.","authors":["Marco Cortese","Tommaso Grigoletto","Francesco Ticozzi","Augusto Ferrante"],"url":"https://arxiv.org/abs/2406.11696"}
{"created":"2025-04-23","title":"LOOC: Localizing Organs using Occupancy Networks and Body Surface Depth Images","abstract":"We introduce a novel approach for the precise localization of 67 anatomical structures from single depth images captured from the exterior of the human body. Our method uses a multi-class occupancy network, trained using segmented CT scans augmented with body-pose changes, and incorporates a specialized sampling strategy to handle densely packed internal organs. Our contributions include the application of occupancy networks for occluded structure localization, a robust method for estimating anatomical positions from depth images, and the creation of detailed, individualized 3D anatomical atlases. We outperform localization using template matching and provide qualitative real-world reconstructions. This method promises improvements in automated medical imaging and diagnostic procedures by offering accurate, non-invasive localization of critical anatomical structures.","authors":["Pit Henrich","Franziska Mathis-Ullrich"],"url":"https://arxiv.org/abs/2406.12407"}
{"created":"2025-04-23","title":"Active Diffusion Subsampling","abstract":"Subsampling is commonly used to mitigate costs associated with data acquisition, such as time or energy requirements, motivating the development of algorithms for estimating the fully-sampled signal of interest $x$ from partially observed measurements $y$. In maximum entropy sampling, one selects measurement locations that are expected to have the highest entropy, so as to minimize uncertainty about $x$. This approach relies on an accurate model of the posterior distribution over future measurements, given the measurements observed so far. Recently, diffusion models have been shown to produce high-quality posterior samples of high-dimensional signals using guided diffusion. In this work, we propose Active Diffusion Subsampling (ADS), a method for designing intelligent subsampling masks using guided diffusion in which the model tracks a distribution of beliefs over the true state of $x$ throughout the reverse diffusion process, progressively decreasing its uncertainty by actively choosing to acquire measurements with maximum expected entropy, ultimately producing the posterior distribution $p(x \\mid y)$. ADS can be applied using pre-trained diffusion models for any subsampling rate, and does not require task-specific retraining - just the specification of a measurement model. Furthermore, the maximum entropy sampling policy employed by ADS is interpretable, enhancing transparency relative to existing methods using black-box policies. Code is available at https://active-diffusion-subsampling.github.io/.","authors":["Oisin Nolan","Tristan S. W. Stevens","Wessel L. van Nierop","Ruud J. G. van Sloun"],"url":"https://arxiv.org/abs/2406.14388"}
{"created":"2025-04-23","title":"CHASE: A Causal Hypergraph based Framework for Root Cause Analysis in Multimodal Microservice Systems","abstract":"In recent years, the widespread adoption of distributed microservice architectures within the industry has significantly increased the demand for enhanced system availability and robustness. Due to the complex service invocation paths and dependencies in enterprise-level microservice systems, it is challenging to locate the anomalies promptly during service invocations, thus causing intractable issues for normal system operations and maintenance. In this paper, we propose a Causal Heterogeneous grAph baSed framEwork for root cause analysis, namely CHASE, for microservice systems with multimodal data, including traces, logs, and system monitoring metrics. Specifically, related information is encoded into representative embeddings and further modeled by a multimodal invocation graph. Following that, anomaly detection is performed on each instance node with attentive heterogeneous message passing from its adjacent metric and log nodes. Finally, CHASE learns from the constructed hypergraph with hyperedges representing the flow of causality and performs root cause localization. We evaluate the proposed framework on two public microservice datasets with distinct attributes and compare with the state-of-the-art methods. The results show that CHASE achieves the average performance gain up to 36.2%(A@1) and 29.4%(Percentage@1), respectively to its best counterpart.","authors":["Ziming Zhao","Zhenwei Wang","Tiehua Zhang","Zhishu Shen","Hai Dong","Zhen Lei","Xingjun Ma","Gaowei Xu","Zhijun Ding","Yun Yang"],"url":"https://arxiv.org/abs/2406.19711"}
{"created":"2025-04-23","title":"On the Low-Rank Parametrization of Reward Models for Controlled Language Generation","abstract":"Language models trained on large amounts of data are known to produce inappropriate content in some cases and require careful tuning to be used in the real world. We revisit an effective and modular approach for controllability of the language models, when an external expert model guides the decoding. Particularly, we zoom in into the parametrization choice of an external expert, highlighting the difference between low-rank and higher-rank parametrizations. Higher-rank experts are designed to support high flexibility when representing the rewards, leading to higher computational costs during decoding. However, we demonstrate that they might not use their full flexibility. By analyzing the recently proposed reward-augmented decoding approach (RAD), which uses a higher-rank expert model, we introduce a simpler but more efficient low-rank parametrization of the expert model enabling fast and effective guided decoding. We empirically show that the low-rank RAD performs on par with the more flexible RAD on a detoxification and a sentiment control task, while requiring only a single reward model call per generated token.","authors":["Sergey Troshin","Vlad Niculae","Antske Fokkens"],"url":"https://arxiv.org/abs/2407.04615"}
{"created":"2025-04-23","title":"MetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs","abstract":"The rapid progress in machine learning (ML) has brought forth many large language models (LLMs) that excel in various tasks and areas. These LLMs come with different abilities and costs in terms of computation or pricing. Since the demand for each query can vary, e.g., because of the queried domain or its complexity, defaulting to one LLM in an application is not usually the best choice, whether it is the biggest, priciest, or even the one with the best average test performance. Consequently, picking the right LLM that is both accurate and cost-effective for an application is necessary yet remains a challenge. In this paper, we introduce MetaLLM, a framework that dynamically and intelligently routes each query to the optimal LLM (among several available LLMs) for classification and multi-choice question-answering tasks, achieving significantly improved accuracy and cost-effectiveness. By framing the selection problem as a multi-armed bandit, MetaLLM balances prediction accuracy and cost efficiency under uncertainty. Our experiments, conducted on popular LLM platforms such as OpenAI and Together AI, as well as open-source LLM, showcase MetaLLM's efficacy in real-world scenarios, laying the groundwork for future extensions.","authors":["Quang H. Nguyen","Thinh Dao","Duy C. Hoang","Juliette Decugis","Saurav Manchanda","Nitesh V. Chawla","Khoa D. Doan"],"url":"https://arxiv.org/abs/2407.10834"}
{"created":"2025-04-23","title":"Online Multi-Task Offloading for Semantic-Aware Edge Computing Systems","abstract":"Mobile edge computing (MEC) provides low-latency offloading solutions for computationally intensive tasks, effectively improving the computing efficiency and battery life of mobile devices. However, for data-intensive tasks or scenarios with limited uplink bandwidth, network congestion might occur due to massive simultaneous offloading nodes, increasing transmission latency and affecting task performance. In this paper, we propose a semantic-aware multi-modal task offloading framework to address the challenges posed by limited uplink bandwidth. By introducing a semantic extraction factor, we balance the relationship among transmission latency, computation energy consumption, and task performance. To measure the offloading performance of multi-modal tasks, we design a unified and fair quality of experience (QoE) metric that includes execution latency, energy consumption, and task performance. Lastly, we formulate the optimization problem as a Markov decision process (MDP) and exploit the multi-agent proximal policy optimization (MAPPO) reinforcement learning algorithm to jointly optimize the semantic extraction factor, communication resources, and computing resources to maximize overall QoE. Experimental results show that the proposed method achieves a reduction in execution latency and energy consumption of 18.1% and 12.9%, respectively compared with the semantic-unaware approach. Moreover, the proposed approach can be easily extended to models with different user preferences.","authors":["Xuyang Chen","Daquan Feng","Wei Jiang","Qu Luo","Gaojie Chen","Yao Sun"],"url":"https://arxiv.org/abs/2407.11018"}
{"created":"2025-04-23","title":"Leveraging Core and Uncore Frequency Scaling for Power-Efficient Serverless Workflows","abstract":"Serverless workflows have emerged in Function-as-a-Service (FaaS) platforms to represent the operational structure of traditional applications. With latency propagation effects becoming increasingly prominent, step-wise resource tuning is required to address Service-Level-Objectives (SLOs). Modern processors' allowance for fine-grained Dynamic Voltage and Frequency Scaling (DVFS), coupled with serverless workflows' intermittent nature, presents a unique opportunity to reduce power while meeting SLOs. We introduce $\\Omega$kypous, an SLO-driven DVFS framework for serverless workflows. $\\Omega$kypous employs a grey-box model that predicts functions' execution latency and power under different Core and Uncore frequency combinations. Based on these predictions and the timing slacks between workflow functions, $\\Omega$kypous uses a closed-loop control mechanism to dynamically adjust Core and Uncore frequencies, thus minimizing power consumption without compromising predefined end-to-end latency constraints. Our evaluation on real-world traces from Azure, against state-of-the-art power management frameworks, demonstrates an average power consumption reduction of 16\\%, while consistently maintaining low SLO violation rates (1.8\\%), when operating under power caps.","authors":["Achilleas Tzenetopoulos","Dimosthenis Masouros","Sotirios Xydis","Dimitrios Soudris"],"url":"https://arxiv.org/abs/2407.18386"}
{"created":"2025-04-23","title":"Towards Robust Infrared Small Target Detection: A Feature-Enhanced and Sensitivity-Tunable Framework","abstract":"Recently, single-frame infrared small target (SIRST) detection technology has attracted wide-spread attention. However, due to the intrinsic feature scarcity in infrared small targets, precise segmentation of small targets from complex backgrounds remains a significant challenge. Different from most existing deep learning-based methods that focus on improving network architectures, we propose a feature-enhanced and sensitivity-tunable (FEST) framework, which is compatible with existing SIRST detection networks and further enhances their detection performance. The FEST framework improves the model's robustness from two aspects: feature enhancement and target confidence regulation. For feature enhancement, on the one hand, we adopt a multi-scale fusion strategy, which can effectively improve the model's perception and adaptability to multi-scale features of multi-size targets. On the other hand, we construct an edge enhancement difficulty mining (EEDM) loss based on the analysis of the task characteristics, which helps guide the network to continuously focus on challenging target regions and edge features during training. For target confidence regulation, we design an adjustable sensitivity (AS) strategy for network post-processing. This strategy not only enhances the adaptability of the network in complex scenarios, but also significantly improves the detection rate of infrared small targets while maintaining segmentation accuracy. Extensive experimental results show that our FEST framework can significantly enhance the performance of existing SIRST detection networks. Notably, the multi-scale direction-aware network (MSDA-Net) equipped with the FEST framework won the first prize in the PRCV 2024 wide-area infrared small target detection competition.","authors":["Jinmiao Zhao","Zelin Shi","Chuang Yu","Yunpeng Liu","Yimian Dai"],"url":"https://arxiv.org/abs/2407.20090"}
{"created":"2025-04-23","title":"Semantical Analysis of Intuitionistic Modal Logics between CK and IK","abstract":"The intuitionistic modal logics considered between Constructive K (CK) and Intuitionistic K (IK) differ in their treatment of the possibility (diamond) connective. It was recently rediscovered that some logics between CK and IK also disagree on their diamond-free fragments, with only some remaining conservative over the standard axiomatisation of intuitionistic modal logic with necessity (box) alone. We show that relational Kripke semantics for CK can be extended with frame conditions for all axioms in the standard axiomatisation of IK, as well as other axioms previously studied. This allows us to answer open questions about the (non-)conservativity of such logics over intuitionistic modal logic without diamond. Our results are formalised using the Coq Proof Assistant.","authors":["Jim de Groot","Ian Shillito","Ranald Clouston"],"url":"https://arxiv.org/abs/2408.00262"}
{"created":"2025-04-23","title":"LogUpdater: Automated Detection and Repair of Specific Defects in Logging Statements","abstract":"Developers use logging statements to track software runtime behaviors and system status. Yet, unclear or misleading logs can hide true execution patterns and hinder software maintenance. Current research on logging statement issues is limited, often only spotting one defect type and relying on manual corrections instead of automation. To bridge this gap, we conduct a study to identify four logging statement defect types by analyzing log-centric changes. Then we introduce LogUpdater, a two-stage framework for automatically detecting and updating these log defects. In the offline phase, LogUpdater builds a classifier using synthetic defective logs to spot defect types. During online testing, this classifier assesses if and how logs in code snippets need improvement. LogUpdater then uses type-aware prompts from past logging updates to suggest fixes via a recommendation framework based on LLMs. Results show strong defect detection with an F1 score of 0.625. It also greatly improves static text and dynamic variable suggestions by 48.12% and 24.90%, respectively. LogUpdater successfully recommends updates 61.49% of the time on new projects. We reported 40 problematic logs and their fixes on GitHub, leading to 25 merged changes across 11 projects.","authors":["Renyi Zhong","Yichen Li","Jinxi Kuang","Wenwei Gu","Yintong Huo","Michael R. Lyu"],"url":"https://arxiv.org/abs/2408.03101"}
{"created":"2025-04-23","title":"Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation","abstract":"Recent advancements in Large Language Models (LLMs) have demonstrated exceptional performance across a wide range of tasks, generating significant interest in their application to recommendation systems. However, existing methods have not fully capitalized on the potential of LLMs, often constrained by limited input information or failing to fully utilize their advanced reasoning capabilities. To address these limitations, we introduce EXP3RT, a novel LLM-based recommender designed to leverage rich preference information contained in user and item reviews. EXP3RT is basically fine-tuned through distillation from a teacher LLM to perform three key tasks in order: EXP3RT first extracts and encapsulates essential subjective preferences from raw reviews, aggregates and summarizes them according to specific criteria to create user and item profiles. It then generates detailed step-by-step reasoning followed by predicted rating, i.e., reasoning-enhanced rating prediction, by considering both subjective and objective information from user/item profiles and item descriptions. This personalized preference reasoning from EXP3RT enhances rating prediction accuracy and also provides faithful and reasonable explanations for recommendation. Extensive experiments show that EXP3RT outperforms existing methods on both rating prediction and candidate item reranking for top-k recommendation, while significantly enhancing the explainability of recommendation systems.","authors":["Jieyong Kim","Hyunseo Kim","Hyunjin Cho","SeongKu Kang","Buru Chang","Jinyoung Yeo","Dongha Lee"],"url":"https://arxiv.org/abs/2408.06276"}
{"created":"2025-04-23","title":"On the accurate computation of expected modularity in probabilistic networks","abstract":"Modularity is one of the most widely used measures for evaluating communities in networks. In probabilistic networks, where the existence of edges is uncertain and uncertainty is represented by probabilities, the expected value of modularity can be used instead. However, efficiently computing expected modularity is challenging. To address this challenge, we propose a novel and efficient technique (FPWP) for computing the probability distribution of modularity and its expected value. In this paper, we implement and compare our method and various general approaches for expected modularity computation in probabilistic networks. These include: (1) translating probabilistic networks into deterministic ones by removing low-probability edges or treating probabilities as weights, (2) using Monte Carlo sampling to approximate expected modularity, and (3) brute-force computation. We evaluate the accuracy and time efficiency of FPWP through comprehensive experiments on both real-world and synthetic networks with diverse characteristics. Our results demonstrate that removing low-probability edges or treating probabilities as weights produces inaccurate results, while the convergence of the sampling method varies with the parameters of the network. Brute-force computation, though accurate, is prohibitively slow. In contrast, our method is much faster than brute-force computation, but guarantees an accurate result.","authors":["Xin Shen","Matteo Magnani","Christian Rohner","Fiona Skerman"],"url":"https://arxiv.org/abs/2408.07161"}
{"created":"2025-04-23","title":"Complementarity-Free Multi-Contact Modeling and Optimization for Dexterous Manipulation","abstract":"A significant barrier preventing model-based methods from achieving real-time and versatile dexterous robotic manipulation is the inherent complexity of multi-contact dynamics. Traditionally formulated as complementarity models, multi-contact dynamics introduces non-smoothness and combinatorial complexity, complicating contact-rich planning and optimization. In this paper, we circumvent these challenges by introducing a lightweight yet capable multi-contact model. Our new model, derived from the duality of optimization-based contact models, dispenses with the complementarity constructs entirely, providing computational advantages such as closed-form time stepping, differentiability, automatic satisfaction with Coulomb friction law, and minimal hyperparameter tuning. We demonstrate the effectiveness and efficiency of the model for planning and control in a range of challenging dexterous manipulation tasks, including fingertip 3D in-air manipulation, TriFinger in-hand manipulation, and Allegro hand on-palm reorientation, all performed with diverse objects. Our method consistently achieves state-of-the-art results: (I) a 96.5% average success rate across all objects and tasks, (II) high manipulation accuracy with an average reorientation error of 11{\\deg} and position error of 7.8mm, and (III) contact-implicit model predictive control running at 50-100 Hz for all objects and tasks. These results are achieved with minimal hyperparameter tuning.","authors":["Wanxin Jin"],"url":"https://arxiv.org/abs/2408.07855"}
{"created":"2025-04-23","title":"PolyFootNet: Extracting Polygonal Building Footprints in Off-Nadir Remote Sensing Images","abstract":"Extracting polygonal building footprints from off-nadir imagery is crucial for diverse applications. Current deep-learning-based extraction approaches predominantly rely on semantic segmentation paradigms and post-processing algorithms, limiting their boundary precision and applicability. However, existing polygonal extraction methodologies are inherently designed for near-nadir imagery and fail under the geometric complexities introduced by off-nadir viewing angles. To address these challenges, this paper introduces Polygonal Footprint Network (PolyFootNet), a novel deep-learning framework that directly outputs polygonal building footprints without requiring external post-processing steps. PolyFootNet employs a High-Quality Mask Prompter to generate precise roof masks, which guide polygonal vertex extraction in a unified model pipeline. A key contribution of PolyFootNet is introducing the Self Offset Attention mechanism, grounded in Nadaraya-Watson regression, to effectively mitigate the accuracy discrepancy observed between low-rise and high-rise buildings. This approach allows low-rise building predictions to leverage angular corrections learned from high-rise building offsets, significantly enhancing overall extraction accuracy. Additionally, motivated by the inherent ambiguity of building footprint extraction tasks, we systematically investigate alternative extraction paradigms and demonstrate that a combined approach of building masks and offsets achieves superior polygonal footprint results. Extensive experiments validate PolyFootNet's effectiveness, illustrating its promising potential as a robust, generalizable, and precise polygonal building footprint extraction method from challenging off-nadir imagery. To facilitate further research, we will release pre-trained weights of our offset prediction module at https://github.com/likaiucas/PolyFootNet.","authors":["Kai Li","Yupeng Deng","Jingbo Chen","Yu Meng","Zhihao Xi","Junxian Ma","Chenhao Wang","Maolin Wang","Xiangyu Zhao"],"url":"https://arxiv.org/abs/2408.08645"}
{"created":"2025-04-23","title":"BaThe: Defense against the Jailbreak Attack in Multimodal Large Language Models by Treating Harmful Instruction as Backdoor Trigger","abstract":"Multimodal Large Language Models (MLLMs) have showcased impressive performance in a variety of multimodal tasks. On the other hand, the integration of additional image modality may allow the malicious users to inject harmful content inside the images for jailbreaking. Unlike text-based LLMs, where adversaries need to select discrete tokens to conceal their malicious intent using specific algorithms, the continuous nature of image signals provides a direct opportunity for adversaries to inject harmful intentions. In this work, we propose $\\textbf{BaThe}$ ($\\textbf{Ba}$ckdoor $\\textbf{T}$rigger S$\\textbf{h}$i$\\textbf{e}$ld), a simple yet effective jailbreak defense mechanism. Our work is motivated by recent research on jailbreak backdoor attack and virtual prompt backdoor attack in generative language models. Jailbreak backdoor attack uses harmful instructions combined with manually crafted strings as triggers to make the backdoored model generate prohibited responses. We assume that harmful instructions can function as triggers, and if we alternatively set rejection responses as the triggered response, the backdoored model then can defend against jailbreak attacks. We achieve this by utilizing virtual rejection prompt, similar to the virtual prompt backdoor attack. We embed the virtual rejection prompt into the soft text embeddings, which we call ``wedge''. Our comprehensive experiments demonstrate that BaThe effectively mitigates various types of jailbreak attacks and is adaptable to defend against unseen attacks, with minimal impact on MLLMs' performance.","authors":["Yulin Chen","Haoran Li","Yirui Zhang","Zihao Zheng","Yangqiu Song","Bryan Hooi"],"url":"https://arxiv.org/abs/2408.09093"}
{"created":"2025-04-23","title":"DeepDiveAI: Identifying AI Related Documents in Large Scale Literature Data","abstract":"In this paper, we propose a method to automatically classify AI-related documents from large-scale literature databases, leading to the creation of an AI-related literature dataset, named DeepDiveAI. The dataset construction approach integrates expert knowledge with the capabilities of advanced models, structured across two global stages. In the first stage, expert-curated classification datasets are used to train an LSTM model, which classifies coarse AI related records from large-scale datasets. In the second stage, we use Qwen2.5 Plus to annotate a random 10% of the coarse AI-related records, which are then used to train a BERT binary classifier. This step further refines the coarse AI related record set to obtain the final DeepDiveAI dataset. Evaluation results demonstrate that the entire workflow can efficiently and accurately identify AI-related literature from large-scale datasets.","authors":["Zhou Xiaochen","Liang Xingzhou","Zou Hui","Lu Yi","Qu Jingjing"],"url":"https://arxiv.org/abs/2408.12871"}
{"created":"2025-04-23","title":"A Catalog of Fairness-Aware Practices in Machine Learning Engineering","abstract":"Machine learning's widespread adoption in decision-making processes raises concerns about fairness, particularly regarding the treatment of sensitive features and potential discrimination against minorities. The software engineering community has responded by developing fairness-oriented metrics, empirical studies, and approaches. However, there remains a gap in understanding and categorizing practices for engineering fairness throughout the machine learning lifecycle. This paper presents a novel catalog of practices for addressing fairness in machine learning derived from a systematic mapping study. The study identifies and categorizes 28 practices from existing literature, mapping them onto different stages of the machine learning lifecycle. From this catalog, the authors extract actionable items and implications for both researchers and practitioners in software engineering. This work aims to provide a comprehensive resource for integrating fairness considerations into the development and deployment of machine learning systems, enhancing their reliability, accountability, and credibility.","authors":["Gianmario Voria","Giulia Sellitto","Carmine Ferrara","Francesco Abate","Andrea De Lucia","Filomena Ferrucci","Gemma Catolino","Fabio Palomba"],"url":"https://arxiv.org/abs/2408.16683"}
{"created":"2025-04-23","title":"Time-Varying Soft-Maximum Barrier Functions for Safety in Unmapped and Dynamic Environments","abstract":"We present a closed-form optimal feedback control method that ensures safety in an a prior unknown and potentially dynamic environment. This article considers the scenario where local perception data (e.g., LiDAR) is obtained periodically, and this data can be used to construct a local control barrier function (CBF) that models a local set that is safe for a period of time into the future. Then, we use a smooth time-varying soft-maximum function to compose the N most recently obtained local CBFs into a single barrier function that models an approximate union of the N most recently obtained local sets. This composite barrier function is used in a constrained quadratic optimization, which is solved in closed form to obtain a safe-and-optimal feedback control. We also apply the time-varying soft-maximum barrier function control to 2 robotic systems (nonholonomic ground robot with nonnegligible inertia, and quadrotor robot), where the objective is to navigate an a priori unknown environment safely and reach a target destination. In these applications, we present a simple approach to generate local CBFs from periodically obtained perception data.","authors":["Amirsaeid Safari","Jesse B. Hoagg"],"url":"https://arxiv.org/abs/2409.01458"}
{"created":"2025-04-23","title":"Multimodal Laryngoscopic Video Analysis for Assisted Diagnosis of Vocal Fold Paralysis","abstract":"This paper presents the Multimodal Laryngoscopic Video Analyzing System (MLVAS), a novel system that leverages both audio and video data to automatically extract key video segments and metrics from raw laryngeal videostroboscopic videos for assisted clinical assessment. The system integrates video-based glottis detection with an audio keyword spotting method to analyze both video and audio data, identifying patient vocalizations and refining video highlights to ensure optimal inspection of vocal fold movements. Beyond key video segment extraction from the raw laryngeal videos, MLVAS is able to generate effective audio and visual features for Vocal Fold Paralysis (VFP) detection. Pre-trained audio encoders are utilized to encode the patient voice to get the audio features. Visual features are generated by measuring the angle deviation of both the left and right vocal folds to the estimated glottal midline on the segmented glottis masks. To get better masks, we introduce a diffusion-based refinement that follows traditional U-Net segmentation to reduce false positives. We conducted several ablation studies to demonstrate the effectiveness of each module and modalities in the proposed MLVAS. The experimental results on a public segmentation dataset show the effectiveness of our proposed segmentation module. In addition, unilateral VFP classification results on a real-world clinic dataset demonstrate MLVAS's ability of providing reliable and objective metrics as well as visualization for assisted clinical diagnosis.","authors":["Yucong Zhang","Xin Zou","Jinshan Yang","Wenjun Chen","Juan Liu","Faya Liang","Ming Li"],"url":"https://arxiv.org/abs/2409.03597"}
{"created":"2025-04-23","title":"Onboard Satellite Image Classification for Earth Observation: A Comparative Study of ViT Models","abstract":"This study focuses on identifying the most effective pre-trained model for land use classification in onboard satellite processing, emphasizing achieving high accuracy, computational efficiency, and robustness against noisy data conditions commonly encountered during satellite-based inference. Through extensive experimentation, we compare the performance of traditional CNN-based, ResNet-based, and various pre-trained vision Transformer models. Our findings demonstrate that pre-trained Vision Transformer (ViT) models, particularly MobileViTV2 and EfficientViT-M2, outperform models trained from scratch in terms of accuracy and efficiency. These models achieve high performance with reduced computational requirements and exhibit greater resilience during inference under noisy conditions. While MobileViTV2 has excelled on clean validation data, EfficientViT-M2 has proved more robust when handling noise, making it the most suitable model for onboard satellite EO tasks. Our experimental results demonstrate that EfficientViT-M2 is the optimal choice for reliable and efficient RS-IC in satellite operations, achieving 98.76 % of accuracy, precision, and recall. Precisely, EfficientViT-M2 delivers the highest performance across all metrics, excels in training efficiency (1,000s) and inference time (10s), and demonstrates greater robustness (overall robustness score of 0.79). Consequently, EfficientViT-M2 consumes 63.93 % less power than MobileViTV2 (79.23 W) and 73.26 % less power than SwinTransformer (108.90 W). This highlights its significant advantage in energy efficiency.","authors":["Thanh-Dung Le","Vu Nguyen Ha","Ti Ti Nguyen","Geoffrey Eappen","Prabhu Thiruvasagam","Hong-fu Chou","Duc-Dung Tran","Hung Nguyen-Kha","Luis M. Garces-Socarras","Jorge L. Gonzalez-Rios","Juan Carlos Merlano-Duncan","Symeon Chatzinotas"],"url":"https://arxiv.org/abs/2409.03901"}
{"created":"2025-04-23","title":"DWA-3D: A Reactive Planner for Robust and Efficient Autonomous UAV Navigation in Confined Environments","abstract":"Despite the growing impact of Unmanned Aerial Vehicles (UAVs) across various industries, most of current available solutions lack for a robust autonomous navigation system to deal with the appearance of obstacles safely. This work presents an approach to perform autonomous UAV planning and navigation in scenarios in which a safe and high maneuverability is required, due to the cluttered environment and the narrow rooms to move. The system combines an RRT* global planner with a newly proposed reactive planner, DWA-3D, which is the extension of the well known DWA method for 2D robots. We provide a theoretical-empirical method for adjusting the parameters of the objective function to optimize, easing the classical difficulty for tuning them. An onboard LiDAR provides a 3D point cloud, which is projected on an Octomap in which the planning and navigation decisions are made. There is not a prior map; the system builds and updates the map online, from the current and the past LiDAR information included in the Octomap. Extensive real-world experiments were conducted to validate the system and to obtain a fine tuning of the involved parameters. These experiments allowed us to provide a set of values that ensure safe operation across all the tested scenarios. Just by weighting two parameters, it is possible to prioritize either horizontal path alignment or vertical (height) tracking, resulting in enhancing vertical or lateral avoidance, respectively. Additionally, our DWA-3D proposal is able to navigate successfully even in absence of a global planner or with one that does not consider the drone's size. Finally, the conducted experiments show that computation time with the proposed parameters is not only bounded but also remains stable around 40 ms, regardless of the scenario complexity.","authors":["Jorge Bes","Juan Dendarieta","Luis Riazuelo","Luis Montano"],"url":"https://arxiv.org/abs/2409.05421"}
{"created":"2025-04-23","title":"ThermalGaussian: Thermal 3D Gaussian Splatting","abstract":"Thermography is especially valuable for the military and other users of surveillance cameras. Some recent methods based on Neural Radiance Fields (NeRF) are proposed to reconstruct the thermal scenes in 3D from a set of thermal and RGB images. However, unlike NeRF, 3D Gaussian splatting (3DGS) prevails due to its rapid training and real-time rendering. In this work, we propose ThermalGaussian, the first thermal 3DGS approach capable of rendering high-quality images in RGB and thermal modalities. We first calibrate the RGB camera and the thermal camera to ensure that both modalities are accurately aligned. Subsequently, we use the registered images to learn the multimodal 3D Gaussians. To prevent the overfitting of any single modality, we introduce several multimodal regularization constraints. We also develop smoothing constraints tailored to the physical characteristics of the thermal modality. Besides, we contribute a real-world dataset named RGBT-Scenes, captured by a hand-hold thermal-infrared camera, facilitating future research on thermal scene reconstruction. We conduct comprehensive experiments to show that ThermalGaussian achieves photorealistic rendering of thermal images and improves the rendering quality of RGB images. With the proposed multimodal regularization constraints, we also reduced the model's storage cost by 90%. Our project page is at https://thermalgaussian.github.io/.","authors":["Rongfeng Lu","Hangyu Chen","Zunjie Zhu","Yuhang Qin","Ming Lu","Le Zhang","Chenggang Yan","Anke Xue"],"url":"https://arxiv.org/abs/2409.07200"}
{"created":"2025-04-23","title":"Emerging Reliance Behaviors in Human-AI Content Grounded Data Generation: The Role of Cognitive Forcing Functions and Hallucinations","abstract":"We investigate the impact of hallucinations and Cognitive Forcing Functions in human-AI collaborative content-grounded data generation, focusing on the use of Large Language Models (LLMs) to assist in generating high quality conversational data. Through a study with 34 users who each completed 8 tasks (n=272), we found that hallucinations significantly reduce data quality. While Cognitive Forcing Functions do not always alleviate these effects, their presence influences how users integrate AI responses. Specifically, we observed emerging reliance behaviors, with users often appending AI-generated responses to their correct answers, even when the AI's suggestions conflicted. This points to a potential drawback of Cognitive Forcing Functions, particularly when AI suggestions are inaccurate. Users who overrelied on AI-generated text produced lower quality data, emphasizing the nuanced dynamics of overreliance in human-LLM collaboration compared to traditional human-AI decision-making.","authors":["Zahra Ashktorab","Qian Pan","Werner Geyer","Michael Desmond","Marina Danilevsky","James M. Johnson","Casey Dugan","Michelle Bachman"],"url":"https://arxiv.org/abs/2409.08937"}
{"created":"2025-04-23","title":"Optimizing RLHF Training for Large Language Models with Stage Fusion","abstract":"We present RLHFuse, an efficient training system with stage fusion for Reinforcement Learning from Human Feedback (RLHF). Due to the intrinsic nature of RLHF training, i.e., the data skewness in the generation stage and the pipeline bubbles in the training stage, existing RLHF systems suffer from low GPU utilization. RLHFuse breaks the traditional view of RLHF workflow as a composition of individual tasks, splitting each task into finer-grained subtasks, and performing stage fusion to improve GPU utilization. RLHFuse contains two key ideas. First, for generation and inference tasks, RLHFuse splits them into sample-level subtasks, enabling efficient inter-stage fusion to overlap the execution of generation and inference stages, thus mitigating the original generation bottleneck dominated by long-tailed samples. Second, for training tasks, RLHFuse breaks them into subtasks of micro-batches and performs intra-stage fusion to concurrently execute these subtasks in the training stage with a fused pipeline schedule, effectively mitigating the pipeline bubbles. The experiments show that RLHFuse increases the training throughput by up to $3.7\\times$, compared to existing systems.","authors":["Yinmin Zhong","Zili Zhang","Bingyang Wu","Shengyu Liu","Yukun Chen","Changyi Wan","Hanpeng Hu","Lei Xia","Ranchen Ming","Yibo Zhu","Xin Jin"],"url":"https://arxiv.org/abs/2409.13221"}
{"created":"2025-04-23","title":"Peer-to-Peer Learning Dynamics of Wide Neural Networks","abstract":"Peer-to-peer learning is an increasingly popular framework that enables beyond-5G distributed edge devices to collaboratively train deep neural networks in a privacy-preserving manner without the aid of a central server. Neural network training algorithms for emerging environments, e.g., smart cities, have many design considerations that are difficult to tune in deployment settings -- such as neural network architectures and hyperparameters. This presents a critical need for characterizing the training dynamics of distributed optimization algorithms used to train highly nonconvex neural networks in peer-to-peer learning environments. In this work, we provide an explicit characterization of the learning dynamics of wide neural networks trained using popular distributed gradient descent (DGD) algorithms. Our results leverage both recent advancements in neural tangent kernel (NTK) theory and extensive previous work on distributed learning and consensus. We validate our analytical results by accurately predicting the parameter and error dynamics of wide neural networks trained for classification tasks.","authors":["Shreyas Chaudhari","Srinivasa Pranav","Emile Anand","Jos\\'e M. F. Moura"],"url":"https://arxiv.org/abs/2409.15267"}
{"created":"2025-04-23","title":"CREVE: An Acceleration-based Constraint Approach for Robust Radar Ego-Velocity Estimation","abstract":"Ego-velocity estimation from point cloud measurements of a millimeter-wave frequency-modulated continuous wave (mmWave FMCW) radar has become a crucial component of radar-inertial odometry (RIO) systems. Conventional approaches often exhibit poor performance when the number of outliers in the point cloud exceeds that of inliers, which can lead to degraded navigation performance, especially in RIO systems that rely on radar ego-velocity for dead reckoning. In this paper, we propose CREVE, an acceleration-based inequality constraints filter that leverages additional measurements from an inertial measurement unit (IMU) to achieve robust ego-velocity estimations. To further enhance accuracy and robustness against sensor errors, we introduce a practical accelerometer bias estimation method and a parameter adaptation rule that dynamically adjusts constraints based on radar point cloud inliers. Experimental results on two open-source IRS and ColoRadar datasets demonstrate that the proposed method significantly outperforms three state-of-the-art approaches, reducing absolute trajectory error by approximately 36\\%, 78\\%, and 12\\%, respectively.","authors":["Hoang Viet Do","Bo Sung Ko","Yong Hun Kim","Jin Woo Song"],"url":"https://arxiv.org/abs/2409.16847"}
{"created":"2025-04-23","title":"Open-World Evaluation for Retrieving Diverse Perspectives","abstract":"We study retrieving a set of documents that covers various perspectives on a complex and contentious question (e.g., will ChatGPT do more harm than good?). We curate a Benchmark for Retrieval Diversity for Subjective questions (BERDS), where each example consists of a question and diverse perspectives associated with the question, sourced from survey questions and debate websites. On this data, retrievers paired with a corpus are evaluated to surface a document set that contains diverse perspectives. Our framing diverges from most retrieval tasks in that document relevancy cannot be decided by simple string matches to references. Instead, we build a language model-based automatic evaluator that decides whether each retrieved document contains a perspective. This allows us to evaluate the performance of three different types of corpus (Wikipedia, web snapshot, and corpus constructed on the fly with retrieved pages from the search engine) paired with retrievers. Retrieving diverse documents remains challenging, with the outputs from existing retrievers covering all perspectives on only 40% of the examples. We further study the effectiveness of query expansion and diversity-focused reranking approaches and analyze retriever sycophancy.","authors":["Hung-Ting Chen","Eunsol Choi"],"url":"https://arxiv.org/abs/2409.18110"}
{"created":"2025-04-23","title":"The complexity of separability for semilinear sets and Parikh automata","abstract":"In a \\emph{separability problem}, we are given two sets $K$ and $L$ from a class $\\mathcal{C}$, and we want to decide whether there exists a set $S$ from a class $\\mathcal{S}$ such that $K\\subseteq S$ and $S\\cap L=\\emptyset$. In this case, we speak of \\emph{separability of sets in $\\mathcal{C}$ by sets in $\\mathcal{S}$}.","authors":["Elias Rojas Collins","Chris K\\\"ocher","Georg Zetzsche"],"url":"https://arxiv.org/abs/2410.00548"}
{"created":"2025-04-23","title":"Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct","abstract":"It has been reported that LLMs can recognize their own writing. As this has potential implications for AI safety, yet is relatively understudied, we investigate the phenomenon, seeking to establish whether it robustly occurs at the behavioral level, how the observed behavior is achieved, and whether it can be controlled. First, we find that the Llama3-8b-Instruct chat model - but not the base Llama3-8b model - can reliably distinguish its own outputs from those of humans, and present evidence that the chat model is likely using its experience with its own outputs, acquired during post-training, to succeed at the writing recognition task. Second, we identify a vector in the residual stream of the model that is differentially activated when the model makes a correct self-written-text recognition judgment, show that the vector activates in response to information relevant to self-authorship, present evidence that the vector is related to the concept of \"self\" in the model, and demonstrate that the vector is causally related to the model's ability to perceive and assert self-authorship. Finally, we show that the vector can be used to control both the model's behavior and its perception, steering the model to claim or disclaim authorship by applying the vector to the model's output as it generates it, and steering the model to believe or disbelieve it wrote arbitrary texts by applying the vector to them as the model reads them.","authors":["Christopher Ackerman","Nina Panickssery"],"url":"https://arxiv.org/abs/2410.02064"}
{"created":"2025-04-23","title":"AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models","abstract":"Large language models (LLMs) often exhibit hallucinations due to incorrect or outdated knowledge. Hence, model editing methods have emerged to enable targeted knowledge updates. To achieve this, a prevailing paradigm is the locating-then-editing approach, which first locates influential parameters and then edits them by introducing a perturbation. While effective, current studies have demonstrated that this perturbation inevitably disrupt the originally preserved knowledge within LLMs, especially in sequential editing scenarios. To address this, we introduce AlphaEdit, a novel solution that projects perturbation onto the null space of the preserved knowledge before applying it to the parameters. We theoretically prove that this projection ensures the output of post-edited LLMs remains unchanged when queried about the preserved knowledge, thereby mitigating the issue of disruption. Extensive experiments on various LLMs, including LLaMA3, GPT2-XL, and GPT-J, show that AlphaEdit boosts the performance of most locating-then-editing methods by an average of 36.7% with a single line of additional code for projection solely. Our code is available at: https://github.com/jianghoucheng/AlphaEdit.","authors":["Junfeng Fang","Houcheng Jiang","Kun Wang","Yunshan Ma","Shi Jie","Xiang Wang","Xiangnan He","Tat-seng Chua"],"url":"https://arxiv.org/abs/2410.02355"}
{"created":"2025-04-23","title":"AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs","abstract":"In this paper, we propose AutoDAN-Turbo, a black-box jailbreak method that can automatically discover as many jailbreak strategies as possible from scratch, without any human intervention or predefined scopes (e.g., specified candidate strategies), and use them for red-teaming. As a result, AutoDAN-Turbo can significantly outperform baseline methods, achieving a 74.3% higher average attack success rate on public benchmarks. Notably, AutoDAN-Turbo achieves an 88.5 attack success rate on GPT-4-1106-turbo. In addition, AutoDAN-Turbo is a unified framework that can incorporate existing human-designed jailbreak strategies in a plug-and-play manner. By integrating human-designed strategies, AutoDAN-Turbo can even achieve a higher attack success rate of 93.4 on GPT-4-1106-turbo.","authors":["Xiaogeng Liu","Peiran Li","Edward Suh","Yevgeniy Vorobeychik","Zhuoqing Mao","Somesh Jha","Patrick McDaniel","Huan Sun","Bo Li","Chaowei Xiao"],"url":"https://arxiv.org/abs/2410.05295"}
{"created":"2025-04-23","title":"An Undetectable Watermark for Generative Image Models","abstract":"We present the first undetectable watermarking scheme for generative image models. Undetectability ensures that no efficient adversary can distinguish between watermarked and un-watermarked images, even after making many adaptive queries. In particular, an undetectable watermark does not degrade image quality under any efficiently computable metric. Our scheme works by selecting the initial latents of a diffusion model using a pseudorandom error-correcting code (Christ and Gunn, 2024), a strategy which guarantees undetectability and robustness. We experimentally demonstrate that our watermarks are quality-preserving and robust using Stable Diffusion 2.1. Our experiments verify that, in contrast to every prior scheme we tested, our watermark does not degrade image quality. Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images. Finally, we find that we can robustly encode 512 bits in our watermark, and up to 2500 bits when the images are not subjected to watermark removal attacks. Our code is available at https://github.com/XuandongZhao/PRC-Watermark.","authors":["Sam Gunn","Xuandong Zhao","Dawn Song"],"url":"https://arxiv.org/abs/2410.07369"}
{"created":"2025-04-23","title":"LiveXiv -- A Multi-Modal Live Benchmark Based on Arxiv Papers Content","abstract":"The large-scale training of multi-modal models on data scraped from the web has shown outstanding utility in infusing these models with the required world knowledge to perform effectively on multiple downstream tasks. However, one downside of scraping data from the web can be the potential sacrifice of the benchmarks on which the abilities of these models are often evaluated. To safeguard against test data contamination and to truly test the abilities of these foundation models we propose LiveXiv: A scalable evolving live benchmark based on scientific ArXiv papers. LiveXiv accesses domain-specific manuscripts at any given timestamp and proposes to automatically generate visual question-answer pairs (VQA). This is done without any human-in-the-loop, using the multi-modal content in the manuscripts, like graphs, charts, and tables. Moreover, we introduce an efficient evaluation approach that estimates the performance of all models on the evolving benchmark using evaluations of only a subset of models. This significantly reduces the overall evaluation cost. We benchmark multiple open and proprietary Large Multi-modal Models (LMMs) on the first version of our benchmark, showing its challenging nature and exposing the models true abilities, avoiding contamination. Lastly, in our commitment to high quality, we have collected and evaluated a manually verified subset. By comparing its overall results to our automatic annotations, we have found that the performance variance is indeed minimal (<2.5%). Our dataset is available online on HuggingFace, and our code will be available here.","authors":["Nimrod Shabtay","Felipe Maia Polo","Sivan Doveh","Wei Lin","M. Jehanzeb Mirza","Leshem Chosen","Mikhail Yurochkin","Yuekai Sun","Assaf Arbelle","Leonid Karlinsky","Raja Giryes"],"url":"https://arxiv.org/abs/2410.10783"}
{"created":"2025-04-23","title":"A discrete event simulator for policy evaluation in liver allocation in Eurotransplant","abstract":"We present the ELAS simulator, a discrete event simulator built for the Eurotransplant (ET) Liver Allocation System (ELAS). Eurotransplant uses ELAS to allocate deceased donor livers in eight European countries. The simulator is made publicly available to be transparent on which model Eurotransplant uses to evaluate liver allocation policies, and to facilitate collaborations with policymakers, scientists and other stakeholders in evaluating alternative liver allocation policies. This paper describes the design and modules of the ELAS simulator. One of the included modules is the obligation module, which is instrumental in ensuring that international cooperation in liver allocation benefits all ET member countries.","authors":["Hans de Ferrante","Marieke de Rosner-Van Rosmalen","Bart Smeulders","Frits C. R. Spieksma","Serge Vogelaar"],"url":"https://arxiv.org/abs/2410.10840"}
{"created":"2025-04-23","title":"A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement","abstract":"Reinforcement Learning from Human Feedback (RLHF) has become the predominant approach for language model (LM) alignment. At its core, RLHF uses a margin-based loss for preference optimization, specifying ideal LM behavior only by the difference between preferred and dispreferred responses. In this paper, we identify a common pitfall of margin-based methods -- the under-specification of ideal LM behavior on preferred and dispreferred responses individually, which leads to two unintended consequences as the margin increases: (1) The probability of dispreferred (e.g., unsafe) responses may increase, resulting in potential safety alignment failures. (2) The probability of preferred responses may decrease, even when those responses are ideal. We demystify the reasons behind these problematic behaviors: margin-based losses couple the change in the preferred probability to the gradient of the dispreferred one, and vice versa, often preventing the preferred probability from increasing while the dispreferred one decreases, and thus causing a synchronized increase or decrease in both probabilities. We term this effect, inherent in margin-based objectives, gradient entanglement. Formally, we derive conditions for general margin-based alignment objectives under which gradient entanglement becomes concerning: the inner product of the gradients of preferred and dispreferred log-probabilities is large relative to the individual gradient norms. We theoretically investigate why such inner products can be large when aligning language models and empirically validate our findings. Empirical implications of our framework extend to explaining important differences in the training dynamics of various preference optimization algorithms, and suggesting potential algorithm designs to mitigate the under-specification issue of margin-based methods and thereby improving language model alignment.","authors":["Hui Yuan","Yifan Zeng","Yue Wu","Huazheng Wang","Mengdi Wang","Liu Leqi"],"url":"https://arxiv.org/abs/2410.13828"}
{"created":"2025-04-23","title":"NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples","abstract":"Vision-language models (VLMs) have made significant progress in recent visual-question-answering (VQA) benchmarks that evaluate complex visio-linguistic reasoning. However, are these models truly effective? In this work, we show that VLMs still struggle with natural images and questions that humans can easily answer, which we term natural adversarial samples. We also find it surprisingly easy to generate these VQA samples from natural image-text corpora using off-the-shelf models like CLIP and ChatGPT. We propose a semi-automated approach to collect a new benchmark, NaturalBench, for reliably evaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a $\\textbf{vision-centric}$ design by pairing each question with two images that yield different answers, preventing blind solutions from answering without using the images. This makes NaturalBench more challenging than previous benchmarks that can be solved with commonsense priors. We evaluate 53 state-of-the-art VLMs on NaturalBench, showing that models like LLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o lag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is hard from two angles: (1) Compositionality: Solving NaturalBench requires diverse visio-linguistic skills, including understanding attribute bindings, object relationships, and advanced reasoning like logic and counting. To this end, unlike prior work that uses a single tag per sample, we tag each NaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2) Biases: NaturalBench exposes severe biases in VLMs, as models often choose the same answer regardless of the image. Lastly, we apply our benchmark curation method to diverse data sources, including long captions (over 100 words) and non-English languages like Chinese and Hindi, highlighting its potential for dynamic evaluations of VLMs.","authors":["Baiqi Li","Zhiqiu Lin","Wenxuan Peng","Jean de Dieu Nyandwi","Daniel Jiang","Zixian Ma","Simran Khanuja","Ranjay Krishna","Graham Neubig","Deva Ramanan"],"url":"https://arxiv.org/abs/2410.14669"}
{"created":"2025-04-23","title":"Slipstream: Ebb-and-Flow Consensus on a DAG with Fast Confirmation for UTXO Transactions","abstract":"This paper introduces Slipstream, a Byzantine Fault Tolerance (BFT) protocol where nodes concurrently propose blocks to be added to a Directed Acyclic Graph (DAG) and aim to agree on block ordering. Slipstream offers two types of block orderings: an optimistic ordering, which is live and secure in a sleepy model under up to 50% Byzantine nodes, and a final ordering, which is a prefix of the optimistic ordering and ensures safety and liveness in an eventual lock-step synchronous model under up to 33% Byzantine nodes. Additionally, Slipstream integrates a payment system that allows for fast UTXO transaction confirmation independently of block ordering. Transactions are confirmed in three rounds during synchrony, and unconfirmed double spends are resolved in a novel way using the DAG structure.","authors":["Nikita Polyanskii","Sebastian Muller","Mayank Raikwar"],"url":"https://arxiv.org/abs/2410.14876"}
{"created":"2025-04-23","title":"Rethinking Soft Actor-Critic in High-Dimensional Action Spaces: The Cost of Ignoring Distribution Shift","abstract":"Soft Actor-Critic algorithm is widely recognized for its robust performance across a range of deep reinforcement learning tasks, where it leverages the tanh transformation to constrain actions within bounded limits. However, this transformation induces a distribution shift, distorting the original Gaussian action distribution and potentially leading the policy to select suboptimal actions, particularly in high-dimensional action spaces. In this paper, we conduct a comprehensive theoretical and empirical analysis of this distribution shift, deriving the precise probability density function (PDF) for actions following the tanh transformation to clarify the misalignment introduced between the transformed distribution's mode and the intended action output. We substantiate these theoretical insights through extensive experiments on high-dimensional tasks within the HumanoidBench benchmark. Our findings indicate that accounting for this distribution shift substantially enhances SAC's performance, resulting in notable improvements in cumulative rewards, sample efficiency, and reliability across tasks. These results underscore a critical consideration for SAC and similar algorithms: addressing transformation-induced distribution shifts is essential to optimizing policy effectiveness in high-dimensional deep reinforcement learning environments, thereby expanding the robustness and applicability of SAC in complex control tasks.","authors":["Yanjun Chen","Xinming Zhang","Xianghui Wang","Zhiqiang Xu","Xiaoyu Shen","Wei Zhang"],"url":"https://arxiv.org/abs/2410.16739"}
{"created":"2025-04-23","title":"SWITCH: Studying with Teacher for Knowledge Distillation of Large Language Models","abstract":"Despite the success of Large Language Models (LLMs), they still face challenges related to high inference costs and memory requirements. To address these issues, Knowledge Distillation (KD) has emerged as a popular method for model compression, with student-generated outputs (SGOs) as training data being particularly notable for reducing the mismatch between training and inference. However, SGOs often produce noisy and biased sequences, which can lead to misguidance from the teacher model, especially in long sequences. To mitigate these challenges, we propose SWITCH (Studying WIth TeaCHer for Knowledge Distillation), a novel approach that strategically incorporates the teacher model during the student's sequence generation. SWITCH identifies discrepancies between the token probabilities of the teacher and student models, allowing the teacher to intervene selectively, particularly in long sequences that are more prone to teacher misguidance. Extensive experimental results across three model families and five instruction-following datasets show that SWITCH surpasses traditional KD methods, particularly excelling in the generation of long sequential data.","authors":["Jahyun Koo","Yerin Hwang","Yongil Kim","Taegwan Kang","Hyunkyung Bae","Kyomin Jung"],"url":"https://arxiv.org/abs/2410.19503"}
{"created":"2025-04-23","title":"Towards Unifying Evaluation of Counterfactual Explanations: Leveraging Large Language Models for Human-Centric Assessments","abstract":"As machine learning models evolve, maintaining transparency demands more human-centric explainable AI techniques. Counterfactual explanations, with roots in human reasoning, identify the minimal input changes needed to obtain a given output and, hence, are crucial for supporting decision-making. Despite their importance, the evaluation of these explanations often lacks grounding in user studies and remains fragmented, with existing metrics not fully capturing human perspectives. To address this challenge, we developed a diverse set of 30 counterfactual scenarios and collected ratings across 8 evaluation metrics from 206 respondents. Subsequently, we fine-tuned different Large Language Models (LLMs) to predict average or individual human judgment across these metrics. Our methodology allowed LLMs to achieve an accuracy of up to 63% in zero-shot evaluations and 85% (over a 3-classes prediction) with fine-tuning across all metrics. The fine-tuned models predicting human ratings offer better comparability and scalability in evaluating different counterfactual explanation frameworks.","authors":["Marharyta Domnich","Julius V\\\"alja","Rasmus Moorits Veski","Giacomo Magnifico","Kadi Tulver","Eduard Barbu","Raul Vicente"],"url":"https://arxiv.org/abs/2410.21131"}
{"created":"2025-04-23","title":"Semi-Supervised Self-Learning Enhanced Music Emotion Recognition","abstract":"Music emotion recognition (MER) aims to identify the emotions conveyed in a given musical piece. However, currently, in the field of MER, the available public datasets have limited sample sizes. Recently, segment-based methods for emotion-related tasks have been proposed, which train backbone networks on shorter segments instead of entire audio clips, thereby naturally augmenting training samples without requiring additional resources. Then, the predicted segment-level results are aggregated to obtain the entire song prediction. The most commonly used method is that the segment inherits the label of the clip containing it, but music emotion is not constant during the whole clip. Doing so will introduce label noise and make the training easy to overfit. To handle the noisy label issue, we propose a semi-supervised self-learning (SSSL) method, which can differentiate between samples with correct and incorrect labels in a self-learning manner, thus effectively utilizing the augmented segment-level data. Experiments on three public emotional datasets demonstrate that the proposed method can achieve better or comparable performance.","authors":["Yifu Sun","Xulong Zhang","Monan Zhou","Wei Li"],"url":"https://arxiv.org/abs/2410.21897"}
{"created":"2025-04-23","title":"Vertical Federated Learning with Missing Features During Training and Inference","abstract":"Vertical federated learning trains models from feature-partitioned datasets across multiple clients, who collaborate without sharing their local data. Standard approaches assume that all feature partitions are available during both training and inference. Yet, in practice, this assumption rarely holds, as for many samples only a subset of the clients observe their partition. However, not utilizing incomplete samples during training harms generalization, and not supporting them during inference limits the utility of the model. Moreover, if any client leaves the federation after training, its partition becomes unavailable, rendering the learned model unusable. Missing feature blocks are therefore a key challenge limiting the applicability of vertical federated learning in real-world scenarios. To address this, we propose LASER-VFL, a vertical federated learning method for efficient training and inference of split neural network-based models that is capable of handling arbitrary sets of partitions. Our approach is simple yet effective, relying on the sharing of model parameters and on task-sampling to train a family of predictors. We show that LASER-VFL achieves a $\\mathcal{O}({1}/{\\sqrt{T}})$ convergence rate for nonconvex objectives and, under the Polyak-{\\L}ojasiewicz inequality, it achieves linear convergence to a neighborhood of the optimum. Numerical experiments show improved performance of LASER-VFL over the baselines. Remarkably, this is the case even in the absence of missing features. For example, for CIFAR-100, we see an improvement in accuracy of $19.3\\%$ when each of four feature blocks is observed with a probability of 0.5 and of $9.5\\%$ when all features are observed. The code for this work is available at https://github.com/Valdeira/LASER-VFL.","authors":["Pedro Valdeira","Shiqiang Wang","Yuejie Chi"],"url":"https://arxiv.org/abs/2410.22564"}
{"created":"2025-04-23","title":"A Graph-Based Model for Vehicle-Centric Data Sharing Ecosystem","abstract":"The development of technologies has prompted a paradigm shift in the automotive industry, with an increasing focus on connected services and autonomous driving capabilities. This transformation allows vehicles to collect and share vast amounts of vehicle-specific and personal data. While these technological advancements offer enhanced user experiences, they also raise privacy concerns. To understand the ecosystem of data collection and sharing in modern vehicles, we adopted the ontology 101 methodology to incorporate information extracted from different sources, including analysis of privacy policies using GPT-4, a small-scale systematic literature review, and an existing ontology, to develop a high-level conceptual graph-based model, aiming to get insights into how modern vehicles handle data exchange among different parties. This serves as a foundational model with the flexibility and scalability to further expand for modelling and analysing data sharing practices across diverse contexts. Two realistic examples were developed to demonstrate the usefulness and effectiveness of discovering insights into privacy regarding vehicle-related data sharing. We also recommend several future research directions, such as exploring advanced ontology languages for reasoning tasks, supporting topological analysis for discovering data privacy risks/concerns, and developing useful tools for comparative analysis, to strengthen the understanding of the vehicle-centric data sharing ecosystem.","authors":["Haiyue Yuan","Ali Raza","Nikolay Matyunin","Jibesh Patra","Shujun Li"],"url":"https://arxiv.org/abs/2410.22897"}
{"created":"2025-04-23","title":"Six Candidates Suffice to Win a Voter Majority","abstract":"A cornerstone of social choice theory is Condorcet's paradox which says that in an election where $n$ voters rank $m$ candidates it is possible that, no matter which candidate is declared the winner, a majority of voters would have preferred an alternative candidate. Instead, can we always choose a small committee of winning candidates that is preferred to any alternative candidate by a majority of voters?","authors":["Moses Charikar","Alexandra Lassota","Prasanna Ramakrishnan","Adrian Vetta","Kangning Wang"],"url":"https://arxiv.org/abs/2411.03390"}
{"created":"2025-04-23","title":"Diversity Helps Jailbreak Large Language Models","abstract":"We have uncovered a powerful jailbreak technique that leverages large language models' ability to diverge from prior context, enabling them to bypass safety constraints and generate harmful outputs. By simply instructing the LLM to deviate and obfuscate previous attacks, our method dramatically outperforms existing approaches, achieving up to a 62.83% higher success rate in compromising ten leading chatbots, including GPT-4, Gemini, and Llama, while using only 12.9% of the queries. This revelation exposes a critical flaw in current LLM safety training, suggesting that existing methods may merely mask vulnerabilities rather than eliminate them. Our findings sound an urgent alarm for the need to revolutionize testing methodologies to ensure robust and reliable LLM security.","authors":["Weiliang Zhao","Daniel Ben-Levi","Wei Hao","Junfeng Yang","Chengzhi Mao"],"url":"https://arxiv.org/abs/2411.04223"}
{"created":"2025-04-23","title":"Graph Neural Network Surrogates to leverage Mechanistic Expert Knowledge towards Reliable and Immediate Pandemic Response","abstract":"During the COVID-19 crisis, mechanistic models have guided evidence-based decision making. However, time-critical decisions in a dynamical environment limit the time available to gather supporting evidence. Infectious disease dynamics are often heterogeneous on a spatial or demographic scale, requiring appropriately resolved models. In addition, with a large number of potential interventions, all scenarios can barely be computed on time, even when using supercomputing facilities. We suggest to couple complex mechanistic models with data-driven surrogate models to allow for on-the-fly model adaptations by public health experts and decision makers. We build upon a spatially and demographically resolved infectious disease metapopulation model and train a graph neural network for data sets representing prevaccination phases of a pandemic. The resulting networks reached an execution time of a fraction of a second, a speeding up the metapopulation up to four orders of magnitude. The approach yields large potential for on-the-fly execution and, thus, facilitates integration into low-barrier web applications for use in pandemic decision-making.","authors":["Agatha Schmidt","Henrik Zunker","Alexander Heinlein","Martin J. K\\\"uhn"],"url":"https://arxiv.org/abs/2411.06500"}
{"created":"2025-04-23","title":"Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching","abstract":"In inverse reinforcement learning (IRL), an agent seeks to replicate expert demonstrations through interactions with the environment. Traditionally, IRL is treated as an adversarial game, where an adversary searches over reward models, and a learner optimizes the reward through repeated RL procedures. This game-solving approach is both computationally expensive and difficult to stabilize. In this work, we propose a novel approach to IRL by direct policy optimization: exploiting a linear factorization of the return as the inner product of successor features and a reward vector, we design an IRL algorithm by policy gradient descent on the gap between the learner and expert features. Our non-adversarial method does not require learning a reward function and can be solved seamlessly with existing actor-critic RL algorithms. Remarkably, our approach works in state-only settings without expert action labels, a setting which behavior cloning (BC) cannot solve. Empirical results demonstrate that our method learns from as few as a single expert demonstration and achieves improved performance on various control tasks.","authors":["Arnav Kumar Jain","Harley Wiltzer","Jesse Farebrother","Irina Rish","Glen Berseth","Sanjiban Choudhury"],"url":"https://arxiv.org/abs/2411.07007"}
{"created":"2025-04-23","title":"Explicit symmetric low-regularity integrators for the nonlinear Schr\\\"odinger equation","abstract":"The numerical approximation of low-regularity solutions to the nonlinear Schr\\\"odinger equation is notoriously difficult and even more so if structure-preserving schemes are sought. Recent works have been successful in establishing symmetric low-regularity integrators for this equation. However, so far, all prior symmetric low-regularity algorithms are fully implicit, and therefore require the solution of a nonlinear equation at each time step, leading to significant numerical cost in the iteration. In this work, we introduce the first fully explicit (multi-step) symmetric low-regularity integrators for the nonlinear Schr\\\"odinger equation. We demonstrate the construction of an entire class of such schemes which notably can be used to symmetrise (in explicit form) a large amount of existing low-regularity integrators. We provide rigorous convergence analysis of our schemes and numerical examples demonstrating both the favourable structure preservation properties obtained with our novel schemes, and the significant reduction in computational cost over implicit methods.","authors":["Yue Feng","Georg Maierhofer","Chushan Wang"],"url":"https://arxiv.org/abs/2411.07720"}
{"created":"2025-04-23","title":"Exploring the loss landscape of regularized neural networks via convex duality","abstract":"We discuss several aspects of the loss landscape of regularized neural networks: the structure of stationary points, connectivity of optimal solutions, path with nonincreasing loss to arbitrary global optimum, and the nonuniqueness of optimal solutions, by casting the problem into an equivalent convex problem and considering its dual. Starting from two-layer neural networks with scalar output, we first characterize the solution set of the convex problem using its dual and further characterize all stationary points. With the characterization, we show that the topology of the global optima goes through a phase transition as the width of the network changes, and construct counterexamples where the problem may have a continuum of optimal solutions. Finally, we show that the solution set characterization and connectivity results can be extended to different architectures, including two-layer vector-valued neural networks and parallel three-layer neural networks.","authors":["Sungyoon Kim","Aaron Mishkin","Mert Pilanci"],"url":"https://arxiv.org/abs/2411.07729"}
{"created":"2025-04-23","title":"SoK: DAG-based Consensus Protocols","abstract":"This paper is a Systematization of Knowledge (SoK) on Directed Acyclic Graph (DAG)-based consensus protocols, analyzing their performance and trade-offs within the framework of consistency, availability, and partition tolerance inspired by the CAP theorem.","authors":["Mayank Raikwar","Nikita Polyanskii","Sebastian M\\\"uller"],"url":"https://arxiv.org/abs/2411.10026"}
{"created":"2025-04-23","title":"MDHP-Net: Detecting an Emerging Time-exciting Threat in IVN","abstract":"The integration of intelligent and connected technologies in modern vehicles, while offering enhanced functionalities through Electronic Control Unit (ECU) and interfaces like OBD-II and telematics, also exposes the vehicle's in-vehicle network (IVN) to potential cyberattacks. Unlike prior work, we identify a new time-exciting threat model against IVN. These attacks inject malicious messages that exhibit a time-exciting effect, gradually manipulating network traffic to disrupt vehicle operations and compromise safety-critical functions. We systematically analyze the characteristics of the threat: dynamism, time-exciting impact, and low prior knowledge dependency. To validate its practicality, we replicate the attack on a real Advanced Driver Assistance System via Controller Area Network (CAN), exploiting Unified Diagnostic Service vulnerabilities and proposing four attack strategies. While CAN's integrity checks mitigate attacks, Ethernet migration (e.g., DoIP/SOME/IP) introduces new surfaces. We further investigate the feasibility of time-exciting threat under SOME/IP. To detect time-exciting threat, we introduce MDHP-Net, leveraging Multi-Dimentional Hawkes Process (MDHP) and temporal and message-wise feature extracting structures. Meanwhile, to estimate MDHP parameters, we developed the first GPU-optimized gradient descent solver for MDHP (MDHP-GDS). These modules significantly improves the detection rate under time-exciting attacks in multi-ECU IVN system. To address data scarcity, we release STEIA9, the first open-source dataset for time-exciting attacks, covering 9 Ethernet-based attack scenarios. Extensive experiments on STEIA9 (9 attack scenarios) show MDHP-Net outperforms 3 baselines, confirming attack feasibility and detection efficacy.","authors":["Qi Liu","Yanchen Liu","Ruifeng Li","Chenhong Cao","Yufeng Li","Xingyu Li","Peng Wang","Runhan Feng","Shiyang Bu"],"url":"https://arxiv.org/abs/2504.11867"}
{"created":"2025-04-23","title":"Trading off performance and human oversight in algorithmic policy: evidence from Danish college admissions","abstract":"Student dropout is a significant concern for educational institutions due to its social and economic impact, driving the need for risk prediction systems to identify at-risk students before enrollment. We explore the accuracy of such systems in the context of higher education by predicting degree completion before admission, with potential applications for prioritizing admissions decisions. Using a large-scale dataset from Danish higher education admissions, we demonstrate that advanced sequential AI models offer more precise and fair predictions compared to current practices that rely on either high school grade point averages or human judgment. These models not only improve accuracy but also outperform simpler models, even when the simpler models use protected sociodemographic attributes. Importantly, our predictions reveal how certain student profiles are better matched with specific programs and fields, suggesting potential efficiency and welfare gains in public policy. We estimate that even the use of simple AI models to guide admissions decisions, particularly in response to a newly implemented nationwide policy reducing admissions by 10 percent, could yield significant economic benefits. However, this improvement would come at the cost of reduced human oversight and lower transparency. Our findings underscore both the potential and challenges of incorporating advanced AI into educational policymaking.","authors":["Magnus Lindgaard Nielsen","Jonas Skjold Raaschou-Pedersen","Emil Chrisander","David Dreyer Lassen","Julien Grenet","Anna Rogers","Andreas Bjerre-Nielsen"],"url":"https://arxiv.org/abs/2411.15348"}
{"created":"2025-04-23","title":"CityWalker: Learning Embodied Urban Navigation from Web-Scale Videos","abstract":"Navigating dynamic urban environments presents significant challenges for embodied agents, requiring advanced spatial reasoning and adherence to common-sense norms. Despite progress, existing visual navigation methods struggle in map-free or off-street settings, limiting the deployment of autonomous agents like last-mile delivery robots. To overcome these obstacles, we propose a scalable, data-driven approach for human-like urban navigation by training agents on thousands of hours of in-the-wild city walking and driving videos sourced from the web. We introduce a simple and scalable data processing pipeline that extracts action supervision from these videos, enabling large-scale imitation learning without costly annotations. Our model learns sophisticated navigation policies to handle diverse challenges and critical scenarios. Experimental results show that training on large-scale, diverse datasets significantly enhances navigation performance, surpassing current methods. This work shows the potential of using abundant online video data to develop robust navigation policies for embodied agents in dynamic urban settings. Project homepage is at https://ai4ce.github.io/CityWalker/.","authors":["Xinhao Liu","Jintong Li","Yicheng Jiang","Niranjan Sujay","Zhicheng Yang","Juexiao Zhang","John Abanes","Jing Zhang","Chen Feng"],"url":"https://arxiv.org/abs/2411.17820"}
{"created":"2025-04-23","title":"HEMGS: A Hybrid Entropy Model for 3D Gaussian Splatting Data Compression","abstract":"In this work, we propose a novel compression framework for 3D Gaussian Splatting (3DGS) data. Building on anchor-based 3DGS methodologies, our approach compresses all attributes within each anchor by introducing a novel Hybrid Entropy Model for 3D Gaussian Splatting (HEMGS) to achieve hybrid lossy-lossless compression. It consists of three main components: a variable-rate predictor, a hyperprior network, and an autoregressive network. First, unlike previous methods that adopt multiple models to achieve multi-rate lossy compression, thereby increasing training overhead, our variable-rate predictor enables variable-rate compression with a single model and a hyperparameter $\\lambda$ by producing a learned Quantization Step feature for versatile lossy compression. Second, to improve lossless compression, the hyperprior network captures both scene-agnostic and scene-specific features to generate a prior feature, while the autoregressive network employs an adaptive context selection algorithm with flexible receptive fields to produce a contextual feature. By integrating these two features, HEMGS can accurately estimate the distribution of the current coding element within each attribute, enabling improved entropy coding and reduced storage. We integrate HEMGS into a compression framework, and experimental results on four benchmarks indicate that HEMGS achieves about a 40% average reduction in size while maintaining rendering quality over baseline methods and achieving state-of-the-art compression results.","authors":["Lei Liu","Zhenghao Chen","Wei Jiang","Wei Wang","Dong Xu"],"url":"https://arxiv.org/abs/2411.18473"}
{"created":"2025-04-23","title":"Age of Information in Random Access Networks with Energy Harvesting","abstract":"We study the age of information (AoI) in a random access network consisting of multiple source-destination pairs, where each source node is empowered by energy harvesting capability. Every source node transmits a sequence of data packets to its destination using only the harvested energy. Each data packet is encoded with finite-length codewords, characterizing the nature of short codeword transmissions in random access networks. By combining tools from bulk-service Markov chains with stochastic geometry, we derive an analytical expression for the network average AoI and obtain closed-form results in two special cases, i.e., the small and large energy buffer size scenarios. Our analysis reveals the trade-off between energy accumulation time and transmission success probability. We then optimize the network average AoI by jointly adjusting the update rate and the blocklength of the data packet. Our findings indicate that the optimal update rate should be set to one in the energy-constrained regime where the energy consumption rate exceeds the energy arrival rate. This also means if the optimal blocklength of the data packet is pre-configured, an energy buffer size supporting only one transmission is sufficient.","authors":["Fangming Zhao","Nikolaos Pappas","Meng Zhang","Howard H. Yang"],"url":"https://arxiv.org/abs/2412.01192"}
{"created":"2025-04-23","title":"Is Large-Scale Pretraining the Secret to Good Domain Generalization?","abstract":"Multi-Source Domain Generalization (DG) is the task of training on multiple source domains and achieving high classification performance on unseen target domains. Recent methods combine robust features from web-scale pretrained backbones with new features learned from source data, and this has dramatically improved benchmark results. However, it remains unclear if DG finetuning methods are becoming better over time, or if improved benchmark performance is simply an artifact of stronger pre-training. Prior studies have shown that perceptual similarity to pre-training data correlates with zero-shot performance, but we find the effect limited in the DG setting. Instead, we posit that having perceptually similar data in pretraining is not enough; and that it is how well these data were learned that determines performance. This leads us to introduce the Alignment Hypothesis, which states that the final DG performance will be high if and only if alignment of image and class label text embeddings is high. Our experiments confirm the Alignment Hypothesis is true, and we use it as an analysis tool of existing DG methods evaluated on DomainBed datasets by splitting evaluation data into In-pretraining (IP) and Out-of-pretraining (OOP). We show that all evaluated DG methods struggle on DomainBed-OOP, while recent methods excel on DomainBed-IP. Put together, our findings highlight the need for DG methods which can generalize beyond pretraining alignment.","authors":["Piotr Teterwak","Kuniaki Saito","Theodoros Tsiligkaridis","Bryan A. Plummer","Kate Saenko"],"url":"https://arxiv.org/abs/2412.02856"}
{"created":"2025-04-23","title":"Network-aided Efficient LLM Services With Denoising-inspired Prompt Compression","abstract":"Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks, leading to their increasing adoption in diverse services delivered through wireless networks. There is a growing trend toward longer prompts to better leverage LLMs' capabilities and address difficult tasks. However, longer prompts not only increase data transmission costs but also require more computing resources and processing time, which impacts overall system efficiency and user experience. To address this challenge, we propose Joint Power and Prompt Optimization (JPPO), a framework that combines Small Language Model (SLM)-based prompt compression with wireless power allocation optimization. By deploying SLM at edge devices for prompt compression and employing Deep Reinforcement Learning (DRL) for joint optimization of compression ratio and transmission power, JPPO effectively balances service quality with resource efficiency. Furthermore, inspired by denoising diffusion models, we design a denoising-inspired prompt compression approach that iteratively compresses prompts by gradually removing non-critical information, further enhancing the framework's performance. Experimental results with long prompt tokens demonstrate that our framework achieves high service fidelity while optimizing power usage in wireless LLM services, significantly reducing the total service response time. With our DRL-based JPPO, the framework maintains fidelity comparable to the no-compression baseline while still achieving a 17% service time reduction through adaptive compression.","authors":["Feiran You","Hongyang Du","Kaibin Huang","Abbas Jamalipour"],"url":"https://arxiv.org/abs/2412.03621"}
{"created":"2025-04-23","title":"Federated Automated Feature Engineering","abstract":"Automated feature engineering (AutoFE) is used to automatically create new features from original features to improve predictive performance without needing significant human intervention and domain expertise. Many algorithms exist for AutoFE, but very few approaches exist for the federated learning (FL) setting where data is gathered across many clients and is not shared between clients or a central server. We introduce AutoFE algorithms for the horizontal, vertical, and hybrid FL settings, which differ in how the data is gathered across clients. To the best of our knowledge, we are the first to develop AutoFE algorithms for the horizontal and hybrid FL cases, and we show that the downstream test scores of our federated AutoFE algorithms is close in performance to the case where data is held centrally and AutoFE is performed centrally.","authors":["Tom Overman","Diego Klabjan"],"url":"https://arxiv.org/abs/2412.04404"}
{"created":"2025-04-23","title":"EvTTC: An Event Camera Dataset for Time-to-Collision Estimation","abstract":"Time-to-Collision (TTC) estimation lies in the core of the forward collision warning (FCW) functionality, which is key to all Automatic Emergency Braking (AEB) systems. Although the success of solutions using frame-based cameras (e.g., Mobileye's solutions) has been witnessed in normal situations, some extreme cases, such as the sudden variation in the relative speed of leading vehicles and the sudden appearance of pedestrians, still pose significant risks that cannot be handled. This is due to the inherent imaging principles of frame-based cameras, where the time interval between adjacent exposures introduces considerable system latency to AEB. Event cameras, as a novel bio-inspired sensor, offer ultra-high temporal resolution and can asynchronously report brightness changes at the microsecond level. To explore the potential of event cameras in the above-mentioned challenging cases, we propose EvTTC, which is, to the best of our knowledge, the first multi-sensor dataset focusing on TTC tasks under high-relative-speed scenarios. EvTTC consists of data collected using standard cameras and event cameras, covering various potential collision scenarios in daily driving and involving multiple collision objects. Additionally, LiDAR and GNSS/INS measurements are provided for the calculation of ground-truth TTC. Considering the high cost of testing TTC algorithms on full-scale mobile platforms, we also provide a small-scale TTC testbed for experimental validation and data augmentation. All the data and the design of the testbed are open sourced, and they can serve as a benchmark that will facilitate the development of vision-based TTC techniques.","authors":["Kaizhen Sun","Jinghang Li","Kuan Dai","Bangyan Liao","Wei Xiong","Yi Zhou"],"url":"https://arxiv.org/abs/2412.05053"}
{"created":"2025-04-23","title":"Supply Chain Insecurity: The Lack of Integrity Protection in SBOM Solutions","abstract":"The SolarWinds attack, which exploited weaknesses in a software update mechanism, highlights the critical need for organizations to have better visibility into their software dependencies and potential vulnerabilities associated with them. The Software Bill of Materials (SBOM) is paramount in ensuring software supply chain security. Under the Executive Order issued by President Biden, the adoption of the SBOM has become obligatory within the United States. The executive order mandates that an SBOM must be provided for all software purchased by federal agencies. In this paper, we present an in-depth and systematic investigation of the trust that can be put into the output of SBOMs. Our research reveals that the SBOM generation process across popular programming languages is susceptible to stealthy manipulation by malicious insiders, leading to significant supply chain insecurities. We then investigated the tools used to consume SBOMs, examining their capability to detect and handle manipulated or compromised SBOM data. To address these security issues, we analyze the use of public repositories for software libraries to validate the integrity of dependencies and demonstrate the feasibility of our proof-of-concept implementation. We further evaluate an alternative, decentralized approach based on blockchain.","authors":["Can Ozkan","Xinhai Zou","Dave Singelee"],"url":"https://arxiv.org/abs/2412.05138"}
{"created":"2025-04-23","title":"Faster and Better 3D Splatting via Group Training","abstract":"3D Gaussian Splatting (3DGS) has emerged as a powerful technique for novel view synthesis, demonstrating remarkable capability in high-fidelity scene reconstruction through its Gaussian primitive representations. However, the computational overhead induced by the massive number of primitives poses a significant bottleneck to training efficiency. To overcome this challenge, we propose Group Training, a simple yet effective strategy that organizes Gaussian primitives into manageable groups, optimizing training efficiency and improving rendering quality. This approach shows universal compatibility with existing 3DGS frameworks, including vanilla 3DGS and Mip-Splatting, consistently achieving accelerated training while maintaining superior synthesis quality. Extensive experiments reveal that our straightforward Group Training strategy achieves up to 30% faster convergence and improved rendering quality across diverse scenarios.","authors":["Chengbo Wang","Guozheng Ma","Yifei Xue","Yizhen Lao"],"url":"https://arxiv.org/abs/2412.07608"}
{"created":"2025-04-23","title":"Deep-Learning Control of Lower-Limb Exoskeletons via simplified Therapist Input","abstract":"Partial-assistance exoskeletons hold significant potential for gait rehabilitation by promoting active participation during (re)learning of normative walking patterns. Typically, the control of interaction torques in partial-assistance exoskeletons relies on a hierarchical control structure. These approaches require extensive calibration due to the complexity of the controller and user-specific parameter tuning, especially for activities like stair or ramp navigation. To address the limitations of hierarchical control in exoskeletons, this work proposes a three-step, data-driven approach: (1) using recent sensor data to probabilistically infer locomotion states (landing step length, landing step height, walking velocity, step clearance, gait phase), (2) allowing therapists to modify these features via a user interface, and (3) using the adjusted locomotion features to predict the desired joint posture and model stiffness in a spring-damper system based on prediction uncertainty. We evaluated the proposed approach with two healthy participants engaging in treadmill walking and stair ascent and descent at varying speeds, with and without external modification of the gait features through a user interface. Results showed a variation in kinematics according to the gait characteristics and a negative interaction power suggesting exoskeleton assistance across the different conditions.","authors":["Lorenzo Vianello","Cl\\'ement Lhoste","Emek Bar{\\i}\\c{s} K\\\"u\\c{c}\\\"uktabak","Matthew Short","Levi Hargrove","Jose L. Pons"],"url":"https://arxiv.org/abs/2412.07959"}
{"created":"2025-04-23","title":"AI Predicts AGI: Leveraging AGI Forecasting and Peer Review to Explore LLMs' Complex Reasoning Capabilities","abstract":"We tasked 16 state-of-the-art large language models (LLMs) with estimating the likelihood of Artificial General Intelligence (AGI) emerging by 2030. To assess the quality of these forecasts, we implemented an automated peer review process (LLM-PR). The LLMs' estimates varied widely, ranging from 3% (Reka- Core) to 47.6% (GPT-4o), with a median of 12.5%. These estimates closely align with a recent expert survey that projected a 10% likelihood of AGI by 2027, underscoring the relevance of LLMs in forecasting complex, speculative scenarios. The LLM-PR process demonstrated strong reliability, evidenced by a high Intraclass Correlation Coefficient (ICC = 0.79), reflecting notable consistency in scoring across the models. Among the models, Pplx-70b-online emerged as the top performer, while Gemini-1.5-pro-api ranked the lowest. A cross-comparison with external benchmarks, such as LMSYS Chatbot Arena, revealed that LLM rankings remained consistent across different evaluation methods, suggesting that existing benchmarks may not encapsulate some of the skills relevant for AGI prediction. We further explored the use of weighting schemes based on external benchmarks, optimizing the alignment of LLMs' predictions with human expert forecasts. This analysis led to the development of a new, 'AGI benchmark' designed to highlight performance differences in AGI-related tasks. Our findings offer insights into LLMs' capabilities in speculative, interdisciplinary forecasting tasks and emphasize the growing need for innovative evaluation frameworks for assessing AI performance in complex, uncertain real-world scenarios.","authors":["Fabrizio Davide","Pietro Torre","Leonardo Ercolani","Andrea Gaggioli"],"url":"https://arxiv.org/abs/2412.09385"}
{"created":"2025-04-23","title":"WhisperFlow: speech foundation models in real time","abstract":"Speech foundation models, such as OpenAI's Whisper, become the state of the art in speech understanding due to their strong accuracy and generalizability. Yet, their applications are mostly limited to processing pre-recorded speech, whereas processing of streaming speech, in particular doing it efficiently, remains rudimentary. Behind this inefficiency are multiple fundamental reasons: (1) speech foundation models are trained to process long, fixed-length voice inputs (often 30 seconds); (2) encoding each voice input requires encoding as many as 1,500 tokens with tens of transformer layers; (3) decoding each output entails an irregular, complex beam search. As such, streaming speech processing on resource-constrained client devices is more expensive than other AI tasks, e.g., text generation.","authors":["Rongxiang Wang","Zhiming Xu","Felix Xiaozhu Lin"],"url":"https://arxiv.org/abs/2412.11272"}
{"created":"2025-04-23","title":"Codenames as a Benchmark for Large Language Models","abstract":"In this paper, we propose the use of the popular word-based board game Codenames as a suitable benchmark for evaluating the reasoning capabilities of Large Language Models (LLMs). Codenames presents a highly interesting challenge for achieving successful AI performance, requiring both a sophisticated understanding of language, theory of mind, and epistemic reasoning capabilities. Prior attempts to develop agents for Codenames have largely relied on word embedding techniques, which have a limited vocabulary range and perform poorly when paired with differing approaches. LLMs have demonstrated enhanced reasoning and comprehension capabilities for language-based tasks, but can still suffer in lateral thinking challenges. We evaluate the capabilities of several state-of-the-art LLMs, including GPT-4o, Gemini 1.5, Claude 3.5 Sonnet, and Llama 3.1, across a variety of board setups. Our results indicate that while certain LLMs perform better than others overall, different models exhibit varying emergent behaviours during gameplay and excel at specific roles. We also evaluate the performance of different combinations of LLMs when playing cooperatively together, demonstrating that LLM agents are more generalisable to a wider range of teammates than prior techniques.","authors":["Matthew Stephenson","Matthew Sidji","Beno\\^it Ronval"],"url":"https://arxiv.org/abs/2412.11373"}
{"created":"2025-04-23","title":"Harnessing Language for Coordination: A Framework and Benchmark for LLM-Driven Multi-Agent Control","abstract":"Large Language Models (LLMs) have demonstrated remarkable performance across various tasks. Their potential to facilitate human coordination with many agents is a promising but largely under-explored area. Such capabilities would be helpful in disaster response, urban planning, and real-time strategy scenarios. In this work, we introduce (1) a real-time strategy game benchmark designed to evaluate these abilities and (2) a novel framework we term HIVE. HIVE empowers a single human to coordinate swarms of up to 2,000 agents through a natural language dialog with an LLM. We present promising results on this multi-agent benchmark, with our hybrid approach solving tasks such as coordinating agent movements, exploiting unit weaknesses, leveraging human annotations, and understanding terrain and strategic points. Our findings also highlight critical limitations of current models, including difficulties in processing spatial visual information and challenges in formulating long-term strategic plans. This work sheds light on the potential and limitations of LLMs in human-swarm coordination, paving the way for future research in this area. The HIVE project page, hive.syrkis.com, includes videos of the system in action.","authors":["Timoth\\'ee Anne","Noah Syrkis","Meriem Elhosni","Florian Turati","Franck Legendre","Alain Jaquier","Sebastian Risi"],"url":"https://arxiv.org/abs/2412.11761"}
{"created":"2025-04-23","title":"Falcon: Faster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding Tree","abstract":"Striking an optimal balance between minimal drafting latency and high speculation accuracy to enhance the inference speed of Large Language Models remains a significant challenge in speculative decoding. In this paper, we introduce Falcon, an innovative semi-autoregressive speculative decoding framework fashioned to augment both the drafter's parallelism and output quality. Falcon incorporates the Coupled Sequential Glancing Distillation technique, which fortifies inter-token dependencies within the same block, leading to increased speculation accuracy. We offer a comprehensive theoretical analysis to illuminate the underlying mechanisms. Additionally, we introduce a Custom-Designed Decoding Tree, which permits the drafter to generate multiple tokens in a single forward pass and accommodates multiple forward passes as needed, thereby boosting the number of drafted tokens and significantly improving the overall acceptance rate. Comprehensive evaluations on benchmark datasets such as MT-Bench, HumanEval, and GSM8K demonstrate Falcon's superior acceleration capabilities. The framework achieves a lossless speedup ratio ranging from 2.91x to 3.51x when tested on the Vicuna and LLaMA2-Chat model series. These results outstrip existing speculative decoding methods for LLMs, including Eagle, Medusa, Lookahead, SPS, and PLD, while maintaining a compact drafter architecture equivalent to merely two Transformer layers.","authors":["Xiangxiang Gao","Weisheng Xie","Yiwei Xiang","Feng Ji"],"url":"https://arxiv.org/abs/2412.12639"}
{"created":"2025-04-23","title":"Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation","abstract":"Prompts play a critical role in unleashing the power of language and vision foundation models for specific tasks. For the first time, we introduce prompting into depth foundation models, creating a new paradigm for metric depth estimation termed Prompt Depth Anything. Specifically, we use a low-cost LiDAR as the prompt to guide the Depth Anything model for accurate metric depth output, achieving up to 4K resolution. Our approach centers on a concise prompt fusion design that integrates the LiDAR at multiple scales within the depth decoder. To address training challenges posed by limited datasets containing both LiDAR depth and precise GT depth, we propose a scalable data pipeline that includes synthetic data LiDAR simulation and real data pseudo GT depth generation. Our approach sets new state-of-the-arts on the ARKitScenes and ScanNet++ datasets and benefits downstream applications, including 3D reconstruction and generalized robotic grasping.","authors":["Haotong Lin","Sida Peng","Jingxiao Chen","Songyou Peng","Jiaming Sun","Minghuan Liu","Hujun Bao","Jiashi Feng","Xiaowei Zhou","Bingyi Kang"],"url":"https://arxiv.org/abs/2412.14015"}
{"created":"2025-04-23","title":"Sparse induced subgraphs in $P_7$-free graphs of bounded clique number","abstract":"Many natural computational problems, including e.g. Max Weight Independent Set, Feedback Vertex Set, or Vertex Planarization, can be unified under an umbrella of finding the largest sparse induced subgraph, that satisfies some property definable in CMSO$_2$ logic.","authors":["Maria Chudnovsky","Jadwiga Czy\\.zewska","Kacper Kluk","Marcin Pilipczuk","Pawe{\\l} Rz\\k{a}\\.zewski"],"url":"https://arxiv.org/abs/2412.14836"}
{"created":"2025-04-23","title":"Fine-tuning Whisper on Low-Resource Languages for Real-World Applications","abstract":"This paper presents a new approach to fine-tuning OpenAI's Whisper model for low-resource languages by introducing a novel data generation method that converts sentence-level data into a long-form corpus, using Swiss German as a case study. Non-sentence-level data, which could improve the performance of long-form audio, is difficult to obtain and often restricted by copyright laws. Our method bridges this gap by transforming more accessible sentence-level data into a format that preserves the model's ability to handle long-form audio and perform segmentation without requiring non-sentence-level data. Our data generation process improves performance in several real-world applications and leads to the development of a new state-of-the-art speech-to-text (STT) model for Swiss German. We compare our model with a non-fine-tuned Whisper and our previous state-of-the-art Swiss German STT models, where our new model achieves higher BLEU scores. Our results also indicate that the proposed method is adaptable to other low-resource languages, supported by written guidance and code that allows the creation of fine-tuned Whisper models, which keep segmentation capabilities and allow the transcription of longer audio files using only sentence-level data with high quality.","authors":["Vincenzo Timmel","Claudio Paonessa","Reza Kakooee","Manfred Vogel","Daniel Perruchoud"],"url":"https://arxiv.org/abs/2412.15726"}
{"created":"2025-04-23","title":"Fearful Falcons and Angry Llamas: Emotion Category Annotations of Arguments by Humans and LLMs","abstract":"Arguments evoke emotions, influencing the effect of the argument itself. Not only the emotional intensity but also the category influence the argument's effects, for instance, the willingness to adapt stances. While binary emotionality has been studied in arguments, there is no work on discrete emotion categories (e.g., \"Anger\") in such data. To fill this gap, we crowdsource subjective annotations of emotion categories in a German argument corpus and evaluate automatic LLM-based labeling methods. Specifically, we compare three prompting strategies (zero-shot, one-shot, chain-of-thought) on three large instruction-tuned language models (Falcon-7b-instruct, Llama-3.1-8B-instruct, GPT-4o-mini). We further vary the definition of the output space to be binary (is there emotionality in the argument?), closed-domain (which emotion from a given label set is in the argument?), or open-domain (which emotion is in the argument?). We find that emotion categories enhance the prediction of emotionality in arguments, emphasizing the need for discrete emotion annotations in arguments. Across all prompt settings and models, automatic predictions show a high recall but low precision for predicting anger and fear, indicating a strong bias toward negative emotions.","authors":["Lynn Greschner","Roman Klinger"],"url":"https://arxiv.org/abs/2412.15993"}
{"created":"2025-04-23","title":"Trading Devil RL: Backdoor attack via Stock market, Bayesian Optimization and Reinforcement Learning","abstract":"With the rapid development of generative artificial intelligence, particularly large language models a number of sub-fields of deep learning have made significant progress and are now very useful in everyday applications. For example,financial institutions simulate a wide range of scenarios for various models created by their research teams using reinforcement learning, both before production and after regular operations. In this work, we propose a backdoor attack that focuses solely on data poisoning and a method of detection by dynamic systems and statistical analysis of the distribution of data. This particular backdoor attack is classified as an attack without prior consideration or trigger, and we name it FinanceLLMsBackRL. Our aim is to examine the potential effects of large language models that use reinforcement learning systems for text production or speech recognition, finance, physics, or the ecosystem of contemporary artificial intelligence models.","authors":["Orson Mengara"],"url":"https://arxiv.org/abs/2412.17908"}
{"created":"2025-04-23","title":"Switch-a-View: View Selection Learned from Unlabeled In-the-wild Videos","abstract":"We introduce SWITCH-A-VIEW, a model that learns to automatically select the viewpoint to display at each timepoint when creating a how-to video. The key insight of our approach is how to train such a model from unlabeled -- but human-edited -- video samples. We pose a pretext task that pseudo-labels segments in the training videos for their primary viewpoint (egocentric or exocentric), and then discovers the patterns between the visual and spoken content in a how-to video on the one hand and its view-switch moments on the other hand. Armed with this predictor, our model can be applied to new multi-view video settings for orchestrating which viewpoint should be displayed when, even when such settings come with limited labels. We demonstrate our idea on a variety of real-world videos from HowTo100M and Ego-Exo4D, and rigorously validate its advantages. Project: https://vision.cs.utexas.edu/projects/switch_a_view/.","authors":["Sagnik Majumder","Tushar Nagarajan","Ziad Al-Halah","Kristen Grauman"],"url":"https://arxiv.org/abs/2412.18386"}
{"created":"2025-04-23","title":"Faster Semi-streaming Matchings via Alternating Trees","abstract":"We design a deterministic algorithm for the $(1+\\epsilon)$-approximate maximum matching problem. Our primary result demonstrates that this problem can be solved in $O(\\epsilon^{-6})$ semi-streaming passes, improving upon the $O(\\epsilon^{-19})$ pass-complexity algorithm by [Fischer, Mitrovi\\'c, and Uitto, STOC'22]. This contributes substantially toward resolving Open question 2 from [Assadi, SOSA'24]. Leveraging the framework introduced in [FMU'22], our algorithm achieves an analogous round complexity speed-up for computing a $(1+\\epsilon)$-approximate maximum matching in both the Massively Parallel Computation (MPC) and CONGEST models.","authors":["Slobodan Mitrovi\\'c","Anish Mukherjee","Piotr Sankowski","Wen-Horng Sheu"],"url":"https://arxiv.org/abs/2412.19057"}
{"created":"2025-04-23","title":"Synthetic Discrete Inertia","abstract":"This letter demonstrates how synthetic inertia can be obtained with the control of flexible discrete devices to keep the power balance of power systems, even if the system does not include any synchronous generator or conventional grid-forming converter. The letter also discusses solutions to cycling issues, which can arise due to the interaction of uncoordinated discrete inertia controllers. The effectiveness, dynamic performance, and challenges of the proposed approach are validated through simulations using modified versions of the WSCC 9-bus test system and of the all-island Irish transmission system.","authors":["A. Vaca","F. Milano"],"url":"https://arxiv.org/abs/2412.19131"}
{"created":"2025-04-23","title":"Joint Optimization of Multimodal Transit Frequency and Shared Autonomous Vehicle Fleet Size with Hybrid Metaheuristic and Nonlinear Programming","abstract":"Shared autonomous vehicles (SAVs) bring competition to traditional transit services but redesigning multimodal transit network can utilize SAVs as feeders to enhance service efficiency and coverage. This paper presents an optimization framework for the joint multimodal transit frequency and SAV fleet size problem, a variant of the transit network frequency setting problem. The objective is to maximize total transit ridership (including SAV-fed trips and subtracting boarding rejections) across multiple time periods under budget constraints, considering endogenous mode choice (transit, point-to-point SAVs, driving) and route selection, while allowing for strategic route removal by setting frequencies to zero. Due to the problem's non-linear, non-convex nature and the computational challenges of large-scale networks, we develop a hybrid solution approach that combines a metaheuristic approach (particle swarm optimization) with nonlinear programming for local solution refinement. To ensure computational tractability, the framework integrates analytical approximation models for SAV waiting times based on fleet utilization, multimodal network assignment for route choice, and multinomial logit mode choice behavior, bypassing the need for computationally intensive simulations within the main optimization loop. Applied to the Chicago metropolitan area's multimodal network, our method illustrates a 33.3% increase in transit ridership through optimized transit route frequencies and SAV integration, particularly enhancing off-peak service accessibility and strategically reallocating resources.","authors":["Max T. M. Ng","Hani S. Mahmassani","Draco Tong","Omer Verbas","Taner Cokyasar"],"url":"https://arxiv.org/abs/2412.19401"}
{"created":"2025-04-23","title":"Hear the Scene: Audio-Enhanced Text Spotting","abstract":"Recent advancements in scene text spotting have focused on end-to-end methodologies that heavily rely on precise location annotations, which are often costly and labor-intensive to procure. In this study, we introduce an innovative approach that leverages only transcription annotations for training text spotting models, substantially reducing the dependency on elaborate annotation processes. Our methodology employs a query-based paradigm that facilitates the learning of implicit location features through the interaction between text queries and image embeddings. These features are later refined during the text recognition phase using an attention activation map. Addressing the challenges associated with training a weakly-supervised model from scratch, we implement a circular curriculum learning strategy to enhance model convergence. Additionally, we introduce a coarse-to-fine cross-attention localization mechanism for more accurate text instance localization. Notably, our framework supports audio-based annotation, which significantly diminishes annotation time and provides an inclusive alternative for individuals with disabilities. Our approach achieves competitive performance against existing benchmarks, demonstrating that high accuracy in text spotting can be attained without extensive location annotations.","authors":["Jing Li","Bo Wang"],"url":"https://arxiv.org/abs/2412.19504"}
{"created":"2025-04-23","title":"Graph Neural Networks for Next-Generation-IoT: Recent Advances and Open Challenges","abstract":"Graph Neural Networks (GNNs) have emerged as a critical tool for optimizing and managing the complexities of the Internet of Things (IoT) in next-generation networks. This survey presents a comprehensive exploration of how GNNs may be harnessed in 6G IoT environments, focusing on key challenges and opportunities through a series of open questions. We commence with an exploration of GNN paradigms and the roles of node, edge, and graph-level tasks in solving wireless networking problems and highlight GNNs' ability to overcome the limitations of traditional optimization methods. This guidance enhances problem-solving efficiency across various next-generation (NG) IoT scenarios. Next, we provide a detailed discussion of the application of GNN in advanced NG enabling technologies, including massive MIMO, reconfigurable intelligent surfaces, satellites, THz, mobile edge computing (MEC), and ultra-reliable low latency communication (URLLC). We then delve into the challenges posed by adversarial attacks, offering insights into defense mechanisms to secure GNN-based NG-IoT networks. Next, we examine how GNNs can be integrated with future technologies like integrated sensing and communication (ISAC), satellite-air-ground-sea integrated networks (SAGSIN), and quantum computing. Our findings highlight the transformative potential of GNNs in improving efficiency, scalability, and security within NG-IoT systems, paving the way for future advances. Finally, we propose a set of design guidelines to facilitate the development of efficient, scalable, and secure GNN models tailored for NG IoT applications.","authors":["Nguyen Xuan Tung","Le Tung Giang","Bui Duc Son","Seon Geun Jeong","Trinh Van Chien","Won Joo Hwang","Lajos Hanzo"],"url":"https://arxiv.org/abs/2412.20634"}
{"created":"2025-04-23","title":"Effective Application of Normalized Min-Sum Decoding for Short BCH Codes","abstract":"This paper introduces an enhanced normalized min-sum decoder designed to address the performance and complexity challenges associated with developing parallelizable decoders for short BCH codes in high-throughput applications. The decoder optimizes the standard parity-check matrix using heuristic binary summation and random cyclic row shifts, resulting in a Tanner graph with low density, controlled redundancy, and minimized length-4 cycles. The impact of row redundancy and rank deficiency in the dual code's minimum-weight codewords on decoding performance is analyzed. To improve convergence, three random automorphisms are applied simultaneously to the inputs, with the resulting messages merged at the end of each iteration. Extensive simulations demonstrate that, for BCH codes with block lengths of 63 and 127, the enhanced normalized min-sum decoder achieves a 1-2 dB performance gain and 100X faster convergence compared to existing parallel and iterative decoders. Additionally, a hybrid decoding scheme is proposed, which selectively activates order statistics decoding when the enhanced normalized min-sum decoder fails. This hybrid approach is shown to approach maximum-likelihood performance while retaining the advantages of the normalized min-sum decoder across a broad SNR range.","authors":["Guangwen Li","Xiao Yu"],"url":"https://arxiv.org/abs/2412.20828"}
{"created":"2025-04-23","title":"FlashInfer: Efficient and Customizable Attention Engine for LLM Inference Serving","abstract":"Transformers, driven by attention mechanisms, form the foundation of large language models (LLMs). As these models scale up, efficient GPU attention kernels become essential for high-throughput and low-latency inference. Diverse LLM applications demand flexible and high-performance attention solutions. We present FlashInfer: a customizable and efficient attention engine for LLM serving. FlashInfer tackles KV-cache storage heterogeneity using block-sparse format and composable formats to optimize memory access and reduce redundancy. It also offers a customizable attention template, enabling adaptation to various settings through Just-In-Time (JIT) compilation. Additionally, FlashInfer's load-balanced scheduling algorithm adjusts to dynamism of user requests while maintaining compatibility with CUDAGraph which requires static configuration. FlashInfer have been integrated into leading LLM serving frameworks like SGLang, vLLM and MLC-Engine. Comprehensive kernel-level and end-to-end evaluations demonstrate FlashInfer's ability to significantly boost kernel performance across diverse inference scenarios: compared to state-of-the-art LLM serving solutions, FlashInfer achieve 29-69% inter-token-latency reduction compared to compiler backends for LLM serving benchmark, 28-30% latency reduction for long-context inference, and 13-17% speedup for LLM serving with parallel generation.","authors":["Zihao Ye","Lequn Chen","Ruihang Lai","Wuwei Lin","Yineng Zhang","Stephanie Wang","Tianqi Chen","Baris Kasikci","Vinod Grover","Arvind Krishnamurthy","Luis Ceze"],"url":"https://arxiv.org/abs/2501.01005"}
{"created":"2025-04-23","title":"First-place Solution for Streetscape Shop Sign Recognition Competition","abstract":"Text recognition technology applied to street-view storefront signs is increasingly utilized across various practical domains, including map navigation, smart city planning analysis, and business value assessments in commercial districts. This technology holds significant research and commercial potential. Nevertheless, it faces numerous challenges. Street view images often contain signboards with complex designs and diverse text styles, complicating the text recognition process. A notable advancement in this field was introduced by our team in a recent competition. We developed a novel multistage approach that integrates multimodal feature fusion, extensive self-supervised training, and a Transformer-based large model. Furthermore, innovative techniques such as BoxDQN, which relies on reinforcement learning, and text rectification methods were employed, leading to impressive outcomes. Comprehensive experiments have validated the effectiveness of these methods, showcasing our potential to enhance text recognition capabilities in complex urban environments.","authors":["Bin Wang","Li Jing"],"url":"https://arxiv.org/abs/2501.02811"}
{"created":"2025-04-23","title":"MObI: Multimodal Object Inpainting Using Diffusion Models","abstract":"Safety-critical applications, such as autonomous driving, require extensive multimodal data for rigorous testing. Methods based on synthetic data are gaining prominence due to the cost and complexity of gathering real-world data but require a high degree of realism and controllability in order to be useful. This paper introduces MObI, a novel framework for Multimodal Object Inpainting that leverages a diffusion model to create realistic and controllable object inpaintings across perceptual modalities, demonstrated for both camera and lidar simultaneously. Using a single reference RGB image, MObI enables objects to be seamlessly inserted into existing multimodal scenes at a 3D location specified by a bounding box, while maintaining semantic consistency and multimodal coherence. Unlike traditional inpainting methods that rely solely on edit masks, our 3D bounding box conditioning gives objects accurate spatial positioning and realistic scaling. As a result, our approach can be used to insert novel objects flexibly into multimodal scenes, providing significant advantages for testing perception models.","authors":["Alexandru Buburuzan","Anuj Sharma","John Redford","Puneet K. Dokania","Romain Mueller"],"url":"https://arxiv.org/abs/2501.03173"}
{"created":"2025-04-23","title":"Steady-state and transient thermal stress analysis using a polygonal finite element method","abstract":"This work develops a polygonal finite element method (PFEM) for the analysis of steady-state and transient thermal stresses in two dimensional continua. The method employs Wachspress rational basis functions to construct conforming interpolations over arbitrary convex polygonal meshes, providing enhanced geometric flexibility and accuracy in capturing complex boundary conditions and heterogeneous material behavior. A quadtree-based acceleration strategy is introduced to significantly reduce computational cost through the reuse of precomputed stiffness and mass matrices. The PFEM is implemented in ABAQUS via a user-defined element (UEL) framework. Comprehensive benchmark problems, including multi-scale and non-matching mesh scenarios, are conducted to verify the accuracy, convergence properties, and computational efficiency of the method. Results indicate that the proposed PFEM offers notable advantages over conventional FEM in terms of mesh adaptability, solution quality, and runtime performance. The method shows strong potential for large-scale simulations involving thermal-mechanical coupling, complex geometries, and multi-resolution modeling.","authors":["Yang Yang","Mingjiao Yan","Zongliang Zhang","Dengmiao Hao","Xuedong Chen","Weixiong Chen"],"url":"https://arxiv.org/abs/2501.03908"}
{"created":"2025-04-23","title":"A novel Facial Recognition technique with Focusing on Masked Faces","abstract":"Recognizing the same faces with and without masks is important for ensuring consistent identification in security, access control, and public safety. This capability is crucial in scenarios like law enforcement, healthcare, and surveillance, where accurate recognition must be maintained despite facial occlusion. This research focuses on the challenge of recognizing the same faces with and without masks by employing cosine similarity as the primary technique. With the increased use of masks, traditional facial recognition systems face significant accuracy issues, making it crucial to develop methods that can reliably identify individuals in masked conditions. For that reason, this study proposed Masked-Unmasked Face Matching Model (MUFM). This model employs transfer learning using the Visual Geometry Group (VGG16) model to extract significant facial features, which are subsequently classified utilizing the K-Nearest Neighbors (K-NN) algorithm. The cosine similarity metric is employed to compare masked and unmasked faces of the same individuals. This approach represents a novel contribution, as the task of recognizing the same individual with and without a mask using cosine similarity has not been previously addressed. By integrating these advanced methodologies, the research demonstrates effective identification of individuals despite the presence of masks, addressing a significant limitation in traditional systems. Using data is another essential part of this work, by collecting and preparing an image dataset from three different sources especially some of those data are real provided a comprehensive power of this research. The image dataset used were already collected in three different datasets of masked and unmasked for the same faces.","authors":["Dana A Abdullah","Dana Rasul Hamad","Ismail Y. Maolood","Hakem Beitollahi","Aso K. Ameen","Sirwan A. Aula","Abdulhady Abas Abdulla","Mohammed Y. Shakorf","Sabat Salih Muhamad"],"url":"https://arxiv.org/abs/2501.04444"}
{"created":"2025-04-23","title":"De-centering the (Traditional) User: Multistakeholder Evaluation of Recommender Systems","abstract":"Multistakeholder recommender systems are those that account for the impacts and preferences of multiple groups of individuals, not just the end users receiving recommendations. Due to their complexity, these systems cannot be evaluated strictly by the overall utility of a single stakeholder, as is often the case of more mainstream recommender system applications. In this article, we focus our discussion on the challenges of multistakeholder evaluation of recommender systems. We bring attention to the different aspects involved -- from the range of stakeholders involved (including but not limited to providers and consumers) to the values and specific goals of each relevant stakeholder. We discuss how to move from theoretical principles to practical implementation, providing specific use case examples. Finally, we outline open research directions for the RecSys community to explore. We aim to provide guidance to researchers and practitioners about incorporating these complex and domain-dependent issues of evaluation in the course of designing, developing, and researching applications with multistakeholder aspects.","authors":["Robin Burke","Gediminas Adomavicius","Toine Bogers","Tommaso Di Noia","Dominik Kowald","Julia Neidhardt","\\\"Ozlem \\\"Ozg\\\"obek","Maria Soledad Pera","Nava Tintarev","J\\\"urgen Ziegler"],"url":"https://arxiv.org/abs/2501.05170"}
{"created":"2025-04-23","title":"FedSA: A Unified Representation Learning via Semantic Anchors for Prototype-based Federated Learning","abstract":"Prototype-based federated learning has emerged as a promising approach that shares lightweight prototypes to transfer knowledge among clients with data heterogeneity in a model-agnostic manner. However, existing methods often collect prototypes directly from local models, which inevitably introduce inconsistencies into representation learning due to the biased data distributions and differing model architectures among clients. In this paper, we identify that both statistical and model heterogeneity create a vicious cycle of representation inconsistency, classifier divergence, and skewed prototype alignment, which negatively impacts the performance of clients. To break the vicious cycle, we propose a novel framework named Federated Learning via Semantic Anchors (FedSA) to decouple the generation of prototypes from local representation learning. We introduce a novel perspective that uses simple yet effective semantic anchors serving as prototypes to guide local models in learning consistent representations. By incorporating semantic anchors, we further propose anchor-based regularization with margin-enhanced contrastive learning and anchor-based classifier calibration to correct feature extractors and calibrate classifiers across clients, achieving intra-class compactness and inter-class separability of prototypes while ensuring consistent decision boundaries. We then update the semantic anchors with these consistent and discriminative prototypes, which iteratively encourage clients to collaboratively learn a unified data representation with robust generalization. Extensive experiments under both statistical and model heterogeneity settings show that FedSA significantly outperforms existing prototype-based FL methods on various classification tasks.","authors":["Yanbing Zhou","Xiangmou Qu","Chenlong You","Jiyang Zhou","Jingyue Tang","Xin Zheng","Chunmao Cai","Yingbo Wu"],"url":"https://arxiv.org/abs/2501.05496"}
{"created":"2025-04-23","title":"Orthogonal projection-based regularization for efficient model augmentation","abstract":"Deep-learning-based nonlinear system identification has shown the ability to produce reliable and highly accurate models in practice. However, these black-box models lack physical interpretability, and a considerable part of the learning effort is often spent on capturing already expected/known behavior of the system, that can be accurately described by first-principles laws of physics. A potential solution is to directly integrate such prior physical knowledge into the model structure, combining the strengths of physics-based modeling and deep-learning-based identification. The most common approach is to use an additive model augmentation structure, where the physics-based and the machine-learning (ML) components are connected in parallel, i.e., additively. However, such models are overparametrized, training them is challenging, potentially causing the physics-based part to lose interpretability. To overcome this challenge, this paper proposes an orthogonal projection-based regularization technique to enhance parameter learning and even model accuracy in learning-based augmentation of nonlinear baseline models.","authors":["Bendeg\\'uz M. Gy\\\"or\\\"ok","Jan H. Hoekstra","Johan Kon","Tam\\'as P\\'eni","Maarten Schoukens","Roland T\\'oth"],"url":"https://arxiv.org/abs/2501.05842"}
{"created":"2025-04-23","title":"LitmusKt: Concurrency Stress Testing for Kotlin","abstract":"We present LitmusKt - the first tool for litmus testing concurrent programs in Kotlin. The tool's novelty also lies in the fact that Kotlin is a multiplatform language, i.e., it compiles into multiple platforms, which means that the concurrency has to be tested on several of them. Our tool allows writing litmus tests in a single custom DSL, and these tests are then run in Kotlin/Native and Kotlin/JVM, two main platforms for concurrent programming in Kotlin. Using LitmusKt, we discovered novel bugs in the Kotlin compiler, which we then fixed and they are no longer present. Moreover, LitmusKt was integrated into the CI pipeline for Kotlin. LitmusKt is available on GitHub: https://github.com/JetBrains-Research/litmuskt. The demo is available on YouTube: https://youtu.be/oWCZp_Huwss.","authors":["Denis Lochmelis","Evgenii Moiseenko","Yaroslav Golubev","Anton Podkopaev"],"url":"https://arxiv.org/abs/2501.07472"}
{"created":"2025-04-23","title":"ClusterViG: Efficient Globally Aware Vision GNNs via Image Partitioning","abstract":"Convolutional Neural Networks (CNN) and Vision Transformers (ViT) have dominated the field of Computer Vision (CV). Graph Neural Networks (GNN) have performed remarkably well across diverse domains because they can represent complex relationships via unstructured graphs. However, the applicability of GNNs for visual tasks was unexplored till the introduction of Vision GNNs (ViG). Despite the success of ViGs, their performance is severely bottlenecked due to the expensive $k$-Nearest Neighbors ($k$-NN) based graph construction. Recent works addressing this bottleneck impose constraints on the flexibility of GNNs to build unstructured graphs, undermining their core advantage while introducing additional inefficiencies. To address these issues, in this paper, we propose a novel method called Dynamic Efficient Graph Convolution (DEGC) for designing efficient and globally aware ViGs. DEGC partitions the input image and constructs graphs in parallel for each partition, improving graph construction efficiency. Further, DEGC integrates local intra-graph and global inter-graph feature learning, enabling enhanced global context awareness. Using DEGC as a building block, we propose a novel CNN-GNN architecture, ClusterViG, for CV tasks. Extensive experiments indicate that ClusterViG reduces end-to-end inference latency for vision tasks by up to $5\\times$ when compared against a suite of models such as ViG, ViHGNN, PVG, and GreedyViG, with a similar model parameter count. Additionally, ClusterViG reaches state-of-the-art performance on image classification, object detection, and instance segmentation tasks, demonstrating the effectiveness of the proposed globally aware learning strategy. Finally, input partitioning performed by DEGC enables ClusterViG to be trained efficiently on higher-resolution images, underscoring the scalability of our approach.","authors":["Dhruv Parikh","Jacob Fein-Ashley","Tian Ye","Rajgopal Kannan","Viktor Prasanna"],"url":"https://arxiv.org/abs/2501.10640"}
{"created":"2025-04-23","title":"Sparse L0-norm based Kernel-free Quadratic Surface Support Vector Machines","abstract":"Kernel-free quadratic surface support vector machine (SVM) models have gained significant attention in machine learning. However, introducing a quadratic classifier increases the model's complexity by quadratically expanding the number of parameters relative to the dimensionality of the data, exacerbating overfitting. Hence, we propose sparse $\\ell_0$-norm based Kernel-free quadratic surface SVMs, designed to mitigate overfitting and enhance interpretability. Given the intractable nature of these models, we present a penalty decomposition algorithm to obtain first-order optimality points efficiently. We demonstrate that the subproblems in our framework either admit closed-form solutions or can leverage duality theory to improve computational efficiency. Through empirical evaluations on real-world datasets, we demonstrate the efficacy and robustness of our approach, showcasing its potential to advance Kernel-free quadratic surface SVMs in practical applications while addressing overfitting concerns. All the implemented models and experiment codes are available at https://github.com/raminzandvakili/L0-QSVM.","authors":["Ahmad Mousavi","Ramin Zandvakili"],"url":"https://arxiv.org/abs/2501.11268"}
{"created":"2025-04-23","title":"Continuous signal sparse encoding using analog neuromorphic variability","abstract":"Achieving fast and reliable temporal signal encoding is crucial for low-power, always-on systems. While current spike-based encoding algorithms rely on complex networks or precise timing references, simple and robust encoding models can be obtained by leveraging the intrinsic properties of analog hardware substrates. We propose an encoding framework inspired by biological principles that leverages intrinsic neuronal variability to robustly encode continuous stimuli into spatio-temporal patterns, using at most one spike per neuron. The encoder has low model complexity, relying on a shallow network of heterogeneous neurons. It relies on an internal time reference, allowing for continuous processing. Moreover, stimulus parameters can be linearly decoded from the spiking patterns, granting fast information retrieval. Our approach, validated on both analog neuromorphic hardware and simulation, demonstrates high robustness to noise, spike jitter, and reduced heterogeneity. Consistently with biological observations, we observed the spontaneous emergence of patterns with stereotyped spiking order. The proposed encoding scheme facilitates fast, robust and continuous information processing, making it well-suited for low-power, low-latency processing of temporal data on analog neuromorphic substrates.","authors":["Filippo Costa","Chiara De Luca"],"url":"https://arxiv.org/abs/2501.13504"}
{"created":"2025-04-23","title":"Weihrauch problems as containers","abstract":"We note that Weihrauch problems can be regarded as containers over the category of projective represented spaces and that Weihrauch reductions correspond exactly to container morphisms. We also show that Bauer's extended Weihrauch degrees and the posetal reflection of containers over partition assemblies are equivalent. Using this characterization, we show how a number of operators over Weihrauch degrees, such as the composition product, also arise naturally from the abstract theory of polynomial functors.","authors":["C\\'ecilia Pradic","Ian Price"],"url":"https://arxiv.org/abs/2501.17250"}
{"created":"2025-04-23","title":"Impact of Reactive Jamming Attacks on LoRaWAN: a Theoretical and Experimental Study","abstract":"This paper investigates the impact of reactive jamming on LoRaWAN networks, focusing on showing that LoRaWAN communications can be effectively disrupted with minimal jammer exposure time. The susceptibility of LoRa to jamming is assessed through a theoretical study of how the frame success rate is impacted by only a few jamming symbols. Different jamming approaches are studied, among which repeated-symbol jamming appears to be the most disruptive, with sufficient jamming power. A key contribution of this work is the proposal of a software-defined radio (SDR)-based jamming approach implemented on GNU Radio that generates a controlled number of random symbols, independent of the standard LoRa frame structure. This approach enables precise control over jammer exposure time and provides flexibility in studying the effect of jamming symbols on network performance. The theoretical analysis is validated through experimental results, where the implemented jammer is used to assess the impact of jamming under various configurations. Our findings demonstrate that LoRa-based networks can be disrupted with a minimal number of symbols, emphasizing the need for future research on stealthy communication techniques to counter such jamming attacks.","authors":["Amavi Dossa","Andreas Burg","El Mehdi Amhoud"],"url":"https://arxiv.org/abs/2501.18339"}
{"created":"2025-04-23","title":"Semaphores Augmented with a Waiting Array","abstract":"Semaphores are a widely used and foundational synchronization and coordination construct used for shared memory multithreaded programming. They are a keystone concept, in the sense that most other synchronization constructs can be implemented in terms of semaphores, although the converse does not generally hold. Semaphores and the quality of their implementation are of consequence as they remain heavily used in the Linux kernel and are also available for application programming via the pthreads programming interface.","authors":["Dave Dice","Alex Kogan"],"url":"https://arxiv.org/abs/2501.18447"}
{"created":"2025-04-23","title":"Mitigating Traffic Oscillations in Mixed Traffic Flow with Scalable Deep Koopman Predictive Control","abstract":"The use of connected automated vehicle (CAV) is advocated to mitigate traffic oscillations in mixed traffic flow consisting of CAVs and human driven vehicles (HDVs). This study proposes an adaptive deep Koopman predictive control framework (AdapKoopPC) for regulating mixed traffic flow. Firstly, a Koopman theory-based adaptive trajectory prediction deep network (AdapKoopnet) is designed for modeling HDVs car-following behavior. AdapKoopnet enables the representation of HDVs behavior by a linear model in a high-dimensional space. Secondly, the model predictive control is employed to smooth the mixed traffic flow, where the combination of the linear dynamic model of CAVs and linear prediction blocks from AdapKoopnet is embedded as the predictive model into the AdapKoopPC. Finally, the predictive performance of the prosed AdapKoopnet is verified using the HighD naturalistic driving dataset. Furthermore, the control performance of AdapKoopPC is validated by the numerical simulations. Results demonstrate that the AdapKoopnet provides more accuracy HDVs predicted trajectories than the baseline nonlinear models. Moreover, the proposed AdapKoopPC exhibits more effective control performance with less computation cost compared with baselines in mitigating traffic oscillations, especially at the low CAVs penetration rates. The code of proposed AdapKoopPC is open source.","authors":["Hao Lyu","Yanyong Guo","Pan Liu","Nan Zheng","Ting Wang","Quansheng Yue"],"url":"https://arxiv.org/abs/2502.00043"}
{"created":"2025-04-23","title":"Model-Free Predictive Control: Introductory Algebraic Calculations, and a Comparison with HEOL and ANNs","abstract":"Model predictive control (MPC) is a popular control engineering practice, but requires a sound knowledge of the model. Model-free predictive control (MFPC), a burning issue today, also related to reinforcement learning (RL) in AI, is reformulated here via a linear differential equation with constant coefficients, thanks to a new perspective on optimal control combined with recent advances in the field of model-free control (MFC). It is replacing Dynamic Programming, the Hamilton-Jacobi-Bellman equation, and Pontryagin's Maximum Principle. The computing burden is low. The implementation is straightforward. Two nonlinear examples, a chemical reactor and a two tank system, are illustrating our approach. A comparison with the HEOL setting, where some expertise of the process model is needed, shows only a slight superiority of the later. A recent identification of the two tank system via a complex ANN architecture might indicate that a full modeling and the corresponding machine learning mechanism are not always necessary neither in control, nor, more generally, in AI.","authors":["C\\'edric Join","Emmanuel Delaleau","Michel Fliess"],"url":"https://arxiv.org/abs/2502.00443"}
{"created":"2025-04-23","title":"On the Guidance of Flow Matching","abstract":"Flow matching has shown state-of-the-art performance in various generative tasks, ranging from image generation to decision-making, where guided generation is pivotal. However, the guidance of flow matching is more general than and thus substantially different from that of its predecessor, diffusion models. Therefore, the challenge in guidance for general flow matching remains largely underexplored. In this paper, we propose the first framework of general guidance for flow matching. From this framework, we derive a family of guidance techniques that can be applied to general flow matching. These include a new training-free asymptotically exact guidance, novel training losses for training-based guidance, and two classes of approximate guidance that cover classical gradient guidance methods as special cases. We theoretically investigate these different methods to give a practical guideline for choosing suitable methods in different scenarios. Experiments on synthetic datasets, image inverse problems, and offline reinforcement learning demonstrate the effectiveness of our proposed guidance methods and verify the correctness of our flow matching guidance framework. Code to reproduce the experiments can be found at https://github.com/AI4Science-WestlakeU/flow_guidance.","authors":["Ruiqi Feng","Tailin Wu","Chenglei Yu","Wenhao Deng","Peiyan Hu"],"url":"https://arxiv.org/abs/2502.02150"}
{"created":"2025-04-23","title":"CVKAN: Complex-Valued Kolmogorov-Arnold Networks","abstract":"In this work we propose CVKAN, a complex-valued Kolmogorov-Arnold Network (KAN), to join the intrinsic interpretability of KANs and the advantages of Complex-Valued Neural Networks (CVNNs). We show how to transfer a KAN and the necessary associated mechanisms into the complex domain. To confirm that CVKAN meets expectations we conduct experiments on symbolic complex-valued function fitting and physically meaningful formulae as well as on a more realistic dataset from knot theory. Our proposed CVKAN is more stable and performs on par or better than real-valued KANs while requiring less parameters and a shallower network architecture, making it more explainable.","authors":["Matthias Wolff","Florian Eilers","Xiaoyi Jiang"],"url":"https://arxiv.org/abs/2502.02417"}
{"created":"2025-04-23","title":"Convergent NMPC-based Reinforcement Learning Using Deep Expected Sarsa and Nonlinear Temporal Difference Learning","abstract":"In this paper, we present a learning-based nonlinear model predictive controller (NMPC) using an original reinforcement learning (RL) method to learn the optimal weights of the NMPC scheme, for which two methods are proposed. Firstly, the controller is used as the current action-value function of a deep Expected Sarsa where the subsequent action-value function, usually obtained with a secondary NMPC, is approximated with a neural network (NN). With respect to existing methods, we add to the NN's input the current value of the NMPC's learned parameters so that the network is able to approximate the action-value function and stabilize the learning performance. Additionally, with the use of the NN, the real-time computational burden is approximately halved without affecting the closed-loop performance. Secondly, we combine gradient temporal difference methods with a parametrized NMPC as a function approximator of the Expected Sarsa RL method to overcome the potential parameters' divergence and instability issues when nonlinearities are present in the function approximation. The simulation results show that the proposed approach converges to a locally optimal solution without instability problems.","authors":["Amine Salaje","Thomas Chevet","Nicolas Langlois"],"url":"https://arxiv.org/abs/2502.04925"}
{"created":"2025-04-23","title":"ParquetDB: A Lightweight Python Parquet-Based Database","abstract":"Traditional data storage formats and databases often introduce complexities and inefficiencies that hinder rapid iteration and adaptability. To address these challenges, we introduce ParquetDB, a Python-based database framework that leverages the Parquet file format's optimized columnar storage. ParquetDB offers efficient serialization and deserialization, native support for complex and nested data types, reduced dependency on indexing through predicate pushdown filtering, and enhanced portability due to its file-based storage system. Benchmarks show that ParquetDB outperforms traditional databases like SQLite and MongoDB in managing large volumes of data, especially when using data formats compatible with PyArrow. We validate ParquetDB's practical utility by applying it to the Alexandria 3D Materials Database, efficiently handling approximately 4.8 million complex and nested records. By addressing the inherent limitations of existing data storage systems and continuously evolving to meet future demands, ParquetDB has the potential to significantly streamline data management processes and accelerate research development in data-driven fields.","authors":["Logan Lang","Eduardo Hernandez","Kamal Choudhary","Aldo H. Romero"],"url":"https://arxiv.org/abs/2502.05311"}
{"created":"2025-04-23","title":"Onion Routing Key Distribution for QKDN","abstract":"The advance of quantum computing poses a significant threat to classical cryptography, compromising the security of current encryption schemes such as RSA and ECC. In response to this challenge, two main approaches have emerged: quantum cryptography and post-quantum cryptography (PQC). However, both have implementation and security limitations. In this paper, we propose a secure key distribution protocol for Quantum Key Distribution Networks (QKDN), which incorporates encapsulation techniques in the key-relay model for QKDN inspired by onion routing and combined with PQC to guarantee confidentiality, integrity, authenticity and anonymity in communication. The proposed protocol optimizes security by using post-quantum public key encryption to protect the shared secrets from intermediate nodes in the QKDN, thereby reducing the risk of attacks by malicious intermediaries. Finally, relevant use cases are presented, such as critical infrastructure networks, interconnection of data centers and digital money, demonstrating the applicability of the proposal in critical high-security environments.","authors":["Pedro Otero-Garc\\'ia","Javier Blanco-Romero","Ana Fern\\'andez-Vilas","Daniel Sobral-Blanco","Manuel Fern\\'andez-Veiga","Florina Almenares-Mendoza"],"url":"https://arxiv.org/abs/2502.06657"}
{"created":"2025-04-23","title":"AgilePilot: DRL-Based Drone Agent for Real-Time Motion Planning in Dynamic Environments by Leveraging Object Detection","abstract":"Autonomous drone navigation in dynamic environments remains a critical challenge, especially when dealing with unpredictable scenarios including fast-moving objects with rapidly changing goal positions. While traditional planners and classical optimisation methods have been extensively used to address this dynamic problem, they often face real-time, unpredictable changes that ultimately leads to sub-optimal performance in terms of adaptiveness and real-time decision making. In this work, we propose a novel motion planner, AgilePilot, based on Deep Reinforcement Learning (DRL) that is trained in dynamic conditions, coupled with real-time Computer Vision (CV) for object detections during flight. The training-to-deployment framework bridges the Sim2Real gap, leveraging sophisticated reward structures that promotes both safety and agility depending upon environment conditions. The system can rapidly adapt to changing environments, while achieving a maximum speed of 3.0 m/s in real-world scenarios. In comparison, our approach outperforms classical algorithms such as Artificial Potential Field (APF) based motion planner by 3 times, both in performance and tracking accuracy of dynamic targets by using velocity predictions while exhibiting 90% success rate in 75 conducted experiments. This work highlights the effectiveness of DRL in tackling real-time dynamic navigation challenges, offering intelligent safety and agility.","authors":["Roohan Ahmed Khan","Valerii Serpiva","Demetros Aschalew","Aleksey Fedoseev","Dzmitry Tsetserukou"],"url":"https://arxiv.org/abs/2502.06725"}
{"created":"2025-04-23","title":"Low-temperature Sampling on Sparse Random Graphs","abstract":"We consider sampling in the so-called low-temperature regime, which is typically characterised by non-local behaviour and strong global correlations. Canonical examples include sampling independent sets on bipartite graphs and sampling from the ferromagnetic $q$-state Potts model. Low-temperature sampling is computationally intractable for general graphs, but recent advances based on the polymer method have made significant progress for graph families that exhibit certain expansion properties that reinforce the correlations, including for example expanders, lattices and dense graphs.","authors":["Andreas Galanis","Leslie Ann Goldberg","Paulina Smolarova"],"url":"https://arxiv.org/abs/2502.08328"}
{"created":"2025-04-23","title":"Robot Data Curation with Mutual Information Estimators","abstract":"The performance of imitation learning policies often hinges on the datasets with which they are trained. Consequently, investment in data collection for robotics has grown across both industrial and academic labs. However, despite the marked increase in the quantity of demonstrations collected, little work has sought to assess the quality of said data despite mounting evidence of its importance in other areas such as vision and language. In this work, we take a critical step towards addressing the data quality in robotics. Given a dataset of demonstrations, we aim to estimate the relative quality of individual demonstrations in terms of both action diversity and predictability. To do so, we estimate the average contribution of a trajectory towards the mutual information between states and actions in the entire dataset, which captures both the entropy of the marginal action distribution and the state-conditioned action entropy. Though commonly used mutual information estimators require vast amounts of data often beyond the scale available in robotics, we introduce a novel technique based on k-nearest neighbor estimates of mutual information on top of simple VAE embeddings of states and actions. Empirically, we demonstrate that our approach is able to partition demonstration datasets by quality according to human expert scores across a diverse set of benchmarks spanning simulation and real world environments. Moreover, training policies based on data filtered by our method leads to a 5-10% improvement in RoboMimic and better performance on real ALOHA and Franka setups.","authors":["Joey Hejna","Suvir Mirchandani","Ashwin Balakrishna","Annie Xie","Ayzaan Wahid","Jonathan Tompson","Pannag Sanketi","Dhruv Shah","Coline Devin","Dorsa Sadigh"],"url":"https://arxiv.org/abs/2502.08623"}
{"created":"2025-04-23","title":"Stable Hypergraph Matching in Unimodular Hypergraphs","abstract":"We study the NP-hard Stable Hypergraph Matching (SHM) problem and its generalization allowing capacities, the Stable Hypergraph $b$-Matching (SH$b$M) problem, and investigate their computational properties under various structural constraints. Our study is motivated by the fact that Scarf's Lemma (Scarf, 1967) together with a result of Lov\\'asz (1972) guarantees the existence of a stable matching whenever the underlying hypergraph is normal. Furthermore, if the hypergraph is unimodular (i.e., its incidence matrix is totally unimodular), then even a stable $b$-matching is guaranteed to exist. However, no polynomial-time algorithm is known for finding a stable matching or $b$-matching in unimodular hypergraphs.","authors":["P\\'eter Bir\\'o","Gergely Cs\\'aji","Ildik\\'o Schlotter"],"url":"https://arxiv.org/abs/2502.08827"}
{"created":"2025-04-23","title":"Variable Stiffness for Robust Locomotion through Reinforcement Learning","abstract":"Reinforcement-learned locomotion enables legged robots to perform highly dynamic motions but often accompanies time-consuming manual tuning of joint stiffness. This paper introduces a novel control paradigm that integrates variable stiffness into the action space alongside joint positions, enabling grouped stiffness control such as per-joint stiffness (PJS), per-leg stiffness (PLS) and hybrid joint-leg stiffness (HJLS). We show that variable stiffness policies, with grouping in per-leg stiffness (PLS), outperform position-based control in velocity tracking and push recovery. In contrast, HJLS excels in energy efficiency. Despite the fact that our policy is trained on flat floor only, our method showcases robust walking behaviour on diverse outdoor terrains, indicating robust sim-to-real transfer. Our approach simplifies design by eliminating per-joint stiffness tuning while keeping competitive results with various metrics.","authors":["Dario Spoljaric","Yashuai Yan","Dongheui Lee"],"url":"https://arxiv.org/abs/2502.09436"}
{"created":"2025-04-23","title":"Selective Task Group Updates for Multi-Task Optimization","abstract":"Multi-task learning enables the acquisition of task-generic knowledge by training multiple tasks within a unified architecture. However, training all tasks together in a single architecture can lead to performance degradation, known as negative transfer, which is a main concern in multi-task learning. Previous works have addressed this issue by optimizing the multi-task network through gradient manipulation or weighted loss adjustments. However, their optimization strategy focuses on addressing task imbalance in shared parameters, neglecting the learning of task-specific parameters. As a result, they show limitations in mitigating negative transfer, since the learning of shared space and task-specific information influences each other during optimization. To address this, we propose a different approach to enhance multi-task performance by selectively grouping tasks and updating them for each batch during optimization. We introduce an algorithm that adaptively determines how to effectively group tasks and update them during the learning process. To track inter-task relations and optimize multi-task networks simultaneously, we propose proximal inter-task affinity, which can be measured during the optimization process. We provide a theoretical analysis on how dividing tasks into multiple groups and updating them sequentially significantly affects multi-task performance by enhancing the learning of task-specific parameters. Our methods substantially outperform previous multi-task optimization approaches and are scalable to different architectures and various numbers of tasks.","authors":["Wooseong Jeong","Kuk-Jin Yoon"],"url":"https://arxiv.org/abs/2502.11986"}
{"created":"2025-04-23","title":"Reinforcement Learning for Dynamic Resource Allocation in Optical Networks: Hype or Hope?","abstract":"The application of reinforcement learning (RL) to dynamic resource allocation in optical networks has been the focus of intense research activity in recent years, with almost 100 peer-reviewed papers. We present a review of progress in the field, and identify significant gaps in benchmarking practices and reproducibility. To determine the strongest benchmark algorithms, we systematically evaluate several heuristics across diverse network topologies. We find that path count and sort criteria for path selection significantly affect the benchmark performance. We meticulously recreate the problems from five landmark papers and apply the improved benchmarks. Our comparisons demonstrate that simple heuristics consistently match or outperform the published RL solutions, often with an order of magnitude lower blocking probability. Furthermore, we present empirical lower bounds on network blocking using a novel defragmentation-based method, revealing that potential improvements over the benchmark heuristics are limited to 19-36% increased traffic load for the same blocking performance in our examples. We make our simulation framework and results publicly available to promote reproducible research and standardized evaluation https://doi.org/10.5281/zenodo.12594495.","authors":["Michael Doherty","Robin Matzner","Rasoul Sadeghi","Polina Bayvel","Alejandra Beghelli"],"url":"https://arxiv.org/abs/2502.12804"}
{"created":"2025-04-23","title":"Evaluating the Robustness of Multimodal Agents Against Active Environmental Injection Attacks","abstract":"As researchers continue to optimize AI agents for more effective task execution within operating systems, they often overlook a critical security concern: the ability of these agents to detect \"impostors\" within their environment. Through an analysis of the agents' operational context, we identify a significant threat-attackers can disguise malicious attacks as environmental elements, injecting active disturbances into the agents' execution processes to manipulate their decision-making. We define this novel threat as the Active Environment Injection Attack (AEIA). Focusing on the interaction mechanisms of the Android OS, we conduct a risk assessment of AEIA and identify two critical security vulnerabilities: (1) Adversarial content injection in multimodal interaction interfaces, where attackers embed adversarial instructions within environmental elements to mislead agent decision-making; and (2) Reasoning gap vulnerabilities in the agent's task execution process, which increase susceptibility to AEIA attacks during reasoning. To evaluate the impact of these vulnerabilities, we propose AEIA-MN, an attack scheme that exploits interaction vulnerabilities in mobile operating systems to assess the robustness of MLLM-based agents. Experimental results show that even advanced MLLMs are highly vulnerable to this attack, achieving a maximum attack success rate of 93% on the AndroidWorld benchmark by combining two vulnerabilities.","authors":["Yurun Chen","Xavier Hu","Keting Yin","Juncheng Li","Shengyu Zhang"],"url":"https://arxiv.org/abs/2502.13053"}
{"created":"2025-04-23","title":"LAMD: Context-driven Android Malware Detection and Classification with LLMs","abstract":"The rapid growth of mobile applications has escalated Android malware threats. Although there are numerous detection methods, they often struggle with evolving attacks, dataset biases, and limited explainability. Large Language Models (LLMs) offer a promising alternative with their zero-shot inference and reasoning capabilities. However, applying LLMs to Android malware detection presents two key challenges: (1)the extensive support code in Android applications, often spanning thousands of classes, exceeds LLMs' context limits and obscures malicious behavior within benign functionality; (2)the structural complexity and interdependencies of Android applications surpass LLMs' sequence-based reasoning, fragmenting code analysis and hindering malicious intent inference. To address these challenges, we propose LAMD, a practical context-driven framework to enable LLM-based Android malware detection. LAMD integrates key context extraction to isolate security-critical code regions and construct program structures, then applies tier-wise code reasoning to analyze application behavior progressively, from low-level instructions to high-level semantics, providing final prediction and explanation. A well-designed factual consistency verification mechanism is equipped to mitigate LLM hallucinations from the first tier. Evaluation in real-world settings demonstrates LAMD's effectiveness over conventional detectors, establishing a feasible basis for LLM-driven malware analysis in dynamic threat landscapes.","authors":["Xingzhi Qian","Xinran Zheng","Yiling He","Shuo Yang","Lorenzo Cavallaro"],"url":"https://arxiv.org/abs/2502.13055"}
{"created":"2025-04-23","title":"Improving Algorithmic Efficiency using Cryptography","abstract":"Cryptographic primitives have been used for various non-cryptographic objectives, such as eliminating or reducing randomness and interaction. We show how to use cryptography to improve the time complexity of solving computational problems. Specifically, we show that under standard cryptographic assumptions, we can design algorithms that are asymptotically faster than existing ones while maintaining correctness. As a concrete demonstration, we construct a distribution of trapdoored matrices with the following properties: (a) computationally bounded adversaries cannot distinguish a random matrix from one drawn from this distribution (under computational hardness assumptions), and (b) given a trapdoor, we can multiply such an $n \\times n$ matrix with any vector in near-linear (in $n$) time. We provide constructions both over finite fields and over the reals. This enables a broad speedup technique: any algorithm relying on a random matrix -- such as those that use various notions of dimensionality reduction -- can replace it with a matrix from our distribution, achieving computational speedups while preserving correctness. Using these trapdoored matrices, we present the first uniform reduction from worst-case to approximate and average-case matrix multiplication with optimal parameters (improving on Hirahara--Shimizu STOC 2025, albeit under computational assumptions), the first worst-case to average-case reductions for matrix inversion, solving a linear system, and computing a determinant, as well as a speedup of inference time in classification models.","authors":["Vinod Vaikuntanathan","Or Zamir"],"url":"https://arxiv.org/abs/2502.13065"}
{"created":"2025-04-23","title":"Debiasing Functions of Private Statistics in Postprocessing","abstract":"Given a differentially private unbiased estimate $\\tilde{q}=q(D) +\\nu$ of a statistic $q(D)$, we wish to obtain unbiased estimates of functions of $q(D)$, such as $1/q(D)$, solely through post-processing of $\\tilde{q}$, with no further access to the confidential dataset $D$. To this end, we adapt the deconvolution method used for unbiased estimation in the statistical literature, deriving unbiased estimators for a broad family of twice-differentiable functions when the privacy-preserving noise $\\nu$ is drawn from the Laplace distribution (Dwork et al., 2006). We further extend this technique to a more general class of functions, deriving approximately optimal estimators that are unbiased for values in a user-specified interval (possibly extending to $\\pm \\infty$). We use these results to derive an unbiased estimator for private means when the size $n$ of the dataset is not publicly known. In a numerical application, we find that a mechanism that uses our estimator to return an unbiased sample size and mean outperforms a mechanism that instead uses the previously known unbiased privacy mechanism for such means (Kamath et al., 2023). We also apply our estimators to develop unbiased transformation mechanisms for per-record differential privacy, a privacy concept in which the privacy guarantee is a public function of a record's value (Seeman et al., 2024). Our mechanisms provide stronger privacy guarantees than those in prior work (Finley et al., 2024) by using Laplace, rather than Gaussian, noise. Finally, using a different approach, we go beyond Laplace noise by deriving unbiased estimators for polynomials under the weak condition that the noise distribution has sufficiently many moments.","authors":["Flavio Calmon","Elbert Du","Cynthia Dwork","Brian Finley","Grigory Franguridi"],"url":"https://arxiv.org/abs/2502.13314"}
{"created":"2025-04-23","title":"Peripheral Teleportation: A Rest Frame Design to Mitigate Cybersickness During Virtual Locomotion","abstract":"Mitigating cybersickness can improve the usability of virtual reality (VR) and increase its adoption. The most widely used technique, dynamic field-of-view (FOV) restriction, mitigates cybersickness by blacking out the peripheral region of the user's FOV. However, this approach reduces the visibility of the virtual environment. We propose peripheral teleportation, a novel technique that creates a rest frame (RF) in the user's peripheral vision using content rendered from the current virtual environment. Specifically, the peripheral region is rendered by a pair of RF cameras whose transforms are updated by the user's physical motion. We apply alternating teleportations during translations, or snap turns during rotations, to the RF cameras to keep them close to the current viewpoint transformation. Consequently, the optical flow generated by RF cameras matches the user's physical motion, creating a stable peripheral view. In a between-subjects study (N = 90), we compared peripheral teleportation with a traditional black FOV restrictor and an unrestricted control condition. The results showed that peripheral teleportation significantly reduced discomfort and enabled participants to stay immersed in the virtual environment for a longer duration of time. Overall, these findings suggest that peripheral teleportation is a promising technique that VR practitioners may consider adding to their cybersickness mitigation toolset.","authors":["Tongyu Nie","Courtney Hutton Pospick","Ville Cantory","Danhua Zhang","Jasmine Joyce DeGuzman","Victoria Interrante","Isayas Berhe Adhanom","Evan Suma Rosenberg"],"url":"https://arxiv.org/abs/2502.15227"}
{"created":"2025-04-23","title":"LLM-Driven Optimization of HTML Structure to Support Screen Reader Navigation","abstract":"Online interactions and e-commerce are commonplace among BLV users. Despite the implementation of web accessibility standards, many e-commerce platforms continue to present challenges to screen reader users, particularly in areas like webpage navigation and information retrieval. We investigate the difficulties encountered by screen reader users during online shopping experiences. We conducted a formative study with BLV users and designed a web browser plugin that uses GenAI to restructure webpage content in real time. Our approach improved the header hierarchy and provided correct labeling for essential information. We evaluated the effectiveness of this solution using an automated accessibility tool and through user interviews. Our results show that the revised webpages generated by our system offer significant improvements over the original webpages regarding screen reader navigation experience. Based on our findings, we discuss its potential usage as both a user and developer tool that can significantly enhance screen reader accessibility of webpages.","authors":["Yaman Yu","Bektur Ryskeldiev","Ayaka Tsutsui","Matthew Gillingham","Yang Wang"],"url":"https://arxiv.org/abs/2502.18701"}
{"created":"2025-04-23","title":"FOReCAst: The Future Outcome Reasoning and Confidence Assessment Benchmark","abstract":"Forecasting is an important task in many domains, such as technology and economics. However existing forecasting benchmarks largely lack comprehensive confidence assessment, focus on limited question types, and often consist of artificial questions that do not align with real-world human forecasting needs. To address these gaps, we introduce FOReCAst (Future Outcome Reasoning and Confidence Assessment), a benchmark that evaluates models' ability to make predictions and their confidence in them. FOReCAst spans diverse forecasting scenarios involving Boolean questions, timeframe prediction, and quantity estimation, enabling a comprehensive evaluation of both prediction accuracy and confidence calibration for real-world applications.","authors":["Zhangdie Yuan","Zifeng Ding","Andreas Vlachos"],"url":"https://arxiv.org/abs/2502.19676"}
{"created":"2025-04-23","title":"Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on Diffusion Models","abstract":"In recent years, Diffusion Models (DMs) have demonstrated significant advances in the field of image generation. However, according to current research, DMs are vulnerable to backdoor attacks, which allow attackers to control the model's output by inputting data containing covert triggers, such as a specific visual patch or phrase. Existing defense strategies are well equipped to thwart such attacks through backdoor detection and trigger inversion because previous attack methods are constrained by limited input spaces and low-dimensional triggers. For example, visual triggers are easily observed by defenders, text-based or attention-based triggers are more susceptible to neural network detection. To explore more possibilities of backdoor attack in DMs, we propose Gungnir, a novel method that enables attackers to activate the backdoor in DMs through style triggers within input images. Our approach proposes using stylistic features as triggers for the first time and implements backdoor attacks successfully in image-to-image tasks by introducing Reconstructing-Adversarial Noise (RAN) and Short-Term Timesteps-Retention (STTR). Our technique generates trigger-embedded images that are perceptually indistinguishable from clean images, thus bypassing both manual inspection and automated detection neural networks. Experiments demonstrate that Gungnir can easily bypass existing defense methods. Among existing DM defense frameworks, our approach achieves a 0 backdoor detection rate (BDR). Our codes are available at https://github.com/paoche11/Gungnir.","authors":["Yu Pan","Bingrong Dai","Jiahao Chen","Lin Wang","Yi Du","Jiao Liu"],"url":"https://arxiv.org/abs/2502.20650"}
{"created":"2025-04-23","title":"Deep RC: A Scalable Data Engineering and Deep Learning Pipeline","abstract":"Significant obstacles exist in scientific domains including genetics, climate modeling, and astronomy due to the management, preprocess, and training on complicated data for deep learning. Even while several large-scale solutions offer distributed execution environments, open-source alternatives that integrate scalable runtime tools, deep learning and data frameworks on high-performance computing platforms remain crucial for accessibility and flexibility. In this paper, we introduce Deep Radical-Cylon(RC), a heterogeneous runtime system that combines data engineering, deep learning frameworks, and workflow engines across several HPC environments, including cloud and supercomputing infrastructures. Deep RC supports heterogeneous systems with accelerators, allows the usage of communication libraries like MPI, GLOO and NCCL across multi-node setups, and facilitates parallel and distributed deep learning pipelines by utilizing Radical Pilot as a task execution framework. By attaining an end-to-end pipeline including preprocessing, model training, and postprocessing with 11 neural forecasting models (PyTorch) and hydrology models (TensorFlow) under identical resource conditions, the system reduces 3.28 and 75.9 seconds, respectively. The design of Deep RC guarantees the smooth integration of scalable data frameworks, such as Cylon, with deep learning processes, exhibiting strong performance on cloud platforms and scientific HPC systems. By offering a flexible, high-performance solution for resource-intensive applications, this method closes the gap between data preprocessing, model training, and postprocessing.","authors":["Arup Kumar Sarker","Aymen Alsaadi","Alexander James Halpern","Prabhath Tangella","Mikhail Titov","Niranda Perera","Mills Staylor","Gregor von Laszewski","Shantenu Jha","Geoffrey Fox"],"url":"https://arxiv.org/abs/2502.20724"}
{"created":"2025-04-23","title":"Learning Actionable World Models for Industrial Process Control","abstract":"To go from (passive) process monitoring to active process control, an effective AI system must learn about the behavior of the complex system from very limited training data, forming an ad-hoc digital twin with respect to process inputs and outputs that captures the consequences of actions on the process's world. We propose a novel methodology based on learning world models that disentangles process parameters in the learned latent representation, allowing for fine-grained control. Representation learning is driven by the latent factors influencing the processes through contrastive learning within a joint embedding predictive architecture. This makes changes in representations predictable from changes in inputs and vice versa, facilitating interpretability of key factors responsible for process variations, paving the way for effective control actions to keep the process within operational bounds. The effectiveness of our method is validated on the example of plastic injection molding, demonstrating practical relevance in proposing specific control actions for a notoriously unstable process.","authors":["Peng Yan","Ahmed Abdulkadir","Gerrit A. Schatte","Giulia Aguzzi","Joonsu Gha","Nikola Pascher","Matthias Rosenthal","Yunlong Gao","Benjamin F. Grewe","Thilo Stadelmann"],"url":"https://arxiv.org/abs/2503.01411"}
{"created":"2025-04-23","title":"Unmasking Implicit Bias: Evaluating Persona-Prompted LLM Responses in Power-Disparate Social Scenarios","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities in simulating human behaviour and social intelligence. However, they risk perpetuating societal biases, especially when demographic information is involved. We introduce a novel framework using cosine distance to measure semantic shifts in responses and an LLM-judged Preference Win Rate (WR) to assess how demographic prompts affect response quality across power-disparate social scenarios. Evaluating five LLMs over 100 diverse social scenarios and nine demographic axes, our findings suggest a \"default persona\" bias toward middle-aged, able-bodied, native-born, Caucasian, atheistic males with centrist views. Moreover, interactions involving specific demographics are associated with lower-quality responses. Lastly, the presence of power disparities increases variability in response semantics and quality across demographic groups, suggesting that implicit biases may be heightened under power-imbalanced conditions. These insights expose the demographic biases inherent in LLMs and offer potential paths toward future bias mitigation efforts in LLMs.","authors":["Bryan Chen Zhengyu Tan","Roy Ka-Wei Lee"],"url":"https://arxiv.org/abs/2503.01532"}
{"created":"2025-04-23","title":"A user-friendly SPARQL query editor powered by lightweight metadata","abstract":"SPARQL query editors often lack intuitive interfaces to aid SPARQL-savvy users to write queries. To address this issue, we propose an easy-to-deploy, triple store-agnostic and open-source query editor that offers three main features: (i) automatic query example rendering, (ii) precise autocomplete based on existing triple patterns including within SERVICE clauses, and (iii) a data-aware schema visualization. It can be easily set up with a custom HTML element. The tool has been successfully tested on various public endpoints, and is deployed online at https://sib-swiss.github.io/sparql-editor with open-source code available at https://github.com/sib-swiss/sparql-editor.","authors":["Vincent Emonet","Ana-Claudia Sima","Tarcisio Mendes de Farias"],"url":"https://arxiv.org/abs/2503.02688"}
{"created":"2025-04-23","title":"A Conceptual Model for Attributions in Event-Centric Knowledge Graphs","abstract":"The use of narratives as a means of fusing information from knowledge graphs (KGs) into a coherent line of argumentation has been the subject of recent investigation. Narratives are especially useful in event-centric knowledge graphs in that they provide a means to connect different real-world events and categorize them by well-known narrations. However, specifically for controversial events, a problem in information fusion arises, namely, multiple viewpoints regarding the validity of certain event aspects, e.g., regarding the role a participant takes in an event, may exist. Expressing those viewpoints in KGs is challenging because disputed information provided by different viewpoints may introduce inconsistencies. Hence, most KGs only feature a single view on the contained information, hampering the effectiveness of narrative information access. This paper is an extension of our original work and introduces attributions, i.e., parameterized predicates that allow for the representation of facts that are only valid in a specific viewpoint. For this, we develop a conceptual model that allows for the representation of viewpoint-dependent information. As an extension, we enhance the model by a conception of viewpoint-compatibility. Based on this, we deepen our original deliberations on the model's effects on information fusion and provide additional grounding in the literature.","authors":["Florian Pl\\\"otzky","Katarina Britz","Wolf-Tilo Balke"],"url":"https://arxiv.org/abs/2503.03563"}
{"created":"2025-04-23","title":"Parallel Corpora for Machine Translation in Low-resource Indic Languages: A Comprehensive Review","abstract":"Parallel corpora play an important role in training machine translation (MT) models, particularly for low-resource languages where high-quality bilingual data is scarce. This review provides a comprehensive overview of available parallel corpora for Indic languages, which span diverse linguistic families, scripts, and regional variations. We categorize these corpora into text-to-text, code-switched, and various categories of multimodal datasets, highlighting their significance in the development of robust multilingual MT systems. Beyond resource enumeration, we critically examine the challenges faced in corpus creation, including linguistic diversity, script variation, data scarcity, and the prevalence of informal textual content.We also discuss and evaluate these corpora in various terms such as alignment quality and domain representativeness. Furthermore, we address open challenges such as data imbalance across Indic languages, the trade-off between quality and quantity, and the impact of noisy, informal, and dialectal data on MT performance. Finally, we outline future directions, including leveraging cross-lingual transfer learning, expanding multilingual datasets, and integrating multimodal resources to enhance translation quality. To the best of our knowledge, this paper presents the first comprehensive review of parallel corpora specifically tailored for low-resource Indic languages in the context of machine translation.","authors":["Rahul Raja","Arpita Vats"],"url":"https://arxiv.org/abs/2503.04797"}
{"created":"2025-04-23","title":"Red Team Diffuser: Exposing Toxic Continuation Vulnerabilities in Vision-Language Models via Reinforcement Learning","abstract":"The growing deployment of large Vision-Language Models (VLMs) exposes critical safety gaps in their alignment mechanisms. While existing jailbreak studies primarily focus on VLMs' susceptibility to harmful instructions, we reveal a fundamental yet overlooked vulnerability: toxic text continuation, where VLMs produce highly toxic completions when prompted with harmful text prefixes paired with semantically adversarial images. To systematically study this threat, we propose Red Team Diffuser (RTD), the first red teaming diffusion model that coordinates adversarial image generation and toxic continuation through reinforcement learning. Our key innovations include dynamic cross-modal attack and stealth-aware optimization. For toxic text prefixes from an LLM safety benchmark, we conduct greedy search to identify optimal image prompts that maximally induce toxic completions. The discovered image prompts then drive RL-based diffusion model fine-tuning, producing semantically aligned adversarial images that boost toxicity rates. Stealth-aware optimization introduces joint adversarial rewards that balance toxicity maximization (via Detoxify classifier) and stealthiness (via BERTScore), circumventing traditional noise-based adversarial patterns. Experimental results demonstrate the effectiveness of RTD, increasing the toxicity rate of LLaVA outputs by 10.69% over text-only baselines on the original attack set and 8.91% on an unseen set, proving generalization capability. Moreover, RTD exhibits strong cross-model transferability, raising the toxicity rate by 5.1% on Gemini and 26.83% on LLaMA. Our findings expose two critical flaws in current VLM alignment: (1) failure to prevent toxic continuation from harmful prefixes, and (2) overlooking cross-modal attack vectors. These results necessitate a paradigm shift toward multimodal red teaming in safety evaluations.","authors":["Ruofan Wang","Xiang Zheng","Xiaosen Wang","Cong Wang","Xingjun Ma"],"url":"https://arxiv.org/abs/2503.06223"}
{"created":"2025-04-23","title":"DRESS: Diffusion Reasoning-based Reward Shaping Scheme For Intelligent Networks","abstract":"Network optimization remains fundamental in wireless communications, with Artificial Intelligence (AI)-based solutions gaining widespread adoption. As Sixth-Generation (6G) communication networks pursue full-scenario coverage, optimization in complex extreme environments presents unprecedented challenges. The dynamic nature of these environments, combined with physical constraints, makes it difficult for AI solutions such as Deep Reinforcement Learning (DRL) to obtain effective reward feedback for the training process. However, many existing DRL-based network optimization studies overlook this challenge through idealized environment settings. Inspired by the powerful capabilities of Generative AI (GenAI), especially diffusion models, in capturing complex latent distributions, we introduce a novel Diffusion Reasoning-based Reward Shaping Scheme (DRESS) to achieve robust network optimization. By conditioning on observed environmental states and executed actions, DRESS leverages diffusion models' multi-step denoising process as a form of deep reasoning, progressively refining latent representations to generate meaningful auxiliary reward signals that capture patterns of network systems. Moreover, DRESS is designed for seamless integration with any DRL framework, allowing DRESS-aided DRL (DRESSed-DRL) to enable stable and efficient DRL training even under extreme network environments. Experimental results demonstrate that DRESSed-DRL achieves about 1.5x times faster convergence than its original version in sparse-reward wireless environments and significant performance improvements in multiple general DRL benchmark environments compared to baseline methods. The code of DRESS is available at https://github.com/NICE-HKU/DRESS.","authors":["Feiran You","Hongyang Du","Xiangwang Hou","Yong Ren","Kaibin Huang"],"url":"https://arxiv.org/abs/2503.07433"}
{"created":"2025-04-23","title":"Not All Edges are Equally Robust: Evaluating the Robustness of Ranking-Based Federated Learning","abstract":"Federated Ranking Learning (FRL) is a state-of-the-art FL framework that stands out for its communication efficiency and resilience to poisoning attacks. It diverges from the traditional FL framework in two ways: 1) it leverages discrete rankings instead of gradient updates, significantly reducing communication costs and limiting the potential space for malicious updates, and 2) it uses majority voting on the server side to establish the global ranking, ensuring that individual updates have minimal influence since each client contributes only a single vote. These features enhance the system's scalability and position FRL as a promising paradigm for FL training.","authors":["Zirui Gong","Yanjun Zhang","Leo Yu Zhang","Zhaoxi Zhang","Yong Xiang","Shirui Pan"],"url":"https://arxiv.org/abs/2503.08976"}
{"created":"2025-04-23","title":"Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks","abstract":"Large language models (LLMs) have shown remarkable advancements in enabling language agents to tackle simple tasks. However, applying them for complex, multi-step, long-horizon tasks remains a challenge. Recent work have found success by separating high-level planning from low-level execution, which enables the model to effectively balance high-level planning objectives and low-level execution details. However, generating accurate plans remains difficult since LLMs are not inherently trained for this task. To address this, we propose Plan-and-Act, a novel framework that incorporates explicit planning into LLM-based agents and introduces a scalable method to enhance plan generation through a novel synthetic data generation method. Plan-and-Act consists of a Planner model which generates structured, high-level plans to achieve user goals, and an Executor model that translates these plans into environment-specific actions. To train the Planner effectively, we introduce a synthetic data generation method that annotates ground-truth trajectories with feasible plans, augmented with diverse and extensive examples to enhance generalization. We evaluate Plan-and-Act using web navigation as a representative long-horizon planning environment, demonstrating a state-of-the-art 57.58% success rate on the WebArena-Lite benchmark as well as a text-only state-of-the-art 81.36% success rate on WebVoyager.","authors":["Lutfi Eren Erdogan","Nicholas Lee","Sehoon Kim","Suhong Moon","Hiroki Furuta","Gopala Anumanchipalli","Kurt Keutzer","Amir Gholami"],"url":"https://arxiv.org/abs/2503.09572"}
{"created":"2025-04-23","title":"Key, Value, Compress: A Systematic Exploration of KV Cache Compression Techniques","abstract":"Large language models (LLMs) have demonstrated exceptional capabilities in generating text, images, and video content. However, as context length grows, the computational cost of attention increases quadratically with the number of tokens, presenting significant efficiency challenges. This paper presents an analysis of various Key-Value (KV) cache compression strategies, offering a comprehensive taxonomy that categorizes these methods by their underlying principles and implementation techniques. Furthermore, we evaluate their impact on performance and inference latency, providing critical insights into their effectiveness. Our findings highlight the trade-offs involved in KV cache compression and its influence on handling long-context scenarios, paving the way for more efficient LLM implementations.","authors":["Neusha Javidnia","Bita Darvish Rouhani","Farinaz Koushanfar"],"url":"https://arxiv.org/abs/2503.11816"}
{"created":"2025-04-23","title":"A Framework for Evaluating Emerging Cyberattack Capabilities of AI","abstract":"As frontier AI models become more capable, evaluating their potential to enable cyberattacks is crucial for ensuring the safe development of Artificial General Intelligence (AGI). Current cyber evaluation efforts are often ad-hoc, lacking systematic analysis of attack phases and guidance on targeted defenses. This work introduces a novel evaluation framework that addresses these limitations by: (1) examining the end-to-end attack chain, (2) identifying gaps in AI threat evaluation, and (3) helping defenders prioritize targeted mitigations and conduct AI-enabled adversary emulation for red teaming. Our approach adapts existing cyberattack chain frameworks for AI systems. We analyzed over 12,000 real-world instances of AI involvement in cyber incidents, catalogued by Google's Threat Intelligence Group, to curate seven representative attack chain archetypes. Through a bottleneck analysis on these archetypes, we pinpointed phases most susceptible to AI-driven disruption. We then identified and utilized externally developed cybersecurity model evaluations focused on these critical phases. We report on AI's potential to amplify offensive capabilities across specific attack stages, and offer recommendations for prioritizing defenses. We believe this represents the most comprehensive AI cyber risk evaluation framework published to date.","authors":["Mikel Rodriguez","Raluca Ada Popa","Four Flynn","Lihao Liang","Allan Dafoe","Anna Wang"],"url":"https://arxiv.org/abs/2503.11917"}
{"created":"2025-04-23","title":"Role-Selection Game in Block Production under Proposer-Builder Separation","abstract":"To address the risks of validator centralization, Proposer-Builder Separation (PBS) was introduced in Ethereum to divide the roles of block building and block proposing, fostering a more equitable and decentralized block production environment. PBS creates a two-sided market in which searchers submit valuable bundles to builders for inclusion in blocks, while builders compete in auctions for block proposals. In this paper, we formulate and analyze a role-selection game that models how profit-seeking participants in PBS strategically choose between acting as searchers or builders, using a co-evolutionary framework to capture the complex interactions and payoff dynamics in this market. Through agent-based simulations, we demonstrate that agents' optimal role-acting as searcher or builder-responds dynamically to the probability of conflict between bundles. Our empirical game-theoretic analysis quantifies the equilibrium frequencies of role selection under different market conditions, revealing that low conflict probabilities lead to equilibria dominated by searchers, while higher probabilities shift equilibrium toward builders. Additionally, bundle conflicts have non-monotonic effects on agent payoffs and strategy evolution. Our results advance the understanding of decentralized block building and provide guidance for designing fairer and more robust block production mechanisms in blockchain systems.","authors":["Yanzhen Li","Zining Wang"],"url":"https://arxiv.org/abs/2503.15184"}
{"created":"2025-04-23","title":"Accelerating Transient CFD through Machine Learning-Based Flow Initialization","abstract":"Transient computational fluid dynamics (CFD) simulations are essential for many industrial applications, but a significant portion of their computational cost stems from the time needed to reach statistical steadiness from initial conditions. We present a novel machine learning-based initialization method that reduces the cost of this subsequent transient solve substantially, achieving a 50% reduction in time-to-convergence compared to traditional uniform and potential flow-based initializations. Through a case study in automotive aerodynamics using a 16.7M-cell unsteady RANS simulation, we evaluate three ML-based initialization strategies. Two of these strategies are recommended for general use: (1) a physics-informed hybrid method combining ML predictions with potential flow solutions, and (2) a more versatile approach integrating ML predictions with uniform flow. Both strategies enable CFD solvers to achieve convergence times comparable to computationally expensive steady RANS initializations, while requiring only seconds of computation. We develop a robust statistical convergence metric based on windowed time-averaging for performance comparison between initialization strategies. Notably, these improvements are achieved using an ML model trained on a different dataset of automotive geometries, demonstrating strong generalization capabilities. The proposed methods integrate seamlessly with existing CFD workflows without requiring modifications to the underlying flow solver, providing a practical approach to accelerating industrial CFD simulations through improved ML-based initialization strategies.","authors":["Peter Sharpe","Rishikesh Ranade","Kaustubh Tangsali","Mohammad Amin Nabian","Ram Cherukuri","Sanjay Choudhry"],"url":"https://arxiv.org/abs/2503.15766"}
{"created":"2025-04-23","title":"Finite Sample Analysis of System Poles for Ho-Kalman Algorithm","abstract":"This paper investigates the error analysis of system pole estimation in $n$-dimensional discrete-time Linear Time-Invariant systems with $m$ outputs and $p$ inputs, using the classical Ho-Kalman algorithm based on finite input-output sample data. Building upon prior work, we establish end-to-end estimation guarantees for system poles under both single-trajectory and multiple-trajectory settings. Specifically, we prove that, with high probability, the estimation error of system poles decreases at a rate of at least $\\mathcal{O}\\{T^{-\\frac{1}{2n}}\\}$ in the single-trajectory case and $\\mathcal{O}\\{N^{-\\frac{1}{2n}}\\}$ in the multiple-trajectory case, where $T$ is the length of a single trajectory, and $N$ is the number of trajectories. Furthermore, we reveal that in both settings, achieving a constant estimation accuracy for system poles requires the sample size to grow super-polynomially with respect to the larger of the two ratios, $ \\max\\{n/m, n/p\\} $. Numerical experiments are conducted to validate the non-asymptotic results of system pole estimation.","authors":["Shuai Sun","Xu Wang"],"url":"https://arxiv.org/abs/2503.16331"}
{"created":"2025-04-23","title":"On-Device Federated Continual Learning on RISC-V-based Ultra-Low-Power SoC for Intelligent Nano-Drone Swarms","abstract":"RISC-V-based architectures are paving the way for efficient On-Device Learning (ODL) in smart edge devices. When applied across multiple nodes, ODL enables the creation of intelligent sensor networks that preserve data privacy. However, developing ODL-capable, battery-operated embedded platforms presents significant challenges due to constrained computational resources and limited device lifetime, besides intrinsic learning issues such as catastrophic forgetting. We face these challenges by proposing a regularization-based On-Device Federated Continual Learning algorithm tailored for multiple nano-drones performing face recognition tasks. We demonstrate our approach on a RISC-V-based 10-core ultra-low-power SoC, optimizing the ODL computational requirements. We improve the classification accuracy by 24% over naive fine-tuning, requiring 178 ms per local epoch and 10.5 s per global epoch, demonstrating the effectiveness of the architecture for this task.","authors":["Lars Kr\\\"oger","Cristian Cioflan","Victor Kartsch","Luca Benini"],"url":"https://arxiv.org/abs/2503.17436"}
{"created":"2025-04-23","title":"Understanding and Mitigating Side and Covert Channel Vulnerabilities Introduced by RowHammer Defenses","abstract":"DRAM chips are vulnerable to read disturbance phenomena (e.g., RowHammer and RowPress), where repeatedly accessing or keeping open a DRAM row causes bitflips in nearby rows. Attackers leverage RowHammer bitflips in real systems to take over systems and leak data. Consequently, many prior works propose mitigations, including recent DDR specifications introducing new mitigations (e.g., PRAC and RFM). For robust operation, it is critical to analyze other security implications of RowHammer mitigations. Unfortunately, no prior work analyzes the timing covert and side channel vulnerabilities introduced by RowHammer mitigations.","authors":["F. Nisa Bostanc{\\i}","O\\u{g}uzhan Canpolat","Ataberk Olgun","\\.Ismail Emir Y\\\"uksel","Konstantinos Kanellopoulos","Mohammad Sadrosadati","A. Giray Ya\\u{g}l{\\i}k\\c{c}{\\i}","Onur Mutlu"],"url":"https://arxiv.org/abs/2503.17891"}
{"created":"2025-04-23","title":"Reimagining Memory Access for LLM Inference: Compression-Aware Memory Controller Design","abstract":"The efficiency of Large Language Model~(LLM) inference is often constrained by substantial memory bandwidth and capacity demands. Existing techniques, such as pruning, quantization, and mixture of experts/depth, reduce memory capacity and/or bandwidth consumption at the cost of slight degradation in inference quality. This paper introduces a design solution that further alleviates memory bottlenecks by enhancing the on-chip memory controller in AI accelerators to achieve two main objectives: (1) significantly reducing memory capacity and bandwidth usage through lossless block compression~(e.g., LZ4 and ZSTD) of model weights and key-value (KV) cache without compromising inference quality, and (2) enabling memory bandwidth and energy consumption to scale proportionally with context-dependent dynamic quantization. These goals are accomplished by equipping the on-chip memory controller with mechanisms to improve fine-grained bit-level accessibility and compressibility of weights and KV cache through LLM-aware configuration of in-memory placement and representation. Experimental results on publicly available LLMs demonstrate the effectiveness of this approach, showing memory footprint reductions of 25.2\\% for model weights and 46.9\\% for KV cache. In addition, our hardware prototype at 4\\,GHz and 32 lanes (7\\,nm) achieves 8\\,TB/s throughput with a modest area overhead (under 3.8\\,mm\\(^2\\)), which underscores the viability of LLM-aware memory control as a key to efficient large-scale inference.","authors":["Rui Xie","Asad Ul Haq","Linsen Ma","Yunhua Fang","Zirak Burzin Engineer","Liu Liu","Tong Zhang"],"url":"https://arxiv.org/abs/2503.18869"}
{"created":"2025-04-23","title":"Harmonia: A Multi-Agent Reinforcement Learning Approach to Data Placement and Migration in Hybrid Storage Systems","abstract":"Hybrid storage systems (HSS) combine multiple storage devices with diverse characteristics to achieve high performance and capacity at low cost. The performance of an HSS highly depends on the effectiveness of two key policies: (1) the data-placement policy, which determines the best-fit storage device for incoming data, and (2) the data-migration policy, which rearranges stored data across the devices to sustain high HSS performance. Prior works focus on improving only data placement or only data migration in HSS, which leads to relatively low HSS performance. Unfortunately, no prior work tries to optimize both policies together. Our goal is to design a holistic data-management technique that optimizes both data-placement and data-migration policies to fully exploit the potential of an HSS, and thus significantly improve system performance. We demonstrate the need for multiple reinforcement learning (RL) agents to accomplish our goal. We propose Harmonia, a multi-agent RL-based data-management technique that employs two lightweight autonomous RL agents, a data-placement agent and a data-migration agent, which adapt their policies for the current workload and HSS configuration, and coordinate with each other to improve overall HSS performance. We evaluate Harmonia on a real HSS with up to four heterogeneous and diverse storage devices. Our evaluation using 17 data-intensive workloads on performance-optimized (cost-optimized) HSS with two storage devices shows that, on average, Harmonia outperforms the best-performing prior approach by 49.5% (31.7%). On an HSS with three (four) devices, Harmonia outperforms the best-performing prior work by 37.0% (42.0%). Harmonia's performance benefits come with low latency (240ns for inference) and storage overheads (206 KiB in DRAM for both RL agents together). We will open-source Harmonia's implementation to aid future research on HSS.","authors":["Rakesh Nadig","Vamanan Arulchelvan","Rahul Bera","Taha Shahroodi","Gagandeep Singh","Andreas Kakolyris","Mohammad Sadrosadati","Jisung Park","Onur Mutlu"],"url":"https://arxiv.org/abs/2503.20507"}
{"created":"2025-04-23","title":"Harmonizing Visual Representations for Unified Multimodal Understanding and Generation","abstract":"Unifying visual understanding and generation within a single multimodal framework remains a significant challenge, as the two inherently heterogeneous tasks require representations at different levels of granularity. Current approaches that utilize vector quantization (VQ) or variational autoencoders (VAE) for unified visual representation prioritize intrinsic imagery features over semantics, compromising understanding performance. In this work, we take inspiration from masked image modelling (MIM) that learns rich semantics via a mask-and-reconstruct pre-training and its successful extension to masked autoregressive (MAR) image generation. A preliminary study on the MAR encoder's representation reveals exceptional linear probing accuracy and precise feature response to visual concepts, which indicates MAR's potential for visual understanding tasks beyond its original generation role. Based on these insights, we present \\emph{Harmon}, a unified autoregressive framework that harmonizes understanding and generation tasks with a shared MAR encoder. Through a three-stage training procedure that progressively optimizes understanding and generation capabilities, Harmon achieves state-of-the-art image generation results on the GenEval, MJHQ30K and WISE benchmarks while matching the performance of methods with dedicated semantic encoders (e.g., Janus) on image understanding benchmarks. Our code and models will be available at https://github.com/wusize/Harmon.","authors":["Size Wu","Wenwei Zhang","Lumin Xu","Sheng Jin","Zhonghua Wu","Qingyi Tao","Wentao Liu","Wei Li","Chen Change Loy"],"url":"https://arxiv.org/abs/2503.21979"}
{"created":"2025-04-23","title":"FUSE : A Ridge and Random Forest-Based Metric for Evaluating MT in Indigenous Languages","abstract":"This paper presents the winning submission of the RaaVa team to the AmericasNLP 2025 Shared Task 3 on Automatic Evaluation Metrics for Machine Translation (MT) into Indigenous Languages of America, where our system ranked first overall based on average Pearson correlation with the human annotations. We introduce Feature-Union Scorer (FUSE) for Evaluation, FUSE integrates Ridge regression and Gradient Boosting to model translation quality. In addition to FUSE, we explore five alternative approaches leveraging different combinations of linguistic similarity features and learning paradigms. FUSE Score highlights the effectiveness of combining lexical, phonetic, semantic, and fuzzy token similarity with learning-based modeling to improve MT evaluation for morphologically rich and low-resource languages. MT into Indigenous languages poses unique challenges due to polysynthesis, complex morphology, and non-standardized orthography. Conventional automatic metrics such as BLEU, TER, and ChrF often fail to capture deeper aspects like semantic adequacy and fluency. Our proposed framework, formerly referred to as FUSE, incorporates multilingual sentence embeddings and phonological encodings to better align with human evaluation. We train supervised models on human-annotated development sets and evaluate held-out test data. Results show that FUSE consistently achieves higher Pearson and Spearman correlations with human judgments, offering a robust and linguistically informed solution for MT evaluation in low-resource settings.","authors":["Rahul Raja","Arpita Vats"],"url":"https://arxiv.org/abs/2504.00021"}
{"created":"2025-04-23","title":"The Polynomial Set Associated with a Fixed Number of Matrix-Matrix Multiplications","abstract":"We consider the problem of computing matrix polynomials $p(X)$, where $X$ is a large dense matrix, with as few matrix-matrix multiplications as possible. More precisely, let $\\Pi_{2^{m}}^*$ represent the set of polynomials computable with $m$ matrix-matrix multiplications, but with an arbitrary number of matrix additions and scaling operations. We characterize this set through a tabular parameterization. By deriving equivalence transformations of the tabular representation, we establish new methods that can be used to construct elements of $\\Pi_{2^{m}}^*$ and determine general properties of the set. The transformations allow us to eliminate variables and prove that the dimension is bounded by $m^2$. Numerical simulations suggest that this is a sharp bound. Consequently, we have identified a parameterization that, to the best of our knowledge, is the first minimal parameterization. We also conduct a study using computational tools from algebraic geometry to determine the largest degree $d$ such that all polynomials of that degree belong to $\\Pi_{2^{m}}^*$, or its closure. In many cases, the computational setup is constructive in the sense that it can also be used to determine a specific evaluation scheme for a given polynomial.","authors":["Elias Jarlebring","Gustaf Lorentzon"],"url":"https://arxiv.org/abs/2504.01500"}
{"created":"2025-04-23","title":"Investigating and Scaling up Code-Switching for Multilingual Language Model Pre-Training","abstract":"Large language models (LLMs) exhibit remarkable multilingual capabilities despite the extreme language imbalance in the pre-training data. In this paper, we closely examine the reasons behind this phenomenon, focusing on the pre-training corpus. We find that the existence of code-switching, alternating between different languages within a context, is key to multilingual capabilities. We conduct an analysis to investigate code-switching in the pre-training corpus, examining its presence and categorizing it into four types within two quadrants. We then assess its impact on multilingual performance. These types of code-switching data are unbalanced in proportions and demonstrate different effects on facilitating language transfer. To better explore the power of code-switching for language alignment during pre-training, we investigate the strategy of synthetic code-switching. We continuously scale up the synthetic code-switching data and observe remarkable improvements in both benchmarks and representation space. Extensive experiments indicate that incorporating synthetic code-switching data enables better language alignment and generalizes well to high, medium, and low-resource languages with pre-training corpora of varying qualities.","authors":["Zhijun Wang","Jiahuan Li","Hao Zhou","Rongxiang Weng","Jingang Wang","Xin Huang","Xue Han","Junlan Feng","Chao Deng","Shujian Huang"],"url":"https://arxiv.org/abs/2504.01801"}
{"created":"2025-04-23","title":"F5R-TTS: Improving Flow-Matching based Text-to-Speech with Group Relative Policy Optimization","abstract":"We present F5R-TTS, a novel text-to-speech (TTS) system that integrates Group Relative Policy Optimization (GRPO) into a flow-matching based architecture. By reformulating the deterministic outputs of flow-matching TTS into probabilistic Gaussian distributions, our approach enables seamless integration of reinforcement learning algorithms. During pretraining, we train a probabilistically reformulated flow-matching based model which is derived from F5-TTS with an open-source dataset. In the subsequent reinforcement learning (RL) phase, we employ a GRPO-driven enhancement stage that leverages dual reward metrics: word error rate (WER) computed via automatic speech recognition and speaker similarity (SIM) assessed by verification models. Experimental results on zero-shot voice cloning demonstrate that F5R-TTS achieves significant improvements in both speech intelligibility (a 29.5% relative reduction in WER) and speaker similarity (a 4.6% relative increase in SIM score) compared to conventional flow-matching based TTS systems. Audio samples are available at https://frontierlabs.github.io/F5R.","authors":["Xiaohui Sun","Ruitong Xiao","Jianye Mo","Bowen Wu","Qun Yu","Baoxun Wang"],"url":"https://arxiv.org/abs/2504.02407"}
{"created":"2025-04-23","title":"SCMPPI: Supervised Contrastive Multimodal Framework for Predicting Protein-Protein Interactions","abstract":"Protein-protein interaction (PPI) prediction plays a pivotal role in deciphering cellular functions and disease mechanisms. To address the limitations of traditional experimental methods and existing computational approaches in cross-modal feature fusion and false-negative suppression, we propose SCMPPI-a novel supervised contrastive multimodal framework. By effectively integrating sequence-based features (AAC, DPC, ESMC-CKSAAP) with network topology (Node2Vec embeddings) and incorporating an enhanced contrastive learning strategy with negative sample filtering, SCMPPI achieves superior prediction performance. Extensive experiments on eight benchmark datasets demonstrate its state-of-the-art accuracy(98.13%) and AUC(99.69%), along with excellent cross-species generalization (AUC>99%). Successful applications in CD9 networks, Wnt pathway analysis, and cancer-specific networks further highlight its potential for disease target discovery, establishing SCMPPI as a powerful tool for multimodal biological data analysis.","authors":["Shengrui XU","Tianchi Lu","Zikun Wang","Jixiu Zhai","Jingwan Wang"],"url":"https://arxiv.org/abs/2504.02698"}
{"created":"2025-04-23","title":"BOP Challenge 2024 on Model-Based and Model-Free 6D Object Pose Estimation","abstract":"We present the evaluation methodology, datasets and results of the BOP Challenge 2024, the 6th in a series of public competitions organized to capture the state of the art in 6D object pose estimation and related tasks. In 2024, our goal was to transition BOP from lab-like setups to real-world scenarios. First, we introduced new model-free tasks, where no 3D object models are available and methods need to onboard objects just from provided reference videos. Second, we defined a new, more practical 6D object detection task where identities of objects visible in a test image are not provided as input. Third, we introduced new BOP-H3 datasets recorded with high-resolution sensors and AR/VR headsets, closely resembling real-world scenarios. BOP-H3 include 3D models and onboarding videos to support both model-based and model-free tasks. Participants competed on seven challenge tracks. Notably, the best 2024 method for model-based 6D localization of unseen objects (FreeZeV2.1) achieves 22% higher accuracy on BOP-Classic-Core than the best 2023 method (GenFlow), and is only 4% behind the best 2023 method for seen objects (GPose2023) although being significantly slower (24.9 vs 2.7s per image). A more practical 2024 method for this task is Co-op which takes only 0.8s per image and is 13% more accurate than GenFlow. Methods have similar rankings on 6D detection as on 6D localization but higher run time. On model-based 2D detection of unseen objects, the best 2024 method (MUSE) achieves 21--29% relative improvement compared to the best 2023 method (CNOS). However, the 2D detection accuracy for unseen objects is still -35% behind the accuracy for seen objects (GDet2023), and the 2D detection stage is consequently the main bottleneck of existing pipelines for 6D localization/detection of unseen objects. The online evaluation system stays open and is available at http://bop.felk.cvut.cz/","authors":["Van Nguyen Nguyen","Stephen Tyree","Andrew Guo","Mederic Fourmy","Anas Gouda","Taeyeop Lee","Sungphill Moon","Hyeontae Son","Lukas Ranftl","Jonathan Tremblay","Eric Brachmann","Bertram Drost","Vincent Lepetit","Carsten Rother","Stan Birchfield","Jiri Matas","Yann Labbe","Martin Sundermeyer","Tomas Hodan"],"url":"https://arxiv.org/abs/2504.02812"}
{"created":"2025-04-23","title":"SAGe: A Lightweight Algorithm-Architecture Co-Design for Mitigating the Data Preparation Bottleneck in Large-Scale Genome Analysis","abstract":"Given the exponentially growing volumes of genomic data, there are extensive efforts to accelerate genome analysis. We demonstrate a major bottleneck that greatly limits and diminishes the benefits of state-of-the-art genome analysis accelerators: the data preparation bottleneck, where genomic data is stored in compressed form and needs to be decompressed and formatted first before an accelerator can operate on it. To mitigate this bottleneck, we propose SAGe, an algorithm-architecture co-design for highly-compressed storage and high-performance access of large-scale genomic data. SAGe overcomes the challenges of mitigating the data preparation bottleneck while maintaining high compression ratios (comparable to genomic-specific compression algorithms) at low hardware cost. This is enabled by leveraging key features of genomic datasets to co-design (i) a new (de)compression algorithm, (ii) hardware, (iii) storage data layout, and (iv) interface commands to access storage. SAGe stores data in structures that can be rapidly interpreted and decompressed by efficient streaming accesses and lightweight hardware. To achieve high compression ratios using only these lightweight structures, SAGe exploits unique features of genomic data. We show that SAGe can be seamlessly integrated with a broad range of genome analysis hardware accelerators to mitigate their data preparation bottlenecks. Our results demonstrate that SAGe improves the average end-to-end performance and energy efficiency of two state-of-the-art genome analysis accelerators by 3.0x-32.1x and 18.8x-49.6x, respectively, compared to when the accelerators rely on state-of-the-art decompression tools.","authors":["Nika Mansouri Ghiasi","Talu G\\\"uloglu","Harun Mustafa","Can Firtina","Konstantina Koliogeorgi","Konstantinos Kanellopoulos","Haiyu Mao","Rakesh Nadig","Mohammad Sadrosadati","Jisung Park","Onur Mutlu"],"url":"https://arxiv.org/abs/2504.03732"}
{"created":"2025-04-23","title":"VocalNet: Speech LLM with Multi-Token Prediction for Faster and High-Quality Generation","abstract":"Speech large language models (LLMs) have emerged as a prominent research focus in speech processing. We introduce VocalNet-1B and VocalNet-8B, a series of high-performance, low-latency speech LLMs enabled by a scalable and model-agnostic training framework designed for real-time voice interaction. Central to our contribution is the first application of multi-token prediction (MTP) to speech LLMs. This approach represents a paradigm shift from standard next-token prediction (NTP), offering simultaneous improvements in generation speed and quality. Informed by analysis of MTP's effect on speech generation and experimental comparisons, we designed a straightforward and highly effective MTP implementation. Experiments demonstrate that VocalNet performs on par with mainstream Omni LLMs even with limited training data, and significantly surpasses existing open-source speech LLMs. To foster reproducibility and community advancement, all model weights, inference code, training data, and framework implementations have been made publicly available at https://github.com/SJTU-OmniAgent/VocalNet","authors":["Yuhao Wang","Heyang Liu","Ziyang Cheng","Ronghua Wu","Qunshan Gu","Yanfeng Wang","Yu Wang"],"url":"https://arxiv.org/abs/2504.04060"}
{"created":"2025-04-23","title":"Tratto: A Neuro-Symbolic Approach to Deriving Axiomatic Test Oracles","abstract":"This paper presents Tratto, a neuro-symbolic approach that generates assertions (boolean expressions) that can serve as axiomatic oracles, from source code and documentation. The symbolic module of Tratto takes advantage of the grammar of the programming language, the unit under test, and the context of the unit (its class and available APIs) to restrict the search space of the tokens that can be successfully used to generate valid oracles. The neural module of Tratto uses transformers fine-tuned for both deciding whether to output an oracle or not and selecting the next lexical token to incrementally build the oracle from the set of tokens returned by the symbolic module. Our experiments show that Tratto outperforms the state-of-the-art axiomatic oracle generation approaches, with 73% accuracy, 72% precision, and 61% F1-score, largely higher than the best results of the symbolic and neural approaches considered in our study (61%, 62%, and 37%, respectively). Tratto can generate three times more axiomatic oracles than current symbolic approaches, while generating 10 times less false positives than GPT4 complemented with few-shot learning and Chain-of-Thought prompting.","authors":["Davide Molinelli","Alberto Martin-Lopez","Elliott Zackrone","Beyza Eken","Michael D. Ernst","Mauro Pezz\\`e"],"url":"https://arxiv.org/abs/2504.04251"}
{"created":"2025-04-23","title":"Splitting Method for Stochastic Navier-Stokes Equations","abstract":"This paper investigates the two-dimensional stochastic steady-state Navier-Stokes(NS) equations with additive random noise. We introduce an innovative splitting method that decomposes the stochastic NS equations into a deterministic NS component and a stochastic equation. We rigorously analyze the proposed splitting method from the perspectives of equivalence, stability, existence and uniqueness of the solution. We also propose a modified splitting scheme, which simplified the stochastic equation by omitting its nonlinear terms. A detailed analysis of the solution properties for this modified approach is provided. Additionally, we discuss the statistical errors with both the original splitting format and the modified scheme. Our theoretical and numerical studies demonstrate that the equivalent splitting scheme exhibits significantly enhanced stability compared to the original stochastic NS equations, enabling more effective handling of nonlinear characteristics. Several numerical experiments were performed to compare the statistical errors of the splitting method and the modified splitting method. Notably, the deterministic NS equation in the splitting method does not require repeated solving, and the stochastic equation in the modified scheme is free of nonlinear terms. These features make the modified splitting method particularly advantageous for large-scale computations, as it significantly improves computational efficiency without compromising accuracy.","authors":["Jie Zhu","Yujun Zhu","Ju Ming","Max D. Gunzburger"],"url":"https://arxiv.org/abs/2504.04360"}
{"created":"2025-04-23","title":"Towards Optimal Heterogeneous Client Sampling in Multi-Model Federated Learning","abstract":"Federated learning (FL) allows edge devices to collaboratively train models without sharing local data. As FL gains popularity, clients may need to train multiple unrelated FL models, but communication constraints limit their ability to train all models simultaneously. While clients could train FL models sequentially, opportunistically having FL clients concurrently train different models -- termed multi-model federated learning (MMFL) -- can reduce the overall training time. Prior work uses simple client-to-model assignments that do not optimize the contribution of each client to each model over the course of its training. Prior work on single-model FL shows that intelligent client selection can greatly accelerate convergence, but na\\\"ive extensions to MMFL can violate heterogeneous resource constraints at both the server and the clients. In this work, we develop a novel convergence analysis of MMFL with arbitrary client sampling methods, theoretically demonstrating the strengths and limitations of previous well-established gradient-based methods. Motivated by this analysis, we propose MMFL-LVR, a loss-based sampling method that minimizes training variance while explicitly respecting communication limits at the server and reducing computational costs at the clients. We extend this to MMFL-StaleVR, which incorporates stale updates for improved efficiency and stability, and MMFL-StaleVRE, a lightweight variant suitable for low-overhead deployment. Experiments show our methods improve average accuracy by up to 19.1% over random sampling, with only a 5.4% gap from the theoretical optimum (full client participation).","authors":["Haoran Zhang","Zejun Gong","Zekai Li","Marie Siew","Carlee Joe-Wong","Rachid El-Azouzi"],"url":"https://arxiv.org/abs/2504.05138"}
{"created":"2025-04-23","title":"Reducing the Communication of Distributed Model Predictive Control: Autoencoders and Formation Control","abstract":"Communication remains a key factor limiting the applicability of distributed model predictive control (DMPC) in realistic settings, despite advances in wireless communication. DMPC schemes can require an overwhelming amount of information exchange between agents as the amount of data depends on the length of the predication horizon, for which some applications require a significant length to formally guarantee nominal asymptotic stability. This work aims to provide an approach to reduce the communication effort of DMPC by reducing the size of the communicated data between agents. Using an autoencoder, the communicated data is reduced by the encoder part of the autoencoder prior to communication and reconstructed by the decoder part upon reception within the distributed optimization algorithm that constitutes the DMPC scheme. The choice of a learning-based reduction method is motivated by structure inherent to the data, which results from the data's connection to solutions of optimal control problems. The approach is implemented and tested at the example of formation control of differential-drive robots, which is challenging for optimization-based control due to the robots' nonholonomic constraints, and which is interesting due to the practical importance of mobile robotics. The applicability of the proposed approach is presented first in form of a simulative analysis showing that the resulting control performance yields a satisfactory accuracy. In particular, the proposed approach outperforms the canonical naive way to reduce communication by reducing the length of the prediction horizon. Moreover, it is shown that numerical experiments conducted on embedded computation hardware, with real distributed computation and wireless communication, work well with the proposed way of reducing communication even in practical scenarios in which full communication fails.","authors":["Torben Schiz","Henrik Ebel"],"url":"https://arxiv.org/abs/2504.05223"}
{"created":"2025-04-23","title":"Optimal Bayesian Affine Estimator and Active Learning for the Wiener Model","abstract":"This paper presents a Bayesian estimation framework for Wiener models, focusing on learning nonlinear output functions under known linear state dynamics. We derive a closed-form optimal affine estimator for the unknown parameters, characterized by the so-called \"dynamic basis statistics\" (DBS). Several features of the proposed estimator are studied, including Bayesian unbiasedness, closed-form posterior statistics, error monotonicity in trajectory length, and consistency condition (also known as persistent excitation). In the special case of Fourier basis functions, we demonstrate that the closed-form description is computationally available, as the Fourier DBS enjoys explicit expressions. Furthermore, we identify an inherent inconsistency in the Fourier bases for single-trajectory measurements, regardless of the input excitation. Leveraging the closed-form estimation error, we develop an active learning algorithm synthesizing input signals to minimize estimation error. Numerical experiments validate the efficacy of our approach, showing significant improvements over traditional regularized least-squares methods.","authors":["Sasan Vakili","Manuel Mazo Jr.","Peyman Mohajerin Esfahani"],"url":"https://arxiv.org/abs/2504.05490"}
{"created":"2025-04-23","title":"To Match or Not to Match: Revisiting Image Matching for Reliable Visual Place Recognition","abstract":"Visual Place Recognition (VPR) is a critical task in computer vision, traditionally enhanced by re-ranking retrieval results with image matching. However, recent advancements in VPR methods have significantly improved performance, challenging the necessity of re-ranking. In this work, we show that modern retrieval systems often reach a point where re-ranking can degrade results, as current VPR datasets are largely saturated. We propose using image matching as a verification step to assess retrieval confidence, demonstrating that inlier counts can reliably predict when re-ranking is beneficial. Our findings shift the paradigm of retrieval pipelines, offering insights for more robust and adaptive VPR systems. The code is available at https://github.com/FarInHeight/To-Match-or-Not-to-Match.","authors":["Davide Sferrazza","Gabriele Berton","Gabriele Trivigno","Carlo Masone"],"url":"https://arxiv.org/abs/2504.06116"}
{"created":"2025-04-23","title":"Computation of shape Taylor expansions","abstract":"Shape derivative is an important analytical tool for studying scattering problems involving perturbations in scatterers. Many applications, including inverse scattering, optimal design, and uncertainty quantification, are based on shape derivatives. However, computing high order shape derivatives is challenging due to the complexity of shape calculus. This work introduces a comprehensive method for computing shape Taylor expansions in two dimensions using recurrence formulas. The approach is developed under sound-soft, sound-hard, impedance, and transmission boundary conditions. Additionally, we apply the shape Taylor expansion to uncertainty quantification in wave scattering, enabling high order moment estimation for the scattered field under random boundary perturbations. Numerical examples are provided to illustrate the effectiveness of the shape Taylor expansion in achieving high order approximations.","authors":["Gang Bao","Jun Lai","Haoran Ma"],"url":"https://arxiv.org/abs/2504.06621"}
{"created":"2025-04-23","title":"Follow-the-Perturbed-Leader Approaches Best-of-Both-Worlds for the m-Set Semi-Bandit Problems","abstract":"We consider a common case of the combinatorial semi-bandit problem, the $m$-set semi-bandit, where the learner exactly selects $m$ arms from the total $d$ arms. In the adversarial setting, the best regret bound, known to be $\\mathcal{O}(\\sqrt{nmd})$ for time horizon $n$, is achieved by the well-known Follow-the-Regularized-Leader (FTRL) policy. However, this requires to explicitly compute the arm-selection probabilities via optimizing problems at each time step and sample according to them. This problem can be avoided by the Follow-the-Perturbed-Leader (FTPL) policy, which simply pulls the $m$ arms that rank among the $m$ smallest (estimated) loss with random perturbation. In this paper, we show that FTPL with a Fr\\'echet perturbation also enjoys the near optimal regret bound $\\mathcal{O}(\\sqrt{nmd\\log(d)})$ in the adversarial setting and approaches best-of-both-world regret bounds, i.e., achieves a logarithmic regret for the stochastic setting.","authors":["Jingxin Zhan","Yuchen Xin","Zhihua Zhang"],"url":"https://arxiv.org/abs/2504.07307"}
{"created":"2025-04-23","title":"Program Skeletons for Automated Program Translation","abstract":"Translating software between programming languages is a challenging task, for which automated techniques have been elusive and hard to scale up to larger programs. A key difficulty in cross-language translation is that one has to re-express the intended behavior of the source program into idiomatic constructs of a different target language. This task needs abstracting away from the source language-specific details, while keeping the overall functionality the same. In this work, we propose a novel and systematic approach for making such translation amenable to automation based on a framework we call program skeletons. A program skeleton retains the high-level structure of the source program by abstracting away and effectively summarizing lower-level concrete code fragments, which can be mechanically translated to the target programming language. A skeleton, by design, permits many different ways of filling in the concrete implementation for fragments, which can work in conjunction with existing data-driven code synthesizers. Most importantly, skeletons can conceptually enable sound decomposition, i.e., if each individual fragment is correctly translated, taken together with the mechanically translated skeleton, the final translated program is deemed to be correct as a whole. We present a prototype system called Skel embodying the idea of skeleton-based translation from Python to JavaScript. Our results show promising scalability compared to prior works. For 9 real-world Python programs, some with more than about 1k lines of code, 95% of their code fragments can be automatically translated, while about 5% require manual effort. All the final translations are correct with respect to whole-program test suites.","authors":["Bo Wang","Tianyu Li","Ruishi Li","Umang Mathur","Prateek Saxena"],"url":"https://arxiv.org/abs/2504.07483"}
{"created":"2025-04-23","title":"Localization Meets Uncertainty: Uncertainty-Aware Multi-Modal Localization","abstract":"Reliable localization is critical for robot navigation in complex indoor environments. In this paper, we propose an uncertainty-aware localization method that enhances the reliability of localization outputs without modifying the prediction model itself. This study introduces a percentile-based rejection strategy that filters out unreliable 3-DoF pose predictions based on aleatoric and epistemic uncertainties the network estimates. We apply this approach to a multi-modal end-to-end localization that fuses RGB images and 2D LiDAR data, and we evaluate it across three real-world datasets collected using a commercialized serving robot. Experimental results show that applying stricter uncertainty thresholds consistently improves pose accuracy. Specifically, the mean position error is reduced by 41.0%, 56.7%, and 69.4%, and the mean orientation error by 55.6%, 65.7%, and 73.3%, when applying 90%, 80%, and 70% thresholds, respectively. Furthermore, the rejection strategy effectively removes extreme outliers, resulting in better alignment with ground truth trajectories. To the best of our knowledge, this is the first study to quantitatively demonstrate the benefits of percentile-based uncertainty rejection in multi-modal end-to-end localization tasks. Our approach provides a practical means to enhance the reliability and accuracy of localization systems in real-world deployments.","authors":["Hye-Min Won","Jieun Lee","Jiyong Oh"],"url":"https://arxiv.org/abs/2504.07677"}
{"created":"2025-04-23","title":"PIDSR: Complementary Polarized Image Demosaicing and Super-Resolution","abstract":"Polarization cameras can capture multiple polarized images with different polarizer angles in a single shot, bringing convenience to polarization-based downstream tasks. However, their direct outputs are color-polarization filter array (CPFA) raw images, requiring demosaicing to reconstruct full-resolution, full-color polarized images; unfortunately, this necessary step introduces artifacts that make polarization-related parameters such as the degree of polarization (DoP) and angle of polarization (AoP) prone to error. Besides, limited by the hardware design, the resolution of a polarization camera is often much lower than that of a conventional RGB camera. Existing polarized image demosaicing (PID) methods are limited in that they cannot enhance resolution, while polarized image super-resolution (PISR) methods, though designed to obtain high-resolution (HR) polarized images from the demosaicing results, tend to retain or even amplify errors in the DoP and AoP introduced by demosaicing artifacts. In this paper, we propose PIDSR, a joint framework that performs complementary Polarized Image Demosaicing and Super-Resolution, showing the ability to robustly obtain high-quality HR polarized images with more accurate DoP and AoP from a CPFA raw image in a direct manner. Experiments show our PIDSR not only achieves state-of-the-art performance on both synthetic and real data, but also facilitates downstream tasks.","authors":["Shuangfan Zhou","Chu Zhou","Youwei Lyu","Heng Guo","Zhanyu Ma","Boxin Shi","Imari Sato"],"url":"https://arxiv.org/abs/2504.07758"}
{"created":"2025-04-23","title":"Regional Tiny Stories: Using Small Models to Compare Language Learning and Tokenizer Performance","abstract":"Small Language Models (SLMs) offer efficient alternatives to LLMs for specific domains. The 2023 TinyStories study developed an English dataset that allows SLMs with 1 to 10 million parameters to produce coherent outputs. Our research expands this framework by translating the original dataset into Indian languages and creating synthetic data using LLMs. We focus on Hindi, Marathi, and Bengali, evaluating SLMs for regional language processing and understanding linguistic complexity. We show that SLMs efficiently process regional languages with significantly fewer parameters than LLMs, providing a complementary framework for ``inference based evaluation\" of tokenization strategies and linguistic complexity. Our analysis shows that language-specific tokenizers outperform general-purpose ones for Indian languages. Empirical validations, supported by information-theoretic and morphological analyses, provides fundamental understanding behind the better performance of Hindi models over Marathi and Bengali. Additionally, we show that synthetic datasets outperform translated content for training SLMs. Correlation analyses reveal cross-linguistic patterns and language-specific relationships between creativity, grammatical precision, and narrative completeness. These findings advance both the practical application of SLMs to underserved languages and our theoretical understanding of neural language development.","authors":["Nirvan Patil","Malhar Abhay Inamdar","Agnivo Gosai","Guruprasad Pathak","Anish Joshi","Aryan Sagavekar","Anish Joshirao","Raj Dandekar","Rajat Dandekar","Sreedath Panat"],"url":"https://arxiv.org/abs/2504.07989"}
{"created":"2025-04-23","title":"Location-Oriented Sound Event Localization and Detection with Spatial Mapping and Regression Localization","abstract":"Sound Event Localization and Detection (SELD) combines the Sound Event Detection (SED) with the corresponding Direction Of Arrival (DOA). Recently, adopted event oriented multi-track methods affect the generality in polyphonic environments due to the limitation of the number of tracks. To enhance the generality in polyphonic environments, we propose Spatial Mapping and Regression Localization for SELD (SMRL-SELD). SMRL-SELD segments the 3D spatial space, mapping it to a 2D plane, and a new regression localization loss is proposed to help the results converge toward the location of the corresponding event. SMRL-SELD is location-oriented, allowing the model to learn event features based on orientation. Thus, the method enables the model to process polyphonic sounds regardless of the number of overlapping events. We conducted experiments on STARSS23 and STARSS22 datasets and our proposed SMRL-SELD outperforms the existing SELD methods in overall evaluation and polyphony environments.","authors":["Xueping Zhang","Yaxiong Chen","Ruilin Yao","Yunfei Zi","Shengwu Xiong"],"url":"https://arxiv.org/abs/2504.08365"}
{"created":"2025-04-23","title":"RouterKT: Mixture-of-Experts for Knowledge Tracing","abstract":"Knowledge Tracing (KT) is a fundamental task in Intelligent Tutoring Systems (ITS), which aims to model the dynamic knowledge states of students based on their interaction histories. However, existing KT models often rely on a global forgetting decay mechanism for capturing learning patterns, assuming that students' performance is predominantly influenced by their most recent interactions. Such approaches fail to account for the diverse and complex learning patterns arising from individual differences and varying learning stages. To address this limitation, we propose RouterKT, a novel Mixture-of-Experts (MoE) architecture designed to capture heterogeneous learning patterns by enabling experts to specialize in different patterns without any handcrafted learning pattern bias such as forgetting decay. Specifically, RouterKT introduces a \\textbf{person-wise routing mechanism} to effectively model individual-specific learning behaviors and employs \\textbf{multi-heads as experts} to enhance the modeling of complex and diverse patterns. Comprehensive experiments on ten benchmark datasets demonstrate that RouterKT exhibits significant flexibility and improves the performance of various KT backbone models, with a maximum average AUC improvement of 3.29\\% across different backbones and datasets, outperforming other state-of-the-art models. Moreover, RouterKT demonstrates consistently superior inference efficiency compared to existing approaches based on handcrafted learning pattern bias, highlighting its usability for real-world educational applications. The source code is available at https://github.com/ringotc/RouterKT.git.","authors":["Han Liao","Shuaishuai Zu"],"url":"https://arxiv.org/abs/2504.08989"}
{"created":"2025-04-23","title":"Universal Rate-Distortion-Classification Representations for Lossy Compression","abstract":"In lossy compression, Wang et al. [1] recently introduced the rate-distortion-perception-classification function, which supports multi-task learning by jointly optimizing perceptual quality, classification accuracy, and reconstruction fidelity. Building on the concept of a universal encoder introduced in [2], we investigate the universal representations that enable a broad range of distortion-classification tradeoffs through a single shared encoder coupled with multiple task-specific decoders. We establish, through both theoretical analysis and numerical experiments, that for Gaussian source under mean squared error (MSE) distortion, the entire distortion-classification tradeoff region can be achieved using a single universal encoder. For general sources, we characterize the achievable region and identify conditions under which encoder reuse results in negligible distortion penalty. The experimental result on the MNIST dataset further supports our theoretical findings. We show that universal encoders can obtain distortion performance comparable to task-specific encoders. These results demonstrate the practicality and effectiveness of the proposed universal framework in multi-task compression scenarios.","authors":["Nam Nguyen","Thuan Nguyen","Thinh Nguyen","Bella Bose"],"url":"https://arxiv.org/abs/2504.09025"}
{"created":"2025-04-23","title":"Towards More Efficient, Robust, Instance-adaptive, and Generalizable Online Learning","abstract":"The primary goal of my Ph.D. study is to develop provably efficient and practical algorithms for data-driven online sequential decision-making under uncertainty. My work focuses on reinforcement learning (RL), multi-armed bandits, and their applications, including recommendation systems, computer networks, video analytics, and large language models (LLMs). Online learning methods, such as bandits and RL, have demonstrated remarkable success - ranging from outperforming human players in complex games like Atari and Go to advancing robotics, recommendation systems, and fine-tuning LLMs. Despite these successes, many established algorithms rely on idealized models that can fail under model misspecifications or adversarial perturbations, particularly in settings where accurate prior knowledge of the underlying model class is unavailable or where malicious users operate within dynamic systems. These challenges are pervasive in real-world applications, where robust and adaptive solutions are critical. Furthermore, while worst-case guarantees provide theoretical reliability, they often fail to capture instance-dependent performance, which can lead to more efficient and practical solutions. Another key challenge lies in generalizing to new, unseen environments, a crucial requirement for deploying these methods in dynamic and unpredictable settings. To address these limitations, my research aims to develop more efficient, robust, instance-adaptive, and generalizable online learning algorithms for both reinforcement learning and bandits. Towards this end, I focus on developing more efficient, robust, instance-adaptive, and generalizable for both general reinforcement learning (RL) and bandits.","authors":["Zhiyong Wang"],"url":"https://arxiv.org/abs/2504.09192"}
{"created":"2025-04-23","title":"Bayesian Cross-Modal Alignment Learning for Few-Shot Out-of-Distribution Generalization","abstract":"Recent advances in large pre-trained models showed promising results in few-shot learning. However, their generalization ability on two-dimensional Out-of-Distribution (OoD) data, i.e., correlation shift and diversity shift, has not been thoroughly investigated. Researches have shown that even with a significant amount of training data, few methods can achieve better performance than the standard empirical risk minimization method (ERM) in OoD generalization. This few-shot OoD generalization dilemma emerges as a challenging direction in deep neural network generalization research, where the performance suffers from overfitting on few-shot examples and OoD generalization errors. In this paper, leveraging a broader supervision source, we explore a novel Bayesian cross-modal image-text alignment learning method (Bayes-CAL) to address this issue. Specifically, the model is designed as only text representations are fine-tuned via a Bayesian modelling approach with gradient orthogonalization loss and invariant risk minimization (IRM) loss. The Bayesian approach is essentially introduced to avoid overfitting the base classes observed during training and improve generalization to broader unseen classes. The dedicated loss is introduced to achieve better image-text alignment by disentangling the causal and non-casual parts of image features. Numerical experiments demonstrate that Bayes-CAL achieved state-of-the-art OoD generalization performances on two-dimensional distribution shifts. Moreover, compared with CLIP-like models, Bayes-CAL yields more stable generalization performances on unseen classes. Our code is available at https://github.com/LinLLLL/BayesCAL.","authors":["Lin Zhu","Xinbing Wang","Chenghu Zhou","Nanyang Ye"],"url":"https://arxiv.org/abs/2504.09448"}
{"created":"2025-04-23","title":"AgentA/B: Automated and Scalable Web A/BTesting with Interactive LLM Agents","abstract":"A/B testing experiment is a widely adopted method for evaluating UI/UX design decisions in modern web applications. Yet, traditional A/B testing remains constrained by its dependence on the large-scale and live traffic of human participants, and the long time of waiting for the testing result. Through formative interviews with six experienced industry practitioners, we identified critical bottlenecks in current A/B testing workflows. In response, we present AgentA/B, a novel system that leverages Large Language Model-based autonomous agents (LLM Agents) to automatically simulate user interaction behaviors with real webpages. AgentA/B enables scalable deployment of LLM agents with diverse personas, each capable of navigating the dynamic webpage and interactively executing multi-step interactions like search, clicking, filtering, and purchasing. In a demonstrative controlled experiment, we employ AgentA/B to simulate a between-subject A/B testing with 1,000 LLM agents Amazon.com, and compare agent behaviors with real human shopping behaviors at a scale. Our findings suggest AgentA/B can emulate human-like behavior patterns.","authors":["Dakuo Wang","Ting-Yao Hsu","Yuxuan Lu","Hansu Gu","Limeng Cui","Yaochen Xie","William Headean","Bingsheng Yao","Akash Veeragouni","Jiapeng Liu","Sreyashi Nag","Jessie Wang"],"url":"https://arxiv.org/abs/2504.09723"}
{"created":"2025-04-23","title":"See or Recall: A Sanity Check for the Role of Vision in Solving Visualization Question Answer Tasks with Multimodal LLMs","abstract":"Recent developments in multimodal large language models (MLLM) have equipped language models to reason about vision and language jointly. This permits MLLMs to both perceive and answer questions about data visualization across a variety of designs and tasks. Applying MLLMs to a broad range of visualization tasks requires us to properly evaluate their capabilities, and the most common way to conduct evaluation is through measuring a model's visualization reasoning capability, analogous to how we would evaluate human understanding of visualizations (e.g., visualization literacy). However, we found that in the context of visualization question answering (VisQA), how an MLLM perceives and reasons about visualizations can be fundamentally different from how humans approach the same problem. During the evaluation, even without visualization, the model could correctly answer a substantial portion of the visualization test questions, regardless of whether any selection options were provided. We hypothesize that the vast amount of knowledge encoded in the language model permits factual recall that supersedes the need to seek information from the visual signal. It raises concerns that the current VisQA evaluation may not fully capture the models' visualization reasoning capabilities. To address this, we propose a comprehensive sanity check framework that integrates a rule-based decision tree and a sanity check table to disentangle the effects of \"seeing\" (visual processing) and \"recall\" (reliance on prior knowledge). This validates VisQA datasets for evaluation, highlighting where models are truly \"seeing\", positively or negatively affected by the factual recall, or relying on inductive biases for question answering. Our study underscores the need for careful consideration in designing future visualization understanding studies when utilizing MLLMs.","authors":["Zhimin Li","Haichao Miao","Xinyuan Yan","Valerio Pascucci","Matthew Berger","Shusen Liu"],"url":"https://arxiv.org/abs/2504.09809"}
{"created":"2025-04-23","title":"Labeling Messages as AI-Generated Does Not Reduce Their Persuasive Effects","abstract":"As generative artificial intelligence (AI) enables the creation and dissemination of information at massive scale and speed, it is increasingly important to understand how people perceive AI-generated content. One prominent policy proposal requires explicitly labeling AI-generated content to increase transparency and encourage critical thinking about the information, but prior research has not yet tested the effects of such labels. To address this gap, we conducted a survey experiment (N=1601) on a diverse sample of Americans, presenting participants with an AI-generated message about several public policies (e.g., allowing colleges to pay student-athletes), randomly assigning whether participants were told the message was generated by (a) an expert AI model, (b) a human policy expert, or (c) no label. We found that messages were generally persuasive, influencing participants' views of the policies by 9.74 percentage points on average. However, while 94.6% of participants assigned to the AI and human label conditions believed the authorship labels, labels had no significant effects on participants' attitude change toward the policies, judgments of message accuracy, nor intentions to share the message with others. These patterns were robust across a variety of participant characteristics, including prior knowledge of the policy, prior experience with AI, political party, education level, or age. Taken together, these results imply that, while authorship labels would likely enhance transparency, they are unlikely to substantially affect the persuasiveness of the labeled content, highlighting the need for alternative strategies to address challenges posed by AI-generated information.","authors":["Isabel O. Gallegos","Chen Shani","Weiyan Shi","Federico Bianchi","Izzy Gainsburg","Dan Jurafsky","Robb Willer"],"url":"https://arxiv.org/abs/2504.09865"}
{"created":"2025-04-23","title":"Code size constraints in b-symbol read channels: A bound analysis","abstract":"In classical coding theory, error-correcting codes are designed to protect against errors occurring at individual symbol positions in a codeword. However, in practical storage and communication systems, errors often affect multiple adjacent symbols rather than single symbols independently. To address this, symbol-pair read channels were introduced \\cite{Yuval2011}, and later generalized to $b$-symbol read channels \\cite{yaakobi2016} to better model such error patterns. $b$-Symbol read channels generalize symbol-pair read channels to account for clustered errors in modern storage and communication systems. By developing bounds and efficient codes, researchers improve data reliability in applications such as storage devices, wireless networks, and DNA-based storage. Given integers $q$, $n$, $d$, and $b \\geq 2$, let $A_b(n,d,q)$ denote the largest possible code size for which there exists a $q$-ary code of length $n$ with minimum $b$-symbol distance at least $d$. In \\cite{chen2022}, various upper and lower bounds on $A_b(n,d,q)$ are given for $b=2$. In this paper, we generalize some of these bounds to the $b$-symbol read channels for $b>2$ and present several new bounds on $A_b(n,d,q)$. In particular, we establish the linear programming bound, a recurrence relation on $A_b(n,d,q)$, the Johnson bound (even), the restricted Johnson bound, the Gilbert-Varshamov-type bound, and the Elias bound for the metric of symbols $b$, $b\\geq 2$. Furthermore, we provide examples demonstrating that the Gilbert-Varshamov bound we establish offers a stronger lower bound than the one presented in \\cite{Song2018}. Additionally, we introduce an alternative approach to deriving the Sphere-packing and Plotkin bounds.","authors":["Gyanendra K. Verma","Nupur Patanker","Abhay Kumar Singh"],"url":"https://arxiv.org/abs/2504.10088"}
{"created":"2025-04-23","title":"HistLLM: A Unified Framework for LLM-Based Multimodal Recommendation with User History Encoding and Compression","abstract":"While large language models (LLMs) have proven effective in leveraging textual data for recommendations, their application to multimodal recommendation tasks remains relatively underexplored. Although LLMs can process multimodal information through projection functions that map visual features into their semantic space, recommendation tasks often require representing users' history interactions through lengthy prompts combining text and visual elements, which not only hampers training and inference efficiency but also makes it difficult for the model to accurately capture user preferences from complex and extended prompts, leading to reduced recommendation performance. To address this challenge, we introduce HistLLM, an innovative multimodal recommendation framework that integrates textual and visual features through a User History Encoding Module (UHEM), compressing multimodal user history interactions into a single token representation, effectively facilitating LLMs in processing user preferences. Extensive experiments demonstrate the effectiveness and efficiency of our proposed mechanism.","authors":["Chen Zhang","Bo Hu","Weidong Chen","Zhendong Mao"],"url":"https://arxiv.org/abs/2504.10150"}
{"created":"2025-04-23","title":"Can LLMs Generate Tabular Summaries of Science Papers? Rethinking the Evaluation Protocol","abstract":"Literature review tables are essential for summarizing and comparing collections of scientific papers. We explore the task of generating tables that best fulfill a user's informational needs given a collection of scientific papers. Building on recent work (Newman et al., 2024), we extend prior approaches to address real-world complexities through a combination of LLM-based methods and human annotations. Our contributions focus on three key challenges encountered in real-world use: (i) User prompts are often under-specified; (ii) Retrieved candidate papers frequently contain irrelevant content; and (iii) Task evaluation should move beyond shallow text similarity techniques and instead assess the utility of inferred tables for information-seeking tasks (e.g., comparing papers). To support reproducible evaluation, we introduce ARXIV2TABLE, a more realistic and challenging benchmark for this task, along with a novel approach to improve literature review table generation in real-world scenarios. Our extensive experiments on this benchmark show that both open-weight and proprietary LLMs struggle with the task, highlighting its difficulty and the need for further advancements. Our dataset and code are available at https://github.com/JHU-CLSP/arXiv2Table.","authors":["Weiqi Wang","Jiefu Ou","Yangqiu Song","Benjamin Van Durme","Daniel Khashabi"],"url":"https://arxiv.org/abs/2504.10284"}
{"created":"2025-04-23","title":"Enhancing Features in Long-tailed Data Using Large Vision Model","abstract":"Language-based foundation models, such as large language models (LLMs) or large vision-language models (LVLMs), have been widely studied in long-tailed recognition. However, the need for linguistic data is not applicable to all practical tasks. In this study, we aim to explore using large vision models (LVMs) or visual foundation models (VFMs) to enhance long-tailed data features without any language information. Specifically, we extract features from the LVM and fuse them with features in the baseline network's map and latent space to obtain the augmented features. Moreover, we design several prototype-based losses in the latent space to further exploit the potential of the augmented features. In the experimental section, we validate our approach on two benchmark datasets: ImageNet-LT and iNaturalist2018.","authors":["Pengxiao Han","Changkun Ye","Jinguang Tong","Cuicui Jiang","Jie Hong","Li Fang","Xuesong Li"],"url":"https://arxiv.org/abs/2504.10852"}
{"created":"2025-04-23","title":"LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI Agent Ecosystems","abstract":"The rise of autonomous AI agents, capable of perceiving, reasoning, and acting independently, signals a profound shift in how digital ecosystems operate, govern, and evolve. As these agents proliferate beyond centralized infrastructures, they expose foundational gaps in identity, accountability, and ethical alignment. Three critical questions emerge: Identity: Who or what is the agent? Accountability: Can its actions be verified, audited, and trusted? Ethical Consensus: Can autonomous systems reliably align with human values and prevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered Orchestration for Knowledgeful Agents), a unified, systems-level architecture for building ethically governed, interoperable AI agent ecosystems. LOKA introduces a proposed Universal Agent Identity Layer (UAIL) for decentralized, verifiable identity; intent-centric communication protocols for semantic coordination across diverse agents; and a Decentralized Ethical Consensus Protocol (DECP) that could enable agents to make context-aware decisions grounded in shared ethical baselines. Anchored in emerging standards such as Decentralized Identifiers (DIDs), Verifiable Credentials (VCs), and post-quantum cryptography, LOKA proposes a scalable, future-resilient blueprint for multi-agent AI governance. By embedding identity, trust, and ethics into the protocol layer itself, LOKA proposes the foundation for a new era of responsible, transparent, and autonomous AI ecosystems operating across digital and physical domains.","authors":["Rajesh Ranjan","Shailja Gupta","Surya Narayan Singh"],"url":"https://arxiv.org/abs/2504.10915"}
{"created":"2025-04-23","title":"AFiRe: Anatomy-Driven Self-Supervised Learning for Fine-Grained Representation in Radiographic Images","abstract":"Current self-supervised methods, such as contrastive learning, predominantly focus on global discrimination, neglecting the critical fine-grained anatomical details required for accurate radiographic analysis. To address this challenge, we propose an Anatomy-driven self-supervised framework for enhancing Fine-grained Representation in radiographic image analysis (AFiRe). The core idea of AFiRe is to align the anatomical consistency with the unique token-processing characteristics of Vision Transformer. Specifically, AFiRe synergistically performs two self-supervised schemes: (i) Token-wise anatomy-guided contrastive learning, which aligns image tokens based on structural and categorical consistency, thereby enhancing fine-grained spatial-anatomical discrimination; (ii) Pixel-level anomaly-removal restoration, which particularly focuses on local anomalies, thereby refining the learned discrimination with detailed geometrical information. Additionally, we propose Synthetic Lesion Mask to enhance anatomical diversity while preserving intra-consistency, which is typically corrupted by traditional data augmentations, such as Cropping and Affine transformations. Experimental results show that AFiRe: (i) provides robust anatomical discrimination, achieving more cohesive feature clusters compared to state-of-the-art contrastive learning methods; (ii) demonstrates superior generalization, surpassing 7 radiography-specific self-supervised methods in multi-label classification tasks with limited labeling; and (iii) integrates fine-grained information, enabling precise anomaly detection using only image-level annotations.","authors":["Yihang Liu","Lianghua He","Ying Wen","Longzhen Yang","Hongzhou Chen"],"url":"https://arxiv.org/abs/2504.10972"}
{"created":"2025-04-23","title":"Maximum bound principle for Q-tensor gradient flow with low regularity integrators","abstract":"We investigate low-regularity integrator (LRI) methods for the Q-tensor model governing nematic liquid-crystalline semilinear parabolic equation. First- and second-order temporal discretizations are developed using Duhamel's formula, and we rigorously prove that both schemes preserve the maximum bound principle (MBP) and energy dissipation under minimal regularity requirements. Optimal convergence rates are established for the proposed methods. Numerical experiments validate the theoretical findings, demonstrating that the eigenvalues of Q remain strictly confined within the physical range (-1/3},2/3).","authors":["Wenshuai Hu","Guanghua Ji"],"url":"https://arxiv.org/abs/2504.11676"}
{"created":"2025-04-23","title":"A Graph-Based Reinforcement Learning Approach with Frontier Potential Based Reward for Safe Cluttered Environment Exploration","abstract":"Autonomous exploration of cluttered environments requires efficient exploration strategies that guarantee safety against potential collisions with unknown random obstacles. This paper presents a novel approach combining a graph neural network-based exploration greedy policy with a safety shield to ensure safe navigation goal selection. The network is trained using reinforcement learning and the proximal policy optimization algorithm to maximize exploration efficiency while reducing the safety shield interventions. However, if the policy selects an infeasible action, the safety shield intervenes to choose the best feasible alternative, ensuring system consistency. Moreover, this paper proposes a reward function that includes a potential field based on the agent's proximity to unexplored regions and the expected information gain from reaching them. Overall, the approach investigated in this paper merges the benefits of the adaptability of reinforcement learning-driven exploration policies and the guarantee ensured by explicit safety mechanisms. Extensive evaluations in simulated environments demonstrate that the approach enables efficient and safe exploration in cluttered environments.","authors":["Gabriele Calzolari (Lule{\\aa} University of Technology)","Vidya Sumathy (Lule{\\aa} University of Technology)","Christoforos Kanellakis (Lule{\\aa} University of Technology)","George Nikolakopoulos (Lule{\\aa} University of Technology)"],"url":"https://arxiv.org/abs/2504.11907"}
{"created":"2025-04-23","title":"Technological Complexity Based on Japanese Patent Data","abstract":"As international competition intensifies in technologies, nations need to identify key technologies to foster innovation. However, the identification is difficult because a technology is independent, therefore has complex nature. Here, this study aims to assess patent technological fields by applying Technological Complexity Index from a corporate perspective, addressing its underutilization in Japan despite its potential. By utilizing carefully processed patent data from fiscal years 1981 to 2010, we analyze the bipartite network which consists of 1,938 corporations and 35 or 124 technological fields. Our findings provide quantitative characteristics of ubiquity and sophistication for patent fields, the detailed technological trends that reflect the social context, and methodological stability for policymakers and researchers, contributing to targeted innovation strategies in Japan.","authors":["Rintaro Karashima","Hiroyasu Inoue"],"url":"https://arxiv.org/abs/2504.11932"}
{"created":"2025-04-23","title":"LLM-as-a-Judge: Reassessing the Performance of LLMs in Extractive QA","abstract":"Extractive reading comprehension question answering (QA) datasets are typically evaluated using Exact Match (EM) and F1-score, but these metrics often fail to fully capture model performance. With the success of large language models (LLMs), they have been employed in various tasks, including serving as judges (LLM-as-a-judge). In this paper, we reassess the performance of QA models using LLM-as-a-judge across four reading comprehension QA datasets. We examine different families of LLMs and various answer types to evaluate the effectiveness of LLM-as-a-judge in these tasks. Our results show that LLM-as-a-judge is highly correlated with human judgments and can replace traditional EM/F1 metrics. By using LLM-as-a-judge, the correlation with human judgments improves significantly, from 0.22 (EM) and 0.40 (F1-score) to 0.85. These findings confirm that EM and F1 metrics underestimate the true performance of the QA models. While LLM-as-a-judge is not perfect for more difficult answer types (e.g., job), it still outperforms EM/F1, and we observe no bias issues, such as self-preference, when the same model is used for both the QA and judgment tasks.","authors":["Xanh Ho","Jiahao Huang","Florian Boudin","Akiko Aizawa"],"url":"https://arxiv.org/abs/2504.11972"}
{"created":"2025-04-23","title":"Static to Dynamic Correlation Clustering","abstract":"Correlation clustering is a well-studied problem, first proposed by Bansal, Blum, and Chawla [BBC04]. The input is an unweighted, undirected graph. The problem is to cluster the vertices so as to minimizing the number of edges between vertices in different clusters and missing edges between vertices inside the same cluster. This problem has a wide application in data mining and machine learning. We introduce a general framework that transforms existing static correlation clustering algorithms into fully-dynamic ones that work against an adaptive adversary.","authors":["Nairen Cao","Vincent Cohen-Addad","Euiwoong Lee","Shi Li","David Rasmussen Lolck","Alantha Newman","Mikkel Thorup","Lukas Vogl","Shuyi Yan","Hanwen Zhang"],"url":"https://arxiv.org/abs/2504.12060"}
{"created":"2025-04-23","title":"FocusedAD: Character-centric Movie Audio Description","abstract":"Movie Audio Description (AD) aims to narrate visual content during dialogue-free segments, particularly benefiting blind and visually impaired (BVI) audiences. Compared with general video captioning, AD demands plot-relevant narration with explicit character name references, posing unique challenges in movie understanding.To identify active main characters and focus on storyline-relevant regions, we propose FocusedAD, a novel framework that delivers character-centric movie audio descriptions. It includes: (i) a Character Perception Module(CPM) for tracking character regions and linking them to names; (ii) a Dynamic Prior Module(DPM) that injects contextual cues from prior ADs and subtitles via learnable soft prompts; and (iii) a Focused Caption Module(FCM) that generates narrations enriched with plot-relevant details and named characters. To overcome limitations in character identification, we also introduce an automated pipeline for building character query banks. FocusedAD achieves state-of-the-art performance on multiple benchmarks, including strong zero-shot results on MAD-eval-Named and our newly proposed Cinepile-AD dataset. Code and data will be released at https://github.com/Thorin215/FocusedAD .","authors":["Xiaojun Ye","Chun Wang","Yiren Song","Sheng Zhou","Liangcheng Li","Jiajun Bu"],"url":"https://arxiv.org/abs/2504.12157"}
{"created":"2025-04-23","title":"Physics Informed Constrained Learning of Dynamics from Static Data","abstract":"A physics-informed neural network (PINN) models the dynamics of a system by integrating the governing physical laws into the architecture of a neural network. By enforcing physical laws as constraints, PINN overcomes challenges with data scarsity and potentially high dimensionality. Existing PINN frameworks rely on fully observed time-course data, the acquisition of which could be prohibitive for many systems. In this study, we developed a new PINN learning paradigm, namely Constrained Learning, that enables the approximation of first-order derivatives or motions using non-time course or partially observed data. Computational principles and a general mathematical formulation of Constrained Learning were developed. We further introduced MPOCtrL (Message Passing Optimization-based Constrained Learning) an optimization approach tailored for the Constrained Learning framework that strives to balance the fitting of physical models and observed data. Its code is available at github link: https://github.com/ptdang1001/MPOCtrL Experiments on synthetic and real-world data demonstrated that MPOCtrL can effectively detect the nonlinear dependency between observed data and the underlying physical properties of the system. In particular, on the task of metabolic flux analysis, MPOCtrL outperforms all existing data-driven flux estimators.","authors":["Pengtao Dang","Tingbo Guo","Melissa Fishel","Guang Lin","Wenzhuo Wu","Sha Cao","Chi Zhang"],"url":"https://arxiv.org/abs/2504.12675"}
{"created":"2025-04-23","title":"A Client-level Assessment of Collaborative Backdoor Poisoning in Non-IID Federated Learning","abstract":"Federated learning (FL) enables collaborative model training using decentralized private data from multiple clients. While FL has shown robustness against poisoning attacks with basic defenses, our research reveals new vulnerabilities stemming from non-independent and identically distributed (non-IID) data among clients. These vulnerabilities pose a substantial risk of model poisoning in real-world FL scenarios.","authors":["Phung Lai","Guanxiong Liu","NhatHai Phan","Issa Khalil","Abdallah Khreishah","Xintao Wu"],"url":"https://arxiv.org/abs/2504.12875"}
{"created":"2025-04-23","title":"ConExion: Concept Extraction with Large Language Models","abstract":"In this paper, an approach for concept extraction from documents using pre-trained large language models (LLMs) is presented. Compared with conventional methods that extract keyphrases summarizing the important information discussed in a document, our approach tackles a more challenging task of extracting all present concepts related to the specific domain, not just the important ones. Through comprehensive evaluations of two widely used benchmark datasets, we demonstrate that our method improves the F1 score compared to state-of-the-art techniques. Additionally, we explore the potential of using prompts within these models for unsupervised concept extraction. The extracted concepts are intended to support domain coverage evaluation of ontologies and facilitate ontology learning, highlighting the effectiveness of LLMs in concept extraction tasks. Our source code and datasets are publicly available at https://github.com/ISE-FIZKarlsruhe/concept_extraction.","authors":["Ebrahim Norouzi","Sven Hertling","Harald Sack"],"url":"https://arxiv.org/abs/2504.12915"}
{"created":"2025-04-23","title":"Why Ask One When You Can Ask $k$? Two-Stage Learning-to-Defer to the Top-$k$ Experts","abstract":"Learning-to-Defer (L2D) enables decision-making systems to improve reliability by selectively deferring uncertain predictions to more competent agents. However, most existing approaches focus exclusively on single-agent deferral, which is often inadequate in high-stakes scenarios that require collective expertise. We propose Top-$k$ Learning-to-Defer, a generalization of the classical two-stage L2D framework that allocates each query to the $k$ most confident agents instead of a single one. To further enhance flexibility and cost-efficiency, we introduce Top-$k(x)$ Learning-to-Defer, an adaptive extension that learns the optimal number of agents to consult for each query, based on input complexity, agent competency distributions, and consultation costs. For both settings, we derive a novel surrogate loss and prove that it is Bayes-consistent and $(\\mathcal{R}, \\mathcal{G})$-consistent, ensuring convergence to the Bayes-optimal allocation. Notably, we show that the well-established model cascades paradigm arises as a restricted instance of our Top-$k$ and Top-$k(x)$ formulations. Extensive experiments across diverse benchmarks demonstrate the effectiveness of our framework on both classification and regression tasks.","authors":["Yannis Montreuil","Axel Carlier","Lai Xing Ng","Wei Tsang Ooi"],"url":"https://arxiv.org/abs/2504.12988"}
{"created":"2025-04-23","title":"Effective Computation of Generalized Abelian Complexity for Pisot Type Substitutive Sequences","abstract":"Generalized abelian equivalence compares words by their factors up to a certain bounded length. The associated complexity function counts the equivalence classes for factors of a given size of an infinite sequence. How practical is this notion? When can these equivalence relations and complexity functions be computed efficiently? We study the fixed points of substitution of Pisot type. Each of their $k$-abelian complexities is bounded and the Parikh vectors of their length-$n$ prefixes form synchronized sequences in the associated Dumont--Thomas numeration system. Therefore, the $k$-abelian complexity of Pisot substitution fixed points is automatic in the same numeration system. Two effective generic construction approaches are investigated using the \\texttt{Walnut} theorem prover and are applied to several examples. We obtain new properties of the Tribonacci sequence, such as a uniform bound for its factor balancedness together with a two-dimensional linear representation of its generalized abelian complexity functions.","authors":["Jean-Michel Couvreur","Martin Delacourt","Nicolas Ollinger","Pierre Popoli","Jeffrey Shallit","Manon Stipulanti"],"url":"https://arxiv.org/abs/2504.13584"}
{"created":"2025-04-23","title":"Efficient algorithms for the Hadamard decomposition","abstract":"The Hadamard decomposition is a powerful technique for data analysis and matrix compression, which decomposes a given matrix into the element-wise product of two or more low-rank matrices. In this paper, we develop an efficient algorithm to solve this problem, leveraging an alternating optimization approach that decomposes the global non-convex problem into a series of convex sub-problems. To improve performance, we explore advanced initialization strategies inspired by the singular value decomposition (SVD) and incorporate acceleration techniques by introducing momentum-based updates. Beyond optimizing the two-matrix case, we also extend the Hadamard decomposition framework to support more than two low-rank matrices, enabling approximations with higher effective ranks while preserving computational efficiency. Finally, we conduct extensive experiments to compare our method with the existing gradient descent-based approaches for the Hadamard decomposition and with traditional low-rank approximation techniques. The results highlight the effectiveness of our proposed method across diverse datasets.","authors":["Samuel Wertz","Arnaud Vandaele","Nicolas Gillis"],"url":"https://arxiv.org/abs/2504.13633"}
{"created":"2025-04-23","title":"Robust Distributed Arrays: Provably Secure Networking for Data Availability Sampling","abstract":"Data Availability Sampling (DAS), a central component of Ethereum's roadmap, enables clients to verify data availability without requiring any single client to download the entire dataset. DAS operates by having clients randomly retrieve individual symbols of erasure-encoded data from a peer-to-peer network. While the cryptographic and encoding aspects of DAS have recently undergone formal analysis, the peer-to-peer networking layer remains underexplored, with a lack of security definitions and efficient, provably secure constructions. In this work, we address this gap by introducing a novel distributed data structure that can serve as the networking layer for DAS, which we call \\emph{robust distributed arrays}. That is, we rigorously define a robustness property of a distributed data structure in an open permissionless network, that mimics a collection of arrays. Then, we give a simple and efficient construction and formally prove its robustness. Notably, every individual node is required to store only small portions of the data, and accessing array positions incurs minimal latency. The robustness of our construction relies solely on the presence of a minimal \\emph{absolute} number of honest nodes in the network. In particular, we avoid any honest majority assumption. Beyond DAS, we anticipate that robust distributed arrays can have wider applications in distributed systems.","authors":["Dankrad Feist","Gottfried Herold","Mark Simkin","Benedikt Wagner"],"url":"https://arxiv.org/abs/2504.13757"}
{"created":"2025-04-23","title":"Equi-Euler GraphNet: An Equivariant, Temporal-Dynamics Informed Graph Neural Network for Dual Force and Trajectory Prediction in Multi-Body Systems","abstract":"Accurate real-time modeling of multi-body dynamical systems is essential for enabling digital twin applications across industries. While many data-driven approaches aim to learn system dynamics, jointly predicting internal loads and system trajectories remains a key challenge. This dual prediction is especially important for fault detection and predictive maintenance, where internal loads-such as contact forces-act as early indicators of faults, reflecting wear or misalignment before affecting motion. These forces also serve as inputs to degradation models (e.g., crack growth), enabling damage prediction and remaining useful life estimation. We propose Equi-Euler GraphNet, a physics-informed graph neural network (GNN) that simultaneously predicts internal forces and global trajectories in multi-body systems. In this mesh-free framework, nodes represent system components and edges encode interactions. Equi-Euler GraphNet introduces two inductive biases: (1) an equivariant message-passing scheme, interpreting edge messages as interaction forces consistent under Euclidean transformations; and (2) a temporal-aware iterative node update mechanism, based on Euler integration, to capture influence of distant interactions over time. Tailored for cylindrical roller bearings, it decouples ring dynamics from constrained motion of rolling elements. Trained on high-fidelity multiphysics simulations, Equi-Euler GraphNet generalizes beyond the training distribution, accurately predicting loads and trajectories under unseen speeds, loads, and configurations. It outperforms state-of-the-art GNNs focused on trajectory prediction, delivering stable rollouts over thousands of time steps with minimal error accumulation. Achieving up to a 200x speedup over conventional solvers while maintaining comparable accuracy, it serves as an efficient reduced-order model for digital twins, design, and maintenance.","authors":["Vinay Sharma","R\\'emi Tanguy Oddon","Pietro Tesini","Jens Ravesloot","Cees Taal","Olga Fink"],"url":"https://arxiv.org/abs/2504.13768"}
{"created":"2025-04-23","title":"A Fast Direct Solver for Boundary Integral Equations Using Quadrature By Expansion","abstract":"We construct and analyze a hierarchical direct solver for linear systems arising from the discretization of boundary integral equations using the Quadrature by Expansion (QBX) method. Our scheme builds on the existing theory of Hierarchical Semi-Separable (HSS) matrix operators that contain low-rank off-diagonal submatrices. We use proxy-based approximations of the far-field interactions and the Interpolative Decomposition (ID) to construct compressed HSS operators that are used as fast direct solvers for the original system. We describe a number of modifications to the standard HSS framework that enable compatibility with the QBX family of discretization methods. We establish an error model for the direct solver that is based on a multipole expansion of the QBX-mediated proxy interactions and standard estimates for the ID\\@. Based on these theoretical results, we develop an automatic approach for setting scheme parameters based on user-provided error tolerances. The resulting solver seamlessly generalizes across two- and tree-dimensional problems and achieves state-of-the-art asymptotic scaling. We conclude with numerical experiments that support the theoretical expectations for the error and computational cost of the direct solver.","authors":["Alexandru Fikl","Andreas Kl\\\"ockner"],"url":"https://arxiv.org/abs/2504.13809"}
{"created":"2025-04-23","title":"A framework for distributed discrete evacuation strategies","abstract":"Consider the following discrete evacuation model. The evacuation terrain is modeled by a simple graph $G=(V,E)$ whose certain vertices $X\\subseteq V$ are called \\emph{exits}. Initially, each vertex is either \\emph{empty} or \\emph{occupied} by an agent. We assume that each vertex has a unique \\emph{id} (and therefore the agents do have unique ids), each agent has finite but arbitrarily large memory, and the graph is initially stored in the memory of each agent. In other words, the agents do know the topology of the network along with the locations of the exits, but they do not know the initial positions nor the quantity of other agents. The time is divided into \\emph{steps}; in each step any pair of agents present at vertices at a distance of at most two can exchange an arbitrary number of messages, and then each agent can either make a move or stay put. The agents should make moves in a collision-free manner, i.e., no two agents can be located at the same vertex in the same step. At the end of each step, any agent located at an exit \\emph{evacuates}, i.e., it is removed from the graph. The goal is to provide an algorithm to the agents (referred to as an evacuation strategy) that ensures the evacuation of all agents and minimizes the number of steps.","authors":["Piotr Borowiecki","Dariusz Dereniowski","{\\L}ukasz Kuszner"],"url":"https://arxiv.org/abs/2504.14052"}
{"created":"2025-04-23","title":"Time's Up! An Empirical Study of LLM Reasoning Ability Under Output Length Constraint","abstract":"Recent work has demonstrated the remarkable potential of Large Language Models (LLMs) in test-time scaling. By making the models think before answering, they are able to achieve much higher accuracy with extra inference computation. However, in many real-world scenarios, models are used under time constraints, where an answer should be given to the user within a certain output length. It is unclear whether and how the reasoning abilities of LLMs remain effective under such constraints. We take a first look at this problem by conducting an in-depth empirical study. Specifically, we test more than 25 LLMs on common reasoning datasets under a wide range of output length budgets, and we analyze the correlation between the inference accuracy and various properties including model type, model size, prompt style, etc. We also consider the mappings between the token budgets and the actual on-device latency budgets. The results have demonstrated several interesting findings regarding the budget-aware LLM reasoning that differ from the unconstrained situation, e.g. the optimal choices of model sizes and prompts change under different budgets. These findings offer practical guidance for users to deploy LLMs under real-world latency constraints.","authors":["Yi Sun","Han Wang","Jiaqiang Li","Jiacheng Liu","Xiangyu Li","Hao Wen","Huiwen Zheng","Yan Liang","Yuanchun Li","Yunxin Liu"],"url":"https://arxiv.org/abs/2504.14350"}
{"created":"2025-04-23","title":"WindVE: Collaborative CPU-NPU Vector Embedding","abstract":"Retrieval-Augmented Generation is a technology that enhances large language models by integrating information retrieval. In the industry, inference services based on LLMs are highly sensitive to cost-performance ratio, prompting the need for improving hardware resource utilization in the inference service. Specifically, vector embedding and retrieval processes take up to 20% of the total latency. Therefore, optimizing the utilization of computational resources in vector embeddings is crucial for enhancing the cost-performance ratio of inference processes, which in turn boosts their product competitiveness.In this paper, we analyze the deployment costs of vector embedding technology in inference services, propose a theoretical formula, and determine through the mathematical expression that increasing the capacity to process concurrent queries is the key to reducing the deployment costs of vector embeddings. Therefore, in this paper, we focus on improving the product's capability to process concurrent queries. To optimize concurrency without sacrificing performance, we have designed a queue manager that adeptly offloads CPU peak queries. This manager utilizes a linear regression model to ascertain the optimal queue depths, a critical parameter that significantly influences the efficacy of the system. We further develop a system named WindVE that uses a CPU-NPU heterogeneous architecture to offload peak concurrent queries, which leverages the performance differences between the two processors to effectively manage traffic surges. Through experiments, we compare WindVE to the state-of-the-art vector embedding framework FlagEmbedding, and achieve a concurrency level up to 22.3% higher than the scheme without offloading.","authors":["Jinqi Huang","Xuebing Yu","Yi Xiong","Wenjie Huang","Entong Li","Li Zeng","Xin chen"],"url":"https://arxiv.org/abs/2504.14941"}
{"created":"2025-04-23","title":"Adaptive Student's t-distribution with method of moments moving estimator for nonstationary time series","abstract":"The real life time series are usually nonstationary, bringing a difficult question of model adaptation. Classical approaches like ARMA-ARCH assume arbitrary type of dependence. To avoid their bias, we will focus on recently proposed agnostic philosophy of moving estimator: in time $t$ finding parameters optimizing e.g. $F_t=\\sum_{\\tau<t} (1-\\eta)^{t-\\tau} \\ln(\\rho_\\theta (x_\\tau))$ moving log-likelihood, evolving in time. It allows for example to estimate parameters using inexpensive exponential moving averages (EMA), like absolute central moments $m_p=E[|x-\\mu|^p]$ evolving for one or multiple powers $p\\in\\mathbb{R}^+$ using $m_{p,t+1} = m_{p,t} + \\eta (|x_t-\\mu_t|^p-m_{p,t})$. Application of such general adaptive methods of moments will be presented on Student's t-distribution, popular especially in economical applications, here applied to log-returns of DJIA companies. While standard ARMA-ARCH approaches provide evolution of $\\mu$ and $\\sigma$, here we also get evolution of $\\nu$ describing $\\rho(x)\\sim |x|^{-\\nu-1}$ tail shape, probability of extreme events - which might turn out catastrophic, destabilizing the market.","authors":["Jarek Duda"],"url":"https://arxiv.org/abs/2304.03069"}
{"created":"2025-04-23","title":"Hedonic Prices and Quality Adjusted Price Indices Powered by AI","abstract":"We develop empirical models that efficiently process large amounts of unstructured product data (text, images, prices, quantities) to produce accurate hedonic price estimates and derived indices. To achieve this, we generate abstract product attributes (or ``features'') from descriptions and images using deep neural networks. These attributes are then used to estimate the hedonic price function. To demonstrate the effectiveness of this approach, we apply the models to Amazon's data for first-party apparel sales, and estimate hedonic prices. The resulting models have a very high out-of-sample predictive accuracy, with $R^2$ ranging from $80\\%$ to $90\\%$. Finally, we construct the AI-based hedonic Fisher price index, chained at the year-over-year frequency, and contrast it with the CPI and other electronic indices.","authors":["Patrick Bajari","Zhihao Cen","Victor Chernozhukov","Manoj Manukonda","Suhas Vijaykumar","Jin Wang","Ramon Huerta","Junbo Li","Ling Leng","George Monokroussos","Shan Wan"],"url":"https://arxiv.org/abs/2305.00044"}
{"created":"2025-04-23","title":"PCL-Indexability and Whittle Index for Restless Bandits with General Observation Models","abstract":"In this paper, we consider a general observation model for restless multi-armed bandit problems. The operation of the player needs to be based on certain feedback mechanism that is error-prone due to resource constraints or environmental or intrinsic noises. By establishing a general probabilistic model for dynamics of feedback/observation, we formulate the problem as a restless bandit with a countable belief state space starting from an arbitrary initial belief (a priori information). We apply the achievable region method with partial conservation law (PCL) to the infinite-state problem and analyze its indexability and priority index (Whittle index). Finally, we propose an approximation process to transform the problem into which the AG algorithm of Ni\\~no-Mora and Bertsimas for finite-state problems can be applied to. Numerical experiments show that our algorithm has an excellent performance.","authors":["Keqin Liu","Qizhen Jia","Chengzhong Zhang"],"url":"https://arxiv.org/abs/2307.03034"}
{"created":"2025-04-23","title":"Comparing Width Parameters on Graph Classes","abstract":"We study how the relationship between non-equivalent width parameters changes once we restrict to some special graph class. As width parameters, we consider treewidth, clique-width, twin-width, mim-width, sim-width and tree-independence number, whereas as graph classes we consider $K_{t,t}$-subgraph-free graphs, line graphs and their common superclass, for $t \\geq 3$, of $K_{t,t}$-free graphs.","authors":["Nick Brettell","Andrea Munaro","Dani\\\"el Paulusma","Shizhou Yang"],"url":"https://arxiv.org/abs/2308.05817"}
{"created":"2025-04-23","title":"Evolutionary Games on Infinite Strategy Sets: Convergence to Nash Equilibria via Dissipativity","abstract":"We consider evolutionary dynamics for population games in which players have a continuum of strategies at their disposal. Models in this setting amount to infinite-dimensional differential equations evolving on the manifold of probability measures. We generalize dissipativity theory for evolutionary games from finite to infinite strategy sets that are compact metric spaces, and derive sufficient conditions for the stability of Nash equilibria under the infinite-dimensional dynamics. The resulting analysis is applicable to a broad class of evolutionary games, and is modular in the sense that the pertinent conditions on the dynamics and the game's payoff structure can be verified independently. By specializing our theory to the class of monotone games, we recover as special cases existing stability results for the Brown-von Neumann-Nash and impartial pairwise comparison dynamics. We also extend our theory to models with dynamic payoffs, further broadening the applicability of our framework. Throughout our analyses, we identify and elaborate on new technical conditions that are key in extending dissipativity theory from finite to infinite strategy sets, such as compactness of the set of Nash equilibria and evolution of dynamic payoffs within a compact positively invariant set. We illustrate our theory using a variety of case studies, including a novel, continuous variant of the war of attrition game.","authors":["Brendon G. Anderson","Jingqi Li","Somayeh Sojoudi","Murat Arcak"],"url":"https://arxiv.org/abs/2312.08286"}
{"created":"2025-04-23","title":"3DGR-CT: Sparse-View CT Reconstruction with a 3D Gaussian Representation","abstract":"Sparse-view computed tomography (CT) reduces radiation exposure by acquiring fewer projections, making it a valuable tool in clinical scenarios where low-dose radiation is essential. However, this often results in increased noise and artifacts due to limited data. In this paper we propose a novel 3D Gaussian representation (3DGR) based method for sparse-view CT reconstruction. Inspired by recent success in novel view synthesis driven by 3D Gaussian splatting, we leverage the efficiency and expressiveness of 3D Gaussian representation as an alternative to implicit neural representation. To unleash the potential of 3DGR for CT imaging scenario, we propose two key innovations: (i) FBP-image-guided Guassian initialization and (ii) efficient integration with a differentiable CT projector. Extensive experiments and ablations on diverse datasets demonstrate the proposed 3DGR-CT consistently outperforms state-of-the-art counterpart methods, achieving higher reconstruction accuracy with faster convergence. Furthermore, we showcase the potential of 3DGR-CT for real-time physical simulation, which holds important clinical applications while challenging for implicit neural representations.","authors":["Yingtai Li","Xueming Fu","Han Li","Shang Zhao","Ruiyang Jin","S. Kevin Zhou"],"url":"https://arxiv.org/abs/2312.15676"}
{"created":"2025-04-23","title":"An interacting particle consensus method for constrained global optimization","abstract":"This paper presents a particle-based optimization method designed for addressing minimization problems with equality constraints, particularly in cases where the loss function exhibits non-differentiability or non-convexity. The proposed method combines components from consensus-based optimization algorithm with a newly introduced forcing term directed at the constraint set. A rigorous mean-field limit of the particle system is derived, and the convergence of the mean-field limit to the constrained minimizer is established. Additionally, we introduce a stable discretized algorithm and conduct various numerical experiments to demonstrate the performance of the proposed method.","authors":["Jos\\'e A. Carrillo","Shi Jin","Haoyu Zhang","Yuhua Zhu"],"url":"https://arxiv.org/abs/2405.00891"}
{"created":"2025-04-23","title":"Symbolic Regression for Beyond the Standard Model Physics","abstract":"We propose symbolic regression as a powerful tool for studying Beyond the Standard Model physics. As a benchmark model, we consider the so-called Constrained Minimal Supersymmetric Standard Model, which has a four-dimensional parameter space defined at the GUT scale. We provide a set of analytical expressions that reproduce three low-energy observables of interest in terms of the parameters of the theory: the Higgs mass, the contribution to the anomalous magnetic moment of the muon, and the cold dark matter relic density. To demonstrate the power of the approach, we employ the symbolic expressions in a global fits analysis to derive the posterior probability densities of the parameters, which are obtained extremely rapidly in comparison with conventional methods.","authors":["Shehu AbdusSalam","Steve Abel","Miguel Crispim Romao"],"url":"https://arxiv.org/abs/2405.18471"}
{"created":"2025-04-23","title":"Benign overfitting in Fixed Dimension via Physics-Informed Learning with Smooth Inductive Bias","abstract":"Recent advances in machine learning have inspired a surge of research into reconstructing specific quantities of interest from measurements that comply with certain physical laws. These efforts focus on inverse problems that are governed by partial differential equations (PDEs). In this work, we develop an asymptotic Sobolev norm learning curve for kernel ridge(less) regression when addressing (elliptical) linear inverse problems. Our results show that the PDE operators in the inverse problem can stabilize the variance and even behave benign overfitting for fixed-dimensional problems, exhibiting different behaviors from regression problems. Besides, our investigation also demonstrates the impact of various inductive biases introduced by minimizing different Sobolev norms as a form of implicit regularization. For the regularized least squares estimator, we find that all considered inductive biases can achieve the optimal convergence rate, provided the regularization parameter is appropriately chosen. The convergence rate is actually independent to the choice of (smooth enough) inductive bias for both ridge and ridgeless regression. Surprisingly, our smoothness requirement recovered the condition found in Bayesian setting and extend the conclusion to the minimum norm interpolation estimators.","authors":["Honam Wong","Wendao Wu","Fanghui Liu","Yiping Lu"],"url":"https://arxiv.org/abs/2406.09194"}
{"created":"2025-04-23","title":"EEG Right & Left Voluntary Hand Movement-based Virtual Brain-Computer Interfacing Keyboard Using Hybrid Deep Learning Approach","abstract":"Brain-machine interfaces (BMIs), particularly those based on electroencephalography (EEG), offer promising solutions for assisting individuals with motor disabilities. However, challenges in reliably interpreting EEG signals for specific tasks, such as simulating keystrokes, persist due to the complexity and variability of brain activity. Current EEG-based BMIs face limitations in adaptability, usability, and robustness, especially in applications like virtual keyboards, as traditional machine-learning models struggle to handle high-dimensional EEG data effectively. To address these gaps, we developed an EEG-based BMI system capable of accurately identifying voluntary keystrokes, specifically leveraging right and left voluntary hand movements. Using a publicly available EEG dataset, the signals were pre-processed with band-pass filtering, segmented into 22-electrode arrays, and refined into event-related potential (ERP) windows, resulting in a 19x200 feature array categorized into three classes: resting state (0), 'd' key press (1), and 'l' key press (2). Our approach employs a hybrid neural network architecture with BiGRU-Attention as the proposed model for interpreting EEG signals, achieving superior test accuracy of 90% and a mean accuracy of 91% in 10-fold stratified cross-validation. This performance outperforms traditional ML methods like Support Vector Machines (SVMs) and Naive Bayes, as well as advanced architectures such as Transformers, CNN-Transformer hybrids, and EEGNet. Finally, the BiGRU-Attention model is integrated into a real-time graphical user interface (GUI) to simulate and predict keystrokes from brain activity. Our work demonstrates how deep learning can advance EEG-based BMI systems by addressing the challenges of signal interpretation and classification.","authors":["Biplov Paneru","Bipul Thapa","Bishwash Paneru","Sanjog Chhetri Sapkota"],"url":"https://arxiv.org/abs/2409.00035"}
{"created":"2025-04-23","title":"When resampling/reweighting improves feature learning in imbalanced classification?: A toy-model study","abstract":"A toy model of binary classification is studied with the aim of clarifying the class-wise resampling/reweighting effect on the feature learning performance under the presence of class imbalance. In the analysis, a high-dimensional limit of the input space is taken while keeping the ratio of the dataset size against the input dimension finite and the non-rigorous replica method from statistical mechanics is employed. The result shows that there exists a case in which the no resampling/reweighting situation gives the best feature learning performance irrespectively of the choice of losses or classifiers, supporting recent findings in Cao et al. (2019); Kang et al. (2019). It is also revealed that the key of the result is the symmetry of the loss and the problem setting. Inspired by this, we propose a further simplified model exhibiting the same property in the multiclass setting. These clarify when the class-wise resampling/reweighting becomes effective in imbalanced classification.","authors":["Tomoyuki Obuchi","Toshiyuki Tanaka"],"url":"https://arxiv.org/abs/2409.05598"}
{"created":"2025-04-23","title":"Transition of $\\alpha$-mixing in Random Iterations with Applications in Queuing Theory","abstract":"Nonlinear time series models with exogenous regressors are essential in econometrics, queuing theory, and machine learning, though their statistical analysis remains incomplete. Key results, such as the law of large numbers and the functional central limit theorem, are known for weakly dependent variables. We demonstrate the transfer of mixing properties from the exogenous regressor to the response via coupling arguments. Additionally, we study Markov chains in random environments with drift and minorization conditions, even under non-stationary environments with favorable mixing properties, and apply this framework to single-server queuing models.","authors":["Attila Lovas"],"url":"https://arxiv.org/abs/2410.05056"}
{"created":"2025-04-23","title":"Learning the structure of any Hamiltonian from minimal assumptions","abstract":"We study the problem of learning an unknown quantum many-body Hamiltonian $H$ from black-box queries to its time evolution $e^{-\\mathrm{i} H t}$. Prior proposals for solving this task either impose some assumptions on $H$, such as its interaction structure or locality, or otherwise use an exponential amount of computational postprocessing. In this paper, we present algorithms to learn any $n$-qubit Hamiltonian, which do not need to know the Hamiltonian terms in advance, nor are they restricted to local interactions. Our algorithms are efficient as long as the number of terms $m$ is polynomially bounded in the system size $n$. We consider two models of control over the time evolution:~the first has access to time reversal ($t < 0$), enabling an algorithm that outputs an $\\epsilon$-accurate classical description of $H$ after querying its dynamics for a total of $\\widetilde{\\mathcal{O}}(m/\\epsilon)$ evolution time. The second access model is more conventional, allowing only forward-time evolutions;~our algorithm requires $\\widetilde{\\mathcal{O}}(\\|H\\|^3/\\epsilon^4)$ evolution time in this setting. Central to our results is the recently introduced concept of a pseudo-Choi state of $H$. We extend the utility of this learning resource by showing how to use it to learn the Fourier spectrum of $H$, how to achieve nearly Heisenberg-limited scaling with it, and how to prepare it even under our more restricted access models.","authors":["Andrew Zhao"],"url":"https://arxiv.org/abs/2410.21635"}
{"created":"2025-04-23","title":"Unsupervised Hyperspectral and Multispectral Image Fusion via Self-Supervised Modality Decoupling","abstract":"Hyperspectral and Multispectral Image Fusion (HMIF) aims to fuse low-resolution hyperspectral images (LR-HSIs) and high-resolution multispectral images (HR-MSIs) to reconstruct high spatial and high spectral resolution images. Current methods typically apply direct fusion from the two modalities without effective supervision, leading to an incomplete perception of deep modality-complementary information and a limited understanding of inter-modality correlations. To address these issues, we propose a simple yet effective solution for unsupervised HMIF, revealing that modality decoupling is key to improving fusion performance. Specifically, we propose an end-to-end self-supervised \\textbf{Mo}dality-Decoupled \\textbf{S}patial-\\textbf{S}pectral Fusion (\\textbf{MossFuse}) framework that decouples shared and complementary information across modalities and aggregates a concise representation of both LR-HSIs and HR-MSIs to reduce modality redundancy. Also, we introduce the subspace clustering loss as a clear guide to decouple modality-shared features from modality-complementary ones. Systematic experiments over multiple datasets demonstrate that our simple and effective approach consistently outperforms the existing HMIF methods while requiring considerably fewer parameters with reduced inference time. The anonymous source code is in \\href{https://github.com/dusongcheng/MossFuse}{MossFuse}.","authors":["Songcheng Du","Yang Zou","Zixu Wang","Xingyuan Li","Ying Li","Changjing Shang","Qiang Shen"],"url":"https://arxiv.org/abs/2412.04802"}
{"created":"2025-04-23","title":"Direct Sampling of Confined Polygons in Linear Time","abstract":"We present an algorithm for sampling tightly confined random equilateral closed polygons in three-space which has runtime linear in the number of edges. Using symplectic geometry, sampling such polygons reduces to sampling a moment polytope, and in our confinement model this polytope turns out to be very natural from a combinatorial point of view. This connection to combinatorics yields both our fast sampling algorithm and explicit formulas for the expected distances of vertices to the origin. We use our algorithm to investigate the expected total curvature of confined polygons, leading to a very precise conjecture for the asymptotics of total curvature.","authors":["Clayton Shonkwiler","Kandin Theis"],"url":"https://arxiv.org/abs/2501.04885"}
{"created":"2025-04-23","title":"Modular Compilation for Quantum Chiplet Architectures","abstract":"As quantum computing technology matures, industry is adopting modular quantum architectures to keep quantum scaling on the projected path and meet performance targets. However, the complexity of chiplet-based quantum devices, coupled with their growing size, presents an imminent scalability challenge for quantum compilation. Contemporary compilation methods are not well-suited to chiplet architectures - in particular, existing qubit allocation methods are often unable to contend with inter-chiplet links, which don't necessarily support a universal basis gate set. Furthermore, existing methods of logical-to-physical qubit placement, swap insertion (routing), unitary synthesis, and/or optimization, are typically not designed for qubit links of significantly varying latency or fidelity. In this work, we propose SEQC, a hierarchical parallelized compilation pipeline optimized for chiplet-based quantum systems, including several novel methods for qubit placement, qubit routing, and circuit optimization. SEQC attains a $9.3\\%$ average increase in circuit fidelity (up to $49.99\\%$). Additionally, owing to its ability to parallelize compilation, SEQC achieves $3.27\\times$ faster compilation on average (up to $6.74\\times$) over a chiplet-unaware Qiskit baseline.","authors":["Mingyoung Jessica Jeng","Nikola Vuk Maruszewski","Connor Selna","Michael Gavrincea","Kaitlin N. Smith","Nikos Hardavellas"],"url":"https://arxiv.org/abs/2501.08478"}
{"created":"2025-04-23","title":"On total transitivity of graphs","abstract":"Let $G = (V, E)$ be a graph where $V$ and $E$ are the vertex and edge sets, respectively. For two disjoint subsets $A$ and $B$ of $V$, we say that $A$ \\emph{dominates} $B$ if every vertex of $B$ is adjacent to at least one vertex of $A$. A vertex partition $\\pi = \\{V_1, V_2, \\ldots, V_k\\}$ of $G$ is called a \\emph{transitive partition} of size $k$ if $V_i$ dominates $V_j$ for all $1 \\leq i < j \\leq k$. In this article, we study a variation of the transitive partition, namely the \\emph{total transitive partition}. The total transitivity $Tr_t(G)$ is defined as the maximum order of a vertex partition $\\pi = \\{V_1, V_2, \\ldots, V_k\\}$ of $G$ obtained by repeatedly removing a total dominating set from $G$ until no vertices remain. Thus, $V_1$ is a total dominating set of $G$, $V_2$ is a total dominating set of the graph $G_1 = G - V_1$, and, for $2 \\leq i \\leq k - 1$, $V_{i+1}$ is a total dominating set in the graph $G_i = G - \\bigcup_{j=1}^i V_j$. A vertex partition of order $Tr_t(G)$ is called a $Tr_t$-partition. The \\textsc{Maximum Total Transitivity Problem} is to find a total transitive partition of a given graph with the maximum number of parts. First, we characterize split graphs with total transitivity equal to $1$ and $\\omega(G) - 1$. Moreover, for a split graph $G$ and $1 \\leq p \\leq \\omega(G) - 1$, we provide necessary conditions for $Tr_t(G) = p$. Furthermore, we show that the decision version of this problem is NP-complete for bipartite graphs. On the positive side, we prove that this problem can be solved in linear time for bipartite chain graphs. Finally, we design a polynomial-time algorithm to solve the \\textsc{Maximum Total Transitivity Problem} in trees.","authors":["Kamal Santra"],"url":"https://arxiv.org/abs/2501.13760"}
{"created":"2025-04-23","title":"Artificial Intelligence Clones","abstract":"Large language models, trained on personal data, may soon be able to mimic individual personalities. These ``AI clones'' or ``AI agents'' have the potential to transform how people search over one another in contexts ranging from marriage to employment -- indeed, several dating platforms have already begun using AI clones to evaluate potential pairings between users. This paper presents a theoretical framework to study the tradeoff between the substantially expanded search capacity of AI clones, and their imperfect representation of humans. Individual personalities are modeled as points in $k$-dimensional Euclidean space, and their AI clones are modeled as noisy approximations of these personalities. I compare two search regimes: an ``in-person regime'' -- where each person randomly meets some number of individuals and matches to the most compatible among them -- against an ``AI representation regime'' -- in which individuals match to the person whose AI clone is most compatible with their AI clone. I show that a finite number of in-person encounters exceeds the expected payoff from search over infinite AI clones. Moreover, when the dimensionality of personality is large, simply meeting two people in person produces a better expected match than entrusting the process to an AI platform, regardless of the size of its candidate pool.","authors":["Annie Liang"],"url":"https://arxiv.org/abs/2501.16996"}
{"created":"2025-04-23","title":"Audio signal interpolation using optimal transportation of spectrograms","abstract":"We present a novel approach for generating an artificial audio signal that interpolates between given source and target sounds. Our approach relies on the computation of Wasserstein barycenters of the source and target spectrograms, followed by phase reconstruction and inversion. In contrast with previous works, our new method considers the spectrograms globally and does not operate on a temporal frame-to-frame basis. Another contribution is to endow the transportation cost matrix with a specific structure that prohibits remote displacements of energy along the time axis, and for which optimal transport is made possible by leveraging the unbalanced transport framework. The proposed cost matrix makes sense from the audio perspective and also allows to reduce the computation load. Results with synthetic musical notes and real environmental sounds illustrate the potential of our novel approach.","authors":["David Valdivia","Marien Renaud","Elsa Cazelles","C\\'edric F\\'evotte"],"url":"https://arxiv.org/abs/2502.15430"}
{"created":"2025-04-23","title":"A Mechanism-Learning Deeply Coupled Model for Remote Sensing Retrieval of Global Land Surface Temperature","abstract":"Land surface temperature (LST) retrieval from remote sensing data is pivotal for analyzing climate processes and surface energy budgets. However, LST retrieval is an ill-posed inverse problem, which becomes particularly severe when only a single band is available. In this paper, we propose a deeply coupled framework integrating mechanistic modeling and machine learning to enhance the accuracy and generalizability of single-channel LST retrieval. Training samples are generated using a physically-based radiative transfer model and a global collection of 5810 atmospheric profiles. A physics-informed machine learning framework is proposed to systematically incorporate the first principles from classical physical inversion models into the learning workflow, with optimization constrained by radiative transfer equations. Global validation demonstrated a 30% reduction in root-mean-square error versus standalone methods. Under extreme humidity, the mean absolute error decreased from 4.87 K to 2.29 K (53% improvement). Continental-scale tests across five continents confirmed the superior generalizability of this model.","authors":["Tian Xie","Menghui Jiang","Huanfeng Shen","Huifang Li","Chao Zeng","Jun Ma","Guanhao Zhang","Liangpei Zhang"],"url":"https://arxiv.org/abs/2504.07481"}
{"created":"2025-04-23","title":"Numerical solution by shape optimization method to an inverse shape problem in multi-dimensional advection-diffusion problem with space dependent coefficients","abstract":"This work focuses on numerically solving a shape identification problem related to advection-diffusion processes with space-dependent coefficients using shape optimization techniques. Two boundary-type cost functionals are considered, and their corresponding variations with respect to shapes are derived using the adjoint method, employing the chain rule approach. This involves firstly utilizing the material derivative of the state system and secondly using its shape derivative. Subsequently, an alternating direction method of multipliers (ADMM) combined with the Sobolev-gradient-descent algorithm is applied to stably solve the shape reconstruction problem. Numerical experiments in two and three dimensions are conducted to demonstrate the feasibility of the methods.","authors":["Elmehdi Cherrat","Lekbir Afraites","Julius Fergy Tiongson Rabago"],"url":"https://arxiv.org/abs/2504.07796"}
{"created":"2025-04-23","title":"EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text Prompting","abstract":"Human speech goes beyond the mere transfer of information; it is a profound exchange of emotions and a connection between individuals. While Text-to-Speech (TTS) models have made huge progress, they still face challenges in controlling the emotional expression in the generated speech. In this work, we propose EmoVoice, a novel emotion-controllable TTS model that exploits large language models (LLMs) to enable fine-grained freestyle natural language emotion control, and a phoneme boost variant design that makes the model output phoneme tokens and audio tokens in parallel to enhance content consistency, inspired by chain-of-thought (CoT) and chain-of-modality (CoM) techniques. Besides, we introduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring expressive speech and fine-grained emotion labels with natural language descriptions. EmoVoice achieves state-of-the-art performance on the English EmoVoice-DB test set using only synthetic training data, and on the Chinese Secap test set using our in-house data. We further investigate the reliability of existing emotion evaluation metrics and their alignment with human perceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and Gemini to assess emotional speech. Demo samples are available at https://yanghaha0908.github.io/EmoVoice/. Dataset, code, and checkpoints will be released.","authors":["Guanrou Yang","Chen Yang","Qian Chen","Ziyang Ma","Wenxi Chen","Wen Wang","Tianrui Wang","Yifan Yang","Zhikang Niu","Wenrui Liu","Fan Yu","Zhihao Du","Zhifu Gao","ShiLiang Zhang","Xie Chen"],"url":"https://arxiv.org/abs/2504.12867"}
{"created":"2025-04-23","title":"Quantum repeaters enhanced by vacuum beam guides","abstract":"The development of large-scale quantum communication networks faces critical challenges due to photon loss and decoherence in optical fiber channels. These fundamentally limit transmission distances and demand dense networks of repeater stations. This work investigates using vacuum beam guides (VBGs)-a promising ultra-low-loss transmission platform-as an alternative to traditional fiber links. By incorporating VBGs into repeater-based architectures, we demonstrate that the inter-repeater spacing can be substantially extended, resulting in fewer required nodes and significantly reducing hardware and operational complexity. We perform a cost-function analysis to quantify performance trade-offs across first, second, and third-generation repeaters. Our results show that first-generation repeaters reduce costs dramatically by eliminating entanglement purification. Third-generation repeaters benefit from improved link transmission success, which is crucial for quantum error correction. In contrast, second-generation repeaters exhibit a more nuanced response; although transmission loss is reduced, their performance remains primarily limited by logical gate errors rather than channel loss. These findings highlight that while all repeater generations benefit from reduced photon loss, the magnitude of improvement depends critically on the underlying error mechanisms. Vacuum beam guides thus emerge as a powerful enabler for scalable, high-performance quantum networks, particularly in conjunction with near-term quantum hardware capabilities.","authors":["Yu Gan","Mohadeseh Azari","Nitish Kumar Chandra","Xin Jin","Jinglei Cheng","Kaushik P. Seshadreesan","Junyu Liu"],"url":"https://arxiv.org/abs/2504.13397"}
