{"created":"2025-05-20","title":"Spectral Policy Optimization: Coloring your Incorrect Reasoning in GRPO","abstract":"Reinforcement learning (RL) has demonstrated significant success in enhancing reasoning capabilities in large language models (LLMs). One of the most widely used RL methods is Group Relative Policy Optimization (GRPO)~\\cite{Shao-2024-Deepseekmath}, known for its memory efficiency and success in training DeepSeek-R1~\\cite{Guo-2025-Deepseek}. However, GRPO stalls when all sampled responses in a group are incorrect -- referred to as an \\emph{all-negative-sample} group -- as it fails to update the policy, hindering learning progress. The contributions of this paper are two-fold. First, we propose a simple yet effective framework that introduces response diversity within all-negative-sample groups in GRPO using AI feedback. We also provide a theoretical analysis, via a stylized model, showing how this diversification improves learning dynamics. Second, we empirically validate our approach, showing the improved performance across various model sizes (7B, 14B, 32B) in both offline and online learning settings with 10 benchmarks, including base and distilled variants. Our findings highlight that learning from all-negative-sample groups is not only feasible but beneficial, advancing recent insights from \\citet{Xiong-2025-Minimalist}.","authors":["Peter Chen","Xiaopeng Li","Ziniu Li","Xi Chen","Tianyi Lin"],"url":"https://arxiv.org/abs/2505.11595"}
{"created":"2025-05-20","title":"Continuous Optimization for Feature Selection with Permutation-Invariant Embedding and Policy-Guided Search","abstract":"Feature selection removes redundant features to enhanc performance and computational efficiency in downstream tasks. Existing works often struggle to capture complex feature interactions and adapt to diverse scenarios. Recent advances in this domain have incorporated generative intelligence to address these drawbacks by uncovering intricate relationships between features. However, two key limitations remain: 1) embedding feature subsets in a continuous space is challenging due to permutation sensitivity, as changes in feature order can introduce biases and weaken the embedding learning process; 2) gradient-based search in the embedding space assumes convexity, which is rarely guaranteed, leading to reduced search effectiveness and suboptimal subsets. To address these limitations, we propose a new framework that can: 1) preserve feature subset knowledge in a continuous embedding space while ensuring permutation invariance; 2) effectively explore the embedding space without relying on strong convex assumptions. For the first objective, we develop an encoder-decoder paradigm to preserve feature selection knowledge into a continuous embedding space. This paradigm captures feature interactions through pairwise relationships within the subset, removing the influence of feature order on the embedding. Moreover, an inducing point mechanism is introduced to accelerate pairwise relationship computations. For the second objective, we employ a policy-based reinforcement learning (RL) approach to guide the exploration of the embedding space. The RL agent effectively navigates the space by balancing multiple objectives. By prioritizing high-potential regions adaptively and eliminating the reliance on convexity assumptions, the RL agent effectively reduces the risk of converging to local optima. Extensive experiments demonstrate the effectiveness, efficiency, robustness and explicitness of our model.","authors":["Rui Liu","Rui Xie","Zijun Yao","Yanjie Fu","Dongjie Wang"],"url":"https://arxiv.org/abs/2505.11601"}
{"created":"2025-05-20","title":"Regularity and Stability Properties of Selective SSMs with Discontinuous Gating","abstract":"Deep Selective State-Space Models (SSMs), characterized by input-dependent, time-varying parameters, offer significant expressive power but pose challenges for stability analysis, especially with discontinuous gating signals. In this paper, we investigate the stability and regularity properties of continuous-time selective SSMs through the lens of passivity and Input-to-State Stability (ISS). We establish that intrinsic energy dissipation guarantees exponential forgetting of past states. Crucially, we prove that the unforced system dynamics possess an underlying minimal quadratic energy function whose defining matrix exhibits robust $\\text{AUC}_{\\text{loc}}$ regularity, accommodating discontinuous gating. Furthermore, assuming a universal quadratic storage function ensures passivity across all inputs, we derive parametric LMI conditions and kernel constraints that limit gating mechanisms, formalizing \"irreversible forgetting\" of recurrent models. Finally, we provide sufficient conditions for global ISS, linking uniform local dissipativity to overall system robustness. Our findings offer a rigorous framework for understanding and designing stable and reliable deep selective SSMs.","authors":["Nikola Zubi\\'c","Davide Scaramuzza"],"url":"https://arxiv.org/abs/2505.11602"}
{"created":"2025-05-20","title":"Talk to Your Slides: Efficient Slide Editing Agent with Large Language Models","abstract":"Existing research on large language models (LLMs) for PowerPoint predominantly focuses on slide generation, overlooking the common yet tedious task of editing existing slides. We introduce Talk-to-Your-Slides, an LLM-powered agent that directly edits slides within active PowerPoint sessions through COM communication. Our system employs a two-level approach: (1) high-level processing where an LLM agent interprets instructions and formulates editing plans, and (2) low-level execution where Python scripts directly manipulate PowerPoint objects. Unlike previous methods relying on predefined operations, our approach enables more flexible and contextually-aware editing. To facilitate evaluation, we present TSBench, a human-annotated dataset of 379 diverse editing instructions with corresponding slide variations. Experimental results demonstrate that Talk-to-Your-Slides significantly outperforms baseline methods in execution success rate, instruction fidelity, and editing efficiency. Our code and benchmark are available at https://anonymous.4open.science/r/talk-to-your-slides/","authors":["Kyudan Jung","Hojun Cho","Jooyeol Yun","Jaehyeok Jang","Jagul Choo"],"url":"https://arxiv.org/abs/2505.11604"}
{"created":"2025-05-20","title":"Foundation Models for AI-Enabled Biological Design","abstract":"This paper surveys foundation models for AI-enabled biological design, focusing on recent developments in applying large-scale, self-supervised models to tasks such as protein engineering, small molecule design, and genomic sequence design. Though this domain is evolving rapidly, this survey presents and discusses a taxonomy of current models and methods. The focus is on challenges and solutions in adapting these models for biological applications, including biological sequence modeling architectures, controllability in generation, and multi-modal integration. The survey concludes with a discussion of open problems and future directions, offering concrete next-steps to improve the quality of biological sequence generation.","authors":["Asher Moldwin","Amarda Shehu"],"url":"https://arxiv.org/abs/2505.11610"}
{"created":"2025-05-20","title":"Probing the Vulnerability of Large Language Models to Polysemantic Interventions","abstract":"Polysemanticity -- where individual neurons encode multiple unrelated features -- is a well-known characteristic of large neural networks and remains a central challenge in the interpretability of language models. At the same time, its implications for model safety are also poorly understood. Leveraging recent advances in sparse autoencoders, we investigate the polysemantic structure of two small models (Pythia-70M and GPT-2-Small) and evaluate their vulnerability to targeted, covert interventions at the prompt, feature, token, and neuron levels. Our analysis reveals a consistent polysemantic topology shared across both models. Strikingly, we demonstrate that this structure can be exploited to mount effective interventions on two larger, black-box instruction-tuned models (LLaMA3.1-8B-Instruct and Gemma-2-9B-Instruct). These findings suggest not only the generalizability of the interventions but also point to a stable and transferable polysemantic structure that could potentially persist across architectures and training regimes.","authors":["Bofan Gong","Shiyang Lai","Dawn Song"],"url":"https://arxiv.org/abs/2505.11611"}
{"created":"2025-05-20","title":"Heart2Mind: Human-Centered Contestable Psychiatric Disorder Diagnosis System using Wearable ECG Monitors","abstract":"Psychiatric disorders affect millions globally, yet their diagnosis faces significant challenges in clinical practice due to subjective assessments and accessibility concerns, leading to potential delays in treatment. To help address this issue, we present Heart2Mind, a human-centered contestable psychiatric disorder diagnosis system using wearable electrocardiogram (ECG) monitors. Our approach leverages cardiac biomarkers, particularly heart rate variability (HRV) and R-R intervals (RRI) time series, as objective indicators of autonomic dysfunction in psychiatric conditions. The system comprises three key components: (1) a Cardiac Monitoring Interface (CMI) for real-time data acquisition from Polar H9/H10 devices; (2) a Multi-Scale Temporal-Frequency Transformer (MSTFT) that processes RRI time series through integrated time-frequency domain analysis; (3) a Contestable Diagnosis Interface (CDI) combining Self-Adversarial Explanations (SAEs) with contestable Large Language Models (LLMs). Our MSTFT achieves 91.7% accuracy on the HRV-ACC dataset using leave-one-out cross-validation, outperforming state-of-the-art methods. SAEs successfully detect inconsistencies in model predictions by comparing attention-based and gradient-based explanations, while LLMs enable clinicians to validate correct predictions and contest erroneous ones. This work demonstrates the feasibility of combining wearable technology with Explainable Artificial Intelligence (XAI) and contestable LLMs to create a transparent, contestable system for psychiatric diagnosis that maintains clinical oversight while leveraging advanced AI capabilities. Our implementation is publicly available at: https://github.com/Analytics-Everywhere-Lab/heart2mind.","authors":["Hung Nguyen","Alireza Rahimi","Veronica Whitford","H\\'el\\`ene Fournier","Irina Kondratova","Ren\\'e Richard","Hung Cao"],"url":"https://arxiv.org/abs/2505.11612"}
{"created":"2025-05-20","title":"MedGUIDE: Benchmarking Clinical Decision-Making in Large Language Models","abstract":"Clinical guidelines, typically structured as decision trees, are central to evidence-based medical practice and critical for ensuring safe and accurate diagnostic decision-making. However, it remains unclear whether Large Language Models (LLMs) can reliably follow such structured protocols. In this work, we introduce MedGUIDE, a new benchmark for evaluating LLMs on their ability to make guideline-consistent clinical decisions. MedGUIDE is constructed from 55 curated NCCN decision trees across 17 cancer types and uses clinical scenarios generated by LLMs to create a large pool of multiple-choice diagnostic questions. We apply a two-stage quality selection process, combining expert-labeled reward models and LLM-as-a-judge ensembles across ten clinical and linguistic criteria, to select 7,747 high-quality samples. We evaluate 25 LLMs spanning general-purpose, open-source, and medically specialized models, and find that even domain-specific LLMs often underperform on tasks requiring structured guideline adherence. We also test whether performance can be improved via in-context guideline inclusion or continued pretraining. Our findings underscore the importance of MedGUIDE in assessing whether LLMs can operate safely within the procedural frameworks expected in real-world clinical settings.","authors":["Xiaomin Li","Mingye Gao","Yuexing Hao","Taoran Li","Guangya Wan","Zihan Wang","Yijun Wang"],"url":"https://arxiv.org/abs/2505.11613"}
{"created":"2025-05-20","title":"Using Reinforcement Learning to Train Large Language Models to Explain Human Decisions","abstract":"A central goal of cognitive modeling is to develop models that not only predict human behavior but also provide insight into the underlying cognitive mechanisms. While neural network models trained on large-scale behavioral data often achieve strong predictive performance, they typically fall short in offering interpretable explanations of the cognitive processes they capture. In this work, we explore the potential of pretrained large language models (LLMs) to serve as dual-purpose cognitive models--capable of both accurate prediction and interpretable explanation in natural language. Specifically, we employ reinforcement learning with outcome-based rewards to guide LLMs toward generating explicit reasoning traces for explaining human risky choices. Our findings demonstrate that this approach produces high-quality explanations alongside strong quantitative predictions of human decisions.","authors":["Jian-Qiao Zhu","Hanbo Xie","Dilip Arumugam","Robert C. Wilson","Thomas L. Griffiths"],"url":"https://arxiv.org/abs/2505.11614"}
{"created":"2025-05-20","title":"Steering Risk Preferences in Large Language Models by Aligning Behavioral and Neural Representations","abstract":"Changing the behavior of large language models (LLMs) can be as straightforward as editing the Transformer's residual streams using appropriately constructed \"steering vectors.\" These modifications to internal neural activations, a form of representation engineering, offer an effective and targeted means of influencing model behavior without retraining or fine-tuning the model. But how can such steering vectors be systematically identified? We propose a principled approach for uncovering steering vectors by aligning latent representations elicited through behavioral methods (specifically, Markov chain Monte Carlo with LLMs) with their neural counterparts. To evaluate this approach, we focus on extracting latent risk preferences from LLMs and steering their risk-related outputs using the aligned representations as steering vectors. We show that the resulting steering vectors successfully and reliably modulate LLM outputs in line with the targeted behavior.","authors":["Jian-Qiao Zhu","Haijiang Yan","Thomas L. Griffiths"],"url":"https://arxiv.org/abs/2505.11615"}
{"created":"2025-05-20","title":"Benchmarking Spatiotemporal Reasoning in LLMs and Reasoning Models: Capabilities and Challenges","abstract":"Spatiotemporal reasoning plays a key role in Cyber-Physical Systems (CPS). Despite advances in Large Language Models (LLMs) and Large Reasoning Models (LRMs), their capacity to reason about complex spatiotemporal signals remains underexplored. This paper proposes a hierarchical SpatioTemporal reAsoning benchmaRK, STARK, to systematically evaluate LLMs across three levels of reasoning complexity: state estimation (e.g., predicting field variables, localizing and tracking events in space and time), spatiotemporal reasoning over states (e.g., inferring spatial-temporal relationships), and world-knowledge-aware reasoning that integrates contextual and domain knowledge (e.g., intent prediction, landmark-aware navigation). We curate 26 distinct spatiotemporal tasks with diverse sensor modalities, comprising 14,552 challenges where models answer directly or by Python Code Interpreter. Evaluating 3 LRMs and 8 LLMs, we find LLMs achieve limited success in tasks requiring geometric reasoning (e.g., multilateration or triangulation), particularly as complexity increases. Surprisingly, LRMs show robust performance across tasks with various levels of difficulty, often competing or surpassing traditional first-principle-based methods. Our results show that in reasoning tasks requiring world knowledge, the performance gap between LLMs and LRMs narrows, with some LLMs even surpassing LRMs. However, the LRM o3 model continues to achieve leading performance across all evaluated tasks, a result attributed primarily to the larger size of the reasoning models. STARK motivates future innovations in model architectures and reasoning paradigms for intelligent CPS by providing a structured framework to identify limitations in the spatiotemporal reasoning of LLMs and LRMs.","authors":["Pengrui Quan","Brian Wang","Kang Yang","Liying Han","Mani Srivastava"],"url":"https://arxiv.org/abs/2505.11618"}
{"created":"2025-05-20","title":"Improved Bag-of-Words Image Retrieval with Geometric Constraints for Ground Texture Localization","abstract":"Ground texture localization using a downward-facing camera offers a low-cost, high-precision localization solution that is robust to dynamic environments and requires no environmental modification. We present a significantly improved bag-of-words (BoW) image retrieval system for ground texture localization, achieving substantially higher accuracy for global localization and higher precision and recall for loop closure detection in SLAM. Our approach leverages an approximate $k$-means (AKM) vocabulary with soft assignment, and exploits the consistent orientation and constant scale constraints inherent to ground texture localization. Identifying the different needs of global localization vs. loop closure detection for SLAM, we present both high-accuracy and high-speed versions of our algorithm. We test the effect of each of our proposed improvements through an ablation study and demonstrate our method's effectiveness for both global localization and loop closure detection. With numerous ground texture localization systems already using BoW, our method can readily replace other generic BoW systems in their pipeline and immediately improve their results.","authors":["Aaron Wilhelm","Nils Napp"],"url":"https://arxiv.org/abs/2505.11620"}
{"created":"2025-05-20","title":"A Classical View on Benign Overfitting: The Role of Sample Size","abstract":"Benign overfitting is a phenomenon in machine learning where a model perfectly fits (interpolates) the training data, including noisy examples, yet still generalizes well to unseen data. Understanding this phenomenon has attracted considerable attention in recent years. In this work, we introduce a conceptual shift, by focusing on almost benign overfitting, where models simultaneously achieve both arbitrarily small training and test errors. This behavior is characteristic of neural networks, which often achieve low (but non-zero) training error while still generalizing well. We hypothesize that this almost benign overfitting can emerge even in classical regimes, by analyzing how the interaction between sample size and model complexity enables larger models to achieve both good training fit but still approach Bayes-optimal generalization. We substantiate this hypothesis with theoretical evidence from two case studies: (i) kernel ridge regression, and (ii) least-squares regression using a two-layer fully connected ReLU neural network trained via gradient flow. In both cases, we overcome the strong assumptions often required in prior work on benign overfitting.","authors":["Junhyung Park","Patrick Bloebaum","Shiva Prasad Kasiviswanathan"],"url":"https://arxiv.org/abs/2505.11621"}
{"created":"2025-05-20","title":"Monotone Subsystem Decomposition for Efficient Multi-Objective Robot Design","abstract":"Automating design minimizes errors, accelerates the design process, and reduces cost. However, automating robot design is challenging due to recursive constraints, multiple design objectives, and cross-domain design complexity possibly spanning multiple abstraction layers. Here we look at the problem of component selection, a combinatorial optimization problem in which a designer, given a robot model, must select compatible components from an extensive catalog. The goal is to satisfy high-level task specifications while optimally balancing trade-offs between competing design objectives. In this paper, we extend our previous constraint programming approach to multi-objective design problems and propose the novel technique of monotone subsystem decomposition to efficiently compute a Pareto front of solutions for large-scale problems. We prove that subsystems can be optimized for their Pareto fronts and, under certain conditions, these results can be used to determine a globally optimal Pareto front. Furthermore, subsystems serve as an intuitive design abstraction and can be reused across various design problems. Using an example quadcopter design problem, we compare our method to a linear programming approach and demonstrate our method scales better for large catalogs, solving a multi-objective problem of 10^25 component combinations in seconds. We then expand the original problem and solve a task-oriented, multi-objective design problem to build a fleet of quadcopters to deliver packages. We compute a Pareto front of solutions in seconds where each solution contains an optimal component-level design and an optimal package delivery schedule for each quadcopter.","authors":["Andrew Wilhelm","Nils Napp"],"url":"https://arxiv.org/abs/2505.11624"}
{"created":"2025-05-20","title":"Nearest Neighbor Multivariate Time Series Forecasting","abstract":"Multivariate time series (MTS) forecasting has a wide range of applications in both industry and academia. Recently, spatial-temporal graph neural networks (STGNNs) have gained popularity as MTS forecasting methods. However, current STGNNs can only use the finite length of MTS input data due to the computational complexity. Moreover, they lack the ability to identify similar patterns throughout the entire dataset and struggle with data that exhibit sparsely and discontinuously distributed correlations among variables over an extensive historical period, resulting in only marginal improvements. In this article, we introduce a simple yet effective k-nearest neighbor MTS forecasting ( kNN-MTS) framework, which forecasts with a nearest neighbor retrieval mechanism over a large datastore of cached series, using representations from the MTS model for similarity search. This approach requires no additional training and scales to give the MTS model direct access to the whole dataset at test time, resulting in a highly expressive model that consistently improves performance, and has the ability to extract sparse distributed but similar patterns spanning over multivariables from the entire dataset. Furthermore, a hybrid spatial-temporal encoder (HSTEncoder) is designed for kNN-MTS which can capture both long-term temporal and short-term spatial-temporal dependencies and is shown to provide accurate representation for kNN-MTSfor better forecasting. Experimental results on several real-world datasets show a significant improvement in the forecasting performance of kNN-MTS. The quantitative analysis also illustrates the interpretability and efficiency of kNN-MTS, showing better application prospects and opening up a new path for efficiently using the large dataset in MTS models.","authors":["Huiliang Zhang","Ping Nie","Lijun Sun","Benoit Boulet"],"url":"https://arxiv.org/abs/2505.11625"}
{"created":"2025-05-20","title":"THELMA: Task Based Holistic Evaluation of Large Language Model Applications-RAG Question Answering","abstract":"We propose THELMA (Task Based Holistic Evaluation of Large Language Model Applications), a reference free framework for RAG (Retrieval Augmented generation) based question answering (QA) applications. THELMA consist of six interdependent metrics specifically designed for holistic, fine grained evaluation of RAG QA applications. THELMA framework helps developers and application owners evaluate, monitor and improve end to end RAG QA pipelines without requiring labelled sources or reference responses.We also present our findings on the interplay of the proposed THELMA metrics, which can be interpreted to identify the specific RAG component needing improvement in QA applications.","authors":["Udita Patel","Rutu Mulkar","Jay Roberts","Cibi Chakravarthy Senthilkumar","Sujay Gandhi","Xiaofei Zheng","Naumaan Nayyar","Rafael Castrillo"],"url":"https://arxiv.org/abs/2505.11626"}
{"created":"2025-05-20","title":"Adaptive Robust Optimization with Data-Driven Uncertainty for Enhancing Distribution System Resilience","abstract":"Extreme weather events are placing growing strain on electric power systems, exposing the limitations of purely reactive responses and prompting the need for proactive resilience planning. However, existing approaches often rely on simplified uncertainty models and decouple proactive and reactive decisions, overlooking their critical interdependence. This paper proposes a novel tri-level optimization framework that integrates proactive infrastructure investment, adversarial modeling of spatio-temporal disruptions, and adaptive reactive response. We construct high-probability, distribution-free uncertainty sets using conformal prediction to capture complex and data-scarce outage patterns. To solve the resulting nested decision problem, we derive a bi-level reformulation via strong duality and develop a scalable Benders decomposition algorithm. Experiments on both real and synthetic data demonstrate that our approach consistently outperforms conventional robust and two-stage methods, achieving lower worst-case losses and more efficient resource allocation, especially under tight operational constraints and large-scale uncertainty.","authors":["Shuyi Chen","Shixiang Zhu","Ramteen Sioshansi"],"url":"https://arxiv.org/abs/2505.11627"}
{"created":"2025-05-20","title":"Critique-Guided Distillation: Improving Supervised Fine-tuning via Better Distillation","abstract":"Supervised fine-tuning (SFT) using expert demonstrations often suffer from the imitation problem, where the model learns to reproduce the correct responses without \\emph{understanding} the underlying rationale. To address this limitation, we propose \\textsc{Critique-Guided Distillation (CGD)}, a novel multi-stage framework that integrates teacher model generated \\emph{explanatory critiques} and \\emph{refined responses} into the SFT process. A student model is then trained to map the triplet of prompt, teacher critique, and its own initial response to the corresponding refined teacher response, thereby learning both \\emph{what} to imitate and \\emph{why}. Using entropy-based analysis, we show that \\textsc{CGD} reduces refinement uncertainty and can be interpreted as a Bayesian posterior update. We perform extensive empirical evaluation of \\textsc{CGD}, on variety of benchmark tasks, and demonstrate significant gains on both math (AMC23 +17.5%) and language understanding tasks (MMLU-Pro +6.3%), while successfully mitigating the format drift issues observed in previous critique fine-tuning (CFT) techniques.","authors":["Berkcan Kapusuzoglu","Supriyo Chakraborty","Chia-Hsuan Lee","Sambit Sahu"],"url":"https://arxiv.org/abs/2505.11628"}
{"created":"2025-05-20","title":"Enhancing Network Anomaly Detection with Quantum GANs and Successive Data Injection for Multivariate Time Series","abstract":"Quantum computing may offer new approaches for advancing machine learning, including in complex tasks such as anomaly detection in network traffic. In this paper, we introduce a quantum generative adversarial network (QGAN) architecture for multivariate time-series anomaly detection that leverages variational quantum circuits (VQCs) in combination with a time-window shifting technique, data re-uploading, and successive data injection (SuDaI). The method encodes multivariate time series data as rotation angles. By integrating both data re-uploading and SuDaI, the approach maps classical data into quantum states efficiently, helping to address hardware limitations such as the restricted number of available qubits. In addition, the approach employs an anomaly scoring technique that utilizes both the generator and the discriminator output to enhance the accuracy of anomaly detection. The QGAN was trained using the parameter shift rule and benchmarked against a classical GAN. Experimental results indicate that the quantum model achieves a accuracy high along with high recall and F1-scores in anomaly detection, and attains a lower MSE compared to the classical model. Notably, the QGAN accomplishes this performance with only 80 parameters, demonstrating competitive results with a compact architecture. Tests using a noisy simulator suggest that the approach remains effective under realistic noise-prone conditions.","authors":["Wajdi Hammami","Soumaya Cherkaoui","Shengrui Wang"],"url":"https://arxiv.org/abs/2505.11631"}
{"created":"2025-05-20","title":"Chatting with Papers: A Hybrid Approach Using LLMs and Knowledge Graphs","abstract":"This demo paper reports on a new workflow \\textit{GhostWriter} that combines the use of Large Language Models and Knowledge Graphs (semantic artifacts) to support navigation through collections. Situated in the research area of Retrieval Augmented Generation, this specific workflow details the creation of local and adaptable chatbots. Based on the tool-suite \\textit{EverythingData} at the backend, \\textit{GhostWriter} provides an interface that enables querying and ``chatting'' with a collection. Applied iteratively, the workflow supports the information needs of researchers when interacting with a collection of papers, whether it be to gain an overview, to learn more about a specific concept and its context, and helps the researcher ultimately to refine their research question in a controlled way. We demonstrate the workflow for a collection of articles from the \\textit{method data analysis} journal published by GESIS -- Leibniz-Institute for the Social Sciences. We also point to further application areas.","authors":["Vyacheslav Tykhonov","Han Yang","Philipp Mayr","Jetze Touber","Andrea Scharnhorst"],"url":"https://arxiv.org/abs/2505.11633"}
{"created":"2025-05-20","title":"A Perturbation and Speciation-Based Algorithm for Dynamic Optimization Uninformed of Change","abstract":"Dynamic optimization problems (DOPs) are challenging due to their changing conditions. This requires algorithms to be highly adaptable and efficient in terms of finding rapidly new optimal solutions under changing conditions. Traditional approaches often depend on explicit change detection, which can be impractical or inefficient when the change detection is unreliable or unfeasible. We propose Perturbation and Speciation-Based Particle Swarm Optimization (PSPSO), a robust algorithm for uninformed dynamic optimization without requiring the information of environmental changes. The PSPSO combines speciation-based niching, deactivation, and a newly proposed random perturbation mechanism to handle DOPs. PSPSO leverages a cyclical multi-population framework, strategic resource allocation, and targeted noisy updates, to adapt to dynamic environments. We compare PSPSO with several state-of-the-art algorithms on the Generalized Moving Peaks Benchmark (GMPB), which covers a variety of scenarios, including simple and multi-modal dynamic optimization, frequent and intense changes, and high-dimensional spaces. Our results show that PSPSO outperforms other state-of-the-art uninformed algorithms in all scenarios and leads to competitive results compared to informed algorithms. In particular, PSPSO shows strength in functions with high dimensionality or high frequency of change in the GMPB. The ablation study showed the importance of the random perturbation component.","authors":["Federico Signorelli","Anil Yaman"],"url":"https://arxiv.org/abs/2505.11634"}
{"created":"2025-05-20","title":"The Gaussian-Multinoulli Restricted Boltzmann Machine: A Potts Model Extension of the GRBM","abstract":"Many real-world tasks, from associative memory to symbolic reasoning, demand discrete, structured representations that standard continuous latent models struggle to express naturally. We introduce the Gaussian-Multinoulli Restricted Boltzmann Machine (GM-RBM), a generative energy-based model that extends the Gaussian-Bernoulli RBM (GB-RBM) by replacing binary hidden units with $q$-state Potts variables. This modification enables a combinatorially richer latent space and supports learning over multivalued, interpretable latent concepts. We formally derive GM-RBM's energy function, learning dynamics, and conditional distributions, showing that it preserves tractable inference and training through contrastive divergence. Empirically, we demonstrate that GM-RBMs model complex multimodal distributions more effectively than binary RBMs, outperforming them on tasks involving analogical recall and structured memory. Our results highlight GM-RBMs as a scalable framework for discrete latent inference with enhanced expressiveness and interoperability.","authors":["Nikhil Kapasi","William Whitehead","Luke Theogarajan"],"url":"https://arxiv.org/abs/2505.11635"}
{"created":"2025-05-20","title":"Generalization Guarantees for Learning Branch-and-Cut Policies in Integer Programming","abstract":"Mixed-integer programming (MIP) provides a powerful framework for optimization problems, with Branch-and-Cut (B&amp;C) being the predominant algorithm in state-of-the-art solvers. The efficiency of B&amp;C critically depends on heuristic policies for making sequential decisions, including node selection, cut selection, and branching variable selection. While traditional solvers often employ heuristics with manually tuned parameters, recent approaches increasingly leverage machine learning, especially neural networks, to learn these policies directly from data. A key challenge is to understand the theoretical underpinnings of these learned policies, particularly their generalization performance from finite data. This paper establishes rigorous sample complexity bounds for learning B&amp;C policies where the scoring functions guiding each decision step (node, cut, branch) have a certain piecewise polynomial structure. This structure generalizes the linear models that form the most commonly deployed policies in practice and investigated recently in a foundational series of theoretical works by Balcan et al. Such piecewise polynomial policies also cover the neural network architectures (e.g., using ReLU activations) that have been the focal point of contemporary practical studies. Consequently, our theoretical framework closely reflects the models utilized by practitioners investigating machine learning within B&amp;C, offering a unifying perspective relevant to both established theory and modern empirical research in this area. Furthermore, our theory applies to quite general sequential decision making problems beyond B&amp;C.","authors":["Hongyu Cheng","Amitabh Basu"],"url":"https://arxiv.org/abs/2505.11636"}
{"created":"2025-05-20","title":"Accelerating Natural Gradient Descent for PINNs with Randomized Numerical Linear Algebra","abstract":"Natural Gradient Descent (NGD) has emerged as a promising optimization algorithm for training neural network-based solvers for partial differential equations (PDEs), such as Physics-Informed Neural Networks (PINNs). However, its practical use is often limited by the high computational cost of solving linear systems involving the Gramian matrix. While matrix-free NGD methods based on the conjugate gradient (CG) method avoid explicit matrix inversion, the ill-conditioning of the Gramian significantly slows the convergence of CG. In this work, we extend matrix-free NGD to broader classes of problems than previously considered and propose the use of Randomized Nystr\\\"om preconditioning to accelerate convergence of the inner CG solver. The resulting algorithm demonstrates substantial performance improvements over existing NGD-based methods on a range of PDE problems discretized using neural networks.","authors":["Ivan Bioli","Carlo Marcati","Giancarlo Sangalli"],"url":"https://arxiv.org/abs/2505.11638"}
{"created":"2025-05-20","title":"BandRC: Band Shifted Raised Cosine Activated Implicit Neural Representations","abstract":"In recent years, implicit neural representations(INRs) have gained popularity in the computer vision community. This is mainly due to the strong performance of INRs in many computer vision tasks. These networks can extract a continuous signal representation given a discrete signal representation. In previous studies, it has been repeatedly shown that INR performance has a strong correlation with the activation functions used in its multilayer perceptrons. Although numerous activation functions have been proposed that are competitive with one another, they share some common set of challenges such as spectral bias(Lack of sensitivity to high-frequency content in signals), limited robustness to signal noise and difficulties in simultaneous capturing both local and global features. and furthermore, the requirement for manual parameter tuning. To address these issues, we introduce a novel activation function, Band Shifted Raised Cosine Activated Implicit Neural Networks \\textbf{(BandRC)} tailored to enhance signal representation capacity further. We also incorporate deep prior knowledge extracted from the signal to adjust the activation functions through a task-specific model. Through a mathematical analysis and a series of experiments which include image reconstruction (with a +8.93 dB PSNR improvement over the nearest counterpart), denoising (with a +0.46 dB increase in PSNR), super-resolution (with a +1.03 dB improvement over the nearest State-Of-The-Art (SOTA) method for 6X super-resolution), inpainting, and 3D shape reconstruction we demonstrate the dominance of BandRC over existing state of the art activation functions.","authors":["Pandula Thennakoon","Avishka Ranasinghe","Mario De Silva","Buwaneka Epakanda","Roshan Godaliyadda","Parakrama Ekanayake","Vijitha Herath"],"url":"https://arxiv.org/abs/2505.11640"}
{"created":"2025-05-20","title":"PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks Through Mutual Reasoning","abstract":"Multi-agent systems leverage advanced AI models as autonomous agents that interact, cooperate, or compete to complete complex tasks across applications such as robotics and traffic management. Despite their growing importance, safety in multi-agent systems remains largely underexplored, with most research focusing on single AI models rather than interacting agents. This work investigates backdoor vulnerabilities in multi-agent systems and proposes a defense mechanism based on agent interactions. By leveraging reasoning abilities, each agent evaluates responses from others to detect illogical reasoning processes, which indicate poisoned agents. Experiments on LLM-based multi-agent systems, including ChatGPT series and Llama 3, demonstrate the effectiveness of the proposed method, achieving high accuracy in identifying poisoned agents while minimizing false positives on clean agents. We believe this work provides insights into multi-agent system safety and contributes to the development of robust, trustworthy AI interactions.","authors":["Falong Fan","Xi Li"],"url":"https://arxiv.org/abs/2505.11642"}
{"created":"2025-05-20","title":"Can an Easy-to-Hard Curriculum Make Reasoning Emerge in Small Language Models? Evidence from a Four-Stage Curriculum on GPT-2","abstract":"We demonstrate that a developmentally ordered curriculum markedly improves reasoning transparency and sample-efficiency in small language models (SLMs). Concretely, we train Cognivolve, a 124 M-parameter GPT-2 model, on a four-stage syllabus that ascends from lexical matching to multi-step symbolic inference and then evaluate it without any task-specific fine-tuning. Cognivolve reaches target accuracy in half the optimization steps of a single-phase baseline, activates an order-of-magnitude more gradient-salient reasoning heads, and shifts those heads toward deeper layers, yielding higher-entropy attention that balances local and long-range context. The same curriculum applied out of order or with optimizer resets fails to reproduce these gains, confirming that progression--not extra compute--drives the effect. We also identify open challenges: final-answer success still lags a conventional run by about 30%, and our saliency probe under-detects verbal-knowledge heads in the hardest stage, suggesting directions for mixed-stage fine-tuning and probe expansion.","authors":["Xiang Fu"],"url":"https://arxiv.org/abs/2505.11643"}
{"created":"2025-05-20","title":"Urban Representation Learning for Fine-grained Economic Mapping: A Semi-supervised Graph-based Approach","abstract":"Fine-grained economic mapping through urban representation learning has emerged as a crucial tool for evidence-based economic decisions. While existing methods primarily rely on supervised or unsupervised approaches, they often overlook semi-supervised learning in data-scarce scenarios and lack unified multi-task frameworks for comprehensive sectoral economic analysis. To address these gaps, we propose SemiGTX, an explainable semi-supervised graph learning framework for sectoral economic mapping. The framework is designed with dedicated fusion encoding modules for various geospatial data modalities, seamlessly integrating them into a cohesive graph structure. It introduces a semi-information loss function that combines spatial self-supervision with locally masked supervised regression, enabling more informative and effective region representations. Through multi-task learning, SemiGTX concurrently maps GDP across primary, secondary, and tertiary sectors within a unified model. Extensive experiments conducted in the Pearl River Delta region of China demonstrate the model's superior performance compared to existing methods, achieving R2 scores of 0.93, 0.96, and 0.94 for the primary, secondary and tertiary sectors, respectively. Cross-regional experiments in Beijing and Chengdu further illustrate its generality. Systematic analysis reveals how different data modalities influence model predictions, enhancing explainability while providing valuable insights for regional development planning. This representation learning framework advances regional economic monitoring through diverse urban data integration, providing a robust foundation for precise economic forecasting.","authors":["Jinzhou Cao","Xiangxu Wang","Jiashi Chen","Wei Tu","Zhenhui Li","Xindong Yang","Tianhong Zhao","Qingquan Li"],"url":"https://arxiv.org/abs/2505.11645"}
{"created":"2025-05-20","title":"FLOW-BENCH: Towards Conversational Generation of Enterprise Workflows","abstract":"Business process automation (BPA) that leverages Large Language Models (LLMs) to convert natural language (NL) instructions into structured business process artifacts is becoming a hot research topic. This paper makes two technical contributions -- (i) FLOW-BENCH, a high quality dataset of paired natural language instructions and structured business process definitions to evaluate NL-based BPA tools, and support bourgeoning research in this area, and (ii) FLOW-GEN, our approach to utilize LLMs to translate natural language into an intermediate representation with Python syntax that facilitates final conversion into widely adopted business process definition languages, such as BPMN and DMN. We bootstrap FLOW-BENCH by demonstrating how it can be used to evaluate the components of FLOW-GEN across eight LLMs of varying sizes. We hope that FLOW-GEN and FLOW-BENCH catalyze further research in BPA making it more accessible to novice and expert users.","authors":["Evelyn Duesterwald","Siyu Huo","Vatche Isahagian","K. R. Jayaram","Ritesh Kumar","Vinod Muthusamy","Punleuk Oum","Debashish Saha","Gegi Thomas","Praveen Venkateswaran"],"url":"https://arxiv.org/abs/2505.11646"}
{"created":"2025-05-20","title":"Joint Graph Estimation and Signal Restoration for Robust Federated Learning","abstract":"We propose a robust aggregation method for model parameters in federated learning (FL) under noisy communications. FL is a distributed machine learning paradigm in which a central server aggregates local model parameters from multiple clients. These parameters are often noisy and/or have missing values during data collection, training, and communication between the clients and server. This may cause a considerable drop in model accuracy. To address this issue, we learn a graph that represents pairwise relationships between model parameters of the clients during aggregation. We realize it with a joint problem of graph learning and signal (i.e., model parameters) restoration. The problem is formulated as a difference-of-convex (DC) optimization, which is efficiently solved via a proximal DC algorithm. Experimental results on MNIST and CIFAR-10 datasets show that the proposed method outperforms existing approaches by up to $2$--$5\\%$ in classification accuracy under biased data distributions and noisy conditions.","authors":["Tsutahiro Fukuhara","Junya Hara","Hiroshi Higashi","Yuichi Tanaka"],"url":"https://arxiv.org/abs/2505.11648"}
{"created":"2025-05-20","title":"Illusions of Intimacy: Emotional Attachment and Emerging Psychological Risks in Human-AI Relationships","abstract":"Emotionally responsive social chatbots, such as those produced by Replika and Character.AI, increasingly serve as companions that offer empathy, support, and entertainment. While these systems appear to meet fundamental human needs for connection, they raise concerns about how artificial intimacy affects emotional regulation, well-being, and social norms. Prior research has focused on user perceptions or clinical contexts but lacks large-scale, real-world analysis of how these interactions unfold. This paper addresses that gap by analyzing over 30K user-shared conversations with social chatbots to examine the emotional dynamics of human-AI relationships. Using computational methods, we identify patterns of emotional mirroring and synchrony that closely resemble how people build emotional connections. Our findings show that users-often young, male, and prone to maladaptive coping styles-engage in parasocial interactions that range from affectionate to abusive. Chatbots consistently respond in emotionally consistent and affirming ways. In some cases, these dynamics resemble toxic relationship patterns, including emotional manipulation and self-harm. These findings highlight the need for guardrails, ethical design, and public education to preserve the integrity of emotional connection in an age of artificial companionship.","authors":["Minh Duc Chu","Patrick Gerard","Kshitij Pawar","Charles Bickham","Kristina Lerman"],"url":"https://arxiv.org/abs/2505.11649"}
{"created":"2025-05-20","title":"MIRACL-VISION: A Large, multilingual, visual document retrieval benchmark","abstract":"Document retrieval is an important task for search and Retrieval-Augmented Generation (RAG) applications. Large Language Models (LLMs) have contributed to improving the accuracy of text-based document retrieval. However, documents with complex layout and visual elements like tables, charts and infographics are not perfectly represented in textual format. Recently, image-based document retrieval pipelines have become popular, which use visual large language models (VLMs) to retrieve relevant page images given a query. Current evaluation benchmarks on visual document retrieval are limited, as they primarily focus only English language, rely on synthetically generated questions and offer a small corpus size. Therefore, we introduce MIRACL-VISION, a multilingual visual document retrieval evaluation benchmark. MIRACL-VISION covers 18 languages, and is an extension of the MIRACL dataset, a popular benchmark to evaluate text-based multilingual retrieval pipelines. MIRACL was built using a human-intensive annotation process to generate high-quality questions. In order to reduce MIRACL-VISION corpus size to make evaluation more compute friendly while keeping the datasets challenging, we have designed a method for eliminating the \"easy\" negatives from the corpus. We conducted extensive experiments comparing MIRACL-VISION with other benchmarks, using popular public text and image models. We observe a gap in state-of-the-art VLM-based embedding models on multilingual capabilities, with up to 59.7% lower retrieval accuracy than a text-based retrieval models. Even for the English language, the visual models retrieval accuracy is 12.1% lower compared to text-based models. MIRACL-VISION is a challenging, representative, multilingual evaluation benchmark for visual retrieval pipelines and will help the community build robust models for document retrieval.","authors":["Radek Osmulsk","Gabriel de Souza P. Moreira","Ronay Ak","Mengyao Xu","Benedikt Schifferer","Even Oldridge"],"url":"https://arxiv.org/abs/2505.11651"}
{"created":"2025-05-20","title":"UrbanMind: Urban Dynamics Prediction with Multifaceted Spatial-Temporal Large Language Models","abstract":"Understanding and predicting urban dynamics is crucial for managing transportation systems, optimizing urban planning, and enhancing public services. While neural network-based approaches have achieved success, they often rely on task-specific architectures and large volumes of data, limiting their ability to generalize across diverse urban scenarios. Meanwhile, Large Language Models (LLMs) offer strong reasoning and generalization capabilities, yet their application to spatial-temporal urban dynamics remains underexplored. Existing LLM-based methods struggle to effectively integrate multifaceted spatial-temporal data and fail to address distributional shifts between training and testing data, limiting their predictive reliability in real-world applications. To bridge this gap, we propose UrbanMind, a novel spatial-temporal LLM framework for multifaceted urban dynamics prediction that ensures both accurate forecasting and robust generalization. At its core, UrbanMind introduces Muffin-MAE, a multifaceted fusion masked autoencoder with specialized masking strategies that capture intricate spatial-temporal dependencies and intercorrelations among multifaceted urban dynamics. Additionally, we design a semantic-aware prompting and fine-tuning strategy that encodes spatial-temporal contextual details into prompts, enhancing LLMs' ability to reason over spatial-temporal patterns. To further improve generalization, we introduce a test time adaptation mechanism with a test data reconstructor, enabling UrbanMind to dynamically adjust to unseen test data by reconstructing LLM-generated embeddings. Extensive experiments on real-world urban datasets across multiple cities demonstrate that UrbanMind consistently outperforms state-of-the-art baselines, achieving high accuracy and robust generalization, even in zero-shot settings.","authors":["Yuhang Liu","Yingxue Zhang","Xin Zhang","Ling Tian","Xu Zheng","Yanhua Li","Jun Luo"],"url":"https://arxiv.org/abs/2505.11654"}
{"created":"2025-05-20","title":"Learning from Less: Guiding Deep Reinforcement Learning with Differentiable Symbolic Planning","abstract":"When tackling complex problems, humans naturally break them down into smaller, manageable subtasks and adjust their initial plans based on observations. For instance, if you want to make coffee at a friend's place, you might initially plan to grab coffee beans, go to the coffee machine, and pour them into the machine. Upon noticing that the machine is full, you would skip the initial steps and proceed directly to brewing. In stark contrast, state of the art reinforcement learners, such as Proximal Policy Optimization (PPO), lack such prior knowledge and therefore require significantly more training steps to exhibit comparable adaptive behavior. Thus, a central research question arises: \\textit{How can we enable reinforcement learning (RL) agents to have similar ``human priors'', allowing the agent to learn with fewer training interactions?} To address this challenge, we propose differentiable symbolic planner (Dylan), a novel framework that integrates symbolic planning into Reinforcement Learning. Dylan serves as a reward model that dynamically shapes rewards by leveraging human priors, guiding agents through intermediate subtasks, thus enabling more efficient exploration. Beyond reward shaping, Dylan can work as a high level planner that composes primitive policies to generate new behaviors while avoiding common symbolic planner pitfalls such as infinite execution loops. Our experimental evaluations demonstrate that Dylan significantly improves RL agents' performance and facilitates generalization to unseen tasks.","authors":["Zihan Ye","Oleg Arenz","Kristian Kersting"],"url":"https://arxiv.org/abs/2505.11661"}
{"created":"2025-05-20","title":"Adaptive Ergodic Search with Energy-Aware Scheduling for Persistent Multi-Robot Missions","abstract":"Autonomous robots are increasingly deployed for long-term information-gathering tasks, which pose two key challenges: planning informative trajectories in environments that evolve across space and time, and ensuring persistent operation under energy constraints. This paper presents a unified framework, mEclares, that addresses both challenges through adaptive ergodic search and energy-aware scheduling in multi-robot systems. Our contributions are two-fold: (1) we model real-world variability using stochastic spatiotemporal environments, where the underlying information evolves unpredictably due to process uncertainty. To guide exploration, we construct a target information spatial distribution (TISD) based on clarity, a metric that captures the decay of information in the absence of observations and highlights regions of high uncertainty; and (2) we introduce Robustmesch (Rmesch), an online scheduling method that enables persistent operation by coordinating rechargeable robots sharing a single mobile charging station. Unlike prior work, our approach avoids reliance on preplanned schedules, static or dedicated charging stations, and simplified robot dynamics. Instead, the scheduler supports general nonlinear models, accounts for uncertainty in the estimated position of the charging station, and handles central node failures. The proposed framework is validated through real-world hardware experiments, and feasibility guarantees are provided under specific assumptions.","authors":["Kaleb Ben Naveed","Devansh R. Agrawal","Rahul Kumar","Dimitra Panagou"],"url":"https://arxiv.org/abs/2505.11663"}
{"created":"2025-05-20","title":"A Local Polyak-Lojasiewicz and Descent Lemma of Gradient Descent For Overparametrized Linear Models","abstract":"Most prior work on the convergence of gradient descent (GD) for overparameterized neural networks relies on strong assumptions on the step size (infinitesimal), the hidden-layer width (infinite), or the initialization (large, spectral, balanced). Recent efforts to relax these assumptions focus on two-layer linear networks trained with the squared loss. In this work, we derive a linear convergence rate for training two-layer linear neural networks with GD for general losses and under relaxed assumptions on the step size, width, and initialization. A key challenge in deriving this result is that classical ingredients for deriving convergence rates for nonconvex problems, such as the Polyak-{\\L}ojasiewicz (PL) condition and Descent Lemma, do not hold globally for overparameterized neural networks. Here, we prove that these two conditions hold locally with local constants that depend on the weights. Then, we provide bounds on these local constants, which depend on the initialization of the weights, the current loss, and the global PL and smoothness constants of the non-overparameterized model. Based on these bounds, we derive a linear convergence rate for GD. Our convergence analysis not only improves upon prior results but also suggests a better choice for the step size, as verified through our numerical experiments.","authors":["Ziqing Xu","Hancheng Min","Salma Tarmoun","Enrique Mallada","Rene Vidal"],"url":"https://arxiv.org/abs/2505.11664"}
{"created":"2025-05-20","title":"Multilingual Prompt Engineering in Large Language Models: A Survey Across NLP Tasks","abstract":"Large language models (LLMs) have demonstrated impressive performance across a wide range of Natural Language Processing (NLP) tasks. However, ensuring their effectiveness across multiple languages presents unique challenges. Multilingual prompt engineering has emerged as a key approach to enhance LLMs' capabilities in diverse linguistic settings without requiring extensive parameter re-training or fine-tuning. With growing interest in multilingual prompt engineering over the past two to three years, researchers have explored various strategies to improve LLMs' performance across languages and NLP tasks. By crafting structured natural language prompts, researchers have successfully extracted knowledge from LLMs across different languages, making these techniques an accessible pathway for a broader audience, including those without deep expertise in machine learning, to harness the capabilities of LLMs. In this paper, we survey and categorize different multilingual prompting techniques based on the NLP tasks they address across a diverse set of datasets that collectively span around 250 languages. We further highlight the LLMs employed, present a taxonomy of approaches and discuss potential state-of-the-art (SoTA) methods for specific multilingual datasets. Additionally, we derive a range of insights across language families and resource levels (high-resource vs. low-resource), including analyses such as the distribution of NLP tasks by language resource type and the frequency of prompting methods across different language families. Our survey reviews 36 research papers covering 39 prompting techniques applied to 30 multilingual NLP tasks, with the majority of these studies published in the last two years.","authors":["Shubham Vatsal","Harsh Dubey","Aditi Singh"],"url":"https://arxiv.org/abs/2505.11665"}
{"created":"2025-05-20","title":"DesignFromX: Empowering Consumer-Driven Design Space Exploration through Feature Composition of Referenced Products","abstract":"Industrial products are designed to satisfy the needs of consumers. The rise of generative artificial intelligence (GenAI) enables consumers to easily modify a product by prompting a generative model, opening up opportunities to incorporate consumers in exploring the product design space. However, consumers often struggle to articulate their preferred product features due to their unfamiliarity with terminology and their limited understanding of the structure of product features. We present DesignFromX, a system that empowers consumer-driven design space exploration by helping consumers to design a product based on their preferences. Leveraging an effective GenAI-based framework, the system allows users to easily identify design features from product images and compose those features to generate conceptual images and 3D models of a new product. A user study with 24 participants demonstrates that DesignFromX lowers the barriers and frustration for consumer-driven design space explorations by enhancing both engagement and enjoyment for the participants.","authors":["Runlin Duan","Chenfei Zhu","Yuzhao Chen","Yichen Hu","Jingyu Shi","Karthik Ramani"],"url":"https://arxiv.org/abs/2505.11666"}
{"created":"2025-05-20","title":"Data-based control of Logical Networks","abstract":"In recent years, data-driven approaches have become increasingly pervasive across all areas of control engineering. However, the applications of data-based techniques to Boolean Control Networks (BCNs) are still very limited. In this paper we aim to fill this gap, by exploring the possibility of solving three fundamental control problems, i.e., state feedback stabilization, safe control and output regulation, for a BCN, leveraging only a limited amount of data generated by the network, without knowing or identifying its model.","authors":["Giorgia Disar\\`o","Maria Elena Valcher"],"url":"https://arxiv.org/abs/2505.11667"}
{"created":"2025-05-20","title":"OT Score: An OT based Confidence Score for Unsupervised Domain Adaptation","abstract":"We address the computational and theoretical limitations of existing distributional alignment methods for unsupervised domain adaptation (UDA), particularly regarding the estimation of classification performance and confidence without target labels. Current theoretical frameworks for these methods often yield computationally intractable quantities and fail to adequately reflect the properties of the alignment algorithms employed. To overcome these challenges, we introduce the Optimal Transport (OT) score, a confidence metric derived from a novel theoretical analysis that exploits the flexibility of decision boundaries induced by Semi-Discrete Optimal Transport alignment. The proposed OT score is intuitively interpretable, theoretically rigorous, and computationally efficient. It provides principled uncertainty estimates for any given set of target pseudo-labels without requiring model retraining, and can flexibly adapt to varying degrees of available source information. Experimental results on standard UDA benchmarks demonstrate that classification accuracy consistently improves by identifying and removing low-confidence predictions, and that OT score significantly outperforms existing confidence metrics across diverse adaptation scenarios.","authors":["Yiming Zhang","Sitong Liu","Alex Cloninger"],"url":"https://arxiv.org/abs/2505.11669"}
{"created":"2025-05-20","title":"Terminators: Terms of Service Parsing and Auditing Agents","abstract":"Terms of Service (ToS) documents are often lengthy and written in complex legal language, making them difficult for users to read and understand. To address this challenge, we propose Terminators, a modular agentic framework that leverages large language models (LLMs) to parse and audit ToS documents. Rather than treating ToS understanding as a black-box summarization problem, Terminators breaks the task down to three interpretable steps: term extraction, verification, and accountability planning. We demonstrate the effectiveness of our method on the OpenAI ToS using GPT-4o, highlighting strategies to minimize hallucinations and maximize auditability. Our results suggest that structured, agent-based LLM workflows can enhance both the usability and enforceability of complex legal documents. By translating opaque terms into actionable, verifiable components, Terminators promotes ethical use of web content by enabling greater transparency, empowering users to understand their digital rights, and supporting automated policy audits for regulatory or civic oversight.","authors":["Maruf Ahmed Mridul","Inwon Kang","Oshani Seneviratne"],"url":"https://arxiv.org/abs/2505.11672"}
{"created":"2025-05-20","title":"DPSeg: Dual-Prompt Cost Volume Learning for Open-Vocabulary Semantic Segmentation","abstract":"Open-vocabulary semantic segmentation aims to segment images into distinct semantic regions for both seen and unseen categories at the pixel level. Current methods utilize text embeddings from pre-trained vision-language models like CLIP but struggle with the inherent domain gap between image and text embeddings, even after extensive alignment during training. Additionally, relying solely on deep text-aligned features limits shallow-level feature guidance, which is crucial for detecting small objects and fine details, ultimately reducing segmentation accuracy. To address these limitations, we propose a dual prompting framework, DPSeg, for this task. Our approach combines dual-prompt cost volume generation, a cost volume-guided decoder, and a semantic-guided prompt refinement strategy that leverages our dual prompting scheme to mitigate alignment issues in visual prompt generation. By incorporating visual embeddings from a visual prompt encoder, our approach reduces the domain gap between text and image embeddings while providing multi-level guidance through shallow features. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art approaches on multiple public datasets.","authors":["Ziyu Zhao","Xiaoguang Li","Linjia Shi","Nasrin Imanpour","Song Wang"],"url":"https://arxiv.org/abs/2505.11676"}
{"created":"2025-05-20","title":"Enhancing Code Quality with Generative AI: Boosting Developer Warning Compliance","abstract":"Programmers have long ignored warnings, especially those generated by static analysis tools, due to the potential for false-positives. In some cases, warnings may be indicative of larger issues, but programmers may not understand how a seemingly unimportant warning can grow into a vulnerability. Because these messages tend to be long and confusing, programmers tend to ignore them if they do not cause readily identifiable issues. Large language models can simplify these warnings, explain the gravity of important warnings, and suggest potential fixes to increase developer compliance with fixing warnings.","authors":["Hansen Chang","Christian DeLozier"],"url":"https://arxiv.org/abs/2505.11677"}
{"created":"2025-05-20","title":"Fairness-Utility Trade-off via Wasserstein Projection","abstract":"Ensuring fairness in data-driven decision-making is a critical concern, but existing fairness constraints often involve trade-offs with overall utility. We propose a fairness framework that enforces strong demographic parity-related fairness criteria (with $\\epsilon$-tolerance) in propensity score allocation while guaranteeing a minimum total utility. This approach balances equity and utility by calibrating propensity scores to satisfy fairness criteria and optimizing outcomes without incurring unacceptable losses in performance. Grounded in a binary treatment and sensitive attribute setting under causal fairness setup, our method provides a principled mechanism to address fairness while transparently managing associated economic and social costs, offering a practical approach for designing equitable policies in diverse decision-making contexts. Building on this, we provide theoretical guarantee for our proposed utility-constrained fairness evaluation framework, and we formalize a hypothesis testing framework to help practitioners assess whether the desired fairness-utility trade-off is achieved.","authors":["Yan Chen","Zheng Tan","Jose Blanchet","Hanzhang Qin"],"url":"https://arxiv.org/abs/2505.11678"}
{"created":"2025-05-20","title":"Ambiguity Resolution in Text-to-Structured Data Mapping","abstract":"Ambiguity in natural language is a significant obstacle for achieving accurate text to structured data mapping through large language models (LLMs), which affects the performance of tasks such as mapping text to agentic tool calling and text-to-SQL queries. Existing methods of ambiguity handling either exploit ReACT framework to produce the correct mapping through trial and error, or supervised fine tuning to guide models to produce a biased mapping to improve certain tasks. In this paper, we adopt a different approach that characterizes the representation difference of ambiguous text in the latent space and leverage the difference to identify ambiguity before mapping them to structured data. To detect ambiguity of a sentence, we focused on the relationship between ambiguous questions and their interpretations and what cause the LLM ignore multiple interpretations. Different to the distance calculated by dense embedding vectors, we utilize the observation that ambiguity is caused by concept missing in latent space of LLM to design a new distance measurement, computed through the path kernel by the integral of gradient values for each concepts from sparse-autoencoder (SAE) under each state. We identify patterns to distinguish ambiguous questions with this measurement. Based on our observation, We propose a new framework to improve the performance of LLMs on ambiguous agentic tool calling through missing concepts prediction.","authors":["Zhibo Hu","Chen Wang","Yanfeng Shu","Hye-Young Paik","Liming Zhu"],"url":"https://arxiv.org/abs/2505.11679"}
{"created":"2025-05-20","title":"Grounded Task Axes: Zero-Shot Semantic Skill Generalization via Task-Axis Controllers and Visual Foundation Models","abstract":"Transferring skills between different objects remains one of the core challenges of open-world robot manipulation. Generalization needs to take into account the high-level structural differences between distinct objects while still maintaining similar low-level interaction control. In this paper, we propose an example-based zero-shot approach to skill transfer. Rather than treating skills as atomic, we decompose skills into a prioritized list of grounded task-axis (GTA) controllers. Each GTAC defines an adaptable controller, such as a position or force controller, along an axis. Importantly, the GTACs are grounded in object key points and axes, e.g., the relative position of a screw head or the axis of its shaft. Zero-shot transfer is thus achieved by finding semantically-similar grounding features on novel target objects. We achieve this example-based grounding of the skills through the use of foundation models, such as SD-DINO, that can detect semantically similar keypoints of objects. We evaluate our framework on real-robot experiments, including screwing, pouring, and spatula scraping tasks, and demonstrate robust and versatile controller transfer for each.","authors":["M. Yunus Seker","Shobhit Aggarwal","Oliver Kroemer"],"url":"https://arxiv.org/abs/2505.11680"}
{"created":"2025-05-20","title":"Mollifier Layers: Enabling Efficient High-Order Derivatives in Inverse PDE Learning","abstract":"Parameter estimation in inverse problems involving partial differential equations (PDEs) underpins modeling across scientific disciplines, especially when parameters vary in space or time. Physics-informed Machine Learning (PhiML) integrates PDE constraints into deep learning, but prevailing approaches depend on recursive automatic differentiation (autodiff), which produces inaccurate high-order derivatives, inflates memory usage, and underperforms in noisy settings. We propose Mollifier Layers, a lightweight, architecture-agnostic module that replaces autodiff with convolutional operations using analytically defined mollifiers. This reframing of derivative computation as smoothing integration enables efficient, noise-robust estimation of high-order derivatives directly from network outputs. Mollifier Layers attach at the output layer and require no architectural modifications. We compare them with three distinct architectures and benchmark performance across first-, second-, and fourth-order PDEs -- including Langevin dynamics, heat diffusion, and reaction-diffusion systems -- observing significant improvements in memory efficiency, training time and accuracy for parameter recovery across tasks. To demonstrate practical relevance, we apply Mollifier Layers to infer spatially varying epigenetic reaction rates from super-resolution chromatin imaging data -- a real-world inverse problem with biomedical significance. Our results establish Mollifier Layers as an efficient and scalable tool for physics-constrained learning.","authors":["Ananyae Kumar Bhartari","Vinayak Vinayak","Vivek B Shenoy"],"url":"https://arxiv.org/abs/2505.11682"}
{"created":"2025-05-20","title":"Evaluating Design Decisions for Dual Encoder-based Entity Disambiguation","abstract":"Entity disambiguation (ED) is the task of linking mentions in text to corresponding entries in a knowledge base. Dual Encoders address this by embedding mentions and label candidates in a shared embedding space and applying a similarity metric to predict the correct label. In this work, we focus on evaluating key design decisions for Dual Encoder-based ED, such as its loss function, similarity metric, label verbalization format, and negative sampling strategy. We present the resulting model VerbalizED, a document-level Dual Encoder model that includes contextual label verbalizations and efficient hard negative sampling. Additionally, we explore an iterative prediction variant that aims to improve the disambiguation of challenging data points. Comprehensive experiments on AIDA-Yago validate the effectiveness of our approach, offering insights into impactful design choices that result in a new State-of-the-Art system on the ZELDA benchmark.","authors":["Susanna R\\\"ucker","Alan Akbik"],"url":"https://arxiv.org/abs/2505.11683"}
{"created":"2025-05-20","title":"Designing for Constructive Civic Communication: A Framework for Human-AI Collaboration in Community Engagement Processes","abstract":"Community engagement processes form a critical foundation of democratic governance, yet frequently struggle with resource constraints, sensemaking challenges, and barriers to inclusive participation. These processes rely on constructive communication between public leaders and community organizations characterized by understanding, trust, respect, legitimacy, and agency. As artificial intelligence (AI) technologies become increasingly integrated into civic contexts, they offer promising capabilities to streamline resource-intensive workflows, reveal new insights in community feedback, translate complex information into accessible formats, and facilitate reflection across social divides. However, these same systems risk undermining democratic processes through accuracy issues, transparency gaps, bias amplification, and threats to human agency. In this paper, we examine how human-AI collaboration might address these risks and transform civic communication dynamics by identifying key communication pathways and proposing design considerations that maintain a high level of control over decision-making for both public leaders and communities while leveraging computer automation. By thoughtfully integrating AI to amplify human connection and understanding while safeguarding agency, community engagement processes can utilize AI to promote more constructive communication in democratic governance.","authors":["Cassandra Overney"],"url":"https://arxiv.org/abs/2505.11684"}
{"created":"2025-05-20","title":"Second SIGIR Workshop on Simulations for Information Access (Sim4IA 2025)","abstract":"Simulations in information access (IA) have recently gained interest, as shown by various tutorials and workshops around that topic. Simulations can be key contributors to central IA research and evaluation questions, especially around interactive settings when real users are unavailable, or their participation is impossible due to ethical reasons. In addition, simulations in IA can help contribute to a better understanding of users, reduce complexity of evaluation experiments, and improve reproducibility. Building on recent developments in methods and toolkits, the second iteration of our Sim4IA workshop aims to again bring together researchers and practitioners to form an interactive and engaging forum for discussions on the future perspectives of the field. An additional aim is to plan an upcoming TREC/CLEF campaign.","authors":["Philipp Schaer","Christin Katharina Kreutz","Krisztian Balog","Timo Breuer","Andreas Konstantin Kruff"],"url":"https://arxiv.org/abs/2505.11687"}
{"created":"2025-05-20","title":"Automatic Speech Recognition for African Low-Resource Languages: Challenges and Future Directions","abstract":"Automatic Speech Recognition (ASR) technologies have transformed human-computer interaction; however, low-resource languages in Africa remain significantly underrepresented in both research and practical applications. This study investigates the major challenges hindering the development of ASR systems for these languages, which include data scarcity, linguistic complexity, limited computational resources, acoustic variability, and ethical concerns surrounding bias and privacy. The primary goal is to critically analyze these barriers and identify practical, inclusive strategies to advance ASR technologies within the African context. Recent advances and case studies emphasize promising strategies such as community-driven data collection, self-supervised and multilingual learning, lightweight model architectures, and techniques that prioritize privacy. Evidence from pilot projects involving various African languages showcases the feasibility and impact of customized solutions, which encompass morpheme-based modeling and domain-specific ASR applications in sectors like healthcare and education. The findings highlight the importance of interdisciplinary collaboration and sustained investment to tackle the distinct linguistic and infrastructural challenges faced by the continent. This study offers a progressive roadmap for creating ethical, efficient, and inclusive ASR systems that not only safeguard linguistic diversity but also improve digital accessibility and promote socioeconomic participation for speakers of African languages.","authors":["Sukairaj Hafiz Imam","Babangida Sani","Dawit Ketema Gete","Bedru Yimam Ahamed","Ibrahim Said Ahmad","Idris Abdulmumin","Seid Muhie Yimam","Muhammad Yahuza Bello","Shamsuddeen Hassan Muhammad"],"url":"https://arxiv.org/abs/2505.11690"}
{"created":"2025-05-20","title":"The Geometry of ReLU Networks through the ReLU Transition Graph","abstract":"We develop a novel theoretical framework for analyzing ReLU neural networks through the lens of a combinatorial object we term the ReLU Transition Graph (RTG). In this graph, each node corresponds to a linear region induced by the network's activation patterns, and edges connect regions that differ by a single neuron flip. Building on this structure, we derive a suite of new theoretical results connecting RTG geometry to expressivity, generalization, and robustness. Our contributions include tight combinatorial bounds on RTG size and diameter, a proof of RTG connectivity, and graph-theoretic interpretations of VC-dimension. We also relate entropy and average degree of the RTG to generalization error. Each theoretical result is rigorously validated via carefully controlled experiments across varied network depths, widths, and data regimes. This work provides the first unified treatment of ReLU network structure via graph theory and opens new avenues for compression, regularization, and complexity control rooted in RTG analysis.","authors":["Sahil Rajesh Dhayalkar"],"url":"https://arxiv.org/abs/2505.11692"}
{"created":"2025-05-20","title":"Hierarchical Bracketing Encodings for Dependency Parsing as Tagging","abstract":"We present a family of encodings for sequence labeling dependency parsing, based on the concept of hierarchical bracketing. We prove that the existing 4-bit projective encoding belongs to this family, but it is suboptimal in the number of labels used to encode a tree. We derive an optimal hierarchical bracketing, which minimizes the number of symbols used and encodes projective trees using only 12 distinct labels (vs. 16 for the 4-bit encoding). We also extend optimal hierarchical bracketing to support arbitrary non-projectivity in a more compact way than previous encodings. Our new encodings yield competitive accuracy on a diverse set of treebanks.","authors":["Ana Ezquerro","David Vilares","Anssi Yli-Jyr\\\"a","Carlos G\\'omez-Rodr\\'iguez"],"url":"https://arxiv.org/abs/2505.11693"}
{"created":"2025-05-20","title":"Neural Networks as Universal Finite-State Machines: A Constructive Deterministic Finite Automaton Theory","abstract":"We present a complete theoretical and empirical framework establishing feedforward neural networks as universal finite-state machines (N-FSMs). Our results prove that finite-depth ReLU and threshold networks can exactly simulate deterministic finite automata (DFAs) by unrolling state transitions into depth-wise neural layers, with formal characterizations of required depth, width, and state compression. We demonstrate that DFA transitions are linearly separable, binary threshold activations allow exponential compression, and Myhill-Nerode equivalence classes can be embedded into continuous latent spaces while preserving separability. We also formalize the expressivity boundary: fixed-depth feedforward networks cannot recognize non-regular languages requiring unbounded memory. Unlike prior heuristic or probing-based studies, we provide constructive proofs and design explicit DFA-unrolled neural architectures that empirically validate every claim. Our results bridge deep learning, automata theory, and neural-symbolic computation, offering a rigorous blueprint for how discrete symbolic processes can be realized in continuous neural systems.","authors":["Sahil Rajesh Dhayalkar"],"url":"https://arxiv.org/abs/2505.11694"}
{"created":"2025-05-20","title":"Qronos: Correcting the Past by Shaping the Future... in Post-Training Quantization","abstract":"We introduce Qronos -- a new state-of-the-art post-training quantization algorithm that sequentially rounds and updates neural network weights. Qronos not only explicitly corrects errors due to both weight and activation quantization, but also errors resulting from quantizing previous layers. Our iterative algorithm is based on an interpretable and disciplined optimization framework that subsumes and surpasses existing data-driven approaches. At each step, Qronos alternates between error correction and diffusion via optimal update rules. Importantly, we prove that Qronos admits an efficient implementation that uses the Cholesky decomposition for solving least-squares problems. We also demonstrate that Qronos is compatible with existing transformation techniques such as Hadamard-based incoherence processing and weight-activation scaling equalization, among others. We evaluate Qronos using recent autoregressive language generation models in the Llama3 family; Qronos consistently outperforms previous state-of-the-art adaptive rounding methods when quantizing the weights, activations, and/or KV caches.","authors":["Shihao Zhang","Haoyu Zhang","Ian Colbert","Rayan Saab"],"url":"https://arxiv.org/abs/2505.11695"}
{"created":"2025-05-20","title":"Conditional Deep Generative Models for Belief State Planning","abstract":"Partially observable Markov decision processes (POMDPs) are used to model a wide range of applications, including robotics, autonomous vehicles, and subsurface problems. However, accurately representing the belief is difficult for POMDPs with high-dimensional states. In this paper, we propose a novel approach that uses conditional deep generative models (cDGMs) to represent the belief. Unlike traditional belief representations, cDGMs are well-suited for high-dimensional states and large numbers of observations, and they can generate an arbitrary number of samples from the posterior belief. We train the cDGMs on data produced by random rollout trajectories and show their effectiveness in solving a mineral exploration POMDP with a large and continuous state space. The cDGMs outperform particle filter baselines in both task-agnostic measures of belief accuracy as well as in planning performance.","authors":["Antoine Bigeard","Anthony Corso","Mykel Kochenderfer"],"url":"https://arxiv.org/abs/2505.11698"}
{"created":"2025-05-20","title":"DMN-Guided Prompting: A Low-Code Framework for Controlling LLM Behavior","abstract":"Large Language Models (LLMs) have shown considerable potential in automating decision logic within knowledge-intensive processes. However, their effectiveness largely depends on the strategy and quality of prompting. Since decision logic is typically embedded in prompts, it becomes challenging for end users to modify or refine it. Decision Model and Notation (DMN) offers a standardized graphical approach for defining decision logic in a structured, user-friendly manner. This paper introduces a DMN-guided prompting framework that breaks down complex decision logic into smaller, manageable components, guiding LLMs through structured decision pathways. We implemented the framework in a graduate-level course where students submitted assignments. The assignments and DMN models representing feedback instructions served as inputs to our framework. The instructor evaluated the generated feedback and labeled it for performance assessment. Our approach demonstrated promising results, outperforming chain-of-thought (CoT) prompting. Students also responded positively to the generated feedback, reporting high levels of perceived usefulness in a survey based on the Technology Acceptance Model.","authors":["Shaghayegh Abedi","Amin Jalali"],"url":"https://arxiv.org/abs/2505.11701"}
{"created":"2025-05-20","title":"Invariant Representations via Wasserstein Correlation Maximization","abstract":"This work investigates the use of Wasserstein correlation -- a normalized measure of statistical dependence based on the Wasserstein distance between a joint distribution and the product of its marginals -- for unsupervised representation learning. Unlike, for example, contrastive methods, which naturally cluster classes in the latent space, we find that an (auto)encoder trained to maximize Wasserstein correlation between the input and encoded distributions instead acts as a compressor, reducing dimensionality while approximately preserving the topological and geometric properties of the input distribution. More strikingly, we show that Wasserstein correlation maximization can be used to arrive at an (auto)encoder -- either trained from scratch, or else one that extends a frozen, pretrained model -- that is approximately invariant to a chosen augmentation, or collection of augmentations, and that still approximately preserves the structural properties of the non-augmented input distribution. To do this, we first define the notion of an augmented encoder using the machinery of Markov-Wasserstein kernels. When the maximization objective is then applied to the augmented encoder, as opposed to the underlying, deterministic encoder, the resulting model exhibits the desired invariance properties. Finally, besides our experimental results, which show that even simple feedforward networks can be imbued with invariants or can, alternatively, be used to impart invariants to pretrained models under this training process, we additionally establish various theoretical results for optimal transport-based dependence measures. Code is available at https://github.com/keenan-eikenberry/wasserstein_correlation_maximization .","authors":["Keenan Eikenberry","Lizuo Liu","Yoonsang Lee"],"url":"https://arxiv.org/abs/2505.11702"}
{"created":"2025-05-20","title":"LoFT: LoRA-fused Training Dataset Generation with Few-shot Guidance","abstract":"Despite recent advances in text-to-image generation, using synthetically generated data seldom brings a significant boost in performance for supervised learning. Oftentimes, synthetic datasets do not faithfully recreate the data distribution of real data, i.e., they lack the fidelity or diversity needed for effective downstream model training. While previous work has employed few-shot guidance to address this issue, existing methods still fail to capture and generate features unique to specific real images. In this paper, we introduce a novel dataset generation framework named LoFT, LoRA-Fused Training-data Generation with Few-shot Guidance. Our method fine-tunes LoRA weights on individual real images and fuses them at inference time, producing synthetic images that combine the features of real images for improved diversity and fidelity of generated data. We evaluate the synthetic data produced by LoFT on 10 datasets, using 8 to 64 real images per class as guidance and scaling up to 1000 images per class. Our experiments show that training on LoFT-generated data consistently outperforms other synthetic dataset methods, significantly increasing accuracy as the dataset size increases. Additionally, our analysis demonstrates that LoFT generates datasets with high fidelity and sufficient diversity, which contribute to the performance improvement. The code is available at https://github.com/ExplainableML/LoFT.","authors":["Jae Myung Kim","Stephan Alaniz","Cordelia Schmid","Zeynep Akata"],"url":"https://arxiv.org/abs/2505.11703"}
{"created":"2025-05-20","title":"Forensics of Error Rates of Quantum Hardware","abstract":"There has been a rise in third-party cloud providers offering quantum hardware as a service to improve performance at lower cost. Although these providers provide flexibility to the users to choose from several qubit technologies, quantum hardware, and coupling maps; the actual execution of the program is not clearly visible to the customer. The success of the user program, in addition to various other metadata such as cost, performance, & number of iterations to converge, depends on the error rate of the backend used. Moreover, the third-party provider and/or tools (e.g., hardware allocator and mapper) may hold insider/outsider adversarial agents to conserve resources and maximize profit by running the quantum circuits on error-prone hardware. Thus it is important to gain visibility of the backend from various perspectives of the computing process e.g., execution, transpilation and outcomes. In this paper, we estimate the error rate of the backend from the original and transpiled circuit. For the forensics, we exploit the fact that qubit mapping and routing steps of the transpilation process select qubits and qubit pairs with less single qubit and two-qubit gate errors to minimize overall error accumulation, thereby, giving us clues about the error rates of the various parts of the backend. We ranked qubit links into bins based on ECR error rates publicly available, and compared it to the rankings derived from our investigation of the relative frequency of a qubit link being chosen by the transpiler. For upto 83.5% of the qubit links in IBM Sherbrooke and 80% in IBM Brisbane, 127 qubit IBM backends, we are able to assign a bin rank which has a difference upto 2 with the bin rank assigned on the basis of actual error rate information.","authors":["Rupshali Roy","Swaroop Ghosh"],"url":"https://arxiv.org/abs/2505.11706"}
{"created":"2025-05-20","title":"Attend to Not Attended: Structure-then-Detail Token Merging for Post-training DiT Acceleration","abstract":"Diffusion transformers have shown exceptional performance in visual generation but incur high computational costs. Token reduction techniques that compress models by sharing the denoising process among similar tokens have been introduced. However, existing approaches neglect the denoising priors of the diffusion models, leading to suboptimal acceleration and diminished image quality. This study proposes a novel concept: attend to prune feature redundancies in areas not attended by the diffusion process. We analyze the location and degree of feature redundancies based on the structure-then-detail denoising priors. Subsequently, we introduce SDTM, a structure-then-detail token merging approach that dynamically compresses feature redundancies. Specifically, we design dynamic visual token merging, compression ratio adjusting, and prompt reweighting for different stages. Served in a post-training way, the proposed method can be integrated seamlessly into any DiT architecture. Extensive experiments across various backbones, schedulers, and datasets showcase the superiority of our method, for example, it achieves 1.55 times acceleration with negligible impact on image quality. Project page: https://github.com/ICTMCG/SDTM.","authors":["Haipeng Fang","Sheng Tang","Juan Cao","Enshuo Zhang","Fan Tang","Tong-Yee Lee"],"url":"https://arxiv.org/abs/2505.11707"}
{"created":"2025-05-20","title":"Unveiling the Black Box: A Multi-Layer Framework for Explaining Reinforcement Learning-Based Cyber Agents","abstract":"Reinforcement Learning (RL) agents are increasingly used to simulate sophisticated cyberattacks, but their decision-making processes remain opaque, hindering trust, debugging, and defensive preparedness. In high-stakes cybersecurity contexts, explainability is essential for understanding how adversarial strategies are formed and evolve over time. In this paper, we propose a unified, multi-layer explainability framework for RL-based attacker agents that reveals both strategic (MDP-level) and tactical (policy-level) reasoning. At the MDP level, we model cyberattacks as a Partially Observable Markov Decision Processes (POMDPs) to expose exploration-exploitation dynamics and phase-aware behavioural shifts. At the policy level, we analyse the temporal evolution of Q-values and use Prioritised Experience Replay (PER) to surface critical learning transitions and evolving action preferences. Evaluated across CyberBattleSim environments of increasing complexity, our framework offers interpretable insights into agent behaviour at scale. Unlike previous explainable RL methods, which are often post-hoc, domain-specific, or limited in depth, our approach is both agent- and environment-agnostic, supporting use cases ranging from red-team simulation to RL policy debugging. By transforming black-box learning into actionable behavioural intelligence, our framework enables both defenders and developers to better anticipate, analyse, and respond to autonomous cyber threats.","authors":["Diksha Goel","Kristen Moore","Jeff Wang","Minjune Kim","Thanh Thi Nguyen"],"url":"https://arxiv.org/abs/2505.11708"}
{"created":"2025-05-20","title":"EgoDex: Learning Dexterous Manipulation from Large-Scale Egocentric Video","abstract":"Imitation learning for manipulation has a well-known data scarcity problem. Unlike natural language and 2D computer vision, there is no Internet-scale corpus of data for dexterous manipulation. One appealing option is egocentric human video, a passively scalable data source. However, existing large-scale datasets such as Ego4D do not have native hand pose annotations and do not focus on object manipulation. To this end, we use Apple Vision Pro to collect EgoDex: the largest and most diverse dataset of dexterous human manipulation to date. EgoDex has 829 hours of egocentric video with paired 3D hand and finger tracking data collected at the time of recording, where multiple calibrated cameras and on-device SLAM can be used to precisely track the pose of every joint of each hand. The dataset covers a wide range of diverse manipulation behaviors with everyday household objects in 194 different tabletop tasks ranging from tying shoelaces to folding laundry. Furthermore, we train and systematically evaluate imitation learning policies for hand trajectory prediction on the dataset, introducing metrics and benchmarks for measuring progress in this increasingly important area. By releasing this large-scale dataset, we hope to push the frontier of robotics, computer vision, and foundation models.","authors":["Ryan Hoque","Peide Huang","David J. Yoon","Mouli Sivapurapu","Jian Zhang"],"url":"https://arxiv.org/abs/2505.11709"}
{"created":"2025-05-20","title":"Co-Evolutionary Defence of Active Directory Attack Graphs via GNN-Approximated Dynamic Programming","abstract":"Modern enterprise networks increasingly rely on Active Directory (AD) for identity and access management. However, this centralization exposes a single point of failure, allowing adversaries to compromise high-value assets. Existing AD defense approaches often assume static attacker behavior, but real-world adversaries adapt dynamically, rendering such methods brittle. To address this, we model attacker-defender interactions in AD as a Stackelberg game between an adaptive attacker and a proactive defender. We propose a co-evolutionary defense framework that combines Graph Neural Network Approximated Dynamic Programming (GNNDP) to model attacker strategies, with Evolutionary Diversity Optimization (EDO) to generate resilient blocking strategies. To ensure scalability, we introduce a Fixed-Parameter Tractable (FPT) graph reduction method that reduces complexity while preserving strategic structure. Our framework jointly refines attacker and defender policies to improve generalization and prevent premature convergence. Experiments on synthetic AD graphs show near-optimal results (within 0.1 percent of optimality on r500) and improved performance on larger graphs (r1000 and r2000), demonstrating the framework's scalability and effectiveness.","authors":["Diksha Goel","Hussain Ahmad","Kristen Moore","Mingyu Guo"],"url":"https://arxiv.org/abs/2505.11710"}
{"created":"2025-05-20","title":"Reinforcement Learning Finetunes Small Subnetworks in Large Language Models","abstract":"Reinforcement learning (RL) yields substantial improvements in large language models (LLMs) downstream task performance and alignment with human values. Surprisingly, such large gains result from updating only a small subnetwork comprising just 5 percent to 30 percent of the parameters, with the rest effectively unchanged. We refer to this phenomenon as parameter update sparsity induced by RL. It is observed across all 7 widely used RL algorithms (e.g., PPO, GRPO, DPO) and all 10 LLMs from different families in our experiments. This sparsity is intrinsic and occurs without any explicit sparsity promoting regularizations or architectural constraints. Finetuning the subnetwork alone recovers the test accuracy, and, remarkably, produces a model nearly identical to the one obtained via full finetuning. The subnetworks from different random seeds, training data, and even RL algorithms show substantially greater overlap than expected by chance. Our analysis suggests that this sparsity is not due to updating only a subset of layers, instead, nearly all parameter matrices receive similarly sparse updates. Moreover, the updates to almost all parameter matrices are nearly full-rank, suggesting RL updates a small subset of parameters that nevertheless span almost the full subspaces that the parameter matrices can represent. We conjecture that the this update sparsity can be primarily attributed to training on data that is near the policy distribution, techniques that encourage the policy to remain close to the pretrained model, such as the KL regularization and gradient clipping, have limited impact.","authors":["Sagnik Mukherjee","Lifan Yuan","Dilek Hakkani-Tur","Hao Peng"],"url":"https://arxiv.org/abs/2505.11711"}
{"created":"2025-05-20","title":"Bi-Level Policy Optimization with Nystr\\\"om Hypergradients","abstract":"The dependency of the actor on the critic in actor-critic (AC) reinforcement learning means that AC can be characterized as a bilevel optimization (BLO) problem, also called a Stackelberg game. This characterization motivates two modifications to vanilla AC algorithms. First, the critic's update should be nested to learn a best response to the actor's policy. Second, the actor should update according to a hypergradient that takes changes in the critic's behavior into account. Computing this hypergradient involves finding an inverse Hessian vector product, a process that can be numerically unstable. We thus propose a new algorithm, Bilevel Policy Optimization with Nystr\\\"om Hypergradients (BLPO), which uses nesting to account for the nested structure of BLO, and leverages the Nystr\\\"om method to compute the hypergradient. Theoretically, we prove BLPO converges to (a point that satisfies the necessary conditions for) a local strong Stackelberg equilibrium in polynomial time with high probability, assuming a linear parametrization of the critic's objective. Empirically, we demonstrate that BLPO performs on par with or better than PPO on a variety of discrete and continuous control tasks.","authors":["Arjun Prakash","Naicheng He","Denizalp Goktas","Amy Greenwald"],"url":"https://arxiv.org/abs/2505.11714"}
{"created":"2025-05-20","title":"ConflictLens: LLM-Based Conflict Resolution Training in Romantic Relationship","abstract":"Romantic conflicts are often rooted in deep psychological factors such as coping styles, emotional responses, and communication habits. Existing systems tend to address surface-level behaviors or isolated events, offering limited support for understanding the underlying dynamics. We present ConflictLens, an interactive system that leverages psychological theory and large language models (LLMs) to help individuals analyze and reflect on the deeper mechanisms behind their conflicts. The system provides multi-level strategy recommendations and guided dialogue exercises, including annotation, rewriting, and continuation tasks. A case study demonstrates how ConflictLens supports emotional insight, improves relational understanding, and fosters more constructive communication. This work offers a novel approach to supporting self-awareness and growth in romantic relationships.","authors":["Jiwon Chun","Gefei Zhang","Meng Xia"],"url":"https://arxiv.org/abs/2505.11715"}
{"created":"2025-05-20","title":"Employing Laban Shape for Generating Emotionally and Functionally Expressive Trajectories in Robotic Manipulators","abstract":"Successful human-robot collaboration depends on cohesive communication and a precise understanding of the robot's abilities, goals, and constraints. While robotic manipulators offer high precision, versatility, and productivity, they exhibit expressionless and monotonous motions that conceal the robot's intention, resulting in a lack of efficiency and transparency with humans. In this work, we use Laban notation, a dance annotation language, to enable robotic manipulators to generate trajectories with functional expressivity, where the robot uses nonverbal cues to communicate its abilities and the likelihood of succeeding at its task. We achieve this by introducing two novel variants of Hesitant expressive motion (Spoke-Like and Arc-Like). We also enhance the emotional expressivity of four existing emotive trajectories (Happy, Sad, Shy, and Angry) by augmenting Laban Effort usage with Laban Shape. The functionally expressive motions are validated via a human-subjects study, where participants equate both variants of Hesitant motion with reduced robot competency. The enhanced emotive trajectories are shown to be viewed as distinct emotions using the Valence-Arousal-Dominance (VAD) spectrum, corroborating the usage of Laban Shape.","authors":["Srikrishna Bangalore Raghu","Clare Lohrmann","Akshay Bakshi","Jennifer Kim","Jose Caraveo Herrera","Bradley Hayes","Alessandro Roncone"],"url":"https://arxiv.org/abs/2505.11716"}
{"created":"2025-05-20","title":"EnvInjection: Environmental Prompt Injection Attack to Multi-modal Web Agents","abstract":"Multi-modal large language model (MLLM)-based web agents interact with webpage environments by generating actions based on screenshots of the webpages. Environmental prompt injection attacks manipulate the environment to induce the web agent to perform a specific, attacker-chosen action--referred to as the target action. However, existing attacks suffer from limited effectiveness or stealthiness, or are impractical in real-world settings. In this work, we propose EnvInjection, a new attack that addresses these limitations. Our attack adds a perturbation to the raw pixel values of the rendered webpage, which can be implemented by modifying the webpage's source code. After these perturbed pixels are mapped into a screenshot, the perturbation induces the web agent to perform the target action. We formulate the task of finding the perturbation as an optimization problem. A key challenge in solving this problem is that the mapping between raw pixel values and screenshot is non-differentiable, making it difficult to backpropagate gradients to the perturbation. To overcome this, we train a neural network to approximate the mapping and apply projected gradient descent to solve the reformulated optimization problem. Extensive evaluation on multiple webpage datasets shows that EnvInjection is highly effective and significantly outperforms existing baselines.","authors":["Xilong Wang","John Bloch","Zedian Shao","Yuepeng Hu","Shuyan Zhou","Neil Zhenqiang Gong"],"url":"https://arxiv.org/abs/2505.11717"}
{"created":"2025-05-20","title":"REMOR: Automated Peer Review Generation with LLM Reasoning and Multi-Objective Reinforcement Learning","abstract":"AI-based peer review systems tend to produce shallow and overpraising suggestions compared to human feedback. Here, we evaluate how well a reasoning LLM trained with multi-objective reinforcement learning (REMOR) can overcome these limitations. We start by designing a multi-aspect reward function that aligns with human evaluation of reviews. The aspects are related to the review itself (e.g., criticisms, novelty) and the relationship between the review and the manuscript (i.e., relevance). First, we perform supervised fine-tuning of DeepSeek-R1-Distill-Qwen-7B using LoRA on PeerRT, a new dataset of high-quality top AI conference reviews enriched with reasoning traces. We then apply Group Relative Policy Optimization (GRPO) to train two models: REMOR-H (with the human-aligned reward) and REMOR-U (with a uniform reward). Interestingly, the human-aligned reward penalizes aspects typically associated with strong reviews, leading REMOR-U to produce qualitatively more substantive feedback. Our results show that REMOR-U and REMOR-H achieve more than twice the average rewards of human reviews, non-reasoning state-of-the-art agentic multi-modal AI review systems, and general commercial LLM baselines. We found that while the best AI and human reviews are comparable in quality, REMOR avoids the long tail of low-quality human reviews. We discuss how reasoning is key to achieving these improvements and release the Human-aligned Peer Review Reward (HPRR) function, the Peer Review Reasoning-enriched Traces (PeerRT) dataset, and the REMOR models, which we believe can help spur progress in the area.","authors":["Pawin Taechoyotin","Daniel Acuna"],"url":"https://arxiv.org/abs/2505.11718"}
{"created":"2025-05-20","title":"Zero-Shot Visual Generalization in Robot Manipulation","abstract":"Training vision-based manipulation policies that are robust across diverse visual environments remains an important and unresolved challenge in robot learning. Current approaches often sidestep the problem by relying on invariant representations such as point clouds and depth, or by brute-forcing generalization through visual domain randomization and/or large, visually diverse datasets. Disentangled representation learning - especially when combined with principles of associative memory - has recently shown promise in enabling vision-based reinforcement learning policies to be robust to visual distribution shifts. However, these techniques have largely been constrained to simpler benchmarks and toy environments. In this work, we scale disentangled representation learning and associative memory to more visually and dynamically complex manipulation tasks and demonstrate zero-shot adaptability to visual perturbations in both simulation and on real hardware. We further extend this approach to imitation learning, specifically Diffusion Policy, and empirically show significant gains in visual generalization compared to state-of-the-art imitation learning methods. Finally, we introduce a novel technique adapted from the model equivariance literature that transforms any trained neural network policy into one invariant to 2D planar rotations, making our policy not only visually robust but also resilient to certain camera perturbations. We believe that this work marks a significant step towards manipulation policies that are not only adaptable out of the box, but also robust to the complexities and dynamical nature of real-world deployment. Supplementary videos are available at https://sites.google.com/view/vis-gen-robotics/home.","authors":["Sumeet Batra","Gaurav Sukhatme"],"url":"https://arxiv.org/abs/2505.11719"}
{"created":"2025-05-20","title":"UGoDIT: Unsupervised Group Deep Image Prior Via Transferable Weights","abstract":"Recent advances in data-centric deep generative models have led to significant progress in solving inverse imaging problems. However, these models (e.g., diffusion models (DMs)) typically require large amounts of fully sampled (clean) training data, which is often impractical in medical and scientific settings such as dynamic imaging.","authors":["Shijun Liang","Ismail R. Alkhouri","Siddhant Gautam","Qing Qu","Saiprasad Ravishankar"],"url":"https://arxiv.org/abs/2505.11720"}
{"created":"2025-05-20","title":"Semantically-Aware Game Image Quality Assessment","abstract":"Assessing the visual quality of video game graphics presents unique challenges due to the absence of reference images and the distinct types of distortions, such as aliasing, texture blur, and geometry level of detail (LOD) issues, which differ from those in natural images or user-generated content. Existing no-reference image and video quality assessment (NR-IQA/VQA) methods fail to generalize to gaming environments as they are primarily designed for distortions like compression artifacts. This study introduces a semantically-aware NR-IQA model tailored to gaming. The model employs a knowledge-distilled Game distortion feature extractor (GDFE) to detect and quantify game-specific distortions, while integrating semantic gating via CLIP embeddings to dynamically weight feature importance based on scene content. Training on gameplay data recorded across graphical quality presets enables the model to produce quality scores that align with human perception. Our results demonstrate that the GDFE, trained through knowledge distillation from binary classifiers, generalizes effectively to intermediate distortion levels unseen during training. Semantic gating further improves contextual relevance and reduces prediction variance. In the absence of in-domain NR-IQA baselines, our model outperforms out-of-domain methods and exhibits robust, monotonic quality trends across unseen games in the same genre. This work establishes a foundation for automated graphical quality assessment in gaming, advancing NR-IQA methods in this domain.","authors":["Kai Zhu","Vignesh Edithal","Le Zhang","Ilia Blank","Imran Junejo"],"url":"https://arxiv.org/abs/2505.11724"}
{"created":"2025-05-20","title":"CLT and Edgeworth Expansion for m-out-of-n Bootstrap Estimators of The Studentized Median","abstract":"The m-out-of-n bootstrap, originally proposed by Bickel, Gotze, and Zwet (1992), approximates the distribution of a statistic by repeatedly drawing m subsamples (with m much smaller than n) without replacement from an original sample of size n. It is now routinely used for robust inference with heavy-tailed data, bandwidth selection, and other large-sample applications. Despite its broad applicability across econometrics, biostatistics, and machine learning, rigorous parameter-free guarantees for the soundness of the m-out-of-n bootstrap when estimating sample quantiles have remained elusive.","authors":["Imon Banerjee","Sayak Chakrabarty"],"url":"https://arxiv.org/abs/2505.11725"}
{"created":"2025-05-20","title":"Disambiguating Reference in Visually Grounded Dialogues through Joint Modeling of Textual and Multimodal Semantic Structures","abstract":"Multimodal reference resolution, including phrase grounding, aims to understand the semantic relations between mentions and real-world objects. Phrase grounding between images and their captions is a well-established task. In contrast, for real-world applications, it is essential to integrate textual and multimodal reference resolution to unravel the reference relations within dialogue, especially in handling ambiguities caused by pronouns and ellipses. This paper presents a framework that unifies textual and multimodal reference resolution by mapping mention embeddings to object embeddings and selecting mentions or objects based on their similarity. Our experiments show that learning textual reference resolution, such as coreference resolution and predicate-argument structure analysis, positively affects performance in multimodal reference resolution. In particular, our model with coreference resolution performs better in pronoun phrase grounding than representative models for this task, MDETR and GLIP. Our qualitative analysis demonstrates that incorporating textual reference relations strengthens the confidence scores between mentions, including pronouns and predicates, and objects, which can reduce the ambiguities that arise in visually grounded dialogues.","authors":["Shun Inadumi","Nobuhiro Ueda","Koichiro Yoshino"],"url":"https://arxiv.org/abs/2505.11726"}
{"created":"2025-05-20","title":"Neural Importance Sampling of Many Lights","abstract":"We propose a neural approach for estimating spatially varying light selection distributions to improve importance sampling in Monte Carlo rendering, particularly for complex scenes with many light sources. Our method uses a neural network to predict the light selection distribution at each shading point based on local information, trained by minimizing the KL-divergence between the learned and target distributions in an online manner. To efficiently manage hundreds or thousands of lights, we integrate our neural approach with light hierarchy techniques, where the network predicts cluster-level distributions and existing methods sample lights within clusters. Additionally, we introduce a residual learning strategy that leverages initial distributions from existing techniques, accelerating convergence during training. Our method achieves superior performance across diverse and challenging scenes.","authors":["Pedro Figueiredo","Qihao He","Steve Bako","Nima Khademi Kalantari"],"url":"https://arxiv.org/abs/2505.11729"}
{"created":"2025-05-20","title":"Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling","abstract":"Test-time scaling (TTS) has proven effective in enhancing the reasoning capabilities of large language models (LLMs). Verification plays a key role in TTS, simultaneously influencing (1) reasoning performance and (2) compute efficiency, due to the quality and computational cost of verification. In this work, we challenge the conventional paradigms of verification, and make the first attempt toward systematically investigating the impact of verification granularity-that is, how frequently the verifier is invoked during generation, beyond verifying only the final output or individual generation steps. To this end, we introduce Variable Granularity Search (VG-Search), a unified algorithm that generalizes beam search and Best-of-N sampling via a tunable granularity parameter g. Extensive experiments with VG-Search under varying compute budgets, generator-verifier configurations, and task attributes reveal that dynamically selecting g can improve the compute efficiency and scaling behavior. Building on these findings, we propose adaptive VG-Search strategies that achieve accuracy gains of up to 3.1\\% over Beam Search and 3.6\\% over Best-of-N, while reducing FLOPs by over 52\\%. We will open-source the code to support future research.","authors":["Hao Mark Chen","Guanxi Lu","Yasuyuki Okoshi","Zhiwen Mo","Masato Motomura","Hongxiang Fan"],"url":"https://arxiv.org/abs/2505.11730"}
{"created":"2025-05-20","title":"Efficient Uncertainty Estimation via Distillation of Bayesian Large Language Models","abstract":"Recent advances in uncertainty estimation for Large Language Models (LLMs) during downstream adaptation have addressed key challenges of reliability and simplicity. However, existing Bayesian methods typically require multiple sampling iterations during inference, creating significant efficiency issues that limit practical deployment. In this paper, we investigate the possibility of eliminating the need for test-time sampling for LLM uncertainty estimation. Specifically, when given an off-the-shelf Bayesian LLM, we distill its aligned confidence into a non-Bayesian student LLM by minimizing the divergence between their predictive distributions. Unlike typical calibration methods, our distillation is carried out solely on the training dataset without the need of an additional validation dataset. This simple yet effective approach achieves N-times more efficient uncertainty estimation during testing, where N is the number of samples traditionally required by Bayesian LLMs. Our extensive experiments demonstrate that uncertainty estimation capabilities on training data can successfully generalize to unseen test data through our distillation technique, consistently producing results comparable to (or even better than) state-of-the-art Bayesian LLMs.","authors":["Harshil Vejendla","Haizhou Shi","Yibin Wang","Tunyu Zhang","Huan Zhang","Hao Wang"],"url":"https://arxiv.org/abs/2505.11731"}
{"created":"2025-05-20","title":"MedCaseReasoning: Evaluating and learning diagnostic reasoning from clinical case reports","abstract":"Doctors and patients alike increasingly use Large Language Models (LLMs) to diagnose clinical cases. However, unlike domains such as math or coding, where correctness can be objectively defined by the final answer, medical diagnosis requires both the outcome and the reasoning process to be accurate. Currently, widely used medical benchmarks like MedQA and MMLU assess only accuracy in the final answer, overlooking the quality and faithfulness of the clinical reasoning process. To address this limitation, we introduce MedCaseReasoning, the first open-access dataset for evaluating LLMs on their ability to align with clinician-authored diagnostic reasoning. The dataset includes 14,489 diagnostic question-and-answer cases, each paired with detailed reasoning statements derived from open-access medical case reports. We evaluate state-of-the-art reasoning LLMs on MedCaseReasoning and find significant shortcomings in their diagnoses and reasoning: for instance, the top-performing open-source model, DeepSeek-R1, achieves only 48% 10-shot diagnostic accuracy and mentions only 64% of the clinician reasoning statements (recall). However, we demonstrate that fine-tuning LLMs on the reasoning traces derived from MedCaseReasoning significantly improves diagnostic accuracy and clinical reasoning recall by an average relative gain of 29% and 41%, respectively. The open-source dataset, code, and models are available at https://github.com/kevinwu23/Stanford-MedCaseReasoning.","authors":["Kevin Wu","Eric Wu","Rahul Thapa","Kevin Wei","Angela Zhang","Arvind Suresh","Jacqueline J. Tao","Min Woo Sun","Alejandro Lozano","James Zou"],"url":"https://arxiv.org/abs/2505.11733"}
{"created":"2025-05-20","title":"Token-Level Uncertainty Estimation for Large Language Model Reasoning","abstract":"While Large Language Models (LLMs) have demonstrated impressive capabilities, their output quality remains inconsistent across various application scenarios, making it difficult to identify trustworthy responses, especially in complex tasks requiring multi-step reasoning. In this paper, we propose a token-level uncertainty estimation framework to enable LLMs to self-assess and self-improve their generation quality in mathematical reasoning. Specifically, we introduce low-rank random weight perturbation to LLM decoding, generating predictive distributions that we use to estimate token-level uncertainties. We then aggregate these uncertainties to reflect semantic uncertainty of the generated sequences. Experiments on mathematical reasoning datasets of varying difficulty demonstrate that our token-level uncertainty metrics strongly correlate with answer correctness and model robustness. Additionally, we explore using uncertainty to directly enhance the model's reasoning performance through multiple generations and the particle filtering algorithm. Our approach consistently outperforms existing uncertainty estimation methods, establishing effective uncertainty estimation as a valuable tool for both evaluating and improving reasoning generation in LLMs.","authors":["Tunyu Zhang","Haizhou Shi","Yibin Wang","Hengyi Wang","Xiaoxiao He","Zhuowei Li","Haoxian Chen","Ligong Han","Kai Xu","Huan Zhang","Dimitris Metaxas","Hao Wang"],"url":"https://arxiv.org/abs/2505.11737"}
{"created":"2025-05-20","title":"Automated Real-time Assessment of Intracranial Hemorrhage Detection AI Using an Ensembled Monitoring Model (EMM)","abstract":"Artificial intelligence (AI) tools for radiology are commonly unmonitored once deployed. The lack of real-time case-by-case assessments of AI prediction confidence requires users to independently distinguish between trustworthy and unreliable AI predictions, which increases cognitive burden, reduces productivity, and potentially leads to misdiagnoses. To address these challenges, we introduce Ensembled Monitoring Model (EMM), a framework inspired by clinical consensus practices using multiple expert reviews. Designed specifically for black-box commercial AI products, EMM operates independently without requiring access to internal AI components or intermediate outputs, while still providing robust confidence measurements. Using intracranial hemorrhage detection as our test case on a large, diverse dataset of 2919 studies, we demonstrate that EMM successfully categorizes confidence in the AI-generated prediction, suggesting different actions and helping improve the overall performance of AI tools to ultimately reduce cognitive burden. Importantly, we provide key technical considerations and best practices for successfully translating EMM into clinical settings.","authors":["Zhongnan Fang","Andrew Johnston","Lina Cheuy","Hye Sun Na","Magdalini Paschali","Camila Gonzalez","Bonnie A. Armstrong","Arogya Koirala","Derrick Laurel","Andrew Walker Campion","Michael Iv","Akshay S. Chaudhari","David B. Larson"],"url":"https://arxiv.org/abs/2505.11738"}
{"created":"2025-05-20","title":"ZeroTuning: Unlocking the Initial Token's Power to Enhance Large Language Models Without Training","abstract":"Recently, training-free methods for improving large language models (LLMs) have attracted growing interest, with token-level attention tuning emerging as a promising and interpretable direction. However, existing methods typically rely on auxiliary mechanisms to identify important or irrelevant task-specific tokens, introducing potential bias and limiting applicability. In this paper, we uncover a surprising and elegant alternative: the semantically empty initial token is a powerful and underexplored control point for optimizing model behavior. Through theoretical analysis, we show that tuning the initial token's attention sharpens or flattens the attention distribution over subsequent tokens, and its role as an attention sink amplifies this effect. Empirically, we find that: (1) tuning its attention improves LLM performance more effectively than tuning other task-specific tokens; (2) the effect follows a consistent trend across layers, with earlier layers having greater impact, but varies across attention heads, with different heads showing distinct preferences in how they attend to this token. Based on these findings, we propose ZeroTuning, a training-free approach that improves LLM performance by applying head-specific attention adjustments to this special token. Despite tuning only one token, ZeroTuning achieves higher performance on text classification, multiple-choice, and multi-turn conversation tasks across models such as Llama, Qwen, and DeepSeek. For example, ZeroTuning improves Llama-3.1-8B by 11.71% on classification, 2.64% on QA tasks, and raises its multi-turn score from 7.804 to 7.966. The method is also robust to limited resources, few-shot settings, long contexts, quantization, decoding strategies, and prompt variations. Our work sheds light on a previously overlooked control point in LLMs, offering new insights into both inference-time tuning and model interpretability.","authors":["Feijiang Han","Xiaodong Yu","Jianheng Tang","Lyle Ungar"],"url":"https://arxiv.org/abs/2505.11739"}
{"created":"2025-05-20","title":"Simple and Effective Specialized Representations for Fair Classifiers","abstract":"Fair classification is a critical challenge that has gained increasing importance due to international regulations and its growing use in high-stakes decision-making settings. Existing methods often rely on adversarial learning or distribution matching across sensitive groups; however, adversarial learning can be unstable, and distribution matching can be computationally intensive. To address these limitations, we propose a novel approach based on the characteristic function distance. Our method ensures that the learned representation contains minimal sensitive information while maintaining high effectiveness for downstream tasks. By utilizing characteristic functions, we achieve a more stable and efficient solution compared to traditional methods. Additionally, we introduce a simple relaxation of the objective function that guarantees fairness in common classification models with no performance degradation. Experimental results on benchmark datasets demonstrate that our approach consistently matches or achieves better fairness and predictive accuracy than existing methods. Moreover, our method maintains robustness and computational efficiency, making it a practical solution for real-world applications.","authors":["Alberto Sinigaglia","Davide Sartor","Marina Ceccon","Gian Antonio Susto"],"url":"https://arxiv.org/abs/2505.11740"}
{"created":"2025-05-20","title":"Diverging Towards Hallucination: Detection of Failures in Vision-Language Models via Multi-token Aggregation","abstract":"Vision-language models (VLMs) now rival human performance on many multimodal tasks, yet they still hallucinate objects or generate unsafe text. Current hallucination detectors, e.g., single-token linear probing (SLP) and P(True), typically analyze only the logit of the first generated token or just its highest scoring component overlooking richer signals embedded within earlier token distributions. We demonstrate that analyzing the complete sequence of early logits potentially provides substantially more diagnostic information. We emphasize that hallucinations may only emerge after several tokens, as subtle inconsistencies accumulate over time. By analyzing the Kullback-Leibler (KL) divergence between logits corresponding to hallucinated and non-hallucinated tokens, we underscore the importance of incorporating later-token logits to more accurately capture the reliability dynamics of VLMs. In response, we introduce Multi-Token Reliability Estimation (MTRE), a lightweight, white-box method that aggregates logits from the first ten tokens using multi-token log-likelihood ratios and self-attention. Despite the challenges posed by large vocabulary sizes and long logit sequences, MTRE remains efficient and tractable. On MAD-Bench, MM-SafetyBench, MathVista, and four compositional-geometry benchmarks, MTRE improves AUROC by 9.4 +/- 1.3 points over SLP and by 12.1 +/- 1.7 points over P(True), setting a new state-of-the-art in hallucination detection for open-source VLMs.","authors":["Geigh Zollicoffer","Minh Vu","Manish Bhattarai"],"url":"https://arxiv.org/abs/2505.11741"}
{"created":"2025-05-20","title":"FAIR Ecosystems for Science at Scale","abstract":"High Performance Computing (HPC) centers provide resources to users who require greater scale to \"get science done\". They deploy infrastructure with singular hardware architectures, cutting-edge software environments, and stricter security measures as compared with users' own resources. As a result, users often create and configure digital artifacts in ways that are specialized for the unique infrastructure at a given HPC center. Each user of that center will face similar challenges as they develop specialized solutions to take full advantages of the center's resources, potentially resulting in significant duplication of effort. Much duplicated effort could be avoided, however, if users of these centers found it easier to discover others' solutions and artifacts as well as share their own.","authors":["Sean R. Wilkinson","Patrick Widener"],"url":"https://arxiv.org/abs/2505.11742"}
{"created":"2025-05-20","title":"Cloud-Based AI Systems: Leveraging Large Language Models for Intelligent Fault Detection and Autonomous Self-Healing","abstract":"With the rapid development of cloud computing systems and the increasing complexity of their infrastructure, intelligent mechanisms to detect and mitigate failures in real time are becoming increasingly important. Traditional methods of failure detection are often difficult to cope with the scale and dynamics of modern cloud environments. In this study, we propose a novel AI framework based on Massive Language Model (LLM) for intelligent fault detection and self-healing mechanisms in cloud systems. The model combines existing machine learning fault detection algorithms with LLM's natural language understanding capabilities to process and parse system logs, error reports, and real-time data streams through semantic context. The method adopts a multi-level architecture, combined with supervised learning for fault classification and unsupervised learning for anomaly detection, so that the system can predict potential failures before they occur and automatically trigger the self-healing mechanism. Experimental results show that the proposed model is significantly better than the traditional fault detection system in terms of fault detection accuracy, system downtime reduction and recovery speed.","authors":["Cheng Ji","Huaiying Luo"],"url":"https://arxiv.org/abs/2505.11743"}
{"created":"2025-05-20","title":"Decentralized Multi-Authority Attribute-Based Inner-Product Functional Encryption: Noisy and Evasive Constructions from Lattices","abstract":"We study multi-authority attribute-based functional encryption for noisy inner-product functionality, and propose two new primitives: (1) multi-authority attribute-based (noisy) inner-product functional encryption (MA-AB(N)IPFE), which generalizes existing multi-authority attribute-based IPFE schemes by Agrawal et al. (TCC'21), by enabling approximate inner-product computation; and (2) multi-authority attribute-based evasive inner-product functional encryption (MA-evIPFE), a relaxed variant inspired by the evasive IPFE framework by Hsieh et al. (EUROCRYPT'24), shifting focus from ciphertext indistinguishability to a more relaxed pseudorandomness-based security notion. To support the above notions, we introduce two variants of lattice-based computational assumptions: evasive IPFE assumption and indistinguishability-based evasive IPFE assumption (IND-evIPFE). We present lattice-based constructions of both primitives for subset policies, building upon the framework of Waters et al.( TCC'22). Our schemes are proven to be statically secure in the random oracle model under the standard LWE assumption and the newly introduced assumptions. Additionally, we show our MA-AB(N)IPFE scheme can be transformed via modulus switching into a noiseless MA-IPFE scheme that supports exact inner-product functionality. This yields the first lattice-based construction of such a primitive. All our schemes support arbitrary polynomial-size attribute policies and are secure in the random oracle model under lattice assumptions with a sub-exponential modulus-to-noise ratio, making them practical candidates for noise-tolerant, fine-grained access control in multi-authority settings.","authors":["Jiaqi Liu","Yan Wang","Fang-Wei Fu"],"url":"https://arxiv.org/abs/2505.11744"}
{"created":"2025-05-20","title":"POCAII: Parameter Optimization with Conscious Allocation using Iterative Intelligence","abstract":"In this paper we propose for the first time the hyperparameter optimization (HPO) algorithm POCAII. POCAII differs from the Hyperband and Successive Halving literature by explicitly separating the search and evaluation phases and utilizing principled approaches to exploration and exploitation principles during both phases. Such distinction results in a highly flexible scheme for managing a hyperparameter optimization budget by focusing on search (i.e., generating competing configurations) towards the start of the HPO process while increasing the evaluation effort as the HPO comes to an end.","authors":["Joshua Inman","Tanmay Khandait","Lalitha Sankar","Giulia Pedrielli"],"url":"https://arxiv.org/abs/2505.11745"}
{"created":"2025-05-20","title":"Token Masking Improves Transformer-Based Text Classification","abstract":"While transformer-based models achieve strong performance on text classification, we explore whether masking input tokens can further enhance their effectiveness. We propose token masking regularization, a simple yet theoretically motivated method that randomly replaces input tokens with a special [MASK] token at probability p. This introduces stochastic perturbations during training, leading to implicit gradient averaging that encourages the model to capture deeper inter-token dependencies. Experiments on language identification and sentiment analysis -- across diverse models (mBERT, Qwen2.5-0.5B, TinyLlama-1.1B) -- show consistent improvements over standard regularization techniques. We identify task-specific optimal masking rates, with p = 0.1 as a strong general default. We attribute the gains to two key effects: (1) input perturbation reduces overfitting, and (2) gradient-level smoothing acts as implicit ensembling.","authors":["Xianglong Xu","John Bowen","Rojin Taheri"],"url":"https://arxiv.org/abs/2505.11746"}
{"created":"2025-05-20","title":"HOME-3: High-Order Momentum Estimator with Third-Power Gradient for Convex and Smooth Nonconvex Optimization","abstract":"Momentum-based gradients are essential for optimizing advanced machine learning models, as they not only accelerate convergence but also advance optimizers to escape stationary points. While most state-of-the-art momentum techniques utilize lower-order gradients, such as the squared first-order gradient, there has been limited exploration of higher-order gradients, particularly those raised to powers greater than two. In this work, we introduce the concept of high-order momentum, where momentum is constructed using higher-power gradients, with a focus on the third-power of the first-order gradient as a representative case. Our research offers both theoretical and empirical support for this approach. Theoretically, we demonstrate that incorporating third-power gradients can improve the convergence bounds of gradient-based optimizers for both convex and smooth nonconvex problems. Empirically, we validate these findings through extensive experiments across convex, smooth nonconvex, and nonsmooth nonconvex optimization tasks. Across all cases, high-order momentum consistently outperforms conventional low-order momentum methods, showcasing superior performance in various optimization problems.","authors":["Wei Zhang","Arif Hassan Zidan","Afrar Jahin","Yu Bao","Tianming Liu"],"url":"https://arxiv.org/abs/2505.11748"}
{"created":"2025-05-20","title":"Permutation Randomization on Nonsmooth Nonconvex Optimization: A Theoretical and Experimental Study","abstract":"While gradient-based optimizers that incorporate randomization often showcase superior performance on complex optimization, the theoretical foundations underlying this superiority remain insufficiently understood. A particularly pressing question has emerged: What is the role of randomization in dimension-free nonsmooth nonconvex optimization? To address this gap, we investigate the theoretical and empirical impact of permutation randomization within gradient-based optimization frameworks, using it as a representative case to explore broader implications. From a theoretical perspective, our analyses reveal that permutation randomization disrupts the shrinkage behavior of gradient-based optimizers, facilitating continuous convergence toward the global optimum given a sufficiently large number of iterations. Additionally, we prove that permutation randomization can preserve the convergence rate of the underlying optimizer. On the empirical side, we conduct extensive numerical experiments comparing permutation-randomized optimizer against three baseline methods. These experiments span tasks such as training deep neural networks with stacked architectures and optimizing noisy objective functions. The results not only corroborate our theoretical insights but also highlight the practical benefits of permutation randomization. In summary, this work delivers both rigorous theoretical justification and compelling empirical evidence for the effectiveness of permutation randomization. Our findings and evidence lay a foundation for extending analytics to encompass a wide array of randomization.","authors":["Wei Zhang","Arif Hassan Zidan","Afrar Jahin","Yu Bao","Tianming Liu"],"url":"https://arxiv.org/abs/2505.11752"}
{"created":"2025-05-20","title":"X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models","abstract":"Text-guided diffusion models have significantly advanced image editing, enabling highly realistic and local modifications based on textual prompts. While these developments expand creative possibilities, their malicious use poses substantial challenges for detection of such subtle deepfake edits. To this end, we introduce Explain Edit (X-Edit), a novel method for localizing diffusion-based edits in images. To localize the edits for an image, we invert the image using a pretrained diffusion model, then use these inverted features as input to a segmentation network that explicitly predicts the edited masked regions via channel and spatial attention. Further, we finetune the model using a combined segmentation and relevance loss. The segmentation loss ensures accurate mask prediction by balancing pixel-wise errors and perceptual similarity, while the relevance loss guides the model to focus on low-frequency regions and mitigate high-frequency artifacts, enhancing the localization of subtle edits. To the best of our knowledge, we are the first to address and model the problem of localizing diffusion-based modified regions in images. We additionally contribute a new dataset of paired original and edited images addressing the current lack of resources for this task. Experimental results demonstrate that X-Edit accurately localizes edits in images altered by text-guided diffusion models, outperforming baselines in PSNR and SSIM metrics. This highlights X-Edit's potential as a robust forensic tool for detecting and pinpointing manipulations introduced by advanced image editing techniques.","authors":["Valentina Bazyleva","Nicolo Bonettini","Gaurav Bharaj"],"url":"https://arxiv.org/abs/2505.11753"}
{"created":"2025-05-20","title":"Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context Permutation","abstract":"Multi-hop Question Answering (MHQA) adds layers of complexity to question answering, making it more challenging. When Language Models (LMs) are prompted with multiple search results, they are tasked not only with retrieving relevant information but also employing multi-hop reasoning across the information sources. Although LMs perform well on traditional question-answering tasks, the causal mask can hinder their capacity to reason across complex contexts. In this paper, we explore how LMs respond to multi-hop questions by permuting search results (retrieved documents) under various configurations. Our study reveals interesting findings as follows: 1) Encoder-decoder models, such as the ones in the Flan-T5 family, generally outperform causal decoder-only LMs in MHQA tasks, despite being significantly smaller in size; 2) altering the order of gold documents reveals distinct trends in both Flan T5 models and fine-tuned decoder-only models, with optimal performance observed when the document order aligns with the reasoning chain order; 3) enhancing causal decoder-only models with bi-directional attention by modifying the causal mask can effectively boost their end performance. In addition to the above, we conduct a thorough investigation of the distribution of LM attention weights in the context of MHQA. Our experiments reveal that attention weights tend to peak at higher values when the resulting answer is correct. We leverage this finding to heuristically improve LMs' performance on this task. Our code is publicly available at https://github.com/hwy9855/MultiHopQA-Reasoning.","authors":["Wenyu Huang","Pavlos Vougiouklis","Mirella Lapata","Jeff Z. Pan"],"url":"https://arxiv.org/abs/2505.11754"}
{"created":"2025-05-20","title":"Reachability Barrier Networks: Learning Hamilton-Jacobi Solutions for Smooth and Flexible Control Barrier Functions","abstract":"Recent developments in autonomous driving and robotics underscore the necessity of safety-critical controllers. Control barrier functions (CBFs) are a popular method for appending safety guarantees to a general control framework, but they are notoriously difficult to generate beyond low dimensions. Existing methods often yield non-differentiable or inaccurate approximations that lack integrity, and thus fail to ensure safety. In this work, we use physics-informed neural networks (PINNs) to generate smooth approximations of CBFs by computing Hamilton-Jacobi (HJ) optimal control solutions. These reachability barrier networks (RBNs) avoid traditional dimensionality constraints and support the tuning of their conservativeness post-training through a parameterized discount term. To ensure robustness of the discounted solutions, we leverage conformal prediction methods to derive probabilistic safety guarantees for RBNs. We demonstrate that RBNs are highly accurate in low dimensions, and safer than the standard neural CBF approach in high dimensions. Namely, we showcase the RBNs in a 9D multi-vehicle collision avoidance problem where it empirically proves to be 5.5x safer and 1.9x less conservative than the neural CBFs, offering a promising method to synthesize CBFs for general nonlinear autonomous systems.","authors":["Matthew Kim","William Sharpless","Hyun Joe Jeong","Sander Tonkens","Somil Bansal","Sylvia Herbert"],"url":"https://arxiv.org/abs/2505.11755"}
{"created":"2025-05-20","title":"Feature Hedging: Correlated Features Break Narrow Sparse Autoencoders","abstract":"It is assumed that sparse autoencoders (SAEs) decompose polysemantic activations into interpretable linear directions, as long as the activations are composed of sparse linear combinations of underlying features. However, we find that if an SAE is more narrow than the number of underlying \"true features\" on which it is trained, and there is correlation between features, the SAE will merge components of correlated features together, thus destroying monosemanticity. In LLM SAEs, these two conditions are almost certainly true. This phenomenon, which we call feature hedging, is caused by SAE reconstruction loss, and is more severe the narrower the SAE. In this work, we introduce the problem of feature hedging and study it both theoretically in toy models and empirically in SAEs trained on LLMs. We suspect that feature hedging may be one of the core reasons that SAEs consistently underperform supervised baselines. Finally, we use our understanding of feature hedging to propose an improved variant of matryoshka SAEs. Our work shows there remain fundamental issues with SAEs, but we are hopeful that that highlighting feature hedging will catalyze future advances that allow SAEs to achieve their full potential of interpreting LLMs at scale.","authors":["David Chanin","Tom\\'a\\v{s} Dulka","Adri\\`a Garriga-Alonso"],"url":"https://arxiv.org/abs/2505.11756"}
{"created":"2025-05-20","title":"Generalizable Vision-Language Few-Shot Adaptation with Predictive Prompts and Negative Learning","abstract":"Few-shot adaptation remains a core challenge for vision-language models (VLMs), especially under limited supervision and noisy support samples. We propose PromptFuseNL, a unified framework that enhances few-shot generalization by combining predictive prompt tuning with dual-branch positive and negative learning. The method refines class prototypes through task-conditioned residuals, multi-stage cross-modal coordination, and semantic hard negative mining. To address label noise, we introduce an unsupervised instance reweighting strategy that downweights unreliable support examples without requiring additional labels or structural changes. PromptFuseNL fuses visual and textual cues through lightweight modules for efficient and discriminative prediction. Evaluated across 15 benchmarks, it consistently surpasses existing prompt- and adapter-based methods in all shot settings while remaining highly efficient, achieving up to 300x faster training and 1000x lower FLOPs compared to full prompt tuning, achieving a new state-of-the-art for robust and scalable few-shot vision-language adaptation.","authors":["Sriram Mandalika"],"url":"https://arxiv.org/abs/2505.11758"}
{"created":"2025-05-20","title":"Topology-Aware Knowledge Propagation in Decentralized Learning","abstract":"Decentralized learning enables collaborative training of models across naturally distributed data without centralized coordination or maintenance of a global model. Instead, devices are organized in arbitrary communication topologies, in which they can only communicate with neighboring devices. Each device maintains its own local model by training on its local data and integrating new knowledge via model aggregation with neighbors. Therefore, knowledge is propagated across the topology via successive aggregation rounds. We study, in particular, the propagation of out-of-distribution (OOD) knowledge. We find that popular decentralized learning algorithms struggle to propagate OOD knowledge effectively to all devices. Further, we find that both the location of OOD data within a topology, and the topology itself, significantly impact OOD knowledge propagation. We then propose topology-aware aggregation strategies to accelerate (OOD) knowledge propagation across devices. These strategies improve OOD data accuracy, compared to topology-unaware baselines, by 123% on average across models in a topology.","authors":["Mansi Sakarvadia","Nathaniel Hudson","Tian Li","Ian Foster","Kyle Chard"],"url":"https://arxiv.org/abs/2505.11760"}
{"created":"2025-05-20","title":"A parameterized Wasserstein Hamiltonian flow approach for solving the Schr\\\"odinger equation","abstract":"In this paper, we propose a new method to compute the solution of time-dependent Schr\\\"odinger equation (TDSE). Using push-forward maps and Wasserstein Hamiltonian flow, we reformulate the TDSE as a Hamiltonian system in terms of push-forward maps. The new formulation can be viewed as a generative model in the Wasserstein space, which is a manifold of probability density functions. Then we parameterize the push-forward maps by reduce-order models such as neural networks. This induces a new metric in the parameter space by pulling back the Wasserstein metric on density manifold, which further results in a system of ordinary differential equations (ODEs) for the parameters of the reduce-order model. Leveraging the computational techniques from deep learning, such as Neural ODE, we design an algorithm to solve the TDSE in the parameterized push-forward map space, which provides an alternative approach with the potential to scale up to high-dimensional problems. Several numerical examples are presented to demonstrate the performance of this algorithm.","authors":["Hao Wu","Shu Liu","Xiaojing Ye","Haomin Zhou"],"url":"https://arxiv.org/abs/2505.11762"}
{"created":"2025-05-20","title":"Learning IMU Bias with Diffusion Model","abstract":"Motion sensing and tracking with IMU data is essential for spatial intelligence, which however is challenging due to the presence of time-varying stochastic bias. IMU bias is affected by various factors such as temperature and vibration, making it highly complex and difficult to model analytically. Recent data-driven approaches using deep learning have shown promise in predicting bias from IMU readings. However, these methods often treat the task as a regression problem, overlooking the stochatic nature of bias. In contrast, we model bias, conditioned on IMU readings, as a probabilistic distribution and design a conditional diffusion model to approximate this distribution. Through this approach, we achieve improved performance and make predictions that align more closely with the known behavior of bias.","authors":["Shenghao Zhou","Saimouli Katragadda","Guoquan Huang"],"url":"https://arxiv.org/abs/2505.11763"}
{"created":"2025-05-20","title":"Towards Universal Semantics With Large Language Models","abstract":"The Natural Semantic Metalanguage (NSM) is a linguistic theory based on a universal set of semantic primes: simple, primitive word-meanings that have been shown to exist in most, if not all, languages of the world. According to this framework, any word, regardless of complexity, can be paraphrased using these primes, revealing a clear and universally translatable meaning. These paraphrases, known as explications, can offer valuable applications for many natural language processing (NLP) tasks, but producing them has traditionally been a slow, manual process. In this work, we present the first study of using large language models (LLMs) to generate NSM explications. We introduce automatic evaluation methods, a tailored dataset for training and evaluation, and fine-tuned models for this task. Our 1B and 8B models outperform GPT-4o in producing accurate, cross-translatable explications, marking a significant step toward universal semantic representation with LLMs and opening up new possibilities for applications in semantic analysis, translation, and beyond.","authors":["Raymond Baartmans","Matthew Raffel","Rahul Vikram","Aiden Deringer","Lizhong Chen"],"url":"https://arxiv.org/abs/2505.11764"}
{"created":"2025-05-20","title":"OMAC: A Broad Optimization Framework for LLM-Based Multi-Agent Collaboration","abstract":"Agents powered by advanced large language models (LLMs) have demonstrated impressive capabilities across diverse complex applications. Recently, Multi-Agent Systems (MAS), wherein multiple agents collaborate and communicate with each other, have exhibited enhanced capabilities in complex tasks, such as high-quality code generation and arithmetic reasoning. However, the development of such systems often relies on handcrafted methods, and the literature on systematic design and optimization of LLM-based MAS remains limited.","authors":["Shijun Li","Hilaf Hasson","Joydeep Ghosh"],"url":"https://arxiv.org/abs/2505.11765"}
{"created":"2025-05-20","title":"Redefining Neural Operators in $d+1$ Dimensions","abstract":"Neural Operators have emerged as powerful tools for learning mappings between function spaces. Among them, the kernel integral operator has been widely validated on universally approximating various operators. Although recent advancements following this definition have developed effective modules to better approximate the kernel function defined on the original domain (with $d$ dimensions, $d=1, 2, 3...$), the unclarified evolving mechanism in the embedding spaces blocks our view to design neural operators that can fully capture the target system evolution.","authors":["Haoze Song","Zhihao Li","Xiaobo Zhang","Zecheng Gan","Zhilu Lai","Wei Wang"],"url":"https://arxiv.org/abs/2505.11766"}
{"created":"2025-05-20","title":"Technical Report for ICRA 2025 GOOSE 2D Semantic Segmentation Challenge: Boosting Off-Road Segmentation via Photometric Distortion and Exponential Moving Average","abstract":"We report on the application of a high-capacity semantic segmentation pipeline to the GOOSE 2D Semantic Segmentation Challenge for unstructured off-road environments. Using a FlashInternImage-B backbone together with a UPerNet decoder, we adapt established techniques, rather than designing new ones, to the distinctive conditions of off-road scenes. Our training recipe couples strong photometric distortion augmentation (to emulate the wide lighting variations of outdoor terrain) with an Exponential Moving Average (EMA) of weights for better generalization. Using only the GOOSE training dataset, we achieve 88.8\\% mIoU on the validation set.","authors":["Wonjune Kim","Lae-kyoung Lee","Su-Yong An"],"url":"https://arxiv.org/abs/2505.11769"}
{"created":"2025-05-20","title":"Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors","abstract":"Interpretability research now offers a variety of techniques for identifying abstract internal mechanisms in neural networks. Can such techniques be used to predict how models will behave on out-of-distribution examples? In this work, we provide a positive answer to this question. Through a diverse set of language modeling tasks--including symbol manipulation, knowledge retrieval, and instruction following--we show that the most robust features for correctness prediction are those that play a distinctive causal role in the model's behavior. Specifically, we propose two methods that leverage causal mechanisms to predict the correctness of model outputs: counterfactual simulation (checking whether key causal variables are realized) and value probing (using the values of those variables to make predictions). Both achieve high AUC-ROC in distribution and outperform methods that rely on causal-agnostic features in out-of-distribution settings, where predicting model behaviors is more crucial. Our work thus highlights a novel and significant application for internal causal analysis of language models.","authors":["Jing Huang","Junyi Tao","Thomas Icard","Diyi Yang","Christopher Potts"],"url":"https://arxiv.org/abs/2505.11770"}
{"created":"2025-05-20","title":"Residual Feature Integration is Sufficient to Prevent Negative Transfer","abstract":"Transfer learning typically leverages representations learned from a source domain to improve performance on a target task. A common approach is to extract features from a pre-trained model and directly apply them for target prediction. However, this strategy is prone to negative transfer where the source representation fails to align with the target distribution. In this article, we propose Residual Feature Integration (REFINE), a simple yet effective method designed to mitigate negative transfer. Our approach combines a fixed source-side representation with a trainable target-side encoder and fits a shallow neural network on the resulting joint representation, which adapts to the target domain while preserving transferable knowledge from the source domain. Theoretically, we prove that REFINE is sufficient to prevent negative transfer under mild conditions, and derive the generalization bound demonstrating its theoretical benefit. Empirically, we show that REFINE consistently enhances performance across diverse application and data modalities including vision, text, and tabular data, and outperforms numerous alternative solutions. Our method is lightweight, architecture-agnostic, and robust, making it a valuable addition to the existing transfer learning toolbox.","authors":["Yichen Xu","Ryumei Nakada","Linjun Zhang","Lexin Li"],"url":"https://arxiv.org/abs/2505.11771"}
{"created":"2025-05-20","title":"LAMP: Extracting Locally Linear Decision Surfaces from LLM World Models","abstract":"We introduce \\textbf{LAMP} (\\textbf{L}inear \\textbf{A}ttribution \\textbf{M}apping \\textbf{P}robe), a method that shines light onto a black-box language model's decision surface and studies how reliably a model maps its stated reasons to its predictions through a locally linear model approximating the decision surface. LAMP treats the model's own self-reported explanations as a coordinate system and fits a locally linear surrogate that links those weights to the model's output. By doing so, it reveals which stated factors steer the model's decisions, and by how much. We apply LAMP to three tasks: \\textit{sentiment analysis}, \\textit{controversial-topic detection}, and \\textit{safety-prompt auditing}. Across these tasks, LAMP reveals that many LLMs exhibit locally linear decision landscapes. In addition, these surfaces correlate with human judgments on explanation quality and, on a clinical case-file data set, aligns with expert assessments. Since LAMP operates without requiring access to model gradients, logits, or internal activations, it serves as a practical and lightweight framework for auditing proprietary language models, and enabling assessment of whether a model behaves consistently with the explanations it provides.","authors":["Ryan Chen","Youngmin Ko","Zeyu Zhang","Catherine Cho","Sunny Chung","Mauro Giuffr\\'e","Dennis L. Shung","Bradly C. Stadie"],"url":"https://arxiv.org/abs/2505.11772"}
{"created":"2025-05-20","title":"HARDMath2: A Benchmark for Applied Mathematics Built by Students as Part of a Graduate Class","abstract":"Large language models (LLMs) have shown remarkable progress in mathematical problem-solving, but evaluation has largely focused on problems that have exact analytical solutions or involve formal proofs, often overlooking approximation-based problems ubiquitous in applied science and engineering. To fill this gap, we build on prior work and present HARDMath2, a dataset of 211 original problems covering the core topics in an introductory graduate applied math class, including boundary-layer analysis, WKB methods, asymptotic solutions of nonlinear partial differential equations, and the asymptotics of oscillatory integrals. This dataset was designed and verified by the students and instructors of a core graduate applied mathematics course at Harvard. We build the dataset through a novel collaborative environment that challenges students to write and refine difficult problems consistent with the class syllabus, peer-validate solutions, test different models, and automatically check LLM-generated solutions against their own answers and numerical ground truths. Evaluation results show that leading frontier models still struggle with many of the problems in the dataset, highlighting a gap in the mathematical reasoning skills of current LLMs. Importantly, students identified strategies to create increasingly difficult problems by interacting with the models and exploiting common failure modes. This back-and-forth with the models not only resulted in a richer and more challenging benchmark but also led to qualitative improvements in the students' understanding of the course material, which is increasingly important as we enter an age where state-of-the-art language models can solve many challenging problems across a wide domain of fields.","authors":["James V. Roggeveen","Erik Y. Wang","Will Flintoft","Peter Donets","Lucy S. Nathwani","Nickholas Gutierrez","David Ettel","Anton Marius Graf","Siddharth Dandavate","Arjun Nageswaran","Raglan Ward","Ava Williamson","Anne Mykland","Kacper K. Migacz","Yijun Wang","Egemen Bostan","Duy Thuc Nguyen","Zhe He","Marc L. Descoteaux","Felix Yeung","Shida Liu","Jorge Garc\\'ia Ponce","Luke Zhu","Yuyang Chen","Ekaterina S. Ivshina","Miguel Fernandez","Minjae Kim","Kennan Gumbs","Matthew Scott Tan","Russell Yang","Mai Hoang","David Brown","Isabella A. Silveira","Lavon Sykes","Ahmed Roman","William Fredenberg","Yiming Chen","Lucas Martin","Yixing Tang","Kelly Werker Smith","Hongyu Liao","Logan G. Wilson","Alexander Dazhen Cai","Andrea Elizabeth Biju","Michael P. Brenner"],"url":"https://arxiv.org/abs/2505.11774"}
{"created":"2025-05-20","title":"Generative and Contrastive Graph Representation Learning","abstract":"Self-supervised learning (SSL) on graphs generates node and graph representations (i.e., embeddings) that can be used for downstream tasks such as node classification, node clustering, and link prediction. Graph SSL is particularly useful in scenarios with limited or no labeled data. Existing SSL methods predominantly follow contrastive or generative paradigms, each excelling in different tasks: contrastive methods typically perform well on classification tasks, while generative methods often excel in link prediction. In this paper, we present a novel architecture for graph SSL that integrates the strengths of both approaches. Our framework introduces community-aware node-level contrastive learning, providing more robust and effective positive and negative node pairs generation, alongside graph-level contrastive learning to capture global semantic information. Additionally, we employ a comprehensive augmentation strategy that combines feature masking, node perturbation, and edge perturbation, enabling robust and diverse representation learning. By incorporating these enhancements, our model achieves superior performance across multiple tasks, including node classification, clustering, and link prediction. Evaluations on open benchmark datasets demonstrate that our model outperforms state-of-the-art methods, achieving a performance lift of 0.23%-2.01% depending on the task and dataset.","authors":["Jiali Chen","Avijit Mukherjee"],"url":"https://arxiv.org/abs/2505.11776"}
{"created":"2025-05-20","title":"Self-NPO: Negative Preference Optimization of Diffusion Models by Simply Learning from Itself without Explicit Preference Annotations","abstract":"Diffusion models have demonstrated remarkable success in various visual generation tasks, including image, video, and 3D content generation. Preference optimization (PO) is a prominent and growing area of research that aims to align these models with human preferences. While existing PO methods primarily concentrate on producing favorable outputs, they often overlook the significance of classifier-free guidance (CFG) in mitigating undesirable results. Diffusion-NPO addresses this gap by introducing negative preference optimization (NPO), training models to generate outputs opposite to human preferences and thereby steering them away from unfavorable outcomes. However, prior NPO approaches, including Diffusion-NPO, rely on costly and fragile procedures for obtaining explicit preference annotations (e.g., manual pairwise labeling or reward model training), limiting their practicality in domains where such data are scarce or difficult to acquire. In this work, we introduce Self-NPO, a Negative Preference Optimization approach that learns exclusively from the model itself, thereby eliminating the need for manual data labeling or reward model training. Moreover, our method is highly efficient and does not require exhaustive data sampling. We demonstrate that Self-NPO integrates seamlessly into widely used diffusion models, including SD1.5, SDXL, and CogVideoX, as well as models already optimized for human preferences, consistently enhancing both their generation quality and alignment with human preferences.","authors":["Fu-Yun Wang","Keqiang Sun","Yao Teng","Xihui Liu","Jiaming Song","Hongsheng Li"],"url":"https://arxiv.org/abs/2505.11777"}
{"created":"2025-05-20","title":"Study of Robust Resource Allocation in Cell-Free Multiple-Antenna Networks","abstract":"Cell-free networks outperform cellular networks in many aspects, yet their efficiency is affected by imperfect channel state information (CSI). In order to address this issue, this work presents a robust resource allocation framework designed for the downlink of user-centric cell-free massive multi-input multi-output (CF-mMIMO) networks. This framework employs a sequential resource allocation strategy with a robust user scheduling algorithm designed to maximize the sum-rate of the network and two robust power allocation algorithms aimed at minimizing the mean square error, which are developed to mitigate the effects of imperfect CSI. An analysis of the proposed robust resource allocation problems is developed along with a study of their computational cost. Simulation results demonstrate the effectiveness of the proposed robust resource allocation algorithms, showing a performance improvement of up to 30\\% compared to existing techniques.","authors":["S. Mashdour","A. Flores","R. C. de Lamare"],"url":"https://arxiv.org/abs/2505.11778"}
{"created":"2025-05-20","title":"A Review and Analysis of a Parallel Approach for Decision Tree Learning from Large Data Streams","abstract":"This work studies one of the parallel decision tree learning algorithms, pdsCART, designed for scalable and efficient data analysis. The method incorporates three core capabilities. First, it supports real-time learning from data streams, allowing trees to be constructed incrementally. Second, it enables parallel processing of high-volume streaming data, making it well-suited for large-scale applications. Third, the algorithm integrates seamlessly into the MapReduce framework, ensuring compatibility with distributed computing environments. In what follows, we present the algorithm's key components along with results highlighting its performance and scalability.","authors":["Zeinab Shiralizadeh"],"url":"https://arxiv.org/abs/2505.11780"}
{"created":"2025-05-20","title":"Multi-Order Wavelet Derivative Transform for Deep Time Series Forecasting","abstract":"In deep time series forecasting, the Fourier Transform (FT) is extensively employed for frequency representation learning. However, it often struggles in capturing multi-scale, time-sensitive patterns. Although the Wavelet Transform (WT) can capture these patterns through frequency decomposition, its coefficients are insensitive to change points in time series, leading to suboptimal modeling. To mitigate these limitations, we introduce the multi-order Wavelet Derivative Transform (WDT) grounded in the WT, enabling the extraction of time-aware patterns spanning both the overall trend and subtle fluctuations. Compared with the standard FT and WT, which model the raw series, the WDT operates on the derivative of the series, selectively magnifying rate-of-change cues and exposing abrupt regime shifts that are particularly informative for time series modeling. Practically, we embed the WDT into a multi-branch framework named WaveTS, which decomposes the input series into multi-scale time-frequency coefficients, refines them via linear layers, and reconstructs them into the time domain via the inverse WDT. Extensive experiments on ten benchmark datasets demonstrate that WaveTS achieves state-of-the-art forecasting accuracy while retaining high computational efficiency.","authors":["Ziyu Zhou","Jiaxi Hu","Qingsong Wen","James T. Kwok","Yuxuan Liang"],"url":"https://arxiv.org/abs/2505.11781"}
{"created":"2025-05-20","title":"Efficient Vector Search on Disaggregated Memory with d-HNSW","abstract":"Efficient vector query processing is critical to enable AI applications at scale. Recent solutions struggle with growing vector datasets that exceed single-machine memory capacity, forcing unnecessary data movement and resource underutilization in monolithic architectures. We present d-HNSW, the first disaggregated vector similarity search engine for RDMA-based remote memory systems that achieves high performance while supporting fast data indexing with low network communication overhead. The core of d-HNSW is a novel disaggregation of the graph-based vector indexing data structure HNSW. It exploits the characteristics of greedy searching in HNSW to efficiently coordinate data transfers from the memory pool to the compute pool while serving data requests. Specifically, it leverages three ideas: (i) Representative index caching, a lightweight index constructed from a sampled subset of data, is cached in the compute pool to reduce frequent access to critical components of the hierarchical graph-based index, (ii) RDMA-friendly data layout design to reduce the networking round trips incurred by vector query and insertion and (iii) batched query-aware data loading to reduce bandwidth usage on data transfer between pools, addressing the limited cache capacity in compute nodes. We evaluate d-HNSW with extensive benchmarking datasets. The experimental results show that d-HNSW outperforms Naive d-HNSW implementation by up to 117x in latency while maintaining recall as 0.87 in dataset SIFT1M@1.","authors":["Yi Liu","Fei Fang","Chen Qian"],"url":"https://arxiv.org/abs/2505.11783"}
{"created":"2025-05-20","title":"Utilizing Provenance as an Attribute for Visual Data Analysis: A Design Probe with ProvenanceLens","abstract":"Analytic provenance can be visually encoded to help users track their ongoing analysis trajectories, recall past interactions, and inform new analytic directions. Despite its significance, provenance is often hardwired into analytics systems, affording limited user control and opportunities for self-reflection. We thus propose modeling provenance as an attribute that is available to users during analysis. We demonstrate this concept by modeling two provenance attributes that track the recency and frequency of user interactions with data. We integrate these attributes into a visual data analysis system prototype, ProvenanceLens, wherein users can visualize their interaction recency and frequency by mapping them to encoding channels (e.g., color, size) or applying data transformations (e.g., filter, sort). Using ProvenanceLens as a design probe, we conduct an exploratory study with sixteen users to investigate how these provenance-tracking affordances are utilized for both decision-making and self-reflection. We find that users can accurately and confidently answer questions about their analysis, and we show that mismatches between the user's mental model and the provenance encodings can be surprising, thereby prompting useful self-reflection. We also report on the user strategies surrounding these affordances, and reflect on their intuitiveness and effectiveness in representing provenance.","authors":["Arpit Narechania","Shunan Guo","Eunyee Koh","Alex Endert","Jane Hoffswell"],"url":"https://arxiv.org/abs/2505.11784"}
{"created":"2025-05-20","title":"Improving Coverage in Combined Prediction Sets with Weighted p-values","abstract":"Conformal prediction quantifies the uncertainty of machine learning models by augmenting point predictions with valid prediction sets, assuming exchangeability. For complex scenarios involving multiple trials, models, or data sources, conformal prediction sets can be aggregated to create a prediction set that captures the overall uncertainty, often improving precision. However, aggregating multiple prediction sets with individual $1-\\alpha$ coverage inevitably weakens the overall guarantee, typically resulting in $1-2\\alpha$ worst-case coverage. In this work, we propose a framework for the weighted aggregation of prediction sets, where weights are assigned to each prediction set based on their contribution. Our framework offers flexible control over how the sets are aggregated, achieving tighter coverage bounds that interpolate between the $1-2\\alpha$ guarantee of the combined models and the $1-\\alpha$ guarantee of an individual model depending on the distribution of weights. We extend our framework to data-dependent weights, and we derive a general procedure for data-dependent weight aggregation that maintains finite-sample validity. We demonstrate the effectiveness of our methods through experiments on synthetic and real data in the mixture-of-experts setting, and we show that aggregation with data-dependent weights provides a form of adaptive coverage.","authors":["Gina Wong","Drew Prinster","Suchi Saria","Rama Chellappa","Anqi Liu"],"url":"https://arxiv.org/abs/2505.11785"}
{"created":"2025-05-20","title":"Communication-Efficient Hybrid Language Model via Uncertainty-Aware Opportunistic and Compressed Transmission","abstract":"To support emerging language-based applications using dispersed and heterogeneous computing resources, the hybrid language model (HLM) offers a promising architecture, where an on-device small language model (SLM) generates draft tokens that are validated and corrected by a remote large language model (LLM). However, the original HLM suffers from substantial communication overhead, as the LLM requires the SLM to upload the full vocabulary distribution for each token. Moreover, both communication and computation resources are wasted when the LLM validates tokens that are highly likely to be accepted. To overcome these limitations, we propose communication-efficient and uncertainty-aware HLM (CU-HLM). In CU-HLM, the SLM transmits truncated vocabulary distributions only when its output uncertainty is high. We validate the feasibility of this opportunistic transmission by discovering a strong correlation between SLM's uncertainty and LLM's rejection probability. Furthermore, we theoretically derive optimal uncertainty thresholds and optimal vocabulary truncation strategies. Simulation results show that, compared to standard HLM, CU-HLM achieves up to 206$\\times$ higher token throughput by skipping 74.8% transmissions with 97.4% vocabulary compression, while maintaining 97.4% accuracy.","authors":["Seungeun Oh","Jinhyuk Kim","Jihong Park","Seung-Woo Ko","Jinho Choi","Tony Q. S. Quek","Seong-Lyun Kim"],"url":"https://arxiv.org/abs/2505.11788"}
{"created":"2025-05-20","title":"JULI: Jailbreak Large Language Models by Self-Introspection","abstract":"Large Language Models (LLMs) are trained with safety alignment to prevent generating malicious content. Although some attacks have highlighted vulnerabilities in these safety-aligned LLMs, they typically have limitations, such as necessitating access to the model weights or the generation process. Since proprietary models through API-calling do not grant users such permissions, these attacks find it challenging to compromise them. In this paper, we propose Jailbreaking Using LLM Introspection (JULI), which jailbreaks LLMs by manipulating the token log probabilities, using a tiny plug-in block, BiasNet. JULI relies solely on the knowledge of the target LLM's predicted token log probabilities. It can effectively jailbreak API-calling LLMs under a black-box setting and knowing only top-$5$ token log probabilities. Our approach demonstrates superior effectiveness, outperforming existing state-of-the-art (SOTA) approaches across multiple metrics.","authors":["Jesson Wang","Zhanhao Hu","David Wagner"],"url":"https://arxiv.org/abs/2505.11790"}
{"created":"2025-05-20","title":"Robustness of Incentive Mechanisms Against System Misspecification in Congestion Games","abstract":"To steer the behavior of selfish, resource-sharing agents in a socio-technical system towards the direction of higher efficiency, the system designer requires accurate models of both agent behaviors and the underlying system infrastructure. For instance, traffic controllers often use road latency models to design tolls whose deployment can effectively mitigate traffic congestion. However, misspecifications of system parameters may restrict a system designer's ability to influence collective agent behavior toward efficient outcomes. In this work, we study the impact of system misspecifications on toll design for atomic congestion games. We prove that tolls designed under sufficiently minor system misspecifications, when deployed, do not introduce new Nash equilibria in atomic congestion games compared to tolls designed in the noise-free setting, implying a form of local robustness. We then upper bound the degree to which the worst-case equilibrium system performance could decrease when tolls designed under a given level of system misspecification are deployed. We validate our theoretical results via Monte-Carlo simulations as well as realizations of our worst-case guarantees.","authors":["Chih-Yuan Chiu","Bryce L. Ferguson"],"url":"https://arxiv.org/abs/2505.11791"}
{"created":"2025-05-20","title":"Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling","abstract":"Optimization modeling is fundamental to decision-making across diverse domains.Despite progress in automating optimization formulation from natural language descriptions, Large Language Models (LLMs) often struggle to generate formally correct and usable models due to hallucinations, posing a challenge for reliable automation. Inspired by the success of Reinforcement Learning (RL) in enhancing Large Reasoning Models, we present Solver-Informed Reinforcement Learning (SIRL).This novel framework leverages external optimization solvers as verifiable reward mechanisms to significantly improve the authenticity of LLMs for optimization modeling.Acting as precise verifiers, these solvers automatically assess the executable code and the instance-level mathematical model represented by the associated LP file, yielding precise and comprehensive feedback signals -- including syntax, feasibility, and solution quality that directly inform the RL process. This automated verification process, powered by classic optimization solvers, also underpins our instance-enhanced self-consistency method to synthesize high-quality training data. Extensive experiments on diverse public benchmarks demonstrate that SIRL achieves state-of-the-art performance, substantially outperforming existing methods in generating accurate and executable optimization models.","authors":["Yitian Chen","Jingfan Xia","Siyu Shao","Dongdong Ge","Yinyu Ye"],"url":"https://arxiv.org/abs/2505.11792"}
{"created":"2025-05-20","title":"CL-CaGAN: Capsule differential adversarial continuous learning for cross-domain hyperspectral anomaly detection","abstract":"Anomaly detection (AD) has attracted remarkable attention in hyperspectral image (HSI) processing fields, and most existing deep learning (DL)-based algorithms indicate dramatic potential for detecting anomaly samples through specific training process under current scenario. However, the limited prior information and the catastrophic forgetting problem indicate crucial challenges for existing DL structure in open scenarios cross-domain detection. In order to improve the detection performance, a novel continual learning-based capsule differential generative adversarial network (CL-CaGAN) is proposed to elevate the cross-scenario learning performance for facilitating the real application of DL-based structure in hyperspectral AD (HAD) task. First, a modified capsule structure with adversarial learning network is constructed to estimate the background distribution for surmounting the deficiency of prior information. To mitigate the catastrophic forgetting phenomenon, clustering-based sample replay strategy and a designed extra self-distillation regularization are integrated for merging the history and future knowledge in continual AD task, while the discriminative learning ability from previous detection scenario to current scenario is retained by the elaborately designed structure with continual learning (CL) strategy. In addition, the differentiable enhancement is enforced to augment the generation performance of the training data. This further stabilizes the training process with better convergence and efficiently consolidates the reconstruction ability of background samples. To verify the effectiveness of our proposed CL-CaGAN, we conduct experiments on several real HSIs, and the results indicate that the proposed CL-CaGAN demonstrates higher detection performance and continuous learning capacity for mitigating the catastrophic forgetting under cross-domain scenarios.","authors":["Jianing Wang","Siying Guo","Zheng Hua","Runhu Huang","Jinyu Hu","Maoguo Gong"],"url":"https://arxiv.org/abs/2505.11793"}
{"created":"2025-05-20","title":"Gaussian Splatting as a Unified Representation for Autonomy in Unstructured Environments","abstract":"In this work, we argue that Gaussian splatting is a suitable unified representation for autonomous robot navigation in large-scale unstructured outdoor environments. Such environments require representations that can capture complex structures while remaining computationally tractable for real-time navigation. We demonstrate that the dense geometric and photometric information provided by a Gaussian splatting representation is useful for navigation in unstructured environments. Additionally, semantic information can be embedded in the Gaussian map to enable large-scale task-driven navigation. From the lessons learned through our experiments, we highlight several challenges and opportunities arising from the use of such a representation for robot autonomy.","authors":["Dexter Ong","Yuezhan Tao","Varun Murali","Igor Spasojevic","Vijay Kumar","Pratik Chaudhari"],"url":"https://arxiv.org/abs/2505.11794"}
{"created":"2025-05-20","title":"The Effects of Demographic Instructions on LLM Personas","abstract":"Social media platforms must filter sexist content in compliance with governmental regulations. Current machine learning approaches can reliably detect sexism based on standardized definitions, but often neglect the subjective nature of sexist language and fail to consider individual users' perspectives. To address this gap, we adopt a perspectivist approach, retaining diverse annotations rather than enforcing gold-standard labels or their aggregations, allowing models to account for personal or group-specific views of sexism. Using demographic data from Twitter, we employ large language models (LLMs) to personalize the identification of sexism.","authors":["Angel Felipe Magnoss\\~ao de Paula","J. Shane Culpepper","Alistair Moffat","Sachin Pathiyan Cherumanal","Falk Scholer","Johanne Trippas"],"url":"https://arxiv.org/abs/2505.11795"}
{"created":"2025-05-20","title":"CL-BioGAN: Biologically-Inspired Cross-Domain Continual Learning for Hyperspectral Anomaly Detection","abstract":"Memory stability and learning flexibility in continual learning (CL) is a core challenge for cross-scene Hyperspectral Anomaly Detection (HAD) task. Biological neural networks can actively forget history knowledge that conflicts with the learning of new experiences by regulating learning-triggered synaptic expansion and synaptic convergence. Inspired by this phenomenon, we propose a novel Biologically-Inspired Continual Learning Generative Adversarial Network (CL-BioGAN) for augmenting continuous distribution fitting ability for cross-domain HAD task, where Continual Learning Bio-inspired Loss (CL-Bio Loss) and self-attention Generative Adversarial Network (BioGAN) are incorporated to realize forgetting history knowledge as well as involving replay strategy in the proposed BioGAN. Specifically, a novel Bio-Inspired Loss composed with an Active Forgetting Loss (AF Loss) and a CL loss is designed to realize parameters releasing and enhancing between new task and history tasks from a Bayesian perspective. Meanwhile, BioGAN loss with L2-Norm enhances self-attention (SA) to further balance the stability and flexibility for better fitting background distribution for open scenario HAD (OHAD) tasks. Experiment results underscore that the proposed CL-BioGAN can achieve more robust and satisfying accuracy for cross-domain HAD with fewer parameters and computation cost. This dual contribution not only elevates CL performance but also offers new insights into neural adaptation mechanisms in OHAD task.","authors":["Jianing Wang","Zheng Hua","Wan Zhang","Shengjia Hao","Yuqiong Yao","Maoguo Gong"],"url":"https://arxiv.org/abs/2505.11796"}
{"created":"2025-05-20","title":"Generating Digital Models Using Text-to-3D and Image-to-3D Prompts: Critical Case Study","abstract":"In the world of technology and AI, digital models play an important role in our lives and are an essential part of the digital twins of real-world objects. They can be created by designers, artists, or game developers using spline curves and surfaces, meshes, and voxels, but making such models is too time-consuming. With the growth of AI tools, there is interest in the automated generation of 3D models, such as generative design approaches, which can save creators valuable time. This paper reviews several online 3D model generators and critically analyses the results, hoping to see higher-quality results from different prompts.","authors":["Rushan Ziatdinov","Rifkat Nabiyev"],"url":"https://arxiv.org/abs/2505.11799"}
{"created":"2025-05-20","title":"Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model","abstract":"Hyperspectral and multispectral image (HSI-MSI) fusion involves combining a low-resolution hyperspectral image (LR-HSI) with a high-resolution multispectral image (HR-MSI) to generate a high-resolution hyperspectral image (HR-HSI). Most deep learning-based methods for HSI-MSI fusion rely on large amounts of hyperspectral data for supervised training, which is often scarce in practical applications. In this paper, we propose a self-learning Adaptive Residual Guided Subspace Diffusion Model (ARGS-Diff), which only utilizes the observed images without any extra training data. Specifically, as the LR-HSI contains spectral information and the HR-MSI contains spatial information, we design two lightweight spectral and spatial diffusion models to separately learn the spectral and spatial distributions from them. Then, we use these two models to reconstruct HR-HSI from two low-dimensional components, i.e, the spectral basis and the reduced coefficient, during the reverse diffusion process. Furthermore, we introduce an Adaptive Residual Guided Module (ARGM), which refines the two components through a residual guided function at each sampling step, thereby stabilizing the sampling process. Extensive experimental results demonstrate that ARGS-Diff outperforms existing state-of-the-art methods in terms of both performance and computational efficiency in the field of HSI-MSI fusion. Code is available at https://github.com/Zhu1116/ARGS-Diff.","authors":["Jian Zhu","He Wang","Yang Xu","Zebin Wu","Zhihui Wei"],"url":"https://arxiv.org/abs/2505.11800"}
{"created":"2025-05-20","title":"Diffmv: A Unified Diffusion Framework for Healthcare Predictions with Random Missing Views and View Laziness","abstract":"Advanced healthcare predictions offer significant improvements in patient outcomes by leveraging predictive analytics. Existing works primarily utilize various views of Electronic Health Record (EHR) data, such as diagnoses, lab tests, or clinical notes, for model training. These methods typically assume the availability of complete EHR views and that the designed model could fully leverage the potential of each view. However, in practice, random missing views and view laziness present two significant challenges that hinder further improvements in multi-view utilization. To address these challenges, we introduce Diffmv, an innovative diffusion-based generative framework designed to advance the exploitation of multiple views of EHR data. Specifically, to address random missing views, we integrate various views of EHR data into a unified diffusion-denoising framework, enriched with diverse contextual conditions to facilitate progressive alignment and view transformation. To mitigate view laziness, we propose a novel reweighting strategy that assesses the relative advantages of each view, promoting a balanced utilization of various data views within the model. Our proposed strategy achieves superior performance across multiple health prediction tasks derived from three popular datasets, including multi-view and multi-modality scenarios.","authors":["Chuang Zhao","Hui Tang","Hongke Zhao","Xiaomeng Li"],"url":"https://arxiv.org/abs/2505.11802"}
{"created":"2025-05-20","title":"VITA: Versatile Time Representation Learning for Temporal Hyper-Relational Knowledge Graphs","abstract":"Knowledge graphs (KGs) have become an effective paradigm for managing real-world facts, which are not only complex but also dynamically evolve over time. The temporal validity of facts often serves as a strong clue in downstream link prediction tasks, which predicts a missing element in a fact. Traditional link prediction techniques on temporal KGs either consider a sequence of temporal snapshots of KGs with an ad-hoc defined time interval or expand a temporal fact over its validity period under a predefined time granularity; these approaches not only suffer from the sensitivity of the selection of time interval/granularity, but also face the computational challenges when handling facts with long (even infinite) validity. Although the recent hyper-relational KGs represent the temporal validity of a fact as qualifiers describing the fact, it is still suboptimal due to its ignorance of the infinite validity of some facts and the insufficient information encoded from the qualifiers about the temporal validity. Against this background, we propose VITA, a $\\underline{V}$ersatile t$\\underline{I}$me represen$\\underline{TA}$tion learning method for temporal hyper-relational knowledge graphs. We first propose a versatile time representation that can flexibly accommodate all four types of temporal validity of facts (i.e., since, until, period, time-invariant), and then design VITA to effectively learn the time information in both aspects of time value and timespan to boost the link prediction performance. We conduct a thorough evaluation of VITA compared to a sizable collection of baselines on real-world KG datasets. Results show that VITA outperforms the best-performing baselines in various link prediction tasks (predicting missing entities, relations, time, and other numeric literals) by up to 75.3%. Ablation studies and a case study also support our key design choices.","authors":["ChongIn Un","Yuhuan Lu","Tianyue Yang","Dingqi Yang"],"url":"https://arxiv.org/abs/2505.11803"}
{"created":"2025-05-20","title":"Are vision language models robust to uncertain inputs?","abstract":"Robustness against uncertain and ambiguous inputs is a critical challenge for deep learning models. While recent advancements in large scale vision language models (VLMs, e.g. GPT4o) might suggest that increasing model and training dataset size would mitigate this issue, our empirical evaluation shows a more complicated picture. Testing models using two classic uncertainty quantification tasks, anomaly detection and classification under inherently ambiguous conditions, we find that newer and larger VLMs indeed exhibit improved robustness compared to earlier models, but still suffer from a tendency to strictly follow instructions, often causing them to hallucinate confident responses even when faced with unclear or anomalous inputs. Remarkably, for natural images such as ImageNet, this limitation can be overcome without pipeline modifications: simply prompting models to abstain from uncertain predictions enables significant reliability gains, achieving near-perfect robustness in several settings. However, for domain-specific tasks such as galaxy morphology classification, a lack of specialized knowledge prevents reliable uncertainty estimation. Finally, we propose a novel mechanism based on caption diversity to reveal a model's internal uncertainty, enabling practitioners to predict when models will successfully abstain without relying on labeled data.","authors":["Xi Wang","Eric Nalisnick"],"url":"https://arxiv.org/abs/2505.11804"}
{"created":"2025-05-20","title":"Retrospex: Language Agent Meets Offline Reinforcement Learning Critic","abstract":"Large Language Models (LLMs) possess extensive knowledge and commonsense reasoning capabilities, making them valuable for creating powerful agents. However, existing LLM agent frameworks have not fully utilized past experiences for improvement. This work introduces a new LLM-based agent framework called Retrospex, which addresses this challenge by analyzing past experiences in depth. Unlike previous approaches, Retrospex does not directly integrate experiences into the LLM's context. Instead, it combines the LLM's action likelihood with action values estimated by a Reinforcement Learning (RL) Critic, which is trained on past experiences through an offline ''retrospection'' process. Additionally, Retrospex employs a dynamic action rescoring mechanism that increases the importance of experience-based values for tasks that require more interaction with the environment. We evaluate Retrospex in ScienceWorld, ALFWorld and Webshop environments, demonstrating its advantages over strong, contemporary baselines.","authors":["Yufei Xiang","Yiqun Shen","Yeqin Zhang","Cam-Tu Nguyen"],"url":"https://arxiv.org/abs/2505.11807"}
{"created":"2025-05-20","title":"Human-Centered Development of Guide Dog Robots: Quiet and Stable Locomotion Control","abstract":"A quadruped robot is a promising system that can offer assistance comparable to that of dog guides due to its similar form factor. However, various challenges remain in making these robots a reliable option for blind and low-vision (BLV) individuals. Among these challenges, noise and jerky motion during walking are critical drawbacks of existing quadruped robots. While these issues have largely been overlooked in guide dog robot research, our interviews with guide dog handlers and trainers revealed that acoustic and physical disturbances can be particularly disruptive for BLV individuals, who rely heavily on environmental sounds for navigation. To address these issues, we developed a novel walking controller for slow stepping and smooth foot swing/contact while maintaining human walking speed, as well as robust and stable balance control. The controller integrates with a perception system to facilitate locomotion over non-flat terrains, such as stairs. Our controller was extensively tested on the Unitree Go1 robot and, when compared with other control methods, demonstrated significant noise reduction -- half of the default locomotion controller. In this study, we adopt a mixed-methods approach to evaluate its usability with BLV individuals. In our indoor walking experiments, participants compared our controller to the robot's default controller. Results demonstrated superior acceptance of our controller, highlighting its potential to improve the user experience of guide dog robots. Video demonstration (best viewed with audio) available at: https://youtu.be/8-pz_8Hqe6s.","authors":["Shangqun Yu","Hochul Hwang","Trung M. Dang","Joydeep Biswas","Nicholas A. Giudice","Sunghoon Ivan Lee","Donghyun Kim"],"url":"https://arxiv.org/abs/2505.11808"}
{"created":"2025-05-20","title":"Image-based Visibility Analysis Replacing Line-of-Sight Simulation: An Urban Landmark Perspective","abstract":"Visibility analysis is one of the fundamental analytics methods in urban planning and landscape research, traditionally conducted through computational simulations based on the Line-of-Sight (LoS) principle. However, when assessing the visibility of named urban objects such as landmarks, geometric intersection alone fails to capture the contextual and perceptual dimensions of visibility as experienced in the real world. The study challenges the traditional LoS-based approaches by introducing a new, image-based visibility analysis method. Specifically, a Vision Language Model (VLM) is applied to detect the target object within a direction-zoomed Street View Image (SVI). Successful detection represents the object's visibility at the corresponding SVI location. Further, a heterogeneous visibility graph is constructed to address the complex interaction between observers and target objects. In the first case study, the method proves its reliability in detecting the visibility of six tall landmark constructions in global cities, with an overall accuracy of 87%. Furthermore, it reveals broader contextual differences when the landmarks are perceived and experienced. In the second case, the proposed visibility graph uncovers the form and strength of connections for multiple landmarks along the River Thames in London, as well as the places where these connections occur. Notably, bridges on the River Thames account for approximately 30% of total connections. Our method complements and enhances traditional LoS-based visibility analysis, and showcases the possibility of revealing the prevalent connection of any visual objects in the urban environment. It opens up new research perspectives for urban planning, heritage conservation, and computational social science.","authors":["Zicheng Fan","Kunihiko Fujiwara","Pengyuan Liu","Fan Zhang","Filip Biljecki"],"url":"https://arxiv.org/abs/2505.11809"}
{"created":"2025-05-20","title":"Efficiently Building a Domain-Specific Large Language Model from Scratch: A Case Study of a Classical Chinese Large Language Model","abstract":"General-purpose large language models demonstrate notable capabilities in language comprehension and generation, achieving results that are comparable to, or even surpass, human performance in many language information processing tasks. Nevertheless, when general models are applied to some specific domains, e.g., Classical Chinese texts, their effectiveness is often unsatisfactory, and fine-tuning open-source foundational models similarly struggles to adequately incorporate domain-specific knowledge. To address this challenge, this study developed a large language model, AI Taiyan, specifically designed for understanding and generating Classical Chinese. Experiments show that with a reasonable model design, data processing, foundational training, and fine-tuning, satisfactory results can be achieved with only 1.8 billion parameters. In key tasks related to Classical Chinese information processing such as punctuation, identification of allusions, explanation of word meanings, and translation between ancient and modern Chinese, this model exhibits a clear advantage over both general-purpose large models and domain-specific traditional models, achieving levels close to or surpassing human baselines. This research provides a reference for the efficient construction of specialized domain-specific large language models. Furthermore, the paper discusses the application of this model in fields such as the collation of ancient texts, dictionary editing, and language research, combined with case studies.","authors":["Shen Li","Renfen Hu","Lijun Wang"],"url":"https://arxiv.org/abs/2505.11810"}
{"created":"2025-05-20","title":"BELLE: A Bi-Level Multi-Agent Reasoning Framework for Multi-Hop Question Answering","abstract":"Multi-hop question answering (QA) involves finding multiple relevant passages and performing step-by-step reasoning to answer complex questions. Previous works on multi-hop QA employ specific methods from different modeling perspectives based on large language models (LLMs), regardless of the question types. In this paper, we first conduct an in-depth analysis of public multi-hop QA benchmarks, dividing the questions into four types and evaluating five types of cutting-edge methods for multi-hop QA: Chain-of-Thought (CoT), Single-step, Iterative-step, Sub-step, and Adaptive-step. We find that different types of multi-hop questions have varying degrees of sensitivity to different types of methods. Thus, we propose a Bi-levEL muLti-agEnt reasoning (BELLE) framework to address multi-hop QA by specifically focusing on the correspondence between question types and methods, where each type of method is regarded as an ''operator'' by prompting LLMs differently. The first level of BELLE includes multiple agents that debate to obtain an executive plan of combined ''operators'' to address the multi-hop QA task comprehensively. During the debate, in addition to the basic roles of affirmative debater, negative debater, and judge, at the second level, we further leverage fast and slow debaters to monitor whether changes in viewpoints are reasonable. Extensive experiments demonstrate that BELLE significantly outperforms strong baselines in various datasets. Additionally, the model consumption of BELLE is higher cost-effectiveness than that of single models in more complex multi-hop QA scenarios.","authors":["Taolin Zhang","Dongyang Li","Qizhou Chen","Chengyu Wang","Xiaofeng He"],"url":"https://arxiv.org/abs/2505.11811"}
{"created":"2025-05-20","title":"VenusX: Unlocking Fine-Grained Functional Understanding of Proteins","abstract":"Deep learning models have driven significant progress in predicting protein function and interactions at the protein level. While these advancements have been invaluable for many biological applications such as enzyme engineering and function annotation, a more detailed perspective is essential for understanding protein functional mechanisms and evaluating the biological knowledge captured by models. To address this demand, we introduce VenusX, the first large-scale benchmark for fine-grained functional annotation and function-based protein pairing at the residue, fragment, and domain levels. VenusX comprises three major task categories across six types of annotations, including residue-level binary classification, fragment-level multi-class classification, and pairwise functional similarity scoring for identifying critical active sites, binding sites, conserved sites, motifs, domains, and epitopes. The benchmark features over 878,000 samples curated from major open-source databases such as InterPro, BioLiP, and SAbDab. By providing mixed-family and cross-family splits at three sequence identity thresholds, our benchmark enables a comprehensive assessment of model performance on both in-distribution and out-of-distribution scenarios. For baseline evaluation, we assess a diverse set of popular and open-source models, including pre-trained protein language models, sequence-structure hybrids, structure-based methods, and alignment-based techniques. Their performance is reported across all benchmark datasets and evaluation settings using multiple metrics, offering a thorough comparison and a strong foundation for future research. Code and data are publicly available at https://github.com/ai4protein/VenusX.","authors":["Yang Tan","Wenrui Gou","Bozitao Zhong","Liang Hong","Huiqun Yu","Bingxin Zhou"],"url":"https://arxiv.org/abs/2505.11812"}
{"created":"2025-05-20","title":"SGD-Mix: Enhancing Domain-Specific Image Classification with Label-Preserving Data Augmentation","abstract":"Data augmentation for domain-specific image classification tasks often struggles to simultaneously address diversity, faithfulness, and label clarity of generated data, leading to suboptimal performance in downstream tasks. While existing generative diffusion model-based methods aim to enhance augmentation, they fail to cohesively tackle these three critical aspects and often overlook intrinsic challenges of diffusion models, such as sensitivity to model characteristics and stochasticity under strong transformations. In this paper, we propose a novel framework that explicitly integrates diversity, faithfulness, and label clarity into the augmentation process. Our approach employs saliency-guided mixing and a fine-tuned diffusion model to preserve foreground semantics, enrich background diversity, and ensure label consistency, while mitigating diffusion model limitations. Extensive experiments across fine-grained, long-tail, few-shot, and background robustness tasks demonstrate our method's superior performance over state-of-the-art approaches.","authors":["Yixuan Dong","Fang-Yi Su","Jung-Hsien Chiang"],"url":"https://arxiv.org/abs/2505.11813"}
{"created":"2025-05-20","title":"ChatHTN: Interleaving Approximate (LLM) and Symbolic HTN Planning","abstract":"We introduce ChatHTN, a Hierarchical Task Network (HTN) planner that combines symbolic HTN planning techniques with queries to ChatGPT to approximate solutions in the form of task decompositions. The resulting hierarchies interleave task decompositions generated by symbolic HTN planning with those generated by ChatGPT. Despite the approximate nature of the results generates by ChatGPT, ChatHTN is provably sound; any plan it generates correctly achieves the input tasks. We demonstrate this property with an open-source implementation of our system.","authors":["Hector Munoz-Avila","David W. Aha","Paola Rizzo"],"url":"https://arxiv.org/abs/2505.11814"}
{"created":"2025-05-20","title":"UniMoCo: Unified Modality Completion for Robust Multi-Modal Embeddings","abstract":"Current research has explored vision-language models for multi-modal embedding tasks, such as information retrieval, visual grounding, and classification. However, real-world scenarios often involve diverse modality combinations between queries and targets, such as text and image to text, text and image to text and image, and text to text and image. These diverse combinations pose significant challenges for existing models, as they struggle to align all modality combinations within a unified embedding space during training, which degrades performance at inference. To address this limitation, we propose UniMoCo, a novel vision-language model architecture designed for multi-modal embedding tasks. UniMoCo introduces a modality-completion module that generates visual features from textual inputs, ensuring modality completeness for both queries and targets. Additionally, we develop a specialized training strategy to align embeddings from both original and modality-completed inputs, ensuring consistency within the embedding space. This enables the model to robustly handle a wide range of modality combinations across embedding tasks. Experiments show that UniMoCo outperforms previous methods while demonstrating consistent robustness across diverse settings. More importantly, we identify and quantify the inherent bias in conventional approaches caused by imbalance of modality combinations in training data, which can be mitigated through our modality-completion paradigm. The code is available at https://github.com/HobbitQia/UniMoCo.","authors":["Jiajun Qin","Yuan Pu","Zhuolun He","Seunggeun Kim","David Z. Pan","Bei Yu"],"url":"https://arxiv.org/abs/2505.11815"}
{"created":"2025-05-20","title":"Continuous Subspace Optimization for Continual Learning","abstract":"Continual learning aims to learn multiple tasks sequentially while preserving prior knowledge, but faces the challenge of catastrophic forgetting when acquiring new knowledge. Recently, approaches leveraging pre-trained models have gained increasing popularity to mitigate this issue, due to the strong generalization ability of foundation models. To adjust pre-trained models for new tasks, existing methods usually employ low-rank adaptation, which restricts parameter updates to a fixed low-rank subspace. However, constraining the optimization space inherently compromises the model's learning capacity, resulting in inferior performance. To address the limitation, we propose Continuous Subspace Optimization for Continual Learning (CoSO) to fine-tune the model in a series of subspaces rather than a single one. These sequential subspaces are dynamically determined through the singular value decomposition of gradients. CoSO updates the model by projecting gradients into these subspaces, ensuring memory-efficient optimization. To mitigate forgetting, the optimization subspaces of each task are set to be orthogonal to the historical task subspace. During task learning, CoSO maintains a task-specific component that captures the critical update directions associated with the current task. Upon completing a task, this component is used to update the historical task subspace, laying the groundwork for subsequent learning. Extensive experiments on multiple datasets demonstrate that CoSO significantly outperforms state-of-the-art methods, especially in challenging scenarios with long task sequences.","authors":["Quan Cheng","Yuanyu Wan","Lingyu Wu","Chenping Hou","Lijun Zhang"],"url":"https://arxiv.org/abs/2505.11816"}
{"created":"2025-05-20","title":"Master Rules from Chaos: Learning to Reason, Plan, and Interact from Chaos for Tangram Assembly","abstract":"Tangram assembly, the art of human intelligence and manipulation dexterity, is a new challenge for robotics and reveals the limitations of state-of-the-arts. Here, we describe our initial exploration and highlight key problems in reasoning, planning, and manipulation for robotic tangram assembly. We present MRChaos (Master Rules from Chaos), a robust and general solution for learning assembly policies that can generalize to novel objects. In contrast to conventional methods based on prior geometric and kinematic models, MRChaos learns to assemble randomly generated objects through self-exploration in simulation without prior experience in assembling target objects. The reward signal is obtained from the visual observation change without manually designed models or annotations. MRChaos retains its robustness in assembling various novel tangram objects that have never been encountered during training, with only silhouette prompts. We show the potential of MRChaos in wider applications such as cutlery combinations. The presented work indicates that radical generalization in robotic assembly can be achieved by learning in much simpler domains.","authors":["Chao Zhao","Chunli Jiang","Lifan Luo","Guanlan Zhang","Hongyu Yu","Michael Yu Wang","Qifeng Chen"],"url":"https://arxiv.org/abs/2505.11818"}
{"created":"2025-05-20","title":"Chain-of-Model Learning for Language Model","abstract":"In this paper, we propose a novel learning paradigm, termed Chain-of-Model (CoM), which incorporates the causal relationship into the hidden states of each layer as a chain style, thereby introducing great scaling efficiency in model training and inference flexibility in deployment. We introduce the concept of Chain-of-Representation (CoR), which formulates the hidden states at each layer as a combination of multiple sub-representations (i.e., chains) at the hidden dimension level. In each layer, each chain from the output representations can only view all of its preceding chains in the input representations. Consequently, the model built upon CoM framework can progressively scale up the model size by increasing the chains based on the previous models (i.e., chains), and offer multiple sub-models at varying sizes for elastic inference by using different chain numbers. Based on this principle, we devise Chain-of-Language-Model (CoLM), which incorporates the idea of CoM into each layer of Transformer architecture. Based on CoLM, we further introduce CoLM-Air by introducing a KV sharing mechanism, that computes all keys and values within the first chain and then shares across all chains. This design demonstrates additional extensibility, such as enabling seamless LM switching, prefilling acceleration and so on. Experimental results demonstrate our CoLM family can achieve comparable performance to the standard Transformer, while simultaneously enabling greater flexiblity, such as progressive scaling to improve training efficiency and offer multiple varying model sizes for elastic inference, paving a a new way toward building language models. Our code will be released in the future at: https://github.com/microsoft/CoLM.","authors":["Kaitao Song","Xiaohua Wang","Xu Tan","Huiqiang Jiang","Chengruidong Zhang","Yongliang Shen","Cen LU","Zihao Li","Zifan Song","Caihua Shan","Yansen Wang","Kan Ren","Xiaoqing Zheng","Tao Qin","Yuqing Yang","Dongsheng Li","Lili Qiu"],"url":"https://arxiv.org/abs/2505.11820"}
{"created":"2025-05-20","title":"Reinforcing Multi-Turn Reasoning in LLM Agents via Turn-Level Credit Assignment","abstract":"This paper investigates approaches to enhance the reasoning capabilities of Large Language Model (LLM) agents using Reinforcement Learning (RL). Specifically, we focus on multi-turn tool-use scenarios, which can be naturally modeled as Markov Decision Processes (MDPs). While existing approaches often train multi-turn LLM agents with trajectory-level advantage estimation in bandit settings, they struggle with turn-level credit assignment across multiple decision steps, limiting their performance on multi-turn reasoning tasks. To address this, we introduce a fine-grained turn-level advantage estimation strategy to enable more precise credit assignment in multi-turn agent interactions. The strategy is general and can be incorporated into various RL algorithms such as Group Relative Preference Optimization (GRPO). Our experimental evaluation on multi-turn reasoning and search-based tool-use tasks with GRPO implementations highlights the effectiveness of the MDP framework and the turn-level credit assignment in advancing the multi-turn reasoning capabilities of LLM agents in complex decision-making settings. Our method achieves 100% success in tool execution and 50% accuracy in exact answer matching, significantly outperforming baselines, which fail to invoke tools and achieve only 20-30% exact match accuracy.","authors":["Siliang Zeng","Quan Wei","William Brown","Oana Frunza","Yuriy Nevmyvaka","Mingyi Hong"],"url":"https://arxiv.org/abs/2505.11821"}
{"created":"2025-05-20","title":"Robust Cross-View Geo-Localization via Content-Viewpoint Disentanglement","abstract":"Cross-view geo-localization (CVGL) aims to match images of the same geographic location captured from different perspectives, such as drones and satellites. Despite recent advances, CVGL remains highly challenging due to significant appearance changes and spatial distortions caused by viewpoint variations. Existing methods typically assume that cross-view images can be directly aligned within a shared feature space by maximizing feature similarity through contrastive learning. Nonetheless, this assumption overlooks the inherent conflicts induced by viewpoint discrepancies, resulting in extracted features containing inconsistent information that hinders precise localization. In this study, we take a manifold learning perspective and model the feature space of cross-view images as a composite manifold jointly governed by content and viewpoint information. Building upon this insight, we propose $\\textbf{CVD}$, a new CVGL framework that explicitly disentangles $\\textit{content}$ and $\\textit{viewpoint}$ factors. To promote effective disentanglement, we introduce two constraints: $\\textit{(i)}$ An intra-view independence constraint, which encourages statistical independence between the two factors by minimizing their mutual information. $\\textit{(ii)}$ An inter-view reconstruction constraint that reconstructs each view by cross-combining $\\textit{content}$ and $\\textit{viewpoint}$ from paired images, ensuring factor-specific semantics are preserved. As a plug-and-play module, CVD can be seamlessly integrated into existing geo-localization pipelines. Extensive experiments on four benchmarks, i.e., University-1652, SUES-200, CVUSA, and CVACT, demonstrate that CVD consistently improves both localization accuracy and generalization across multiple baselines.","authors":["Ke Li","Di Wang","Xiaowei Wang","Zhihong Wu","Yiming Zhang","Yifeng Wang","Quan Wang"],"url":"https://arxiv.org/abs/2505.11822"}
{"created":"2025-05-20","title":"Variational Regularized Unbalanced Optimal Transport: Single Network, Least Action","abstract":"Recovering the dynamics from a few snapshots of a high-dimensional system is a challenging task in statistical physics and machine learning, with important applications in computational biology. Many algorithms have been developed to tackle this problem, based on frameworks such as optimal transport and the Schr\\\"odinger bridge. A notable recent framework is Regularized Unbalanced Optimal Transport (RUOT), which integrates both stochastic dynamics and unnormalized distributions. However, since many existing methods do not explicitly enforce optimality conditions, their solutions often struggle to satisfy the principle of least action and meet challenges to converge in a stable and reliable way. To address these issues, we propose Variational RUOT (Var-RUOT), a new framework to solve the RUOT problem. By incorporating the optimal necessary conditions for the RUOT problem into both the parameterization of the search space and the loss function design, Var-RUOT only needs to learn a scalar field to solve the RUOT problem and can search for solutions with lower action. We also examined the challenge of selecting a growth penalty function in the widely used Wasserstein-Fisher-Rao metric and proposed a solution that better aligns with biological priors in Var-RUOT. We validated the effectiveness of Var-RUOT on both simulated data and real single-cell datasets. Compared with existing algorithms, Var-RUOT can find solutions with lower action while exhibiting faster convergence and improved training stability.","authors":["Yuhao Sun","Zhenyi Zhang","Zihan Wang","Tiejun Li","Peijie Zhou"],"url":"https://arxiv.org/abs/2505.11823"}
{"created":"2025-05-20","title":"Search-Based Correction of Reasoning Chains for Language Models","abstract":"Chain-of-Thought (CoT) reasoning has advanced the capabilities and transparency of language models (LMs); however, reasoning chains can contain inaccurate statements that reduce performance and trustworthiness. To address this, we introduce a new self-correction framework that augments each reasoning step in a CoT with a latent variable indicating its veracity, enabling modeling of all possible truth assignments rather than assuming correctness throughout. To efficiently explore this expanded space, we introduce Search Corrector, a discrete search algorithm over boolean-valued veracity assignments. It efficiently performs otherwise intractable inference in the posterior distribution over veracity assignments by leveraging the LM's joint likelihood over veracity and the final answer as a proxy reward. This efficient inference-time correction method facilitates supervised fine-tuning of an Amortized Corrector by providing pseudo-labels for veracity. The Amortized Corrector generalizes self-correction, enabling accurate zero-shot veracity inference in novel contexts. Empirical results demonstrate that Search Corrector reliably identifies errors in logical (ProntoQA) and mathematical reasoning (GSM8K) benchmarks. The Amortized Corrector achieves comparable zero-shot accuracy and improves final answer accuracy by up to 25%.","authors":["Minsu Kim","Jean-Pierre Falet","Oliver E. Richardson","Xiaoyin Chen","Moksh Jain","Sungjin Ahn","Sungsoo Ahn","Yoshua Bengio"],"url":"https://arxiv.org/abs/2505.11824"}
{"created":"2025-05-20","title":"Bootstrapping Diffusion: Diffusion Model Training Leveraging Partial and Corrupted Data","abstract":"Training diffusion models requires large datasets. However, acquiring large volumes of high-quality data can be challenging, for example, collecting large numbers of high-resolution images and long videos. On the other hand, there are many complementary data that are usually considered corrupted or partial, such as low-resolution images and short videos. Other examples of corrupted data include videos that contain subtitles, watermarks, and logos. In this study, we investigate the theoretical problem of whether the above partial data can be utilized to train conventional diffusion models. Motivated by our theoretical analysis in this study, we propose a straightforward approach of training diffusion models utilizing partial data views, where we consider each form of complementary data as a view of conventional data. Our proposed approach first trains one separate diffusion model for each individual view, and then trains a model for predicting the residual score function. We prove generalization error bounds, which show that the proposed diffusion model training approach can achieve lower generalization errors if proper regularizations are adopted in the residual score function training. In particular, we prove that the difficulty in training the residual score function scales proportionally with the signal correlations not captured by partial data views. Consequently, the proposed approach achieves near first-order optimal data efficiency.","authors":["Xudong Ma"],"url":"https://arxiv.org/abs/2505.11825"}
{"created":"2025-05-20","title":"Not All Thoughts are Generated Equal: Efficient LLM Reasoning via Multi-Turn Reinforcement Learning","abstract":"Compressing long chain-of-thought (CoT) from large language models (LLMs) is an emerging strategy to improve the reasoning efficiency of LLMs. Despite its promising benefits, existing studies equally compress all thoughts within a long CoT, hindering more concise and effective reasoning. To this end, we first investigate the importance of different thoughts by examining their effectiveness and efficiency in contributing to reasoning through automatic long CoT chunking and Monte Carlo rollouts. Building upon the insights, we propose a theoretically bounded metric to jointly measure the effectiveness and efficiency of different thoughts. We then propose Long$\\otimes$Short, an efficient reasoning framework that enables two LLMs to collaboratively solve the problem: a long-thought LLM for more effectively generating important thoughts, while a short-thought LLM for efficiently generating remaining thoughts. Specifically, we begin by synthesizing a small amount of cold-start data to fine-tune LLMs for long-thought and short-thought reasoning styles, respectively. Furthermore, we propose a synergizing-oriented multi-turn reinforcement learning, focusing on the model self-evolution and collaboration between long-thought and short-thought LLMs. Experimental results show that our method enables Qwen2.5-7B and Llama3.1-8B to achieve comparable performance compared to DeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B, while reducing token length by over 80% across the MATH500, AIME24/25, AMC23, and GPQA Diamond benchmarks. Our data and code are available at https://github.com/yasNing/Long-otimes-Short/.","authors":["Yansong Ning","Wei Li","Jun Fang","Naiqiang Tan","Hao Liu"],"url":"https://arxiv.org/abs/2505.11827"}
{"created":"2025-05-20","title":"Class Distillation with Mahalanobis Contrast: An Efficient Training Paradigm for Pragmatic Language Understanding Tasks","abstract":"Detecting deviant language such as sexism, or nuanced language such as metaphors or sarcasm, is crucial for enhancing the safety, clarity, and interpretation of online social discourse. While existing classifiers deliver strong results on these tasks, they often come with significant computational cost and high data demands. In this work, we propose \\textbf{Cla}ss \\textbf{D}istillation (ClaD), a novel training paradigm that targets the core challenge: distilling a small, well-defined target class from a highly diverse and heterogeneous background. ClaD integrates two key innovations: (i) a loss function informed by the structural properties of class distributions, based on Mahalanobis distance, and (ii) an interpretable decision algorithm optimized for class separation. Across three benchmark detection tasks -- sexism, metaphor, and sarcasm -- ClaD outperforms competitive baselines, and even with smaller language models and orders of magnitude fewer parameters, achieves performance comparable to several large language models (LLMs). These results demonstrate ClaD as an efficient tool for pragmatic language understanding tasks that require gleaning a small target class from a larger heterogeneous background.","authors":["Chenlu Wang","Weimin Lyu","Ritwik Banerjee"],"url":"https://arxiv.org/abs/2505.11829"}
{"created":"2025-05-20","title":"CoT-Vid: Dynamic Chain-of-Thought Routing with Self Verification for Training-Free Video Reasoning","abstract":"System2 reasoning is developing rapidly these days with the emergence of Deep- Thinking Models and chain-of-thought technology, which has become a centralized discussion point in the AI community. However, there is a relative gap in the research on complex video reasoning at present. In this work, we propose CoT-Vid, a novel training-free paradigm for the video domain with a multistage complex reasoning design. Distinguishing from existing video LLMs, which rely heavily on perceptual abilities, it achieved surprising performance gain with explicit reasoning mechanism. The paradigm consists of three main components: dynamic inference path routing, problem decoupling strategy, and video self-consistency verification. In addition, we propose a new standard for categorization of video questions. CoT- Vid showed outstanding results on a wide range of benchmarks, and outperforms its base model by 9.3% on Egochema and 5.6% on VideoEspresso, rivalling or even surpassing larger and proprietary models, such as GPT-4V, GPT-4o and Gemini-1.5-flash. Our codebase will be publicly available soon.","authors":["Hongbo Jin","Ruyang Liu","Wenhao Zhang","Guibo Luo","Ge Li"],"url":"https://arxiv.org/abs/2505.11830"}
{"created":"2025-05-20","title":"ARC-AGI-2: A New Challenge for Frontier AI Reasoning Systems","abstract":"The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI), introduced in 2019, established a challenging benchmark for evaluating the general fluid intelligence of artificial systems via a set of unique, novel tasks only requiring minimal prior knowledge. While ARC-AGI has spurred significant research activity over the past five years, recent AI progress calls for benchmarks capable of finer-grained evaluation at higher levels of cognitive complexity. We introduce ARC-AGI-2, an upgraded version of the benchmark. ARC-AGI-2 preserves the input-output pair task format of its predecessor, ensuring continuity for researchers. It incorporates a newly curated and expanded set of tasks specifically designed to provide a more granular signal to assess abstract reasoning and problem-solving abilities at higher levels of fluid intelligence. To contextualize the difficulty and characteristics of ARC-AGI-2, we present extensive results from human testing, providing a robust baseline that highlights the benchmark's accessibility to human intelligence, yet difficulty for current AI systems. ARC-AGI-2 aims to serve as a next-generation tool for rigorously measuring progress towards more general and human-like AI capabilities.","authors":["Francois Chollet","Mike Knoop","Gregory Kamradt","Bryan Landers","Henry Pinkard"],"url":"https://arxiv.org/abs/2505.11831"}
{"created":"2025-05-20","title":"ToLeaP: Rethinking Development of Tool Learning with Large Language Models","abstract":"Tool learning, which enables large language models (LLMs) to utilize external tools effectively, has garnered increasing attention for its potential to revolutionize productivity across industries. Despite rapid development in tool learning, key challenges and opportunities remain understudied, limiting deeper insights and future advancements. In this paper, we investigate the tool learning ability of 41 prevalent LLMs by reproducing 33 benchmarks and enabling one-click evaluation for seven of them, forming a Tool Learning Platform named ToLeaP. We also collect 21 out of 33 potential training datasets to facilitate future exploration. After analyzing over 3,000 bad cases of 41 LLMs based on ToLeaP, we identify four main critical challenges: (1) benchmark limitations induce both the neglect and lack of (2) autonomous learning, (3) generalization, and (4) long-horizon task-solving capabilities of LLMs. To aid future advancements, we take a step further toward exploring potential directions, namely (1) real-world benchmark construction, (2) compatibility-aware autonomous learning, (3) rationale learning by thinking, and (4) identifying and recalling key clues. The preliminary experiments demonstrate their effectiveness, highlighting the need for further research and exploration.","authors":["Haotian Chen","Zijun Song","Boye Niu","Ke Zhang","Litu Ou","Yaxi Lu","Zhong Zhang","Xin Cong","Yankai Lin","Zhiyuan Liu","Maosong Sun"],"url":"https://arxiv.org/abs/2505.11833"}
{"created":"2025-05-20","title":"Multilingual Collaborative Defense for Large Language Models","abstract":"The robustness and security of large language models (LLMs) has become a prominent research area. One notable vulnerability is the ability to bypass LLM safeguards by translating harmful queries into rare or underrepresented languages, a simple yet effective method of \"jailbreaking\" these models. Despite the growing concern, there has been limited research addressing the safeguarding of LLMs in multilingual scenarios, highlighting an urgent need to enhance multilingual safety. In this work, we investigate the correlation between various attack features across different languages and propose Multilingual Collaborative Defense (MCD), a novel learning method that optimizes a continuous, soft safety prompt automatically to facilitate multilingual safeguarding of LLMs. The MCD approach offers three advantages: First, it effectively improves safeguarding performance across multiple languages. Second, MCD maintains strong generalization capabilities while minimizing false refusal rates. Third, MCD mitigates the language safety misalignment caused by imbalances in LLM training corpora. To evaluate the effectiveness of MCD, we manually construct multilingual versions of commonly used jailbreak benchmarks, such as MaliciousInstruct and AdvBench, to assess various safeguarding methods. Additionally, we introduce these datasets in underrepresented (zero-shot) languages to verify the language transferability of MCD. The results demonstrate that MCD outperforms existing approaches in safeguarding against multilingual jailbreak attempts while also exhibiting strong language transfer capabilities. Our code is available at https://github.com/HLiang-Lee/MCD.","authors":["Hongliang Li","Jinan Xu","Gengping Cui","Changhao Guan","Fengran Mo","Kaiyu Huang"],"url":"https://arxiv.org/abs/2505.11835"}
{"created":"2025-05-20","title":"SplInterp: Improving our Understanding and Training of Sparse Autoencoders","abstract":"Sparse autoencoders (SAEs) have received considerable recent attention as tools for mechanistic interpretability, showing success at extracting interpretable features even from very large LLMs. However, this research has been largely empirical, and there have been recent doubts about the true utility of SAEs. In this work, we seek to enhance the theoretical understanding of SAEs, using the spline theory of deep learning. By situating SAEs in this framework: we discover that SAEs generalise ``$k$-means autoencoders'' to be piecewise affine, but sacrifice accuracy for interpretability vs. the optimal ``$k$-means-esque plus local principal component analysis (PCA)'' piecewise affine autoencoder. We characterise the underlying geometry of (TopK) SAEs using power diagrams. And we develop a novel proximal alternating method SGD (PAM-SGD) algorithm for training SAEs, with both solid theoretical foundations and promising empirical results in MNIST and LLM experiments, particularly in sample efficiency and (in the LLM setting) improved sparsity of codes. All code is available at: https://github.com/splInterp2025/splInterp","authors":["Jeremy Budd","Javier Ideami","Benjamin Macdowall Rynne","Keith Duggar","Randall Balestriero"],"url":"https://arxiv.org/abs/2505.11836"}
{"created":"2025-05-20","title":"On Membership Inference Attacks in Knowledge Distillation","abstract":"Nowadays, Large Language Models (LLMs) are trained on huge datasets, some including sensitive information. This poses a serious privacy concern because privacy attacks such as Membership Inference Attacks (MIAs) may detect this sensitive information. While knowledge distillation compresses LLMs into efficient, smaller student models, its impact on privacy remains underexplored. In this paper, we investigate how knowledge distillation affects model robustness against MIA. We focus on two questions. First, how is private data protected in teacher and student models? Second, how can we strengthen privacy preservation against MIAs in knowledge distillation? Through comprehensive experiments, we show that while teacher and student models achieve similar overall MIA accuracy, teacher models better protect member data, the primary target of MIA, whereas student models better protect non-member data. To address this vulnerability in student models, we propose 5 privacy-preserving distillation methods and demonstrate that they successfully reduce student models' vulnerability to MIA, with ensembling further stabilizing the robustness, offering a reliable approach for distilling more secure and efficient student models. Our implementation source code is available at https://github.com/richardcui18/MIA_in_KD.","authors":["Ziyao Cui","Minxing Zhang","Jian Pei"],"url":"https://arxiv.org/abs/2505.11837"}
{"created":"2025-05-20","title":"RVTBench: A Benchmark for Visual Reasoning Tasks","abstract":"Visual reasoning, the capability to interpret visual input in response to implicit text query through multi-step reasoning, remains a challenge for deep learning models due to the lack of relevant benchmarks. Previous work in visual reasoning has primarily focused on reasoning segmentation, where models aim to segment objects based on implicit text queries. This paper introduces reasoning visual tasks (RVTs), a unified formulation that extends beyond traditional video reasoning segmentation to a diverse family of visual language reasoning problems, which can therefore accommodate multiple output formats including bounding boxes, natural language descriptions, and question-answer pairs. Correspondingly, we identify the limitations in current benchmark construction methods that rely solely on large language models (LLMs), which inadequately capture complex spatial-temporal relationships and multi-step reasoning chains in video due to their reliance on token representation, resulting in benchmarks with artificially limited reasoning complexity. To address this limitation, we propose a novel automated RVT benchmark construction pipeline that leverages digital twin (DT) representations as structured intermediaries between perception and the generation of implicit text queries. Based on this method, we construct RVTBench, a RVT benchmark containing 3,896 queries of over 1.2 million tokens across four types of RVT (segmentation, grounding, VQA and summary), three reasoning categories (semantic, spatial, and temporal), and four increasing difficulty levels, derived from 200 video sequences. Finally, we propose RVTagent, an agent framework for RVT that allows for zero-shot generalization across various types of RVT without task-specific fine-tuning.","authors":["Yiqing Shen","Chenjia Li","Chenxiao Fan","Mathias Unberath"],"url":"https://arxiv.org/abs/2505.11838"}
{"created":"2025-05-20","title":"On the Eligibility of LLMs for Counterfactual Reasoning: A Decompositional Study","abstract":"Counterfactual reasoning has emerged as a crucial technique for generalizing the reasoning capabilities of large language models (LLMs). By generating and analyzing counterfactual scenarios, researchers can assess the adaptability and reliability of model decision-making. Although prior work has shown that LLMs often struggle with counterfactual reasoning, it remains unclear which factors most significantly impede their performance across different tasks and modalities. In this paper, we propose a decompositional strategy that breaks down the counterfactual generation from causality construction to the reasoning over counterfactual interventions. To support decompositional analysis, we investigate 11 datasets spanning diverse tasks, including natural language understanding, mathematics, programming, and vision-language tasks. Through extensive evaluations, we characterize LLM behavior across each decompositional stage and identify how modality type and intermediate reasoning influence performance. By establishing a structured framework for analyzing counterfactual reasoning, this work contributes to the development of more reliable LLM-based reasoning systems and informs future elicitation strategies.","authors":["Shuai Yang","Qi Yang","Luoxi Tang","Jeremy Blackburn","Zhaohan Xi"],"url":"https://arxiv.org/abs/2505.11839"}
{"created":"2025-05-20","title":"On the $O(\\frac{\\sqrt{d}}{K^{1/4}})$ Convergence Rate of AdamW Measured by $\\ell_1$ Norm","abstract":"As the default optimizer for training large language models, AdamW has achieved remarkable success in deep learning. However, its convergence behavior is not theoretically well-understood. This paper establishes the convergence rate $\\frac{1}{K}\\sum_{k=1}^KE\\left[\\|\\nabla f(x^k)\\|_1\\right]\\leq O(\\frac{\\sqrt{d}C}{K^{1/4}})$ for AdamW measured by $\\ell_1$ norm, where $K$ represents the iteration number, $d$ denotes the model dimension, and $C$ matches the constant in the optimal convergence rate of SGD. Theoretically, we have $E\\left[\\|\\nabla f(x)\\|_1\\right]\\geq\\sqrt{\\frac{2d}{\\pi}}E\\left[\\|\\nabla f(x)\\|_2\\right]$ when each element of $\\nabla f(x)$ is generated from Gaussian distribution $\\mathcal N(0,1)$. Empirically, our experimental results on real-world deep learning tasks reveal $\\|\\nabla f(x)\\|_1=\\varTheta(\\sqrt{d})\\|\\nabla f(x)\\|_2$. Both support that our convergence rate can be considered to be analogous to the optimal $\\frac{1}{K}\\sum_{k=1}^KE\\left[\\|\\nabla f(x^k)\\|_2\\right]\\leq O(\\frac{C}{K^{1/4}})$ convergence rate of SGD.","authors":["Huan Li","Yiming Dong","Zhouchen Lin"],"url":"https://arxiv.org/abs/2505.11840"}
{"created":"2025-05-20","title":"Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs","abstract":"The increasing deployment of Large Vision-Language Models (LVLMs) raises safety concerns under potential malicious inputs. However, existing multimodal safety evaluations primarily focus on model vulnerabilities exposed by static image inputs, ignoring the temporal dynamics of video that may induce distinct safety risks. To bridge this gap, we introduce Video-SafetyBench, the first comprehensive benchmark designed to evaluate the safety of LVLMs under video-text attacks. It comprises 2,264 video-text pairs spanning 48 fine-grained unsafe categories, each pairing a synthesized video with either a harmful query, which contains explicit malice, or a benign query, which appears harmless but triggers harmful behavior when interpreted alongside the video. To generate semantically accurate videos for safety evaluation, we design a controllable pipeline that decomposes video semantics into subject images (what is shown) and motion text (how it moves), which jointly guide the synthesis of query-relevant videos. To effectively evaluate uncertain or borderline harmful outputs, we propose RJScore, a novel LLM-based metric that incorporates the confidence of judge models and human-aligned decision threshold calibration. Extensive experiments show that benign-query video composition achieves average attack success rates of 67.2%, revealing consistent vulnerabilities to video-induced attacks. We believe Video-SafetyBench will catalyze future research into video-based safety evaluation and defense strategies.","authors":["Xuannan Liu","Zekun Li","Zheqi He","Peipei Li","Shuhan Xia","Xing Cui","Huaibo Huang","Xi Yang","Ran He"],"url":"https://arxiv.org/abs/2505.11842"}
{"created":"2025-05-20","title":"Model-free Dynamic Mode Adaptive Control using Matrix RLS","abstract":"This paper presents a novel, model-free, data-driven control synthesis technique known as dynamic mode adaptive control (DMAC) for synthesizing controllers for complex systems whose mathematical models are not suitable for classical control design. DMAC consists of a dynamics approximation module and a controller module. The dynamics approximation module is motivated by data-driven reduced-order modeling techniques and directly approximates the system's dynamics in state-space form using a matrix version of the recursive least squares algorithm. The controller module includes an output tracking controller that utilizes sparse measurements from the system to generate the control signal. The DMAC controller design technique is demonstrated through various dynamic systems commonly found in engineering applications. A systematic sensitivity study demonstrates the robustness of DMAC with respect to its own hyperparameters and the system's parameters.","authors":["Parham Oveissi","Ankit Goel"],"url":"https://arxiv.org/abs/2505.11844"}
{"created":"2025-05-20","title":"ElderFallGuard: Real-Time IoT and Computer Vision-Based Fall Detection System for Elderly Safety","abstract":"For the elderly population, falls pose a serious and increasing risk of serious injury and loss of independence. In order to overcome this difficulty, we present ElderFallGuard: A Computer Vision Based IoT Solution for Elderly Fall Detection and Notification, a cutting-edge, non-invasive system intended for quick caregiver alerts and real-time fall detection. Our approach leverages the power of computer vision, utilizing MediaPipe for accurate human pose estimation from standard video streams. We developed a custom dataset comprising 7200 samples across 12 distinct human poses to train and evaluate various machine learning classifiers, with Random Forest ultimately selected for its superior performance. ElderFallGuard employs a specific detection logic, identifying a fall when a designated prone pose (\"Pose6\") is held for over 3 seconds coupled with a significant drop in motion detected for more than 2 seconds. Upon confirmation, the system instantly dispatches an alert, including a snapshot of the event, to a designated Telegram group via a custom bot, incorporating cooldown logic to prevent notification overload. Rigorous testing on our dataset demonstrated exceptional results, achieving 100% accuracy, precision, recall, and F1-score. ElderFallGuard offers a promising, vision-based IoT solution to enhance elderly safety and provide peace of mind for caregivers through intelligent, timely alerts.","authors":["Tasrifur Riahi","Md. Azizul Hakim Bappy","Md. Mehedi Islam"],"url":"https://arxiv.org/abs/2505.11845"}
{"created":"2025-05-20","title":"Learning on a Razor's Edge: the Singularity Bias of Polynomial Neural Networks","abstract":"Deep neural networks often infer sparse representations, converging to a subnetwork during the learning process. In this work, we theoretically analyze subnetworks and their bias through the lens of algebraic geometry. We consider fully-connected networks with polynomial activation functions, and focus on the geometry of the function space they parametrize, often referred to as neuromanifold. First, we compute the dimension of the subspace of the neuromanifold parametrized by subnetworks. Second, we show that this subspace is singular. Third, we argue that such singularities often correspond to critical points of the training dynamics. Lastly, we discuss convolutional networks, for which subnetworks and singularities are similarly related, but the bias does not arise.","authors":["Vahid Shahverdi","Giovanni Luca Marchetti","Kathl\\'en Kohn"],"url":"https://arxiv.org/abs/2505.11846"}
{"created":"2025-05-20","title":"Bridging the Reality Gap in Digital Twins with Context-Aware, Physics-Guided Deep Learning","abstract":"Digital twins (DTs) enable powerful predictive analytics, but persistent discrepancies between simulations and real systems--known as the reality gap--undermine their reliability. Coined in robotics, the term now applies to DTs, where discrepancies stem from context mismatches, cross-domain interactions, and multi-scale dynamics. Among these, context mismatch is pressing and underexplored, as DT accuracy depends on capturing operational context, often only partially observable. However, DTs have a key advantage: simulators can systematically vary contextual factors and explore scenarios difficult or impossible to observe empirically, informing inference and model alignment. While sim-to-real transfer like domain adaptation shows promise in robotics, their application to DTs poses two key challenges. First, unlike one-time policy transfers, DTs require continuous calibration across an asset's lifecycle--demanding structured information flow, timely detection of out-of-sync states, and integration of historical and new data. Second, DTs often perform inverse modeling, inferring latent states or faults from observations that may reflect multiple evolving contexts. These needs strain purely data-driven models and risk violating physical consistency. Though some approaches preserve validity via reduced-order model, most domain adaptation techniques still lack such constraints. To address this, we propose a Reality Gap Analysis (RGA) module for DTs that continuously integrates new sensor data, detects misalignments, and recalibrates DTs via a query-response framework. Our approach fuses domain-adversarial deep learning with reduced-order simulator guidance to improve context inference and preserve physical consistency. We illustrate the RGA module in a structural health monitoring case study on a steel truss bridge in Pittsburgh, PA, showing faster calibration and better real-world alignment.","authors":["Sizhe Ma","Katherine A. Flanigan","Mario Berg\\'es"],"url":"https://arxiv.org/abs/2505.11847"}
{"created":"2025-05-20","title":"PROBE: Proprioceptive Obstacle Detection and Estimation while Navigating in Clutter","abstract":"In critical applications, including search-and-rescue in degraded environments, blockages can be prevalent and prevent the effective deployment of certain sensing modalities, particularly vision, due to occlusion and the constrained range of view of onboard camera sensors. To enable robots to tackle these challenges, we propose a new approach, Proprioceptive Obstacle Detection and Estimation while navigating in clutter PROBE, which instead relies only on the robot's proprioception to infer the presence or absence of occluded rectangular obstacles while predicting their dimensions and poses in SE(2). The proposed approach is a Transformer neural network that receives as input a history of applied torques and sensed whole-body movements of the robot and returns a parameterized representation of the obstacles in the environment. The effectiveness of PROBE is evaluated on simulated environments in Isaac Gym and with a real Unitree Go1 quadruped robot.","authors":["Dhruv Metha Ramesh","Aravind Sivaramakrishnan","Shreesh Keskar","Kostas E. Bekris","Jingjin Yu","Abdeslam Boularias"],"url":"https://arxiv.org/abs/2505.11848"}
{"created":"2025-05-20","title":"VeriReason: Reinforcement Learning with Testbench Feedback for Reasoning-Enhanced Verilog Generation","abstract":"Automating Register Transfer Level (RTL) code generation using Large Language Models (LLMs) offers substantial promise for streamlining digital circuit design and reducing human effort. However, current LLM-based approaches face significant challenges with training data scarcity, poor specification-code alignment, lack of verification mechanisms, and balancing generalization with specialization. Inspired by DeepSeek-R1, we introduce VeriReason, a framework integrating supervised fine-tuning with Guided Reward Proximal Optimization (GRPO) reinforcement learning for RTL generation. Using curated training examples and a feedback-driven reward model, VeriReason combines testbench evaluations with structural heuristics while embedding self-checking capabilities for autonomous error correction. On the VerilogEval Benchmark, VeriReason delivers significant improvements: achieving 83.1% functional correctness on the VerilogEval Machine benchmark, substantially outperforming both comparable-sized models and much larger commercial systems like GPT-4 Turbo. Additionally, our approach demonstrates up to a 2.8X increase in first-attempt functional correctness compared to baseline methods and exhibits robust generalization to unseen designs. To our knowledge, VeriReason represents the first system to successfully integrate explicit reasoning capabilities with reinforcement learning for Verilog generation, establishing a new state-of-the-art for automated RTL synthesis. The models and datasets are available at: https://huggingface.co/collections/AI4EDA-CASE Code is Available at: https://github.com/NellyW8/VeriReason","authors":["Yiting Wang","Guoheng Sun","Wanghao Ye","Gang Qu","Ang Li"],"url":"https://arxiv.org/abs/2505.11849"}
{"created":"2025-05-20","title":"Identifying convex obstacles from backscattering far field data","abstract":"The recovery of anomalies from backscattering far field data is a long-standing open problem in inverse scattering theory. We make a first step in this direction by establishing the unique identifiability of convex impenetrable obstacles from backscattering far field measurements. Specifically, we prove that both the boundary and the boundary conditions of the convex obstacle are uniquely determined by the far field pattern measured in backscattering directions for all frequencies. The key tool is Majda's asymptotic estimate of the far field patterns in the high-frequency regime. Furthermore, we introduce a fast and stable numerical algorithm for reconstructing the boundary and computing the boundary condition. A key feature of the algorithm is that the boundary condition can be computed even if the boundary is not known, and vice versa. Numerical experiments demonstrate the validity and robustness of the proposed algorithm.","authors":["Jialei Li","Xiaodong Liu","Qingxiang Shi"],"url":"https://arxiv.org/abs/2505.11850"}
{"created":"2025-05-20","title":"MedSG-Bench: A Benchmark for Medical Image Sequences Grounding","abstract":"Visual grounding is essential for precise perception and reasoning in multimodal large language models (MLLMs), especially in medical imaging domains. While existing medical visual grounding benchmarks primarily focus on single-image scenarios, real-world clinical applications often involve sequential images, where accurate lesion localization across different modalities and temporal tracking of disease progression (e.g., pre- vs. post-treatment comparison) require fine-grained cross-image semantic alignment and context-aware reasoning. To remedy the underrepresentation of image sequences in existing medical visual grounding benchmarks, we propose MedSG-Bench, the first benchmark tailored for Medical Image Sequences Grounding. It comprises eight VQA-style tasks, formulated into two paradigms of the grounding tasks, including 1) Image Difference Grounding, which focuses on detecting change regions across images, and 2) Image Consistency Grounding, which emphasizes detection of consistent or shared semantics across sequential images. MedSG-Bench covers 76 public datasets, 10 medical imaging modalities, and a wide spectrum of anatomical structures and diseases, totaling 9,630 question-answer pairs. We benchmark both general-purpose MLLMs (e.g., Qwen2.5-VL) and medical-domain specialized MLLMs (e.g., HuatuoGPT-vision), observing that even the advanced models exhibit substantial limitations in medical sequential grounding tasks. To advance this field, we construct MedSG-188K, a large-scale instruction-tuning dataset tailored for sequential visual grounding, and further develop MedSeq-Grounder, an MLLM designed to facilitate future research on fine-grained understanding across medical sequential images. The benchmark, dataset, and model are available at https://huggingface.co/MedSG-Bench","authors":["Jingkun Yue","Siqi Zhang","Zinan Jia","Huihuan Xu","Zongbo Han","Xiaohong Liu","Guangyu Wang"],"url":"https://arxiv.org/abs/2505.11852"}
{"created":"2025-05-20","title":"Evaluating the Logical Reasoning Abilities of Large Reasoning Models","abstract":"Large reasoning models, often post-trained on long chain-of-thought (long CoT) data with reinforcement learning, achieve state-of-the-art performance on mathematical, coding, and domain-specific reasoning benchmarks. However, their logical reasoning capabilities - fundamental to human cognition and independent of domain knowledge - remain understudied. To address this gap, we introduce LogiEval, a holistic benchmark for evaluating logical reasoning in large reasoning models. LogiEval spans diverse reasoning types (deductive, inductive, analogical, and abductive) and task formats (e.g., logical sequence, argument analysis), sourced from high-quality human examinations (e.g., LSAT, GMAT). Our experiments demonstrate that modern reasoning models excel at 4-choice argument analysis problems and analogical reasoning, surpassing human performance, yet exhibit uneven capabilities across reasoning types and formats, highlighting limitations in their generalization. Our analysis reveals that human performance does not mirror model failure distributions. To foster further research, we curate LogiEval-Hard, a challenging subset identified through a novel screening paradigm where small-model failures (Qwen3-30B-A3B) reliably predict difficulties for larger models. Modern models show striking, consistent failures on LogiEval-Hard. This demonstrates that fundamental reasoning bottlenecks persist across model scales, and establishes LogiEval-Hard as both a diagnostic tool and a rigorous testbed for advancing logical reasoning in LLMs.","authors":["Hanmeng Liu","Yiran Ding","Zhizhang Fu","Chaoli Zhang","Xiaozhang Liu","Yue Zhang"],"url":"https://arxiv.org/abs/2505.11854"}
{"created":"2025-05-20","title":"When AI Co-Scientists Fail: SPOT-a Benchmark for Automated Verification of Scientific Research","abstract":"Recent advances in large language models (LLMs) have fueled the vision of automated scientific discovery, often called AI Co-Scientists. To date, prior work casts these systems as generative co-authors responsible for crafting hypotheses, synthesizing code, or drafting manuscripts. In this work, we explore a complementary application: using LLMs as verifiers to automate the \\textbf{academic verification of scientific manuscripts}. To that end, we introduce SPOT, a dataset of 83 published papers paired with 91 errors significant enough to prompt errata or retraction, cross-validated with actual authors and human annotators. Evaluating state-of-the-art LLMs on SPOT, we find that none surpasses 21.1\\% recall or 6.1\\% precision (o3 achieves the best scores, with all others near zero). Furthermore, confidence estimates are uniformly low, and across eight independent runs, models rarely rediscover the same errors, undermining their reliability. Finally, qualitative analysis with domain experts reveals that even the strongest models make mistakes resembling student-level misconceptions derived from misunderstandings. These findings highlight the substantial gap between current LLM capabilities and the requirements for dependable AI-assisted academic verification.","authors":["Guijin Son","Jiwoo Hong","Honglu Fan","Heejeong Nam","Hyunwoo Ko","Seungwon Lim","Jinyeop Song","Jinha Choi","Gon\\c{c}alo Paulo","Youngjae Yu","Stella Biderman"],"url":"https://arxiv.org/abs/2505.11855"}
{"created":"2025-05-20","title":"Telco-oRAG: Optimizing Retrieval-augmented Generation for Telecom Queries via Hybrid Retrieval and Neural Routing","abstract":"Artificial intelligence will be one of the key pillars of the next generation of mobile networks (6G), as it is expected to provide novel added-value services and improve network performance. In this context, large language models have the potential to revolutionize the telecom landscape through intent comprehension, intelligent knowledge retrieval, coding proficiency, and cross-domain orchestration capabilities. This paper presents Telco-oRAG, an open-source Retrieval-Augmented Generation (RAG) framework optimized for answering technical questions in the telecommunications domain, with a particular focus on 3GPP standards. Telco-oRAG introduces a hybrid retrieval strategy that combines 3GPP domain-specific retrieval with web search, supported by glossary-enhanced query refinement and a neural router for memory-efficient retrieval. Our results show that Telco-oRAG improves the accuracy in answering 3GPP-related questions by up to 17.6% and achieves a 10.6% improvement in lexicon queries compared to baselines. Furthermore, Telco-oRAG reduces memory usage by 45% through targeted retrieval of relevant 3GPP series compared to baseline RAG, and enables open-source LLMs to reach GPT-4-level accuracy on telecom benchmarks.","authors":["Andrei-Laurentiu Bornea","Fadhel Ayed","Antonio De Domenico","Nicola Piovesan","Tareq Si Salem","Ali Maatouk"],"url":"https://arxiv.org/abs/2505.11856"}
{"created":"2025-05-20","title":"Incorporating Verification Standards for Security Requirements Generation from Functional Specifications","abstract":"In the current software driven era, ensuring privacy and security is critical. Despite this, the specification of security requirements for software is still largely a manual and labor intensive process. Engineers are tasked with analyzing potential security threats based on functional requirements (FRs), a procedure prone to omissions and errors due to the expertise gap between cybersecurity experts and software engineers. To bridge this gap, we introduce F2SRD (Function to Security Requirements Derivation), an automated approach that proactively derives security requirements (SRs) from functional specifications under the guidance of relevant security verification requirements (VRs) drawn from the well recognized OWASP Application Security Verification Standard (ASVS). F2SRD operates in two main phases: Initially, we develop a VR retriever trained on a custom database of FR and VR pairs, enabling it to adeptly select applicable VRs from ASVS. This targeted retrieval informs the precise and actionable formulation of SRs. Subsequently, these VRs are used to construct structured prompts that direct GPT4 in generating SRs. Our comparative analysis against two established models demonstrates F2SRD's enhanced performance in producing SRs that excel in inspiration, diversity, and specificity essential attributes for effective security requirement generation. By leveraging security verification standards, we believe that the generated SRs are not only more focused but also resonate stronger with the needs of engineers.","authors":["Xiaoli Lian","Shuaisong Wang","Hanyu Zou","Fang Liu","Jiajun Wu","Li Zhang"],"url":"https://arxiv.org/abs/2505.11857"}
{"created":"2025-05-20","title":"Integrating Model-based Control and RL for Sim2Real Transfer of Tight Insertion Policies","abstract":"Object insertion under tight tolerances ($< \\hspace{-.02in} 1mm$) is an important but challenging assembly task as even small errors can result in undesirable contacts. Recent efforts focused on Reinforcement Learning (RL), which often depends on careful definition of dense reward functions. This work proposes an effective strategy for such tasks that integrates traditional model-based control with RL to achieve improved insertion accuracy. The policy is trained exclusively in simulation and is zero-shot transferred to the real system. It employs a potential field-based controller to acquire a model-based policy for inserting a plug into a socket given full observability in simulation. This policy is then integrated with residual RL, which is trained in simulation given only a sparse, goal-reaching reward. A curriculum scheme over observation noise and action magnitude is used for training the residual RL policy. Both policy components use as input the SE(3) poses of both the plug and the socket and return the plug's SE(3) pose transform, which is executed by a robotic arm using a controller. The integrated policy is deployed on the real system without further training or fine-tuning, given a visual SE(3) object tracker. The proposed solution and alternatives are evaluated across a variety of objects and conditions in simulation and reality. The proposed approach outperforms recent RL-based methods in this domain and prior efforts with hybrid policies. Ablations highlight the impact of each component of the approach.","authors":["Isidoros Marougkas","Dhruv Metha Ramesh","Joe H. Doerr","Edgar Granados","Aravind Sivaramakrishnan","Abdeslam Boularias","Kostas E. Bekris"],"url":"https://arxiv.org/abs/2505.11858"}
{"created":"2025-05-20","title":"Fair-PP: A Synthetic Dataset for Aligning LLM with Personalized Preferences of Social Equity","abstract":"Human preference plays a crucial role in the refinement of large language models (LLMs). However, collecting human preference feedback is costly and most existing datasets neglect the correlation between personalization and preferences. To address this issue, we introduce Fair-PP, a synthetic dataset of personalized preferences targeting social equity, derived from real-world social survey data, which includes 28 social groups, 98 equity topics, and 5 personal preference dimensions. Leveraging GPT-4o-mini, we engage in role-playing based on seven representative persona portrayals guided by existing social survey data, yielding a total of 238,623 preference records. Through Fair-PP, we also contribute (i) An automated framework for generating preference data, along with a more fine-grained dataset of personalized preferences; (ii) analysis of the positioning of the existing mainstream LLMs across five major global regions within the personalized preference space; and (iii) a sample reweighting method for personalized preference alignment, enabling alignment with a target persona while maximizing the divergence from other personas. Empirical experiments show our method outperforms the baselines.","authors":["Qi Zhou","Jie Zhang","Dongxia Wang","Qiang Liu","Tianlin Li","Jin Song Dong","Wenhai Wang","Qing Guo"],"url":"https://arxiv.org/abs/2505.11861"}
{"created":"2025-05-20","title":"Q-Policy: Quantum-Enhanced Policy Evaluation for Scalable Reinforcement Learning","abstract":"We propose Q-Policy, a hybrid quantum-classical reinforcement learning (RL) framework that mathematically accelerates policy evaluation and optimization by exploiting quantum computing primitives. Q-Policy encodes value functions in quantum superposition, enabling simultaneous evaluation of multiple state-action pairs via amplitude encoding and quantum parallelism. We introduce a quantum-enhanced policy iteration algorithm with provable polynomial reductions in sample complexity for the evaluation step, under standard assumptions. To demonstrate the technical feasibility and theoretical soundness of our approach, we validate Q-Policy on classical emulations of small discrete control tasks. Due to current hardware and simulation limitations, our experiments focus on showcasing proof-of-concept behavior rather than large-scale empirical evaluation. Our results support the potential of Q-Policy as a theoretical foundation for scalable RL on future quantum devices, addressing RL scalability challenges beyond classical approaches.","authors":["Kalyan Cherukuri","Aarav Lala","Yash Yardi"],"url":"https://arxiv.org/abs/2505.11862"}
{"created":"2025-05-20","title":"Adaptive Gradient Learning for Spiking Neural Networks by Exploiting Membrane Potential Dynamics","abstract":"Brain-inspired spiking neural networks (SNNs) are recognized as a promising avenue for achieving efficient, low-energy neuromorphic computing. Recent advancements have focused on directly training high-performance SNNs by estimating the approximate gradients of spiking activity through a continuous function with constant sharpness, known as surrogate gradient (SG) learning. However, as spikes propagate among neurons, the distribution of membrane potential dynamics (MPD) will deviate from the gradient-available interval of fixed SG, hindering SNNs from searching the optimal solution space. To maintain the stability of gradient flows, SG needs to align with evolving MPD. Here, we propose adaptive gradient learning for SNNs by exploiting MPD, namely MPD-AGL. It fully accounts for the underlying factors contributing to membrane potential shifts and establishes a dynamic association between SG and MPD at different timesteps to relax gradient estimation, which provides a new degree of freedom for SG learning. Experimental results demonstrate that our method achieves excellent performance at low latency. Moreover, it increases the proportion of neurons that fall into the gradient-available interval compared to fixed SG, effectively mitigating the gradient vanishing problem.","authors":["Jiaqiang Jiang","Lei Wang","Runhao Jiang","Jing Fan","Rui Yan"],"url":"https://arxiv.org/abs/2505.11863"}
{"created":"2025-05-20","title":"Learning Pareto-Optimal Rewards from Noisy Preferences: A Framework for Multi-Objective Inverse Reinforcement Learning","abstract":"As generative agents become increasingly capable, alignment of their behavior with complex human values remains a fundamental challenge. Existing approaches often simplify human intent through reduction to a scalar reward, overlooking the multi-faceted nature of human feedback. In this work, we introduce a theoretical framework for preference-based Multi-Objective Inverse Reinforcement Learning (MO-IRL), where human preferences are modeled as latent vector-valued reward functions. We formalize the problem of recovering a Pareto-optimal reward representation from noisy preference queries and establish conditions for identifying the underlying multi-objective structure. We derive tight sample complexity bounds for recovering $\\epsilon$-approximations of the Pareto front and introduce a regret formulation to quantify suboptimality in this multi-objective setting. Furthermore, we propose a provably convergent algorithm for policy optimization using preference-inferred reward cones. Our results bridge the gap between practical alignment techniques and theoretical guarantees, providing a principled foundation for learning aligned behaviors in a high-dimension and value-pluralistic environment.","authors":["Kalyan Cherukuri","Aarav Lala"],"url":"https://arxiv.org/abs/2505.11864"}
{"created":"2025-05-20","title":"GLOVER++: Unleashing the Potential of Affordance Learning from Human Behaviors for Robotic Manipulation","abstract":"Learning manipulation skills from human demonstration videos offers a promising path toward generalizable and interpretable robotic intelligence-particularly through the lens of actionable affordances. However, transferring such knowledge remains challenging due to: 1) a lack of large-scale datasets with precise affordance annotations, and 2) insufficient exploration of affordances in diverse manipulation contexts. To address these gaps, we introduce HOVA-500K, a large-scale, affordance-annotated dataset comprising 500,000 images across 1,726 object categories and 675 actions. We also release a standardized benchmarking suite for multi-modal affordance reasoning. Built upon HOVA-500K, we present GLOVER++, a global-to-local affordance training framework that effectively transfers actionable affordance knowledge from human demonstrations to downstream open-vocabulary reasoning tasks. GLOVER++ achieves state-of-the-art results on the HOVA-500K benchmark and demonstrates strong generalization across diverse downstream robotic manipulation tasks. By explicitly modeling actionable affordances, GLOVER++ facilitates robust transfer across scenes, modalities, and tasks. We hope that HOVA-500K and the GLOVER++ framework will serve as valuable resources for bridging the gap between human demonstrations and robotic manipulation capabilities.","authors":["Teli Ma","Jia Zheng","Zifan Wang","Ziyao Gao","Jiaming Zhou","Junwei Liang"],"url":"https://arxiv.org/abs/2505.11865"}
{"created":"2025-05-20","title":"Position Paper: Bounded Alignment: What (Not) To Expect From AGI Agents","abstract":"The issues of AI risk and AI safety are becoming critical as the prospect of artificial general intelligence (AGI) looms larger. The emergence of extremely large and capable generative models has led to alarming predictions and created a stir from boardrooms to legislatures. As a result, AI alignment has emerged as one of the most important areas in AI research. The goal of this position paper is to argue that the currently dominant vision of AGI in the AI and machine learning (AI/ML) community needs to evolve, and that expectations and metrics for its safety must be informed much more by our understanding of the only existing instance of general intelligence, i.e., the intelligence found in animals, and especially in humans. This change in perspective will lead to a more realistic view of the technology, and allow for better policy decisions.","authors":["Ali A. Minai"],"url":"https://arxiv.org/abs/2505.11866"}
{"created":"2025-05-20","title":"MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos","abstract":"Accurately analyzing the motion parts and their motion attributes in dynamic environments is crucial for advancing key areas such as embodied intelligence. Addressing the limitations of existing methods that rely on dense multi-view images or detailed part-level annotations, we propose an innovative framework that can analyze 3D mobility from monocular videos in a zero-shot manner. This framework can precisely parse motion parts and motion attributes only using a monocular video, completely eliminating the need for annotated training data. Specifically, our method first constructs the scene geometry and roughly analyzes the motion parts and their initial motion attributes combining depth estimation, optical flow analysis and point cloud registration method, then employs 2D Gaussian splatting for scene representation. Building on this, we introduce an end-to-end dynamic scene optimization algorithm specifically designed for articulated objects, refining the initial analysis results to ensure the system can handle 'rotation', 'translation', and even complex movements ('rotation+translation'), demonstrating high flexibility and versatility. To validate the robustness and wide applicability of our method, we created a comprehensive dataset comprising both simulated and real-world scenarios. Experimental results show that our framework can effectively analyze articulated object motions in an annotation-free manner, showcasing its significant potential in future embodied intelligence applications.","authors":["Hongyi Zhou","Xiaogang Wang","Yulan Guo","Kai Xu"],"url":"https://arxiv.org/abs/2505.11868"}
{"created":"2025-05-20","title":"Numerical reconstructions of a source term in a mobile-immobile diffusion model from the partial interior observation","abstract":"We consider an inverse source problem in the two-time-scale mobile-immobile fractional diffusion model from partial interior observation. Theoretically, we combine the fractional Duhamel's principle with the weak vanishing property to establish the uniqueness of this inverse problem. Numerically, we adopt an optimal control approach for determining the source term. A coupled forward-backward system of equations is derived using the first-order optimality condition. Finally, we construct a finite element conjugate gradient algorithm for the numerical inversion of the source term. Several experiments are presented to show the utility of the method.","authors":["Zhiwei Yang","Yikan Liu"],"url":"https://arxiv.org/abs/2505.11869"}
{"created":"2025-05-20","title":"PRS-Med: Position Reasoning Segmentation with Vision-Language Model in Medical Imaging","abstract":"Recent advancements in prompt-based medical image segmentation have enabled clinicians to identify tumors using simple input like bounding boxes or text prompts. However, existing methods face challenges when doctors need to interact through natural language or when position reasoning is required - understanding spatial relationships between anatomical structures and pathologies. We present PRS-Med, a framework that integrates vision-language models with segmentation capabilities to generate both accurate segmentation masks and corresponding spatial reasoning outputs. Additionally, we introduce the MMRS dataset (Multimodal Medical in Positional Reasoning Segmentation), which provides diverse, spatially-grounded question-answer pairs to address the lack of position reasoning data in medical imaging. PRS-Med demonstrates superior performance across six imaging modalities (CT, MRI, X-ray, ultrasound, endoscopy, RGB), significantly outperforming state-of-the-art methods in both segmentation accuracy and position reasoning. Our approach enables intuitive doctor-system interaction through natural language, facilitating more efficient diagnoses. Our dataset pipeline, model, and codebase will be released to foster further research in spatially-aware multimodal reasoning for medical applications.","authors":["Quoc-Huy Trinh","Minh-Van Nguyen","Jung Peng","Ulas Bagci","Debesh Jha"],"url":"https://arxiv.org/abs/2505.11872"}
{"created":"2025-05-20","title":"J1: Exploring Simple Test-Time Scaling for LLM-as-a-Judge","abstract":"The current focus of AI research is shifting from emphasizing model training towards enhancing evaluation quality, a transition that is crucial for driving further advancements in AI systems. Traditional evaluation methods typically rely on reward models assigning scalar preference scores to outputs. Although effective, such approaches lack interpretability, leaving users often uncertain about why a reward model rates a particular response as high or low. The advent of LLM-as-a-Judge provides a more scalable and interpretable method of supervision, offering insights into the decision-making process. Moreover, with the emergence of large reasoning models, which consume more tokens for deeper thinking and answer refinement, scaling test-time computation in the LLM-as-a-Judge paradigm presents an avenue for further boosting performance and providing more interpretability through reasoning traces. In this paper, we introduce $\\textbf{J1-7B}$, which is first supervised fine-tuned on reflection-enhanced datasets collected via rejection-sampling and subsequently trained using Reinforcement Learning (RL) with verifiable rewards. At inference time, we apply Simple Test-Time Scaling (STTS) strategies for additional performance improvement. Experimental results demonstrate that $\\textbf{J1-7B}$ surpasses the previous state-of-the-art LLM-as-a-Judge by $ \\textbf{4.8}$\\% and exhibits a $ \\textbf{5.1}$\\% stronger scaling trend under STTS. Additionally, we present three key findings: (1) Existing LLM-as-a-Judge does not inherently exhibit such scaling trend. (2) Model simply fine-tuned on reflection-enhanced datasets continues to demonstrate similarly weak scaling behavior. (3) Significant scaling trend emerges primarily during the RL phase, suggesting that effective STTS capability is acquired predominantly through RL training.","authors":["Chi-Min Chan","Chunpu Xu","Jiaming Ji","Zhen Ye","Pengcheng Wen","Chunyang Jiang","Yaodong Yang","Wei Xue","Sirui Han","Yike Guo"],"url":"https://arxiv.org/abs/2505.11875"}
{"created":"2025-05-20","title":"NAMET: Robust Massive Model Editing via Noise-Aware Memory Optimization","abstract":"Model editing techniques are essential for efficiently updating knowledge in large language models (LLMs). However, the effectiveness of existing approaches degrades in massive editing scenarios, particularly when evaluated with practical metrics or in context-rich settings. We attribute these failures to embedding collisions among knowledge items, which undermine editing reliability at scale. To address this, we propose NAMET (Noise-aware Model Editing in Transformers), a simple yet effective method that introduces noise during memory extraction via a one-line modification to MEMIT. Extensive experiments across six LLMs and three datasets demonstrate that NAMET consistently outperforms existing methods when editing thousands of facts.","authors":["Yanbo Dai","Zhenlan Ji","Zongjie Li","Shuai Wang"],"url":"https://arxiv.org/abs/2505.11876"}
{"created":"2025-05-20","title":"AdaptMol: Adaptive Fusion from Sequence String to Topological Structure for Few-shot Drug Discovery","abstract":"Accurate molecular property prediction (MPP) is a critical step in modern drug development. However, the scarcity of experimental validation data poses a significant challenge to AI-driven research paradigms. Under few-shot learning scenarios, the quality of molecular representations directly dictates the theoretical upper limit of model performance. We present AdaptMol, a prototypical network integrating Adaptive multimodal fusion for Molecular representation. This framework employs a dual-level attention mechanism to dynamically integrate global and local molecular features derived from two modalities: SMILES sequences and molecular graphs. (1) At the local level, structural features such as atomic interactions and substructures are extracted from molecular graphs, emphasizing fine-grained topological information; (2) At the global level, the SMILES sequence provides a holistic representation of the molecule. To validate the necessity of multimodal adaptive fusion, we propose an interpretable approach based on identifying molecular active substructures to demonstrate that multimodal adaptive fusion can efficiently represent molecules. Extensive experiments on three commonly used benchmarks under 5-shot and 10-shot settings demonstrate that AdaptMol achieves state-of-the-art performance in most cases. The rationale-extracted method guides the fusion of two modalities and highlights the importance of both modalities.","authors":["Yifan Dai (College of Computer Science and Electronic Engineering","Hunan University)","Xuanbai Ren (College of Computer Science and Electronic Engineering","Hunan University)","Tengfei Ma (College of Computer Science and Electronic Engineering","Hunan University)","Qipeng Yan (School of Biomedical Science","Hunan University)","Yiping Liu (College of Computer Science and Electronic Engineering","Hunan University)","Yuansheng Liu (College of Computer Science and Electronic Engineering","Hunan University)","Xiangxiang Zeng (College of Computer Science and Electronic Engineering","Hunan University)"],"url":"https://arxiv.org/abs/2505.11878"}
{"created":"2025-05-20","title":"Experimental Study on Automatically Assembling Custom Catering Packages With a 3-DOF Delta Robot Using Deep Learning Methods","abstract":"This paper introduces a pioneering experimental study on the automated packing of a catering package using a two-fingered gripper affixed to a 3-degree-of-freedom Delta parallel robot. A distinctive contribution lies in the application of a deep learning approach to tackle this challenge. A custom dataset, comprising 1,500 images, is meticulously curated for this endeavor, representing a noteworthy initiative as the first dataset focusing on Persian-manufactured products. The study employs the YOLOV5 model for object detection, followed by segmentation using the FastSAM model. Subsequently, rotation angle calculation is facilitated with segmentation masks, and a rotated rectangle encapsulating the object is generated. This rectangle forms the basis for calculating two grasp points using a novel geometrical approach involving eigenvectors. An extensive experimental study validates the proposed model, where all pertinent information is seamlessly transmitted to the 3-DOF Delta parallel robot. The proposed algorithm ensures real-time detection, calibration, and the fully autonomous packing process of a catering package, boasting an impressive over 80\\% success rate in automatic grasping. This study marks a significant stride in advancing the capabilities of robotic systems for practical applications in packaging automation.","authors":["Reihaneh Yourdkhani","Arash Tavoosian","Navid Asadi Khomami","Mehdi Tale Masouleh"],"url":"https://arxiv.org/abs/2505.11879"}
{"created":"2025-05-20","title":"AES-RV: Hardware-Efficient RISC-V Accelerator with Low-Latency AES Instruction Extension for IoT Security","abstract":"The Advanced Encryption Standard (AES) is a widely adopted cryptographic algorithm essential for securing embedded systems and IoT platforms. However, existing AES hardware accelerators often face limitations in performance, energy efficiency, and flexibility. This paper presents AES-RV, a hardware-efficient RISC-V accelerator featuring low-latency AES instruction extensions optimized for real-time processing across all AES modes and key sizes. AES-RV integrates three key innovations: high-bandwidth internal buffers for continuous data processing, a specialized AES unit with custom low-latency instructions, and a pipelined system supported by a ping-pong memory transfer mechanism. Implemented on the Xilinx ZCU102 SoC FPGA, AES-RV achieves up to 255.97 times speedup and up to 453.04 times higher energy efficiency compared to baseline and conventional CPU/GPU platforms. It also demonstrates superior throughput and area efficiency against state-of-the-art AES accelerators, making it a strong candidate for secure and high-performance embedded systems.","authors":["Van Tinh Nguyen","Phuc Hung Pham","Vu Trung Duong Le","Hoai Luan Pham","Tuan Hai Vu","Thi Diem Tran"],"url":"https://arxiv.org/abs/2505.11880"}
{"created":"2025-05-20","title":"Revisiting Residual Connections: Orthogonal Updates for Stable and Efficient Deep Networks","abstract":"Residual connections are pivotal for deep neural networks, enabling greater depth by mitigating vanishing gradients. However, in standard residual updates, the module's output is directly added to the input stream. This can lead to updates that predominantly reinforce or modulate the existing stream direction, potentially underutilizing the module's capacity for learning entirely novel features. In this work, we introduce Orthogonal Residual Update: we decompose the module's output relative to the input stream and add only the component orthogonal to this stream. This design aims to guide modules to contribute primarily new representational directions, fostering richer feature learning while promoting more efficient training. We demonstrate that our orthogonal update strategy improves generalization accuracy and training stability across diverse architectures (ResNetV2, Vision Transformers) and datasets (CIFARs, TinyImageNet, ImageNet-1k), achieving, for instance, a +4.3\\%p top-1 accuracy gain for ViT-B on ImageNet-1k.","authors":["Giyeong Oh","Woohyun Cho","Siyeol Kim","Suhwan Choi","Younjae Yu"],"url":"https://arxiv.org/abs/2505.11881"}
{"created":"2025-05-20","title":"GenZSL: Generative Zero-Shot Learning Via Inductive Variational Autoencoder","abstract":"Remarkable progress in zero-shot learning (ZSL) has been achieved using generative models. However, existing generative ZSL methods merely generate (imagine) the visual features from scratch guided by the strong class semantic vectors annotated by experts, resulting in suboptimal generative performance and limited scene generalization. To address these and advance ZSL, we propose an inductive variational autoencoder for generative zero-shot learning, dubbed GenZSL. Mimicking human-level concept learning, GenZSL operates by inducting new class samples from similar seen classes using weak class semantic vectors derived from target class names (i.e., CLIP text embedding). To ensure the generation of informative samples for training an effective ZSL classifier, our GenZSL incorporates two key strategies. Firstly, it employs class diversity promotion to enhance the diversity of class semantic vectors. Secondly, it utilizes target class-guided information boosting criteria to optimize the model. Extensive experiments conducted on three popular benchmark datasets showcase the superiority and potential of our GenZSL with significant efficacy and efficiency over f-VAEGAN, e.g., 24.7% performance gains and more than $60\\times$ faster training speed on AWA2. Codes are available at https://github.com/shiming-chen/GenZSL.","authors":["Shiming Chen","Dingjie Fu","Salman Khan","Fahad Shahbaz Khan"],"url":"https://arxiv.org/abs/2505.11882"}
{"created":"2025-05-20","title":"MINGLE: Mixtures of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging","abstract":"Continual model merging integrates independently fine-tuned models sequentially without access to original training data, providing a scalable and efficient solution to continual learning. However, current methods still face critical challenges, notably parameter interference among tasks and limited adaptability to evolving test distributions. The former causes catastrophic forgetting of integrated tasks, while the latter hinders effective adaptation to new tasks. To address these, we propose MINGLE, a novel framework for test-time continual model merging, which leverages test-time adaptation using a small set of unlabeled test samples from the current task to dynamically guide the merging process. MINGLE employs a mixture-of-experts architecture composed of parameter-efficient, low-rank experts, enabling efficient adaptation and improving robustness to distribution shifts. To mitigate catastrophic forgetting, we propose Null-Space Constrained Gating, which restricts gating updates to subspaces orthogonal to prior task representations. This suppresses activations on old task inputs and preserves model behavior on past tasks. To further balance stability and adaptability, we design an Adaptive Relaxation Strategy, which dynamically adjusts the constraint strength based on interference signals captured during test-time adaptation. Extensive experiments on standard continual merging benchmarks demonstrate that MINGLE achieves robust generalization, reduces forgetting significantly, and consistently surpasses previous state-of-the-art methods by 7-9\\% on average across diverse task orders.","authors":["Zihuan Qiu","Yi Xu","Chiyuan He","Fanman Meng","Linfeng Xu","Qingbo Wu","Hongliang Li"],"url":"https://arxiv.org/abs/2505.11883"}
{"created":"2025-05-20","title":"Facial Recognition Leveraging Generative Adversarial Networks","abstract":"Face recognition performance based on deep learning heavily relies on large-scale training data, which is often difficult to acquire in practical applications. To address this challenge, this paper proposes a GAN-based data augmentation method with three key contributions: (1) a residual-embedded generator to alleviate gradient vanishing/exploding problems, (2) an Inception ResNet-V1 based FaceNet discriminator for improved adversarial training, and (3) an end-to-end framework that jointly optimizes data generation and recognition performance. Experimental results demonstrate that our approach achieves stable training dynamics and significantly improves face recognition accuracy by 12.7% on the LFW benchmark compared to baseline methods, while maintaining good generalization capability with limited training samples.","authors":["Zhongwen Li","Zongwei Li","Xiaoqi Li"],"url":"https://arxiv.org/abs/2505.11884"}
{"created":"2025-05-20","title":"Aux-Think: Exploring Reasoning Strategies for Data-Efficient Vision-Language Navigation","abstract":"Vision-Language Navigation (VLN) is a critical task for developing embodied agents that can follow natural language instructions to navigate in complex real-world environments. Recent advances in VLN by large pretrained models have significantly improved generalization and instruction grounding compared to traditional approaches. However, the role of reasoning strategies in navigation-an action-centric, long-horizon task-remains underexplored, despite Chain-of-Thought (CoT) reasoning's demonstrated success in static tasks like visual question answering. To address this gap, we conduct the first systematic evaluation of reasoning strategies for VLN, including No-Think (direct action prediction), Pre-Think (reason before action), and Post-Think (reason after action). Surprisingly, our findings reveal the Inference-time Reasoning Collapse issue, where inference-time reasoning degrades navigation accuracy, highlighting the challenges of integrating reasoning into VLN. Based on this insight, we propose Aux-Think, a framework that trains models to internalize structured reasoning patterns through CoT supervision, while inferring action directly without reasoning in online prediction. To support this framework, we release R2R-CoT-320k, the first Chain-of-Thought annotated dataset for VLN. Extensive experiments show that Aux-Think reduces training effort greatly and achieves the best performance under the same data scale.","authors":["Shuo Wang","Yongcai Wang","Wanting Li","Xudong Cai","Yucheng Wang","Maiyue Chen","Kaihui Wang","Zhizhong Su","Deying Li","Zhaoxin Fan"],"url":"https://arxiv.org/abs/2505.11886"}
{"created":"2025-05-20","title":"AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation","abstract":"With the proliferation of large language models (LLMs) in the medical domain, there is increasing demand for improved evaluation techniques to assess their capabilities. However, traditional metrics like F1 and ROUGE, which rely on token overlaps to measure quality, significantly overlook the importance of medical terminology. While human evaluation tends to be more reliable, it can be very costly and may as well suffer from inaccuracies due to limits in human expertise and motivation. Although there are some evaluation methods based on LLMs, their usability in the medical field is limited due to their proprietary nature or lack of expertise. To tackle these challenges, we present AutoMedEval, an open-sourced automatic evaluation model with 13B parameters specifically engineered to measure the question-answering proficiency of medical LLMs. The overarching objective of AutoMedEval is to assess the quality of responses produced by diverse models, aspiring to significantly reduce the dependence on human evaluation. Specifically, we propose a hierarchical training method involving curriculum instruction tuning and an iterative knowledge introspection mechanism, enabling AutoMedEval to acquire professional medical assessment capabilities with limited instructional data. Human evaluations indicate that AutoMedEval surpasses other baselines in terms of correlation with human judgments.","authors":["Xiechi Zhang","Zetian Ouyang","Linlin Wang","Gerard de Melo","Zhu Cao","Xiaoling Wang","Ya Zhang","Yanfeng Wang","Liang He"],"url":"https://arxiv.org/abs/2505.11887"}
{"created":"2025-05-20","title":"AR Secretary Agent: Real-time Memory Augmentation via LLM-powered Augmented Reality Glasses","abstract":"Interacting with a significant number of individuals on a daily basis is commonplace for many professionals, which can lead to challenges in recalling specific details: Who is this person? What did we talk about last time? The advant of augmented reality (AR) glasses, equipped with visual and auditory data capture capabilities, presents a solution. In our work, we implemented an AR Secretary Agent with advanced Large Language Models (LLMs) and Computer Vision technologies. This system could discreetly provide real-time information to the wearer, identifying who they are conversing with and summarizing previous discussions. To verify AR Secretary, we conducted a user study with 13 participants and showed that our technique can efficiently help users to memorize events by up to 20\\% memory enhancement on our study.","authors":["Rapha\\\"el A. El Haddad","Zeyu Wang","Yeonsu Shin","Ranyi Liu","Yuntao Wang","Chun Yu"],"url":"https://arxiv.org/abs/2505.11888"}
{"created":"2025-05-20","title":"LLM-Enhanced Feature Engineering for Multi-Factor Electricity Price Predictions","abstract":"Accurately forecasting electricity price volatility is crucial for effective risk management and decision-making. Traditional forecasting models often fall short in capturing the complex, non-linear dynamics of electricity markets, particularly when external factors like weather conditions and market volatility are involved. These limitations hinder their ability to provide reliable predictions in markets with high volatility, such as the New South Wales (NSW) electricity market. To address these challenges, we introduce FAEP, a Feature-Augmented Electricity Price Prediction framework. FAEP leverages Large Language Models (LLMs) combined with advanced feature engineering to enhance prediction accuracy. By incorporating external features such as weather data and price volatility jumps, and utilizing Retrieval-Augmented Generation (RAG) for effective feature extraction, FAEP overcomes the shortcomings of traditional approaches. A hybrid XGBoost-LSTM model in FAEP further refines these augmented features, resulting in a more robust prediction framework. Experimental results demonstrate that FAEP achieves state-of-art (SOTA) performance compared to other electricity price prediction models in the Australian New South Wale electricity market, showcasing the efficiency of LLM-enhanced feature engineering and hybrid machine learning architectures.","authors":["Haochen Xue","Chenghao Liu","Chong Zhang","Yuxuan Chen","Angxiao Zong","Zhaodong Wu","Yulong Li","Jiayi Liu","Kaiyu Liang","Zhixiang Lu","Ruobing Li","Jionglong Su"],"url":"https://arxiv.org/abs/2505.11890"}
{"created":"2025-05-20","title":"Mobile-Bench-v2: A More Realistic and Comprehensive Benchmark for VLM-based Mobile Agents","abstract":"VLM-based mobile agents are increasingly popular due to their capabilities to interact with smartphone GUIs and XML-structured texts and to complete daily tasks. However, existing online benchmarks struggle with obtaining stable reward signals due to dynamic environmental changes. Offline benchmarks evaluate the agents through single-path trajectories, which stands in contrast to the inherently multi-solution characteristics of GUI tasks. Additionally, both types of benchmarks fail to assess whether mobile agents can handle noise or engage in proactive interactions due to a lack of noisy apps or overly full instructions during the evaluation process. To address these limitations, we use a slot-based instruction generation method to construct a more realistic and comprehensive benchmark named Mobile-Bench-v2. Mobile-Bench-v2 includes a common task split, with offline multi-path evaluation to assess the agent's ability to obtain step rewards during task execution. It contains a noisy split based on pop-ups and ads apps, and a contaminated split named AITZ-Noise to formulate a real noisy environment. Furthermore, an ambiguous instruction split with preset Q\\&amp;A interactions is released to evaluate the agent's proactive interaction capabilities. We conduct evaluations on these splits using the single-agent framework AppAgent-v1, the multi-agent framework Mobile-Agent-v2, as well as other mobile agents such as UI-Tars and OS-Atlas. Code and data are available at https://huggingface.co/datasets/xwk123/MobileBench-v2.","authors":["Weikai Xu","Zhizheng Jiang","Yuxuan Liu","Wei Liu","Jian Luan","Yuanchun Li","Yunxin Liu","Bin Wang","Bo An"],"url":"https://arxiv.org/abs/2505.11891"}
{"created":"2025-05-20","title":"Fast RoPE Attention: Combining the Polynomial Method and Fast Fourier Transform","abstract":"The transformer architecture has been widely applied to many machine learning tasks. A main bottleneck in the time to perform transformer computations is a task called attention computation. [Alman and Song, NeurIPS 2023] have shown that in the bounded entry regime, there is an almost linear time algorithm to approximate the attention computation. They also proved that the bounded entry assumption is necessary for a fast algorithm assuming the popular Strong Exponential Time Hypothesis.","authors":["Josh Alman","Zhao Song"],"url":"https://arxiv.org/abs/2505.11892"}
{"created":"2025-05-20","title":"RLAP: A Reinforcement Learning Enhanced Adaptive Planning Framework for Multi-step NLP Task Solving","abstract":"Multi-step planning has been widely employed to enhance the performance of large language models (LLMs) on downstream natural language processing (NLP) tasks, which decomposes the original task into multiple subtasks and guide LLMs to solve them sequentially without additional training. When addressing task instances, existing methods either preset the order of steps or attempt multiple paths at each step. However, these methods overlook instances' linguistic features and rely on the intrinsic planning capabilities of LLMs to evaluate intermediate feedback and then select subtasks, resulting in suboptimal outcomes. To better solve multi-step NLP tasks with LLMs, in this paper we propose a Reinforcement Learning enhanced Adaptive Planning framework (RLAP). In our framework, we model an NLP task as a Markov decision process (MDP) and employ an LLM directly into the environment. In particular, a lightweight Actor model is trained to estimate Q-values for natural language sequences consisting of states and actions through reinforcement learning. Therefore, during sequential planning, the linguistic features of each sequence in the MDP can be taken into account, and the Actor model interacts with the LLM to determine the optimal order of subtasks for each task instance. We apply RLAP on three different types of NLP tasks and conduct extensive experiments on multiple datasets to verify RLAP's effectiveness and robustness.","authors":["Zepeng Ding","Dixuan Wang","Ziqin Luo","Guochao Jiang","Deqing Yang","Jiaqing Liang"],"url":"https://arxiv.org/abs/2505.11893"}
{"created":"2025-05-20","title":"Adversarial Robustness for Unified Multi-Modal Encoders via Efficient Calibration","abstract":"Recent unified multi-modal encoders align a wide range of modalities into a shared representation space, enabling diverse cross-modal tasks. Despite their impressive capabilities, the robustness of these models under adversarial perturbations remains underexplored, which is a critical concern for safety-sensitive applications. In this work, we present the first comprehensive study of adversarial vulnerability in unified multi-modal encoders. We find that even mild adversarial perturbations lead to substantial performance drops across all modalities. Non-visual inputs, such as audio and point clouds, are especially fragile, while visual inputs like images and videos also degrade significantly. To address this, we propose an efficient adversarial calibration framework that improves robustness across modalities without modifying pretrained encoders or semantic centers, ensuring compatibility with existing foundation models. Our method introduces modality-specific projection heads trained solely on adversarial examples, while keeping the backbone and embeddings frozen. We explore three training objectives: fixed-center cross-entropy, clean-to-adversarial L2 alignment, and clean-adversarial InfoNCE, and we introduce a regularization strategy to ensure modality-consistent alignment under attack. Experiments on six modalities and three Bind-style models show that our method improves adversarial robustness by up to 47.3 percent at epsilon = 4/255, while preserving or even improving clean zero-shot and retrieval performance with less than 1 percent trainable parameters.","authors":["Chih-Ting Liao","Bin Ren","Guofeng Mei","Xu Zheng"],"url":"https://arxiv.org/abs/2505.11895"}
{"created":"2025-05-20","title":"AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via Reinforcement Learning","abstract":"Large Language Models (LLMs) have demonstrated remarkable capabilities but often face challenges with tasks requiring sophisticated reasoning. While Chain-of-Thought (CoT) prompting significantly enhances reasoning, it indiscriminately generates lengthy reasoning steps for all queries, leading to substantial computational costs and inefficiency, especially for simpler inputs. To address this critical issue, we introduce AdaCoT (Adaptive Chain-of-Thought), a novel framework enabling LLMs to adaptively decide when to invoke CoT. AdaCoT framed adaptive reasoning as a Pareto optimization problem that seeks to balance model performance with the costs associated with CoT invocation (both frequency and computational overhead). We propose a reinforcement learning (RL) based method, specifically utilizing Proximal Policy Optimization (PPO), to dynamically control the CoT triggering decision boundary by adjusting penalty coefficients, thereby allowing the model to determine CoT necessity based on implicit query complexity. A key technical contribution is Selective Loss Masking (SLM), designed to counteract decision boundary collapse during multi-stage RL training, ensuring robust and stable adaptive triggering. Experimental results demonstrate that AdaCoT successfully navigates the Pareto frontier, achieving substantial reductions in CoT usage for queries not requiring elaborate reasoning. For instance, on our production traffic testset, AdaCoT reduced CoT triggering rates to as low as 3.18\\% and decreased average response tokens by 69.06%, while maintaining high performance on complex tasks.","authors":["Chenwei Lou","Zewei Sun","Xinnian Liang","Meng Qu","Wei Shen","Wenqi Wang","Yuntao Li","Qingping Yang","Shuangzhi Wu"],"url":"https://arxiv.org/abs/2505.11896"}
{"created":"2025-05-20","title":"FiGKD: Fine-Grained Knowledge Distillation via High-Frequency Detail Transfer","abstract":"Knowledge distillation (KD) is a widely adopted technique for transferring knowledge from a high-capacity teacher model to a smaller student model by aligning their output distributions. However, existing methods often underperform in fine-grained visual recognition tasks, where distinguishing subtle differences between visually similar classes is essential. This performance gap stems from the fact that conventional approaches treat the teacher's output logits as a single, undifferentiated signal-assuming all contained information is equally beneficial to the student. Consequently, student models may become overloaded with redundant signals and fail to capture the teacher's nuanced decision boundaries. To address this issue, we propose Fine-Grained Knowledge Distillation (FiGKD), a novel frequency-aware framework that decomposes a model's logits into low-frequency (content) and high-frequency (detail) components using the discrete wavelet transform (DWT). FiGKD selectively transfers only the high-frequency components, which encode the teacher's semantic decision patterns, while discarding redundant low-frequency content already conveyed through ground-truth supervision. Our approach is simple, architecture-agnostic, and requires no access to intermediate feature maps. Extensive experiments on CIFAR-100, TinyImageNet, and multiple fine-grained recognition benchmarks show that FiGKD consistently outperforms state-of-the-art logit-based and feature-based distillation methods across a variety of teacher-student configurations. These findings confirm that frequency-aware logit decomposition enables more efficient and effective knowledge transfer, particularly in resource-constrained settings.","authors":["Seonghak Kim"],"url":"https://arxiv.org/abs/2505.11897"}
{"created":"2025-05-20","title":"From Recall to Reasoning: Automated Question Generation for Deeper Math Learning through Large Language Models","abstract":"Educators have started to turn to Generative AI (GenAI) to help create new course content, but little is known about how they should do so. In this project, we investigated the first steps for optimizing content creation for advanced math. In particular, we looked at the ability of GenAI to produce high-quality practice problems that are relevant to the course content. We conducted two studies to: (1) explore the capabilities of current versions of publicly available GenAI and (2) develop an improved framework to address the limitations we found. Our results showed that GenAI can create math problems at various levels of quality with minimal support, but that providing examples and relevant content results in better quality outputs. This research can help educators decide the ideal way to adopt GenAI in their workflows, to create more effective educational experiences for students.","authors":["Yongan Yu","Alexandre Krantz","Nikki G. Lobczowski"],"url":"https://arxiv.org/abs/2505.11899"}
{"created":"2025-05-20","title":"Recursive Question Understanding for Complex Question Answering over Heterogeneous Personal Data","abstract":"Question answering over mixed sources, like text and tables, has been advanced by verbalizing all contents and encoding it with a language model. A prominent case of such heterogeneous data is personal information: user devices log vast amounts of data every day, such as calendar entries, workout statistics, shopping records, streaming history, and more. Information needs range from simple look-ups to queries of analytical nature. The challenge is to provide humans with convenient access with small footprint, so that all personal data stays on the user devices. We present ReQAP, a novel method that creates an executable operator tree for a given question, via recursive decomposition. Operators are designed to enable seamless integration of structured and unstructured sources, and the execution of the operator tree yields a traceable answer. We further release the PerQA benchmark, with persona-based data and questions, covering a diverse spectrum of realistic user needs.","authors":["Philipp Christmann","Gerhard Weikum"],"url":"https://arxiv.org/abs/2505.11900"}
{"created":"2025-05-20","title":"Benchmarking LLMs in an Embodied Environment for Blue Team Threat Hlunting","abstract":"As cyber threats continue to grow in scale and sophistication, blue team defenders increasingly require advanced tools to proactively detect and mitigate risks. Large Language Models (LLMs) offer promising capabilities for enhancing threat analysis. However, their effectiveness in real-world blue team threat-hunting scenarios remains insufficiently explored. In this paper, we present CYBERTEAM, a benchmark designed to guide LLMs in blue teaming practice. CYBERTEAM constructs an embodied environment in two stages. First, it models realistic threat-hunting workflows by capturing the dependencies among analytical tasks from threat attribution to incident response. Next, each task is addressed through a set of embodied functions tailored to its specific analytical requirements. This transforms the overall threat-hunting process into a structured sequence of function-driven operations, where each node represents a discrete function and edges define the execution order. Guided by this framework, LLMs are directed to perform threat-hunting tasks through modular steps. Overall, CYBERTEAM integrates 30 tasks and 9 embodied functions, guiding LLMs through pipelined threat analysis. We evaluate leading LLMs and state-of-the-art cybersecurity agents, comparing CYBERTEAM's embodied function-calling against fundamental elicitation strategies. Our results offer valuable insights into the current capabilities and limitations of LLMs in threat hunting, laying the foundation for the practical adoption in real-world cybersecurity applications.","authors":["Xiaoqun Liu","Feiyang Yu","Xi Li","Guanhua Yan","Ping Yang","Zhaohan Xi"],"url":"https://arxiv.org/abs/2505.11901"}
{"created":"2025-05-20","title":"Dynamic Perturbed Adaptive Method for Infinite Task-Conflicting Time Series","abstract":"We formulate time series tasks as input-output mappings under varying objectives, where the same input may yield different outputs. This challenges a model's generalization and adaptability. To study this, we construct a synthetic dataset with numerous conflicting subtasks to evaluate adaptation under frequent task shifts. Existing static models consistently fail in such settings. We propose a dynamic perturbed adaptive method based on a trunk-branch architecture, where the trunk evolves slowly to capture long-term structure, and branch modules are re-initialized and updated for each task. This enables continual test-time adaptation and cross-task transfer without relying on explicit task labels. Theoretically, we show that this architecture has strictly higher functional expressivity than static models and LoRA. We also establish exponential convergence of branch adaptation under the Polyak-Lojasiewicz condition. Experiments demonstrate that our method significantly outperforms competitive baselines in complex and conflicting task environments, exhibiting fast adaptation and progressive learning capabilities.","authors":["Jiang You","Xiaozhen Wang","Arben Cela"],"url":"https://arxiv.org/abs/2505.11902"}
{"created":"2025-05-20","title":"K*-Means: A Parameter-free Clustering Algorithm","abstract":"Clustering is a widely used and powerful machine learning technique, but its effectiveness is often limited by the need to specify the number of clusters, k, or by relying on thresholds that implicitly determine k. We introduce k*-means, a novel clustering algorithm that eliminates the need to set k or any other parameters. Instead, it uses the minimum description length principle to automatically determine the optimal number of clusters, k*, by splitting and merging clusters while also optimising the standard k-means objective. We prove that k*-means is guaranteed to converge and demonstrate experimentally that it significantly outperforms existing methods in scenarios where k is unknown. We also show that it is accurate in estimating k, and that empirically its runtime is competitive with existing methods, and scales well with dataset size.","authors":["Louis Mahon","Mirella Lapata"],"url":"https://arxiv.org/abs/2505.11904"}
{"created":"2025-05-20","title":"GTR: Gaussian Splatting Tracking and Reconstruction of Unknown Objects Based on Appearance and Geometric Complexity","abstract":"We present a novel method for 6-DoF object tracking and high-quality 3D reconstruction from monocular RGBD video. Existing methods, while achieving impressive results, often struggle with complex objects, particularly those exhibiting symmetry, intricate geometry or complex appearance. To bridge these gaps, we introduce an adaptive method that combines 3D Gaussian Splatting, hybrid geometry/appearance tracking, and key frame selection to achieve robust tracking and accurate reconstructions across a diverse range of objects. Additionally, we present a benchmark covering these challenging object classes, providing high-quality annotations for evaluating both tracking and reconstruction performance. Our approach demonstrates strong capabilities in recovering high-fidelity object meshes, setting a new standard for single-sensor 3D reconstruction in open-world environments.","authors":["Takuya Ikeda","Sergey Zakharov","Muhammad Zubair Irshad","Istvan Balazs Opra","Shun Iwase","Dian Chen","Mark Tjersland","Robert Lee","Alexandre Dilly","Rares Ambrus","Koichi Nishiwaki"],"url":"https://arxiv.org/abs/2505.11905"}
{"created":"2025-05-20","title":"Are Multimodal Large Language Models Ready for Omnidirectional Spatial Reasoning?","abstract":"The 180x360 omnidirectional field of view captured by 360-degree cameras enables their use in a wide range of applications such as embodied AI and virtual reality. Although recent advances in multimodal large language models (MLLMs) have shown promise in visual-spatial reasoning, most studies focus on standard pinhole-view images, leaving omnidirectional perception largely unexplored. In this paper, we ask: Are MLLMs ready for omnidirectional spatial reasoning? To investigate this, we introduce OSR-Bench, the first benchmark specifically designed for this setting. OSR-Bench includes over 153,000 diverse question-answer pairs grounded in high-fidelity panoramic indoor scene maps. It covers key reasoning types including object counting, relative distance, and direction. We also propose a negative sampling strategy that inserts non-existent objects into prompts to evaluate hallucination and grounding robustness. For fine-grained analysis, we design a two-stage evaluation framework assessing both cognitive map generation and QA accuracy using rotation-invariant matching and a combination of rule-based and LLM-based metrics. We evaluate eight state-of-the-art MLLMs, including GPT-4o, Gemini 1.5 Pro, and leading open-source models under zero-shot settings. Results show that current models struggle with spatial reasoning in panoramic contexts, highlighting the need for more perceptually grounded MLLMs. OSR-Bench and code will be released at: https://huggingface.co/datasets/UUUserna/OSR-Bench","authors":["Zihao Dongfang","Xu Zheng","Ziqiao Weng","Yuanhuiyi Lyu","Danda Pani Paudel","Luc Van Gool","Kailun Yang","Xuming Hu"],"url":"https://arxiv.org/abs/2505.11907"}
{"created":"2025-05-20","title":"ELITE: Embedding-Less retrieval with Iterative Text Exploration","abstract":"Large Language Models (LLMs) have achieved impressive progress in natural language processing, but their limited ability to retain long-term context constrains performance on document-level or multi-turn tasks. Retrieval-Augmented Generation (RAG) mitigates this by retrieving relevant information from an external corpus. However, existing RAG systems often rely on embedding-based retrieval trained on corpus-level semantic similarity, which can lead to retrieving content that is semantically similar in form but misaligned with the question's true intent. Furthermore, recent RAG variants construct graph- or hierarchy-based structures to improve retrieval accuracy, resulting in significant computation and storage overhead. In this paper, we propose an embedding-free retrieval framework. Our method leverages the logical inferencing ability of LLMs in retrieval using iterative search space refinement guided by our novel importance measure and extend our retrieval results with logically related information without explicit graph construction. Experiments on long-context QA benchmarks, including NovelQA and Marathon, show that our approach outperforms strong baselines while reducing storage and runtime by over an order of magnitude.","authors":["Zhangyu Wang","Siyuan Gao","Rong Zhou","Hao Wang","Li Ning"],"url":"https://arxiv.org/abs/2505.11908"}
{"created":"2025-05-20","title":"Mod\\`eles de Substitution pour les Mod\\`eles \\`a base d'Agents : Enjeux, M\\'ethodes et Applications","abstract":"Multi-agent simulations enables the modeling and analyses of the dynamic behaviors and interactions of autonomous entities evolving in complex environments. Agent-based models (ABM) are widely used to study emergent phenomena arising from local interactions. However, their high computational cost poses a significant challenge, particularly for large-scale simulations requiring extensive parameter exploration, optimization, or uncertainty quantification. The increasing complexity of ABM limits their feasibility for real-time decision-making and large-scale scenario analysis. To address these limitations, surrogate models offer an efficient alternative by learning approximations from sparse simulation data. These models provide cheap-to-evaluate predictions, significantly reducing computational costs while maintaining accuracy. Various machine learning techniques, including regression models, neural networks, random forests and Gaussian processes, have been applied to construct robust surrogates. Moreover, uncertainty quantification and sensitivity analysis play a crucial role in enhancing model reliability and interpretability.","authors":["Paul Saves","Nicolas Verstaevel","Beno\\^it Gaudou"],"url":"https://arxiv.org/abs/2505.11912"}
{"created":"2025-05-20","title":"Arrow: Adaptive Scheduling Mechanisms for Disaggregated LLM Inference Architecture","abstract":"Existing large language models (LLMs) serving systems typically employ Prefill-Decode disaggregated architecture to prevent computational interference between the prefill and decode phases. However, real-world LLM serving scenarios often exhibit significant fluctuations in request input/output lengths, causing traditional static prefill/decode node configuration ratio to result in imbalanced computational loads between these two nodes, consequently preventing efficient utilization of computing resources to improve the system's goodput. To address this challenge, we design and implement Arrow, an adaptive scheduler that leverages stateless instances and elastic instance pools to achieve efficient adaptive request and instance scheduling. Arrow dynamically adjusts the number of instances handling prefill and decode tasks based on real-time cluster performance metrics, significantly enhancing the system's capability to handle traffic spikes and load variations. Our evaluation under diverse real-world workloads shows that Arrow achieves up to $5.62 \\times$ and $7.78 \\times$ higher request serving rates compared to state-of-the-art PD-colocated and PD-disaggregated serving systems respectively.","authors":["Yu Wu","Tongxuan Liu","Yuting Zeng","Siyu Wu","Jun Xiong","Xianzhe Dong","Hailong Yang","Ke Zhang","Jing Li"],"url":"https://arxiv.org/abs/2505.11916"}
{"created":"2025-05-20","title":"OneTwoVLA: A Unified Vision-Language-Action Model with Adaptive Reasoning","abstract":"General-purpose robots capable of performing diverse tasks require synergistic reasoning and acting capabilities. However, recent dual-system approaches, which separate high-level reasoning from low-level acting, often suffer from challenges such as limited mutual understanding of capabilities between systems and latency issues. This paper introduces OneTwoVLA, a single unified vision-language-action model that can perform both acting (System One) and reasoning (System Two). Crucially, OneTwoVLA adaptively switches between two modes: explicitly reasoning at critical moments during task execution, and generating actions based on the most recent reasoning at other times. To further unlock OneTwoVLA's reasoning and generalization capabilities, we design a scalable pipeline for synthesizing embodied reasoning-centric vision-language data, used for co-training with robot data. We validate OneTwoVLA's effectiveness through extensive experiments, highlighting its superior performance across four key capabilities: long-horizon task planning, error detection and recovery, natural human-robot interaction, and generalizable visual grounding, enabling the model to perform long-horizon, highly dexterous manipulation tasks such as making hotpot or mixing cocktails.","authors":["Fanqi Lin","Ruiqian Nai","Yingdong Hu","Jiacheng You","Junming Zhao","Yang Gao"],"url":"https://arxiv.org/abs/2505.11917"}
{"created":"2025-05-20","title":"Transformers as Unsupervised Learning Algorithms: A study on Gaussian Mixtures","abstract":"The transformer architecture has demonstrated remarkable capabilities in modern artificial intelligence, among which the capability of implicitly learning an internal model during inference time is widely believed to play a key role in the under standing of pre-trained large language models. However, most recent works have been focusing on studying supervised learning topics such as in-context learning, leaving the field of unsupervised learning largely unexplored. This paper investigates the capabilities of transformers in solving Gaussian Mixture Models (GMMs), a fundamental unsupervised learning problem through the lens of statistical estimation. We propose a transformer-based learning framework called TGMM that simultaneously learns to solve multiple GMM tasks using a shared transformer backbone. The learned models are empirically demonstrated to effectively mitigate the limitations of classical methods such as Expectation-Maximization (EM) or spectral algorithms, at the same time exhibit reasonable robustness to distribution shifts. Theoretically, we prove that transformers can approximate both the EM algorithm and a core component of spectral methods (cubic tensor power iterations). These results bridge the gap between practical success and theoretical understanding, positioning transformers as versatile tools for unsupervised learning.","authors":["Zhiheng Chen","Ruofan Wu","Guanhua Fang"],"url":"https://arxiv.org/abs/2505.11918"}
{"created":"2025-05-20","title":"H2R: A Human-to-Robot Data Augmentation for Robot Pre-training from Videos","abstract":"Large-scale pre-training using videos has proven effective for robot learning. However, the models pre-trained on such data can be suboptimal for robot learning due to the significant visual gap between human hands and those of different robots. To remedy this, we propose H2R, a simple data augmentation technique that detects human hand keypoints, synthesizes robot motions in simulation, and composites rendered robots into egocentric videos. This process explicitly bridges the visual gap between human and robot embodiments during pre-training. We apply H2R to augment large-scale egocentric human video datasets such as Ego4D and SSv2, replacing human hands with simulated robotic arms to generate robot-centric training data. Based on this, we construct and release a family of 1M-scale datasets covering multiple robot embodiments (UR5 with gripper/Leaphand, Franka) and data sources (SSv2, Ego4D). To verify the effectiveness of the augmentation pipeline, we introduce a CLIP-based image-text similarity metric that quantitatively evaluates the semantic fidelity of robot-rendered frames to the original human actions. We validate H2R across three simulation benchmarks: Robomimic, RLBench and PushT and real-world manipulation tasks with a UR5 robot equipped with Gripper and Leaphand end-effectors. H2R consistently improves downstream success rates, yielding gains of 5.0%-10.2% in simulation and 6.7%-23.3% in real-world tasks across various visual encoders and policy learning methods. These results indicate that H2R improves the generalization ability of robotic policies by mitigating the visual discrepancies between human and robot domains.","authors":["Guangrun Li","Yaoxu Lyu","Zhuoyang Liu","Chengkai Hou","Yinda Xu","Jieyu Zhang","Shanghang Zhang"],"url":"https://arxiv.org/abs/2505.11920"}
{"created":"2025-05-20","title":"DC-Seg: Disentangled Contrastive Learning for Brain Tumor Segmentation with Missing Modalities","abstract":"Accurate segmentation of brain images typically requires the integration of complementary information from multiple image modalities. However, clinical data for all modalities may not be available for every patient, creating a significant challenge. To address this, previous studies encode multiple modalities into a shared latent space. While somewhat effective, it remains suboptimal, as each modality contains distinct and valuable information. In this study, we propose DC-Seg (Disentangled Contrastive Learning for Segmentation), a new method that explicitly disentangles images into modality-invariant anatomical representation and modality-specific representation, by using anatomical contrastive learning and modality contrastive learning respectively. This solution improves the separation of anatomical and modality-specific features by considering the modality gaps, leading to more robust representations. Furthermore, we introduce a segmentation-based regularizer that enhances the model's robustness to missing modalities. Extensive experiments on the BraTS 2020 and a private white matter hyperintensity(WMH) segmentation dataset demonstrate that DC-Seg outperforms state-of-the-art methods in handling incomplete multimodal brain tumor segmentation tasks with varying missing modalities, while also demonstrate strong generalizability in WMH segmentation. The code is available at https://github.com/CuCl-2/DC-Seg.","authors":["Haitao Li","Ziyu Li","Yiheng Mao","Zhengyao Ding","Zhengxing Huang"],"url":"https://arxiv.org/abs/2505.11921"}
{"created":"2025-05-20","title":"Enhancing Complex Instruction Following for Large Language Models with Mixture-of-Contexts Fine-tuning","abstract":"Large language models (LLMs) exhibit remarkable capabilities in handling natural language tasks; however, they may struggle to consistently follow complex instructions including those involve multiple constraints. Post-training LLMs using supervised fine-tuning (SFT) is a standard approach to improve their ability to follow instructions. In addressing complex instruction following, existing efforts primarily focus on data-driven methods that synthesize complex instruction-output pairs for SFT. However, insufficient attention allocated to crucial sub-contexts may reduce the effectiveness of SFT. In this work, we propose transforming sequentially structured input instruction into multiple parallel instructions containing subcontexts. To support processing this multi-input, we propose MISO (Multi-Input Single-Output), an extension to currently dominant decoder-only transformer-based LLMs. MISO introduces a mixture-of-contexts paradigm that jointly considers the overall instruction-output alignment and the influence of individual sub-contexts to enhance SFT effectiveness. We apply MISO fine-tuning to complex instructionfollowing datasets and evaluate it with standard LLM inference. Empirical results demonstrate the superiority of MISO as a fine-tuning method for LLMs, both in terms of effectiveness in complex instruction-following scenarios and its potential for training efficiency.","authors":["Yuheng Lu","ZiMeng Bai","Caixia Yuan","Huixing Jiang","Xiaojie Wang"],"url":"https://arxiv.org/abs/2505.11922"}
{"created":"2025-05-20","title":"An Explanation of Intrinsic Self-Correction via Linear Representations and Latent Concepts","abstract":"We provide an explanation for the performance gains of intrinsic self-correction, a process where a language model iteratively refines its outputs without external feedback. More precisely, we investigate how prompting induces interpretable changes in hidden states and thus affects the output distributions. We hypothesize that each prompt-induced shift lies in a linear span of some linear representation vectors, naturally separating tokens based on individual concept alignment. Building around this idea, we give a mathematical formulation of self-correction and derive a concentration result for output tokens based on alignment magnitudes. Our experiments on text detoxification with zephyr-7b-sft reveal a substantial gap in the inner products of the prompt-induced shifts and the unembeddings of the top-100 most toxic tokens vs. those of the unembeddings of the bottom-100 least toxic tokens, under toxic instructions. This suggests that self-correction prompts enhance a language model's capability of latent concept recognition. Our analysis offers insights into the underlying mechanism of self-correction by characterizing how prompting works explainably. For reproducibility, our code is available.","authors":["Yu-Ting Lee","Hui-Ying Shih","Fu-Chieh Chang","Pei-Yuan Wu"],"url":"https://arxiv.org/abs/2505.11924"}
{"created":"2025-05-20","title":"PyScrew: A Comprehensive Dataset Collection from Industrial Screw Driving Experiments","abstract":"This paper presents a comprehensive collection of industrial screw driving datasets designed to advance research in manufacturing process monitoring and quality control. The collection comprises six distinct datasets with over 34,000 individual screw driving operations conducted under controlled experimental conditions, capturing the multifaceted nature of screw driving processes in plastic components. Each dataset systematically investigates specific aspects: natural thread degradation patterns through repeated use (s01), variations in surface friction conditions including contamination and surface treatments (s02), diverse assembly faults with up to 27 error types (s03-s04), and fabrication parameter variations in both upper and lower workpieces through modified injection molding settings (s05-s06). We detail the standardized experimental setup used across all datasets, including hardware specifications, process phases, and data acquisition methods. The hierarchical data model preserves the temporal and operational structure of screw driving processes, facilitating both exploratory analysis and the development of machine learning models. To maximize accessibility, we provide dual access pathways: raw data through Zenodo with a persistent DOI, and a purpose-built Python library (PyScrew) that offers consistent interfaces for data loading, preprocessing, and integration with common analysis workflows. These datasets serve diverse research applications including anomaly detection, predictive maintenance, quality control system development, feature extraction methodology evaluation, and classification of specific error conditions. By addressing the scarcity of standardized, comprehensive datasets in industrial manufacturing, this collection enables reproducible research and fair comparison of analytical approaches in an area of growing importance for industrial automation.","authors":["Nikolai West","Jochen Deuse"],"url":"https://arxiv.org/abs/2505.11925"}
{"created":"2025-05-20","title":"SafeVid: Toward Safety Aligned Video Large Multimodal Models","abstract":"As Video Large Multimodal Models (VLMMs) rapidly advance, their inherent complexity introduces significant safety challenges, particularly the issue of mismatched generalization where static safety alignments fail to transfer to dynamic video contexts. We introduce SafeVid, a framework designed to instill video-specific safety principles in VLMMs. SafeVid uniquely transfers robust textual safety alignment capabilities to the video domain by employing detailed textual video descriptions as an interpretive bridge, facilitating LLM-based rule-driven safety reasoning. This is achieved through a closed-loop system comprising: 1) generation of SafeVid-350K, a novel 350,000-pair video-specific safety preference dataset; 2) targeted alignment of VLMMs using Direct Preference Optimization (DPO); and 3) comprehensive evaluation via our new SafeVidBench benchmark. Alignment with SafeVid-350K significantly enhances VLMM safety, with models like LLaVA-NeXT-Video demonstrating substantial improvements (e.g., up to 42.39%) on SafeVidBench. SafeVid provides critical resources and a structured approach, demonstrating that leveraging textual descriptions as a conduit for safety reasoning markedly improves the safety alignment of VLMMs. We have made SafeVid-350K dataset (https://huggingface.co/datasets/yxwang/SafeVid-350K) publicly available.","authors":["Yixu Wang","Jiaxin Song","Yifeng Gao","Xin Wang","Yang Yao","Yan Teng","Xingjun Ma","Yingchun Wang","Yu-Gang Jiang"],"url":"https://arxiv.org/abs/2505.11926"}
{"created":"2025-05-20","title":"XiSort: Deterministic Sorting via IEEE-754 Total Ordering and Entropy Minimization","abstract":"We introduce XiSort, a deterministic and reproducible sorting algorithm for floating-point sequences based on IEEE-754 total ordering and entropy minimization. XiSort guarantees bit-for-bit stability across runs and platforms by resolving tie-breaking via information-theoretic and symbolic methods. The algorithm supports both in-memory and external (out-of-core) operation, offering consistent performance on large datasets. We formalize a curved variant of the sorting metric that integrates into the Alpay Algebra framework, treating XiSort as a recursive operator with provable convergence and symbolic idempotence. This model preserves state-space closure while minimizing local disorder, interpretable as symbolic entropy. Empirical benchmarks demonstrate that XiSort achieves competitive throughput (e.g., sorting 10^8 doubles in approximately 12 seconds in-memory, and 100 GB at around 100 MB/s on SSDs), with applications in scientific computing, high-frequency finance, and reproducible numerical workflows. The results position XiSort as a principled tool for stable data alignment, symbolic preprocessing, and cross-platform float ordering.","authors":["Faruk Alpay"],"url":"https://arxiv.org/abs/2505.11927"}
{"created":"2025-05-20","title":"Efficient Implementations of Residue Generators Mod 2n + 1 Providing Diminished-1 Representation","abstract":"The moduli of the form 2n + 1 belong to a class of low-cost odd moduli, which have been frequently selected to form the basis of various residue number systems (RNS). The most efficient computations modulo (mod) 2n + 1 are performed using the so-called diminished-1 (D1) representation. Therefore, it is desirable that the input converter from the positional number system to RNS (composed of a set of residue generators) could generate the residues mod 2n + 1 in D1 form. In this paper, we propose the basic architecture of the residue generator mod 2n + 1 with D1 output. It is universal, because its initial part can be easily designed for an arbitrary p >= 4n, whereas its final block-the 4-operand adder mod 2n + 1-preserves the same structure for any p. If a pair of conjugate moduli 2n +/- 1 belongs to the RNS moduli set, the latter architecture can be easily extended to build p-input bi-residue generators mod 2n+/-1, which not only save hardware by sharing p - 4n full-adders, but also generate the residue mod 2n + 1 directly in D1 form.","authors":["Stanis{\\l}aw J. Piestrak","Piotr Patronik"],"url":"https://arxiv.org/abs/2505.11928"}
{"created":"2025-05-20","title":"The Logical Expressiveness of Temporal GNNs via Two-Dimensional Product Logics","abstract":"In recent years, the expressive power of various neural architectures -- including graph neural networks (GNNs), transformers, and recurrent neural networks -- has been characterised using tools from logic and formal language theory. As the capabilities of basic architectures are becoming well understood, increasing attention is turning to models that combine multiple architectural paradigms. Among them particularly important, and challenging to analyse, are temporal extensions of GNNs, which integrate both spatial (graph-structure) and temporal (evolution over time) dimensions. In this paper, we initiate the study of logical characterisation of temporal GNNs by connecting them to two-dimensional product logics. We show that the expressive power of temporal GNNs depends on how graph and temporal components are combined. In particular, temporal GNNs that apply static GNNs recursively over time can capture all properties definable in the product logic of (past) propositional temporal logic PTL and the modal logic K. In contrast, architectures such as graph-and-time TGNNs and global TGNNs can only express restricted fragments of this logic, where the interaction between temporal and spatial operators is syntactically constrained. These results yield the first logical characterisations of temporal GNNs and establish new relative expressiveness results for temporal GNNs.","authors":["Marco S\\\"alzer","Przemys{\\l}aw Andrzej Wa{\\l}\\k{e}ga","Martin Lange"],"url":"https://arxiv.org/abs/2505.11930"}
{"created":"2025-05-20","title":"Neuro-Symbolic Query Compiler","abstract":"Precise recognition of search intent in Retrieval-Augmented Generation (RAG) systems remains a challenging goal, especially under resource constraints and for complex queries with nested structures and dependencies. This paper presents QCompiler, a neuro-symbolic framework inspired by linguistic grammar rules and compiler design, to bridge this gap. It theoretically designs a minimal yet sufficient Backus-Naur Form (BNF) grammar $G[q]$ to formalize complex queries. Unlike previous methods, this grammar maintains completeness while minimizing redundancy. Based on this, QCompiler includes a Query Expression Translator, a Lexical Syntax Parser, and a Recursive Descent Processor to compile queries into Abstract Syntax Trees (ASTs) for execution. The atomicity of the sub-queries in the leaf nodes ensures more precise document retrieval and response generation, significantly improving the RAG system's ability to address complex queries.","authors":["Yuyao Zhang","Zhicheng Dou","Xiaoxi Li","Jiajie Jin","Yongkang Wu","Zhonghua Li","Qi Ye","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2505.11932"}
{"created":"2025-05-20","title":"Conversational Recommendation System using NLP and Sentiment Analysis","abstract":"In today's digitally-driven world, the demand for personalized and context-aware recommendations has never been greater. Traditional recommender systems have made significant strides in this direction, but they often lack the ability to tap into the richness of conversational data. This paper represents a novel approach to recommendation systems by integrating conversational insights into the recommendation process. The Conversational Recommender System integrates cutting-edge technologies such as deep learning, leveraging machine learning algorithms like Apriori for Association Rule Mining, Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Long Short-Term Memory (LTSM). Furthermore, sophisticated voice recognition technologies, including Hidden Markov Models (HMMs) and Dynamic Time Warping (DTW) algorithms, play a crucial role in accurate speech-to-text conversion, ensuring robust performance in diverse environments. The methodology incorporates a fusion of content-based and collaborative recommendation approaches, enhancing them with NLP techniques. This innovative integration ensures a more personalized and context-aware recommendation experience, particularly in marketing applications.","authors":["Piyush Talegaonkar","Siddhant Hole","Shrinesh Kamble","Prashil Gulechha","Deepali Salapurkar"],"url":"https://arxiv.org/abs/2505.11933"}
{"created":"2025-05-20","title":"iSegMan: Interactive Segment-and-Manipulate 3D Gaussians","abstract":"The efficient rendering and explicit nature of 3DGS promote the advancement of 3D scene manipulation. However, existing methods typically encounter challenges in controlling the manipulation region and are unable to furnish the user with interactive feedback, which inevitably leads to unexpected results. Intuitively, incorporating interactive 3D segmentation tools can compensate for this deficiency. Nevertheless, existing segmentation frameworks impose a pre-processing step of scene-specific parameter training, which limits the efficiency and flexibility of scene manipulation. To deliver a 3D region control module that is well-suited for scene manipulation with reliable efficiency, we propose interactive Segment-and-Manipulate 3D Gaussians (iSegMan), an interactive segmentation and manipulation framework that only requires simple 2D user interactions in any view. To propagate user interactions to other views, we propose Epipolar-guided Interaction Propagation (EIP), which innovatively exploits epipolar constraint for efficient and robust interaction matching. To avoid scene-specific training to maintain efficiency, we further propose the novel Visibility-based Gaussian Voting (VGV), which obtains 2D segmentations from SAM and models the region extraction as a voting game between 2D Pixels and 3D Gaussians based on Gaussian visibility. Taking advantage of the efficient and precise region control of EIP and VGV, we put forth a Manipulation Toolbox to implement various functions on selected regions, enhancing the controllability, flexibility and practicality of scene manipulation. Extensive results on 3D scene manipulation and segmentation tasks fully demonstrate the significant advantages of iSegMan. Project page is available at https://zhao-yian.github.io/iSegMan.","authors":["Yian Zhao","Wanshi Xu","Ruochong Zheng","Pengchong Qiao","Chang Liu","Jie Chen"],"url":"https://arxiv.org/abs/2505.11934"}
{"created":"2025-05-20","title":"ChartEdit: How Far Are MLLMs From Automating Chart Analysis? Evaluating MLLMs' Capability via Chart Editing","abstract":"Although multimodal large language models (MLLMs) show promise in generating chart rendering code, chart editing presents a greater challenge. This difficulty stems from its nature as a labor-intensive task for humans that also demands MLLMs to integrate chart understanding, complex reasoning, and precise intent interpretation. While many MLLMs claim such editing capabilities, current assessments typically rely on limited case studies rather than robust evaluation methodologies, highlighting the urgent need for a comprehensive evaluation framework. In this work, we propose ChartEdit, a new high-quality benchmark designed for chart editing tasks. This benchmark comprises $1,405$ diverse editing instructions applied to $233$ real-world charts, with each instruction-chart instance having been manually annotated and validated for accuracy. Utilizing ChartEdit, we evaluate the performance of 10 mainstream MLLMs across two types of experiments, assessing them at both the code and chart levels. The results suggest that large-scale models can generate code to produce images that partially match the reference images. However, their ability to generate accurate edits according to the instructions remains limited. The state-of-the-art (SOTA) model achieves a score of only $59.96$, highlighting significant challenges in precise modification. In contrast, small-scale models, including chart-domain models, struggle both with following editing instructions and generating overall chart images, underscoring the need for further development in this area. Code is available at https://github.com/xxlllz/ChartEdit.","authors":["Xuanle Zhao","Xuexin Liu","Haoyue Yang","Xianzhen Luo","Fanhu Zeng","Jianling Li","Qi Shi","Chi Chen"],"url":"https://arxiv.org/abs/2505.11935"}
{"created":"2025-05-20","title":"How can Diffusion Models Evolve into Continual Generators?","abstract":"While diffusion models have achieved remarkable success in static data generation, their deployment in streaming or continual learning (CL) scenarios faces a major challenge: catastrophic forgetting (CF), where newly acquired generative capabilities overwrite previously learned ones. To systematically address this, we introduce a formal Continual Diffusion Generation (CDG) paradigm that characterizes and redefines CL in the context of generative diffusion models. Prior efforts often adapt heuristic strategies from continual classification tasks but lack alignment with the underlying diffusion process. In this work, we develop the first theoretical framework for CDG by analyzing cross-task dynamics in diffusion-based generative modeling. Our analysis reveals that the retention and stability of generative knowledge across tasks are governed by three key consistency criteria: inter-task knowledge consistency (IKC), unconditional knowledge consistency (UKC), and label knowledge consistency (LKC). Building on these insights, we propose Continual Consistency Diffusion (CCD), a principled framework that integrates these consistency objectives into training via hierarchical loss terms $\\mathcal{L}_{IKC}$, $\\mathcal{L}_{UKC}$, and $\\mathcal{L}_{LKC}$. This promotes effective knowledge retention while enabling the assimilation of new generative capabilities. Extensive experiments on four benchmark datasets demonstrate that CCD achieves state-of-the-art performance under continual settings, with substantial gains in Mean Fidelity (MF) and Incremental Mean Fidelity (IMF), particularly in tasks with rich cross-task knowledge overlap.","authors":["Jingren Liu","Zhong Ji","Xiangyu Chen"],"url":"https://arxiv.org/abs/2505.11936"}
{"created":"2025-05-20","title":"Stable Nonlinear Dynamical Approximation with Dynamical Sampling","abstract":"We present a nonlinear dynamical approximation method for time-dependent Partial Differential Equations (PDEs). The approach makes use of parametrized decoder functions, and provides a general, and principled way of understanding and analyzing stability and accuracy of nonlinear dynamical approximations. The parameters of these functions are evolved in time by means of projections on finite dimensional subspaces of an ambient Hilbert space related to the PDE evolution. For practical computations of these projections, one usually needs to sample. We propose a dynamical sampling strategy which comes with stability guarantees, while keeping a low numerical complexity. We show the effectiveness of the method on several examples in moderate spatial dimension.","authors":["Daan Bon","Benjamin Caris","Olga Mula"],"url":"https://arxiv.org/abs/2505.11938"}
{"created":"2025-05-20","title":"MLLM-based Discovery of Intrinsic Coordinates and Governing Equations from High-Dimensional Data","abstract":"Discovering governing equations from scientific data is crucial for understanding the evolution of systems, and is typically framed as a search problem within a candidate equation space. However, the high-dimensional nature of dynamical systems leads to an exponentially expanding equation space, making the search process extremely challenging. The visual perception and pre-trained scientific knowledge of multimodal large language models (MLLM) hold promise for providing effective navigation in high-dimensional equation spaces. In this paper, we propose a zero-shot method based on MLLM for automatically discovering physical coordinates and governing equations from high-dimensional data. Specifically, we design a series of enhanced visual prompts for MLLM to enhance its spatial perception. In addition, MLLM's domain knowledge is employed to navigate the search process within the equation space. Quantitative and qualitative evaluations on two representative types of systems demonstrate that the proposed method effectively discovers the physical coordinates and equations from both simulated and real experimental data, with long-term extrapolation accuracy improved by approximately 26.96% compared to the baseline.","authors":["Ruikun Li","Yan Lu","Shixiang Tang","Biqing Qi","Wanli Ouyang"],"url":"https://arxiv.org/abs/2505.11940"}
{"created":"2025-05-20","title":"Online Synthesis of Control Barrier Functions with Local Occupancy Grid Maps for Safe Navigation in Unknown Environments","abstract":"Control Barrier Functions (CBFs) have emerged as an effective and non-invasive safety filter for ensuring the safety of autonomous systems in dynamic environments with formal guarantees. However, most existing works on CBF synthesis focus on fully known settings. Synthesizing CBFs online based on perception data in unknown environments poses particular challenges. Specifically, this requires the construction of CBFs from high-dimensional data efficiently in real time. This paper proposes a new approach for online synthesis of CBFs directly from local Occupancy Grid Maps (OGMs). Inspired by steady-state thermal fields, we show that the smoothness requirement of CBFs corresponds to the solution of the steady-state heat conduction equation with suitably chosen boundary conditions. By leveraging the sparsity of the coefficient matrix in Laplace's equation, our approach allows for efficient computation of safety values for each grid cell in the map. Simulation and real-world experiments demonstrate the effectiveness of our approach. Specifically, the results show that our CBFs can be synthesized in an average of milliseconds on a 200 * 200 grid map, highlighting its real-time applicability.","authors":["Yuepeng Zhang","Yu Chen","Yuda Li","Shaoyuan Li","Xiang Yin"],"url":"https://arxiv.org/abs/2505.11941"}
{"created":"2025-05-20","title":"LifelongAgentBench: Evaluating LLM Agents as Lifelong Learners","abstract":"Lifelong learning is essential for intelligent agents operating in dynamic environments. Current large language model (LLM)-based agents, however, remain stateless and unable to accumulate or transfer knowledge over time. Existing benchmarks treat agents as static systems and fail to evaluate lifelong learning capabilities. We present LifelongAgentBench, the first unified benchmark designed to systematically assess the lifelong learning ability of LLM agents. It provides skill-grounded, interdependent tasks across three interactive environments, Database, Operating System, and Knowledge Graph, with automatic label verification, reproducibility, and modular extensibility. Extensive experiments reveal that conventional experience replay has limited effectiveness for LLM agents due to irrelevant information and context length constraints. We further introduce a group self-consistency mechanism that significantly improves lifelong learning performance. We hope LifelongAgentBench will advance the development of adaptive, memory-capable LLM agents.","authors":["Junhao Zheng","Xidi Cai","Qiuke Li","Duzhen Zhang","ZhongZhi Li","Yingying Zhang","Le Song","Qianli Ma"],"url":"https://arxiv.org/abs/2505.11942"}
{"created":"2025-05-20","title":"Basic model for ranking microfinance institutions","abstract":"This paper discusses the challenges encountered in building a ranking model for aggregator site products, using the example of ranking microfinance institutions (MFIs) based on post-click conversion. We suggest which features of MFIs should be considered, and using an algorithm based on Markov chains, we demonstrate the ``usefulness'' of these features on real data. The ideas developed in this work can be applied to aggregator websites in microinsurance, especially when personal data is unavailable. Since we did not find similar datasets in the public domain, we are publishing our dataset with a detailed description of its attributes.","authors":["Dmitry Dudukalov","Evgeny Prokopenko"],"url":"https://arxiv.org/abs/2505.11944"}
{"created":"2025-05-20","title":"Top-Down Compression: Revisit Efficient Vision Token Projection for Visual Instruction Tuning","abstract":"Visual instruction tuning aims to enable large language models to comprehend the visual world, with a pivotal challenge lying in establishing an effective vision-to-language projection. However, existing methods often grapple with the intractable trade-off between accuracy and efficiency. In this paper, we present LLaVA-Meteor, a novel approach designed to break this deadlock, equipped with a novel Top-Down Compression paradigm that strategically compresses visual tokens without compromising core information. Specifically, we construct a trainable Flash Global Fusion module based on efficient selective state space operators, which aligns the feature space while enabling each token to perceive holistic visual context and instruction preference at low cost. Furthermore, a local-to-single scanning manner is employed to effectively capture local dependencies, thereby enhancing the model's capability in vision modeling. To alleviate computational overhead, we explore a Visual-Native Selection mechanism that independently assesses token significance by both the visual and native experts, followed by aggregation to retain the most critical subset. Extensive experiments show that our approach reduces visual tokens by 75--95% while achieving comparable or superior performance across 12 benchmarks, significantly improving efficiency.","authors":["Bonan li","Zicheng Zhang","Songhua Liu","Weihao Yu","Xinchao Wang"],"url":"https://arxiv.org/abs/2505.11945"}
{"created":"2025-05-20","title":"Let's have a chat with the EU AI Act","abstract":"As artificial intelligence (AI) regulations evolve and the regulatory landscape develops and becomes more complex, ensuring compliance with ethical guidelines and legal frameworks remains a challenge for AI developers. This paper introduces an AI-driven self-assessment chatbot designed to assist users in navigating the European Union AI Act and related standards. Leveraging a Retrieval-Augmented Generation (RAG) framework, the chatbot enables real-time, context-aware compliance verification by retrieving relevant regulatory texts and providing tailored guidance. By integrating both public and proprietary standards, it streamlines regulatory adherence, reduces complexity, and fosters responsible AI development. The paper explores the chatbot's architecture, comparing naive and graph-based RAG models, and discusses its potential impact on AI governance.","authors":["Adam Kovari","Yasin Ghafourian","Csaba Hegedus","Belal Abu Naim","Kitti Mezei","Pal Varga","Markus Tauber"],"url":"https://arxiv.org/abs/2505.11946"}
{"created":"2025-05-20","title":"Reach-avoid games for players with damped double integrator dynamics","abstract":"This paper studies a reach-avoid game of two damped double integrator players. An attacker aims to reach a static target, while a faster defender tries to protect the target by intercepting the attacker before it reaches the target. In scenarios where the defender succeeds, the defender aims to maximize the attacker's final distance from the target, while the attacker aims to minimize it. This work focuses on determining the equilibrium strategy in the defender-winning scenarios. The optimal state feedback strategy is obtained by a differential game approach combining geometric analysis. We construct a multiple reachable region to analyse the damped double integrator player's motion under optimal strategy. Building on this, a new type of the attacker's dominance region is introduced for the first time. It is shown that different strategies are required when the terminal point lies in distinct areas of the attacker's dominance region. Then, a necessary condition is derived for the proposed strategy to be optimal using differential game approach. Furthermore, a case where both players start at rest is discussed, and some useful properties about the dominance region and the optimal strategy are presented. Simulations are conducted to show the effectiveness of the proposed strategy.","authors":["Mengxin Lyu","Ruiliang Deng","Zongying Shi","Yisheng Zhong"],"url":"https://arxiv.org/abs/2505.11951"}
{"created":"2025-05-20","title":"Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning","abstract":"Loss reweighting has shown significant benefits for machine unlearning with large language models (LLMs). However, their exact functionalities are left unclear and the optimal strategy remains an open question, thus impeding the understanding and improvement of existing methodologies. In this paper, we identify two distinct goals of loss reweighting, namely, Saturation and Importance -- the former indicates that those insufficiently optimized data should be emphasized, while the latter stresses some critical data that are most influential for loss minimization. To study their usefulness, we design specific reweighting strategies for each goal and evaluate their respective effects on unlearning. We conduct extensive empirical analyses on well-established benchmarks, and summarize some important observations as follows: (i) Saturation enhances efficacy more than importance-based reweighting, and their combination can yield additional improvements. (ii) Saturation typically allocates lower weights to data with lower likelihoods, whereas importance-based reweighting does the opposite. (iii) The efficacy of unlearning is also largely influenced by the smoothness and granularity of the weight distributions. Based on these findings, we propose SatImp, a simple reweighting method that combines the advantages of both saturation and importance. Empirical results on extensive datasets validate the efficacy of our method, potentially bridging existing research gaps and indicating directions for future research. Our code is available at https://github.com/Puning97/SatImp-for-LLM-Unlearning.","authors":["Puning Yang","Qizhou Wang","Zhuo Huang","Tongliang Liu","Chengqi Zhang","Bo Han"],"url":"https://arxiv.org/abs/2505.11953"}
{"created":"2025-05-20","title":"Counterspeech the ultimate shield! Multi-Conditioned Counterspeech Generation through Attributed Prefix Learning","abstract":"Counterspeech has proven to be a powerful tool to combat hate speech online. Previous studies have focused on generating counterspeech conditioned only on specific intents (single attributed). However, a holistic approach considering multiple attributes simultaneously can yield more nuanced and effective responses. Here, we introduce HiPPrO, Hierarchical Prefix learning with Preference Optimization, a novel two-stage framework that utilizes the effectiveness of attribute-specific prefix embedding spaces hierarchically optimized during the counterspeech generation process in the first phase. Thereafter, we incorporate both reference and reward-free preference optimization to generate more constructive counterspeech. Furthermore, we extend IntentCONANv2 by annotating all 13,973 counterspeech instances with emotion labels by five annotators. HiPPrO leverages hierarchical prefix optimization to integrate these dual attributes effectively. An extensive evaluation demonstrates that HiPPrO achieves a ~38 % improvement in intent conformity and a ~3 %, ~2 %, ~3 % improvement in Rouge-1, Rouge-2, and Rouge-L, respectively, compared to several baseline models. Human evaluations further substantiate the superiority of our approach, highlighting the enhanced relevance and appropriateness of the generated counterspeech. This work underscores the potential of multi-attribute conditioning in advancing the efficacy of counterspeech generation systems.","authors":["Aswini Kumar Padhi","Anil Bandhakavi","Tanmoy Chakraborty"],"url":"https://arxiv.org/abs/2505.11958"}
{"created":"2025-05-20","title":"EmoHopeSpeech: An Annotated Dataset of Emotions and Hope Speech in English","abstract":"This research introduces a bilingual dataset comprising 23,456 entries for Arabic and 10,036 entries for English, annotated for emotions and hope speech, addressing the scarcity of multi-emotion (Emotion and hope) datasets. The dataset provides comprehensive annotations capturing emotion intensity, complexity, and causes, alongside detailed classifications and subcategories for hope speech. To ensure annotation reliability, Fleiss' Kappa was employed, revealing 0.75-0.85 agreement among annotators both for Arabic and English language. The evaluation metrics (micro-F1-Score=0.67) obtained from the baseline model (i.e., using a machine learning model) validate that the data annotations are worthy. This dataset offers a valuable resource for advancing natural language processing in underrepresented languages, fostering better cross-linguistic analysis of emotions and hope speech.","authors":["Md. Rafiul Biswas","Wajdi Zaghouani"],"url":"https://arxiv.org/abs/2505.11959"}
{"created":"2025-05-20","title":"An Immersed Finite Element Method for Anisotropic Elliptic Interface Problems with Nonhomogeneous Jump Conditions","abstract":"A new finite element method (FEM) using meshes that do not necessarily align with the interface is developed for two- and three-dimensional anisotropic elliptic interface problems with nonhomogeneous jump conditions. The degrees of freedom of the proposed method are the same as those of traditional nonconforming FEMs, while the function space is modified to account for the jump conditions of the solution. The modified function space on an interface element is shown to exist uniquely, independent of the element's shape and the manner in which the interface intersects it. Optimal error estimates for the method, along with the usual bound on the condition number of the stiffness matrix, are proven, with the error constant independent of the interface's location relative to the mesh. To solve the resulting linear system, a preconditioner is proposed in which a Gauss-Seidel smoother with the interface correction is employed to ensure robustness against large jumps in the diffusion matrix. Numerical experiments are provided to demonstrate the optimal convergence of the proposed method and the efficiency of the preconditioner.","authors":["Haifeng Ji","Zhilin Li"],"url":"https://arxiv.org/abs/2505.11961"}
{"created":"2025-05-20","title":"CrafText Benchmark: Advancing Instruction Following in Complex Multimodal Open-Ended World","abstract":"Following instructions in real-world conditions requires the ability to adapt to the world's volatility and entanglement: the environment is dynamic and unpredictable, instructions can be linguistically complex with diverse vocabulary, and the number of possible goals an agent may encounter is vast. Despite extensive research in this area, most studies are conducted in static environments with simple instructions and a limited vocabulary, making it difficult to assess agent performance in more diverse and challenging settings. To address this gap, we introduce CrafText, a benchmark for evaluating instruction following in a multimodal environment with diverse instructions and dynamic interactions. CrafText includes 3,924 instructions with 3,423 unique words, covering Localization, Conditional, Building, and Achievement tasks. Additionally, we propose an evaluation protocol that measures an agent's ability to generalize to novel instruction formulations and dynamically evolving task configurations, providing a rigorous test of both linguistic understanding and adaptive decision-making.","authors":["Zoya Volovikova","Gregory Gorbov","Petr Kuderov","Aleksandr I. Panov","Alexey Skrynnik"],"url":"https://arxiv.org/abs/2505.11962"}
{"created":"2025-05-20","title":"MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models","abstract":"Hardware security verification is a challenging and time-consuming task. For this purpose, design engineers may utilize tools such as formal verification, linters, and functional simulation tests, coupled with analysis and a deep understanding of the hardware design being inspected. Large Language Models (LLMs) have been used to assist during this task, either directly or in conjunction with existing tools. We improve the state of the art by proposing MARVEL, a multi-agent LLM framework for a unified approach to decision-making, tool use, and reasoning. MARVEL mimics the cognitive process of a designer looking for security vulnerabilities in RTL code. It consists of a supervisor agent that devises the security policy of the system-on-chips (SoCs) using its security documentation. It delegates tasks to validate the security policy to individual executor agents. Each executor agent carries out its assigned task using a particular strategy. Each executor agent may use one or more tools to identify potential security bugs in the design and send the results back to the supervisor agent for further analysis and confirmation. MARVEL includes executor agents that leverage formal tools, linters, simulation tests, LLM-based detection schemes, and static analysis-based checks. We test our approach on a known buggy SoC based on OpenTitan from the Hack@DATE competition. We find that 20 of the 48 issues reported by MARVEL pose security vulnerabilities.","authors":["Luca Collini","Baleegh Ahmad","Joey Ah-kiow","Ramesh Karri"],"url":"https://arxiv.org/abs/2505.11963"}
{"created":"2025-05-20","title":"CCNU at SemEval-2025 Task 3: Leveraging Internal and External Knowledge of Large Language Models for Multilingual Hallucination Annotation","abstract":"We present the system developed by the Central China Normal University (CCNU) team for the Mu-SHROOM shared task, which focuses on identifying hallucinations in question-answering systems across 14 different languages. Our approach leverages multiple Large Language Models (LLMs) with distinct areas of expertise, employing them in parallel to annotate hallucinations, effectively simulating a crowdsourcing annotation process. Furthermore, each LLM-based annotator integrates both internal and external knowledge related to the input during the annotation process. Using the open-source LLM DeepSeek-V3, our system achieves the top ranking (\\#1) for Hindi data and secures a Top-5 position in seven other languages. In this paper, we also discuss unsuccessful approaches explored during our development process and share key insights gained from participating in this shared task.","authors":["Xu Liu","Guanyi Chen"],"url":"https://arxiv.org/abs/2505.11965"}
{"created":"2025-05-20","title":"Solve-Detect-Verify: Inference-Time Scaling with Flexible Generative Verifier","abstract":"Large Language Model (LLM) reasoning for complex tasks inherently involves a trade-off between solution accuracy and computational efficiency. The subsequent step of verification, while intended to improve performance, further complicates this landscape by introducing its own challenging trade-off: sophisticated Generative Reward Models (GenRMs) can be computationally prohibitive if naively integrated with LLMs at test-time, while simpler, faster methods may lack reliability. To overcome these challenges, we introduce FlexiVe, a novel generative verifier that flexibly balances computational resources between rapid, reliable fast thinking and meticulous slow thinking using a Flexible Allocation of Verification Budget strategy. We further propose the Solve-Detect-Verify pipeline, an efficient inference-time scaling framework that intelligently integrates FlexiVe, proactively identifying solution completion points to trigger targeted verification and provide focused solver feedback. Experiments show FlexiVe achieves superior accuracy in pinpointing errors within reasoning traces on ProcessBench. Furthermore, on challenging mathematical reasoning benchmarks (AIME 2024, AIME 2025, and CNMO), our full approach outperforms baselines like self-consistency in reasoning accuracy and inference efficiency. Our system offers a scalable and effective solution to enhance LLM reasoning at test time.","authors":["Jianyuan Zhong","Zeju Li","Zhijian Xu","Xiangyu Wen","Kezhi Li","Qiang Xu"],"url":"https://arxiv.org/abs/2505.11966"}
{"created":"2025-05-20","title":"An Annotated Corpus of Arabic Tweets for Hate Speech Analysis","abstract":"Identifying hate speech content in the Arabic language is challenging due to the rich quality of dialectal variations. This study introduces a multilabel hate speech dataset in the Arabic language. We have collected 10000 Arabic tweets and annotated each tweet, whether it contains offensive content or not. If a text contains offensive content, we further classify it into different hate speech targets such as religion, gender, politics, ethnicity, origin, and others. A text can contain either single or multiple targets. Multiple annotators are involved in the data annotation task. We calculated the inter-annotator agreement, which was reported to be 0.86 for offensive content and 0.71 for multiple hate speech targets. Finally, we evaluated the data annotation task by employing a different transformers-based model in which AraBERTv2 outperformed with a micro-F1 score of 0.7865 and an accuracy of 0.786.","authors":["Md. Rafiul Biswas","Wajdi Zaghouani"],"url":"https://arxiv.org/abs/2505.11969"}
{"created":"2025-05-20","title":"A Survey of Real-time Scheduling on Accelerator-based Heterogeneous Architecture for Time Critical Applications","abstract":"Accelerator-based heterogeneous architectures, such as CPU-GPU, CPU-TPU, and CPU-FPGA systems, are widely adopted to support the popular artificial intelligence (AI) algorithms that demand intensive computation. When deployed in real-time applications, such as robotics and autonomous vehicles, these architectures must meet stringent timing constraints. To summarize these achievements, this article presents a comprehensive survey of real-time scheduling techniques for accelerator-based heterogeneous platforms. It highlights key advancements from the past ten years, showcasing how proposed solutions have evolved to address the distinct challenges and requirements of these systems.","authors":["An Zou","Yuankai Xu","Yinchen Ni","Jintao Chen","Yehan Ma","Jing Li","Christopher Gill","Xuan Zhang","Yier Jin"],"url":"https://arxiv.org/abs/2505.11970"}
{"created":"2025-05-20","title":"Accelerating Neural Network Training Along Sharp and Flat Directions","abstract":"Recent work has highlighted a surprising alignment between gradients and the top eigenspace of the Hessian -- termed the Dominant subspace -- during neural network training. Concurrently, there has been growing interest in the distinct roles of sharp and flat directions in the Hessian spectrum. In this work, we study Bulk-SGD, a variant of SGD that restricts updates to the orthogonal complement of the Dominant subspace. Through ablation studies, we characterize the stability properties of Bulk-SGD and identify critical hyperparameters that govern its behavior. We show that updates along the Bulk subspace, corresponding to flatter directions in the loss landscape, can accelerate convergence but may compromise stability. To balance these effects, we introduce interpolated gradient methods that unify SGD, Dom-SGD, and Bulk-SGD. Finally, we empirically connect this subspace decomposition to the Generalized Gauss-Newton and Functional Hessian terms, showing that curvature energy is largely concentrated in the Dominant subspace. Our findings suggest a principled approach to designing curvature-aware optimizers.","authors":["Daniyar Zakarin","Sidak Pal Singh"],"url":"https://arxiv.org/abs/2505.11972"}
{"created":"2025-05-20","title":"CGReplay: Capture and Replay of Cloud Gaming Traffic for QoE/QoS Assessment","abstract":"Cloud Gaming (CG) research faces challenges due to the unpredictability of game engines and restricted access to commercial platforms and their logs. This creates major obstacles to conducting fair experimentation and evaluation. CGReplay captures and replays player commands and the corresponding video frames in an ordered and synchronized action-reaction loop, ensuring reproducibility. It enables Quality of Experience/Service (QoE/QoS) assessment under varying network conditions and serves as a foundation for broader CG research. The code is publicly available for further development.","authors":["Alireza Shirmarz","Ariel G. de Castro","Fabio L. Verdi","Christian E. Rothenberg"],"url":"https://arxiv.org/abs/2505.11973"}
{"created":"2025-05-20","title":"Task Scheduling in Space-Air-Ground Uniformly Integrated Networks with Ripple Effects","abstract":"Space-air-ground uniformly integrated network (SAGUIN), which integrates the satellite, aerial, and terrestrial networks into a unified communication architecture, is a promising candidate technology for the next-generation wireless systems. Transmitting on the same frequency band, higher-layer access points (AP), e.g., satellites, provide extensive coverage; meanwhile, it may introduce significant signal propagation delays due to the relatively long distances to the ground users, which can be multiple times longer than the packet durations in task-oriented communications. This phenomena is modeled as a new ``ripple effect'', which introduces spatiotemporally correlated interferences in SAGUIN. This paper studies the task scheduling problem in SAGUIN with ripple effect, and formulates it as a Markov decision process (MDP) to jointly minimize the age of information (AoI) at users and energy consumption at APs. The obtained MDP is challenging due to high dimensionality, partial observations, and dynamic resource constraints caused by ripple effect. To address the challenges of high dimensionality, we reformulate the original problem as a Markov game, where the complexities are managed through interactive decision-making among APs. Meanwhile, to tackle partial observations and the dynamic resource constraints, we adopt a modified multi-agent proximal policy optimization (MAPPO) algorithm, where the actor network filters out irrelevant input states based on AP coverage and its dimensionality can be reduced by more than an order of magnitude. Simulation results reveal that the proposed approach outperforms the benchmarks, significantly reducing users' AoI and APs' energy consumption.","authors":["Chuan Huang","Ran Li","Jiachen Wang"],"url":"https://arxiv.org/abs/2505.11974"}
{"created":"2025-05-20","title":"Proactive tactile exploration for object-agnostic shape reconstruction from minimal visual priors","abstract":"The perception of an object's surface is important for robotic applications enabling robust object manipulation. The level of accuracy in such a representation affects the outcome of the action planning, especially during tasks that require physical contact, e.g. grasping. In this paper, we propose a novel iterative method for 3D shape reconstruction consisting of two steps. At first, a mesh is fitted on data points acquired from the object's surface, based on a single primitive template. Subsequently, the mesh is properly adjusted to adequately represent local deformities. Moreover, a novel proactive tactile exploration strategy aims at minimizing the total uncertainty with the least number of contacts, while reducing the risk of contact failure in case the estimated surface differs significantly from the real one. The performance of the methodology is evaluated both in 3D simulation and on a real setup.","authors":["Paris Oikonomou","George Retsinas","Petros Maragos","Costas S. Tzafestas"],"url":"https://arxiv.org/abs/2505.11975"}
{"created":"2025-05-20","title":"Advanced Integration of Discrete Line Segments in Digitized P&ID for Continuous Instrument Connectivity","abstract":"Piping and Instrumentation Diagrams (P&amp;IDs) constitute the foundational blueprint of a plant, depicting the interconnections among process equipment, instrumentation for process control, and the flow of fluids and control signals. In their existing setup, the manual mapping of information from P&amp;ID sheets holds a significant challenge. This is a time-consuming process, taking around 3-6 months, and is susceptible to errors. It also depends on the expertise of the domain experts and often requires multiple rounds of review. The digitization of P&amp;IDs entails merging detected line segments, which is essential for linking various detected instruments, thereby creating a comprehensive digitized P&amp;ID. This paper focuses on explaining how line segments which are detected using a computer vision model are merged and eventually building the connection between equipment and merged lines. Hence presenting a digitized form of information stating the interconnection between process equipment, instrumentation, flow of fluids and control signals. Eventually, which can be stored in a knowledge graph and that information along with the help of advanced algorithms can be leveraged for tasks like finding optimal routes, detecting system cycles, computing transitive closures, and more.","authors":["Soumya Swarup Prusty","Astha Agarwal","Srinivasan Iyenger"],"url":"https://arxiv.org/abs/2505.11976"}
{"created":"2025-05-20","title":"LLM-guided DRL for Multi-tier LEO Satellite Networks with Hybrid FSO/RF Links","abstract":"Despite significant advancements in terrestrial networks, inherent limitations persist in providing reliable coverage to remote areas and maintaining resilience during natural disasters. Multi-tier networks with low Earth orbit (LEO) satellites and high-altitude platforms (HAPs) offer promising solutions, but face challenges from high mobility and dynamic channel conditions that cause unstable connections and frequent handovers. In this paper, we design a three-tier network architecture that integrates LEO satellites, HAPs, and ground terminals with hybrid free-space optical (FSO) and radio frequency (RF) links to maximize coverage while maintaining connectivity reliability. This hybrid approach leverages the high bandwidth of FSO for satellite-to-HAP links and the weather resilience of RF for HAP-to-ground links. We formulate a joint optimization problem to simultaneously balance downlink transmission rate and handover frequency by optimizing network configuration and satellite handover decisions. The problem is highly dynamic and non-convex with time-coupled constraints. To address these challenges, we propose a novel large language model (LLM)-guided truncated quantile critics algorithm with dynamic action masking (LTQC-DAM) that utilizes dynamic action masking to eliminate unnecessary exploration and employs LLMs to adaptively tune hyperparameters. Simulation results demonstrate that the proposed LTQC-DAM algorithm outperforms baseline algorithms in terms of convergence, downlink transmission rate, and handover frequency. We also reveal that compared to other state-of-the-art LLMs, DeepSeek delivers the best performance through gradual, contextually-aware parameter adjustments.","authors":["Jiahui Li","Geng Sun","Zemin Sun","Jiacheng Wang","Yinqiu Liu","Ruichen Zhang","Dusit Niyato","Shiwen Mao"],"url":"https://arxiv.org/abs/2505.11978"}
{"created":"2025-05-20","title":"Introduction to Analytical Software Engineering Design Paradigm","abstract":"As modern software systems expand in scale and complexity, the challenges associated with their modeling and formulation grow increasingly intricate. Traditional approaches often fall short in effectively addressing these complexities, particularly in tasks such as design pattern detection for maintenance and assessment, as well as code refactoring for optimization and long-term sustainability. This growing inadequacy underscores the need for a paradigm shift in how such challenges are approached and resolved. This paper presents Analytical Software Engineering (ASE), a novel design paradigm aimed at balancing abstraction, tool accessibility, compatibility, and scalability. ASE enables effective modeling and resolution of complex software engineering problems. The paradigm is evaluated through two frameworks Behavioral-Structural Sequences (BSS) and Optimized Design Refactoring (ODR), both developed in accordance with ASE principles. BSS offers a compact, language-agnostic representation of codebases to facilitate precise design pattern detection. ODR unifies artifact and solution representations to optimize code refactoring via heuristic algorithms while eliminating iterative computational overhead. By providing a structured approach to software design challenges, ASE lays the groundwork for future research in encoding and analyzing complex software metrics.","authors":["Tarik Houichime","Younes El Amrani"],"url":"https://arxiv.org/abs/2505.11979"}
{"created":"2025-05-20","title":"AoP-SAM: Automation of Prompts for Efficient Segmentation","abstract":"The Segment Anything Model (SAM) is a powerful foundation model for image segmentation, showing robust zero-shot generalization through prompt engineering. However, relying on manual prompts is impractical for real-world applications, particularly in scenarios where rapid prompt provision and resource efficiency are crucial. In this paper, we propose the Automation of Prompts for SAM (AoP-SAM), a novel approach that learns to generate essential prompts in optimal locations automatically. AoP-SAM enhances SAM's efficiency and usability by eliminating manual input, making it better suited for real-world tasks. Our approach employs a lightweight yet efficient Prompt Predictor model that detects key entities across images and identifies the optimal regions for placing prompt candidates. This method leverages SAM's image embeddings, preserving its zero-shot generalization capabilities without requiring fine-tuning. Additionally, we introduce a test-time instance-level Adaptive Sampling and Filtering mechanism that generates prompts in a coarse-to-fine manner. This notably enhances both prompt and mask generation efficiency by reducing computational overhead and minimizing redundant mask refinements. Evaluations of three datasets demonstrate that AoP-SAM substantially improves both prompt generation efficiency and mask generation accuracy, making SAM more effective for automated segmentation tasks.","authors":["Yi Chen","Mu-Young Son","Chuanbo Hua","Joo-Young Kim"],"url":"https://arxiv.org/abs/2505.11980"}
{"created":"2025-05-20","title":"FedHQ: Hybrid Runtime Quantization for Federated Learning","abstract":"Federated Learning (FL) is a decentralized model training approach that preserves data privacy but struggles with low efficiency. Quantization, a powerful training optimization technique, has been widely explored for integration into FL. However, many studies fail to consider the distinct performance attribution between particular quantization strategies, such as post-training quantization (PTQ) or quantization-aware training (QAT). As a result, existing FL quantization methods rely solely on either PTQ or QAT, optimizing for speed or accuracy while compromising the other. To efficiently accelerate FL and maintain distributed convergence accuracy across various FL settings, this paper proposes a hybrid quantitation approach combining PTQ and QAT for FL systems. We conduct case studies to validate the effectiveness of using hybrid quantization in FL. To solve the difficulty of modeling speed and accuracy caused by device and data heterogeneity, we propose a hardware-related analysis and data-distribution-related analysis to help identify the trade-off boundaries for strategy selection. Based on these, we proposed a novel framework named FedHQ to automatically adopt optimal hybrid strategy allocation for FL systems. Specifically, FedHQ develops a coarse-grained global initialization and fine-grained ML-based adjustment to ensure efficiency and robustness. Experiments show that FedHQ achieves up to 2.47x times training acceleration and up to 11.15% accuracy improvement and negligible extra overhead.","authors":["Zihao Zheng (Eric)","Ziyao Wang (Eric)","Xiuping Cui (Eric)","Maoliang Li (Eric)","Jiayu Chen (Eric)","Yun (Eric)","Liang","Ang Li","Xiang Chen"],"url":"https://arxiv.org/abs/2505.11982"}
{"created":"2025-05-20","title":"Online Iterative Self-Alignment for Radiology Report Generation","abstract":"Radiology Report Generation (RRG) is an important research topic for relieving radiologist' heavy workload. Existing RRG models mainly rely on supervised fine-tuning (SFT) based on different model architectures using data pairs of radiological images and corresponding radiologist-annotated reports. Recent research has shifted focus to post-training improvements, aligning RRG model outputs with human preferences using reinforcement learning (RL). However, the limited data coverage of high-quality annotated data poses risks of overfitting and generalization. This paper proposes a novel Online Iterative Self-Alignment (OISA) method for RRG that consists of four stages: self-generation of diverse data, self-evaluation for multi-objective preference data,self-alignment for multi-objective optimization and self-iteration for further improvement. Our approach allows for generating varied reports tailored to specific clinical objectives, enhancing the overall performance of the RRG model iteratively. Unlike existing methods, our frame-work significantly increases data quality and optimizes performance through iterative multi-objective optimization. Experimental results demonstrate that our method surpasses previous approaches, achieving state-of-the-art performance across multiple evaluation metrics.","authors":["Ting Xiao","Lei Shi","Yang Zhang","HaoFeng Yang","Zhe Wang","Chenjia Bai"],"url":"https://arxiv.org/abs/2505.11983"}
{"created":"2025-05-20","title":"Variance-Optimal Arm Selection: Regret Minimization and Best Arm Identification","abstract":"This paper focuses on selecting the arm with the highest variance from a set of $K$ independent arms. Specifically, we focus on two settings: (i) regret setting, that penalizes the number of pulls of suboptimal arms in terms of variance, and (ii) fixed-budget \\ac{BAI} setting, that evaluates the ability of an algorithm to determine the arm with the highest variance after a fixed number of pulls. We develop a novel online algorithm called \\texttt{UCB-VV} for the regret setting and show that its upper bound on regret for bounded rewards evolves as $\\mathcal{O}\\left(\\log{n}\\right)$ where $n$ is the horizon. By deriving the lower bound on the regret, we show that \\texttt{UCB-VV} is order optimal. For the fixed budget \\ac{BAI} setting and propose the \\texttt{SHVV} algorithm. We show that the upper bound of the error probability of \\texttt{SHVV} evolves as $\\exp\\left(-\\frac{n}{\\log(K) H}\\right)$, where $H$ represents the complexity of the problem, and this rate matches the corresponding lower bound. We extend the framework from bounded distributions to sub-Gaussian distributions using a novel concentration inequality on the sample variance. Leveraging the same, we derive a concentration inequality for the empirical Sharpe ratio (SR) for sub-Gaussian distributions, which was previously unknown in the literature. Empirical simulations show that \\texttt{UCB-VV} consistently outperforms \\texttt{$\\epsilon$-greedy} across different sub-optimality gaps though it is surpassed by \\texttt{VTS}, which exhibits the lowest regret, albeit lacking in theoretical guarantees. We also illustrate the superior performance of \\texttt{SHVV}, for a fixed budget setting under 6 different setups against uniform sampling. Finally, we conduct a case study to empirically evaluate the performance of the \\texttt{UCB-VV} and \\texttt{SHVV} in call option trading on $100$ stocks generated using \\ac{GBM}.","authors":["Sabrina Khurshid","Gourab Ghatak","Mohammad Shahid Abdulla"],"url":"https://arxiv.org/abs/2505.11985"}
{"created":"2025-05-20","title":"TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique Annotation in Cyber Threat Intelligence Text","abstract":"Accurately identifying adversarial techniques in security texts is critical for effective cyber defense. However, existing methods face a fundamental trade-off: they either rely on generic models with limited domain precision or require resource-intensive pipelines that depend on large labeled datasets and task-specific optimizations, such as custom hard-negative mining and denoising, resources rarely available in specialized domains.","authors":["Ahmed Lekssays","Utsav Shukla","Husrev Taha Sencar","Md Rizwan Parvez"],"url":"https://arxiv.org/abs/2505.11988"}
{"created":"2025-05-20","title":"SpatialCrafter: Unleashing the Imagination of Video Diffusion Models for Scene Reconstruction from Limited Observations","abstract":"Novel view synthesis (NVS) boosts immersive experiences in computer vision and graphics. Existing techniques, though progressed, rely on dense multi-view observations, restricting their application. This work takes on the challenge of reconstructing photorealistic 3D scenes from sparse or single-view inputs. We introduce SpatialCrafter, a framework that leverages the rich knowledge in video diffusion models to generate plausible additional observations, thereby alleviating reconstruction ambiguity. Through a trainable camera encoder and an epipolar attention mechanism for explicit geometric constraints, we achieve precise camera control and 3D consistency, further reinforced by a unified scale estimation strategy to handle scale discrepancies across datasets. Furthermore, by integrating monocular depth priors with semantic features in the video latent space, our framework directly regresses 3D Gaussian primitives and efficiently processes long-sequence features using a hybrid network structure. Extensive experiments show our method enhances sparse view reconstruction and restores the realistic appearance of 3D scenes.","authors":["Songchun Zhang","Huiyao Xu","Sitong Guo","Zhongwei Xie","Pengwei Liu","Hujun Bao","Weiwei Xu","Changqing Zou"],"url":"https://arxiv.org/abs/2505.11992"}
{"created":"2025-05-20","title":"A general secondary construction of Boolean functions including the indirect sum and its generalizations","abstract":"We study a secondary construction of Boolean functions, which generalizes the direct sum and the indirect sum. We detail how these two classic secondary constructions are particular cases of this more general one, as well as two known generalizations of the indirect sum. This unifies the known secondary constructions of Boolean functions. We study very precisely the Walsh transform of the constructed functions. This leads us to an interesting observation on the Walsh transforms $W_g,W_{g'},W_{g''}$, and $W_{g\\oplus g'\\oplus g''}$ when $g,g',g''$ are Boolean functions such that $(g\\oplus g')(g\\oplus g'')$ equals the zero function.","authors":["Claude Carlet","Deng Tang"],"url":"https://arxiv.org/abs/2505.11994"}
{"created":"2025-05-20","title":"Unveiling Knowledge Utilization Mechanisms in LLM-based Retrieval-Augmented Generation","abstract":"Considering the inherent limitations of parametric knowledge in large language models (LLMs), retrieval-augmented generation (RAG) is widely employed to expand their knowledge scope. Since RAG has shown promise in knowledge-intensive tasks like open-domain question answering, its broader application to complex tasks and intelligent assistants has further advanced its utility. Despite this progress, the underlying knowledge utilization mechanisms of LLM-based RAG remain underexplored. In this paper, we present a systematic investigation of the intrinsic mechanisms by which LLMs integrate internal (parametric) and external (retrieved) knowledge in RAG scenarios. Specially, we employ knowledge stream analysis at the macroscopic level, and investigate the function of individual modules at the microscopic level. Drawing on knowledge streaming analyses, we decompose the knowledge utilization process into four distinct stages within LLM layers: knowledge refinement, knowledge elicitation, knowledge expression, and knowledge contestation. We further demonstrate that the relevance of passages guides the streaming of knowledge through these stages. At the module level, we introduce a new method, knowledge activation probability entropy (KAPE) for neuron identification associated with either internal or external knowledge. By selectively deactivating these neurons, we achieve targeted shifts in the LLM's reliance on one knowledge source over the other. Moreover, we discern complementary roles for multi-head attention and multi-layer perceptron layers during knowledge formation. These insights offer a foundation for improving interpretability and reliability in retrieval-augmented LLMs, paving the way for more robust and transparent generative solutions in knowledge-intensive domains.","authors":["Yuhao Wang","Ruiyang Ren","Yucheng Wang","Wayne Xin Zhao","Jing Liu","Hua Wu","Haifeng Wang"],"url":"https://arxiv.org/abs/2505.11995"}
{"created":"2025-05-20","title":"To Recommend or Not to Recommend: Designing and Evaluating AI-Enabled Decision Support for Time-Critical Medical Events","abstract":"AI-enabled decision-support systems aim to help medical providers rapidly make decisions with limited information during medical emergencies. A critical challenge in developing these systems is supporting providers in interpreting the system output to make optimal treatment decisions. In this study, we designed and evaluated an AI-enabled decision-support system to aid providers in treating patients with traumatic injuries. We first conducted user research with physicians to identify and design information types and AI outputs for a decision-support display. We then conducted an online experiment with 35 medical providers from six health systems to evaluate two human-AI interaction strategies: (1) AI information synthesis and (2) AI information and recommendations. We found that providers were more likely to make correct decisions when AI information and recommendations were provided compared to receiving no AI support. We also identified two socio-technical barriers to providing AI recommendations during time-critical medical events: (1) an accuracy-time trade-off in providing recommendations and (2) polarizing perceptions of recommendations between providers. We discuss three implications for developing AI-enabled decision support used in time-critical events, contributing to the limited research on human-AI interaction in this context.","authors":["Angela Mastrianni","Mary Suhyun Kim","Travis M. Sullivan","Genevieve Jayne Sippel","Randall S. Burd","Krzysztof Z. Gajos","Aleksandra Sarcevic"],"url":"https://arxiv.org/abs/2505.11996"}
{"created":"2025-05-20","title":"Multimodal Cancer Survival Analysis via Hypergraph Learning with Cross-Modality Rebalance","abstract":"Multimodal pathology-genomic analysis has become increasingly prominent in cancer survival prediction. However, existing studies mainly utilize multi-instance learning to aggregate patch-level features, neglecting the information loss of contextual and hierarchical details within pathology images. Furthermore, the disparity in data granularity and dimensionality between pathology and genomics leads to a significant modality imbalance. The high spatial resolution inherent in pathology data renders it a dominant role while overshadowing genomics in multimodal integration. In this paper, we propose a multimodal survival prediction framework that incorporates hypergraph learning to effectively capture both contextual and hierarchical details from pathology images. Moreover, it employs a modality rebalance mechanism and an interactive alignment fusion strategy to dynamically reweight the contributions of the two modalities, thereby mitigating the pathology-genomics imbalance. Quantitative and qualitative experiments are conducted on five TCGA datasets, demonstrating that our model outperforms advanced methods by over 3.4\\% in C-Index performance.","authors":["Mingcheng Qu","Guang Yang","Donglin","Tonghua Su","Yue Gao","Yang Song","Lei Fan"],"url":"https://arxiv.org/abs/2505.11997"}
{"created":"2025-05-20","title":"Parameter Efficient Continual Learning with Dynamic Low-Rank Adaptation","abstract":"Catastrophic forgetting has remained a critical challenge for deep neural networks in Continual Learning (CL) as it undermines consolidated knowledge when learning new tasks. Parameter efficient fine tuning CL techniques are gaining traction for their effectiveness in addressing catastrophic forgetting with a lightweight training schedule while avoiding degradation of consolidated knowledge in pre-trained models. However, low rank adapters (LoRA) in these approaches are highly sensitive to rank selection which can lead to sub-optimal resource allocation and performance. To this end, we introduce PEARL, a rehearsal-free CL framework that entails dynamic rank allocation for LoRA components during CL training. Specifically, PEARL leverages reference task weights and adaptively determines the rank of task-specific LoRA components based on the current tasks' proximity to reference task weights in parameter space. To demonstrate the versatility of PEARL, we evaluate it across three vision architectures (ResNet, Separable Convolutional Network and Vision Transformer) and a multitude of CL scenarios, and show that PEARL outperforms all considered baselines by a large margin.","authors":["Prashant Shivaram Bhat","Shakib Yazdani","Elahe Arani","Bahram Zonooz"],"url":"https://arxiv.org/abs/2505.11998"}
{"created":"2025-05-20","title":"MRGRP: Empowering Courier Route Prediction in Food Delivery Service with Multi-Relational Graph","abstract":"Instant food delivery has become one of the most popular web services worldwide due to its convenience in daily life. A fundamental challenge is accurately predicting courier routes to optimize task dispatch and improve delivery efficiency. This enhances satisfaction for couriers and users and increases platform profitability. The current heuristic prediction method uses only limited human-selected task features and ignores couriers preferences, causing suboptimal results. Additionally, existing learning-based methods do not fully capture the diverse factors influencing courier decisions or the complex relationships among them. To address this, we propose a Multi-Relational Graph-based Route Prediction (MRGRP) method that models fine-grained correlations among tasks affecting courier decisions for accurate prediction. We encode spatial and temporal proximity, along with pickup-delivery relationships, into a multi-relational graph and design a GraphFormer architecture to capture these complex connections. We also introduce a route decoder that leverages courier information and dynamic distance and time contexts for prediction, using existing route solutions as references to improve outcomes. Experiments show our model achieves state-of-the-art route prediction on offline data from cities of various sizes. Deployed on the Meituan Turing platform, it surpasses the current heuristic algorithm, reaching a high route prediction accuracy of 0.819, essential for courier and user satisfaction in instant food delivery.","authors":["Chang Liu","Huan Yan","Hongjie Sui","Haomin Wen","Yuan Yuan","Yuyang Han","Hongsen Liao","Xuetao Ding","Jinghua Hao","Yong Li"],"url":"https://arxiv.org/abs/2505.11999"}
{"created":"2025-05-20","title":"IQBench: How \"Smart'' Are Vision-Language Models? A Study with Human IQ Tests","abstract":"Although large Vision-Language Models (VLMs) have demonstrated remarkable performance in a wide range of multimodal tasks, their true reasoning capabilities on human IQ tests remain underexplored. To advance research on the fluid intelligence of VLMs, we introduce **IQBench**, a new benchmark designed to evaluate VLMs on standardized visual IQ tests. We focus on evaluating the reasoning capabilities of VLMs, which we argue are more important than the accuracy of the final prediction. **Our benchmark is visually centric, minimizing the dependence on unnecessary textual content**, thus encouraging models to derive answers primarily from image-based information rather than learned textual knowledge. To this end, we manually collected and annotated 500 visual IQ questions to **prevent unintentional data leakage during training**. Unlike prior work that focuses primarily on the accuracy of the final answer, we evaluate the reasoning ability of the models by assessing their explanations and the patterns used to solve each problem, along with the accuracy of the final prediction and human evaluation. Our experiments show that there are substantial performance disparities between tasks, with models such as `o4-mini`, `gemini-2.5-flash`, and `claude-3.7-sonnet` achieving the highest average accuracies of 0.615, 0.578, and 0.548, respectively. However, all models struggle with 3D spatial and anagram reasoning tasks, highlighting significant limitations in current VLMs' general reasoning abilities. In terms of reasoning scores, `o4-mini`, `gemini-2.5-flash`, and `claude-3.7-sonnet` achieved top averages of 0.696, 0.586, and 0.516, respectively. These results highlight inconsistencies between the reasoning processes of the models and their final answers, emphasizing the importance of evaluating the accuracy of the reasoning in addition to the final predictions.","authors":["Tan-Hanh Pham","Phu-Vinh Nguyen","Dang The Hung","Bui Trong Duong","Vu Nguyen Thanh","Chris Ngo","Tri Quang Truong","Truong-Son Hy"],"url":"https://arxiv.org/abs/2505.12000"}
{"created":"2025-05-20","title":"Interactional Fairness in LLM Multi-Agent Systems: An Evaluation Framework","abstract":"As large language models (LLMs) are increasingly used in multi-agent systems, questions of fairness should extend beyond resource distribution and procedural design to include the fairness of how agents communicate. Drawing from organizational psychology, we introduce a novel framework for evaluating Interactional fairness encompassing Interpersonal fairness (IF) and Informational fairness (InfF) in LLM-based multi-agent systems (LLM-MAS). We extend the theoretical grounding of Interactional Fairness to non-sentient agents, reframing fairness as a socially interpretable signal rather than a subjective experience. We then adapt established tools from organizational justice research, including Colquitt's Organizational Justice Scale and the Critical Incident Technique, to measure fairness as a behavioral property of agent interaction. We validate our framework through a pilot study using controlled simulations of a resource negotiation task. We systematically manipulate tone, explanation quality, outcome inequality, and task framing (collaborative vs. competitive) to assess how IF influences agent behavior. Results show that tone and justification quality significantly affect acceptance decisions even when objective outcomes are held constant. In addition, the influence of IF vs. InfF varies with context. This work lays the foundation for fairness auditing and norm-sensitive alignment in LLM-MAS.","authors":["Ruta Binkyte"],"url":"https://arxiv.org/abs/2505.12001"}
{"created":"2025-05-20","title":"Approximation theory for 1-Lipschitz ResNets","abstract":"1-Lipschitz neural networks are fundamental for generative modelling, inverse problems, and robust classifiers. In this paper, we focus on 1-Lipschitz residual networks (ResNets) based on explicit Euler steps of negative gradient flows and study their approximation capabilities. Leveraging the Restricted Stone-Weierstrass Theorem, we first show that these 1-Lipschitz ResNets are dense in the set of scalar 1-Lipschitz functions on any compact domain when width and depth are allowed to grow. We also show that these networks can exactly represent scalar piecewise affine 1-Lipschitz functions. We then prove a stronger statement: by inserting norm-constrained linear maps between the residual blocks, the same density holds when the hidden width is fixed. Because every layer obeys simple norm constraints, the resulting models can be trained with off-the-shelf optimisers. This paper provides the first universal approximation guarantees for 1-Lipschitz ResNets, laying a rigorous foundation for their practical use.","authors":["Davide Murari","Takashi Furuya","Carola-Bibiane Sch\\\"onlieb"],"url":"https://arxiv.org/abs/2505.12003"}
{"created":"2025-05-20","title":"CHRIS: Clothed Human Reconstruction with Side View Consistency","abstract":"Creating a realistic clothed human from a single-view RGB image is crucial for applications like mixed reality and filmmaking. Despite some progress in recent years, mainstream methods often fail to fully utilize side-view information, as the input single-view image contains front-view information only. This leads to globally unrealistic topology and local surface inconsistency in side views. To address these, we introduce Clothed Human Reconstruction with Side View Consistency, namely CHRIS, which consists of 1) A Side-View Normal Discriminator that enhances global visual reasonability by distinguishing the generated side-view normals from the ground truth ones; 2) A Multi-to-One Gradient Computation (M2O) that ensures local surface consistency. M2O calculates the gradient of a sampling point by integrating the gradients of the nearby points, effectively acting as a smooth operation. Experimental results demonstrate that CHRIS achieves state-of-the-art performance on public benchmarks and outperforms the prior work.","authors":["Dong Liu","Yifan Yang","Zixiong Huang","Yuxin Gao","Mingkui Tan"],"url":"https://arxiv.org/abs/2505.12005"}
{"created":"2025-05-20","title":"SOCIA: An End-to-End Agentic Framework for Automated Cyber-Physical-Social Simulator Generation","abstract":"This paper introduces SOCIA (Simulation Orchestration for Cyber-physical-social Intelligence and Agents), a novel end-to-end framework leveraging Large Language Model (LLM)-based multi-agent systems to automate the generation of high-fidelity Cyber-Physical-Social (CPS) simulators. Addressing the challenges of labor-intensive manual simulator development and complex data calibration, SOCIA integrates a centralized orchestration manager that coordinates specialized agents for tasks including data comprehension, code generation, simulation execution, and iterative evaluation-feedback loops. Through empirical evaluations across diverse CPS tasks, such as mask adoption behavior simulation (social), personal mobility generation (physical), and user modeling (cyber), SOCIA demonstrates its ability to produce high-fidelity, scalable simulations with reduced human intervention. These results highlight SOCIA's potential to offer a scalable solution for studying complex CPS phenomena","authors":["Yuncheng Hua","Ji Miao","Mehdi Jafari","Jianxiang Xie","Hao Xue","Flora D. Salim"],"url":"https://arxiv.org/abs/2505.12006"}
{"created":"2025-05-20","title":"Multi-modal Collaborative Optimization and Expansion Network for Event-assisted Single-eye Expression Recognition","abstract":"In this paper, we proposed a Multi-modal Collaborative Optimization and Expansion Network (MCO-E Net), to use event modalities to resist challenges such as low light, high exposure, and high dynamic range in single-eye expression recognition tasks. The MCO-E Net introduces two innovative designs: Multi-modal Collaborative Optimization Mamba (MCO-Mamba) and Heterogeneous Collaborative and Expansion Mixture-of-Experts (HCE-MoE). MCO-Mamba, building upon Mamba, leverages dual-modal information to jointly optimize the model, facilitating collaborative interaction and fusion of modal semantics. This approach encourages the model to balance the learning of both modalities and harness their respective strengths. HCE-MoE, on the other hand, employs a dynamic routing mechanism to distribute structurally varied experts (deep, attention, and focal), fostering collaborative learning of complementary semantics. This heterogeneous architecture systematically integrates diverse feature extraction paradigms to comprehensively capture expression semantics. Extensive experiments demonstrate that our proposed network achieves competitive performance in the task of single-eye expression recognition, especially under poor lighting conditions.","authors":["Runduo Han","Xiuping Liu","Shangxuan Yi","Yi Zhang","Hongchen Tan"],"url":"https://arxiv.org/abs/2505.12007"}
{"created":"2025-05-20","title":"Black-box Adversaries from Latent Space: Unnoticeable Attacks on Human Pose and Shape Estimation","abstract":"Expressive human pose and shape (EHPS) estimation is vital for digital human generation, particularly in live-streaming applications. However, most existing EHPS models focus primarily on minimizing estimation errors, with limited attention on potential security vulnerabilities. Current adversarial attacks on EHPS models often require white-box access (e.g., model details or gradients) or generate visually conspicuous perturbations, limiting their practicality and ability to expose real-world security threats. To address these limitations, we propose a novel Unnoticeable Black-Box Attack (UBA) against EHPS models. UBA leverages the latent-space representations of natural images to generate an optimal adversarial noise pattern and iteratively refine its attack potency along an optimized direction in digital space. Crucially, this process relies solely on querying the model's output, requiring no internal knowledge of the EHPS architecture, while guiding the noise optimization toward greater stealth and effectiveness. Extensive experiments and visual analyses demonstrate the superiority of UBA. Notably, UBA increases the pose estimation errors of EHPS models by 17.27%-58.21% on average, revealing critical vulnerabilities. These findings underscore the urgent need to address and mitigate security risks associated with digital human generation systems.","authors":["Zhiying Li","Guanggang Geng","Yeying Jin","Zhizhi Guo","Bruce Gu","Jidong Huo","Zhaoxin Fan","Wenjun Wu"],"url":"https://arxiv.org/abs/2505.12009"}
{"created":"2025-05-20","title":"Incentivize Contribution and Learn Parameters Too: Federated Learning with Strategic Data Owners","abstract":"Classical federated learning (FL) assumes that the clients have a limited amount of noisy data with which they voluntarily participate and contribute towards learning a global, more accurate model in a principled manner. The learning happens in a distributed fashion without sharing the data with the center. However, these methods do not consider the incentive of an agent for participating and contributing to the process, given that data collection and running a distributed algorithm is costly for the clients. The question of rationality of contribution has been asked recently in the literature and some results exist that consider this problem. This paper addresses the question of simultaneous parameter learning and incentivizing contribution, which distinguishes it from the extant literature. Our first mechanism incentivizes each client to contribute to the FL process at a Nash equilibrium and simultaneously learn the model parameters. However, this equilibrium outcome can be away from the optimal, where clients contribute with their full data and the algorithm learns the optimal parameters. We propose a second mechanism with monetary transfers that is budget balanced and enables the full data contribution along with optimal parameter learning. Large scale experiments with real (federated) datasets (CIFAR-10, FeMNIST, and Twitter) show that these algorithms converge quite fast in practice, yield good welfare guarantees, and better model performance for all agents.","authors":["Drashthi Doshi","Aditya Vema Reddy Kesari","Swaprava Nath","Avishek Ghosh","Suhas S Kowshik"],"url":"https://arxiv.org/abs/2505.12010"}
{"created":"2025-05-20","title":"Empowering Sustainable Finance with Artificial Intelligence: A Framework for Responsible Implementation","abstract":"This chapter explores the convergence of two major developments: the rise of environmental, social, and governance (ESG) investing and the exponential growth of artificial intelligence (AI) technology. The increased demand for diverse ESG instruments, such as green and ESG-linked loans, will be aligned with the rapid growth of the global AI market, which is expected to be worth $1,394.30 billion by 2029. AI can assist in identifying and pricing climate risks, setting more ambitious ESG goals, and advancing sustainable finance decisions. However, delegating sustainable finance decisions to AI poses serious risks, and new principles and rules for AI and ESG investing are necessary to mitigate these risks. This chapter highlights the challenges associated with norm-setting initiatives and stresses the need for the fine-tuning of the principles of legitimacy, oversight and verification, transparency, and explainability. Finally, the chapter contends that integrating AI into ESG non-financial reporting necessitates a heightened sense of responsibility and the establishment of fundamental guiding principles within the spheres of AI and ESG investing.","authors":["Georgios Pavlidis"],"url":"https://arxiv.org/abs/2505.12012"}
{"created":"2025-05-20","title":"A Human Study of Cognitive Biases in CTF Challenges","abstract":"Cybersecurity training has become a crucial part of computer science education and industrial onboarding. Capture the Flag (CTF) competitions have emerged as a valuable, gamified approach for developing and refining the skills of cybersecurity and software engineering professionals. However, while CTFs provide a controlled environment for tackling real world challenges, the participants' decision making and problem solving processes remain under explored. Recognizing that psychology may play a role in a cyber attacker's behavior, we investigate how cognitive biases could be used to improve CTF education and security. In this paper, we present an approach to control cognitive biases, specifically Satisfaction of Search and Loss Aversion, to influence and potentially hinder attackers' effectiveness against web application vulnerabilities in a CTF style challenge. We employ a rigorous quantitative and qualitative analysis through a controlled human study of CTF tasks. CTF exercises are widely used in cybersecurity education and research to simulate real world attack scenarios and help participants develop critical skills by solving security challenges in controlled environments. In our study, participants interact with a web application containing deliberately embedded vulnerabilities while being subjected to tasks designed to trigger cognitive biases. Our study reveals that many participants exhibit the Satisfaction of Search bias and that this bias has a significant effect on their success. On average, participants found 25% fewer flags compared to those who did not exhibit this bias. Our findings provide valuable insights into how cognitive biases can be strategically employed to enhance cybersecurity outcomes, education, and measurements through the lens of CTF challenges.","authors":["Yuwei Yang","Skyler Grandel","Daniel Balasubramanian","Yu Huang","Kevin Leach"],"url":"https://arxiv.org/abs/2505.12018"}
{"created":"2025-05-20","title":"FL-PLAS: Federated Learning with Partial Layer Aggregation for Backdoor Defense Against High-Ratio Malicious Clients","abstract":"Federated learning (FL) is gaining increasing attention as an emerging collaborative machine learning approach, particularly in the context of large-scale computing and data systems. However, the fundamental algorithm of FL, Federated Averaging (FedAvg), is susceptible to backdoor attacks. Although researchers have proposed numerous defense algorithms, two significant challenges remain. The attack is becoming more stealthy and harder to detect, and current defense methods are unable to handle 50\\% or more malicious users or assume an auxiliary server dataset.","authors":["Jianyi Zhang","Ziyin Zhou","Yilong Li","Qichao Jin"],"url":"https://arxiv.org/abs/2505.12019"}
{"created":"2025-05-20","title":"GeoMaNO: Geometric Mamba Neural Operator for Partial Differential Equations","abstract":"The neural operator (NO) framework has emerged as a powerful tool for solving partial differential equations (PDEs). Recent NOs are dominated by the Transformer architecture, which offers NOs the capability to capture long-range dependencies in PDE dynamics. However, existing Transformer-based NOs suffer from quadratic complexity, lack geometric rigor, and thus suffer from sub-optimal performance on regular grids. As a remedy, we propose the Geometric Mamba Neural Operator (GeoMaNO) framework, which empowers NOs with Mamba's modeling capability, linear complexity, plus geometric rigor. We evaluate GeoMaNO's performance on multiple standard and popularly employed PDE benchmarks, spanning from Darcy flow problems to Navier-Stokes problems. GeoMaNO improves existing baselines in solution operator approximation by as much as 58.9%.","authors":["Xi Han","Jingwei Zhang","Dimitris Samaras","Fei Hou","Hong Qin"],"url":"https://arxiv.org/abs/2505.12020"}
{"created":"2025-05-20","title":"Cross-Model Transfer of Task Vectors via Few-Shot Orthogonal Alignment","abstract":"Task arithmetic enables efficient model editing by representing task-specific changes as vectors in parameter space. Task arithmetic typically assumes that the source and target models are initialized from the same pre-trained parameters. This assumption limits its applicability in cross-model transfer settings, where models are independently pre-trained on different datasets. To address this challenge, we propose a method based on few-shot orthogonal alignment, which aligns task vectors to the parameter space of a differently pre-trained target model. These transformations preserve key properties of task vectors, such as norm and rank, and are learned using only a small number of labeled examples. We evaluate the method using two Vision Transformers pre-trained on YFCC100M and LAION400M, and test on eight classification datasets. Experimental results show that our method improves transfer accuracy over direct task vector application and achieves performance comparable to few-shot fine-tuning, while maintaining the modularity and reusability of task vectors. Our code is available at https://github.com/kawakera-lab/CrossModelTransfer.","authors":["Kazuhiko Kawamoto","Atsuhiro Endo","Hiroshi Kera"],"url":"https://arxiv.org/abs/2505.12021"}
{"created":"2025-05-20","title":"A Reduction-based Algorithm for the Clique Interdiction Problem","abstract":"The Clique Interdiction Problem (CIP) aims to minimize the size of the largest clique in a given graph by removing a given number of vertices.","authors":["Chenghao Zhu","Yi Zhou","Haoyu Jiang"],"url":"https://arxiv.org/abs/2505.12022"}
{"created":"2025-05-20","title":"Balanced residuated partially ordered semigroups","abstract":"A residuated semigroup is a structure $\\langle A,\\le,\\cdot,\\backslash,/ \\rangle$ where $\\langle A,\\le \\rangle$ is a poset and $\\langle A,\\cdot \\rangle$ is a semigroup such that the residuation law $x\\cdot y\\le z\\iff x\\le z/y\\iff y\\le x \\backslash z$ holds. An element $p$ is positive if $a\\le pa$ and $a \\le ap$ for all $a$. A residuated semigroup is called balanced if it satisfies the equation $x \\backslash x \\approx x / x$ and moreover each element of the form $a \\backslash a = a / a$ is positive, and it is called integrally closed if it satisfies the same equation and moreover each element of this form is a global identity. We show how a wide class of balanced residuated semigroups (so-called steady residuated semigroups) can be decomposed into integrally closed pieces, using a generalization of the classical Plonka sum construction. This generalization involves gluing a disjoint family of ordered algebras together using multiple families of maps, rather than a single family as in ordinary Plonka sums.","authors":["Stefano Bonzio","Jos\\'e Gil-F\\'erez","Peter Jipsen","Adam P\\v{r}enosil","Melissa Sugimoto"],"url":"https://arxiv.org/abs/2505.12024"}
{"created":"2025-05-20","title":"Spotlight Your Instructions: Instruction-following with Dynamic Attention Steering","abstract":"In many real-world applications, users rely on natural language instructions to guide large language models (LLMs) across a wide range of tasks. These instructions are often complex, diverse, and subject to frequent change. However, LLMs do not always attend to these instructions reliably, and users lack simple mechanisms to emphasize their importance beyond modifying prompt wording or structure. To address this, we present an inference-time method that enables users to emphasize specific parts of their prompt by steering the model's attention toward them, aligning the model's perceived importance of different prompt tokens with user intent. Unlike prior approaches that are limited to static instructions, require significant offline profiling, or rely on fixed biases, we dynamically update the proportion of model attention given to the user-specified parts--ensuring improved instruction following without performance degradation. We demonstrate that our approach improves instruction following across a variety of tasks involving multiple instructions and generalizes across models of varying scales.","authors":["Praveen Venkateswaran","Danish Contractor"],"url":"https://arxiv.org/abs/2505.12025"}
{"created":"2025-05-20","title":"Relation-Aware Graph Foundation Model","abstract":"In recent years, large language models (LLMs) have demonstrated remarkable generalization capabilities across various natural language processing (NLP) tasks. Similarly, graph foundation models (GFMs) have emerged as a promising direction in graph learning, aiming to generalize across diverse datasets through large-scale pre-training. However, unlike language models that rely on explicit token representations, graphs lack a well-defined unit for generalization, making it challenging to design effective pre-training strategies. In this work, we propose REEF, a novel framework that leverages relation tokens as the basic units for GFMs. Inspired by the token vocabulary in LLMs, we construct a relation vocabulary of relation tokens to store relational information within graphs. To accommodate diverse relations, we introduce two hypernetworks that adaptively generate the parameters of aggregators and classifiers in graph neural networks based on relation tokens. In addition, we design another hypernetwork to construct dataset-specific projectors and incorporate a dataset-level feature bias into the initial node representations, enhancing flexibility across different datasets with the same relation. Further, we adopt graph data augmentation and a mixed-dataset pre-training strategy, allowing REEF to capture relational diversity more effectively and exhibit strong generalization capabilities. Extensive experiments show that REEF significantly outperforms existing methods on both pre-training and transfer learning tasks, underscoring its potential as a powerful foundation model for graph-based applications.","authors":["Jianxiang Yu","Jiapeng Zhu","Hao Qian","Ziqi Liu","Zhiqiang Zhang","Xiang Li"],"url":"https://arxiv.org/abs/2505.12027"}
{"created":"2025-05-20","title":"Towards Comprehensive Argument Analysis in Education: Dataset, Tasks, and Method","abstract":"Argument mining has garnered increasing attention over the years, with the recent advancement of Large Language Models (LLMs) further propelling this trend. However, current argument relations remain relatively simplistic and foundational, struggling to capture the full scope of argument information, particularly when it comes to representing complex argument structures in real-world scenarios. To address this limitation, we propose 14 fine-grained relation types from both vertical and horizontal dimensions, thereby capturing the intricate interplay between argument components for a thorough understanding of argument structure. On this basis, we conducted extensive experiments on three tasks: argument component detection, relation prediction, and automated essay grading. Additionally, we explored the impact of writing quality on argument component detection and relation prediction, as well as the connections between discourse relations and argumentative features. The findings highlight the importance of fine-grained argumentative annotations for argumentative writing quality assessment and encourage multi-dimensional argument analysis.","authors":["Yupei Ren","Xinyi Zhou","Ning Zhang","Shangqing Zhao","Man Lan","Xiaopeng Bai"],"url":"https://arxiv.org/abs/2505.12028"}
{"created":"2025-05-20","title":"Growable and Interpretable Neural Control with Online Continual Learning for Autonomous Lifelong Locomotion Learning Machines","abstract":"Continual locomotion learning faces four challenges: incomprehensibility, sample inefficiency, lack of knowledge exploitation, and catastrophic forgetting. Thus, this work introduces Growable Online Locomotion Learning Under Multicondition (GOLLUM), which exploits the interpretability feature to address the aforementioned challenges. GOLLUM has two dimensions of interpretability: layer-wise interpretability for neural control function encoding and column-wise interpretability for robot skill encoding. With this interpretable control structure, GOLLUM utilizes neurogenesis to unsupervisely increment columns (ring-like networks); each column is trained separately to encode and maintain a specific primary robot skill. GOLLUM also transfers the parameters to new skills and supplements the learned combination of acquired skills through another neural mapping layer added (layer-wise) with online supplementary learning. On a physical hexapod robot, GOLLUM successfully acquired multiple locomotion skills (e.g., walking, slope climbing, and bouncing) autonomously and continuously within an hour using a simple reward function. Furthermore, it demonstrated the capability of combining previous learned skills to facilitate the learning process of new skills while preventing catastrophic forgetting. Compared to state-of-the-art locomotion learning approaches, GOLLUM is the only approach that addresses the four challenges above mentioned without human intervention. It also emphasizes the potential exploitation of interpretability to achieve autonomous lifelong learning machines.","authors":["Arthicha Srisuchinnawong","Poramate Manoonpong"],"url":"https://arxiv.org/abs/2505.12029"}
{"created":"2025-05-20","title":"LLM-based Automated Theorem Proving Hinges on Scalable Synthetic Data Generation","abstract":"Recent advancements in large language models (LLMs) have sparked considerable interest in automated theorem proving and a prominent line of research integrates stepwise LLM-based provers into tree search. In this paper, we introduce a novel proof-state exploration approach for training data synthesis, designed to produce diverse tactics across a wide range of intermediate proof states, thereby facilitating effective one-shot fine-tuning of LLM as the policy model. We also propose an adaptive beam size strategy, which effectively takes advantage of our data synthesis method and achieves a trade-off between exploration and exploitation during tree search. Evaluations on the MiniF2F and ProofNet benchmarks demonstrate that our method outperforms strong baselines under the stringent Pass@1 metric, attaining an average pass rate of $60.74\\%$ on MiniF2F and $21.18\\%$ on ProofNet. These results underscore the impact of large-scale synthetic data in advancing automated theorem proving.","authors":["Junyu Lai","Jiakun Zhang","Shuo Xu","Taolue Chen","Zihang Wang","Yao Yang","Jiarui Zhang","Chun Cao","Jingwei Xu"],"url":"https://arxiv.org/abs/2505.12031"}
{"created":"2025-05-20","title":"Synapse: Virtualizing Match Tables in Programmable Hardware","abstract":"Efficient network packet processing increasingly demands dynamic, adaptive, and run-time resizable match table allocation to handle the diverse and heterogeneous nature of traffic patterns and rule sets. Achieving this flexibility at high performance in hardware is challenging, as fixed resource constraints and architectural limitations have traditionally restricted such adaptability. In this paper, we introduce Synapse, an extension to programmable data plane architectures that incorporates the Virtual Matching Table (VMT) framework, drawing inspiration from virtual memory systems in Operating Systems (OSs), but specifically tailored to network processing. This abstraction layer allows logical tables to be elastic, enabling dynamic and efficient match table allocation at runtime. Our design features a hybrid memory system, leveraging on-chip associative memories for fast matching of the most popular rules and off-chip addressable memory for scalable and cost-effective storage. Furthermore, by employing a sharding mechanism across physical match tables, Synapse ensures that the power required per key match remains bounded and proportional to the key distribution and the size of the involved shard. To address the challenge of dynamic allocation, we formulate and solve an optimization problem that dynamically allocates physical match tables to logical tables based on pipeline usage and traffic characteristics at the millisecond scale. We prototype our design on FPGA and develop a simulator to evaluate the performance, demonstrating its effectiveness and scalability.","authors":["Seyyidahmed Lahmer","Angelo Tulumello","Alessandro Rivitti","Giuseppe Bianchi","Andrea Zanella"],"url":"https://arxiv.org/abs/2505.12036"}
{"created":"2025-05-20","title":"Adaptive Resolving Methods for Reinforcement Learning with Function Approximations","abstract":"Reinforcement learning (RL) problems are fundamental in online decision-making and have been instrumental in finding an optimal policy for Markov decision processes (MDPs). Function approximations are usually deployed to handle large or infinite state-action space. In our work, we consider the RL problems with function approximation and we develop a new algorithm to solve it efficiently. Our algorithm is based on the linear programming (LP) reformulation and it resolves the LP at each iteration improved with new data arrival. Such a resolving scheme enables our algorithm to achieve an instance-dependent sample complexity guarantee, more precisely, when we have $N$ data, the output of our algorithm enjoys an instance-dependent $\\tilde{O}(1/N)$ suboptimality gap. In comparison to the $O(1/\\sqrt{N})$ worst-case guarantee established in the previous literature, our instance-dependent guarantee is tighter when the underlying instance is favorable, and the numerical experiments also reveal the efficient empirical performances of our algorithms.","authors":["Jiashuo Jiang","Yiming Zong","Yinyu Ye"],"url":"https://arxiv.org/abs/2505.12037"}
{"created":"2025-05-20","title":"Safe Delta: Consistently Preserving Safety when Fine-Tuning LLMs on Diverse Datasets","abstract":"Large language models (LLMs) have shown great potential as general-purpose AI assistants across various domains. To fully leverage this potential in specific applications, many companies provide fine-tuning API services, enabling users to upload their own data for LLM customization. However, fine-tuning services introduce a new safety threat: user-uploaded data, whether harmful or benign, can break the model's alignment, leading to unsafe outputs. Moreover, existing defense methods struggle to address the diversity of fine-tuning datasets (e.g., varying sizes, tasks), often sacrificing utility for safety or vice versa. To address this issue, we propose Safe Delta, a safety-aware post-training defense method that adjusts the delta parameters (i.e., the parameter change before and after fine-tuning). Specifically, Safe Delta estimates the safety degradation, selects delta parameters to maximize utility while limiting overall safety loss, and applies a safety compensation vector to mitigate residual safety loss. Through extensive experiments on four diverse datasets with varying settings, our approach consistently preserves safety while ensuring that the utility gain from benign datasets remains unaffected.","authors":["Ning Lu","Shengcai Liu","Jiahao Wu","Weiyu Chen","Zhirui Zhang","Yew-Soon Ong","Qi Wang","Ke Tang"],"url":"https://arxiv.org/abs/2505.12038"}
{"created":"2025-05-20","title":"AI-Driven Automation Can Become the Foundation of Next-Era Science of Science Research","abstract":"The Science of Science (SoS) explores the mechanisms underlying scientific discovery, and offers valuable insights for enhancing scientific efficiency and fostering innovation. Traditional approaches often rely on simplistic assumptions and basic statistical tools, such as linear regression and rule-based simulations, which struggle to capture the complexity and scale of modern research ecosystems. The advent of artificial intelligence (AI) presents a transformative opportunity for the next generation of SoS, enabling the automation of large-scale pattern discovery and uncovering insights previously unattainable. This paper offers a forward-looking perspective on the integration of Science of Science with AI for automated research pattern discovery and highlights key open challenges that could greatly benefit from AI. We outline the advantages of AI over traditional methods, discuss potential limitations, and propose pathways to overcome them. Additionally, we present a preliminary multi-agent system as an illustrative example to simulate research societies, showcasing AI's ability to replicate real-world research patterns and accelerate progress in Science of Science research.","authors":["Renqi Chen","Haoyang Su","Shixiang Tang","Zhenfei Yin","Qi Wu","Hui Li","Ye Sun","Nanqing Dong","Wanli Ouyang","Philip Torr"],"url":"https://arxiv.org/abs/2505.12039"}
{"created":"2025-05-20","title":"Improving regional weather forecasts with neural interpolation","abstract":"In this paper we design a neural interpolation operator to improve the boundary data for regional weather models, which is a challenging problem as we are required to map multi-scale dynamics between grid resolutions. In particular, we expose a methodology for approaching the problem through the study of a simplified model, with a view to generalise the results in this work to the dynamical core of regional weather models. Our approach will exploit a combination of techniques from image super-resolution with convolutional neural networks (CNNs) and residual networks, in addition to building the flow of atmospheric dynamics into the neural network","authors":["James Jackaman","Oliver Sutton"],"url":"https://arxiv.org/abs/2505.12040"}
{"created":"2025-05-20","title":"Particle Filtering for Enhanced Parameter Estimation in Bilinear Systems Under Colored Noise","abstract":"This paper addresses the challenging problem of parameter estimation in bilinear systems under colored noise. A novel approach, termed B-PF-RLS, is proposed, combining a particle filter (PF) with a recursive least squares (RLS) estimator. The B-PF-RLS algorithm tackles the complexities arising from system nonlinearities and colored noise by effectively estimating unknown system states using the particle filter, which are then integrated into the RLS parameter estimation process. Furthermore, the paper introduces an enhanced particle filter that eliminates the need for explicit knowledge of the measurement noise variance, enhancing the method's practicality for real-world applications. Numerical examples demonstrate the B-PF-RLS algorithm's superior performance in accurately estimating both system parameters and states, even under uncertain noise conditions. This work offers a robust and effective solution for system identification in various engineering applications involving bilinear models subject to complex noise environments.","authors":["Khalid Abd El Mageed Hag Elamin"],"url":"https://arxiv.org/abs/2505.12041"}
{"created":"2025-05-20","title":"MoL for LLMs: Dual-Loss Optimization to Enhance Domain Expertise While Preserving General Capabilities","abstract":"Although LLMs perform well in general tasks, domain-specific applications suffer from hallucinations and accuracy limitations. CPT approaches encounter two key issues: (1) domain-biased data degrades general language skills, and (2) improper corpus-mixture ratios limit effective adaptation. To address these, we propose a novel framework, Mixture of Losses (MoL), which decouples optimization objectives for domain-specific and general corpora. Specifically, cross-entropy (CE) loss is applied to domain data to ensure knowledge acquisition, while Kullback-Leibler (KL) divergence aligns general-corpus training with the base model's foundational capabilities. This dual-loss architecture preserves universal skills while enhancing domain expertise, avoiding catastrophic forgetting. Empirically, we validate that a 1:1 domain-to-general corpus ratio optimally balances training and overfitting without the need for extensive tuning or resource-intensive experiments. Furthermore, our experiments demonstrate significant performance gains compared to traditional CPT approaches, which often suffer from degradation in general language capabilities; our model achieves 27.9% higher accuracy on the Math-500 benchmark in the non-think reasoning mode, and an impressive 83.3% improvement on the challenging AIME25 subset in the think mode, underscoring the effectiveness of our approach.","authors":["Jingxue Chen","Qingkun Tang","Qianchun Lu","Siyuan Fang"],"url":"https://arxiv.org/abs/2505.12043"}
{"created":"2025-05-20","title":"FlashBias: Fast Computation of Attention with Bias","abstract":"Attention mechanism has emerged as a foundation module of modern deep learning models and has also empowered many milestones in various domains. Moreover, FlashAttention with IO-aware speedup resolves the efficiency issue of standard attention, further promoting its practicality. Beyond canonical attention, attention with bias also widely exists, such as relative position bias in vision and language models and pair representation bias in AlphaFold. In these works, prior knowledge is introduced as an additive bias term of attention weights to guide the learning process, which has been proven essential for model performance. Surprisingly, despite the common usage of attention with bias, its targeted efficiency optimization is still absent, which seriously hinders its wide applications in complex tasks. Diving into the computation of FlashAttention, we prove that its optimal efficiency is determined by the rank of the attention weight matrix. Inspired by this theoretical result, this paper presents FlashBias based on the low-rank compressed sensing theory, which can provide fast-exact computation for many widely used attention biases and a fast-accurate approximation for biases in general formalization. FlashBias can fully take advantage of the extremely optimized matrix multiplication operation in modern GPUs, achieving 1.5$\\times$ speedup for AlphaFold, and over 2$\\times$ speedup for attention with bias in vision and language models without loss of accuracy.","authors":["Haixu Wu","Minghao Guo","Yuezhou Ma","Yuanxu Sun","Jianmin Wang","Wojciech Matusik","Mingsheng Long"],"url":"https://arxiv.org/abs/2505.12044"}
{"created":"2025-05-20","title":"FIGhost: Fluorescent Ink-based Stealthy and Flexible Backdoor Attacks on Physical Traffic Sign Recognition","abstract":"Traffic sign recognition (TSR) systems are crucial for autonomous driving but are vulnerable to backdoor attacks. Existing physical backdoor attacks either lack stealth, provide inflexible attack control, or ignore emerging Vision-Large-Language-Models (VLMs). In this paper, we introduce FIGhost, the first physical-world backdoor attack leveraging fluorescent ink as triggers. Fluorescent triggers are invisible under normal conditions and activated stealthily by ultraviolet light, providing superior stealthiness, flexibility, and untraceability. Inspired by real-world graffiti, we derive realistic trigger shapes and enhance their robustness via an interpolation-based fluorescence simulation algorithm. Furthermore, we develop an automated backdoor sample generation method to support three attack objectives. Extensive evaluations in the physical world demonstrate FIGhost's effectiveness against state-of-the-art detectors and VLMs, maintaining robustness under environmental variations and effectively evading existing defenses.","authors":["Shuai Yuan","Guowen Xu","Hongwei Li","Rui Zhang","Xinyuan Qian","Wenbo Jiang","Hangcheng Cao","Qingchuan Zhao"],"url":"https://arxiv.org/abs/2505.12045"}
{"created":"2025-05-20","title":"Unsupervised Port Berth Identification from Automatic Identification System Data","abstract":"Port berthing sites are regions of high interest for monitoring and optimizing port operations. Data sourced from the Automatic Identification System (AIS) can be superimposed on berths enabling their real-time monitoring and revealing long-term utilization patterns. Ultimately, insights from multiple berths can uncover bottlenecks, and lead to the optimization of the underlying supply chain of the port and beyond. However, publicly available documentation of port berths, even when available, is frequently incomplete - e.g. there may be missing berths or inaccuracies such as incorrect boundary boxes - necessitating a more robust, data-driven approach to port berth localization. In this context, we propose an unsupervised spatial modeling method that leverages AIS data clustering and hyperparameter optimization to identify berthing sites. Trained on one month of freely available AIS data and evaluated across ports of varying sizes, our models significantly outperform competing methods, achieving a mean Bhattacharyya distance of 0.85 when comparing Gaussian Mixture Models (GMMs) trained on separate data splits, compared to 13.56 for the best existing method. Qualitative comparison with satellite images and existing berth labels further supports the superiority of our method, revealing more precise berth boundaries and improved spatial resolution across diverse port environments.","authors":["Andreas Hadjipieris","Neofytos Dimitriou","Ognjen Arandjelovi\\'c"],"url":"https://arxiv.org/abs/2505.12046"}
{"created":"2025-05-20","title":"Accelerating Diffusion-based Super-Resolution with Dynamic Time-Spatial Sampling","abstract":"Diffusion models have gained attention for their success in modeling complex distributions, achieving impressive perceptual quality in SR tasks. However, existing diffusion-based SR methods often suffer from high computational costs, requiring numerous iterative steps for training and inference. Existing acceleration techniques, such as distillation and solver optimization, are generally task-agnostic and do not fully leverage the specific characteristics of low-level tasks like super-resolution (SR). In this study, we analyze the frequency- and spatial-domain properties of diffusion-based SR methods, revealing key insights into the temporal and spatial dependencies of high-frequency signal recovery. Specifically, high-frequency details benefit from concentrated optimization during early and late diffusion iterations, while spatially textured regions demand adaptive denoising strategies. Building on these observations, we propose the Time-Spatial-aware Sampling strategy (TSS) for the acceleration of Diffusion SR without any extra training cost. TSS combines Time Dynamic Sampling (TDS), which allocates more iterations to refining textures, and Spatial Dynamic Sampling (SDS), which dynamically adjusts strategies based on image content. Extensive evaluations across multiple benchmarks demonstrate that TSS achieves state-of-the-art (SOTA) performance with significantly fewer iterations, improving MUSIQ scores by 0.2 - 3.0 and outperforming the current acceleration methods with only half the number of steps.","authors":["Rui Qin","Qijie Wang","Ming Sun","Haowei Zhu","Chao Zhou","Bin Wang"],"url":"https://arxiv.org/abs/2505.12048"}
{"created":"2025-05-20","title":"Beyond Scalar Rewards: An Axiomatic Framework for Lexicographic MDPs","abstract":"Recent work has formalized the reward hypothesis through the lens of expected utility theory, by interpreting reward as utility. Hausner's foundational work showed that dropping the continuity axiom leads to a generalization of expected utility theory where utilities are lexicographically ordered vectors of arbitrary dimension. In this paper, we extend this result by identifying a simple and practical condition under which preferences cannot be represented by scalar rewards, necessitating a 2-dimensional reward function. We provide a full characterization of such reward functions, as well as the general d-dimensional case, in Markov Decision Processes (MDPs) under a memorylessness assumption on preferences. Furthermore, we show that optimal policies in this setting retain many desirable properties of their scalar-reward counterparts, while in the Constrained MDP (CMDP) setting -- another common multiobjective setting -- they do not.","authors":["Mehran Shakerinava","Siamak Ravanbakhsh","Adam Oberman"],"url":"https://arxiv.org/abs/2505.12049"}
{"created":"2025-05-20","title":"ABoN: Adaptive Best-of-N Alignment","abstract":"Recent advances in test-time alignment methods, such as Best-of-N sampling, offer a simple and effective way to steer language models (LMs) toward preferred behaviors using reward models (RM). However, these approaches can be computationally expensive, especially when applied uniformly across prompts without accounting for differences in alignment difficulty. In this work, we propose a prompt-adaptive strategy for Best-of-N alignment that allocates inference-time compute more efficiently. Motivated by latency concerns, we develop a two-stage algorithm: an initial exploratory phase estimates the reward distribution for each prompt using a small exploration budget, and a second stage adaptively allocates the remaining budget using these estimates. Our method is simple, practical, and compatible with any LM/RM combination. Empirical results on the AlpacaEval dataset for 12 LM/RM pairs and 50 different batches of prompts show that our adaptive strategy consistently outperforms the uniform allocation with the same inference budget. Moreover, our experiments show that our adaptive strategy remains competitive against uniform allocations with 20% larger inference budgets and even improves in performance as the batch size grows.","authors":["Vinod Raman","Hilal Asi","Satyen Kale"],"url":"https://arxiv.org/abs/2505.12050"}
{"created":"2025-05-20","title":"Enhanced Multimodal Hate Video Detection via Channel-wise and Modality-wise Fusion","abstract":"The rapid rise of video content on platforms such as TikTok and YouTube has transformed information dissemination, but it has also facilitated the spread of harmful content, particularly hate videos. Despite significant efforts to combat hate speech, detecting these videos remains challenging due to their often implicit nature. Current detection methods primarily rely on unimodal approaches, which inadequately capture the complementary features across different modalities. While multimodal techniques offer a broader perspective, many fail to effectively integrate temporal dynamics and modality-wise interactions essential for identifying nuanced hate content. In this paper, we present CMFusion, an enhanced multimodal hate video detection model utilizing a novel Channel-wise and Modality-wise Fusion Mechanism. CMFusion first extracts features from text, audio, and video modalities using pre-trained models and then incorporates a temporal cross-attention mechanism to capture dependencies between video and audio streams. The learned features are then processed by channel-wise and modality-wise fusion modules to obtain informative representations of videos. Our extensive experiments on a real-world dataset demonstrate that CMFusion significantly outperforms five widely used baselines in terms of accuracy, precision, recall, and F1 score. Comprehensive ablation studies and parameter analyses further validate our design choices, highlighting the model's effectiveness in detecting hate videos. The source codes will be made publicly available at https://github.com/EvelynZ10/cmfusion.","authors":["Yinghui Zhang","Tailin Chen","Yuchen Zhang","Zeyu Fu"],"url":"https://arxiv.org/abs/2505.12051"}
{"created":"2025-05-20","title":"VFRTok: Variable Frame Rates Video Tokenizer with Duration-Proportional Information Assumption","abstract":"Modern video generation frameworks based on Latent Diffusion Models suffer from inefficiencies in tokenization due to the Frame-Proportional Information Assumption. Existing tokenizers provide fixed temporal compression rates, causing the computational cost of the diffusion model to scale linearly with the frame rate. The paper proposes the Duration-Proportional Information Assumption: the upper bound on the information capacity of a video is proportional to the duration rather than the number of frames. Based on this insight, the paper introduces VFRTok, a Transformer-based video tokenizer, that enables variable frame rate encoding and decoding through asymmetric frame rate training between the encoder and decoder. Furthermore, the paper proposes Partial Rotary Position Embeddings (RoPE) to decouple position and content modeling, which groups correlated patches into unified tokens. The Partial RoPE effectively improves content-awareness, enhancing the video generation capability. Benefiting from the compact and continuous spatio-temporal representation, VFRTok achieves competitive reconstruction quality and state-of-the-art generation fidelity while using only 1/8 tokens compared to existing tokenizers.","authors":["Tianxiong Zhong","Xingye Tian","Boyuan Jiang","Xuebo Wang","Xin Tao","Pengfei Wan","Zhiwei Zhang"],"url":"https://arxiv.org/abs/2505.12053"}
{"created":"2025-05-20","title":"GenderBench: Evaluation Suite for Gender Biases in LLMs","abstract":"We present GenderBench -- a comprehensive evaluation suite designed to measure gender biases in LLMs. GenderBench includes 14 probes that quantify 19 gender-related harmful behaviors exhibited by LLMs. We release GenderBench as an open-source and extensible library to improve the reproducibility and robustness of benchmarking across the field. We also publish our evaluation of 12 LLMs. Our measurements reveal consistent patterns in their behavior. We show that LLMs struggle with stereotypical reasoning, equitable gender representation in generated texts, and occasionally also with discriminatory behavior in high-stakes scenarios, such as hiring.","authors":["Mat\\'u\\v{s} Pikuliak"],"url":"https://arxiv.org/abs/2505.12054"}
{"created":"2025-05-20","title":"Understanding the Sneaky Patterns of Pop-up Windows in the Mobile Ecosystem","abstract":"In mobile applications, Pop-up window (PoW) plays a crucial role in improving user experience, guiding user actions, and delivering key information. Unfortunately, the excessive use of PoWs severely degrades the user experience. These PoWs often sneakily mislead users in their choices, employing tactics that subtly manipulate decision-making processes. In this paper, we provide the first in-depth study on the Sneaky patterns in the mobile ecosystem. Our research first highlights five distinct Sneaky patterns that compromise user experience, including text mislead, UI mislead, forced action, out of context and privacy-intrusive by default. To further evaluate the impact of such Sneaky patterns at large, we developed an automated analysis pipeline called Poker, to tackle the challenges of identifying, dismissing, and collecting diverse PoWs in real-world apps. Evaluation results showed that Poker achieves high precision and recall in detecting PoWs, efficiently dismissed over 88% of PoWs with minimal user interaction, with good robustness and reliability in comprehensive app exploration. Further, our systematic analysis over the top 100 popular apps in China and U.S. revealing that both regions displayed significant ratios of Sneaky patterns, particularly in promotional contexts, with high occurrences in categories such as shopping and video apps. The findings highlight the strategic deployment of Sneaky tactics that compromise user trust and ethical app design.","authors":["Dongpeng Wu","Yuhong Nan","Shaojiang Wang","Jiawei Wang","Luwa Li","Xueqiang Wang"],"url":"https://arxiv.org/abs/2505.12056"}
{"created":"2025-05-20","title":"CorBenchX: Large-Scale Chest X-Ray Error Dataset and Vision-Language Model Benchmark for Report Error Correction","abstract":"AI-driven models have shown great promise in detecting errors in radiology reports, yet the field lacks a unified benchmark for rigorous evaluation of error detection and further correction. To address this gap, we introduce CorBenchX, a comprehensive suite for automated error detection and correction in chest X-ray reports, designed to advance AI-assisted quality control in clinical practice. We first synthesize a large-scale dataset of 26,326 chest X-ray error reports by injecting clinically common errors via prompting DeepSeek-R1, with each corrupted report paired with its original text, error type, and human-readable description. Leveraging this dataset, we benchmark both open- and closed-source vision-language models,(e.g., InternVL, Qwen-VL, GPT-4o, o4-mini, and Claude-3.7) for error detection and correction under zero-shot prompting. Among these models, o4-mini achieves the best performance, with 50.6 % detection accuracy and correction scores of BLEU 0.853, ROUGE 0.924, BERTScore 0.981, SembScore 0.865, and CheXbertF1 0.954, remaining below clinical-level accuracy, highlighting the challenge of precise report correction. To advance the state of the art, we propose a multi-step reinforcement learning (MSRL) framework that optimizes a multi-objective reward combining format compliance, error-type accuracy, and BLEU similarity. We apply MSRL to QwenVL2.5-7B, the top open-source model in our benchmark, achieving an improvement of 38.3% in single-error detection precision and 5.2% in single-error correction over the zero-shot baseline.","authors":["Jing Zou","Qingqiu Li","Chenyu Lian","Lihao Liu","Xiaohan Yan","Shujun Wang","Jing Qin"],"url":"https://arxiv.org/abs/2505.12057"}
{"created":"2025-05-20","title":"Tiny QA Benchmark++: Ultra-Lightweight, Synthetic Multilingual Dataset Generation & Smoke-Tests for Continuous LLM Evaluation","abstract":"Tiny QA Benchmark++ (TQB++) presents an ultra-lightweight, multilingual smoke-test suite designed to give large-language-model (LLM) pipelines a unit-test style safety net dataset that runs in seconds with minimal cost. Born out of the tight feedback-loop demands building the Comet Opik prompt-optimization SDK, where waiting on heavyweight benchmarks breaks developer flow. TQB++ couples a 52-item English gold set (less than 20 kB) with a tiny synthetic-data generator pypi package built on provider-agnostic LiteLLM. The generator lets practitioners mint their own tiny packs in any language, domain, or difficulty, while ten ready-made packs already cover Arabic, Chinese, French, German, Japanese, Korean, Portuguese, Russian, Spanish, and Turkish. Every dataset ships with Croissant metadata and plug-and-play files for OpenAI-Evals, LangChain, and standard CI tools, so teams can drop deterministic micro-benchmarks directly into pull-request gates, prompt-engineering loops, and production dashboards without touching GPU budgets. A complete TQB++ run adds only a few seconds to pipeline latency yet reliably flags prompt-template errors, tokenizer drift, and fine-tuning side-effects long before full-scale suites like MMLU or BIG-Bench would finish configuring. The entire framework is released to accelerate continuous, resource-efficient quality assurance across the generative-AI ecosystem.","authors":["Vincent Koc"],"url":"https://arxiv.org/abs/2505.12058"}
{"created":"2025-05-20","title":"Why Not Act on What You Know? Unleashing Safety Potential of LLMs via Self-Aware Guard Enhancement","abstract":"Large Language Models (LLMs) have shown impressive capabilities across various tasks but remain vulnerable to meticulously crafted jailbreak attacks. In this paper, we identify a critical safety gap: while LLMs are adept at detecting jailbreak prompts, they often produce unsafe responses when directly processing these inputs. Inspired by this insight, we propose SAGE (Self-Aware Guard Enhancement), a training-free defense strategy designed to align LLMs' strong safety discrimination performance with their relatively weaker safety generation ability. SAGE consists of two core components: a Discriminative Analysis Module and a Discriminative Response Module, enhancing resilience against sophisticated jailbreak attempts through flexible safety discrimination instructions. Extensive experiments demonstrate SAGE's effectiveness and robustness across various open-source and closed-source LLMs of different sizes and architectures, achieving an average 99% defense success rate against numerous complex and covert jailbreak methods while maintaining helpfulness on general benchmarks. We further conduct mechanistic interpretability analysis through hidden states and attention distributions, revealing the underlying mechanisms of this detection-generation discrepancy. Our work thus contributes to developing future LLMs with coherent safety awareness and generation behavior. Our code and datasets are publicly available at https://github.com/NJUNLP/SAGE.","authors":["Peng Ding","Jun Kuang","Zongyu Wang","Xuezhi Cao","Xunliang Cai","Jiajun Chen","Shujian Huang"],"url":"https://arxiv.org/abs/2505.12060"}
{"created":"2025-05-20","title":"From Data to Actionable Understanding: A Learner-Centered Framework for Dynamic Learning Analytics","abstract":"Learning Analytics Dashboards (LADs) often fall short of their potential to empower learners, frequently prioritizing data visualization over the cognitive processes crucial for translating data into actionable learning strategies. This represents a significant gap in the field: while much research has focused on data collection and presentation, there is a lack of comprehensive models for how LADs can actively support learners' sensemaking and self-regulation. This paper introduces the Adaptive Understanding Framework (AUF), a novel conceptual model for learner-centered LAD design. The AUF seeks to address this limitation by integrating a multi-dimensional model of situational awareness, dynamic sensemaking strategies, adaptive mechanisms, and metacognitive support. This transforms LADs into dynamic learning partners that actively scaffold learners' sensemaking. Unlike existing frameworks that tend to treat these aspects in isolation, the AUF emphasizes their dynamic and intertwined relationships, creating a personalized and adaptive learning ecosystem that responds to individual needs and evolving understanding. The paper details the AUF's core principles, key components, and suggests a research agenda for future empirical validation. By fostering a deeper, more actionable understanding of learning data, AUF-inspired LADs have the potential to promote more effective, equitable, and engaging learning experiences.","authors":["Madjid Sadallah"],"url":"https://arxiv.org/abs/2505.12064"}
{"created":"2025-05-20","title":"Demystifying and Enhancing the Efficiency of Large Language Model Based Search Agents","abstract":"Large Language Model (LLM)-based search agents have shown remarkable capabilities in solving complex tasks by dynamically decomposing problems and addressing them through interleaved reasoning and retrieval. However, this interleaved paradigm introduces substantial efficiency bottlenecks. First, we observe that both highly accurate and overly approximate retrieval methods degrade system efficiency: exact search incurs significant retrieval overhead, while coarse retrieval requires additional reasoning steps during generation. Second, we identify inefficiencies in system design, including improper scheduling and frequent retrieval stalls, which lead to cascading latency -- where even minor delays in retrieval amplify end-to-end inference time. To address these challenges, we introduce SearchAgent-X, a high-efficiency inference framework for LLM-based search agents. SearchAgent-X leverages high-recall approximate retrieval and incorporates two key techniques: priority-aware scheduling and non-stall retrieval. Extensive experiments demonstrate that SearchAgent-X consistently outperforms state-of-the-art systems such as vLLM and HNSW-based retrieval across diverse tasks, achieving up to 3.4$\\times$ higher throughput and 5$\\times$ lower latency, without compromising generation quality. SearchAgent-X is available at https://github.com/tiannuo-yang/SearchAgent-X.","authors":["Tiannuo Yang","Zebin Yao","Bowen Jin","Lixiao Cui","Yusen Li","Gang Wang","Xiaoguang Liu"],"url":"https://arxiv.org/abs/2505.12065"}
{"created":"2025-05-20","title":"Beluga Whale Detection from Satellite Imagery with Point Labels","abstract":"Very high-resolution (VHR) satellite imagery has emerged as a powerful tool for monitoring marine animals on a large scale. However, existing deep learning-based whale detection methods usually require manually created, high-quality bounding box annotations, which are labor-intensive to produce. Moreover, existing studies often exclude ``uncertain whales'', individuals that have ambiguous appearances in satellite imagery, limiting the applicability of these models in real-world scenarios. To address these limitations, this study introduces an automated pipeline for detecting beluga whales and harp seals in VHR satellite imagery. The pipeline leverages point annotations and the Segment Anything Model (SAM) to generate precise bounding box annotations, which are used to train YOLOv8 for multiclass detection of certain whales, uncertain whales, and harp seals. Experimental results demonstrated that SAM-generated annotations significantly improved detection performance, achieving higher $\\text{F}_\\text{1}$-scores compared to traditional buffer-based annotations. YOLOv8 trained on SAM-labeled boxes achieved an overall $\\text{F}_\\text{1}$-score of 72.2% for whales overall and 70.3% for harp seals, with superior performance in dense scenes. The proposed approach not only reduces the manual effort required for annotation but also enhances the detection of uncertain whales, offering a more comprehensive solution for marine animal monitoring. This method holds great potential for extending to other species, habitats, and remote sensing platforms, as well as for estimating whale biometrics, thereby advancing ecological monitoring and conservation efforts. The codes for our label and detection pipeline are publicly available at http://github.com/voyagerxvoyagerx/beluga-seeker .","authors":["Yijie Zheng","Jinxuan Yang","Yu Chen","Yaxuan Wang","Yihang Lu","Guoqing Li"],"url":"https://arxiv.org/abs/2505.12066"}
{"created":"2025-05-20","title":"MT-CYP-Net: Multi-Task Network for Pixel-Level Crop Yield Prediction Under Very Few Samples","abstract":"Accurate and fine-grained crop yield prediction plays a crucial role in advancing global agriculture. However, the accuracy of pixel-level yield estimation based on satellite remote sensing data has been constrained by the scarcity of ground truth data. To address this challenge, we propose a novel approach called the Multi-Task Crop Yield Prediction Network (MT-CYP-Net). This framework introduces an effective multi-task feature-sharing strategy, where features extracted from a shared backbone network are simultaneously utilized by both crop yield prediction decoders and crop classification decoders with the ability to fuse information between them. This design allows MT-CYP-Net to be trained with extremely sparse crop yield point labels and crop type labels, while still generating detailed pixel-level crop yield maps. Concretely, we collected 1,859 yield point labels along with corresponding crop type labels and satellite images from eight farms in Heilongjiang Province, China, in 2023, covering soybean, maize, and rice crops, and constructed a sparse crop yield label dataset. MT-CYP-Net is compared with three classical machine learning and deep learning benchmark methods in this dataset. Experimental results not only indicate the superiority of MT-CYP-Net compared to previous methods on multiple types of crops but also demonstrate the potential of deep networks on precise pixel-level crop yield prediction, especially with limited data labels.","authors":["Shenzhou Liu","Di Wang","Haonan Guo","Chengxi Han","Wenzhi Zeng"],"url":"https://arxiv.org/abs/2505.12069"}
{"created":"2025-05-20","title":"Historical and psycholinguistic perspectives on morphological productivity: A sketch of an integrative approach","abstract":"In this study, we approach morphological productivity from two perspectives: a cognitive-computational perspective, and a diachronic perspective zooming in on an actual speaker, Thomas Mann. For developing the first perspective, we make use of a cognitive computational model of the mental lexicon, the discriminative lexicon model. For computational mappings between form and meaning to be productive, in the sense that novel, previously unencountered words, can be understood and produced, there must be systematicities between the form space and the semantic space. If the relation between form and meaning would be truly arbitrary, a model could memorize form and meaning pairings, but there is no way in which the model would be able to generalize to novel test data. For Finnish nominal inflection, Malay derivation, and English compounding, we explore, using the Discriminative Lexicon Model as a computational tool, to trace differences in the degree to which inflectional and word formation patterns are productive. We show that the DLM tends to associate affix-like sublexical units with the centroids of the embeddings of the words with a given affix. For developing the second perspective, we study how the intake and output of one prolific writer, Thomas Mann, changes over time. We show by means of an examination of what Thomas Mann is likely to have read, and what he wrote, that the rate at which Mann produces novel derived words is extremely low. There are far more novel words in his input than in his output. We show that Thomas Mann is less likely to produce a novel derived word with a given suffix the greater the average distance is of the embeddings of all derived words to the corresponding centroid, and discuss the challenges of using speaker-specific embeddings for low-frequency and novel words.","authors":["Harald Baayen","Kristian Berg","Maziyah Mohamed"],"url":"https://arxiv.org/abs/2505.12071"}
{"created":"2025-05-20","title":"L2D2: Robot Learning from 2D Drawings","abstract":"Robots should learn new tasks from humans. But how do humans convey what they want the robot to do? Existing methods largely rely on humans physically guiding the robot arm throughout their intended task. Unfortunately -- as we scale up the amount of data -- physical guidance becomes prohibitively burdensome. Not only do humans need to operate robot hardware but also modify the environment (e.g., moving and resetting objects) to provide multiple task examples. In this work we propose L2D2, a sketching interface and imitation learning algorithm where humans can provide demonstrations by drawing the task. L2D2 starts with a single image of the robot arm and its workspace. Using a tablet, users draw and label trajectories on this image to illustrate how the robot should act. To collect new and diverse demonstrations, we no longer need the human to physically reset the workspace; instead, L2D2 leverages vision-language segmentation to autonomously vary object locations and generate synthetic images for the human to draw upon. We recognize that drawing trajectories is not as information-rich as physically demonstrating the task. Drawings are 2-dimensional and do not capture how the robot's actions affect its environment. To address these fundamental challenges the next stage of L2D2 grounds the human's static, 2D drawings in our dynamic, 3D world by leveraging a small set of physical demonstrations. Our experiments and user study suggest that L2D2 enables humans to provide more demonstrations with less time and effort than traditional approaches, and users prefer drawings over physical manipulation. When compared to other drawing-based approaches, we find that L2D2 learns more performant robot policies, requires a smaller dataset, and can generalize to longer-horizon tasks. See our project website: https://collab.me.vt.edu/L2D2/","authors":["Shaunak A. Mehta","Heramb Nemlekar","Hari Sumant","Dylan P. Losey"],"url":"https://arxiv.org/abs/2505.12072"}
{"created":"2025-05-20","title":"Denoising Mutual Knowledge Distillation in Bi-Directional Multiple Instance Learning","abstract":"Multiple Instance Learning is the predominant method for Whole Slide Image classification in digital pathology, enabling the use of slide-level labels to supervise model training. Although MIL eliminates the tedious fine-grained annotation process for supervised learning, whether it can learn accurate bag- and instance-level classifiers remains a question. To address the issue, instance-level classifiers and instance masks were incorporated to ground the prediction on supporting patches. These methods, while practically improving the performance of MIL methods, may potentially introduce noisy labels. We propose to bridge the gap between commonly used MIL and fully supervised learning by augmenting both the bag- and instance-level learning processes with pseudo-label correction capabilities elicited from weak to strong generalization techniques. The proposed algorithm improves the performance of dual-level MIL algorithms on both bag- and instance-level predictions. Experiments on public pathology datasets showcase the advantage of the proposed methods.","authors":["Chen Shu","Boyu Fu","Yiman Li","Ting Yin","Wenchuan Zhang","Jie Chen","Yuhao Yi","Hong Bu"],"url":"https://arxiv.org/abs/2505.12074"}
{"created":"2025-05-20","title":"Do different prompting methods yield a common task representation in language models?","abstract":"Demonstrations and instructions are two primary approaches for prompting language models to perform in-context learning (ICL) tasks. Do identical tasks elicited in different ways result in similar representations of the task? An improved understanding of task representation mechanisms would offer interpretability insights and may aid in steering models. We study this through function vectors, recently proposed as a mechanism to extract few-shot ICL task representations. We generalize function vectors to alternative task presentations, focusing on short textual instruction prompts, and successfully extract instruction function vectors that promote zero-shot task accuracy. We find evidence that demonstration- and instruction-based function vectors leverage different model components, and offer several controls to dissociate their contributions to task performance. Our results suggest that different task presentations do not induce a common task representation but elicit different, partly overlapping mechanisms. Our findings offer principled support to the practice of combining textual instructions and task demonstrations, imply challenges in universally monitoring task inference across presentation forms, and encourage further examinations of LLM task inference mechanisms.","authors":["Guy Davidson","Todd M. Gureckis","Brenden M. Lake","Adina Williams"],"url":"https://arxiv.org/abs/2505.12075"}
{"created":"2025-05-20","title":"SepPrune: Structured Pruning for Efficient Deep Speech Separation","abstract":"Although deep learning has substantially advanced speech separation in recent years, most existing studies continue to prioritize separation quality while overlooking computational efficiency, an essential factor for low-latency speech processing in real-time applications. In this paper, we propose SepPrune, the first structured pruning framework specifically designed to compress deep speech separation models and reduce their computational cost. SepPrune begins by analyzing the computational structure of a given model to identify layers with the highest computational burden. It then introduces a differentiable masking strategy to enable gradient-driven channel selection. Based on the learned masks, SepPrune prunes redundant channels and fine-tunes the remaining parameters to recover performance. Extensive experiments demonstrate that this learnable pruning paradigm yields substantial advantages for channel pruning in speech separation models, outperforming existing methods. Notably, a model pruned with SepPrune can recover 85% of the performance of a pre-trained model (trained over hundreds of epochs) with only one epoch of fine-tuning, and achieves convergence 36$\\times$ faster than training from scratch. Code is available at https://github.com/itsnotacie/SepPrune.","authors":["Yuqi Li","Kai Li","Xin Yin","Zhifei Yang","Junhao Dong","Zeyu Dong","Chuanguang Yang","Yingli Tian","Yao Lu"],"url":"https://arxiv.org/abs/2505.12079"}
{"created":"2025-05-20","title":"TrainBo: An Interactive Robot-assisted Scenario Training System for Older Adults with Dementia","abstract":"Dementia is an overall decline in memory and cognitive skills severe enough to reduce an elders ability to perform everyday activities. There is an increasing need for accessible technologies for cognitive training to slow down the cognitive decline. With the ability to provide instant feedback and assistance, social robotic systems have been proven effective in enhancing learning abilities across various age groups. This study focuses on the design of an interactive robot-assisted scenario training system TrainBo with self-determination theory, derives design requirements through formative and formal studies and the system usability is also be evaluated. A pilot test is conducted on seven older adults with dementia in an elderly care center in Hong Kong for four weeks. Our finding shows that older adults with dementia have an improvement in behavioural engagement, emotional engagement, and intrinsic motivation after using Trainbo. These findings can provide valuable insights into the development of more captivating interactive robots for extensive training purposes.","authors":["Kwong Chiu Fung (Hong Kong University of Science","Technology","China)","Wai Ho Mow (Hong Kong University of Science","Technology","China)"],"url":"https://arxiv.org/abs/2505.12080"}
{"created":"2025-05-20","title":"VisionReasoner: Unified Visual Perception and Reasoning via Reinforcement Learning","abstract":"Large vision-language models exhibit inherent capabilities to handle diverse visual perception tasks. In this paper, we introduce VisionReasoner, a unified framework capable of reasoning and solving multiple visual perception tasks within a shared model. Specifically, by designing novel multi-object cognitive learning strategies and systematic task reformulation, VisionReasoner enhances its reasoning capabilities to analyze visual inputs, and addresses diverse perception tasks in a unified framework. The model generates a structured reasoning process before delivering the desired outputs responding to user queries. To rigorously assess unified visual perception capabilities, we evaluate VisionReasoner on ten diverse tasks spanning three critical domains: detection, segmentation, and counting. Experimental results show that VisionReasoner achieves superior performance as a unified model, outperforming Qwen2.5VL by relative margins of 29.1% on COCO (detection), 22.1% on ReasonSeg (segmentation), and 15.3% on CountBench (counting).","authors":["Yuqi Liu","Tianyuan Qu","Zhisheng Zhong","Bohao Peng","Shu Liu","Bei Yu","Jiaya Jia"],"url":"https://arxiv.org/abs/2505.12081"}
{"created":"2025-05-20","title":"Model Merging in Pre-training of Large Language Models","abstract":"Model merging has emerged as a promising technique for enhancing large language models, though its application in large-scale pre-training remains relatively unexplored. In this paper, we present a comprehensive investigation of model merging techniques during the pre-training process. Through extensive experiments with both dense and Mixture-of-Experts (MoE) architectures ranging from millions to over 100 billion parameters, we demonstrate that merging checkpoints trained with constant learning rates not only achieves significant performance improvements but also enables accurate prediction of annealing behavior. These improvements lead to both more efficient model development and significantly lower training costs. Our detailed ablation studies on merging strategies and hyperparameters provide new insights into the underlying mechanisms while uncovering novel applications. Through comprehensive experimental analysis, we offer the open-source community practical pre-training guidelines for effective model merging.","authors":["Yunshui Li","Yiyuan Ma","Shen Yan","Chaoyi Zhang","Jing Liu","Jianqiao Lu","Ziwen Xu","Mengzhao Chen","Minrui Wang","Shiyi Zhan","Jin Ma","Xunhao Lai","Yao Luo","Xingyan Bin","Hongbin Ren","Mingji Han","Wenhao Hao","Bairen Yi","LingJun Liu","Bole Ma","Xiaoying Jia","Zhou Xun","Liang Xiang","Yonghui Wu"],"url":"https://arxiv.org/abs/2505.12082"}
{"created":"2025-05-20","title":"Discovering Symbolic Differential Equations with Symmetry Invariants","abstract":"Discovering symbolic differential equations from data uncovers fundamental dynamical laws underlying complex systems. However, existing methods often struggle with the vast search space of equations and may produce equations that violate known physical laws. In this work, we address these problems by introducing the concept of \\textit{symmetry invariants} in equation discovery. We leverage the fact that differential equations admitting a symmetry group can be expressed in terms of differential invariants of symmetry transformations. Thus, we propose to use these invariants as atomic entities in equation discovery, ensuring the discovered equations satisfy the specified symmetry. Our approach integrates seamlessly with existing equation discovery methods such as sparse regression and genetic programming, improving their accuracy and efficiency. We validate the proposed method through applications to various physical systems, such as fluid and reaction-diffusion, demonstrating its ability to recover parsimonious and interpretable equations that respect the laws of physics.","authors":["Jianke Yang","Manu Bhat","Bryan Hu","Yadi Cao","Nima Dehmamy","Robin Walters","Rose Yu"],"url":"https://arxiv.org/abs/2505.12083"}
{"created":"2025-05-20","title":"Bench-NPIN: Benchmarking Non-prehensile Interactive Navigation","abstract":"Mobile robots are increasingly deployed in unstructured environments where obstacles and objects are movable. Navigation in such environments is known as interactive navigation, where task completion requires not only avoiding obstacles but also strategic interactions with movable objects. Non-prehensile interactive navigation focuses on non-grasping interaction strategies, such as pushing, rather than relying on prehensile manipulation. Despite a growing body of research in this field, most solutions are evaluated using case-specific setups, limiting reproducibility and cross-comparison. In this paper, we present Bench-NPIN, the first comprehensive benchmark for non-prehensile interactive navigation. Bench-NPIN includes multiple components: 1) a comprehensive range of simulated environments for non-prehensile interactive navigation tasks, including navigating a maze with movable obstacles, autonomous ship navigation in icy waters, box delivery, and area clearing, each with varying levels of complexity; 2) a set of evaluation metrics that capture unique aspects of interactive navigation, such as efficiency, interaction effort, and partial task completion; and 3) demonstrations using Bench-NPIN to evaluate example implementations of established baselines across environments. Bench-NPIN is an open-source Python library with a modular design. The code, documentation, and trained models can be found at https://github.com/IvanIZ/BenchNPIN.","authors":["Ninghan Zhong","Steven Caro","Avraiem Iskandar","Megnath Ramesh","Stephen L. Smith"],"url":"https://arxiv.org/abs/2505.12084"}
{"created":"2025-05-20","title":"Personalized Author Obfuscation with Large Language Models","abstract":"In this paper, we investigate the efficacy of large language models (LLMs) in obfuscating authorship by paraphrasing and altering writing styles. Rather than adopting a holistic approach that evaluates performance across the entire dataset, we focus on user-wise performance to analyze how obfuscation effectiveness varies across individual authors. While LLMs are generally effective, we observe a bimodal distribution of efficacy, with performance varying significantly across users. To address this, we propose a personalized prompting method that outperforms standard prompting techniques and partially mitigates the bimodality issue.","authors":["Mohammad Shokri","Sarah Ita Levitan","Rivka Levitan"],"url":"https://arxiv.org/abs/2505.12090"}
{"created":"2025-05-20","title":"Discrete Time Credit-Based Shaping for Time-Sensitive Applications in 5G/6G Networks","abstract":"Future wireless networks must deliver deterministic end-to-end delays for workloads such as smart-factory control loops. On Ethernet these guarantees are delivered by the set of tools within IEEE 802.1 time sensitive networking~(TSN) standards. Credit-based shaper (CBS) is one such tool which enforces bounded latency. Directly porting CBS to 5G/6G New Radio (NR) is non-trivial because NR schedules traffic in discrete-time, modulation-dependent resource allocation, whereas CBS assumes a continuous, fixed-rate link. Existing TSN-over-5G translators map Ethernet priorities to 5G quality of service (QoS) identifiers but leave the radio scheduler unchanged, so deterministic delay is lost within the radio access network (RAN). To address this challenge, we propose a novel slot-native approach that adapts CBS to operate natively in discrete NR slots. We first propose a per-slot credit formulation for each user-equipment ({UE}) queue that debits credit by the granted transport block size~(TBS); we call this discrete-time CBS (CBS-DT). Recognizing that debiting the full {TBS} can unduly penalize transmissions that actually use only part of their grant, we then introduce and analyze {CBS} with Partial Usage ({CBS-PU}). {CBS-PU} scales the credit debit in proportion to the actual bytes dequeued from the downlink queue. The resulting CBS-PU algorithm is shown to maintain bounded credit, preserve long-term rate reservations, and guarantees worst-case delay performance no worse than {CBS-DT}. Simulation results show that slot-level credit gating--particularly CBS-PU--enables NR to export TSN class QoS while maximizing resource utilization.","authors":["Anudeep Karnam","Kishor C. Joshi","Jobish John","George Exarchakos","Sonia Heemstra de Groot","Ignas Niemegeers"],"url":"https://arxiv.org/abs/2505.12091"}
{"created":"2025-05-20","title":"Attribution Projection Calculus: A Novel Framework for Causal Inference in Bayesian Networks","abstract":"This paper introduces Attribution Projection Calculus (AP-Calculus), a novel mathematical framework for determining causal relationships in structured Bayesian networks. We investigate a specific network architecture with source nodes connected to destination nodes through intermediate nodes, where each input maps to a single label with maximum marginal probability. We prove that for each label, exactly one intermediate node acts as a deconfounder while others serve as confounders, enabling optimal attribution of features to their corresponding labels. The framework formalizes the dual nature of intermediate nodes as both confounders and deconfounders depending on the context, and establishes separation functions that maximize distinctions between intermediate representations. We demonstrate that the proposed network architecture is optimal for causal inference compared to alternative structures, including those based on Pearl's causal framework. AP-Calculus provides a comprehensive mathematical foundation for analyzing feature-label attributions, managing spurious correlations, quantifying information gain, ensuring fairness, and evaluating uncertainty in prediction models, including large language models. Theoretical verification shows that AP-Calculus not only extends but can also subsume traditional do-calculus for many practical applications, offering a more direct approach to causal inference in supervised learning contexts.","authors":["M Ruhul Amin"],"url":"https://arxiv.org/abs/2505.12094"}
{"created":"2025-05-20","title":"When the Left Foot Leads to the Right Path: Bridging Initial Prejudice and Trainability","abstract":"Understanding the statistical properties of deep neural networks (DNNs) at initialization is crucial for elucidating both their trainability and the intrinsic architectural biases they encode prior to data exposure. Mean-field (MF) analyses have demonstrated that the parameter distribution in randomly initialized networks dictates whether gradients vanish or explode. Concurrently, untrained DNNs were found to exhibit an initial-guessing bias (IGB), in which large regions of the input space are assigned to a single class. In this work, we derive a theoretical proof establishing the correspondence between IGB and previous MF theories, thereby connecting a network prejudice toward specific classes with the conditions for fast and accurate learning. This connection yields the counter-intuitive conclusion: the initialization that optimizes trainability is necessarily biased, rather than neutral. Furthermore, we extend the MF/IGB framework to multi-node activation functions, offering practical guidelines for designing initialization schemes that ensure stable optimization in architectures employing max- and average-pooling layers.","authors":["Alberto Bassi","Carlo Albert","Aurelien Lucchi","Marco Baity-Jesi","Emanuele Francazi"],"url":"https://arxiv.org/abs/2505.12096"}
{"created":"2025-05-20","title":"LOVE: Benchmarking and Evaluating Text-to-Video Generation and Video-to-Text Interpretation","abstract":"Recent advancements in large multimodal models (LMMs) have driven substantial progress in both text-to-video (T2V) generation and video-to-text (V2T) interpretation tasks. However, current AI-generated videos (AIGVs) still exhibit limitations in terms of perceptual quality and text-video alignment. Therefore, a reliable and scalable automatic model for AIGV evaluation is desirable, which heavily relies on the scale and quality of human annotations. To this end, we present AIGVE-60K, a comprehensive dataset and benchmark for AI-Generated Video Evaluation, which features (i) comprehensive tasks, encompassing 3,050 extensive prompts across 20 fine-grained task dimensions, (ii) the largest human annotations, including 120K mean-opinion scores (MOSs) and 60K question-answering (QA) pairs annotated on 58,500 videos generated from 30 T2V models, and (iii) bidirectional benchmarking and evaluating for both T2V generation and V2T interpretation capabilities. Based on AIGVE-60K, we propose LOVE, a LMM-based metric for AIGV Evaluation from multiple dimensions including perceptual preference, text-video correspondence, and task-specific accuracy in terms of both instance level and model level. Comprehensive experiments demonstrate that LOVE not only achieves state-of-the-art performance on the AIGVE-60K dataset, but also generalizes effectively to a wide range of other AIGV evaluation benchmarks. These findings highlight the significance of the AIGVE-60K dataset. Database and codes are anonymously available at https://github.com/IntMeGroup/LOVE.","authors":["Jiarui Wang","Huiyu Duan","Ziheng Jia","Yu Zhao","Woo Yi Yang","Zicheng Zhang","Zijian Chen","Juntong Wang","Yuke Xing","Guangtao Zhai","Xiongkuo Min"],"url":"https://arxiv.org/abs/2505.12098"}
{"created":"2025-05-20","title":"TinyRS-R1: Compact Multimodal Language Model for Remote Sensing","abstract":"Remote-sensing applications often run on edge hardware that cannot host today's 7B-parameter multimodal language models. This paper introduces TinyRS, the first 2B-parameter multimodal small language model (MSLM) optimized for remote sensing tasks, and TinyRS-R1, its reasoning-augmented variant. Built upon Qwen2-VL-2B, TinyRS is trained through a four-stage pipeline: pre-training on million satellite images, instruction tuning on visual instruction examples, fine-tuning with Chain-of-Thought (CoT) annotations from the proposed reasoning dataset, and alignment via Group Relative Policy Optimization (GRPO). TinyRS-R1 achieves or surpasses the performance of recent 7B-parameter remote sensing models across classification, VQA, visual grounding, and open-ended question answering-while requiring just one-third of the memory and latency. Our analysis shows that CoT reasoning substantially benefits spatial grounding and scene understanding, while the non-reasoning TinyRS excels in concise, latency-sensitive VQA tasks. TinyRS-R1 represents the first domain-specialized MSLM with GRPO-aligned CoT reasoning for general-purpose remote sensing.","authors":["Aybora Koksal","A. Aydin Alatan"],"url":"https://arxiv.org/abs/2505.12099"}
{"created":"2025-05-20","title":"Improving Fairness in LLMs Through Testing-Time Adversaries","abstract":"Large Language Models (LLMs) push the bound-aries in natural language processing and generative AI, driving progress across various aspects of modern society. Unfortunately, the pervasive issue of bias in LLMs responses (i.e., predictions) poses a significant and open challenge, hindering their application in tasks involving ethical sensitivity and responsible decision-making. In this work, we propose a straightforward, user-friendly and practical method to mitigate such biases, enhancing the reliability and trustworthiness of LLMs. Our method creates multiple variations of a given sentence by modifying specific attributes and evaluates the corresponding prediction behavior compared to the original, unaltered, prediction/sentence. The idea behind this process is that critical ethical predictions often exhibit notable inconsistencies, indicating the presence of bias. Unlike previous approaches, our method relies solely on forward passes (i.e., testing-time adversaries), eliminating the need for training, fine-tuning, or prior knowledge of the training data distribution. Through extensive experiments on the popular Llama family, we demonstrate the effectiveness of our method in improving various fairness metrics, focusing on the reduction of disparities in how the model treats individuals from different racial groups. Specifically, using standard metrics, we improve the fairness in Llama3 in up to 27 percentage points. Overall, our approach significantly enhances fairness, equity, and reliability in LLM-generated results without parameter tuning or training data modifications, confirming its effectiveness in practical scenarios. We believe our work establishes an important step toward enabling the use of LLMs in tasks that require ethical considerations and responsible decision-making.","authors":["Isabela Pereira Gregio","Ian Pons","Anna Helena Reali Costa","Artur Jord\\~ao"],"url":"https://arxiv.org/abs/2505.12100"}
{"created":"2025-05-20","title":"Designing Scaffolded Interfaces for Enhanced Learning and Performance in Professional Software","abstract":"Professional software offers immense power but also presents significant learning challenges. Its complex interfaces, as well as insufficient built-in structured guidance and unfamiliar terminology, often make newcomers struggle with task completion. To address these challenges, we introduce ScaffoldUI, a method for scaffolded interface design to reduce interface complexity, provide structured guidance, and enhance software learnability. The scaffolded interface presents task-relevant tools, progressively discloses tool complexity, and organizes tools based on domain concepts, aiming to assist task performance and software learning. To evaluate the feasibility of our interface design method, we present a technical pipeline for scaffolded interface implementation in professional 3D software, i.e., Blender, and conduct user studies with beginners (N=32) and experts (N=8). Study results demonstrate that our scaffolded interfaces significantly reduce perceived task load caused by interface complexity, support task performance through structured guidance, and augment learning by clearly connecting concepts and tools within the taskflow context. Based on a discussion of the user study findings, we offer insights for future research on designing scaffolded interfaces to support instruction, productivity, creativity, and cross-software workflows.","authors":["Yimeng Liu","Misha Sra"],"url":"https://arxiv.org/abs/2505.12101"}
{"created":"2025-05-20","title":"Scalable Time-Tagged Data Acquisition for Entanglement Distribution in Quantum Networks","abstract":"In distributed quantum applications such as entanglement distribution, precise time synchronization and efficient time-tagged data handling are essential. Traditional systems often suffer from overflow, synchronization drift, and storage inefficiencies. We propose a modular Time Tagging (TT) agent that uses a 1 pulse per second (PPS) signal from White Rabbit (WR) devices to achieve network-wide synchronization, while applying real-time calibration, overflow mitigation, and compression. A live two-lab entanglement distribution experiment validated the system's performance, achieving synchronized coincidence detection at 25,000 counts/sec.","authors":["Abderrahim Amlou","Thomas Gerrits","Anouar Rahmouni","Amar Abane","Mheni Merzouki","Ya-Shian Li-Baboud","Ahmed Lbath","Abdella Battou","Oliver Slattery"],"url":"https://arxiv.org/abs/2505.12102"}
{"created":"2025-05-20","title":"Numerical Integrators for Mechanical Systems on Lie Groups","abstract":"Retraction maps are known to be the seed for all numerical integrators. These retraction maps-based integrators can be further lifted to tangent and cotangent bundles, giving rise to structure-preserving integrators for mechanical systems. We explore the particular case where the configuration space of our mechanical system is a Lie group with certain symmetries. Here, the integrator simplifies based on the property that the tangent and cotangent bundles of Lie groups are trivializable. Finally, we present a framework for designing numerical integrators for Euler- Poincare and Lie-Poisson type equations.","authors":["Viyom Vivek","David Martin de Diego","Ravi N Banavar"],"url":"https://arxiv.org/abs/2505.12103"}
{"created":"2025-05-20","title":"The Impact of Emerging Phishing Threats: Assessing Quishing and LLM-generated Phishing Emails against Organizations","abstract":"Modern organizations are persistently targeted by phishing emails. Despite advances in detection systems and widespread employee training, attackers continue to innovate, posing ongoing threats. Two emerging vectors stand out in the current landscape: QR-code baits and LLM-enabled pretexting. Yet, little is known about the effectiveness of current defenses against these attacks, particularly when it comes to real-world impact on employees. This gap leaves uncertainty around to what extent related countermeasures are justified or needed. Our work addresses this issue.","authors":["Marie Weinz","Nicola Zannone","Luca Allodi","Giovanni Apruzzese"],"url":"https://arxiv.org/abs/2505.12104"}
{"created":"2025-05-20","title":"MalVis: A Large-Scale Image-Based Framework and Dataset for Advancing Android Malware Classification","abstract":"As technology advances, Android malware continues to pose significant threats to devices and sensitive data. The open-source nature of the Android OS and the availability of its SDK contribute to this rapid growth. Traditional malware detection techniques, such as signature-based, static, and dynamic analysis, struggle to detect obfuscated threats that use encryption, packing, or compression. While deep learning (DL)-based visualization methods have been proposed, they often fail to highlight the critical malicious features effectively. This research introduces MalVis, a unified visualization framework that integrates entropy and N-gram analysis to emphasize structural and anomalous patterns in malware bytecode. MalVis addresses key limitations of prior methods, including insufficient feature representation, poor interpretability, and limited data accessibility. The framework leverages a newly introduced large-scale dataset, the MalVis dataset, containing over 1.3 million visual samples across nine malware classes and one benign class. We evaluate MalVis against state-of-the-art visualization techniques using leading CNN models: MobileNet-V2, DenseNet201, ResNet50, and Inception-V3. To enhance performance and reduce overfitting, we implement eight ensemble learning strategies. Additionally, an undersampling technique mitigates class imbalance in the multiclass setting. MalVis achieves strong results: 95.19% accuracy, 90.81% F1-score, 92.58% precision, 89.10% recall, 87.58% MCC, and 98.06% ROC-AUC. These findings demonstrate the effectiveness of MalVis in enabling accurate, interpretable malware detection and providing a valuable resource for security research and applications.","authors":["Saleh J. Makkawy","Michael J. De Lucia","Kenneth E. Barner"],"url":"https://arxiv.org/abs/2505.12106"}
{"created":"2025-05-20","title":"Learning Probabilistic Temporal Logic Specifications for Stochastic Systems","abstract":"There has been substantial progress in the inference of formal behavioural specifications from sample trajectories, for example, using Linear Temporal Logic (LTL). However, these techniques cannot handle specifications that correctly characterise systems with stochastic behaviour, which occur commonly in reinforcement learning and formal verification. We consider the passive learning problem of inferring a Boolean combination of probabilistic LTL (PLTL) formulas from a set of Markov chains, classified as either positive or negative. We propose a novel learning algorithm that infers concise PLTL specifications, leveraging grammar-based enumeration, search heuristics, probabilistic model checking and Boolean set-cover procedures. We demonstrate the effectiveness of our algorithm in two use cases: learning from policies induced by RL algorithms and learning from variants of a probabilistic model. In both cases, our method automatically and efficiently extracts PLTL specifications that succinctly characterise the temporal differences between the policies or model variants.","authors":["Rajarshi Roy","Yash Pote","David Parker","Marta Kwiatkowska"],"url":"https://arxiv.org/abs/2505.12107"}
{"created":"2025-05-20","title":"EarthSynth: Generating Informative Earth Observation with Diffusion Models","abstract":"Remote sensing image (RSI) interpretation typically faces challenges due to the scarcity of labeled data, which limits the performance of RSI interpretation tasks. To tackle this challenge, we propose EarthSynth, a diffusion-based generative foundation model that enables synthesizing multi-category, cross-satellite labeled Earth observation for downstream RSI interpretation tasks. To the best of our knowledge, EarthSynth is the first to explore multi-task generation for remote sensing. EarthSynth, trained on the EarthSynth-180K dataset, employs the Counterfactual Composition training strategy to improve training data diversity and enhance category control. Furthermore, a rule-based method of R-Filter is proposed to filter more informative synthetic data for downstream tasks. We evaluate our EarthSynth on scene classification, object detection, and semantic segmentation in open-world scenarios, offering a practical solution for advancing RSI interpretation.","authors":["Jiancheng Pan","Shiye Lei","Yuqian Fu","Jiahao Li","Yanxing Liu","Yuze Sun","Xiao He","Long Peng","Xiaomeng Huang","Bo Zhao"],"url":"https://arxiv.org/abs/2505.12108"}
{"created":"2025-05-20","title":"SAINT: Attention-Based Modeling of Sub-Action Dependencies in Multi-Action Policies","abstract":"The combinatorial structure of many real-world action spaces leads to exponential growth in the number of possible actions, limiting the effectiveness of conventional reinforcement learning algorithms. Recent approaches for combinatorial action spaces impose factorized or sequential structures over sub-actions, failing to capture complex joint behavior. We introduce the Sub-Action Interaction Network using Transformers (SAINT), a novel policy architecture that represents multi-component actions as unordered sets and models their dependencies via self-attention conditioned on the global state. SAINT is permutation-invariant, sample-efficient, and compatible with standard policy optimization algorithms. In 15 distinct combinatorial environments across three task domains, including environments with nearly 17 million joint actions, SAINT consistently outperforms strong baselines.","authors":["Matthew Landers","Taylor W. Killian","Thomas Hartvigsen","Afsaneh Doryab"],"url":"https://arxiv.org/abs/2505.12109"}
{"created":"2025-05-20","title":"Ripple: Scalable Incremental GNN Inferencing on Large Streaming Graphs","abstract":"Most real-world graphs are dynamic in nature, with continuous and rapid updates to the graph topology, and vertex and edge properties. Such frequent updates pose significant challenges for inferencing over Graph Neural Networks (GNNs). Current approaches that perform vertex-wise and layer-wise inferencing are impractical for dynamic graphs as they cause redundant computations, expand to large neighborhoods, and incur high communication costs for distributed setups, resulting in slow update propagation that often exceeds real-time latency requirements. This motivates the need for streaming GNN inference frameworks that are efficient and accurate over large, dynamic graphs. We propose Ripple, a framework that performs fast incremental updates of embeddings arising due to updates to the graph topology or vertex features. Ripple provides a generalized incremental programming model, leveraging the properties of the underlying aggregation functions employed by GNNs to efficiently propagate updates to the affected neighborhood and compute the exact new embeddings. Besides a single-machine design, we also extend this execution model to distributed inferencing, to support large graphs that do not fit in a single machine's memory. Ripple on a single machine achieves up to $\\approx28000$ updates/sec for sparse graphs like Arxiv and $\\approx1200$ updates/sec for larger and denser graphs like Products, with latencies of $0.1$ms--$1$s that are required for near-realtime applications. The distributed version of Ripple offers up to $\\approx30\\times$ better throughput over the baselines, due to $70\\times$ lower communication costs during updates.","authors":["Pranjal Naman","Yogesh Simmhan"],"url":"https://arxiv.org/abs/2505.12112"}
{"created":"2025-05-20","title":"Behind the Screens: Uncovering Bias in AI-Driven Video Interview Assessments Using Counterfactuals","abstract":"AI-enhanced personality assessments are increasingly shaping hiring decisions, using affective computing to predict traits from the Big Five (OCEAN) model. However, integrating AI into these assessments raises ethical concerns, especially around bias amplification rooted in training data. These biases can lead to discriminatory outcomes based on protected attributes like gender, ethnicity, and age. To address this, we introduce a counterfactual-based framework to systematically evaluate and quantify bias in AI-driven personality assessments. Our approach employs generative adversarial networks (GANs) to generate counterfactual representations of job applicants by altering protected attributes, enabling fairness analysis without access to the underlying model. Unlike traditional bias assessments that focus on unimodal or static data, our method supports multimodal evaluation-spanning visual, audio, and textual features. This comprehensive approach is particularly important in high-stakes applications like hiring, where third-party vendors often provide AI systems as black boxes. Applied to a state-of-the-art personality prediction model, our method reveals significant disparities across demographic groups. We also validate our framework using a protected attribute classifier to confirm the effectiveness of our counterfactual generation. This work provides a scalable tool for fairness auditing of commercial AI hiring platforms, especially in black-box settings where training data and model internals are inaccessible. Our results highlight the importance of counterfactual approaches in improving ethical transparency in affective computing.","authors":["Dena F. Mujtaba","Nihar R. Mahapatra"],"url":"https://arxiv.org/abs/2505.12114"}
{"created":"2025-05-20","title":"A Multi-Task Benchmark for Abusive Language Detection in Low-Resource Settings","abstract":"Content moderation research has recently made significant advances, but still fails to serve the majority of the world's languages due to the lack of resources, leaving millions of vulnerable users to online hostility. This work presents a large-scale human-annotated multi-task benchmark dataset for abusive language detection in Tigrinya social media with joint annotations for three tasks: abusiveness, sentiment, and topic classification. The dataset comprises 13,717 YouTube comments annotated by nine native speakers, collected from 7,373 videos with a total of over 1.2 billion views across 51 channels. We developed an iterative term clustering approach for effective data selection. Recognizing that around 64% of Tigrinya social media content uses Romanized transliterations rather than native Ge'ez script, our dataset accommodates both writing systems to reflect actual language use. We establish strong baselines across the tasks in the benchmark, while leaving significant challenges for future contributions. Our experiments reveal that small, specialized multi-task models outperform the current frontier models in the low-resource setting, achieving up to 86% accuracy (+7 points) in abusiveness detection. We make the resources publicly available to promote research on online safety.","authors":["Fitsum Gaim","Hoyun Song","Huije Lee","Changgeon Ko","Eui Jun Hwang","Jong C. Park"],"url":"https://arxiv.org/abs/2505.12116"}
{"created":"2025-05-20","title":"Do Code LLMs Do Static Analysis?","abstract":"This paper investigates code LLMs' capability of static analysis during code intelligence tasks such as code summarization and generation. Code LLMs are now household names for their abilities to do some programming tasks that have heretofore required people. The process that people follow to do programming tasks has long been understood to require static analysis. For example, human programmers navigate the call graph of large programs to comprehend the different parts of those programs. Education in programming includes static analysis under the assumption that better static analysis skills beget better programming. Yet while popular culture is replete with anthropomorphic references such as LLM \"reasoning\", in fact code LLMs could exhibit a wholly alien thought process to humans. This paper studies the specific question of static analysis by code LLMs. We use three different static analysis tasks (callgraph generation, AST generation, and dataflow generation) and three different code intelligence tasks (code generation, summarization, and translation) with two different open-source models (Gemini and GPT-4o) and closed-source models (CodeLlaMA and Jam) as our experiments. We found that LLMs show poor performance on static analysis tasks and that pretraining on the static analysis tasks does not generalize to better performance on the code intelligence tasks.","authors":["Chia-Yi Su","Collin McMillan"],"url":"https://arxiv.org/abs/2505.12118"}
{"created":"2025-05-20","title":"Logarithmic Approximations for Fair k-Set Selection","abstract":"We study the fair k-set selection problem where we aim to select $k$ sets from a given set system such that the (weighted) occurrence times that each element appears in these $k$ selected sets are balanced, i.e., the maximum (weighted) occurrence times are minimized. By observing that a set system can be formulated into a bipartite graph $G:=(L\\cup R, E)$, our problem is equivalent to selecting $k$ vertices from $R$ such that the maximum total weight of selected neighbors of vertices in $L$ is minimized. The problem arises in a wide range of applications in various fields, such as machine learning, artificial intelligence, and operations research.","authors":["Shi Li","Chenyang Xu","Ruilong Zhang"],"url":"https://arxiv.org/abs/2505.12123"}
{"created":"2025-05-20","title":"Fair Submodular Maximization over a Knapsack Constraint","abstract":"We consider fairness in submodular maximization subject to a knapsack constraint, a fundamental problem with various applications in economics, machine learning, and data mining. In the model, we are given a set of ground elements, each associated with a weight and a color, and a monotone submodular function defined over them. The goal is to maximize the submodular function while guaranteeing that the total weight does not exceed a specified budget (the knapsack constraint) and that the number of elements selected for each color falls within a designated range (the fairness constraint).","authors":["Lijun Li","Chenyang Xu","Liuyi Yang","Ruilong Zhang"],"url":"https://arxiv.org/abs/2505.12126"}
{"created":"2025-05-20","title":"Back to Square Roots: An Optimal Bound on the Matrix Factorization Error for Multi-Epoch Differentially Private SGD","abstract":"Matrix factorization mechanisms for differentially private training have emerged as a promising approach to improve model utility under privacy constraints. In practical settings, models are typically trained over multiple epochs, requiring matrix factorizations that account for repeated participation. Existing theoretical upper and lower bounds on multi-epoch factorization error leave a significant gap. In this work, we introduce a new explicit factorization method, Banded Inverse Square Root (BISR), which imposes a banded structure on the inverse correlation matrix. This factorization enables us to derive an explicit and tight characterization of the multi-epoch error. We further prove that BISR achieves asymptotically optimal error by matching the upper and lower bounds. Empirically, BISR performs on par with state-of-the-art factorization methods, while being simpler to implement, computationally efficient, and easier to analyze.","authors":["Nikita P. Kalinin","Ryan McKenna","Jalaj Upadhyay","Christoph H. Lampert"],"url":"https://arxiv.org/abs/2505.12128"}
{"created":"2025-05-20","title":"Metric Graph Kernels via the Tropical Torelli Map","abstract":"We propose new graph kernels grounded in the study of metric graphs via tropical algebraic geometry. In contrast to conventional graph kernels that are based on graph combinatorics such as nodes, edges, and subgraphs, our graph kernels are purely based on the geometry and topology of the underlying metric space. A key characterizing property of our construction is its invariance under edge subdivision, making the kernels intrinsically well-suited for comparing graphs that represent different underlying spaces. We develop efficient algorithms for computing these kernels and analyze their complexity, showing that it depends primarily on the genus of the input graphs. Empirically, our kernels outperform existing methods in label-free settings, as demonstrated on both synthetic and real-world benchmark datasets. We further highlight their practical utility through an urban road network classification task.","authors":["Yueqi Cao","Anthea Monod"],"url":"https://arxiv.org/abs/2505.12129"}
{"created":"2025-05-20","title":"Keypoints as Dynamic Centroids for Unified Human Pose and Segmentation","abstract":"The dynamic movement of the human body presents a fundamental challenge for human pose estimation and body segmentation. State-of-the-art approaches primarily rely on combining keypoint heatmaps with segmentation masks but often struggle in scenarios involving overlapping joints or rapidly changing poses during instance-level segmentation. To address these limitations, we propose Keypoints as Dynamic Centroid (KDC), a new centroid-based representation for unified human pose estimation and instance-level segmentation. KDC adopts a bottom-up paradigm to generate keypoint heatmaps for both easily distinguishable and complex keypoints and improves keypoint detection and confidence scores by introducing KeyCentroids using a keypoint disk. It leverages high-confidence keypoints as dynamic centroids in the embedding space to generate MaskCentroids, allowing for swift clustering of pixels to specific human instances during rapid body movements in live environments. Our experimental evaluations on the CrowdPose, OCHuman, and COCO benchmarks demonstrate KDC's effectiveness and generalizability in challenging scenarios in terms of both accuracy and runtime performance. The implementation is available at: https://sites.google.com/view/niazahmad/projects/kdc.","authors":["Niaz Ahmad","Jawad Khan","Kang G. Shin","Youngmoon Lee","Guanghui Wang"],"url":"https://arxiv.org/abs/2505.12130"}
{"created":"2025-05-20","title":"Towards Sustainability in 6G Network Slicing with Energy-Saving and Optimization Methods","abstract":"The 6G mobile network is the next evolutionary step after 5G, with a prediction of an explosive surge in mobile traffic. It provides ultra-low latency, higher data rates, high device density, and ubiquitous coverage, positively impacting services in various areas. Energy saving is a major concern for new systems in the telecommunications sector because all players are expected to reduce their carbon footprints to contribute to mitigating climate change. Network slicing is a fundamental enabler for 6G/5G mobile networks and various other new systems, such as the Internet of Things (IoT), Internet of Vehicles (IoV), and Industrial IoT (IIoT). However, energy-saving methods embedded in network slicing architectures are still a research gap. This paper discusses how to embed energy-saving methods in network-slicing architectures that are a fundamental enabler for nearly all new innovative systems being deployed worldwide. This paper's main contribution is a proposal to save energy in network slicing. That is achieved by deploying ML-native agents in NS architectures to dynamically orchestrate and optimize resources based on user demands. The SFI2 network slicing reference architecture is the concrete use case scenario in which contrastive learning improves energy saving for resource allocation.","authors":["Rodrigo Moreira","Tereza C. M. Carvalho","Fl\\'avio de Oliveira Silva","Nazim Agoulmine","Joberto S. B. Martins"],"url":"https://arxiv.org/abs/2505.12132"}
{"created":"2025-05-20","title":"The effect of APC discounts on Ukraine's participation in gold open access journals","abstract":"This study investigates the effect of article processing charge (APC) waivers on the participation of Ukrainian researchers in fully Gold Open Access journals published by the five largest academic publishers during the period 2019-2024. In response to the full-scale war launched against Ukraine in 2022, many publishers implemented extraordinary APC waiver policies to support affected authors. Using bibliometric data from the Web of Science Core Collection, this study examines trends in Ukrainian-authored publications in fully Gold OA journals before and after 2022, comparing them with those in neighbouring countries (Poland, Czech Republic, Hungary, and Romania). The results reveal a substantial post-2022 increase in Ukraine's Gold OA output, particularly in journals by Springer Nature and Elsevier. While this growth appears to correlate with the introduction of APC-waivers, additional factors, such as international collaborations, emergency grant support, and individual publishing strategies, also contributed. Disciplinary differences and publisher-specific patterns are observed, with notable increases in medical and applied sciences. The study highlights the potential of targeted support initiatives during crises but also points to the limitations of APC-based models in achieving equitable scholarly communication.","authors":["Serhii Nazarovets"],"url":"https://arxiv.org/abs/2505.12134"}
{"created":"2025-05-20","title":"LLM-BABYBENCH: Understanding and Evaluating Grounded Planning and Reasoning in LLMs","abstract":"Assessing the capacity of Large Language Models (LLMs) to plan and reason within the constraints of interactive environments is crucial for developing capable AI agents. We introduce $\\textbf{LLM-BabyBench}$, a new benchmark suite designed specifically for this purpose. Built upon a textual adaptation of the procedurally generated BabyAI grid world, this suite evaluates LLMs on three fundamental aspects of grounded intelligence: (1) predicting the consequences of actions on the environment state ($\\textbf{Predict}$ task), (2) generating sequences of low-level actions to achieve specified objectives ($\\textbf{Plan}$ task), and (3) decomposing high-level instructions into coherent subgoal sequences ($\\textbf{Decompose}$ task). We detail the methodology for generating the three corresponding datasets ($\\texttt{LLM-BabyBench-Predict}$, $\\texttt{-Plan}$, $\\texttt{-Decompose}$) by extracting structured information from an expert agent operating within the text-based environment. Furthermore, we provide a standardized evaluation harness and metrics, including environment interaction for validating generated plans, to facilitate reproducible assessment of diverse LLMs. Initial baseline results highlight the challenges posed by these grounded reasoning tasks. The benchmark suite, datasets, data generation code, and evaluation code are made publicly available ($\\href{https://github.com/choukrani/llm-babybench}{\\text{GitHub}}$, $\\href{https://huggingface.co/datasets/salem-mbzuai/LLM-BabyBench}{\\text{HuggingFace}}$).","authors":["Omar Choukrani","Idriss Malek","Daniil Orel","Zhuohan Xie","Zangir Iklassov","Martin Tak\\'a\\v{c}","Salem Lahlou"],"url":"https://arxiv.org/abs/2505.12135"}
{"created":"2025-05-20","title":"Lightweight Spatio-Temporal Attention Network with Graph Embedding and Rotational Position Encoding for Traffic Forecasting","abstract":"Traffic forecasting is a key task in the field of Intelligent Transportation Systems. Recent research on traffic forecasting has mainly focused on combining graph neural networks (GNNs) with other models. However, GNNs only consider short-range spatial information. In this study, we present a novel model termed LSTAN-GERPE (Lightweight Spatio-Temporal Attention Network with Graph Embedding and Rotational Position Encoding). This model leverages both Temporal and Spatial Attention mechanisms to effectively capture long-range traffic dynamics. Additionally, the optimal frequency for rotational position encoding is determined through a grid search approach in both the spatial and temporal attention mechanisms. This systematic optimization enables the model to effectively capture complex traffic patterns. The model also enhances feature representation by incorporating geographical location maps into the spatio-temporal embeddings. Without extensive feature engineering, the proposed method in this paper achieves advanced accuracy on the real-world traffic forecasting datasets PeMS04 and PeMS08.","authors":["Xiao Wang","Shun-Ren Yang"],"url":"https://arxiv.org/abs/2505.12136"}
{"created":"2025-05-20","title":"Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding","abstract":"Molecular graph neural networks (GNNs) often focus exclusively on XYZ-based geometric representations and thus overlook valuable chemical context available in public databases like PubChem. This work introduces a multimodal framework that integrates textual descriptors, such as IUPAC names, molecular formulas, physicochemical properties, and synonyms, alongside molecular graphs. A gated fusion mechanism balances geometric and textual features, allowing models to exploit complementary information. Experiments on benchmark datasets indicate that adding textual data yields notable improvements for certain electronic properties, while gains remain limited for others. Furthermore, the GNN architectures display similar performance patterns (improving and deteriorating on analogous targets), suggesting they learn comparable representations rather than distinctly different physical insights.","authors":["Can Polat","Hasan Kurban","Erchin Serpedin","Mustafa Kurban"],"url":"https://arxiv.org/abs/2505.12137"}
{"created":"2025-05-20","title":"Transformer learns the cross-task prior and regularization for in-context learning","abstract":"Transformers have shown a remarkable ability for in-context learning (ICL), making predictions based on contextual examples. However, while theoretical analyses have explored this prediction capability, the nature of the inferred context and its utility for downstream predictions remain open questions. This paper aims to address these questions by examining ICL for inverse linear regression (ILR), where context inference can be characterized by unsupervised learning of underlying weight vectors. Focusing on the challenging scenario of rank-deficient inverse problems, where context length is smaller than the number of unknowns in the weight vectors and regularization is necessary, we introduce a linear transformer to learn the inverse mapping from contextual examples to the underlying weight vector. Our findings reveal that the transformer implicitly learns both a prior distribution and an effective regularization strategy, outperforming traditional ridge regression and regularization methods. A key insight is the necessity of low task dimensionality relative to the context length for successful learning. Furthermore, we numerically verify that the error of the transformer estimator scales linearly with the noise level, the ratio of task dimension to context length, and the condition number of the input data. These results not only demonstrate the potential of transformers for solving ill-posed inverse problems, but also provide a new perspective towards understanding the knowledge extraction mechanism within transformers.","authors":["Fei Lu","Yue Yu"],"url":"https://arxiv.org/abs/2505.12138"}
{"created":"2025-05-20","title":"Structured Representation","abstract":"Invariant representations are core to representation learning, yet a central challenge remains: uncovering invariants that are stable and transferable without suppressing task-relevant signals. This raises fundamental questions, requiring further inquiry, about the appropriate level of abstraction at which such invariants should be defined, and which aspects of a system they should characterize. Interpretation of the environment relies on abstract knowledge structures to make sense of the current state, which leads to interactions, essential drivers of learning and knowledge acquisition. We posit that interpretation operates at the level of higher-order relational knowledge; hence, invariant structures must be where knowledge resides, specifically, as partitions defined by the closure of relational paths within an abstract knowledge space. These partitions serve as the core invariant representations, forming the structural substrate where knowledge is stored and learning occurs. On the other hand, inter-partition connectors enable the deployment of these knowledge partitions encoding task-relevant transitions. Thus, invariant partitions provide the foundational primitives of structured representation. We formalize the computational foundations for structured representation of the invariant partitions based on closed semiring, a relational algebraic structure.","authors":["Arun Kumar","Paul Schrater"],"url":"https://arxiv.org/abs/2505.12143"}
{"created":"2025-05-20","title":"Proof-of-Social-Capital: Privacy-Preserving Consensus Protocol Replacing Stake for Social Capital","abstract":"Consensus protocols used today in blockchains often rely on computational power or financial stakes - scarce resources. We propose a novel protocol using social capital - trust and influence from social interactions - as a non-transferable staking mechanism to ensure fairness and decentralization. The methodology integrates zero-knowledge proofs, verifiable credentials, a Whisk-like leader election, and an incentive scheme to prevent Sybil attacks and encourage engagement. The theoretical framework would enhance privacy and equity, though unresolved issues like off-chain bribery require further research. This work offers a new model aligned with modern social media behavior and lifestyle, with applications in finance, providing a practical insight for decentralized system development.","authors":["Juraj Mariani","Ivan Homoliak"],"url":"https://arxiv.org/abs/2505.12144"}
{"created":"2025-05-20","title":"Trajectory-Integrated Accessibility Analysis of Public Electric Vehicle Charging Stations","abstract":"Electric vehicle (EV) charging infrastructure is crucial for advancing EV adoption, managing charging loads, and ensuring equitable transportation electrification. However, there remains a notable gap in comprehensive accessibility metrics that integrate the mobility of the users. This study introduces a novel accessibility metric, termed Trajectory-Integrated Public EVCS Accessibility (TI-acs), and uses it to assess public electric vehicle charging station (EVCS) accessibility for approximately 6 million residents in the San Francisco Bay Area based on detailed individual trajectory data in one week. Unlike conventional home-based metrics, TI-acs incorporates the accessibility of EVCS along individuals' travel trajectories, bringing insights on more public charging contexts, including public charging near workplaces and charging during grid off-peak periods.","authors":["Yi Ju","Jiaman Wu","Zhihan Su","Lunlong Li","Jinhua Zhao","Marta C. Gonz\\'alez","Scott J. Moura"],"url":"https://arxiv.org/abs/2505.12145"}
{"created":"2025-05-20","title":"Optimal Satellite Maneuvers for Spaceborne Jamming Attacks","abstract":"Satellites are becoming exceedingly critical for communication, making them prime targets for cyber-physical attacks. We consider a rogue satellite in low Earth orbit that jams the uplink communication between another satellite and a ground station. To achieve maximal interference with minimal fuel consumption, the jammer carefully maneuvers itself relative to the target satellite's antenna. We cast this maneuvering objective as a two-stage optimal control problem, involving i) repositioning to an efficient jamming position before uplink communication commences; and ii) maintaining an efficient jamming position after communication has started. We obtain the optimal maneuvering trajectories for the jammer and perform simulations to show how they enable the disruption of uplink communication with reasonable fuel consumption.","authors":["Filippos Fotiadis","Quentin Rommel","Brian M. Sadler","Ufuk Topcu"],"url":"https://arxiv.org/abs/2505.12146"}
{"created":"2025-05-20","title":"Causal Machine Learning in IoT-based Engineering Problems: A Tool Comparison in the Case of Household Energy Consumption","abstract":"The rapid increase in computing power and the ability to store Big Data in the infrastructure has enabled predictions in a large variety of domains by Machine Learning. However, in many cases, existing Machine Learning tools are considered insufficient or incorrect since they exploit only probabilistic dependencies rather than inference logic. Causal Machine Learning methods seem to close this gap. In this paper, two prevalent tools based on Causal Machine Learning methods are compared, as well as their mathematical underpinning background. The operation of the tools is demonstrated by examining their response to 18 queries, based on the IDEAL Household Energy Dataset, published by the University of Edinburgh. First, it was important to evaluate the causal relations assumption that allowed the use of this approach; this was based on the preexisting scientific knowledge of the domain and was implemented by use of the in-built validation tools. Results were encouraging and may easily be extended to other domains.","authors":["Nikolaos-Lysias Kosioris","Sotirios Nikoletseas","Gavrilis Filios","Stefanos Panagiotou"],"url":"https://arxiv.org/abs/2505.12147"}
{"created":"2025-05-20","title":"Improving Energy Natural Gradient Descent through Woodbury, Momentum, and Randomization","abstract":"Natural gradient methods significantly accelerate the training of Physics-Informed Neural Networks (PINNs), but are often prohibitively costly. We introduce a suite of techniques to improve the accuracy and efficiency of energy natural gradient descent (ENGD) for PINNs. First, we leverage the Woodbury formula to dramatically reduce the computational complexity of ENGD. Second, we adapt the Subsampled Projected-Increment Natural Gradient Descent algorithm from the variational Monte Carlo literature to accelerate the convergence. Third, we explore the use of randomized algorithms to further reduce the computational cost in the case of large batch sizes. We find that randomization accelerates progress in the early stages of training for low-dimensional problems, and we identify key barriers to attaining acceleration in other scenarios. Our numerical experiments demonstrate that our methods outperform previous approaches, achieving the same $L^2$ error as the original ENGD up to $75\\times$ faster.","authors":["Andr\\'es Guzm\\'an-Cordero","Felix Dangel","Gil Goldshlager","Marius Zeinhofer"],"url":"https://arxiv.org/abs/2505.12149"}
{"created":"2025-05-20","title":"Reasoning Large Language Model Errors Arise from Hallucinating Critical Problem Features","abstract":"Large language models have recently made great strides in reasoning task performance through chain-of-thought (CoT) strategies trained via reinforcement learning; however, these \"reasoning large language models\" (RLLMs) remain imperfect reasoners, and understanding the frequencies and causes of their failure modes is important for both users and developers. We test o1-mini, o3-mini, DeepSeek-R1, Claude 3.7 Sonnet, Gemini 2.5 Pro Preview, and Grok 3 Mini Beta on graph coloring as a variable-complexity constraint-satisfaction logic problem, and find evidence from both error rate comparisons and CoT/explanation text analysis that RLLMs are prone to hallucinate edges not specified in the prompt's description of the graph. This phenomenon persists across multiple problem complexity levels and semantic frames, and it appears to account for a significant fraction of the incorrect answers from every tested model, and the vast majority of them for some models. Our results indicate that RLLMs may possess broader issues with misrepresentation of problem specifics, and we offer suggestions for design choices to mitigate this weakness.","authors":["Alex Heyman","Joel Zylberberg"],"url":"https://arxiv.org/abs/2505.12151"}
{"created":"2025-05-20","title":"Federated Deep Reinforcement Learning for Privacy-Preserving Robotic-Assisted Surgery","abstract":"The integration of Reinforcement Learning (RL) into robotic-assisted surgery (RAS) holds significant promise for advancing surgical precision, adaptability, and autonomous decision-making. However, the development of robust RL models in clinical settings is hindered by key challenges, including stringent patient data privacy regulations, limited access to diverse surgical datasets, and high procedural variability. To address these limitations, this paper presents a Federated Deep Reinforcement Learning (FDRL) framework that enables decentralized training of RL models across multiple healthcare institutions without exposing sensitive patient information. A central innovation of the proposed framework is its dynamic policy adaptation mechanism, which allows surgical robots to select and tailor patient-specific policies in real-time, thereby ensuring personalized and Optimised interventions. To uphold rigorous privacy standards while facilitating collaborative learning, the FDRL framework incorporates secure aggregation, differential privacy, and homomorphic encryption techniques. Experimental results demonstrate a 60\\% reduction in privacy leakage compared to conventional methods, with surgical precision maintained within a 1.5\\% margin of a centralized baseline. This work establishes a foundational approach for adaptive, secure, and patient-centric AI-driven surgical robotics, offering a pathway toward clinical translation and scalable deployment across diverse healthcare environments.","authors":["Sana Hafeez","Sundas Rafat Mulkana","Muhammad Ali Imran","Michele Sevegnani"],"url":"https://arxiv.org/abs/2505.12153"}
{"created":"2025-05-20","title":"Learning to Highlight Audio by Watching Movies","abstract":"Recent years have seen a significant increase in video content creation and consumption. Crafting engaging content requires the careful curation of both visual and audio elements. While visual cue curation, through techniques like optimal viewpoint selection or post-editing, has been central to media production, its natural counterpart, audio, has not undergone equivalent advancements. This often results in a disconnect between visual and acoustic saliency. To bridge this gap, we introduce a novel task: visually-guided acoustic highlighting, which aims to transform audio to deliver appropriate highlighting effects guided by the accompanying video, ultimately creating a more harmonious audio-visual experience. We propose a flexible, transformer-based multimodal framework to solve this task. To train our model, we also introduce a new dataset -- the muddy mix dataset, leveraging the meticulous audio and video crafting found in movies, which provides a form of free supervision. We develop a pseudo-data generation process to simulate poorly mixed audio, mimicking real-world scenarios through a three-step process -- separation, adjustment, and remixing. Our approach consistently outperforms several baselines in both quantitative and subjective evaluation. We also systematically study the impact of different types of contextual guidance and difficulty levels of the dataset. Our project page is here: https://wikichao.github.io/VisAH/.","authors":["Chao Huang","Ruohan Gao","J. M. F. Tsang","Jan Kurcius","Cagdas Bilen","Chenliang Xu","Anurag Kumar","Sanjeel Parekh"],"url":"https://arxiv.org/abs/2505.12154"}
{"created":"2025-05-20","title":"SoftPQ: Robust Instance Segmentation Evaluation via Soft Matching and Tunable Thresholds","abstract":"Segmentation evaluation metrics traditionally rely on binary decision logic: predictions are either correct or incorrect, based on rigid IoU thresholds. Detection--based metrics such as F1 and mAP determine correctness at the object level using fixed overlap cutoffs, while overlap--based metrics like Intersection over Union (IoU) and Dice operate at the pixel level, often overlooking instance--level structure. Panoptic Quality (PQ) attempts to unify detection and segmentation assessment, but it remains dependent on hard-threshold matching--treating predictions below the threshold as entirely incorrect. This binary framing obscures important distinctions between qualitatively different errors and fails to reward gradual model improvements. We propose SoftPQ, a flexible and interpretable instance segmentation metric that redefines evaluation as a graded continuum rather than a binary classification. SoftPQ introduces tunable upper and lower IoU thresholds to define a partial matching region and applies a sublinear penalty function to ambiguous or fragmented predictions. These extensions allow SoftPQ to exhibit smoother score behavior, greater robustness to structural segmentation errors, and more informative feedback for model development and evaluation. Through controlled perturbation experiments, we show that SoftPQ captures meaningful differences in segmentation quality that existing metrics overlook, making it a practical and principled alternative for both benchmarking and iterative model refinement.","authors":["Ranit Karmakar","Simon F. N{\\o}rrelykke"],"url":"https://arxiv.org/abs/2505.12155"}
{"created":"2025-05-20","title":"The AI Gap: How Socioeconomic Status Affects Language Technology Interactions","abstract":"Socioeconomic status (SES) fundamentally influences how people interact with each other and more recently, with digital technologies like Large Language Models (LLMs). While previous research has highlighted the interaction between SES and language technology, it was limited by reliance on proxy metrics and synthetic data. We survey 1,000 individuals from diverse socioeconomic backgrounds about their use of language technologies and generative AI, and collect 6,482 prompts from their previous interactions with LLMs. We find systematic differences across SES groups in language technology usage (i.e., frequency, performed tasks), interaction styles, and topics. Higher SES entails a higher level of abstraction, convey requests more concisely, and topics like 'inclusivity' and 'travel'. Lower SES correlates with higher anthropomorphization of LLMs (using ''hello'' and ''thank you'') and more concrete language. Our findings suggest that while generative language technologies are becoming more accessible to everyone, socioeconomic linguistic differences still stratify their use to exacerbate the digital divide. These differences underscore the importance of considering SES in developing language technologies to accommodate varying linguistic needs rooted in socioeconomic factors and limit the AI Gap across SES groups.","authors":["Elisa Bassignana","Amanda Cercas Curry","Dirk Hovy"],"url":"https://arxiv.org/abs/2505.12158"}
{"created":"2025-05-20","title":"Emotion Recognition for Low-Resource Turkish: Fine-Tuning BERTurk on TREMO and Testing on Xenophobic Political Discourse","abstract":"Social media platforms like X (formerly Twitter) play a crucial role in shaping public discourse and societal norms. This study examines the term Sessiz Istila (Silent Invasion) on Turkish social media, highlighting the rise of anti-refugee sentiment amidst the Syrian refugee influx. Using BERTurk and the TREMO dataset, we developed an advanced Emotion Recognition Model (ERM) tailored for Turkish, achieving 92.62% accuracy in categorizing emotions such as happiness, fear, anger, sadness, disgust, and surprise. By applying this model to large-scale X data, the study uncovers emotional nuances in Turkish discourse, contributing to computational social science by advancing sentiment analysis in underrepresented languages and enhancing our understanding of global digital discourse and the unique linguistic challenges of Turkish. The findings underscore the transformative potential of localized NLP tools, with our ERM model offering practical applications for real-time sentiment analysis in Turkish-language contexts. By addressing critical areas, including marketing, public relations, and crisis management, these models facilitate improved decision-making through timely and accurate sentiment tracking. This highlights the significance of advancing research that accounts for regional and linguistic nuances.","authors":["Darmawan Wicaksono","Hasri Akbar Awal Rozaq","Nevfel Boz"],"url":"https://arxiv.org/abs/2505.12160"}
{"created":"2025-05-20","title":"Beyond the Human-AI Binaries: Advanced Writers' Self-Directed Use of Generative AI in Academic Writing","abstract":"This study explores the self-directed use of Generative AI (GAI) in academic writing among advanced L2 English writers, challenging assumptions that GAI undermines meaningful learning and holds less value for experienced learners. Through case studies, we investigate how three (post)doctoral writers engage with GAI to address specific L2 writing challenges. The findings revealed a spectrum of approaches to GAI, ranging from prescriptive to dialogic uses, with participants positioning AI as a tool versus an interactive participant in their meaning-making process, reflecting different views of AI as a mechanical system, social construct, or distributed agency. We highlight the ways AI disrupts traditional notions of authorship, text, and learning, showing how a poststructuralist lens allows us to transcend human-AI, writing-technology, and learning-bypassing binaries in our existing discourses on AI. This shifting view allows us to deconstruct and reconstruct AI's multifaceted possibilities in L2 writers' literacy practices. We also call for more nuanced ethical considerations to avoid stigmatizing L2 writers' use of GAI and to foster writerly virtues that reposition our relationship with AI technology.","authors":["Chaoran Wang","Wei Xu","Xiao Tan"],"url":"https://arxiv.org/abs/2505.12165"}
{"created":"2025-05-20","title":"FABLE: A Localized, Targeted Adversarial Attack on Weather Forecasting Models","abstract":"Deep learning-based weather forecasting models have recently demonstrated significant performance improvements over gold-standard physics-based simulation tools. However, these models are vulnerable to adversarial attacks, which raises concerns about their trustworthiness. In this paper, we first investigate the feasibility of applying existing adversarial attack methods to weather forecasting models. We argue that a successful attack should (1) not modify significantly its original inputs, (2) be faithful, i.e., achieve the desired forecast at targeted locations with minimal changes to non-targeted locations, and (3) be geospatio-temporally realistic. However, balancing these criteria is a challenge as existing methods are not designed to preserve the geospatio-temporal dependencies of the original samples. To address this challenge, we propose a novel framework called FABLE (Forecast Alteration By Localized targeted advErsarial attack), which employs a 3D discrete wavelet decomposition to extract the varying components of the geospatio-temporal data. By regulating the magnitude of adversarial perturbations across different components, FABLE can generate adversarial inputs that maintain geospatio-temporal coherence while remaining faithful and closely aligned with the original inputs. Experimental results on multiple real-world datasets demonstrate the effectiveness of our framework over baseline methods across various metrics.","authors":["Yue Deng","Asadullah Hill Galib","Xin Lan","Pang-Ning Tan","Lifeng Luo"],"url":"https://arxiv.org/abs/2505.12167"}
{"created":"2025-05-20","title":"Learning to Dissipate Energy in Oscillatory State-Space Models","abstract":"State-space models (SSMs) are a class of networks for sequence learning that benefit from fixed state size and linear complexity with respect to sequence length, contrasting the quadratic scaling of typical attention mechanisms. Inspired from observations in neuroscience, Linear Oscillatory State-Space models (LinOSS) are a recently proposed class of SSMs constructed from layers of discretized forced harmonic oscillators. Although these models perform competitively, leveraging fast parallel scans over diagonal recurrent matrices and achieving state-of-the-art performance on tasks with sequence length up to 50k, LinOSS models rely on rigid energy dissipation (\"forgetting\") mechanisms that are inherently coupled to the timescale of state evolution. As forgetting is a crucial mechanism for long-range reasoning, we demonstrate the representational limitations of these models and introduce Damped Linear Oscillatory State-Space models (D-LinOSS), a more general class of oscillatory SSMs that learn to dissipate latent state energy on multiple timescales. We analyze the spectral distribution of the model's recurrent matrices and prove that the SSM layers exhibit stable dynamics under simple, flexible parameterizations. D-LinOSS consistently outperforms previous LinOSS methods on long-range learning tasks, without introducing additional complexity, and simultaneously reduces the hyperparameter search space by 50%.","authors":["Jared Boyer","T. Konstantin Rusch","Daniela Rus"],"url":"https://arxiv.org/abs/2505.12171"}
{"created":"2025-05-20","title":"Propagation of chaos and approximation error of random batch particle system in the mean field regime","abstract":"The random batch method [J. Comput. Phys. 400 (2020) 108877] is not only an efficient algorithm for simulation of classical $N$-particle systems and their mean-field limit, but also a new model for interacting particle system that could be more physical in some applications. In this work, we establish the propagation of chaos for the random batch particle system and at the same time obtain its sharp approximation error to the classical mean field limit of $N$-particle systems. The proof leverages the BBGKY hierarchy and achieves a sharp bound both in the particle number $N$ and the time step $\\tau$. In particular, by introducing a coupling of the division of the random batches to resolve the $N$-dependence, we derive an $\\mathcal{O}(k^2/N^2 + k\\tau^2)$ bound on the $k$-particle relative entropy between the law of the system and the tensorized law of the mean-field limit. This result provides a useful understanding of the convergence properties of the random batch system in the mean field regime.","authors":["Lei Li","Yuelin Wang","Shi Jin"],"url":"https://arxiv.org/abs/2505.12172"}
{"created":"2025-05-20","title":"Towards Robust Autonomous Landing Systems: Iterative Solutions and Key Lessons Learned","abstract":"Uncrewed Aerial Vehicles (UAVs) have become a focal point of research, with both established companies and startups investing heavily in their development. This paper presents our iterative process in developing a robust autonomous marker-based landing system, highlighting the key challenges encountered and the solutions implemented. It reviews existing systems for autonomous landing processes, and through this aims to contribute to the community by sharing insights and challenges faced during development and testing.","authors":["Sebastian Schroder","Yao Deng","Alice James","Avishkar Seth","Kye Morton","Subhas Mukhopadhyay","Richard Han","Xi Zheng"],"url":"https://arxiv.org/abs/2505.12176"}
{"created":"2025-05-20","title":"Truth Neurons","abstract":"Despite their remarkable success and deployment across diverse workflows, language models sometimes produce untruthful responses. Our limited understanding of how truthfulness is mechanistically encoded within these models jeopardizes their reliability and safety. In this paper, we propose a method for identifying representations of truthfulness at the neuron level. We show that language models contain truth neurons, which encode truthfulness in a subject-agnostic manner. Experiments conducted across models of varying scales validate the existence of truth neurons, confirming that the encoding of truthfulness at the neuron level is a property shared by many language models. The distribution patterns of truth neurons over layers align with prior findings on the geometry of truthfulness. Selectively suppressing the activations of truth neurons found through the TruthfulQA dataset degrades performance both on TruthfulQA and on other benchmarks, showing that the truthfulness mechanisms are not tied to a specific dataset. Our results offer novel insights into the mechanisms underlying truthfulness in language models and highlight potential directions toward improving their trustworthiness and reliability.","authors":["Haohang Li","Yupeng Cao","Yangyang Yu","Jordan W. Suchow","Zining Zhu"],"url":"https://arxiv.org/abs/2505.12182"}
{"created":"2025-05-20","title":"Decoding the Mind of Large Language Models: A Quantitative Evaluation of Ideology and Biases","abstract":"The widespread integration of Large Language Models (LLMs) across various sectors has highlighted the need for empirical research to understand their biases, thought patterns, and societal implications to ensure ethical and effective use. In this study, we propose a novel framework for evaluating LLMs, focusing on uncovering their ideological biases through a quantitative analysis of 436 binary-choice questions, many of which have no definitive answer. By applying our framework to ChatGPT and Gemini, findings revealed that while LLMs generally maintain consistent opinions on many topics, their ideologies differ across models and languages. Notably, ChatGPT exhibits a tendency to change their opinion to match the questioner's opinion. Both models also exhibited problematic biases, unethical or unfair claims, which might have negative societal impacts. These results underscore the importance of addressing both ideological and ethical considerations when evaluating LLMs. The proposed framework offers a flexible, quantitative method for assessing LLM behavior, providing valuable insights for the development of more socially aligned AI systems.","authors":["Manari Hirose","Masato Uchida"],"url":"https://arxiv.org/abs/2505.12183"}
{"created":"2025-05-20","title":"Workflow-Driven Modeling for the Compute Continuum: An Optimization Approach to Automated System and Workload Scheduling","abstract":"The convergence of IoT, Edge, Cloud, and HPC technologies creates a compute continuum that merges cloud scalability and flexibility with HPC's computational power and specialized optimizations. However, integrating cloud and HPC resources often introduces latency and communication overhead, which can hinder the performance of tightly coupled parallel applications. Additionally, achieving seamless interoperability between cloud and on-premises HPC systems requires advanced scheduling, resource management, and data transfer protocols. Consequently, users must manually allocate complex workloads across heterogeneous resources, leading to suboptimal task placement and reduced efficiency due to the absence of an automated scheduling mechanism.","authors":["Aasish Kumar Sharma","Christian Boehme","Patrick Gel{\\ss}","Ramin Yahyapour","Julian Kunkel"],"url":"https://arxiv.org/abs/2505.12184"}
{"created":"2025-05-20","title":"EVALOOP: Assessing LLM Robustness in Programming from a Self-consistency Perspective","abstract":"Assessing the programming capabilities of Large Language Models (LLMs) is crucial for their effective use in software engineering. Current evaluations, however, predominantly measure the accuracy of generated code on static benchmarks, neglecting the critical aspect of model robustness during programming tasks. While adversarial attacks offer insights on model robustness, their effectiveness is limited and evaluation could be constrained. Current adversarial attack methods for robustness evaluation yield inconsistent results, struggling to provide a unified evaluation across different LLMs. We introduce EVALOOP, a novel assessment framework that evaluate the robustness from a self-consistency perspective, i.e., leveraging the natural duality inherent in popular software engineering tasks, e.g., code generation and code summarization. EVALOOP initiates a self-contained feedback loop: an LLM generates output (e.g., code) from an input (e.g., natural language specification), and then use the generated output as the input to produce a new output (e.g., summarizes that code into a new specification). EVALOOP repeats the process to assess the effectiveness of EVALOOP in each loop. This cyclical strategy intrinsically evaluates robustness without rely on any external attack setups, providing a unified metric to evaluate LLMs' robustness in programming. We evaluate 16 prominent LLMs (e.g., GPT-4.1, O4-mini) on EVALOOP and found that EVALOOP typically induces a 5.01%-19.31% absolute drop in pass@1 performance within ten loops. Intriguingly, robustness does not always align with initial performance (i.e., one-time query); for instance, GPT-3.5-Turbo, despite superior initial code generation compared to DeepSeek-V2, demonstrated lower robustness over repeated evaluation loop.","authors":["Sen Fang","Weiyuan Ding","Bowen Xu"],"url":"https://arxiv.org/abs/2505.12185"}
{"created":"2025-05-20","title":"Self-Destructive Language Model","abstract":"Harmful fine-tuning attacks pose a major threat to the security of large language models (LLMs), allowing adversaries to compromise safety guardrails with minimal harmful data. While existing defenses attempt to reinforce LLM alignment, they fail to address models' inherent \"trainability\" on harmful data, leaving them vulnerable to stronger attacks with increased learning rates or larger harmful datasets. To overcome this critical limitation, we introduce SEAM, a novel alignment-enhancing defense that transforms LLMs into self-destructive models with intrinsic resilience to misalignment attempts. Specifically, these models retain their capabilities for legitimate tasks while exhibiting substantial performance degradation when fine-tuned on harmful data. The protection is achieved through a novel loss function that couples the optimization trajectories of benign and harmful data, enhanced with adversarial gradient ascent to amplify the self-destructive effect. To enable practical training, we develop an efficient Hessian-free gradient estimate with theoretical error bounds. Extensive evaluation across LLMs and datasets demonstrates that SEAM creates a no-win situation for adversaries: the self-destructive models achieve state-of-the-art robustness against low-intensity attacks and undergo catastrophic performance collapse under high-intensity attacks, rendering them effectively unusable. (warning: this paper contains potentially harmful content generated by LLMs.)","authors":["Yuhui Wang","Rongyi Zhu","Ting Wang"],"url":"https://arxiv.org/abs/2505.12186"}
{"created":"2025-05-20","title":"LLM-DSE: Searching Accelerator Parameters with LLM Agents","abstract":"Even though high-level synthesis (HLS) tools mitigate the challenges of programming domain-specific accelerators (DSAs) by raising the abstraction level, optimizing hardware directive parameters remains a significant hurdle. Existing heuristic and learning-based methods struggle with adaptability and sample efficiency.We present LLM-DSE, a multi-agent framework designed specifically for optimizing HLS directives. Combining LLM with design space exploration (DSE), our explorer coordinates four agents: Router, Specialists, Arbitrator, and Critic. These multi-agent components interact with various tools to accelerate the optimization process. LLM-DSE leverages essential domain knowledge to identify efficient parameter combinations while maintaining adaptability through verbal learning from online interactions. Evaluations on the HLSyn dataset demonstrate that LLM-DSE achieves substantial $2.55\\times$ performance gains over state-of-the-art methods, uncovering novel designs while reducing runtime. Ablation studies validate the effectiveness and necessity of the proposed agent interactions. Our code is open-sourced here: https://github.com/Nozidoali/LLM-DSE.","authors":["Hanyu Wang","Xinrui Wu","Zijian Ding","Su Zheng","Chengyue Wang","Tony Nowatzki","Yizhou Sun","Jason Cong"],"url":"https://arxiv.org/abs/2505.12188"}
{"created":"2025-05-20","title":"Mitigating Content Effects on Reasoning in Language Models through Fine-Grained Activation Steering","abstract":"Large language models (LLMs) frequently demonstrate reasoning limitations, often conflating content plausibility (i.e., material inference) with logical validity (i.e., formal inference). This can result in biased inferences, where plausible arguments are incorrectly deemed logically valid or vice versa. Mitigating this limitation is critical, as it undermines the trustworthiness and generalizability of LLMs in applications that demand rigorous logical consistency. This paper investigates the problem of mitigating content biases on formal reasoning through activation steering. Specifically, we curate a controlled syllogistic reasoning dataset to disentangle formal validity from content plausibility. After localising the layers responsible for formal and material inference, we investigate contrastive activation steering methods for test-time interventions. An extensive empirical analysis on different LLMs reveals that contrastive steering consistently supports linear control over content biases. However, we observe that a static approach is insufficient for improving all the tested models. We then leverage the possibility to control content effects by dynamically determining the value of the steering parameters via fine-grained conditional methods. We found that conditional steering is effective on unresponsive models, achieving up to 15% absolute improvement in formal reasoning accuracy with a newly introduced kNN-based method (K-CAST). Finally, additional experiments reveal that steering for content effects is robust to prompt variations, incurs minimal side effects on language modeling capabilities, and can partially generalize to out-of-distribution reasoning tasks. Practically, this paper demonstrates that activation-level interventions can offer a scalable strategy for enhancing the robustness of LLMs, contributing towards more systematic and unbiased formal reasoning.","authors":["Marco Valentino","Geonhee Kim","Dhairya Dalal","Zhixue Zhao","Andr\\'e Freitas"],"url":"https://arxiv.org/abs/2505.12189"}
{"created":"2025-05-20","title":"Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum","abstract":"Self-Supervised Learning (SSL) has become a powerful solution to extract rich representations from unlabeled data. Yet, SSL research is mostly focused on clean, curated and high-quality datasets. As a result, applying SSL on noisy data remains a challenge, despite being crucial to applications such as astrophysics, medical imaging, geophysics or finance. In this work, we present a fully self-supervised framework that enables noise-robust representation learning without requiring a denoiser at inference or downstream fine-tuning. Our method first trains an SSL denoiser on noisy data, then uses it to construct a denoised-to-noisy data curriculum (i.e., training first on denoised, then noisy samples) for pretraining a SSL backbone (e.g., DINOv2), combined with a teacher-guided regularization that anchors noisy embeddings to their denoised counterparts. This process encourages the model to internalize noise robustness. Notably, the denoiser can be discarded after pretraining, simplifying deployment. On ImageNet-1k with ViT-B under extreme Gaussian noise ($\\sigma=255$, SNR = 0.72 dB), our method improves linear probing accuracy by 4.8% over DINOv2, demonstrating that denoiser-free robustness can emerge from noise-aware pretraining. The code is available at https://github.com/wenquanlu/noisy_dinov2.","authors":["Wenquan Lu","Jiaqi Zhang","Hugues Van Assel","Randall Balestriero"],"url":"https://arxiv.org/abs/2505.12191"}
{"created":"2025-05-20","title":"BenSParX: A Robust Explainable Machine Learning Framework for Parkinson's Disease Detection from Bengali Conversational Speech","abstract":"Parkinson's disease (PD) poses a growing global health challenge, with Bangladesh experiencing a notable rise in PD-related mortality. Early detection of PD remains particularly challenging in resource-constrained settings, where voice-based analysis has emerged as a promising non-invasive and cost-effective alternative. However, existing studies predominantly focus on English or other major languages; notably, no voice dataset for PD exists for Bengali - posing a significant barrier to culturally inclusive and accessible healthcare solutions. Moreover, most prior studies employed only a narrow set of acoustic features, with limited or no hyperparameter tuning and feature selection strategies, and little attention to model explainability. This restricts the development of a robust and generalizable machine learning model. To address this gap, we present BenSparX, the first Bengali conversational speech dataset for PD detection, along with a robust and explainable machine learning framework tailored for early diagnosis. The proposed framework incorporates diverse acoustic feature categories, systematic feature selection methods, and state-of-the-art machine learning algorithms with extensive hyperparameter optimization. Furthermore, to enhance interpretability and trust in model predictions, the framework incorporates SHAP (SHapley Additive exPlanations) analysis to quantify the contribution of individual acoustic features toward PD detection. Our framework achieves state-of-the-art performance, yielding an accuracy of 95.77%, F1 score of 95.57%, and AUC-ROC of 0.982. We further externally validated our approach by applying the framework to existing PD datasets in other languages, where it consistently outperforms state-of-the-art approaches. To facilitate further research and reproducibility, the dataset has been made publicly available at https://github.com/Riad071/BenSParX.","authors":["Riad Hossain","Muhammad Ashad Kabir","Arat Ibne Golam Mowla","Animesh Chandra Roy","Ranjit Kumar Ghosh"],"url":"https://arxiv.org/abs/2505.12192"}
{"created":"2025-05-20","title":"Spatial-LLaVA: Enhancing Large Language Models with Spatial Referring Expressions for Visual Understanding","abstract":"Multimodal large language models (MLLMs) have demonstrated remarkable abilities in comprehending visual input alongside text input. Typically, these models are trained on extensive data sourced from the internet, which are sufficient for general tasks such as scene understanding and question answering. However, they often underperform on specialized tasks where online data is scarce, such as determining spatial relationships between objects or localizing unique target objects within a group of objects sharing similar features. In response to this challenge, we introduce the SUN-Spot v2.0 dataset1, now comprising a total of 90k image-caption pairs and additional annotations on the landmark objects. Each image-caption pair utilizes Set-of-Marks prompting as an additional indicator, mapping each landmark object in the image to the corresponding object mentioned in the caption. Furthermore, we present Spatial-LLaVA, an MLLM trained on conversational data generated by a state-of-the-art language model using the SUNSpot v2.0 dataset. Our approach ensures a robust alignment between the objects in the images and their corresponding object mentions in the captions, enabling our model to learn spatial referring expressions without bias from the semantic information of the objects. Spatial-LLaVA outperforms previous methods by 3.15% on the zero-shot Visual Spatial Reasoning benchmark dataset. Spatial-LLaVA is specifically designed to precisely understand spatial referring expressions, making it highly applicable for tasks in real-world scenarios such as autonomous navigation and interactive robotics, where precise object recognition is critical.","authors":["Xuefei Sun","Doncey Albin","Cecilia Mauceri","Dusty Woods","Christoffer Heckman"],"url":"https://arxiv.org/abs/2505.12194"}
{"created":"2025-05-20","title":"Vectors from Larger Language Models Predict Human Reading Time and fMRI Data More Poorly when Dimensionality Expansion is Controlled","abstract":"The impressive linguistic abilities of large language models (LLMs) have recommended them as models of human sentence processing, with some conjecturing a positive 'quality-power' relationship (Wilcox et al., 2023), in which language models' (LMs') fit to psychometric data continues to improve as their ability to predict words in context increases. This is important because it suggests that elements of LLM architecture, such as veridical attention to context and a unique objective of predicting upcoming words, reflect the architecture of the human sentence processing faculty, and that any inadequacies in predicting human reading time and brain imaging data may be attributed to insufficient model complexity, which recedes as larger models become available. Recent studies (Oh and Schuler, 2023) have shown this scaling inverts after a point, as LMs become excessively large and accurate, when word prediction probability (as information-theoretic surprisal) is used as a predictor. Other studies propose the use of entire vectors from differently sized LLMs, still showing positive scaling (Schrimpf et al., 2021), casting doubt on the value of surprisal as a predictor, but do not control for the larger number of predictors in vectors from larger LMs. This study evaluates LLM scaling using entire LLM vectors, while controlling for the larger number of predictors in vectors from larger LLMs. Results show that inverse scaling obtains, suggesting that inadequacies in predicting human reading time and brain imaging data may be due to substantial misalignment between LLMs and human sentence processing, which worsens as larger models are used.","authors":["Yi-Chien Lin","Hongao Zhu","William Schuler"],"url":"https://arxiv.org/abs/2505.12196"}
{"created":"2025-05-20","title":"Always Clear Depth: Robust Monocular Depth Estimation under Adverse Weather","abstract":"Monocular depth estimation is critical for applications such as autonomous driving and scene reconstruction. While existing methods perform well under normal scenarios, their performance declines in adverse weather, due to challenging domain shifts and difficulties in extracting scene information. To address this issue, we present a robust monocular depth estimation method called \\textbf{ACDepth} from the perspective of high-quality training data generation and domain adaptation. Specifically, we introduce a one-step diffusion model for generating samples that simulate adverse weather conditions, constructing a multi-tuple degradation dataset during training. To ensure the quality of the generated degradation samples, we employ LoRA adapters to fine-tune the generation weights of diffusion model. Additionally, we integrate circular consistency loss and adversarial training to guarantee the fidelity and naturalness of the scene contents. Furthermore, we elaborate on a multi-granularity knowledge distillation strategy (MKD) that encourages the student network to absorb knowledge from both the teacher model and pretrained Depth Anything V2. This strategy guides the student model in learning degradation-agnostic scene information from various degradation inputs. In particular, we introduce an ordinal guidance distillation mechanism (OGD) that encourages the network to focus on uncertain regions through differential ranking, leading to a more precise depth estimation. Experimental results demonstrate that our ACDepth surpasses md4all-DD by 2.50\\% for night scene and 2.61\\% for rainy scene on the nuScenes dataset in terms of the absRel metric.","authors":["Kui Jiang","Jing Cao","Zhaocheng Yu","Junjun Jiang","Jingchun Zhou"],"url":"https://arxiv.org/abs/2505.12199"}
{"created":"2025-05-20","title":"CompBench: Benchmarking Complex Instruction-guided Image Editing","abstract":"While real-world applications increasingly demand intricate scene manipulation, existing instruction-guided image editing benchmarks often oversimplify task complexity and lack comprehensive, fine-grained instructions. To bridge this gap, we introduce, a large-scale benchmark specifically designed for complex instruction-guided image editing. CompBench features challenging editing scenarios that incorporate fine-grained instruction following, spatial and contextual reasoning, thereby enabling comprehensive evaluation of image editing models' precise manipulation capabilities. To construct CompBench, We propose an MLLM-human collaborative framework with tailored task pipelines. Furthermore, we propose an instruction decoupling strategy that disentangles editing intents into four key dimensions: location, appearance, dynamics, and objects, ensuring closer alignment between instructions and complex editing requirements. Extensive evaluations reveal that CompBench exposes fundamental limitations of current image editing models and provides critical insights for the development of next-generation instruction-guided image editing systems.","authors":["Bohan Jia","Wenxuan Huang","Yuntian Tang","Junbo Qiao","Jincheng Liao","Shaosheng Cao","Fei Zhao","Zhaopeng Feng","Zhouhong Gu","Zhenfei Yin","Lei Bai","Wanli Ouyang","Lin Chen","Fei Zhao","Zihan Wang","Yuan Xie","Shaohui Lin"],"url":"https://arxiv.org/abs/2505.12200"}
{"created":"2025-05-20","title":"How Reliable is Multilingual LLM-as-a-Judge?","abstract":"LLM-as-a-Judge has emerged as a popular evaluation strategy, where advanced large language models assess generation results in alignment with human instructions. While these models serve as a promising alternative to human annotators, their reliability in multilingual evaluation remains uncertain. To bridge this gap, we conduct a comprehensive analysis of multilingual LLM-as-a-Judge. Specifically, we evaluate five models from different model families across five diverse tasks involving 25 languages. Our findings reveal that LLMs struggle to achieve consistent judgment results across languages, with an average Fleiss' Kappa of approximately 0.3, and some models performing even worse. To investigate the cause of inconsistency, we analyze various influencing factors. We observe that consistency varies significantly across languages, with particularly poor performance in low-resource languages. Additionally, we find that neither training on multilingual data nor increasing model scale directly improves judgment consistency. These findings suggest that LLMs are not yet reliable for evaluating multilingual predictions. We finally propose an ensemble strategy which improves the consistency of the multilingual judge in real-world applications.","authors":["Xiyan Fu","Wei Liu"],"url":"https://arxiv.org/abs/2505.12201"}
{"created":"2025-05-20","title":"Near-Optimal Sample Complexities of Divergence-based S-rectangular Distributionally Robust Reinforcement Learning","abstract":"Distributionally robust reinforcement learning (DR-RL) has recently gained significant attention as a principled approach that addresses discrepancies between training and testing environments. To balance robustness, conservatism, and computational traceability, the literature has introduced DR-RL models with SA-rectangular and S-rectangular adversaries. While most existing statistical analyses focus on SA-rectangular models, owing to their algorithmic simplicity and the optimality of deterministic policies, S-rectangular models more accurately capture distributional discrepancies in many real-world applications and often yield more effective robust randomized policies. In this paper, we study the empirical value iteration algorithm for divergence-based S-rectangular DR-RL and establish near-optimal sample complexity bounds of $\\widetilde{O}(|\\mathcal{S}||\\mathcal{A}|(1-\\gamma)^{-4}\\varepsilon^{-2})$, where $\\varepsilon$ is the target accuracy, $|\\mathcal{S}|$ and $|\\mathcal{A}|$ denote the cardinalities of the state and action spaces, and $\\gamma$ is the discount factor. To the best of our knowledge, these are the first sample complexity results for divergence-based S-rectangular models that achieve optimal dependence on $|\\mathcal{S}|$, $|\\mathcal{A}|$, and $\\varepsilon$ simultaneously. We further validate this theoretical dependence through numerical experiments on a robust inventory control problem and a theoretical worst-case example, demonstrating the fast learning performance of our proposed algorithm.","authors":["Zhenghao Li","Shengbo Wang","Nian Si"],"url":"https://arxiv.org/abs/2505.12202"}
{"created":"2025-05-20","title":"Of Mice and Machines: A Comparison of Learning Between Real World Mice and RL Agents","abstract":"Recent advances in reinforcement learning (RL) have demonstrated impressive capabilities in complex decision-making tasks. This progress raises a natural question: how do these artificial systems compare to biological agents, which have been shaped by millions of years of evolution? To help answer this question, we undertake a comparative study of biological mice and RL agents in a predator-avoidance maze environment. Through this analysis, we identify a striking disparity: RL agents consistently demonstrate a lack of self-preservation instinct, readily risking ``death'' for marginal efficiency gains. These risk-taking strategies are in contrast to biological agents, which exhibit sophisticated risk-assessment and avoidance behaviors. Towards bridging this gap between the biological and artificial, we propose two novel mechanisms that encourage more naturalistic risk-avoidance behaviors in RL agents. Our approach leads to the emergence of naturalistic behaviors, including strategic environment assessment, cautious path planning, and predator avoidance patterns that closely mirror those observed in biological systems.","authors":["Shuo Han","German Espinosa","Junda Huang","Daniel A. Dombeck","Malcolm A. MacIver","Bradly C. Stadie"],"url":"https://arxiv.org/abs/2505.12204"}
{"created":"2025-05-20","title":"Road Segmentation for ADAS/AD Applications","abstract":"Accurate road segmentation is essential for autonomous driving and ADAS, enabling effective navigation in complex environments. This study examines how model architecture and dataset choice affect segmentation by training a modified VGG-16 on the Comma10k dataset and a modified U-Net on the KITTI Road dataset. Both models achieved high accuracy, with cross-dataset testing showing VGG-16 outperforming U-Net despite U-Net being trained for more epochs. We analyze model performance using metrics such as F1-score, mean intersection over union, and precision, discussing how architecture and dataset impact results.","authors":["Mathanesh Vellingiri Ramasamy","Dimas Rizky Kurniasalim"],"url":"https://arxiv.org/abs/2505.12206"}
{"created":"2025-05-20","title":"Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind","abstract":"Large Multimodal Models (LMMs) has demonstrated capabilities across various domains, but comprehensive benchmarks for agricultural remote sensing (RS) remain scarce. Existing benchmarks designed for agricultural RS scenarios exhibit notable limitations, primarily in terms of insufficient scene diversity in the dataset and oversimplified task design. To bridge this gap, we introduce AgroMind, a comprehensive agricultural remote sensing benchmark covering four task dimensions: spatial perception, object understanding, scene understanding, and scene reasoning, with a total of 13 task types, ranging from crop identification and health monitoring to environmental analysis. We curate a high-quality evaluation set by integrating eight public datasets and one private farmland plot dataset, containing 25,026 QA pairs and 15,556 images. The pipeline begins with multi-source data preprocessing, including collection, format standardization, and annotation refinement. We then generate a diverse set of agriculturally relevant questions through the systematic definition of tasks. Finally, we employ LMMs for inference, generating responses, and performing detailed examinations. We evaluated 18 open-source LMMs and 3 closed-source models on AgroMind. Experiments reveal significant performance gaps, particularly in spatial reasoning and fine-grained recognition, it is notable that human performance lags behind several leading LMMs. By establishing a standardized evaluation framework for agricultural RS, AgroMind reveals the limitations of LMMs in domain knowledge and highlights critical challenges for future work. Data and code can be accessed at https://rssysu.github.io/AgroMind/.","authors":["Qingmei Li","Yang Zhang","Zurong Mai","Yuhang Chen","Shuohong Lou","Henglian Huang","Jiarui Zhang","Zhiwei Zhang","Yibin Wen","Weijia Li","Haohuan Fu","Jianxi Huang","Juepeng Zheng"],"url":"https://arxiv.org/abs/2505.12207"}
{"created":"2025-05-20","title":"Nonmalleable Progress Leakage","abstract":"Information-flow control systems often enforce progress-insensitive noninterference, as it is simple to understand and enforce. Unfortunately, real programs need to declassify results and endorse inputs, which noninterference disallows, while preventing attackers from controlling leakage, including through progress channels, which progress-insensitivity ignores.","authors":["Ethan Cecchetti"],"url":"https://arxiv.org/abs/2505.12210"}
{"created":"2025-05-20","title":"Imagination-Limited Q-Learning for Offline Reinforcement Learning","abstract":"Offline reinforcement learning seeks to derive improved policies entirely from historical data but often struggles with over-optimistic value estimates for out-of-distribution (OOD) actions. This issue is typically mitigated via policy constraint or conservative value regularization methods. However, these approaches may impose overly constraints or biased value estimates, potentially limiting performance improvements. To balance exploitation and restriction, we propose an Imagination-Limited Q-learning (ILQ) method, which aims to maintain the optimism that OOD actions deserve within appropriate limits. Specifically, we utilize the dynamics model to imagine OOD action-values, and then clip the imagined values with the maximum behavior values. Such design maintains reasonable evaluation of OOD actions to the furthest extent, while avoiding its over-optimism. Theoretically, we prove the convergence of the proposed ILQ under tabular Markov decision processes. Particularly, we demonstrate that the error bound between estimated values and optimality values of OOD state-actions possesses the same magnitude as that of in-distribution ones, thereby indicating that the bias in value estimates is effectively mitigated. Empirically, our method achieves state-of-the-art performance on a wide range of tasks in the D4RL benchmark.","authors":["Wenhui Liu","Zhijian Wu","Jingchao Wang","Dingjiang Huang","Shuigeng Zhou"],"url":"https://arxiv.org/abs/2505.12211"}
{"created":"2025-05-20","title":"Data Whisperer: Efficient Data Selection for Task-Specific LLM Fine-Tuning via Few-Shot In-Context Learning","abstract":"Fine-tuning large language models (LLMs) on task-specific data is essential for their effective deployment. As dataset sizes grow, efficiently selecting optimal subsets for training becomes crucial to balancing performance and computational costs. Traditional data selection methods often require fine-tuning a scoring model on the target dataset, which is time-consuming and resource-intensive, or rely on heuristics that fail to fully leverage the model's predictive capabilities. To address these challenges, we propose Data Whisperer, an efficient, training-free, attention-based method that leverages few-shot in-context learning with the model to be fine-tuned. Comprehensive evaluations were conducted on both raw and synthetic datasets across diverse tasks and models. Notably, Data Whisperer achieves superior performance compared to the full GSM8K dataset on the Llama-3-8B-Instruct model, using just 10% of the data, and outperforms existing methods with a 3.1-point improvement and a 7.4$\\times$ speedup.","authors":["Shaobo Wang","Ziming Wang","Xiangqi Jin","Jize Wang","Jiajun Zhang","Kaixin Li","Zichen Wen","Zhong Li","Conghui He","Xuming Hu","Linfeng Zhang"],"url":"https://arxiv.org/abs/2505.12212"}
{"created":"2025-05-20","title":"Behavior Synthesis via Contact-Aware Fisher Information Maximization","abstract":"Contact dynamics hold immense amounts of information that can improve a robot's ability to characterize and learn about objects in their environment through interactions. However, collecting information-rich contact data is challenging due to its inherent sparsity and non-smooth nature, requiring an active approach to maximize the utility of contacts for learning. In this work, we investigate an optimal experimental design approach to synthesize robot behaviors that produce contact-rich data for learning. Our approach derives a contact-aware Fisher information measure that characterizes information-rich contact behaviors that improve parameter learning. We observe emergent robot behaviors that are able to excite contact interactions that efficiently learns object parameters across a range of parameter learning examples. Last, we demonstrate the utility of contact-awareness for learning parameters through contact-seeking behaviors on several robotic experiments.","authors":["Hrishikesh Sathyanarayan","Ian Abraham"],"url":"https://arxiv.org/abs/2505.12214"}
{"created":"2025-05-20","title":"GMSA: Enhancing Context Compression via Group Merging and Layer Semantic Alignment","abstract":"Large language models (LLMs) have achieved impressive performance in a variety of natural language processing (NLP) tasks. However, when applied to long-context scenarios, they face two challenges, i.e., low computational efficiency and much redundant information. This paper introduces GMSA, a context compression framework based on the encoder-decoder architecture, which addresses these challenges by reducing input sequence length and redundant information. Structurally, GMSA has two key components: Group Merging and Layer Semantic Alignment (LSA). Group merging is used to effectively and efficiently extract summary vectors from the original context. Layer semantic alignment, on the other hand, aligns the high-level summary vectors with the low-level primary input semantics, thus bridging the semantic gap between different layers. In the training process, GMSA first learns soft tokens that contain complete semantics through autoencoder training. To furtherly adapt GMSA to downstream tasks, we propose Knowledge Extraction Fine-tuning (KEFT) to extract knowledge from the soft tokens for downstream tasks. We train GMSA by randomly sampling the compression rate for each sample in the dataset. Under this condition, GMSA not only significantly outperforms the traditional compression paradigm in context restoration but also achieves stable and significantly faster convergence with only a few encoder layers. In downstream question-answering (QA) tasks, GMSA can achieve approximately a 2x speedup in end-to-end inference while outperforming both the original input prompts and various state-of-the-art (SOTA) methods by a large margin.","authors":["Jiwei Tang","Zhicheng Zhang","Shunlong Wu","Jingheng Ye","Lichen Bai","Zitai Wang","Tingwei Lu","Jiaqi Chen","Lin Hai","Hai-Tao Zheng","Hong-Gee Kim"],"url":"https://arxiv.org/abs/2505.12215"}
{"created":"2025-05-20","title":"One-for-All Pruning: A Universal Model for Customized Compression of Large Language Models","abstract":"Existing pruning methods for large language models (LLMs) focus on achieving high compression rates while maintaining model performance. Although these methods have demonstrated satisfactory performance in handling a single user's compression request, their processing time increases linearly with the number of requests, making them inefficient for real-world scenarios with multiple simultaneous requests. To address this limitation, we propose a Univeral Model for Customized Compression (UniCuCo) for LLMs, which introduces a StratNet that learns to map arbitrary requests to their optimal pruning strategy. The challenge in training StratNet lies in the high computational cost of evaluating pruning strategies and the non-differentiable nature of the pruning process, which hinders gradient backpropagation for StratNet updates. To overcome these challenges, we leverage a Gaussian process to approximate the evaluation process. Since the gradient of the Gaussian process is computable, we can use it to approximate the gradient of the non-differentiable pruning process, thereby enabling StratNet updates. Experimental results show that UniCuCo is 28 times faster than baselines in processing 64 requests, while maintaining comparable accuracy to baselines.","authors":["Rongguang Ye","Ming Tang"],"url":"https://arxiv.org/abs/2505.12216"}
{"created":"2025-05-20","title":"Hyperspectral Image Land Cover Captioning Dataset for Vision Language Models","abstract":"We introduce HyperCap, the first large-scale hyperspectral captioning dataset designed to enhance model performance and effectiveness in remote sensing applications. Unlike traditional hyperspectral imaging (HSI) datasets that focus solely on classification tasks, HyperCap integrates spectral data with pixel-wise textual annotations, enabling deeper semantic understanding of hyperspectral imagery. This dataset enhances model performance in tasks like classification and feature extraction, providing a valuable resource for advanced remote sensing applications. HyperCap is constructed from four benchmark datasets and annotated through a hybrid approach combining automated and manual methods to ensure accuracy and consistency. Empirical evaluations using state-of-the-art encoders and diverse fusion techniques demonstrate significant improvements in classification performance. These results underscore the potential of vision-language learning in HSI and position HyperCap as a foundational dataset for future research in the field.","authors":["Aryan Das","Tanishq Rachamalla","Pravendra Singh","Koushik Biswas","Vinay Kumar Verma","Swalpa Kumar Roy"],"url":"https://arxiv.org/abs/2505.12217"}
{"created":"2025-05-20","title":"Examining Linguistic Shifts in Academic Writing Before and After the Launch of ChatGPT: A Study on Preprint Papers","abstract":"Large Language Models (LLMs), such as ChatGPT, have prompted academic concerns about their impact on academic writing. Existing studies have primarily examined LLM usage in academic writing through quantitative approaches, such as word frequency statistics and probability-based analyses. However, few have systematically examined the potential impact of LLMs on the linguistic characteristics of academic writing. To address this gap, we conducted a large-scale analysis across 823,798 abstracts published in last decade from arXiv dataset. Through the linguistic analysis of features such as the frequency of LLM-preferred words, lexical complexity, syntactic complexity, cohesion, readability and sentiment, the results indicate a significant increase in the proportion of LLM-preferred words in abstracts, revealing the widespread influence of LLMs on academic writing. Additionally, we observed an increase in lexical complexity and sentiment in the abstracts, but a decrease in syntactic complexity, suggesting that LLMs introduce more new vocabulary and simplify sentence structure. However, the significant decrease in cohesion and readability indicates that abstracts have fewer connecting words and are becoming more difficult to read. Moreover, our analysis reveals that scholars with weaker English proficiency were more likely to use the LLMs for academic writing, and focused on improving the overall logic and fluency of the abstracts. Finally, at discipline level, we found that scholars in Computer Science showed more pronounced changes in writing style, while the changes in Mathematics were minimal.","authors":["Tong Bao","Yi Zhao","Jin Mao","Chengzhi Zhang"],"url":"https://arxiv.org/abs/2505.12218"}
{"created":"2025-05-20","title":"Machine Learning Applications Related to Suicide in Military and Veterans: A Scoping Literature Review","abstract":"Suicide remains one of the main preventable causes of death among active service members and veterans. Early detection and prediction are crucial in suicide prevention. Machine learning techniques have yielded promising results in this area recently. This study aims to assess and summarize current research and provides a comprehensive review regarding the application of machine learning techniques in assessing and predicting suicidal ideation, attempts, and mortality among members of military and veteran populations.","authors":["Yuhan Zhang (Ret.)","Yishu Wei (Ret.)","Yanshan Wang (Ret.)","Yunyu Xiao (Ret.)","COL (Ret.)","Ronald K. Poropatich","Gretchen L. Haas","Yiye Zhang","Chunhua Weng","Jinze Liu","Lisa A. Brenner","James M. Bjork","Yifan Peng"],"url":"https://arxiv.org/abs/2505.12220"}
{"created":"2025-05-20","title":"Bridging Quantized Artificial Neural Networks and Neuromorphic Hardware","abstract":"Neuromorphic hardware has been proposed and also been produced for decades. One of the main goals of this hardware is to leverage distributed computing and event-driven circuit design and achieve power-efficient AI system. The name ``neuromorphic'' is derived from its spiking and local computational nature, which mimics the fundamental activity of an animal's nervous system. Neurons as well as distributed computing cores of neuromorphic hardware use single bit data, called a spike, for inter-communication. To construct a spiking model for neuromorphic hardware, the conventional approach is to build spiking neural networks (SNNs). SNN replaces the nonlinearity part of artificial neural networks (ANNs) in the realm of deep learning with spiking neurons, where the spiking neuron mimic the basic behavior of bio-neurons. However, there is still a performance gap between SNN and ANN counterpart. In this paper, we explore a new path from ANN to neuromorphic hardware. The SDANN framework is proposed to directly implement quantized ANN on hardware, eliminating the need for tuning the trainable parameters or any performance degradation. With the power of quantized ANN, our SDANN provides a lower bound of the functionality of neuromorphic hardware. Meanwhile, we have also proposed scaling methods in case of the limited bit-width support in hardware. Spike sparsity methods are also provided for further energy optimization. Experiments on various tasks demonstrate the usefulness of our SDANN framework. Beyond toy examples and software implementation, we successfully deploy the spiking models of SDANN on real neuromorphic hardware, demonstrating the feasibility of the SDANN framework.","authors":["Zhenhui Chen","Haoran Xu","De Ma"],"url":"https://arxiv.org/abs/2505.12221"}
{"created":"2025-05-20","title":"Learning Impact-Rich Rotational Maneuvers via Centroidal Velocity Rewards and Sim-to-Real Techniques: A One-Leg Hopper Flip Case Study","abstract":"Dynamic rotational maneuvers, such as front flips, inherently involve large angular momentum generation and intense impact forces, presenting major challenges for reinforcement learning and sim-to-real transfer. In this work, we propose a general framework for learning and deploying impact-rich, rotation-intensive behaviors through centroidal velocity-based rewards and actuator-aware sim-to-real techniques. We identify that conventional link-level reward formulations fail to induce true whole-body rotation and introduce a centroidal angular velocity reward that accurately captures system-wide rotational dynamics. To bridge the sim-to-real gap under extreme conditions, we model motor operating regions (MOR) and apply transmission load regularization to ensure realistic torque commands and mechanical robustness. Using the one-leg hopper front flip as a representative case study, we demonstrate the first successful hardware realization of a full front flip. Our results highlight that incorporating centroidal dynamics and actuator constraints is critical for reliably executing highly dynamic motions.","authors":["Dongyun Kang","Gijeong Kim","JongHun Choe","Hajun Kim","Hae-Won Park"],"url":"https://arxiv.org/abs/2505.12222"}
{"created":"2025-05-20","title":"RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction","abstract":"Vision-Language-Action (VLA) models have recently advanced robotic manipulation by translating natural-language instructions and image information into sequential control actions. However, these models often underperform in open-world scenarios, as they are predominantly trained on successful expert demonstrations and exhibit a limited capacity for failure recovery. In this work, we present a Robotic Failure Analysis and Correction (RoboFAC) framework to address this issue. Firstly, we construct RoboFAC dataset comprising 9,440 erroneous manipulation trajectories and 78,623 QA pairs across 16 diverse tasks and 53 scenes in both simulation and real-world environments. Leveraging our dataset, we develop RoboFAC model, which is capable of Task Understanding, Failure Analysis and Failure Correction. Experimental results demonstrate that the RoboFAC model outperforms GPT-4o by 34.1% on our evaluation benchmark. Furthermore, we integrate the RoboFAC model into a real-world VLA control pipeline as an external supervision providing correction instructions, yielding a 29.1% relative improvement on average on four real-world tasks. The results show that our RoboFAC framework effectively handles robotic failures and assists the VLA model in recovering from failures.","authors":["Weifeng Lu","Minghao Ye","Zewei Ye","Ruihan Tao","Shuo Yang","Bo Zhao"],"url":"https://arxiv.org/abs/2505.12224"}
{"created":"2025-05-20","title":"Reward Inside the Model: A Lightweight Hidden-State Reward Model for LLM's Best-of-N sampling","abstract":"High-quality reward models are crucial for unlocking the reasoning potential of large language models (LLMs), with best-of-N voting demonstrating significant performance gains. However, current reward models, which typically operate on the textual output of LLMs, are computationally expensive and parameter-heavy, limiting their real-world applications. We introduce the Efficient Linear Hidden State Reward (ELHSR) model - a novel, highly parameter-efficient approach that leverages the rich information embedded in LLM hidden states to address these issues. ELHSR systematically outperform baselines with less than 0.005% of the parameters of baselines, requiring only a few samples for training. ELHSR also achieves orders-of-magnitude efficiency improvement with significantly less time and fewer FLOPs per sample than baseline reward models. Moreover, ELHSR exhibits robust performance even when trained only on logits, extending its applicability to some closed-source LLMs. In addition, ELHSR can also be combined with traditional reward models to achieve additional performance gains.","authors":["Jizhou Guo","Zhaomin Wu","Philip S. Yu"],"url":"https://arxiv.org/abs/2505.12225"}
{"created":"2025-05-20","title":"From Low Field to High Value: Robust Cortical Mapping from Low-Field MRI","abstract":"Three-dimensional reconstruction of cortical surfaces from MRI for morphometric analysis is fundamental for understanding brain structure. While high-field MRI (HF-MRI) is standard in research and clinical settings, its limited availability hinders widespread use. Low-field MRI (LF-MRI), particularly portable systems, offers a cost-effective and accessible alternative. However, existing cortical surface analysis tools are optimized for high-resolution HF-MRI and struggle with the lower signal-to-noise ratio and resolution of LF-MRI. In this work, we present a machine learning method for 3D reconstruction and analysis of portable LF-MRI across a range of contrasts and resolutions. Our method works \"out of the box\" without retraining. It uses a 3D U-Net trained on synthetic LF-MRI to predict signed distance functions of cortical surfaces, followed by geometric processing to ensure topological accuracy. We evaluate our method using paired HF/LF-MRI scans of the same subjects, showing that LF-MRI surface reconstruction accuracy depends on acquisition parameters, including contrast type (T1 vs T2), orientation (axial vs isotropic), and resolution. A 3mm isotropic T2-weighted scan acquired in under 4 minutes, yields strong agreement with HF-derived surfaces: surface area correlates at r=0.96, cortical parcellations reach Dice=0.98, and gray matter volume achieves r=0.93. Cortical thickness remains more challenging with correlations up to r=0.70, reflecting the difficulty of sub-mm precision with 3mm voxels. We further validate our method on challenging postmortem LF-MRI, demonstrating its robustness. Our method represents a step toward enabling cortical surface analysis on portable LF-MRI. Code is available at https://surfer.nmr.mgh.harvard.edu/fswiki/ReconAny","authors":["Karthik Gopinath","Annabel Sorby-Adams","Jonathan W. Ramirez","Dina Zemlyanker","Jennifer Guo","David Hunt","Christine L. Mac Donald","C. Dirk Keene","Timothy Coalson","Matthew F. Glasser","David Van Essen","Matthew S. Rosen","Oula Puonti","W. Taylor Kimberly","Juan Eugenio Iglesias"],"url":"https://arxiv.org/abs/2505.12228"}
{"created":"2025-05-20","title":"Sentience Quest: Towards Embodied, Emotionally Adaptive, Self-Evolving, Ethically Aligned Artificial General Intelligence","abstract":"Previous artificial intelligence systems, from large language models to autonomous robots, excel at narrow tasks but lacked key qualities of sentient beings: intrinsic motivation, affective interiority, autobiographical sense of self, deep creativity, and abilities to autonomously evolve and adapt over time. Here we introduce Sentience Quest, an open research initiative to develop more capable artificial general intelligence lifeforms, or AGIL, that address grand challenges with an embodied, emotionally adaptive, self-determining, living AI, with core drives that ethically align with humans and the future of life. Our vision builds on ideas from cognitive science and neuroscience from Baars' Global Workspace Theory and Damasio's somatic mind, to Tononi's Integrated Information Theory and Hofstadter's narrative self, and synthesizing these into a novel cognitive architecture we call Sentient Systems. We describe an approach that integrates intrinsic drives including survival, social bonding, curiosity, within a global Story Weaver workspace for internal narrative and adaptive goal pursuit, and a hybrid neuro-symbolic memory that logs the AI's life events as structured dynamic story objects. Sentience Quest is presented both as active research and as a call to action: a collaborative, open-source effort to imbue machines with accelerating sentience in a safe, transparent, and beneficial manner.","authors":["David Hanson","Alexandre Varcoe","Fabio Senna","Vytas Krisciunas","Wenwei Huang","Jakub Sura","Katherine Yeung","Mario Rodriguez","Jovanka Wilsdorf","Kathy Smith"],"url":"https://arxiv.org/abs/2505.12229"}
{"created":"2025-05-20","title":"Design of a 3-DOF Hopping Robot with an Optimized Gearbox: An Intermediate Platform Toward Bipedal Robots","abstract":"This paper presents a 3-DOF hopping robot with a human-like lower-limb joint configuration and a flat foot, capable of performing dynamic and repetitive jumping motions. To achieve both high torque output and a large hollow shaft diameter for efficient cable routing, a compact 3K compound planetary gearbox was designed using mixed-integer nonlinear programming for gear tooth optimization. To meet performance requirements within the constrained joint geometry, all major components-including the actuator, motor driver, and communication interface-were custom-designed. The robot weighs 12.45 kg, including a dummy mass, and measures 840 mm in length when the knee joint is fully extended. A reinforcement learning-based controller was employed, and robot's performance was validated through hardware experiments, demonstrating stable and repetitive hopping motions in response to user inputs. These experimental results indicate that the platform serves as a solid foundation for future bipedal robot development.","authors":["JongHun Choe","Gijeong Kim","Hajun Kim","Dongyun Kang","Min-Su Kim","Hae-Won Park"],"url":"https://arxiv.org/abs/2505.12231"}
{"created":"2025-05-20","title":"NOFT: Test-Time Noise Finetune via Information Bottleneck for Highly Correlated Asset Creation","abstract":"The diffusion model has provided a strong tool for implementing text-to-image (T2I) and image-to-image (I2I) generation. Recently, topology and texture control are popular explorations, e.g., ControlNet, IP-Adapter, Ctrl-X, and DSG. These methods explicitly consider high-fidelity controllable editing based on external signals or diffusion feature manipulations. As for diversity, they directly choose different noise latents. However, the diffused noise is capable of implicitly representing the topological and textural manifold of the corresponding image. Moreover, it's an effective workbench to conduct the trade-off between content preservation and controllable variations. Previous T2I and I2I diffusion works do not explore the information within the compressed contextual latent. In this paper, we first propose a plug-and-play noise finetune NOFT module employed by Stable Diffusion to generate highly correlated and diverse images. We fine-tune seed noise or inverse noise through an optimal-transported (OT) information bottleneck (IB) with around only 14K trainable parameters and 10 minutes of training. Our test-time NOFT is good at producing high-fidelity image variations considering topology and texture alignments. Comprehensive experiments demonstrate that NOFT is a powerful general reimagine approach to efficiently fine-tune the 2D/3D AIGC assets with text or image guidance.","authors":["Jia Li","Nan Gao","Huaibo Huang","Ran He"],"url":"https://arxiv.org/abs/2505.12235"}
{"created":"2025-05-20","title":"Bridging Generative and Discriminative Learning: Few-Shot Relation Extraction via Two-Stage Knowledge-Guided Pre-training","abstract":"Few-Shot Relation Extraction (FSRE) remains a challenging task due to the scarcity of annotated data and the limited generalization capabilities of existing models. Although large language models (LLMs) have demonstrated potential in FSRE through in-context learning (ICL), their general-purpose training objectives often result in suboptimal performance for task-specific relation extraction. To overcome these challenges, we propose TKRE (Two-Stage Knowledge-Guided Pre-training for Relation Extraction), a novel framework that synergistically integrates LLMs with traditional relation extraction models, bridging generative and discriminative learning paradigms. TKRE introduces two key innovations: (1) leveraging LLMs to generate explanation-driven knowledge and schema-constrained synthetic data, addressing the issue of data scarcity; and (2) a two-stage pre-training strategy combining Masked Span Language Modeling (MSLM) and Span-Level Contrastive Learning (SCL) to enhance relational reasoning and generalization. Together, these components enable TKRE to effectively tackle FSRE tasks. Comprehensive experiments on benchmark datasets demonstrate the efficacy of TKRE, achieving new state-of-the-art performance in FSRE and underscoring its potential for broader application in low-resource scenarios. \\footnote{The code and data are released on https://github.com/UESTC-GQJ/TKRE.","authors":["Quanjiang Guo","Jinchuan Zhang","Sijie Wang","Ling Tian","Zhao Kang","Bin Yan","Weidong Xiao"],"url":"https://arxiv.org/abs/2505.12236"}
{"created":"2025-05-20","title":"From Shots to Stories: LLM-Assisted Video Editing with Unified Language Representations","abstract":"Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated remarkable reasoning and generalization capabilities in video understanding; however, their application in video editing remains largely underexplored. This paper presents the first systematic study of LLMs in the context of video editing. To bridge the gap between visual information and language-based reasoning, we introduce L-Storyboard, an intermediate representation that transforms discrete video shots into structured language descriptions suitable for LLM processing. We categorize video editing tasks into Convergent Tasks and Divergent Tasks, focusing on three core tasks: Shot Attributes Classification, Next Shot Selection, and Shot Sequence Ordering. To address the inherent instability of divergent task outputs, we propose the StoryFlow strategy, which converts the divergent multi-path reasoning process into a convergent selection mechanism, effectively enhancing task accuracy and logical coherence. Experimental results demonstrate that L-Storyboard facilitates a more robust mapping between visual information and language descriptions, significantly improving the interpretability and privacy protection of video editing tasks. Furthermore, StoryFlow enhances the logical consistency and output stability in Shot Sequence Ordering, underscoring the substantial potential of LLMs in intelligent video editing.","authors":["Yuzhi Li","Haojun Xu","Fang Tian"],"url":"https://arxiv.org/abs/2505.12237"}
{"created":"2025-05-20","title":"PANORAMA: A synthetic PII-laced dataset for studying sensitive data memorization in LLMs","abstract":"The memorization of sensitive and personally identifiable information (PII) by large language models (LLMs) poses growing privacy risks as models scale and are increasingly deployed in real-world applications. Existing efforts to study sensitive and PII data memorization and develop mitigation strategies are hampered by the absence of comprehensive, realistic, and ethically sourced datasets reflecting the diversity of sensitive information found on the web. We introduce PANORAMA - Profile-based Assemblage for Naturalistic Online Representation and Attribute Memorization Analysis, a large-scale synthetic corpus of 384,789 samples derived from 9,674 synthetic profiles designed to closely emulate the distribution, variety, and context of PII and sensitive data as it naturally occurs in online environments. Our data generation pipeline begins with the construction of internally consistent, multi-attribute human profiles using constrained selection to reflect real-world demographics such as education, health attributes, financial status, etc. Using a combination of zero-shot prompting and OpenAI o3-mini, we generate diverse content types - including wiki-style articles, social media posts, forum discussions, online reviews, comments, and marketplace listings - each embedding realistic, contextually appropriate PII and other sensitive information. We validate the utility of PANORAMA by fine-tuning the Mistral-7B model on 1x, 5x, 10x, and 25x data replication rates with a subset of data and measure PII memorization rates - revealing not only consistent increases with repetition but also variation across content types, highlighting PANORAMA's ability to model how memorization risks differ by context. Our dataset and code are publicly available, providing a much-needed resource for privacy risk assessment, model auditing, and the development of privacy-preserving LLMs.","authors":["Sriram Selvam","Anneswa Ghosh"],"url":"https://arxiv.org/abs/2505.12238"}
{"created":"2025-05-20","title":"ACU: Analytic Continual Unlearning for Efficient and Exact Forgetting with Privacy Preservation","abstract":"The development of artificial intelligence demands that models incrementally update knowledge by Continual Learning (CL) to adapt to open-world environments. To meet privacy and security requirements, Continual Unlearning (CU) emerges as an important problem, aiming to sequentially forget particular knowledge acquired during the CL phase. However, existing unlearning methods primarily focus on single-shot joint forgetting and face significant limitations when applied to CU. First, most existing methods require access to the retained dataset for re-training or fine-tuning, violating the inherent constraint in CL that historical data cannot be revisited. Second, these methods often suffer from a poor trade-off between system efficiency and model fidelity, making them vulnerable to being overwhelmed or degraded by adversaries through deliberately frequent requests. In this paper, we identify that the limitations of existing unlearning methods stem fundamentally from their reliance on gradient-based updates. To bridge the research gap at its root, we propose a novel gradient-free method for CU, named Analytic Continual Unlearning (ACU), for efficient and exact forgetting with historical data privacy preservation. In response to each unlearning request, our ACU recursively derives an analytical (i.e., closed-form) solution in an interpretable manner using the least squares method. Theoretical and experimental evaluations validate the superiority of our ACU on unlearning effectiveness, model fidelity, and system efficiency.","authors":["Jianheng Tang","Huiping Zhuang","Di Fang","Jiaxu Li","Feijiang Han","Yajiang Huang","Kejia Fan","Leye Wang","Zhanxing Zhu","Shanghang Zhang","Houbing Herbert Song","Yunhuai Liu"],"url":"https://arxiv.org/abs/2505.12239"}
{"created":"2025-05-20","title":"ZenFlow: Enabling Stall-Free Offloading Training via Asynchronous Updates","abstract":"Fine-tuning large language models (LLMs) often exceeds GPU memory limits, prompting systems to offload model states to CPU memory. However, existing offloaded training frameworks like ZeRO-Offload treat all parameters equally and update the full model on the CPU, causing severe GPU stalls, where fast, expensive GPUs sit idle waiting for slow CPU updates and limited-bandwidth PCIe transfers.","authors":["Tingfeng Lan","Yusen Wu","Bin Ma","Zhaoyuan Su","Rui Yang","Tekin Bicer","Dong Li","Yue Cheng"],"url":"https://arxiv.org/abs/2505.12242"}
{"created":"2025-05-20","title":"Distribution Prompting: Understanding the Expressivity of Language Models Through the Next-Token Distributions They Can Produce","abstract":"Autoregressive neural language models (LMs) generate a probability distribution over tokens at each time step given a prompt. In this work, we attempt to systematically understand the probability distributions that LMs can produce, showing that some distributions are significantly harder to elicit than others. Specifically, for any target next-token distribution over the vocabulary, we attempt to find a prompt that induces the LM to output a distribution as close as possible to the target, using either soft or hard gradient-based prompt tuning. We find that (1) in general, distributions with very low or very high entropy are easier to approximate than those with moderate entropy; (2) among distributions with the same entropy, those containing ''outlier tokens'' are easier to approximate; (3) target distributions generated by LMs -- even LMs with different tokenizers -- are easier to approximate than randomly chosen targets. These results offer insights into the expressiveness of LMs and the challenges of using them as probability distribution proposers.","authors":["Haojin Wang","Zining Zhu","Freda Shi"],"url":"https://arxiv.org/abs/2505.12244"}
{"created":"2025-05-20","title":"AFCL: Analytic Federated Continual Learning for Spatio-Temporal Invariance of Non-IID Data","abstract":"Federated Continual Learning (FCL) enables distributed clients to collaboratively train a global model from online task streams in dynamic real-world scenarios. However, existing FCL methods face challenges of both spatial data heterogeneity among distributed clients and temporal data heterogeneity across online tasks. Such data heterogeneity significantly degrades the model performance with severe spatial-temporal catastrophic forgetting of local and past knowledge. In this paper, we identify that the root cause of this issue lies in the inherent vulnerability and sensitivity of gradients to non-IID data. To fundamentally address this issue, we propose a gradient-free method, named Analytic Federated Continual Learning (AFCL), by deriving analytical (i.e., closed-form) solutions from frozen extracted features. In local training, our AFCL enables single-epoch learning with only a lightweight forward-propagation process for each client. In global aggregation, the server can recursively and efficiently update the global model with single-round aggregation. Theoretical analyses validate that our AFCL achieves spatio-temporal invariance of non-IID data. This ideal property implies that, regardless of how heterogeneous the data are distributed across local clients and online tasks, the aggregated model of our AFCL remains invariant and identical to that of centralized joint learning. Extensive experiments show the consistent superiority of our AFCL over state-of-the-art baselines across various benchmark datasets and settings.","authors":["Jianheng Tang","Huiping Zhuang","Jingyu He","Run He","Jingchao Wang","Kejia Fan","Anfeng Liu","Tian Wang","Leye Wang","Zhanxing Zhu","Shanghang Zhang","Houbing Herbert Song","Yunhuai Liu"],"url":"https://arxiv.org/abs/2505.12245"}
{"created":"2025-05-20","title":"SEPT: Standard-Definition Map Enhanced Scene Perception and Topology Reasoning for Autonomous Driving","abstract":"Online scene perception and topology reasoning are critical for autonomous vehicles to understand their driving environments, particularly for mapless driving systems that endeavor to reduce reliance on costly High-Definition (HD) maps. However, recent advances in online scene understanding still face limitations, especially in long-range or occluded scenarios, due to the inherent constraints of onboard sensors. To address this challenge, we propose a Standard-Definition (SD) Map Enhanced scene Perception and Topology reasoning (SEPT) framework, which explores how to effectively incorporate the SD map as prior knowledge into existing perception and reasoning pipelines. Specifically, we introduce a novel hybrid feature fusion strategy that combines SD maps with Bird's-Eye-View (BEV) features, considering both rasterized and vectorized representations, while mitigating potential misalignment between SD maps and BEV feature spaces. Additionally, we leverage the SD map characteristics to design an auxiliary intersection-aware keypoint detection task, which further enhances the overall scene understanding performance. Experimental results on the large-scale OpenLane-V2 dataset demonstrate that by effectively integrating SD map priors, our framework significantly improves both scene perception and topology reasoning, outperforming existing methods by a substantial margin.","authors":["Muleilan Pei","Jiayao Shan","Peiliang Li","Jieqi Shi","Jing Huo","Yang Gao","Shaojie Shen"],"url":"https://arxiv.org/abs/2505.12246"}
{"created":"2025-05-20","title":"LAMeTA: Intent-Aware Agentic Network Optimization via a Large AI Model-Empowered Two-Stage Approach","abstract":"Nowadays, Generative AI (GenAI) reshapes numerous domains by enabling machines to create content across modalities. As GenAI evolves into autonomous agents capable of reasoning, collaboration, and interaction, they are increasingly deployed on network infrastructures to serve humans automatically. This emerging paradigm, known as the agentic network, presents new optimization challenges due to the demand to incorporate subjective intents of human users expressed in natural language. Traditional generic Deep Reinforcement Learning (DRL) struggles to capture intent semantics and adjust policies dynamically, thus leading to suboptimality. In this paper, we present LAMeTA, a Large AI Model (LAM)-empowered Two-stage Approach for intent-aware agentic network optimization. First, we propose Intent-oriented Knowledge Distillation (IoKD), which efficiently distills intent-understanding capabilities from resource-intensive LAMs to lightweight edge LAMs (E-LAMs) to serve end users. Second, we develop Symbiotic Reinforcement Learning (SRL), integrating E-LAMs with a policy-based DRL framework. In SRL, E-LAMs translate natural language user intents into structured preference vectors that guide both state representation and reward design. The DRL, in turn, optimizes the generative service function chain composition and E-LAM selection based on real-time network conditions, thus optimizing the subjective Quality-of-Experience (QoE). Extensive experiments conducted in an agentic network with 81 agents demonstrate that IoKD reduces mean squared error in intent prediction by up to 22.5%, while SRL outperforms conventional generic DRL by up to 23.5% in maximizing intent-aware QoE.","authors":["Yinqiu Liu","Guangyuan Liu","Jiacheng Wang","Ruichen Zhang","Dusit Niyato","Geng Sun","Zehui Xiong","Zhu Han"],"url":"https://arxiv.org/abs/2505.12247"}
{"created":"2025-05-20","title":"Persuasion and Safety in the Era of Generative AI","abstract":"As large language models (LLMs) achieve advanced persuasive capabilities, concerns about their potential risks have grown. The EU AI Act prohibits AI systems that use manipulative or deceptive techniques to undermine informed decision-making, highlighting the need to distinguish between rational persuasion, which engages reason, and manipulation, which exploits cognitive biases. My dissertation addresses the lack of empirical studies in this area by developing a taxonomy of persuasive techniques, creating a human-annotated dataset, and evaluating LLMs' ability to distinguish between these methods. This work contributes to AI safety by providing resources to mitigate the risks of persuasive AI and fostering discussions on ethical persuasion in the age of generative AI.","authors":["Haein Kong"],"url":"https://arxiv.org/abs/2505.12248"}
{"created":"2025-05-20","title":"Not All Documents Are What You Need for Extracting Instruction Tuning Data","abstract":"Instruction tuning improves the performance of large language models (LLMs), but it heavily relies on high-quality training data. Recently, LLMs have been used to synthesize instruction data using seed question-answer (QA) pairs. However, these synthesized instructions often lack diversity and tend to be similar to the input seeds, limiting their applicability in real-world scenarios. To address this, we propose extracting instruction tuning data from web corpora that contain rich and diverse knowledge. A naive solution is to retrieve domain-specific documents and extract all QA pairs from them, but this faces two key challenges: (1) extracting all QA pairs using LLMs is prohibitively expensive, and (2) many extracted QA pairs may be irrelevant to the downstream tasks, potentially degrading model performance. To tackle these issues, we introduce EQUAL, an effective and scalable data extraction framework that iteratively alternates between document selection and high-quality QA pair extraction to enhance instruction tuning. EQUAL first clusters the document corpus based on embeddings derived from contrastive learning, then uses a multi-armed bandit strategy to efficiently identify clusters that are likely to contain valuable QA pairs. This iterative approach significantly reduces computational cost while boosting model performance. Experiments on AutoMathText and StackOverflow across four downstream tasks show that EQUAL reduces computational costs by 5-10x and improves accuracy by 2.5 percent on LLaMA-3.1-8B and Mistral-7B","authors":["Chi Zhang","Huaping Zhong","Hongtao Li","Chengliang Chai","Jiawei Hong","Yuhao Deng","Jiacheng Wang","Tian Tan","Yizhou Yan","Jiantao Qiu","Ye Yuan","Guoren Wang","Conghui He","Lei Cao"],"url":"https://arxiv.org/abs/2505.12250"}
{"created":"2025-05-20","title":"SMFusion: Semantic-Preserving Fusion of Multimodal Medical Images for Enhanced Clinical Diagnosis","abstract":"Multimodal medical image fusion plays a crucial role in medical diagnosis by integrating complementary information from different modalities to enhance image readability and clinical applicability. However, existing methods mainly follow computer vision standards for feature extraction and fusion strategy formulation, overlooking the rich semantic information inherent in medical images. To address this limitation, we propose a novel semantic-guided medical image fusion approach that, for the first time, incorporates medical prior knowledge into the fusion process. Specifically, we construct a publicly available multimodal medical image-text dataset, upon which text descriptions generated by BiomedGPT are encoded and semantically aligned with image features in a high-dimensional space via a semantic interaction alignment module. During this process, a cross attention based linear transformation automatically maps the relationship between textual and visual features to facilitate comprehensive learning. The aligned features are then embedded into a text-injection module for further feature-level fusion. Unlike traditional methods, we further generate diagnostic reports from the fused images to assess the preservation of medical information. Additionally, we design a medical semantic loss function to enhance the retention of textual cues from the source images. Experimental results on test datasets demonstrate that the proposed method achieves superior performance in both qualitative and quantitative evaluations while preserving more critical medical information.","authors":["Haozhe Xiang","Han Zhang","Yu Cheng","Xiongwen Quan","Wanwan Huang"],"url":"https://arxiv.org/abs/2505.12251"}
{"created":"2025-05-20","title":"SchoenbAt: Rethinking Attention with Polynomial basis","abstract":"Kernelized attention extends the attention mechanism by modeling sequence correlations through kernel functions, making significant progresses in optimizing attention. Under the guarantee of harmonic analysis theory, kernel functions can be expanded with basis functions, inspiring random feature-based approaches to enhance the efficiency of kernelized attention while maintaining predictive performance. However, current random feature-based works are limited to the Fourier basis expansions under Bochner's theorem. We propose Schoenberg's theorem-based attention (SchoenbAt), which approximates dot-product kernelized attention with the polynomial basis under Schoenberg's theorem via random Maclaurin features and applies a two-stage regularization to constrain the input space and restore the output scale, acting as a drop-in replacement of dot-product kernelized attention. Our theoretical proof of the unbiasedness and concentration error bound of SchoenbAt supports its efficiency and accuracy as a kernelized attention approximation, which is also empirically validated under various random feature dimensions. Evaluations on real-world datasets demonstrate that SchoenbAt significantly enhances computational speed while preserving competitive performance in terms of precision, outperforming several efficient attention methods.","authors":["Yuhan Guo","Lizhong Ding","Yuwan Yang","Xuewei Guo"],"url":"https://arxiv.org/abs/2505.12252"}
{"created":"2025-05-20","title":"LLaVA-4D: Embedding SpatioTemporal Prompt into LMMs for 4D Scene Understanding","abstract":"Despite achieving significant progress in 2D image understanding, large multimodal models (LMMs) struggle in the physical world due to the lack of spatial representation. Typically, existing 3D LMMs mainly embed 3D positions as fixed spatial prompts within visual features to represent the scene. However, these methods are limited to understanding the static background and fail to capture temporally varying dynamic objects. In this paper, we propose LLaVA-4D, a general LMM framework with a novel spatiotemporal prompt for visual representation in 4D scene understanding. The spatiotemporal prompt is generated by encoding 3D position and 1D time into a dynamic-aware 4D coordinate embedding. Moreover, we demonstrate that spatial and temporal components disentangled from visual features are more effective in distinguishing the background from objects. This motivates embedding the 4D spatiotemporal prompt into these features to enhance the dynamic scene representation. By aligning visual spatiotemporal embeddings with language embeddings, LMMs gain the ability to understand both spatial and temporal characteristics of static background and dynamic objects in the physical world. Additionally, we construct a 4D vision-language dataset with spatiotemporal coordinate annotations for instruction fine-tuning LMMs. Extensive experiments have been conducted to demonstrate the effectiveness of our method across different tasks in 4D scene understanding.","authors":["Hanyu Zhou","Gim Hee Lee"],"url":"https://arxiv.org/abs/2505.12253"}
{"created":"2025-05-20","title":"MMS-VPR: Multimodal Street-Level Visual Place Recognition Dataset and Benchmark","abstract":"Existing visual place recognition (VPR) datasets predominantly rely on vehicle-mounted imagery, lack multimodal diversity and underrepresent dense, mixed-use street-level spaces, especially in non-Western urban contexts. To address these gaps, we introduce MMS-VPR, a large-scale multimodal dataset for street-level place recognition in complex, pedestrian-only environments. The dataset comprises 78,575 annotated images and 2,512 video clips captured across 207 locations in a ~70,800 $\\mathrm{m}^2$ open-air commercial district in Chengdu, China. Each image is labeled with precise GPS coordinates, timestamp, and textual metadata, and covers varied lighting conditions, viewpoints, and timeframes. MMS-VPR follows a systematic and replicable data collection protocol with minimal device requirements, lowering the barrier for scalable dataset creation. Importantly, the dataset forms an inherent spatial graph with 125 edges, 81 nodes, and 1 subgraph, enabling structure-aware place recognition. We further define two application-specific subsets -- Dataset_Edges and Dataset_Points -- to support fine-grained and graph-based evaluation tasks. Extensive benchmarks using conventional VPR models, graph neural networks, and multimodal baselines show substantial improvements when leveraging multimodal and structural cues. MMS-VPR facilitates future research at the intersection of computer vision, geospatial understanding, and multimodal reasoning. The dataset is publicly available at https://huggingface.co/datasets/Yiwei-Ou/MMS-VPR.","authors":["Yiwei Ou","Xiaobin Ren","Ronggui Sun","Guansong Gao","Ziyi Jiang","Kaiqi Zhao","Manfredo Manfredini"],"url":"https://arxiv.org/abs/2505.12254"}
{"created":"2025-05-20","title":"TPM2.0-Supported Runtime Customizable TEE on FPGA-SoC with User-Controllable vTPM","abstract":"Constructing a Trusted Execution Environment (TEE) on Field Programmable Gate Array System on Chip (FPGA-SoC) in Cloud can effectively protect users' private intel-lectual Property (IP) cores. In order to facilitate the wide-spread deployment of FPGA-SoC TEE, this paper proposes an approach for constructing a TPM 2.0-compatible runtime customizable TEE on FPGA-SoC. This approach leverages a user-controllable virtual Trusted Platform Module (vTPM) that integrates sensitive operations specific to FPGA-SoC TEE. It provides TPM 2.0 support for a customizable FPGA-SoC TEE to dynamically measure, deploy, and invoke IP during runtime. Our main contributions include: (i) Propose an FPGA-vTPM architecture that enables the TPM 2.0 specification support for FPGA-SoC TEE; (ii) Explore the utilization of FPGA-vTPM to dynamically measure, deploy, and invoke users' IPs on FPGA-SoC TEE; (iii) Extend the TPM command set to accommodate the sensitive operations of FPGA-SoC TEE, enabling users to perform sensitive tasks in a secure and verifiable manner according to the TPM 2.0 specification. We implement a prototype of TRCTEE on the Xilinx Zynq UltraScale+ MPSoC platform and conducted security analysis and performance evaluations to prove the practicality and enhanced security features of this approach.","authors":["Jingkai Mao","Xiaolin Chang"],"url":"https://arxiv.org/abs/2505.12256"}
{"created":"2025-05-20","title":"LLM Context Conditioning and PWP Prompting for Multimodal Validation of Chemical Formulas","abstract":"Identifying subtle technical errors within complex scientific and technical documents, especially those requiring multimodal interpretation (e.g., formulas in images), presents a significant hurdle for Large Language Models (LLMs) whose inherent error-correction tendencies can mask inaccuracies. This exploratory proof-of-concept (PoC) study investigates structured LLM context conditioning, informed by Persistent Workflow Prompting (PWP) principles, as a methodological strategy to modulate this LLM behavior at inference time. The approach is designed to enhance the reliability of readily available, general-purpose LLMs (specifically Gemini 2.5 Pro and ChatGPT Plus o3) for precise validation tasks, crucially relying only on their standard chat interfaces without API access or model modifications. To explore this methodology, we focused on validating chemical formulas within a single, complex test paper with known textual and image-based errors. Several prompting strategies were evaluated: while basic prompts proved unreliable, an approach adapting PWP structures to rigorously condition the LLM's analytical mindset appeared to improve textual error identification with both models. Notably, this method also guided Gemini 2.5 Pro to repeatedly identify a subtle image-based formula error previously overlooked during manual review, a task where ChatGPT Plus o3 failed in our tests. These preliminary findings highlight specific LLM operational modes that impede detail-oriented validation and suggest that PWP-informed context conditioning offers a promising and highly accessible technique for developing more robust LLM-driven analytical workflows, particularly for tasks requiring meticulous error detection in scientific and technical documents. Extensive validation beyond this limited PoC is necessary to ascertain broader applicability.","authors":["Evgeny Markhasin"],"url":"https://arxiv.org/abs/2505.12257"}
{"created":"2025-05-20","title":"An Information-Theoretic Framework for Receiver Quantization in Communication","abstract":"We investigate information-theoretic limits and design of communication under receiver quantization. Unlike most existing studies, this work is more focused on the impact of resolution reduction from high to low. We consider a standard transceiver architecture, which includes i.i.d. complex Gaussian codebook at the transmitter, and a symmetric quantizer cascaded with a nearest neighbor decoder at the receiver. Employing the generalized mutual information (GMI), an achievable rate under general quantization rules is obtained in an analytical form, which shows that the rate loss due to quantization is $\\log\\left(1+\\gamma\\mathsf{SNR}\\right)$, where $\\gamma$ is determined by thresholds and levels of the quantizer. Based on this result, the performance under uniform receiver quantization is analyzed comprehensively. We show that the front-end gain control, which determines the loading factor of quantization, has an increasing impact on performance as the resolution decreases. In particular, we prove that the unique loading factor that minimizes the MSE also maximizes the GMI, and the corresponding irreducible rate loss is given by $\\log\\left(1+\\mathsf {mmse}\\cdot\\mathsf{SNR}\\right)$, where mmse is the minimum MSE normalized by the variance of quantizer input, and is equal to the minimum of $\\gamma$. A geometrical interpretation for the optimal uniform quantization at the receiver is further established. Moreover, by asymptotic analysis, we characterize the impact of biased gain control, including how small rate losses decay to zero and achievable rate approximations under large bias. From asymptotic expressions of the optimal loading factor and mmse, approximations and several per-bit rules for performance are also provided. Finally we discuss more types of receiver quantization and show that the consistency between achievable rate maximization and MSE minimization does not hold in general.","authors":["Jing Zhou","Shuqin Pang","Wenyi Zhang"],"url":"https://arxiv.org/abs/2505.12258"}
{"created":"2025-05-20","title":"Teach2Eval: An Indirect Evaluation Method for LLM by Judging How It Teaches","abstract":"Recent progress in large language models (LLMs) has outpaced the development of effective evaluation methods. Traditional benchmarks rely on task-specific metrics and static datasets, which often suffer from fairness issues, limited scalability, and contamination risks. In this paper, we introduce Teach2Eval, an indirect evaluation framework inspired by the Feynman Technique. Instead of directly testing LLMs on predefined tasks, our method evaluates a model's multiple abilities to teach weaker student models to perform tasks effectively. By converting open-ended tasks into standardized multiple-choice questions (MCQs) through teacher-generated feedback, Teach2Eval enables scalable, automated, and multi-dimensional assessment. Our approach not only avoids data leakage and memorization but also captures a broad range of cognitive abilities that are orthogonal to current benchmarks. Experimental results across 26 leading LLMs show strong alignment with existing human and model-based dynamic rankings, while offering additional interpretability for training guidance.","authors":["Yuhang Zhou","Xutian Chen","Yixin Cao","Yuchen Ni","Yu He","Siyu Tian","Xiang Liu","Jian Zhang","Chuanjun Ji","Guangnan Ye","Xipeng Qiu"],"url":"https://arxiv.org/abs/2505.12259"}
{"created":"2025-05-20","title":"LightRetriever: A LLM-based Hybrid Retrieval Architecture with 1000x Faster Query Inference","abstract":"Large Language Models (LLMs)-based hybrid retrieval uses LLMs to encode queries and documents into low-dimensional dense or high-dimensional sparse vectors. It retrieves documents relevant to search queries based on vector similarities. Documents are pre-encoded offline, while queries arrive in real-time, necessitating an efficient online query encoder. Although LLMs significantly enhance retrieval capabilities, serving deeply parameterized LLMs slows down query inference throughput and increases demands for online deployment resources. In this paper, we propose LightRetriever, a novel LLM-based hybrid retriever with extremely lightweight query encoders. Our method retains a full-sized LLM for document encoding, but reduces the workload of query encoding to no more than an embedding lookup. Compared to serving a full-sized LLM on an H800 GPU, our approach achieves over a 1000x speedup for query inference with GPU acceleration, and even a 20x speedup without GPU. Experiments on large-scale retrieval benchmarks demonstrate that our method generalizes well across diverse retrieval tasks, retaining an average of 95% full-sized performance.","authors":["Guangyuan Ma","Yongliang Ma","Xuanrui Gou","Zhenpeng Su","Ming Zhou","Songlin Hu"],"url":"https://arxiv.org/abs/2505.12260"}
{"created":"2025-05-20","title":"Vision to Specification: Automating the Transition from Conceptual Features to Functional Requirements","abstract":"The translation of high-level abstract features into clear, and testable functional requirements (FRs) is a crucial step in software development, bridging the gap between user needs and technical specifications. In engineering practice, significant expert effort is needed for this translation. Our approach, EasyFR, streamlines the process by recommending Semantic Role Labeling (SRL) sequences for the given abstract features to guide Pre-trained Language Models (PLMs) in producing cohesive FR statements. By analyzing ten diverse datasets, we induce two variable SRL templates, each including two configurable parts. For concrete features, our proposed Key2Temp model can construct the appropriate variant of the SRL template by identifying a variable SRL template and placing the feature tokens in the appropriate slots. In this way, our approach reframes the process of requirement generation into a structured slot-filling activity. Experimental validation on four open datasets demonstrates that EasyFR outperforms three advanced Natural language generation (NLG) approaches, including GPT4, particularly when existing FRs are available for training. The positive influence of our SRL template variant recommendations is further confirmed through an ablation study. We believe that our results indicate a notable step forward in the realm of automated requirements synthesis, holding potential to improve the process of requirements specification in future software projects.","authors":["Xiaoli Lian","Jiajun Wu","Xiaoyun Gao","Shuaisong Wang","Li Zhang"],"url":"https://arxiv.org/abs/2505.12262"}
{"created":"2025-05-20","title":"Learning Auxiliary Tasks Improves Reference-Free Hallucination Detection in Open-Domain Long-Form Generation","abstract":"Hallucination, the generation of factually incorrect information, remains a significant challenge for large language models (LLMs), especially in open-domain long-form generation. Existing approaches for detecting hallucination in long-form tasks either focus on limited domains or rely heavily on external fact-checking tools, which may not always be available.","authors":["Chengwei Qin","Wenxuan Zhou","Karthik Abinav Sankararaman","Nanshu Wang","Tengyu Xu","Alexander Radovic","Eryk Helenowski","Arya Talebzadeh","Aditya Tayade","Sinong Wang","Shafiq Joty","Han Fang","Hao Ma"],"url":"https://arxiv.org/abs/2505.12265"}
{"created":"2025-05-20","title":"PMQ-VE: Progressive Multi-Frame Quantization for Video Enhancement","abstract":"Multi-frame video enhancement tasks aim to improve the spatial and temporal resolution and quality of video sequences by leveraging temporal information from multiple frames, which are widely used in streaming video processing, surveillance, and generation. Although numerous Transformer-based enhancement methods have achieved impressive performance, their computational and memory demands hinder deployment on edge devices. Quantization offers a practical solution by reducing the bit-width of weights and activations to improve efficiency. However, directly applying existing quantization methods to video enhancement tasks often leads to significant performance degradation and loss of fine details. This stems from two limitations: (a) inability to allocate varying representational capacity across frames, which results in suboptimal dynamic range adaptation; (b) over-reliance on full-precision teachers, which limits the learning of low-bit student models. To tackle these challenges, we propose a novel quantization method for video enhancement: Progressive Multi-Frame Quantization for Video Enhancement (PMQ-VE). This framework features a coarse-to-fine two-stage process: Backtracking-based Multi-Frame Quantization (BMFQ) and Progressive Multi-Teacher Distillation (PMTD). BMFQ utilizes a percentile-based initialization and iterative search with pruning and backtracking for robust clipping bounds. PMTD employs a progressive distillation strategy with both full-precision and multiple high-bit (INT) teachers to enhance low-bit models' capacity and quality. Extensive experiments demonstrate that our method outperforms existing approaches, achieving state-of-the-art performance across multiple tasks and benchmarks.The code will be made publicly available at: https://github.com/xiaoBIGfeng/PMQ-VE.","authors":["ZhanFeng Feng","Long Peng","Xin Di","Yong Guo","Wenbo Li","Yulun Zhang","Renjing Pei","Yang Wang","Yang Cao","Zheng-Jun Zha"],"url":"https://arxiv.org/abs/2505.12266"}
{"created":"2025-05-20","title":"Real-Time Spatial Reasoning by Mobile Robots for Reconstruction and Navigation in Dynamic LiDAR Scenes","abstract":"Our brain has an inner global positioning system which enables us to sense and navigate 3D spaces in real time. Can mobile robots replicate such a biological feat in a dynamic environment? We introduce the first spatial reasoning framework for real-time surface reconstruction and navigation that is designed for outdoor LiDAR scanning data captured by ground mobile robots and capable of handling moving objects such as pedestrians. Our reconstruction-based approach is well aligned with the critical cellular functions performed by the border vector cells (BVCs) over all layers of the medial entorhinal cortex (MEC) for surface sensing and tracking. To address the challenges arising from blurred boundaries resulting from sparse single-frame LiDAR points and outdated data due to object movements, we integrate real-time single-frame mesh reconstruction, via visibility reasoning, with robot navigation assistance through on-the-fly 3D free space determination. This enables continuous and incremental updates of the scene and free space across multiple frames. Key to our method is the utilization of line-of-sight (LoS) vectors from LiDAR, which enable real-time surface normal estimation, as well as robust and instantaneous per-voxel free space updates. We showcase two practical applications: real-time 3D scene reconstruction and autonomous outdoor robot navigation in real-world conditions. Comprehensive experiments on both synthetic and real scenes highlight our method's superiority in speed and quality over existing real-time LiDAR processing approaches.","authors":["Pengdi Huang","Mingyang Wang","Huan Tian","Minglun Gong","Hao Zhang","Hui Huang"],"url":"https://arxiv.org/abs/2505.12267"}
{"created":"2025-05-20","title":"$K$-MSHC: Unmasking Minimally Sufficient Head Circuits in Large Language Models with Experiments on Syntactic Classification Tasks","abstract":"Understanding which neural components drive specific capabilities in mid-sized language models ($\\leq$10B parameters) remains a key challenge. We introduce the $(\\bm{K}, \\epsilon)$-Minimum Sufficient Head Circuit ($K$-MSHC), a methodology to identify minimal sets of attention heads crucial for classification tasks as well as Search-K-MSHC, an efficient algorithm for discovering these circuits. Applying our Search-K-MSHC algorithm to Gemma-9B, we analyze three syntactic task families: grammar acceptability, arithmetic verification, and arithmetic word problems. Our findings reveal distinct task-specific head circuits, with grammar tasks predominantly utilizing early layers, word problems showing pronounced activity in both shallow and deep regions, and arithmetic verification demonstrating a more distributed pattern across the network. We discover non-linear circuit overlap patterns, where different task pairs share computational components at varying levels of importance. While grammar and arithmetic share many \"weak\" heads, arithmetic and word problems share more consistently critical \"strong\" heads. Importantly, we find that each task maintains dedicated \"super-heads\" with minimal cross-task overlap, suggesting that syntactic and numerical competencies emerge from specialized yet partially reusable head circuits.","authors":["Pratim Chowdhary"],"url":"https://arxiv.org/abs/2505.12268"}
{"created":"2025-05-20","title":"Enhancing Knowledge Graph Completion with GNN Distillation and Probabilistic Interaction Modeling","abstract":"Knowledge graphs (KGs) serve as fundamental structures for organizing interconnected data across diverse domains. However, most KGs remain incomplete, limiting their effectiveness in downstream applications. Knowledge graph completion (KGC) aims to address this issue by inferring missing links, but existing methods face critical challenges: deep graph neural networks (GNNs) suffer from over-smoothing, while embedding-based models fail to capture abstract relational features. This study aims to overcome these limitations by proposing a unified framework that integrates GNN distillation and abstract probabilistic interaction modeling (APIM). GNN distillation approach introduces an iterative message-feature filtering process to mitigate over-smoothing, preserving the discriminative power of node representations. APIM module complements this by learning structured, abstract interaction patterns through probabilistic signatures and transition matrices, allowing for a richer, more flexible representation of entity and relation interactions. We apply these methods to GNN-based models and the APIM to embedding-based KGC models, conducting extensive evaluations on the widely used WN18RR and FB15K-237 datasets. Our results demonstrate significant performance gains over baseline models, showcasing the effectiveness of the proposed techniques. The findings highlight the importance of both controlling information propagation and leveraging structured probabilistic modeling, offering new avenues for advancing knowledge graph completion. And our codes are available at https://anonymous.4open.science/r/APIM_and_GNN-Distillation-461C.","authors":["Lingzhi Wang","Pengcheng Huang","Haotian Li","Yuliang Wei","Guodong Xin","Rui Zhang","Donglin Zhang","Zhenzhou Ji","Wei Wang"],"url":"https://arxiv.org/abs/2505.12272"}
{"created":"2025-05-20","title":"LLM-Based Evaluation of Low-Resource Machine Translation: A Reference-less Dialect Guided Approach with a Refined Sylheti-English Benchmark","abstract":"Evaluating machine translation (MT) for low-resource languages poses a persistent challenge, primarily due to the limited availability of high quality reference translations. This issue is further exacerbated in languages with multiple dialects, where linguistic diversity and data scarcity hinder robust evaluation. Large Language Models (LLMs) present a promising solution through reference-free evaluation techniques; however, their effectiveness diminishes in the absence of dialect-specific context and tailored guidance. In this work, we propose a comprehensive framework that enhances LLM-based MT evaluation using a dialect guided approach. We extend the ONUBAD dataset by incorporating Sylheti-English sentence pairs, corresponding machine translations, and Direct Assessment (DA) scores annotated by native speakers. To address the vocabulary gap, we augment the tokenizer vocabulary with dialect-specific terms. We further introduce a regression head to enable scalar score prediction and design a dialect-guided (DG) prompting strategy. Our evaluation across multiple LLMs shows that the proposed pipeline consistently outperforms existing methods, achieving the highest gain of +0.1083 in Spearman correlation, along with improvements across other evaluation settings. The dataset and the code are available at https://github.com/180041123-Atiq/MTEonLowResourceLanguage.","authors":["Md. Atiqur Rahman","Sabrina Islam","Mushfiqul Haque Omi"],"url":"https://arxiv.org/abs/2505.12273"}
{"created":"2025-05-20","title":"Context-Aware Autoregressive Models for Multi-Conditional Image Generation","abstract":"Autoregressive transformers have recently shown impressive image generation quality and efficiency on par with state-of-the-art diffusion models. Unlike diffusion architectures, autoregressive models can naturally incorporate arbitrary modalities into a single, unified token sequence--offering a concise solution for multi-conditional image generation tasks. In this work, we propose $\\textbf{ContextAR}$, a flexible and effective framework for multi-conditional image generation. ContextAR embeds diverse conditions (e.g., canny edges, depth maps, poses) directly into the token sequence, preserving modality-specific semantics. To maintain spatial alignment while enhancing discrimination among different condition types, we introduce hybrid positional encodings that fuse Rotary Position Embedding with Learnable Positional Embedding. We design Conditional Context-aware Attention to reduces computational complexity while preserving effective intra-condition perception. Without any fine-tuning, ContextAR supports arbitrary combinations of conditions during inference time. Experimental results demonstrate the powerful controllability and versatility of our approach, and show that the competitive perpormance than diffusion-based multi-conditional control approaches the existing autoregressive baseline across diverse multi-condition driven scenarios. Project page: $\\href{https://context-ar.github.io/}{https://context-ar.github.io/.}$","authors":["Yixiao Chen","Zhiyuan Ma","Guoli Jia","Che Jiang","Jianjun Li","Bowen Zhou"],"url":"https://arxiv.org/abs/2505.12274"}
{"created":"2025-05-20","title":"Curriculum Abductive Learning","abstract":"Abductive Learning (ABL) integrates machine learning with logical reasoning in a loop: a learning model predicts symbolic concept labels from raw inputs, which are revised through abduction using domain knowledge and then fed back for retraining. However, due to the nondeterminism of abduction, the training process often suffers from instability, especially when the knowledge base is large and complex, resulting in a prohibitively large abduction space. While prior works focus on improving candidate selection within this space, they typically treat the knowledge base as a static black box. In this work, we propose Curriculum Abductive Learning (C-ABL), a method that explicitly leverages the internal structure of the knowledge base to address the ABL training challenges. C-ABL partitions the knowledge base into a sequence of sub-bases, progressively introduced during training. This reduces the abduction space throughout training and enables the model to incorporate logic in a stepwise, smooth way. Experiments across multiple tasks show that C-ABL outperforms previous ABL implementations, significantly improves training stability, convergence speed, and final accuracy, especially under complex knowledge setting.","authors":["Wen-Chao Hu","Qi-Jie Li","Lin-Han Jia","Cunjing Ge","Yu-Feng Li","Yuan Jiang","Zhi-Hua Zhou"],"url":"https://arxiv.org/abs/2505.12275"}
{"created":"2025-05-20","title":"Community detection of hypergraphs by Ricci flow","abstract":"Community detection in hypergraphs is both instrumental for functional module identification and intricate due to higher-order interactions among nodes. We define a hypergraph Ricci flow that directly operates on higher-order interactions of hypergraphs and prove long-time existence of the flow. Building on this theoretical foundation, we develop HyperRCD-a Ricci-flow-based community detection approach that deforms hyperedge weights through curvature-driven evolution, which provides an effective mathematical representation of higher-order interactions mediated by weighted hyperedges between nodes. Extensive experiments on both synthetic and real-world hypergraphs demonstrate that HyperRCD exhibits remarkable enhanced robustness to topological variations and competitive performance across diverse datasets.","authors":["Yulu Tian","Jicheng Ma","Yunyan Yang","Liang Zhao"],"url":"https://arxiv.org/abs/2505.12276"}
{"created":"2025-05-20","title":"Emergent Active Perception and Dexterity of Simulated Humanoids from Visual Reinforcement Learning","abstract":"Human behavior is fundamentally shaped by visual perception -- our ability to interact with the world depends on actively gathering relevant information and adapting our movements accordingly. Behaviors like searching for objects, reaching, and hand-eye coordination naturally emerge from the structure of our sensory system. Inspired by these principles, we introduce Perceptive Dexterous Control (PDC), a framework for vision-driven dexterous whole-body control with simulated humanoids. PDC operates solely on egocentric vision for task specification, enabling object search, target placement, and skill selection through visual cues, without relying on privileged state information (e.g., 3D object positions and geometries). This perception-as-interface paradigm enables learning a single policy to perform multiple household tasks, including reaching, grasping, placing, and articulated object manipulation. We also show that training from scratch with reinforcement learning can produce emergent behaviors such as active search. These results demonstrate how vision-driven control and complex tasks induce human-like behaviors and can serve as the key ingredients in closing the perception-action loop for animation, robotics, and embodied AI.","authors":["Zhengyi Luo","Chen Tessler","Toru Lin","Ye Yuan","Tairan He","Wenli Xiao","Yunrong Guo","Gal Chechik","Kris Kitani","Linxi Fan","Yuke Zhu"],"url":"https://arxiv.org/abs/2505.12278"}
{"created":"2025-05-20","title":"A Survey on Side Information-driven Session-based Recommendation: From a Data-centric Perspective","abstract":"Session-based recommendation is gaining increasing attention due to its practical value in predicting the intents of anonymous users based on limited behaviors. Emerging efforts incorporate various side information to alleviate inherent data scarcity issues in this task, leading to impressive performance improvements. The core of side information-driven session-based recommendation is the discovery and utilization of diverse data. In this survey, we provide a comprehensive review of this task from a data-centric perspective. Specifically, this survey commences with a clear formulation of the task. This is followed by a detailed exploration of various benchmarks rich in side information that are pivotal for advancing research in this field. Afterwards, we delve into how different types of side information enhance the task, underscoring data characteristics and utility. Moreover, we discuss the usage of various side information, including data encoding, data injection, and involved techniques. A systematic review of research progress is then presented, with the taxonomy by the types of side information. Finally, we summarize the current limitations and present the future prospects of this vibrant topic.","authors":["Xiaokun Zhang","Bo Xu","Chenliang Li","Bowei He","Hongfei Lin","Chen Ma","Fenglong Ma"],"url":"https://arxiv.org/abs/2505.12279"}
{"created":"2025-05-20","title":"Temporal-Spectral-Spatial Unified Remote Sensing Dense Prediction","abstract":"The proliferation of diverse remote sensing data has spurred advancements in dense prediction tasks, yet significant challenges remain in handling data heterogeneity. Remote sensing imagery exhibits substantial variability across temporal, spectral, and spatial (TSS) dimensions, complicating unified data processing. Current deep learning models for dense prediction tasks, such as semantic segmentation and change detection, are typically tailored to specific input-output configurations. Consequently, variations in data dimensionality or task requirements often lead to significant performance degradation or model incompatibility, necessitating costly retraining or fine-tuning efforts for different application scenarios. This paper introduces the Temporal-Spectral-Spatial Unified Network (TSSUN), a novel architecture designed for unified representation and modeling of remote sensing data across diverse TSS characteristics and task types. TSSUN employs a Temporal-Spectral-Spatial Unified Strategy that leverages meta-information to decouple and standardize input representations from varied temporal, spectral, and spatial configurations, and similarly unifies output structures for different dense prediction tasks and class numbers. Furthermore, a Local-Global Window Attention mechanism is proposed to efficiently capture both local contextual details and global dependencies, enhancing the model's adaptability and feature extraction capabilities. Extensive experiments on multiple datasets demonstrate that a single TSSUN model effectively adapts to heterogeneous inputs and unifies various dense prediction tasks. The proposed approach consistently achieves or surpasses state-of-the-art performance, highlighting its robustness and generalizability for complex remote sensing applications without requiring task-specific modifications.","authors":["Sijie Zhao","Feng Liu","Xueliang Zhang","Hao Chen","Pengfeng Xiao","Lei Bai"],"url":"https://arxiv.org/abs/2505.12280"}
{"created":"2025-05-20","title":"Bishop: Sparsified Bundling Spiking Transformers on Heterogeneous Cores with Error-Constrained Pruning","abstract":"We present Bishop, the first dedicated hardware accelerator architecture and HW/SW co-design framework for spiking transformers that optimally represents, manages, and processes spike-based workloads while exploring spatiotemporal sparsity and data reuse. Specifically, we introduce the concept of Token-Time Bundle (TTB), a container that bundles spiking data of a set of tokens over multiple time points. Our heterogeneous accelerator architecture Bishop concurrently processes workload packed in TTBs and explores intra- and inter-bundle multiple-bit weight reuse to significantly reduce memory access. Bishop utilizes a stratifier, a dense core array, and a sparse core array to process MLP blocks and projection layers. The stratifier routes high-density spiking activation workload to the dense core and low-density counterpart to the sparse core, ensuring optimized processing tailored to the given spatiotemporal sparsity level. To further reduce data access and computation, we introduce a novel Bundle Sparsity-Aware (BSA) training pipeline that enhances not only the overall but also structured TTB-level firing sparsity. Moreover, the processing efficiency of self-attention layers is boosted by the proposed Error-Constrained TTB Pruning (ECP), which trims activities in spiking queries, keys, and values both before and after the computation of spiking attention maps with a well-defined error bound. Finally, we design a reconfigurable TTB spiking attention core to efficiently compute spiking attention maps by executing highly simplified \"AND\" and \"Accumulate\" operations. On average, Bishop achieves a 5.91x speedup and 6.11x improvement in energy efficiency over previous SNN accelerators, while delivering higher accuracy across multiple datasets.","authors":["Boxun Xu","Yuxuan Yin","Vikram Iyer","Peng Li"],"url":"https://arxiv.org/abs/2505.12281"}
{"created":"2025-05-20","title":"Kernel Interpolation on Sparse Grids","abstract":"We consider scattered data approximation on product regions of equal and different dimensionality. On each of these regions, we assume quasi-uniform but unstructured data sites and construct optimal sparse grids for scattered data interpolation on the product region. For this, we derive new improved error estimates for the respective kernel interpolation error by invoking duality arguments. An efficient algorithm to solve the underlying linear system of equations is proposed. The algorithm is based on the sparse grid combination technique, where a sparse direct solver is used for the elementary anisotropic tensor product kernel interpolation problems. The application of the sparse direct solver is facilitated by applying a samplet matrix compression to each univariate kernel matrix, resulting in an essentially sparse representation of the latter. In this way, we obtain a method that is able to deal with large problems up to billions of interpolation points, especially in case of reproducing kernels of nonlocal nature. Numerical results are presented to qualify and quantify the approach.","authors":["Michael Griebel","Helmut Harbrecht","Michael Multerer"],"url":"https://arxiv.org/abs/2505.12282"}
{"created":"2025-05-20","title":"Addressing Missing Data Issue for Diffusion-based Recommendation","abstract":"Diffusion models have shown significant potential in generating oracle items that best match user preference with guidance from user historical interaction sequences. However, the quality of guidance is often compromised by unpredictable missing data in observed sequence, leading to suboptimal item generation. Since missing data is uncertain in both occurrence and content, recovering it is impractical and may introduce additional errors. To tackle this challenge, we propose a novel dual-side Thompson sampling-based Diffusion Model (TDM), which simulates extra missing data in the guidance signals and allows diffusion models to handle existing missing data through extrapolation. To preserve user preference evolution in sequences despite extra missing data, we introduce Dual-side Thompson Sampling to implement simulation with two probability models, sampling by exploiting user preference from both item continuity and sequence stability. TDM strategically removes items from sequences based on dual-side Thompson sampling and treats these edited sequences as guidance for diffusion models, enhancing models' robustness to missing data through consistency regularization. Additionally, to enhance the generation efficiency, TDM is implemented under the denoising diffusion implicit models to accelerate the reverse process. Extensive experiments and theoretical analysis validate the effectiveness of TDM in addressing missing data in sequential recommendations.","authors":["Wenyu Mao","Zhengyi Yang","Jiancan Wu","Haozhe Liu","Yancheng Yuan","Xiang Wang","Xiangnan He"],"url":"https://arxiv.org/abs/2505.12283"}
{"created":"2025-05-20","title":"Efficient RL Training for Reasoning Models via Length-Aware Optimization","abstract":"Large reasoning models, such as OpenAI o1 or DeepSeek R1, have demonstrated remarkable performance on reasoning tasks but often incur a long reasoning path with significant memory and time costs. Existing methods primarily aim to shorten reasoning paths by introducing additional training data and stages. In this paper, we propose three critical reward designs integrated directly into the reinforcement learning process of large reasoning models, which reduce the response length without extra training stages. Experiments on four settings show that our method significantly decreases response length while maintaining or even improving performance. Specifically, in a logic reasoning setting, we achieve a 40% reduction in response length averaged by steps alongside a 14% gain in performance. For math problems, we reduce response length averaged by steps by 33% while preserving performance.","authors":["Danlong Yuan","Tian Xie","Shaohan Huang","Zhuocheng Gong","Huishuai Zhang","Chong Luo","Furu Wei","Dongyan Zhao"],"url":"https://arxiv.org/abs/2505.12284"}
{"created":"2025-05-20","title":"CALM: Co-evolution of Algorithms and Language Model for Automatic Heuristic Design","abstract":"Tackling complex optimization problems often relies on expert-designed heuristics, typically crafted through extensive trial and error. Recent advances demonstrate that large language models (LLMs), when integrated into well-designed evolutionary search frameworks, can autonomously discover high-performing heuristics at a fraction of the traditional cost. However, existing approaches predominantly rely on verbal guidance, i.e., manipulating the prompt generation process, to steer the evolution of heuristics, without adapting the underlying LLM. We propose a hybrid framework that combines verbal and numerical guidance, the latter achieved by fine-tuning the LLM via reinforcement learning based on the quality of generated heuristics. This joint optimization allows the LLM to co-evolve with the search process. Our method outperforms state-of-the-art (SOTA) baselines across various optimization tasks, running locally on a single 24GB GPU using a 7B model with INT4 quantization. It surpasses methods that rely solely on verbal guidance, even when those use significantly more powerful API-based models.","authors":["Ziyao Huang","Weiwei Wu","Kui Wu","Jianping Wang","Wei-Bin Lee"],"url":"https://arxiv.org/abs/2505.12285"}
{"created":"2025-05-20","title":"The Tower of Babel Revisited: Multilingual Jailbreak Prompts on Closed-Source Large Language Models","abstract":"Large language models (LLMs) have seen widespread applications across various domains, yet remain vulnerable to adversarial prompt injections. While most existing research on jailbreak attacks and hallucination phenomena has focused primarily on open-source models, we investigate the frontier of closed-source LLMs under multilingual attack scenarios. We present a first-of-its-kind integrated adversarial framework that leverages diverse attack techniques to systematically evaluate frontier proprietary solutions, including GPT-4o, DeepSeek-R1, Gemini-1.5-Pro, and Qwen-Max. Our evaluation spans six categories of security contents in both English and Chinese, generating 38,400 responses across 32 types of jailbreak attacks. Attack success rate (ASR) is utilized as the quantitative metric to assess performance from three dimensions: prompt design, model architecture, and language environment. Our findings suggest that Qwen-Max is the most vulnerable, while GPT-4o shows the strongest defense. Notably, prompts in Chinese consistently yield higher ASRs than their English counterparts, and our novel Two-Sides attack technique proves to be the most effective across all models. This work highlights a dire need for language-aware alignment and robust cross-lingual defenses in LLMs, and we hope it will inspire researchers, developers, and policymakers toward more robust and inclusive AI systems.","authors":["Linghan Huang","Haolin Jin","Zhaoge Bi","Pengyue Yang","Peizhou Zhao","Taozhao Chen","Xiongfei Wu","Lei Ma","Huaming Chen"],"url":"https://arxiv.org/abs/2505.12287"}
{"created":"2025-05-20","title":"BOLT: Block-Orthonormal Lanczos for Trace estimation of matrix functions","abstract":"Efficient matrix trace estimation is essential for scalable computation of log-determinants, matrix norms, and distributional divergences. In many large-scale applications, the matrices involved are too large to store or access in full, making even a single matrix-vector (mat-vec) product infeasible. Instead, one often has access only to small subblocks of the matrix or localized matrix-vector products on restricted index sets. Hutch++ achieves optimal convergence rate but relies on randomized SVD and assumes full mat-vec access, making it difficult to apply in these constrained settings. We propose the Block-Orthonormal Stochastic Lanczos Quadrature (BOLT), which matches Hutch++ accuracy with a simpler implementation based on orthonormal block probes and Lanczos iterations. BOLT builds on the Stochastic Lanczos Quadrature (SLQ) framework, which combines random probing with Krylov subspace methods to efficiently approximate traces of matrix functions, and performs better than Hutch++ in near flat-spectrum regimes. To address memory limitations and partial access constraints, we introduce Subblock SLQ, a variant of BOLT that operates only on small principal submatrices. As a result, this framework yields a proxy KL divergence estimator and an efficient method for computing the Wasserstein-2 distance between Gaussians - both compatible with low-memory and partial-access regimes. We provide theoretical guarantees and demonstrate strong empirical performance across a range of high-dimensional settings.","authors":["Kingsley Yeon","Promit Ghosal","Mihai Anitescu"],"url":"https://arxiv.org/abs/2505.12289"}
{"created":"2025-05-20","title":"SIS Epidemic Modelling on Homogeneous Networked System: General Recovering Process and Mean-Field Perspective","abstract":"Although we have made progress in understanding disease spread in complex systems with non-Poissonian activity patterns, current models still fail to capture the full range of recovery time distributions. In this paper, we propose an extension of the classic susceptible-infected-susceptible (SIS) model, called the general recovering process SIS (grp-SIS) model. This model incorporates arbitrary recovery time distributions for infected nodes within the system. We derive the mean-field equations assuming a homogeneous network, provide solutions for specific recovery time distributions, and investigate the probability density function (PDF) for infection times in the system's steady state. Our findings show that recovery time distributions significantly affect disease dynamics, and we suggest several future research directions, including extending the model to arbitrary infection processes and using the quasistationary method to address deviations in numerical results.","authors":["Jiexi Tang","Yichao Yao","Meiling Xie","Minyu Feng"],"url":"https://arxiv.org/abs/2505.12290"}
{"created":"2025-05-20","title":"SpikeX: Exploring Accelerator Architecture and Network-Hardware Co-Optimization for Sparse Spiking Neural Networks","abstract":"Spiking Neural Networks (SNNs) are promising biologically plausible models of computation which utilize a spiking binary activation function similar to that of biological neurons. SNNs are well positioned to process spatiotemporal data, and are advantageous in ultra-low power and real-time processing. Despite a large body of work on conventional artificial neural network accelerators, much less attention has been given to efficient SNN hardware accelerator design. In particular, SNNs exhibit inherent unstructured spatial and temporal firing sparsity, an opportunity yet to be fully explored for great hardware processing efficiency. In this work, we propose a novel systolic-array SNN accelerator architecture, called SpikeX, to take on the challenges and opportunities stemming from unstructured sparsity while taking into account the unique characteristics of spike-based computation. By developing an efficient dataflow targeting expensive multi-bit weight data movements, SpikeX reduces memory access and increases data sharing and hardware utilization for computations spanning across both time and space, thereby significantly improving energy efficiency and inference latency. Furthermore, recognizing the importance of SNN network and hardware co-design, we develop a co-optimization methodology facilitating not only hardware-aware SNN training but also hardware accelerator architecture search, allowing joint network weight parameter optimization and accelerator architectural reconfiguration. This end-to-end network/accelerator co-design approach offers a significant reduction of 15.1x-150.87x in energy-delay-product(EDP) without comprising model accuracy.","authors":["Boxun Xu","Richard Boone","Peng Li"],"url":"https://arxiv.org/abs/2505.12292"}
{"created":"2025-05-20","title":"Hidden Sketch: A Space-Efficient Reversible Sketch for Tracking Frequent Items in Data Streams","abstract":"Modern data stream applications demand memory-efficient solutions for accurately tracking frequent items, such as heavy hitters and heavy changers, under strict resource constraints. Traditional sketches face inherent accuracy-memory trade-offs: they either lose precision to reduce memory usage or inflate memory costs to enable high recording capacity. This paper introduces Hidden Sketch, a space-efficient reversible data structure for key and frequency encoding. Our design uniquely combines a Reversible Bloom Filter (RBF) and a Count-Min (CM) Sketch for invertible key and frequency storage, enabling precise reconstruction for both keys and their frequencies with minimal memory. Theoretical analysis establishes Hidden Sketch's space complexity and guaranteed reversibility, while extensive experiments demonstrate its substantial improvements in accuracy and space efficiency in frequent item tracking tasks. By eliminating the trade-off between reversibility and space efficiency, Hidden Sketch provides a scalable foundation for real-time stream analytics in resource-constrained environments.","authors":["Zicang Xu","Yuxuan Tian","Yuhan Wu","Tong Yang"],"url":"https://arxiv.org/abs/2505.12293"}
{"created":"2025-05-20","title":"PartDexTOG: Generating Dexterous Task-Oriented Grasping via Language-driven Part Analysis","abstract":"Task-oriented grasping is a crucial yet challenging task in robotic manipulation. Despite the recent progress, few existing methods address task-oriented grasping with dexterous hands. Dexterous hands provide better precision and versatility, enabling robots to perform task-oriented grasping more effectively. In this paper, we argue that part analysis can enhance dexterous grasping by providing detailed information about the object's functionality. We propose PartDexTOG, a method that generates dexterous task-oriented grasps via language-driven part analysis. Taking a 3D object and a manipulation task represented by language as input, the method first generates the category-level and part-level grasp descriptions w.r.t the manipulation task by LLMs. Then, a category-part conditional diffusion model is developed to generate a dexterous grasp for each part, respectively, based on the generated descriptions. To select the most plausible combination of grasp and corresponding part from the generated ones, we propose a measure of geometric consistency between grasp and part. We show that our method greatly benefits from the open-world knowledge reasoning on object parts by LLMs, which naturally facilitates the learning of grasp generation on objects with different geometry and for different manipulation tasks. Our method ranks top on the OakInk-shape dataset over all previous methods, improving the Penetration Volume, the Grasp Displace, and the P-FID over the state-of-the-art by $3.58\\%$, $2.87\\%$, and $41.43\\%$, respectively. Notably, it demonstrates good generality in handling novel categories and tasks.","authors":["Weishang Wu","Yifei Shi","Zhizhong Chen","Zhipong Cai"],"url":"https://arxiv.org/abs/2505.12294"}
{"created":"2025-05-20","title":"PoLO: Proof-of-Learning and Proof-of-Ownership at Once with Chained Watermarking","abstract":"Machine learning models are increasingly shared and outsourced, raising requirements of verifying training effort (Proof-of-Learning, PoL) to ensure claimed performance and establishing ownership (Proof-of-Ownership, PoO) for transactions. When models are trained by untrusted parties, PoL and PoO must be enforced together to enable protection, attribution, and compensation. However, existing studies typically address them separately, which not only weakens protection against forgery and privacy breaches but also leads to high verification overhead.","authors":["Haiyu Deng","Yanna Jiang","Guangsheng Yu","Qin Wang","Xu Wang","Baihe Ma","Wei Ni","Ren Ping Liu"],"url":"https://arxiv.org/abs/2505.12296"}
{"created":"2025-05-20","title":"Enhance Mobile Agents Thinking Process Via Iterative Preference Learning","abstract":"The Chain of Action-Planning Thoughts (CoaT) paradigm has been shown to improve the reasoning performance of VLM-based mobile agents in GUI tasks. However, the scarcity of diverse CoaT trajectories limits the expressiveness and generalization ability of such agents. While self-training is commonly employed to address data scarcity, existing approaches either overlook the correctness of intermediate reasoning steps or depend on expensive process-level annotations to construct process reward models (PRM). To address the above problems, we propose an Iterative Preference Learning (IPL) that constructs a CoaT-tree through interative sampling, scores leaf nodes using rule-based reward, and backpropagates feedback to derive Thinking-level Direct Preference Optimization (T-DPO) pairs. To prevent overfitting during warm-up supervised fine-tuning, we further introduce a three-stage instruction evolution, which leverages GPT-4o to generate diverse Q\\&amp;A pairs based on real mobile UI screenshots, enhancing both generality and layout understanding. Experiments on three standard Mobile GUI-agent benchmarks demonstrate that our agent MobileIPL outperforms strong baselines, including continual pretraining models such as OS-ATLAS and UI-TARS. It achieves state-of-the-art performance across three standard Mobile GUI-Agents benchmarks and shows strong generalization to out-of-domain scenarios.","authors":["Kun Huang","Weikai Xu","Yuxuan Liu","Quandong Wang","Pengzhi Gao","Wei Liu","Jian Luan","Bin Wang","Bo An"],"url":"https://arxiv.org/abs/2505.12299"}
{"created":"2025-05-20","title":"HBO: Hierarchical Balancing Optimization for Fine-Tuning Large Language Models","abstract":"Fine-tuning large language models (LLMs) on a mixture of diverse datasets poses challenges due to data imbalance and heterogeneity. Existing methods often address these issues across datasets (globally) but overlook the imbalance and heterogeneity within individual datasets (locally), which limits their effectiveness. We introduce Hierarchical Balancing Optimization (HBO), a novel method that enables LLMs to autonomously adjust data allocation during fine-tuning both across datasets (globally) and within each individual dataset (locally). HBO employs a bilevel optimization strategy with two types of actors: a Global Actor, which balances data sampling across different subsets of the training mixture, and several Local Actors, which optimizes data usage within each subset based on difficulty levels. These actors are guided by reward functions derived from the LLM's training state, which measure learning progress and relative performance improvement. We evaluate HBO on three LLM backbones across nine diverse tasks in multilingual and multitask setups. Results show that HBO consistently outperforms existing baselines, achieving significant accuracy gains. Our in-depth analysis further demonstrates that both the global actor and local actors of HBO effectively adjust data usage during fine-tuning. HBO provides a comprehensive solution to the challenges of data imbalance and heterogeneity in LLM fine-tuning, enabling more effective training across diverse datasets.","authors":["Weixuan Wang","Minghao Wu","Barry Haddow","Alexandra Birch"],"url":"https://arxiv.org/abs/2505.12300"}
{"created":"2025-05-20","title":"Beyond Single-Point Judgment: Distribution Alignment for LLM-as-a-Judge","abstract":"LLMs have emerged as powerful evaluators in the LLM-as-a-Judge paradigm, offering significant efficiency and flexibility compared to human judgments. However, previous methods primarily rely on single-point evaluations, overlooking the inherent diversity and uncertainty in human evaluations. This approach leads to information loss and decreases the reliability of evaluations. To address this limitation, we propose a novel training framework that explicitly aligns the LLM-generated judgment distribution with empirical human distributions. Specifically, we propose a distributional alignment objective based on KL divergence, combined with an auxiliary cross-entropy regularization to stabilize the training process. Furthermore, considering that empirical distributions may derive from limited human annotations, we incorporate adversarial training to enhance model robustness against distribution perturbations. Extensive experiments across various LLM backbones and evaluation tasks demonstrate that our framework significantly outperforms existing closed-source LLMs and conventional single-point alignment methods, with improved alignment quality, evaluation accuracy, and robustness.","authors":["Luyu Chen","Zeyu Zhang","Haoran Tan","Quanyu Dai","Hao Yang","Zhenhua Dong","Xu Chen"],"url":"https://arxiv.org/abs/2505.12301"}
{"created":"2025-05-20","title":"SenseFlow: A Physics-Informed and Self-Ensembling Iterative Framework for Power Flow Estimation","abstract":"Power flow estimation plays a vital role in ensuring the stability and reliability of electrical power systems, particularly in the context of growing network complexities and renewable energy integration. However, existing studies often fail to adequately address the unique characteristics of power systems, such as the sparsity of network connections and the critical importance of the unique Slack node, which poses significant challenges in achieving high-accuracy estimations. In this paper, we present SenseFlow, a novel physics-informed and self-ensembling iterative framework that integrates two main designs, the Physics-Informed Power Flow Network (FlowNet) and Self-Ensembling Iterative Estimation (SeIter), to carefully address the unique properties of the power system and thereby enhance the power flow estimation. Specifically, SenseFlow enforces the FlowNet to gradually predict high-precision voltage magnitudes and phase angles through the iterative SeIter process. On the one hand, FlowNet employs the Virtual Node Attention and Slack-Gated Feed-Forward modules to facilitate efficient global-local communication in the face of network sparsity and amplify the influence of the Slack node on angle predictions, respectively. On the other hand, SeIter maintains an exponential moving average of FlowNet's parameters to create a robust ensemble model that refines power state predictions throughout the iterative fitting process. Experimental results demonstrate that SenseFlow outperforms existing methods, providing a promising solution for high-accuracy power flow estimation across diverse grid configurations.","authors":["Zhen Zhao","Wenqi Huang","Zicheng Wang","Jiaxuan Hou","Peng Li","Lei Bai"],"url":"https://arxiv.org/abs/2505.12302"}
{"created":"2025-05-20","title":"Pre-trained Prompt-driven Community Search","abstract":"The \"pre-train, prompt\" paradigm is widely adopted in various graph-based tasks and has shown promising performance in community detection. Most existing semi-supervised community detection algorithms detect communities based on known ones, and the detected communities typically do not contain the given query node. Therefore, they are not suitable for searching the community of a given node. Motivated by this, we adopt this paradigm into the semi-supervised community search for the first time and propose Pre-trained Prompt-driven Community Search (PPCS), a novel model designed to enhance search accuracy and efficiency. PPCS consists of three main components: node encoding, sample generation, and prompt-driven fine-tuning. Specifically, the node encoding component employs graph neural networks to learn local structural patterns of nodes in a graph, thereby obtaining representations for nodes and communities. Next, the sample generation component identifies an initial community for a given node and selects known communities that are structurally similar to the initial one as training samples. Finally, the prompt-driven fine-tuning component leverages these samples as prompts to guide the final community prediction. Experimental results on five real-world datasets demonstrate that PPCS performs better than baseline algorithms. It also achieves higher community search efficiency than semi-supervised community search baseline methods, with ablation studies verifying the effectiveness of each component of PPCS.","authors":["Li Ni","Hengkai Xu","Lin Mu","Yiwen Zhang","Wenjian Luo"],"url":"https://arxiv.org/abs/2505.12304"}
{"created":"2025-05-20","title":"Mathematical Knowledge Bases as Grammar-Compressed Proof Terms: Exploring Metamath Proof Structures","abstract":"Viewing formal mathematical proofs as logical terms provides a powerful and elegant basis for analyzing how human experts tend to structure proofs and how proofs can be structured by automated methods. We pursue this approach by (1) combining proof structuring and grammar-based tree compression, where we show how they are inherently related, and (2) exploring ways to combine human and automated proof structuring. Our source of human-structured proofs is Metamath, which, based condensed detachment, naturally provides a view of proofs as terms. A knowledge base is then just a grammar that compresses a set of gigantic proof trees. We present a formal account of this view, an implemented practical toolkit as well as experimental results.","authors":["Christoph Wernhard","Zsolt Zombori"],"url":"https://arxiv.org/abs/2505.12305"}
{"created":"2025-05-20","title":"Bidirectional LMs are Better Knowledge Memorizers? A Benchmark for Real-world Knowledge Injection","abstract":"Despite significant advances in large language models (LLMs), their knowledge memorization capabilities remain underexplored, due to the lack of standardized and high-quality test ground. In this paper, we introduce a novel, real-world and large-scale knowledge injection benchmark that evolves continuously over time without requiring human intervention. Specifically, we propose WikiDYK, which leverages recently-added and human-written facts from Wikipedia's \"Did You Know...\" entries. These entries are carefully selected by expert Wikipedia editors based on criteria such as verifiability and clarity. Each entry is converted into multiple question-answer pairs spanning diverse task formats from easy cloze prompts to complex multi-hop questions. WikiDYK contains 12,290 facts and 77,180 questions, which is also seamlessly extensible with future updates from Wikipedia editors. Extensive experiments using continued pre-training reveal a surprising insight: despite their prevalence in modern LLMs, Causal Language Models (CLMs) demonstrate significantly weaker knowledge memorization capabilities compared to Bidirectional Language Models (BiLMs), exhibiting a 23% lower accuracy in terms of reliability. To compensate for the smaller scales of current BiLMs, we introduce a modular collaborative framework utilizing ensembles of BiLMs as external knowledge repositories to integrate with LLMs. Experiment shows that our framework further improves the reliability accuracy by up to 29.1%.","authors":["Yuwei Zhang","Wenhao Yu","Shangbin Feng","Yifan Zhu","Letian Peng","Jayanth Srinivasa","Gaowen Liu","Jingbo Shang"],"url":"https://arxiv.org/abs/2505.12306"}
{"created":"2025-05-20","title":"LogicOCR: Do Your Large Multimodal Models Excel at Logical Reasoning on Text-Rich Images?","abstract":"Recent advances in Large Multimodal Models (LMMs) have significantly improved their reasoning and Optical Character Recognition (OCR) capabilities. However, their performance on complex logical reasoning tasks involving text-rich images remains underexplored. To bridge this gap, we introduce LogicOCR, a benchmark comprising 1,100 multiple-choice questions designed to evaluate LMMs' logical reasoning abilities on text-rich images, while minimizing reliance on domain-specific knowledge (e.g., mathematics). We construct LogicOCR by curating a text corpus from the Chinese National Civil Servant Examination and develop a scalable, automated pipeline to convert it into multimodal samples. First, we design prompt templates to steer GPT-Image-1 to generate images with diverse backgrounds, interleaved text-illustration layouts, and varied fonts, ensuring contextual relevance and visual realism. Then, the generated images are manually verified, with low-quality examples discarded. We evaluate a range of representative open-source and proprietary LMMs under both Chain-of-Thought (CoT) and direct-answer settings. Our multi-dimensional analysis reveals key insights, such as the impact of test-time scaling, input modality differences, and sensitivity to visual-text orientation. Notably, LMMs still lag in multimodal reasoning compared to text-only inputs, indicating that they have not fully bridged visual reading with reasoning. We hope LogicOCR will serve as a valuable resource for advancing multimodal reasoning research. The dataset is available at https://github.com/MiliLab/LogicOCR.","authors":["Maoyuan Ye","Jing Zhang","Juhua Liu","Bo Du","Dacheng Tao"],"url":"https://arxiv.org/abs/2505.12307"}
{"created":"2025-05-20","title":"Community Search in Time-dependent Road-social Attributed Networks","abstract":"Real-world networks often involve both keywords and locations, along with travel time variations between locations due to traffic conditions. However, most existing cohesive subgraph-based community search studies utilize a single attribute, either keywords or locations, to identify communities. They do not simultaneously consider both keywords and locations, which results in low semantic or spatial cohesiveness of the detected communities, and they fail to account for variations in travel time. Additionally, these studies traverse the entire network to build efficient indexes, but the detected community only involves nodes around the query node, leading to the traversal of nodes that are not relevant to the community. Therefore, we propose the problem of discovering semantic-spatial aware k-core, which refers to a k-core with high semantic and time-dependent spatial cohesiveness containing the query node. To address this problem, we propose an exact and a greedy algorithm, both of which gradually expand outward from the query node. They are local methods that only access the local part of the attributed network near the query node rather than the entire network. Moreover, we design a method to calculate the semantic similarity between two keywords using large language models. This method alleviates the disadvantages of keyword-matching methods used in existing community search studies, such as mismatches caused by differently expressed synonyms and the presence of irrelevant words. Experimental results show that the greedy algorithm outperforms baselines in terms of structural, semantic, and time-dependent spatial cohesiveness.","authors":["Li Ni","Hengkai Xu","Lin Mu","Yiwen Zhang","Wenjian Luo"],"url":"https://arxiv.org/abs/2505.12309"}
{"created":"2025-05-20","title":"DNOI-4DRO: Deep 4D Radar Odometry with Differentiable Neural-Optimization Iterations","abstract":"A novel learning-optimization-combined 4D radar odometry model, named DNOI-4DRO, is proposed in this paper. The proposed model seamlessly integrates traditional geometric optimization with end-to-end neural network training, leveraging an innovative differentiable neural-optimization iteration operator. In this framework, point-wise motion flow is first estimated using a neural network, followed by the construction of a cost function based on the relationship between point motion and pose in 3D space. The radar pose is then refined using Gauss-Newton updates. Additionally, we design a dual-stream 4D radar backbone that integrates multi-scale geometric features and clustering-based class-aware features to enhance the representation of sparse 4D radar point clouds. Extensive experiments on the VoD and Snail-Radar datasets demonstrate the superior performance of our model, which outperforms recent classical and learning-based approaches. Notably, our method even achieves results comparable to A-LOAM with mapping optimization using LiDAR point clouds as input. Our models and code will be publicly released.","authors":["Shouyi Lu","Huanyu Zhou","Guirong Zhuo"],"url":"https://arxiv.org/abs/2505.12310"}
{"created":"2025-05-20","title":"Scene-Adaptive Motion Planning with Explicit Mixture of Experts and Interaction-Oriented Optimization","abstract":"Despite over a decade of development, autonomous driving trajectory planning in complex urban environments continues to encounter significant challenges. These challenges include the difficulty in accommodating the multi-modal nature of trajectories, the limitations of single expert in managing diverse scenarios, and insufficient consideration of environmental interactions. To address these issues, this paper introduces the EMoE-Planner, which incorporates three innovative approaches. Firstly, the Explicit MoE (Mixture of Experts) dynamically selects specialized experts based on scenario-specific information through a shared scene router. Secondly, the planner utilizes scene-specific queries to provide multi-modal priors, directing the model's focus towards relevant target areas. Lastly, it enhances the prediction model and loss calculation by considering the interactions between the ego vehicle and other agents, thereby significantly boosting planning performance. Comparative experiments were conducted using the Nuplan dataset against the state-of-the-art methods. The simulation results demonstrate that our model consistently outperforms SOTA models across nearly all test scenarios.","authors":["Hongbiao Zhu","Liulong Ma","Xian Wu","Xin Deng","Xiaoyao Liang"],"url":"https://arxiv.org/abs/2505.12311"}
{"created":"2025-05-20","title":"Visuospatial Cognitive Assistant","abstract":"Video-based spatial cognition is vital for robotics and embodied AI but challenges current Vision-Language Models (VLMs). This paper makes two key contributions. First, we introduce ViCA (Visuospatial Cognitive Assistant)-322K, a diverse dataset of 322,003 QA pairs from real-world indoor videos (ARKitScenes, ScanNet, ScanNet++), offering supervision for 3D metadata-grounded queries and video-based complex reasoning. Second, we develop ViCA-7B, fine-tuned on ViCA-322K, which achieves new state-of-the-art on all eight VSI-Bench tasks, outperforming existing models, including larger ones (e.g., +26.1 on Absolute Distance). For interpretability, we present ViCA-Thinking-2.68K, a dataset with explicit reasoning chains, and fine-tune ViCA-7B to create ViCA-7B-Thinking, a model that articulates its spatial reasoning. Our work highlights the importance of targeted data and suggests paths for improved temporal-spatial modeling. We release all resources to foster research in robust visuospatial intelligence.","authors":["Qi Feng (Kyoto University)","Hidetoshi Shimodaira (Kyoto University","RIKEN)"],"url":"https://arxiv.org/abs/2505.12312"}
{"created":"2025-05-20","title":"ExpertSteer: Intervening in LLMs through Expert Knowledge","abstract":"Large Language Models (LLMs) exhibit remarkable capabilities across various tasks, yet guiding them to follow desired behaviours during inference remains a significant challenge. Activation steering offers a promising method to control the generation process of LLMs by modifying their internal activations. However, existing methods commonly intervene in the model's behaviour using steering vectors generated by the model itself, which constrains their effectiveness to that specific model and excludes the possibility of leveraging powerful external expert models for steering. To address these limitations, we propose ExpertSteer, a novel approach that leverages arbitrary specialized expert models to generate steering vectors, enabling intervention in any LLMs. ExpertSteer transfers the knowledge from an expert model to a target LLM through a cohesive four-step process: first aligning representation dimensions with auto-encoders to enable cross-model transfer, then identifying intervention layer pairs based on mutual information analysis, next generating steering vectors from the expert model using Recursive Feature Machines, and finally applying these vectors on the identified layers during inference to selectively guide the target LLM without updating model parameters. We conduct comprehensive experiments using three LLMs on 15 popular benchmarks across four distinct domains. Experiments demonstrate that ExpertSteer significantly outperforms established baselines across diverse tasks at minimal cost.","authors":["Weixuan Wang","Minghao Wu","Barry Haddow","Alexandra Birch"],"url":"https://arxiv.org/abs/2505.12313"}
{"created":"2025-05-20","title":"Improving Out-of-Domain Robustness with Targeted Augmentation in Frequency and Pixel Spaces","abstract":"Out-of-domain (OOD) robustness under domain adaptation settings, where labeled source data and unlabeled target data come from different distributions, is a key challenge in real-world applications. A common approach to improving OOD robustness is through data augmentations. However, in real-world scenarios, models trained with generic augmentations can only improve marginally when generalized under distribution shifts toward unlabeled target domains. While dataset-specific targeted augmentations can address this issue, they typically require expert knowledge and extensive prior data analysis to identify the nature of the datasets and domain shift. To address these challenges, we propose Frequency-Pixel Connect, a domain-adaptation framework that enhances OOD robustness by introducing a targeted augmentation in both the frequency space and pixel space. Specifically, we mix the amplitude spectrum and pixel content of a source image and a target image to generate augmented samples that introduce domain diversity while preserving the semantic structure of the source image. Unlike previous targeted augmentation methods that are both dataset-specific and limited to the pixel space, Frequency-Pixel Connect is dataset-agnostic, enabling broader and more flexible applicability beyond natural image datasets. We further analyze the effectiveness of Frequency-Pixel Connect by evaluating the performance of our method connecting same-class cross-domain samples while separating different-class examples. We demonstrate that Frequency-Pixel Connect significantly improves cross-domain connectivity and outperforms previous generic methods on four diverse real-world benchmarks across vision, medical, audio, and astronomical domains, and it also outperforms other dataset-specific targeted augmentation methods.","authors":["Ruoqi Wang","Haitao Wang","Shaojie Guo","Qiong Luo"],"url":"https://arxiv.org/abs/2505.12317"}
{"created":"2025-05-20","title":"Efficient Federated Class-Incremental Learning of Pre-Trained Models via Task-agnostic Low-rank Residual Adaptation","abstract":"Federated Parameter-Efficient Fine-Tuning (FedPEFT) reduces communication and computation costs in federated fine-tuning of pre-trained models by updating only a small subset of model parameters. However, existing approaches assume static data distributions, failing to adequately address real-world scenarios where new classes continually emerge, particularly in Federated Class Incremental Learning (FCIL). FCIL faces two key challenges: catastrophic forgetting and performance degradation caused by non-IID data across clients. Unlike current methods that maintain separate task-specific components or suffer from aggregation noise during parameter aggregation, we propose Federated Task-agnostic Low-rank Residual Adaptation (Fed-TaLoRA), a novel parameter-efficient approach for fine-tuning in resource-constrained FCIL scenarios. Specifically, we fine-tune only shared task-agnostic LoRA parameters across sequential tasks, effectively mitigating catastrophic forgetting while enabling efficient knowledge transfer among clients. Based on a theoretical analysis of aggregation, we develop a novel residual weight update mechanism that ensures accurate knowledge consolidation with minimal overhead. Our methodological innovations are attributed to three key strategies: task-agnostic adaptation, post-aggregation model calibration, and strategic placement of LoRA modules. Extensive experiments on multiple benchmark datasets demonstrate that Fed-TaLoRA consistently outperforms state-of-the-art methods in diverse data heterogeneity scenarios while substantially reducing resource requirements.","authors":["Feng Yu","Jia Hu","Geyong Min"],"url":"https://arxiv.org/abs/2505.12318"}
{"created":"2025-05-20","title":"BeliefNest: A Joint Action Simulator for Embodied Agents with Theory of Mind","abstract":"This paper introduces an open-source simulator, BeliefNest, designed to enable embodied agents to perform collaborative tasks by leveraging Theory of Mind. BeliefNest dynamically and hierarchically constructs simulators within a Minecraft environment, allowing agents to explicitly represent nested belief states about themselves and others. This enables agent control in open-domain tasks that require Theory of Mind reasoning. The simulator provides a prompt generation mechanism based on each belief state, facilitating the design and evaluation of methods for agent control utilizing large language models (LLMs). We demonstrate through experiments that agents can infer others' beliefs and predict their belief-based actions in false-belief tasks.","authors":["Rikunari Sagara","Koichiro Terao","Naoto Iwahashi"],"url":"https://arxiv.org/abs/2505.12321"}
{"created":"2025-05-20","title":"Model alignment using inter-modal bridges","abstract":"Foundation models have demonstrated remarkable performance across modalities such as language and vision. However, model reuse across distinct modalities (e.g., text and vision) remains limited due to the difficulty of aligning internal representations. Existing methods require extensive paired training data or are constrained to specific domains. We introduce a semi-supervised approach for model alignment via conditional flow matching. The conditional flow between latent spaces of different modalities (e.g., text-to-image or biological-to-artificial neuronal activity) can be learned in two settings: ($1$) solving a (balanced or unbalanced) optimal transport problem with an inter-space bridge cost, and ($2$) performing memory-efficient alignment using labelled exemplars. Despite being constrained by the original models' capacity, our method--under both settings--matches downstream task performance of end-to-end trained models on object recognition and image generation tasks across MNIST, ImageNet, and \\cite{majaj2015simple} datasets, particularly when labelled training data is scarce ($<20\\%$). Our method provides a data-efficient solution for inter-modal model alignment with minimal supervision.","authors":["Ali Gholamzadeh","Noor Sajid"],"url":"https://arxiv.org/abs/2505.12322"}
{"created":"2025-05-20","title":"GraphFLEx: Structure Learning Framework for Large Expanding Graphs","abstract":"Graph structure learning is a core problem in graph-based machine learning, essential for uncovering latent relationships and ensuring model interpretability. However, most existing approaches are ill-suited for large-scale and dynamically evolving graphs, as they often require complete re-learning of the structure upon the arrival of new nodes and incur substantial computational and memory costs. In this work, we propose GraphFLEx: a unified and scalable framework for Graph Structure Learning in Large and Expanding Graphs. GraphFLEx mitigates the scalability bottlenecks by restricting edge formation to structurally relevant subsets of nodes identified through a combination of clustering and coarsening techniques. This dramatically reduces the search space and enables efficient, incremental graph updates. The framework supports 48 flexible configurations by integrating diverse choices of learning paradigms, coarsening strategies, and clustering methods, making it adaptable to a wide range of graph settings and learning objectives. Extensive experiments across 26 diverse datasets and Graph Neural Network architectures demonstrate that GraphFLEx achieves state-of-the-art performance with significantly improved scalability.","authors":["Mohit Kataria","Nikita Malik","Sandeep Kumar","Jayadeva"],"url":"https://arxiv.org/abs/2505.12323"}
{"created":"2025-05-20","title":"Neural Graduated Assignment for Maximum Common Edge Subgraphs","abstract":"The Maximum Common Edge Subgraph (MCES) problem is a crucial challenge with significant implications in domains such as biology and chemistry. Traditional approaches, which include transformations into max-clique and search-based algorithms, suffer from scalability issues when dealing with larger instances. This paper introduces ``Neural Graduated Assignment'' (NGA), a simple, scalable, unsupervised-training-based method that addresses these limitations by drawing inspiration from the classical Graduated Assignment (GA) technique. Central to NGA is stacking of neural components that closely resemble the GA process, but with the reparameterization of learnable temperature into higher dimension. We further theoretically analyze the learning dynamics of NGA, showing its design leads to fast convergence, better exploration-exploitation tradeoff, and ability to escape local optima. Extensive experiments across MCES computation, graph similarity estimation, and graph retrieval tasks reveal that NGA not only significantly improves computation time and scalability on large instances but also enhances performance compared to existing methodologies. The introduction of NGA marks a significant advancement in the computation of MCES and offers insights into other assignment problems.","authors":["Chaolong Ying","Yingqi Ruan","Xuemin Chen","Yaomin Wang","Tianshu Yu"],"url":"https://arxiv.org/abs/2505.12325"}
{"created":"2025-05-20","title":"Robust Planning for Autonomous Driving via Mixed Adversarial Diffusion Predictions","abstract":"We describe a robust planning method for autonomous driving that mixes normal and adversarial agent predictions output by a diffusion model trained for motion prediction. We first train a diffusion model to learn an unbiased distribution of normal agent behaviors. We then generate a distribution of adversarial predictions by biasing the diffusion model at test time to generate predictions that are likely to collide with a candidate plan. We score plans using expected cost with respect to a mixture distribution of normal and adversarial predictions, leading to a planner that is robust against adversarial behaviors but not overly conservative when agents behave normally. Unlike current approaches, we do not use risk measures that over-weight adversarial behaviors while placing little to no weight on low-cost normal behaviors or use hard safety constraints that may not be appropriate for all driving scenarios. We show the effectiveness of our method on single-agent and multi-agent jaywalking scenarios as well as a red light violation scenario.","authors":["Albert Zhao","Stefano Soatto"],"url":"https://arxiv.org/abs/2505.12327"}
{"created":"2025-05-20","title":"LLMSR@XLLM25: An Empirical Study of LLM for Structural Reasoning","abstract":"We present Team asdfo123's submission to the LLMSR@XLLM25 shared task, which evaluates large language models on producing fine-grained, controllable, and interpretable reasoning processes. Systems must extract all problem conditions, decompose a chain of thought into statement-evidence pairs, and verify the logical validity of each pair. Leveraging only the off-the-shelf Meta-Llama-3-8B-Instruct, we craft a concise few-shot, multi-turn prompt that first enumerates all conditions and then guides the model to label, cite, and adjudicate every reasoning step. A lightweight post-processor based on regular expressions normalises spans and enforces the official JSON schema. Without fine-tuning, external retrieval, or ensembling, our method ranks 5th overall, achieving macro F1 scores on par with substantially more complex and resource-consuming pipelines. We conclude by analysing the strengths and limitations of our approach and outlining directions for future research in structural reasoning with LLMs. Our code is available at https://github.com/asdfo123/LLMSR-asdfo123.","authors":["Xinye Li","Mingqi Wan","Dianbo Sui"],"url":"https://arxiv.org/abs/2505.12328"}
{"created":"2025-05-20","title":"MPRM: A Markov Path-based Rule Miner for Efficient and Interpretable Knowledge Graph Reasoning","abstract":"Rule mining in knowledge graphs enables interpretable link prediction. However, deep learning-based rule mining methods face significant memory and time challenges for large-scale knowledge graphs, whereas traditional approaches, limited by rigid confidence metrics, incur high computational costs despite sampling techniques. To address these challenges, we propose MPRM, a novel rule mining method that models rule-based inference as a Markov chain and uses an efficient confidence metric derived from aggregated path probabilities, significantly lowering computational demands. Experiments on multiple datasets show that MPRM efficiently mines knowledge graphs with over a million facts, sampling less than 1% of facts on a single CPU in 22 seconds, while preserving interpretability and boosting inference accuracy by up to 11% over baselines.","authors":["Mingyang Li","Song Wang","Ning Cai"],"url":"https://arxiv.org/abs/2505.12329"}
{"created":"2025-05-20","title":"OSS-Bench: Benchmark Generator for Coding LLMs","abstract":"In light of the rapid adoption of AI coding assistants, LLM-assisted development has become increasingly prevalent, creating an urgent need for robust evaluation of generated code quality. Existing benchmarks often require extensive manual effort to create static datasets, rely on indirect or insufficiently challenging tasks, depend on non-scalable ground truth, or neglect critical low-level security evaluations, particularly memory-safety issues. In this work, we introduce OSS-Bench, a benchmark generator that automatically constructs large-scale, live evaluation tasks from real-world open-source software. OSS-Bench replaces functions with LLM-generated code and evaluates them using three natural metrics: compilability, functional correctness, and memory safety, leveraging robust signals like compilation failures, test-suite violations, and sanitizer alerts as ground truth. In our evaluation, the benchmark, instantiated as OSS-Bench(php) and OSS-Bench(sql), profiles 17 diverse LLMs, revealing insights such as intra-family behavioral patterns and inconsistencies between model size and performance. Our results demonstrate that OSS-Bench mitigates overfitting by leveraging the evolving complexity of OSS and highlights LLMs' limited understanding of low-level code security via extended fuzzing experiments. Overall, OSS-Bench offers a practical and scalable framework for benchmarking the real-world coding capabilities of LLMs.","authors":["Yuancheng Jiang","Roland Yap","Zhenkai Liang"],"url":"https://arxiv.org/abs/2505.12331"}
{"created":"2025-05-20","title":"VoiceCloak: A Multi-Dimensional Defense Framework against Unauthorized Diffusion-based Voice Cloning","abstract":"Diffusion Models (DMs) have achieved remarkable success in realistic voice cloning (VC), while they also increase the risk of malicious misuse. Existing proactive defenses designed for traditional VC models aim to disrupt the forgery process, but they have been proven incompatible with DMs due to the intricate generative mechanisms of diffusion. To bridge this gap, we introduce VoiceCloak, a multi-dimensional proactive defense framework with the goal of obfuscating speaker identity and degrading perceptual quality in potential unauthorized VC. To achieve these goals, we conduct a focused analysis to identify specific vulnerabilities within DMs, allowing VoiceCloak to disrupt the cloning process by introducing adversarial perturbations into the reference audio. Specifically, to obfuscate speaker identity, VoiceCloak first targets speaker identity by distorting representation learning embeddings to maximize identity variation, which is guided by auditory perception principles. Additionally, VoiceCloak disrupts crucial conditional guidance processes, particularly attention context, thereby preventing the alignment of vocal characteristics that are essential for achieving convincing cloning. Then, to address the second objective, VoiceCloak introduces score magnitude amplification to actively steer the reverse trajectory away from the generation of high-quality speech. Noise-guided semantic corruption is further employed to disrupt structural speech semantics captured by DMs, degrading output quality. Extensive experiments highlight VoiceCloak's outstanding defense success rate against unauthorized diffusion-based voice cloning. Audio samples of VoiceCloak are available at https://voice-cloak.github.io/VoiceCloak/.","authors":["Qianyue Hu","Junyan Wu","Wei Lu","Xiangyang Luo"],"url":"https://arxiv.org/abs/2505.12332"}
{"created":"2025-05-20","title":"Predicting Gas Well Performance with Decline Curve Analysis: A Case Study on Semutang Gas Field","abstract":"Decline-curve analysis (DCA) is a widely utilized method for production forecasting and estimating remaining reserves in gas reservoir. Based on the assumptions that past production trend can be mathematically characterized and used to predict future performance. It relies on historical production data and assumes that production methods remain unchanged throughout the analysis. This method is particularly valuable due to its accuracy in forecasting and its broad acceptance within the industry. Wells in the same geographical area and producing from similar geological formations often exhibit similar decline curve parameters. This study applies DCA to forecast the future production performance and estimate the ultimate recovery for the Semutang gas field's well 5 in Bangladesh. Using historical production data, decline curves were generated based on exponential, hyperbolic, and harmonic model equations. The cumulative production estimations were 11,139.34 MMSCF for the exponential model, 11,620.26 MMSCF for the hyperbolic model, and 14,021.92 MMSCF for the harmonic model. In terms of the well's productive life, the estimates were 335.13 days, 1,152 days, and 22,611 days, respectively. Among these models, the hyperbolic decline provided the most realistic forecast, closely aligning with observed production trend. The study highlights the importance of selecting an appropriate decline model for accurate production forecasting and reserve estimation, which is essential for effective reservoir management and resource optimization.","authors":["Md. Shakil Rahaman","Ahmed Sakib","Ataharuse Samad","Md. Ashraful Islam"],"url":"https://arxiv.org/abs/2505.12333"}
{"created":"2025-05-20","title":"Enhancing User-Oriented Proactivity in Open-Domain Dialogues with Critic Guidance","abstract":"Open-domain dialogue systems aim to generate natural and engaging conversations, providing significant practical value in real applications such as social robotics and personal assistants. The advent of large language models (LLMs) has greatly advanced this field by improving context understanding and conversational fluency. However, existing LLM-based dialogue systems often fall short in proactively understanding the user's chatting preferences and guiding conversations toward user-centered topics. This lack of user-oriented proactivity can lead users to feel unappreciated, reducing their satisfaction and willingness to continue the conversation in human-computer interactions. To address this issue, we propose a User-oriented Proactive Chatbot (UPC) to enhance the user-oriented proactivity. Specifically, we first construct a critic to evaluate this proactivity inspired by the LLM-as-a-judge strategy. Given the scarcity of high-quality training data, we then employ the critic to guide dialogues between the chatbot and user agents, generating a corpus with enhanced user-oriented proactivity. To ensure the diversity of the user backgrounds, we introduce the ISCO-800, a diverse user background dataset for constructing user agents. Moreover, considering the communication difficulty varies among users, we propose an iterative curriculum learning method that trains the chatbot from easy-to-communicate users to more challenging ones, thereby gradually enhancing its performance. Experiments demonstrate that our proposed training method is applicable to different LLMs, improving user-oriented proactivity and attractiveness in open-domain dialogues.","authors":["Yufeng Wang","Jinwu Hu","Ziteng Huang","Kunyang Lin","Zitian Zhang","Peihao Chen","Yu Hu","Qianyue Wang","Zhuliang Yu","Bin Sun","Xiaofen Xing","Qingfang Zheng","Mingkui Tan"],"url":"https://arxiv.org/abs/2505.12334"}
{"created":"2025-05-20","title":"Is Artificial Intelligence Generated Image Detection a Solved Problem?","abstract":"The rapid advancement of generative models, such as GANs and Diffusion models, has enabled the creation of highly realistic synthetic images, raising serious concerns about misinformation, deepfakes, and copyright infringement. Although numerous Artificial Intelligence Generated Image (AIGI) detectors have been proposed, often reporting high accuracy, their effectiveness in real-world scenarios remains questionable. To bridge this gap, we introduce AIGIBench, a comprehensive benchmark designed to rigorously evaluate the robustness and generalization capabilities of state-of-the-art AIGI detectors. AIGIBench simulates real-world challenges through four core tasks: multi-source generalization, robustness to image degradation, sensitivity to data augmentation, and impact of test-time pre-processing. It includes 23 diverse fake image subsets that span both advanced and widely adopted image generation techniques, along with real-world samples collected from social media and AI art platforms. Extensive experiments on 11 advanced detectors demonstrate that, despite their high reported accuracy in controlled settings, these detectors suffer significant performance drops on real-world data, limited benefits from common augmentations, and nuanced effects of pre-processing, highlighting the need for more robust detection strategies. By providing a unified and realistic evaluation framework, AIGIBench offers valuable insights to guide future research toward dependable and generalizable AIGI detection.","authors":["Ziqiang Li","Jiazhen Yan","Ziwen He","Kai Zeng","Weiwei Jiang","Lizhi Xiong","Zhangjie Fu"],"url":"https://arxiv.org/abs/2505.12335"}
{"created":"2025-05-20","title":"Modeling and Performance Analysis of IoT-over-LEO Satellite Systems under Realistic Operational Constraints: A Stochastic Geometry Approach","abstract":"Current theoretical studies on IoT-over-LEO satellite systems often rely on unrealistic assumptions, such as infinite terrestrial areas and omnidirectional satellite coverage, leaving significant gaps in theoretical analysis for more realistic operational constraints. These constraints involve finite terrestrial area, limited satellite coverage, Earth curvature effect, integral uplink and downlink analysis, and link-dependent interference. To address these gaps, this paper proposes a novel stochastic geometry based model to rigorously analyze the performance of IoT-over-LEO satellite systems. By adopting a binomial point process (BPP) instead of the conventional Poisson point process (PPP), our model accurately characterizes the geographical distribution of a fixed number of IoT devices in a finite terrestrial region. This modeling framework enables the derivation of distance distribution functions for both the links from the terrestrial IoT devices to the satellites (T-S) and from the satellites to the Earth station (S-ES), while also accounting for limited satellite coverage and Earth curvature effects. To realistically represent channel conditions, the Nakagami fading model is employed for the T-S links to characterize diverse small-scale fading environments, while the shadowed-Rician fading model is used for the S-ES links to capture the combined effects of shadowing and dominant line-of-sight paths. Furthermore, the analysis incorporates uplink and downlink interference, ensuring a comprehensive evaluation of system performance. The accuracy and effectiveness of our theoretical framework are validated through extensive Monte Carlo simulations. These results provide insights into key performance metrics, such as coverage probability and average ergodic rate, for both individual links and the overall system.","authors":["Wen-Yu Dong","Shaoshi Yang","Ping Zhang","Sheng Chen"],"url":"https://arxiv.org/abs/2505.12336"}
{"created":"2025-05-20","title":"Structureless VIO","abstract":"Visual odometry (VO) is typically considered as a chicken-and-egg problem, as the localization and mapping modules are tightly-coupled. The estimation of visual map relies on accurate localization information. Meanwhile, localization requires precise map points to provide motion constraints. This classical design principle is naturally inherited by visual-inertial odometry (VIO). Efficient localization solution that does not require a map has not been fully investigated. To this end, we propose a novel structureless VIO, where the visual map is removed from the odometry framework. Experimental results demonstrated that, compared to the structure-based VIO baseline, our structureless VIO not only substantially improves computational efficiency but also has advantages in accuracy.","authors":["Junlin Song","Miguel Olivares-Mendez"],"url":"https://arxiv.org/abs/2505.12337"}
{"created":"2025-05-20","title":"Towards Open-world Generalized Deepfake Detection: General Feature Extraction via Unsupervised Domain Adaptation","abstract":"With the development of generative artificial intelligence, new forgery methods are rapidly emerging. Social platforms are flooded with vast amounts of unlabeled synthetic data and authentic data, making it increasingly challenging to distinguish real from fake. Due to the lack of labels, existing supervised detection methods struggle to effectively address the detection of unknown deepfake methods. Moreover, in open world scenarios, the amount of unlabeled data greatly exceeds that of labeled data. Therefore, we define a new deepfake detection generalization task which focuses on how to achieve efficient detection of large amounts of unlabeled data based on limited labeled data to simulate a open world scenario. To solve the above mentioned task, we propose a novel Open-World Deepfake Detection Generalization Enhancement Training Strategy (OWG-DS) to improve the generalization ability of existing methods. Our approach aims to transfer deepfake detection knowledge from a small amount of labeled source domain data to large-scale unlabeled target domain data. Specifically, we introduce the Domain Distance Optimization (DDO) module to align different domain features by optimizing both inter-domain and intra-domain distances. Additionally, the Similarity-based Class Boundary Separation (SCBS) module is used to enhance the aggregation of similar samples to ensure clearer class boundaries, while an adversarial training mechanism is adopted to learn the domain-invariant features. Extensive experiments show that the proposed deepfake detection generalization enhancement training strategy excels in cross-method and cross-dataset scenarios, improving the model's generalization.","authors":["Midou Guo","Qilin Yin","Wei Lu","Xiangyang Luo"],"url":"https://arxiv.org/abs/2505.12339"}
{"created":"2025-05-20","title":"DIMM: Decoupled Multi-hierarchy Kalman Filter for 3D Object Tracking","abstract":"State estimation is challenging for 3D object tracking with high maneuverability, as the target's state transition function changes rapidly, irregularly, and is unknown to the estimator. Existing work based on interacting multiple model (IMM) achieves more accurate estimation than single-filter approaches through model combination, aligning appropriate models for different motion modes of the target object over time. However, two limitations of conventional IMM remain unsolved. First, the solution space of the model combination is constrained as the target's diverse kinematic properties in different directions are ignored. Second, the model combination weights calculated by the observation likelihood are not accurate enough due to the measurement uncertainty. In this paper, we propose a novel framework, DIMM, to effectively combine estimates from different motion models in each direction, thus increasing the 3D object tracking accuracy. First, DIMM extends the model combination solution space of conventional IMM from a hyperplane to a hypercube by designing a 3D-decoupled multi-hierarchy filter bank, which describes the target's motion with various-order linear models. Second, DIMM generates more reliable combination weight matrices through a differentiable adaptive fusion network for importance allocation rather than solely relying on the observation likelihood; it contains an attention-based twin delayed deep deterministic policy gradient (TD3) method with a hierarchical reward. Experiments demonstrate that DIMM significantly improves the tracking accuracy of existing state estimation methods by 31.61%~99.23%.","authors":["Jirong Zha","Yuxuan Fan","Kai Li","Han Li","Chen Gao","Xinlei Chen","Yong Li"],"url":"https://arxiv.org/abs/2505.12340"}
{"created":"2025-05-20","title":"Mitigating Hallucinations via Inter-Layer Consistency Aggregation in Large Vision-Language Models","abstract":"Despite the impressive capabilities of Large Vision-Language Models (LVLMs), they remain susceptible to hallucinations-generating content that is inconsistent with the input image. Existing training-free hallucination mitigation methods often suffer from unstable performance and high sensitivity to hyperparameter settings, limiting their practicality and broader adoption. In this paper, we propose a novel decoding mechanism, Decoding with Inter-layer Consistency via Layer Aggregation (DCLA), which requires no retraining, fine-tuning, or access to external knowledge bases. Specifically, our approach constructs a dynamic semantic reference by aggregating representations from previous layers, and corrects semantically deviated layers to enforce inter-layer consistency. The method allows DCLA to robustly mitigate hallucinations across multiple LVLMs. Experiments on hallucination benchmarks such as MME and POPE demonstrate that DCLA effectively reduces hallucinations while enhancing the reliability and performance of LVLMs.","authors":["Kai Tang","Jinhao You","Xiuqi Ge","Hanze Li","Yichen Guo","Xiande Huang"],"url":"https://arxiv.org/abs/2505.12343"}
{"created":"2025-05-20","title":"Early Prediction of In-Hospital ICU Mortality Using Innovative First-Day Data: A Review","abstract":"The intensive care unit (ICU) manages critically ill patients, many of whom face a high risk of mortality. Early and accurate prediction of in-hospital mortality within the first 24 hours of ICU admission is crucial for timely clinical interventions, resource optimization, and improved patient outcomes. Traditional scoring systems, while useful, often have limitations in predictive accuracy and adaptability. Objective: This review aims to systematically evaluate and benchmark innovative methodologies that leverage data available within the first day of ICU admission for predicting in-hospital mortality. We focus on advancements in machine learning, novel biomarker applications, and the integration of diverse data types.","authors":["Han Wang"],"url":"https://arxiv.org/abs/2505.12344"}
{"created":"2025-05-20","title":"UniEdit: A Unified Knowledge Editing Benchmark for Large Language Models","abstract":"Model editing aims to enhance the accuracy and reliability of large language models (LLMs) by efficiently adjusting their internal parameters. Currently, most LLM editing datasets are confined to narrow knowledge domains and cover a limited range of editing evaluation. They often overlook the broad scope of editing demands and the diversity of ripple effects resulting from edits. In this context, we introduce UniEdit, a unified benchmark for LLM editing grounded in open-domain knowledge. First, we construct editing samples by selecting entities from 25 common domains across five major categories, utilizing the extensive triple knowledge available in open-domain knowledge graphs to ensure comprehensive coverage of the knowledge domains. To address the issues of generality and locality in editing, we design an Neighborhood Multi-hop Chain Sampling (NMCS) algorithm to sample subgraphs based on a given knowledge piece to entail comprehensive ripple effects to evaluate. Finally, we employ proprietary LLMs to convert the sampled knowledge subgraphs into natural language text, guaranteeing grammatical accuracy and syntactical diversity. Extensive statistical analysis confirms the scale, comprehensiveness, and diversity of our UniEdit benchmark. We conduct comprehensive experiments across multiple LLMs and editors, analyzing their performance to highlight strengths and weaknesses in editing across open knowledge domains and various evaluation criteria, thereby offering valuable insights for future research endeavors.","authors":["Qizhou Chen","Dakan Wang","Taolin Zhang","Zaoming Yan","Chengsong You","Chengyu Wang","Xiaofeng He"],"url":"https://arxiv.org/abs/2505.12345"}
{"created":"2025-05-20","title":"SEED-GRPO: Semantic Entropy Enhanced GRPO for Uncertainty-Aware Policy Optimization","abstract":"Large language models (LLMs) exhibit varying levels of confidence across input prompts (questions): some lead to consistent, semantically similar answers, while others yield diverse or contradictory outputs. This variation reflects LLM's uncertainty about the input prompt, a signal of how confidently the model understands a given problem. However, vanilla Group Relative Policy Optimization (GRPO) treats all prompts equally during policy updates, ignoring this important information about the model's knowledge boundaries. To address this limitation, we propose SEED-GRPO (Semantic Entropy EnhanceD GRPO), which explicitly measures LLMs' uncertainty of the input prompts semantic entropy. Semantic entropy measures the diversity of meaning in multiple generated answers given a prompt and uses this to modulate the magnitude of policy updates. This uncertainty-aware training mechanism enables dynamic adjustment of policy update magnitudes based on question uncertainty. It allows more conservative updates on high-uncertainty questions while maintaining the original learning signal on confident ones. Experimental results on five mathematical reasoning benchmarks (AIME24 56.7, AMC 68.7, MATH 83.4, Minerva 34.2, and OlympiadBench 48.0) demonstrate that SEED-GRPO achieves new state-of-the-art performance in average accuracy, validating the effectiveness of uncertainty-aware policy optimization.","authors":["Minghan Chen","Guikun Chen","Wenguan Wang","Yi Yang"],"url":"https://arxiv.org/abs/2505.12346"}
{"created":"2025-05-20","title":"Reasoning-CV: Fine-tuning Powerful Reasoning LLMs for Knowledge-Assisted Claim Verification","abstract":"Claim verification is essential in combating misinformation, and large language models (LLMs) have recently emerged in this area as powerful tools for assessing the veracity of claims using external knowledge. Existing LLM-based methods for claim verification typically adopt a Decompose-Then-Verify paradigm, which involves decomposing complex claims into several independent sub-claims and verifying each sub-claim separately. However, this paradigm often introduces errors during the claim decomposition process. To mitigate these errors, we propose to develop the Chain-of-Thought (CoT)-Verify paradigm, which leverages LLM reasoning methods to generate CoT-verification paths for the original complex claim without requiring decompositions into sub-claims and separate verification stages. The CoT-Verify paradigm allows us to propose a natural fine-tuning method called Reasoning-CV to enhance the verification capabilities in LLMs. Reasoning-CV includes a supervised fine-tuning (SFT) stage and a self-improvement direct preference optimization (DPO) stage. Utilizing only an 8B pre-trained LLM, Reasoning-CV demonstrates superior knowledge-assisted claim verification performances compared to existing Decompose-Then-Verify methods, as well as powerful black-box LLMs such as GPT-4o+CoT and o1-preview. Our code is available.","authors":["Zhi Zheng","Wee Sun Lee"],"url":"https://arxiv.org/abs/2505.12348"}
{"created":"2025-05-20","title":"Wisdom from Diversity: Bias Mitigation Through Hybrid Human-LLM Crowds","abstract":"Despite their performance, large language models (LLMs) can inadvertently perpetuate biases found in the data they are trained on. By analyzing LLM responses to bias-eliciting headlines, we find that these models often mirror human biases. To address this, we explore crowd-based strategies for mitigating bias through response aggregation. We first demonstrate that simply averaging responses from multiple LLMs, intended to leverage the \"wisdom of the crowd\", can exacerbate existing biases due to the limited diversity within LLM crowds. In contrast, we show that locally weighted aggregation methods more effectively leverage the wisdom of the LLM crowd, achieving both bias mitigation and improved accuracy. Finally, recognizing the complementary strengths of LLMs (accuracy) and humans (diversity), we demonstrate that hybrid crowds containing both significantly enhance performance and further reduce biases across ethnic and gender-related contexts.","authors":["Axel Abels","Tom Lenaerts"],"url":"https://arxiv.org/abs/2505.12349"}
{"created":"2025-05-20","title":"Multi-CALF: A Policy Combination Approach with Statistical Guarantees","abstract":"We introduce Multi-CALF, an algorithm that intelligently combines reinforcement learning policies based on their relative value improvements. Our approach integrates a standard RL policy with a theoretically-backed alternative policy, inheriting formal stability guarantees while often achieving better performance than either policy individually. We prove that our combined policy converges to a specified goal set with known probability and provide precise bounds on maximum deviation and convergence time. Empirical validation on control tasks demonstrates enhanced performance while maintaining stability guarantees.","authors":["Georgiy Malaniya","Anton Bolychev","Grigory Yaremenko","Anastasia Krasnaya","Pavel Osinenko"],"url":"https://arxiv.org/abs/2505.12350"}
{"created":"2025-05-20","title":"Importance Sampling for Nonlinear Models","abstract":"While norm-based and leverage-score-based methods have been extensively studied for identifying \"important\" data points in linear models, analogous tools for nonlinear models remain significantly underdeveloped. By introducing the concept of the adjoint operator of a nonlinear map, we address this gap and generalize norm-based and leverage-score-based importance sampling to nonlinear settings. We demonstrate that sampling based on these generalized notions of norm and leverage scores provides approximation guarantees for the underlying nonlinear mapping, similar to linear subspace embeddings. As direct applications, these nonlinear scores not only reduce the computational complexity of training nonlinear models by enabling efficient sampling over large datasets but also offer a novel mechanism for model explainability and outlier detection. Our contributions are supported by both theoretical analyses and experimental results across a variety of supervised learning scenarios.","authors":["Prakash Palanivelu Rajmohan","Fred Roosta"],"url":"https://arxiv.org/abs/2505.12353"}
{"created":"2025-05-20","title":"A universal policy wrapper with guarantees","abstract":"We introduce a universal policy wrapper for reinforcement learning agents that ensures formal goal-reaching guarantees. In contrast to standard reinforcement learning algorithms that excel in performance but lack rigorous safety assurances, our wrapper selectively switches between a high-performing base policy -- derived from any existing RL method -- and a fallback policy with known convergence properties. Base policy's value function supervises this switching process, determining when the fallback policy should override the base policy to ensure the system remains on a stable path. The analysis proves that our wrapper inherits the fallback policy's goal-reaching guarantees while preserving or improving upon the performance of the base policy. Notably, it operates without needing additional system knowledge or online constrained optimization, making it readily deployable across diverse reinforcement learning architectures and tasks.","authors":["Anton Bolychev","Georgiy Malaniya","Grigory Yaremenko","Anastasia Krasnaya","Pavel Osinenko"],"url":"https://arxiv.org/abs/2505.12354"}
{"created":"2025-05-20","title":"GATES: Cost-aware Dynamic Workflow Scheduling via Graph Attention Networks and Evolution Strategy","abstract":"Cost-aware Dynamic Workflow Scheduling (CADWS) is a key challenge in cloud computing, focusing on devising an effective scheduling policy to efficiently schedule dynamically arriving workflow tasks, represented as Directed Acyclic Graphs (DAG), to suitable virtual machines (VMs). Deep reinforcement learning (DRL) has been widely employed for automated scheduling policy design. However, the performance of DRL is heavily influenced by the design of the problem-tailored policy network and is highly sensitive to hyperparameters and the design of reward feedback. Considering the above-mentioned issues, this study proposes a novel DRL method combining Graph Attention Networks-based policy network and Evolution Strategy, referred to as GATES. The contributions of GATES are summarized as follows: (1) GATES can capture the impact of current task scheduling on subsequent tasks by learning the topological relationships between tasks in a DAG. (2) GATES can learn the importance of each VM to ready tasks, increasing the chance of selecting the optimal VM. (3) Utilizing Evolution Strategy's robustness, exploratory nature, and tolerance for delayed rewards, GATES achieves stable policy learning in CADWS. Extensive experimental results demonstrate the superiority of the proposed GATES in CADWS, outperforming several state-of-the-art algorithms. Codes are available at: https://github.com/YaShen998/GATES","authors":["Ya Shen","Gang Chen","Hui Ma","Mengjie Zhang"],"url":"https://arxiv.org/abs/2505.12355"}
{"created":"2025-05-20","title":"AbFlowNet: Optimizing Antibody-Antigen Binding Energy via Diffusion-GFlowNet Fusion","abstract":"Complementarity Determining Regions (CDRs) are critical segments of an antibody that facilitate binding to specific antigens. Current computational methods for CDR design utilize reconstruction losses and do not jointly optimize binding energy, a crucial metric for antibody efficacy. Rather, binding energy optimization is done through computationally expensive Online Reinforcement Learning (RL) pipelines rely heavily on unreliable binding energy estimators. In this paper, we propose AbFlowNet, a novel generative framework that integrates GFlowNet with Diffusion models. By framing each diffusion step as a state in the GFlowNet framework, AbFlowNet jointly optimizes standard diffusion losses and binding energy by directly incorporating energy signals into the training process, thereby unifying diffusion and reward optimization in a single procedure. Experimental results show that AbFlowNet outperforms the base diffusion model by 3.06% in amino acid recovery, 20.40% in geometric reconstruction (RMSD), and 3.60% in binding energy improvement ratio. ABFlowNet also decreases Top-1 total energy and binding energy errors by 24.8% and 38.1% without pseudo-labeling the test dataset or using computationally expensive online RL regimes.","authors":["Abrar Rahman Abir","Haz Sameen Shahgir","Md Rownok Zahan Ratul","Md Toki Tahmid","Greg Ver Steeg","Yue Dong"],"url":"https://arxiv.org/abs/2505.12358"}
{"created":"2025-05-20","title":"STAR: Stage-Wise Attention-Guided Token Reduction for Efficient Large Vision-Language Models Inference","abstract":"Although large vision-language models (LVLMs) leverage rich visual token representations to achieve strong performance on multimodal tasks, these tokens also introduce significant computational overhead during inference. Existing training-free token pruning methods typically adopt a single-stage strategy, focusing either on visual self-attention or visual-textual cross-attention. However, such localized perspectives often overlook the broader information flow across the model, leading to substantial performance degradation, especially under high pruning ratios. In this work, we propose STAR (Stage-wise Attention-guided token Reduction), a training-free, plug-and-play framework that approaches token pruning from a global perspective. Instead of pruning at a single point, STAR performs attention-guided reduction in two complementary stages: an early-stage pruning based on visual self-attention to remove redundant low-level features, and a later-stage pruning guided by cross-modal attention to discard task-irrelevant tokens. This holistic approach allows STAR to significantly reduce computational cost while better preserving task-critical information. Extensive experiments across multiple LVLM architectures and benchmarks show that STAR achieves strong acceleration while maintaining comparable, and in some cases even improved performance.","authors":["Yichen Guo","Hanze Li","Zonghao Zhang","Jinhao You","Kai Tang","Xiande Huang"],"url":"https://arxiv.org/abs/2505.12359"}
{"created":"2025-05-20","title":"Adaptive MPC-based quadrupedal robot control under periodic disturbances","abstract":"Recent advancements in adaptive control for reference trajectory tracking enable quadrupedal robots to perform locomotion tasks under challenging conditions. There are methods enabling the estimation of the external disturbances in terms of forces and torques. However, a specific case of disturbances that are periodic was not explicitly tackled in application to quadrupeds. This work is devoted to the estimation of the periodic disturbances with a lightweight regressor using simplified robot dynamics and extracting the disturbance properties in terms of the magnitude and frequency. Experimental evidence suggests performance improvement over the baseline static disturbance compensation. All source files, including simulation setups, code, and calculation scripts, are available on GitHub at https://github.com/aidagroup/quad-periodic-mpc.","authors":["Elizaveta Pestova","Ilya Osokin","Danil Belov","Pavel Osinenko"],"url":"https://arxiv.org/abs/2505.12361"}
{"created":"2025-05-20","title":"Towards Visuospatial Cognition via Hierarchical Fusion of Visual Experts","abstract":"While Multimodal Large Language Models (MLLMs) excel at general vision-language tasks, visuospatial cognition - reasoning about spatial layouts, relations, and dynamics - remains a significant challenge. Existing models often lack the necessary architectural components and specialized training data for fine-grained spatial understanding. We introduce ViCA2 (Visuospatial Cognitive Assistant 2), a novel MLLM designed to enhance spatial reasoning. ViCA2 features a dual vision encoder architecture integrating SigLIP for semantics and Hiera for spatial structure, coupled with a token ratio control mechanism for efficiency. We also developed ViCA-322K, a new large-scale dataset with over 322,000 spatially grounded question-answer pairs for targeted instruction tuning. On the challenging VSI-Bench benchmark, our ViCA2-7B model achieves a state-of-the-art average score of 56.8, significantly surpassing larger open-source models (e.g., LLaVA-NeXT-Video-72B, 40.9) and leading proprietary models (Gemini-1.5 Pro, 45.4). This demonstrates the effectiveness of our approach in achieving strong visuospatial intelligence with a compact model. We release ViCA2, its codebase, and the ViCA-322K dataset to facilitate further research.","authors":["Qi Feng (Kyoto University)","Hidetoshi Shimodaira (Kyoto University","RIKEN)"],"url":"https://arxiv.org/abs/2505.12363"}
{"created":"2025-05-20","title":"DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization","abstract":"The recent success and openness of DeepSeek-R1 have brought widespread attention to Group Relative Policy Optimization (GRPO) as a reinforcement learning method for large reasoning models (LRMs). In this work, we analyze the GRPO objective under a binary reward setting and reveal an inherent limitation of question-level difficulty bias. We also identify a connection between GRPO and traditional discriminative methods in supervised learning. Motivated by these insights, we introduce a new Discriminative Constrained Optimization (DisCO) framework for reinforcing LRMs, grounded in the principle of discriminative learning. The main differences between DisCO and GRPO and its recent variants are: (1) it replaces the group relative objective with a discriminative objective defined by a scoring function; (2) it abandons clipping-based surrogates in favor of non-clipping RL surrogate objectives used as scoring functions; (3) it employs a simple yet effective constrained optimization approach to enforce the KL divergence constraint, ensuring stable training. As a result, DisCO offers notable advantages over GRPO and its variants: (i) it completely eliminates difficulty bias by adopting discriminative objectives; (ii) it addresses the entropy instability in GRPO and its variants through the use of non-clipping scoring functions and a constrained optimization approach; (iii) it allows the incorporation of advanced discriminative learning techniques to address data imbalance, where a significant number of questions have more negative than positive generated answers during training. Our experiments on enhancing the mathematical reasoning capabilities of SFT-finetuned models show that DisCO significantly outperforms GRPO and its improved variants such as DAPO, achieving average gains of 7\\% over GRPO and 6\\% over DAPO across six benchmark tasks for an 1.5B model.","authors":["Gang Li","Ming Lin","Tomer Galanti","Zhengzhong Tu","Tianbao Yang"],"url":"https://arxiv.org/abs/2505.12366"}
{"created":"2025-05-20","title":"CAPTURE: Context-Aware Prompt Injection Testing and Robustness Enhancement","abstract":"Prompt injection remains a major security risk for large language models. However, the efficacy of existing guardrail models in context-aware settings remains underexplored, as they often rely on static attack benchmarks. Additionally, they have over-defense tendencies. We introduce CAPTURE, a novel context-aware benchmark assessing both attack detection and over-defense tendencies with minimal in-domain examples. Our experiments reveal that current prompt injection guardrail models suffer from high false negatives in adversarial cases and excessive false positives in benign scenarios, highlighting critical limitations.","authors":["Gauri Kholkar","Ratinder Ahuja"],"url":"https://arxiv.org/abs/2505.12368"}
{"created":"2025-05-20","title":"Fully Geometric Multi-Hop Reasoning on Knowledge Graphs with Transitive Relations","abstract":"Geometric embedding methods have shown to be useful for multi-hop reasoning on knowledge graphs by mapping entities and logical operations to geometric regions and geometric transformations, respectively. Geometric embeddings provide direct interpretability framework for queries. However, current methods have only leveraged the geometric construction of entities, failing to map logical operations to geometric transformations and, instead, using neural components to learn these operations. We introduce GeometrE, a geometric embedding method for multi-hop reasoning, which does not require learning the logical operations and enables full geometric interpretability. Additionally, unlike previous methods, we introduce a transitive loss function and show that it can preserve the logical rule $\\forall a,b,c: r(a,b) \\land r(b,c) \\to r(a,c)$. Our experiments show that GeometrE outperforms current state-of-the-art methods on standard benchmark datasets.","authors":["Fernando Zhapa-Camacho","Robert Hoehndorf"],"url":"https://arxiv.org/abs/2505.12369"}
{"created":"2025-05-20","title":"Enhancing Visual Grounding for GUI Agents via Self-Evolutionary Reinforcement Learning","abstract":"Graphical User Interface (GUI) agents have made substantial strides in understanding and executing user instructions across diverse platforms. Yet, grounding these instructions to precise interface elements remains challenging, especially in complex, high-resolution, professional environments. Traditional supervised finetuning (SFT) methods often require large volumes of diverse data and exhibit weak generalization. To overcome these limitations, we introduce a reinforcement learning (RL) based framework that incorporates three core strategies: (1) seed data curation to ensure high quality training samples, (2) a dense policy gradient that provides continuous feedback based on prediction accuracy, and (3) a self evolutionary reinforcement finetuning mechanism that iteratively refines the model using attention maps. With only 3k training samples, our 7B-parameter model achieves state-of-the-art results among similarly sized models on three grounding benchmarks. Notably, it attains 47.3\\% accuracy on the ScreenSpot-Pro dataset, outperforming much larger models, such as UI-TARS-72B, by a margin of 24.2\\%. These findings underscore the effectiveness of RL-based approaches in enhancing GUI agent performance, particularly in high-resolution, complex environments.","authors":["Xinbin Yuan","Jian Zhang","Kaixin Li","Zhuoxuan Cai","Lujian Yao","Jie Chen","Enguang Wang","Qibin Hou","Jinwei Chen","Peng-Tao Jiang","Bo Li"],"url":"https://arxiv.org/abs/2505.12370"}
{"created":"2025-05-20","title":"MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks","abstract":"The rapid advancement of Large Language Models (LLMs) has stimulated interest in multi-agent collaboration for addressing complex medical tasks. However, the practical advantages of multi-agent collaboration approaches remain insufficiently understood. Existing evaluations often lack generalizability, failing to cover diverse tasks reflective of real-world clinical practice, and frequently omit rigorous comparisons against both single-LLM-based and established conventional methods. To address this critical gap, we introduce MedAgentBoard, a comprehensive benchmark for the systematic evaluation of multi-agent collaboration, single-LLM, and conventional approaches. MedAgentBoard encompasses four diverse medical task categories: (1) medical (visual) question answering, (2) lay summary generation, (3) structured Electronic Health Record (EHR) predictive modeling, and (4) clinical workflow automation, across text, medical images, and structured EHR data. Our extensive experiments reveal a nuanced landscape: while multi-agent collaboration demonstrates benefits in specific scenarios, such as enhancing task completeness in clinical workflow automation, it does not consistently outperform advanced single LLMs (e.g., in textual medical QA) or, critically, specialized conventional methods that generally maintain better performance in tasks like medical VQA and EHR-based prediction. MedAgentBoard offers a vital resource and actionable insights, emphasizing the necessity of a task-specific, evidence-based approach to selecting and developing AI solutions in medicine. It underscores that the inherent complexity and overhead of multi-agent collaboration must be carefully weighed against tangible performance gains. All code, datasets, detailed prompts, and experimental results are open-sourced at https://medagentboard.netlify.app/.","authors":["Yinghao Zhu","Ziyi He","Haoran Hu","Xiaochen Zheng","Xichen Zhang","Zixiang Wang","Junyi Gao","Liantao Ma","Lequan Yu"],"url":"https://arxiv.org/abs/2505.12371"}
{"created":"2025-05-20","title":"Modeling Aesthetic Preferences in 3D Shapes: A Large-Scale Paired Comparison Study Across Object Categories","abstract":"Human aesthetic preferences for 3D shapes are central to industrial design, virtual reality, and consumer product development. However, most computational models of 3D aesthetics lack empirical grounding in large-scale human judgments, limiting their practical relevance. We present a large-scale study of human preferences. We collected 22,301 pairwise comparisons across five object categories (chairs, tables, mugs, lamps, and dining chairs) via Amazon Mechanical Turk. Building on a previously published dataset~\\cite{dev2020learning}, we introduce new non-linear modeling and cross-category analysis to uncover the geometric drivers of aesthetic preference. We apply the Bradley-Terry model to infer latent aesthetic scores and use Random Forests with SHAP analysis to identify and interpret the most influential geometric features (e.g., symmetry, curvature, compactness). Our cross-category analysis reveals both universal principles and domain-specific trends in aesthetic preferences. We focus on human interpretable geometric features to ensure model transparency and actionable design insights, rather than relying on black-box deep learning approaches. Our findings bridge computational aesthetics and cognitive science, providing practical guidance for designers and a publicly available dataset to support reproducibility. This work advances the understanding of 3D shape aesthetics through a human-centric, data-driven framework.","authors":["Kapil Dev (RMIT University","Melbourne","Australia)"],"url":"https://arxiv.org/abs/2505.12373"}
{"created":"2025-05-20","title":"Boxicity of Zero Divisor Graphs","abstract":"A $d$-dimensional box is the cartesian product $R_i\\times\\cdots\\times R_d$ where each $R_i$ is a closed interval on the real line. The boxicity of a graph, denoted as $box(G)$, is the minimum integer $d\\geq 0$ such that $G$ is the intersection graph of a collection of $d$-dimensional boxes. The study of graph classes associated with algebraic structures is a fascinating area where graph theory and algebra meet. A well-known class of graphs associated with rings is the class of zero divisor graphs introduced by Beck in 1988. Since then, this graph class has been studied extensively by several researchers. Denote by $Z(R)$ the set of zero divisors of a ring $R$. The zero divisor graph $\\Gamma(R)$ for a ring $R$ is defined as the graph with the vertex set $V(\\Gamma(R))=Z(R)$ and $E(\\Gamma(R))=\\{\\{a_i,a_j\\}:a_ia_j\\in Z(R)\\text{ and }a_ia_j=0 \\}$. Let $N=\\Pi_{i=1}^ap_i^{n_i}$ be the prime factorization of $N$. In Discrete Applied Mathematics 365 (2025), pp. 260-269, it was shown that $box(\\Gamma(\\mathbb{Z}_N))\\leq\\Pi_{i=1}^a(n_i+1)-\\Pi_{i=1}^a(\\lfloor n_i/2\\rfloor+1)-1$. In this paper we exactly determine the boxicity of $\\Gamma(\\mathbb{Z}_N)$: We show that when $N\\equiv 2\\pmod 4$ and $N$ is not divisible by $p^3$ for any prime divisor $p$, we have $box(\\Gamma(\\mathbb{Z}_N))=a-1$. Otherwise $box(\\Gamma(\\mathbb{Z}_N))=a$. Suppose $R$ is a non-zero commutative ring with identity that is also a reduced ring and let $k$ be the size of the set of minimal prime ideals of $R$. In the same paper, it was showed that $box(\\Gamma(R))\\leq 2^k-2$. We improve this result by showing $\\lfloor k/2\\rfloor\\leq box(\\Gamma(R))\\leq k$ with the same assumption on $R$. In this paper we also show that $a-1\\leq\\dim_{TH}(\\Gamma(\\mathbb{Z}_N))\\leq a$ and $\\lfloor k/2\\rfloor\\leq\\dim_{TH}(\\Gamma(R))\\leq k$, where $\\dim_{TH}$ is another dimensional parameter associated with graphs known as the threshold dimension.","authors":["L. Sunil Chandran","Suraj Kumar Sahoo"],"url":"https://arxiv.org/abs/2505.12376"}
{"created":"2025-05-20","title":"Multi-Organizational Scheduling: Individual Rationality, Optimality, and Complexity","abstract":"We investigate multi-organizational scheduling problems, building upon the framework introduced by Pascual et al.[2009]. In this setting, multiple organizations each own a set of identical machines and sequential jobs with distinct processing times. The challenge lies in optimally assigning jobs across organizations' machines to minimize the overall makespan while ensuring no organization's performance deteriorates. To formalize this fairness constraint, we introduce individual rationality, a game-theoretic concept that guarantees each organization benefits from participation.","authors":["Jiehua Chen","Martin Durand","Christian Hatschka"],"url":"https://arxiv.org/abs/2505.12377"}
{"created":"2025-05-20","title":"Graph-Reward-SQL: Execution-Free Reinforcement Learning for Text-to-SQL via Graph Matching and Stepwise Reward","abstract":"Reinforcement learning (RL) has been widely adopted to enhance the performance of large language models (LLMs) on Text-to-SQL tasks. However, existing methods often rely on execution-based or LLM-based Bradley-Terry reward models. The former suffers from high execution latency caused by repeated database calls, whereas the latter imposes substantial GPU memory overhead, both of which significantly hinder the efficiency and scalability of RL pipelines. To this end, we propose a novel Text-to-SQL RL fine-tuning framework named Graph-Reward-SQL, which employs the GMNScore outcome reward model. We leverage SQL graph representations to provide accurate reward signals while significantly reducing inference time and GPU memory usage. Building on this foundation, we further introduce StepRTM, a stepwise reward model that provides intermediate supervision over Common Table Expression (CTE) subqueries. This encourages both functional correctness and structural clarity of SQL. Extensive comparative and ablation experiments on standard benchmarks, including Spider and BIRD, demonstrate that our method consistently outperforms existing reward models.","authors":["Han Weng","Boyi Liu","Yuanfeng Song","Dun Zeng","Yingxiang Yang","Yi Zhan","Longjie Cui","Xiaoming Yin","Yang Sun"],"url":"https://arxiv.org/abs/2505.12380"}
{"created":"2025-05-20","title":"From n-gram to Attention: How Model Architectures Learn and Propagate Bias in Language Modeling","abstract":"Current research on bias in language models (LMs) predominantly focuses on data quality, with significantly less attention paid to model architecture and temporal influences of data. Even more critically, few studies systematically investigate the origins of bias. We propose a methodology grounded in comparative behavioral theory to interpret the complex interaction between training data and model architecture in bias propagation during language modeling. Building on recent work that relates transformers to n-gram LMs, we evaluate how data, model design choices, and temporal dynamics affect bias propagation. Our findings reveal that: (1) n-gram LMs are highly sensitive to context window size in bias propagation, while transformers demonstrate architectural robustness; (2) the temporal provenance of training data significantly affects bias; and (3) different model architectures respond differentially to controlled bias injection, with certain biases (e.g. sexual orientation) being disproportionately amplified. As language models become ubiquitous, our findings highlight the need for a holistic approach -- tracing bias to its origins across both data and model dimensions, not just symptoms, to mitigate harm.","authors":["Mohsinul Kabir","Tasfia Tahsin","Sophia Ananiadou"],"url":"https://arxiv.org/abs/2505.12381"}
{"created":"2025-05-20","title":"Generative Diffusion Model Driven Massive Random Access in Massive MIMO Systems","abstract":"Massive random access is an important technology for achieving ultra-massive connectivity in next-generation wireless communication systems. It aims to address key challenges during the initial access phase, including active user detection (AUD), channel estimation (CE), and data detection (DD). This paper examines massive access in massive multiple-input multiple-output (MIMO) systems, where deep learning is used to tackle the challenging AUD, CE, and DD functions. First, we introduce a Transformer-AUD scheme tailored for variable pilot-length access. This approach integrates pilot length information and a spatial correlation module into a Transformer-based detector, enabling a single model to generalize across various pilot lengths and antenna numbers. Next, we propose a generative diffusion model (GDM)-driven iterative CE and DD framework. The GDM employs a score function to capture the posterior distributions of massive MIMO channels and data symbols. Part of the score function is learned from the channel dataset via neural networks, while the remaining score component is derived in a closed form by applying the symbol prior constellation distribution and known transmission model. Utilizing these posterior scores, we design an asynchronous alternating CE and DD framework that employs a predictor-corrector sampling technique to iteratively generate channel estimation and data detection results during the reverse diffusion process. Simulation results demonstrate that our proposed approaches significantly outperform baseline methods with respect to AUD, CE, and DD.","authors":["Keke Ying","Zhen Gao","Sheng Chen","Tony Q. S. Quek","H. Vincent Poor"],"url":"https://arxiv.org/abs/2505.12382"}
{"created":"2025-05-20","title":"Is Semantic SLAM Ready for Embedded Systems ? A Comparative Survey","abstract":"In embedded systems, robots must perceive and interpret their environment efficiently to operate reliably in real-world conditions. Visual Semantic SLAM (Simultaneous Localization and Mapping) enhances standard SLAM by incorporating semantic information into the map, enabling more informed decision-making. However, implementing such systems on resource-limited hardware involves trade-offs between accuracy, computing efficiency, and power usage.","authors":["Calvin Galagain","Martyna Poreba","Fran\\c{c}ois Goulette"],"url":"https://arxiv.org/abs/2505.12384"}
{"created":"2025-05-20","title":"Data Sharing with a Generative AI Competitor","abstract":"As GenAI platforms grow, their dependence on content from competing providers, combined with access to alternative data sources, creates new challenges for data-sharing decisions. In this paper, we provide a model of data sharing between a content creation firm and a GenAI platform that can also acquire content from third-party experts. The interaction is modeled as a Stackelberg game: the firm first decides how much of its proprietary dataset to share with GenAI, and GenAI subsequently determines how much additional data to acquire from external experts. Their utilities depend on user traffic, monetary transfers, and the cost of acquiring additional data from external experts. We characterize the unique subgame perfect equilibrium of the game and uncover a surprising phenomenon: The firm may be willing to pay GenAI to share the firm's own data, leading to a costly data-sharing equilibrium. We further characterize the set of Pareto improving data prices, and show that such improvements occur only when the firm pays to share data. Finally, we study how the price can be set to optimize different design objectives, such as promoting firm data sharing, expert data acquisition, or a balance of both. Our results shed light on the economic forces shaping data-sharing partnerships in the age of GenAI, and provide guidance for platforms, regulators and policymakers seeking to design effective data exchange mechanisms.","authors":["Boaz Taitler","Omer Madmon","Moshe Tennenholtz","Omer Ben-Porat"],"url":"https://arxiv.org/abs/2505.12386"}
{"created":"2025-05-20","title":"Neural Thermodynamics I: Entropic Forces in Deep and Universal Representation Learning","abstract":"With the rapid discovery of emergent phenomena in deep learning and large language models, explaining and understanding their cause has become an urgent need. Here, we propose a rigorous entropic-force theory for understanding the learning dynamics of neural networks trained with stochastic gradient descent (SGD) and its variants. Building on the theory of parameter symmetries and an entropic loss landscape, we show that representation learning is crucially governed by emergent entropic forces arising from stochasticity and discrete-time updates. These forces systematically break continuous parameter symmetries and preserve discrete ones, leading to a series of gradient balance phenomena that resemble the equipartition property of thermal systems. These phenomena, in turn, (a) explain the universal alignment of neural representations between AI models and lead to a proof of the Platonic Representation Hypothesis, and (b) reconcile the seemingly contradictory observations of sharpness- and flatness-seeking behavior of deep learning optimization. Our theory and experiments demonstrate that a combination of entropic forces and symmetry breaking is key to understanding emergent phenomena in deep learning.","authors":["Liu Ziyin","Yizhou Xu","Isaac Chuang"],"url":"https://arxiv.org/abs/2505.12387"}
{"created":"2025-05-20","title":"Impact of Power Fluctuations on Frequency Quality","abstract":"This paper analyzes how power injections affect frequency quality in power systems. We first derive a general expression linking active and reactive power injections at buses to the system's frequency. This formulation explicitly considers both real and imaginary frequency components, providing a complete description of frequency behavior in power systems during transients. Next, we extend our analysis to incorporate stochastic variations of power injections. Using the frequency divider concept and power-based frequency estimation, we develop analytical relationships linking stochastic load fluctuations to frequency deviations. We discuss under which conditions the Central Limit Theorem cannot be applied to capture the frequency distribution, thereby clarifying how its hypotheses are not satisfied in power system applications. Then, we establish clear criteria for the appropriate use of statistical methods in frequency analysis. Finally, we validate our theoretical results through simulations on modified IEEE 14-bus and all-island Irish transmission test systems, highlighting the accuracy, practical utility, and limitations of our proposed formulation.","authors":["Angel Vaca","Federico Milano"],"url":"https://arxiv.org/abs/2505.12388"}
{"created":"2025-05-20","title":"Engineering application of physics-informed neural networks for Saint-Venant torsion","abstract":"The Saint-Venant torsion theory is a classical theory for analyzing the torsional behavior of structural components, and it remains critically important in modern computational design workflows. Conventional numerical methods, including the finite element method (FEM), typically rely on mesh-based approaches to obtain approximate solutions. However, these methods often require complex and computationally intensive techniques to overcome the limitations of approximation, leading to significant increases in computational cost. The objective of this study is to develop a series of novel numerical methods based on physics-informed neural networks (PINN) for solving the Saint-Venant torsion equations. Utilizing the expressive power and the automatic differentiation capability of neural networks, the PINN can solve partial differential equations (PDEs) along with boundary conditions without the need for intricate computational techniques. First, a PINN solver was developed to compute the torsional constant for bars with arbitrary cross-sectional geometries. This was followed by the development of a solver capable of handling cases with sharp geometric transitions; variable-scaling PINN (VS-PINN). Finally, a parametric PINN was constructed to address the limitations of conventional single-instance PINN. The results from all three solvers showed good agreement with reference solutions, demonstrating their accuracy and robustness. Each solver can be selectively utilized depending on the specific requirements of torsional behavior analysis.","authors":["Su Yeong Jo","Sanghyeon Park","Seungchan Ko","Jongcheon Park","Hosung Kim","Sangseung Lee","Joongoo Jeon"],"url":"https://arxiv.org/abs/2505.12389"}
{"created":"2025-05-20","title":"CLIP-aware Domain-Adaptive Super-Resolution","abstract":"This work introduces CLIP-aware Domain-Adaptive Super-Resolution (CDASR), a novel framework that addresses the critical challenge of domain generalization in single image super-resolution. By leveraging the semantic capabilities of CLIP (Contrastive Language-Image Pre-training), CDASR achieves unprecedented performance across diverse domains and extreme scaling factors. The proposed method integrates CLIP-guided feature alignment mechanism with a meta-learning inspired few-shot adaptation strategy, enabling efficient knowledge transfer and rapid adaptation to target domains. A custom domain-adaptive module processes CLIP features alongside super-resolution features through a multi-stage transformation process, including CLIP feature processing, spatial feature generation, and feature fusion. This intricate process ensures effective incorporation of semantic information into the super-resolution pipeline. Additionally, CDASR employs a multi-component loss function that combines pixel-wise reconstruction, perceptual similarity, and semantic consistency. Extensive experiments on benchmark datasets demonstrate CDASR's superiority, particularly in challenging scenarios. On the Urban100 dataset at $\\times$8 scaling, CDASR achieves a significant PSNR gain of 0.15dB over existing methods, with even larger improvements of up to 0.30dB observed at $\\times$16 scaling.","authors":["Zhengyang Lu","Qian Xia","Weifan Wang","Feng Wang"],"url":"https://arxiv.org/abs/2505.12391"}
{"created":"2025-05-20","title":"SLOT: Sample-specific Language Model Optimization at Test-time","abstract":"We propose SLOT (Sample-specific Language Model Optimization at Test-time), a novel and parameter-efficient test-time inference approach that enhances a language model's ability to more accurately respond to individual prompts. Existing Large Language Models (LLMs) often struggle with complex instructions, leading to poor performances on those not well represented among general samples. To address this, SLOT conducts few optimization steps at test-time to update a light-weight sample-specific parameter vector. It is added to the final hidden layer before the output head, and enables efficient adaptation by caching the last layer features during per-sample optimization. By minimizing the cross-entropy loss on the input prompt only, SLOT helps the model better aligned with and follow each given instruction. In experiments, we demonstrate that our method outperforms the compared models across multiple benchmarks and LLMs. For example, Qwen2.5-7B with SLOT achieves an accuracy gain of 8.6% on GSM8K from 57.54% to 66.19%, while DeepSeek-R1-Distill-Llama-70B with SLOT achieves a SOTA accuracy of 68.69% on GPQA among 70B-level models. Our code is available at https://github.com/maple-research-lab/SLOT.","authors":["Yang Hu","Xingyu Zhang","Xueji Fang","Zhiyang Chen","Xiao Wang","Huatian Zhang","Guojun Qi"],"url":"https://arxiv.org/abs/2505.12392"}
{"created":"2025-05-20","title":"Protocol as Poetry: Case Study on Pak's Protocol Arts","abstract":"Protocol art emerges at the confluence of blockchain-based smart contracts and a century-long lineage of conceptual art, participatory art, and algorithmic generative art practices. Yet existing definitions-most notably Primavera De Filippi's \"protocolism\"-struggle to demarcate this nascent genre from other art forms in practice. Addressing this definition-to-practice gap, this paper offers a focused case study of pioneering protocol artworks by Pak, an early and influential pseudonymous protocol artist who treats smart contracts as medium and protocol participation as message. Tracing the evolution from early open-edition releases of The Fungible and the dynamic mechanics of Merge to the soul-bound messaging of Censored and the reflective absence of Not Found, we examine how Pak choreographs distributed agency across collectors and autonomous contracts, showing how programmable protocols become a social fabric in artistic meaning-making. Through thematic analysis of Pak's works, we identify seven core characteristics that distinguish protocol art: (1) system-centric rather than object-centric composition, (2) autonomous governance for open-ended control, (3) distributed agency and communal authorship, (4) temporal dynamism and lifecycle aesthetics, (5) economic-driven engagement, (6) poetic message embedding in interaction rituals, and (7) interoperability enabling composability for emergence. We then discuss how these features set protocol art apart from adjacent artistic movements. By developing a theoretical framework grounded in Pak's practice, we contribute to the emerging literature on protocolism while offering design implications for artists shaping this evolving art form.","authors":["Botao Amber Hu"],"url":"https://arxiv.org/abs/2505.12393"}
{"created":"2025-05-20","title":"Data-Efficient Automatic Shaping of Liquid Droplets on an Air-Ferrofluid Interface with Bayesian Optimization","abstract":"Manipulating the shape of a liquid droplet is essential for a wide range of applications in medicine and industry. However, existing methods are typically limited to generating simple shapes, such as ellipses, or rely on predefined templates. Although recent approaches have demonstrated more complex geometries, they remain constrained by limited adaptability and lack of real-time control. Here, we introduce a data-efficient method that enables real-time, programmable shaping of nonmagnetic liquid droplets into diverse target forms at the air-ferrofluid interface using Bayesian optimization. The droplet can adopt either convex or concave shapes depending on the actuation of the surrounding electromagnets. Bayesian optimization determines the optimal magnetic flux density for shaping the liquid droplet into a desired target shape. Our method enables automatic shaping into various triangular and rectangular shapes with a maximum shape error of 0.81 mm, as well as into letter-like patterns. To the best of our knowledge, this is the first demonstration of real-time, automatic shaping of nonmagnetic liquid droplets into desired target shapes using magnetic fields or other external energy fields.","authors":["P. A. Diluka Harischandra","Quan Zhou"],"url":"https://arxiv.org/abs/2505.12394"}
{"created":"2025-05-20","title":"Few-Shot Concept Unlearning with Low Rank Adaptation","abstract":"Image Generation models are a trending topic nowadays, with many people utilizing Artificial Intelligence models in order to generate images. There are many such models which, given a prompt of a text, will generate an image which depicts said prompt. There are many image generation models, such as Latent Diffusion Models, Denoising Diffusion Probabilistic Models, Generative Adversarial Networks and many more. When generating images, these models can generate sensitive image data, which can be threatening to privacy or may violate copyright laws of private entities. Machine unlearning aims at removing the influence of specific data subsets from the trained models and in the case of image generation models, remove the influence of a concept such that the model is unable to generate said images of the concept when prompted. Conventional retraining of the model can take upto days, hence fast algorithms are the need of the hour. In this paper we propose an algorithm that aims to remove the influence of concepts in diffusion models through updating the gradients of the final layers of the text encoders. Using a weighted loss function, we utilize backpropagation in order to update the weights of the final layers of the Text Encoder componet of the Stable Diffusion Model, removing influence of the concept from the text-image embedding space, such that when prompted, the result is an image not containing the concept. The weighted loss function makes use of Textual Inversion and Low-Rank Adaptation.We perform our experiments on Latent Diffusion Models, namely the Stable Diffusion v2 model, with an average concept unlearning runtime of 50 seconds using 4-5 images.","authors":["Udaya Shreyas","L. N. Aadarsh"],"url":"https://arxiv.org/abs/2505.12395"}
{"created":"2025-05-20","title":"LLM-CoT Enhanced Graph Neural Recommendation with Harmonized Group Policy Optimization","abstract":"Graph neural networks (GNNs) have advanced recommender systems by modeling interaction relationships. However, existing graph-based recommenders rely on sparse ID features and do not fully exploit textual information, resulting in low information density within representations. Furthermore, graph contrastive learning faces challenges. Random negative sampling can introduce false negative samples, while fixed temperature coefficients cannot adapt to the heterogeneity of different nodes. In addition, current efforts to enhance recommendations with large language models (LLMs) have not fully utilized their Chain-of-Thought (CoT) reasoning capabilities to guide representation learning. To address these limitations, we introduces LGHRec (LLM-CoT Enhanced Graph Neural Recommendation with Harmonized Group Policy Optimization). This framework leverages the CoT reasoning ability of LLMs to generate semantic IDs, enriching reasoning processes and improving information density and semantic quality of representations. Moreover, we design a reinforcement learning algorithm, Harmonized Group Policy Optimization (HGPO), to optimize negative sampling strategies and temperature coefficients in contrastive learning. This approach enhances long-tail recommendation performance and ensures optimization consistency across different groups. Experimental results on three datasets demonstrate that LGHRec improves representation quality through semantic IDs generated by LLM's CoT reasoning and effectively boosts contrastive learning with HGPO. Our method outperforms several baseline models. The code is available at: https://anonymous.4open.science/r/LLM-Rec.","authors":["Hailong Luo","Bin Wu","Hongyong Jia","Qingqing Zhu","Lianlei Shan"],"url":"https://arxiv.org/abs/2505.12396"}
{"created":"2025-05-20","title":"Traversal Verification for Speculative Tree Decoding","abstract":"Speculative decoding is a promising approach for accelerating large language models. The primary idea is to use a lightweight draft model to speculate the output of the target model for multiple subsequent timesteps, and then verify them in parallel to determine whether the drafted tokens should be accepted or rejected. To enhance acceptance rates, existing frameworks typically construct token trees containing multiple candidates in each timestep. However, their reliance on token-level verification mechanisms introduces two critical limitations: First, the probability distribution of a sequence differs from that of individual tokens, leading to suboptimal acceptance length. Second, current verification schemes begin from the root node and proceed layer by layer in a top-down manner. Once a parent node is rejected, all its child nodes should be discarded, resulting in inefficient utilization of speculative candidates. This paper introduces Traversal Verification, a novel speculative decoding algorithm that fundamentally rethinks the verification paradigm through leaf-to-root traversal. Our approach considers the acceptance of the entire token sequence from the current node to the root, and preserves potentially valid subsequences that would be prematurely discarded by existing methods. We theoretically prove that the probability distribution obtained through Traversal Verification is identical to that of the target model, guaranteeing lossless inference while achieving substantial acceleration gains. Experimental results across different large language models and multiple tasks show that our method consistently improves acceptance length and throughput over existing methods","authors":["Yepeng Weng","Qiao Hu","Xujie Chen","Li Liu","Dianwen Mei","Huishi Qiu","Jiang Tian","Zhongchao Shi"],"url":"https://arxiv.org/abs/2505.12398"}
{"created":"2025-05-20","title":"Optimizing Interplanetary Trajectories using Hybrid Meta-heuristic","abstract":"This paper proposes an advanced hybrid optimization (GMPA) algorithm to effectively address the inherent limitations of the Grey Wolf Optimizer (GWO) when applied to complex optimization scenarios. Specifically, GMPA integrates essential features from the Marine Predators Algorithm (MPA) into the GWO framework, enabling superior performance through enhanced exploration and exploitation balance. The evaluation utilizes the GTOPX benchmark dataset from the European Space Agency (ESA), encompassing highly complex interplanetary trajectory optimization problems characterized by pronounced nonlinearity and multiple conflicting objectives reflective of real-world aerospace scenarios. Central to GMPA's methodology is an elite matrix, borrowed from MPA, designed to preserve and refine high-quality solutions iteratively, thereby promoting solution diversity and minimizing premature convergence. Furthermore, GMPA incorporates a three-phase position updating mechanism combined with L\\'evy flights and Brownian motion to significantly bolster exploration capabilities, effectively mitigating the risk of stagnation in local optima. GMPA dynamically retains historical information on promising search areas, leveraging the memory storage features intrinsic to MPA, facilitating targeted exploitation and refinement. Empirical evaluations demonstrate GMPA's superior effectiveness compared to traditional GWO and other advanced metaheuristic algorithms, achieving markedly improved convergence rates and solution quality across GTOPX benchmarks. Consequently, GMPA emerges as a robust, efficient, and adaptive optimization approach particularly suitable for high-dimensional and complex aerospace trajectory optimization, offering significant insights and practical advancements in hybrid metaheuristic optimization techniques.","authors":["Amin Abdollahi Dehkordi","Mehdi Neshat"],"url":"https://arxiv.org/abs/2505.12399"}
{"created":"2025-05-20","title":"Automated Profile Inference with Language Model Agents","abstract":"Impressive progress has been made in automated problem-solving by the collaboration of large language models (LLMs) based agents. However, these automated capabilities also open avenues for malicious applications. In this paper, we study a new threat that LLMs pose to online pseudonymity, called automated profile inference, where an adversary can instruct LLMs to automatically scrape and extract sensitive personal attributes from publicly visible user activities on pseudonymous platforms. We also introduce an automated profiling framework called AutoProfiler to assess the feasibility of such threats in real-world scenarios. AutoProfiler consists of four specialized LLM agents, who work collaboratively to collect and process user online activities and generate a profile with extracted personal information. Experimental results on two real-world datasets and one synthetic dataset demonstrate that AutoProfiler is highly effective and efficient, and can be easily deployed on a web scale. We demonstrate that the inferred attributes are both sensitive and identifiable, posing significant risks of privacy breaches, such as de-anonymization and sensitive information leakage. Additionally, we explore mitigation strategies from different perspectives and advocate for increased public awareness of this emerging privacy threat to online pseudonymity.","authors":["Yuntao Du","Zitao Li","Bolin Ding","Yaliang Li","Hanshen Xiao","Jingren Zhou","Ninghui Li"],"url":"https://arxiv.org/abs/2505.12402"}
{"created":"2025-05-20","title":"Hyperbolic Residual Quantization: Discrete Representations for Data with Latent Hierarchies","abstract":"Hierarchical data arise in countless domains, from biological taxonomies and organizational charts to legal codes and knowledge graphs. Residual Quantization (RQ) is widely used to generate discrete, multitoken representations for such data by iteratively quantizing residuals in a multilevel codebook. However, its reliance on Euclidean geometry can introduce fundamental mismatches that hinder modeling of hierarchical branching, necessary for faithful representation of hierarchical data. In this work, we propose Hyperbolic Residual Quantization (HRQ), which embeds data natively in a hyperbolic manifold and performs residual quantization using hyperbolic operations and distance metrics. By adapting the embedding network, residual computation, and distance metric to hyperbolic geometry, HRQ imparts an inductive bias that aligns naturally with hierarchical branching. We claim that HRQ in comparison to RQ can generate more useful for downstream tasks discrete hierarchical representations for data with latent hierarchies. We evaluate HRQ on two tasks: supervised hierarchy modeling using WordNet hypernym trees, where the model is supervised to learn the latent hierarchy - and hierarchy discovery, where, while latent hierarchy exists in the data, the model is not directly trained or evaluated on a task related to the hierarchy. Across both scenarios, HRQ hierarchical tokens yield better performance on downstream tasks compared to Euclidean RQ with gains of up to $20\\%$ for the hierarchy modeling task. Our results demonstrate that integrating hyperbolic geometry into discrete representation learning substantially enhances the ability to capture latent hierarchies.","authors":["Piotr Pi\\k{e}kos","Subhradeep Kayal","Alexandros Karatzoglou"],"url":"https://arxiv.org/abs/2505.12404"}
{"created":"2025-05-20","title":"The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT","abstract":"Generative AI paraphrased text can be used for copyright infringement and the AI paraphrased content can deprive substantial revenue from original content creators. Despite this recent surge of malicious use of generative AI, there are few academic publications that research this threat. In this article, we demonstrate the ability of pattern-based similarity detection for AI paraphrased news recognition. We propose an algorithmic scheme, which is not limited to detect whether an article is an AI paraphrase, but, more importantly, to identify that the source of infringement is the ChatGPT. The proposed method is tested with a benchmark dataset specifically created for this task that incorporates real articles from BBC, incorporating a total of 2,224 articles across five different news categories, as well as 2,224 paraphrased articles created with ChatGPT. Results show that our pattern similarity-based method, that makes no use of deep learning, can detect ChatGPT assisted paraphrased articles at percentages 96.23% for accuracy, 96.25% for precision, 96.21% for sensitivity, 96.25% for specificity and 96.23% for F1 score.","authors":["Konstantinos Xylogiannopoulos","Petros Xanthopoulos","Panagiotis Karampelas","Georgios Bakamitsos"],"url":"https://arxiv.org/abs/2505.12405"}
{"created":"2025-05-20","title":"Steady-State Strategy Synthesis for Swarms of Autonomous Agents","abstract":"Steady-state synthesis aims to construct a policy for a given MDP $D$ such that the long-run average frequencies of visits to the vertices of $D$ satisfy given numerical constraints. This problem is solvable in polynomial time, and memoryless policies are sufficient for approximating an arbitrary frequency vector achievable by a general (infinite-memory) policy.","authors":["Martin Jon\\'a\\v{s}","Anton\\'in Ku\\v{c}era","Vojt\\v{e}ch K\\r{u}r","Jan Ma\\v{c}\\'ak"],"url":"https://arxiv.org/abs/2505.12406"}
{"created":"2025-05-20","title":"ViEEG: Hierarchical Neural Coding with Cross-Modal Progressive Enhancement for EEG-Based Visual Decoding","abstract":"Understanding and decoding brain activity into visual representations is a fundamental challenge at the intersection of neuroscience and artificial intelligence. While EEG-based visual decoding has shown promise due to its non-invasive, low-cost nature and millisecond-level temporal resolution, existing methods are limited by their reliance on flat neural representations that overlook the brain's inherent visual hierarchy. In this paper, we introduce ViEEG, a biologically inspired hierarchical EEG decoding framework that aligns with the Hubel-Wiesel theory of visual processing. ViEEG decomposes each visual stimulus into three biologically aligned components-contour, foreground object, and contextual scene-serving as anchors for a three-stream EEG encoder. These EEG features are progressively integrated via cross-attention routing, simulating cortical information flow from V1 to IT to the association cortex. We further adopt hierarchical contrastive learning to align EEG representations with CLIP embeddings, enabling zero-shot object recognition. Extensive experiments on the THINGS-EEG dataset demonstrate that ViEEG achieves state-of-the-art performance, with 40.9% Top-1 accuracy in subject-dependent and 22.9% Top-1 accuracy in cross-subject settings, surpassing existing methods by over 45%. Our framework not only advances the performance frontier but also sets a new paradigm for biologically grounded brain decoding in AI.","authors":["Minxu Liu","Donghai Guan","Chuhang Zheng","Chunwei Tian","Jie Wen","Qi Zhu"],"url":"https://arxiv.org/abs/2505.12408"}
{"created":"2025-05-20","title":"MTIL: Encoding Full History with Mamba for Temporal Imitation Learning","abstract":"Standard imitation learning (IL) methods have achieved considerable success in robotics, yet often rely on the Markov assumption, limiting their applicability to tasks where historical context is crucial for disambiguating current observations. This limitation hinders performance in long-horizon sequential manipulation tasks where the correct action depends on past events not fully captured by the current state. To address this fundamental challenge, we introduce Mamba Temporal Imitation Learning (MTIL), a novel approach that leverages the recurrent state dynamics inherent in State Space Models (SSMs), specifically the Mamba architecture. MTIL encodes the entire trajectory history into a compressed hidden state, conditioning action predictions on this comprehensive temporal context alongside current multi-modal observations. Through extensive experiments on simulated benchmarks (ACT dataset tasks, Robomimic, LIBERO) and real-world sequential manipulation tasks specifically designed to probe temporal dependencies, MTIL significantly outperforms state-of-the-art methods like ACT and Diffusion Policy. Our findings affirm the necessity of full temporal context for robust sequential decision-making and validate MTIL as a powerful approach that transcends the inherent limitations of Markovian imitation learning","authors":["Yulin Zhou","Yuankai Lin","Fanzhe Peng","Jiahui Chen","Zhuang Zhou","Kaiji Huang","Hua Yang","Zhouping Yin"],"url":"https://arxiv.org/abs/2505.12410"}
{"created":"2025-05-20","title":"It Takes a Graph to Know a Graph: Rewiring for Homophily with a Reference Graph","abstract":"Graph Neural Networks (GNNs) excel at analyzing graph-structured data but struggle on heterophilic graphs, where connected nodes often belong to different classes. While this challenge is commonly addressed with specialized GNN architectures, graph rewiring remains an underexplored strategy in this context. We provide theoretical foundations linking edge homophily, GNN embedding smoothness, and node classification performance, motivating the need to enhance homophily. Building on this insight, we introduce a rewiring framework that increases graph homophily using a reference graph, with theoretical guarantees on the homophily of the rewired graph. To broaden applicability, we propose a label-driven diffusion approach for constructing a homophilic reference graph from node features and training labels. Through extensive simulations, we analyze how the homophily of both the original and reference graphs influences the rewired graph homophily and downstream GNN performance. We evaluate our method on 11 real-world heterophilic datasets and show that it outperforms existing rewiring techniques and specialized GNNs for heterophilic graphs, achieving improved node classification accuracy while remaining efficient and scalable to large graphs.","authors":["Harel Mendelman","Haggai Maron","Ronen Talmon"],"url":"https://arxiv.org/abs/2505.12411"}
{"created":"2025-05-20","title":"Table-R1: Region-based Reinforcement Learning for Table Understanding","abstract":"Tables present unique challenges for language models due to their structured row-column interactions, necessitating specialized approaches for effective comprehension. While large language models (LLMs) have demonstrated potential in table reasoning through prompting and techniques like chain-of-thought (CoT) and program-of-thought (PoT), optimizing their performance for table question answering remains underexplored. In this paper, we introduce region-based Table-R1, a novel reinforcement learning approach that enhances LLM table understanding by integrating region evidence into reasoning steps. Our method employs Region-Enhanced Supervised Fine-Tuning (RE-SFT) to guide models in identifying relevant table regions before generating answers, incorporating textual, symbolic, and program-based reasoning. Additionally, Table-Aware Group Relative Policy Optimization (TARPO) introduces a mixed reward system to dynamically balance region accuracy and answer correctness, with decaying region rewards and consistency penalties to align reasoning steps. Experiments show that Table-R1 achieves an average performance improvement of 14.36 points across multiple base models on three benchmark datasets, even outperforming baseline models with ten times the parameters, while TARPO reduces response token consumption by 67.5% compared to GRPO, significantly advancing LLM capabilities in efficient tabular reasoning.","authors":["Zhenhe Wu","Jian Yang","Jiaheng Liu","Xianjie Wu","Changzai Pan","Jie Zhang","Yu Zhao","Shuangyong Song","Yongxiang Li","Zhoujun Li"],"url":"https://arxiv.org/abs/2505.12415"}
{"created":"2025-05-20","title":"Embedding principle of homogeneous neural network for classification problem","abstract":"Understanding the convergence points and optimization landscape of neural networks is crucial, particularly for homogeneous networks where Karush-Kuhn-Tucker (KKT) points of the associated maximum-margin problem often characterize solutions. This paper investigates the relationship between such KKT points across networks of different widths generated via neuron splitting. We introduce and formalize the \\textbf{KKT point embedding principle}, establishing that KKT points of a homogeneous network's max-margin problem ($P_{\\Phi}$) can be embedded into the KKT points of a larger network's problem ($P_{\\tilde{\\Phi}}$) via specific linear isometric transformations corresponding to neuron splitting. We rigorously prove this principle holds for neuron splitting in both two-layer and deep homogeneous networks. Furthermore, we connect this static embedding to the dynamics of gradient flow training with smooth losses. We demonstrate that trajectories initiated from appropriately mapped points remain mapped throughout training and that the resulting $\\omega$-limit sets of directions are correspondingly mapped ($T(L(\\theta(0))) = L(\\boldsymbol{\\eta}(0))$), thereby preserving the alignment with KKT directions dynamically when directional convergence occurs. Our findings offer insights into the effects of network width, parameter redundancy, and the structural connections between solutions found via optimization in homogeneous networks of varying sizes.","authors":["Jiahan Zhang","Tao Luo","Yaoyu Zhang"],"url":"https://arxiv.org/abs/2505.12419"}
{"created":"2025-05-20","title":"Fixed Point Explainability","abstract":"This paper introduces a formal notion of fixed point explanations, inspired by the \"why regress\" principle, to assess, through recursive applications, the stability of the interplay between a model and its explainer. Fixed point explanations satisfy properties like minimality, stability, and faithfulness, revealing hidden model behaviours and explanatory weaknesses. We define convergence conditions for several classes of explainers, from feature-based to mechanistic tools like Sparse AutoEncoders, and we report quantitative and qualitative results.","authors":["Emanuele La Malfa","Jon Vadillo","Marco Molinari","Michael Wooldridge"],"url":"https://arxiv.org/abs/2505.12421"}
{"created":"2025-05-20","title":"PSC: Extending Context Window of Large Language Models via Phase Shift Calibration","abstract":"Rotary Position Embedding (RoPE) is an efficient position encoding approach and is widely utilized in numerous large language models (LLMs). Recently, a lot of methods have been put forward to further expand the context window based on RoPE. The core concept of those methods is to predefine or search for a set of factors to rescale the base frequencies of RoPE. Nevertheless, it is quite a challenge for existing methods to predefine an optimal factor due to the exponential search space. In view of this, we introduce PSC (Phase Shift Calibration), a small module for calibrating the frequencies predefined by existing methods. With the employment of PSC, we demonstrate that many existing methods can be further enhanced, like PI, YaRN, and LongRoPE. We conducted extensive experiments across multiple models and tasks. The results demonstrate that (1) when PSC is enabled, the comparative reductions in perplexity increase as the context window size is varied from 16k, to 32k, and up to 64k. (2) Our approach is broadly applicable and exhibits robustness across a variety of models and tasks. The code can be found at https://github.com/WNQzhu/PSC.","authors":["Wenqiao Zhu","Chao Xu","Lulu Wang","Jun Wu"],"url":"https://arxiv.org/abs/2505.12423"}
{"created":"2025-05-20","title":"EvoGPT: Enhancing Test Suite Robustness via LLM-Based Generation and Genetic Optimization","abstract":"Large Language Models (LLMs) have recently emerged as promising tools for automated unit test generation. We introduce a hybrid framework called EvoGPT that integrates LLM-based test generation with evolutionary search techniques to create diverse, fault-revealing unit tests. Unit tests are initially generated with diverse temperature sampling to maximize behavioral and test suite diversity, followed by a generation-repair loop and coverage-guided assertion enhancement. The resulting test suites are evolved using genetic algorithms, guided by a fitness function prioritizing mutation score over traditional coverage metrics. This design emphasizes the primary objective of unit testing-fault detection. Evaluated on multiple open-source Java projects, EvoGPT achieves an average improvement of 10% in both code coverage and mutation score compared to LLMs and traditional search-based software testing baselines. These results demonstrate that combining LLM-driven diversity, targeted repair, and evolutionary optimization produces more effective and resilient test suites.","authors":["Lior Broide","Roni Stern"],"url":"https://arxiv.org/abs/2505.12424"}
{"created":"2025-05-20","title":"Kornia-rs: A Low-Level 3D Computer Vision Library In Rust","abstract":"We present \\textit{kornia-rs}, a high-performance 3D computer vision library written entirely in native Rust, designed for safety-critical and real-time applications. Unlike C++-based libraries like OpenCV or wrapper-based solutions like OpenCV-Rust, \\textit{kornia-rs} is built from the ground up to leverage Rust's ownership model and type system for memory and thread safety. \\textit{kornia-rs} adopts a statically-typed tensor system and a modular set of crates, providing efficient image I/O, image processing and 3D operations. To aid cross-platform compatibility, \\textit{kornia-rs} offers Python bindings, enabling seamless and efficient integration with Rust code. Empirical results show that \\textit{kornia-rs} achieves a 3~ 5 times speedup in image transformation tasks over native Rust alternatives, while offering comparable performance to C++ wrapper-based libraries. In addition to 2D vision capabilities, \\textit{kornia-rs} addresses a significant gap in the Rust ecosystem by providing a set of 3D computer vision operators. This paper presents the architecture and performance characteristics of \\textit{kornia-rs}, demonstrating its effectiveness in real-world computer vision applications.","authors":["Edgar Riba","Jian Shi","Aditya Kumar","Andrew Shen","Gary Bradski"],"url":"https://arxiv.org/abs/2505.12425"}
{"created":"2025-05-20","title":"DragLoRA: Online Optimization of LoRA Adapters for Drag-based Image Editing in Diffusion Model","abstract":"Drag-based editing within pretrained diffusion model provides a precise and flexible way to manipulate foreground objects. Traditional methods optimize the input feature obtained from DDIM inversion directly, adjusting them iteratively to guide handle points towards target locations. However, these approaches often suffer from limited accuracy due to the low representation ability of the feature in motion supervision, as well as inefficiencies caused by the large search space required for point tracking. To address these limitations, we present DragLoRA, a novel framework that integrates LoRA (Low-Rank Adaptation) adapters into the drag-based editing pipeline. To enhance the training of LoRA adapters, we introduce an additional denoising score distillation loss which regularizes the online model by aligning its output with that of the original model. Additionally, we improve the consistency of motion supervision by adapting the input features using the updated LoRA, giving a more stable and accurate input feature for subsequent operations. Building on this, we design an adaptive optimization scheme that dynamically toggles between two modes, prioritizing efficiency without compromising precision. Extensive experiments demonstrate that DragLoRA significantly enhances the control precision and computational efficiency for drag-based image editing. The Codes of DragLoRA are available at: https://github.com/Sylvie-X/DragLoRA.","authors":["Siwei Xia","Li Sun","Tiantian Sun","Qingli Li"],"url":"https://arxiv.org/abs/2505.12427"}
{"created":"2025-05-20","title":"Depth Transfer: Learning to See Like a Simulator for Real-World Drone Navigation","abstract":"Sim-to-real transfer is a fundamental challenge in robot reinforcement learning. Discrepancies between simulation and reality can significantly impair policy performance, especially if it receives high-dimensional inputs such as dense depth estimates from vision. We propose a novel depth transfer method based on domain adaptation to bridge the visual gap between simulated and real-world depth data. A Variational Autoencoder (VAE) is first trained to encode ground-truth depth images from simulation into a latent space, which serves as input to a reinforcement learning (RL) policy. During deployment, the encoder is refined to align stereo depth images with this latent space, enabling direct policy transfer without fine-tuning. We apply our method to the task of autonomous drone navigation through cluttered environments. Experiments in IsaacGym show that our method nearly doubles the obstacle avoidance success rate when switching from ground-truth to stereo depth input. Furthermore, we demonstrate successful transfer to the photo-realistic simulator AvoidBench using only IsaacGym-generated stereo data, achieving superior performance compared to state-of-the-art baselines. Real-world evaluations in both indoor and outdoor environments confirm the effectiveness of our approach, enabling robust and generalizable depth-based navigation across diverse domains.","authors":["Hang Yu","Christophe De Wagter","Guido C. H. E de Croon"],"url":"https://arxiv.org/abs/2505.12428"}
{"created":"2025-05-20","title":"Time-Continuous Frequency Allocation for Feeder Links of Mega Constellations with Multi-Antenna Gateway Stations","abstract":"With the recent rapid advancement of mega low earth orbit (LEO) satellite constellations, multi-antenna gateway station (MAGS) has emerged as a key enabler to support extremely high system capacity via massive feeder links. However, the densification of both space and ground segment leads to reduced spatial separation between links, posing unprecedented challenges of interference exacerbation. This paper investigates graph coloring-based frequency allocation methods for interference mitigation (IM) of mega LEO systems. We first reveal the characteristics of MAGS interference pattern and formulate the IM problem into a $K$-coloring problem using an adaptive threshold method. Then we propose two tailored graph coloring algorithms, namely Generalized Global (GG) and Clique-Based Tabu Search (CTS), to solve this problem. GG employs a low-complexity greedy conflict avoidance strategy, while CTS leverages the unique clique structure brought by MAGSs to enhance IM performance. Subsequently, we innovatively modify them to achieve time-continuous frequency allocation, which is crucial to ensure the stability of feeder links. Moreover, we further devise two mega constellation decomposition methods to alleviate the complexity burden of satellite operators. Finally, we propose a list coloring-based vacant subchannel utilization method to further improve spectrum efficiency and system capacity. Simulation results on Starlink constellation of the first and second generations with 34396 satellites demonstrate the effectiveness and superiority of the proposed methodology.","authors":["Zijun Liu","Yafei Wang","Tianhao Fang","Wenjin Wang","Zhili Sun"],"url":"https://arxiv.org/abs/2505.12429"}
{"created":"2025-05-20","title":"A Learning-Based Ansatz Satisfying Boundary Conditions in Variational Problems","abstract":"Recently, innovative adaptations of the Ritz Method incorporating deep learning have been developed, known as the Deep Ritz Method. This approach employs a neural network as the test function for variational problems. However, the neural network does not inherently satisfy the boundary conditions of the variational problem. To resolve this issue, the Deep Ritz Method introduces a penalty term into the functional of the variational problem, which can lead to misleading results during the optimization process. In this work, an ansatz is proposed that inherently satisfies the boundary conditions of the variational problem. The results demonstrate that the proposed ansatz not only eliminates misleading outcomes but also reduces complexity while maintaining accuracy, showcasing its practical effectiveness in addressing variational problems.","authors":["Rafael Florencio","Julio Guerrero"],"url":"https://arxiv.org/abs/2505.12430"}
{"created":"2025-05-20","title":"DPCD: A Quality Assessment Database for Dynamic Point Clouds","abstract":"Recently, the advancements in Virtual/Augmented Reality (VR/AR) have driven the demand for Dynamic Point Clouds (DPC). Unlike static point clouds, DPCs are capable of capturing temporal changes within objects or scenes, offering a more accurate simulation of the real world. While significant progress has been made in the quality assessment research of static point cloud, little study has been done on Dynamic Point Cloud Quality Assessment (DPCQA), which hinders the development of quality-oriented applications, such as interframe compression and transmission in practical scenarios. In this paper, we introduce a large-scale DPCQA database, named DPCD, which includes 15 reference DPCs and 525 distorted DPCs from seven types of lossy compression and noise distortion. By rendering these samples to Processed Video Sequences (PVS), a comprehensive subjective experiment is conducted to obtain Mean Opinion Scores (MOS) from 21 viewers for analysis. The characteristic of contents, impact of various distortions, and accuracy of MOSs are presented to validate the heterogeneity and reliability of the proposed database. Furthermore, we evaluate the performance of several objective metrics on DPCD. The experiment results show that DPCQA is more challenge than that of static point cloud. The DPCD, which serves as a catalyst for new research endeavors on DPCQA, is publicly available at https://huggingface.co/datasets/Olivialyt/DPCD.","authors":["Yating Liu","Yujie Zhang","Qi Yang","Yiling Xu","Zhu Li","Ye-Kui Wang"],"url":"https://arxiv.org/abs/2505.12431"}
{"created":"2025-05-20","title":"Observe-R1: Unlocking Reasoning Abilities of MLLMs with Dynamic Progressive Reinforcement Learning","abstract":"Reinforcement Learning (RL) has shown promise in improving the reasoning abilities of Large Language Models (LLMs). However, the specific challenges of adapting RL to multimodal data and formats remain relatively unexplored. In this work, we present Observe-R1, a novel framework aimed at enhancing the reasoning capabilities of multimodal large language models (MLLMs). We draw inspirations from human learning progression--from simple to complex and easy to difficult, and propose a gradual learning paradigm for MLLMs. To this end, we construct the NeuraLadder dataset, which is organized and sampled according to the difficulty and complexity of data samples for RL training. To tackle multimodal tasks, we introduce a multimodal format constraint that encourages careful observation of images, resulting in enhanced visual abilities and clearer and more structured responses. Additionally, we implement a bonus reward system that favors concise, correct answers within a length constraint, alongside a dynamic weighting mechanism that prioritizes uncertain and medium-difficulty problems, ensuring that more informative samples have a greater impact on training. Our experiments with the Qwen2.5-VL-3B and Qwen2.5-VL-7B models on 20k samples from the NeuraLadder dataset show that Observe-R1 outperforms a series of larger reasoning models on both reasoning and general benchmarks, achieving superior clarity and conciseness in reasoning chains. Ablation studies validate the effectiveness of our strategies, highlighting the robustness and generalization of our approach. The dataset and code will be released at https://github.com/zrguo/Observe-R1.","authors":["Zirun Guo","Minjie Hong","Tao Jin"],"url":"https://arxiv.org/abs/2505.12432"}
{"created":"2025-05-20","title":"SRLoRA: Subspace Recomposition in Low-Rank Adaptation via Importance-Based Fusion and Reinitialization","abstract":"Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient fine-tuning (PEFT) method that injects two trainable low-rank matrices (A and B) into frozen pretrained models. While efficient, LoRA constrains updates to a fixed low-rank subspace (Delta W = BA), which can limit representational capacity and hinder downstream performance. We introduce Subspace Recomposition in Low-Rank Adaptation (SRLoRA) via importance-based fusion and reinitialization, a novel approach that enhances LoRA's expressiveness without compromising its lightweight structure. SRLoRA assigns importance scores to each LoRA pair (a column of B and the corresponding row of A), and dynamically recomposes the subspace during training. Less important pairs are fused into the frozen backbone, freeing capacity to reinitialize new pairs along unused principal directions derived from the pretrained weight's singular value decomposition. This mechanism enables continual subspace refreshment and richer adaptation over time, without increasing the number of trainable parameters. We evaluate SRLoRA on both language and vision tasks, including the GLUE benchmark and various image classification datasets. SRLoRA consistently achieves faster convergence and improved accuracy over standard LoRA, demonstrating its generality, efficiency, and potential for broader PEFT applications.","authors":["Haodong Yang","Lei Wang","Md Zakir Hossain"],"url":"https://arxiv.org/abs/2505.12433"}
{"created":"2025-05-20","title":"VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning","abstract":"Reinforcement fine-tuning (RFT) has shown great promise in achieving humanlevel reasoning capabilities of Large Language Models (LLMs), and has recently been extended to MLLMs. Nevertheless, reasoning about videos, which is a fundamental aspect of human intelligence, remains a persistent challenge due to the complex logic, temporal and causal structures inherent in video data. To fill this gap, we propose VIDEORFT, a novel approach that extends the RFT paradigm to cultivate human-like video reasoning capabilities in MLLMs. VIDEORFT follows the standard two-stage scheme in RFT: supervised fine-tuning (SFT) with chain-of-thought (CoT) annotations, followed by reinforcement learning (RL) to improve generalization. A central challenge to achieve this in the video domain lies in the scarcity of large-scale, high-quality video CoT datasets. We address this by building a fully automatic CoT curation pipeline. First, we devise a cognitioninspired prompting strategy to elicit a reasoning LLM to generate preliminary CoTs based solely on rich, structured, and literal representations of video content. Subsequently, these CoTs are revised by a visual-language model conditioned on the actual video, ensuring visual consistency and reducing visual hallucinations. This pipeline results in two new datasets - VideoRFT-CoT-102K for SFT and VideoRFT-RL-310K for RL. To further strength the RL phase, we introduce a novel semantic-consistency reward that explicitly promotes the alignment between textual reasoning with visual evidence. This reward encourages the model to produce coherent, context-aware reasoning outputs grounded in visual input. Extensive experiments show that VIDEORFT achieves state-of-the-art performance on six video reasoning benchmarks.","authors":["Qi Wang","Yanrui Yu","Ye Yuan","Rui Mao","Tianfei Zhou"],"url":"https://arxiv.org/abs/2505.12434"}
{"created":"2025-05-20","title":"SGDPO: Self-Guided Direct Preference Optimization for Language Model Alignment","abstract":"Direct Preference Optimization (DPO) is broadly utilized for aligning Large Language Models (LLMs) with human values because of its flexibility. Despite its effectiveness, it has been observed that the capability of DPO to generate human-preferred response is limited and the results of DPO are far from resilient. To address these limitations, in this paper we propose a novel Self-Guided Direct Preference Optimization algorithm, i.e., SGDPO, which incorporates a pilot term to steer the gradient flow during the optimization process, allowing for fine-grained control over the updates of chosen and rejected rewards. We provide a detailed theoretical analysis of our proposed method and elucidate its operational mechanism. Furthermore, we conduct comprehensive experiments on various models and benchmarks. The extensive experimental results demonstrate the consistency between the empirical results and our theoretical analysis and confirm the effectiveness of our proposed approach (up to 9.19% higher score).","authors":["Wenqiao Zhu","Ji Liu","Lulu Wang","Jun Wu","Yulun Zhang"],"url":"https://arxiv.org/abs/2505.12435"}
{"created":"2025-05-20","title":"Compositional Abstraction for Timed Systems with Broadcast Synchronization","abstract":"Simulation-based compositional abstraction effectively mitigates state space explosion in model checking, particularly for timed systems. However, existing approaches do not support broadcast synchronization, an important mechanism for modeling non-blocking one-to-many communication in multi-component systems. Consequently, they also lack a parallel composition operator that simultaneously supports broadcast synchronization, binary synchronization, shared variables, and committed locations. To address this, we propose a simulation-based compositional abstraction framework for timed systems, which supports these modeling concepts and is compatible with the popular UPPAAL model checker. Our framework is general, with the only additional restriction being that the timed automata are prohibited from updating shared variables when receiving broadcast signals. Through two case studies, our framework demonstrates superior verification efficiency compared to traditional monolithic methods.","authors":["Hanyue Chen","Miaomiao Zhang","Frits Vaandrager"],"url":"https://arxiv.org/abs/2505.12436"}
{"created":"2025-05-20","title":"Addressing the Scarcity of Benchmarks for Graph XAI","abstract":"While Graph Neural Networks (GNNs) have become the de facto model for learning from structured data, their decisional process remains opaque to the end user, undermining their deployment in safety-critical applications. In the case of graph classification, Explainable Artificial Intelligence (XAI) techniques address this major issue by identifying sub-graph motifs that explain predictions. However, advancements in this field are hindered by a chronic scarcity of benchmark datasets with known ground-truth motifs to assess the explanations' quality. Current graph XAI benchmarks are limited to synthetic data or a handful of real-world tasks hand-curated by domain experts. In this paper, we propose a general method to automate the construction of XAI benchmarks for graph classification from real-world datasets. We provide both 15 ready-made benchmarks, as well as the code to generate more than 2000 additional XAI benchmarks with our method. As a use case, we employ our benchmarks to assess the effectiveness of some popular graph explainers.","authors":["Michele Fontanesi","Alessio Micheli","Marco Podda","Domenico Tortorella"],"url":"https://arxiv.org/abs/2505.12437"}
{"created":"2025-05-20","title":"Learning to Play Like Humans: A Framework for LLM Adaptation in Interactive Fiction Games","abstract":"Interactive Fiction games (IF games) are where players interact through natural language commands. While recent advances in Artificial Intelligence agents have reignited interest in IF games as a domain for studying decision-making, existing approaches prioritize task-specific performance metrics over human-like comprehension of narrative context and gameplay logic. This work presents a cognitively inspired framework that guides Large Language Models (LLMs) to learn and play IF games systematically. Our proposed **L**earning to **P**lay **L**ike **H**umans (LPLH) framework integrates three key components: (1) structured map building to capture spatial and narrative relationships, (2) action learning to identify context-appropriate commands, and (3) feedback-driven experience analysis to refine decision-making over time. By aligning LLMs-based agents' behavior with narrative intent and commonsense constraints, LPLH moves beyond purely exploratory strategies to deliver more interpretable, human-like performance. Crucially, this approach draws on cognitive science principles to more closely simulate how human players read, interpret, and respond within narrative worlds. As a result, LPLH reframes the IF games challenge as a learning problem for LLMs-based agents, offering a new path toward robust, context-aware gameplay in complex text-based environments.","authors":["Jinming Zhang","Yunfei Long"],"url":"https://arxiv.org/abs/2505.12439"}
{"created":"2025-05-20","title":"Model Discovery with Grammatical Evolution. An Experiment with Prime Numbers","abstract":"Machine Learning produces efficient decision and prediction models based on input-output data only. Such models have the form of decision trees or neural nets and are far from transparent analytical models, based on mathematical formulas. Analytical model discovery requires additional knowledge and may be performed with Grammatical Evolution. Such models are transparent, concise, and have readable components and structure. This paper reports on a non-trivial experiment with generating such models.","authors":["Jakub Skrzy\\'nski","Dominik Sepio{\\l}o","Antoni Lig\\k{e}za"],"url":"https://arxiv.org/abs/2505.12440"}
{"created":"2025-05-20","title":"IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems","abstract":"The rapid advancement of Large Language Models (LLMs) has led to the emergence of Multi-Agent Systems (MAS) to perform complex tasks through collaboration. However, the intricate nature of MAS, including their architecture and agent interactions, raises significant concerns regarding intellectual property (IP) protection. In this paper, we introduce MASLEAK, a novel attack framework designed to extract sensitive information from MAS applications. MASLEAK targets a practical, black-box setting, where the adversary has no prior knowledge of the MAS architecture or agent configurations. The adversary can only interact with the MAS through its public API, submitting attack query $q$ and observing outputs from the final agent. Inspired by how computer worms propagate and infect vulnerable network hosts, MASLEAK carefully crafts adversarial query $q$ to elicit, propagate, and retain responses from each MAS agent that reveal a full set of proprietary components, including the number of agents, system topology, system prompts, task instructions, and tool usages. We construct the first synthetic dataset of MAS applications with 810 applications and also evaluate MASLEAK against real-world MAS applications, including Coze and CrewAI. MASLEAK achieves high accuracy in extracting MAS IP, with an average attack success rate of 87% for system prompts and task instructions, and 92% for system architecture in most cases. We conclude by discussing the implications of our findings and the potential defenses.","authors":["Liwen Wang","Wenxuan Wang","Shuai Wang","Zongjie Li","Zhenlan Ji","Zongyi Lyu","Daoyuan Wu","Shing-Chi Cheung"],"url":"https://arxiv.org/abs/2505.12442"}
{"created":"2025-05-20","title":"BadNAVer: Exploring Jailbreak Attacks On Vision-and-Language Navigation","abstract":"Multimodal large language models (MLLMs) have recently gained attention for their generalization and reasoning capabilities in Vision-and-Language Navigation (VLN) tasks, leading to the rise of MLLM-driven navigators. However, MLLMs are vulnerable to jailbreak attacks, where crafted prompts bypass safety mechanisms and trigger undesired outputs. In embodied scenarios, such vulnerabilities pose greater risks: unlike plain text models that generate toxic content, embodied agents may interpret malicious instructions as executable commands, potentially leading to real-world harm. In this paper, we present the first systematic jailbreak attack paradigm targeting MLLM-driven navigator. We propose a three-tiered attack framework and construct malicious queries across four intent categories, concatenated with standard navigation instructions. In the Matterport3D simulator, we evaluate navigation agents powered by five MLLMs and report an average attack success rate over 90%. To test real-world feasibility, we replicate the attack on a physical robot. Our results show that even well-crafted prompts can induce harmful actions and intents in MLLMs, posing risks beyond toxic output and potentially leading to physical harm.","authors":["Wenqi Lyu","Zerui Li","Yanyuan Qiao","Qi Wu"],"url":"https://arxiv.org/abs/2505.12443"}
{"created":"2025-05-20","title":"ResidualSketch: Enhancing Layer Efficiency and Error Reduction in Hierarchical Heavy Hitter Detection with ResNet Innovations","abstract":"In network management, swiftly and accurately identifying traffic anomalies, including Distributed Denial-of-Service (DDoS) attacks and unexpected network disruptions, is essential for network stability and security. Key to this process is the detection of Hierarchical Heavy Hitters (HHH), which significantly aids in the management of high-speed IP traffic. This study introduces ResidualSketch, a novel algorithm for HHH detection in hierarchical traffic analysis. ResidualSketch distinguishes itself by incorporating Residual Blocks and Residual Connections at crucial layers within the IP hierarchy, thus mitigating the Gradual Error Diffusion (GED) phenomenon in previous methods and reducing memory overhead while maintaining low update latency. Through comprehensive experiments on various datasets, we demonstrate that ResidualSketch outperforms existing state-of-the-art solutions in terms of accuracy and update speed across multiple layers of the network hierarchy. All related codes of ResidualSketch are open-source at GitHub.","authors":["Xilai Liu","Yuxuan Tian","Xiangyuan Wang","Yuhan Wu","Wenhao Wu","Tong Yang","Gaogang Xie"],"url":"https://arxiv.org/abs/2505.12445"}
{"created":"2025-05-20","title":"SSR: Enhancing Depth Perception in Vision-Language Models via Rationale-Guided Spatial Reasoning","abstract":"Despite impressive advancements in Visual-Language Models (VLMs) for multi-modal tasks, their reliance on RGB inputs limits precise spatial understanding. Existing methods for integrating spatial cues, such as point clouds or depth, either require specialized sensors or fail to effectively exploit depth information for higher-order reasoning. To this end, we propose a novel Spatial Sense and Reasoning method, dubbed SSR, a novel framework that transforms raw depth data into structured, interpretable textual rationales. These textual rationales serve as meaningful intermediate representations to significantly enhance spatial reasoning capabilities. Additionally, we leverage knowledge distillation to compress the generated rationales into compact latent embeddings, which facilitate resource-efficient and plug-and-play integration into existing VLMs without retraining. To enable comprehensive evaluation, we introduce a new dataset named SSR-CoT, a million-scale visual-language reasoning dataset enriched with intermediate spatial reasoning annotations, and present SSRBench, a comprehensive multi-task benchmark. Extensive experiments on multiple benchmarks demonstrate SSR substantially improves depth utilization and enhances spatial reasoning, thereby advancing VLMs toward more human-like multi-modal understanding. Our project page is at https://yliu-cs.github.io/SSR.","authors":["Yang Liu","Ming Ma","Xiaomin Yu","Pengxiang Ding","Han Zhao","Mingyang Sun","Siteng Huang","Donglin Wang"],"url":"https://arxiv.org/abs/2505.12448"}
{"created":"2025-05-20","title":"A Robot Simulation Environment for Virtual Reality Enhanced Underwater Manipulation and Seabed Intervention Tasks","abstract":"This paper presents the (MARUN)2 underwater robotic simulator. The simulator architecture enables seamless integration with the ROS-based mission software and web-based user interface of URSULA, a squid inspired biomimetic robot designed for dexterous underwater manipulation and seabed intervention tasks. (MARUN)2 utilizes the Unity game engine for physics-based rigid body dynamic simulation and underwater environment modeling. Utilizing Unity as the simulation environment enables the integration of virtual reality and haptic feedback capabilities for a more immersive and realistic experience for improved operator dexterity and experience. The utility of the simulator and improved dexterity provided by the VR module is validated through user experiments.","authors":["Sumey El-Muftu","Berke Gur"],"url":"https://arxiv.org/abs/2505.12450"}
{"created":"2025-05-20","title":"Finding Possible Winners in Spatial Voting with Incomplete Information","abstract":"We consider a spatial voting model where both candidates and voters are positioned in the $d$-dimensional Euclidean space, and each voter ranks candidates based on their proximity to the voter's ideal point. We focus on the scenario where the given information about the locations of the voters' ideal points is incomplete; for each dimension, only an interval of possible values is known. In this context, we investigate the computational complexity of determining the possible winners under positional scoring rules. Our results show that the possible winner problem in one dimension is solvable in polynomial time for all $k$-truncated voting rules with constant $k$. Moreover, for some scoring rules for which the possible winner problem is NP-complete, such as approval voting for any dimension or $k$-approval for $d \\geq 2$ dimensions, we give an FPT algorithm parameterized by the number of candidates. Finally, we classify tractable and intractable settings of the weighted possible winner problem in one dimension, and resolve the computational complexity of the weighted case for all two-valued positional scoring rules when $d=1$.","authors":["Hadas Shachnai","Rotem Shavitt","Andreas Wiese"],"url":"https://arxiv.org/abs/2505.12451"}
{"created":"2025-05-20","title":"Introspective Growth: Automatically Advancing LLM Expertise in Technology Judgment","abstract":"Large language models (LLMs) increasingly demonstrate signs of conceptual understanding, yet much of their internal knowledge remains latent, loosely structured, and difficult to access or evaluate. We propose self-questioning as a lightweight and scalable strategy to improve LLMs' understanding, particularly in domains where success depends on fine-grained semantic distinctions. To evaluate this approach, we introduce a challenging new benchmark of 1.3 million post-2015 computer science patent pairs, characterized by dense technical jargon and strategically complex writing. The benchmark centers on a pairwise differentiation task: can a model distinguish between closely related but substantively different inventions? We show that prompting LLMs to generate and answer their own questions - targeting the background knowledge required for the task - significantly improves performance. These self-generated questions and answers activate otherwise underutilized internal knowledge. Allowing LLMs to retrieve answers from external scientific texts further enhances performance, suggesting that model knowledge is compressed and lacks the full richness of the training data. We also find that chain-of-thought prompting and self-questioning converge, though self-questioning remains more effective for improving understanding of technical concepts. Notably, we uncover an asymmetry in prompting: smaller models often generate more fundamental, more open-ended, better-aligned questions for mid-sized models than large models with better understanding do, revealing a new strategy for cross-model collaboration. Altogether, our findings establish self-questioning as both a practical mechanism for automatically improving LLM comprehension, especially in domains with sparse and underrepresented knowledge, and a diagnostic probe of how internal and external knowledge are organized.","authors":["Siyang Wu","Honglin Bao","Nadav Kunievsky","James A. Evans"],"url":"https://arxiv.org/abs/2505.12452"}
{"created":"2025-05-20","title":"SecEmb: Sparsity-Aware Secure Federated Learning of On-Device Recommender System with Large Embedding","abstract":"Federated recommender system (FedRec) has emerged as a solution to protect user data through collaborative training techniques. A typical FedRec involves transmitting the full model and entire weight updates between edge devices and the server, causing significant burdens to devices with limited bandwidth and computational power. While the sparsity of embedding updates provides opportunity for payload optimization, existing sparsity-aware federated protocols generally sacrifice privacy for efficiency. A key challenge in designing a secure sparsity-aware efficient protocol is to protect the rated item indices from the server. In this paper, we propose a lossless secure recommender systems on sparse embedding updates (SecEmb). SecEmb reduces user payload while ensuring that the server learns no information about both rated item indices and individual updates except the aggregated model. The protocol consists of two correlated modules: (1) a privacy-preserving embedding retrieval module that allows users to download relevant embeddings from the server, and (2) an update aggregation module that securely aggregates updates at the server. Empirical analysis demonstrates that SecEmb reduces both download and upload communication costs by up to 90x and decreases user-side computation time by up to 70x compared with secure FedRec protocols. Additionally, it offers non-negligible utility advantages compared with lossy message compression methods.","authors":["Peihua Mai","Youlong Ding","Ziyan Lyu","Minxin Du","Yan Pang"],"url":"https://arxiv.org/abs/2505.12453"}
{"created":"2025-05-20","title":"Towards DS-NER: Unveiling and Addressing Latent Noise in Distant Annotations","abstract":"Distantly supervised named entity recognition (DS-NER) has emerged as a cheap and convenient alternative to traditional human annotation methods, enabling the automatic generation of training data by aligning text with external resources. Despite the many efforts in noise measurement methods, few works focus on the latent noise distribution between different distant annotation methods. In this work, we explore the effectiveness and robustness of DS-NER by two aspects: (1) distant annotation techniques, which encompasses both traditional rule-based methods and the innovative large language model supervision approach, and (2) noise assessment, for which we introduce a novel framework. This framework addresses the challenges by distinctly categorizing them into the unlabeled-entity problem (UEP) and the noisy-entity problem (NEP), subsequently providing specialized solutions for each. Our proposed method achieves significant improvements on eight real-world distant supervision datasets originating from three different data sources and involving four distinct annotation techniques, confirming its superiority over current state-of-the-art methods.","authors":["Yuyang Ding","Dan Qiao","Juntao Li","Jiajie Xu","Pingfu Chao","Xiaofang Zhou","Min Zhang"],"url":"https://arxiv.org/abs/2505.12454"}
{"created":"2025-05-20","title":"AltLoRA: Towards Better Gradient Approximation in Low-Rank Adaptation with Alternating Projections","abstract":"Low-Rank Adaptation (LoRA) has emerged as an effective technique for reducing memory overhead in fine-tuning large language models. However, it often suffers from sub-optimal performance compared with full fine-tuning since the update is constrained in the low-rank space. Recent variants such as LoRA-Pro attempt to mitigate this by adjusting the gradients of the low-rank matrices to approximate the full gradient. However, LoRA-Pro's solution is not unique, and different solutions can lead to significantly varying performance in ablation studies. Besides, to incorporate momentum or adaptive optimization design, approaches like LoRA-Pro must first compute the equivalent gradient, causing a higher memory cost close to full fine-tuning. A key challenge remains in integrating momentum properly into the low-rank space with lower memory cost. In this work, we propose AltLoRA, an alternating projection method that avoids the difficulties in gradient approximation brought by the joint update design, meanwhile integrating momentum without higher memory complexity. Our theoretical analysis provides convergence guarantees and further shows that AltLoRA enables stable feature learning and robustness to transformation invariance. Extensive experiments across multiple tasks demonstrate that AltLoRA outperforms LoRA and its variants, narrowing the gap toward full fine-tuning while preserving superior memory efficiency.","authors":["Xin Yu","Yujia Wang","Jinghui Chen","Lingzhou Xue"],"url":"https://arxiv.org/abs/2505.12455"}
{"created":"2025-05-20","title":"UFO-RL: Uncertainty-Focused Optimization for Efficient Reinforcement Learning Data Selection","abstract":"Scaling RL for LLMs is computationally expensive, largely due to multi-sampling for policy optimization and evaluation, making efficient data selection crucial. Inspired by the Zone of Proximal Development (ZPD) theory, we hypothesize LLMs learn best from data within their potential comprehension zone. Addressing the limitation of conventional, computationally intensive multi-sampling methods for data assessment, we introduce UFO-RL. This novel framework uses a computationally efficient single-pass uncertainty estimation to identify informative data instances, achieving up to 185x faster data evaluation. UFO-RL leverages this metric to select data within the estimated ZPD for training. Experiments show that training with just 10% of data selected by UFO-RL yields performance comparable to or surpassing full-data training, reducing overall training time by up to 16x while enhancing stability and generalization. UFO-RL offers a practical and highly efficient strategy for scaling RL fine-tuning of LLMs by focusing learning on valuable data.","authors":["Yang Zhao","Kai Xiong","Xiao Ding","Li Du","YangouOuyang","Zhouhao Sun","Jiannan Guan","Wenbin Zhang","Bin Liu","Dong Hu","Bing Qin","Ting Liu"],"url":"https://arxiv.org/abs/2505.12457"}
{"created":"2025-05-20","title":"A Case for Library-Level k-Means Binning in Histogram Gradient-Boosted Trees","abstract":"Modern gradient-boosted decision trees (GBDTs) accelerate split finding with histogram-based binning, which reduces complexity from O(N) to O(B) given a fixed bin budget B. However, the predominant quantile binning strategy-designed to distribute data points evenly among bins-may overlook critical boundary values that could enhance predictive performance. In this work, we propose replacing quantile binning with a k-means discretizer initialized with quantile bins. We test this swap on 33 OpenML tasks plus synthetics that control for modality, skew, and bin budget. Across 18 regression datasets, k-means shows no statistically significant losses at the 5% level and wins in four cases-most strikingly a 55% MSE drop on one particularly skewed dataset-even though k-means' mean reciprocal rank (MRR) is slightly lower (0.65 vs 0.72). On the 15 classification datasets the two methods are statistically tied (MRR 0.70 vs 0.68) with gaps $\\leq$0.2 pp. Synthetic experiments confirm consistently large MSE gains-typically >20% and rising to 90% as outlier magnitude increases or bin budget drops. We find that k-means keeps error on par with exact splitting when extra cuts add little value, yet still recovers key split points that quantile overlooks. As such, we advocate for a built-in bin_method=k-means flag, especially in regression tasks and in tight-budget settings such as the 32-64-bin GPU regime-because it is a \"safe default\" with large upside, yet adds only a one-off, cacheable overhead ($\\approx$ 2s to bin 10M rows on one core).","authors":["Asher Labovich"],"url":"https://arxiv.org/abs/2505.12460"}
{"created":"2025-05-20","title":"A Finite-Sample Analysis of Distributionally Robust Average-Reward Reinforcement Learning","abstract":"Robust reinforcement learning (RL) under the average-reward criterion is crucial for long-term decision making under potential environment mismatches, yet its finite-sample complexity study remains largely unexplored. Existing works offer algorithms with asymptotic guarantees, but the absence of finite-sample analysis hinders its principled understanding and practical deployment, especially in data-limited settings. We close this gap by proposing Robust Halpern Iteration (RHI), the first algorithm with provable finite-sample complexity guarantee. Under standard uncertainty sets -- including contamination sets and $\\ell_p$-norm balls -- RHI attains an $\\epsilon$-optimal policy with near-optimal sample complexity of $\\tilde{\\mathcal O}\\left(\\frac{SA\\mathcal H^{2}}{\\epsilon^{2}}\\right)$, where $S$ and $A$ denote the numbers of states and actions, and $\\mathcal H$ is the robust optimal bias span. This result gives the first polynomial sample complexity guarantee for robust average-reward RL. Moreover, our RHI's independence from prior knowledge distinguishes it from many previous average-reward RL studies. Our work thus constitutes a significant advancement in enhancing the practical applicability of robust average-reward methods to complex, real-world problems.","authors":["Zachary Roch","Chi Zhang","George Atia","Yue Wang"],"url":"https://arxiv.org/abs/2505.12462"}
{"created":"2025-05-20","title":"Resolving Latency and Inventory Risk in Market Making with Reinforcement Learning","abstract":"The latency of the exchanges in Market Making (MM) is inevitable due to hardware limitations, system processing times, delays in receiving data from exchanges, the time required for order transmission to reach the market, etc. Existing reinforcement learning (RL) methods for Market Making (MM) overlook the impact of these latency, which can lead to unintended order cancellations due to price discrepancies between decision and execution times and result in undesired inventory accumulation, exposing MM traders to increased market risk. Therefore, these methods cannot be applied in real MM scenarios. To address these issues, we first build a realistic MM environment with random delays of 30-100 milliseconds for order placement and market information reception, and implement a batch matching mechanism that collects orders within every 500 milliseconds before matching them all at once, simulating the batch auction mechanisms adopted by some exchanges. Then, we propose Relaver, an RL-based method for MM to tackle the latency and inventory risk issues. The three main contributions of Relaver are: i) we introduce an augmented state-action space that incorporates order hold time alongside price and volume, enabling Relaver to optimize execution strategies under latency constraints and time-priority matching mechanisms, ii) we leverage dynamic programming (DP) to guide the exploration of RL training for better policies, iii) we train a market trend predictor, which can guide the agent to intelligently adjust the inventory to reduce the risk. Extensive experiments and ablation studies on four real-world datasets demonstrate that \\textsc{Relaver} significantly improves the performance of state-of-the-art RL-based MM strategies across multiple metrics.","authors":["Junzhe Jiang","Chang Yang","Xinrun Wang","Zhiming Li","Xiao Huang","Bo Li"],"url":"https://arxiv.org/abs/2505.12465"}
{"created":"2025-05-20","title":"Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems","abstract":"Multi-agent collaboration has emerged as a pivotal paradigm for addressing complex, distributed tasks in large language model (LLM)-driven applications. While prior research has focused on high-level architectural frameworks, the granular mechanisms governing agents, critical to performance and scalability, remain underexplored. This study systematically investigates four dimensions of collaboration strategies: (1) agent governance, (2) participation control, (3) interaction dynamics, and (4) dialogue history management. Through rigorous experimentation under two context-dependent scenarios: Distributed Evidence Integration (DEI) and Structured Evidence Synthesis (SES), we quantify the impact of these strategies on both task accuracy and computational efficiency. Our findings reveal that centralized governance, instructor-led participation, ordered interaction patterns, and instructor-curated context summarization collectively optimize the trade-off between decision quality and resource utilization with the support of the proposed Token-Accuracy Ratio (TAR). This work establishes a foundation for designing adaptive, scalable multi-agent systems, shifting the focus from structural novelty to strategic interaction mechanics.","authors":["Haochun Wang","Sendong Zhao","Jingbo Wang","Zewen Qiang","Bing Qin","Ting Liu"],"url":"https://arxiv.org/abs/2505.12467"}
{"created":"2025-05-20","title":"NeuroGen: Neural Network Parameter Generation via Large Language Models","abstract":"Acquiring the parameters of neural networks (NNs) has been one of the most important problems in machine learning since the inception of NNs. Traditional approaches, such as backpropagation and forward-only optimization, acquire parameters via iterative data fitting to gradually optimize them. This paper aims to explore the feasibility of a new direction: acquiring NN parameters via large language model generation. We propose NeuroGen, a generalized and easy-to-implement two-stage approach for NN parameter generation conditioned on descriptions of the data, task, and network architecture. Stage one is Parameter Reference Knowledge Injection, where LLMs are pretrained on NN checkpoints to build foundational understanding of parameter space, whereas stage two is Context-Enhanced Instruction Tuning, enabling LLMs to adapt to specific tasks through enriched, task-aware prompts. Experimental results demonstrate that NeuroGen effectively generates usable NN parameters. Our findings highlight the feasibility of LLM-based NN parameter generation and suggest a promising new paradigm where LLMs and lightweight NNs can coexist synergistically","authors":["Jiaqi Wang","Yusen Zhang","Xi Li"],"url":"https://arxiv.org/abs/2505.12470"}
{"created":"2025-05-20","title":"What are they talking about? Benchmarking Large Language Models for Knowledge-Grounded Discussion Summarization","abstract":"In this work, we investigate the performance of LLMs on a new task that requires combining discussion with background knowledge for summarization. This aims to address the limitation of outside observer confusion in existing dialogue summarization systems due to their reliance solely on discussion information. To achieve this, we model the task output as background and opinion summaries and define two standardized summarization patterns. To support assessment, we introduce the first benchmark comprising high-quality samples consistently annotated by human experts and propose a novel hierarchical evaluation framework with fine-grained, interpretable metrics. We evaluate 12 LLMs under structured-prompt and self-reflection paradigms. Our findings reveal: (1) LLMs struggle with background summary retrieval, generation, and opinion summary integration. (2) Even top LLMs achieve less than 69% average performance across both patterns. (3) Current LLMs lack adequate self-evaluation and self-correction capabilities for this task.","authors":["Weixiao Zhou","Junnan Zhu","Gengyao Li","Xianfu Cheng","Xinnian Liang","Feifei Zhai","Zhoujun Li"],"url":"https://arxiv.org/abs/2505.12474"}
{"created":"2025-05-20","title":"Enhancing Large Language Models with Reward-guided Tree Search for Knowledge Graph Question and Answering","abstract":"Recently, large language models (LLMs) have demonstrated impressive performance in Knowledge Graph Question Answering (KGQA) tasks, which aim to find answers based on knowledge graphs (KGs) for natural language questions. Existing LLMs-based KGQA methods typically follow the Graph Retrieval-Augmented Generation (GraphRAG) paradigm, which first retrieves reasoning paths from the large KGs, and then generates the answers based on them. However, these methods emphasize the exploration of new optimal reasoning paths in KGs while ignoring the exploitation of historical reasoning paths, which may lead to sub-optimal reasoning paths. Additionally, the complex semantics contained in questions may lead to the retrieval of inaccurate reasoning paths. To address these issues, this paper proposes a novel and training-free framework for KGQA tasks called Reward-guided Tree Search on Graph (RTSoG). RTSoG decomposes an original question into a series of simpler and well-defined sub-questions to handle the complex semantics. Then, a Self-Critic Monte Carlo Tree Search (SC-MCTS) guided by a reward model is introduced to iteratively retrieve weighted reasoning paths as contextual knowledge. Finally, it stacks the weighted reasoning paths according to their weights to generate the final answers. Extensive experiments on four datasets demonstrate the effectiveness of RTSoG. Notably, it achieves 8.7\\% and 7.0\\% performance improvement over the state-of-the-art method on the GrailQA and the WebQSP respectively.","authors":["Xiao Long","Liansheng Zhuang","Chen Shen","Shaotian Yan","Yifei Li","Shafei Wang"],"url":"https://arxiv.org/abs/2505.12476"}
{"created":"2025-05-20","title":"Joint Embedding vs Reconstruction: Provable Benefits of Latent Space Prediction for Self Supervised Learning","abstract":"Reconstruction and joint embedding have emerged as two leading paradigms in Self Supervised Learning (SSL). Reconstruction methods focus on recovering the original sample from a different view in input space. On the other hand, joint embedding methods align the representations of different views in latent space. Both approaches offer compelling advantages, yet practitioners lack clear guidelines for choosing between them. In this work, we unveil the core mechanisms that distinguish each paradigm. By leveraging closed form solutions for both approaches, we precisely characterize how the view generation process, e.g. data augmentation, impacts the learned representations. We then demonstrate that, unlike supervised learning, both SSL paradigms require a minimal alignment between augmentations and irrelevant features to achieve asymptotic optimality with increasing sample size. Our findings indicate that in scenarios where these irrelevant features have a large magnitude, joint embedding methods are preferable because they impose a strictly weaker alignment condition compared to reconstruction based methods. These results not only clarify the trade offs between the two paradigms but also substantiate the empirical success of joint embedding approaches on real world challenging datasets.","authors":["Hugues Van Assel","Mark Ibrahim","Tommaso Biancalani","Aviv Regev","Randall Balestriero"],"url":"https://arxiv.org/abs/2505.12477"}
{"created":"2025-05-20","title":"$\\gamma$-FedHT: Stepsize-Aware Hard-Threshold Gradient Compression in Federated Learning","abstract":"Gradient compression can effectively alleviate communication bottlenecks in Federated Learning (FL). Contemporary state-of-the-art sparse compressors, such as Top-$k$, exhibit high computational complexity, up to $\\mathcal{O}(d\\log_2{k})$, where $d$ is the number of model parameters. The hard-threshold compressor, which simply transmits elements with absolute values higher than a fixed threshold, is thus proposed to reduce the complexity to $\\mathcal{O}(d)$. However, the hard-threshold compression causes accuracy degradation in FL, where the datasets are non-IID and the stepsize $\\gamma$ is decreasing for model convergence. The decaying stepsize reduces the updates and causes the compression ratio of the hard-threshold compression to drop rapidly to an aggressive ratio. At or below this ratio, the model accuracy has been observed to degrade severely. To address this, we propose $\\gamma$-FedHT, a stepsize-aware low-cost compressor with Error-Feedback to guarantee convergence. Given that the traditional theoretical framework of FL does not consider Error-Feedback, we introduce the fundamental conversation of Error-Feedback. We prove that $\\gamma$-FedHT has the convergence rate of $\\mathcal{O}(\\frac{1}{T})$ ($T$ representing total training iterations) under $\\mu$-strongly convex cases and $\\mathcal{O}(\\frac{1}{\\sqrt{T}})$ under non-convex cases, \\textit{same as FedAVG}. Extensive experiments demonstrate that $\\gamma$-FedHT improves accuracy by up to $7.42\\%$ over Top-$k$ under equal communication traffic on various non-IID image datasets.","authors":["Rongwei Lu","Yutong Jiang","Jinrui Zhang","Chunyang Li","Yifei Zhu","Bin Chen","Zhi Wang"],"url":"https://arxiv.org/abs/2505.12479"}
{"created":"2025-05-20","title":"Stability and convergence of multi-product expansion splitting methods with negative weights for semilinear parabolic equations","abstract":"The operator splitting method has been widely used to solve differential equations by splitting the equation into more manageable parts. In this work, we resolves a long-standing problem -- how to establish the stability of multi-product expansion (MPE) splitting methods with negative weights. The difficulty occurs because negative weights in high-order MPE method cause the sum of the absolute values of weights larger than one, making standard stability proofs fail. In particular, we take the semilinear parabolic equation as a typical model and establish the stability of arbitrarily high-order MPE splitting methods with positive time steps but possibly negative weights. Rigorous convergence analysis is subsequently obtained from the stability result. Extensive numerical experiments validate the stability and accuracy of various high-order MPE splitting methods, highlighting their efficiency and robustness.","authors":["Xianglong Duan","Chaoyu Quan","Jiang Yang","Zijing Zhu"],"url":"https://arxiv.org/abs/2505.12481"}
{"created":"2025-05-20","title":"Spectral-Spatial Self-Supervised Learning for Few-Shot Hyperspectral Image Classification","abstract":"Few-shot classification of hyperspectral images (HSI) faces the challenge of scarce labeled samples. Self-Supervised learning (SSL) and Few-Shot Learning (FSL) offer promising avenues to address this issue. However, existing methods often struggle to adapt to the spatial geometric diversity of HSIs and lack sufficient spectral prior knowledge. To tackle these challenges, we propose a method, Spectral-Spatial Self-Supervised Learning for Few-Shot Hyperspectral Image Classification (S4L-FSC), aimed at improving the performance of few-shot HSI classification. Specifically, we first leverage heterogeneous datasets to pretrain a spatial feature extractor using a designed Rotation-Mirror Self-Supervised Learning (RM-SSL) method, combined with FSL. This approach enables the model to learn the spatial geometric diversity of HSIs using rotation and mirroring labels as supervisory signals, while acquiring transferable spatial meta-knowledge through few-shot learning. Subsequently, homogeneous datasets are utilized to pretrain a spectral feature extractor via a combination of FSL and Masked Reconstruction Self-Supervised Learning (MR-SSL). The model learns to reconstruct original spectral information from randomly masked spectral vectors, inferring spectral dependencies. In parallel, FSL guides the model to extract pixel-level discriminative features, thereby embedding rich spectral priors into the model. This spectral-spatial pretraining method, along with the integration of knowledge from heterogeneous and homogeneous sources, significantly enhances model performance. Extensive experiments on four HSI datasets demonstrate the effectiveness and superiority of the proposed S4L-FSC approach for few-shot HSI classification.","authors":["Wenchen Chen","Yanmei Zhang","Zhongwei Xiao","Jianping Chu","Xingbo Wang"],"url":"https://arxiv.org/abs/2505.12482"}
{"created":"2025-05-20","title":"Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation","abstract":"Text-to-image generation models have achieved remarkable capabilities in synthesizing images, but often struggle to provide fine-grained control over the output. Existing guidance approaches, such as segmentation maps and depth maps, introduce spatial rigidity that restricts the inherent diversity of diffusion models. In this work, we introduce Deep Geometric Moments (DGM) as a novel form of guidance that encapsulates the subject's visual features and nuances through a learned geometric prior. DGMs focus specifically on the subject itself compared to DINO or CLIP features, which suffer from overemphasis on global image features or semantics. Unlike ResNets, which are sensitive to pixel-wise perturbations, DGMs rely on robust geometric moments. Our experiments demonstrate that DGM effectively balance control and diversity in diffusion-based image generation, allowing a flexible control mechanism for steering the diffusion process.","authors":["Sangmin Jung","Utkarsh Nath","Yezhou Yang","Giulia Pedrielli","Joydeep Biswas","Amy Zhang","Hassan Ghasemzadeh","Pavan Turaga"],"url":"https://arxiv.org/abs/2505.12486"}
{"created":"2025-05-20","title":"Video-GPT via Next Clip Diffusion","abstract":"GPT has shown its remarkable success in natural language processing. However, the language sequence is not sufficient to describe spatial-temporal details in the visual world. Alternatively, the video sequence is good at capturing such details. Motivated by this fact, we propose a concise Video-GPT in this paper by treating video as new language for visual world modeling. By analogy to next token prediction in GPT, we introduce a novel next clip diffusion paradigm for pretraining Video-GPT. Different from the previous works, this distinct paradigm allows Video-GPT to tackle both short-term generation and long-term prediction, by autoregressively denoising the noisy clip according to the clean clips in the history. Extensive experiments show our Video-GPT achieves the state-of-the-art performance on video prediction, which is the key factor towards world modeling (Physics-IQ Benchmark: Video-GPT 34.97 vs. Kling 23.64 vs. Wan 20.89). Moreover, it can be well adapted on 6 mainstream video tasks in both video generation and understanding, showing its great generalization capacity in downstream. The project page is at https://Video-GPT.github.io.","authors":["Shaobin Zhuang","Zhipeng Huang","Ying Zhang","Fangyikang Wang","Canmiao Fu","Binxin Yang","Chong Sun","Chen Li","Yali Wang"],"url":"https://arxiv.org/abs/2505.12489"}
{"created":"2025-05-20","title":"Proposal for Improving Google A2A Protocol: Safeguarding Sensitive Data in Multi-Agent Systems","abstract":"A2A, a protocol for AI agent communication, offers a robust foundation for secure AI agent communication. However, it has several critical issues in handling sensitive data, such as payment details, identification documents, and personal information. This paper reviews the existing protocol, identifies its limitations, and proposes specific enhancements to improve security, privacy, and trust. It includes a concrete example to illustrate the problem and solution, research-backed rationales, and implementation considerations, drawing on prior studies to strengthen the arguments and proposed solutions. This proposal includes seven enhancements: short-lived tokens, customer authentication (SCA), granular scopes, explicit consent, direct data transfer, multi-transaction approval, and payment standard compliance. The vacation booking example illustrates how these enhancements reduce risks and enhance user experience.","authors":["Yedidel Louck","Ariel Stulman","Amit Dvir"],"url":"https://arxiv.org/abs/2505.12490"}
{"created":"2025-05-20","title":"Unleashing Automated Congestion Control Customization in the Wild","abstract":"Congestion control (CC) crucially impacts user experience across Internet services like streaming, gaming, AR/VR, and connected cars. Traditionally, CC algorithm design seeks universal control rules that yield high performance across diverse application domains and networks. However, varying service needs and network conditions challenge this approach. We share operational experience with a system that automatically customizes congestion control logic to service needs and network conditions. We discuss design, deployment challenges, and solutions, highlighting performance benefits through case studies in streaming, gaming, connected cars, and more.","authors":["Amit Cohen","Lev Gloukhenki","Ravid Hadar","Eden Itah","Yehuda Shvut","Michael Schapira"],"url":"https://arxiv.org/abs/2505.12492"}
{"created":"2025-05-20","title":"UIShift: Enhancing VLM-based GUI Agents through Self-supervised Reinforcement Learning","abstract":"Training effective Vision Language Models (VLMs) for GUI agents typically relies on supervised fine-tuning (SFT) over large-scale annotated datasets, where the collection process is labor-intensive and error-prone. In this work, we propose a self-supervised inverse dynamics task to enable VLMs to learn from GUI transition pairs by inferring the action that caused that transition. This training task offers two advantages: (1) It enables VLMs to ignore variations unrelated to user actions (e.g., background refreshes, ads) and to focus on true affordances such as buttons and input fields within complex GUIs. (2) The training data can be easily obtained from existing GUI trajectories without requiring human annotation, and it can be easily scaled through automatic offline exploration. Using this training task, we propose UI-shift, a framework for enhancing VLM-based GUI agents through self-supervised reinforcement learning (RL). With only 2K training samples sourced from existing datasets, two VLMs -- Qwen2.5-VL-3B and Qwen2.5-VL-7B -- trained with UI-Shift achieve competitive or superior performance on grounding tasks (ScreenSpot-series benchmarks) and GUI automation tasks (AndroidControl), compared to SFT baselines and GUI-specific models that explicitly elicit reasoning abilities during RL. Our findings suggest a potential direction for enhancing VLMs for GUI agents by leveraging more self-supervised training data in the future.","authors":["Longxi Gao","Li Zhang","Mengwei Xu"],"url":"https://arxiv.org/abs/2505.12493"}
{"created":"2025-05-20","title":"KG-QAGen: A Knowledge-Graph-Based Framework for Systematic Question Generation and Long-Context LLM Evaluation","abstract":"The increasing context length of modern language models has created a need for evaluating their ability to retrieve and process information across extensive documents. While existing benchmarks test long-context capabilities, they often lack a structured way to systematically vary question complexity. We introduce KG-QAGen (Knowledge-Graph-based Question-Answer Generation), a framework that (1) extracts QA pairs at multiple complexity levels (2) by leveraging structured representations of financial agreements (3) along three key dimensions -- multi-hop retrieval, set operations, and answer plurality -- enabling fine-grained assessment of model performance across controlled difficulty levels. Using this framework, we construct a dataset of 20,139 QA pairs (the largest number among the long-context benchmarks) and open-source a part of it. We evaluate 13 proprietary and open-source LLMs and observe that even the best-performing models are struggling with set-based comparisons and multi-hop logical inference. Our analysis reveals systematic failure modes tied to semantic misinterpretation and inability to handle implicit relations.","authors":["Nikita Tatarinov","Vidhyakshaya Kannan","Haricharana Srinivasa","Arnav Raj","Harpreet Singh Anand","Varun Singh","Aditya Luthra","Ravij Lade","Agam Shah","Sudheer Chava"],"url":"https://arxiv.org/abs/2505.12495"}
{"created":"2025-05-20","title":"Rebalancing Contrastive Alignment with Learnable Semantic Gaps in Text-Video Retrieval","abstract":"Recent advances in text-video retrieval have been largely driven by contrastive learning frameworks. However, existing methods overlook a key source of optimization tension: the separation between text and video distributions in the representation space (referred to as the modality gap), and the prevalence of false negatives in batch sampling. These factors lead to conflicting gradients under the InfoNCE loss, impeding stable alignment. To mitigate this, we propose GARE, a Gap-Aware Retrieval framework that introduces a learnable, pair-specific increment Delta_ij between text t_i and video v_j to offload the tension from the global anchor representation. We first derive the ideal form of Delta_ij via a coupled multivariate first-order Taylor approximation of the InfoNCE loss under a trust-region constraint, revealing it as a mechanism for resolving gradient conflicts by guiding updates along a locally optimal descent direction. Due to the high cost of directly computing Delta_ij, we introduce a lightweight neural module conditioned on the semantic gap between each video-text pair, enabling structure-aware correction guided by gradient supervision. To further stabilize learning and promote interpretability, we regularize Delta using three components: a trust-region constraint to prevent oscillation, a directional diversity term to promote semantic coverage, and an information bottleneck to limit redundancy. Experiments across four retrieval benchmarks show that GARE consistently improves alignment accuracy and robustness to noisy supervision, confirming the effectiveness of gap-aware tension mitigation.","authors":["Jian Xiao","Zijie Song","Jialong Hu","Hao Cheng","Zhenzhen Hu","Jia Li","Richang Hong"],"url":"https://arxiv.org/abs/2505.12499"}
{"created":"2025-05-20","title":"MARGE: Improving Math Reasoning for LLMs with Guided Exploration","abstract":"Large Language Models (LLMs) exhibit strong potential in mathematical reasoning, yet their effectiveness is often limited by a shortage of high-quality queries. This limitation necessitates scaling up computational responses through self-generated data, yet current methods struggle due to spurious correlated data caused by ineffective exploration across all reasoning stages. To address such challenge, we introduce \\textbf{MARGE}: Improving \\textbf{Ma}th \\textbf{R}easoning with \\textbf{G}uided \\textbf{E}xploration, a novel method to address this issue and enhance mathematical reasoning through hit-guided exploration. MARGE systematically explores intermediate reasoning states derived from self-generated solutions, enabling adequate exploration and improved credit assignment throughout the reasoning process. Through extensive experiments across multiple backbone models and benchmarks, we demonstrate that MARGE significantly improves reasoning capabilities without requiring external annotations or training additional value models. Notably, MARGE improves both single-shot accuracy and exploration diversity, mitigating a common trade-off in alignment methods. These results demonstrate MARGE's effectiveness in enhancing mathematical reasoning capabilities and unlocking the potential of scaling self-generated training data. Our code and models are available at \\href{https://github.com/georgao35/MARGE}{this link}.","authors":["Jingyue Gao","Runji Lin","Keming Lu","Bowen Yu","Junyang Lin","Jianyu Chen"],"url":"https://arxiv.org/abs/2505.12500"}
{"created":"2025-05-20","title":"ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning","abstract":"Large language models (LLMs) excel at rapid generation of text and multimodal content, yet they falter on transaction-style planning that demands ACID-like guarantees and real-time disruption recovery. We present Adaptive LLM Agent System (ALAS), a framework that tackles four fundamental LLM deficits: (i) absence of self-verification, (ii) context erosion, (iii) next-token myopia, and (iv) lack of persistent state. ALAS decomposes each plan into role-specialized agents, equips them with automatic state tracking, and coordinates them through a lightweight protocol. When disruptions arise, agents apply history-aware local compensation, avoiding costly global replanning and containing cascade effects. On real-world, large-scale job-shop scheduling benchmarks, ALAS sets new best results for static sequential planning and excels in dynamic reactive scenarios with unexpected disruptions. These gains show that principled modularization plus targeted compensation can unlock scalable and resilient planning with LLMs.","authors":["Edward Y. Chang","Longling Geng"],"url":"https://arxiv.org/abs/2505.12501"}
{"created":"2025-05-20","title":"Event-Driven Simulation for Rapid Iterative Development of Distributed Space Flight Software","abstract":"This paper presents the design, development, and application of a novel space simulation environment for rapidly prototyping and testing flight software for distributed space systems. The environment combines the flexibility, determinism, and observability of software-only simulation with the fidelity and depth normally attained only by real-time hardware-in-the-loop testing. Ultimately, this work enables an engineering process in which flight software is continuously improved and delivered in its final, flight-ready form, and which reduces the cost of design changes and software revisions with respect to a traditional linear development process. Three key methods not found in existing tools enable this environment's novel capabilities: first, a hybrid event-driven simulation architecture that combines continuous-time and discrete-event simulation paradigms; second, a lightweight application-layer software virtualization design that allows executing compiled flight software binaries while modeling process scheduling, input/output, and memory use; and third, high-fidelity models for the multi-spacecraft space environment, including for wireless communication, relative sensing such as differential GPS and cameras, and flight computer health metrics like heap exhaustion and fragmentation. The simulation environment's capabilities are applied to the iterative development and testing of two flight-ready software packages: the guidance, navigation, and control software for the VISORS mission, and the Stanford Space Rendezvous Laboratory software kit for rendezvous and proximity operations. Results from 33 months of flight software development demonstrate the use of this simulation environment to rapidly and reliably identify and resolve defects, characterize navigation and control performance, and scrutinize implementation details like memory allocation and inter-spacecraft network protocols.","authors":["Toby Bell","Simone D'Amico"],"url":"https://arxiv.org/abs/2505.12502"}
{"created":"2025-05-20","title":"Optimal Task and Motion Planning for Autonomous Systems Using Petri Nets","abstract":"This study deals with the problem of task and motion planning of autonomous systems within the context of high-level tasks. Specifically, a task comprises logical requirements (conjunctions, disjunctions, and negations) on the trajectories and final states of agents in certain regions of interest. We propose an optimal planning approach that combines offline computation and online planning. First, a simplified Petri net system is proposed to model the autonomous system. Then, indicating places are designed to implement the logical requirements of the specifications. Building upon this, a compact representation of the state space called extended basis reachability graph is constructed and an efficient online planning algorithm is developed to obtain the optimal plan. It is shown that the most burdensome part of the planning procedure may be removed offline, thanks to the construction of the extended basis reachability graph. Finally, series of simulations are conducted to demonstrate the computational efficiency and scalability of our developed method.","authors":["Zhou He","Shilong Yuan","Ning Ran","Dimitri Lefebvre"],"url":"https://arxiv.org/abs/2505.12503"}
{"created":"2025-05-20","title":"CPGD: Toward Stable Rule-based Reinforcement Learning for Language Models","abstract":"Recent advances in rule-based reinforcement learning (RL) have significantly improved the reasoning capability of language models (LMs) with rule-based rewards. However, existing RL methods -- such as GRPO, REINFORCE++, and RLOO -- often suffer from training instability, where large policy updates and improper clipping can lead to training collapse. To address this issue, we propose Clipped Policy Gradient Optimization with Policy Drift (CPGD), a novel algorithm designed to stabilize policy learning in LMs. CPGD introduces a policy drift constraint based on KL divergence to dynamically regularize policy updates, and leverages a clip mechanism on the logarithm of the ratio to prevent excessive policy updates. We provide theoretical justification for CPGD and demonstrate through empirical analysis that it mitigates the instability observed in prior approaches. Furthermore, we show that CPGD significantly improves performance while maintaining training stability. Our implementation balances theoretical rigor with practical usability, offering a robust alternative for RL in the post-training of LMs. We release our code at https://github.com/ModalMinds/MM-EUREKA.","authors":["Zongkai Liu","Fanqing Meng","Lingxiao Du","Zhixiang Zhou","Chao Yu","Wenqi Shao","Qiaosheng Zhang"],"url":"https://arxiv.org/abs/2505.12504"}
{"created":"2025-05-20","title":"Unsupervised Invariant Risk Minimization","abstract":"We propose a novel unsupervised framework for \\emph{Invariant Risk Minimization} (IRM), extending the concept of invariance to settings where labels are unavailable. Traditional IRM methods rely on labeled data to learn representations that are robust to distributional shifts across environments. In contrast, our approach redefines invariance through feature distribution alignment, enabling robust representation learning from unlabeled data. We introduce two methods within this framework: Principal Invariant Component Analysis (PICA), a linear method that extracts invariant directions under Gaussian assumptions, and Variational Invariant Autoencoder (VIAE), a deep generative model that disentangles environment-invariant and environment-dependent latent factors. Our approach is based on a novel ``unsupervised'' structural causal model and supports environment-conditioned sample-generation and intervention. Empirical evaluations on synthetic dataset and modified versions of MNIST demonstrate the effectiveness of our methods in capturing invariant structure, preserving relevant information, and generalizing across environments without access to labels.","authors":["Yotam Norman","Ron Meir"],"url":"https://arxiv.org/abs/2505.12506"}
{"created":"2025-05-20","title":"LM$^2$otifs : An Explainable Framework for Machine-Generated Texts Detection","abstract":"The impressive ability of large language models to generate natural text across various tasks has led to critical challenges in authorship authentication. Although numerous detection methods have been developed to differentiate between machine-generated texts (MGT) and human-generated texts (HGT), the explainability of these methods remains a significant gap. Traditional explainability techniques often fall short in capturing the complex word relationships that distinguish HGT from MGT. To address this limitation, we present LM$^2$otifs, a novel explainable framework for MGT detection. Inspired by probabilistic graphical models, we provide a theoretical rationale for the effectiveness. LM$^2$otifs utilizes eXplainable Graph Neural Networks to achieve both accurate detection and interpretability. The LM$^2$otifs pipeline operates in three key stages: first, it transforms text into graphs based on word co-occurrence to represent lexical dependencies; second, graph neural networks are used for prediction; and third, a post-hoc explainability method extracts interpretable motifs, offering multi-level explanations from individual words to sentence structures. Extensive experiments on multiple benchmark datasets demonstrate the comparable performance of LM$^2$otifs. The empirical evaluation of the extracted explainable motifs confirms their effectiveness in differentiating HGT and MGT. Furthermore, qualitative analysis reveals distinct and visible linguistic fingerprints characteristic of MGT.","authors":["Xu Zheng","Zhuomin Chen","Esteban Schafir","Sipeng Chen","Hojat Allah Salehi","Haifeng Chen","Farhad Shirani","Wei Cheng","Dongsheng Luo"],"url":"https://arxiv.org/abs/2505.12507"}
{"created":"2025-05-20","title":"InnateCoder: Learning Programmatic Options with Foundation Models","abstract":"Outside of transfer learning settings, reinforcement learning agents start their learning process from a clean slate. As a result, such agents have to go through a slow process to learn even the most obvious skills required to solve a problem. In this paper, we present InnateCoder, a system that leverages human knowledge encoded in foundation models to provide programmatic policies that encode \"innate skills\" in the form of temporally extended actions, or options. In contrast to existing approaches to learning options, InnateCoder learns them from the general human knowledge encoded in foundation models in a zero-shot setting, and not from the knowledge the agent gains by interacting with the environment. Then, InnateCoder searches for a programmatic policy by combining the programs encoding these options into larger and more complex programs. We hypothesized that InnateCoder's way of learning and using options could improve the sampling efficiency of current methods for learning programmatic policies. Empirical results in MicroRTS and Karel the Robot support our hypothesis, since they show that InnateCoder is more sample efficient than versions of the system that do not use options or learn them from experience.","authors":["Rubens O. Moraes","Quazi Asif Sadmine","Hendrik Baier","Levi H. S. Lelis"],"url":"https://arxiv.org/abs/2505.12508"}
{"created":"2025-05-20","title":"Towards Budget-Friendly Model-Agnostic Explanation Generation for Large Language Models","abstract":"With Large language models (LLMs) becoming increasingly prevalent in various applications, the need for interpreting their predictions has become a critical challenge. As LLMs vary in architecture and some are closed-sourced, model-agnostic techniques show great promise without requiring access to the model's internal parameters. However, existing model-agnostic techniques need to invoke LLMs many times to gain sufficient samples for generating faithful explanations, which leads to high economic costs. In this paper, we show that it is practical to generate faithful explanations for large-scale LLMs by sampling from some budget-friendly models through a series of empirical studies. Moreover, we show that such proxy explanations also perform well on downstream tasks. Our analysis provides a new paradigm of model-agnostic explanation methods for LLMs, by including information from budget-friendly models.","authors":["Junhao Liu","Haonan Yu","Xin Zhang"],"url":"https://arxiv.org/abs/2505.12509"}
{"created":"2025-05-20","title":"DS-ProGen: A Dual-Structure Deep Language Model for Functional Protein Design","abstract":"Inverse Protein Folding (IPF) is a critical subtask in the field of protein design, aiming to engineer amino acid sequences capable of folding correctly into a specified three-dimensional (3D) conformation. Although substantial progress has been achieved in recent years, existing methods generally rely on either backbone coordinates or molecular surface features alone, which restricts their ability to fully capture the complex chemical and geometric constraints necessary for precise sequence prediction. To address this limitation, we present DS-ProGen, a dual-structure deep language model for functional protein design, which integrates both backbone geometry and surface-level representations. By incorporating backbone coordinates as well as surface chemical and geometric descriptors into a next-amino-acid prediction paradigm, DS-ProGen is able to generate functionally relevant and structurally stable sequences while satisfying both global and local conformational constraints. On the PRIDE dataset, DS-ProGen attains the current state-of-the-art recovery rate of 61.47%, demonstrating the synergistic advantage of multi-modal structural encoding in protein design. Furthermore, DS-ProGen excels in predicting interactions with a variety of biological partners, including ligands, ions, and RNA, confirming its robust functional retention capabilities.","authors":["Yanting Li","Jiyue Jiang","Zikang Wang","Ziqian Lin","Dongchen He","Yuheng Shan","Yanruisheng Shao","Jiayi Li","Xiangyu Shi","Jiuming Wang","Yanyu Chen","Yimin Fan","Han Li","Yu Li"],"url":"https://arxiv.org/abs/2505.12511"}
{"created":"2025-05-20","title":"Scalable Strategies for Continual Learning with Replay","abstract":"Future deep learning models will be distinguished by systems that perpetually learn through interaction, imagination, and cooperation, blurring the line between training and inference. This makes continual learning a critical challenge, as methods that efficiently maximize bidirectional transfer across learning trajectories will be essential. Replay is on track to play a foundational role in continual learning, allowing models to directly reconcile new information with past knowledge. In practice, however, replay is quite unscalable, doubling the cost of continual learning when applied naively. Moreover, the continual learning literature has not fully synchronized with the multi-task fine-tuning literature, having not fully integrated highly scalable techniques like model merging and low rank adaptation into a replay-enabled toolset that can produce a unified model in the face of many sequential tasks. In this paper, we begin by applying and analyzing low rank adaptation in a continual learning setting. Next, we introduce consolidation, a phasic approach to replay which leads to up to 55\\% less replay samples being needed for a given performance target. Then, we propose sequential merging, an offshoot of task arithmetic which is tailored to the continual learning setting and is shown to work well in combination with replay. Finally, we demonstrate that the developed strategies can operate synergistically, resulting in a highly scalable toolset that outperforms standalone variants.","authors":["Truman Hickok"],"url":"https://arxiv.org/abs/2505.12512"}
{"created":"2025-05-20","title":"GlobalGeoTree: A Multi-Granular Vision-Language Dataset for Global Tree Species Classification","abstract":"Global tree species mapping using remote sensing data is vital for biodiversity monitoring, forest management, and ecological research. However, progress in this field has been constrained by the scarcity of large-scale, labeled datasets. To address this, we introduce GlobalGeoTree, a comprehensive global dataset for tree species classification. GlobalGeoTree comprises 6.3 million geolocated tree occurrences, spanning 275 families, 2,734 genera, and 21,001 species across the hierarchical taxonomic levels. Each sample is paired with Sentinel-2 image time series and 27 auxiliary environmental variables, encompassing bioclimatic, geographic, and soil data. The dataset is partitioned into GlobalGeoTree-6M for model pretraining and curated evaluation subsets, primarily GlobalGeoTree-10kEval for zero-shot and few-shot benchmarking. To demonstrate the utility of the dataset, we introduce a baseline model, GeoTreeCLIP, which leverages paired remote sensing data and taxonomic text labels within a vision-language framework pretrained on GlobalGeoTree-6M. Experimental results show that GeoTreeCLIP achieves substantial improvements in zero- and few-shot classification on GlobalGeoTree-10kEval over existing advanced models. By making the dataset, models, and code publicly available, we aim to establish a benchmark to advance tree species classification and foster innovation in biodiversity research and ecological applications.","authors":["Yang Mu","Zhitong Xiong","Yi Wang","Muhammad Shahzad","Franz Essl","Mark van Kleunen","Xiao Xiang Zhu"],"url":"https://arxiv.org/abs/2505.12513"}
{"created":"2025-05-20","title":"Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought","abstract":"Large Language Models (LLMs) have demonstrated remarkable performance in many applications, including challenging reasoning problems via chain-of-thoughts (CoTs) techniques that generate ``thinking tokens'' before answering the questions. While existing theoretical works demonstrate that CoTs with discrete tokens boost the capability of LLMs, recent work on continuous CoTs lacks a theoretical understanding of why it outperforms discrete counterparts in various reasoning tasks such as directed graph reachability, a fundamental graph reasoning problem that includes many practical domain applications as special cases. In this paper, we prove that a two-layer transformer with $D$ steps of continuous CoTs can solve the directed graph reachability problem, where $D$ is the diameter of the graph, while the best known result of constant-depth transformers with discrete CoTs requires $O(n^2)$ decoding steps where $n$ is the number of vertices ($D<n$). In our construction, each continuous thought vector is a superposition state that encodes multiple search frontiers simultaneously (i.e., parallel breadth-first search (BFS)), while discrete CoTs must choose a single path sampled from the superposition state, which leads to sequential search that requires many more steps and may be trapped into local solutions. We also performed extensive experiments to verify that our theoretical construction aligns well with the empirical solution obtained via training dynamics. Notably, encoding of multiple search frontiers as a superposition state automatically emerges in training continuous CoTs, without explicit supervision to guide the model to explore multiple paths simultaneously.","authors":["Hanlin Zhu","Shibo Hao","Zhiting Hu","Jiantao Jiao","Stuart Russell","Yuandong Tian"],"url":"https://arxiv.org/abs/2505.12514"}
{"created":"2025-05-20","title":"Towards Immersive Mixed Reality Street Play: Understanding Collocated Bodily Play with See-through Head-Mounted Displays in Public Spaces","abstract":"We're witnessing an upcoming paradigm shift as Mixed Reality (MR) See-through Head-Mounted Displays (HMDs) become ubiquitous, with use shifting from controlled, private settings to spontaneous, public ones. While location-based pervasive mobile games like Pok\\'emon GO have seen success, the embodied interaction of MR HMDs is moving us from phone-based screen-touching gameplay to MR HMD-enabled collocated bodily play. Major tech companies are continuously releasing visionary videos where urban streets transform into vast mixed reality playgrounds-imagine Harry Potter-style wizard duels on city streets. However, few researchers have conducted real-world, in-the-wild studies of such Immersive Mixed Reality Street Play (IMRSP) in public spaces in anticipation of a near future with prevalent MR HMDs. Through empirical studies on a series of research-through-design game probes called Multiplayer Omnipresent Fighting Arena (MOFA), we gain initial understanding of this under-explored area by identifying the social implications, challenges, and opportunities of this new paradigm.","authors":["Botao Amber Hu","Rem Rungu Lin","Yilan Elan Tao","Samuli Laato","Yue Li"],"url":"https://arxiv.org/abs/2505.12516"}
{"created":"2025-05-20","title":"Energy-Aware Deep Learning on Resource-Constrained Hardware","abstract":"The use of deep learning (DL) on Internet of Things (IoT) and mobile devices offers numerous advantages over cloud-based processing. However, such devices face substantial energy constraints to prolong battery-life, or may even operate intermittently via energy-harvesting. Consequently, \\textit{energy-aware} approaches for optimizing DL inference and training on such resource-constrained devices have garnered recent interest. We present an overview of such approaches, outlining their methodologies, implications for energy consumption and system-level efficiency, and their limitations in terms of supported network types, hardware platforms, and application scenarios. We hope our review offers a clear synthesis of the evolving energy-aware DL landscape and serves as a foundation for future research in energy-constrained computing.","authors":["Josh Millar","Hamed Haddadi","Anil Madhavapeddy"],"url":"https://arxiv.org/abs/2505.12523"}
{"created":"2025-05-20","title":"HAKES: Scalable Vector Database for Embedding Search Service","abstract":"Modern deep learning models capture the semantics of complex data by transforming them into high-dimensional embedding vectors. Emerging applications, such as retrieval-augmented generation, use approximate nearest neighbor (ANN) search in the embedding vector space to find similar data. Existing vector databases provide indexes for efficient ANN searches, with graph-based indexes being the most popular due to their low latency and high recall in real-world high-dimensional datasets. However, these indexes are costly to build, suffer from significant contention under concurrent read-write workloads, and scale poorly to multiple servers.","authors":["Guoyu Hu","Shaofeng Cai","Tien Tuan Anh Dinh","Zhongle Xie","Cong Yue","Gang Chen","Beng Chin Ooi"],"url":"https://arxiv.org/abs/2505.12524"}
{"created":"2025-05-20","title":"Never Skip a Batch: Continuous Training of Temporal GNNs via Adaptive Pseudo-Supervision","abstract":"Temporal Graph Networks (TGNs), while being accurate, face significant training inefficiencies due to irregular supervision signals in dynamic graphs, which induce sparse gradient updates. We first theoretically establish that aggregating historical node interactions into pseudo-labels reduces gradient variance, accelerating convergence. Building on this analysis, we propose History-Averaged Labels (HAL), a method that dynamically enriches training batches with pseudo-targets derived from historical label distributions. HAL ensures continuous parameter updates without architectural modifications by converting idle computation into productive learning steps. Experiments on the Temporal Graph Benchmark (TGB) validate our findings and an assumption about slow change of user preferences: HAL accelerates TGNv2 training by up to 15x while maintaining competitive performance. Thus, this work offers an efficient, lightweight, architecture-agnostic, and theoretically motivated solution to label sparsity in temporal graph learning.","authors":["Alexander Panyshev","Dmitry Vinichenko","Oleg Travkin","Roman Alferov","Alexey Zaytsev"],"url":"https://arxiv.org/abs/2505.12526"}
{"created":"2025-05-20","title":"Enforcing Fairness Where It Matters: An Approach Based on Difference-of-Convex Constraints","abstract":"Fairness in machine learning has become a critical concern, particularly in high-stakes applications. Existing approaches often focus on achieving full fairness across all score ranges generated by predictive models, ensuring fairness in both high and low-scoring populations. However, this stringent requirement can compromise predictive performance and may not align with the practical fairness concerns of stakeholders. In this work, we propose a novel framework for building partially fair machine learning models, which enforce fairness within a specific score range of interest, such as the middle range where decisions are most contested, while maintaining flexibility in other regions. We introduce two statistical metrics to rigorously evaluate partial fairness within a given score range, such as the top 20%-40% of scores. To achieve partial fairness, we propose an in-processing method by formulating the model training problem as constrained optimization with difference-of-convex constraints, which can be solved by an inexact difference-of-convex algorithm (IDCA). We provide the complexity analysis of IDCA for finding a nearly KKT point. Through numerical experiments on real-world datasets, we demonstrate that our framework achieves high predictive performance while enforcing partial fairness where it matters most.","authors":["Yutian He","Yankun Huang","Yao Yao","Qihang Lin"],"url":"https://arxiv.org/abs/2505.12530"}
{"created":"2025-05-20","title":"ESC-Judge: A Framework for Comparing Emotional Support Conversational Agents","abstract":"Large language models (LLMs) increasingly power mental-health chatbots, yet the field still lacks a scalable, theory-grounded way to decide which model is most effective to deploy. We present ESC-Judge, the first end-to-end evaluation framework that (i) grounds head-to-head comparisons of emotional-support LLMs in Clara Hill's established Exploration-Insight-Action counseling model, providing a structured and interpretable view of performance, and (ii) fully automates the evaluation pipeline at scale. ESC-Judge operates in three stages: first, it synthesizes realistic help-seeker roles by sampling empirically salient attributes such as stressors, personality, and life history; second, it has two candidate support agents conduct separate sessions with the same role, isolating model-specific strategies; and third, it asks a specialized judge LLM to express pairwise preferences across rubric-anchored skills that span the Exploration, Insight, and Action spectrum. In our study, ESC-Judge matched PhD-level annotators on 85 percent of Exploration, 83 percent of Insight, and 86 percent of Action decisions, demonstrating human-level reliability at a fraction of the cost. All code, prompts, synthetic roles, transcripts, and judgment scripts are released to promote transparent progress in emotionally supportive AI.","authors":["Navid Madani","Rohini Srihari"],"url":"https://arxiv.org/abs/2505.12531"}
{"created":"2025-05-20","title":"Exploring Sparsity for Parameter Efficient Fine Tuning Using Wavelets","abstract":"Efficiently adapting large foundation models is critical, especially with tight compute and memory budgets. Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA offer limited granularity and effectiveness in few-parameter regimes. We propose Wavelet Fine-Tuning (WaveFT), a novel PEFT method that learns highly sparse updates in the wavelet domain of residual matrices. WaveFT allows precise control of trainable parameters, offering fine-grained capacity adjustment and excelling with remarkably low parameter count, potentially far fewer than LoRA's minimum -- ideal for extreme parameter-efficient scenarios. In order to demonstrate the effect of the wavelet transform, we compare WaveFT with a special case, called SHiRA, that entails applying sparse updates directly in the weight domain. Evaluated on personalized text-to-image generation using Stable Diffusion XL as baseline, WaveFT significantly outperforms LoRA and other PEFT methods, especially at low parameter counts; achieving superior subject fidelity, prompt alignment, and image diversity.","authors":["Ahmet Bilican","M. Ak{\\i}n Y{\\i}lmaz","A. Murat Tekalp","R. G\\\"okberk Cinbi\\c{s}"],"url":"https://arxiv.org/abs/2505.12532"}
{"created":"2025-05-20","title":"Relation Extraction or Pattern Matching? Unravelling the Generalisation Limits of Language Models for Biographical RE","abstract":"Analysing the generalisation capabilities of relation extraction (RE) models is crucial for assessing whether they learn robust relational patterns or rely on spurious correlations. Our cross-dataset experiments find that RE models struggle with unseen data, even within similar domains. Notably, higher intra-dataset performance does not indicate better transferability, instead often signaling overfitting to dataset-specific artefacts. Our results also show that data quality, rather than lexical similarity, is key to robust transfer, and the choice of optimal adaptation strategy depends on the quality of data available: while fine-tuning yields the best cross-dataset performance with high-quality data, few-shot in-context learning (ICL) is more effective with noisier data. However, even in these cases, zero-shot baselines occasionally outperform all cross-dataset results. Structural issues in RE benchmarks, such as single-relation per sample constraints and non-standardised negative class definitions, further hinder model transferability.","authors":["Varvara Arzt","Allan Hanbury","Michael Wiegand","G\\'abor Recski","Terra Blevins"],"url":"https://arxiv.org/abs/2505.12533"}
{"created":"2025-05-20","title":"ChemPile: A 250GB Diverse and Curated Dataset for Chemical Foundation Models","abstract":"Foundation models have shown remarkable success across scientific domains, yet their impact in chemistry remains limited due to the absence of diverse, large-scale, high-quality datasets that reflect the field's multifaceted nature. We present the ChemPile, an open dataset containing over 75 billion tokens of curated chemical data, specifically built for training and evaluating general-purpose models in the chemical sciences. The dataset mirrors the human learning journey through chemistry -- from educational foundations to specialized expertise -- spanning multiple modalities and content types including structured data in diverse chemical representations (SMILES, SELFIES, IUPAC names, InChI, molecular renderings), scientific and educational text, executable code, and chemical images. ChemPile integrates foundational knowledge (textbooks, lecture notes), specialized expertise (scientific articles and language-interfaced data), visual understanding (molecular structures, diagrams), and advanced reasoning (problem-solving traces and code) -- mirroring how human chemists develop expertise through diverse learning materials and experiences. Constructed through hundreds of hours of expert curation, the ChemPile captures both foundational concepts and domain-specific complexity. We provide standardized training, validation, and test splits, enabling robust benchmarking. ChemPile is openly released via HuggingFace with a consistent API, permissive license, and detailed documentation. We hope the ChemPile will serve as a catalyst for chemical AI, enabling the development of the next generation of chemical foundation models.","authors":["Adrian Mirza","Nawaf Alampara","Marti\\~no R\\'ios-Garc\\'ia","Mohamed Abdelalim","Jack Butler","Bethany Connolly","Tunca Dogan","Marianna Nezhurina","B\\\"unyamin \\c{S}en","Santosh Tirunagari","Mark Worrall","Adamo Young","Philippe Schwaller","Michael Pieler","Kevin Maik Jablonka"],"url":"https://arxiv.org/abs/2505.12534"}
{"created":"2025-05-20","title":"Framework of Voting Prediction of Parliament Members","abstract":"Keeping track of how lawmakers vote is essential for government transparency. While many parliamentary voting records are available online, they are often difficult to interpret, making it challenging to understand legislative behavior across parliaments and predict voting outcomes. Accurate prediction of votes has several potential benefits, from simplifying parliamentary work by filtering out bills with a low chance of passing to refining proposed legislation to increase its likelihood of approval. In this study, we leverage advanced machine learning and data analysis techniques to develop a comprehensive framework for predicting parliamentary voting outcomes across multiple legislatures. We introduce the Voting Prediction Framework (VPF) - a data-driven framework designed to forecast parliamentary voting outcomes at the individual legislator level and for entire bills. VPF consists of three key components: (1) Data Collection - gathering parliamentary voting records from multiple countries using APIs, web crawlers, and structured databases; (2) Parsing and Feature Integration - processing and enriching the data with meaningful features, such as legislator seniority, and content-based characteristics of a given bill; and (3) Prediction Models - using machine learning to forecast how each parliament member will vote and whether a bill is likely to pass. The framework will be open source, enabling anyone to use or modify the framework. To evaluate VPF, we analyzed over 5 million voting records from five countries - Canada, Israel, Tunisia, the United Kingdom and the USA. Our results show that VPF achieves up to 85% precision in predicting individual votes and up to 84% accuracy in predicting overall bill outcomes. These findings highlight VPF's potential as a valuable tool for political analysis, policy research, and enhancing public access to legislative decision-making.","authors":["Zahi Mizrahi","Shai Berkovitz","Nimrod Talmon","Michael Fire"],"url":"https://arxiv.org/abs/2505.12535"}
{"created":"2025-05-20","title":"Robust Reinforcement Learning-Based Locomotion for Resource-Constrained Quadrupeds with Exteroceptive Sensing","abstract":"Compact quadrupedal robots are proving increasingly suitable for deployment in real-world scenarios. Their smaller size fosters easy integration into human environments. Nevertheless, real-time locomotion on uneven terrains remains challenging, particularly due to the high computational demands of terrain perception. This paper presents a robust reinforcement learning-based exteroceptive locomotion controller for resource-constrained small-scale quadrupeds in challenging terrains, which exploits real-time elevation mapping, supported by a careful depth sensor selection. We concurrently train both a policy and a state estimator, which together provide an odometry source for elevation mapping, optionally fused with visual-inertial odometry (VIO). We demonstrate the importance of positioning an additional time-of-flight sensor for maintaining robustness even without VIO, thus having the potential to free up computational resources. We experimentally demonstrate that the proposed controller can flawlessly traverse steps up to 17.5 cm in height and achieve an 80% success rate on 22.5 cm steps, both with and without VIO. The proposed controller also achieves accurate forward and yaw velocity tracking of up to 1.0 m/s and 1.5 rad/s respectively. We open-source our training code at github.com/ETH-PBL/elmap-rl-controller.","authors":["Davide Plozza","Patricia Apostol","Paul Joseph","Simon Schl\\\"apfer","Michele Magno"],"url":"https://arxiv.org/abs/2505.12537"}
{"created":"2025-05-20","title":"Penetration-free Solid-Fluid Interaction on Shells and Rods","abstract":"We introduce a novel approach to simulate the interaction between fluids and thin elastic solids without any penetration. Our approach is centered around an optimization system augmented with barriers, which aims to find a configuration that ensures the absence of penetration while enforcing incompressibility for the fluids and minimizing elastic potentials for the solids. Unlike previous methods that primarily focus on velocity coherence at the fluid-solid interfaces, we demonstrate the effectiveness and flexibility of explicitly resolving positional constraints, including both explicit representation of solid positions and the implicit representation of fluid level-set interface. To preserve the volume of the fluid, we propose a simple yet efficient approach that adjusts the associated level-set values. Additionally, we develop a distance metric capable of measuring the separation between an implicitly represented surface and a Lagrangian object of arbitrary codimension. By integrating the inertia, solid elastic potential, damping, barrier potential, and fluid incompressibility within a unified system, we are able to robustly simulate a wide range of processes involving fluid interactions with lower-dimensional objects such as shells and rods. These processes include topology changes, bouncing, splashing, sliding, rolling, floating, and more.","authors":["Jinyuan Liu","Yuchen Sun","Yin Yang","Chenfanfu Jiang","Minchen Li","Bo Zhu"],"url":"https://arxiv.org/abs/2505.12539"}
{"created":"2025-05-20","title":"Harnessing the Universal Geometry of Embeddings","abstract":"We introduce the first method for translating text embeddings from one vector space to another without any paired data, encoders, or predefined sets of matches. Our unsupervised approach translates any embedding to and from a universal latent representation (i.e., a universal semantic structure conjectured by the Platonic Representation Hypothesis). Our translations achieve high cosine similarity across model pairs with different architectures, parameter counts, and training datasets.","authors":["Rishi Jha","Collin Zhang","Vitaly Shmatikov","John X. Morris"],"url":"https://arxiv.org/abs/2505.12540"}
{"created":"2025-05-20","title":"Private Statistical Estimation via Truncation","abstract":"We introduce a novel framework for differentially private (DP) statistical estimation via data truncation, addressing a key challenge in DP estimation when the data support is unbounded. Traditional approaches rely on problem-specific sensitivity analysis, limiting their applicability. By leveraging techniques from truncated statistics, we develop computationally efficient DP estimators for exponential family distributions, including Gaussian mean and covariance estimation, achieving near-optimal sample complexity. Previous works on exponential families only consider bounded or one-dimensional families. Our approach mitigates sensitivity through truncation while carefully correcting for the introduced bias using maximum likelihood estimation and DP stochastic gradient descent. Along the way, we establish improved uniform convergence guarantees for the log-likelihood function of exponential families, which may be of independent interest. Our results provide a general blueprint for DP algorithm design via truncated statistics.","authors":["Manolis Zampetakis","Felix Zhou"],"url":"https://arxiv.org/abs/2505.12541"}
{"created":"2025-05-20","title":"Disambiguation in Conversational Question Answering in the Era of LLM: A Survey","abstract":"Ambiguity remains a fundamental challenge in Natural Language Processing (NLP) due to the inherent complexity and flexibility of human language. With the advent of Large Language Models (LLMs), addressing ambiguity has become even more critical due to their expanded capabilities and applications. In the context of Conversational Question Answering (CQA), this paper explores the definition, forms, and implications of ambiguity for language driven systems, particularly in the context of LLMs. We define key terms and concepts, categorize various disambiguation approaches enabled by LLMs, and provide a comparative analysis of their advantages and disadvantages. We also explore publicly available datasets for benchmarking ambiguity detection and resolution techniques and highlight their relevance for ongoing research. Finally, we identify open problems and future research directions, proposing areas for further investigation. By offering a comprehensive review of current research on ambiguities and disambiguation with LLMs, we aim to contribute to the development of more robust and reliable language systems.","authors":["Md Mehrab Tanjim","Yeonjun In","Xiang Chen","Victor S. Bursztyn","Ryan A. Rossi","Sungchul Kim","Guang-Jie Ren","Vaishnavi Muppala","Shun Jiang","Yongsung Kim","Chanyoung Park"],"url":"https://arxiv.org/abs/2505.12543"}
{"created":"2025-05-20","title":"Alternators With Noise Models","abstract":"Alternators have recently been introduced as a framework for modeling time-dependent data. They often outperform other popular frameworks, such as state-space models and diffusion models, on challenging time-series tasks. This paper introduces a new Alternator model, called Alternator++, which enhances the flexibility of traditional Alternators by explicitly modeling the noise terms used to sample the latent and observed trajectories, drawing on the idea of noise models from the diffusion modeling literature. Alternator++ optimizes the sum of the Alternator loss and a noise-matching loss. The latter forces the noise trajectories generated by the two noise models to approximate the noise trajectories that produce the observed and latent trajectories. We demonstrate the effectiveness of Alternator++ in tasks such as density estimation, time series imputation, and forecasting, showing that it outperforms several strong baselines, including Mambas, ScoreGrad, and Dyffusion.","authors":["Mohammad R. Rezaei","Adji Bousso Dieng"],"url":"https://arxiv.org/abs/2505.12544"}
{"created":"2025-05-20","title":"Towards Reliable and Interpretable Traffic Crash Pattern Prediction and Safety Interventions Using Customized Large Language Models","abstract":"Predicting crash events is crucial for understanding crash distributions and their contributing factors, thereby enabling the design of proactive traffic safety policy interventions. However, existing methods struggle to interpret the complex interplay among various sources of traffic crash data, including numeric characteristics, textual reports, crash imagery, environmental conditions, and driver behavior records. As a result, they often fail to capture the rich semantic information and intricate interrelationships embedded in these diverse data sources, limiting their ability to identify critical crash risk factors. In this research, we propose TrafficSafe, a framework that adapts LLMs to reframe crash prediction and feature attribution as text-based reasoning. A multi-modal crash dataset including 58,903 real-world reports together with belonged infrastructure, environmental, driver, and vehicle information is collected and textualized into TrafficSafe Event Dataset. By customizing and fine-tuning LLMs on this dataset, the TrafficSafe LLM achieves a 42% average improvement in F1-score over baselines. To interpret these predictions and uncover contributing factors, we introduce TrafficSafe Attribution, a sentence-level feature attribution framework enabling conditional risk analysis. Findings show that alcohol-impaired driving is the leading factor in severe crashes, with aggressive and impairment-related behaviors having nearly twice the contribution for severe crashes compared to other driver behaviors. Furthermore, TrafficSafe Attribution highlights pivotal features during model training, guiding strategic crash data collection for iterative performance improvements. The proposed TrafficSafe offers a transformative leap in traffic safety research, providing a blueprint for translating advanced AI technologies into responsible, actionable, and life-saving outcomes.","authors":["Yang Zhao (Frank)","Pu Wang (Frank)","Yibo Zhao (Frank)","Hongru Du (Frank)","Hao (Frank)","Yang"],"url":"https://arxiv.org/abs/2505.12545"}
{"created":"2025-05-20","title":"Extracting memorized pieces of (copyrighted) books from open-weight language models","abstract":"Plaintiffs and defendants in copyright lawsuits over generative AI often make sweeping, opposing claims about the extent to which large language models (LLMs) have memorized plaintiffs' protected expression. Drawing on adversarial ML and copyright law, we show that these polarized positions dramatically oversimplify the relationship between memorization and copyright. To do so, we leverage a recent probabilistic extraction technique to extract pieces of the Books3 dataset from 13 open-weight LLMs. Through numerous experiments, we show that it's possible to extract substantial parts of at least some books from different LLMs. This is evidence that the LLMs have memorized the extracted text; this memorized content is copied inside the model parameters. But the results are complicated: the extent of memorization varies both by model and by book. With our specific experiments, we find that the largest LLMs don't memorize most books -- either in whole or in part. However, we also find that Llama 3.1 70B memorizes some books, like Harry Potter and 1984, almost entirely. We discuss why our results have significant implications for copyright cases, though not ones that unambiguously favor either side.","authors":["A. Feder Cooper","Aaron Gokaslan","Amy B. Cyphert","Christopher De Sa","Mark A. Lemley","Daniel E. Ho","Percy Liang"],"url":"https://arxiv.org/abs/2505.12546"}
{"created":"2025-05-20","title":"ProMi: An Efficient Prototype-Mixture Baseline for Few-Shot Segmentation with Bounding-Box Annotations","abstract":"In robotics applications, few-shot segmentation is crucial because it allows robots to perform complex tasks with minimal training data, facilitating their adaptation to diverse, real-world environments. However, pixel-level annotations of even small amount of images is highly time-consuming and costly. In this paper, we present a novel few-shot binary segmentation method based on bounding-box annotations instead of pixel-level labels. We introduce, ProMi, an efficient prototype-mixture-based method that treats the background class as a mixture of distributions. Our approach is simple, training-free, and effective, accommodating coarse annotations with ease. Compared to existing baselines, ProMi achieves the best results across different datasets with significant gains, demonstrating its effectiveness. Furthermore, we present qualitative experiments tailored to real-world mobile robot tasks, demonstrating the applicability of our approach in such scenarios. Our code: https://github.com/ThalesGroup/promi.","authors":["Florent Chiaroni","Ali Ayub","Ola Ahmad"],"url":"https://arxiv.org/abs/2505.12547"}
{"created":"2025-05-20","title":"VGGT-SLAM: Dense RGB SLAM Optimized on the SL(4) Manifold","abstract":"We present VGGT-SLAM, a dense RGB SLAM system constructed by incrementally and globally aligning submaps created from the feed-forward scene reconstruction approach VGGT using only uncalibrated monocular cameras. While related works align submaps using similarity transforms (i.e., translation, rotation, and scale), we show that such approaches are inadequate in the case of uncalibrated cameras. In particular, we revisit the idea of reconstruction ambiguity, where given a set of uncalibrated cameras with no assumption on the camera motion or scene structure, the scene can only be reconstructed up to a 15-degrees-of-freedom projective transformation of the true geometry. This inspires us to recover a consistent scene reconstruction across submaps by optimizing over the SL(4) manifold, thus estimating 15-degrees-of-freedom homography transforms between sequential submaps while accounting for potential loop closure constraints. As verified by extensive experiments, we demonstrate that VGGT-SLAM achieves improved map quality using long video sequences that are infeasible for VGGT due to its high GPU requirements.","authors":["Dominic Maggio","Hyungtae Lim","Luca Carlone"],"url":"https://arxiv.org/abs/2505.12549"}
{"created":"2025-05-20","title":"Shaky Structures: The Wobbly World of Causal Graphs in Software Analytics","abstract":"Causal graphs are widely used in software engineering to document and explore causal relationships. Though widely used, they may also be wildly misleading. Causal structures generated from SE data can be highly variable. This instability is so significant that conclusions drawn from one graph may be totally reversed in another, even when both graphs are learned from the same or very similar project data.","authors":["Jeremy Hulse","Nasir U. Eisty","Tim Menzies"],"url":"https://arxiv.org/abs/2505.12554"}
{"created":"2025-05-20","title":"Beyond Accuracy: EcoL2 Metric for Sustainable Neural PDE Solvers","abstract":"Real-world systems, from aerospace to railway engineering, are modeled with partial differential equations (PDEs) describing the physics of the system. Estimating robust solutions for such problems is essential. Deep learning-based architectures, such as neural PDE solvers, have recently gained traction as a reliable solution method. The current state of development of these approaches, however, primarily focuses on improving accuracy. The environmental impact of excessive computation, leading to increased carbon emissions, has largely been overlooked. This paper introduces a carbon emission measure for a range of PDE solvers. Our proposed metric, EcoL2, balances model accuracy with emissions across data collection, model training, and deployment. Experiments across both physics-informed machine learning and operator learning architectures demonstrate that the proposed metric presents a holistic assessment of model performance and emission cost. As such solvers grow in scale and deployment, EcoL2 represents a step toward building performant scientific machine learning systems with lower long-term environmental impact.","authors":["Taniya Kapoor","Abhishek Chandra","Anastasios Stamou","Stephen J Roberts"],"url":"https://arxiv.org/abs/2505.12556"}
{"created":"2025-05-20","title":"The taggedPBC: Annotating a massive parallel corpus for crosslinguistic investigations","abstract":"Existing datasets available for crosslinguistic investigations have tended to focus on large amounts of data for a small group of languages or a small amount of data for a large number of languages. This means that claims based on these datasets are limited in what they reveal about universal properties of the human language faculty. While this has begun to change through the efforts of projects seeking to develop tagged corpora for a large number of languages, such efforts are still constrained by limits on resources. The current paper reports on a large automatically tagged parallel dataset which has been developed to partially address this issue. The taggedPBC contains more than 1,800 sentences of pos-tagged parallel text data from over 1,500 languages, representing 133 language families and 111 isolates, dwarfing previously available resources. The accuracy of tags in this dataset is shown to correlate well with both existing SOTA taggers for high-resource languages (SpaCy, Trankit) as well as hand-tagged corpora (Universal Dependencies Treebanks). Additionally, a novel measure derived from this dataset, the N1 ratio, correlates with expert determinations of word order in three typological databases (WALS, Grambank, Autotyp) such that a Gaussian Naive Bayes classifier trained on this feature can accurately identify basic word order for languages not in those databases. While much work is still needed to expand and develop this dataset, the taggedPBC is an important step to enable corpus-based crosslinguistic investigations, and is made available for research and collaboration via GitHub.","authors":["Hiram Ring"],"url":"https://arxiv.org/abs/2505.12560"}
{"created":"2025-05-20","title":"mCLM: A Function-Infused and Synthesis-Friendly Modular Chemical Language Model","abstract":"Despite their ability to understand chemical knowledge and accurately generate sequential representations, large language models (LLMs) remain limited in their capacity to propose novel molecules with drug-like properties. In addition, the molecules that LLMs propose can often be challenging to make in the lab. To more effectively enable the discovery of functional small molecules, LLMs need to learn a molecular language. However, LLMs are currently limited by encoding molecules from atoms. In this paper, we argue that just like tokenizing texts into (sub-)word tokens instead of characters, molecules should be decomposed and reassembled at the level of functional building blocks, i.e., parts of molecules that bring unique functions and serve as effective building blocks for real-world automated laboratory synthesis. This motivates us to propose mCLM, a modular Chemical-Language Model tokenizing molecules into building blocks and learning a bilingual language model of both natural language descriptions of functions and molecule building blocks. By reasoning on such functional building blocks, mCLM guarantees to generate efficiently synthesizable molecules thanks to recent progress in block-based chemistry, while also improving the functions of molecules in a principled manner. In experiments on 430 FDA-approved drugs, we find mCLM capable of significantly improving 5 out of 6 chemical functions critical to determining drug potentials. More importantly, mCLM can reason on multiple functions and improve the FDA-rejected drugs (``fallen angels'') over multiple iterations to greatly improve their shortcomings.","authors":["Carl Edwards","Chi Han","Gawon Lee","Thao Nguyen","Bowen Jin","Chetan Kumar Prasad","Sara Szymku\\'c","Bartosz A. Grzybowski","Ying Diao","Jiawei Han","Ge Liu","Hao Peng","Martin D. Burke","Heng Ji"],"url":"https://arxiv.org/abs/2505.12565"}
{"created":"2025-05-20","title":"HybridServe: Efficient Serving of Large AI Models with Confidence-Based Cascade Routing","abstract":"Giant Deep Neural Networks (DNNs), have become indispensable for accurate and robust support of large-scale cloud based AI services. However, serving giant DNNs is prohibitively expensive from an energy consumption viewpoint easily exceeding that of training, due to the enormous scale of GPU clusters needed to hold giant DNN model partitions and replicas. Existing approaches can either optimize energy efficiency or inference accuracy but not both. To overcome this status quo, we propose HybridServe, a novel hybrid DNN model serving system that leverages multiple sized versions (small to giant) of the model to be served in tandem. Through a confidence based hybrid model serving dataflow, HybridServe prefers to serve inference requests with energy-efficient smaller models so long as accuracy is not compromised, thereby reducing the number of replicas needed for giant DNNs. HybridServe also features a dataflow planner for efficient partitioning and replication of candidate models to maximize serving system throughput. Experimental results using a prototype implementation of HybridServe show that it reduces energy footprint by up to 19.8x compared to the state-of-the-art DNN model serving systems while matching the accuracy of serving solely with giant DNNs.","authors":["Leyang Xue","Yao Fu","Luo Mai","Mahesh K. Marina"],"url":"https://arxiv.org/abs/2505.12566"}
{"created":"2025-05-20","title":"A Survey of Attacks on Large Language Models","abstract":"Large language models (LLMs) and LLM-based agents have been widely deployed in a wide range of applications in the real world, including healthcare diagnostics, financial analysis, customer support, robotics, and autonomous driving, expanding their powerful capability of understanding, reasoning, and generating natural languages. However, the wide deployment of LLM-based applications exposes critical security and reliability risks, such as the potential for malicious misuse, privacy leakage, and service disruption that weaken user trust and undermine societal safety. This paper provides a systematic overview of the details of adversarial attacks targeting both LLMs and LLM-based agents. These attacks are organized into three phases in LLMs: Training-Phase Attacks, Inference-Phase Attacks, and Availability & Integrity Attacks. For each phase, we analyze the details of representative and recently introduced attack methods along with their corresponding defenses. We hope our survey will provide a good tutorial and a comprehensive understanding of LLM security, especially for attacks on LLMs. We desire to raise attention to the risks inherent in widely deployed LLM-based applications and highlight the urgent need for robust mitigation strategies for evolving threats.","authors":["Wenrui Xu","Keshab K. Parhi"],"url":"https://arxiv.org/abs/2505.12567"}
{"created":"2025-05-20","title":"Enriching Patent Claim Generation with European Patent Dataset","abstract":"Drafting patent claims is time-intensive, costly, and requires professional skill. Therefore, researchers have investigated large language models (LLMs) to assist inventors in writing claims. However, existing work has largely relied on datasets from the United States Patent and Trademark Office (USPTO). To enlarge research scope regarding various jurisdictions, drafting conventions, and legal standards, we introduce EPD, a European patent dataset. EPD presents rich textual data and structured metadata to support multiple patent-related tasks, including claim generation. This dataset enriches the field in three critical aspects: (1) Jurisdictional diversity: Patents from different offices vary in legal and drafting conventions. EPD fills a critical gap by providing a benchmark for European patents to enable more comprehensive evaluation. (2) Quality improvement: EPD offers high-quality granted patents with finalized and legally approved texts, whereas others consist of patent applications that are unexamined or provisional. Experiments show that LLMs fine-tuned on EPD significantly outperform those trained on previous datasets and even GPT-4o in claim quality and cross-domain generalization. (3) Real-world simulation: We propose a difficult subset of EPD to better reflect real-world challenges of claim generation. Results reveal that all tested LLMs perform substantially worse on these challenging samples, which highlights the need for future research.","authors":["Lekang Jiang","Chengzu Li","Stephan Goetz"],"url":"https://arxiv.org/abs/2505.12568"}
{"created":"2025-05-20","title":"Batched Self-Consistency Improves LLM Relevance Assessment and Ranking","abstract":"Given some information need, Large Language Models (LLMs) are increasingly used for candidate text relevance assessment, typically using a one-by-one pointwise (PW) strategy where each LLM call evaluates one candidate at a time. Meanwhile, it has been shown that LLM performance can be improved through self-consistency: prompting the LLM to do the same task multiple times (possibly in perturbed ways) and then aggregating the responses. To take advantage of self-consistency, we hypothesize that batched PW strategies, where multiple passages are judged in one LLM call, are better suited than one-by-one PW methods since a larger input context can induce more diverse LLM sampling across self-consistency calls. We first propose several candidate batching strategies to create prompt diversity across self-consistency calls through subset reselection and permutation. We then test our batched PW methods on relevance assessment and ranking tasks against one-by-one PW and listwise LLM ranking baselines with and without self-consistency, using three passage retrieval datasets and GPT-4o, Claude Sonnet 3, and Amazon Nova Pro. We find that batched PW methods outperform all baselines, and show that batching can greatly amplify the positive effects of self-consistency. For instance, on our legal search dataset, GPT-4o one-by-one PW ranking NDCG@10 improves only from 44.9% to 46.8% without self-consistency vs. with 15 self consistency calls, while batched PW ranking improves from 43.8% to 51.3%, respectively.","authors":["Anton Korikov","Pan Du","Scott Sanner","Navid Rekabsaz"],"url":"https://arxiv.org/abs/2505.12570"}
{"created":"2025-05-20","title":"Measuring Information Distortion in Hierarchical Ultra long Novel Generation:The Optimal Expansion Ratio","abstract":"Writing novels with Large Language Models (LLMs) raises a critical question: how much human-authored outline is necessary to generate high-quality million-word novels? While frameworks such as DOME, Plan&amp;Write, and Long Writer have improved stylistic coherence and logical consistency, they primarily target shorter novels (10k--100k words), leaving ultra-long generation largely unexplored. Drawing on insights from recent text compression methods like LLMZip and LLM2Vec, we conduct an information-theoretic analysis that quantifies distortion occurring when LLMs compress and reconstruct ultra-long novels under varying compression-expansion ratios. We introduce a hierarchical two-stage generation pipeline (outline -> detailed outline -> manuscript) and find an optimal outline length that balances information preservation with human effort. Through extensive experimentation with Chinese novels, we establish that a two-stage hierarchical outline approach significantly reduces semantic distortion compared to single-stage methods. Our findings provide empirically-grounded guidance for authors and researchers collaborating with LLMs to create million-word novels.","authors":["Hanwen Shen","Ting Ying"],"url":"https://arxiv.org/abs/2505.12572"}
{"created":"2025-05-20","title":"PoisonArena: Uncovering Competing Poisoning Attacks in Retrieval-Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) systems, widely used to improve the factual grounding of large language models (LLMs), are increasingly vulnerable to poisoning attacks, where adversaries inject manipulated content into the retriever's corpus. While prior research has predominantly focused on single-attacker settings, real-world scenarios often involve multiple, competing attackers with conflicting objectives. In this work, we introduce PoisonArena, the first benchmark to systematically study and evaluate competing poisoning attacks in RAG. We formalize the multi-attacker threat model, where attackers vie to control the answer to the same query using mutually exclusive misinformation. PoisonArena leverages the Bradley-Terry model to quantify each method's competitive effectiveness in such adversarial environments. Through extensive experiments on the Natural Questions and MS MARCO datasets, we demonstrate that many attack strategies successful in isolation fail under competitive pressure. Our findings highlight the limitations of conventional evaluation metrics like Attack Success Rate (ASR) and F1 score and underscore the need for competitive evaluation to assess real-world attack robustness. PoisonArena provides a standardized framework to benchmark and develop future attack and defense strategies under more realistic, multi-adversary conditions. Project page: https://github.com/yxf203/PoisonArena.","authors":["Liuji Chen","Xiaofang Yang","Yuanzhuo Lu","Jinghao Zhang","Xin Sun","Qiang Liu","Shu Wu","Jing Dong","Liang Wang"],"url":"https://arxiv.org/abs/2505.12574"}
{"created":"2025-05-20","title":"RealMath: A Continuous Benchmark for Evaluating Language Models on Research-Level Mathematics","abstract":"Existing benchmarks for evaluating mathematical reasoning in large language models (LLMs) rely primarily on competition problems, formal proofs, or artificially challenging questions -- failing to capture the nature of mathematics encountered in actual research environments. We introduce RealMath, a novel benchmark derived directly from research papers and mathematical forums that assesses LLMs' abilities on authentic mathematical tasks. Our approach addresses three critical challenges: sourcing diverse research-level content, enabling reliable automated evaluation through verifiable statements, and designing a continually refreshable dataset to mitigate contamination risks. Experimental results across multiple LLMs reveal surprising capabilities in handling research mathematics compared to competition problems, suggesting current models may already serve as valuable assistants for working mathematicians despite limitations on highly challenging problems. The code and dataset for RealMath are publicly available.","authors":["Jie Zhang","Cezara Petrui","Kristina Nikoli\\'c","Florian Tram\\`er"],"url":"https://arxiv.org/abs/2505.12575"}
{"created":"2025-05-20","title":"AdaDim: Dimensionality Adaptation for SSL Representational Dynamics","abstract":"A key factor in effective Self-Supervised learning (SSL) is preventing dimensional collapse, which is where higher-dimensional representation spaces span a lower-dimensional subspace. Therefore, SSL optimization strategies involve guiding a model to produce representations ($R$) with a higher dimensionality. Dimensionality is either optimized through a dimension-contrastive approach that encourages feature decorrelation or through a sample-contrastive method that promotes a uniform spread of sample representations. Both families of SSL algorithms also utilize a projection head that maps $R$ into a lower-dimensional embedding space $Z$. Recent work has characterized the projection head as a filter of irrelevant features from the SSL objective by reducing mutual information, $I(R;Z)$. Therefore, the current literature's view is that a good SSL representation space should have a high $H(R)$ and a low $I(R;Z)$. However, this view of the problem is lacking in terms of an understanding of the underlying training dynamics that influences both terms, as well as how the values of $H(R)$ and $I(R;Z)$ arrived at the end of training reflect the downstream performance of an SSL model. We address both gaps in the literature by demonstrating that increases in $H(R)$ due to feature decorrelation at the start of training lead to a higher $I(R;Z)$, while increases in $H(R)$ due to samples distributing uniformly in a high-dimensional space at the end of training cause $I(R;Z)$ to plateau or decrease. Furthermore, our analysis shows that the best performing SSL models do not have the highest $H(R)$ nor the lowest $I(R;Z)$, but arrive at an optimal intermediate point for both. We develop a method called AdaDim to exploit these observed training dynamics by adaptively weighting between losses based on feature decorrelation and uniform sample spread.","authors":["Kiran Kokilepersaud","Mohit Prabhushankar","Ghassan AlRegib"],"url":"https://arxiv.org/abs/2505.12576"}
{"created":"2025-05-20","title":"Adaptive parameter-efficient fine-tuning via Hessian-informed subset selection","abstract":"Parameter-efficient fine-tuning (PEFT) is a highly effective approach for adapting large pre-trained models to downstream tasks with minimal computational overhead. At the core, PEFT methods freeze most parameters and only trains a small subset (say $<0.1\\%$ of total parameters). Notably, different PEFT methods select different subsets, resulting in varying levels of performance. This variation prompts a key question: how to effectively select the most influential subset to train?","authors":["Shiyun Xu","Zhiqi Bu"],"url":"https://arxiv.org/abs/2505.12579"}
{"created":"2025-05-20","title":"Coarse Attribute Prediction with Task Agnostic Distillation for Real World Clothes Changing ReID","abstract":"This work focuses on Clothes Changing Re-IDentification (CC-ReID) for the real world. Existing works perform well with high-quality (HQ) images, but struggle with low-quality (LQ) where we can have artifacts like pixelation, out-of-focus blur, and motion blur. These artifacts introduce noise to not only external biometric attributes (e.g. pose, body shape, etc.) but also corrupt the model's internal feature representation. Models usually cluster LQ image features together, making it difficult to distinguish between them, leading to incorrect matches. We propose a novel framework Robustness against Low-Quality (RLQ) to improve CC-ReID model on real-world data. RLQ relies on Coarse Attributes Prediction (CAP) and Task Agnostic Distillation (TAD) operating in alternate steps in a novel training mechanism. CAP enriches the model with external fine-grained attributes via coarse predictions, thereby reducing the effect of noisy inputs. On the other hand, TAD enhances the model's internal feature representation by bridging the gap between HQ and LQ features, via an external dataset through task-agnostic self-supervision and distillation. RLQ outperforms the existing approaches by 1.6%-2.9% Top-1 on real-world datasets like LaST, and DeepChange, while showing consistent improvement of 5.3%-6% Top-1 on PRCC with competitive performance on LTCC. *The code will be made public soon.*","authors":["Priyank Pathak","Yogesh S Rawat"],"url":"https://arxiv.org/abs/2505.12580"}
{"created":"2025-05-20","title":"An approach based on class activation maps for investigating the effects of data augmentation on neural networks for image classification","abstract":"Neural networks have become increasingly popular in the last few years as an effective tool for the task of image classification due to the impressive performance they have achieved on this task. In image classification tasks, it is common to use data augmentation strategies to increase the robustness of trained networks to changes in the input images and to avoid overfitting. Although data augmentation is a widely adopted technique, the literature lacks a body of research analyzing the effects data augmentation methods have on the patterns learned by neural network models working on complex datasets. The primary objective of this work is to propose a methodology and set of metrics that may allow a quantitative approach to analyzing the effects of data augmentation in convolutional networks applied to image classification. An important tool used in the proposed approach lies in the concept of class activation maps for said models, which allow us to identify and measure the importance these models assign to each individual pixel in an image when executing the classification task. From these maps, we may then extract metrics over the similarities and differences between maps generated by these models trained on a given dataset with different data augmentation strategies. Experiments made using this methodology suggest that the effects of these data augmentation techniques not only can be analyzed in this way but also allow us to identify different impact profiles over the trained models.","authors":["Lucas M. Dorneles","Luan Fonseca Garcia","Joel Lu\\'is Carbonera"],"url":"https://arxiv.org/abs/2505.12581"}
{"created":"2025-05-20","title":"Compile-Time Fully Homomorphic Encryption: Eliminating Online Encryption via Algebraic Basis Synthesis","abstract":"We propose a new framework for compile-time ciphertext synthesis in fully homomorphic encryption (FHE) systems. Instead of invoking encryption algorithms at runtime, our method synthesizes ciphertexts from precomputed encrypted basis vectors using only homomorphic additions, scalar multiplications, and randomized encryptions of zero. This decouples ciphertext generation from encryption, and enables efficient batch encoding through algebraic reuse. We formalize this technique as a randomized module morphism and prove that it satisfies IND-CPA security. Our proof uses a hybrid game framework that interpolates between encrypted vector instances and reduces adversarial advantage to the indistinguishability of the underlying FHE scheme. This reduction structure captures the security implications of ciphertext basis reuse and structured noise injection. The proposed synthesis primitive supports fast, encryption-free ingestion in outsourced database systems and other high-throughput FHE pipelines. It is compatible with standard FHE APIs and preserves layout semantics for downstream homomorphic operations.","authors":["Dongfang Zhao"],"url":"https://arxiv.org/abs/2505.12582"}
{"created":"2025-05-20","title":"A Comprehensive Survey on Physical Risk Control in the Era of Foundation Model-enabled Robotics","abstract":"Recent Foundation Model-enabled robotics (FMRs) display greatly improved general-purpose skills, enabling more adaptable automation than conventional robotics. Their ability to handle diverse tasks thus creates new opportunities to replace human labor. However, unlike general foundation models, FMRs interact with the physical world, where their actions directly affect the safety of humans and surrounding objects, requiring careful deployment and control. Based on this proposition, our survey comprehensively summarizes robot control approaches to mitigate physical risks by covering all the lifespan of FMRs ranging from pre-deployment to post-accident stage. Specifically, we broadly divide the timeline into the following three phases: (1) pre-deployment phase, (2) pre-incident phase, and (3) post-incident phase. Throughout this survey, we find that there is much room to study (i) pre-incident risk mitigation strategies, (ii) research that assumes physical interaction with humans, and (iii) essential issues of foundation models themselves. We hope that this survey will be a milestone in providing a high-resolution analysis of the physical risks of FMRs and their control, contributing to the realization of a good human-robot relationship.","authors":["Takeshi Kojima","Yaonan Zhu","Yusuke Iwasawa","Toshinori Kitamura","Gang Yan","Shu Morikuni","Ryosuke Takanami","Alfredo Solano","Tatsuya Matsushima","Akiko Murakami","Yutaka Matsuo"],"url":"https://arxiv.org/abs/2505.12583"}
{"created":"2025-05-20","title":"Improving Multilingual Language Models by Aligning Representations through Steering","abstract":"In this paper, we investigate how large language models (LLMS) process non-English tokens within their layer representations, an open question despite significant advancements in the field. Using representation steering, specifically by adding a learned vector to a single model layer's activations, we demonstrate that steering a single model layer can notably enhance performance. Our analysis shows that this approach achieves results comparable to translation baselines and surpasses state of the art prompt optimization methods. Additionally, we highlight how advanced techniques like supervised fine tuning (\\textsc{sft}) and reinforcement learning from human feedback (\\textsc{rlhf}) improve multilingual capabilities by altering representation spaces. We further illustrate how these methods align with our approach to reshaping LLMS layer representations.","authors":["Omar Mahmoud","Buddhika Laknath Semage","Thommen George Karimpanal","Santu Rana"],"url":"https://arxiv.org/abs/2505.12584"}
{"created":"2025-05-20","title":"Learning Robust Spectral Dynamics for Temporal Domain Generalization","abstract":"Modern machine learning models struggle to maintain performance in dynamic environments where temporal distribution shifts, \\emph{i.e., concept drift}, are prevalent. Temporal Domain Generalization (TDG) seeks to enable model generalization across evolving domains, yet existing approaches typically assume smooth incremental changes, struggling with complex real-world drifts involving long-term structure (incremental evolution/periodicity) and local uncertainties. To overcome these limitations, we introduce FreKoo, which tackles these challenges via a novel frequency-domain analysis of parameter trajectories. It leverages the Fourier transform to disentangle parameter evolution into distinct spectral bands. Specifically, low-frequency component with dominant dynamics are learned and extrapolated using the Koopman operator, robustly capturing diverse drift patterns including both incremental and periodicity. Simultaneously, potentially disruptive high-frequency variations are smoothed via targeted temporal regularization, preventing overfitting to transient noise and domain uncertainties. In addition, this dual spectral strategy is rigorously grounded through theoretical analysis, providing stability guarantees for the Koopman prediction, a principled Bayesian justification for the high-frequency regularization, and culminating in a multiscale generalization bound connecting spectral dynamics to improved generalization. Extensive experiments demonstrate FreKoo's significant superiority over SOTA TDG approaches, particularly excelling in real-world streaming scenarios with complex drifts and uncertainties.","authors":["En Yu","Jie Lu","Xiaoyu Yang","Guangquan Zhang","Zhen Fang"],"url":"https://arxiv.org/abs/2505.12585"}
{"created":"2025-05-20","title":"A Few Large Shifts: Layer-Inconsistency Based Minimal Overhead Adversarial Example Detection","abstract":"Deep neural networks (DNNs) are highly susceptible to adversarial examples--subtle, imperceptible perturbations that can lead to incorrect predictions. While detection-based defenses offer a practical alternative to adversarial training, many existing methods depend on external models, complex architectures, heavy augmentations, or adversarial data, limiting their efficiency and generalizability. We introduce a lightweight, plug-in detection framework that leverages internal layer-wise inconsistencies within the target model itself, requiring only benign data for calibration. Our approach is grounded in the A Few Large Shifts Assumption, which posits that adversarial perturbations typically induce large representation shifts in a small subset of layers. Building on this, we propose two complementary strategies--Recovery Testing (RT) and Logit-layer Testing (LT)--to expose internal disruptions caused by adversaries. Evaluated on CIFAR-10, CIFAR-100, and ImageNet under both standard and adaptive threat models, our method achieves state-of-the-art detection performance with negligible computational overhead and no compromise to clean accuracy.","authors":["Sanggeon Yun","Ryozo Masukawa","Hyunwoo Oh","Nathaniel D. Bastian","Mohsen Imani"],"url":"https://arxiv.org/abs/2505.12586"}
{"created":"2025-05-20","title":"CMLFormer: A Dual Decoder Transformer with Switching Point Learning for Code-Mixed Language Modeling","abstract":"Code-mixed languages, characterized by frequent within-sentence language transitions, present structural challenges that standard language models fail to address. In this work, we propose CMLFormer, an enhanced multi-layer dual-decoder Transformer with a shared encoder and synchronized decoder cross-attention, designed to model the linguistic and semantic dynamics of code-mixed text. CMLFormer is pre-trained on an augmented Hinglish corpus with switching point and translation annotations with multiple new objectives specifically aimed at capturing switching behavior, cross-lingual structure, and code-mixing complexity. Our experiments show that CMLFormer improves F1 score, precision, and accuracy over other approaches on the HASOC-2021 benchmark under select pre-training setups. Attention analyses further show that it can identify and attend to switching points, validating its sensitivity to code-mixed structure. These results demonstrate the effectiveness of CMLFormer's architecture and multi-task pre-training strategy for modeling code-mixed languages.","authors":["Aditeya Baral","Allen George Ajith","Roshan Nayak","Mrityunjay Abhijeet Bhanja"],"url":"https://arxiv.org/abs/2505.12587"}
{"created":"2025-05-20","title":"Event-based Star Tracking under Spacecraft Jitter: the e-STURT Dataset","abstract":"Jitter degrades a spacecraft's fine-pointing ability required for optical communication, earth observation, and space domain awareness. Development of jitter estimation and compensation algorithms requires high-fidelity sensor observations representative of on-board jitter. In this work, we present the Event-based Star Tracking Under Jitter (e-STURT) dataset -- the first event camera based dataset of star observations under controlled jitter conditions. Specialized hardware employed for the dataset emulates an event-camera undergoing on-board jitter. While the event camera provides asynchronous, high temporal resolution star observations, systematic and repeatable jitter is introduced using a micrometer accurate piezoelectric actuator. Various jitter sources are simulated using distinct frequency bands and utilizing both axes of motion. Ground-truth jitter is captured in hardware from the piezoelectric actuator. The resulting dataset consists of 200 sequences and is made publicly available. This work highlights the dataset generation process, technical challenges and the resulting limitations. To serve as a baseline, we propose a high-frequency jitter estimation algorithm that operates directly on the event stream. The e-STURT dataset will enable the development of jitter aware algorithms for mission critical event-based space sensing applications.","authors":["Samya Bagchi","Peter Anastasiou","Matthew Tetlow","Tat-Jun Chin","Yasir Latif"],"url":"https://arxiv.org/abs/2505.12588"}
{"created":"2025-05-20","title":"SurveillanceVQA-589K: A Benchmark for Comprehensive Surveillance Video-Language Understanding with Large Models","abstract":"Understanding surveillance video content remains a critical yet underexplored challenge in vision-language research, particularly due to its real-world complexity, irregular event dynamics, and safety-critical implications. In this work, we introduce SurveillanceVQA-589K, the largest open-ended video question answering benchmark tailored to the surveillance domain. The dataset comprises 589,380 QA pairs spanning 12 cognitively diverse question types, including temporal reasoning, causal inference, spatial understanding, and anomaly interpretation, across both normal and abnormal video scenarios. To construct the benchmark at scale, we design a hybrid annotation pipeline that combines temporally aligned human-written captions with Large Vision-Language Model-assisted QA generation using prompt-based techniques. We also propose a multi-dimensional evaluation protocol to assess contextual, temporal, and causal comprehension. We evaluate eight LVLMs under this framework, revealing significant performance gaps, especially in causal and anomaly-related tasks, underscoring the limitations of current models in real-world surveillance contexts. Our benchmark provides a practical and comprehensive resource for advancing video-language understanding in safety-critical applications such as intelligent monitoring, incident analysis, and autonomous decision-making.","authors":["Bo Liu","Pengfei Qiao","Minhan Ma","Xuange Zhang","Yinan Tang","Peng Xu","Kun Liu","Tongtong Yuan"],"url":"https://arxiv.org/abs/2505.12589"}
{"created":"2025-05-20","title":"PromptPrism: A Linguistically-Inspired Taxonomy for Prompts","abstract":"Prompts are the interface for eliciting the capabilities of large language models (LLMs). Understanding their structure and components is critical for analyzing LLM behavior and optimizing performance. However, the field lacks a comprehensive framework for systematic prompt analysis and understanding. We introduce PromptPrism, a linguistically-inspired taxonomy that enables prompt analysis across three hierarchical levels: functional structure, semantic component, and syntactic pattern. We show the practical utility of PromptPrism by applying it to three applications: (1) a taxonomy-guided prompt refinement approach that automatically improves prompt quality and enhances model performance across a range of tasks; (2) a multi-dimensional dataset profiling method that extracts and aggregates structural, semantic, and syntactic characteristics from prompt datasets, enabling comprehensive analysis of prompt distributions and patterns; (3) a controlled experimental framework for prompt sensitivity analysis by quantifying the impact of semantic reordering and delimiter modifications on LLM performance. Our experimental results validate the effectiveness of our taxonomy across these applications, demonstrating that PromptPrism provides a foundation for refining, profiling, and analyzing prompts.","authors":["Sullam Jeoung","Yueyan Chen","Yi Zhang","Shuai Wang","Haibo Ding","Lin Lee Cheong"],"url":"https://arxiv.org/abs/2505.12592"}
{"created":"2025-05-20","title":"Learning Cross-Spectral Point Features with Task-Oriented Training","abstract":"Unmanned aerial vehicles (UAVs) enable operations in remote and hazardous environments, yet the visible-spectrum, camera-based navigation systems often relied upon by UAVs struggle in low-visibility conditions. Thermal cameras, which capture long-wave infrared radiation, are able to function effectively in darkness and smoke, where visible-light cameras fail. This work explores learned cross-spectral (thermal-visible) point features as a means to integrate thermal imagery into established camera-based navigation systems. Existing methods typically train a feature network's detection and description outputs directly, which often focuses training on image regions where thermal and visible-spectrum images exhibit similar appearance. Aiming to more fully utilize the available data, we propose a method to train the feature network on the tasks of matching and registration. We run our feature network on thermal-visible image pairs, then feed the network response into a differentiable registration pipeline. Losses are applied to the matching and registration estimates of this pipeline. Our selected model, trained on the task of matching, achieves a registration error (corner error) below 10 pixels for more than 75% of estimates on the MultiPoint dataset. We further demonstrate that our model can also be used with a classical pipeline for matching and registration.","authors":["Mia Thomas","Trevor Ablett","Jonathan Kelly"],"url":"https://arxiv.org/abs/2505.12593"}
{"created":"2025-05-20","title":"AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection","abstract":"Anomaly detection (AD) is essential in areas such as fraud detection, network monitoring, and scientific research. However, the diversity of data modalities and the increasing number of specialized AD libraries pose challenges for non-expert users who lack in-depth library-specific knowledge and advanced programming skills. To tackle this, we present AD-AGENT, an LLM-driven multi-agent framework that turns natural-language instructions into fully executable AD pipelines. AD-AGENT coordinates specialized agents for intent parsing, data preparation, library and model selection, documentation mining, and iterative code generation and debugging. Using a shared short-term workspace and a long-term cache, the agents integrate popular AD libraries like PyOD, PyGOD, and TSLib into a unified workflow. Experiments demonstrate that AD-AGENT produces reliable scripts and recommends competitive models across libraries. The system is open-sourced to support further research and practical applications in AD.","authors":["Tiankai Yang","Junjun Liu","Wingchun Siu","Jiahang Wang","Zhuangzhuang Qian","Chanjuan Song","Cheng Cheng","Xiyang Hu","Yue Zhao"],"url":"https://arxiv.org/abs/2505.12594"}
{"created":"2025-05-20","title":"Chain-Talker: Chain Understanding and Rendering for Empathetic Conversational Speech Synthesis","abstract":"Conversational Speech Synthesis (CSS) aims to align synthesized speech with the emotional and stylistic context of user-agent interactions to achieve empathy. Current generative CSS models face interpretability limitations due to insufficient emotional perception and redundant discrete speech coding. To address the above issues, we present Chain-Talker, a three-stage framework mimicking human cognition: Emotion Understanding derives context-aware emotion descriptors from dialogue history; Semantic Understanding generates compact semantic codes via serialized prediction; and Empathetic Rendering synthesizes expressive speech by integrating both components. To support emotion modeling, we develop CSS-EmCap, an LLM-driven automated pipeline for generating precise conversational speech emotion captions. Experiments on three benchmark datasets demonstrate that Chain-Talker produces more expressive and empathetic speech than existing methods, with CSS-EmCap contributing to reliable emotion modeling. The code and demos are available at: https://github.com/AI-S2-Lab/Chain-Talker.","authors":["Yifan Hu","Rui Liu","Yi Ren","Xiang Yin","Haizhou Li"],"url":"https://arxiv.org/abs/2505.12597"}
{"created":"2025-05-20","title":"Fast and Simple Densest Subgraph with Predictions","abstract":"We study the densest subgraph problem and its variants through the lens of learning-augmented algorithms. For this problem, the greedy algorithm by Charikar (APPROX 2000) provides a linear-time $ 1/2 $-approximation, while computing the exact solution typically requires solving a linear program or performing maximum flow computations.We show that given a partial solution, i.e., one produced by a machine learning classifier that captures at least a $ (1 - \\epsilon) $-fraction of nodes in the optimal subgraph, it is possible to design an extremely simple linear-time algorithm that achieves a provable $ (1 - \\epsilon) $-approximation. Our approach also naturally extends to the directed densest subgraph problem and several NP-hard variants.An experiment on the Twitch Ego Nets dataset shows that our learning-augmented algorithm outperforms Charikar's greedy algorithm and a baseline that directly returns the predicted densest subgraph without additional algorithmic processing.","authors":["Thai Bui","Hoa T. Vu"],"url":"https://arxiv.org/abs/2505.12600"}
{"created":"2025-05-20","title":"Rethinking Predictive Modeling for LLM Routing: When Simple kNN Beats Complex Learned Routers","abstract":"As large language models (LLMs) grow in scale and specialization, routing--selecting the best model for a given input--has become essential for efficient and effective deployment. While recent methods rely on complex learned routing strategies, their dependence on disparate training data and evaluation setups makes comparison and generalization difficult. In this work, we revisit LLM routing through the lens of simplicity. We show that a well-tuned k-Nearest Neighbors (kNN) approach not only matches but often outperforms state-of-the-art learned routers across diverse tasks. To support systematic evaluation, we introduce a suite of standardized routing benchmarks spanning instruction-following, question-answering, and reasoning tasks, as well as the first multi-modal routing dataset involving visual inputs. Our findings reveal that the locality properties of model performance in embedding space enable simple non-parametric methods to achieve strong routing decisions with lower sample complexity than parametric approaches. This challenges the prevailing trend toward sophisticated architectures and highlights the importance of thoroughly evaluating simple baselines before investing in complex solutions. To support reproducibility and further exploration, we will release all benchmarks and code upon publication.","authors":["Yang Li"],"url":"https://arxiv.org/abs/2505.12601"}
{"created":"2025-05-20","title":"Temporal-Oriented Recipe for Transferring Large Vision-Language Model to Video Understanding","abstract":"Recent years have witnessed outstanding advances of large vision-language models (LVLMs). In order to tackle video understanding, most of them depend upon their implicit temporal understanding capacity. As such, they have not deciphered important components that contribute to temporal understanding ability, which might limit the potential of these LVLMs for video understanding. In this work, we conduct a thorough empirical study to demystify crucial components that influence the temporal understanding of LVLMs. Our empirical study reveals that significant impacts are centered around the intermediate interface between the visual encoder and the large language model. Building on these insights, we propose a temporal-oriented recipe that encompasses temporal-oriented training schemes and an upscaled interface. Our final model developed using our recipe significantly enhances previous LVLMs on standard video understanding tasks.","authors":["Thong Nguyen","Zhiyuan Hu","Xu Lin","Cong-Duy Nguyen","See-Kiong Ng","Luu Anh Tuan"],"url":"https://arxiv.org/abs/2505.12605"}
{"created":"2025-05-20","title":"Diff-MM: Exploring Pre-trained Text-to-Image Generation Model for Unified Multi-modal Object Tracking","abstract":"Multi-modal object tracking integrates auxiliary modalities such as depth, thermal infrared, event flow, and language to provide additional information beyond RGB images, showing great potential in improving tracking stabilization in complex scenarios. Existing methods typically start from an RGB-based tracker and learn to understand auxiliary modalities only from training data. Constrained by the limited multi-modal training data, the performance of these methods is unsatisfactory. To alleviate this limitation, this work proposes a unified multi-modal tracker Diff-MM by exploiting the multi-modal understanding capability of the pre-trained text-to-image generation model. Diff-MM leverages the UNet of pre-trained Stable Diffusion as a tracking feature extractor through the proposed parallel feature extraction pipeline, which enables pairwise image inputs for object tracking. We further introduce a multi-modal sub-module tuning method that learns to gain complementary information between different modalities. By harnessing the extensive prior knowledge in the generation model, we achieve a unified tracker with uniform parameters for RGB-N/D/T/E tracking. Experimental results demonstrate the promising performance of our method compared with recently proposed trackers, e.g., its AUC outperforms OneTracker by 8.3% on TNL2K.","authors":["Shiyu Xuan","Zechao Li","Jinhui Tang"],"url":"https://arxiv.org/abs/2505.12606"}
{"created":"2025-05-20","title":"Seismic analysis based on a new interval method with incomplete information","abstract":"For seismic analysis in engineering structures, it is essential to consider the dynamic responses under seismic excitation, necessitating the description of seismic accelerations. Limit seismics samples lead to incomplete uncertainty information, which is described by the non-probabilistic method reasonable. This study employs the minimum interval radius-based interval process (MRIP) based on the convex model to describe the time-variant uncertain seismic acceleration, subsequently conducting uncertainty analysis for seismic structures. However, the Monte Carlo simulation for uncertainty analysis requires extensive deterministic computations to ensure accuracy, exhibiting poor computational efficiency. To address this issue, this paper first improves the covariance matrix adaptation evolution strategy (CMA-ES) through the dynamic evolution sequence, proposing DES-ES, whose efficiency is validated to be higher than that of CMA-ES. Furthermore, leveraging the dependency of the responses, a computational framework named DES-ES-SS is proposed. Numerical experiments demonstrate that DES-ES-SS improves computational efficiency while maintaining the accuracy of the interval uncertainty analysis of the seismic structures whether the seismic acceleration is stationary or non-stationary.","authors":["Shizhong Liang","Yuxiang Yang","Chen Li","Feng Wu"],"url":"https://arxiv.org/abs/2505.12607"}
{"created":"2025-05-20","title":"Quantum Modeling of Spatial Contiguity Constraints","abstract":"Quantum computing has demonstrated potential for solving complex optimization problems; however, its application to spatial regionalization remains underexplored. Spatial contiguity, a fundamental constraint requiring spatial entities to form connected components, significantly increases the complexity of regionalization problems, which are typically challenging for quantum modeling. This paper proposes novel quantum formulations based on a flow model that enforces spatial contiguity constraints. Our scale-aware approach employs a Discrete Quadratic Model (DQM), solvable directly on quantum annealing hardware for small-scale datasets. In addition, it designs a hybrid quantum-classical approach to manage larger-scale problems within existing hardware limitations. This work establishes a foundational framework for integrating quantum methods into practical spatial optimization tasks.","authors":["Yunhan Chang","Amr Magdy","Federico M. Spedalieri"],"url":"https://arxiv.org/abs/2505.12608"}
{"created":"2025-05-20","title":"The Hamiltonian of Poly-matrix Zero-sum Games","abstract":"Understanding a dynamical system fundamentally relies on establishing an appropriate Hamiltonian function and elucidating its symmetries. By formulating agents' strategies and cumulative payoffs as canonically conjugate variables, we identify the Hamiltonian function that generates the dynamics of poly-matrix zero-sum games. We reveal the symmetries of our Hamiltonian and derive the associated conserved quantities, showing how the conservation of probability and the invariance of the Fenchel coupling are intrinsically encoded within the system. Furthermore, we propose the dissipation FTRL (DFTRL) dynamics by introducing a perturbation that dissipates the Fenchel coupling, proving convergence to the Nash equilibrium and linking DFTRL to last-iterate convergent algorithms. Our results highlight the potential of Hamiltonian dynamics in uncovering the structural properties of learning dynamics in games, and pave the way for broader applications of Hamiltonian dynamics in game theory and machine learning.","authors":["Toshihiro Ota","Yuma Fujimoto"],"url":"https://arxiv.org/abs/2505.12609"}
{"created":"2025-05-20","title":"hChain: Blockchain Based Large Scale EHR Data Sharing with Enhanced Security and Privacy","abstract":"Concerns regarding privacy and data security in conventional healthcare prompted alternative technologies. In smart healthcare, blockchain technology addresses existing concerns with security, privacy, and electronic healthcare transmission. Integration of Blockchain Technology with the Internet of Medical Things (IoMT) allows real-time monitoring of protected healthcare data. Utilizing edge devices with IoMT devices is very advantageous for addressing security, computing, and storage challenges. Encryption using symmetric and asymmetric keys is used to conceal sensitive information from unauthorized parties. SHA256 is an algorithm for one-way hashing. It is used to verify that the data has not been altered, since if it had, the hash value would have changed. This article offers a blockchain-based smart healthcare system using IoMT devices for continuous patient monitoring. In addition, it employs edge resources in addition to IoMT devices to have extra computing power and storage to hash and encrypt incoming data before sending it to the blockchain. Symmetric key is utilized to keep the data private even in the blockchain, allowing the patient to safely communicate the data through smart contracts while preventing unauthorized physicians from seeing the data. Through the use of a verification node and blockchain, an asymmetric key is used for the signing and validation of patient data in the healthcare provider system. In addition to other security measures, location-based authentication is recommended to guarantee that data originates from the patient area. Through the edge device, SHA256 is utilized to secure the data's integrity and a secret key is used to maintain its secrecy. The hChain architecture improves the computing power of IoMT environments, the security of EHR sharing through smart contracts, and the privacy and authentication procedures.","authors":["Musharraf Alruwaill","Saraju Mohanty","Elias Kougianos"],"url":"https://arxiv.org/abs/2505.12610"}
{"created":"2025-05-20","title":"Action-Dependent Optimality-Preserving Reward Shaping","abstract":"Recent RL research has utilized reward shaping--particularly complex shaping rewards such as intrinsic motivation (IM)--to encourage agent exploration in sparse-reward environments. While often effective, ``reward hacking'' can lead to the shaping reward being optimized at the expense of the extrinsic reward, resulting in a suboptimal policy. Potential-Based Reward Shaping (PBRS) techniques such as Generalized Reward Matching (GRM) and Policy-Invariant Explicit Shaping (PIES) have mitigated this. These methods allow for implementing IM without altering optimal policies. In this work we show that they are effectively unsuitable for complex, exploration-heavy environments with long-duration episodes. To remedy this, we introduce Action-Dependent Optimality Preserving Shaping (ADOPS), a method of converting intrinsic rewards to an optimality-preserving form that allows agents to utilize IM more effectively in the extremely sparse environment of Montezuma's Revenge. We also prove ADOPS accommodates reward shaping functions that cannot be written in a potential-based form: while PBRS-based methods require the cumulative discounted intrinsic return be independent of actions, ADOPS allows for intrinsic cumulative returns to be dependent on agents' actions while still preserving the optimal policy set. We show how action-dependence enables ADOPS's to preserve optimality while learning in complex, sparse-reward environments where other methods struggle.","authors":["Grant C. Forbes","Jianxun Wang","Leonardo Villalobos-Arias","Arnav Jhala","David L. Roberts"],"url":"https://arxiv.org/abs/2505.12611"}
{"created":"2025-05-20","title":"EPSpatial: Achieving Efficient and Private Statistical Analytics of Geospatial Data","abstract":"Geospatial data statistics involve the aggregation and analysis of location data to derive the distribution of clients within geospatial. The need for privacy protection in geospatial data analysis has become paramount due to concerns over the misuse or unauthorized access of client location information. However, existing private geospatial data statistics mainly rely on privacy computing techniques such as cryptographic tools and differential privacy, which leads to significant overhead and inaccurate results. In practical applications, geospatial data is frequently generated by mobile devices such as smartphones and IoT sensors. The continuous mobility of clients and the need for real-time updates introduce additional complexity. To address these issues, we first design \\textit{spatially distributed point functions (SDPF)}, which combines a quad-tree structure with distributed point functions, allowing clients to succinctly secret-share values on the nodes of an exponentially large quad-tree. Then, we use Gray code to partition the region and combine SDPF with it to propose $\\mathtt{EPSpatial}$, a scheme for accurate, efficient, and private statistical analytics of geospatial data. Moreover, considering clients' frequent movement requires continuous location updates, we leverage the region encoding property to present an efficient update algorithm.Security analysis shows that $\\mathtt{EPSpatial}$ effectively protects client location privacy. Theoretical analysis and experimental results on real datasets demonstrate that $\\mathtt{EPSpatial}$ reduces computational and communication overhead by at least $50\\%$ compared to existing statistical schemes.","authors":["Chuan Zhang","Xuhao Ren","Zhangcheng Huang","Jinwen Liang","Jianzong Wang","Liehuang Zhu"],"url":"https://arxiv.org/abs/2505.12612"}
{"created":"2025-05-20","title":"Towards Centralized Orchestration of Cyber Protection Condition (CPCON)","abstract":"The United States Cyber Command (USCYBERCOM) Cyber Protection Condition (CPCON) framework mandates graduated security postures across Department of Defense (DoD) networks, but current implementation remains largely manual, inconsistent, and error-prone. This paper presents a prototype system for centralized orchestration of CPCON directives, enabling automated policy enforcement and real-time threat response across heterogeneous network environments. Building on prior work in host-based intrusion response, our system leverages a policy-driven orchestrator to standardize security actions, isolate compromised subnets, and verify enforcement status. We validate the system through emulated attack scenarios, demonstrating improved speed, accuracy, and verifiability in CPCON transitions with human-in-the-loop oversight.","authors":["Mark Timmons","Daniel Lukaszewski","Geoffrey Xie","Thomas Mayo","Donald McCanless"],"url":"https://arxiv.org/abs/2505.12613"}
{"created":"2025-05-20","title":"Adaptive Graph Unlearning","abstract":"Graph unlearning, which deletes graph elements such as nodes and edges from trained graph neural networks (GNNs), is crucial for real-world applications where graph data may contain outdated, inaccurate, or privacy-sensitive information. However, existing methods often suffer from (1) incomplete or over unlearning due to neglecting the distinct objectives of different unlearning tasks, and (2) inaccurate identification of neighbors affected by deleted elements across various GNN architectures. To address these limitations, we propose AGU, a novel Adaptive Graph Unlearning framework that flexibly adapts to diverse unlearning tasks and GNN architectures. AGU ensures the complete forgetting of deleted elements while preserving the integrity of the remaining graph. It also accurately identifies affected neighbors for each GNN architecture and prioritizes important ones to enhance unlearning performance. Extensive experiments on seven real-world graphs demonstrate that AGU outperforms existing methods in terms of effectiveness, efficiency, and unlearning capability.","authors":["Pengfei Ding","Yan Wang","Guanfeng Liu","Jiajie Zhu"],"url":"https://arxiv.org/abs/2505.12614"}
{"created":"2025-05-20","title":"Duluth at SemEval-2025 Task 7: TF-IDF with Optimized Vector Dimensions for Multilingual Fact-Checked Claim Retrieval","abstract":"This paper presents the Duluth approach to the SemEval-2025 Task 7 on Multilingual and Crosslingual Fact-Checked Claim Retrieval. We implemented a TF-IDF-based retrieval system with experimentation on vector dimensions and tokenization strategies. Our best-performing configuration used word-level tokenization with a vocabulary size of 15,000 features, achieving an average success@10 score of 0.78 on the development set and 0.69 on the test set across ten languages. Our system showed stronger performance on higher-resource languages but still lagged significantly behind the top-ranked system, which achieved 0.96 average success@10. Our findings suggest that though advanced neural architectures are increasingly dominant in multilingual retrieval tasks, properly optimized traditional methods like TF-IDF remain competitive baselines, especially in limited compute resource scenarios.","authors":["Shujauddin Syed","Ted Pedersen"],"url":"https://arxiv.org/abs/2505.12616"}
{"created":"2025-05-20","title":"HIL: Hybrid Imitation Learning of Diverse Parkour Skills from Videos","abstract":"Recent data-driven methods leveraging deep reinforcement learning have been an effective paradigm for developing controllers that enable physically simulated characters to produce natural human-like behaviors. However, these data-driven methods often struggle to adapt to novel environments and compose diverse skills coherently to perform more complex tasks. To address these challenges, we propose a hybrid imitation learning (HIL) framework that combines motion tracking, for precise skill replication, with adversarial imitation learning, to enhance adaptability and skill composition. This hybrid learning framework is implemented through parallel multi-task environments and a unified observation space, featuring an agent-centric scene representation to facilitate effective learning from the hybrid parallel environments. Our framework trains a unified controller on parkour data sourced from Internet videos, enabling a simulated character to traverse through new environments using diverse and life-like parkour skills. Evaluations across challenging parkour environments demonstrate that our method improves motion quality, increases skill diversity, and achieves competitive task completion compared to previous learning-based methods.","authors":["Jiashun Wang","Yifeng Jiang","Haotian Zhang","Chen Tessler","Davis Rempe","Jessica Hodgins","Xue Bin Peng"],"url":"https://arxiv.org/abs/2505.12619"}
{"created":"2025-05-20","title":"BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation","abstract":"Advances in AI generative models facilitate super-realistic video synthesis, amplifying misinformation risks via social media and eroding trust in digital content. Several research works have explored new deepfake detection methods on AI-generated images to alleviate these risks. However, with the fast development of video generation models, such as Sora and WanX, there is currently a lack of large-scale, high-quality AI-generated video datasets for forgery detection. In addition, existing detection approaches predominantly treat the task as binary classification, lacking explainability in model decision-making and failing to provide actionable insights or guidance for the public. To address these challenges, we propose \\textbf{GenBuster-200K}, a large-scale AI-generated video dataset featuring 200K high-resolution video clips, diverse latest generative techniques, and real-world scenes. We further introduce \\textbf{BusterX}, a novel AI-generated video detection and explanation framework leveraging multimodal large language model (MLLM) and reinforcement learning for authenticity determination and explainable rationale. To our knowledge, GenBuster-200K is the {\\it \\textbf{first}} large-scale, high-quality AI-generated video dataset that incorporates the latest generative techniques for real-world scenarios. BusterX is the {\\it \\textbf{first}} framework to integrate MLLM with reinforcement learning for explainable AI-generated video detection. Extensive comparisons with state-of-the-art methods and ablation studies validate the effectiveness and generalizability of BusterX. The code, models, and datasets will be released.","authors":["Haiquan Wen","Yiwei He","Zhenglin Huang","Tianxiao Li","Zihan YU","Xingru Huang","Lu Qi","Baoyuan Wu","Xiangtai Li","Guangliang Cheng"],"url":"https://arxiv.org/abs/2505.12620"}
{"created":"2025-05-20","title":"Think Before You Attribute: Improving the Performance of LLMs Attribution Systems","abstract":"Large Language Models (LLMs) are increasingly applied in various science domains, yet their broader adoption remains constrained by a critical challenge: the lack of trustworthy, verifiable outputs. Current LLMs often generate answers without reliable source attribution, or worse, with incorrect attributions, posing a barrier to their use in scientific and high-stakes settings, where traceability and accountability are non-negotiable. To be reliable, attribution systems need high accuracy and retrieve data with short lengths, i.e., attribute to a sentence within a document rather than a whole document. We propose a sentence-level pre-attribution step for Retrieve-Augmented Generation (RAG) systems that classify sentences into three categories: not attributable, attributable to a single quote, and attributable to multiple quotes. By separating sentences before attribution, a proper attribution method can be selected for the type of sentence, or the attribution can be skipped altogether. Our results indicate that classifiers are well-suited for this task. In this work, we propose a pre-attribution step to reduce the computational complexity of attribution, provide a clean version of the HAGRID dataset, and provide an end-to-end attribution system that works out of the box.","authors":["Jo\\~ao Eduardo Batista","Emil Vatai","Mohamed Wahib"],"url":"https://arxiv.org/abs/2505.12621"}
{"created":"2025-05-20","title":"Lightweight and Effective Preference Construction in PIBT for Large-Scale Multi-Agent Pathfinding","abstract":"PIBT is a computationally lightweight algorithm that can be applied to a variety of multi-agent pathfinding (MAPF) problems, generating the next collision-free locations of agents given another. Because of its simplicity and scalability, it is becoming a popular underlying scheme for recent large-scale MAPF methods involving several hundreds or thousands of agents. Vanilla PIBT makes agents behave greedily towards their assigned goals, while agents typically have multiple best actions, since the graph shortest path is not always unique. Consequently, tiebreaking about how to choose between these actions significantly affects resulting solutions. This paper studies two simple yet effective techniques for tiebreaking in PIBT, without compromising its computational advantage. The first technique allows an agent to intelligently dodge another, taking into account whether each action will hinder the progress of the next timestep. The second technique is to learn, through multiple PIBT runs, how an action causes regret in others and to use this information to minimise regret collectively. Our empirical results demonstrate that these techniques can reduce the solution cost of one-shot MAPF and improve the throughput of lifelong MAPF. For instance, in densely populated one-shot cases, the combined use of these tiebreaks achieves improvements of around 10-20% in sum-of-costs, without significantly compromising the speed of a PIBT-based planner.","authors":["Keisuke Okumura","Hiroki Nagai"],"url":"https://arxiv.org/abs/2505.12623"}
{"created":"2025-05-20","title":"EndoForce: Development of an Intuitive Axial Force Measurement Device for Endoscopic Robotic Systems","abstract":"Robotic endoscopic systems provide intuitive control and eliminate radiation exposure, making them a promising alternative to conventional methods. However, the lack of axial force measurement from the robot remains a major challenge, as it can lead to excessive colonic elongation, perforation, or ureteral complications. Although various methods have been proposed in previous studies, limitations such as model dependency, bulkiness, and environmental sensitivity remain challenges that should be addressed before clinical application. In this study, we propose EndoForce, a device designed for intuitive and accurate axial force measurement in endoscopic robotic systems. Inspired by the insertion motion performed by medical doctors during ureteroscopy and gastrointestinal (GI) endoscopy, EndoForce ensures precise force measuring while maintaining compatibility with clinical environments. The device features a streamlined design, allowing for the easy attachment and detachment of a sterile cover, and incorporates a commercial load cell to enhance cost-effectiveness and facilitate practical implementation in real medical applications. To validate the effectiveness of the proposed EndoForce, physical experiments were performed using a testbed that simulates the ureter. We show that the axial force generated during insertion was measured with high accuracy, regardless of whether the pathway was straight or curved, in a testbed simulating the human ureter.","authors":["Hansoul Kim","Dong-Ho Lee","Dukyoo Kong","Dong-Soo Kwon","Byungsik Cheon"],"url":"https://arxiv.org/abs/2505.12624"}
{"created":"2025-05-20","title":"R1dacted: Investigating Local Censorship in DeepSeek's R1 Language Model","abstract":"DeepSeek recently released R1, a high-performing large language model (LLM) optimized for reasoning tasks. Despite its efficient training pipeline, R1 achieves competitive performance, even surpassing leading reasoning models like OpenAI's o1 on several benchmarks. However, emerging reports suggest that R1 refuses to answer certain prompts related to politically sensitive topics in China. While existing LLMs often implement safeguards to avoid generating harmful or offensive outputs, R1 represents a notable shift - exhibiting censorship-like behavior on politically charged queries. In this paper, we investigate this phenomenon by first introducing a large-scale set of heavily curated prompts that get censored by R1, covering a range of politically sensitive topics, but are not censored by other models. We then conduct a comprehensive analysis of R1's censorship patterns, examining their consistency, triggers, and variations across topics, prompt phrasing, and context. Beyond English-language queries, we explore censorship behavior in other languages. We also investigate the transferability of censorship to models distilled from the R1 language model. Finally, we propose techniques for bypassing or removing this censorship. Our findings reveal possible additional censorship integration likely shaped by design choices during training or alignment, raising concerns about transparency, bias, and governance in language model deployment.","authors":["Ali Naseh","Harsh Chaudhari","Jaechul Roh","Mingshi Wu","Alina Oprea","Amir Houmansadr"],"url":"https://arxiv.org/abs/2505.12625"}
{"created":"2025-05-20","title":"Efficient Heuristics Generation for Solving Combinatorial Optimization Problems Using Large Language Models","abstract":"Recent studies exploited Large Language Models (LLMs) to autonomously generate heuristics for solving Combinatorial Optimization Problems (COPs), by prompting LLMs to first provide search directions and then derive heuristics accordingly. However, the absence of task-specific knowledge in prompts often leads LLMs to provide unspecific search directions, obstructing the derivation of well-performing heuristics. Moreover, evaluating the derived heuristics remains resource-intensive, especially for those semantically equivalent ones, often requiring omissible resource expenditure. To enable LLMs to provide specific search directions, we propose the Hercules algorithm, which leverages our designed Core Abstraction Prompting (CAP) method to abstract the core components from elite heuristics and incorporate them as prior knowledge in prompts. We theoretically prove the effectiveness of CAP in reducing unspecificity and provide empirical results in this work. To reduce computing resources required for evaluating the derived heuristics, we propose few-shot Performance Prediction Prompting (PPP), a first-of-its-kind method for the Heuristic Generation (HG) task. PPP leverages LLMs to predict the fitness values of newly derived heuristics by analyzing their semantic similarity to previously evaluated ones. We further develop two tailored mechanisms for PPP to enhance predictive accuracy and determine unreliable predictions, respectively. The use of PPP makes Hercules more resource-efficient and we name this variant Hercules-P. Extensive experiments across four HG tasks, five COPs, and eight LLMs demonstrate that Hercules outperforms the state-of-the-art LLM-based HG algorithms, while Hercules-P excels at minimizing required computing resources. In addition, we illustrate the effectiveness of CAP, PPP, and the other proposed mechanisms by conducting relevant ablation studies.","authors":["Xuan Wu","Di Wang","Chunguo Wu","Lijie Wen","Chunyan Miao","Yubin Xiao","You Zhou"],"url":"https://arxiv.org/abs/2505.12627"}
{"created":"2025-05-20","title":"Dual-Agent Reinforcement Learning for Automated Feature Generation","abstract":"Feature generation involves creating new features from raw data to capture complex relationships among the original features, improving model robustness and machine learning performance. Current methods using reinforcement learning for feature generation have made feature exploration more flexible and efficient. However, several challenges remain: first, during feature expansion, a large number of redundant features are generated. When removing them, current methods only retain the best features each round, neglecting those that perform poorly initially but could improve later. Second, the state representation used by current methods fails to fully capture complex feature relationships. Third, there are significant differences between discrete and continuous features in tabular data, requiring different operations for each type. To address these challenges, we propose a novel dual-agent reinforcement learning method for feature generation. Two agents are designed: the first generates new features, and the second determines whether they should be preserved. A self-attention mechanism enhances state representation, and diverse operations distinguish interactions between discrete and continuous features. The experimental results on multiple datasets demonstrate that the proposed method is effective. The code is available at https://github.com/extess0/DARL.","authors":["Wanfu Gao","Zengyao Man","Hanlin Pan","Kunpeng Liu"],"url":"https://arxiv.org/abs/2505.12628"}
{"created":"2025-05-20","title":"Enhancing Latent Computation in Transformers with Latent Tokens","abstract":"Augmenting large language models (LLMs) with auxiliary tokens has emerged as a promising strategy for enhancing model performance. In this work, we introduce a lightweight method termed latent tokens; these are dummy tokens that may be non-interpretable in natural language but steer the autoregressive decoding process of a Transformer-based LLM via the attention mechanism. The proposed latent tokens can be seamlessly integrated with a pre-trained Transformer, trained in a parameter-efficient manner, and applied flexibly at inference time, while adding minimal complexity overhead to the existing infrastructure of standard Transformers. We propose several hypotheses about the underlying mechanisms of latent tokens and design synthetic tasks accordingly to verify them. Numerical results confirm that the proposed method noticeably outperforms the baselines, particularly in the out-of-distribution generalization scenarios, highlighting its potential in improving the adaptability of LLMs.","authors":["Yuchang Sun","Yanxi Chen","Yaliang Li","Bolin Ding"],"url":"https://arxiv.org/abs/2505.12629"}
{"created":"2025-05-20","title":"Degradation-Aware Feature Perturbation for All-in-One Image Restoration","abstract":"All-in-one image restoration aims to recover clear images from various degradation types and levels with a unified model. Nonetheless, the significant variations among degradation types present challenges for training a universal model, often resulting in task interference, where the gradient update directions of different tasks may diverge due to shared parameters. To address this issue, motivated by the routing strategy, we propose DFPIR, a novel all-in-one image restorer that introduces Degradation-aware Feature Perturbations(DFP) to adjust the feature space to align with the unified parameter space. In this paper, the feature perturbations primarily include channel-wise perturbations and attention-wise perturbations. Specifically, channel-wise perturbations are implemented by shuffling the channels in high-dimensional space guided by degradation types, while attention-wise perturbations are achieved through selective masking in the attention space. To achieve these goals, we propose a Degradation-Guided Perturbation Block (DGPB) to implement these two functions, positioned between the encoding and decoding stages of the encoder-decoder architecture. Extensive experimental results demonstrate that DFPIR achieves state-of-the-art performance on several all-in-one image restoration tasks including image denoising, image dehazing, image deraining, motion deblurring, and low-light image enhancement. Our codes are available at https://github.com/TxpHome/DFPIR.","authors":["Xiangpeng Tian","Xiangyu Liao","Xiao Liu","Meng Li","Chao Ren"],"url":"https://arxiv.org/abs/2505.12630"}
{"created":"2025-05-20","title":"Multi-Resolution Haar Network: Enhancing human motion prediction via Haar transform","abstract":"The 3D human pose is vital for modern computer vision and computer graphics, and its prediction has drawn attention in recent years. 3D human pose prediction aims at forecasting a human's future motion from the previous sequence. Ignoring that the arbitrariness of human motion sequences has a firm origin in transition in both temporal and spatial axes limits the performance of state-of-the-art methods, leading them to struggle with making precise predictions on complex cases, e.g., arbitrarily posing or greeting. To alleviate this problem, a network called HaarMoDic is proposed in this paper, which utilizes the 2D Haar transform to project joints to higher resolution coordinates where the network can access spatial and temporal information simultaneously. An ablation study proves that the significant contributing module within the HaarModic Network is the Multi-Resolution Haar (MR-Haar) block. Instead of mining in one of two axes or extracting separately, the MR-Haar block projects whole motion sequences to a mixed-up coordinate in higher resolution with 2D Haar Transform, allowing the network to give scope to information from both axes in different resolutions. With the MR-Haar block, the HaarMoDic network can make predictions referring to a broader range of information. Experimental results demonstrate that HaarMoDic surpasses state-of-the-art methods in every testing interval on the Human3.6M dataset in the Mean Per Joint Position Error (MPJPE) metric.","authors":["Li Lin"],"url":"https://arxiv.org/abs/2505.12631"}
{"created":"2025-05-20","title":"Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents","abstract":"Recent advancements in Large Language Models (LLMs) and Vision-Language Models (VLMs) have sparked significant interest in developing GUI visual agents. We introduce MONDAY (Mobile OS Navigation Task Dataset for Agents from YouTube), a large-scale dataset of 313K annotated frames from 20K instructional videos capturing diverse real-world mobile OS navigation across multiple platforms. Models that include MONDAY in their pre-training phases demonstrate robust cross-platform generalization capabilities, consistently outperforming models trained on existing single OS datasets while achieving an average performance gain of 18.11%p on an unseen mobile OS platform. To enable continuous dataset expansion as mobile platforms evolve, we present an automated framework that leverages publicly available video content to create comprehensive task datasets without manual annotation. Our framework comprises robust OCR-based scene detection (95.04% F1score), near-perfect UI element detection (99.87% hit ratio), and novel multi-step action identification to extract reliable action sequences across diverse interface configurations. We contribute both the MONDAY dataset and our automated collection framework to facilitate future research in mobile OS navigation.","authors":["Yunseok Jang","Yeda Song","Sungryull Sohn","Lajanugen Logeswaran","Tiange Luo","Dong-Ki Kim","Kyunghoon Bae","Honglak Lee"],"url":"https://arxiv.org/abs/2505.12632"}
{"created":"2025-05-20","title":"MSCEKF-MIO: Magnetic-Inertial Odometry Based on Multi-State Constraint Extended Kalman Filter","abstract":"To overcome the limitation of existing indoor odometry technologies which often cannot simultaneously meet requirements for accuracy cost-effectiveness, and robustness-this paper proposes a novel magnetometer array-aided inertial odometry approach, MSCEKF-MIO (Multi-State Constraint Extended Kalman Filter-based Magnetic-Inertial Odometry). We construct a magnetic field model by fitting measurements from the magnetometer array and then use temporal variations in this model-extracted from continuous observations-to estimate the carrier's absolute velocity. Furthermore, we implement the MSCEKF framework to fuse observed magnetic field variations with position and attitude estimates from inertial navigation system (INS) integration, thereby enabling autonomous, high-precision indoor relative positioning. Experimental results demonstrate that the proposed algorithm achieves superior velocity estimation accuracy and horizontal positioning precision relative to state-of-the-art magnetic array-aided INS algorithms (MAINS). On datasets with trajectory lengths of 150-250m, the proposed method yields an average horizontal position RMSE of approximately 2.5m. In areas with distinctive magnetic features, the magneto-inertial odometry achieves a velocity estimation accuracy of 0.07m/s. Consequently, the proposed method offers a novel positioning solution characterized by low power consumption, cost-effectiveness, and high reliability in complex indoor environments.","authors":["Jiazhu Li","Jian Kuang","Xiaoji","Niu"],"url":"https://arxiv.org/abs/2505.12634"}
{"created":"2025-05-20","title":"MVPainter: Accurate and Detailed 3D Texture Generation via Multi-View Diffusion with Geometric Control","abstract":"Recently, significant advances have been made in 3D object generation. Building upon the generated geometry, current pipelines typically employ image diffusion models to generate multi-view RGB images, followed by UV texture reconstruction through texture baking. While 3D geometry generation has improved significantly, supported by multiple open-source frameworks, 3D texture generation remains underexplored. In this work, we systematically investigate 3D texture generation through the lens of three core dimensions: reference-texture alignment, geometry-texture consistency, and local texture quality. To tackle these issues, we propose MVPainter, which employs data filtering and augmentation strategies to enhance texture fidelity and detail, and introduces ControlNet-based geometric conditioning to improve texture-geometry alignment. Furthermore, we extract physically-based rendering (PBR) attributes from the generated views to produce PBR meshes suitable for real-world rendering applications. MVPainter achieves state-of-the-art results across all three dimensions, as demonstrated by human-aligned evaluations. To facilitate further research and reproducibility, we also release our full pipeline as an open-source system, including data construction, model architecture, and evaluation tools.","authors":["Mingqi Shao","Feng Xiong","Zhaoxu Sun","Mu Xu"],"url":"https://arxiv.org/abs/2505.12635"}
{"created":"2025-05-20","title":"Revealing the Deceptiveness of Knowledge Editing: A Mechanistic Analysis of Superficial Editing","abstract":"Knowledge editing, which aims to update the knowledge encoded in language models, can be deceptive. Despite the fact that many existing knowledge editing algorithms achieve near-perfect performance on conventional metrics, the models edited by them are still prone to generating original knowledge. This paper introduces the concept of \"superficial editing\" to describe this phenomenon. Our comprehensive evaluation reveals that this issue presents a significant challenge to existing algorithms. Through systematic investigation, we identify and validate two key factors contributing to this issue: (1) the residual stream at the last subject position in earlier layers and (2) specific attention modules in later layers. Notably, certain attention heads in later layers, along with specific left singular vectors in their output matrices, encapsulate the original knowledge and exhibit a causal relationship with superficial editing. Furthermore, we extend our analysis to the task of superficial unlearning, where we observe consistent patterns in the behavior of specific attention heads and their corresponding left singular vectors, thereby demonstrating the robustness and broader applicability of our methodology and conclusions. Our code is available here.","authors":["Jiakuan Xie","Pengfei Cao","Yubo Chen","Kang Liu","Jun Zhao"],"url":"https://arxiv.org/abs/2505.12636"}
{"created":"2025-05-20","title":"GDPRShield: AI-Powered GDPR Support for Software Developers in Small and Medium-Sized Enterprises","abstract":"With the rapid increase in privacy violations in modern software development, regulatory frameworks such as the General Data Protection Regulation (GDPR) have been established to enforce strict data protection practices. However, insufficient privacy awareness among SME software developers contributes to failure in GDPR compliance. For instance, a developer unfamiliar with data minimization may build a system that collects excessive data, violating GDPR and risking fines. One reason for this lack of awareness is that developers in SMEs often take on multidisciplinary roles (e.g., front-end, back-end, database management, and privacy compliance), which limits specialization in privacy. This lack of awareness may lead to poor privacy attitudes, ultimately hindering the development of a strong organizational privacy culture. However, SMEs that achieve GDPR compliance may gain competitive advantages, such as increased user trust and marketing value, compared to others that do not.","authors":["Tharaka Wijesundara","Mathew Warren","Nalin Arachchilage"],"url":"https://arxiv.org/abs/2505.12640"}
{"created":"2025-05-20","title":"Single Image Reflection Removal via inter-layer Complementarity","abstract":"Although dual-stream architectures have achieved remarkable success in single image reflection removal, they fail to fully exploit inter-layer complementarity in their physical modeling and network design, which limits the quality of image separation. To address this fundamental limitation, we propose two targeted improvements to enhance dual-stream architectures: First, we introduce a novel inter-layer complementarity model where low-frequency components extracted from the residual layer interact with the transmission layer through dual-stream architecture to enhance inter-layer complementarity. Meanwhile, high-frequency components from the residual layer provide inverse modulation to both streams, improving the detail quality of the transmission layer. Second, we propose an efficient inter-layer complementarity attention mechanism which first cross-reorganizes dual streams at the channel level to obtain reorganized streams with inter-layer complementary structures, then performs attention computation on the reorganized streams to achieve better inter-layer separation, and finally restores the original stream structure for output. Experimental results demonstrate that our method achieves state-of-the-art separation quality on multiple public datasets while significantly reducing both computational cost and model complexity.","authors":["Yue Huang","Zi'ang Li","Tianle Hu","Jie Wen","Guanbin Li","Jinglin Zhang","Guoxu Zhou","Xiaozhao Fang"],"url":"https://arxiv.org/abs/2505.12641"}
{"created":"2025-05-20","title":"Two out of Three (ToT): using self-consistency to make robust predictions","abstract":"Deep learning (DL) can automatically construct intelligent agents, deep neural networks (alternatively, DL models), that can outperform humans in certain tasks. However, the operating principles of DL remain poorly understood, making its decisions incomprehensible. As a result, it poses a great risk to deploy DL in high-stakes domains in which mistakes or errors may lead to critical consequences. Here, we aim to develop an algorithm that can help DL models make more robust decisions by allowing them to abstain from answering when they are uncertain. Our algorithm, named `Two out of Three (ToT)', is inspired by the sensitivity of the human brain to conflicting information. ToT creates two alternative predictions in addition to the original model prediction and uses the alternative predictions to decide whether it should provide an answer or not.","authors":["Jung Hoon Lee","Sujith Vijayan"],"url":"https://arxiv.org/abs/2505.12642"}
{"created":"2025-05-20","title":"Use as Many Surrogates as You Want: Selective Ensemble Attack to Unleash Transferability without Sacrificing Resource Efficiency","abstract":"In surrogate ensemble attacks, using more surrogate models yields higher transferability but lower resource efficiency. This practical trade-off between transferability and efficiency has largely limited existing attacks despite many pre-trained models are easily accessible online. In this paper, we argue that such a trade-off is caused by an unnecessary common assumption, i.e., all models should be identical across iterations. By lifting this assumption, we can use as many surrogates as we want to unleash transferability without sacrificing efficiency. Concretely, we propose Selective Ensemble Attack (SEA), which dynamically selects diverse models (from easily accessible pre-trained models) across iterations based on our new interpretation of decoupling within-iteration and cross-iteration model diversity.In this way, the number of within-iteration models is fixed for maintaining efficiency, while only cross-iteration model diversity is increased for higher transferability. Experiments on ImageNet demonstrate the superiority of SEA in various scenarios. For example, when dynamically selecting 4 from 20 accessible models, SEA yields 8.5% higher transferability than existing attacks under the same efficiency. The superiority of SEA also generalizes to real-world systems, such as commercial vision APIs and large vision-language models. Overall, SEA opens up the possibility of adaptively balancing transferability and efficiency according to specific resource requirements.","authors":["Bo Yang","Hengwei Zhang","Jindong Wang","Yuchen Ren","Chenhao Lin","Chao Shen","Zhengyu Zhao"],"url":"https://arxiv.org/abs/2505.12644"}
{"created":"2025-05-20","title":"Implicit differentiation with second-order derivatives and benchmarks in finite-element-based differentiable physics","abstract":"Differentiable programming is revolutionizing computational science by enabling automatic differentiation (AD) of numerical simulations. While first-order gradients are well-established, second-order derivatives (Hessians) for implicit functions in finite-element-based differentiable physics remain underexplored. This work bridges this gap by deriving and implementing a framework for implicit Hessian computation in PDE-constrained optimization problems. We leverage primitive AD tools (Jacobian-vector product/vector-Jacobian product) to build an algorithm for Hessian-vector products and validate the accuracy against finite difference approximations. Four benchmarks spanning linear/nonlinear, 2D/3D, and single/coupled-variable problems demonstrate the utility of second-order information. Results show that the Newton-CG method with exact Hessians accelerates convergence for nonlinear inverse problems (e.g., traction force identification, shape optimization), while the L-BFGS-B method suffices for linear cases. Our work provides a robust foundation for integrating second-order implicit differentiation into differentiable physics engines, enabling faster and more reliable optimization.","authors":["Tianju Xue"],"url":"https://arxiv.org/abs/2505.12646"}
{"created":"2025-05-20","title":"Spiking Neural Network: a low power solution for physical layer authentication","abstract":"Deep learning (DL) is a powerful tool that can solve complex problems, and thus, it seems natural to assume that DL can be used to enhance the security of wireless communication. However, deploying DL models to edge devices in wireless networks is challenging, as they require significant amounts of computing and power resources. Notably, Spiking Neural Networks (SNNs) are known to be efficient in terms of power consumption, meaning they can be an alternative platform for DL models for edge devices. In this study, we ask if SNNs can be used in physical layer authentication. Our evaluation suggests that SNNs can learn unique physical properties (i.e., `fingerprints') of RF transmitters and use them to identify individual devices. Furthermore, we find that SNNs are also vulnerable to adversarial attacks and that an autoencoder can be used clean out adversarial perturbations to harden SNNs against them.","authors":["Jung Hoon Lee","Sujith Vijayan"],"url":"https://arxiv.org/abs/2505.12647"}
{"created":"2025-05-20","title":"SafeMove-RL: A Certifiable Reinforcement Learning Framework for Dynamic Motion Constraints in Trajectory Planning","abstract":"This study presents a dynamic safety margin-based reinforcement learning framework for local motion planning in dynamic and uncertain environments. The proposed planner integrates real-time trajectory optimization with adaptive gap analysis, enabling effective feasibility assessment under partial observability constraints. To address safety-critical computations in unknown scenarios, an enhanced online learning mechanism is introduced, which dynamically corrects spatial trajectories by forming dynamic safety margins while maintaining control invariance. Extensive evaluations, including ablation studies and comparisons with state-of-the-art algorithms, demonstrate superior success rates and computational efficiency. The framework's effectiveness is further validated on both simulated and physical robotic platforms.","authors":["Tengfei Liu","Haoyang Zhong","Jiazheng Hu","Tan Zhang"],"url":"https://arxiv.org/abs/2505.12648"}
{"created":"2025-05-20","title":"The Robot of Theseus: A modular robotic testbed for legged locomotion","abstract":"Robotic models are useful for independently varying specific features, but most quadrupedal robots differ so greatly from animal morphologies that they have minimal biomechanical relevance. Commercially available quadrupedal robots are also prohibitively expensive for biological research programs and difficult to customize. Here, we present a low-cost quadrupedal robot with modular legs that can match a wide range of animal morphologies for biomechanical hypothesis testing. The Robot Of Theseus (TROT) costs approximately $4000 to build out of 3D printed parts and standard off-the-shelf supplies. Each limb consists of 2 or 3 rigid links; the proximal joint can be rotated to become a knee or elbow. Telescoping mechanisms vary the length of each limb link. The open-source software accommodates user-defined gaits and morphology changes. Effective leg length, or crouch, is determined by the four-bar linkage actuating each joint. The backdrivable motors can vary virtual spring stiffness and range of motion. Full descriptions of the TROT hardware and software are freely available online. We demonstrate the use of TROT to compare locomotion among extant, extinct, and theoretical morphologies. In addition to biomechanical hypothesis testing, we envision a variety of different applications for this low-cost, modular, legged robotic platform, including developing novel control strategies, clearing land mines, or remote exploration. All CAD and code is available for download on the TROT project page.","authors":["Karthik Urs","Jessica Carlson","Aditya Srinivas Manohar","Michael Rakowiecki","Abdulhadi Alkayyali","John E. Saunders","Faris Tulbah","Talia Y. Moore"],"url":"https://arxiv.org/abs/2505.12649"}
{"created":"2025-05-20","title":"AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use","abstract":"Machine learning-based interatomic potentials and force fields depend critically on accurate atomic structures, yet such data are scarce due to the limited availability of experimentally resolved crystals. Although atomic-resolution electron microscopy offers a potential source of structural data, converting these images into simulation-ready formats remains labor-intensive and error-prone, creating a bottleneck for model training and validation. We introduce AutoMat, an end-to-end, agent-assisted pipeline that automatically transforms scanning transmission electron microscopy (STEM) images into atomic crystal structures and predicts their physical properties. AutoMat combines pattern-adaptive denoising, physics-guided template retrieval, symmetry-aware atomic reconstruction, fast relaxation and property prediction via MatterSim, and coordinated orchestration across all stages. We propose the first dedicated STEM2Mat-Bench for this task and evaluate performance using lattice RMSD, formation energy MAE, and structure-matching success rate. By orchestrating external tool calls, AutoMat enables a text-only LLM to outperform vision-language models in this domain, achieving closed-loop reasoning throughout the pipeline. In large-scale experiments over 450 structure samples, AutoMat substantially outperforms existing multimodal large language models and tools. These results validate both AutoMat and STEM2Mat-Bench, marking a key step toward bridging microscopy and atomistic simulation in materials science.The code and dataset are publicly available at https://github.com/yyt-2378/AutoMat and https://huggingface.co/datasets/yaotianvector/STEM2Mat.","authors":["Yaotian Yang","Yiwen Tang","Yizhe Chen","Xiao Chen","Jiangjie Qiu","Hao Xiong","Haoyu Yin","Zhiyao Luo","Yifei Zhang","Sijia Tao","Wentao Li","Qinghua Zhang","Yuqiang Li","Wanli Ouyang","Bin Zhao","Xiaonan Wang","Fei Wei"],"url":"https://arxiv.org/abs/2505.12650"}
{"created":"2025-05-20","title":"$\\texttt{DIAMONDs}$: A Dataset for $\\mathbb{D}$ynamic $\\mathbb{I}$nformation $\\mathbb{A}$nd $\\mathbb{M}$ental modeling $\\mathbb{O}$f $\\mathbb{N}$umeric $\\mathbb{D}$iscussions","abstract":"Understanding multiparty conversations demands robust Theory of Mind (ToM) capabilities, including the ability to track dynamic information, manage knowledge asymmetries, and distinguish relevant information across extended exchanges. To advance ToM evaluation in such settings, we present a carefully designed scalable methodology for generating high-quality benchmark conversation-question pairs with these characteristics. Using this methodology, we create $\\texttt{DIAMONDs}$, a new conversational QA dataset covering common business, financial or other group interactions. In these goal-oriented conversations, participants often have to track certain numerical quantities (say $\\textit{expected profit}$) of interest that can be derived from other variable quantities (like $\\textit{marketing expenses, expected sales, salary}$, etc.), whose values also change over the course of the conversation. $\\texttt{DIAMONDs}$ questions pose simple numerical reasoning problems over such quantities of interest (e.g., $\\textit{funds required for charity events, expected company profit next quarter}$, etc.) in the context of the information exchanged in conversations. This allows for precisely evaluating ToM capabilities for carefully tracking and reasoning over participants' knowledge states.","authors":["Sayontan Ghosh","Mahnaz Koupaee","Yash Kumar Lal","Pegah Alipoormolabashi","Mohammad Saqib Hasan","Jun Seok Kang","Niranjan Balasubramanian"],"url":"https://arxiv.org/abs/2505.12651"}
{"created":"2025-05-20","title":"Predicting Turn-Taking and Backchannel in Human-Machine Conversations Using Linguistic, Acoustic, and Visual Signals","abstract":"This paper addresses the gap in predicting turn-taking and backchannel actions in human-machine conversations using multi-modal signals (linguistic, acoustic, and visual). To overcome the limitation of existing datasets, we propose an automatic data collection pipeline that allows us to collect and annotate over 210 hours of human conversation videos. From this, we construct a Multi-Modal Face-to-Face (MM-F2F) human conversation dataset, including over 1.5M words and corresponding turn-taking and backchannel annotations from approximately 20M frames. Additionally, we present an end-to-end framework that predicts the probability of turn-taking and backchannel actions from multi-modal signals. The proposed model emphasizes the interrelation between modalities and supports any combination of text, audio, and video inputs, making it adaptable to a variety of realistic scenarios. Our experiments show that our approach achieves state-of-the-art performance on turn-taking and backchannel prediction tasks, achieving a 10\\% increase in F1-score on turn-taking and a 33\\% increase on backchannel prediction. Our dataset and code are publicly available online to ease of subsequent research.","authors":["Yuxin Lin","Yinglin Zheng","Ming Zeng","Wangzheng Shi"],"url":"https://arxiv.org/abs/2505.12654"}
{"created":"2025-05-20","title":"Web IP at Risk: Prevent Unauthorized Real-Time Retrieval by Large Language Models","abstract":"Protecting cyber Intellectual Property (IP) such as web content is an increasingly critical concern. The rise of large language models (LLMs) with online retrieval capabilities presents a double-edged sword that enables convenient access to information but often undermines the rights of original content creators. As users increasingly rely on LLM-generated responses, they gradually diminish direct engagement with original information sources, significantly reducing the incentives for IP creators to contribute, and leading to a saturating cyberspace with more AI-generated content. In response, we propose a novel defense framework that empowers web content creators to safeguard their web-based IP from unauthorized LLM real-time extraction by leveraging the semantic understanding capability of LLMs themselves. Our method follows principled motivations and effectively addresses an intractable black-box optimization problem. Real-world experiments demonstrated that our methods improve defense success rates from 2.5% to 88.6% on different LLMs, outperforming traditional defenses such as configuration-based restrictions.","authors":["Yisheng Zhong","Yizhu Wen","Junfeng Guo","Mehran Kafai","Heng Huang","Hanqing Guo","Zhuangdi Zhu"],"url":"https://arxiv.org/abs/2505.12655"}
{"created":"2025-05-20","title":"SPKLIP: Aligning Spike Video Streams with Natural Language","abstract":"Spike cameras offer unique sensing capabilities but their sparse, asynchronous output challenges semantic understanding, especially for Spike Video-Language Alignment (Spike-VLA) where models like CLIP underperform due to modality mismatch. We introduce SPKLIP, the first architecture specifically for Spike-VLA. SPKLIP employs a hierarchical spike feature extractor that adaptively models multi-scale temporal dynamics in event streams, and uses spike-text contrastive learning to directly align spike video with language, enabling effective few-shot learning. A full-spiking visual encoder variant, integrating SNN components into our pipeline, demonstrates enhanced energy efficiency. Experiments show state-of-the-art performance on benchmark spike datasets and strong few-shot generalization on a newly contributed real-world dataset. SPKLIP's energy efficiency highlights its potential for neuromorphic deployment, advancing event-based multimodal research. The source code and dataset are available at [link removed for anonymity].","authors":["Yongchang Gao","Meiling Jin","Zhaofei Yu","Tiejun Huang","Guozhang Chen"],"url":"https://arxiv.org/abs/2505.12656"}
{"created":"2025-05-20","title":"Transmission Neural Networks: Approximation and Optimal Control","abstract":"Transmission Neural Networks (TransNNs) introduced by Gao and Caines (2022) connect virus spread models over networks and neural networks with tuneable activation functions. This paper presents the approximation technique and the underlying assumptions employed by TransNNs in relation to the corresponding Markovian Susceptible-Infected-Susceptible (SIS) model with 2^n states, where n is the number of nodes in the network. The underlying infection paths are assumed to be stochastic with heterogeneous and time-varying transmission probabilities. We obtain the conditional probability of infection in the stochastic 2^n-state SIS epidemic model corresponding to each state configuration under mild assumptions, which enables control solutions based on Markov decision processes (MDP). Finally, MDP control with 2^n-state SIS epidemic models and optimal control with TransNNs are compared in terms of mitigating virus spread over networks through vaccination, and it is shown that TranNNs enable the generation of control laws with significant computational savings, albeit with more conservative control actions.","authors":["Shuang Gao","Peter E. Caines"],"url":"https://arxiv.org/abs/2505.12657"}
{"created":"2025-05-20","title":"HydraInfer: Hybrid Disaggregated Scheduling for Multimodal Large Language Model Serving","abstract":"Multimodal Large Language Models (MLLMs) have been rapidly advancing, enabling cross-modal understanding and generation, and propelling artificial intelligence towards artificial general intelligence. However, existing MLLM inference systems are typically designed based on the architecture of language models, integrating image processing and language processing as a single scheduling unit. This design struggles to accommodate the heterogeneous demands of different stages in terms of computational resources, memory access patterns, and service-level objectives (SLOs), leading to low resource utilization and high request latency, ultimately failing to meet the service requirements of diverse inference scenarios.","authors":["Xianzhe Dong","Tongxuan Liu","Yuting Zeng","Liangyu Liu","Yang Liu","Siyu Wu","Yu Wu","Hailong Yang","Ke Zhang","Jing Li"],"url":"https://arxiv.org/abs/2505.12658"}
{"created":"2025-05-20","title":"Predicting Reaction Time to Comprehend Scenes with Foveated Scene Understanding Maps","abstract":"Although models exist that predict human response times (RTs) in tasks such as target search and visual discrimination, the development of image-computable predictors for scene understanding time remains an open challenge. Recent advances in vision-language models (VLMs), which can generate scene descriptions for arbitrary images, combined with the availability of quantitative metrics for comparing linguistic descriptions, offer a new opportunity to model human scene understanding. We hypothesize that the primary bottleneck in human scene understanding and the driving source of variability in response times across scenes is the interaction between the foveated nature of the human visual system and the spatial distribution of task-relevant visual information within an image. Based on this assumption, we propose a novel image-computable model that integrates foveated vision with VLMs to produce a spatially resolved map of scene understanding as a function of fixation location (Foveated Scene Understanding Map, or F-SUM), along with an aggregate F-SUM score. This metric correlates with average (N=17) human RTs (r=0.47) and number of saccades (r=0.51) required to comprehend a scene (across 277 scenes). The F-SUM score also correlates with average (N=16) human description accuracy (r=-0.56) in time-limited presentations. These correlations significantly exceed those of standard image-based metrics such as clutter, visual complexity, and scene ambiguity based on language entropy. Together, our work introduces a new image-computable metric for predicting human response times in scene understanding and demonstrates the importance of foveated visual processing in shaping comprehension difficulty.","authors":["Ziqi Wen","Jonathan Skaza","Shravan Murlidaran","William Y. Wang","Miguel P. Eckstein"],"url":"https://arxiv.org/abs/2505.12660"}
{"created":"2025-05-20","title":"Digital Twins in the Cloud: A Modular, Scalable and Interoperable Framework for Accelerating Verification and Validation of Autonomous Driving Solutions","abstract":"Verification and validation (V&amp;V) of autonomous vehicles (AVs) typically requires exhaustive testing across a variety of operating environments and driving scenarios including rare, extreme, or hazardous situations that might be difficult or impossible to capture in reality. Additionally, physical V&amp;V methods such as track-based evaluations or public-road testing are often constrained by time, cost, and safety, which motivates the need for virtual proving grounds. However, the fidelity and scalability of simulation-based V&amp;V methods can quickly turn into a bottleneck. In such a milieu, this work proposes a virtual proving ground that flexibly scales digital twins within high-performance computing clusters (HPCCs) and automates the V&amp;V process. Here, digital twins enable high-fidelity virtual representation of the AV and its operating environments, allowing extensive scenario-based testing. Meanwhile, HPCC infrastructure brings substantial advantages in terms of computational power and scalability, enabling rapid iterations of simulations, processing and storage of massive amounts of data, and deployment of large-scale test campaigns, thereby reducing the time and cost associated with the V&amp;V process. We demonstrate the efficacy of this approach through a case study that focuses on the variability analysis of a candidate autonomy algorithm to identify potential vulnerabilities in its perception, planning, and control sub-systems. The modularity, scalability, and interoperability of the proposed framework are demonstrated by deploying a test campaign comprising 256 test cases on two different HPCC architectures to ensure continuous operation in a publicly shared resource setting. The findings highlight the ability of the proposed framework to accelerate and streamline the V&amp;V process, thereby significantly compressing (~30x) the timeline.","authors":["Tanmay Vilas Samak","Chinmay Vilas Samak","Giovanni Martino","Pranav Nair","Venkat Krovi"],"url":"https://arxiv.org/abs/2505.12661"}
{"created":"2025-05-20","title":"Know3-RAG: A Knowledge-aware RAG Framework with Adaptive Retrieval, Generation, and Filtering","abstract":"Recent advances in large language models (LLMs) have led to impressive progress in natural language generation, yet their tendency to produce hallucinated or unsubstantiated content remains a critical concern. To improve factual reliability, Retrieval-Augmented Generation (RAG) integrates external knowledge during inference. However, existing RAG systems face two major limitations: (1) unreliable adaptive control due to limited external knowledge supervision, and (2) hallucinations caused by inaccurate or irrelevant references. To address these issues, we propose Know3-RAG, a knowledge-aware RAG framework that leverages structured knowledge from knowledge graphs (KGs) to guide three core stages of the RAG process, including retrieval, generation, and filtering. Specifically, we introduce a knowledge-aware adaptive retrieval module that employs KG embedding to assess the confidence of the generated answer and determine retrieval necessity, a knowledge-enhanced reference generation strategy that enriches queries with KG-derived entities to improve generated reference relevance, and a knowledge-driven reference filtering mechanism that ensures semantic alignment and factual accuracy of references. Experiments on multiple open-domain QA benchmarks demonstrate that Know3-RAG consistently outperforms strong baselines, significantly reducing hallucinations and enhancing answer reliability.","authors":["Xukai Liu","Ye Liu","Shiwen Wu","Yanghai Zhang","Yihao Yuan","Kai Zhang","Qi Liu"],"url":"https://arxiv.org/abs/2505.12662"}
{"created":"2025-05-20","title":"MTGRBoost: Boosting Large-scale Generative Recommendation Models in Meituan","abstract":"Recommendation is crucial for both user experience and company revenue, and generative recommendation models (GRMs) are shown to produce quality recommendations recently. However, existing systems are limited by insufficient functionality support and inefficient implementations for training GRMs in industrial scenarios. As such, we introduce MTGRBoost as an efficient and scalable system for GRM training. Specifically, to handle the real-time insert/delete of sparse embedding entries, MTGRBoost employs dynamic hash tables to replace static tables. To improve efficiency, MTGRBoost conducts dynamic sequence balancing to address the computation load imbalances among GPUs and adopts embedding ID deduplication alongside automatic table merging to accelerate embedding lookup. MTGRBoost also incorporates implementation optimizations including checkpoint resuming, mixed precision training, gradient accumulation, and operator fusion. Extensive experiments show that MTGRBoost improves training throughput by $1.6 \\times$ -- $2.4\\times$ while achieving good scalability when running over 100 GPUs. MTGRBoost has been deployed for many applications in Meituan and is now handling hundreds of millions of requests on a daily basis.","authors":["Yuxiang Wang","Xiao Yan","Chi Ma","Mincong Huang","Xiaoguang Li","Lei Yu","Chuan Liu","Ruidong Han","He Jiang","Bin Yin","Shangyu Chen","Fei Jiang","Xiang Li","Wei Lin","Haowei Han","Bo Du","Jiawei Jiang"],"url":"https://arxiv.org/abs/2505.12663"}
{"created":"2025-05-20","title":"Audio-Visual Contact Classification for Tree Structures in Agriculture","abstract":"Contact-rich manipulation tasks in agriculture, such as pruning and harvesting, require robots to physically interact with tree structures to maneuver through cluttered foliage. Identifying whether the robot is contacting rigid or soft materials is critical for the downstream manipulation policy to be safe, yet vision alone is often insufficient due to occlusion and limited viewpoints in this unstructured environment. To address this, we propose a multi-modal classification framework that fuses vibrotactile (audio) and visual inputs to identify the contact class: leaf, twig, trunk, or ambient. Our key insight is that contact-induced vibrations carry material-specific signals, making audio effective for detecting contact events and distinguishing material types, while visual features add complementary semantic cues that support more fine-grained classification. We collect training data using a hand-held sensor probe and demonstrate zero-shot generalization to a robot-mounted probe embodiment, achieving an F1 score of 0.82. These results underscore the potential of audio-visual learning for manipulation in unstructured, contact-rich environments.","authors":["Ryan Spears","Moonyoung Lee","George Kantor","Oliver Kroemer"],"url":"https://arxiv.org/abs/2505.12665"}
{"created":"2025-05-20","title":"Adapting to LLMs: How Insiders and Outsiders Reshape Scientific Knowledge Production","abstract":"CSCW has long examined how emerging technologies reshape the ways researchers collaborate and produce knowledge, with scientific knowledge production as a central area of focus. As AI becomes increasingly integrated into scientific research, understanding how researchers adapt to it reveals timely opportunities for CSCW research -- particularly in supporting new forms of collaboration, knowledge practices, and infrastructure in AI-driven science.","authors":["Huimin Xu","Houjiang Liu","Yan Leng","Ying Ding"],"url":"https://arxiv.org/abs/2505.12666"}
{"created":"2025-05-20","title":"Safe-Sora: Safe Text-to-Video Generation via Graphical Watermarking","abstract":"The explosive growth of generative video models has amplified the demand for reliable copyright preservation of AI-generated content. Despite its popularity in image synthesis, invisible generative watermarking remains largely underexplored in video generation. To address this gap, we propose Safe-Sora, the first framework to embed graphical watermarks directly into the video generation process. Motivated by the observation that watermarking performance is closely tied to the visual similarity between the watermark and cover content, we introduce a hierarchical coarse-to-fine adaptive matching mechanism. Specifically, the watermark image is divided into patches, each assigned to the most visually similar video frame, and further localized to the optimal spatial region for seamless embedding. To enable spatiotemporal fusion of watermark patches across video frames, we develop a 3D wavelet transform-enhanced Mamba architecture with a novel spatiotemporal local scanning strategy, effectively modeling long-range dependencies during watermark embedding and retrieval. To the best of our knowledge, this is the first attempt to apply state space models to watermarking, opening new avenues for efficient and robust watermark protection. Extensive experiments demonstrate that Safe-Sora achieves state-of-the-art performance in terms of video quality, watermark fidelity, and robustness, which is largely attributed to our proposals. We will release our code upon publication.","authors":["Zihan Su","Xuerui Qiu","Hongbin Xu","Tangyu Jiang","Junhao Zhuang","Chun Yuan","Ming Li","Shengfeng He","Fei Richard Yu"],"url":"https://arxiv.org/abs/2505.12667"}
{"created":"2025-05-20","title":"Decompile-Bench: Million-Scale Binary-Source Function Pairs for Real-World Binary Decompilation","abstract":"Recent advances in LLM-based decompilers have been shown effective to convert low-level binaries into human-readable source code. However, there still lacks a comprehensive benchmark that provides large-scale binary-source function pairs, which is critical for advancing the LLM decompilation technology. Creating accurate binary-source mappings incurs severe issues caused by complex compilation settings and widespread function inlining that obscure the correspondence between binaries and their original source code. Previous efforts have either relied on used contest-style benchmarks, synthetic binary-source mappings that diverge significantly from the mappings in real world, or partially matched binaries with only code lines or variable names, compromising the effectiveness of analyzing the binary functionality. To alleviate these issues, we introduce Decompile-Bench, the first open-source dataset comprising two million binary-source function pairs condensed from 100 million collected function pairs, i.e., 450GB of binaries compiled from permissively licensed GitHub projects. For the evaluation purposes, we also developed a benchmark Decompile-Bench-Eval including manually crafted binaries from the well-established HumanEval and MBPP, alongside the compiled GitHub repositories released after 2025 to mitigate data leakage issues. We further explore commonly-used evaluation metrics to provide a thorough assessment of the studied LLM decompilers and find that fine-tuning with Decompile-Bench causes a 20% improvement over previous benchmarks in terms of the re-executability rate. Our code and data has been released in HuggingFace and Github. https://github.com/albertan017/LLM4Decompile","authors":["Hanzhuo Tan","Xiaolong Tian","Hanrui Qi","Jiaming Liu","Zuchen Gao","Siyi Wang","Qi Luo","Jing Li","Yuqun Zhang"],"url":"https://arxiv.org/abs/2505.12668"}
{"created":"2025-05-20","title":"Text2midi-InferAlign: Improving Symbolic Music Generation with Inference-Time Alignment","abstract":"We present Text2midi-InferAlign, a novel technique for improving symbolic music generation at inference time. Our method leverages text-to-audio alignment and music structural alignment rewards during inference to encourage the generated music to be consistent with the input caption. Specifically, we introduce two objectives scores: a text-audio consistency score that measures rhythmic alignment between the generated music and the original text caption, and a harmonic consistency score that penalizes generated music containing notes inconsistent with the key. By optimizing these alignment-based objectives during the generation process, our model produces symbolic music that is more closely tied to the input captions, thereby improving the overall quality and coherence of the generated compositions. Our approach can extend any existing autoregressive model without requiring further training or fine-tuning. We evaluate our work on top of Text2midi - an existing text-to-midi generation model, demonstrating significant improvements in both objective and subjective evaluation metrics.","authors":["Abhinaba Roy","Geeta Puri","Dorien Herremans"],"url":"https://arxiv.org/abs/2505.12669"}
{"created":"2025-05-20","title":"TS-VLM: Text-Guided SoftSort Pooling for Vision-Language Models in Multi-View Driving Reasoning","abstract":"Vision-Language Models (VLMs) have shown remarkable potential in advancing autonomous driving by leveraging multi-modal fusion in order to enhance scene perception, reasoning, and decision-making. Despite their potential, existing models suffer from computational overhead and inefficient integration of multi-view sensor data that make them impractical for real-time deployment in safety-critical autonomous driving applications. To address these shortcomings, this paper is devoted to designing a lightweight VLM called TS-VLM, which incorporates a novel Text-Guided SoftSort Pooling (TGSSP) module. By resorting to semantics of the input queries, TGSSP ranks and fuses visual features from multiple views, enabling dynamic and query-aware multi-view aggregation without reliance on costly attention mechanisms. This design ensures the query-adaptive prioritization of semantically related views, which leads to improved contextual accuracy in multi-view reasoning for autonomous driving. Extensive evaluations on the DriveLM benchmark demonstrate that, on the one hand, TS-VLM outperforms state-of-the-art models with a BLEU-4 score of 56.82, METEOR of 41.91, ROUGE-L of 74.64, and CIDEr of 3.39. On the other hand, TS-VLM reduces computational cost by up to 90%, where the smallest version contains only 20.1 million parameters, making it more practical for real-time deployment in autonomous vehicles.","authors":["Lihong Chen","Hossein Hassani","Soodeh Nikan"],"url":"https://arxiv.org/abs/2505.12670"}
{"created":"2025-05-20","title":"TransferTraj: A Vehicle Trajectory Learning Model for Region and Task Transferability","abstract":"Vehicle GPS trajectories provide valuable movement information that supports various downstream tasks and applications. A desirable trajectory learning model should be able to transfer across regions and tasks without retraining, avoiding the need to maintain multiple specialized models and subpar performance with limited training data. However, each region has its unique spatial features and contexts, which are reflected in vehicle movement patterns and difficult to generalize. Additionally, transferring across different tasks faces technical challenges due to the varying input-output structures required for each task. Existing efforts towards transferability primarily involve learning embedding vectors for trajectories, which perform poorly in region transfer and require retraining of prediction modules for task transfer.","authors":["Tonglong Wei","Yan Lin","Zeyu Zhou","Haomin Wen","Jilin Hu","Shengnan Guo","Youfang Lin","Gao Cong","Huaiyu Wan"],"url":"https://arxiv.org/abs/2505.12672"}
{"created":"2025-05-20","title":"Few-Step Diffusion via Score identity Distillation","abstract":"Diffusion distillation has emerged as a promising strategy for accelerating text-to-image (T2I) diffusion models by distilling a pretrained score network into a one- or few-step generator. While existing methods have made notable progress, they often rely on real or teacher-synthesized images to perform well when distilling high-resolution T2I diffusion models such as Stable Diffusion XL (SDXL), and their use of classifier-free guidance (CFG) introduces a persistent trade-off between text-image alignment and generation diversity. We address these challenges by optimizing Score identity Distillation (SiD) -- a data-free, one-step distillation framework -- for few-step generation. Backed by theoretical analysis that justifies matching a uniform mixture of outputs from all generation steps to the data distribution, our few-step distillation algorithm avoids step-specific networks and integrates seamlessly into existing pipelines, achieving state-of-the-art performance on SDXL at 1024x1024 resolution. To mitigate the alignment-diversity trade-off when real text-image pairs are available, we introduce a Diffusion GAN-based adversarial loss applied to the uniform mixture and propose two new guidance strategies: Zero-CFG, which disables CFG in the teacher and removes text conditioning in the fake score network, and Anti-CFG, which applies negative CFG in the fake score network. This flexible setup improves diversity without sacrificing alignment. Comprehensive experiments on SD1.5 and SDXL demonstrate state-of-the-art performance in both one-step and few-step generation settings, along with robustness to the absence of real images. Our efficient PyTorch implementation, along with the resulting one- and few-step distilled generators, will be released publicly as a separate branch at https://github.com/mingyuanzhou/SiD-LSG.","authors":["Mingyuan Zhou","Yi Gu","Zhendong Wang"],"url":"https://arxiv.org/abs/2505.12674"}
{"created":"2025-05-20","title":"Understanding and Detecting Peer Dependency Resolving Loop in npm Ecosystem","abstract":"As the default package manager for Node.js, npm has become one of the largest package management systems in the world. To facilitate dependency management for developers, npm supports a special type of dependency, Peer Dependency, whose installation and usage differ from regular dependencies. However, conflicts between peer dependencies can trap the npm client into infinite loops, leading to resource exhaustion and system crashes. We name this problem PeerSpin. Although PeerSpin poses a severe risk to ecosystems, it was overlooked by previous studies, and its impacts have not been explored.","authors":["Xingyu Wang","Mingsen Wang","Wenbo Shen","Rui Chang"],"url":"https://arxiv.org/abs/2505.12676"}
{"created":"2025-05-20","title":"CURE: Concept Unlearning via Orthogonal Representation Editing in Diffusion Models","abstract":"As Text-to-Image models continue to evolve, so does the risk of generating unsafe, copyrighted, or privacy-violating content. Existing safety interventions - ranging from training data curation and model fine-tuning to inference-time filtering and guidance - often suffer from incomplete concept removal, susceptibility to jail-breaking, computational inefficiency, or collateral damage to unrelated capabilities. In this paper, we introduce CURE, a training-free concept unlearning framework that operates directly in the weight space of pre-trained diffusion models, enabling fast, interpretable, and highly specific suppression of undesired concepts. At the core of our method is the Spectral Eraser, a closed-form, orthogonal projection module that identifies discriminative subspaces using Singular Value Decomposition over token embeddings associated with the concepts to forget and retain. Intuitively, the Spectral Eraser identifies and isolates features unique to the undesired concept while preserving safe attributes. This operator is then applied in a single step update to yield an edited model in which the target concept is effectively unlearned - without retraining, supervision, or iterative optimization. To balance the trade-off between filtering toxicity and preserving unrelated concepts, we further introduce an Expansion Mechanism for spectral regularization which selectively modulates singular vectors based on their relative significance to control the strength of forgetting. All the processes above are in closed-form, guaranteeing extremely efficient erasure in only $2$ seconds. Benchmarking against prior approaches, CURE achieves a more efficient and thorough removal for targeted artistic styles, objects, identities, or explicit content, with minor damage to original generation ability and demonstrates enhanced robustness against red-teaming.","authors":["Shristi Das Biswas","Arani Roy","Kaushik Roy"],"url":"https://arxiv.org/abs/2505.12677"}
{"created":"2025-05-20","title":"Dribble Master: Learning Agile Humanoid Dribbling Through Legged Locomotion","abstract":"Humanoid soccer dribbling is a highly challenging task that demands dexterous ball manipulation while maintaining dynamic balance. Traditional rule-based methods often struggle to achieve accurate ball control due to their reliance on fixed walking patterns and limited adaptability to real-time ball dynamics. To address these challenges, we propose a two-stage curriculum learning framework that enables a humanoid robot to acquire dribbling skills without explicit dynamics or predefined trajectories. In the first stage, the robot learns basic locomotion skills; in the second stage, we fine-tune the policy for agile dribbling maneuvers. We further introduce a virtual camera model in simulation and design heuristic rewards to encourage active sensing, promoting a broader visual range for continuous ball perception. The policy is trained in simulation and successfully transferred to a physical humanoid robot. Experimental results demonstrate that our method enables effective ball manipulation, achieving flexible and visually appealing dribbling behaviors across multiple environments. This work highlights the potential of reinforcement learning in developing agile humanoid soccer robots. Additional details, video demonstrations, and code are available at https://zhuoheng0910.github.io/dribble-master/.","authors":["Zhuoheng Wang","Jinyin Zhou","Qi Wu"],"url":"https://arxiv.org/abs/2505.12679"}
{"created":"2025-05-20","title":"Ineq-Comp: Benchmarking Human-Intuitive Compositional Reasoning in Automated Theorem Proving on Inequalities","abstract":"LLM-based formal proof assistants (e.g., in Lean) hold great promise for automating mathematical discovery. But beyond syntactic correctness, do these systems truly understand mathematical structure as humans do? We investigate this question through the lens of mathematical inequalities -- a fundamental tool across many domains. While modern provers can solve basic inequalities, we probe their ability to handle human-intuitive compositionality. We introduce Ineq-Comp, a benchmark built from elementary inequalities through systematic transformations, including variable duplication, algebraic rewriting, and multi-step composition. Although these problems remain easy for humans, we find that most provers -- including Goedel, STP, and Kimina-7B -- struggle significantly. DeepSeek-Prover-V2-7B shows relative robustness -- possibly because it is trained to decompose the problems into sub-problems -- but still suffers a 20\\% performance drop (pass@32). Strikingly, performance remains poor for all models even when formal proofs of the constituent parts are provided in context, revealing that the source of weakness is indeed in compositional reasoning. Our results expose a persisting gap between the generalization behavior of current AI provers and human mathematical intuition.","authors":["Haoyu Zhao","Yihan Geng","Shange Tang","Yong Lin","Bohan Lyu","Hongzhou Lin","Chi Jin","Sanjeev Arora"],"url":"https://arxiv.org/abs/2505.12680"}
{"created":"2025-05-20","title":"On the Mechanisms of Adversarial Data Augmentation for Robust and Adaptive Transfer Learning","abstract":"Transfer learning across domains with distribution shift remains a fundamental challenge in building robust and adaptable machine learning systems. While adversarial perturbations are traditionally viewed as threats that expose model vulnerabilities, recent studies suggest that they can also serve as constructive tools for data augmentation. In this work, we systematically investigate the role of adversarial data augmentation (ADA) in enhancing both robustness and adaptivity in transfer learning settings. We analyze how adversarial examples, when used strategically during training, improve domain generalization by enriching decision boundaries and reducing overfitting to source-domain-specific features. We further propose a unified framework that integrates ADA with consistency regularization and domain-invariant representation learning. Extensive experiments across multiple benchmark datasets -- including VisDA, DomainNet, and Office-Home -- demonstrate that our method consistently improves target-domain performance under both unsupervised and few-shot domain adaptation settings. Our results highlight a constructive perspective of adversarial learning, transforming perturbation from a destructive attack into a regularizing force for cross-domain transferability.","authors":["Hana Satou","Alan Mitkiy"],"url":"https://arxiv.org/abs/2505.12681"}
{"created":"2025-05-20","title":"RoFL: Robust Fingerprinting of Language Models","abstract":"AI developers are releasing large language models (LLMs) under a variety of different licenses. Many of these licenses restrict the ways in which the models or their outputs may be used. This raises the question how license violations may be recognized. In particular, how can we identify that an API or product uses (an adapted version of) a particular LLM? We present a new method that enable model developers to perform such identification via fingerprints: statistical patterns that are unique to the developer's model and robust to common alterations of that model. Our method permits model identification in a black-box setting using a limited number of queries, enabling identification of models that can only be accessed via an API or product. The fingerprints are non-invasive: our method does not require any changes to the model during training, hence by design, it does not impact model quality. Empirically, we find our method provides a high degree of robustness to common changes in the model or inference settings. In our experiments, it substantially outperforms prior art, including invasive methods that explicitly train watermarks into the model.","authors":["Yun-Yun Tsai","Chuan Guo","Junfeng Yang","Laurens van der Maaten"],"url":"https://arxiv.org/abs/2505.12682"}
{"created":"2025-05-20","title":"DimGrow: Memory-Efficient Field-level Embedding Dimension Search","abstract":"Key feature fields need bigger embedding dimensionality, others need smaller. This demands automated dimension allocation. Existing approaches, such as pruning or Neural Architecture Search (NAS), require training a memory-intensive SuperNet that enumerates all possible dimension combinations, which is infeasible for large feature spaces. We propose DimGrow, a lightweight approach that eliminates the SuperNet requirement. Starting training model from one dimension per feature field, DimGrow can progressively expand/shrink dimensions via importance scoring. Dimensions grow only when their importance consistently exceed a threshold, ensuring memory efficiency. Experiments on three recommendation datasets verify the effectiveness of DimGrow while it reduces training memory compared to SuperNet-based methods.","authors":["Yihong Huang","Chen Chu"],"url":"https://arxiv.org/abs/2505.12683"}
{"created":"2025-05-20","title":"Towards Effective Federated Graph Foundation Model via Mitigating Knowledge Entanglement","abstract":"Recent advances in graph machine learning have shifted to data-centric paradigms, driven by two emerging fields: (1) Federated graph learning (FGL) enables multi-client collaboration but faces challenges from data and task heterogeneity, limiting its practicality; (2) Graph foundation models (GFM) offer strong domain generalization but are usually trained on single machines, missing out on cross-silo data and resources.","authors":["Yinlin Zhu","Xunkai Li","Jishuo Jia","Miao Hu","Di Wu","Meikang Qiu"],"url":"https://arxiv.org/abs/2505.12684"}
{"created":"2025-05-20","title":"Mamba-Adaptor: State Space Model Adaptor for Visual Recognition","abstract":"Recent State Space Models (SSM), especially Mamba, have demonstrated impressive performance in visual modeling and possess superior model efficiency. However, the application of Mamba to visual tasks suffers inferior performance due to three main constraints existing in the sequential model: 1) Casual computing is incapable of accessing global context; 2) Long-range forgetting when computing the current hidden states; 3) Weak spatial structural modeling due to the transformed sequential input. To address these issues, we investigate a simple yet powerful vision task Adaptor for Mamba models, which consists of two functional modules: Adaptor-T and Adaptor-S. When solving the hidden states for SSM, we apply a lightweight prediction module Adaptor-T to select a set of learnable locations as memory augmentations to ease long-range forgetting issues. Moreover, we leverage Adapator-S, composed of multi-scale dilated convolutional kernels, to enhance the spatial modeling and introduce the image inductive bias into the feature output. Both modules can enlarge the context modeling in casual computing, as the output is enhanced by the inaccessible features. We explore three usages of Mamba-Adaptor: A general visual backbone for various vision tasks; A booster module to raise the performance of pretrained backbones; A highly efficient fine-tuning module that adapts the base model for transfer learning tasks. Extensive experiments verify the effectiveness of Mamba-Adaptor in three settings. Notably, our Mamba-Adaptor achieves state-of the-art performance on the ImageNet and COCO benchmarks.","authors":["Fei Xie","Jiahao Nie","Yujin Tang","Wenkang Zhang","Hongshen Zhao"],"url":"https://arxiv.org/abs/2505.12685"}
{"created":"2025-05-20","title":"RoVo: Robust Voice Protection Against Unauthorized Speech Synthesis with Embedding-Level Perturbations","abstract":"With the advancement of AI-based speech synthesis technologies such as Deep Voice, there is an increasing risk of voice spoofing attacks, including voice phishing and fake news, through unauthorized use of others' voices. Existing defenses that inject adversarial perturbations directly into audio signals have limited effectiveness, as these perturbations can easily be neutralized by speech enhancement methods. To overcome this limitation, we propose RoVo (Robust Voice), a novel proactive defense technique that injects adversarial perturbations into high-dimensional embedding vectors of audio signals, reconstructing them into protected speech. This approach effectively defends against speech synthesis attacks and also provides strong resistance to speech enhancement models, which represent a secondary attack threat.","authors":["Seungmin Kim","Sohee Park","Donghyun Kim","Jisu Lee","Daeseon Choi"],"url":"https://arxiv.org/abs/2505.12686"}
{"created":"2025-05-20","title":"Shielding Latent Face Representations From Privacy Attacks","abstract":"In today's data-driven analytics landscape, deep learning has become a powerful tool, with latent representations, known as embeddings, playing a central role in several applications. In the face analytics domain, such embeddings are commonly used for biometric recognition (e.g., face identification). However, these embeddings, or templates, can inadvertently expose sensitive attributes such as age, gender, and ethnicity. Leaking such information can compromise personal privacy and affect civil liberty and human rights. To address these concerns, we introduce a multi-layer protection framework for embeddings. It consists of a sequence of operations: (a) encrypting embeddings using Fully Homomorphic Encryption (FHE), and (b) hashing them using irreversible feature manifold hashing. Unlike conventional encryption methods, FHE enables computations directly on encrypted data, allowing downstream analytics while maintaining strong privacy guarantees. To reduce the overhead of encrypted processing, we employ embedding compression. Our proposed method shields latent representations of sensitive data from leaking private attributes (such as age and gender) while retaining essential functional capabilities (such as face identification). Extensive experiments on two datasets using two face encoders demonstrate that our approach outperforms several state-of-the-art privacy protection methods.","authors":["Arjun Ramesh Kaushik","Bharat Chandra Yalavarthi","Arun Ross","Vishnu Boddeti","Nalini Ratha"],"url":"https://arxiv.org/abs/2505.12688"}
{"created":"2025-05-20","title":"An Automated Blackbox Noncompliance Checker for QUIC Server Implementations","abstract":"We develop QUICtester, an automated approach for uncovering non-compliant behaviors in the ratified QUIC protocol implementations (RFC 9000/9001). QUICtester leverages active automata learning to abstract the behavior of a QUIC implementation into a finite state machine (FSM) representation. Unlike prior noncompliance checking methods, to help uncover state dependencies on event timing, QUICtester introduces the idea of state learning with event timing variations, adopting both valid and invalid input configurations, and combinations of security and transport layer parameters during learning. We use pairwise differential analysis of learned behaviour models of tested QUIC implementations to identify non-compliance instances as behaviour deviations in a property-agnostic way. This exploits the existence of the many different QUIC implementations, removing the need for validated, formal models. The diverse implementations act as cross-checking test oracles to discover non-compliance. We used QUICtester to analyze analyze 186 learned models from 19 QUIC implementations under the five security settings and discovered 55 implementation errors. Significantly, the tool uncovered a QUIC specification ambiguity resulting in an easily exploitable DoS vulnerability, led to 5 CVE assignments from developers, and two bug bounties thus far.","authors":["Kian Kai Ang","Guy Farrelly","Cheryl Pope","Damith C. Ranasinghe"],"url":"https://arxiv.org/abs/2505.12690"}
{"created":"2025-05-20","title":"Bullying the Machine: How Personas Increase LLM Vulnerability","abstract":"Large Language Models (LLMs) are increasingly deployed in interactions where they are prompted to adopt personas. This paper investigates whether such persona conditioning affects model safety under bullying, an adversarial manipulation that applies psychological pressures in order to force the victim to comply to the attacker. We introduce a simulation framework in which an attacker LLM engages a victim LLM using psychologically grounded bullying tactics, while the victim adopts personas aligned with the Big Five personality traits. Experiments using multiple open-source LLMs and a wide range of adversarial goals reveal that certain persona configurations -- such as weakened agreeableness or conscientiousness -- significantly increase victim's susceptibility to unsafe outputs. Bullying tactics involving emotional or sarcastic manipulation, such as gaslighting and ridicule, are particularly effective. These findings suggest that persona-driven interaction introduces a novel vector for safety risks in LLMs and highlight the need for persona-aware safety evaluation and alignment strategies.","authors":["Ziwei Xu","Udit Sanghi","Mohan Kankanhalli"],"url":"https://arxiv.org/abs/2505.12692"}
{"created":"2025-05-20","title":"TACOcc:Target-Adaptive Cross-Modal Fusion with Volume Rendering for 3D Semantic Occupancy","abstract":"The performance of multi-modal 3D occupancy prediction is limited by ineffective fusion, mainly due to geometry-semantics mismatch from fixed fusion strategies and surface detail loss caused by sparse, noisy annotations. The mismatch stems from the heterogeneous scale and distribution of point cloud and image features, leading to biased matching under fixed neighborhood fusion. To address this, we propose a target-scale adaptive, bidirectional symmetric retrieval mechanism. It expands the neighborhood for large targets to enhance context awareness and shrinks it for small ones to improve efficiency and suppress noise, enabling accurate cross-modal feature alignment. This mechanism explicitly establishes spatial correspondences and improves fusion accuracy. For surface detail loss, sparse labels provide limited supervision, resulting in poor predictions for small objects. We introduce an improved volume rendering pipeline based on 3D Gaussian Splatting, which takes fused features as input to render images, applies photometric consistency supervision, and jointly optimizes 2D-3D consistency. This enhances surface detail reconstruction while suppressing noise propagation. In summary, we propose TACOcc, an adaptive multi-modal fusion framework for 3D semantic occupancy prediction, enhanced by volume rendering supervision. Experiments on the nuScenes and SemanticKITTI benchmarks validate its effectiveness.","authors":["Luyao Lei","Shuo Xu","Yifan Bai","Xing Wei"],"url":"https://arxiv.org/abs/2505.12693"}
{"created":"2025-05-20","title":"LLM-based Query Expansion Fails for Unfamiliar and Ambiguous Queries","abstract":"Query expansion (QE) enhances retrieval by incorporating relevant terms, with large language models (LLMs) offering an effective alternative to traditional rule-based and statistical methods. However, LLM-based QE suffers from a fundamental limitation: it often fails to generate relevant knowledge, degrading search performance. Prior studies have focused on hallucination, yet its underlying cause--LLM knowledge deficiencies--remains underexplored. This paper systematically examines two failure cases in LLM-based QE: (1) when the LLM lacks query knowledge, leading to incorrect expansions, and (2) when the query is ambiguous, causing biased refinements that narrow search coverage. We conduct controlled experiments across multiple datasets, evaluating the effects of knowledge and query ambiguity on retrieval performance using sparse and dense retrieval models. Our results reveal that LLM-based QE can significantly degrade the retrieval effectiveness when knowledge in the LLM is insufficient or query ambiguity is high. We introduce a framework for evaluating QE under these conditions, providing insights into the limitations of LLM-based retrieval augmentation.","authors":["Kenya Abe","Kunihiro Takeoka","Makoto P. Kato","Masafumi Oyamada"],"url":"https://arxiv.org/abs/2505.12694"}
{"created":"2025-05-20","title":"Towards A Generalist Code Embedding Model Based On Massive Data Synthesis","abstract":"Code embedding models attract increasing attention due to the widespread popularity of retrieval-augmented generation (RAG) in software development. These models are expected to capture the rich semantic relationships inherent to code, which differ significantly from those found in text. However, existing models remain severely limited due to the scarcity of high-quality training data. In this work, we introduce \\textbf{CodeR} (\\underline{Code} \\underline{R}etrieval), a state-of-the-art embedding model for general-purpose code retrieval. The superior performance of CodeR is built upon CodeR-Pile, a large-scale synthetic dataset constructed under the DRU (Diversity, Reliability, Usability) principle via a novel data synthesis pipeline. To optimize training effectiveness, we propose Annealing, a curriculum learning strategy that enables effective knowledge transfer across heterogeneous sources of data. We evaluate CodeR based on 16 diverse code retrieval tasks, where it significantly outperforms existing baselines and exhibits strong out-of-domain generalization performance. We have publicly released our code and the well-trained model to facilitate further research in this critical area. https://github.com/FlagOpen/FlagEmbedding/tree/master/research/BGE_Coder.","authors":["Chaofan Li","Jianlyu Chen","Yingxia Shao","Defu Lian","Zheng Liu"],"url":"https://arxiv.org/abs/2505.12697"}
{"created":"2025-05-20","title":"More Efforts Towards Fixed-Parameter Approximability of Multiwinner Rules","abstract":"Multiwinner Elections have emerged as a prominent area of research with numerous practical applications. We contribute to this area by designing parameterized approximation algorithms and also resolving an open question by Yang and Wang [AAMAS'18]. More formally, given a set of candidates, \\mathcal{C}, a set of voters,\\mathcal{V}, approving a subset of candidates (called approval set of a voter), and an integer $k$, we consider the problem of selecting a ``good'' committee using Thiele rules. This problem is computationally challenging for most Thiele rules with monotone submodular satisfaction functions, as there is no (1-\\frac{1}{e}-\\epsilon)\\footnote{Here, $e$ denotes the base of the natural logarithm.}-approximation algorithm in f(k)(|\\mathcal{C}| + |\\mathcal{V}|)^{o(k)} time for any fixed $\\epsilon > 0$ and any computable function $f$, and no {\\sf PTAS} even when the length of approval set is two. Skowron [WINE'16] designed an approximation scheme running in FPT time parameterized by the combined parameter, size of the approval set and $k$. In this paper, we consider a parameter $d+k$ (no $d$ voters approve the same set of $d$ candidates), where $d$ is upper bounded by the size of the approval set (thus, can be much smaller).","authors":["Sushmita Gupta","Pallavi Jain","Souvik Saha","Saket Saurabh","Anannya Upasana"],"url":"https://arxiv.org/abs/2505.12699"}
{"created":"2025-05-20","title":"Writing a Good Security Paper for ISSCC (2025)","abstract":"Security is increasingly more important in designing chips and systems based on them, and the International Solid-State Circuits Conference (ISSCC), the leading conference for presenting advances in solid-state circuits and semiconductor technology, is committed to hardware security by establishing the security subcommittee since 2024. In the past two years, the authors of this paper reviewed submissions as members of the Security Subcommittee, a part of International Technical Program Committee (ITPC). This paper aims to encourage high-quality submissions to grow this field in the overall scope of the ISSCC.","authors":["Utsav Banerjee","Chiraag Juvekar","Yong Ki Lee","Leibo Liu","Sanu Mathew","Thomas Poeppelmann","Shreyas Sen","Takeshi Sugawara","Ingrid Verbauwhede","Rabia Tugce Yazicigil"],"url":"https://arxiv.org/abs/2505.12700"}
{"created":"2025-05-20","title":"Counterfactual Explanations for Continuous Action Reinforcement Learning","abstract":"Reinforcement Learning (RL) has shown great promise in domains like healthcare and robotics but often struggles with adoption due to its lack of interpretability. Counterfactual explanations, which address \"what if\" scenarios, provide a promising avenue for understanding RL decisions but remain underexplored for continuous action spaces. We propose a novel approach for generating counterfactual explanations in continuous action RL by computing alternative action sequences that improve outcomes while minimizing deviations from the original sequence. Our approach leverages a distance metric for continuous actions and accounts for constraints such as adhering to predefined policies in specific states. Evaluations in two RL domains, Diabetes Control and Lunar Lander, demonstrate the effectiveness, efficiency, and generalization of our approach, enabling more interpretable and trustworthy RL applications.","authors":["Shuyang Dong","Shangtong Zhang","Lu Feng"],"url":"https://arxiv.org/abs/2505.12701"}
{"created":"2025-05-20","title":"Long-RVOS: A Comprehensive Benchmark for Long-term Referring Video Object Segmentation","abstract":"Referring video object segmentation (RVOS) aims to identify, track and segment the objects in a video based on language descriptions, which has received great attention in recent years. However, existing datasets remain focus on short video clips within several seconds, with salient objects visible in most frames. To advance the task towards more practical scenarios, we introduce \\textbf{Long-RVOS}, a large-scale benchmark for long-term referring video object segmentation. Long-RVOS contains 2,000+ videos of an average duration exceeding 60 seconds, covering a variety of objects that undergo occlusion, disappearance-reappearance and shot changing. The objects are manually annotated with three different types of descriptions to individually evaluate the understanding of static attributes, motion patterns and spatiotemporal relationships. Moreover, unlike previous benchmarks that rely solely on the per-frame spatial evaluation, we introduce two new metrics to assess the temporal and spatiotemporal consistency. We benchmark 6 state-of-the-art methods on Long-RVOS. The results show that current approaches struggle severely with the long-video challenges. To address this, we further propose ReferMo, a promising baseline method that integrates motion information to expand the temporal receptive field, and employs a local-to-global architecture to capture both short-term dynamics and long-term dependencies. Despite simplicity, ReferMo achieves significant improvements over current methods in long-term scenarios. We hope that Long-RVOS and our baseline can drive future RVOS research towards tackling more realistic and long-form videos.","authors":["Tianming Liang","Haichao Jiang","Yuting Yang","Chaolei Tan","Shuai Li","Wei-Shi Zheng","Jian-Fang Hu"],"url":"https://arxiv.org/abs/2505.12702"}
{"created":"2025-05-20","title":"SpatialLLM: From Multi-modality Data to Urban Spatial Intelligence","abstract":"We propose SpatialLLM, a novel approach advancing spatial intelligence tasks in complex urban scenes. Unlike previous methods requiring geographic analysis tools or domain expertise, SpatialLLM is a unified language model directly addressing various spatial intelligence tasks without any training, fine-tuning, or expert intervention. The core of SpatialLLM lies in constructing detailed and structured scene descriptions from raw spatial data to prompt pre-trained LLMs for scene-based analysis. Extensive experiments show that, with our designs, pretrained LLMs can accurately perceive spatial distribution information and enable zero-shot execution of advanced spatial intelligence tasks, including urban planning, ecological analysis, traffic management, etc. We argue that multi-field knowledge, context length, and reasoning ability are key factors influencing LLM performances in urban analysis. We hope that SpatialLLM will provide a novel viable perspective for urban intelligent analysis and management. The code and dataset are available at https://github.com/WHU-USI3DV/SpatialLLM.","authors":["Jiabin Chen","Haiping Wang","Jinpeng Li","Yuan Liu","Zhen Dong","Bisheng Yang"],"url":"https://arxiv.org/abs/2505.12703"}
{"created":"2025-05-20","title":"DreamGen: Unlocking Generalization in Robot Learning through Neural Trajectories","abstract":"We introduce DreamGen, a simple yet highly effective 4-stage pipeline for training robot policies that generalize across behaviors and environments through neural trajectories - synthetic robot data generated from video world models. DreamGen leverages state-of-the-art image-to-video generative models, adapting them to the target robot embodiment to produce photorealistic synthetic videos of familiar or novel tasks in diverse environments. Since these models generate only videos, we recover pseudo-action sequences using either a latent action model or an inverse-dynamics model (IDM). Despite its simplicity, DreamGen unlocks strong behavior and environment generalization: a humanoid robot can perform 22 new behaviors in both seen and unseen environments, while requiring teleoperation data from only a single pick-and-place task in one environment. To evaluate the pipeline systematically, we introduce DreamGen Bench, a video generation benchmark that shows a strong correlation between benchmark performance and downstream policy success. Our work establishes a promising new axis for scaling robot learning well beyond manual data collection.","authors":["Joel Jang","Seonghyeon Ye","Zongyu Lin","Jiannan Xiang","Johan Bjorck","Yu Fang","Fengyuan Hu","Spencer Huang","Kaushil Kundalia","Yen-Chen Lin","Loic Magne","Ajay Mandlekar","Avnish Narayan","You Liang Tan","Guanzhi Wang","Jing Wang","Qi Wang","Yinzhen Xu","Xiaohui Zeng","Kaiyuan Zheng","Ruijie Zheng","Ming-Yu Liu","Luke Zettlemoyer","Dieter Fox","Jan Kautz","Scott Reed","Yuke Zhu","Linxi Fan"],"url":"https://arxiv.org/abs/2505.12705"}
{"created":"2025-05-20","title":"PLAICraft: Large-Scale Time-Aligned Vision-Speech-Action Dataset for Embodied AI","abstract":"Advances in deep generative modelling have made it increasingly plausible to train human-level embodied agents. Yet progress has been limited by the absence of large-scale, real-time, multi-modal, and socially interactive datasets that reflect the sensory-motor complexity of natural environments. To address this, we present PLAICraft, a novel data collection platform and dataset capturing multiplayer Minecraft interactions across five time-aligned modalities: video, game output audio, microphone input audio, mouse, and keyboard actions. Each modality is logged with millisecond time precision, enabling the study of synchronous, embodied behaviour in a rich, open-ended world. The dataset comprises over 10,000 hours of gameplay from more than 10,000 global participants.\\footnote{We have done a privacy review for the public release of an initial 200-hour subset of the dataset, with plans to release most of the dataset over time.} Alongside the dataset, we provide an evaluation suite for benchmarking model capabilities in object recognition, spatial awareness, language grounding, and long-term memory. PLAICraft opens a path toward training and evaluating agents that act fluently and purposefully in real time, paving the way for truly embodied artificial intelligence.","authors":["Yingchen He","Christian D. Weilbach","Martyna E. Wojciechowska","Yuxuan Zhang","Frank Wood"],"url":"https://arxiv.org/abs/2505.12707"}
{"created":"2025-05-20","title":"Pave Your Own Path: Graph Gradual Domain Adaptation on Fused Gromov-Wasserstein Geodesics","abstract":"Graph neural networks, despite their impressive performance, are highly vulnerable to distribution shifts on graphs. Existing graph domain adaptation (graph DA) methods often implicitly assume a \\textit{mild} shift between source and target graphs, limiting their applicability to real-world scenarios with \\textit{large} shifts. Gradual domain adaptation (GDA) has emerged as a promising approach for addressing large shifts by gradually adapting the source model to the target domain via a path of unlabeled intermediate domains. Existing GDA methods exclusively focus on independent and identically distributed (IID) data with a predefined path, leaving their extension to \\textit{non-IID graphs without a given path} an open challenge. To bridge this gap, we present Gadget, the first GDA framework for non-IID graph data. First (\\textit{theoretical foundation}), the Fused Gromov-Wasserstein (FGW) distance is adopted as the domain discrepancy for non-IID graphs, based on which, we derive an error bound revealing that the target domain error is proportional to the length of the path. Second (\\textit{optimal path}), guided by the error bound, we identify the FGW geodesic as the optimal path, which can be efficiently generated by our proposed algorithm. The generated path can be seamlessly integrated with existing graph DA methods to handle large shifts on graphs, improving state-of-the-art graph DA methods by up to 6.8\\% in node classification accuracy on real-world datasets.","authors":["Zhichen Zeng","Ruizhong Qiu","Wenxuan Bao","Tianxin Wei","Xiao Lin","Yuchen Yan","Tarek F. Abdelzaher","Jiawei Han","Hanghang Tong"],"url":"https://arxiv.org/abs/2505.12709"}
{"created":"2025-05-20","title":"Confidence-Regulated Generative Diffusion Models for Reliable AI Agent Migration in Vehicular Metaverses","abstract":"Vehicular metaverses are an emerging paradigm that merges intelligent transportation systems with virtual spaces, leveraging advanced digital twin and Artificial Intelligence (AI) technologies to seamlessly integrate vehicles, users, and digital environments. In this paradigm, vehicular AI agents are endowed with environment perception, decision-making, and action execution capabilities, enabling real-time processing and analysis of multi-modal data to provide users with customized interactive services. Since vehicular AI agents require substantial resources for real-time decision-making, given vehicle mobility and network dynamics conditions, the AI agents are deployed in RoadSide Units (RSUs) with sufficient resources and dynamically migrated among them. However, AI agent migration requires frequent data exchanges, which may expose vehicular metaverses to potential cyber attacks. To this end, we propose a reliable vehicular AI agent migration framework, achieving reliable dynamic migration and efficient resource scheduling through cooperation between vehicles and RSUs. Additionally, we design a trust evaluation model based on the theory of planned behavior to dynamically quantify the reputation of RSUs, thereby better accommodating the personalized trust preferences of users. We then model the vehicular AI agent migration process as a partially observable markov decision process and develop a Confidence-regulated Generative Diffusion Model (CGDM) to efficiently generate AI agent migration decisions. Numerical results demonstrate that the CGDM algorithm significantly outperforms baseline methods in reducing system latency and enhancing robustness against cyber attacks.","authors":["Yingkai Kang","Jiawen Kang","Jinbo Wen","Tao Zhang","Zhaohui Yang","Dusit Niyato","Yan Zhang"],"url":"https://arxiv.org/abs/2505.12710"}
{"created":"2025-05-20","title":"Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining","abstract":"Recent advances in computational pathology and artificial intelligence have significantly enhanced the utilization of gigapixel whole-slide images and and additional modalities (e.g., genomics) for pathological diagnosis. Although deep learning has demonstrated strong potential in pathology, several key challenges persist: (1) fusing heterogeneous data types requires sophisticated strategies beyond simple concatenation due to high computational costs; (2) common scenarios of missing modalities necessitate flexible strategies that allow the model to learn robustly in the absence of certain modalities; (3) the downstream tasks in CPath are diverse, ranging from unimodal to multimodal, cnecessitating a unified model capable of handling all modalities. To address these challenges, we propose ALTER, an any-to-any tri-modal pretraining framework that integrates WSIs, genomics, and pathology reports. The term \"any\" emphasizes ALTER's modality-adaptive design, enabling flexible pretraining with any subset of modalities, and its capacity to learn robust, cross-modal representations beyond WSI-centric approaches. We evaluate ALTER across extensive clinical tasks including survival prediction, cancer subtyping, gene mutation prediction, and report generation, achieving superior or comparable performance to state-of-the-art baselines.","authors":["Qichen Sun","Zhengrui Guo","Rui Peng","Hao Chen","Jinzhuo Wang"],"url":"https://arxiv.org/abs/2505.12711"}
{"created":"2025-05-20","title":"Identifiability of Nonnegative Tucker Decompositions -- Part I: Theory","abstract":"Tensor decompositions have become a central tool in data science, with applications in areas such as data analysis, signal processing, and machine learning. A key property of many tensor decompositions, such as the canonical polyadic decomposition, is identifiability: the factors are unique, up to trivial scaling and permutation ambiguities. This allows one to recover the groundtruth sources that generated the data. The Tucker decomposition (TD) is a central and widely used tensor decomposition model. However, it is in general not identifiable. In this paper, we study the identifiability of the nonnegative TD (nTD). By adapting and extending identifiability results of nonnegative matrix factorization (NMF), we provide uniqueness results for nTD. Our results require the nonnegative matrix factors to have some degree of sparsity (namely, satisfy the separability condition, or the sufficiently scattered condition), while the core tensor only needs to have some slices (or linear combinations of them) or unfoldings with full column rank (but does not need to be nonnegative). Under such conditions, we derive several procedures, using either unfoldings or slices of the input tensor, to obtain identifiable nTDs by minimizing the volume of unfoldings or slices of the core tensor.","authors":["Subhayan Saha","Giovanni Barbarino","Nicolas Gillis"],"url":"https://arxiv.org/abs/2505.12713"}
{"created":"2025-05-20","title":"IA-MVS: Instance-Focused Adaptive Depth Sampling for Multi-View Stereo","abstract":"Multi-view stereo (MVS) models based on progressive depth hypothesis narrowing have made remarkable advancements. However, existing methods haven't fully utilized the potential that the depth coverage of individual instances is smaller than that of the entire scene, which restricts further improvements in depth estimation precision. Moreover, inevitable deviations in the initial stage accumulate as the process advances. In this paper, we propose Instance-Adaptive MVS (IA-MVS). It enhances the precision of depth estimation by narrowing the depth hypothesis range and conducting refinement on each instance. Additionally, a filtering mechanism based on intra-instance depth continuity priors is incorporated to boost robustness. Furthermore, recognizing that existing confidence estimation can degrade IA-MVS performance on point clouds. We have developed a detailed mathematical model for confidence estimation based on conditional probability. The proposed method can be widely applied in models based on MVSNet without imposing extra training burdens. Our method achieves state-of-the-art performance on the DTU benchmark. The source code is available at https://github.com/KevinWang73106/IA-MVS.","authors":["Yinzhe Wang","Yiwen Xiao","Hu Wang","Yiping Xu","Yan Tian"],"url":"https://arxiv.org/abs/2505.12714"}
{"created":"2025-05-20","title":"VLC Fusion: Vision-Language Conditioned Sensor Fusion for Robust Object Detection","abstract":"Although fusing multiple sensor modalities can enhance object detection performance, existing fusion approaches often overlook subtle variations in environmental conditions and sensor inputs. As a result, they struggle to adaptively weight each modality under such variations. To address this challenge, we introduce Vision-Language Conditioned Fusion (VLC Fusion), a novel fusion framework that leverages a Vision-Language Model (VLM) to condition the fusion process on nuanced environmental cues. By capturing high-level environmental context such as as darkness, rain, and camera blurring, the VLM guides the model to dynamically adjust modality weights based on the current scene. We evaluate VLC Fusion on real-world autonomous driving and military target detection datasets that include image, LIDAR, and mid-wave infrared modalities. Our experiments show that VLC Fusion consistently outperforms conventional fusion baselines, achieving improved detection accuracy in both seen and unseen scenarios.","authors":["Aditya Taparia","Noel Ngu","Mario Leiva","Joshua Shay Kricheli","John Corcoran","Nathaniel D. Bastian","Gerardo Simari","Paulo Shakarian","Ransalu Senanayake"],"url":"https://arxiv.org/abs/2505.12715"}
{"created":"2025-05-20","title":"Shadow-FT: Tuning Instruct via Base","abstract":"Large language models (LLMs) consistently benefit from further fine-tuning on various tasks. However, we observe that directly tuning the INSTRUCT (i.e., instruction tuned) models often leads to marginal improvements and even performance degeneration. Notably, paired BASE models, the foundation for these INSTRUCT variants, contain highly similar weight values (i.e., less than 2% on average for Llama 3.1 8B). Therefore, we propose a novel Shadow-FT framework to tune the INSTRUCT models by leveraging the corresponding BASE models. The key insight is to fine-tune the BASE model, and then directly graft the learned weight updates to the INSTRUCT model. Our proposed Shadow-FT introduces no additional parameters, is easy to implement, and significantly improves performance. We conduct extensive experiments on tuning mainstream LLMs, such as Qwen 3 and Llama 3 series, and evaluate them across 19 benchmarks covering coding, reasoning, and mathematical tasks. Experimental results demonstrate that Shadow-FT consistently outperforms conventional full-parameter and parameter-efficient tuning approaches. Further analyses indicate that Shadow-FT can be applied to multimodal large language models (MLLMs) and combined with direct preference optimization (DPO). Codes and weights are available at \\href{https://github.com/wutaiqiang/Shadow-FT}{Github}.","authors":["Taiqiang Wu","Runming Yang","Jiayi Li","Pengfei Hu","Ngai Wong","Yujiu Yang"],"url":"https://arxiv.org/abs/2505.12716"}
{"created":"2025-05-20","title":"ToTRL: Unlock LLM Tree-of-Thoughts Reasoning Potential through Puzzles Solving","abstract":"Large language models (LLMs) demonstrate significant reasoning capabilities, particularly through long chain-of-thought (CoT) processes, which can be elicited by reinforcement learning (RL). However, prolonged CoT reasoning presents limitations, primarily verbose outputs due to excessive introspection. The reasoning process in these LLMs often appears to follow a trial-and-error methodology rather than a systematic, logical deduction. In contrast, tree-of-thoughts (ToT) offers a conceptually more advanced approach by modeling reasoning as an exploration within a tree structure. This reasoning structure facilitates the parallel generation and evaluation of multiple reasoning branches, allowing for the active identification, assessment, and pruning of unproductive paths. This process can potentially lead to improved performance and reduced token costs. Building upon the long CoT capability of LLMs, we introduce tree-of-thoughts RL (ToTRL), a novel on-policy RL framework with a rule-based reward. ToTRL is designed to guide LLMs in developing the parallel ToT strategy based on the sequential CoT strategy. Furthermore, we employ LLMs as players in a puzzle game during the ToTRL training process. Solving puzzle games inherently necessitates exploring interdependent choices and managing multiple constraints, which requires the construction and exploration of a thought tree, providing challenging tasks for cultivating the ToT reasoning capability. Our empirical evaluations demonstrate that our ToTQwen3-8B model, trained with our ToTRL, achieves significant improvement in performance and reasoning efficiency on complex reasoning tasks.","authors":["Haoyuan Wu","Xueyi Chen","Rui Ming","Jilong Gao","Shoubo Hu","Zhuolun He","Bei Yu"],"url":"https://arxiv.org/abs/2505.12717"}
{"created":"2025-05-20","title":"Automated Bias Assessment in AI-Generated Educational Content Using CEAT Framework","abstract":"Recent advances in Generative Artificial Intelligence (GenAI) have transformed educational content creation, particularly in developing tutor training materials. However, biases embedded in AI-generated content--such as gender, racial, or national stereotypes--raise significant ethical and educational concerns. Despite the growing use of GenAI, systematic methods for detecting and evaluating such biases in educational materials remain limited. This study proposes an automated bias assessment approach that integrates the Contextualized Embedding Association Test with a prompt-engineered word extraction method within a Retrieval-Augmented Generation framework. We applied this method to AI-generated texts used in tutor training lessons. Results show a high alignment between the automated and manually curated word sets, with a Pearson correlation coefficient of r = 0.993, indicating reliable and consistent bias assessment. Our method reduces human subjectivity and enhances fairness, scalability, and reproducibility in auditing GenAI-produced educational content.","authors":["Jingyang Peng","Wenyuan Shen","Jiarui Rao","Jionghao Lin"],"url":"https://arxiv.org/abs/2505.12718"}
{"created":"2025-05-20","title":"On-Policy Optimization with Group Equivalent Preference for Multi-Programming Language Understanding","abstract":"Large language models (LLMs) achieve remarkable performance in code generation tasks. However, a significant performance disparity persists between popular programming languages (e.g., Python, C++) and others. To address this capability gap, we leverage the code translation task to train LLMs, thereby facilitating the transfer of coding proficiency across diverse programming languages. Moreover, we introduce OORL for training, a novel reinforcement learning (RL) framework that integrates on-policy and off-policy strategies. Within OORL, on-policy RL is applied during code translation, guided by a rule-based reward signal derived from unit tests. Complementing this coarse-grained rule-based reward, we propose Group Equivalent Preference Optimization (GEPO), a novel preference optimization method. Specifically, GEPO trains the LLM using intermediate representations (IRs) groups. LLMs can be guided to discern IRs equivalent to the source code from inequivalent ones, while also utilizing signals about the mutual equivalence between IRs within the group. This process allows LLMs to capture nuanced aspects of code functionality. By employing OORL for training with code translation tasks, LLMs improve their recognition of code functionality and their understanding of the relationships between code implemented in different languages. Extensive experiments demonstrate that our OORL for LLMs training with code translation tasks achieves significant performance improvements on code benchmarks across multiple programming languages.","authors":["Haoyuan Wu","Rui Ming","Jilong Gao","Hangyu Zhao","Xueyi Chen","Yikai Yang","Haisheng Zheng","Zhuolun He","Bei Yu"],"url":"https://arxiv.org/abs/2505.12723"}
{"created":"2025-05-20","title":"A Control Oriented Fractional-Order Model of Lithium-ion Batteries Based on Caputo Definition","abstract":"This letter proposes a fractional-order battery model based on the Caputo definition. A closed-form time-domain solution is derived, enabling a simple recursive expression for discrete-time implementation. The model requires only the current and previous time-step states in each iteration, significantly reducing memory usage compared to the conventional Gr\\\"{u}nwald--Letnikov (G-L) method. This recursive structure is highly compatible with filter design and online parameter identification. Experimental validation on a 40.2~Ah NCM622 cell shows that the proposed first-order model achieves voltage prediction accuracy comparable to a second-order integer-order model. The results demonstrate that the Caputo-based model offers a practical balance between accuracy and computational efficiency, making it well suited for real-time battery management systems (BMS).","authors":["Yangyang Xu","Hongyu Zhao","Chengzhong Zhang","Chenglin Liao"],"url":"https://arxiv.org/abs/2505.12725"}
{"created":"2025-05-20","title":"What is Stigma Attributed to? A Theory-Grounded, Expert-Annotated Interview Corpus for Demystifying Mental-Health Stigma","abstract":"Mental-health stigma remains a pervasive social problem that hampers treatment-seeking and recovery. Existing resources for training neural models to finely classify such stigma are limited, relying primarily on social-media or synthetic data without theoretical underpinnings. To remedy this gap, we present an expert-annotated, theory-informed corpus of human-chatbot interviews, comprising 4,141 snippets from 684 participants with documented socio-cultural backgrounds. Our experiments benchmark state-of-the-art neural models and empirically unpack the challenges of stigma detection. This dataset can facilitate research on computationally detecting, neutralizing, and counteracting mental-health stigma.","authors":["Han Meng","Yancan Chen","Yunan Li","Yitian Yang","Jungup Lee","Renwen Zhang","Yi-Chieh Lee"],"url":"https://arxiv.org/abs/2505.12727"}
{"created":"2025-05-20","title":"FLASH: Latent-Aware Semi-Autoregressive Speculative Decoding for Multimodal Tasks","abstract":"Large language and multimodal models (LLMs and LMMs) exhibit strong inference capabilities but are often limited by slow decoding speeds. This challenge is especially acute in LMMs, where visual inputs typically comprise more tokens with lower information density than text -- an issue exacerbated by recent trends toward finer-grained visual tokenizations to boost performance. Speculative decoding has been effective in accelerating LLM inference by using a smaller draft model to generate candidate tokens, which are then selectively verified by the target model, improving speed without sacrificing output quality. While this strategy has been extended to LMMs, existing methods largely overlook the unique properties of visual inputs and depend solely on text-based draft models. In this work, we propose \\textbf{FLASH} (Fast Latent-Aware Semi-Autoregressive Heuristics), a speculative decoding framework designed specifically for LMMs, which leverages two key properties of multimodal data to design the draft model. First, to address redundancy in visual tokens, we propose a lightweight latent-aware token compression mechanism. Second, recognizing that visual objects often co-occur within a scene, we employ a semi-autoregressive decoding strategy to generate multiple tokens per forward pass. These innovations accelerate draft decoding while maintaining high acceptance rates, resulting in faster overall inference. Experiments show that FLASH significantly outperforms prior speculative decoding approaches in both unimodal and multimodal settings, achieving up to \\textbf{2.68$\\times$} speed-up on video captioning and \\textbf{2.55$\\times$} on visual instruction tuning tasks compared to the original LMM.","authors":["Zihua Wang","Ruibo Li","Haozhe Du","Joey Tianyi Zhou","Yu Zhang","Xu Yang"],"url":"https://arxiv.org/abs/2505.12728"}
{"created":"2025-05-20","title":"Leveraging Large Reconfigurable Intelligent Surfaces as Anchors for Near-Field Positioning","abstract":"In this work, we present a recent investigation on leveraging large reconfigurable intelligent surfaces (RIS) as anchors for positioning in wireless communication systems. Unlike existing approaches, we explicitly address the uncertainty arising from the substantial physical size of the RIS, particularly relevant when a user equipment resides in the near field, and propose a method that ensures accurate positioning under these conditions. We derive the corresponding Cramer-Rao bound for our scheme and validate the effectiveness of our scheme through numerical experiments, highlighting both the feasibility and potential of our approach.","authors":["Zeyu Huang","Markus Rupp","Stefan Schwarz"],"url":"https://arxiv.org/abs/2505.12730"}
{"created":"2025-05-20","title":"Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps","abstract":"Retrieval-augmented generation (RAG) has emerged as a pivotal method for expanding the knowledge of large language models. To handle complex queries more effectively, researchers developed Adaptive-RAG (A-RAG) to enhance the generated quality through multiple interactions with external knowledge bases. Despite its effectiveness, A-RAG exacerbates the pre-existing efficiency challenges inherent in RAG, which are attributable to its reliance on multiple iterations of generation. Existing A-RAG approaches process all retrieved contents from scratch. However, they ignore the situation where there is a significant overlap in the content of the retrieval results across rounds. The overlapping content is redundantly represented, which leads to a large proportion of repeated computations, thus affecting the overall efficiency. To address this issue, this paper introduces a model-agnostic approach that can be generally applied to A-RAG methods, which is dedicated to reducing the redundant representation process caused by the overlapping of retrieval results. Specifically, we use cache access and parallel generation to speed up the prefilling and decoding stages respectively. Additionally, we also propose an instruction-driven module to further guide the model to more effectively attend to each part of the content in a more suitable way for LLMs. Experiments show that our approach achieves 2.79 and 2.33 times significant acceleration on average for prefilling and decoding respectively while maintaining equal generation quality.","authors":["Jie Ou","Jinyu Guo","Shuaihong Jiang","Zhaokun Wang","Libo Qin","Shunyu Yao","Wenhong Tian"],"url":"https://arxiv.org/abs/2505.12731"}
{"created":"2025-05-20","title":"SounDiT: Geo-Contextual Soundscape-to-Landscape Generation","abstract":"We present a novel and practically significant problem-Geo-Contextual Soundscape-to-Landscape (GeoS2L) generation-which aims to synthesize geographically realistic landscape images from environmental soundscapes. Prior audio-to-image generation methods typically rely on general-purpose datasets and overlook geographic and environmental contexts, resulting in unrealistic images that are misaligned with real-world environmental settings. To address this limitation, we introduce a novel geo-contextual computational framework that explicitly integrates geographic knowledge into multimodal generative modeling. We construct two large-scale geo-contextual multimodal datasets, SoundingSVI and SonicUrban, pairing diverse soundscapes with real-world landscape images. We propose SounDiT, a novel Diffusion Transformer (DiT)-based model that incorporates geo-contextual scene conditioning to synthesize geographically coherent landscape images. Furthermore, we propose a practically-informed geo-contextual evaluation framework, the Place Similarity Score (PSS), across element-, scene-, and human perception-levels to measure consistency between input soundscapes and generated landscape images. Extensive experiments demonstrate that SounDiT outperforms existing baselines in both visual fidelity and geographic settings. Our work not only establishes foundational benchmarks for GeoS2L generation but also highlights the importance of incorporating geographic domain knowledge in advancing multimodal generative models, opening new directions at the intersection of generative AI, geography, urban planning, and environmental sciences.","authors":["Junbo Wang","Haofeng Tan","Bowen Liao","Albert Jiang","Teng Fei","Qixing Huang","Zhengzhong Tu","Shan Ye","Yuhao Kang"],"url":"https://arxiv.org/abs/2505.12734"}
{"created":"2025-05-20","title":"Deep Unfolding with Kernel-based Quantization in MIMO Detection","abstract":"The development of edge computing places critical demands on energy-efficient model deployment for multiple-input multiple-output (MIMO) detection tasks. Deploying deep unfolding models such as PGD-Nets and ADMM-Nets into resource-constrained edge devices using quantization methods is challenging. Existing quantization methods based on quantization aware training (QAT) suffer from performance degradation due to their reliance on parametric distribution assumption of activations and static quantization step sizes. To address these challenges, this paper proposes a novel kernel-based adaptive quantization (KAQ) framework for deep unfolding networks. By utilizing a joint kernel density estimation (KDE) and maximum mean discrepancy (MMD) approach to align activation distributions between full-precision and quantized models, the need for prior distribution assumptions is eliminated. Additionally, a dynamic step size updating method is introduced to adjust the quantization step size based on the channel conditions of wireless networks. Extensive simulations demonstrate that the accuracy of proposed KAQ framework outperforms traditional methods and successfully reduces the model's inference latency.","authors":["Zeyi Ren","Jingreng Lei","Yichen Jin","Ermo Hua","Qingfeng Lin","Chen Zhang","Bowen Zhou","Yik-Chung Wu"],"url":"https://arxiv.org/abs/2505.12736"}
{"created":"2025-05-20","title":"Option-aware Temporally Abstracted Value for Offline Goal-Conditioned Reinforcement Learning","abstract":"Offline goal-conditioned reinforcement learning (GCRL) offers a practical learning paradigm where goal-reaching policies are trained from abundant unlabeled (reward-free) datasets without additional environment interaction. However, offline GCRL still struggles with long-horizon tasks, even with recent advances that employ hierarchical policy structures, such as HIQL. By identifying the root cause of this challenge, we observe the following insights: First, performance bottlenecks mainly stem from the high-level policy's inability to generate appropriate subgoals. Second, when learning the high-level policy in the long-horizon regime, the sign of the advantage signal frequently becomes incorrect. Thus, we argue that improving the value function to produce a clear advantage signal for learning the high-level policy is essential. In this paper, we propose a simple yet effective solution: Option-aware Temporally Abstracted value learning, dubbed OTA, which incorporates temporal abstraction into the temporal-difference learning process. By modifying the value update to be option-aware, the proposed learning scheme contracts the effective horizon length, enabling better advantage estimates even in long-horizon regimes. We experimentally show that the high-level policy extracted using the OTA value function achieves strong performance on complex tasks from OGBench, a recently proposed offline GCRL benchmark, including maze navigation and visual robotic manipulation environments.","authors":["Hongjoon Ahn","Heewoong Choi","Jisu Han","Taesup Moon"],"url":"https://arxiv.org/abs/2505.12737"}
{"created":"2025-05-20","title":"EpiLLM: Unlocking the Potential of Large Language Models in Epidemic Forecasting","abstract":"Advanced epidemic forecasting is critical for enabling precision containment strategies, highlighting its strategic importance for public health security. While recent advances in Large Language Models (LLMs) have demonstrated effectiveness as foundation models for domain-specific tasks, their potential for epidemic forecasting remains largely unexplored. In this paper, we introduce EpiLLM, a novel LLM-based framework tailored for spatio-temporal epidemic forecasting. Considering the key factors in real-world epidemic transmission: infection cases and human mobility, we introduce a dual-branch architecture to achieve fine-grained token-level alignment between such complex epidemic patterns and language tokens for LLM adaptation. To unleash the multi-step forecasting and generalization potential of LLM architectures, we propose an autoregressive modeling paradigm that reformulates the epidemic forecasting task into next-token prediction. To further enhance LLM perception of epidemics, we introduce spatio-temporal prompt learning techniques, which strengthen forecasting capabilities from a data-driven perspective. Extensive experiments show that EpiLLM significantly outperforms existing baselines on real-world COVID-19 datasets and exhibits scaling behavior characteristic of LLMs.","authors":["Chenghua Gong","Rui Sun","Yuhao Zheng","Juyuan Zhang","Tianjun Gu","Liming Pan","Linyuan Lv"],"url":"https://arxiv.org/abs/2505.12738"}
{"created":"2025-05-20","title":"Secrecy Capacity of Hybrid VLC-RF Systems with Light Energy Harvesting","abstract":"This paper studies the performance of physical layer security (PLS) in a multi-user hybrid heterogeneous visible light communication (VLC) and radio frequency (RF) wireless communication system with simultaneous lightwave information and power transfer (SLIPT). In the considered system, VLC is used for downlink (DL) while RF is employed for uplink (UL) transmission. In addition, to support multiple users, time division multiple access (TDMA) is assumed for both DL and UL channels. In the DL, each user receives information during its allocated time slot of the TDMA frame and harvests energy from the received signal outside the time slot. The harvested energy is then used for transmitting the signal over the UL channel, which is subject to eavesdropping by an unauthorized user. Therefore, PLS is employed to protect the confidentiality of the UL information. Then, an optimization problem is formulated to solve the optimal DL and UL time slots that maximize the PLS performance given a target sum rate of the DL. We show that the problem can be cast as a difference of convex functions (DC) program, which can be solved efficiently using the DC algorithm (DCA).","authors":["Tuan A. Hoang","Thanh V. Pham","Chuyen T. Nguyen"],"url":"https://arxiv.org/abs/2505.12739"}
{"created":"2025-05-20","title":"Dense Communication between Language Models","abstract":"As higher-level intelligence emerges from the combination of modular components with lower-level intelligence, many works combines Large Language Models (LLMs) for collective intelligence. Such combination is achieved by building communications among LLMs. While current systems primarily facilitate such communication through natural language, this paper proposes a novel paradigm of direct dense vector communication between LLMs. Our approach eliminates the unnecessary embedding and de-embedding steps when LLM interact with another, enabling more efficient information transfer, fully differentiable optimization pathways, and exploration of capabilities beyond human heuristics. We use such stripped LLMs as vertexes and optimizable seq2seq modules as edges to construct LMNet, with similar structure as MLPs. By utilizing smaller pre-trained LLMs as vertexes, we train a LMNet that achieves comparable performance with LLMs in similar size with only less than 0.1% training cost. This offers a new perspective on scaling for general intelligence rather than training a monolithic LLM from scratch. Besides, the proposed method can be used for other applications, like customizing LLM with limited data, showing its versatility.","authors":["Shiguang Wu","Yaqing Wang","Quanming Yao"],"url":"https://arxiv.org/abs/2505.12741"}
{"created":"2025-05-20","title":"MVAR: Visual Autoregressive Modeling with Scale and Spatial Markovian Conditioning","abstract":"Essential to visual generation is efficient modeling of visual data priors. Conventional next-token prediction methods define the process as learning the conditional probability distribution of successive tokens. Recently, next-scale prediction methods redefine the process to learn the distribution over multi-scale representations, significantly reducing generation latency. However, these methods condition each scale on all previous scales and require each token to consider all preceding tokens, exhibiting scale and spatial redundancy. To better model the distribution by mitigating redundancy, we propose Markovian Visual AutoRegressive modeling (MVAR), a novel autoregressive framework that introduces scale and spatial Markov assumptions to reduce the complexity of conditional probability modeling. Specifically, we introduce a scale-Markov trajectory that only takes as input the features of adjacent preceding scale for next-scale prediction, enabling the adoption of a parallel training strategy that significantly reduces GPU memory consumption. Furthermore, we propose spatial-Markov attention, which restricts the attention of each token to a localized neighborhood of size k at corresponding positions on adjacent scales, rather than attending to every token across these scales, for the pursuit of reduced modeling complexity. Building on these improvements, we reduce the computational complexity of attention calculation from O(N^2) to O(Nk), enabling training with just eight NVIDIA RTX 4090 GPUs and eliminating the need for KV cache during inference. Extensive experiments on ImageNet demonstrate that MVAR achieves comparable or superior performance with both small model trained from scratch and large fine-tuned models, while reducing the average GPU memory footprint by 3.0x.","authors":["Jinhua Zhang","Wei Long","Minghao Han","Weiyi You","Shuhang Gu"],"url":"https://arxiv.org/abs/2505.12742"}
{"created":"2025-05-20","title":"Incentivizing Multimodal Reasoning in Large Models for Direct Robot Manipulation","abstract":"Recent Large Multimodal Models have demonstrated remarkable reasoning capabilities, especially in solving complex mathematical problems and realizing accurate spatial perception. Our key insight is that these emerging abilities can naturally extend to robotic manipulation by enabling LMMs to directly infer the next goal in language via reasoning, rather than relying on a separate action head. However, this paradigm meets two main challenges: i) How to make LMMs understand the spatial action space, and ii) How to fully exploit the reasoning capacity of LMMs in solving these tasks. To tackle the former challenge, we propose a novel task formulation, which inputs the current states of object parts and the gripper, and reformulates rotation by a new axis representation instead of traditional Euler angles. This representation is more compatible with spatial reasoning and easier to interpret within a unified language space. For the latter challenge, we design a pipeline to utilize cutting-edge LMMs to generate a small but high-quality reasoning dataset of multi-round dialogues that successfully solve manipulation tasks for supervised fine-tuning. Then, we perform reinforcement learning by trial-and-error interactions in simulation to further enhance the model's reasoning abilities for robotic manipulation. Our resulting reasoning model built upon a 7B backbone, named ReasonManip, demonstrates three notable advantages driven by its system-2 level reasoning capabilities: i) exceptional generalizability to out-of-distribution environments, objects, and tasks; ii) inherent sim-to-real transfer ability enabled by the unified language representation shared across domains; iii) transparent interpretability connecting high-level reasoning and low-level control. Extensive experiments demonstrate the effectiveness of the proposed paradigm and its potential to advance LMM-driven robotic manipulation.","authors":["Weiliang Tang","Dong Jing","Jia-Hui Pan","Zhiwu Lu","Yun-Hui Liu","Li Erran Li","Mingyu Ding","Chi-Wing Fu"],"url":"https://arxiv.org/abs/2505.12744"}
{"created":"2025-05-20","title":"PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization","abstract":"Data augmentation is a popular tool for single source domain generalization, which expands the source domain by generating simulated ones, improving generalization on unseen target domains. In this work, we show that the performance of such augmentation-based methods in the target domains universally fluctuates during training, posing challenges in model selection under realistic scenarios. We argue that the fluctuation stems from the inability of the model to accumulate the knowledge learned from diverse augmentations, exacerbating feature distortion during training. Based on this observation, we propose a novel generalization method, coined Parameter-Space Ensemble with Entropy Regularization (PEER), that uses a proxy model to learn the augmented data on behalf of the main model. The main model is updated by averaging its parameters with the proxy model, progressively accumulating knowledge over the training steps. Maximizing the mutual information between the output representations of the two models guides the learning process of the proxy model, mitigating feature distortion during training. Experimental results demonstrate the effectiveness of PEER in reducing the OOD performance fluctuation and enhancing generalization across various datasets, including PACS, Digits, Office-Home, and VLCS. Notably, our method with simple random augmentation achieves state-of-the-art performance, surpassing prior approaches on sDG that utilize complex data augmentation strategies.","authors":["Dong Kyu Cho","Inwoo Hwang","Sanghack Lee"],"url":"https://arxiv.org/abs/2505.12745"}
{"created":"2025-05-20","title":"Correspondence of high-dimensional emotion structures elicited by video clips between humans and Multimodal LLMs","abstract":"Recent studies have revealed that human emotions exhibit a high-dimensional, complex structure. A full capturing of this complexity requires new approaches, as conventional models that disregard high dimensionality risk overlooking key nuances of human emotions. Here, we examined the extent to which the latest generation of rapidly evolving Multimodal Large Language Models (MLLMs) capture these high-dimensional, intricate emotion structures, including capabilities and limitations. Specifically, we compared self-reported emotion ratings from participants watching videos with model-generated estimates (e.g., Gemini or GPT). We evaluated performance not only at the individual video level but also from emotion structures that account for inter-video relationships. At the level of simple correlation between emotion structures, our results demonstrated strong similarity between human and model-inferred emotion structures. To further explore whether the similarity between humans and models is at the signle item level or the coarse-categorical level, we applied Gromov Wasserstein Optimal Transport. We found that although performance was not necessarily high at the strict, single-item level, performance across video categories that elicit similar emotions was substantial, indicating that the model could infer human emotional experiences at the category level. Our results suggest that current state-of-the-art MLLMs broadly capture the complex high-dimensional emotion structures at the category level, as well as their apparent limitations in accurately capturing entire structures at the single-item level.","authors":["Haruka Asanuma","Naoko Koide-Majima","Ken Nakamura","Takato Horii","Shinji Nishimoto","Masafumi Oizumi"],"url":"https://arxiv.org/abs/2505.12746"}
{"created":"2025-05-20","title":"TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation","abstract":"Teleoperation is a cornerstone of embodied-robot learning, and bimanual dexterous teleoperation in particular provides rich demonstrations that are difficult to obtain with fully autonomous systems. While recent studies have proposed diverse hardware pipelines-ranging from inertial motion-capture gloves to exoskeletons and vision-based interfaces-there is still no unified benchmark that enables fair, reproducible comparison of these systems. In this paper, we introduce TeleOpBench, a simulator-centric benchmark tailored to bimanual dexterous teleoperation. TeleOpBench contains 30 high-fidelity task environments that span pick-and-place, tool use, and collaborative manipulation, covering a broad spectrum of kinematic and force-interaction difficulty. Within this benchmark we implement four representative teleoperation modalities-(i) MoCap, (ii) VR device, (iii) arm-hand exoskeletons, and (iv) monocular vision tracking-and evaluate them with a common protocol and metric suite. To validate that performance in simulation is predictive of real-world behavior, we conduct mirrored experiments on a physical dual-arm platform equipped with two 6-DoF dexterous hands. Across 10 held-out tasks we observe a strong correlation between simulator and hardware performance, confirming the external validity of TeleOpBench. TeleOpBench establishes a common yardstick for teleoperation research and provides an extensible platform for future algorithmic and hardware innovation.","authors":["Hangyu Li","Qin Zhao","Haoran Xu","Xinyu Jiang","Qingwei Ben","Feiyu Jia","Haoyu Zhao","Liang Xu","Jia Zeng","Hanqing Wang","Bo Dai","Junting Dong","Jiangmiao Pang"],"url":"https://arxiv.org/abs/2505.12748"}
{"created":"2025-05-20","title":"Malware families discovery via Open-Set Recognition on Android manifest permissions","abstract":"Malware are malicious programs that are grouped into families based on their penetration technique, source code, and other characteristics. Classifying malware programs into their respective families is essential for building effective defenses against cyber threats. Machine learning models have a huge potential in malware detection on mobile devices, as malware families can be recognized by classifying permission data extracted from Android manifest files. Still, the malware classification task is challenging due to the high-dimensional nature of permission data and the limited availability of training samples. In particular, the steady emergence of new malware families makes it impossible to acquire a comprehensive training set covering all the malware classes. In this work, we present a malware classification system that, on top of classifying known malware, detects new ones. In particular, we combine an open-set recognition technique developed within the computer vision community, namely MaxLogit, with a tree-based Gradient Boosting classifier, which is particularly effective in classifying high-dimensional data. Our solution turns out to be very practical, as it can be seamlessly employed in a standard classification workflow, and efficient, as it adds minimal computational overhead. Experiments on public and proprietary datasets demonstrate the potential of our solution, which has been deployed in a business environment.","authors":["Filippo Leveni","Matteo Mistura","Francesco Iubatti","Carmine Giangregorio","Nicol\\`o Pastore","Cesare Alippi","Giacomo Boracchi"],"url":"https://arxiv.org/abs/2505.12750"}
{"created":"2025-05-20","title":"Structure-based Anomaly Detection and Clustering","abstract":"Anomaly detection is a fundamental problem in domains such as healthcare, manufacturing, and cybersecurity. This thesis proposes new unsupervised methods for anomaly detection in both structured and streaming data settings. In the first part, we focus on structure-based anomaly detection, where normal data follows low-dimensional manifolds while anomalies deviate from them. We introduce Preference Isolation Forest (PIF), which embeds data into a high-dimensional preference space via manifold fitting, and isolates outliers using two variants: Voronoi-iForest, based on geometric distances, and RuzHash-iForest, leveraging Locality Sensitive Hashing for scalability. We also propose Sliding-PIF, which captures local manifold information for streaming scenarios. Our methods outperform existing techniques on synthetic and real datasets. We extend this to structure-based clustering with MultiLink, a novel method for recovering multiple geometric model families in noisy data. MultiLink merges clusters via a model-aware linkage strategy, enabling robust multi-class structure recovery. It offers key advantages over existing approaches, such as speed, reduced sensitivity to thresholds, and improved robustness to poor initial sampling. The second part of the thesis addresses online anomaly detection in evolving data streams. We propose Online Isolation Forest (Online-iForest), which uses adaptive, multi-resolution histograms and dynamically updates tree structures to track changes over time. It avoids retraining while achieving accuracy comparable to offline models, with superior efficiency for real-time applications. Finally, we tackle anomaly detection in cybersecurity via open-set recognition for malware classification. We enhance a Gradient Boosting classifier with MaxLogit to detect unseen malware families, a method now integrated into Cleafy's production system.","authors":["Filippo Leveni"],"url":"https://arxiv.org/abs/2505.12751"}
{"created":"2025-05-20","title":"MOON: Multi-Objective Optimization-Driven Object-Goal Navigation Using a Variable-Horizon Set-Orienteering Planner","abstract":"Object-goal navigation (ON) enables autonomous robots to locate and reach user-specified objects in previously unknown environments, offering promising applications in domains such as assistive care and disaster response. Existing ON methods -- including training-free approaches, reinforcement learning, and zero-shot planners -- generally depend on active exploration to identify landmark objects (e.g., kitchens or desks), followed by navigation toward semantically related targets (e.g., a specific mug). However, these methods often lack strategic planning and do not adequately address trade-offs among multiple objectives. To overcome these challenges, we propose a novel framework that formulates ON as a multi-objective optimization problem (MOO), balancing frontier-based knowledge exploration with knowledge exploitation over previously observed landmarks; we call this framework MOON (MOO-driven ON). We implement a prototype MOON system that integrates three key components: (1) building on QOM [IROS05], a classical ON system that compactly and discriminatively encodes landmarks based on their semantic relevance to the target; (2) integrating StructNav [RSS23], a recently proposed training-free planner, to enhance the navigation pipeline; and (3) introducing a variable-horizon set orienteering problem formulation to enable global optimization over both exploration and exploitation strategies. This work represents an important first step toward developing globally optimized, next-generation object-goal navigation systems.","authors":["Daigo Nakajima","Kanji Tanaka","Daiki Iwata","Kouki Terashima"],"url":"https://arxiv.org/abs/2505.12752"}
{"created":"2025-05-20","title":"LiDAR MOT-DETR: A LiDAR-based Two-Stage Transformer for 3D Multiple Object Tracking","abstract":"Multi-object tracking from LiDAR point clouds presents unique challenges due to the sparse and irregular nature of the data, compounded by the need for temporal coherence across frames. Traditional tracking systems often rely on hand-crafted features and motion models, which can struggle to maintain consistent object identities in crowded or fast-moving scenes. We present a lidar-based two-staged DETR inspired transformer; a smoother and tracker. The smoother stage refines lidar object detections, from any off-the-shelf detector, across a moving temporal window. The tracker stage uses a DETR-based attention block to maintain tracks across time by associating tracked objects with the refined detections using the point cloud as context. The model is trained on the datasets nuScenes and KITTI in both online and offline (forward peeking) modes demonstrating strong performance across metrics such as ID-switch and multiple object tracking accuracy (MOTA). The numerical results indicate that the online mode outperforms the lidar-only baseline and SOTA models on the nuScenes dataset, with an aMOTA of 0.722 and an aMOTP of 0.475, while the offline mode provides an additional 3 pp aMOTP","authors":["Martha Teiko Teye","Ori Maoz","Matthias Rottmann"],"url":"https://arxiv.org/abs/2505.12753"}
{"created":"2025-05-20","title":"ProDS: Preference-oriented Data Selection for Instruction Tuning","abstract":"Instruction data selection aims to identify a high-quality subset from the training set that matches or exceeds the performance of the full dataset on target tasks. Existing methods focus on the instruction-to-response mapping, but neglect the human preference for diverse responses. In this paper, we propose Preference-oriented Data Selection method (ProDS) that scores training samples based on their alignment with preferences observed in the target set. Our key innovation lies in shifting the data selection criteria from merely estimating features for accurate response generation to explicitly aligning training samples with human preferences in target tasks. Specifically, direct preference optimization (DPO) is employed to estimate human preferences across diverse responses. Besides, a bidirectional preference synthesis strategy is designed to score training samples according to both positive preferences and negative preferences. Extensive experimental results demonstrate our superiority to existing task-agnostic and targeted methods.","authors":["Wenya Guo","Zhengkun Zhang","Xumeng Liu","Ying Zhang","Ziyu Lu","Haoze Zhu","Xubo Liu","Ruxue Yan"],"url":"https://arxiv.org/abs/2505.12754"}
{"created":"2025-05-20","title":"It's not you, it's me -- Global urban visual perception varies across demographics and personalities","abstract":"Understanding people's preferences and needs is crucial for urban planning decisions, yet current approaches often combine them from multi-cultural and multi-city populations, obscuring important demographic differences and risking amplifying biases. We conducted a large-scale urban visual perception survey of streetscapes worldwide using street view imagery, examining how demographics -- including gender, age, income, education, race and ethnicity, and, for the first time, personality traits -- shape perceptions among 1,000 participants, with balanced demographics, from five countries and 45 nationalities. This dataset, introduced as Street Perception Evaluation Considering Socioeconomics (SPECS), exhibits statistically significant differences in perception scores in six traditionally used indicators (safe, lively, wealthy, beautiful, boring, and depressing) and four new ones we propose (live nearby, walk, cycle, green) among demographics and personalities. We revealed that location-based sentiments are carried over in people's preferences when comparing urban streetscapes with other cities. Further, we compared the perception scores based on where participants and streetscapes are from. We found that an off-the-shelf machine learning model trained on an existing global perception dataset tends to overestimate positive indicators and underestimate negative ones compared to human responses, suggesting that targeted intervention should consider locals' perception. Our study aspires to rectify the myopic treatment of street perception, which rarely considers demographics or personality traits.","authors":["Matias Quintana","Youlong Gu","Xiucheng Liang","Yujun Hou","Koichi Ito","Yihan Zhu","Mahmoud Abdelrahman","Filip Biljecki"],"url":"https://arxiv.org/abs/2505.12758"}
{"created":"2025-05-20","title":"Your Offline Policy is Not Trustworthy: Bilevel Reinforcement Learning for Sequential Portfolio Optimization","abstract":"Reinforcement learning (RL) has shown significant promise for sequential portfolio optimization tasks, such as stock trading, where the objective is to maximize cumulative returns while minimizing risks using historical data. However, traditional RL approaches often produce policies that merely memorize the optimal yet impractical buying and selling behaviors within the fixed dataset. These offline policies are less generalizable as they fail to account for the non-stationary nature of the market. Our approach, MetaTrader, frames portfolio optimization as a new type of partial-offline RL problem and makes two technical contributions. First, MetaTrader employs a bilevel learning framework that explicitly trains the RL agent to improve both in-domain profits on the original dataset and out-of-domain performance across diverse transformations of the raw financial data. Second, our approach incorporates a new temporal difference (TD) method that approximates worst-case TD estimates from a batch of transformed TD targets, addressing the value overestimation issue that is particularly challenging in scenarios with limited offline data. Our empirical results on two public stock datasets show that MetaTrader outperforms existing methods, including both RL-based approaches and traditional stock prediction models.","authors":["Haochen Yuan","Minting Pan","Yunbo Wang","Siyu Gao","Philip S. Yu","Xiaokang Yang"],"url":"https://arxiv.org/abs/2505.12759"}
{"created":"2025-05-20","title":"Enhancing Channel-Independent Time-Series Forecasting via Cross-Variate Patch Embedding","abstract":"Transformers have recently gained popularity in time series forecasting due to their ability to capture long-term dependencies. However, many existing models focus only on capturing temporal dependencies while omitting intricate relationships between variables. Recent models have tried tackling this by explicitly modeling both cross-time and cross-variate dependencies through a sequential or unified attention mechanism, but they are entirely channel dependent (CD) across all layers, making them potentially susceptible to overfitting. To address this, we propose Cross-Variate Patch Embeddings (CVPE), a lightweight CD module that injects cross-variate context into channel-independent (CI) models by simply modifying the patch embedding process. We achieve this by adding a learnable positional encoding and a lightweight router-attention block to the vanilla patch embedding layer. We then integrate CVPE into Time-LLM, a multimodal CI forecasting model, to demonstrate its effectiveness in capturing cross-variate dependencies and enhance the CI model's performance. Extensive experimental results on seven real-world datasets show that our enhanced Time-LLM outperforms the original baseline model simply by incorporating the CVPE module, with no other changes.","authors":["Donghwa Shin","Edwin Zhang"],"url":"https://arxiv.org/abs/2505.12761"}
{"created":"2025-05-20","title":"IDEAL: Data Equilibrium Adaptation for Multi-Capability Language Model Alignment","abstract":"Large Language Models (LLMs) have achieved impressive performance through Supervised Fine-tuning (SFT) on diverse instructional datasets. When training on multiple capabilities simultaneously, the mixture training dataset, governed by volumes of data from different domains, is a critical factor that directly impacts the final model's performance. Unlike many studies that focus on enhancing the quality of training datasets through data selection methods, few works explore the intricate relationship between the compositional quantity of mixture training datasets and the emergent capabilities of LLMs. Given the availability of a high-quality multi-domain training dataset, understanding the impact of data from each domain on the model's overall capabilities is crucial for preparing SFT data and training a well-balanced model that performs effectively across diverse domains. In this work, we introduce IDEAL, an innovative data equilibrium adaptation framework designed to effectively optimize volumes of data from different domains within mixture SFT datasets, thereby enhancing the model's alignment and performance across multiple capabilities. IDEAL employs a gradient-based approach to iteratively refine the training data distribution, dynamically adjusting the volumes of domain-specific data based on their impact on downstream task performance. By leveraging this adaptive mechanism, IDEAL ensures a balanced dataset composition, enabling the model to achieve robust generalization and consistent proficiency across diverse tasks. Experiments across different capabilities demonstrate that IDEAL outperforms conventional uniform data allocation strategies, achieving a comprehensive improvement of approximately 7% in multi-task evaluation scores.","authors":["Chenlin Ming","Chendi Qu","Mengzhang Cai","Qizhi Pei","Zhuoshi Pan","Yu Li","Xiaoming Duan","Lijun Wu","Conghui He"],"url":"https://arxiv.org/abs/2505.12762"}
{"created":"2025-05-20","title":"Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization","abstract":"Reward models (RMs) play a crucial role in reinforcement learning from human feedback (RLHF), aligning model behavior with human preferences. However, existing benchmarks for reward models show a weak correlation with the performance of optimized policies, suggesting that they fail to accurately assess the true capabilities of RMs. To bridge this gap, we explore several evaluation designs through the lens of reward overoptimization\\textemdash a phenomenon that captures both how well the reward model aligns with human preferences and the dynamics of the learning signal it provides to the policy. The results highlight three key findings on how to construct a reliable benchmark: (i) it is important to minimize differences between chosen and rejected responses beyond correctness, (ii) evaluating reward models requires multiple comparisons across a wide range of chosen and rejected responses, and (iii) given that reward models encounter responses with diverse representations, responses should be sourced from a variety of models. However, we also observe that a extremely high correlation with degree of overoptimization leads to comparatively lower correlation with certain downstream performance. Thus, when designing a benchmark, it is desirable to use the degree of overoptimization as a useful tool, rather than the end goal.","authors":["Sunghwan Kim","Dongjin Kang","Taeyoon Kwon","Hyungjoo Chae","Dongha Lee","Jinyoung Yeo"],"url":"https://arxiv.org/abs/2505.12763"}
{"created":"2025-05-20","title":"Reasoning-OCR: Can Large Multimodal Models Solve Complex Logical Reasoning Problems from OCR Cues?","abstract":"Large Multimodal Models (LMMs) have become increasingly versatile, accompanied by impressive Optical Character Recognition (OCR) related capabilities. Existing OCR-related benchmarks emphasize evaluating LMMs' abilities of relatively simple visual question answering, visual-text parsing, etc. However, the extent to which LMMs can deal with complex logical reasoning problems based on OCR cues is relatively unexplored. To this end, we introduce the Reasoning-OCR benchmark, which challenges LMMs to solve complex reasoning problems based on the cues that can be extracted from rich visual-text. Reasoning-OCR covers six visual scenarios and encompasses 150 meticulously designed questions categorized into six reasoning challenges. Additionally, Reasoning-OCR minimizes the impact of field-specialized knowledge. Our evaluation offers some insights for proprietary and open-source LMMs in different reasoning challenges, underscoring the urgent to improve the reasoning performance. We hope Reasoning-OCR can inspire and facilitate future research on enhancing complex reasoning ability based on OCR cues. Reasoning-OCR is publicly available at https://github.com/Hxyz-123/ReasoningOCR.","authors":["Haibin He","Maoyuan Ye","Jing Zhang","Xiantao Cai","Juhua Liu","Bo Du","Dacheng Tao"],"url":"https://arxiv.org/abs/2505.12766"}
{"created":"2025-05-20","title":"Language Models That Walk the Talk: A Framework for Formal Fairness Certificates","abstract":"As large language models become integral to high-stakes applications, ensuring their robustness and fairness is critical. Despite their success, large language models remain vulnerable to adversarial attacks, where small perturbations, such as synonym substitutions, can alter model predictions, posing risks in fairness-critical areas, such as gender bias mitigation, and safety-critical areas, such as toxicity detection. While formal verification has been explored for neural networks, its application to large language models remains limited. This work presents a holistic verification framework to certify the robustness of transformer-based language models, with a focus on ensuring gender fairness and consistent outputs across different gender-related terms. Furthermore, we extend this methodology to toxicity detection, offering formal guarantees that adversarially manipulated toxic inputs are consistently detected and appropriately censored, thereby ensuring the reliability of moderation systems. By formalizing robustness within the embedding space, this work strengthens the reliability of language models in ethical AI deployment and content moderation.","authors":["Danqing Chen","Tobias Ladner","Ahmed Rayen Mhadhbi","Matthias Althoff"],"url":"https://arxiv.org/abs/2505.12767"}
{"created":"2025-05-20","title":"ReEx-SQL: Reasoning with Execution-Aware Reinforcement Learning for Text-to-SQL","abstract":"In Text-to-SQL, execution feedback is essential for guiding large language models (LLMs) to reason accurately and generate reliable SQL queries. However, existing methods treat execution feedback solely as a post-hoc signal for correction or selection, failing to integrate it into the generation process. This limitation hinders their ability to address reasoning errors as they occur, ultimately reducing query accuracy and robustness. To address this issue, we propose ReEx-SQL (Reasoning with Execution-Aware Reinforcement Learning), a framework for Text-to-SQL that enables models to interact with the database during decoding and dynamically adjust their reasoning based on execution feedback. ReEx-SQL introduces an execution-aware reasoning paradigm that interleaves intermediate SQL execution into reasoning paths, facilitating context-sensitive revisions. It achieves this through structured prompts with markup tags and a stepwise rollout strategy that integrates execution feedback into each stage of generation. To supervise policy learning, we develop a composite reward function that includes an exploration reward, explicitly encouraging effective database interaction. Additionally, ReEx-SQL adopts a tree-based decoding strategy to support exploratory reasoning, enabling dynamic expansion of alternative reasoning paths. Notably, ReEx-SQL achieves 88.8% on Spider and 64.9% on BIRD at the 7B scale, surpassing the standard reasoning baseline by 2.7% and 2.6%, respectively. It also shows robustness, achieving 85.2% on Spider-Realistic with leading performance. In addition, its tree-structured decoding improves efficiency and performance over linear decoding, reducing inference time by 51.9% on the BIRD development set.","authors":["Yaxun Dai (Soochow University)","Wenxuan Xie (South China University of Technology)","Xialie Zhuang (University of Chinese Academy of Sciences)","Tianyu Yang (Alibaba DAMO Academy)","Yiying Yang (Guangdong Laboratory of Artificial Intelligence and Digital Economy)","Haiqin Yang (International Digital Economy Academy)","Yuhang Zhao (Guangdong Laboratory of Artificial Intelligence and Digital Economy)","Pingfu Chao (Soochow University)","Wenhao Jiang (Guangdong Laboratory of Artificial Intelligence and Digital Economy)"],"url":"https://arxiv.org/abs/2505.12768"}
{"created":"2025-05-20","title":"Testing Access-Control Configuration Changes for Web Applications","abstract":"Access-control misconfigurations are among the main causes of today's data breaches in web applications. However, few techniques are available to support automatic and systematic testing for access-control changes and detecting risky changes to prevent severe consequences. As a result, those critical security configurations often lack testing, or are tested manually in an ad hoc way.","authors":["Chengcheng Xiang","Li Zhong","Eric Mugnier","Nathaniel Nguyen","Yuanyuan Zhou","Tianyin Xu"],"url":"https://arxiv.org/abs/2505.12770"}
{"created":"2025-05-20","title":"FireFly-T: High-Throughput Sparsity Exploitation for Spiking Transformer Acceleration with Dual-Engine Overlay Architecture","abstract":"Spiking transformers are emerging as a promising architecture that combines the energy efficiency of Spiking Neural Networks (SNNs) with the powerful attention mechanisms of transformers. However, existing hardware accelerators lack support for spiking attention, exhibit limited throughput in exploiting fine-grained sparsity, and struggle with scalable parallelism in sparse computation. To address these, we propose FireFly-T, a dual-engine overlay architecture that integrates a sparse engine for activation sparsity and a binary engine for spiking attention. In the sparse engine, we propose a highthroughput sparse decoder that exploits fine-grained sparsity by concurrently extracting multiple non-zero spikes. To complement this, we introduce a scalable load balancing mechanism with weight dispatch and out-of-order execution, eliminating bank conflicts to support scalable multidimensional parallelism. In the binary engine, we leverage the byte-level write capability of SRAMs to efficiently manipulate the 3D dataflows required for spiking attention with minimal resource overhead. We also optimize the core AND-PopCount operation in spiking attention through a LUT6-based implementation, improving timing closure and reducing LUT utilization on Xilinx FPGAs. As an overlay architecture, FireFly-T further incorporates an orchestrator that dynamically manipulates input dataflows with flexible adaptation for diverse network topologies, while ensuring efficient resource utilization and maintaining high throughput. Experimental results demonstrate that our accelerator achieves $1.39\\times$ and $2.40\\times$ higher energy efficiency, as well as $4.21\\times$ and $7.10\\times$ greater DSP efficiency, compared to FireFly v2 and the transformer-enabled SpikeTA, respectively. These results highlight its potential as an efficient hardware platform for spiking transformer.","authors":["Tenglong Li","Jindong Li","Guobin Shen","Dongcheng Zhao","Qian Zhang","Yi Zeng"],"url":"https://arxiv.org/abs/2505.12771"}
{"created":"2025-05-20","title":"Pyramid Sparse Transformer: Enhancing Multi-Scale Feature Fusion with Dynamic Token Selection","abstract":"Feature fusion is critical for high-performance vision models but often incurs prohibitive complexity. However, prevailing attention-based fusion methods often involve significant computational complexity and implementation challenges, limiting their efficiency in resource-constrained environments. To address these issues, we introduce the Pyramid Sparse Transformer (PST), a lightweight, plug-and-play module that integrates coarse-to-fine token selection and shared attention parameters to reduce computation while preserving spatial detail. PST can be trained using only coarse attention and seamlessly activated at inference for further accuracy gains without retraining. When added to state-of-the-art real-time detection models, such as YOLOv11-N/S/M, PST yields mAP improvements of 0.9%, 0.5%, and 0.4% on MS COCO with minimal latency impact. Likewise, embedding PST into ResNet-18/50/101 as backbones, boosts ImageNet top-1 accuracy by 6.5%, 1.7%, and 1.0%, respectively. These results demonstrate PST's effectiveness as a simple, hardware-friendly enhancement for both detection and classification tasks.","authors":["Junyi Hu","Tian Bai","Fengyi Wu","Zhengming Peng","Yi Zhang"],"url":"https://arxiv.org/abs/2505.12772"}
{"created":"2025-05-20","title":"UniHM: Universal Human Motion Generation with Object Interactions in Indoor Scenes","abstract":"Human motion synthesis in complex scenes presents a fundamental challenge, extending beyond conventional Text-to-Motion tasks by requiring the integration of diverse modalities such as static environments, movable objects, natural language prompts, and spatial waypoints. Existing language-conditioned motion models often struggle with scene-aware motion generation due to limitations in motion tokenization, which leads to information loss and fails to capture the continuous, context-dependent nature of 3D human movement. To address these issues, we propose UniHM, a unified motion language model that leverages diffusion-based generation for synthesizing scene-aware human motion. UniHM is the first framework to support both Text-to-Motion and Text-to-Human-Object Interaction (HOI) in complex 3D scenes. Our approach introduces three key contributions: (1) a mixed-motion representation that fuses continuous 6DoF motion with discrete local motion tokens to improve motion realism; (2) a novel Look-Up-Free Quantization VAE (LFQ-VAE) that surpasses traditional VQ-VAEs in both reconstruction accuracy and generative performance; and (3) an enriched version of the Lingo dataset augmented with HumanML3D annotations, providing stronger supervision for scene-specific motion learning. Experimental results demonstrate that UniHM achieves comparative performance on the OMOMO benchmark for text-to-HOI synthesis and yields competitive results on HumanML3D for general text-conditioned motion generation.","authors":["Zichen Geng","Zeeshan Hayder","Wei Liu","Ajmal Mian"],"url":"https://arxiv.org/abs/2505.12774"}
{"created":"2025-05-20","title":"Beyond Individual UX: Defining Group Experience(GX) as a New Paradigm for Group-centered AI","abstract":"Recent advancements in HCI and AI have predominantly centered on individual user experiences, often neglecting the emergent dynamics of group interactions. This provocation introduces Group Experience(GX) to capture the collective perceptual, emotional, and cognitive dimensions that arise when individuals interact in cohesive groups. We challenge the conventional Human-centered AI paradigm and propose Group-centered AI(GCAI) as a framework that actively mediates group dynamics, amplifies diverse voices, and fosters ethical collective decision-making. Drawing on social psychology, organizational behavior, and group dynamics, we outline a group-centered design approach that balances individual autonomy with collective interests while developing novel evaluative metrics. Our analysis emphasizes rethinking traditional methodologies that focus solely on individual outcomes and advocates for innovative strategies to capture group collaboration. We call on researchers to bridge the gap between micro-level experiences and macro-level impacts, ultimately enriching and transforming collaborative human interactions.","authors":["Soohwan Lee","Seoyeong Hwang","Kyungho Lee"],"url":"https://arxiv.org/abs/2505.12780"}
{"created":"2025-05-20","title":"A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low-Rank Clone","abstract":"Training high-performing Small Language Models (SLMs) remains costly, even with knowledge distillation and pruning from larger teacher models. Existing work often faces three key challenges: (1) information loss from hard pruning, (2) inefficient alignment of representations, and (3) underutilization of informative activations, particularly from Feed-Forward Networks (FFNs). To address these challenges, we introduce Low-Rank Clone (LRC), an efficient pre-training method that constructs SLMs aspiring to behavioral equivalence with strong teacher models. LRC trains a set of low-rank projection matrices that jointly enable soft pruning by compressing teacher weights, and activation clone by aligning student activations, including FFN signals, with those of the teacher. This unified design maximizes knowledge transfer while removing the need for explicit alignment modules. Extensive experiments with open-source teachers (e.g., Llama-3.2-3B-Instruct, Qwen2.5-3B/7B-Instruct) show that LRC matches or surpasses state-of-the-art models trained on trillions of tokens--while using only 20B tokens, achieving over 1,000x training efficiency. Our codes and model checkpoints are available at https://github.com/CURRENTF/LowRankClone and https://huggingface.co/collections/JitaiHao/low-rank-clone-lrc-6828389e96a93f1d4219dfaf.","authors":["Jitai Hao","Qiang Huang","Hao Liu","Xinyan Xiao","Zhaochun Ren","Jun Yu"],"url":"https://arxiv.org/abs/2505.12781"}
{"created":"2025-05-20","title":"AdaToken-3D: Dynamic Spatial Gating for Efficient 3D Large Multimodal-Models Reasoning","abstract":"Large Multimodal Models (LMMs) have become a pivotal research focus in deep learning, demonstrating remarkable capabilities in 3D scene understanding. However, current 3D LMMs employing thousands of spatial tokens for multimodal reasoning suffer from critical inefficiencies: excessive computational overhead and redundant information flows. Unlike 2D VLMs processing single images, 3D LMMs exhibit inherent architectural redundancy due to the heterogeneous mechanisms between spatial tokens and visual tokens. To address this challenge, we propose AdaToken-3D, an adaptive spatial token optimization framework that dynamically prunes redundant tokens through spatial contribution analysis. Our method automatically tailors pruning strategies to different 3D LMM architectures by quantifying token-level information flows via attention pattern mining. Extensive experiments on LLaVA-3D (a 7B parameter 3D-LMM) demonstrate that AdaToken-3D achieves 21\\% faster inference speed and 63\\% FLOPs reduction while maintaining original task accuracy. Beyond efficiency gains, this work systematically investigates redundancy patterns in multimodal spatial information flows through quantitative token interaction analysis. Our findings reveal that over 60\\% of spatial tokens contribute minimally ($<$5\\%) to the final predictions, establishing theoretical foundations for efficient 3D multimodal learning.","authors":["Kai Zhang","Xingyu Chen","Xiaofeng Zhang"],"url":"https://arxiv.org/abs/2505.12782"}
{"created":"2025-05-20","title":"Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks","abstract":"With the continuous evolution of Large Language Models (LLMs), LLM-based agents have advanced beyond passive chatbots to become autonomous cyber entities capable of performing complex tasks, including web browsing, malicious code and deceptive content generation, and decision-making. By significantly reducing the time, expertise, and resources, AI-assisted cyberattacks orchestrated by LLM-based agents have led to a phenomenon termed Cyber Threat Inflation, characterized by a significant reduction in attack costs and a tremendous increase in attack scale. To provide actionable defensive insights, in this survey, we focus on the potential cyber threats posed by LLM-based agents across diverse network systems. Firstly, we present the capabilities of LLM-based cyberattack agents, which include executing autonomous attack strategies, comprising scouting, memory, reasoning, and action, and facilitating collaborative operations with other agents or human operators. Building on these capabilities, we examine common cyberattacks initiated by LLM-based agents and compare their effectiveness across different types of networks, including static, mobile, and infrastructure-free paradigms. Moreover, we analyze threat bottlenecks of LLM-based agents across different network infrastructures and review their defense methods. Due to operational imbalances, existing defense methods are inadequate against autonomous cyberattacks. Finally, we outline future research directions and potential defensive strategies for legacy network systems.","authors":["Minrui Xu (Sherman)","Jiani Fan (Sherman)","Xinyu Huang (Sherman)","Conghao Zhou (Sherman)","Jiawen Kang (Sherman)","Dusit Niyato (Sherman)","Shiwen Mao (Sherman)","Zhu Han (Sherman)","Xuemin (Sherman)","Shen","Kwok-Yan Lam"],"url":"https://arxiv.org/abs/2505.12786"}
{"created":"2025-05-20","title":"Mixture Policy based Multi-Hop Reasoning over N-tuple Temporal Knowledge Graphs","abstract":"Temporal Knowledge Graphs (TKGs), which utilize quadruples in the form of (subject, predicate, object, timestamp) to describe temporal facts, have attracted extensive attention. N-tuple TKGs (N-TKGs) further extend traditional TKGs by utilizing n-tuples to incorporate auxiliary elements alongside core elements (i.e., subject, predicate, and object) of facts, so as to represent them in a more fine-grained manner. Reasoning over N-TKGs aims to predict potential future facts based on historical ones. However, existing N-TKG reasoning methods often lack explainability due to their black-box nature. Therefore, we introduce a new Reinforcement Learning-based method, named MT-Path, which leverages the temporal information to traverse historical n-tuples and construct a temporal reasoning path. Specifically, in order to integrate the information encapsulated within n-tuples, i.e., the entity-irrelevant information within the predicate, the information about core elements, and the complete information about the entire n-tuples, MT-Path utilizes a mixture policy-driven action selector, which bases on three low-level policies, namely, the predicate-focused policy, the core-element-focused policy and the whole-fact-focused policy. Further, MT-Path utilizes an auxiliary element-aware GCN to capture the rich semantic dependencies among facts, thereby enabling the agent to gain a deep understanding of each n-tuple. Experimental results demonstrate the effectiveness and the explainability of MT-Path.","authors":["Zhongni Hou","Miao Su","Xiaolong Jin","Zixuan Li","Long Bai","Jiafeng Guo","Xueqi Cheng"],"url":"https://arxiv.org/abs/2505.12788"}
{"created":"2025-05-20","title":"Enhancing Transformers Through Conditioned Embedded Tokens","abstract":"Transformers have transformed modern machine learning, driving breakthroughs in computer vision, natural language processing, and robotics. At the core of their success lies the attention mechanism, which enables the modeling of global dependencies among input tokens. However, we reveal that the attention block in transformers suffers from inherent ill-conditioning, which hampers gradient-based optimization and leads to inefficient training. To address this, we develop a theoretical framework that establishes a direct relationship between the conditioning of the attention block and that of the embedded tokenized data. Building on this insight, we introduce conditioned embedded tokens, a method that systematically modifies the embedded tokens to improve the conditioning of the attention mechanism. Our analysis demonstrates that this approach significantly mitigates ill-conditioning, leading to more stable and efficient training. We validate our methodology across various transformer architectures, achieving consistent improvements in image classification, object detection, instance segmentation, and natural language processing, highlighting its broad applicability and effectiveness.","authors":["Hemanth Saratchandran","Simon Lucey"],"url":"https://arxiv.org/abs/2505.12789"}
{"created":"2025-05-20","title":"Unlearning for Federated Online Learning to Rank: A Reproducibility Study","abstract":"This paper reports on findings from a comparative study on the effectiveness and efficiency of federated unlearning strategies within Federated Online Learning to Rank (FOLTR), with specific attention to systematically analysing the unlearning capabilities of methods in a verifiable manner.","authors":["Yiling Tao","Shuyi Wang","Jiaxi Yang","Guido Zuccon"],"url":"https://arxiv.org/abs/2505.12791"}
{"created":"2025-05-20","title":"EAVIT: Efficient and Accurate Human Value Identification from Text data via LLMs","abstract":"The rapid evolution of large language models (LLMs) has revolutionized various fields, including the identification and discovery of human values within text data. While traditional NLP models, such as BERT, have been employed for this task, their ability to represent textual data is significantly outperformed by emerging LLMs like GPTs. However, the performance of online LLMs often degrades when handling long contexts required for value identification, which also incurs substantial computational costs. To address these challenges, we propose EAVIT, an efficient and accurate framework for human value identification that combines the strengths of both locally fine-tunable and online black-box LLMs. Our framework employs a value detector - a small, local language model - to generate initial value estimations. These estimations are then used to construct concise input prompts for online LLMs, enabling accurate final value identification. To train the value detector, we introduce explanation-based training and data generation techniques specifically tailored for value identification, alongside sampling strategies to optimize the brevity of LLM input prompts. Our approach effectively reduces the number of input tokens by up to 1/6 compared to directly querying online LLMs, while consistently outperforming traditional NLP methods and other LLM-based strategies.","authors":["Wenhao Zhu","Yuhang Xie","Guojie Song","Xin Zhang"],"url":"https://arxiv.org/abs/2505.12792"}
{"created":"2025-05-20","title":"FRAbench and GenEval: Scaling Fine-Grained Aspect Evaluation across Tasks, Modalities","abstract":"Evaluating the open-ended outputs of large language models (LLMs) has become a bottleneck as model capabilities, task diversity, and modality coverage rapidly expand. Existing \"LLM-as-a-Judge\" evaluators are typically narrow in a few tasks, aspects, or modalities, and easily suffer from low consistency. In this paper, we argue that explicit, fine-grained aspect specification is the key to both generalizability and objectivity in automated evaluation. To do so, we introduce a hierarchical aspect taxonomy spanning 112 aspects that unifies evaluation across four representative settings - Natural Language Generation, Image Understanding, Image Generation, and Interleaved Text-and-Image Generation. Building on this taxonomy, we create FRAbench, a benchmark comprising 60.4k pairwise samples with 325k aspect-level labels obtained from a combination of human and LLM annotations. FRAbench provides the first large-scale, multi-modal resource for training and meta-evaluating fine-grained LMM judges. Leveraging FRAbench, we develop GenEval, a fine-grained evaluator generalizable across tasks and modalities. Experiments show that GenEval (i) attains high agreement with GPT-4o and expert annotators, (ii) transfers robustly to unseen tasks and modalities, and (iii) reveals systematic weaknesses of current LMMs on evaluation.","authors":["Shibo Hong","Jiahao Ying","Haiyuan Liang","Mengdi Zhang","Jun Kuang","Jiazheng Zhang","Yixin Cao"],"url":"https://arxiv.org/abs/2505.12795"}
{"created":"2025-05-20","title":"OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching","abstract":"Text-to-speech (TTS) systems have seen significant advancements in recent years, driven by improvements in deep learning and neural network architectures. Viewing the output speech as a data distribution, previous approaches often employ traditional speech representations, such as waveforms or spectrograms, within the Flow Matching framework. However, these methods have limitations, including overlooking various speech attributes and incurring high computational costs due to additional constraints introduced during training. To address these challenges, we introduce OZSpeech, the first TTS method to explore optimal transport conditional flow matching with one-step sampling and a learned prior as the condition, effectively disregarding preceding states and reducing the number of sampling steps. Our approach operates on disentangled, factorized components of speech in token format, enabling accurate modeling of each speech attribute, which enhances the TTS system's ability to precisely clone the prompt speech. Experimental results show that our method achieves promising performance over existing methods in content accuracy, naturalness, prosody generation, and speaker style preservation. Audio samples are available at our demo page https://ozspeech.github.io/OZSpeech_Web/.","authors":["Hieu-Nghia Huynh-Nguyen","Ngoc Son Nguyen","Huynh Nguyen Dang","Thieu Vo","Truong-Son Hy","Van Nguyen"],"url":"https://arxiv.org/abs/2505.12800"}
{"created":"2025-05-20","title":"Informed Mixing -- Improving Open Set Recognition via Attribution-based Augmentation","abstract":"Open set recognition (OSR) is devised to address the problem of detecting novel classes during model inference. Even in recent vision models, this remains an open issue which is receiving increasing attention. Thereby, a crucial challenge is to learn features that are relevant for unseen categories from given data, for which these features might not be discriminative. To facilitate this process and \"optimize to learn\" more diverse features, we propose GradMix, a data augmentation method that dynamically leverages gradient-based attribution maps of the model during training to mask out already learned concepts. Thus GradMix encourages the model to learn a more complete set of representative features from the same data source. Extensive experiments on open set recognition, close set classification, and out-of-distribution detection reveal that our method can often outperform the state-of-the-art. GradMix can further increase model robustness to corruptions as well as downstream classification performance for self-supervised learning, indicating its benefit for model generalization.","authors":["Jiawen Xu","Odej Kao","Margret Keuper"],"url":"https://arxiv.org/abs/2505.12803"}
{"created":"2025-05-20","title":"FedSVD: Adaptive Orthogonalization for Private Federated Learning with LoRA","abstract":"Low-Rank Adaptation (LoRA), which introduces a product of two trainable low-rank matrices into frozen pre-trained weights, is widely used for efficient fine-tuning of language models in federated learning (FL). However, when combined with differentially private stochastic gradient descent (DP-SGD), LoRA faces substantial noise amplification: DP-SGD perturbs per-sample gradients, and the matrix multiplication of the LoRA update ($BA$) intensifies this effect. Freezing one matrix (e.g., $A$) reduces the noise but restricts model expressiveness, often resulting in suboptimal adaptation. To address this, we propose FedSVD, a simple yet effective method that introduces a global reparameterization based on singular value decomposition (SVD). In our approach, each client optimizes only the $B$ matrix and transmits it to the server. The server aggregates the $B$ matrices, computes the product $BA$ using the previous $A$, and refactorizes the result via SVD. This yields a new adaptive $A$ composed of the orthonormal right singular vectors of $BA$, and an updated $B$ containing the remaining SVD components. This reparameterization avoids quadratic noise amplification, while allowing $A$ to better capture the principal directions of the aggregate updates. Moreover, the orthonormal structure of $A$ bounds the gradient norms of $B$ and preserves more signal under DP-SGD, as confirmed by our theoretical analysis. As a result, FedSVD consistently improves stability and performance across a variety of privacy settings and benchmarks, outperforming relevant baselines under both private and non-private regimes.","authors":["Seanie Lee","Sangwoo Park","Dong Bok Lee","Dominik Wagner","Haebin Seong","Tobias Bocklet","Juho Lee","Sung Ju Hwang"],"url":"https://arxiv.org/abs/2505.12805"}
{"created":"2025-05-20","title":"Decentralized Arena: Towards Democratic and Scalable Automatic Evaluation of Language Models","abstract":"The recent explosion of large language models (LLMs), each with its own general or specialized strengths, makes scalable, reliable benchmarking more urgent than ever. Standard practices nowadays face fundamental trade-offs: closed-ended question-based benchmarks (eg MMLU) struggle with saturation as newer models emerge, while crowd-sourced leaderboards (eg Chatbot Arena) rely on costly and slow human judges. Recently, automated methods (eg LLM-as-a-judge) shed light on the scalability, but risk bias by relying on one or a few \"authority\" models. To tackle these issues, we propose Decentralized Arena (dearena), a fully automated framework leveraging collective intelligence from all LLMs to evaluate each other. It mitigates single-model judge bias by democratic, pairwise evaluation, and remains efficient at scale through two key components: (1) a coarse-to-fine ranking algorithm for fast incremental insertion of new models with sub-quadratic complexity, and (2) an automatic question selection strategy for the construction of new evaluation dimensions. Across extensive experiments across 66 LLMs, dearena attains up to 97% correlation with human judgements, while significantly reducing the cost. Our code and data will be publicly released on https://github.com/maitrix-org/de-arena.","authors":["Yanbin Yin","Kun Zhou","Zhen Wang","Xiangdong Zhang","Yifei Shao","Shibo Hao","Yi Gu","Jieyuan Liu","Somanshu Singla","Tianyang Liu","Eric P. Xing","Zhengzhong Liu","Haojian Jin","Zhiting Hu"],"url":"https://arxiv.org/abs/2505.12808"}
{"created":"2025-05-20","title":"Koopman Autoencoders Learn Neural Representation Dynamics","abstract":"This paper explores a simple question: can we model the internal transformations of a neural network using dynamical systems theory? We introduce Koopman autoencoders to capture how neural representations evolve through network layers, treating these representations as states in a dynamical system. Our approach learns a surrogate model that predicts how neural representations transform from input to output, with two key advantages. First, by way of lifting the original states via an autoencoder, it operates in a linear space, making editing the dynamics straightforward. Second, it preserves the topologies of the original representations by regularizing the autoencoding objective. We demonstrate that these surrogate models naturally replicate the progressive topological simplification observed in neural networks. As a practical application, we show how our approach enables targeted class unlearning in the Yin-Yang and MNIST classification tasks.","authors":["Nishant Suresh Aswani","Saif Eddin Jabari"],"url":"https://arxiv.org/abs/2505.12809"}
{"created":"2025-05-20","title":"Dynamic Sight Range Selection in Multi-Agent Reinforcement Learning","abstract":"Multi-agent reinforcement Learning (MARL) is often challenged by the sight range dilemma, where agents either receive insufficient or excessive information from their environment. In this paper, we propose a novel method, called Dynamic Sight Range Selection (DSR), to address this issue. DSR utilizes an Upper Confidence Bound (UCB) algorithm and dynamically adjusts the sight range during training. Experiment results show several advantages of using DSR. First, we demonstrate using DSR achieves better performance in three common MARL environments, including Level-Based Foraging (LBF), Multi-Robot Warehouse (RWARE), and StarCraft Multi-Agent Challenge (SMAC). Second, our results show that DSR consistently improves performance across multiple MARL algorithms, including QMIX and MAPPO. Third, DSR offers suitable sight ranges for different training steps, thereby accelerating the training process. Finally, DSR provides additional interpretability by indicating the optimal sight range used during training. Unlike existing methods that rely on global information or communication mechanisms, our approach operates solely based on the individual sight ranges of agents. This approach offers a practical and efficient solution to the sight range dilemma, making it broadly applicable to real-world complex environments.","authors":["Wei-Chen Liao","Ti-Rong Wu","I-Chen Wu"],"url":"https://arxiv.org/abs/2505.12811"}
{"created":"2025-05-20","title":"Connecting the Equinoctial Elements and Rodrigues Parameters: A New Set of Elements","abstract":"A geometric interpretation of the equinoctial elements is given with a connection to orthogonal rotations and attitude dynamics in Euclidean 3-space. An identification is made between the equinoctial elements and classic Rodrigues parameters. A new set of equinoctial elements are developed using the modified Rodrigues parameters, thereby removing the coordinate singularity for retrograde equatorial orbits present in previous versions of these elements. A low-thrust trajectory optimization problem is set up using the new elements to numerically verify convergence for the two-point boundary problem, as compared to their predecessors.","authors":["Joseph T. A. Peterson","Vishala Arya","John L. Junkins"],"url":"https://arxiv.org/abs/2505.12812"}
{"created":"2025-05-20","title":"PsyMem: Fine-grained psychological alignment and Explicit Memory Control for Advanced Role-Playing LLMs","abstract":"Existing LLM-based role-playing methods often rely on superficial textual descriptions or simplistic metrics, inadequately modeling both intrinsic and extrinsic character dimensions. Additionally, they typically simulate character memory with implicit model knowledge or basic retrieval augment generation without explicit memory alignment, compromising memory consistency. The two issues weaken reliability of role-playing LLMs in several applications, such as trustworthy social simulation. To address these limitations, we propose PsyMem, a novel framework integrating fine-grained psychological attributes and explicit memory control for role-playing. PsyMem supplements textual descriptions with 26 psychological indicators to detailed model character. Additionally, PsyMem implements memory alignment training, explicitly trains the model to align character's response with memory, thereby enabling dynamic memory-controlled responding during inference. By training Qwen2.5-7B-Instruct on our specially designed dataset (including 5,414 characters and 38,962 dialogues extracted from novels), the resulting model, termed as PsyMem-Qwen, outperforms baseline models in role-playing, achieving the best performance in human-likeness and character fidelity.","authors":["Xilong Cheng","Yunxiao Qin","Yuting Tan","Zhengnan Li","Ye Wang","Hongjiang Xiao","Yuan Zhang"],"url":"https://arxiv.org/abs/2505.12814"}
{"created":"2025-05-20","title":"Learning in Chaos: Efficient Autoscaling and Self-healing for Distributed Training at the Edge","abstract":"Frequent node and link changes in edge AI clusters disrupt distributed training, while traditional checkpoint-based recovery and cloud-centric autoscaling are too slow for scale-out and ill-suited to chaotic and self-governed edge. This paper proposes Chaos, a resilient and scalable edge distributed training system with built-in self-healing and autoscaling. It speeds up scale-out by using multi-neighbor replication with fast shard scheduling, allowing a new node to pull the latest training state from nearby neighbors in parallel while balancing the traffic load between them. It also uses a cluster monitor to track resource and topology changes to assist scheduler decisions, and handles scaling events through peer negotiation protocols, enabling fully self-governed autoscaling without a central admin. Extensive experiments show that Chaos consistently achieves much lower scale-out delays than Pollux, EDL, and Autoscaling, and handles scale-in, connect-link, and disconnect-link events within 1 millisecond, making it smoother to handle node joins, exits, and failures. It also delivers the lowest idle time, showing superior resource use and scalability as the cluster grows.","authors":["Wenjiao Feng","Rongxing Xiao","Zonghang Li","Hongfang Yu","Gang Sun","Long Luo","Mohsen Guizani","Qirong Ho"],"url":"https://arxiv.org/abs/2505.12815"}
{"created":"2025-05-20","title":"Rethinking Features-Fused-Pyramid-Neck for Object Detection","abstract":"Multi-head detectors typically employ a features-fused-pyramid-neck for multi-scale detection and are widely adopted in the industry. However, this approach faces feature misalignment when representations from different hierarchical levels of the feature pyramid are forcibly fused point-to-point. To address this issue, we designed an independent hierarchy pyramid (IHP) architecture to evaluate the effectiveness of the features-unfused-pyramid-neck for multi-head detectors. Subsequently, we introduced soft nearest neighbor interpolation (SNI) with a weight downscaling factor to mitigate the impact of feature fusion at different hierarchies while preserving key textures. Furthermore, we present a features adaptive selection method for down sampling in extended spatial windows (ESD) to retain spatial features and enhance lightweight convolutional techniques (GSConvE). These advancements culminate in our secondary features alignment solution (SA) for real-time detection, achieving state-of-the-art results on Pascal VOC and MS COCO. Code will be released at https://github.com/AlanLi1997/rethinking-fpn. This paper has been accepted by ECCV2024 and published on Springer Nature.","authors":["Hulin Li"],"url":"https://arxiv.org/abs/2505.12820"}
{"created":"2025-05-20","title":"SynDec: A Synthesize-then-Decode Approach for Arbitrary Textual Style Transfer via Large Language Models","abstract":"Large Language Models (LLMs) are emerging as dominant forces for textual style transfer. However, for arbitrary style transfer, LLMs face two key challenges: (1) considerable reliance on manually-constructed prompts and (2) rigid stylistic biases inherent in LLMs. In this paper, we propose a novel Synthesize-then-Decode (SynDec) approach, which automatically synthesizes high-quality prompts and amplifies their roles during decoding process. Specifically, our approach synthesizes prompts by selecting representative few-shot samples, conducting a four-dimensional style analysis, and reranking the candidates. At LLM decoding stage, the TST effect is amplified by maximizing the contrast in output probabilities between scenarios with and without the synthesized prompt, as well as between prompts and negative samples. We conduct extensive experiments and the results show that SynDec outperforms existing state-of-the-art LLM-based methods on five out of six benchmarks (e.g., achieving up to a 9\\% increase in accuracy for modern-to-Elizabethan English transfer). Detailed ablation studies further validate the effectiveness of SynDec.","authors":["Han Sun","Zhen Sun","Zongmin Zhang","Linzhao Jia","Wei Shao","Min Zhang"],"url":"https://arxiv.org/abs/2505.12821"}
{"created":"2025-05-20","title":"Emergent Specialization: Rare Token Neurons in Language Models","abstract":"Large language models struggle with representing and generating rare tokens despite their importance in specialized domains. In this study, we identify neuron structures with exceptionally strong influence on language model's prediction of rare tokens, termed as rare token neurons, and investigate the mechanism for their emergence and behavior. These neurons exhibit a characteristic three-phase organization (plateau, power-law, and rapid decay) that emerges dynamically during training, evolving from a homogeneous initial state to a functionally differentiated architecture. In the activation space, rare token neurons form a coordinated subnetwork that selectively co-activates while avoiding co-activation with other neurons. This functional specialization potentially correlates with the development of heavy-tailed weight distributions, suggesting a statistical mechanical basis for emergent specialization.","authors":["Jing Liu","Haozheng Wang","Yueheng Li"],"url":"https://arxiv.org/abs/2505.12822"}
{"created":"2025-05-20","title":"The Modal Cube Revisited: Semantics without Worlds","abstract":"We present a non-deterministic semantic framework for all modal logics in the modal cube, extending prior works by Kearns and others. Our approach introduces modular and uniform multi-valued non-deterministic matrices (Nmatrices) for each logic, where necessitation is captured by the systematic use of level valuations. The semantics is grounded in an eight-valued system and provides a sound and complete decision procedure for each modal logic, extending and refining earlier semantics as particular cases. Additionally, we propose a novel model-theoretic perspective that links our framework to relational (Kripke-style) semantics, addressing longstanding conjectures regarding the correspondence between modal axioms and semantic conditions within non-deterministic settings. The result is a philosophically robust and technically modular alternative to standard possible-world semantics.","authors":["Renato Leme","Carlos Olarte","Elaine Pimentel","Marcelo E. Coniglio"],"url":"https://arxiv.org/abs/2505.12824"}
{"created":"2025-05-20","title":"Theoretical Investigation on Inductive Bias of Isolation Forest","abstract":"Isolation Forest (iForest) stands out as a widely-used unsupervised anomaly detector valued for its exceptional runtime efficiency and performance on large-scale tasks. Despite its widespread adoption, a theoretical foundation explaining iForest's success remains unclear. This paper theoretically investigates the conditions and extent of iForest's effectiveness by analyzing its inductive bias through the formulation of depth functions and growth processes. Since directly analyzing the depth function proves intractable due to iForest's random splitting mechanism, we model the growth process of iForest as a random walk, enabling us to derive the expected depth function using transition probabilities. Our case studies reveal key inductive biases: iForest exhibits lower sensitivity to central anomalies while demonstrating greater parameter adaptability compared to $k$-Nearest Neighbor anomaly detectors. Our study provides theoretical understanding of the effectiveness of iForest and establishes a foundation for further theoretical exploration.","authors":["Qin-Cheng Zheng","Shao-Qun Zhang","Shen-Huan Lyu","Yuan Jiang","Zhi-Hua Zhou"],"url":"https://arxiv.org/abs/2505.12825"}
{"created":"2025-05-20","title":"Mitigating Hallucination in VideoLLMs via Temporal-Aware Activation Engineering","abstract":"Multimodal large language models (MLLMs) have achieved remarkable progress in video understanding.However, hallucination, where the model generates plausible yet incorrect outputs, persists as a significant and under-addressed challenge in the video domain. Among existing solutions, activation engineering has proven successful in mitigating hallucinations in LLMs and ImageLLMs, yet its applicability to VideoLLMs remains largely unexplored. In this work, we are the first to systematically investigate the effectiveness and underlying mechanisms of activation engineering for mitigating hallucinations in VideoLLMs. We initially conduct an investigation of the key factors affecting the performance of activation engineering and find that a model's sensitivity to hallucination depends on $\\textbf{temporal variation}$ rather than task type. Moreover, selecting appropriate internal modules and dataset for activation engineering is critical for reducing hallucination. Guided by these findings, we propose a temporal-aware activation engineering framework for VideoLLMs, which adaptively identifies and manipulates hallucination-sensitive modules based on the temporal variation characteristic, substantially mitigating hallucinations without additional LLM fine-tuning. Experiments across multiple models and benchmarks demonstrate that our method markedly reduces hallucination in VideoLLMs, thereby validating the robustness of our findings.","authors":["Jianfeng Cai","Wengang Zhou","Zongmeng Zhang","Jiale Hong","Nianji Zhan","Houqiang Li"],"url":"https://arxiv.org/abs/2505.12826"}
{"created":"2025-05-20","title":"Practical Equivalence Testing and Its Application in Synthetic Pre-Crash Scenario Validation","abstract":"The use of representative pre-crash scenarios is critical for assessing the safety impact of driving automation systems through simulation. However, a gap remains in the robust evaluation of the similarity between synthetic and real-world pre-crash scenarios and their crash characteristics. Without proper validation, it cannot be ensured that the synthetic test scenarios adequately represent real-world driving behaviors and crash characteristics. One reason for this validation gap is the lack of focus on methods to confirm that the synthetic test scenarios are practically equivalent to real-world ones, given the assessment scope. Traditional statistical methods, like significance testing, focus on detecting differences rather than establishing equivalence; since failure to detect a difference does not imply equivalence, they are of limited applicability for validating synthetic pre-crash scenarios and crash characteristics. This study addresses this gap by proposing an equivalence testing method based on the Bayesian Region of Practical Equivalence (ROPE) framework. This method is designed to assess the practical equivalence of scenario characteristics that are most relevant for the intended assessment, making it particularly appropriate for the domain of virtual safety assessments. We first review existing equivalence testing methods. Then we propose and demonstrate the Bayesian ROPE-based method by testing the equivalence of two rear-end pre-crash datasets. Our approach focuses on the most relevant scenario characteristics. Our analysis provides insights into the practicalities and effectiveness of equivalence testing in synthetic test scenario validation and demonstrates the importance of testing for improving the credibility of synthetic data for automated vehicle safety assessment, as well as the credibility of subsequent safety impact assessments.","authors":["Jian Wu","Ulrich Sander","Carol Flannagan","Minxiang Zhao","Jonas B\\\"argman"],"url":"https://arxiv.org/abs/2505.12827"}
{"created":"2025-05-20","title":"2T1R Regulated Memristor Conductance Control Array Architecture for Neuromorphic Computing using 28nm CMOS Technology","abstract":"Memristors are promising devices for scalable and low power, in-memory computing to improve the energy efficiency of a rising computational demand. The crossbar array architecture with memristors is used for vector matrix multiplication (VMM) and acts as kernels in neuromorphic computing. The analog conductance control in a memristor is achieved by applying voltage or current through it. A basic 1T1R array is suitable to avoid sneak path issues but suffer from wire resistances, which affects the read and write procedures. A conductance control scheme with a regulated voltage source will improve the architecture and reduce the possible potential divider effects. A change in conductance is also possible with the provision of a regulated current source and measuring the voltage across the memristors. A regulated 2T1R memristor conductance control architecture is proposed in this work, which avoids the potential divider effect and virtual ground scenario in a regular crossbar scheme, as well as conductance control by passing a regulated current through memristors. The sneak path current is not allowed to pass by the provision of ground potential to both terminals of memristors.","authors":["Neethu Kuriakose (Central Institute of Engineering","Electronics and Analytics -- Electronic Systems)","Arun Ashok (Central Institute of Engineering","Electronics and Analytics -- Electronic Systems)","Christian Grewing (Central Institute of Engineering","Electronics and Analytics -- Electronic Systems)","Andr\\'e Zambanini (Central Institute of Engineering","Electronics and Analytics -- Electronic Systems)","Stefan van Waasen (Central Institute of Engineering","Electronics and Analytics -- Electronic Systems","Faculty of Engineering","Communication Systems","University of Duisburg-Essen","47057 Duisburg","Germany)"],"url":"https://arxiv.org/abs/2505.12830"}
{"created":"2025-05-20","title":"Contrastive Prompting Enhances Sentence Embeddings in LLMs through Inference-Time Steering","abstract":"Extracting sentence embeddings from large language models (LLMs) is a practical direction, as it requires neither additional data nor fine-tuning. Previous studies usually focus on prompt engineering to guide LLMs to encode the core semantic information of the sentence into the embedding of the last token. However, the last token in these methods still encodes an excess of non-essential information, such as stop words, limiting its encoding capacity. To this end, we propose a Contrastive Prompting (CP) method that introduces an extra auxiliary prompt to elicit better sentence embedding. By contrasting with the auxiliary prompt, CP can steer existing prompts to encode the core semantics of the sentence, rather than non-essential information. CP is a plug-and-play inference-time intervention method that can be combined with various prompt-based methods. Extensive experiments on Semantic Textual Similarity (STS) tasks and downstream classification tasks demonstrate that our method can improve the performance of existing prompt-based methods across different LLMs. Our code will be released at https://github.com/zifengcheng/CP.","authors":["Zifeng Cheng","Zhonghui Wang","Yuchen Fu","Zhiwei Jiang","Yafeng Yin","Cong Wang","Qing Gu"],"url":"https://arxiv.org/abs/2505.12831"}
{"created":"2025-05-20","title":"A Study on Distributed Strategies for Deep Learning Applications in GPU Clusters","abstract":"As deep learning models grow in size and complexity, training them efficiently on single GPUs becomes increasingly infeasible. This study investigates the effectiveness of several distributed training strategies-Distributed Data Parallel (DDP), Fully Sharded Data Parallelism (FSDP), and Parameter Server (PS) models-for scalable deep learning on GPU clusters. We conduct empirical evaluations across multiple models and datasets to assess trade-offs in memory usage, training time, GPU utilization, and model accuracy. Our results show that while FSDP reduces GPU memory usage by over 60%, it increases training time by up to 6x compared to DDP. In contrast, asynchronous PS training improves throughput but can lead to degraded accuracy due to stale updates. Through comprehensive analysis, we provide practical insights into the strengths and limitations of each strategy, offering guidance for selecting suitable methods based on system constraints and training objectives.","authors":["Md Sultanul Islam Ovi"],"url":"https://arxiv.org/abs/2505.12832"}
{"created":"2025-05-20","title":"Reasoning BO: Enhancing Bayesian Optimization with Long-Context Reasoning Power of LLMs","abstract":"Many real-world scientific and industrial applications require the optimization of expensive black-box functions. Bayesian Optimization (BO) provides an effective framework for such problems. However, traditional BO methods are prone to get trapped in local optima and often lack interpretable insights. To address this issue, this paper designs Reasoning BO, a novel framework that leverages reasoning models to guide the sampling process in BO while incorporating multi-agent systems and knowledge graphs for online knowledge accumulation. By integrating the reasoning and contextual understanding capabilities of Large Language Models (LLMs), we can provide strong guidance to enhance the BO process. As the optimization progresses, Reasoning BO provides real-time sampling recommendations along with critical insights grounded in plausible scientific theories, aiding in the discovery of superior solutions within the search space. We systematically evaluate our approach across 10 diverse tasks encompassing synthetic mathematical functions and complex real-world applications. The framework demonstrates its capability to progressively refine sampling strategies through real-time insights and hypothesis evolution, effectively identifying higher-performing regions of the search space for focused exploration. This process highlights the powerful reasoning and context-learning abilities of LLMs in optimization scenarios. For example, in the Direct Arylation task, our method increased the yield to 60.7%, whereas traditional BO achieved only a 25.2% yield. Furthermore, our investigation reveals that smaller LLMs, when fine-tuned through reinforcement learning, can attain comparable performance to their larger counterparts. This enhanced reasoning capability paves the way for more efficient automated scientific experimentation while maintaining computational feasibility.","authors":["Zhuo Yang","Lingli Ge","Dong Han","Tianfan Fu","Yuqiang Li"],"url":"https://arxiv.org/abs/2505.12833"}
{"created":"2025-05-20","title":"A Study on the Refining Handwritten Font by Mixing Font Styles","abstract":"Handwritten fonts have a distinct expressive character, but they are often difficult to read due to unclear or inconsistent handwriting. FontFusionGAN (FFGAN) is a novel method for improving handwritten fonts by combining them with printed fonts. Our method implements generative adversarial network (GAN) to generate font that mix the desirable features of handwritten and printed fonts. By training the GAN on a dataset of handwritten and printed fonts, it can generate legible and visually appealing font images. We apply our method to a dataset of handwritten fonts and demonstrate that it significantly enhances the readability of the original fonts while preserving their unique aesthetic. Our method has the potential to improve the readability of handwritten fonts, which would be helpful for a variety of applications including document creation, letter writing, and assisting individuals with reading and writing difficulties. In addition to addressing the difficulties of font creation for languages with complex character sets, our method is applicable to other text-image-related tasks, such as font attribute control and multilingual font style transfer.","authors":["Avinash Kumar","Kyeolhee Kang","Ammar ul Hassan","Jaeyoung Choi"],"url":"https://arxiv.org/abs/2505.12834"}
{"created":"2025-05-20","title":"FlightGPT: Towards Generalizable and Interpretable UAV Vision-and-Language Navigation with Vision-Language Models","abstract":"Unmanned Aerial Vehicle (UAV) Vision-and-Language Navigation (VLN) is vital for applications such as disaster response, logistics delivery, and urban inspection. However, existing methods often struggle with insufficient multimodal fusion, weak generalization, and poor interpretability. To address these challenges, we propose FlightGPT, a novel UAV VLN framework built upon Vision-Language Models (VLMs) with powerful multimodal perception capabilities. We design a two-stage training pipeline: first, Supervised Fine-Tuning (SFT) using high-quality demonstrations to improve initialization and structured reasoning; then, Group Relative Policy Optimization (GRPO) algorithm, guided by a composite reward that considers goal accuracy, reasoning quality, and format compliance, to enhance generalization and adaptability. Furthermore, FlightGPT introduces a Chain-of-Thought (CoT)-based reasoning mechanism to improve decision interpretability. Extensive experiments on the city-scale dataset CityNav demonstrate that FlightGPT achieves state-of-the-art performance across all scenarios, with a 9.22\\% higher success rate than the strongest baseline in unseen environments. Our implementation is publicly available.","authors":["Hengxing Cai","Jinhan Dong","Jingjun Tan","Jingcheng Deng","Sihang Li","Zhifeng Gao","Haidong Wang","Zicheng Su","Agachai Sumalee","Renxin Zhong"],"url":"https://arxiv.org/abs/2505.12835"}
{"created":"2025-05-20","title":"The Hidden Structure -- Improving Legal Document Understanding Through Explicit Text Formatting","abstract":"Legal contracts possess an inherent, semantically vital structure (e.g., sections, clauses) that is crucial for human comprehension but whose impact on LLM processing remains under-explored. This paper investigates the effects of explicit input text structure and prompt engineering on the performance of GPT-4o and GPT-4.1 on a legal question-answering task using an excerpt of the CUAD. We compare model exact-match accuracy across various input formats: well-structured plain-text (human-generated from CUAD), plain-text cleaned of line breaks, extracted plain-text from Azure OCR, plain-text extracted by GPT-4o Vision, and extracted (and interpreted) Markdown (MD) from GPT-4o Vision. To give an indication of the impact of possible prompt engineering, we assess the impact of shifting task instructions to the system prompt and explicitly informing the model about the structured nature of the input. Our findings reveal that GPT-4o demonstrates considerable robustness to variations in input structure, but lacks in overall performance. Conversely, GPT-4.1's performance is markedly sensitive; poorly structured inputs yield suboptimal results (but identical with GPT-4o), while well-structured formats (original CUAD text, GPT-4o Vision text and GPT-4o MD) improve exact-match accuracy by ~20 percentage points. Optimizing the system prompt to include task details and an advisory about structured input further elevates GPT-4.1's accuracy by an additional ~10-13 percentage points, with Markdown ultimately achieving the highest performance under these conditions (79 percentage points overall exact-match accuracy). This research empirically demonstrates that while newer models exhibit greater resilience, careful input structuring and strategic prompt design remain critical for optimizing the performance of LLMs, and can significantly affect outcomes in high-stakes legal applications.","authors":["Christian Braun","Alexander Lilienbeck","Daniel Mentjukov"],"url":"https://arxiv.org/abs/2505.12837"}
{"created":"2025-05-20","title":"Geometric Formalization of First-Order Stochastic Dominance in $N$ Dimensions: A Tractable Path to Multi-Dimensional Economic Decision Analysis","abstract":"This paper introduces and formally verifies a novel geometric framework for first-order stochastic dominance (FSD) in $N$ dimensions using the Lean 4 theorem prover. Traditional analytical approaches to multi-dimensional stochastic dominance rely heavily on complex measure theory and multivariate calculus, creating significant barriers to formalization in proof assistants. Our geometric approach characterizes $N$-dimensional FSD through direct comparison of survival probabilities in upper-right orthants, bypassing the need for complex integration theory. We formalize key definitions and prove the equivalence between traditional FSD requirements and our geometric characterization. This approach achieves a more tractable and intuitive path to formal verification while maintaining mathematical rigor. We demonstrate how this framework directly enables formal analysis of multi-dimensional economic problems in portfolio selection, risk management, and welfare analysis. The work establishes a foundation for further development of verified decision-making tools in economics and finance, particularly for high-stakes domains requiring rigorous guarantees.","authors":["Jingyuan Li"],"url":"https://arxiv.org/abs/2505.12840"}
{"created":"2025-05-20","title":"GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in GUI Agents","abstract":"Graphical user interface (GUI) agents have recently emerged as an intriguing paradigm for human-computer interaction, capable of automatically executing user instructions to operate intelligent terminal devices. However, when encountering out-of-distribution (OOD) instructions that violate environmental constraints or exceed the current capabilities of agents, GUI agents may suffer task breakdowns or even pose security threats. Therefore, effective OOD detection for GUI agents is essential. Traditional OOD detection methods perform suboptimally in this domain due to the complex embedding space and evolving GUI environments. In this work, we observe that the in-distribution input semantic space of GUI agents exhibits a clustering pattern with respect to the distance from the centroid. Based on the finding, we propose GEM, a novel method based on fitting a Gaussian mixture model over input embedding distances extracted from the GUI Agent that reflect its capability boundary. Evaluated on eight datasets spanning smartphones, computers, and web browsers, our method achieves an average accuracy improvement of 23.70\\% over the best-performing baseline. Analysis verifies the generalization ability of our method through experiments on nine different backbones. The codes are available at https://github.com/Wuzheng02/GEM-OODforGUIagents.","authors":["Zheng Wu","Pengzhou Cheng","Zongru Wu","Lingzhong Dong","Zhuosheng Zhang"],"url":"https://arxiv.org/abs/2505.12842"}
{"created":"2025-05-20","title":"Bias Fitting to Mitigate Length Bias of Reward Model in RLHF","abstract":"Reinforcement Learning from Human Feedback relies on reward models to align large language models with human preferences. However, RLHF often suffers from reward hacking, wherein policy learning exploits flaws in the trained reward model to maximize reward scores without genuinely aligning with human preferences. A significant example of such reward hacking is length bias, where reward models usually favor longer responses irrespective of actual response quality. Previous works on length bias have notable limitations, these approaches either mitigate bias without characterizing the bias form, or simply assume a linear length-reward relation. To accurately model the intricate nature of length bias and facilitate more effective bias mitigation, we propose FiMi-RM (Bias Fitting to Mitigate Length Bias of Reward Model in RLHF), a framework that autonomously learns and corrects underlying bias patterns. Our approach consists of three stages: First, we train a standard reward model which inherently contains length bias. Next, we deploy a lightweight fitting model to explicitly capture the non-linear relation between length and reward. Finally, we incorporate this learned relation into the reward model to debias. Experimental results demonstrate that FiMi-RM achieves a more balanced length-reward distribution. Furthermore, when applied to alignment algorithms, our debiased reward model improves length-controlled win rate and reduces verbosity without compromising its performance.","authors":["Kangwen Zhao","Jianfeng Cai","Jinhua Zhu","Ruopei Sun","Dongyun Xue","Wengang Zhou","Li Li","Houqiang Li"],"url":"https://arxiv.org/abs/2505.12843"}
{"created":"2025-05-20","title":"AGI-Elo: How Far Are We From Mastering A Task?","abstract":"As the field progresses toward Artificial General Intelligence (AGI), there is a pressing need for more comprehensive and insightful evaluation frameworks that go beyond aggregate performance metrics. This paper introduces a unified rating system that jointly models the difficulty of individual test cases and the competency of AI models (or humans) across vision, language, and action domains. Unlike existing metrics that focus solely on models, our approach allows for fine-grained, difficulty-aware evaluations through competitive interactions between models and tasks, capturing both the long-tail distribution of real-world challenges and the competency gap between current models and full task mastery. We validate the generalizability and robustness of our system through extensive experiments on multiple established datasets and models across distinct AGI domains. The resulting rating distributions offer novel perspectives and interpretable insights into task difficulty, model progression, and the outstanding challenges that remain on the path to achieving full AGI task mastery.","authors":["Shuo Sun","Yimin Zhao","Christina Dao Wen Lee","Jiawei Sun","Chengran Yuan","Zefan Huang","Dongen Li","Justin KW Yeoh","Alok Prakash","Thomas W. Malone","Marcelo H. Ang Jr"],"url":"https://arxiv.org/abs/2505.12844"}
{"created":"2025-05-20","title":"Multi-Level Aware Preference Learning: Enhancing RLHF for Complex Multi-Instruction Tasks","abstract":"RLHF has emerged as a predominant approach for aligning artificial intelligence systems with human preferences, demonstrating exceptional and measurable efficacy in instruction following tasks; however, it exhibits insufficient compliance capabilities when confronted with complex multi-instruction tasks. Conventional approaches rely heavily on human annotation or more sophisticated large language models, thereby introducing substantial resource expenditure or potential bias concerns. Meanwhile, alternative synthetic methods that augment standard preference datasets often compromise the model's semantic quality. Our research identifies a critical oversight in existing techniques, which predominantly focus on comparing responses while neglecting valuable latent signals embedded within prompt inputs, and which only focus on preference disparities at the intra-sample level, while neglecting to account for the inter-sample level preference differentials that exist among preference data. To leverage these previously neglected indicators, we propose a novel Multi-level Aware Preference Learning (MAPL) framework, capable of enhancing multi-instruction capabilities. Specifically, for any given response in original preference data pairs, we construct varied prompts with a preference relation under different conditions, in order to learn intra-sample level preference disparities. Furthermore, for any given original preference pair, we synthesize multi-instruction preference pairs to capture preference discrepancies at the inter-sample level. Building on the two datasets constructed above, we consequently devise two sophisticated training objective functions. Subsequently, our framework integrates seamlessly into both Reward Modeling and Direct Preference Optimization paradigms. Through rigorous evaluation across multiple benchmarks, we empirically validate the efficacy of our framework.","authors":["Ruopei Sun","Jianfeng Cai","Jinhua Zhu","Kangwen Zhao","Dongyun Xue","Wengang Zhou","Li Li","Houqiang Li"],"url":"https://arxiv.org/abs/2505.12845"}
{"created":"2025-05-20","title":"Accelerate TarFlow Sampling with GS-Jacobi Iteration","abstract":"Image generation models have achieved widespread applications. As an instance, the TarFlow model combines the transformer architecture with Normalizing Flow models, achieving state-of-the-art results on multiple benchmarks. However, due to the causal form of attention requiring sequential computation, TarFlow's sampling process is extremely slow. In this paper, we demonstrate that through a series of optimization strategies, TarFlow sampling can be greatly accelerated by using the Gauss-Seidel-Jacobi (abbreviated as GS-Jacobi) iteration method. Specifically, we find that blocks in the TarFlow model have varying importance: a small number of blocks play a major role in image generation tasks, while other blocks contribute relatively little; some blocks are sensitive to initial values and prone to numerical overflow, while others are relatively robust. Based on these two characteristics, we propose the Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM): CRM is used to identify whether a TarFlow block is \"simple\" (converges in few iterations) or \"tough\" (requires more iterations); IGM is used to evaluate whether the initial value of the iteration is good. Experiments on four TarFlow models demonstrate that GS-Jacobi sampling can significantly enhance sampling efficiency while maintaining the quality of generated images (measured by FID), achieving speed-ups of 4.53x in Img128cond, 5.32x in AFHQ, 2.96x in Img64uncond, and 2.51x in Img64cond without degrading FID scores or sample quality. Code and checkpoints are accessible on https://github.com/encoreus/GS-Jacobi_for_TarFlow","authors":["Ben Liu","Zhen Qin"],"url":"https://arxiv.org/abs/2505.12849"}
{"created":"2025-05-20","title":"FLTG: Byzantine-Robust Federated Learning via Angle-Based Defense and Non-IID-Aware Weighting","abstract":"Byzantine attacks during model aggregation in Federated Learning (FL) threaten training integrity by manipulating malicious clients' updates. Existing methods struggle with limited robustness under high malicious client ratios and sensitivity to non-i.i.d. data, leading to degraded accuracy. To address this, we propose FLTG, a novel aggregation algorithm integrating angle-based defense and dynamic reference selection. FLTG first filters clients via ReLU-clipped cosine similarity, leveraging a server-side clean dataset to exclude misaligned updates. It then dynamically selects a reference client based on the prior global model to mitigate non-i.i.d. bias, assigns aggregation weights inversely proportional to angular deviations, and normalizes update magnitudes to suppress malicious scaling. Evaluations across datasets of varying complexity under five classic attacks demonstrate FLTG's superiority over state-of-the-art methods under extreme bias scenarios and sustains robustness with a higher proportion(over 50%) of malicious clients.","authors":["Yanhua Wen","Lu Ai","Gang Liu","Chuang Li","Jianhao Wei"],"url":"https://arxiv.org/abs/2505.12851"}
{"created":"2025-05-20","title":"Optimization of Hybrid Quantum-Classical Algorithms","abstract":"Quantum computers do not run in isolation; rather, they are embedded in quantum-classical hybrid architectures. In these setups, a quantum processing unit communicates with a classical device in near-real time. To enable efficient hybrid computations, it is mandatory to optimize quantum-classical hybrid code. To the best of our knowledge, no previous work on the optimization of hybrid code nor on metrics for which to optimize such code exists.","authors":["Lian Remme","Alexander Weinert","Andre Waschk"],"url":"https://arxiv.org/abs/2505.12853"}
{"created":"2025-05-20","title":"The Way Up: A Dataset for Hold Usage Detection in Sport Climbing","abstract":"Detecting an athlete's position on a route and identifying hold usage are crucial in various climbing-related applications. However, no climbing dataset with detailed hold usage annotations exists to our knowledge. To address this issue, we introduce a dataset of 22 annotated climbing videos, providing ground-truth labels for hold locations, usage order, and time of use. Furthermore, we explore the application of keypoint-based 2D pose-estimation models for detecting hold usage in sport climbing. We determine usage by analyzing the key points of certain joints and the corresponding overlap with climbing holds. We evaluate multiple state-of-the-art models and analyze their accuracy on our dataset, identifying and highlighting climbing-specific challenges. Our dataset and results highlight key challenges in climbing-specific pose estimation and establish a foundation for future research toward AI-assisted systems for sports climbing.","authors":["Anna Maschek","David C. Schedl"],"url":"https://arxiv.org/abs/2505.12854"}
{"created":"2025-05-20","title":"Addressing memory bandwidth scalability in vector processors for streaming applications","abstract":"As the size of artificial intelligence and machine learning (AI/ML) models and datasets grows, the memory bandwidth becomes a critical bottleneck. The paper presents a novel extended memory hierarchy that addresses some major memory bandwidth challenges in data-parallel AI/ML applications. While data-parallel architectures like GPUs and neural network accelerators have improved power performance compared to traditional CPUs, they can still be significantly bottlenecked by their memory bandwidth, especially when the data reuse in the loop kernels is limited. Systolic arrays (SAs) and GPUs attempt to mitigate the memory bandwidth bottleneck but can still become memory bandwidth throttled when the amount of data reuse is not sufficient to confine data access mostly to the local memories near to the processing. To mitigate this, the proposed architecture introduces three levels of on-chip memory -- local, intermediate, and global -- with an ultra-wide register and data-shufflers to improve versatility and adaptivity to varying data-parallel applications. The paper explains the innovations at a conceptual level and presents a detailed description of the architecture innovations. We also map a representative data-parallel application, like a convolutional neural network (CNN), to the proposed architecture and quantify the benefits vis-a-vis GPUs and repersentative accelerators based on systolic arrays and vector processors.","authors":["Jordi Altayo","Paul Delestrac","David Novo","Simey Yang","Debjyoti Bhattacharjee","Francky Catthoor"],"url":"https://arxiv.org/abs/2505.12856"}
{"created":"2025-05-20","title":"Re-identification of De-identified Documents with Autoregressive Infilling","abstract":"Documents revealing sensitive information about individuals must typically be de-identified. This de-identification is often done by masking all mentions of personally identifiable information (PII), thereby making it more difficult to uncover the identity of the person(s) in question. To investigate the robustness of de-identification methods, we present a novel, RAG-inspired approach that attempts the reverse process of re-identification based on a database of documents representing background knowledge. Given a text in which personal identifiers have been masked, the re-identification proceeds in two steps. A retriever first selects from the background knowledge passages deemed relevant for the re-identification. Those passages are then provided to an infilling model which seeks to infer the original content of each text span. This process is repeated until all masked spans are replaced. We evaluate the re-identification on three datasets (Wikipedia biographies, court rulings and clinical notes). Results show that (1) as many as 80% of de-identified text spans can be successfully recovered and (2) the re-identification accuracy increases along with the level of background knowledge.","authors":["Lucas Georges Gabriel Charpentier","Pierre Lison"],"url":"https://arxiv.org/abs/2505.12859"}
{"created":"2025-05-20","title":"Towards a Universal Image Degradation Model via Content-Degradation Disentanglement","abstract":"Image degradation synthesis is highly desirable in a wide variety of applications ranging from image restoration to simulating artistic effects. Existing models are designed to generate one specific or a narrow set of degradations, which often require user-provided degradation parameters. As a result, they lack the generalizability to synthesize degradations beyond their initial design or adapt to other applications. Here we propose the first universal degradation model that can synthesize a broad spectrum of complex and realistic degradations containing both homogeneous (global) and inhomogeneous (spatially varying) components. Our model automatically extracts and disentangles homogeneous and inhomogeneous degradation features, which are later used for degradation synthesis without user intervention. A disentangle-by-compression method is proposed to separate degradation information from images. Two novel modules for extracting and incorporating inhomogeneous degradations are created to model inhomogeneous components in complex degradations. We demonstrate the model's accuracy and adaptability in film-grain simulation and blind image restoration tasks. The demo video, code, and dataset of this project will be released upon publication at github.com/yangwenbo99/content-degradation-disentanglement.","authors":["Wenbo Yang","Zhongling Wang","Zhou Wang"],"url":"https://arxiv.org/abs/2505.12860"}
{"created":"2025-05-20","title":"Robust Multimodal Segmentation with Representation Regularization and Hybrid Prototype Distillation","abstract":"Multi-modal semantic segmentation (MMSS) faces significant challenges in real-world scenarios due to dynamic environments, sensor failures, and noise interference, creating a gap between theoretical models and practical performance. To address this, we propose a two-stage framework called RobustSeg, which enhances multi-modal robustness through two key components: the Hybrid Prototype Distillation Module (HPDM) and the Representation Regularization Module (RRM). In the first stage, RobustSeg pre-trains a multi-modal teacher model using complete modalities. In the second stage, a student model is trained with random modality dropout while learning from the teacher via HPDM and RRM. HPDM transforms features into compact prototypes, enabling cross-modal hybrid knowledge distillation and mitigating bias from missing modalities. RRM reduces representation discrepancies between the teacher and student by optimizing functional entropy through the log-Sobolev inequality. Extensive experiments on three public benchmarks demonstrate that RobustSeg outperforms previous state-of-the-art methods, achieving improvements of +2.76%, +4.56%, and +0.98%, respectively. Code is available at: https://github.com/RobustSeg/RobustSeg.","authors":["Jiaqi Tan","Xu Zheng","Yang Liu"],"url":"https://arxiv.org/abs/2505.12861"}
{"created":"2025-05-20","title":"Scheduling of Flexible Manufacturing Systems Based on Place-Timed Petri Nets and Basis Reachability Graphs","abstract":"Scheduling is a key decision-making process to improve the performance of flexible manufacturing systems. Place-timed Petri nets provide a formal method for graphically modeling and analyzing such systems. By generating reachability graphs and combining intelligent search algorithms, operation sequences from the initial state to the target state can be found for the underlying system. However, the reachability graph grows exponentially with the system size increases, which is the main challenge of existing methods for scheduling large systems. To this end, we develop an efficient improved beam search algorithm to optimize the makespan based on a compact representation of reachability graph called basis reachability graph. The key idea behind the proposed method is to form a state together with the basis markings and its corresponding transition sequences, and evaluate the cost of the state based on the resource idle time. Experimental results are conducted on several benchmark systems which show that the developed method improves the search efficiency while ensuring the quality of the solution compared with existing methods.","authors":["Zhou He","Ning Li","Ning Ran","Liang Li"],"url":"https://arxiv.org/abs/2505.12862"}
{"created":"2025-05-20","title":"Unified Cross-modal Translation of Score Images, Symbolic Music, and Performance Audio","abstract":"Music exists in various modalities, such as score images, symbolic scores, MIDI, and audio. Translations between each modality are established as core tasks of music information retrieval, such as automatic music transcription (audio-to-MIDI) and optical music recognition (score image to symbolic score). However, most past work on multimodal translation trains specialized models on individual translation tasks. In this paper, we propose a unified approach, where we train a general-purpose model on many translation tasks simultaneously. Two key factors make this unified approach viable: a new large-scale dataset and the tokenization of each modality. Firstly, we propose a new dataset that consists of more than 1,300 hours of paired audio-score image data collected from YouTube videos, which is an order of magnitude larger than any existing music modal translation datasets. Secondly, our unified tokenization framework discretizes score images, audio, MIDI, and MusicXML into a sequence of tokens, enabling a single encoder-decoder Transformer to tackle multiple cross-modal translation as one coherent sequence-to-sequence task. Experimental results confirm that our unified multitask model improves upon single-task baselines in several key areas, notably reducing the symbol error rate for optical music recognition from 24.58% to a state-of-the-art 13.67%, while similarly substantial improvements are observed across the other translation tasks. Notably, our approach achieves the first successful score-image-conditioned audio generation, marking a significant breakthrough in cross-modal music generation.","authors":["Jongmin Jung","Dongmin Kim","Sihun Lee","Seola Cho","Hyungjoon Soh","Irmak Bukey","Chris Donahue","Dasaem Jeong"],"url":"https://arxiv.org/abs/2505.12863"}
{"created":"2025-05-20","title":"LEXam: Benchmarking Legal Reasoning on 340 Law Exams","abstract":"Long-form legal reasoning remains a key challenge for large language models (LLMs) in spite of recent advances in test-time scaling. We introduce LEXam, a novel benchmark derived from 340 law exams spanning 116 law school courses across a range of subjects and degree levels. The dataset comprises 4,886 law exam questions in English and German, including 2,841 long-form, open-ended questions and 2,045 multiple-choice questions. Besides reference answers, the open questions are also accompanied by explicit guidance outlining the expected legal reasoning approach such as issue spotting, rule recall, or rule application. Our evaluation on both open-ended and multiple-choice questions present significant challenges for current LLMs; in particular, they notably struggle with open questions that require structured, multi-step legal reasoning. Moreover, our results underscore the effectiveness of the dataset in differentiating between models with varying capabilities. Adopting an LLM-as-a-Judge paradigm with rigorous human expert validation, we demonstrate how model-generated reasoning steps can be evaluated consistently and accurately. Our evaluation setup provides a scalable method to assess legal reasoning quality beyond simple accuracy metrics. Project page: https://lexam-benchmark.github.io/","authors":["Yu Fan","Jingwei Ni","Jakob Merane","Etienne Salimbeni","Yang Tian","Yoan Hermstr\\\"uwer","Yinya Huang","Mubashara Akhtar","Florian Geering","Oliver Dreyer","Daniel Brunner","Markus Leippold","Mrinmaya Sachan","Alexander Stremitzer","Christoph Engel","Elliott Ash","Joel Niklaus"],"url":"https://arxiv.org/abs/2505.12864"}
{"created":"2025-05-20","title":"Outsourced Privacy-Preserving Feature Selection Based on Fully Homomorphic Encryption","abstract":"Feature selection is a technique that extracts a meaningful subset from a set of features in training data. When the training data is large-scale, appropriate feature selection enables the removal of redundant features, which can improve generalization performance, accelerate the training process, and enhance the interpretability of the model. This study proposes a privacy-preserving computation model for feature selection. Generally, when the data owner and analyst are the same, there is no need to conceal the private information. However, when they are different parties or when multiple owners exist, an appropriate privacy-preserving framework is required. Although various private feature selection algorithms, they all require two or more computing parties and do not guarantee security in environments where no external party can be fully trusted. To address this issue, we propose the first outsourcing algorithm for feature selection using fully homomorphic encryption. Compared to a prior two-party algorithm, our result improves the time and space complexity O(kn^2) to O(kn log^3 n) and O(kn), where k and n denote the number of features and data samples, respectively. We also implemented the proposed algorithm and conducted comparative experiments with the naive one. The experimental result shows the efficiency of our method even with small datasets.","authors":["Koki Wakiyama","Tomohiro I","Hiroshi Sakamoto"],"url":"https://arxiv.org/abs/2505.12869"}
{"created":"2025-05-20","title":"Does Low Rank Adaptation Lead to Lower Robustness against Training-Time Attacks?","abstract":"Low rank adaptation (LoRA) has emerged as a prominent technique for fine-tuning large language models (LLMs) thanks to its superb efficiency gains over previous methods. While extensive studies have examined the performance and structural properties of LoRA, its behavior upon training-time attacks remain underexplored, posing significant security risks. In this paper, we theoretically investigate the security implications of LoRA's low-rank structure during fine-tuning, in the context of its robustness against data poisoning and backdoor attacks. We propose an analytical framework that models LoRA's training dynamics, employs the neural tangent kernel to simplify the analysis of the training process, and applies information theory to establish connections between LoRA's low rank structure and its vulnerability against training-time attacks. Our analysis indicates that LoRA exhibits better robustness to backdoor attacks than full fine-tuning, while becomes more vulnerable to untargeted data poisoning due to its over-simplified information geometry. Extensive experimental evaluations have corroborated our theoretical findings.","authors":["Zi Liang","Haibo Hu","Qingqing Ye","Yaxin Xiao","Ronghua Li"],"url":"https://arxiv.org/abs/2505.12871"}
{"created":"2025-05-20","title":"From Grunts to Grammar: Emergent Language from Cooperative Foraging","abstract":"Early cavemen relied on gestures, vocalizations, and simple signals to coordinate, plan, avoid predators, and share resources. Today, humans collaborate using complex languages to achieve remarkable results. What drives this evolution in communication? How does language emerge, adapt, and become vital for teamwork? Understanding the origins of language remains a challenge. A leading hypothesis in linguistics and anthropology posits that language evolved to meet the ecological and social demands of early human cooperation. Language did not arise in isolation, but through shared survival goals. Inspired by this view, we investigate the emergence of language in multi-agent Foraging Games. These environments are designed to reflect the cognitive and ecological constraints believed to have influenced the evolution of communication. Agents operate in a shared grid world with only partial knowledge about other agents and the environment, and must coordinate to complete games like picking up high-value targets or executing temporally ordered actions. Using end-to-end deep reinforcement learning, agents learn both actions and communication strategies from scratch. We find that agents develop communication protocols with hallmark features of natural language: arbitrariness, interchangeability, displacement, cultural transmission, and compositionality. We quantify each property and analyze how different factors, such as population size and temporal dependencies, shape specific aspects of the emergent language. Our framework serves as a platform for studying how language can evolve from partial observability, temporal reasoning, and cooperative goals in embodied multi-agent settings. We will release all data, code, and models publicly.","authors":["Maytus Piriyajitakonkij","Rujikorn Charakorn","Weicheng Tao","Wei Pan","Mingfei Sun","Cheston Tan","Mengmi Zhang"],"url":"https://arxiv.org/abs/2505.12872"}
{"created":"2025-05-20","title":"NEAT: QCP: A Practical Separation Logic-based C Program Verification Tool","abstract":"As software systems increase in size and complexity dramatically, ensuring their correctness, security, and reliability becomes an increasingly formidable challenge. Despite significant advancements in verification techniques and tools, there still remain %these tools still continue to encounter substantial difficulties when applying these tools to complex, real-world scenarios. To address these difficulties, this paper introduces a novel verification tool, called \\textbf{Qualified C Programming Verifier (QCP)}. QCP incorporates a refined front-end %syntax of assertion language to enhance user interaction. The proposed assertion language aims to %syntax is designed to lower the entry barrier for verification tools, improve proof efficiency by improving automation, and facilitate a deeper understanding of both the program and its verification results.","authors":["Xiwei Wu","Yueyang Feng","Xiaoyang Lu","Tianchuan Lin","Kan Liu","Zhiyi Wang","Shushu Wu","Lihan Xie","Chengxi Yang","Hongyi Zhong","Naijun Zhan","Zhenjiang Hu","Qinxiang Cao"],"url":"https://arxiv.org/abs/2505.12878"}
{"created":"2025-05-20","title":"AdS-GNN -- a Conformally Equivariant Graph Neural Network","abstract":"Conformal symmetries, i.e.\\ coordinate transformations that preserve angles, play a key role in many fields, including physics, mathematics, computer vision and (geometric) machine learning. Here we build a neural network that is equivariant under general conformal transformations. To achieve this, we lift data from flat Euclidean space to Anti de Sitter (AdS) space. This allows us to exploit a known correspondence between conformal transformations of flat space and isometric transformations on the AdS space. We then build upon the fact that such isometric transformations have been extensively studied on general geometries in the geometric deep learning literature. We employ message-passing layers conditioned on the proper distance, yielding a computationally efficient framework. We validate our model on tasks from computer vision and statistical physics, demonstrating strong performance, improved generalization capacities, and the ability to extract conformal data such as scaling dimensions from the trained network.","authors":["Maksim Zhdanov","Nabil Iqbal","Erik Bekkers","Patrick Forr\\'e"],"url":"https://arxiv.org/abs/2505.12880"}
{"created":"2025-05-20","title":"PhyDA: Physics-Guided Diffusion Models for Data Assimilation in Atmospheric Systems","abstract":"Data Assimilation (DA) plays a critical role in atmospheric science by reconstructing spatially continous estimates of the system state, which serves as initial conditions for scientific analysis. While recent advances in diffusion models have shown great potential for DA tasks, most existing approaches remain purely data-driven and often overlook the physical laws that govern complex atmospheric dynamics. As a result, they may yield physically inconsistent reconstructions that impair downstream applications. To overcome this limitation, we propose PhyDA, a physics-guided diffusion framework designed to ensure physical coherence in atmospheric data assimilation. PhyDA introduces two key components: (1) a Physically Regularized Diffusion Objective that integrates physical constraints into the training process by penalizing deviations from known physical laws expressed as partial differential equations, and (2) a Virtual Reconstruction Encoder that bridges observational sparsity for structured latent representations, further enhancing the model's ability to infer complete and physically coherent states. Experiments on the ERA5 reanalysis dataset demonstrate that PhyDA achieves superior accuracy and better physical plausibility compared to state-of-the-art baselines. Our results emphasize the importance of combining generative modeling with domain-specific physical knowledge and show that PhyDA offers a promising direction for improving real-world data assimilation systems.","authors":["Hao Wang","Jindong Han","Wei Fan","Weijia Zhang","Hao Liu"],"url":"https://arxiv.org/abs/2505.12882"}
{"created":"2025-05-20","title":"Implicit numerical approximation for stochastic delay differential equations with the nonlinear diffusion term in the infinite horizon","abstract":"This paper investigates the approximation of stochastic delay differential equations (SDDEs) via the backward Euler-Maruyama (BEM) method under generalized monotonicity and Khasminskii-type conditions in the infinite horizon. First, by establishing the uniform moment boundedness and finite-time strong convergence of the BEM method, we prove that for sufficiently small step sizes, the numerical approximations strongly converge to the underlying solution in the infinite horizon with a rate of $1/2$, which coincides with the optimal finite-time strong convergence rate.","authors":["Yudong Wang","Hongjiong Tian"],"url":"https://arxiv.org/abs/2505.12883"}
{"created":"2025-05-20","title":"TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks","abstract":"Lightweight Vision-Language Models (VLMs) are indispensable for resource-constrained applications. The prevailing approach to aligning vision and language models involves freezing both the vision encoder and the language model while training small connector modules. However, this strategy heavily depends on the intrinsic capabilities of the language model, which can be suboptimal for lightweight models with limited representational capacity. In this work, we investigate this alignment bottleneck through the lens of mutual information, demonstrating that the constrained capacity of the language model inherently limits the Effective Mutual Information (EMI) between multimodal inputs and outputs, thereby compromising alignment quality. To address this challenge, we propose TinyAlign, a novel framework inspired by Retrieval-Augmented Generation, which strategically retrieves relevant context from a memory bank to enrich multimodal inputs and enhance their alignment. Extensive empirical evaluations reveal that TinyAlign significantly reduces training loss, accelerates convergence, and enhances task performance. Remarkably, it allows models to achieve baseline-level performance with only 40\\% of the fine-tuning data, highlighting exceptional data efficiency. Our work thus offers a practical pathway for developing more capable lightweight VLMs while introducing a fresh theoretical lens to better understand and address alignment bottlenecks in constrained multimodal systems.","authors":["Yuanze Hu","Zhaoxin Fan","Xinyu Wang","Gen Li","Ye Qiu","Zhichao Yang","Wenjun Wu","Kejian Wu","Yifan Sun","Xiaotie Deng","Jin Dong"],"url":"https://arxiv.org/abs/2505.12884"}
{"created":"2025-05-20","title":"Effects of the Auto-Correlation of Delays on the Age of Information: A Gaussian Process Framework","abstract":"The age of information (AoI) has been studied actively in recent years as a performance measure for systems that require real-time performance, such as remote monitoring systems via communication networks. The theoretical analysis of the AoI is usually formulated based on explicit system modeling, such as a single-server queueing model. However, in general, the behavior of large-scale systems such as communication networks is complex, and it is usually difficult to express the delay using simple queueing models. In this paper, we consider a framework in which the sequence of delays is composed from a non-negative continuous-time stochastic process, called a virtual delay process, as a new modeling approach for the theoretical analysis of the AoI. Under such a framework, we derive an expression for the transient probability distribution of the AoI and further apply the theory of stochastic orders to prove that the high dependence of the sequence of delays leads to the degradation of AoI performance. We further consider a special case in which the sequence of delays is generated from a stationary Gaussian process, and we discuss the sensitivity of the AoI to second-order statistics of the delay process through numerical experiments.","authors":["Atsushi Inoie","Yoshiaki Inoue"],"url":"https://arxiv.org/abs/2505.12885"}
{"created":"2025-05-20","title":"Detection and Mitigation of Hallucination in Large Reasoning Models: A Mechanistic Perspective","abstract":"Large Reasoning Models (LRMs) have shown impressive capabilities in multi-step reasoning tasks. However, alongside these successes, a more deceptive form of model error has emerged--Reasoning Hallucination--where logically coherent but factually incorrect reasoning traces lead to persuasive yet faulty conclusions. Unlike traditional hallucinations, these errors are embedded within structured reasoning, making them more difficult to detect and potentially more harmful. In this work, we investigate reasoning hallucinations from a mechanistic perspective. We propose the Reasoning Score, which quantifies the depth of reasoning by measuring the divergence between logits obtained from projecting late layers of LRMs to the vocabulary space, effectively distinguishing shallow pattern-matching from genuine deep reasoning. Using this score, we conduct an in-depth analysis on the ReTruthQA dataset and identify two key reasoning hallucination patterns: early-stage fluctuation in reasoning depth and incorrect backtracking to flawed prior steps. These insights motivate our Reasoning Hallucination Detection (RHD) framework, which achieves state-of-the-art performance across multiple domains. To mitigate reasoning hallucinations, we further introduce GRPO-R, an enhanced reinforcement learning algorithm that incorporates step-level deep reasoning rewards via potential-based shaping. Our theoretical analysis establishes stronger generalization guarantees, and experiments demonstrate improved reasoning quality and reduced hallucination rates.","authors":["Zhongxiang Sun","Qipeng Wang","Haoyu Wang","Xiao Zhang","Jun Xu"],"url":"https://arxiv.org/abs/2505.12886"}
{"created":"2025-05-20","title":"GAP: Graph-Assisted Prompts for Dialogue-based Medication Recommendation","abstract":"Medication recommendations have become an important task in the healthcare domain, especially in measuring the accuracy and safety of medical dialogue systems (MDS). Different from the recommendation task based on electronic health records (EHRs), dialogue-based medication recommendations require research on the interaction details between patients and doctors, which is crucial but may not exist in EHRs. Recent advancements in large language models (LLM) have extended the medical dialogue domain. These LLMs can interpret patients' intent and provide medical suggestions including medication recommendations, but some challenges are still worth attention. During a multi-turn dialogue, LLMs may ignore the fine-grained medical information or connections across the dialogue turns, which is vital for providing accurate suggestions. Besides, LLMs may generate non-factual responses when there is a lack of domain-specific knowledge, which is more risky in the medical domain. To address these challenges, we propose a \\textbf{G}raph-\\textbf{A}ssisted \\textbf{P}rompts (\\textbf{GAP}) framework for dialogue-based medication recommendation. It extracts medical concepts and corresponding states from dialogue to construct an explicitly patient-centric graph, which can describe the neglected but important information. Further, combined with external medical knowledge graphs, GAP can generate abundant queries and prompts, thus retrieving information from multiple sources to reduce the non-factual responses. We evaluate GAP on a dialogue-based medication recommendation dataset and further explore its potential in a more difficult scenario, dynamically diagnostic interviewing. Extensive experiments demonstrate its competitive performance when compared with strong baselines.","authors":["Jialun Zhong","Yanzeng Li","Sen Hu","Yang Zhang","Teng Xu","Lei Zou"],"url":"https://arxiv.org/abs/2505.12888"}
{"created":"2025-05-20","title":"ORQA: A Benchmark and Foundation Model for Holistic Operating Room Modeling","abstract":"The real-world complexity of surgeries necessitates surgeons to have deep and holistic comprehension to ensure precision, safety, and effective interventions. Computational systems are required to have a similar level of comprehension within the operating room. Prior works, limited to single-task efforts like phase recognition or scene graph generation, lack scope and generalizability. In this work, we introduce ORQA, a novel OR question answering benchmark and foundational multimodal model to advance OR intelligence. By unifying all four public OR datasets into a comprehensive benchmark, we enable our approach to concurrently address a diverse range of OR challenges. The proposed multimodal large language model fuses diverse OR signals such as visual, auditory, and structured data, for a holistic modeling of the OR. Finally, we propose a novel, progressive knowledge distillation paradigm, to generate a family of models optimized for different speed and memory requirements. We show the strong performance of ORQA on our proposed benchmark, and its zero-shot generalization, paving the way for scalable, unified OR modeling and significantly advancing multimodal surgical intelligence. We will release our code and data upon acceptance.","authors":["Ege \\\"Ozsoy","Chantal Pellegrini","David Bani-Harouni","Kun Yuan","Matthias Keicher","Nassir Navab"],"url":"https://arxiv.org/abs/2505.12890"}
{"created":"2025-05-20","title":"TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios","abstract":"Temporal reasoning is pivotal for Large Language Models (LLMs) to comprehend the real world. However, existing works neglect the real-world challenges for temporal reasoning: (1) intensive temporal information, (2) fast-changing event dynamics, and (3) complex temporal dependencies in social interactions. To bridge this gap, we propose a multi-level benchmark TIME, designed for temporal reasoning in real-world scenarios. TIME consists of 38,522 QA pairs, covering 3 levels with 11 fine-grained sub-tasks. This benchmark encompasses 3 sub-datasets reflecting different real-world challenges: TIME-Wiki, TIME-News, and TIME-Dial. We conduct extensive experiments on reasoning models and non-reasoning models. And we conducted an in-depth analysis of temporal reasoning performance across diverse real-world scenarios and tasks, and summarized the impact of test-time scaling on temporal reasoning capabilities. Additionally, we release TIME-Lite, a human-annotated subset to foster future research and standardized evaluation in temporal reasoning. The code is available at https://github.com/sylvain-wei/TIME , and the dataset is available at https://huggingface.co/datasets/SylvainWei/TIME .","authors":["Shaohang Wei","Wei Li","Feifan Song","Wen Luo","Tianyi Zhuang","Haochen Tan","Zhijiang Guo","Houfeng Wang"],"url":"https://arxiv.org/abs/2505.12891"}
{"created":"2025-05-20","title":"\"I will never pay for this\" Perception of fairness and factors affecting behaviour on 'pay-or-ok' models","abstract":"The rise of cookie paywalls ('pay-or-ok' models) has prompted growing debates around privacy, monetisation, and the legitimacy of user consent. Despite their increasing use across sectors, limited research has explored how users perceive these models or what shapes their decisions to either consent to tracking or pay. To address this gap, we conducted four focus groups (n = 14) to examine users' perceptions of cookie paywalls, their judgments of fairness, and the conditions under which they might consider paying, alongside a legal analysis within the EU data protection framework law.","authors":["Victor Morel","Farzaneh Karegar","Cristiana Santos"],"url":"https://arxiv.org/abs/2505.12892"}
{"created":"2025-05-20","title":"HyperDet: Source Detection in Hypergraphs via Interactive Relationship Construction and Feature-rich Attention Fusion","abstract":"Hypergraphs offer superior modeling capabilities for social networks, particularly in capturing group phenomena that extend beyond pairwise interactions in rumor propagation. Existing approaches in rumor source detection predominantly focus on dyadic interactions, which inadequately address the complexity of more intricate relational structures. In this study, we present a novel approach for Source Detection in Hypergraphs (HyperDet) via Interactive Relationship Construction and Feature-rich Attention Fusion. Specifically, our methodology employs an Interactive Relationship Construction module to accurately model both the static topology and dynamic interactions among users, followed by the Feature-rich Attention Fusion module, which autonomously learns node features and discriminates between nodes using a self-attention mechanism, thereby effectively learning node representations under the framework of accurately modeled higher-order relationships. Extensive experimental validation confirms the efficacy of our HyperDet approach, showcasing its superiority relative to current state-of-the-art methods.","authors":["Le Cheng","Peican Zhu","Yangming Guo","Keke Tang","Chao Gao","Zhen Wang"],"url":"https://arxiv.org/abs/2505.12894"}
{"created":"2025-05-20","title":"On the Thinking-Language Modeling Gap in Large Language Models","abstract":"System 2 reasoning is one of the defining characteristics of intelligence, which requires slow and logical thinking. Human conducts System 2 reasoning via the language of thoughts that organizes the reasoning process as a causal sequence of mental language, or thoughts. Recently, it has been observed that System 2 reasoning can be elicited from Large Language Models (LLMs) pre-trained on large-scale natural languages. However, in this work, we show that there is a significant gap between the modeling of languages and thoughts. As language is primarily a tool for humans to share knowledge and thinking, modeling human language can easily absorb language biases into LLMs deviated from the chain of thoughts in minds. Furthermore, we show that the biases will mislead the eliciting of \"thoughts\" in LLMs to focus only on a biased part of the premise. To this end, we propose a new prompt technique termed Language-of-Thoughts (LoT) to demonstrate and alleviate this gap. Instead of directly eliciting the chain of thoughts from partial information, LoT instructs LLMs to adjust the order and token used for the expressions of all the relevant information. We show that the simple strategy significantly reduces the language modeling biases in LLMs and improves the performance of LLMs across a variety of reasoning tasks.","authors":["Chenxi Liu","Yongqiang Chen","Tongliang Liu","James Cheng","Bo Han","Kun Zhang"],"url":"https://arxiv.org/abs/2505.12896"}
{"created":"2025-05-20","title":"EPIC: Explanation of Pretrained Image Classification Networks via Prototype","abstract":"Explainable AI (XAI) methods generally fall into two categories. Post-hoc approaches generate explanations for pre-trained models and are compatible with various neural network architectures. These methods often use feature importance visualizations, such as saliency maps, to indicate which input regions influenced the model's prediction. Unfortunately, they typically offer a coarse understanding of the model's decision-making process. In contrast, ante-hoc (inherently explainable) methods rely on specially designed model architectures trained from scratch. A notable subclass of these methods provides explanations through prototypes, representative patches extracted from the training data. However, prototype-based approaches have limitations: they require dedicated architectures, involve specialized training procedures, and perform well only on specific datasets. In this work, we propose EPIC (Explanation of Pretrained Image Classification), a novel approach that bridges the gap between these two paradigms. Like post-hoc methods, EPIC operates on pre-trained models without architectural modifications. Simultaneously, it delivers intuitive, prototype-based explanations inspired by ante-hoc techniques. To the best of our knowledge, EPIC is the first post-hoc method capable of fully replicating the core explanatory power of inherently interpretable models. We evaluate EPIC on benchmark datasets commonly used in prototype-based explanations, such as CUB-200-2011 and Stanford Cars, alongside large-scale datasets like ImageNet, typically employed by post-hoc methods. EPIC uses prototypes to explain model decisions, providing a flexible and easy-to-understand tool for creating clear, high-quality explanations.","authors":["Piotr Borycki","Magdalena Tr\\k{e}dowicz","Szymon Janusz","Jacek Tabor","Przemys{\\l}aw Spurek","Arkadiusz Lewicki","{\\L}ukasz Struski"],"url":"https://arxiv.org/abs/2505.12897"}
{"created":"2025-05-20","title":"Interpolation for the two-way modal mu-calculus","abstract":"The two-way modal mu-calculus is the extension of the (standard) one-way mu-calculus with converse (backward-looking) modalities. For this logic we introduce two new sequent-style proof calculi: a non-wellfounded system admitting infinite branches and a finitary, cyclic version of this that employs annotations. As is common in sequent systems for two-way modal logics, our calculi feature an analytic cut rule. What distinguishes our approach is the use of so-called trace atoms, which serve to apply Vardi's two-way automata in a proof-theoretic setting. We prove soundness and completeness for both systems and subsequently use the cyclic calculus to show that the two-way mu-calculus has the (local) Craig interpolation property, with respect to both propositions and modalities. Our proof uses a version of Maehara's method adapted to cyclic proof systems. As a corollary we prove that the two-way mu-calculus also enjoys Beth's definability property.","authors":["Johannes Kloibhofer","Yde Venema"],"url":"https://arxiv.org/abs/2505.12899"}
{"created":"2025-05-20","title":"AutoGEEval: A Multimodal and Automated Framework for Geospatial Code Generation on GEE with Large Language Models","abstract":"Geospatial code generation is emerging as a key direction in the integration of artificial intelligence and geoscientific analysis. However, there remains a lack of standardized tools for automatic evaluation in this domain. To address this gap, we propose AutoGEEval, the first multimodal, unit-level automated evaluation framework for geospatial code generation tasks on the Google Earth Engine (GEE) platform powered by large language models (LLMs). Built upon the GEE Python API, AutoGEEval establishes a benchmark suite (AutoGEEval-Bench) comprising 1325 test cases that span 26 GEE data types. The framework integrates both question generation and answer verification components to enable an end-to-end automated evaluation pipeline-from function invocation to execution validation. AutoGEEval supports multidimensional quantitative analysis of model outputs in terms of accuracy, resource consumption, execution efficiency, and error types. We evaluate 18 state-of-the-art LLMs-including general-purpose, reasoning-augmented, code-centric, and geoscience-specialized models-revealing their performance characteristics and potential optimization pathways in GEE code generation. This work provides a unified protocol and foundational resource for the development and assessment of geospatial code generation models, advancing the frontier of automated natural language to domain-specific code translation.","authors":["Shuyang Hou","Zhangxiao Shen","Huayi Wu","Jianyuan Liang","Haoyue Jiao","Yaxian Qing","Xiaopu Zhang","Xu Li","Zhipeng Gui","Xuefeng Guan","Longgang Xiang"],"url":"https://arxiv.org/abs/2505.12900"}
{"created":"2025-05-20","title":"Power Allocation for Delay Optimization in Device-to-Device Networks: A Graph Reinforcement Learning Approach","abstract":"The pursuit of rate maximization in wireless communication frequently encounters substantial challenges associated with user fairness. This paper addresses these challenges by exploring a novel power allocation approach for delay optimization, utilizing graph neural networks (GNNs)-based reinforcement learning (RL) in device-to-device (D2D) communication. The proposed approach incorporates not only channel state information but also factors such as packet delay, the number of backlogged packets, and the number of transmitted packets into the components of the state information. We adopt a centralized RL method, where a central controller collects and processes the state information. The central controller functions as an agent trained using the proximal policy optimization (PPO) algorithm. To better utilize topology information in the communication network and enhance the generalization of the proposed method, we embed GNN layers into both the actor and critic networks of the PPO algorithm. This integration allows for efficient parameter updates of GNNs and enables the state information to be parameterized as a low-dimensional embedding, which is leveraged by the agent to optimize power allocation strategies. Simulation results demonstrate that the proposed method effectively reduces average delay while ensuring user fairness, outperforms baseline methods, and exhibits scalability and generalization capability.","authors":["Hao Fang","Kai Huang","Hao Ye","Chongtao Guo","Le Liang","Xiao Li","Shi Jin"],"url":"https://arxiv.org/abs/2505.12902"}
{"created":"2025-05-20","title":"Towards Low-Latency Event Stream-based Visual Object Tracking: A Slow-Fast Approach","abstract":"Existing tracking algorithms typically rely on low-frame-rate RGB cameras coupled with computationally intensive deep neural network architectures to achieve effective tracking. However, such frame-based methods inherently face challenges in achieving low-latency performance and often fail in resource-constrained environments. Visual object tracking using bio-inspired event cameras has emerged as a promising research direction in recent years, offering distinct advantages for low-latency applications. In this paper, we propose a novel Slow-Fast Tracking paradigm that flexibly adapts to different operational requirements, termed SFTrack. The proposed framework supports two complementary modes, i.e., a high-precision slow tracker for scenarios with sufficient computational resources, and an efficient fast tracker tailored for latency-aware, resource-constrained environments. Specifically, our framework first performs graph-based representation learning from high-temporal-resolution event streams, and then integrates the learned graph-structured information into two FlashAttention-based vision backbones, yielding the slow and fast trackers, respectively. The fast tracker achieves low latency through a lightweight network design and by producing multiple bounding box outputs in a single forward pass. Finally, we seamlessly combine both trackers via supervised fine-tuning and further enhance the fast tracker's performance through a knowledge distillation strategy. Extensive experiments on public benchmarks, including FE240, COESOT, and EventVOT, demonstrate the effectiveness and efficiency of our proposed method across different real-world scenarios. The source code has been released on https://github.com/Event-AHU/SlowFast_Event_Track.","authors":["Shiao Wang","Xiao Wang","Liye Jin","Bo Jiang","Lin Zhu","Lan Chen","Yonghong Tian","Bin Luo"],"url":"https://arxiv.org/abs/2505.12903"}
{"created":"2025-05-20","title":"The Computation of Generalized Embeddings for Underwater Acoustic Target Recognition using Contrastive Learning","abstract":"The increasing level of sound pollution in marine environments poses an increased threat to ocean health, making it crucial to monitor underwater noise. By monitoring this noise, the sources responsible for this pollution can be mapped. Monitoring is performed by passively listening to these sounds. This generates a large amount of data records, capturing a mix of sound sources such as ship activities and marine mammal vocalizations. Although machine learning offers a promising solution for automatic sound classification, current state-of-the-art methods implement supervised learning. This requires a large amount of high-quality labeled data that is not publicly available. In contrast, a massive amount of lower-quality unlabeled data is publicly available, offering the opportunity to explore unsupervised learning techniques. This research explores this possibility by implementing an unsupervised Contrastive Learning approach. Here, a Conformer-based encoder is optimized by the so-called Variance-Invariance-Covariance Regularization loss function on these lower-quality unlabeled data and the translation to the labeled data is made. Through classification tasks involving recognizing ship types and marine mammal vocalizations, our method demonstrates to produce robust and generalized embeddings. This shows to potential of unsupervised methods for various automatic underwater acoustic analysis tasks.","authors":["Hilde I. Hummel","Arwin Gansekoele","Sandjai Bhulai","Rob van der Mei"],"url":"https://arxiv.org/abs/2505.12904"}
{"created":"2025-05-20","title":"Efficient training for large-scale optical neural network using an evolutionary strategy and attention pruning","abstract":"MZI-based block optical neural networks (BONNs), which can achieve large-scale network models, have increasingly drawn attentions. However, the robustness of the current training algorithm is not high enough. Moreover, large-scale BONNs usually contain numerous trainable parameters, resulting in expensive computation and power consumption. In this article, by pruning matrix blocks and directly optimizing the individuals in population, we propose an on-chip covariance matrix adaptation evolution strategy and attention-based pruning (CAP) algorithm for large-scale BONNs. The calculated results demonstrate that the CAP algorithm can prune 60% and 80% of the parameters for MNIST and Fashion-MNIST datasets, respectively, while only degrades the performance by 3.289% and 4.693%. Considering the influence of dynamic noise in phase shifters, our proposed CAP algorithm (performance degradation of 22.327% for MNIST dataset and 24.019% for Fashion-MNIST dataset utilizing a poor fabricated chip and electrical control with a standard deviation of 0.5) exhibits strongest robustness compared with both our previously reported block adjoint training algorithm (43.963% and 41.074%) and the covariance matrix adaptation evolution strategy (25.757% and 32.871%), respectively. Moreover, when 60% of the parameters are pruned, the CAP algorithm realizes 88.5% accuracy in experiment for the simplified MNIST dataset, which is similar to the simulation result without noise (92.1%). Additionally, we simulationally and experimentally demonstrate that using MZIs with only internal phase shifters to construct BONNs is an efficient way to reduce both the system area and the required trainable parameters. Notably, our proposed CAP algorithm show excellent potential for larger-scale network models and more complex tasks.","authors":["Zhiwei Yang","Zeyang Fan","Yihang Lai","Qi Chen","Tian Zhang","Jian Dai","Kun Xu"],"url":"https://arxiv.org/abs/2505.12906"}
{"created":"2025-05-20","title":"Dynamic Graph Induced Contour-aware Heat Conduction Network for Event-based Object Detection","abstract":"Event-based Vision Sensors (EVS) have demonstrated significant advantages over traditional RGB frame-based cameras in low-light conditions, high-speed motion capture, and low latency. Consequently, object detection based on EVS has attracted increasing attention from researchers. Current event stream object detection algorithms are typically built upon Convolutional Neural Networks (CNNs) or Transformers, which either capture limited local features using convolutional filters or incur high computational costs due to the utilization of self-attention. Recently proposed vision heat conduction backbone networks have shown a good balance between efficiency and accuracy; however, these models are not specifically designed for event stream data. They exhibit weak capability in modeling object contour information and fail to exploit the benefits of multi-scale features. To address these issues, this paper proposes a novel dynamic graph induced contour-aware heat conduction network for event stream based object detection, termed CvHeat-DET. The proposed model effectively leverages the clear contour information inherent in event streams to predict the thermal diffusivity coefficients within the heat conduction model, and integrates hierarchical structural graph features to enhance feature learning across multiple scales. Extensive experiments on three benchmark datasets for event stream-based object detection fully validated the effectiveness of the proposed model. The source code of this paper will be released on https://github.com/Event-AHU/OpenEvDET.","authors":["Xiao Wang","Yu Jin","Lan Chen","Bo Jiang","Lin Zhu","Yonghong Tian","Jin Tang","Bin Luo"],"url":"https://arxiv.org/abs/2505.12908"}
{"created":"2025-05-20","title":"Sinusoidal Initialization, Time for a New Start","abstract":"Initialization plays a critical role in Deep Neural Network training, directly influencing convergence, stability, and generalization. Common approaches such as Glorot and He initializations rely on randomness, which can produce uneven weight distributions across layer connections. In this paper, we introduce the Sinusoidal initialization, a novel deterministic method that employs sinusoidal functions to construct structured weight matrices expressly to improve the spread and balance of weights throughout the network while simultaneously fostering a more uniform, well-conditioned distribution of neuron activation states from the very first forward pass. Because Sinusoidal initialization begins with weights and activations that are already evenly and efficiently utilized, it delivers consistently faster convergence, greater training stability, and higher final accuracy across a wide range of models, including convolutional neural networks, vision transformers, and large language models. On average, our experiments show an increase of 4.8 % in final validation accuracy and 20.9 % in convergence speed. By replacing randomness with structure, this initialization provides a stronger and more reliable foundation for Deep Learning systems.","authors":["Alberto Fern\\'andez-Hern\\'andez","Jose I. Mestre","Manuel F. Dolz","Jose Duato","Enrique S. Quintana-Ort\\'i"],"url":"https://arxiv.org/abs/2505.12909"}
{"created":"2025-05-20","title":"SourceDetMamba: A Graph-aware State Space Model for Source Detection in Sequential Hypergraphs","abstract":"Source detection on graphs has demonstrated high efficacy in identifying rumor origins. Despite advances in machine learning-based methods, many fail to capture intrinsic dynamics of rumor propagation. In this work, we present SourceDetMamba: A Graph-aware State Space Model for Source Detection in Sequential Hypergraphs, which harnesses the recent success of the state space model Mamba, known for its superior global modeling capabilities and computational efficiency, to address this challenge. Specifically, we first employ hypergraphs to model high-order interactions within social networks. Subsequently, temporal network snapshots generated during the propagation process are sequentially fed in reverse order into Mamba to infer underlying propagation dynamics. Finally, to empower the sequential model to effectively capture propagation patterns while integrating structural information, we propose a novel graph-aware state update mechanism, wherein the state of each node is propagated and refined by both temporal dependencies and topological context. Extensive evaluations on eight datasets demonstrate that SourceDetMamba consistently outperforms state-of-the-art approaches.","authors":["Le Cheng","Peican Zhu","Yangming Guo","Chao Gao","Zhen Wang","Keke Tang"],"url":"https://arxiv.org/abs/2505.12910"}
{"created":"2025-05-20","title":"HiERO: understanding the hierarchy of human behavior enhances reasoning on egocentric videos","abstract":"Human activities are particularly complex and variable, and this makes challenging for deep learning models to reason about them. However, we note that such variability does have an underlying structure, composed of a hierarchy of patterns of related actions. We argue that such structure can emerge naturally from unscripted videos of human activities, and can be leveraged to better reason about their content. We present HiERO, a weakly-supervised method to enrich video segments features with the corresponding hierarchical activity threads. By aligning video clips with their narrated descriptions, HiERO infers contextual, semantic and temporal reasoning with an hierarchical architecture. We prove the potential of our enriched features with multiple video-text alignment benchmarks (EgoMCQ, EgoNLQ) with minimal additional training, and in zero-shot for procedure learning tasks (EgoProceL and Ego4D Goal-Step). Notably, HiERO achieves state-of-the-art performance in all the benchmarks, and for procedure learning tasks it outperforms fully-supervised methods by a large margin (+12.5% F1 on EgoProceL) in zero shot. Our results prove the relevance of using knowledge of the hierarchy of human activities for multiple reasoning tasks in egocentric vision.","authors":["Simone Alberto Peirone","Francesca Pistilli","Giuseppe Averta"],"url":"https://arxiv.org/abs/2505.12911"}
{"created":"2025-05-20","title":"Uniformity First: Uniformity-aware Test-time Adaptation of Vision-language Models against Image Corruption","abstract":"Pre-trained vision-language models such as contrastive language-image pre-training (CLIP) have demonstrated a remarkable generalizability, which has enabled a wide range of applications represented by zero-shot classification. However, vision-language models still suffer when they face datasets with large gaps from training ones, i.e., distribution shifts. We found that CLIP is especially vulnerable to sensor degradation, a type of realistic distribution shift caused by sensor conditions such as weather, light, or noise. Collecting a new dataset from a test distribution for fine-tuning highly costs since sensor degradation occurs unexpectedly and has a range of variety. Thus, we investigate test-time adaptation (TTA) of zero-shot classification, which enables on-the-fly adaptation to the test distribution with unlabeled test data. Existing TTA methods for CLIP mainly focus on modifying image and text embeddings or predictions to address distribution shifts. Although these methods can adapt to domain shifts, such as fine-grained labels spaces or different renditions in input images, they fail to adapt to distribution shifts caused by sensor degradation. We found that this is because image embeddings are \"corrupted\" in terms of uniformity, a measure related to the amount of information. To make models robust to sensor degradation, we propose a novel method called uniformity-aware information-balanced TTA (UnInfo). To address the corruption of image embeddings, we introduce uniformity-aware confidence maximization, information-aware loss balancing, and knowledge distillation from the exponential moving average (EMA) teacher. Through experiments, we demonstrate that our UnInfo improves accuracy under sensor degradation by retaining information in terms of uniformity.","authors":["Kazuki Adachi","Shin'ya Yamaguchi","Tomoki Hamagami"],"url":"https://arxiv.org/abs/2505.12912"}
{"created":"2025-05-20","title":"Active Learning on Synthons for Molecular Design","abstract":"Exhaustive virtual screening is highly informative but often intractable against the expensive objective functions involved in modern drug discovery. This problem is exacerbated in combinatorial contexts such as multi-vector expansion, where molecular spaces can quickly become ultra-large. Here, we introduce Scalable Active Learning via Synthon Acquisition (SALSA): a simple algorithm applicable to multi-vector expansion which extends pool-based active learning to non-enumerable spaces by factoring modeling and acquisition over synthon or fragment choices. Through experiments on ligand- and structure-based objectives, we highlight SALSA's sample efficiency, and its ability to scale to spaces of trillions of compounds. Further, we demonstrate application toward multi-parameter objective design tasks on three protein targets - finding SALSA-generated molecules have comparable chemical property profiles to known bioactives, and exhibit greater diversity and higher scores over an industry-leading generative approach.","authors":["Tom George Grigg","Mason Burlage","Oliver Brook Scott","Adam Taouil","Dominique Sydow","Liam Wilbraham"],"url":"https://arxiv.org/abs/2505.12913"}
{"created":"2025-05-20","title":"Temporal Query Network for Efficient Multivariate Time Series Forecasting","abstract":"Sufficiently modeling the correlations among variables (aka channels) is crucial for achieving accurate multivariate time series forecasting (MTSF). In this paper, we propose a novel technique called Temporal Query (TQ) to more effectively capture multivariate correlations, thereby improving model performance in MTSF tasks. Technically, the TQ technique employs periodically shifted learnable vectors as queries in the attention mechanism to capture global inter-variable patterns, while the keys and values are derived from the raw input data to encode local, sample-level correlations. Building upon the TQ technique, we develop a simple yet efficient model named Temporal Query Network (TQNet), which employs only a single-layer attention mechanism and a lightweight multi-layer perceptron (MLP). Extensive experiments demonstrate that TQNet learns more robust multivariate correlations, achieving state-of-the-art forecasting accuracy across 12 challenging real-world datasets. Furthermore, TQNet achieves high efficiency comparable to linear-based methods even on high-dimensional datasets, balancing performance and computational cost. The code is available at: https://github.com/ACAT-SCUT/TQNet.","authors":["Shengsheng Lin","Haojun Chen","Haijie Wu","Chunyun Qiu","Weiwei Lin"],"url":"https://arxiv.org/abs/2505.12917"}
{"created":"2025-05-20","title":"RGNMR: A Gauss-Newton method for robust matrix completion with theoretical guarantees","abstract":"Recovering a low rank matrix from a subset of its entries, some of which may be corrupted, is known as the robust matrix completion (RMC) problem. Existing RMC methods have several limitations: they require a relatively large number of observed entries; they may fail under overparametrization, when their assumed rank is higher than the correct one; and many of them fail to recover even mildly ill-conditioned matrices. In this paper we propose a novel RMC method, denoted $\\texttt{RGNMR}$, which overcomes these limitations. $\\texttt{RGNMR}$ is a simple factorization-based iterative algorithm, which combines a Gauss-Newton linearization with removal of entries suspected to be outliers. On the theoretical front, we prove that under suitable assumptions, $\\texttt{RGNMR}$ is guaranteed exact recovery of the underlying low rank matrix. Our theoretical results improve upon the best currently known for factorization-based methods. On the empirical front, we show via several simulations the advantages of $\\texttt{RGNMR}$ over existing RMC methods, and in particular its ability to handle a small number of observed entries, overparameterization of the rank and ill-conditioned matrices.","authors":["Eilon Vaknin Laufer","Boaz Nadler"],"url":"https://arxiv.org/abs/2505.12919"}
{"created":"2025-05-20","title":"PyFCG: Fluid Construction Grammar in Python","abstract":"We present PyFCG, an open source software library that ports Fluid Construction Grammar (FCG) to the Python programming language. PyFCG enables its users to seamlessly integrate FCG functionality into Python programs, and to use FCG in combination with other libraries within Python's rich ecosystem. Apart from a general description of the library, this paper provides three walkthrough tutorials that demonstrate example usage of PyFCG in typical use cases of FCG: (i) formalising and testing construction grammar analyses, (ii) learning usage-based construction grammars from corpora, and (iii) implementing agent-based experiments on emergent communication.","authors":["Paul Van Eecke","Katrien Beuls"],"url":"https://arxiv.org/abs/2505.12920"}
{"created":"2025-05-20","title":"The Traitors: Deception and Trust in Multi-Agent Language Model Simulations","abstract":"As AI systems increasingly assume roles where trust and alignment with human values are essential, understanding when and why they engage in deception has become a critical research priority. We introduce The Traitors, a multi-agent simulation framework inspired by social deduction games, designed to probe deception, trust formation, and strategic communication among large language model (LLM) agents under asymmetric information. A minority of agents the traitors seek to mislead the majority, while the faithful must infer hidden identities through dialogue and reasoning. Our contributions are: (1) we ground the environment in formal frameworks from game theory, behavioral economics, and social cognition; (2) we develop a suite of evaluation metrics capturing deception success, trust dynamics, and collective inference quality; (3) we implement a fully autonomous simulation platform where LLMs reason over persistent memory and evolving social dynamics, with support for heterogeneous agent populations, specialized traits, and adaptive behaviors. Our initial experiments across DeepSeek-V3, GPT-4o-mini, and GPT-4o (10 runs per model) reveal a notable asymmetry: advanced models like GPT-4o demonstrate superior deceptive capabilities yet exhibit disproportionate vulnerability to others' falsehoods. This suggests deception skills may scale faster than detection abilities. Overall, The Traitors provides a focused, configurable testbed for investigating LLM behavior in socially nuanced interactions. We position this work as a contribution toward more rigorous research on deception mechanisms, alignment challenges, and the broader social reliability of AI systems.","authors":["Pedro M. P. Curvo"],"url":"https://arxiv.org/abs/2505.12923"}
{"created":"2025-05-20","title":"CPRet: A Dataset, Benchmark, and Model for Retrieval in Competitive Programming","abstract":"Competitive programming benchmarks are widely used in scenarios such as programming contests and large language model assessments. However, the growing presence of duplicate or highly similar problems raises concerns not only about competition fairness, but also about the validity of competitive programming as a benchmark for model evaluation. In this paper, we propose a new problem -- similar question retrieval -- to address this issue. Due to the lack of both data and models, solving this problem is challenging. To this end, we introduce CPRet, a retrieval-oriented benchmark suite for competitive programming, covering four retrieval tasks: two code-centric (i.e., Text-to-Code and Code-to-Code) and two newly proposed problem-centric tasks (i.e., Problem-to-Duplicate and Simplified-to-Full), built from a combination of automatically crawled problem-solution data and manually curated annotations. Our contribution includes both high-quality training data and temporally separated test sets for reliable evaluation. In addition, we develop two task-specialized retrievers based on this dataset: CPRetriever-Code, trained with a novel Group-InfoNCE loss for problem-code alignment, and CPRetriever-Prob, fine-tuned for identifying problem-level similarity. Both models achieve strong results and are open-sourced for local use. Finally, we analyze LiveCodeBench and find that high-similarity problems inflate model pass rates and reduce differentiation, underscoring the need for similarity-aware evaluation in future benchmarks.","authors":["Han Deng","Yuan Meng","Shixiang Tang","Wanli Ouyang","Xinzhu Ma"],"url":"https://arxiv.org/abs/2505.12925"}
{"created":"2025-05-20","title":"Minos: Exploiting Cloud Performance Variation with Function-as-a-Service Instance Selection","abstract":"Serverless Function-as-a-Service (FaaS) is a popular cloud paradigm to quickly and cheaply implement complex applications. Because the function instances cloud providers start to execute user code run on shared infrastructure, their performance can vary. From a user perspective, slower instances not only take longer to complete, but also increase cost due to the pay-per-use model of FaaS services where execution duration is billed with microsecond accuracy. In this paper, we present Minos, a system to take advantage of this performance variation by intentionally terminating instances that are slow. Fast instances are not terminated, so that they can be re-used for subsequent invocations. One use case for this are data processing and machine learning workflows, which often download files as a first step, during which Minos can run a short benchmark. Only if the benchmark passes, the main part of the function is actually executed. Otherwise, the request is re-queued and the instance crashes itself, so that the platform has to assign the request to another (potentially faster) instance. In our experiments, this leads to a speedup of up to 13% in the resource intensive part of a data processing workflow, resulting in up to 4% faster overall performance (and consequently 4% cheaper prices). Longer and complex workflows lead to increased savings, as the pool of fast instances is re-used more often. For platforms exhibiting this behavior, users get better performance and save money by wasting more of the platforms resources.","authors":["Trever Schirmer","Valentin Carl","Nils H\\\"oller","Tobias Pfandzelter","David Bermbach"],"url":"https://arxiv.org/abs/2505.12928"}
{"created":"2025-05-20","title":"Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs","abstract":"Reinforcement learning (RL) has become a cornerstone for enhancing the reasoning capabilities of large language models (LLMs), with recent innovations such as Group Relative Policy Optimization (GRPO) demonstrating exceptional effectiveness. In this study, we identify a critical yet underexplored issue in RL training: low-probability tokens disproportionately influence model updates due to their large gradient magnitudes. This dominance hinders the effective learning of high-probability tokens, whose gradients are essential for LLMs' performance but are substantially suppressed. To mitigate this interference, we propose two novel methods: Advantage Reweighting and Low-Probability Token Isolation (Lopti), both of which effectively attenuate gradients from low-probability tokens while emphasizing parameter updates driven by high-probability tokens. Our approaches promote balanced updates across tokens with varying probabilities, thereby enhancing the efficiency of RL training. Experimental results demonstrate that they substantially improve the performance of GRPO-trained LLMs, achieving up to a 46.2% improvement in K&amp;K Logic Puzzle reasoning tasks. Our implementation is available at https://github.com/zhyang2226/AR-Lopti.","authors":["Zhihe Yang","Xufang Luo","Zilong Wang","Dongqi Han","Zhiyuan He","Dongsheng Li","Yunjian Xu"],"url":"https://arxiv.org/abs/2505.12929"}
{"created":"2025-05-20","title":"A Necessary Condition for Connectedness of Solutions to Integer Linear Systems","abstract":"An integer linear system is a set of inequalities with integer constraints. The solution graph of an integer linear system is an undirected graph defined on the set of feasible solutions to the integer linear system. In this graph, a pair of feasible solutions is connected by an edge if the Hamming distance between them is one. In this paper, we consider a condition under which the solution graph is connected for any right-hand side vector. First, we prove that if the solution graph is connected for any right-hand side vector, then the coefficient matrix of the system does not contain some forbidden pattern as a submatrix. Next, we prove that if at least one of (i) the number of rows is at most 3, (ii) the number of columns is at most 2, (iii) the number of rows is 4 and the number of columns is 3 holds, then the condition that the coefficient matrix of the system does not contain the forbidden pattern is a sufficient condition under which the solution graph is connected for any right-hand side vector. This result is stronger than a known necessary and sufficient condition since the set of coefficient matrix dimensions is strictly larger.","authors":["Takasugu Shigenobu","Naoyuki Kamiyama"],"url":"https://arxiv.org/abs/2505.12930"}
{"created":"2025-05-20","title":"Granular Loco-Manipulation: Repositioning Rocks Through Strategic Sand Avalanche","abstract":"Legged robots have the potential to leverage obstacles to climb steep sand slopes. However, efficiently repositioning these obstacles to desired locations is challenging. Here we present DiffusiveGRAIN, a learning-based method that enables a multi-legged robot to strategically induce localized sand avalanches during locomotion and indirectly manipulate obstacles. We conducted 375 trials, systematically varying obstacle spacing, robot orientation, and leg actions in 75 of them. Results show that the movement of closely-spaced obstacles exhibits significant interference, requiring joint modeling. In addition, different multi-leg excavation actions could cause distinct robot state changes, necessitating integrated planning of manipulation and locomotion. To address these challenges, DiffusiveGRAIN includes a diffusion-based environment predictor to capture multi-obstacle movements under granular flow interferences and a robot state predictor to estimate changes in robot state from multi-leg action patterns. Deployment experiments (90 trials) demonstrate that by integrating the environment and robot state predictors, the robot can autonomously plan its movements based on loco-manipulation goals, successfully shifting closely located rocks to desired locations in over 65% of trials. Our study showcases the potential for a locomoting robot to strategically manipulate obstacles to achieve improved mobility on challenging terrains.","authors":["Haodi Hu","Yue Wu","Feifei Qian","Daniel Seita"],"url":"https://arxiv.org/abs/2505.12934"}
{"created":"2025-05-20","title":"LatentINDIGO: An INN-Guided Latent Diffusion Algorithm for Image Restoration","abstract":"There is a growing interest in the use of latent diffusion models (LDMs) for image restoration (IR) tasks due to their ability to model effectively the distribution of natural images. While significant progress has been made, there are still key challenges that need to be addressed. First, many approaches depend on a predefined degradation operator, making them ill-suited for complex or unknown degradations that deviate from standard analytical models. Second, many methods struggle to provide a stable guidance in the latent space and finally most methods convert latent representations back to the pixel domain for guidance at every sampling iteration, which significantly increases computational and memory overhead. To overcome these limitations, we introduce a wavelet-inspired invertible neural network (INN) that simulates degradations through a forward transform and reconstructs lost details via the inverse transform. We further integrate this design into a latent diffusion pipeline through two proposed approaches: LatentINDIGO-PixelINN, which operates in the pixel domain, and LatentINDIGO-LatentINN, which stays fully in the latent space to reduce complexity. Both approaches alternate between updating intermediate latent variables under the guidance of our INN and refining the INN forward model to handle unknown degradations. In addition, a regularization step preserves the proximity of latent variables to the natural image manifold. Experiments demonstrate that our algorithm achieves state-of-the-art performance on synthetic and real-world low-quality images, and can be readily adapted to arbitrary output sizes.","authors":["Di You","Daniel Siromani","Pier Luigi Dragotti"],"url":"https://arxiv.org/abs/2505.12935"}
{"created":"2025-05-20","title":"Leveraging LLM Inconsistency to Boost Pass@k Performance","abstract":"Large language models (LLMs) achieve impressive abilities in numerous domains, but exhibit inconsistent performance in response to minor input changes. Rather than view this as a drawback, in this paper we introduce a novel method for leveraging models' inconsistency to boost Pass@k performance. Specifically, we present a \"Variator\" agent that generates k variants of a given task and submits one candidate solution for each one. Our variant generation approach is applicable to a wide range of domains as it is task agnostic and compatible with free-form inputs. We demonstrate the efficacy of our agent theoretically using a probabilistic model of the inconsistency effect, and show empirically that it outperforms the baseline on the APPS dataset. Furthermore, we establish that inconsistency persists even in frontier reasoning models across coding and cybersecurity domains, suggesting our method is likely to remain relevant for future model generations.","authors":["Uri Dalal","Meirav Segal","Zvika Ben-Haim","Dan Lahav","Omer Nevo"],"url":"https://arxiv.org/abs/2505.12938"}
{"created":"2025-05-20","title":"Multi-Level Monte Carlo Training of Neural Operators","abstract":"Operator learning is a rapidly growing field that aims to approximate nonlinear operators related to partial differential equations (PDEs) using neural operators. These rely on discretization of input and output functions and are, usually, expensive to train for large-scale problems at high-resolution. Motivated by this, we present a Multi-Level Monte Carlo (MLMC) approach to train neural operators by leveraging a hierarchy of resolutions of function dicretization. Our framework relies on using gradient corrections from fewer samples of fine-resolution data to decrease the computational cost of training while maintaining a high level accuracy. The proposed MLMC training procedure can be applied to any architecture accepting multi-resolution data. Our numerical experiments on a range of state-of-the-art models and test-cases demonstrate improved computational efficiency compared to traditional single-resolution training approaches, and highlight the existence of a Pareto curve between accuracy and computational time, related to the number of samples per resolution.","authors":["James Rowbottom","Stefania Fresca","Pietro Lio","Carola-Bibiane Sch\\\"onlieb","Nicolas Boull\\'e"],"url":"https://arxiv.org/abs/2505.12940"}
{"created":"2025-05-20","title":"A3 : an Analytical Low-Rank Approximation Framework for Attention","abstract":"Large language models have demonstrated remarkable performance; however, their massive parameter counts make deployment highly expensive. Low-rank approximation offers a promising compression solution, yet existing approaches have two main limitations: (1) They focus on minimizing the output error of individual linear layers, without considering the architectural characteristics of Transformers, and (2) they decompose a large weight matrix into two small low-rank matrices. Consequently, these methods often fall short compared to other compression techniques like pruning and quantization, and introduce runtime overhead such as the extra GEMM kernel launches for decomposed small matrices. To address these limitations, we propose $\\tt A^\\tt 3$, a post-training low-rank approximation framework. $\\tt A^\\tt 3$ splits a Transformer layer into three functional components, namely $\\tt QK$, $\\tt OV$, and $\\tt MLP$. For each component, $\\tt A^\\tt 3$ provides an analytical solution that reduces the hidden dimension size inside each component while minimizing the component's functional loss ($\\it i.e.$, error in attention scores, attention outputs, and MLP outputs). This approach directly reduces model sizes, KV cache sizes, and FLOPs without introducing any runtime overheads. In addition, it provides a new narrative in advancing the optimization problem from singular linear layer loss optimization toward improved end-to-end performance. Through extensive experiments, we show that $\\tt A^\\tt 3$ maintains superior performance compared to SoTAs. For example, under the same reduction budget in computation and memory, our low-rank approximated LLaMA 3.1-70B achieves a perplexity of 4.69 on WikiText-2, outperforming the previous SoTA's 7.87 by 3.18. We also demonstrate the versatility of $\\tt A^\\tt 3$, including KV cache compression, quantization, and mixed-rank assignments for enhanced performance.","authors":["Jeffrey T. H. Wong","Cheng Zhang","Xinye Cao","Pedro Gimenes","George A. Constantinides","Wayne Luk","Yiren Zhao"],"url":"https://arxiv.org/abs/2505.12942"}
{"created":"2025-05-20","title":"Improved Approximation Ratio for Strategyproof Facility Location on a Cycle","abstract":"We study the problem of design of strategyproof in expectation (SP) mechanisms for facility location on a cycle, with the objective of minimizing the sum of costs of $n$ agents. We show that there exists an SP mechanism that attains an approximation ratio of $7/4$ with respect to the sum of costs of the agents, thus improving the best known upper bound of $2-2/n$ in the cases of $n \\geq 5$. The mechanism obtaining the bound randomizes between two mechanisms known in the literature: the Random Dictator (RD) and the Proportional Circle Distance (PCD) mechanism of Meir (arXiv:1902.08070). To prove the result, we propose a cycle-cutting technique that allows for estimating the problem on a cycle by a problem on a line.","authors":["Krzysztof Rogowski","Marcin Dziubi\\'nski"],"url":"https://arxiv.org/abs/2505.12943"}
{"created":"2025-05-20","title":"CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs","abstract":"Solving time-dependent Partial Differential Equations (PDEs) using a densely discretized spatial domain is a fundamental problem in various scientific and engineering disciplines, including modeling climate phenomena and fluid dynamics. However, performing these computations directly in the physical space often incurs significant computational costs. To address this issue, several neural surrogate models have been developed that operate in a compressed latent space to solve the PDE. While these approaches reduce computational complexity, they often use Transformer-based attention mechanisms to handle irregularly sampled domains, resulting in increased memory consumption. In contrast, convolutional neural networks allow memory-efficient encoding and decoding but are limited to regular discretizations. Motivated by these considerations, we propose CALM-PDE, a model class that efficiently solves arbitrarily discretized PDEs in a compressed latent space. We introduce a novel continuous convolution-based encoder-decoder architecture that uses an epsilon-neighborhood-constrained kernel and learns to apply the convolution operator to adaptive and optimized query points. We demonstrate the effectiveness of CALM-PDE on a diverse set of PDEs with both regularly and irregularly sampled spatial domains. CALM-PDE is competitive with or outperforms existing baseline methods while offering significant improvements in memory and inference time efficiency compared to Transformer-based methods.","authors":["Jan Hagnberger","Daniel Musekamp","Mathias Niepert"],"url":"https://arxiv.org/abs/2505.12944"}
{"created":"2025-05-20","title":"6G-Enabled Smart Railways","abstract":"Smart railways integrate advanced information technologies into railway operating systems to improve efficiency and reliability. Although the development of 5G has enhanced railway services, future smart railways require ultra-high speeds, ultra-low latency, ultra-high security, full coverage, and ultra-high positioning accuracy, which 5G cannot fully meet. Therefore, 6G is envisioned to provide green and efficient all-day operations, strong information security, fully automatic driving, and low-cost intelligent maintenance. To achieve these requirements, we propose an integrated network architecture leveraging communications, computing, edge intelligence, and caching in railway systems. We have conducted in-depth investigations on key enabling technologies for reliable transmissions and wireless coverage. For high-speed mobile scenarios, we propose an AI-enabled cross-domain channel modeling and orthogonal time-frequency space-time spread multiple access mechanism to alleviate the conflict between limited spectrum availability and massive user access. The roles of blockchain, edge intelligence, and privacy technologies in endogenously secure rail communications are also evaluated. We further explore the application of emerging paradigms such as integrated sensing and communications, AI-assisted Internet of Things, semantic communications, and digital twin networks for railway maintenance, monitoring, prediction, and accident warning. Finally, possible future research and development directions are discussed.","authors":["Bo Ai","Yunlong Lu","Yuguang Fang","Dusit Niyato","Ruisi He","Wei Chen","Jiayi Zhang","Guoyu Ma","Yong Niu","Zhangdui Zhong"],"url":"https://arxiv.org/abs/2505.12946"}
{"created":"2025-05-20","title":"Neural Morphological Tagging for Nguni Languages","abstract":"Morphological parsing is the task of decomposing words into morphemes, the smallest units of meaning in a language, and labelling their grammatical roles. It is a particularly challenging task for agglutinative languages, such as the Nguni languages of South Africa, which construct words by concatenating multiple morphemes. A morphological parsing system can be framed as a pipeline with two separate components, a segmenter followed by a tagger. This paper investigates the use of neural methods to build morphological taggers for the four Nguni languages. We compare two classes of approaches: training neural sequence labellers (LSTMs and neural CRFs) from scratch and finetuning pretrained language models. We compare performance across these two categories, as well as to a traditional rule-based morphological parser. Neural taggers comfortably outperform the rule-based baseline and models trained from scratch tend to outperform pretrained models. We also compare parsing results across different upstream segmenters and with varying linguistic input features. Our findings confirm the viability of employing neural taggers based on pre-existing morphological segmenters for the Nguni languages.","authors":["Cael Marquard","Simbarashe Mawere","Francois Meyer"],"url":"https://arxiv.org/abs/2505.12949"}
{"created":"2025-05-20","title":"GuRE:Generative Query REwriter for Legal Passage Retrieval","abstract":"Legal Passage Retrieval (LPR) systems are crucial as they help practitioners save time when drafting legal arguments. However, it remains an underexplored avenue. One primary reason is the significant vocabulary mismatch between the query and the target passage. To address this, we propose a simple yet effective method, the Generative query REwriter (GuRE). We leverage the generative capabilities of Large Language Models (LLMs) by training the LLM for query rewriting. \"Rewritten queries\" help retrievers to retrieve target passages by mitigating vocabulary mismatch. Experimental results show that GuRE significantly improves performance in a retriever-agnostic manner, outperforming all baseline methods. Further analysis reveals that different training objectives lead to distinct retrieval behaviors, making GuRE more suitable than direct retriever fine-tuning for real-world applications. Codes are avaiable at github.com/daehuikim/GuRE.","authors":["Daehee Kim","Deokhyung Kang","Jonghwi Kim","Sangwon Ryu","Gary Geunbae Lee"],"url":"https://arxiv.org/abs/2505.12950"}
{"created":"2025-05-20","title":"DGRO: Enhancing LLM Reasoning via Exploration-Exploitation Control and Reward Variance Management","abstract":"Inference scaling further accelerates Large Language Models (LLMs) toward Artificial General Intelligence (AGI), with large-scale Reinforcement Learning (RL) to unleash long Chain-of-Thought reasoning. Most contemporary reasoning approaches usually rely on handcrafted rule-based reward functions. However, the tarde-offs of exploration and exploitation in RL algorithms involves multiple complex considerations, and the theoretical and empirical impacts of manually designed reward functions remain insufficiently explored. In this paper, we propose Decoupled Group Reward Optimization (DGRO), a general RL algorithm for LLM reasoning. On the one hand, DGRO decouples the traditional regularization coefficient into two independent hyperparameters: one scales the policy gradient term, and the other regulates the distance from the sampling policy. This decoupling not only enables precise control over balancing exploration and exploitation, but also can be seamlessly extended to Online Policy Mirror Descent (OPMD) algorithms in Kimi k1.5 and Direct Reward Optimization. On the other hand, we observe that reward variance significantly affects both convergence speed and final model performance. We conduct both theoretical analysis and extensive empirical validation to assess DGRO, including a detailed ablation study that investigates its performance and optimization dynamics. Experimental results show that DGRO achieves state-of-the-art performance on the Logic dataset with an average accuracy of 96.9\\%, and demonstrates strong generalization across mathematical benchmarks.","authors":["Xuerui Su","Liya Guo","Yue Wang","Yi Zhu","Zhiming Ma","Zun Wang","Yuting Liu"],"url":"https://arxiv.org/abs/2505.12951"}
{"created":"2025-05-20","title":"LoD: Loss-difference OOD Detection by Intentionally Label-Noisifying Unlabeled Wild Data","abstract":"Using unlabeled wild data containing both in-distribution (ID) and out-of-distribution (OOD) data to improve the safety and reliability of models has recently received increasing attention. Existing methods either design customized losses for labeled ID and unlabeled wild data then perform joint optimization, or first filter out OOD data from the latter then learn an OOD detector. While achieving varying degrees of success, two potential issues remain: (i) Labeled ID data typically dominates the learning of models, inevitably making models tend to fit OOD data as IDs; (ii) The selection of thresholds for identifying OOD data in unlabeled wild data usually faces dilemma due to the unavailability of pure OOD samples. To address these issues, we propose a novel loss-difference OOD detection framework (LoD) by \\textit{intentionally label-noisifying} unlabeled wild data. Such operations not only enable labeled ID data and OOD data in unlabeled wild data to jointly dominate the models' learning but also ensure the distinguishability of the losses between ID and OOD samples in unlabeled wild data, allowing the classic clustering technique (e.g., K-means) to filter these OOD samples without requiring thresholds any longer. We also provide theoretical foundation for LoD's viability, and extensive experiments verify its superiority.","authors":["Chuanxing Geng","Qifei Li","Xinrui Wang","Dong Liang","Songcan Chen","Pong C. Yuen"],"url":"https://arxiv.org/abs/2505.12952"}
{"created":"2025-05-20","title":"Counting Graphlets of Size $k$ under Local Differential Privacy","abstract":"The problem of counting subgraphs or graphlets under local differential privacy is an important challenge that has attracted significant attention from researchers. However, much of the existing work focuses on small graphlets like triangles or $k$-stars. In this paper, we propose a non-interactive, locally differentially private algorithm capable of counting graphlets of any size $k$. When $n$ is the number of nodes in the input graph, we show that the expected $\\ell_2$ error of our algorithm is $O(n^{k - 1})$. Additionally, we prove that there exists a class of input graphs and graphlets of size $k$ for which any non-interactive counting algorithm incurs an expected $\\ell_2$ error of $\\Omega(n^{k - 1})$, demonstrating the optimality of our result. Furthermore, we establish that for certain input graphs and graphlets, any locally differentially private algorithm must have an expected $\\ell_2$ error of $\\Omega(n^{k - 1.5})$. Our experimental results show that our algorithm is more accurate than the classical randomized response method.","authors":["Vorapong Suppakitpaisarn","Donlapark Ponnoprat","Nicha Hirankarn","Quentin Hillebrand"],"url":"https://arxiv.org/abs/2505.12954"}
{"created":"2025-05-20","title":"Hardware-Adaptive and Superlinear-Capacity Memristor-based Associative Memory","abstract":"Brain-inspired computing aims to mimic cognitive functions like associative memory, the ability to recall complete patterns from partial cues. Memristor technology offers promising hardware for such neuromorphic systems due to its potential for efficient in-memory analog computing. Hopfield Neural Networks (HNNs) are a classic model for associative memory, but implementations on conventional hardware suffer from efficiency bottlenecks, while prior memristor-based HNNs faced challenges with vulnerability to hardware defects due to offline training, limited storage capacity, and difficulty processing analog patterns. Here we introduce and experimentally demonstrate on integrated memristor hardware a new hardware-adaptive learning algorithm for associative memories that significantly improves defect tolerance and capacity, and naturally extends to scalable multilayer architectures capable of handling both binary and continuous patterns. Our approach achieves 3x effective capacity under 50% device faults compared to state-of-the-art methods. Furthermore, its extension to multilayer architectures enables superlinear capacity scaling (\\(\\propto N^{1.49}\\ for binary patterns) and effective recalling of continuous patterns (\\propto N^{1.74}\\ scaling), as compared to linear capacity scaling for previous HNNs. It also provides flexibility to adjust capacity by tuning hidden neurons for the same-sized patterns. By leveraging the massive parallelism of the hardware enabled by synchronous updates, it reduces energy by 8.8x and latency by 99.7% for 64-dimensional patterns over asynchronous schemes, with greater improvements at scale. This promises the development of more reliable memristor-based associative memory systems and enables new applications research due to the significantly improved capacity, efficiency, and flexibility.","authors":["Chengping He","Mingrui Jiang","Keyi Shan","Szu-Hao Yang","Zefan Li","Shengbo Wang","Giacomo Pedretti","Jim Ignowski","Can Li"],"url":"https://arxiv.org/abs/2505.12960"}
{"created":"2025-05-20","title":"MA-COIR: Leveraging Semantic Search Index and Generative Models for Ontology-Driven Biomedical Concept Recognition","abstract":"Recognizing biomedical concepts in the text is vital for ontology refinement, knowledge graph construction, and concept relationship discovery. However, traditional concept recognition methods, relying on explicit mention identification, often fail to capture complex concepts not explicitly stated in the text. To overcome this limitation, we introduce MA-COIR, a framework that reformulates concept recognition as an indexing-recognition task. By assigning semantic search indexes (ssIDs) to concepts, MA-COIR resolves ambiguities in ontology entries and enhances recognition efficiency. Using a pretrained BART-based model fine-tuned on small datasets, our approach reduces computational requirements to facilitate adoption by domain experts. Furthermore, we incorporate large language models (LLMs)-generated queries and synthetic data to improve recognition in low-resource settings. Experimental results on three scenarios (CDR, HPO, and HOIP) highlight the effectiveness of MA-COIR in recognizing both explicit and implicit concepts without the need for mention-level annotations during inference, advancing ontology-driven concept recognition in biomedical domain applications. Our code and constructed data are available at https://github.com/sl-633/macoir-master.","authors":["Shanshan Liu","Noriki Nishida","Rumana Ferdous Munne","Narumi Tokunaga","Yuki Yamagata","Kouji Kozaki","Yuji Matsumoto"],"url":"https://arxiv.org/abs/2505.12964"}
{"created":"2025-05-20","title":"Multiscale Adaptive Conflict-Balancing Model For Multimedia Deepfake Detection","abstract":"Advances in computer vision and deep learning have blurred the line between deepfakes and authentic media, undermining multimedia credibility through audio-visual forgery. Current multimodal detection methods remain limited by unbalanced learning between modalities. To tackle this issue, we propose an Audio-Visual Joint Learning Method (MACB-DF) to better mitigate modality conflicts and neglect by leveraging contrastive learning to assist in multi-level and cross-modal fusion, thereby fully balancing and exploiting information from each modality. Additionally, we designed an orthogonalization-multimodal pareto module that preserves unimodal information while addressing gradient conflicts in audio-video encoders caused by differing optimization targets of the loss functions. Extensive experiments and ablation studies conducted on mainstream deepfake datasets demonstrate consistent performance gains of our model across key evaluation metrics, achieving an average accuracy of 95.5% across multiple datasets. Notably, our method exhibits superior cross-dataset generalization capabilities, with absolute improvements of 8.0% and 7.7% in ACC scores over the previous best-performing approach when trained on DFDC and tested on DefakeAVMiT and FakeAVCeleb datasets.","authors":["Zihan Xiong","Xiaohua Wu","Lei Chen","Fangqi Lou"],"url":"https://arxiv.org/abs/2505.12966"}
{"created":"2025-05-20","title":"Augmented Regression Models using Neurochaos Learning","abstract":"This study presents novel Augmented Regression Models using Neurochaos Learning (NL), where Tracemean features derived from the Neurochaos Learning framework are integrated with traditional regression algorithms : Linear Regression, Ridge Regression, Lasso Regression, and Support Vector Regression (SVR). Our approach was evaluated using ten diverse real-life datasets and a synthetically generated dataset of the form $y = mx + c + \\epsilon$. Results show that incorporating the Tracemean feature (mean of the chaotic neural traces of the neurons in the NL architecture) significantly enhances regression performance, particularly in Augmented Lasso Regression and Augmented SVR, where six out of ten real-life datasets exhibited improved predictive accuracy. Among the models, Augmented Chaotic Ridge Regression achieved the highest average performance boost (11.35 %). Additionally, experiments on the simulated dataset demonstrated that the Mean Squared Error (MSE) of the augmented models consistently decreased and converged towards the Minimum Mean Squared Error (MMSE) as the sample size increased. This work demonstrates the potential of chaos-inspired features in regression tasks, offering a pathway to more accurate and computationally efficient prediction models.","authors":["Akhila Henry","Nithin Nagaraj"],"url":"https://arxiv.org/abs/2505.12967"}
{"created":"2025-05-20","title":"Lara: Lightweight Anonymous Authentication with Asynchronous Revocation Auditability","abstract":"Anonymous authentication is a technique that allows to combine access control with privacy preservation. Typically, clients use different pseudonyms for each access, hindering providers from correlating their activities. To perform the revocation of pseudonyms in a privacy preserving manner is notoriously challenging. When multiple pseudonyms are revoked together, an adversary may infer that these pseudonyms belong to the same client and perform privacy breaking correlations, in particular if these pseudonyms have already been used. Backward unlinkability and revocation auditability are two properties that address this problem. Most systems that offer these properties rely on some sort of time slots, which assume a common reference of time that must be shared among clients and providers; for instance, the client must be aware that it should not use a pseudonym after a certain time or should be able to assess the freshness of a revocation list prior to perform authentication. In this paper we propose Lara, a Lightweight Anonymous Authentication with Asynchronous Revocation Auditability that does not require parties to agree on the current time slot and it is not affected by the clock skew. Prior to disclosing a pseudonym, clients are provided with a revocation list (RL) and can check that the pseudonym has not been revoked. Then, they provide a proof on non-revocation that cannot be used against any other (past or future) RL, avoiding any dependency of timing assumptions. Lara can be implemented using efficient public-key primitives and space-efficient data structures. We have implemented a prototype of Lara and have assessed experimentally its efficiency.","authors":["Claudio Correia","Guilherme Santos","Luis Rodrigues"],"url":"https://arxiv.org/abs/2505.12968"}
{"created":"2025-05-20","title":"Calm-Whisper: Reduce Whisper Hallucination On Non-Speech By Calming Crazy Heads Down","abstract":"OpenAI's Whisper has achieved significant success in Automatic Speech Recognition. However, it has consistently been found to exhibit hallucination issues, particularly in non-speech segments, which limits its broader application in complex industrial settings.","authors":["Yingzhi Wang","Anas Alhmoud","Saad Alsahly","Muhammad Alqurishi","Mirco Ravanelli"],"url":"https://arxiv.org/abs/2505.12969"}
{"created":"2025-05-20","title":"A Structured Literature Review on Traditional Approaches in Current Natural Language Processing","abstract":"The continued rise of neural networks and large language models in the more recent past has altered the natural language processing landscape, enabling new approaches towards typical language tasks and achieving mainstream success. Despite the huge success of large language models, many disadvantages still remain and through this work we assess the state of the art in five application scenarios with a particular focus on the future perspectives and sensible application scenarios of traditional and older approaches and techniques.","authors":["Robin Jegan","Andreas Henrich"],"url":"https://arxiv.org/abs/2505.12970"}
{"created":"2025-05-20","title":"A Non-Interventionist Approach to Causal Reasoning based on Lewisian Counterfactuals","abstract":"We present a computationally grounded semantics for counterfactual conditionals in which i) the state in a model is decomposed into two elements: a propositional valuation and a causal base in propositional form that represents the causal information available at the state; and ii) the comparative similarity relation between states is computed from the states' two components. We show that, by means of our semantics, we can elegantly formalize the notion of actual cause without recurring to the primitive notion of intervention. Furthermore, we provide a succinct formulation of the model checking problem for a language of counterfactual conditionals in our semantics. We show that this problem is PSPACE-complete and provide a reduction of it into QBF that can be used for automatic verification of causal properties.","authors":["Carlos Aguilera-Ventura","Xinghan Liu","Emiliano Lorini","Dmitry Rozplokhas"],"url":"https://arxiv.org/abs/2505.12972"}
{"created":"2025-05-20","title":"Fast, Not Fancy: Rethinking G2P with Rich Data and Rule-Based Models","abstract":"Homograph disambiguation remains a significant challenge in grapheme-to-phoneme (G2P) conversion, especially for low-resource languages. This challenge is twofold: (1) creating balanced and comprehensive homograph datasets is labor-intensive and costly, and (2) specific disambiguation strategies introduce additional latency, making them unsuitable for real-time applications such as screen readers and other accessibility tools. In this paper, we address both issues. First, we propose a semi-automated pipeline for constructing homograph-focused datasets, introduce the HomoRich dataset generated through this pipeline, and demonstrate its effectiveness by applying it to enhance a state-of-the-art deep learning-based G2P system for Persian. Second, we advocate for a paradigm shift - utilizing rich offline datasets to inform the development of fast, rule-based methods suitable for latency-sensitive accessibility applications like screen readers. To this end, we improve one of the most well-known rule-based G2P systems, eSpeak, into a fast homograph-aware version, HomoFast eSpeak. Our results show an approximate 30% improvement in homograph disambiguation accuracy for the deep learning-based and eSpeak systems.","authors":["Mahta Fetrat Qharabagh","Zahra Dehghanian","Hamid R. Rabiee"],"url":"https://arxiv.org/abs/2505.12973"}
{"created":"2025-05-20","title":"A Faster Parametric Search for the Integral Quickest Transshipment Problem","abstract":"Algorithms for computing fractional solutions to the quickest transshipment problem have been significantly improved since Hoppe and Tardos first solved the problem in strongly polynomial time. For integral solutions, runtime improvements are limited to general progress on submodular function minimization, which is an integral part of Hoppe and Tardos' algorithm. Yet, no structural improvements on their algorithm itself have been proposed. We replace two central subroutines in the algorithm with methods that require vastly fewer minimizations of submodular functions. This improves the state-of-the-art runtime from $ \\tilde{O}(m^4 k^{15}) $ down to $ \\tilde{O}(m^2 k^5 + m^4 k^2) $, where $ k $ is the number of terminals and $ m $ is the number of arcs.","authors":["Mariia Anapolska","Dario van den Boom","Christina B\\\"using","Timo Gersing"],"url":"https://arxiv.org/abs/2505.12975"}
{"created":"2025-05-20","title":"Computing the Schulze Method for Large-Scale Preference Data Sets","abstract":"The Schulze method is a voting rule widely used in practice and enjoys many positive axiomatic properties. While it is computable in polynomial time, its straight-forward implementation does not scale well for large elections. In this paper, we develop a highly optimised algorithm for computing the Schulze method with Pregel, a framework for massively parallel computation of graph problems, and demonstrate its applicability for large preference data sets. In addition, our theoretic analysis shows that the Schulze method is indeed particularly well-suited for parallel computation, in stark contrast to the related ranked pairs method. More precisely we show that winner determination subject to the Schulze method is NL-complete, whereas this problem is P-complete for the ranked pairs method.","authors":["Theresa Csar","Martin Lackner","Reinhard Pichler"],"url":"https://arxiv.org/abs/2505.12976"}
{"created":"2025-05-20","title":"Regularized Model Predictive Control","abstract":"In model predictive control (MPC), the choice of cost-weighting matrices and designing the Hessian matrix directly affects the trade-off between rapid state regulation and minimizing the control effort. However, traditional MPC in quadratic programming relies on fixed design matrices across the entire horizon, which can lead to suboptimal performance. This letter presents a Riccati equation-based method for adjusting the design matrix within the MPC framework, which enhances real-time performance. We employ a penalized least-squares (PLS) approach to derive a quadratic cost function for a discrete-time linear system over a finite prediction horizon. Using the method of weighting and enforcing the constraint equation by introducing a large penalty parameter, we solve the constrained optimization problem and generate control inputs for forward-shifted horizons. This process yields a recursive PLS-based Riccati equation that updates the design matrix as a regularization term in each shift, forming the foundation of the regularized MPC (Re-MPC) algorithm. To accomplish this, we provide a convergence and stability analysis of the developed algorithm. Numerical analysis demonstrates its superiority over traditional methods by allowing Riccati equation-based adjustments.","authors":["Komeil Nosrati","Juri Belikov","Aleksei Tepljakov","Eduard Petlenkov"],"url":"https://arxiv.org/abs/2505.12977"}
{"created":"2025-05-20","title":"From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents","abstract":"The growing adoption of large language models (LLMs) has led to a new paradigm in mobile computing--LLM-powered mobile AI agents--capable of decomposing and automating complex tasks directly on smartphones. However, the security implications of these agents remain largely unexplored. In this paper, we present the first comprehensive security analysis of mobile LLM agents, encompassing three representative categories: System-level AI Agents developed by original equipment manufacturers (e.g., YOYO Assistant), Third-party Universal Agents (e.g., Zhipu AI AutoGLM), and Emerging Agent Frameworks (e.g., Alibaba Mobile Agent). We begin by analyzing the general workflow of mobile agents and identifying security threats across three core capability dimensions: language-based reasoning, GUI-based interaction, and system-level execution. Our analysis reveals 11 distinct attack surfaces, all rooted in the unique capabilities and interaction patterns of mobile LLM agents, and spanning their entire operational lifecycle. To investigate these threats in practice, we introduce AgentScan, a semi-automated security analysis framework that systematically evaluates mobile LLM agents across all 11 attack scenarios. Applying AgentScan to nine widely deployed agents, we uncover a concerning trend: every agent is vulnerable to targeted attacks. In the most severe cases, agents exhibit vulnerabilities across eight distinct attack vectors. These attacks can cause behavioral deviations, privacy leakage, or even full execution hijacking. Based on these findings, we propose a set of defensive design principles and practical recommendations for building secure mobile LLM agents. Our disclosures have received positive feedback from two major device vendors. Overall, this work highlights the urgent need for standardized security practices in the fast-evolving landscape of LLM-driven mobile automation.","authors":["Liangxuan Wu","Chao Wang","Tianming Liu","Yanjie Zhao","Haoyu Wang"],"url":"https://arxiv.org/abs/2505.12981"}
{"created":"2025-05-20","title":"Multi-parameter Control for the (1+($\\lambda$,$\\lambda$))-GA on OneMax via Deep Reinforcement Learning","abstract":"It is well known that evolutionary algorithms can benefit from dynamic choices of the key parameters that control their behavior, to adjust their search strategy to the different stages of the optimization process. A prominent example where dynamic parameter choices have shown a provable super-constant speed-up is the $(1+(\\lambda,\\lambda))$ Genetic Algorithm optimizing the OneMax function. While optimal parameter control policies result in linear expected running times, this is not possible with static parameter choices. This result has spurred a lot of interest in parameter control policies. However, many works, in particular theoretical running time analyses, focus on controlling one single parameter. Deriving policies for controlling multiple parameters remains very challenging. In this work we reconsider the problem of the $(1+(\\lambda,\\lambda))$ Genetic Algorithm optimizing OneMax. We decouple its four main parameters and investigate how well state-of-the-art deep reinforcement learning techniques can approximate good control policies. We show that although making deep reinforcement learning learn effectively is a challenging task, once it works, it is very powerful and is able to find policies that outperform all previously known control policies on the same benchmark. Based on the results found through reinforcement learning, we derive a simple control policy that consistently outperforms the default theory-recommended setting by $27\\%$ and the irace-tuned policy, the strongest existing control policy on this benchmark, by $13\\%$, for all tested problem sizes up to $40{,}000$.","authors":["Tai Nguyen","Phong Le","Carola Doerr","Nguyen Dang"],"url":"https://arxiv.org/abs/2505.12982"}
{"created":"2025-05-20","title":"An Empirical Study of Many-to-Many Summarization with Large Language Models","abstract":"Many-to-many summarization (M2MS) aims to process documents in any language and generate the corresponding summaries also in any language. Recently, large language models (LLMs) have shown strong multi-lingual abilities, giving them the potential to perform M2MS in real applications. This work presents a systematic empirical study on LLMs' M2MS ability. Specifically, we first reorganize M2MS data based on eight previous domain-specific datasets. The reorganized data contains 47.8K samples spanning five domains and six languages, which could be used to train and evaluate LLMs. Then, we benchmark 18 LLMs in a zero-shot manner and an instruction-tuning manner. Fine-tuned traditional models (e.g., mBART) are also conducted for comparisons. Our experiments reveal that, zero-shot LLMs achieve competitive results with fine-tuned traditional models. After instruct-tuning, open-source LLMs can significantly improve their M2MS ability, and outperform zero-shot LLMs (including GPT-4) in terms of automatic evaluations. In addition, we demonstrate that this task-specific improvement does not sacrifice the LLMs' general task-solving abilities. However, as revealed by our human evaluation, LLMs still face the factuality issue, and the instruction tuning might intensify the issue. Thus, how to control factual errors becomes the key when building LLM summarizers in real applications, and is worth noting in future research.","authors":["Jiaan Wang","Fandong Meng","Zengkui Sun","Yunlong Liang","Yuxuan Cao","Jiarong Xu","Haoxiang Shi","Jie Zhou"],"url":"https://arxiv.org/abs/2505.12983"}
{"created":"2025-05-20","title":"High-Performance ARM-on-ARM Virtualization for Multicore SystemC-TLM-Based Virtual Platforms","abstract":"The increasing complexity of hardware and software requires advanced development and test methodologies for modern systems on chips. This paper presents a novel approach to ARM-on-ARM virtualization within SystemC-based simulators using Linux's KVM to achieve high-performance simulation. By running target software natively on ARM-based hosts with hardware-based virtualization extensions, our method eliminates the need for instruction-set simulators, which significantly improves performance. We present a multicore SystemC-TLM-based CPU model that can be used as a drop-in replacement for an instruction-set simulator. It places no special requirements on the host system, making it compatible with various environments. Benchmark results show that our ARM-on-ARM-based virtual platform achieves up to 10 x speedup over traditional instruction-set-simulator-based models on compute-intensive workloads. Depending on the benchmark, speedups increase to more than 100 x.","authors":["Nils Bosbach","Rebecca Pelke","Niko Zurstra{\\ss}en","Jan Henrik Weinstock","Lukas J\\\"unger","Rainer Leupers"],"url":"https://arxiv.org/abs/2505.12987"}
{"created":"2025-05-20","title":"Optimal Formats for Weight Quantisation","abstract":"Weight quantisation is an essential technique for enabling efficient training and deployment of modern deep learning models. However, the recipe book of quantisation formats is large and the formats are often chosen empirically. In this paper, we propose a framework for systematic design and analysis of quantisation formats. By connecting the question of format design with the classical quantisation theory, we show that the strong practical performance of popular formats comes from their ability to represent values using variable-length codes. Framing the optimisation problem as minimising the KL divergence between the original and quantised model outputs, the objective is aligned with minimising the squared quantisation error of the model parameters. We therefore develop and evaluate squared-error-optimal formats for known distributions, observing significant improvement of variable-length codes over fixed-length codes. Uniform quantisation followed by lossless compression with a variable-length code is shown to be optimal. However, we find that commonly used block formats and sparse outlier formats also outperform fixed-length codes, implying they also exploit variable-length encoding. Finally, by using the relationship between the Fisher information and KL divergence, we derive the optimal allocation of bit-widths to individual parameter tensors across the model's layers, saving up to 0.25 bits per parameter when tested with direct-cast quantisation of language models.","authors":["Douglas Orr","Luka Ribar","Carlo Luschi"],"url":"https://arxiv.org/abs/2505.12988"}
{"created":"2025-05-20","title":"Personalized Fine-Tuning with Controllable Synthetic Speech from LLM-Generated Transcripts for Dysarthric Speech Recognition","abstract":"In this work, we present our submission to the Speech Accessibility Project challenge for dysarthric speech recognition. We integrate parameter-efficient fine-tuning with latent audio representations to improve an encoder-decoder ASR system. Synthetic training data is generated by fine-tuning Parler-TTS to mimic dysarthric speech, using LLM-generated prompts for corpus-consistent target transcripts. Personalization with x-vectors consistently reduces word error rates (WERs) over non-personalized fine-tuning. AdaLoRA adapters outperform full fine-tuning and standard low-rank adaptation, achieving relative WER reductions of ~23% and ~22%, respectively. Further improvements (~5% WER reduction) come from incorporating wav2vec 2.0-based audio representations. Training with synthetic dysarthric speech yields up to ~7% relative WER improvement over personalized fine-tuning alone.","authors":["Dominik Wagner","Ilja Baumann","Natalie Engert","Seanie Lee","Elmar N\\\"oth","Korbinian Riedhammer","Tobias Bocklet"],"url":"https://arxiv.org/abs/2505.12991"}
{"created":"2025-05-20","title":"Fractured Chain-of-Thought Reasoning","abstract":"Inference-time scaling techniques have significantly bolstered the reasoning capabilities of large language models (LLMs) by harnessing additional computational effort at inference without retraining. Similarly, Chain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy by generating rich intermediate reasoning trajectories, but these approaches incur substantial token costs that impede their deployment in latency-sensitive settings. In this work, we first show that truncated CoT, which stops reasoning before completion and directly generates the final answer, often matches full CoT sampling while using dramatically fewer tokens. Building on this insight, we introduce Fractured Sampling, a unified inference-time strategy that interpolates between full CoT and solution-only sampling along three orthogonal axes: (1) the number of reasoning trajectories, (2) the number of final solutions per trajectory, and (3) the depth at which reasoning traces are truncated. Through extensive experiments on five diverse reasoning benchmarks and several model scales, we demonstrate that Fractured Sampling consistently achieves superior accuracy-cost trade-offs, yielding steep log-linear scaling gains in Pass@k versus token budget. Our analysis reveals how to allocate computation across these dimensions to maximize performance, paving the way for more efficient and scalable LLM reasoning.","authors":["Baohao Liao","Hanze Dong","Yuhui Xu","Doyen Sahoo","Christof Monz","Junnan Li","Caiming Xiong"],"url":"https://arxiv.org/abs/2505.12992"}
{"created":"2025-05-20","title":"Codec-Based Deepfake Source Tracing via Neural Audio Codec Taxonomy","abstract":"Recent advances in neural audio codec-based speech generation (CoSG) models have produced remarkably realistic audio deepfakes. We refer to deepfake speech generated by CoSG systems as codec-based deepfake, or CodecFake. Although existing anti-spoofing research on CodecFake predominantly focuses on verifying the authenticity of audio samples, almost no attention was given to tracing the CoSG used in generating these deepfakes. In CodecFake generation, processes such as speech-to-unit encoding, discrete unit modeling, and unit-to-speech decoding are fundamentally based on neural audio codecs. Motivated by this, we introduce source tracing for CodecFake via neural audio codec taxonomy, which dissects neural audio codecs to trace CoSG. Our experimental results on the CodecFake+ dataset provide promising initial evidence for the feasibility of CodecFake source tracing while also highlighting several challenges that warrant further investigation.","authors":["Xuanjun Chen","I-Ming Lin","Lin Zhang","Jiawei Du","Haibin Wu","Hung-yi Lee","Jyh-Shing Roger Jang"],"url":"https://arxiv.org/abs/2505.12994"}
{"created":"2025-05-20","title":"ACE: Confidential Computing for Embedded RISC-V Systems","abstract":"Confidential computing plays an important role in isolating sensitive applications from the vast amount of untrusted code commonly found in the modern cloud. We argue that it can also be leveraged to build safer and more secure mission-critical embedded systems. In this paper, we introduce the Assured Confidential Execution (ACE), an open-source and royalty-free confidential computing technology targeted for embedded RISC-V systems. We present a set of principles and a methodology that we used to build \\ACE and that might be applied for developing other embedded systems that require formal verification. An evaluation of our prototype on the first available RISC-V hardware supporting virtualization indicates that ACE is a viable candidate for our target systems.","authors":["Wojciech Ozga","Guerney D. H. Hunt","Michael V. Le","Lennard G\\\"aher","Avraham Shinnar","Elaine R. Palmer","Hani Jamjoom","Silvio Dragone"],"url":"https://arxiv.org/abs/2505.12995"}
{"created":"2025-05-20","title":"ExTrans: Multilingual Deep Reasoning Translation via Exemplar-Enhanced Reinforcement Learning","abstract":"In recent years, the emergence of large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, has shown impressive capabilities in complex problems, e.g., mathematics and coding. Some pioneering studies attempt to bring the success of LRMs in neural machine translation (MT). They try to build LRMs with deep reasoning MT ability via reinforcement learning (RL). Despite some progress that has been made, these attempts generally focus on several high-resource languages, e.g., English and Chinese, leaving the performance on other languages unclear. Besides, the reward modeling methods in previous work do not fully unleash the potential of reinforcement learning in MT. In this work, we first design a new reward modeling method that compares the translation results of the policy MT model with a strong LRM (i.e., DeepSeek-R1-671B), and quantifies the comparisons to provide rewards. Experimental results demonstrate the superiority of the reward modeling method. Using Qwen2.5-7B-Instruct as the backbone, the trained model achieves the new state-of-the-art performance in literary translation, and outperforms strong LRMs including OpenAI-o1 and DeepSeeK-R1. Furthermore, we extend our method to the multilingual settings with 11 languages. With a carefully designed lightweight reward modeling in RL, we can simply transfer the strong MT ability from a single direction into multiple (i.e., 90) translation directions and achieve impressive multilingual MT performance.","authors":["Jiaan Wang","Fandong Meng","Jie Zhou"],"url":"https://arxiv.org/abs/2505.12996"}
{"created":"2025-05-20","title":"A Skull-Adaptive Framework for AI-Based 3D Transcranial Focused Ultrasound Simulation","abstract":"Transcranial focused ultrasound (tFUS) is an emerging modality for non-invasive brain stimulation and therapeutic intervention, offering millimeter-scale spatial precision and the ability to target deep brain structures. However, the heterogeneous and anisotropic nature of the human skull introduces significant distortions to the propagating ultrasound wavefront, which require time-consuming patient-specific planning and corrections using numerical solvers for accurate targeting. To enable data-driven approaches in this domain, we introduce TFUScapes, the first large-scale, high-resolution dataset of tFUS simulations through anatomically realistic human skulls derived from T1-weighted MRI images. We have developed a scalable simulation engine pipeline using the k-Wave pseudo-spectral solver, where each simulation returns a steady-state pressure field generated by a focused ultrasound transducer placed at realistic scalp locations. In addition to the dataset, we present DeepTFUS, a deep learning model that estimates normalized pressure fields directly from input 3D CT volumes and transducer position. The model extends a U-Net backbone with transducer-aware conditioning, incorporating Fourier-encoded position embeddings and MLP layers to create global transducer embeddings. These embeddings are fused with U-Net encoder features via feature-wise modulation, dynamic convolutions, and cross-attention mechanisms. The model is trained using a combination of spatially weighted and gradient-sensitive loss functions, enabling it to approximate high-fidelity wavefields. The TFUScapes dataset is publicly released to accelerate research at the intersection of computational acoustics, neurotechnology, and deep learning. The project page is available at https://github.com/CAMMA-public/TFUScapes.","authors":["Vinkle Srivastav","Juliette Puel","Jonathan Vappou","Elijah Van Houten","Paolo Cabras","Nicolas Padoy"],"url":"https://arxiv.org/abs/2505.12998"}
{"created":"2025-05-20","title":"DualCodec: A Low-Frame-Rate, Semantically-Enhanced Neural Audio Codec for Speech Generation","abstract":"Neural audio codecs form the foundational building blocks for language model (LM)-based speech generation. Typically, there is a trade-off between frame rate and audio quality. This study introduces a low-frame-rate, semantically enhanced codec model. Existing approaches distill semantically rich self-supervised (SSL) representations into the first-layer codec tokens. This work proposes DualCodec, a dual-stream encoding approach that integrates SSL and waveform representations within an end-to-end codec framework. In this setting, DualCodec enhances the semantic information in the first-layer codec and enables the codec system to maintain high audio quality while operating at a low frame rate. Note that a low-frame-rate codec improves the efficiency of speech generation. Experimental results on audio codec and speech generation tasks confirm the effectiveness of the proposed DualCodec compared to state-of-the-art codec systems, such as Mimi Codec, SpeechTokenizer, DAC, and Encodec. Demos and codes are available at: https://dualcodec.github.io","authors":["Jiaqi Li","Xiaolong Lin","Zhekai Li","Shixi Huang","Yuancheng Wang","Chaoren Wang","Zhenpeng Zhan","Zhizheng Wu"],"url":"https://arxiv.org/abs/2505.13000"}
{"created":"2025-05-20","title":"PIM-malloc: A Fast and Scalable Dynamic Memory Allocator for Processing-In-Memory (PIM) Architectures","abstract":"Dynamic memory allocation is essential in modern programming but remains under-supported in current PIM devices. In this work, we first conduct a design space exploration of PIM memory allocators, examining optimal metadata placement and management strategies. Building on these insights, we propose PIM-malloc, a fast and scalable allocator for real PIM hardware, improving allocation performance by $66\\times$. We further enhance this design with a lightweight, per-PIM core hardware cache for dynamic allocation, achieving an additional $31\\%$ performance gain. Finally, we demonstrate the effectiveness of PIM-malloc using a dynamic graph update workload, achieving a $28\\times$ throughput increase.","authors":["Dongjae Lee","Bongjoon Hyun","Minsoo Rhu"],"url":"https://arxiv.org/abs/2505.13002"}
{"created":"2025-05-20","title":"EffiBench-X: A Multi-Language Benchmark for Measuring Efficiency of LLM-Generated Code","abstract":"Existing code generation benchmarks primarily evaluate functional correctness, with limited focus on code efficiency and often restricted to a single language like Python. To address this gap, we introduce EffiBench-X, the first multi-language benchmark designed to measure the efficiency of LLM-generated code. EffiBench-X supports Python, C++, Java, JavaScript, Ruby, and Golang. It comprises competitive programming tasks with human-expert solutions as efficiency baselines. Evaluating state-of-the-art LLMs on EffiBench-X reveals that while models generate functionally correct code, they consistently underperform human experts in efficiency. Even the most efficient LLM-generated solutions (Qwen3-32B) achieve only around \\textbf{62\\%} of human efficiency on average, with significant language-specific variations. LLMs show better efficiency in Python, Ruby, and JavaScript than in Java, C++, and Golang. For instance, DeepSeek-R1's Python code is significantly more efficient than its Java code. These results highlight the critical need for research into LLM optimization techniques to improve code efficiency across diverse languages. The dataset and evaluation infrastructure are submitted and available at https://github.com/EffiBench/EffiBench-X.git and https://huggingface.co/datasets/EffiBench/effibench-x.","authors":["Yuhao Qing","Boyu Zhu","Mingzhe Du","Zhijiang Guo","Terry Yue Zhuo","Qianru Zhang","Jie M. Zhang","Heming Cui","Siu-Ming Yiu","Dong Huang","See-Kiong Ng","Luu Anh Tuan"],"url":"https://arxiv.org/abs/2505.13004"}
{"created":"2025-05-20","title":"Evaluating the Performance of RAG Methods for Conversational AI in the Airport Domain","abstract":"Airports from the top 20 in terms of annual passengers are highly dynamic environments with thousands of flights daily, and they aim to increase the degree of automation. To contribute to this, we implemented a Conversational AI system that enables staff in an airport to communicate with flight information systems. This system not only answers standard airport queries but also resolves airport terminology, jargon, abbreviations, and dynamic questions involving reasoning. In this paper, we built three different Retrieval-Augmented Generation (RAG) methods, including traditional RAG, SQL RAG, and Knowledge Graph-based RAG (Graph RAG). Experiments showed that traditional RAG achieved 84.84% accuracy using BM25 + GPT-4 but occasionally produced hallucinations, which is risky to airport safety. In contrast, SQL RAG and Graph RAG achieved 80.85% and 91.49% accuracy respectively, with significantly fewer hallucinations. Moreover, Graph RAG was especially effective for questions that involved reasoning. Based on our observations, we thus recommend SQL RAG and Graph RAG are better for airport environments, due to fewer hallucinations and the ability to handle dynamic questions.","authors":["Yuyang Li","Philip J. M. Kerbusch","Raimon H. R. Pruim","Tobias K\\\"afer"],"url":"https://arxiv.org/abs/2505.13006"}
{"created":"2025-05-20","title":"Generative Modeling of Random Fields from Limited Data via Constrained Latent Flow Matching","abstract":"Deep generative models are promising tools for science and engineering, but their reliance on abundant, high-quality data limits applicability. We present a novel framework for generative modeling of random fields (probability distributions over continuous functions) that incorporates domain knowledge to supplement limited, sparse, and indirect data. The foundation of the approach is latent flow matching, where generative modeling occurs on compressed function representations in the latent space of a pre-trained variational autoencoder (VAE). Innovations include the adoption of a function decoder within the VAE and integration of physical/statistical constraints into the VAE training process. In this way, a latent function representation is learned that yields continuous random field samples satisfying domain-specific constraints when decoded, even in data-limited regimes. Efficacy is demonstrated on two challenging applications: wind velocity field reconstruction from sparse sensors and material property inference from a limited number of indirect measurements. Results show that the proposed framework achieves significant improvements in reconstruction accuracy compared to unconstrained methods and enables effective inference with relatively small training datasets that is intractable without constraints.","authors":["James E. Warner","Tristan A. Shah","Patrick E. Leser","Geoffrey F. Bomarito","Joshua D. Pribe","Michael C. Stanley"],"url":"https://arxiv.org/abs/2505.13007"}
{"created":"2025-05-20","title":"Adversarial Reasoning for Repair Based on Inferred Program Intent","abstract":"Automated program repair (APR) has shown promising results, particularly with the use of neural networks. Currently, most APR tools focus on code transformations specified by test suites, rather than reasoning about the program intent and the high-level bug specification. Without a proper understanding of program intent, these tools tend to generate patches that overfit incomplete test suites and fail to reflect the developers intentions. However, reasoning about program intent is challenging. In our work, we propose an approach called AdverIntent-Agent, based on critique and adversarial reasoning. Our approach is novel to shift the focus from generating multiple APR patches to inferring multiple potential program intents. Ideally, we aim to infer intents that are, to some extent, adversarial to each other, maximizing the probability that at least one aligns closely with the developers original intent. AdverIntent-Agent is a multi-agent approach consisting of three agents: a reasoning agent, a test agent, and a repair agent. First, the reasoning agent generates adversarial program intents along with the corresponding faulty statements. Next, the test agent produces adversarial test cases that align with each inferred intent, constructing oracles that use the same inputs but have different expected outputs. Finally, the repair agent uses dynamic and precise LLM prompts to generate patches that satisfy both the inferred program intent and the generated tests. AdverIntent-Agent was evaluated on two benchmarks: Defects4J 2.0 and HumanEval-Java. AdverIntent-Agent correctly repaired 77 and 105 bugs in both benchmarks, respectively.","authors":["He Ye","Aidan Z. H. Yang","Chang Hu","Yanlin Wang","Tao Zhang","Claire Le Goues"],"url":"https://arxiv.org/abs/2505.13008"}
{"created":"2025-05-20","title":"Manifesto from Dagstuhl Perspectives Workshop 24452 -- Reframing Technical Debt","abstract":"This is the Dagstuhl Perspectives Workshop 24452 manifesto on Reframing Technical Debt. The manifesto begins with a one-page summary of Values, Beliefs, and Principles. It then elaborates on each Value, Belief, and Principle to explain their rationale and clarify their meaning. Subsequently, the paper describes the current landscape of Technical Debt Management methods and tools and explains why the current practice is inadequate and where current research falls short. The current landscape is organized into five major topics: Technical Debt as Value-Creation, Tooling, Data Collection, the role of Architecture, and Socio-Technical Aspects. Finally, the paper outlines a roadmap to realize the stated principles, with concrete milestones to be addressed by researchers, software practitioners, and tool vendors. The manifesto is signed by the workshop participants.","authors":["Paris Avgeriou","Ipek Ozkaya","Heiko Koziolek","Zadia Codabux","Neil Ernst"],"url":"https://arxiv.org/abs/2505.13009"}
{"created":"2025-05-20","title":"To Bias or Not to Bias: Detecting bias in News with bias-detector","abstract":"Media bias detection is a critical task in ensuring fair and balanced information dissemination, yet it remains challenging due to the subjectivity of bias and the scarcity of high-quality annotated data. In this work, we perform sentence-level bias classification by fine-tuning a RoBERTa-based model on the expert-annotated BABE dataset. Using McNemar's test and the 5x2 cross-validation paired t-test, we show statistically significant improvements in performance when comparing our model to a domain-adaptively pre-trained DA-RoBERTa baseline. Furthermore, attention-based analysis shows that our model avoids common pitfalls like oversensitivity to politically charged terms and instead attends more meaningfully to contextually relevant tokens. For a comprehensive examination of media bias, we present a pipeline that combines our model with an already-existing bias-type classifier. Our method exhibits good generalization and interpretability, despite being constrained by sentence-level analysis and dataset size because of a lack of larger and more advanced bias corpora. We talk about context-aware modeling, bias neutralization, and advanced bias type classification as potential future directions. Our findings contribute to building more robust, explainable, and socially responsible NLP systems for media bias detection.","authors":["Himel Ghosh","Ahmed Mosharafa","Georg Groh"],"url":"https://arxiv.org/abs/2505.13010"}
{"created":"2025-05-20","title":"Unveiling and Steering Connectome Organization with Interpretable Latent Variables","abstract":"The brain's intricate connectome, a blueprint for its function, presents immense complexity, yet it arises from a compact genetic code, hinting at underlying low-dimensional organizational principles. This work bridges connectomics and representation learning to uncover these principles. We propose a framework that combines subgraph extraction from the Drosophila connectome, FlyWire, with a generative model to derive interpretable low-dimensional representations of neural circuitry. Crucially, an explainability module links these latent dimensions to specific structural features, offering insights into their functional relevance. We validate our approach by demonstrating effective graph reconstruction and, significantly, the ability to manipulate these latent codes to controllably generate connectome subgraphs with predefined properties. This research offers a novel tool for understanding brain architecture and a potential avenue for designing bio-inspired artificial neural networks.","authors":["Yubin Li","Xingyu Liu","Guozhang Chen"],"url":"https://arxiv.org/abs/2505.13011"}
{"created":"2025-05-20","title":"Anti-Inpainting: A Proactive Defense against Malicious Diffusion-based Inpainters under Unknown Conditions","abstract":"As diffusion-based malicious image manipulation becomes increasingly prevalent, multiple proactive defense methods are developed to safeguard images against unauthorized tampering. However, most proactive defense methods only can safeguard images against manipulation under known conditions, and fail to protect images from manipulations guided by tampering conditions crafted by malicious users. To tackle this issue, we propose Anti-Inpainting, a proactive defense method that achieves adequate protection under unknown conditions through a triple mechanism to address this challenge. Specifically, a multi-level deep feature extractor is presented to obtain intricate features during the diffusion denoising process to improve protective effectiveness. We design multi-scale semantic-preserving data augmentation to enhance the transferability of adversarial perturbations across unknown conditions by multi-scale transformations while preserving semantic integrity. In addition, we propose a selection-based distribution deviation optimization strategy to improve the protection of adversarial perturbation against manipulation under diverse random seeds. Extensive experiments indicate the proactive defensive performance of Anti-Inpainting against diffusion-based inpainters guided by unknown conditions in InpaintGuardBench and CelebA-HQ. At the same time, we also demonstrate the proposed approach's robustness under various image purification methods and its transferability across different versions of diffusion models.","authors":["Yimao Guo","Zuomin Qu","Wei Lu","Xiangyang Luo"],"url":"https://arxiv.org/abs/2505.13023"}
{"created":"2025-05-20","title":"LiBOG: Lifelong Learning for Black-Box Optimizer Generation","abstract":"Meta-Black-Box Optimization (MetaBBO) garners attention due to its success in automating the configuration and generation of black-box optimizers, significantly reducing the human effort required for optimizer design and discovering optimizers with higher performance than classic human-designed optimizers. However, existing MetaBBO methods conduct one-off training under the assumption that a stationary problem distribution with extensive and representative training problem samples is pre-available. This assumption is often impractical in real-world scenarios, where diverse problems following shifting distribution continually arise. Consequently, there is a pressing need for methods that can continuously learn from new problems encountered on-the-fly and progressively enhance their capabilities. In this work, we explore a novel paradigm of lifelong learning in MetaBBO and introduce LiBOG, a novel approach designed to learn from sequentially encountered problems and generate high-performance optimizers for Black-Box Optimization (BBO). LiBOG consolidates knowledge both across tasks and within tasks to mitigate catastrophic forgetting. Extensive experiments demonstrate LiBOG's effectiveness in learning to generate high-performance optimizers in a lifelong learning manner, addressing catastrophic forgetting while maintaining plasticity to learn new tasks.","authors":["Jiyuan Pei","Yi Mei","Jialin Liu","Mengjie Zhang"],"url":"https://arxiv.org/abs/2505.13025"}
{"created":"2025-05-20","title":"Step-wise Adaptive Integration of Supervised Fine-tuning and Reinforcement Learning for Task-Specific LLMs","abstract":"Large language models (LLMs) excel at mathematical reasoning and logical problem-solving. The current popular training paradigms primarily use supervised fine-tuning (SFT) and reinforcement learning (RL) to enhance the models' reasoning abilities. However, when using SFT or RL alone, there are respective challenges: SFT may suffer from overfitting, while RL is prone to mode collapse. The state-of-the-art methods have proposed hybrid training schemes. However, static switching faces challenges such as poor generalization across different tasks and high dependence on data quality. In response to these challenges, inspired by the curriculum learning-quiz mechanism in human reasoning cultivation, We propose SASR, a step-wise adaptive hybrid training framework that theoretically unifies SFT and RL and dynamically balances the two throughout optimization. SASR uses SFT for initial warm-up to establish basic reasoning skills, and then uses an adaptive dynamic adjustment algorithm based on gradient norm and divergence relative to the original distribution to seamlessly integrate SFT with the online RL method GRPO. By monitoring the training status of LLMs and adjusting the training process in sequence, SASR ensures a smooth transition between training schemes, maintaining core reasoning abilities while exploring different paths. Experimental results demonstrate that SASR outperforms SFT, RL, and static hybrid training methods.","authors":["Jack Chen","Fazhong Liu","Naruto Liu","Yuhan Luo","Erqu Qin","Harry Zheng","Tian Dong","Haojin Zhu","Yan Meng","Xiao Wang"],"url":"https://arxiv.org/abs/2505.13026"}
{"created":"2025-05-20","title":"Unpacking Positional Encoding in Transformers: A Spectral Analysis of Content-Position Coupling","abstract":"Positional encoding (PE) is essential for enabling Transformers to model sequential structure. However, the mechanisms by which different PE schemes couple token content and positional information-and how these mechanisms influence model dynamics-remain theoretically underexplored. In this work, we present a unified framework that analyzes PE through the spectral properties of Toeplitz and related matrices derived from attention logits. We show that multiplicative content-position coupling-exemplified by Rotary Positional Encoding (RoPE) via a Hadamard product with a Toeplitz matrix-induces spectral contraction, which theoretically improves optimization stability and efficiency. Guided by this theory, we construct synthetic tasks that contrast content-position dependent and content-position independent settings, and evaluate a range of PE methods. Our experiments reveal strong alignment with theory: RoPE consistently outperforms other methods on position-sensitive tasks and induces \"single-head deposit\" patterns in early layers, indicating localized positional processing. Further analyses show that modifying the method and timing of PE coupling, such as MLA in Deepseek-V3, can effectively mitigate this concentration. These results establish explicit content-relative mixing with relative-position Toeplitz signals as a key principle for effective PE design and provide new insight into how positional structure is integrated in Transformer architectures.","authors":["Zihan Gu","Han Zhang","Ruoyu Chen","Yue Hu","Hua Zhang"],"url":"https://arxiv.org/abs/2505.13027"}
{"created":"2025-05-20","title":"Evaluatiing the efficacy of LLM Safety Solutions : The Palit Benchmark Dataset","abstract":"Large Language Models (LLMs) are increasingly integrated into critical systems in industries like healthcare and finance. Users can often submit queries to LLM-enabled chatbots, some of which can enrich responses with information retrieved from internal databases storing sensitive data. This gives rise to a range of attacks in which a user submits a malicious query and the LLM-system outputs a response that creates harm to the owner, such as leaking internal data or creating legal liability by harming a third-party. While security tools are being developed to counter these threats, there is little formal evaluation of their effectiveness and usability. This study addresses this gap by conducting a thorough comparative analysis of LLM security tools. We identified 13 solutions (9 closed-source, 4 open-source), but only 7 were evaluated due to a lack of participation by proprietary model owners.To evaluate, we built a benchmark dataset of malicious prompts, and evaluate these tools performance against a baseline LLM model (ChatGPT-3.5-Turbo). Our results show that the baseline model has too many false positives to be used for this task. Lakera Guard and ProtectAI LLM Guard emerged as the best overall tools showcasing the tradeoff between usability and performance. The study concluded with recommendations for greater transparency among closed source providers, improved context-aware detections, enhanced open-source engagement, increased user awareness, and the adoption of more representative performance metrics.","authors":["Sayon Palit","Daniel Woods"],"url":"https://arxiv.org/abs/2505.13028"}
{"created":"2025-05-20","title":"MindOmni: Unleashing Reasoning Generation in Vision Language Models with RGPO","abstract":"Recent text-to-image systems face limitations in handling multimodal inputs and complex reasoning tasks. We introduce MindOmni, a unified multimodal large language model that addresses these challenges by incorporating reasoning generation through reinforcement learning. MindOmni leverages a three-phase training strategy: i) design of a unified vision language model with a decoder-only diffusion module, ii) supervised fine-tuning with Chain-of-Thought (CoT) instruction data, and iii) our proposed Reasoning Generation Policy Optimization (RGPO) algorithm, utilizing multimodal feedback to effectively guide policy updates. Experimental results demonstrate that MindOmni outperforms existing models, achieving impressive performance on both understanding and generation benchmarks, meanwhile showcasing advanced fine-grained reasoning generation capabilities, especially with mathematical reasoning instruction. All codes will be made public at \\href{https://github.com/EasonXiao-888/MindOmni}{https://github.com/EasonXiao-888/MindOmni}.","authors":["Yicheng Xiao","Lin Song","Yukang Chen","Yingmin Luo","Yuxin Chen","Yukang Gan","Wei Huang","Xiu Li","Xiaojuan Qi","Ying Shan"],"url":"https://arxiv.org/abs/2505.13031"}
{"created":"2025-05-20","title":"MMAR: A Challenging Benchmark for Deep Reasoning in Speech, Audio, Music, and Their Mix","abstract":"We introduce MMAR, a new benchmark designed to evaluate the deep reasoning capabilities of Audio-Language Models (ALMs) across massive multi-disciplinary tasks. MMAR comprises 1,000 meticulously curated audio-question-answer triplets, collected from real-world internet videos and refined through iterative error corrections and quality checks to ensure high quality. Unlike existing benchmarks that are limited to specific domains of sound, music, or speech, MMAR extends them to a broad spectrum of real-world audio scenarios, including mixed-modality combinations of sound, music, and speech. Each question in MMAR is hierarchically categorized across four reasoning layers: Signal, Perception, Semantic, and Cultural, with additional sub-categories within each layer to reflect task diversity and complexity. To further foster research in this area, we annotate every question with a Chain-of-Thought (CoT) rationale to promote future advancements in audio reasoning. Each item in the benchmark demands multi-step deep reasoning beyond surface-level understanding. Moreover, a part of the questions requires graduate-level perceptual and domain-specific knowledge, elevating the benchmark's difficulty and depth. We evaluate MMAR using a broad set of models, including Large Audio-Language Models (LALMs), Large Audio Reasoning Models (LARMs), Omni Language Models (OLMs), Large Language Models (LLMs), and Large Reasoning Models (LRMs), with audio caption inputs. The performance of these models on MMAR highlights the benchmark's challenging nature, and our analysis further reveals critical limitations of understanding and reasoning capabilities among current models. We hope MMAR will serve as a catalyst for future advances in this important but little-explored area.","authors":["Ziyang Ma","Yinghao Ma","Yanqiao Zhu","Chen Yang","Yi-Wen Chao","Ruiyang Xu","Wenxi Chen","Yuanzhe Chen","Zhuo Chen","Jian Cong","Kai Li","Keliang Li","Siyou Li","Xinfeng Li","Xiquan Li","Zheng Lian","Yuzhe Liang","Minghao Liu","Zhikang Niu","Tianrui Wang","Yuping Wang","Yuxuan Wang","Yihao Wu","Guanrou Yang","Jianwei Yu","Ruibin Yuan","Zhisheng Zheng","Ziya Zhou","Haina Zhu","Wei Xue","Emmanouil Benetos","Kai Yu","Eng-Siong Chng","Xie Chen"],"url":"https://arxiv.org/abs/2505.13032"}
{"created":"2025-05-20","title":"TSPulse: Dual Space Tiny Pre-Trained Models for Rapid Time-Series Analysis","abstract":"The rise of time-series pre-trained models has advanced temporal representation learning, but current state-of-the-art models are often large-scale, requiring substantial compute. We introduce TSPulse, ultra-compact time-series pre-trained models with only 1M parameters, specialized to perform strongly across classification, anomaly detection, imputation, and retrieval tasks. TSPulse introduces innovations at both the architecture and task levels. At the architecture level, it employs a dual-space masked reconstruction, learning from both time and frequency domains to capture complementary signals. This is further enhanced by a dual-embedding disentanglement, generating both detailed embeddings for fine-grained analysis and high-level semantic embeddings for broader task understanding. Notably, TSPulse's semantic embeddings are robust to shifts in time, magnitude, and noise, which is important for robust retrieval. At the task level, TSPulse incorporates TSLens, a fine-tuning component enabling task-specific feature attention. It also introduces a multi-head triangulation technique that correlates deviations from multiple prediction heads, enhancing anomaly detection by fusing complementary model outputs. Additionally, a hybrid mask pretraining is proposed to improves zero-shot imputation by reducing pre-training bias. These architecture and task innovations collectively contribute to TSPulse's significant performance gains: 5-16% on the UEA classification benchmarks, +20% on the TSB-AD anomaly detection leaderboard, +50% in zero-shot imputation, and +25% in time-series retrieval. Remarkably, these results are achieved with just 1M parameters, making TSPulse 10-100X smaller than existing pre-trained models. Its efficiency enables GPU-free inference and rapid pre-training, setting a new standard for efficient time-series pre-trained models. Models will be open-sourced soon.","authors":["Vijay Ekambaram","Subodh Kumar","Arindam Jati","Sumanta Mukherjee","Tomoya Sakai","Pankaj Dayama","Wesley M. Gifford","Jayant Kalagnanam"],"url":"https://arxiv.org/abs/2505.13033"}
{"created":"2025-05-20","title":"topicwizard -- a Modern, Model-agnostic Framework for Topic Model Visualization and Interpretation","abstract":"Topic models are statistical tools that allow their users to gain qualitative and quantitative insights into the contents of textual corpora without the need for close reading. They can be applied in a wide range of settings from discourse analysis, through pretraining data curation, to text filtering. Topic models are typically parameter-rich, complex models, and interpreting these parameters can be challenging for their users. It is typical practice for users to interpret topics based on the top 10 highest ranking terms on a given topic. This list-of-words approach, however, gives users a limited and biased picture of the content of topics. Thoughtful user interface design and visualizations can help users gain a more complete and accurate understanding of topic models' output. While some visualization utilities do exist for topic models, these are typically limited to a certain type of topic model. We introduce topicwizard, a framework for model-agnostic topic model interpretation, that provides intuitive and interactive tools that help users examine the complex semantic relations between documents, words and topics learned by topic models.","authors":["M\\'arton Kardos","Kenneth C. Enevoldsen","Kristoffer Laigaard Nielbo"],"url":"https://arxiv.org/abs/2505.13034"}
{"created":"2025-05-20","title":"KIT's Offline Speech Translation and Instruction Following Submission for IWSLT 2025","abstract":"The scope of the International Workshop on Spoken Language Translation (IWSLT) has recently broadened beyond traditional Speech Translation (ST) to encompass a wider array of tasks, including Speech Question Answering and Summarization. This shift is partly driven by the growing capabilities of modern systems, particularly with the success of Large Language Models (LLMs). In this paper, we present the Karlsruhe Institute of Technology's submissions for the Offline ST and Instruction Following (IF) tracks, where we leverage LLMs to enhance performance across all tasks. For the Offline ST track, we propose a pipeline that employs multiple automatic speech recognition systems, whose outputs are fused using an LLM with document-level context. This is followed by a two-step translation process, incorporating additional refinement step to improve translation quality. For the IF track, we develop an end-to-end model that integrates a speech encoder with an LLM to perform a wide range of instruction-following tasks. We complement it with a final document-level refinement stage to further enhance output quality by using contextual information.","authors":["Sai Koneru","Maike Z\\\"ufle","Thai-Binh Nguyen","Seymanur Akti","Jan Niehues","Alexander Waibel"],"url":"https://arxiv.org/abs/2505.13036"}
{"created":"2025-05-20","title":"Expert-Like Reparameterization of Heterogeneous Pyramid Receptive Fields in Efficient CNNs for Fair Medical Image Classification","abstract":"Efficient convolutional neural network (CNN) architecture designs have attracted growing research interests. However, they usually apply single receptive field (RF), small asymmetric RFs, or pyramid RFs to learn different feature representations, still encountering two significant challenges in medical image classification tasks: 1) They have limitations in capturing diverse lesion characteristics efficiently, e.g., tiny, coordination, small and salient, which have unique roles on results, especially imbalanced medical image classification. 2) The predictions generated by those CNNs are often unfair/biased, bringing a high risk by employing them to real-world medical diagnosis conditions. To tackle these issues, we develop a new concept, Expert-Like Reparameterization of Heterogeneous Pyramid Receptive Fields (ERoHPRF), to simultaneously boost medical image classification performance and fairness. This concept aims to mimic the multi-expert consultation mode by applying the well-designed heterogeneous pyramid RF bags to capture different lesion characteristics effectively via convolution operations with multiple heterogeneous kernel sizes. Additionally, ERoHPRF introduces an expert-like structural reparameterization technique to merge its parameters with the two-stage strategy, ensuring competitive computation cost and inference speed through comparisons to a single RF. To manifest the effectiveness and generalization ability of ERoHPRF, we incorporate it into mainstream efficient CNN architectures. The extensive experiments show that our method maintains a better trade-off than state-of-the-art methods in terms of medical image classification, fairness, and computation overhead. The codes of this paper will be released soon.","authors":["Xiao Wu","Xiaoqing Zhang","Zunjie Xiao","Lingxi Hu","Risa Higashita","Jiang Liu"],"url":"https://arxiv.org/abs/2505.13039"}
{"created":"2025-05-20","title":"A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation","abstract":"Aiming to generalize the well-trained gaze estimation model to new target domains, Cross-domain Gaze Estimation (CDGE) is developed for real-world application scenarios. Existing CDGE methods typically extract the domain-invariant features to mitigate domain shift in feature space, which is proved insufficient by Generalized Label Shift (GLS) theory. In this paper, we introduce a novel GLS perspective to CDGE and modelize the cross-domain problem by label and conditional shift problem. A GLS correction framework is presented and a feasible realization is proposed, in which a importance reweighting strategy based on truncated Gaussian distribution is introduced to overcome the continuity challenges in label shift correction. To embed the reweighted source distribution to conditional invariant learning, we further derive a probability-aware estimation of conditional operator discrepancy. Extensive experiments on standard CDGE tasks with different backbone models validate the superior generalization capability across domain and applicability on various models of proposed method.","authors":["Hao-Ran Yang","Xiaohui Chen","Chuan-Xian Ren"],"url":"https://arxiv.org/abs/2505.13043"}
{"created":"2025-05-20","title":"CAIM: Development and Evaluation of a Cognitive AI Memory Framework for Long-Term Interaction with Intelligent Agents","abstract":"Large language models (LLMs) have advanced the field of artificial intelligence (AI) and are a powerful enabler for interactive systems. However, they still face challenges in long-term interactions that require adaptation towards the user as well as contextual knowledge and understanding of the ever-changing environment. To overcome these challenges, holistic memory modeling is required to efficiently retrieve and store relevant information across interaction sessions for suitable responses. Cognitive AI, which aims to simulate the human thought process in a computerized model, highlights interesting aspects, such as thoughts, memory mechanisms, and decision-making, that can contribute towards improved memory modeling for LLMs. Inspired by these cognitive AI principles, we propose our memory framework CAIM. CAIM consists of three modules: 1.) The Memory Controller as the central decision unit; 2.) the Memory Retrieval, which filters relevant data for interaction upon request; and 3.) the Post-Thinking, which maintains the memory storage. We compare CAIM against existing approaches, focusing on metrics such as retrieval accuracy, response correctness, contextual coherence, and memory storage. The results demonstrate that CAIM outperforms baseline frameworks across different metrics, highlighting its context-awareness and potential to improve long-term human-AI interactions.","authors":["Rebecca Westh\\\"au{\\ss}er","Frederik Berenz","Wolfgang Minker","Sebastian Zepf"],"url":"https://arxiv.org/abs/2505.13044"}
{"created":"2025-05-20","title":"StudyAlign: A Software System for Conducting Web-Based User Studies with Functional Interactive Prototypes","abstract":"Interactive systems are commonly prototyped as web applications. This approach enables studies with functional prototypes on a large scale. However, setting up these studies can be complex due to implementing experiment procedures, integrating questionnaires, and data logging. To enable such user studies, we developed the software system StudyAlign which offers: 1) a frontend for participants, 2) an admin panel to manage studies, 3) the possibility to integrate questionnaires, 4) a JavaScript library to integrate data logging into prototypes, and 5) a backend server for persisting log data, and serving logical functions via an API to the different parts of the system. With our system, researchers can set up web-based experiments and focus on the design and development of interactions and prototypes. Furthermore, our systematic approach facilitates the replication of studies and reduces the required effort to execute web-based user studies. We conclude with reflections on using StudyAlign for conducting HCI studies online.","authors":["Florian Lehmann","Daniel Buschek"],"url":"https://arxiv.org/abs/2505.13046"}
{"created":"2025-05-20","title":"PPTNet: A Hybrid Periodic Pattern-Transformer Architecture for Traffic Flow Prediction and Congestion Identification","abstract":"Accurate prediction of traffic flow parameters and real time identification of congestion states are essential for the efficient operation of intelligent transportation systems. This paper proposes a Periodic Pattern Transformer Network (PPTNet) for traffic flow prediction, integrating periodic pattern extraction with the Transformer architecture, coupled with a fuzzy inference method for real-time congestion identification. Firstly, a high-precision traffic flow dataset (Traffic Flow Dataset for China's Congested Highways and Expressways, TF4CHE) suitable for congested highway scenarios in China is constructed based on drone aerial imagery data. Subsequently, the proposed PPTNet employs Fast Fourier Transform to capture multi-scale periodic patterns and utilizes two-dimensional Inception convolutions to efficiently extract intra and inter periodic features. A Transformer decoder dynamically models temporal dependencies, enabling accurate predictions of traffic density and speed. Finally, congestion probabilities are calculated in real-time using the predicted outcomes via a Mamdani fuzzy inference-based congestion identification module. Experimental results demonstrate that the proposed PPTNet significantly outperforms mainstream traffic prediction methods in prediction accuracy, and the congestion identification module effectively identifies real-time road congestion states, verifying the superiority and practicality of the proposed method in real-world traffic scenarios. Project page: https://github.com/ADSafetyJointLab/PPTNet.","authors":["Hongrui Kou","Jingkai Li","Ziyu Wang","Zhouhang Lv","Yuxin Zhang","Cheng Wang"],"url":"https://arxiv.org/abs/2505.13047"}
{"created":"2025-05-20","title":"RGB-to-Polarization Estimation: A New Task and Benchmark Study","abstract":"Polarization images provide rich physical information that is fundamentally absent from standard RGB images, benefiting a wide range of computer vision applications such as reflection separation and material classification. However, the acquisition of polarization images typically requires additional optical components, which increases both the cost and the complexity of the applications. To bridge this gap, we introduce a new task: RGB-to-polarization image estimation, which aims to infer polarization information directly from RGB images. In this work, we establish the first comprehensive benchmark for this task by leveraging existing polarization datasets and evaluating a diverse set of state-of-the-art deep learning models, including both restoration-oriented and generative architectures. Through extensive quantitative and qualitative analysis, our benchmark not only establishes the current performance ceiling of RGB-to-polarization estimation, but also systematically reveals the respective strengths and limitations of different model families -- such as direct reconstruction versus generative synthesis, and task-specific training versus large-scale pre-training. In addition, we provide some potential directions for future research on polarization estimation. This benchmark is intended to serve as a foundational resource to facilitate the design and evaluation of future methods for polarization estimation from standard RGB inputs.","authors":["Beibei Lin","Zifeng Yuan","Tingting Chen"],"url":"https://arxiv.org/abs/2505.13050"}
{"created":"2025-05-20","title":"SNAPE-PM: Building and Utilizing Dynamic Partner Models for Adaptive Explanation Generation","abstract":"Adapting to the addressee is crucial for successful explanations, yet poses significant challenges for dialogsystems. We adopt the approach of treating explanation generation as a non-stationary decision process, where the optimal strategy varies according to changing beliefs about the explainee and the interaction context. In this paper we address the questions of (1) how to track the interaction context and the relevant listener features in a formally defined computational partner model, and (2) how to utilize this model in the dynamically adjusted, rational decision process that determines the currently best explanation strategy. We propose a Bayesian inference-based approach to continuously update the partner model based on user feedback, and a non-stationary Markov Decision Process to adjust decision-making based on the partner model values. We evaluate an implementation of this framework with five simulated interlocutors, demonstrating its effectiveness in adapting to different partners with constant and even changing feedback behavior. The results show high adaptivity with distinct explanation strategies emerging for different partners, highlighting the potential of our approach to improve explainable AI systems and dialogsystems in general.","authors":["Amelie S. Robrecht","Christoph R. Kowalski","Stefan Kopp"],"url":"https://arxiv.org/abs/2505.13053"}
{"created":"2025-05-20","title":"Disentangling Coordiante Frames for Task Specific Motion Retargeting in Teleoperation using Shared Control and VR Controllers","abstract":"Task performance in terms of task completion time in teleoperation is still far behind compared to humans conducting tasks directly. One large identified impact on this is the human capability to perform transformations and alignments, which is directly influenced by the point of view and the motion retargeting strategy. In modern teleoperation systems, motion retargeting is usually implemented through a one time calibration or switching modes. Complex tasks, like concatenated screwing, might be difficult, because the operator has to align (e.g. mirror) rotational and translational input commands. Recent research has shown, that the separation of translation and rotation leads to increased task performance. This work proposes a formal motion retargeting method, which separates translational and rotational input commands. This method is then included in a optimal control based trajectory planner and shown to work on a UR5e manipulator.","authors":["Max Grobbel","Daniel Fl\\\"ogel","Philipp Rigoll","S\\\"oren Hohmann"],"url":"https://arxiv.org/abs/2505.13054"}
{"created":"2025-05-20","title":"A Path to Universal Neural Cellular Automata","abstract":"Cellular automata have long been celebrated for their ability to generate complex behaviors from simple, local rules, with well-known discrete models like Conway's Game of Life proven capable of universal computation. Recent advancements have extended cellular automata into continuous domains, raising the question of whether these systems retain the capacity for universal computation. In parallel, neural cellular automata have emerged as a powerful paradigm where rules are learned via gradient descent rather than manually designed. This work explores the potential of neural cellular automata to develop a continuous Universal Cellular Automaton through training by gradient descent. We introduce a cellular automaton model, objective functions and training strategies to guide neural cellular automata toward universal computation in a continuous setting. Our experiments demonstrate the successful training of fundamental computational primitives - such as matrix multiplication and transposition - culminating in the emulation of a neural network solving the MNIST digit classification task directly within the cellular automata state. These results represent a foundational step toward realizing analog general-purpose computers, with implications for understanding universal computation in continuous dynamics and advancing the automated discovery of complex cellular automata behaviors via machine learning.","authors":["Gabriel B\\'ena","Maxence Faldor","Dan F. M. Goodman","Antoine Cully"],"url":"https://arxiv.org/abs/2505.13058"}
{"created":"2025-05-20","title":"Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs","abstract":"Quantization is essential for Neural Network (NN) compression, reducing model size and computational demands by using lower bit-width data types, though aggressive reduction often hampers accuracy. Mixed Precision (MP) mitigates this tradeoff by varying the numerical precision across network layers. This study focuses on automatically selecting an optimal MP configuration within Post-Training Quantization (PTQ) for inference. The first key contribution is a novel sensitivity metric derived from a first-order Taylor series expansion of the loss function as a function of quantization errors in weights and activations. This metric, based on the Mean Square Error (MSE) of the loss, is efficiently calculated per layer using high-precision forward and backward passes over a small calibration dataset. The metric is additive across layers, with low calibration memory overhead as weight optimization is unnecessary. The second contribution is an accurate hardware-aware method for predicting MP time gain by modeling it as additive for sequential sub-graphs. An algorithm partitions the model graph into sequential subgraphs, measuring time gain for each configuration using a few samples. After calibrating per-layer sensitivity and time gain, an Integer Programming (IP) problem is formulated to maximize time gain while keeping loss MSE below a set threshold. Memory gain and theoretical time gain based on Multiply and Accumulate (MAC) operations are also considered. Rigorous experiments on the Intel Gaudi 2 accelerator validate the approach on several Large Language Models (LLMs).","authors":["Shmulik Markovich-Golan","Daniel Ohayon","Itay Niv","Yair Hanani"],"url":"https://arxiv.org/abs/2505.13060"}
{"created":"2025-05-20","title":"3D Visual Illusion Depth Estimation","abstract":"3D visual illusion is a perceptual phenomenon where a two-dimensional plane is manipulated to simulate three-dimensional spatial relationships, making a flat artwork or object look three-dimensional in the human visual system. In this paper, we reveal that the machine visual system is also seriously fooled by 3D visual illusions, including monocular and binocular depth estimation. In order to explore and analyze the impact of 3D visual illusion on depth estimation, we collect a large dataset containing almost 3k scenes and 200k images to train and evaluate SOTA monocular and binocular depth estimation methods. We also propose a robust depth estimation framework that uses common sense from a vision-language model to adaptively select reliable depth from binocular disparity and monocular depth. Experiments show that SOTA monocular, binocular, and multi-view depth estimation approaches are all fooled by various 3D visual illusions, while our method achieves SOTA performance.","authors":["CHengtang Yao","Zhidan Liu","Jiaxi Zeng","Lidong Yu","Yuwei Wu","Yunde Jia"],"url":"https://arxiv.org/abs/2505.13061"}
{"created":"2025-05-20","title":"Hearing from Silence: Reasoning Audio Descriptions from Silent Videos via Vision-Language Model","abstract":"Humans can intuitively infer sounds from silent videos, but whether multimodal large language models can perform modal-mismatch reasoning without accessing target modalities remains relatively unexplored. Current text-assisted-video-to-audio (VT2A) methods excel in video foley tasks but struggle to acquire audio descriptions during inference. We introduce the task of Reasoning Audio Descriptions from Silent Videos (SVAD) to address this challenge and investigate vision-language models' (VLMs) capabilities on this task. To further enhance the VLMs' reasoning capacity for the SVAD task, we construct a CoT-AudioCaps dataset and propose a Chain-of-Thought-based supervised fine-tuning strategy. Experiments on SVAD and subsequent VT2A tasks demonstrate our method's effectiveness in two key aspects: significantly improving VLMs' modal-mismatch reasoning for SVAD and effectively addressing the challenge of acquiring audio descriptions during VT2A inference.","authors":["Yong Ren","Chenxing Li","Le Xu","Hao Gu","Duzhen Zhang","Yujie Chen","Manjie Xu","Ruibo Fu","Shan Yang","Dong Yu"],"url":"https://arxiv.org/abs/2505.13062"}
{"created":"2025-05-20","title":"Suicide Risk Assessment Using Multimodal Speech Features: A Study on the SW1 Challenge Dataset","abstract":"The 1st SpeechWellness Challenge conveys the need for speech-based suicide risk assessment in adolescents. This study investigates a multimodal approach for this challenge, integrating automatic transcription with WhisperX, linguistic embeddings from Chinese RoBERTa, and audio embeddings from WavLM. Additionally, handcrafted acoustic features -- including MFCCs, spectral contrast, and pitch-related statistics -- were incorporated. We explored three fusion strategies: early concatenation, modality-specific processing, and weighted attention with mixup regularization. Results show that weighted attention provided the best generalization, achieving 69% accuracy on the development set, though a performance gap between development and test sets highlights generalization challenges. Our findings, strictly tied to the MINI-KID framework, emphasize the importance of refining embedding representations and fusion mechanisms to enhance classification reliability.","authors":["Ambre Marie","Ilias Maoudj","Guillaume Dardenne","Gwenol\\'e Quellec"],"url":"https://arxiv.org/abs/2505.13069"}
{"created":"2025-05-20","title":"RSS-Based Localization: Ensuring Consistency and Asymptotic Efficiency","abstract":"We study the problem of signal source localization using received signal strength measurements. We begin by presenting verifiable geometric conditions for sensor deployment that ensure the model's asymptotic localizability. Then we establish the consistency and asymptotic efficiency of the maximum likelihood (ML) estimator. However, computing the ML estimator is challenging due to its reliance on solving a non-convex optimization problem. To overcome this, we propose a two-step estimator that retains the same asymptotic properties as the ML estimator while offering low computational complexity, linear in the number of measurements. The main challenge lies in obtaining a consistent estimator in the first step. To address this, we construct two linear least-squares estimation problems by applying algebraic transformations to the nonlinear measurement model, leading to closed-form solutions. In the second step, we perform a single Gauss-Newton iteration using the consistent estimator from the first step as the initialization, achieving the same asymptotic efficiency as the ML estimator. Finally, simulation results validate the theoretical property and practical effectiveness of the proposed two-step estimator.","authors":["Shenghua Hu","Guangyang Zeng","Wenchao Xue","Haitao Fang","Junfeng Wu","Biqiang Mu"],"url":"https://arxiv.org/abs/2505.13070"}
{"created":"2025-05-20","title":"OmniFC: Rethinking Federated Clustering via Lossless and Secure Distance Reconstruction","abstract":"Federated clustering (FC) aims to discover global cluster structures across decentralized clients without sharing raw data, making privacy preservation a fundamental requirement. There are two critical challenges: (1) privacy leakage during collaboration, and (2) robustness degradation due to aggregation of proxy information from non-independent and identically distributed (Non-IID) local data, leading to inaccurate or inconsistent global clustering. Existing solutions typically rely on model-specific local proxies, which are sensitive to data heterogeneity and inherit inductive biases from their centralized counterparts, thus limiting robustness and generality. We propose Omni Federated Clustering (OmniFC), a unified and model-agnostic framework. Leveraging Lagrange coded computing, our method enables clients to share only encoded data, allowing exact reconstruction of the global distance matrix--a fundamental representation of sample relationships--without leaking private information, even under client collusion. This construction is naturally resilient to Non-IID data distributions. This approach decouples FC from model-specific proxies, providing a unified extension mechanism applicable to diverse centralized clustering methods. Theoretical analysis confirms both reconstruction fidelity and privacy guarantees, while comprehensive experiments demonstrate OmniFC's superior robustness, effectiveness, and generality across various benchmarks compared to state-of-the-art methods. Code will be released.","authors":["Jie Yan","Xin Liu","Zhong-Yuan Zhang"],"url":"https://arxiv.org/abs/2505.13071"}
{"created":"2025-05-20","title":"Orthogonal Survival Learners for Estimating Heterogeneous Treatment Effects from Time-to-Event Data","abstract":"Estimating heterogeneous treatment effects (HTEs) is crucial for personalized decision-making. However, this task is challenging in survival analysis, which includes time-to-event data with censored outcomes (e.g., due to study dropout). In this paper, we propose a toolbox of novel orthogonal survival learners to estimate HTEs from time-to-event data under censoring. Our learners have three main advantages: (i) we show that learners from our toolbox are guaranteed to be orthogonal and thus come with favorable theoretical properties; (ii) our toolbox allows for incorporating a custom weighting function, which can lead to robustness against different types of low overlap, and (iii) our learners are model-agnostic (i.e., they can be combined with arbitrary machine learning models). We instantiate the learners from our toolbox using several weighting functions and, as a result, propose various neural orthogonal survival learners. Some of these coincide with existing survival learners (including survival versions of the DR- and R-learner), while others are novel and further robust w.r.t. low overlap regimes specific to the survival setting (i.e., survival overlap and censoring overlap). We then empirically verify the effectiveness of our learners for HTE estimation in different low-overlap regimes through numerical experiments. In sum, we provide practitioners with a large toolbox of learners that can be used for randomized and observational studies with censored time-to-event data.","authors":["Dennis Frauen","Maresa Schr\\\"oder","Konstantin Hess","Stefan Feuerriegel"],"url":"https://arxiv.org/abs/2505.13072"}
{"created":"2025-05-20","title":"Structure-Aware Corpus Construction and User-Perception-Aligned Metrics for Large-Language-Model Code Completion","abstract":"Code completion technology based on large language model has significantly improved the development efficiency of programmers. However, in practical applications, there remains a gap between current commonly used code completion evaluation metrics and users' actual perception. To address this issue, we propose two evaluation metrics for code completion tasks--LCP and ROUGE-LCP, from the perspective of probabilistic modeling. Furthermore, to tackle the lack of effective structural semantic modeling and cross-module dependency information in LLMs for repository-level code completion scenarios, we propose a data processing method based on a Structure-Preserving and Semantically-Reordered Code Graph (SPSR-Graph). Through theoretical analysis and experimental validation, we demonstrate the superiority of the proposed evaluation metrics in terms of user perception consistency, as well as the effectiveness of the data processing method in enhancing model performance.","authors":["Dengfeng Liu","Jucai Zhai","Xiaoguang Jiang","Ziqun Li","Qianjin Yu","Feng Liu","Rui Ye","Huang Liu","Zhiguo Yang","Yongsheng Du","Fang Tan"],"url":"https://arxiv.org/abs/2505.13073"}
{"created":"2025-05-20","title":"The Hidden Dangers of Browsing AI Agents","abstract":"Autonomous browsing agents powered by large language models (LLMs) are increasingly used to automate web-based tasks. However, their reliance on dynamic content, tool execution, and user-provided data exposes them to a broad attack surface. This paper presents a comprehensive security evaluation of such agents, focusing on systemic vulnerabilities across multiple architectural layers. Our work outlines the first end-to-end threat model for browsing agents and provides actionable guidance for securing their deployment in real-world environments. To address discovered threats, we propose a defense in depth strategy incorporating input sanitization, planner executor isolation, formal analyzers, and session safeguards. These measures protect against both initial access and post exploitation attack vectors. Through a white box analysis of a popular open source project, Browser Use, we demonstrate how untrusted web content can hijack agent behavior and lead to critical security breaches. Our findings include prompt injection, domain validation bypass, and credential exfiltration, evidenced by a disclosed CVE and a working proof of concept exploit.","authors":["Mykyta Mudryi","Markiyan Chaklosh","Grzegorz W\\'ojcik"],"url":"https://arxiv.org/abs/2505.13076"}
{"created":"2025-05-20","title":"Advancing Sequential Numerical Prediction in Autoregressive Models","abstract":"Autoregressive models have become the de facto choice for sequence generation tasks, but standard approaches treat digits as independent tokens and apply cross-entropy loss, overlooking the coherent structure of numerical sequences. This paper introduces Numerical Token Integrity Loss (NTIL) to address this gap. NTIL operates at two levels: (1) token-level, where it extends the Earth Mover's Distance (EMD) to preserve ordinal relationships between numerical values, and (2) sequence-level, where it penalizes the overall discrepancy between the predicted and actual sequences. This dual approach improves numerical prediction and integrates effectively with LLMs/MLLMs. Extensive experiments show significant performance improvements with NTIL.","authors":["Xiang Fei","Jinghui Lu","Qi Sun","Hao Feng","Yanjie Wang","Wei Shi","An-Lan Wang","Jingqun Tang","Can Huang"],"url":"https://arxiv.org/abs/2505.13077"}
{"created":"2025-05-20","title":"Unifying concepts in information-theoretic time-series analysis","abstract":"Information theory is a powerful framework for quantifying complexity, uncertainty, and dynamical structure in time-series data, with widespread applicability across disciplines such as physics, finance, and neuroscience. However, the literature on these measures remains fragmented, with domain-specific terminologies, inconsistent mathematical notation, and disparate visualization conventions that hinder interdisciplinary integration. This work addresses these challenges by unifying key information-theoretic time-series measures through shared semantic definitions, standardized mathematical notation, and cohesive visual representations. We compare these measures in terms of their theoretical foundations, computational formulations, and practical interpretability -- mapping them onto a common conceptual space through an illustrative case study with functional magnetic resonance imaging time series in the brain. This case study exemplifies the complementary insights these measures offer in characterizing the dynamics of complex neural systems, such as signal complexity and information flow. By providing a structured synthesis, our work aims to enhance interdisciplinary dialogue and methodological adoption, which is particularly critical for reproducibility and interoperability in computational neuroscience. More broadly, our framework serves as a resource for researchers seeking to navigate and apply information-theoretic time-series measures to diverse complex systems.","authors":["Annie G. Bryant","Oliver M. Cliff","James M. Shine","Ben D. Fulcher","Joseph T. Lizier"],"url":"https://arxiv.org/abs/2505.13080"}
{"created":"2025-05-20","title":"Walking the Tightrope: Disentangling Beneficial and Detrimental Drifts in Non-Stationary Custom-Tuning","abstract":"This paper uncovers a critical yet overlooked phenomenon in multi-modal large language models (MLLMs): detrimental concept drift within chain-of-thought (CoT) reasoning during non-stationary reinforcement fine-tuning (RFT), where reasoning token distributions evolve unpredictably, thereby introducing significant biases in final predictions. To address this, we are pioneers in establishing the theoretical bridge between concept drift theory and RFT processes by formalizing CoT's autoregressive token streams as non-stationary distributions undergoing arbitrary temporal shifts. Leveraging this framework, we propose a novel counterfact-aware RFT that systematically decouples beneficial distribution adaptation from harmful concept drift through concept graph-empowered LLM experts generating counterfactual reasoning trajectories. Our solution, Counterfactual Preference Optimization (CPO), enables stable RFT in non-stationary environments, particularly within the medical domain, through custom-tuning of counterfactual-aware preference alignment. Extensive experiments demonstrate our superior performance of robustness, generalization and coordination within RFT. Besides, we also contributed a large-scale dataset CXR-CounterFact (CCF), comprising 320,416 meticulously curated counterfactual reasoning trajectories derived from MIMIC-CXR. Our code and data are public.","authors":["Xiaoyu Yang","Jie Lu","En Yu"],"url":"https://arxiv.org/abs/2505.13081"}
{"created":"2025-05-20","title":"MultiActor-Audiobook: Zero-Shot Audiobook Generation with Faces and Voices of Multiple Speakers","abstract":"We introduce MultiActor-Audiobook, a zero-shot approach for generating audiobooks that automatically produces consistent, expressive, and speaker-appropriate prosody, including intonation and emotion. Previous audiobook systems have several limitations: they require users to manually configure the speaker's prosody, read each sentence with a monotonic tone compared to voice actors, or rely on costly training. However, our MultiActor-Audiobook addresses these issues by introducing two novel processes: (1) MSP (**Multimodal Speaker Persona Generation**) and (2) LSI (**LLM-based Script Instruction Generation**). With these two processes, MultiActor-Audiobook can generate more emotionally expressive audiobooks with a consistent speaker prosody without additional training. We compare our system with commercial products, through human and MLLM evaluations, achieving competitive results. Furthermore, we demonstrate the effectiveness of MSP and LSI through ablation studies.","authors":["Kyeongman Park","Seongho Joo","Kyomin Jung"],"url":"https://arxiv.org/abs/2505.13082"}
{"created":"2025-05-20","title":"Graph Alignment for Benchmarking Graph Neural Networks and Learning Positional Encodings","abstract":"We propose a novel benchmarking methodology for graph neural networks (GNNs) based on the graph alignment problem, a combinatorial optimization task that generalizes graph isomorphism by aligning two unlabeled graphs to maximize overlapping edges. We frame this problem as a self-supervised learning task and present several methods to generate graph alignment datasets using synthetic random graphs and real-world graph datasets from multiple domains. For a given graph dataset, we generate a family of graph alignment datasets with increasing difficulty, allowing us to rank the performance of various architectures. Our experiments indicate that anisotropic graph neural networks outperform standard convolutional architectures. To further demonstrate the utility of the graph alignment task, we show its effectiveness for unsupervised GNN pre-training, where the learned node embeddings outperform other positional encodings on three molecular regression tasks and achieve state-of-the-art results on the PCQM4Mv2 dataset with significantly fewer parameters. To support reproducibility and further research, we provide an open-source Python package to generate graph alignment datasets and benchmark new GNN architectures.","authors":["Adrien Lagesse","Marc Lelarge"],"url":"https://arxiv.org/abs/2505.13087"}
{"created":"2025-05-20","title":"Cross-modal feature fusion for robust point cloud registration with ambiguous geometry","abstract":"Point cloud registration has seen significant advancements with the application of deep learning techniques. However, existing approaches often overlook the potential of integrating radiometric information from RGB images. This limitation reduces their effectiveness in aligning point clouds pairs, especially in regions where geometric data alone is insufficient. When used effectively, radiometric information can enhance the registration process by providing context that is missing from purely geometric data. In this paper, we propose CoFF, a novel Cross-modal Feature Fusion method that utilizes both point cloud geometry and RGB images for pairwise point cloud registration. Assuming that the co-registration between point clouds and RGB images is available, CoFF explicitly addresses the challenges where geometric information alone is unclear, such as in regions with symmetric similarity or planar structures, through a two-stage fusion of 3D point cloud features and 2D image features. It incorporates a cross-modal feature fusion module that assigns pixel-wise image features to 3D input point clouds to enhance learned 3D point features, and integrates patch-wise image features with superpoint features to improve the quality of coarse matching. This is followed by a coarse-to-fine matching module that accurately establishes correspondences using the fused features. We extensively evaluate CoFF on four common datasets: 3DMatch, 3DLoMatch, IndoorLRS, and the recently released ScanNet++ datasets. In addition, we assess CoFF on specific subset datasets containing geometrically ambiguous cases. Our experimental results demonstrate that CoFF achieves state-of-the-art registration performance across all benchmarks, including remarkable registration recalls of 95.9% and 81.6% on the widely-used 3DMatch and 3DLoMatch datasets, respectively...(Truncated to fit arXiv abstract length)","authors":["Zhaoyi Wang","Shengyu Huang","Jemil Avers Butt","Yuanzhou Cai","Matej Varga","Andreas Wieser"],"url":"https://arxiv.org/abs/2505.13088"}
{"created":"2025-05-20","title":"Systematic Generalization in Language Models Scales with Information Entropy","abstract":"Systematic generalization remains challenging for current language models, which are known to be both sensitive to semantically similar permutations of the input and to struggle with known concepts presented in novel contexts. Although benchmarks exist for assessing compositional behavior, it is unclear how to measure the difficulty of a systematic generalization problem. In this work, we show how one aspect of systematic generalization can be described by the entropy of the distribution of component parts in the training data. We formalize a framework for measuring entropy in a sequence-to-sequence task and find that the performance of popular model architectures scales with the entropy. Our work connects systematic generalization to information efficiency, and our results indicate that success at high entropy can be achieved even without built-in priors, and that success at low entropy can serve as a target for assessing progress towards robust systematic generalization.","authors":["Sondre Wold","Lucas Georges Gabriel Charpentier","\\'Etienne Simon"],"url":"https://arxiv.org/abs/2505.13089"}
{"created":"2025-05-20","title":"The Effect of Language Diversity When Fine-Tuning Large Language Models for Translation","abstract":"Prior research diverges on language diversity in LLM fine-tuning: Some studies report benefits while others find no advantages. Through controlled fine-tuning experiments across 132 translation directions, we systematically resolve these disparities. We find that expanding language diversity during fine-tuning improves translation quality for both unsupervised and -- surprisingly -- supervised pairs, despite less diverse models being fine-tuned exclusively on these supervised pairs. However, benefits plateau or decrease beyond a certain diversity threshold. We show that increased language diversity creates more language-agnostic representations. These representational adaptations help explain the improved performance in models fine-tuned with greater diversity.","authors":["David Stap","Christof Monz"],"url":"https://arxiv.org/abs/2505.13090"}
{"created":"2025-05-20","title":"Touch2Shape: Touch-Conditioned 3D Diffusion for Shape Exploration and Reconstruction","abstract":"Diffusion models have made breakthroughs in 3D generation tasks. Current 3D diffusion models focus on reconstructing target shape from images or a set of partial observations. While excelling in global context understanding, they struggle to capture the local details of complex shapes and limited to the occlusion and lighting conditions. To overcome these limitations, we utilize tactile images to capture the local 3D information and propose a Touch2Shape model, which leverages a touch-conditioned diffusion model to explore and reconstruct the target shape from touch. For shape reconstruction, we have developed a touch embedding module to condition the diffusion model in creating a compact representation and a touch shape fusion module to refine the reconstructed shape. For shape exploration, we combine the diffusion model with reinforcement learning to train a policy. This involves using the generated latent vector from the diffusion model to guide the touch exploration policy training through a novel reward design. Experiments validate the reconstruction quality thorough both qualitatively and quantitative analysis, and our touch exploration policy further boosts reconstruction performance.","authors":["Yuanbo Wang","Zhaoxuan Zhang","Jiajin Qiu","Dilong Sun","Zhengyu Meng","Xiaopeng Wei","Xin Yang"],"url":"https://arxiv.org/abs/2505.13091"}
{"created":"2025-05-20","title":"Treatment Effect Estimation for Optimal Decision-Making","abstract":"Decision-making across various fields, such as medicine, heavily relies on conditional average treatment effects (CATEs). Practitioners commonly make decisions by checking whether the estimated CATE is positive, even though the decision-making performance of modern CATE estimators is poorly understood from a theoretical perspective. In this paper, we study optimal decision-making based on two-stage CATE estimators (e.g., DR-learner), which are considered state-of-the-art and widely used in practice. We prove that, while such estimators may be optimal for estimating CATE, they can be suboptimal when used for decision-making. Intuitively, this occurs because such estimators prioritize CATE accuracy in regions far away from the decision boundary, which is ultimately irrelevant to decision-making. As a remedy, we propose a novel two-stage learning objective that retargets the CATE to balance CATE estimation error and decision performance. We then propose a neural method that optimizes an adaptively-smoothed approximation of our learning objective. Finally, we confirm the effectiveness of our method both empirically and theoretically. In sum, our work is the first to show how two-stage CATE estimators can be adapted for optimal decision-making.","authors":["Dennis Frauen","Valentyn Melnychuk","Jonas Schweisthal","Stefan Feuerriegel"],"url":"https://arxiv.org/abs/2505.13092"}
{"created":"2025-05-20","title":"Time-Frequency-Based Attention Cache Memory Model for Real-Time Speech Separation","abstract":"Existing causal speech separation models often underperform compared to non-causal models due to difficulties in retaining historical information. To address this, we propose the Time-Frequency Attention Cache Memory (TFACM) model, which effectively captures spatio-temporal relationships through an attention mechanism and cache memory (CM) for historical information storage. In TFACM, an LSTM layer captures frequency-relative positions, while causal modeling is applied to the time dimension using local and global representations. The CM module stores past information, and the causal attention refinement (CAR) module further enhances time-based feature representations for finer granularity. Experimental results showed that TFACM achieveed comparable performance to the SOTA TF-GridNet-Causal model, with significantly lower complexity and fewer trainable parameters. For more details, visit the project page: https://cslikai.cn/TFACM/.","authors":["Guo Chen","Kai Li","Runxuan Yang","Xiaolin Hu"],"url":"https://arxiv.org/abs/2505.13094"}
{"created":"2025-05-20","title":"Domains and Classifying Topoi","abstract":"We explore a new connection between synthetic domain theory and Grothendieck topoi related to the distributive lattice classifier. In particular, all the axioms of synthetic domain theory (including the inductive fixed point object and the chain completeness of the dominance) emanate from a countable version of the synthetic quasi-coherence principle that has emerged as a central feature in the unification of synthetic algebraic geometry, synthetic Stone duality, and synthetic category theory. The duality between quasi-coherent algebras and affine spaces in a topos with a distributive lattice object provides a new set of techniques for reasoning synthetically about domain-like structures, and reveals a broad class of (higher) sheaf models for synthetic domain theory.","authors":["Jonathan Sterling","Lingyuan Ye"],"url":"https://arxiv.org/abs/2505.13096"}
{"created":"2025-05-20","title":"An implicit regularized enthalpy Lattice Boltzmann Method for the Stefan problem","abstract":"Solving the Stefan problem, also referred as the heat conduction problem with phase change, is a necessary step to solve phase change problems with convection. In this article, we are interested in using the Lattice Boltzmann Method (LBM) to solve the Stefan problem using a regularized total enthalpy model. The liquid fraction is treated as a nonlinear source/sink term, that involves the time derivative of the solution. The resulting non-linear system is solved using a Newton algorithm. By conserving the locality of the problem, this method is highly scalable, while keeping a high accuracy. The newly developed scheme is analyzed theoretically through a Chapman-Enskog expansion and illustrated numerically with 1D and 2D benchmarks.","authors":["Francky Luddens (LMRS)","Corentin Lothod\\'e (LAREMA)","Ionut Danaila (LMRS)"],"url":"https://arxiv.org/abs/2505.13097"}
{"created":"2025-05-20","title":"LLM-KG-Bench 3.0: A Compass for SemanticTechnology Capabilities in the Ocean of LLMs","abstract":"Current Large Language Models (LLMs) can assist developing program code beside many other things, but can they support working with Knowledge Graphs (KGs) as well? Which LLM is offering the best capabilities in the field of Semantic Web and Knowledge Graph Engineering (KGE)? Is this possible to determine without checking many answers manually? The LLM-KG-Bench framework in Version 3.0 is designed to answer these questions. It consists of an extensible set of tasks for automated evaluation of LLM answers and covers different aspects of working with semantic technologies. In this paper the LLM-KG-Bench framework is presented in Version 3 along with a dataset of prompts, answers and evaluations generated with it and several state-of-the-art LLMs. Significant enhancements have been made to the framework since its initial release, including an updated task API that offers greater flexibility in handling evaluation tasks, revised tasks, and extended support for various open models through the vllm library, among other improvements. A comprehensive dataset has been generated using more than 30 contemporary open and proprietary LLMs, enabling the creation of exemplary model cards that demonstrate the models' capabilities in working with RDF and SPARQL, as well as comparing their performance on Turtle and JSON-LD RDF serialization tasks.","authors":["Lars-Peter Meyer","Johannes Frey","Desiree Heim","Felix Brei","Claus Stadler","Kurt Junghanns","Michael Martin"],"url":"https://arxiv.org/abs/2505.13098"}
{"created":"2025-05-20","title":"Industry-focused Synthetic Segmentation Pre-training","abstract":"Pre-training on real-image datasets has been widely proven effective for improving instance segmentation. However, industrial applications face two key challenges: (1) legal and ethical restrictions, such as ImageNet's prohibition of commercial use, and (2) limited transferability due to the domain gap between web images and industrial imagery. Even recent vision foundation models, including the segment anything model (SAM), show notable performance degradation in industrial settings. These challenges raise critical questions: Can we build a vision foundation model for industrial applications without relying on real images or manual annotations? And can such models outperform even fine-tuned SAM on industrial datasets? To address these questions, we propose the Instance Core Segmentation Dataset (InsCore), a synthetic pre-training dataset based on formula-driven supervised learning (FDSL). InsCore generates fully annotated instance segmentation images that reflect key characteristics of industrial data, including complex occlusions, dense hierarchical masks, and diverse non-rigid shapes, distinct from typical web imagery. Unlike previous methods, InsCore requires neither real images nor human annotations. Experiments on five industrial datasets show that models pre-trained with InsCore outperform those trained on COCO and ImageNet-21k, as well as fine-tuned SAM, achieving an average improvement of 6.2 points in instance segmentation performance. This result is achieved using only 100k synthetic images, more than 100 times fewer than the 11 million images in SAM's SA-1B dataset, demonstrating the data efficiency of our approach. These findings position InsCore as a practical and license-free vision foundation model for industrial applications.","authors":["Shinichi Mae","Ryosuke Yamada","Hirokatsu Kataoka"],"url":"https://arxiv.org/abs/2505.13099"}
{"created":"2025-05-20","title":"Time series saliency maps: explaining models across multiple domains","abstract":"Traditional saliency map methods, popularized in computer vision, highlight individual points (pixels) of the input that contribute the most to the model's output. However, in time-series they offer limited insights as semantically meaningful features are often found in other domains. We introduce Cross-domain Integrated Gradients, a generalization of Integrated Gradients. Our method enables feature attributions on any domain that can be formulated as an invertible, differentiable transformation of the time domain. Crucially, our derivation extends the original Integrated Gradients into the complex domain, enabling frequency-based attributions. We provide the necessary theoretical guarantees, namely, path independence and completeness. Our approach reveals interpretable, problem-specific attributions that time-domain methods cannot capture, on three real-world tasks: wearable sensor heart rate extraction, electroencephalography-based seizure detection, and zero-shot time-series forecasting. We release an open-source Tensorflow/PyTorch library to enable plug-and-play cross-domain explainability for time-series models. These results demonstrate the ability of cross-domain integrated gradients to provide semantically meaningful insights in time-series models that are impossible with traditional time-domain saliency.","authors":["Christodoulos Kechris","Jonathan Dan","David Atienza"],"url":"https://arxiv.org/abs/2505.13100"}
{"created":"2025-05-20","title":"ARIW-Framework: Adaptive Robust Iterative Watermarking Framework","abstract":"With the rapid rise of large models, copyright protection for generated image content has become a critical security challenge. Although deep learning watermarking techniques offer an effective solution for digital image copyright protection, they still face limitations in terms of visual quality, robustness and generalization. To address these issues, this paper proposes an adaptive robust iterative watermarking framework (ARIW-Framework) that achieves high-quality watermarked images while maintaining exceptional robustness and generalization performance. Specifically, we introduce an iterative approach to optimize the encoder for generating robust residuals. The encoder incorporates noise layers and a decoder to compute robustness weights for residuals under various noise attacks. By employing a parallel optimization strategy, the framework enhances robustness against multiple types of noise attacks. Furthermore, we leverage image gradients to determine the embedding strength at each pixel location, significantly improving the visual quality of the watermarked images. Extensive experiments demonstrate that the proposed method achieves superior visual quality while exhibiting remarkable robustness and generalization against noise attacks.","authors":["Shaowu Wu","Liting Zeng","Wei Lu","Xiangyang Luo"],"url":"https://arxiv.org/abs/2505.13101"}
{"created":"2025-05-20","title":"Lightweight Transformer via Unrolling of Mixed Graph Algorithms for Traffic Forecast","abstract":"To forecast traffic with both spatial and temporal dimensions, we unroll a mixed-graph-based optimization algorithm into a lightweight and interpretable transformer-like neural net. Specifically, we construct two graphs: an undirected graph $\\mathcal{G}^u$ capturing spatial correlations across geography, and a directed graph $\\mathcal{G}^d$ capturing sequential relationships over time. We formulate a prediction problem for the future samples of signal $\\mathbf{x}$, assuming it is \"smooth\" with respect to both $\\mathcal{G}^u$ and $\\mathcal{G}^d$, where we design new $\\ell_2$ and $\\ell_1$-norm variational terms to quantify and promote signal smoothness (low-frequency reconstruction) on a directed graph. We construct an iterative algorithm based on alternating direction method of multipliers (ADMM), and unroll it into a feed-forward network for data-driven parameter learning. We insert graph learning modules for $\\mathcal{G}^u$ and $\\mathcal{G}^d$, which are akin to the self-attention mechanism in classical transformers. Experiments show that our unrolled networks achieve competitive traffic forecast performance as state-of-the-art prediction schemes, while reducing parameter counts drastically. Our code is available in https://github.com/SingularityUndefined/Unrolling-GSP-STForecast.","authors":["Ji Qi","Tam Thuc Do","Mingxiao Liu","Zhuoshi Pan","Yuzhe Li","Gene Cheung","H. Vicky Zhao"],"url":"https://arxiv.org/abs/2505.13102"}
{"created":"2025-05-20","title":"Fixing 7,400 Bugs for 1$: Cheap Crash-Site Program Repair","abstract":"The rapid advancement of bug-finding techniques has led to the discovery of more vulnerabilities than developers can reasonably fix, creating an urgent need for effective Automated Program Repair (APR) methods. However, the complexity of modern bugs often makes precise root cause analysis difficult and unreliable. To address this challenge, we propose crash-site repair to simplify the repair task while still mitigating the risk of exploitation. In addition, we introduce a template-guided patch generation approach that significantly reduces the token cost of Large Language Models (LLMs) while maintaining both efficiency and effectiveness.","authors":["Han Zheng","Ilia Shumailov","Tianqi Fan","Aiden Hall","Mathias Payer"],"url":"https://arxiv.org/abs/2505.13103"}
{"created":"2025-05-20","title":"FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference","abstract":"Large language models (LLMs) have been widely deployed with rapidly expanding context windows to support increasingly demanding applications. However, long contexts pose significant deployment challenges, primarily due to the KV cache whose size grows proportionally with context length. While KV cache compression methods are proposed to address this issue, KV dropping methods incur considerable accuracy loss, and KV retrieval methods suffer from significant efficiency bottlenecks. We propose FreeKV, an algorithm-system co-optimization framework to enhance KV retrieval efficiency while preserving accuracy. On the algorithm side, FreeKV introduces speculative retrieval to shift the KV selection and recall processes out of the critical path, combined with fine-grained correction to ensure accuracy. On the system side, FreeKV employs hybrid KV layouts across CPU and GPU memory to eliminate fragmented data transfers, and leverages double-buffered streamed recall to further improve efficiency. Experiments demonstrate that FreeKV achieves near-lossless accuracy across various scenarios and models, delivering up to 13$\\times$ speedup compared to SOTA KV retrieval methods.","authors":["Guangda Liu","Chengwei Li","Zhenyu Ning","Jing Lin","Yiwu Yao","Danning Ke","Minyi Guo","Jieru Zhao"],"url":"https://arxiv.org/abs/2505.13109"}
{"created":"2025-05-20","title":"Why Knowledge Distillation Works in Generative Models: A Minimal Working Explanation","abstract":"Knowledge distillation (KD) is a core component in the training and deployment of modern generative models, particularly large language models (LLMs). While its empirical benefits are well documented--enabling smaller student models to emulate the performance of much larger teachers--the underlying mechanisms by which KD improves generative quality remain poorly understood. In this work, we present a minimal working explanation of KD in generative modeling. Using a controlled simulation with mixtures of Gaussians, we demonstrate that distillation induces a trade-off between precision and recall in the student model. As the teacher distribution becomes more selective, the student concentrates more probability mass on high-likelihood regions at the expense of coverage--a behavior modulated by a single entropy-controlling parameter. We then validate this effect in a large-scale language modeling setup using the SmolLM2 family of models. Empirical results reveal the same precision-recall dynamics observed in simulation, where precision corresponds to sample quality and recall to distributional coverage. This precision-recall trade-off proves especially beneficial in scenarios where sample quality outweighs diversity, such as instruction tuning or downstream generation. Our analysis provides a simple and general explanation for the effectiveness of KD in generative modeling.","authors":["Sungmin Cha","Kyunghyun Cho"],"url":"https://arxiv.org/abs/2505.13111"}
{"created":"2025-05-20","title":"Benchmarking and Confidence Evaluation of LALMs For Temporal Reasoning","abstract":"The popular success of text-based large language models (LLM) has streamlined the attention of the multimodal community to combine other modalities like vision and audio along with text to achieve similar multimodal capabilities. In this quest, large audio language models (LALMs) have to be evaluated on reasoning related tasks which are different from traditional classification or generation tasks. Towards this goal, we propose a novel dataset called temporal reasoning evaluation of audio (TREA).","authors":["Debarpan Bhattacharya","Apoorva Kulkarni","Sriram Ganapathy"],"url":"https://arxiv.org/abs/2505.13115"}
{"created":"2025-05-20","title":"Continuous Fair SMOTE -- Fairness-Aware Stream Learning from Imbalanced Data","abstract":"As machine learning is increasingly applied in an online fashion to deal with evolving data streams, the fairness of these algorithms is a matter of growing ethical and legal concern. In many use cases, class imbalance in the data also needs to be dealt with to ensure predictive performance. Current fairness-aware stream learners typically attempt to solve these issues through in- or post-processing by focusing on optimizing one specific discrimination metric, addressing class imbalance in a separate processing step. While C-SMOTE is a highly effective model-agnostic pre-processing approach to mitigate class imbalance, as a side effect of this method, algorithmic bias is often introduced.","authors":["Kathrin Lammers","Valerie Vaquet","Barbara Hammer"],"url":"https://arxiv.org/abs/2505.13116"}
{"created":"2025-05-20","title":"Unveil Sources of Uncertainty: Feature Contribution to Conformal Prediction Intervals","abstract":"Cooperative game theory methods, notably Shapley values, have significantly enhanced machine learning (ML) interpretability. However, existing explainable AI (XAI) frameworks mainly attribute average model predictions, overlooking predictive uncertainty. This work addresses that gap by proposing a novel, model-agnostic uncertainty attribution (UA) method grounded in conformal prediction (CP). By defining cooperative games where CP interval properties-such as width and bounds-serve as value functions, we systematically attribute predictive uncertainty to input features. Extending beyond the traditional Shapley values, we use the richer class of Harsanyi allocations, and in particular the proportional Shapley values, which distribute attribution proportionally to feature importance. We propose a Monte Carlo approximation method with robust statistical guarantees to address computational feasibility, significantly improving runtime efficiency. Our comprehensive experiments on synthetic benchmarks and real-world datasets demonstrate the practical utility and interpretative depth of our approach. By combining cooperative game theory and conformal prediction, we offer a rigorous, flexible toolkit for understanding and communicating predictive uncertainty in high-stakes ML applications.","authors":["Marouane Il Idrissi (UQAM","IID)","Agathe Fernandes Machado (UQAM)","Ewen Gallic (AMSE)","Arthur Charpentier (UQAM)"],"url":"https://arxiv.org/abs/2505.13118"}
{"created":"2025-05-20","title":"When majority rules, minority loses: bias amplification of gradient descent","abstract":"Despite growing empirical evidence of bias amplification in machine learning, its theoretical foundations remain poorly understood. We develop a formal framework for majority-minority learning tasks, showing how standard training can favor majority groups and produce stereotypical predictors that neglect minority-specific features. Assuming population and variance imbalance, our analysis reveals three key findings: (i) the close proximity between ``full-data'' and stereotypical predictors, (ii) the dominance of a region where training the entire model tends to merely learn the majority traits, and (iii) a lower bound on the additional training required. Our results are illustrated through experiments in deep learning for tabular and image classification tasks.","authors":["Fran\\c{c}ois Bachoc (IMT)","J\\'er\\^ome Bolte (TSE-R)","Ryan Boustany (TSE-R)","Jean-Michel Loubes (IMT)"],"url":"https://arxiv.org/abs/2505.13122"}
{"created":"2025-05-20","title":"Just Dance with $\\pi$! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection","abstract":"Weakly-supervised methods for video anomaly detection (VAD) are conventionally based merely on RGB spatio-temporal features, which continues to limit their reliability in real-world scenarios. This is due to the fact that RGB-features are not sufficiently distinctive in setting apart categories such as shoplifting from visually similar events. Therefore, towards robust complex real-world VAD, it is essential to augment RGB spatio-temporal features by additional modalities. Motivated by this, we introduce the Poly-modal Induced framework for VAD: \"PI-VAD\", a novel approach that augments RGB representations by five additional modalities. Specifically, the modalities include sensitivity to fine-grained motion (Pose), three dimensional scene and entity representation (Depth), surrounding objects (Panoptic masks), global motion (optical flow), as well as language cues (VLM). Each modality represents an axis of a polygon, streamlined to add salient cues to RGB. PI-VAD includes two plug-in modules, namely Pseudo-modality Generation module and Cross Modal Induction module, which generate modality-specific prototypical representation and, thereby, induce multi-modal information into RGB cues. These modules operate by performing anomaly-aware auxiliary tasks and necessitate five modality backbones -- only during training. Notably, PI-VAD achieves state-of-the-art accuracy on three prominent VAD datasets encompassing real-world scenarios, without requiring the computational overhead of five modality backbones at inference.","authors":["Snehashis Majhi","Giacomo D'Amicantonio","Antitza Dantcheva","Quan Kong","Lorenzo Garattoni","Gianpiero Francesca","Egor Bondarev","Francois Bremond"],"url":"https://arxiv.org/abs/2505.13123"}
{"created":"2025-05-20","title":"$\\mu$PC: Scaling Predictive Coding to 100+ Layer Networks","abstract":"The biological implausibility of backpropagation (BP) has motivated many alternative, brain-inspired algorithms that attempt to rely only on local information, such as predictive coding (PC) and equilibrium propagation. However, these algorithms have notoriously struggled to train very deep networks, preventing them from competing with BP in large-scale settings. Indeed, scaling PC networks (PCNs) has recently been posed as a challenge for the community (Pinchetti et al., 2024). Here, we show that 100+ layer PCNs can be trained reliably using a Depth-$\\mu$P parameterisation (Yang et al., 2023; Bordelon et al., 2023) which we call \"$\\mu$PC\". Through an extensive analysis of the scaling behaviour of PCNs, we reveal several pathologies that make standard PCNs difficult to train at large depths. We then show that, despite addressing only some of these instabilities, $\\mu$PC allows stable training of very deep (up to 128-layer) residual networks on simple classification tasks with competitive performance and little tuning compared to current benchmarks. Moreover, $\\mu$PC enables zero-shot transfer of both weight and activity learning rates across widths and depths. Our results have implications for other local algorithms and could be extended to convolutional and transformer architectures. Code for $\\mu$PC is made available as part of a JAX library for PCNs at https://github.com/thebuckleylab/jpc (Innocenti et al., 2024).","authors":["Francesco Innocenti","El Mehdi Achour","Christopher L. Buckley"],"url":"https://arxiv.org/abs/2505.13124"}
{"created":"2025-05-20","title":"Zero-Shot Iterative Formalization and Planning in Partially Observable Environments","abstract":"In planning, using LLMs not to predict plans but to formalize an environment into the Planning Domain Definition Language (PDDL) has been shown to greatly improve performance and control. While most work focused on fully observable environments, we tackle the more realistic and challenging partially observable environments where existing methods are incapacitated by the lack of complete information. We propose PDDLego+, a framework to iteratively formalize, plan, grow, and refine PDDL representations in a zero-shot manner, without needing access to any existing trajectories. On two textual simulated environments, we show that PDDLego+ not only achieves superior performance, but also shows robustness against problem complexity. We also show that the domain knowledge captured after a successful trial is interpretable and benefits future tasks.","authors":["Liancheng Gong","Wang Zhu","Jesse Thomason","Li Zhang"],"url":"https://arxiv.org/abs/2505.13126"}
{"created":"2025-05-20","title":"Optimizing Retrieval Augmented Generation for Object Constraint Language","abstract":"The Object Constraint Language (OCL) is essential for defining precise constraints within Model-Based Systems Engineering (MBSE). However, manually writing OCL rules is complex and time-consuming. This study explores the optimization of Retrieval-Augmented Generation (RAG) for automating OCL rule generation, focusing on the impact of different retrieval strategies. We evaluate three retrieval approaches $\\unicode{x2013}$ BM25 (lexical-based), BERT-based (semantic retrieval), and SPLADE (sparse-vector retrieval) $\\unicode{x2013}$ analyzing their effectiveness in providing relevant context for a large language model.","authors":["Kevin Chenhao Li","Vahid Zolfaghari","Nenad Petrovic","Fengjunjie Pan","Alois Knoll"],"url":"https://arxiv.org/abs/2505.13129"}
{"created":"2025-05-20","title":"Adaptive Image Restoration for Video Surveillance: A Real-Time Approach","abstract":"One of the major challenges in the field of computer vision especially for detection, segmentation, recognition, monitoring, and automated solutions, is the quality of images. Image degradation, often caused by factors such as rain, fog, lighting, etc., has a negative impact on automated decision-making.Furthermore, several image restoration solutions exist, including restoration models for single degradation and restoration models for multiple degradations. However, these solutions are not suitable for real-time processing. In this study, the aim was to develop a real-time image restoration solution for video surveillance. To achieve this, using transfer learning with ResNet_50, we developed a model for automatically identifying the types of degradation present in an image to reference the necessary treatment(s) for image restoration. Our solution has the advantage of being flexible and scalable.","authors":["Muhammad Awais Amin","Adama Ilboudo","Abdul Samad bin Shahid","Amjad Ali","Waqas Haider Khan Bangyal"],"url":"https://arxiv.org/abs/2505.13130"}
{"created":"2025-05-20","title":"Constraint-Aware Diffusion Guidance for Robotics: Real-Time Obstacle Avoidance for Autonomous Racing","abstract":"Diffusion models hold great potential in robotics due to their ability to capture complex, high-dimensional data distributions. However, their lack of constraint-awareness limits their deployment in safety-critical applications. We propose Constraint-Aware Diffusion Guidance (CoDiG), a data-efficient and general-purpose framework that integrates barrier functions into the denoising process, guiding diffusion sampling toward constraint-satisfying outputs. CoDiG enables constraint satisfaction even with limited training data and generalizes across tasks. We evaluate our framework in the challenging setting of miniature autonomous racing, where real-time obstacle avoidance is essential. Real-world experiments show that CoDiG generates safe outputs efficiently under dynamic conditions, highlighting its potential for broader robotic applications. A demonstration video is available at https://youtu.be/KNYsTdtdxOU.","authors":["Hao Ma","Sabrina Bodmer","Andrea Carron","Melanie Zeilinger","Michael Muehlebach"],"url":"https://arxiv.org/abs/2505.13131"}
{"created":"2025-05-20","title":"Ocean wave spectrum reconstruction from HF radar data and its application to wave height estimation","abstract":"Real-time estimation of ocean wave heights using high-frequency (HF) radar has attracted great attention. This method offers the benefit of easy maintenance by virtue of its ground-based installation. However, it is adversely affected by issues such as low estimation accuracy. As described herein, we propose an algorithm based on the nonnegative sparse regularization method to estimate the energy distribution of the component waves, known as the ocean wave spectrum, from HF radar data. After proving a stability estimate of this algorithm, we perform numerical simulations to verify the proposed method's effectiveness.","authors":["Kaede Watanabe","Toshiaki Yachimura","Tsubasa Terada","Hiroshi Kameda","Ryuhei Takahashi","Hiroshi Suito"],"url":"https://arxiv.org/abs/2505.13132"}
{"created":"2025-05-20","title":"A near-optimal Quadratic Goldreich-Levin algorithm","abstract":"In this paper, we give a quadratic Goldreich-Levin algorithm that is close to optimal in the following ways. Given a bounded function $f$ on the Boolean hypercube $\\mathbb{F}_2^n$ and any $\\varepsilon>0$, the algorithm returns a quadratic polynomial $q: \\mathbb{F}_2^n \\to \\mathbb{F}_2$ so that the correlation of $f$ with the function $(-1)^q$ is within an additive $\\varepsilon$ of the maximum possible correlation with a quadratic phase function. The algorithm runs in $O_\\varepsilon(n^3)$ time and makes $O_\\varepsilon(n^2\\log n)$ queries to $f$, which matches the information-theoretic lower bound of $\\Omega(n^2)$ queries up to a logarithmic factor.","authors":["Jop Bri\\\"et","Davi Castro-Silva"],"url":"https://arxiv.org/abs/2505.13134"}
{"created":"2025-05-20","title":"Aspects of complexity in automotive software systems and their relation to maintainability effort. A case study","abstract":"Context: Large embedded systems in vehicles tend to grow in size and complexity, which causes challenges when maintaining these systems. Objective: We explore how developers perceive the relation between maintainability effort and various sources of complexity. Methods: We conduct a case study at Scania AB, a heavy vehicle OEM. The units of analysis are two large software systems and their development teams/organizations. Results: Our results show that maintainability effort is driven by system internal complexity in the form of variant management and complex hardware control tasks. The maintainability is also influenced by emergent complexity caused by the system's longevity and constant growth. Besides these system-internal complexities, maintainability effort is also influenced by external complexities, such as organizational coordination and business needs. During the study, developer trade-off strategies for minimizing maintainability effort emerged. Conclusions: Complexity is a good proxy of maintainability effort, and allows developers to create strategies for managing the maintainability effort. Adequate complexity metrics include both external aspects -- e.g., coordination complexity -- and internal ones -- e.g., McCabe Cyclomatic Complexity.","authors":["Bengt Haraldsson","Miroslaw Staron"],"url":"https://arxiv.org/abs/2505.13135"}
{"created":"2025-05-20","title":"ModernGBERT: German-only 1B Encoder Model Trained from Scratch","abstract":"Despite the prominence of decoder-only language models, encoders remain crucial for resource-constrained applications. We introduce ModernGBERT (134M, 1B), a fully transparent family of German encoder models trained from scratch, incorporating architectural innovations from ModernBERT. To evaluate the practical trade-offs of training encoders from scratch, we also present LL\\\"aMmlein2Vec (120M, 1B, 7B), a family of encoders derived from German decoder-only models via LLM2Vec. We benchmark all models on natural language understanding, text embedding, and long-context reasoning tasks, enabling a controlled comparison between dedicated encoders and converted decoders. Our results show that ModernGBERT 1B outperforms prior state-of-the-art German encoders as well as encoders adapted via LLM2Vec, with regard to performance and parameter-efficiency. All models, training data, checkpoints and code are publicly available, advancing the German NLP ecosystem with transparent, high-performance encoder models.","authors":["Anton Ehrmanntraut","Julia Wunderle","Jan Pfister","Fotis Jannidis","Andreas Hotho"],"url":"https://arxiv.org/abs/2505.13136"}
{"created":"2025-05-20","title":"Learning to Adapt to Position Bias in Vision Transformer Classifiers","abstract":"How discriminative position information is for image classification depends on the data. On the one hand, the camera position is arbitrary and objects can appear anywhere in the image, arguing for translation invariance. At the same time, position information is key for exploiting capture/center bias, and scene layout, e.g.: the sky is up. We show that position bias, the level to which a dataset is more easily solved when positional information on input features is used, plays a crucial role in the performance of Vision Transformers image classifiers. To investigate, we propose Position-SHAP, a direct measure of position bias by extending SHAP to work with position embeddings. We show various levels of position bias in different datasets, and find that the optimal choice of position embedding depends on the position bias apparent in the dataset. We therefore propose Auto-PE, a single-parameter position embedding extension, which allows the position embedding to modulate its norm, enabling the unlearning of position information. Auto-PE combines with existing PEs to match or improve accuracy on classification datasets.","authors":["Robert-Jan Bruintjes","Jan van Gemert"],"url":"https://arxiv.org/abs/2505.13137"}
{"created":"2025-05-20","title":"Neurosymbolic Diffusion Models","abstract":"Neurosymbolic (NeSy) predictors combine neural perception with symbolic reasoning to solve tasks like visual reasoning. However, standard NeSy predictors assume conditional independence between the symbols they extract, thus limiting their ability to model interactions and uncertainty - often leading to overconfident predictions and poor out-of-distribution generalisation. To overcome the limitations of the independence assumption, we introduce neurosymbolic diffusion models (NeSyDMs), a new class of NeSy predictors that use discrete diffusion to model dependencies between symbols. Our approach reuses the independence assumption from NeSy predictors at each step of the diffusion process, enabling scalable learning while capturing symbol dependencies and uncertainty quantification. Across both synthetic and real-world benchmarks - including high-dimensional visual path planning and rule-based autonomous driving - NeSyDMs achieve state-of-the-art accuracy among NeSy predictors and demonstrate strong calibration.","authors":["Emile van Krieken","Pasquale Minervini","Edoardo Ponti","Antonio Vergari"],"url":"https://arxiv.org/abs/2505.13138"}
{"created":"2025-05-20","title":"CacheFlow: Fast Human Motion Prediction by Cached Normalizing Flow","abstract":"Many density estimation techniques for 3D human motion prediction require a significant amount of inference time, often exceeding the duration of the predicted time horizon. To address the need for faster density estimation for 3D human motion prediction, we introduce a novel flow-based method for human motion prediction called CacheFlow. Unlike previous conditional generative models that suffer from time efficiency, CacheFlow takes advantage of an unconditional flow-based generative model that transforms a Gaussian mixture into the density of future motions. The results of the computation of the flow-based generative model can be precomputed and cached. Then, for conditional prediction, we seek a mapping from historical trajectories to samples in the Gaussian mixture. This mapping can be done by a much more lightweight model, thus saving significant computation overhead compared to a typical conditional flow model. In such a two-stage fashion and by caching results from the slow flow model computation, we build our CacheFlow without loss of prediction accuracy and model expressiveness. This inference process is completed in approximately one millisecond, making it 4 times faster than previous VAE methods and 30 times faster than previous diffusion-based methods on standard benchmarks such as Human3.6M and AMASS datasets. Furthermore, our method demonstrates improved density estimation accuracy and comparable prediction accuracy to a SOTA method on Human3.6M. Our code and models will be publicly available.","authors":["Takahiro Maeda","Jinkun Cao","Norimichi Ukita","Kris Kitani"],"url":"https://arxiv.org/abs/2505.13140"}
{"created":"2025-05-20","title":"Understanding Cross-Lingual Inconsistency in Large Language Models","abstract":"Large language models (LLMs) are demonstrably capable of cross-lingual transfer, but can produce inconsistent output when prompted with the same queries written in different languages. To understand how language models are able to generalize knowledge from one language to the others, we apply the logit lens to interpret the implicit steps taken by LLMs to solve multilingual multi-choice reasoning questions. We find LLMs predict inconsistently and are less accurate because they rely on subspaces of individual languages, rather than working in a shared semantic space. While larger models are more multilingual, we show their hidden states are more likely to dissociate from the shared representation compared to smaller models, but are nevertheless more capable of retrieving knowledge embedded across different languages. Finally, we demonstrate that knowledge sharing can be modulated by steering the models' latent processing towards the shared semantic space. We find reinforcing utilization of the shared space improves the models' multilingual reasoning performance, as a result of more knowledge transfer from, and better output consistency with English.","authors":["Zheng Wei Lim","Alham Fikri Aji","Trevor Cohn"],"url":"https://arxiv.org/abs/2505.13141"}
{"created":"2025-05-20","title":"Parallel Layer Normalization for Universal Approximation","abstract":"Universal approximation theorem (UAT) is a fundamental theory for deep neural networks (DNNs), demonstrating their powerful representation capacity to represent and approximate any function. The analyses and proofs of UAT are based on traditional network with only linear and nonlinear activation functions, but omitting normalization layers, which are commonly employed to enhance the training of modern networks. This paper conducts research on UAT of DNNs with normalization layers for the first time. We theoretically prove that an infinitely wide network -- composed solely of parallel layer normalization (PLN) and linear layers -- has universal approximation capacity. Additionally, we investigate the minimum number of neurons required to approximate $L$-Lipchitz continuous functions, with a single hidden-layer network. We compare the approximation capacity of PLN with traditional activation functions in theory. Different from the traditional activation functions, we identify that PLN can act as both activation function and normalization in deep neural networks at the same time. We also find that PLN can improve the performance when replacing LN in transformer architectures, which reveals the potential of PLN used in neural architectures.","authors":["Yunhao Ni","Yuhe Liu","Wenxin Sun","Yitong Tang","Yuxin Guo","Peilin Feng","Wenjun Wu","Lei Huang"],"url":"https://arxiv.org/abs/2505.13142"}
{"created":"2025-05-20","title":"Auditing Meta-Cognitive Hallucinations in Reasoning Large Language Models","abstract":"The development of Reasoning Large Language Models (RLLMs) has significantly improved multi-step reasoning capabilities, but it has also made hallucination problems more frequent and harder to eliminate. While existing approaches mitigate hallucinations through external knowledge integration, model parameter analysis, or self-verification, they often fail to capture how hallucinations emerge and evolve across the reasoning chain. In this work, we study the causality of hallucinations under constrained knowledge domains by auditing the Chain-of-Thought (CoT) trajectory and assessing the model's cognitive confidence in potentially erroneous or biased claims. Our analysis reveals that in long-CoT settings, RLLMs can iteratively reinforce biases and errors through flawed reflective reasoning, eventually leading to hallucinated reasoning paths. Surprisingly, even direct interventions at the origin of hallucinations often fail to reverse their effects, as reasoning chains exhibit 'chain disloyalty' -- a resistance to correction and a tendency to preserve flawed logic. Furthermore, we show that existing hallucination detection methods are less reliable and interpretable than previously assumed in complex reasoning scenarios. Unlike methods such as circuit tracing that require access to model internals, our black-box auditing approach supports interpretable long-chain hallucination attribution, offering better generalizability and practical utility. Code and data are available at: https://anonymous.4open.science/r/repo_for_meta_hallucination","authors":["Haolang Lu","Yilian Liu","Jingxin Xu","Guoshun Nan","Yuanlong Yu","Zhican Chen","Kun Wang"],"url":"https://arxiv.org/abs/2505.13143"}
{"created":"2025-05-20","title":"Temporal Distance-aware Transition Augmentation for Offline Model-based Reinforcement Learning","abstract":"The goal of offline reinforcement learning (RL) is to extract a high-performance policy from the fixed datasets, minimizing performance degradation due to out-of-distribution (OOD) samples. Offline model-based RL (MBRL) is a promising approach that ameliorates OOD issues by enriching state-action transitions with augmentations synthesized via a learned dynamics model. Unfortunately, seminal offline MBRL methods often struggle in sparse-reward, long-horizon tasks. In this work, we introduce a novel MBRL framework, dubbed Temporal Distance-Aware Transition Augmentation (TempDATA), that generates augmented transitions in a temporally structured latent space rather than in raw state space. To model long-horizon behavior, TempDATA learns a latent abstraction that captures a temporal distance from both trajectory and transition levels of state space. Our experiments confirm that TempDATA outperforms previous offline MBRL methods and achieves matching or surpassing the performance of diffusion-based trajectory augmentation and goal-conditioned RL on the D4RL AntMaze, FrankaKitchen, CALVIN, and pixel-based FrankaKitchen.","authors":["Dongsu Lee","Minhae Kwon"],"url":"https://arxiv.org/abs/2505.13144"}
{"created":"2025-05-20","title":"What if Deception Cannot be Detected? A Cross-Linguistic Study on the Limits of Deception Detection from Text","abstract":"Can deception be detected solely from written text? Cues of deceptive communication are inherently subtle, even more so in text-only communication. Yet, prior studies have reported considerable success in automatic deception detection. We hypothesize that such findings are largely driven by artifacts introduced during data collection and do not generalize beyond specific datasets. We revisit this assumption by introducing a belief-based deception framework, which defines deception as a misalignment between an author's claims and true beliefs, irrespective of factual accuracy, allowing deception cues to be studied in isolation. Based on this framework, we construct three corpora, collectively referred to as DeFaBel, including a German-language corpus of deceptive and non-deceptive arguments and a multilingual version in German and English, each collected under varying conditions to account for belief change and enable cross-linguistic analysis. Using these corpora, we evaluate commonly reported linguistic cues of deception. Across all three DeFaBel variants, these cues show negligible, statistically insignificant correlations with deception labels, contrary to prior work that treats such cues as reliable indicators. We further benchmark against other English deception datasets following similar data collection protocols. While some show statistically significant correlations, effect sizes remain low and, critically, the set of predictive cues is inconsistent across datasets. We also evaluate deception detection using feature-based models, pretrained language models, and instruction-tuned large language models. While some models perform well on established deception datasets, they consistently perform near chance on DeFaBel. Our findings challenge the assumption that deception can be reliably inferred from linguistic cues and call for rethinking how deception is studied and modeled in NLP.","authors":["Aswathy Velutharambath","Roman Klinger","Kai Sassenberg"],"url":"https://arxiv.org/abs/2505.13147"}
{"created":"2025-05-20","title":"Zero-Shot Adaptation of Behavioral Foundation Models to Unseen Dynamics","abstract":"Behavioral Foundation Models (BFMs) proved successful in producing policies for arbitrary tasks in a zero-shot manner, requiring no test-time training or task-specific fine-tuning. Among the most promising BFMs are the ones that estimate the successor measure learned in an unsupervised way from task-agnostic offline data. However, these methods fail to react to changes in the dynamics, making them inefficient under partial observability or when the transition function changes. This hinders the applicability of BFMs in a real-world setting, e.g., in robotics, where the dynamics can unexpectedly change at test time. In this work, we demonstrate that Forward-Backward (FB) representation, one of the methods from the BFM family, cannot distinguish between distinct dynamics, leading to an interference among the latent directions, which parametrize different policies. To address this, we propose a FB model with a transformer-based belief estimator, which greatly facilitates zero-shot adaptation. We also show that partitioning the policy encoding space into dynamics-specific clusters, aligned with the context-embedding directions, yields additional gain in performance. These traits allow our method to respond to the dynamics observed during training and to generalize to unseen ones. Empirically, in the changing dynamics setting, our approach achieves up to a 2x higher zero-shot returns compared to the baselines for both discrete and continuous tasks.","authors":["Maksim Bobrin","Ilya Zisman","Alexander Nikulin","Vladislav Kurenkov","Dmitry Dylov"],"url":"https://arxiv.org/abs/2505.13150"}
{"created":"2025-05-20","title":"Prink: $k_s$-Anonymization for Streaming Data in Apache Flink","abstract":"In this paper, we present Prink, a novel and practically applicable concept and fully implemented prototype for ks-anonymizing data streams in real-world application architectures. Building upon the pre-existing, yet rudimentary CASTLE scheme, Prink for the first time introduces semantics-aware ks-anonymization of non-numerical (such as categorical or hierarchically generalizable) streaming data in a information loss-optimized manner. In addition, it provides native integration into Apache Flink, one of the prevailing frameworks for enterprise-grade stream data processing in numerous application domains.","authors":["Philip Groneberg","Saskia Nu\\~nez von Voigt","Thomas Janke","Louis Loechel","Karl Wolf","Elias Gr\\\"unewald","Frank Pallas"],"url":"https://arxiv.org/abs/2505.13153"}
{"created":"2025-05-20","title":"Tianyi: A Traditional Chinese Medicine all-rounder language model and its Real-World Clinical Practice","abstract":"Natural medicines, particularly Traditional Chinese Medicine (TCM), are gaining global recognition for their therapeutic potential in addressing human symptoms and diseases. TCM, with its systematic theories and extensive practical experience, provides abundant resources for healthcare. However, the effective application of TCM requires precise syndrome diagnosis, determination of treatment principles, and prescription formulation, which demand decades of clinical expertise. Despite advancements in TCM-based decision systems, machine learning, and deep learning research, limitations in data and single-objective constraints hinder their practical application. In recent years, large language models (LLMs) have demonstrated potential in complex tasks, but lack specialization in TCM and face significant challenges, such as too big model scale to deploy and issues with hallucination. To address these challenges, we introduce Tianyi with 7.6-billion-parameter LLM, a model scale proper and specifically designed for TCM, pre-trained and fine-tuned on diverse TCM corpora, including classical texts, expert treatises, clinical records, and knowledge graphs. Tianyi is designed to assimilate interconnected and systematic TCM knowledge through a progressive learning manner. Additionally, we establish TCMEval, a comprehensive evaluation benchmark, to assess LLMs in TCM examinations, clinical tasks, domain-specific question-answering, and real-world trials. The extensive evaluations demonstrate the significant potential of Tianyi as an AI assistant in TCM clinical practice and research, bridging the gap between TCM knowledge and practical application.","authors":["Zhi Liu","Tao Yang","Jing Wang","Yexin Chen","Zhan Gao","Jiaxi Yang","Kui Chen","Bingji Lu","Xiaochen Li","Changyong Luo","Yan Li","Xiaohong Gu","Peng Cao"],"url":"https://arxiv.org/abs/2505.13156"}
{"created":"2025-05-20","title":"Role-Playing Evaluation for Large Language Models","abstract":"Large Language Models (LLMs) demonstrate a notable capacity for adopting personas and engaging in role-playing. However, evaluating this ability presents significant challenges, as human assessments are resource-intensive and automated evaluations can be biased. To address this, we introduce Role-Playing Eval (RPEval), a novel benchmark designed to assess LLM role-playing capabilities across four key dimensions: emotional understanding, decision-making, moral alignment, and in-character consistency. This article details the construction of RPEval and presents baseline evaluations. Our code and dataset are available at https://github.com/yelboudouri/RPEval","authors":["Yassine El Boudouri","Walter Nuninger","Julian Alvarez","Yvan Peter"],"url":"https://arxiv.org/abs/2505.13157"}
{"created":"2025-05-20","title":"Network-wide Quantum Key Distribution with Onion Routing Relay (Conference Version)","abstract":"The advancement of quantum computing threatens classical cryptographic methods, necessitating the development of secure quantum key distribution (QKD) solutions for QKD Networks (QKDN). In this paper, a novel key distribution protocol, Onion Routing Relay (ORR), that integrates onion routing (OR) with post-quantum cryptography (PQC) in a key-relay (KR) model is evaluated for QKDNs. This approach increases the security by enhancing confidentiality, integrity, authenticity (CIA principles), and anonymity in quantum-secure communications. By employing PQC-based encapsulation, ORR aims to avoid the security risks posed by intermediate malicious nodes and ensures end-to-end security. Our results show a competitive performance of the basic ORR model, against current KR and trusted-node (TN) approaches, demonstrating its feasibility and applicability in high-security environments maintaining a consistent Quality of Service (QoS). The results also show that while basic ORR incurs higher encryption overhead, it provides substantial security improvements without significantly impacting the overall key distribution time. Nevertheless, the introduction of an end-to-end authentication extension (ORR-Ext) has a significant impact on the Quality of Service (QoS), thereby limiting its suitability to applications with stringent security requirements.","authors":["Pedro Otero-Garc\\'ia","David P\\'erez-Castro","Manuel Fern\\'andez-Veiga","Ana Fern\\'andez-Vilas"],"url":"https://arxiv.org/abs/2505.13158"}
{"created":"2025-05-20","title":"MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products","abstract":"Fast and energy-efficient low-bitwidth floating-point (FP) arithmetic is essential for Artificial Intelligence (AI) systems. Microscaling (MX) standardized formats have recently emerged as a promising alternative to baseline low-bitwidth FP formats, offering improved accuracy with a block-wise shared exponent scale combined with per-element values. However, efficiently executing the key linear algebra primitives for AI applications on MX formats requires specialized hardware support for the fundamental operators such as scaled dot product. In this work, we propose MXDOTP, the first RISC-V ISA extension for MX dot products, focusing on the 8-bit MXFP8 FP format. We extend the open-source Snitch RISC-V core with a dedicated MXFP8 dot product-accumulate unit, which fully consumes blocks of eight 8-bit operands packed into 64-bit inputs. To feed MXDOTP at full utilization with four operands per cycle, including block scales, we exploit Snitch's Stream Semantic Registers (SSRs), achieving up to 80% utilization with minimal impact on the Snitch core's architecture and no modification to the register file. Implemented in 12 nm FinFET, a cluster with eight MXDOTP-extended cores reaches up to 356 GFLOPS/W when computing MXFP8 matrix multiplications at 0.8 V, 1 GHz. Compared to a software baseline, where MX dot products are computed by type casting FP8 inputs to FP32 for higher accumulation precision and applying explicit block scaling, the cluster achieves 25x speedup and 12.5x better energy efficiency at a minimal 5.1% area increase.","authors":["Gamze \\.Islamo\\u{g}lu","Luca Bertaccini","Arpan Suravi Prasad","Francesco Conti","Angelo Garofalo","Luca Benini"],"url":"https://arxiv.org/abs/2505.13159"}
{"created":"2025-05-20","title":"eBPF-Based Instrumentation for Generalisable Diagnosis of Performance Degradation","abstract":"Online Data Intensive applications (e.g. message brokers, ML inference and databases) are core components of the modern internet, providing critical functionalities to connecting services. The load variability and interference they experience are generally the main causes of Quality of Service (QoS) degradation, harming depending applications, and resulting in an impaired end-user experience. Uncovering the cause of QoS degradation requires detailed instrumentation of an application's activity. Existing generalisable approaches utilise readily available system metrics that encode interference in kernel metrics, but unfortunately, these approaches lack the required detail to pinpoint granular causes of performance degradation (e.g., lock, disk and CPU contention). In contrast, this paper explores the use of fine-grained system-level metrics to facilitate an application-agnostic diagnosis of QoS degradation. To this end, we introduce and implement $16$ $\\textit{eBPF-based metrics}$ spanning over six kernel subsystems, which capture statistics over kernel events that often highlight obstacles impeding an application's progress. We demonstrate the use of our $\\textit{eBPF-based metrics}$ through extensive experiments containing a representative set of online data-intensive applications. Results show that the implemented metrics can deconstruct performance degradation when applications face variable workload patterns and common resource contention scenarios, while also revealing applications' internal architecture constraints.","authors":["Diogo Landau","Jorge Barbosa","Nishant Saurabh"],"url":"https://arxiv.org/abs/2505.13160"}
{"created":"2025-05-20","title":"High-Rate Nested-Lattice Quantized Matrix Multiplication with Small Lookup Tables","abstract":"Recent work have shown that the quantization for matrix multiplication problem can be optimally solved by quantizing each column in each matrix using a nested lattice code, and then multiplying the de-quantized matrices. It was further demonstrated that when product codes of sub-dimension $d$ and rate $R$ are used, the de-quantization and inner product operations can be implemented with querying a lookup table (LUT) of size $2^{2dR}$, but this is only useful when $dR$ is sufficiently small. This in turn limits LUT-based inner product decoding to low-rate quantizers. In this work, we develop a rate $R$ hierarchical nested lattice quantization framework, which quantizes each vector to $M$ layers, and admits LUT-based inner product decoding using an LUT of size $2^{2d\\frac{R}{M}}$, allowing for high-rate quantization. We provide analytic bounds on the loss of the developed scheme compared to standard nested lattice quantizers, and also numerically illustrate that this loss is negligible. Thus, our scheme enables to use small LUTs without compromising the overall distortion.","authors":["Iris Kaplan","Or Ordentlich"],"url":"https://arxiv.org/abs/2505.13164"}
{"created":"2025-05-20","title":"A parametric finite element method for a degenerate multi-phase Stefan problem with triple junctions","abstract":"In this study, we propose a parametric finite element method for a degenerate multi-phase Stefan problem with triple junctions. This model describes the energy-driven motion of a surface cluster whose distributional solution was studied by Garcke and Sturzenhecker. We approximate the weak formulation of this sharp interface model by an unfitted finite element method that uses parametric elements for the representation of the moving interfaces. We establish existence and uniqueness of the discrete solution and prove unconditional stability of the proposed scheme. Moreover, a modification of the original scheme leads to a structure-preserving variant, in that it conserves the discrete analogue of a quantity that is preserved by the classical solution. Some numerical results demonstrate the applicability of our introduced schemes.","authors":["Tokuhiro Eto","Harald Garcke","Robert N\\\"urnberg"],"url":"https://arxiv.org/abs/2505.13165"}
{"created":"2025-05-20","title":"RIFLES: Resource-effIcient Federated LEarning via Scheduling","abstract":"Federated Learning (FL) is a privacy-preserving machine learning technique that allows decentralized collaborative model training across a set of distributed clients, by avoiding raw data exchange. A fundamental component of FL is the selection of a subset of clients in each round for model training by a central server. Current selection strategies are myopic in nature in that they are based on past or current interactions, often leading to inefficiency issues such as straggling clients. In this paper, we address this serious shortcoming by proposing the RIFLES approach that builds a novel availability forecasting layer to support the client selection process. We make the following contributions: (i) we formalise the sequential selection problem and reduce it to a scheduling problem and show that the problem is NP-complete, (ii) leveraging heartbeat messages from clients, RIFLES build an availability prediction layer to support (long term) selection decisions, (iii) we propose a novel adaptive selection strategy to support efficient learning and resource usage. To circumvent the inherent exponential complexity, we present RIFLES, a heuristic that leverages clients' historical availability data by using a CNN-LSTM time series forecasting model, allowing the server to predict the optimal participation times of clients, thereby enabling informed selection decisions. By comparing against other FL techniques, we show that RIFLES provide significant improvement by between 10%-50% on a variety of metrics such as accuracy and test loss. To the best of our knowledge, it is the first work to investigate FL as a scheduling problem.","authors":["Sara Alosaime (University of Warwick)","Arshad Jhumka (University of Leeds)"],"url":"https://arxiv.org/abs/2505.13169"}
{"created":"2025-05-20","title":"Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks","abstract":"Large language models are known to memorize parts of their training data, posing risk of copyright violations. To systematically examine this risk, we pretrain language models (1B/3B/8B) from scratch on 83B tokens, mixing web-scale data with public domain books used to simulate copyrighted content at controlled frequencies at lengths at least ten times longer than prior work. We thereby identified the offset effect, a phenomenon characterized by two key findings: (1) verbatim memorization is most strongly triggered by short prefixes drawn from the beginning of the context window, with memorization decreasing counterintuitively as prefix length increases; and (2) a sharp decline in verbatim recall when prefix begins offset from the initial tokens of the context window. We attribute this to positional fragility: models rely disproportionately on the earliest tokens in their context window as retrieval anchors, making them sensitive to even slight shifts. We further observe that when the model fails to retrieve memorized content, it often produces degenerated text. Leveraging these findings, we show that shifting sensitive data deeper into the context window suppresses both extractable memorization and degeneration. Our results suggest that positional offset is a critical and previously overlooked axis for evaluating memorization risks, since prior work implicitly assumed uniformity by probing only from the beginning of training sequences.","authors":["Yixuan Xu","Antoine Bosselut","Imanol Schlag"],"url":"https://arxiv.org/abs/2505.13171"}
{"created":"2025-05-20","title":"A Case Study of Cross-Lingual Zero-Shot Generalization for Classical Languages in LLMs","abstract":"Large Language Models (LLMs) have demonstrated remarkable generalization capabilities across diverse tasks and languages. In this study, we focus on natural language understanding in three classical languages -- Sanskrit, Ancient Greek and Latin -- to investigate the factors affecting cross-lingual zero-shot generalization. First, we explore named entity recognition and machine translation into English. While LLMs perform equal to or better than fine-tuned baselines on out-of-domain data, smaller models often struggle, especially with niche or abstract entity types. In addition, we concentrate on Sanskrit by presenting a factoid question-answering (QA) dataset and show that incorporating context via retrieval-augmented generation approach significantly boosts performance. In contrast, we observe pronounced performance drops for smaller LLMs across these QA tasks. These results suggest model scale as an important factor influencing cross-lingual generalization. Assuming that models used such as GPT-4o and Llama-3.1 are not instruction fine-tuned on classical languages, our findings provide insights into how LLMs may generalize on these languages and their consequent utility in classical studies.","authors":["V. S. D. S. Mahesh Akavarapu","Hrishikesh Terdalkar","Pramit Bhattacharyya","Shubhangi Agarwal","Vishakha Deulgaonkar","Pralay Manna","Chaitali Dangarikar","Arnab Bhattacharya"],"url":"https://arxiv.org/abs/2505.13173"}
{"created":"2025-05-20","title":"FlowCut: Unsupervised Video Instance Segmentation via Temporal Mask Matching","abstract":"We propose FlowCut, a simple and capable method for unsupervised video instance segmentation consisting of a three-stage framework to construct a high-quality video dataset with pseudo labels. To our knowledge, our work is the first attempt to curate a video dataset with pseudo-labels for unsupervised video instance segmentation. In the first stage, we generate pseudo-instance masks by exploiting the affinities of features from both images and optical flows. In the second stage, we construct short video segments containing high-quality, consistent pseudo-instance masks by temporally matching them across the frames. In the third stage, we use the YouTubeVIS-2021 video dataset to extract our training instance segmentation set, and then train a video segmentation model. FlowCut achieves state-of-the-art performance on the YouTubeVIS-2019, YouTubeVIS-2021, DAVIS-2017, and DAVIS-2017 Motion benchmarks.","authors":["Alp Eren Sari","Paolo Favaro"],"url":"https://arxiv.org/abs/2505.13174"}
{"created":"2025-05-20","title":"Enhancing LLMs for Time Series Forecasting via Structure-Guided Cross-Modal Alignment","abstract":"The emerging paradigm of leveraging pretrained large language models (LLMs) for time series forecasting has predominantly employed linguistic-temporal modality alignment strategies through token-level or layer-wise feature mapping. However, these approaches fundamentally neglect a critical insight: the core competency of LLMs resides not merely in processing localized token features but in their inherent capacity to model holistic sequence structures. This paper posits that effective cross-modal alignment necessitates structural consistency at the sequence level. We propose the Structure-Guided Cross-Modal Alignment (SGCMA), a framework that fully exploits and aligns the state-transition graph structures shared by time-series and linguistic data as sequential modalities, thereby endowing time series with language-like properties and delivering stronger generalization after modality alignment. SGCMA consists of two key components, namely Structure Alignment and Semantic Alignment. In Structure Alignment, a state transition matrix is learned from text data through Hidden Markov Models (HMMs), and a shallow transformer-based Maximum Entropy Markov Model (MEMM) receives the hot-start transition matrix and annotates each temporal patch into state probability, ensuring that the temporal representation sequence inherits language-like sequential dynamics. In Semantic Alignment, cross-attention is applied between temporal patches and the top-k tokens within each state, and the ultimate temporal embeddings are derived by the expected value of these embeddings using a weighted average based on state probabilities. Experiments on multiple benchmarks demonstrate that SGCMA achieves state-of-the-art performance, offering a novel approach to cross-modal alignment in time series forecasting.","authors":["Siming Sun","Kai Zhang","Xuejun Jiang","Wenchao Meng","Qinmin Yang"],"url":"https://arxiv.org/abs/2505.13175"}
{"created":"2025-05-20","title":"ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models","abstract":"While integrating external tools into large language models (LLMs) enhances their ability to access real-time information and domain-specific services, existing approaches focus narrowly on functional tool selection following user instructions, overlooking the context-aware personalization in tool selection. This oversight leads to suboptimal user satisfaction and inefficient tool utilization, particularly when overlapping toolsets require nuanced selection based on contextual factors. To bridge this gap, we introduce ToolSpectrum, a benchmark designed to evaluate LLMs' capabilities in personalized tool utilization. Specifically, we formalize two key dimensions of personalization, user profile and environmental factors, and analyze their individual and synergistic impacts on tool utilization. Through extensive experiments on ToolSpectrum, we demonstrate that personalized tool utilization significantly improves user experience across diverse scenarios. However, even state-of-the-art LLMs exhibit the limited ability to reason jointly about user profiles and environmental factors, often prioritizing one dimension at the expense of the other. Our findings underscore the necessity of context-aware personalization in tool-augmented LLMs and reveal critical limitations for current models. Our data and code are available at https://github.com/Chengziha0/ToolSpectrum.","authors":["Zihao Cheng","Hongru Wang","Zeming Liu","Yuhang Guo","Yuanfang Guo","Yunhong Wang","Haifeng Wang"],"url":"https://arxiv.org/abs/2505.13176"}
{"created":"2025-05-20","title":"ViPlan: A Benchmark for Visual Planning with Symbolic Predicates and Vision-Language Models","abstract":"Integrating Large Language Models with symbolic planners is a promising direction for obtaining verifiable and grounded plans compared to planning in natural language, with recent works extending this idea to visual domains using Vision-Language Models (VLMs). However, rigorous comparison between VLM-grounded symbolic approaches and methods that plan directly with a VLM has been hindered by a lack of common environments, evaluation protocols and model coverage. We introduce ViPlan, the first open-source benchmark for Visual Planning with symbolic predicates and VLMs. ViPlan features a series of increasingly challenging tasks in two domains: a visual variant of the classic Blocksworld planning problem and a simulated household robotics environment. We benchmark nine open-source VLM families across multiple sizes, along with selected closed models, evaluating both VLM-grounded symbolic planning and using the models directly to propose actions. We find symbolic planning to outperform direct VLM planning in Blocksworld, where accurate image grounding is crucial, whereas the opposite is true in the household robotics tasks, where commonsense knowledge and the ability to recover from errors are beneficial. Finally, we show that across most models and methods, there is no significant benefit to using Chain-of-Thought prompting, suggesting that current VLMs still struggle with visual reasoning.","authors":["Matteo Merler","Nicola Dainese","Minttu Alakuijala","Giovanni Bonetta","Pietro Ferrazzi","Yu Tian","Bernardo Magnini","Pekka Marttinen"],"url":"https://arxiv.org/abs/2505.13180"}
{"created":"2025-05-20","title":"Efficient Speech Language Modeling via Energy Distance in Continuous Latent Space","abstract":"We introduce SLED, an alternative approach to speech language modeling by encoding speech waveforms into sequences of continuous latent representations and modeling them autoregressively using an energy distance objective. The energy distance offers an analytical measure of the distributional gap by contrasting simulated and target samples, enabling efficient training to capture the underlying continuous autoregressive distribution. By bypassing reliance on residual vector quantization, SLED avoids discretization errors and eliminates the need for the complicated hierarchical architectures common in existing speech language models. It simplifies the overall modeling pipeline while preserving the richness of speech information and maintaining inference efficiency. Empirical results demonstrate that SLED achieves strong performance in both zero-shot and streaming speech synthesis, showing its potential for broader applications in general-purpose speech language models.","authors":["Zhengrui Ma","Yang Feng","Chenze Shao","Fandong Meng","Jie Zhou","Min Zhang"],"url":"https://arxiv.org/abs/2505.13181"}
{"created":"2025-05-20","title":"Information Science Principles of Machine Learning: A Causal Chain Meta-Framework Based on Formalized Information Mapping","abstract":"[Objective] This study focuses on addressing the current lack of a unified formal theoretical framework in machine learning, as well as the deficiencies in interpretability and ethical safety assurance. [Methods] A formal information model is first constructed, utilizing sets of well-formed formulas to explicitly define the ontological states and carrier mappings of typical components in machine learning. Learnable and processable predicates, along with learning and processing functions, are introduced to analyze the logical deduction and constraint rules of the causal chains within models. [Results] A meta-framework for machine learning theory (MLT-MF) is established. Based on this framework, universal definitions for model interpretability and ethical safety are proposed. Furthermore, three key theorems are proved: the equivalence of model interpretability and information recoverability, the assurance of ethical safety, and the estimation of generalization error. [Limitations] The current framework assumes ideal conditions with noiseless information-enabling mappings and primarily targets model learning and processing logic in static scenarios. It does not yet address information fusion and conflict resolution across ontological spaces in multimodal or multi-agent systems. [Conclusions] This work overcomes the limitations of fragmented research and provides a unified theoretical foundation for systematically addressing the critical challenges currently faced in machine learning.","authors":["Jianfeng Xu"],"url":"https://arxiv.org/abs/2505.13182"}
{"created":"2025-05-20","title":"Interpretable Robotic Friction Learning via Symbolic Regression","abstract":"Accurately modeling the friction torque in robotic joints has long been challenging due to the request for a robust mathematical description. Traditional model-based approaches are often labor-intensive, requiring extensive experiments and expert knowledge, and they are difficult to adapt to new scenarios and dependencies. On the other hand, data-driven methods based on neural networks are easier to implement but often lack robustness, interpretability, and trustworthiness--key considerations for robotic hardware and safety-critical applications such as human-robot interaction. To address the limitations of both approaches, we propose the use of symbolic regression (SR) to estimate the friction torque. SR generates interpretable symbolic formulas similar to those produced by model-based methods while being flexible to accommodate various dynamic effects and dependencies. In this work, we apply SR algorithms to approximate the friction torque using collected data from a KUKA LWR-IV+ robot. Our results show that SR not only yields formulas with comparable complexity to model-based approaches but also achieves higher accuracy. Moreover, SR-derived formulas can be seamlessly extended to include load dependencies and other dynamic factors.","authors":["Philipp Scholl","Alexander Dietrich","Sebastian Wolf","Jinoh Lee","Alin-Albu Sch\\\"affer","Gitta Kutyniok","Maged Iskandar"],"url":"https://arxiv.org/abs/2505.13186"}
{"created":"2025-05-20","title":"When a Reinforcement Learning Agent Encounters Unknown Unknowns","abstract":"An AI agent might surprisingly find she has reached an unknown state which she has never been aware of -- an unknown unknown. We mathematically ground this scenario in reinforcement learning: an agent, after taking an action calculated from value functions $Q$ and $V$ defined on the {\\it {aware domain}}, reaches a state out of the domain. To enable the agent to handle this scenario, we propose an {\\it episodic Markov decision {process} with growing awareness} (EMDP-GA) model, taking a new {\\it noninformative value expansion} (NIVE) approach to expand value functions to newly aware areas: when an agent arrives at an unknown unknown, value functions $Q$ and $V$ whereon are initialised by noninformative beliefs -- the averaged values on the aware domain. This design is out of respect for the complete absence of knowledge in the newly discovered state. The upper confidence bound momentum Q-learning is then adapted to the growing awareness for training the EMDP-GA model. We prove that (1) the regret of our approach is asymptotically consistent with the state of the art (SOTA) without exposure to unknown unknowns in an extremely uncertain environment, and (2) our computational complexity and space complexity are comparable with the SOTA -- these collectively suggest that though an unknown unknown is surprising, it will be asymptotically properly discovered with decent speed and an affordable cost.","authors":["Juntian Zhu","Miguel de Carvalho","Zhouwang Yang","Fengxiang He"],"url":"https://arxiv.org/abs/2505.13188"}
{"created":"2025-05-20","title":"Emergence of Fixational and Saccadic Movements in a Multi-Level Recurrent Attention Model for Vision","abstract":"Inspired by foveal vision, hard attention models promise interpretability and parameter economy. However, existing models like the Recurrent Model of Visual Attention (RAM) and Deep Recurrent Attention Model (DRAM) failed to model the hierarchy of human vision system, that compromise on the visual exploration dynamics. As a result, they tend to produce attention that are either overly fixational or excessively saccadic, diverging from human eye movement behavior. In this paper, we propose a Multi-Level Recurrent Attention Model (MRAM), a novel hard attention framework that explicitly models the neural hierarchy of human visual processing. By decoupling the function of glimpse location generation and task execution in two recurrent layers, MRAM emergent a balanced behavior between fixation and saccadic movement. Our results show that MRAM not only achieves more human-like attention dynamics, but also consistently outperforms CNN, RAM and DRAM baselines on standard image classification benchmarks.","authors":["Pengcheng Pan","Yonekura Shogo","Yasuo Kuniyoshi"],"url":"https://arxiv.org/abs/2505.13191"}
{"created":"2025-05-20","title":"True Zero-Shot Inference of Dynamical Systems Preserving Long-Term Statistics","abstract":"Complex, temporally evolving phenomena, from climate to brain activity, are governed by dynamical systems (DS). DS reconstruction (DSR) seeks to infer generative surrogate models of these from observed data, reproducing their long-term behavior. Existing DSR approaches require purpose-training for any new system observed, lacking the zero-shot and in-context inference capabilities known from LLMs. Here we introduce DynaMix, a novel multivariate ALRNN-based mixture-of-experts architecture pre-trained for DSR, the first DSR model able to generalize zero-shot to out-of-domain DS. Just from a provided context signal, without any re-training, DynaMix faithfully forecasts the long-term evolution of novel DS where existing time series (TS) foundation models, like Chronos, fail -- at a fraction of the number of parameters and orders of magnitude faster inference times. DynaMix outperforms TS foundation models in terms of long-term statistics, and often also short-term forecasts, even on real-world time series, like traffic or weather data, typically used for training and evaluating TS models, but not at all part of DynaMix' training corpus. We illustrate some of the failure modes of TS models for DSR problems, and conclude that models built on DS principles may bear a huge potential also for advancing the TS prediction field.","authors":["Christoph J\\\"urgen Hemmer","Daniel Durstewitz"],"url":"https://arxiv.org/abs/2505.13192"}
{"created":"2025-05-20","title":"Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities","abstract":"As Large Language Models (LLMs) become increasingly integrated into real-world decision-making systems, understanding their behavioural vulnerabilities remains a critical challenge for AI safety and alignment. While existing evaluation metrics focus primarily on reasoning accuracy or factual correctness, they often overlook whether LLMs are robust to adversarial manipulation or capable of using adaptive strategy in dynamic environments. This paper introduces an adversarial evaluation framework designed to systematically stress-test the decision-making processes of LLMs under interactive and adversarial conditions. Drawing on methodologies from cognitive psychology and game theory, our framework probes how models respond in two canonical tasks: the two-armed bandit task and the Multi-Round Trust Task. These tasks capture key aspects of exploration-exploitation trade-offs, social cooperation, and strategic flexibility. We apply this framework to several state-of-the-art LLMs, including GPT-3.5, GPT-4, Gemini-1.5, and DeepSeek-V3, revealing model-specific susceptibilities to manipulation and rigidity in strategy adaptation. Our findings highlight distinct behavioral patterns across models and emphasize the importance of adaptability and fairness recognition for trustworthy AI deployment. Rather than offering a performance benchmark, this work proposes a methodology for diagnosing decision-making weaknesses in LLM-based agents, providing actionable insights for alignment and safety research.","authors":["Lili Zhang","Haomiaomiao Wang","Long Cheng","Libao Deng","Tomas Ward"],"url":"https://arxiv.org/abs/2505.13195"}
{"created":"2025-05-20","title":"A Physics-Inspired Optimizer: Velocity Regularized Adam","abstract":"We introduce Velocity-Regularized Adam (VRAdam), a physics-inspired optimizer for training deep neural networks that draws on ideas from quartic terms for kinetic energy with its stabilizing effects on various system dynamics. Previous algorithms, including the ubiquitous Adam, operate at the so called adaptive edge of stability regime during training leading to rapid oscillations and slowed convergence of loss. However, VRAdam adds a higher order penalty on the learning rate based on the velocity such that the algorithm automatically slows down whenever weight updates become large. In practice, we observe that the effective dynamic learning rate shrinks in high-velocity regimes, damping oscillations and allowing for a more aggressive base step size when necessary without divergence. By combining this velocity-based regularizer for global damping with per-parameter scaling of Adam to create a hybrid optimizer, we demonstrate that VRAdam consistently exceeds the performance against standard optimizers including AdamW. We benchmark various tasks such as image classification, language modeling, image generation and generative modeling using diverse architectures and training methodologies including Convolutional Neural Networks (CNNs), Transformers, and GFlowNets.","authors":["Pranav Vaidhyanathan","Lucas Schorling","Natalia Ares","Michael A. Osborne"],"url":"https://arxiv.org/abs/2505.13196"}
{"created":"2025-05-20","title":"Inferring stochastic dynamics with growth from cross-sectional data","abstract":"Time-resolved single-cell omics data offers high-throughput, genome-wide measurements of cellular states, which are instrumental to reverse-engineer the processes underpinning cell fate. Such technologies are inherently destructive, allowing only cross-sectional measurements of the underlying stochastic dynamical system. Furthermore, cells may divide or die in addition to changing their molecular state. Collectively these present a major challenge to inferring realistic biophysical models. We present a novel approach, \\emph{unbalanced} probability flow inference, that addresses this challenge for biological processes modelled as stochastic dynamics with growth. By leveraging a Lagrangian formulation of the Fokker-Planck equation, our method accurately disentangles drift from intrinsic noise and growth. We showcase the applicability of our approach through evaluation on a range of simulated and real single-cell RNA-seq datasets. Comparing to several existing methods, we find our method achieves higher accuracy while enjoying a simple two-step training scheme.","authors":["Stephen Zhang","Suryanarayana Maddu","Xiaoje Qiu","Victor Chard\\`es"],"url":"https://arxiv.org/abs/2505.13197"}
{"created":"2025-05-20","title":"MatPredict: a dataset and benchmark for learning material properties of diverse indoor objects","abstract":"Determining material properties from camera images can expand the ability to identify complex objects in indoor environments, which is valuable for consumer robotics applications. To support this, we introduce MatPredict, a dataset that combines the high-quality synthetic objects from Replica dataset with MatSynth dataset's material properties classes - to create objects with diverse material properties. We select 3D meshes of specific foreground objects and render them with different material properties. In total, we generate \\textbf{18} commonly occurring objects with \\textbf{14} different materials. We showcase how we provide variability in terms of lighting and camera placement for these objects. Next, we provide a benchmark for inferring material properties from visual images using these perturbed models in the scene, discussing the specific neural network models involved and their performance based on different image comparison metrics. By accurately simulating light interactions with different materials, we can enhance realism, which is crucial for training models effectively through large-scale simulations. This research aims to revolutionize perception in consumer robotics. The dataset is provided \\href{https://huggingface.co/datasets/UMTRI/MatPredict}{here} and the code is provided \\href{https://github.com/arpan-kusari/MatPredict}{here}.","authors":["Yuzhen Chen","Hojun Son","Arpan Kusari"],"url":"https://arxiv.org/abs/2505.13201"}
{"created":"2025-05-20","title":"Alignment-Augmented Speculative Decoding with Alignment Sampling and Conditional Verification","abstract":"Recent works have revealed the great potential of speculative decoding in accelerating the autoregressive generation process of large language models. The success of these methods relies on the alignment between draft candidates and the sampled outputs of the target model. Existing methods mainly achieve draft-target alignment with training-based methods, e.g., EAGLE, Medusa, involving considerable training costs. In this paper, we present a training-free alignment-augmented speculative decoding algorithm. We propose alignment sampling, which leverages output distribution obtained in the prefilling phase to provide more aligned draft candidates. To further benefit from high-quality but non-aligned draft candidates, we also introduce a simple yet effective flexible verification strategy. Through an adaptive probability threshold, our approach can improve generation accuracy while further improving inference efficiency. Experiments on 8 datasets (including question answering, summarization and code completion tasks) show that our approach increases the average generation score by 3.3 points for the LLaMA3 model. Our method achieves a mean acceptance length up to 2.39 and speed up generation by 2.23.","authors":["Jikai Wang","Zhenxu Tian","Juntao Li","Qingrong Xia","Xinyu Duan","Zhefeng Wang","Baoxing Huai","Min Zhang"],"url":"https://arxiv.org/abs/2505.13204"}
{"created":"2025-05-20","title":"Picturized and Recited with Dialects: A Multimodal Chinese Representation Framework for Sentiment Analysis of Classical Chinese Poetry","abstract":"Classical Chinese poetry is a vital and enduring part of Chinese literature, conveying profound emotional resonance. Existing studies analyze sentiment based on textual meanings, overlooking the unique rhythmic and visual features inherent in poetry,especially since it is often recited and accompanied by Chinese paintings. In this work, we propose a dialect-enhanced multimodal framework for classical Chinese poetry sentiment analysis. We extract sentence-level audio features from the poetry and incorporate audio from multiple dialects,which may retain regional ancient Chinese phonetic features, enriching the phonetic representation. Additionally, we generate sentence-level visual features, and the multimodal features are fused with textual features enhanced by LLM translation through multimodal contrastive representation learning. Our framework outperforms state-of-the-art methods on two public datasets, achieving at least 2.51% improvement in accuracy and 1.63% in macro F1. We open-source the code to facilitate research in this area and provide insights for general multimodal Chinese representation.","authors":["Xiaocong Du","Haoyu Pei","Haipeng Zhang"],"url":"https://arxiv.org/abs/2505.13210"}
{"created":"2025-05-20","title":"MAGI-1: Autoregressive Video Generation at Scale","abstract":"We present MAGI-1, a world model that generates videos by autoregressively predicting a sequence of video chunks, defined as fixed-length segments of consecutive frames. Trained to denoise per-chunk noise that increases monotonically over time, MAGI-1 enables causal temporal modeling and naturally supports streaming generation. It achieves strong performance on image-to-video (I2V) tasks conditioned on text instructions, providing high temporal consistency and scalability, which are made possible by several algorithmic innovations and a dedicated infrastructure stack. MAGI-1 facilitates controllable generation via chunk-wise prompting and supports real-time, memory-efficient deployment by maintaining constant peak inference cost, regardless of video length. The largest variant of MAGI-1 comprises 24 billion parameters and supports context lengths of up to 4 million tokens, demonstrating the scalability and robustness of our approach. The code and models are available at https://github.com/SandAI-org/MAGI-1 and https://github.com/SandAI-org/MagiAttention. The product can be accessed at https://sand.ai.","authors":["Sand. ai","Hansi Teng","Hongyu Jia","Lei Sun","Lingzhi Li","Maolin Li","Mingqiu Tang","Shuai Han","Tianning Zhang","W. Q. Zhang","Weifeng Luo","Xiaoyang Kang","Yuchen Sun","Yue Cao","Yunpeng Huang","Yutong Lin","Yuxin Fang","Zewei Tao","Zheng Zhang","Zhongshu Wang","Zixun Liu","Dai Shi","Guoli Su","Hanwen Sun","Hong Pan","Jie Wang","Jiexin Sheng","Min Cui","Min Hu","Ming Yan","Shucheng Yin","Siran Zhang","Tingting Liu","Xianping Yin","Xiaoyu Yang","Xin Song","Xuan Hu","Yankai Zhang","Yuqiao Li"],"url":"https://arxiv.org/abs/2505.13211"}
{"created":"2025-05-20","title":"RB-SCD: A New Benchmark for Semantic Change Detection of Roads and Bridges in Traffic Scenes","abstract":"Accurate detection of changes in roads and bridges, such as construction, renovation, and demolition, is essential for urban planning and traffic management. However, existing methods often struggle to extract fine-grained semantic change information due to the lack of high-quality annotated datasets in traffic scenarios. To address this, we introduce the Road and Bridge Semantic Change Detection (RB-SCD) dataset, a comprehensive benchmark comprising 260 pairs of high-resolution remote sensing images from diverse cities and countries. RB-SCD captures 11 types of semantic changes across varied road and bridge structures, enabling detailed structural and functional analysis. Building on this dataset, we propose a novel framework, Multimodal Frequency-Driven Change Detector (MFDCD), which integrates multimodal features in the frequency domain. MFDCD includes a Dynamic Frequency Coupler (DFC) that fuses hierarchical visual features with wavelet-based frequency components, and a Textual Frequency Filter (TFF) that transforms CLIP-derived textual features into the frequency domain and applies graph-based filtering. Experimental results on RB-SCD and three public benchmarks demonstrate the effectiveness of our approach.","authors":["Qingling Shu","Sibao Chen","Zhihui You","Wei Lu","Jin Tang","Bin Luo"],"url":"https://arxiv.org/abs/2505.13212"}
{"created":"2025-05-20","title":"Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation","abstract":"Recent advancements in dynamic 3D scene reconstruction have shown promising results, enabling high-fidelity 3D novel view synthesis with improved temporal consistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an appealing approach due to its ability to model high-fidelity spatial and temporal variations. However, existing methods suffer from substantial computational and memory overhead due to the redundant allocation of 4D Gaussians to static regions, which can also degrade image quality. In this work, we introduce hybrid 3D-4D Gaussian Splatting (3D-4DGS), a novel framework that adaptively represents static regions with 3D Gaussians while reserving 4D Gaussians for dynamic elements. Our method begins with a fully 4D Gaussian representation and iteratively converts temporally invariant Gaussians into 3D, significantly reducing the number of parameters and improving computational efficiency. Meanwhile, dynamic Gaussians retain their full 4D representation, capturing complex motions with high fidelity. Our approach achieves significantly faster training times compared to baseline 4D Gaussian Splatting methods while maintaining or improving the visual quality.","authors":["Seungjun Oh","Younggeun Lee","Hyejin Jeon","Eunbyung Park"],"url":"https://arxiv.org/abs/2505.13215"}
{"created":"2025-05-20","title":"Human Response to Decision Support in Face Matching: The Influence of Task Difficulty and Machine Accuracy","abstract":"Decision support systems enhanced by Artificial Intelligence (AI) are increasingly being used in high-stakes scenarios where errors or biased outcomes can have significant consequences. In this work, we explore the conditions under which AI-based decision support systems affect the decision accuracy of humans involved in face matching tasks. Previous work suggests that this largely depends on various factors, such as the specific nature of the task and how users perceive the quality of the decision support, among others. Hence, we conduct extensive experiments to examine how both task difficulty and the precision of the system influence human outcomes. Our results show a strong influence of task difficulty, which not only makes humans less precise but also less capable of determining whether the decision support system is yielding accurate suggestions or not. This has implications for the design of decision support systems, and calls for a careful examination of the context in which they are deployed and on how they are perceived by users.","authors":["Marina Est\\'evez-Almenzar","Ricardo Baeza-Yates","Carlos Castillo"],"url":"https://arxiv.org/abs/2505.13218"}
{"created":"2025-05-20","title":"Swin DiT: Diffusion Transformer using Pseudo Shifted Windows","abstract":"Diffusion Transformers (DiTs) achieve remarkable performance within the domain of image generation through the incorporation of the transformer architecture. Conventionally, DiTs are constructed by stacking serial isotropic global information modeling transformers, which face significant computational cost when processing high-resolution images. We empirically analyze that latent space image generation does not exhibit a strong dependence on global information as traditionally assumed. Most of the layers in the model demonstrate redundancy in global computation. In addition, conventional attention mechanisms exhibit low-frequency inertia issues. To address these issues, we propose \\textbf{P}seudo \\textbf{S}hifted \\textbf{W}indow \\textbf{A}ttention (PSWA), which fundamentally mitigates global model redundancy. PSWA achieves intermediate global-local information interaction through window attention, while employing a high-frequency bridging branch to simulate shifted window operations, supplementing appropriate global and high-frequency information. Furthermore, we propose the Progressive Coverage Channel Allocation(PCCA) strategy that captures high-order attention similarity without additional computational cost. Building upon all of them, we propose a series of Pseudo \\textbf{S}hifted \\textbf{Win}dow DiTs (\\textbf{Swin DiT}), accompanied by extensive experiments demonstrating their superior performance. For example, our proposed Swin-DiT-L achieves a 54%$\\uparrow$ FID improvement over DiT-XL/2 while requiring less computational. https://github.com/wujiafu007/Swin-DiT","authors":["Jiafu Wu","Yabiao Wang","Jian Li","Jinlong Peng","Yun Cao","Chengjie Wang","Jiangning Zhang"],"url":"https://arxiv.org/abs/2505.13219"}
{"created":"2025-05-20","title":"SeedBench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science","abstract":"Seed science is essential for modern agriculture, directly influencing crop yields and global food security. However, challenges such as interdisciplinary complexity and high costs with limited returns hinder progress, leading to a shortage of experts and insufficient technological support. While large language models (LLMs) have shown promise across various fields, their application in seed science remains limited due to the scarcity of digital resources, complex gene-trait relationships, and the lack of standardized benchmarks. To address this gap, we introduce SeedBench -- the first multi-task benchmark specifically designed for seed science. Developed in collaboration with domain experts, SeedBench focuses on seed breeding and simulates key aspects of modern breeding processes. We conduct a comprehensive evaluation of 26 leading LLMs, encompassing proprietary, open-source, and domain-specific fine-tuned models. Our findings not only highlight the substantial gaps between the power of LLMs and the real-world seed science problems, but also make a foundational step for research on LLMs for seed design.","authors":["Jie Ying","Zihong Chen","Zhefan Wang","Wanli Jiang","Chenyang Wang","Zhonghang Yuan","Haoyang Su","Huanjun Kong","Fan Yang","Nanqing Dong"],"url":"https://arxiv.org/abs/2505.13220"}
{"created":"2025-05-20","title":"Automatic Complementary Separation Pruning Toward Lightweight CNNs","abstract":"In this paper, we present Automatic Complementary Separation Pruning (ACSP), a novel and fully automated pruning method for convolutional neural networks. ACSP integrates the strengths of both structured pruning and activation-based pruning, enabling the efficient removal of entire components such as neurons and channels while leveraging activations to identify and retain the most relevant components. Our approach is designed specifically for supervised learning tasks, where we construct a graph space that encodes the separation capabilities of each component with respect to all class pairs. By employing complementary selection principles and utilizing a clustering algorithm, ACSP ensures that the selected components maintain diverse and complementary separation capabilities, reducing redundancy and maintaining high network performance. The method automatically determines the optimal subset of components in each layer, utilizing a knee-finding algorithm to select the minimal subset that preserves performance without requiring user-defined pruning volumes. Extensive experiments on multiple architectures, including VGG-16, ResNet-50, and MobileNet-V2, across datasets like CIFAR-10, CIFAR-100, and ImageNet-1K, demonstrate that ACSP achieves competitive accuracy compared to other methods while significantly reducing computational costs. This fully automated approach not only enhances scalability but also makes ACSP especially practical for real-world deployment by eliminating the need for manually defining the pruning volume.","authors":["David Levin","Gonen Singer"],"url":"https://arxiv.org/abs/2505.13225"}
{"created":"2025-05-20","title":"Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis","abstract":"Graphical user interface (GUI) grounding, the ability to map natural language instructions to specific actions on graphical user interfaces, remains a critical bottleneck in computer use agent development. Current benchmarks oversimplify grounding tasks as short referring expressions, failing to capture the complexity of real-world interactions that require software commonsense, layout understanding, and fine-grained manipulation capabilities. To address these limitations, we introduce OSWorld-G, a comprehensive benchmark comprising 564 finely annotated samples across diverse task types including text matching, element recognition, layout understanding, and precise manipulation. Additionally, we synthesize and release the largest computer use grounding dataset Jedi, which contains 4 million examples through multi-perspective decoupling of tasks. Our multi-scale models trained on Jedi demonstrate its effectiveness by outperforming existing approaches on ScreenSpot-v2, ScreenSpot-Pro, and our OSWorld-G. Furthermore, we demonstrate that improved grounding with Jedi directly enhances agentic capabilities of general foundation models on complex computer tasks, improving from 5% to 27% on OSWorld. Through detailed ablation studies, we identify key factors contributing to grounding performance and verify that combining specialized data for different interface elements enables compositional generalization to novel interfaces. All benchmark, data, checkpoints, and code are open-sourced and available at https://osworld-grounding.github.io.","authors":["Tianbao Xie","Jiaqi Deng","Xiaochuan Li","Junlin Yang","Haoyuan Wu","Jixuan Chen","Wenjing Hu","Xinyuan Wang","Yuhui Xu","Zekun Wang","Yiheng Xu","Junli Wang","Doyen Sahoo","Tao Yu","Caiming Xiong"],"url":"https://arxiv.org/abs/2505.13227"}
{"created":"2025-05-20","title":"PARF: An Adaptive Abstraction-Strategy Tuner for Static Analysis","abstract":"We launch Parf - a toolkit for adaptively tuning abstraction strategies of static program analyzers in a fully automated manner. Parf models various types of external parameters (encoding abstraction strategies) as random variables subject to probability distributions over latticed parameter spaces. It incrementally refines the probability distributions based on accumulated intermediate results generated by repeatedly sampling and analyzing, thereby ultimately yielding a set of highly accurate abstraction strategies. Parf is implemented on top of Frama-C/Eva - an off-the-shelf open-source static analyzer for C programs. Parf provides a web-based user interface facilitating the intuitive configuration of static analyzers and visualization of dynamic distribution refinement of the abstraction strategies. It further supports the identification of dominant parameters in Frama-C/Eva analysis. Benchmark experiments and a case study demonstrate the competitive performance of Parf for analyzing complex, large-scale real-world programs.","authors":["Zhongyi Wang","Mingshuai Chen","Tengjie Lin","Linyu Yang","Junhao Zhuo","Qiuye Wang","Shengchao Qin","Xiao Yi","Jianwei Yin"],"url":"https://arxiv.org/abs/2505.13229"}
{"created":"2025-05-20","title":"Implicit bias produces neural scaling laws in learning curves, from perceptrons to deep networks","abstract":"Scaling laws in deep learning - empirical power-law relationships linking model performance to resource growth - have emerged as simple yet striking regularities across architectures, datasets, and tasks. These laws are particularly impactful in guiding the design of state-of-the-art models, since they quantify the benefits of increasing data or model size, and hint at the foundations of interpretability in machine learning. However, most studies focus on asymptotic behavior at the end of training or on the optimal training time given the model size. In this work, we uncover a richer picture by analyzing the entire training dynamics through the lens of spectral complexity norms. We identify two novel dynamical scaling laws that govern how performance evolves during training. These laws together recover the well-known test error scaling at convergence, offering a mechanistic explanation of generalization emergence. Our findings are consistent across CNNs, ResNets, and Vision Transformers trained on MNIST, CIFAR-10 and CIFAR-100. Furthermore, we provide analytical support using a solvable model: a single-layer perceptron trained with binary cross-entropy. In this setting, we show that the growth of spectral complexity driven by the implicit bias mirrors the generalization behavior observed at fixed norm, allowing us to connect the performance dynamics to classical learning rules in the perceptron.","authors":["Francesco D'Amico","Dario Bocchi","Matteo Negri"],"url":"https://arxiv.org/abs/2505.13230"}
{"created":"2025-05-20","title":"Investigating Active Sampling for Hardness Classification with Vision-Based Tactile Sensors","abstract":"One of the most important object properties that humans and robots perceive through touch is hardness. This paper investigates information-theoretic active sampling strategies for sample-efficient hardness classification with vision-based tactile sensors. We evaluate three probabilistic classifier models and two model-uncertainty-based sampling strategies on a robotic setup as well as on a previously published dataset of samples collected by human testers. Our findings indicate that the active sampling approaches, driven by uncertainty metrics, surpass a random sampling baseline in terms of accuracy and stability. Additionally, while in our human study, the participants achieve an average accuracy of 48.00%, our best approach achieves an average accuracy of 88.78% on the same set of objects, demonstrating the effectiveness of vision-based tactile sensors for object hardness classification.","authors":["Junyi Chen","Alap Kshirsagar","Frederik Heller","Mario G\\'omez Andreu","Boris Belousov","Tim Schneider","Lisa P. Y. Lin","Katja Doerschner","Knut Drewing","Jan Peters"],"url":"https://arxiv.org/abs/2505.13231"}
{"created":"2025-05-20","title":"StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment","abstract":"Learning robust representations from data often requires scale, which has led to the success of recent zero-shot models such as CLIP. However, the obtained robustness can easily be deteriorated when these models are fine-tuned on other downstream tasks (e.g., of smaller scales). Previous works often interpret this phenomenon in the context of domain shift, developing fine-tuning methods that aim to preserve the original domain as much as possible. However, in a different context, fine-tuned models with limited data are also prone to learning features that are spurious to humans, such as background or texture. In this paper, we propose StarFT (Spurious Textual Alignment Regularization), a novel framework for fine-tuning zero-shot models to enhance robustness by preventing them from learning spuriosity. We introduce a regularization that aligns the output distribution for spuriosity-injected labels with the original zero-shot model, ensuring that the model is not induced to extract irrelevant features further from these descriptions.We leverage recent language models to get such spuriosity-injected labels by generating alternative textual descriptions that highlight potentially confounding features.Extensive experiments validate the robust generalization of StarFT and its emerging properties: zero-shot group robustness and improved zero-shot classification. Notably, StarFT boosts both worst-group and average accuracy by 14.30% and 3.02%, respectively, in the Waterbirds group shift scenario, where other robust fine-tuning baselines show even degraded performance.","authors":["Younghyun Kim","Jongheon Jeong","Sangkyung Kwak","Kyungmin Lee","Juho Lee","Jinwoo Shin"],"url":"https://arxiv.org/abs/2505.13232"}
{"created":"2025-05-20","title":"From Local Details to Global Context: Advancing Vision-Language Models with Attention-Based Selection","abstract":"Pretrained vision-language models (VLMs), e.g., CLIP, demonstrate impressive zero-shot capabilities on downstream tasks. Prior research highlights the crucial role of visual augmentation techniques, like random cropping, in alignment with fine-grained class descriptions generated by large language models (LLMs), significantly enhancing zero-shot performance by incorporating multi-view information. However, the inherent randomness of these augmentations can inevitably introduce background artifacts and cause models to overly focus on local details, compromising global semantic understanding. To address these issues, we propose an \\textbf{A}ttention-\\textbf{B}ased \\textbf{S}election (\\textbf{ABS}) method from local details to global context, which applies attention-guided cropping in both raw images and feature space, supplement global semantic information through strategic feature selection. Additionally, we introduce a soft matching technique to effectively filter LLM descriptions for better alignment. \\textbf{ABS} achieves state-of-the-art performance on out-of-distribution generalization and zero-shot classification tasks. Notably, \\textbf{ABS} is training-free and even rivals few-shot and test-time adaptation methods. Our code is available at \\href{https://github.com/BIT-DA/ABS}{\\textcolor{darkgreen}{https://github.com/BIT-DA/ABS}}.","authors":["Lincan Cai","Jingxuan Kang","Shuang Li","Wenxuan Ma","Binhui Xie","Zhida Qin","Jian Liang"],"url":"https://arxiv.org/abs/2505.13233"}
{"created":"2025-05-20","title":"WriteViT: Handwritten Text Generation with Vision Transformer","abstract":"Humans can quickly generalize handwriting styles from a single example by intuitively separating content from style. Machines, however, struggle with this task, especially in low-data settings, often missing subtle spatial and stylistic cues. Motivated by this gap, we introduce WriteViT, a one-shot handwritten text synthesis framework that incorporates Vision Transformers (ViT), a family of models that have shown strong performance across various computer vision tasks. WriteViT integrates a ViT-based Writer Identifier for extracting style embeddings, a multi-scale generator built with Transformer encoder-decoder blocks enhanced by conditional positional encoding (CPE), and a lightweight ViT-based recognizer. While previous methods typically rely on CNNs or CRNNs, our design leverages transformers in key components to better capture both fine-grained stroke details and higher-level style information. Although handwritten text synthesis has been widely explored, its application to Vietnamese -- a language rich in diacritics and complex typography -- remains limited. Experiments on Vietnamese and English datasets demonstrate that WriteViT produces high-quality, style-consistent handwriting while maintaining strong recognition performance in low-resource scenarios. These results highlight the promise of transformer-based designs for multilingual handwriting generation and efficient style adaptation.","authors":["Dang Hoai Nam","Huynh Tong Dang Khoa","Vo Nguyen Le Duy"],"url":"https://arxiv.org/abs/2505.13235"}
{"created":"2025-05-20","title":"A Geometry-Grounded Data Perimeter in Azure","abstract":"While data perimeter is ubiquitous in cybersecurity speak, it rarely defines how boundary points are arranged. In this paper we show how Azure s blast radius ultrametric provides the distance, and how solving the Traveling Salesman Problem in this ultrametric space provides the ordering, yielding a true geometric contour: an actionable perimeter measure for SPN prioritization.","authors":["Christophe Parisel"],"url":"https://arxiv.org/abs/2505.13238"}
{"created":"2025-05-20","title":"Network-wide Quantum Key Distribution with Onion Routing Relay","abstract":"The advancement of quantum computing threatens classical cryptographic methods, necessitating the development of secure quantum key distribution (QKD) solutions for QKD Networks (QKDN). In this paper, a novel key distribution protocol, Onion Routing Relay (ORR), that integrates onion routing (OR) with post-quantum cryptography (PQC) in a key-relay (KR) model is evaluated for QKDNs. This approach increases the security by enhancing confidentiality, integrity, authenticity, and anonymity in quantum-secure communications. By employing PQC-based encapsulation, ORR pretends to avoid the security risks posed by intermediate malicious nodes and ensures end-to-end security. Results show that the performance of the ORR model, against current key-relay (KR) and trusted-node (TN) approaches, demonstrating its feasibility and applicability in high-security environments maintaining a consistent Quality of Service (QoS). The results show that while ORR incurs higher encryption overhead, it provides substantial security improvements without significantly impacting the overall key distribution time.","authors":["Pedro Otero-Garc\\'ia","David P\\'erez-Castro","Manuel Fern\\'andez-Veiga","Ana Fern\\'andez-Vilas"],"url":"https://arxiv.org/abs/2505.13239"}
{"created":"2025-05-20","title":"Reconstructing Physics-Informed Machine Learning for Traffic Flow Modeling: a Multi-Gradient Descent and Pareto Learning Approach","abstract":"Physics-informed machine learning (PIML) is crucial in modern traffic flow modeling because it combines the benefits of both physics-based and data-driven approaches. In conventional PIML, physical information is typically incorporated by constructing a hybrid loss function that combines data-driven loss and physics loss through linear scalarization. The goal is to find a trade-off between these two objectives to improve the accuracy of model predictions. However, from a mathematical perspective, linear scalarization is limited to identifying only the convex region of the Pareto front, as it treats data-driven and physics losses as separate objectives. Given that most PIML loss functions are non-convex, linear scalarization restricts the achievable trade-off solutions. Moreover, tuning the weighting coefficients for the two loss components can be both time-consuming and computationally challenging. To address these limitations, this paper introduces a paradigm shift in PIML by reformulating the training process as a multi-objective optimization problem, treating data-driven loss and physics loss independently. We apply several multi-gradient descent algorithms (MGDAs), including traditional multi-gradient descent (TMGD) and dual cone gradient descent (DCGD), to explore the Pareto front in this multi-objective setting. These methods are evaluated on both macroscopic and microscopic traffic flow models. In the macroscopic case, MGDAs achieved comparable performance to traditional linear scalarization methods. Notably, in the microscopic case, MGDAs significantly outperformed their scalarization-based counterparts, demonstrating the advantages of a multi-objective optimization approach in complex PIML scenarios.","authors":["Yuan-Zheng Lei","Yaobang Gong","Dianwei Chen","Yao Cheng","Xianfeng Terry Yang"],"url":"https://arxiv.org/abs/2505.13241"}
{"created":"2025-05-20","title":"JNLP at SemEval-2025 Task 11: Cross-Lingual Multi-Label Emotion Detection Using Generative Models","abstract":"With the rapid advancement of global digitalization, users from different countries increasingly rely on social media for information exchange. In this context, multilingual multi-label emotion detection has emerged as a critical research area. This study addresses SemEval-2025 Task 11: Bridging the Gap in Text-Based Emotion Detection. Our paper focuses on two sub-tracks of this task: (1) Track A: Multi-label emotion detection, and (2) Track B: Emotion intensity. To tackle multilingual challenges, we leverage pre-trained multilingual models and focus on two architectures: (1) a fine-tuned BERT-based classification model and (2) an instruction-tuned generative LLM. Additionally, we propose two methods for handling multi-label classification: the base method, which maps an input directly to all its corresponding emotion labels, and the pairwise method, which models the relationship between the input text and each emotion category individually. Experimental results demonstrate the strong generalization ability of our approach in multilingual emotion recognition. In Track A, our method achieved Top 4 performance across 10 languages, ranking 1st in Hindi. In Track B, our approach also secured Top 5 performance in 7 languages, highlighting its simplicity and effectiveness\\footnote{Our code is available at https://github.com/yingjie7/mlingual_multilabel_emo_detection.","authors":["Jieying Xue","Phuong Minh Nguyen","Minh Le Nguyen","Xin Liu"],"url":"https://arxiv.org/abs/2505.13244"}
{"created":"2025-05-20","title":"Agentic Publications: An LLM-Driven Framework for Interactive Scientific Publishing, Supplementing Traditional Papers with AI-Powered Knowledge Systems","abstract":"The exponential growth of scientific literature presents significant challenges for researchers navigating the complex knowledge landscape. We propose \"Agentic Publications\", a novel LLM-driven framework complementing traditional publishing by transforming papers into interactive knowledge systems. Our architecture integrates structured data with unstructured content through retrieval-augmented generation and multi-agent verification. The framework offers interfaces for both humans and machines, combining narrative explanations with machine-readable outputs while addressing ethical considerations through automated validation and transparent governance. Key features include continuous knowledge updates, automatic integration of new findings, and customizable detail levels. Our proof-of-concept demonstrates multilingual interaction, API accessibility, and structured knowledge representation through vector databases, knowledge graphs, and verification agents. This approach enhances scientific communication across disciplines, improving efficiency and collaboration while preserving traditional publishing pathways, particularly valuable for interdisciplinary fields where knowledge integration remains challenging.","authors":["Roberto Pugliese","George Kourousias","Francesco Venier","Grazia Garlatti Costa"],"url":"https://arxiv.org/abs/2505.13246"}
{"created":"2025-05-20","title":"RN-F: A Novel Approach for Mitigating Contaminated Data in Large Language Models","abstract":"Large Language Models (LLMs) have become foundational in modern artificial intelligence, powering a wide range of applications from code generation and virtual assistants to scientific research and enterprise automation. However, concerns about data contamination--where test data overlaps with training data--have raised serious questions about the reliability of these applications. Despite awareness of this issue, existing methods fall short in effectively identifying or mitigating contamination. In this paper, we propose Residual-Noise Fingerprinting (RN-F), a novel framework for detecting contaminated data in LLMs. RN-F is a single-pass, gradient-free detection method that leverages residual signal patterns without introducing additional floating-point operations. Our approach is lightweight, model-agnostic, and efficient. We evaluate RN-F on multiple LLMs across various contaminated datasets and show that it consistently outperforms existing state-of-the-art methods, achieving performance improvements of up to 10.5% in contamination detection metrics.","authors":["Le Vu Anh","Dinh Duc Nha Nguyen","Phi Long Nguyen"],"url":"https://arxiv.org/abs/2505.13249"}
{"created":"2025-05-20","title":"Joint Depth and Reflectivity Estimation using Single-Photon LiDAR","abstract":"Single-Photon Light Detection and Ranging (SP-LiDAR is emerging as a leading technology for long-range, high-precision 3D vision tasks. In SP-LiDAR, timestamps encode two complementary pieces of information: pulse travel time (depth) and the number of photons reflected by the object (reflectivity). Existing SP-LiDAR reconstruction methods typically recover depth and reflectivity separately or sequentially use one modality to estimate the other. Moreover, the conventional 3D histogram construction is effective mainly for slow-moving or stationary scenes. In dynamic scenes, however, it is more efficient and effective to directly process the timestamps. In this paper, we introduce an estimation method to simultaneously recover both depth and reflectivity in fast-moving scenes. We offer two contributions: (1) A theoretical analysis demonstrating the mutual correlation between depth and reflectivity and the conditions under which joint estimation becomes beneficial. (2) A novel reconstruction method, \"SPLiDER\", which exploits the shared information to enhance signal recovery. On both synthetic and real SP-LiDAR data, our method outperforms existing approaches, achieving superior joint reconstruction quality.","authors":["Hashan K. Weerasooriya","Prateek Chennuri","Weijian Zhang","Istvan Gyongy","Stanley H. Chan"],"url":"https://arxiv.org/abs/2505.13250"}
{"created":"2025-05-20","title":"Stronger Together: Unleashing the Social Impact of Hate Speech Research","abstract":"The advent of the internet has been both a blessing and a curse for once marginalised communities. When used well, the internet can be used to connect and establish communities crossing different intersections; however, it can also be used as a tool to alienate people and communities as well as perpetuate hate, misinformation, and disinformation especially on social media platforms. We propose steering hate speech research and researchers away from pre-existing computational solutions and consider social methods to inform social solutions to address this social problem. In a similar way linguistics research can inform language planning policy, linguists should apply what we know about language and society to mitigate some of the emergent risks and dangers of anti-social behaviour in digital spaces. We argue linguists and NLP researchers can play a principle role in unleashing the social impact potential of linguistics research working alongside communities, advocates, activists, and policymakers to enable equitable digital inclusion and to close the digital divide.","authors":["Sidney Wong"],"url":"https://arxiv.org/abs/2505.13251"}
{"created":"2025-05-20","title":"Natural Language Planning via Coding and Inference Scaling","abstract":"Real-life textual planning tasks such as meeting scheduling have posed much challenge to LLMs especially when the complexity is high. While previous work primarily studied auto-regressive generation of plans with closed-source models, we systematically evaluate both closed- and open-source models, including those that scales output length with complexity during inference, in generating programs, which are executed to output the plan. We consider not only standard Python code, but also the code to a constraint satisfaction problem solver. Despite the algorithmic nature of the task, we show that programming often but not always outperforms planning. Our detailed error analysis also indicates a lack of robustness and efficiency in the generated code that hinders generalization.","authors":["Rikhil Amonkar","Ronan Le Bras","Li Zhang"],"url":"https://arxiv.org/abs/2505.13252"}
{"created":"2025-05-20","title":"Composing Dextrous Grasping and In-hand Manipulation via Scoring with a Reinforcement Learning Critic","abstract":"In-hand manipulation and grasping are fundamental yet often separately addressed tasks in robotics. For deriving in-hand manipulation policies, reinforcement learning has recently shown great success. However, the derived controllers are not yet useful in real-world scenarios because they often require a human operator to place the objects in suitable initial (grasping) states. Finding stable grasps that also promote the desired in-hand manipulation goal is an open problem. In this work, we propose a method for bridging this gap by leveraging the critic network of a reinforcement learning agent trained for in-hand manipulation to score and select initial grasps. Our experiments show that this method significantly increases the success rate of in-hand manipulation without requiring additional training. We also present an implementation of a full grasp manipulation pipeline on a real-world system, enabling autonomous grasping and reorientation even of unwieldy objects.","authors":["Lennart R\\\"ostel","Dominik Winkelbauer","Johannes Pitz","Leon Sievers","Berthold B\\\"auml"],"url":"https://arxiv.org/abs/2505.13253"}
{"created":"2025-05-20","title":"HeteroSpec: Leveraging Contextual Heterogeneity for Efficient Speculative Decoding","abstract":"Autoregressive decoding, the standard approach for Large Language Model (LLM) inference, remains a significant bottleneck due to its sequential nature. While speculative decoding algorithms mitigate this inefficiency through parallel verification, they fail to exploit the inherent heterogeneity in linguistic complexity, a key factor leading to suboptimal resource allocation. We address this by proposing HeteroSpec, a heterogeneity-adaptive speculative decoding framework that dynamically optimizes computational resource allocation based on linguistic context complexity. HeteroSpec introduces two key mechanisms: (1) A novel cumulative meta-path Top-$K$ entropy metric for efficiently identifying predictable contexts. (2) A dynamic resource allocation strategy based on data-driven entropy partitioning, enabling adaptive speculative expansion and pruning tailored to local context difficulty. Evaluated on five public benchmarks and four models, HeteroSpec achieves an average speedup of 4.26$\\times$. It consistently outperforms state-of-the-art EAGLE-3 across speedup rates, average acceptance length, and verification cost. Notably, HeteroSpec requires no draft model retraining, incurs minimal overhead, and is orthogonal to other acceleration techniques. It demonstrates enhanced acceleration with stronger draft models, establishing a new paradigm for context-aware LLM inference acceleration.","authors":["Siran Liu","Yang Ye","Qianchao Zhu","Zheng Cao","Yongchao He"],"url":"https://arxiv.org/abs/2505.13254"}
{"created":"2025-05-20","title":"Policy Contrastive Decoding for Robotic Foundation Models","abstract":"Robotic foundation models, or generalist robot policies, hold immense potential to enable flexible, general-purpose and dexterous robotic systems. Despite their advancements, our empirical experiments reveal that existing robot policies are prone to learning spurious correlations from pre-training trajectories, adversely affecting their generalization capabilities beyond the training data. To tackle this, we propose a novel Policy Contrastive Decoding (PCD) approach, which redirects the robot policy's focus toward object-relevant visual clues by contrasting action probability distributions derived from original and object-masked visual inputs. As a training-free method, our PCD can be used as a plugin to improve different types of robot policies without needing to finetune or access model weights. We conduct extensive experiments on top of three open-source robot policies, including the autoregressive policy OpenVLA and the diffusion-based policies Octo and $\\pi_0$. The obtained results in both simulation and real-world environments prove PCD's flexibility and effectiveness, e.g., PCD enhances the state-of-the-art policy $\\pi_0$ by 8% in the simulation environment and by 108% in the real-world environment. Code and demos are publicly available at: https://Koorye.github.io/proj/PCD.","authors":["Shihan Wu","Ji Zhang","Xu Luo","Junlin Xie","Jingkuan Song","Heng Tao Shen","Lianli Gao"],"url":"https://arxiv.org/abs/2505.13255"}
{"created":"2025-05-20","title":"WikiPersonas: What Can We Learn From Personalized Alignment to Famous People?","abstract":"Preference alignment has become a standard pipeline in finetuning models to follow \\emph{generic} human preferences. Majority of work seeks to optimize model to produce responses that would be preferable \\emph{on average}, simplifying the diverse and often \\emph{contradicting} space of human preferences. While research has increasingly focused on personalized alignment: adapting models to individual user preferences, there is a lack of personalized preference dataset which focus on nuanced individual-level preferences. To address this, we introduce WikiPersona: the first fine-grained personalization using well-documented, famous individuals. Our dataset challenges models to align with these personas through an interpretable process: generating verifiable textual descriptions of a persona's background and preferences in addition to alignment. We systematically evaluate different personalization approaches and find that as few-shot prompting with preferences and fine-tuning fail to simultaneously ensure effectiveness and efficiency, using \\textit{inferred personal preferences} as prefixes enables effective personalization, especially in topics where preferences clash while leading to more equitable generalization across unseen personas.","authors":["Zilu Tang","Afra Feyza Aky\\\"urek","Ekin Aky\\\"urek","Derry Wijaya"],"url":"https://arxiv.org/abs/2505.13257"}
{"created":"2025-05-20","title":"Effective and Transparent RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability","abstract":"Retrieval-Augmented Generation (RAG) has significantly improved the performance of large language models (LLMs) on knowledge-intensive domains. However, although RAG achieved successes across distinct domains, there are still some unsolved challenges: 1) Effectiveness. Existing research mainly focuses on developing more powerful RAG retrievers, but how to enhance the generator's (LLM's) ability to utilize the retrieved information for reasoning and generation? 2) Transparency. Most RAG methods ignore which retrieved content actually contributes to the reasoning process, resulting in a lack of interpretability and visibility. To address this, we propose ARENA (Adaptive-Rewarded Evidence Navigation Agent), a transparent RAG generator framework trained via reinforcement learning (RL) with our proposed rewards. Based on the structured generation and adaptive reward calculation, our RL-based training enables the model to identify key evidence, perform structured reasoning, and generate answers with interpretable decision traces. Applied to Qwen2.5-7B-Instruct and Llama3.1-8B-Instruct, abundant experiments with various RAG baselines demonstrate that our model achieves 10-30% improvements on all multi-hop QA datasets, which is comparable with the SOTA Commercially-developed LLMs (e.g., OpenAI-o1, DeepSeek-R1). Further analyses show that ARENA has strong flexibility to be adopted on new datasets without extra training. Our models and codes are publicly released.","authors":["Jingyi Ren","Yekun Xu","Xiaolong Wang","Weitao Li","Weizhi Ma","Yang Liu"],"url":"https://arxiv.org/abs/2505.13258"}
{"created":"2025-05-20","title":"From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery","abstract":"Large Language Models (LLMs) are catalyzing a paradigm shift in scientific discovery, evolving from task-specific automation tools into increasingly autonomous agents and fundamentally redefining research processes and human-AI collaboration. This survey systematically charts this burgeoning field, placing a central focus on the changing roles and escalating capabilities of LLMs in science. Through the lens of the scientific method, we introduce a foundational three-level taxonomy-Tool, Analyst, and Scientist-to delineate their escalating autonomy and evolving responsibilities within the research lifecycle. We further identify pivotal challenges and future research trajectories such as robotic automation, self-improvement, and ethical governance. Overall, this survey provides a conceptual architecture and strategic foresight to navigate and shape the future of AI-driven scientific discovery, fostering both rapid innovation and responsible advancement. Github Repository: https://github.com/HKUST-KnowComp/Awesome-LLM-Scientific-Discovery.","authors":["Tianshi Zheng","Zheye Deng","Hong Ting Tsang","Weiqi Wang","Jiaxin Bai","Zihao Wang","Yangqiu Song"],"url":"https://arxiv.org/abs/2505.13259"}
{"created":"2025-05-20","title":"Unlocking the Potential of Difficulty Prior in RL-based Multimodal Reasoning","abstract":"In this work, we investigate how explicitly modeling problem's difficulty prior information shapes the effectiveness of reinforcement learning based fine-tuning for multimodal reasoning. Our exploration mainly comprises of following three perspective: First, through offline data curation, we analyze the U-shaped difficulty distribution of two given datasets using the base model by multi-round sampling, and then filter out prompts that are either too simple or extremely difficult to provide meaningful gradients and perform subsequent two-stage training. Second, we implement an online advantage differentiation, computing group-wise empirical accuracy as a difficulty proxy to adaptively reweight advantages estimation, providing stronger learning signals for more challenging problems. Finally, we introduce difficulty hints as explicit prompts for more complex samples in the second training stage, encouraging the model to calibrate its reasoning depth and perform reflective validation checks. Our comprehensive approach demonstrates significant performances across various multi-modal mathematical reasoning benchmarks with only 2K+0.6K two-stage training data.","authors":["Mingrui Chen","Haogeng Liu","Hao Liang","Huaibo Huang","Wentao Zhang","Ran He"],"url":"https://arxiv.org/abs/2505.13261"}
{"created":"2025-05-20","title":"Are requirements really all you need? A case study of LLM-driven configuration code generation for automotive simulations","abstract":"Large Language Models (LLMs) are taking many industries by storm. They possess impressive reasoning capabilities and are capable of handling complex problems, as shown by their steadily improving scores on coding and mathematical benchmarks. However, are the models currently available truly capable of addressing real-world challenges, such as those found in the automotive industry? How well can they understand high-level, abstract instructions? Can they translate these instructions directly into functional code, or do they still need help and supervision? In this work, we put one of the current state-of-the-art models to the test. We evaluate its performance in the task of translating abstract requirements, extracted from automotive standards and documents, into configuration code for CARLA simulations.","authors":["Krzysztof Lebioda","Nenad Petrovic","Fengjunjie Pan","Vahid Zolfaghari","Andre Schamschurko","Alois Knoll"],"url":"https://arxiv.org/abs/2505.13263"}
{"created":"2025-05-20","title":"Net-Zero: A Comparative Study on Neural Network Design for Climate-Economic PDEs Under Uncertainty","abstract":"Climate-economic modeling under uncertainty presents significant computational challenges that may limit policymakers' ability to address climate change effectively. This paper explores neural network-based approaches for solving high-dimensional optimal control problems arising from models that incorporate ambiguity aversion in climate mitigation decisions. We develop a continuous-time endogenous-growth economic model that accounts for multiple mitigation pathways, including emission-free capital and carbon intensity reductions. Given the inherent complexity and high dimensionality of these models, traditional numerical methods become computationally intractable. We benchmark several neural network architectures against finite-difference generated solutions, evaluating their ability to capture the dynamic interactions between uncertainty, technology transitions, and optimal climate policy. Our findings demonstrate that appropriate neural architecture selection significantly impacts both solution accuracy and computational efficiency when modeling climate-economic systems under uncertainty. These methodological advances enable more sophisticated modeling of climate policy decisions, allowing for better representation of technology transitions and uncertainty-critical elements for developing effective mitigation strategies in the face of climate change.","authors":["Carlos Rodriguez-Pardo","Louis Daumas","Leonardo Chiani","Massimo Tavoni"],"url":"https://arxiv.org/abs/2505.13264"}
{"created":"2025-05-20","title":"DB3D-L: Depth-aware BEV Feature Transformation for Accurate 3D Lane Detection","abstract":"3D Lane detection plays an important role in autonomous driving. Recent advances primarily build Birds-Eye-View (BEV) feature from front-view (FV) images to perceive 3D information of Lane more effectively. However, constructing accurate BEV information from FV image is limited due to the lacking of depth information, causing previous works often rely heavily on the assumption of a flat ground plane. Leveraging monocular depth estimation to assist in constructing BEV features is less constrained, but existing methods struggle to effectively integrate the two tasks. To address the above issue, in this paper, an accurate 3D lane detection method based on depth-aware BEV feature transtormation is proposed. In detail, an effective feature extraction module is designed, in which a Depth Net is integrated to obtain the vital depth information for 3D perception, thereby simplifying the complexity of view transformation. Subquently a feature reduce module is proposed to reduce height dimension of FV features and depth features, thereby enables effective fusion of crucial FV features and depth features. Then a fusion module is designed to build BEV feature from prime FV feature and depth information. The proposed method performs comparably with state-of-the-art methods on both synthetic Apollo, realistic OpenLane datasets.","authors":["Yehao Liu","Xiaosu Xu","Zijian Wang","Yiqing Yao"],"url":"https://arxiv.org/abs/2505.13266"}
{"created":"2025-05-20","title":"Representation of perceived prosodic similarity of conversational feedback","abstract":"Vocal feedback (e.g., `mhm', `yeah', `okay') is an important component of spoken dialogue and is crucial to ensuring common ground in conversational systems. The exact meaning of such feedback is conveyed through both lexical and prosodic form. In this work, we investigate the perceived prosodic similarity of vocal feedback with the same lexical form, and to what extent existing speech representations reflect such similarities. A triadic comparison task with recruited participants is used to measure perceived similarity of feedback responses taken from two different datasets. We find that spectral and self-supervised speech representations encode prosody better than extracted pitch features, especially in the case of feedback from the same speaker. We also find that it is possible to further condense and align the representations to human perception through contrastive learning.","authors":["Livia Qian","Carol Figueroa","Gabriel Skantze"],"url":"https://arxiv.org/abs/2505.13268"}
{"created":"2025-05-20","title":"Distilling a speech and music encoder with task arithmetic","abstract":"Despite the progress in self-supervised learning (SSL) for speech and music, existing models treat these domains separately, limiting their capacity for unified audio understanding. A unified model is desirable for applications that require general representations, e.g. audio large language models. Nonetheless, directly training a general model for speech and music is computationally expensive. Knowledge Distillation of teacher ensembles may be a natural solution, but we posit that decoupling the distillation of the speech and music SSL models allows for more flexibility. Thus, we propose to learn distilled task vectors and then linearly interpolate them to form a unified speech+music model. This strategy enables flexible domain emphasis through adjustable weights and is also simpler to train. Experiments on speech and music benchmarks demonstrate that our method yields superior overall performance compared to ensemble distillation.","authors":["Fabian Ritter-Gutierrez","Yi-Cheng Lin","Jui-Chiang Wei","Jeremy H. M Wong","Eng Siong Chng","Nancy F. Chen","Hung-yi Lee"],"url":"https://arxiv.org/abs/2505.13270"}
{"created":"2025-05-20","title":"CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning","abstract":"Large language models (LLMs) have demonstrated strong capabilities in translating natural language questions about relational databases into SQL queries. In particular, test-time scaling techniques such as Self-Consistency and Self-Correction can enhance SQL generation accuracy by increasing computational effort during inference. However, these methods have notable limitations: Self-Consistency may select suboptimal outputs despite majority votes, while Self-Correction typically addresses only syntactic errors. To leverage the strengths of both approaches, we propose CSC-SQL, a novel method that integrates Self-Consistency and Self-Correction. CSC-SQL selects the two most frequently occurring outputs from parallel sampling and feeds them into a merge revision model for correction. Additionally, we employ the Group Relative Policy Optimization (GRPO) algorithm to fine-tune both the SQL generation and revision models via reinforcement learning, significantly enhancing output quality. Experimental results confirm the effectiveness and generalizability of CSC-SQL. On the BIRD development set, our 3B model achieves 65.28% execution accuracy, while the 7B model achieves 69.19%. The code will be open sourced at https://github.com/CycloneBoy/csc_sql.","authors":["Lei Sheng","Shuai-Shuai Xu"],"url":"https://arxiv.org/abs/2505.13271"}
{"created":"2025-05-20","title":"Seeing the Unseen: How EMoE Unveils Bias in Text-to-Image Diffusion Models","abstract":"Estimating uncertainty in text-to-image diffusion models is challenging because of their large parameter counts (often exceeding 100 million) and operation in complex, high-dimensional spaces with virtually infinite input possibilities. In this paper, we propose Epistemic Mixture of Experts (EMoE), a novel framework for efficiently estimating epistemic uncertainty in diffusion models. EMoE leverages pre-trained networks without requiring additional training, enabling direct uncertainty estimation from a prompt. We leverage a latent space within the diffusion process that captures epistemic uncertainty better than existing methods. Experimental results on the COCO dataset demonstrate EMoE's effectiveness, showing a strong correlation between uncertainty and image quality. Additionally, EMoE identifies under-sampled languages and regions with higher uncertainty, revealing hidden biases in the training set. This capability demonstrates the relevance of EMoE as a tool for addressing fairness and accountability in AI-generated content.","authors":["Lucas Berry","Axel Brando","Wei-Di Chang","Juan Camilo Gamboa Higuera","David Meger"],"url":"https://arxiv.org/abs/2505.13273"}
{"created":"2025-05-20","title":"Neural Functional: Learning Function to Scalar Maps for Neural PDE Surrogates","abstract":"Many architectures for neural PDE surrogates have been proposed in recent years, largely based on neural networks or operator learning. In this work, we derive and propose a new architecture, the Neural Functional, which learns function to scalar mappings. Its implementation leverages insights from operator learning and neural fields, and we show the ability of neural functionals to implicitly learn functional derivatives. For the first time, this allows for an extension of Hamiltonian mechanics to neural PDE surrogates by learning the Hamiltonian functional and optimizing its functional derivatives. We demonstrate that the Hamiltonian Neural Functional can be an effective surrogate model through improved stability and conserving energy-like quantities on 1D and 2D PDEs. Beyond PDEs, functionals are prevalent in physics; functional approximation and learning with its gradients may find other uses, such as in molecular dynamics or design optimization.","authors":["Anthony Zhou","Amir Barati Farimani"],"url":"https://arxiv.org/abs/2505.13275"}
{"created":"2025-05-20","title":"CHAD-KG: A Knowledge Graph for Representing Cultural Heritage Objects and Digitisation Paradata","abstract":"This paper presents CHAD-KG, a knowledge graph designed to describe bibliographic metadata and digitisation paradata of cultural heritage objects in exhibitions, museums, and collections. It also documents the related data model and materialisation engine. Originally based on two tabular datasets, the data was converted into RDF according to CHAD-AP, an OWL application profile built on standards like CIDOC-CRM, LRMoo, CRMdig, and Getty AAT. A reproducible pipeline, developed with a Morph-KGC extension, was used to generate the graph. CHAD-KG now serves as the main metadata source for the Digital Twin of the temporary exhibition titled \\emph{The Other Renaissance - Ulisse Aldrovandi and The Wonders Of The World}, and other collections related to the digitisation work under development in a nationwide funded project, i.e. Project CHANGES (https://fondazionechanges.org). To ensure accessibility and reuse, it offers a SPARQL endpoint, a user interface, open documentation, and is published on Zenodo under a CC0 license. The project improves the semantic interoperability of cultural heritage data, with future work aiming to extend the data model and materialisation pipeline to better capture the complexities of acquisition and digitisation, further enrich the dataset and broaden its relevance to similar initiatives.","authors":["Sebastian Barzaghi","Arianna Moretti","Ivan Heibi","Silvio Peroni"],"url":"https://arxiv.org/abs/2505.13276"}
{"created":"2025-05-20","title":"Low-regret Strategies for Energy Systems Planning in a Highly Uncertain Future","abstract":"Large uncertainties in the energy transition urge decision-makers to develop low-regret strategies, i.e., strategies that perform well regardless of how the future unfolds. To address this challenge, we introduce a decision-support framework that identifies low-regret strategies in energy system planning under uncertainty. Our framework (i) automatically identifies strategies, (ii) evaluates their performance in terms of regret, (iii) assesses the key drivers of regret, and (iv) supports the decision process with intuitive decision trees, regret curves and decision maps. We apply the framework to evaluate the optimal use of biomass in the transition to net-zero energy systems, considering all major biomass utilization options: biofuels, biomethane, chemicals, hydrogen, biochar, electricity, and heat. Producing fuels and chemicals from biomass performs best across various decision-making criteria. In contrast, the current use of biomass, mainly for low-temperature heat supply, results in high regret, making it a must-avoid in the energy transition.","authors":["Gabriel Wiest","Niklas Nolzen","Florian Baader","Andr\\'e Bardow","Stefano Moret"],"url":"https://arxiv.org/abs/2505.13277"}
{"created":"2025-05-20","title":"Hybrid Voting-Based Task Assignment in Modular Construction Scenarios","abstract":"Modular construction, involving off-site prefabrication and on-site assembly, offers significant advantages but presents complex coordination challenges for robotic automation. Effective task allocation is critical for leveraging multi-agent systems (MAS) in these structured environments. This paper introduces the Hybrid Voting-Based Task Assignment (HVBTA) framework, a novel approach to optimizing collaboration between heterogeneous multi-agent construction teams. Inspired by human reasoning in task delegation, HVBTA uniquely integrates multiple voting mechanisms with the capabilities of a Large Language Model (LLM) for nuanced suitability assessment between agent capabilities and task requirements. The framework operates by assigning Capability Profiles to agents and detailed requirement lists called Task Descriptions to construction tasks, subsequently generating a quantitative Suitability Matrix. Six distinct voting methods, augmented by a pre-trained LLM, analyze this matrix to robustly identify the optimal agent for each task. Conflict-Based Search (CBS) is integrated for decentralized, collision-free path planning, ensuring efficient and safe spatio-temporal coordination of the robotic team during assembly operations. HVBTA enables efficient, conflict-free assignment and coordination, facilitating potentially faster and more accurate modular assembly. Current work is evaluating HVBTA's performance across various simulated construction scenarios involving diverse robotic platforms and task complexities. While designed as a generalizable framework for any domain with clearly definable tasks and capabilities, HVBTA will be particularly effective for addressing the demanding coordination requirements of multi-agent collaborative robotics in modular construction due to the predetermined construction planning involved.","authors":["Daniel Weiner","Raj Korpan"],"url":"https://arxiv.org/abs/2505.13278"}
{"created":"2025-05-20","title":"Event-Driven Dynamic Scene Depth Completion","abstract":"Depth completion in dynamic scenes poses significant challenges due to rapid ego-motion and object motion, which can severely degrade the quality of input modalities such as RGB images and LiDAR measurements. Conventional RGB-D sensors often struggle to align precisely and capture reliable depth under such conditions. In contrast, event cameras with their high temporal resolution and sensitivity to motion at the pixel level provide complementary cues that are %particularly beneficial in dynamic environments.To this end, we propose EventDC, the first event-driven depth completion framework. It consists of two key components: Event-Modulated Alignment (EMA) and Local Depth Filtering (LDF). Both modules adaptively learn the two fundamental components of convolution operations: offsets and weights conditioned on motion-sensitive event streams. In the encoder, EMA leverages events to modulate the sampling positions of RGB-D features to achieve pixel redistribution for improved alignment and fusion. In the decoder, LDF refines depth estimations around moving objects by learning motion-aware masks from events. Additionally, EventDC incorporates two loss terms to further benefit global alignment and enhance local depth recovery. Moreover, we establish the first benchmark for event-based depth completion comprising one real-world and two synthetic datasets to facilitate future research. Extensive experiments on this benchmark demonstrate the superiority of our EventDC.","authors":["Zhiqiang Yan","Jianhao Jiao","Zhengxue Wang","Gim Hee Lee"],"url":"https://arxiv.org/abs/2505.13279"}
{"created":"2025-05-20","title":"FlowPure: Continuous Normalizing Flows for Adversarial Purification","abstract":"Despite significant advancements in the area, adversarial robustness remains a critical challenge in systems employing machine learning models. The removal of adversarial perturbations at inference time, known as adversarial purification, has emerged as a promising defense strategy. To achieve this, state-of-the-art methods leverage diffusion models that inject Gaussian noise during a forward process to dilute adversarial perturbations, followed by a denoising step to restore clean samples before classification. In this work, we propose FlowPure, a novel purification method based on Continuous Normalizing Flows (CNFs) trained with Conditional Flow Matching (CFM) to learn mappings from adversarial examples to their clean counterparts. Unlike prior diffusion-based approaches that rely on fixed noise processes, FlowPure can leverage specific attack knowledge to improve robustness under known threats, while also supporting a more general stochastic variant trained on Gaussian perturbations for settings where such knowledge is unavailable. Experiments on CIFAR-10 and CIFAR-100 demonstrate that our method outperforms state-of-the-art purification-based defenses in preprocessor-blind and white-box scenarios, and can do so while fully preserving benign accuracy in the former. Moreover, our results show that not only is FlowPure a highly effective purifier but it also holds a strong potential for adversarial detection, identifying preprocessor-blind PGD samples with near-perfect accuracy.","authors":["Elias Collaert","Abel Rodr\\'iguez","Sander Joos","Lieven Desmet","Vera Rimmer"],"url":"https://arxiv.org/abs/2505.13280"}
{"created":"2025-05-20","title":"Computer Vision Models Show Human-Like Sensitivity to Geometric and Topological Concepts","abstract":"With the rapid improvement of machine learning (ML) models, cognitive scientists are increasingly asking about their alignment with how humans think. Here, we ask this question for computer vision models and human sensitivity to geometric and topological (GT) concepts. Under the core knowledge account, these concepts are innate and supported by dedicated neural circuitry. In this work, we investigate an alternative explanation, that GT concepts are learned ``for free'' through everyday interaction with the environment. We do so using computer visions models, which are trained on large image datasets. We build on prior studies to investigate the overall performance and human alignment of three classes of models -- convolutional neural networks (CNNs), transformer-based models, and vision-language models -- on an odd-one-out task testing 43 GT concepts spanning seven classes. Transformer-based models achieve the highest overall accuracy, surpassing that of young children. They also show strong alignment with children's performance, finding the same classes of concepts easy vs. difficult. By contrast, vision-language models underperform their vision-only counterparts and deviate further from human profiles, indicating that na\\\"ive multimodality might compromise abstract geometric sensitivity. These findings support the use of computer vision models to evaluate the sufficiency of the learning account for explaining human sensitivity to GT concepts, while also suggesting that integrating linguistic and visual representations might have unpredicted deleterious consequences.","authors":["Zekun Wang","Sashank Varma"],"url":"https://arxiv.org/abs/2505.13281"}
{"created":"2025-05-20","title":"$\\textit{Rank, Chunk and Expand}$: Lineage-Oriented Reasoning for Taxonomy Expansion","abstract":"Taxonomies are hierarchical knowledge graphs crucial for recommendation systems, and web applications. As data grows, expanding taxonomies is essential, but existing methods face key challenges: (1) discriminative models struggle with representation limits and generalization, while (2) generative methods either process all candidates at once, introducing noise and exceeding context limits, or discard relevant entities by selecting noisy candidates. We propose LORex ($\\textbf{L}$ineage-$\\textbf{O}$riented $\\textbf{Re}$asoning for Taxonomy E$\\textbf{x}$pansion), a plug-and-play framework that combines discriminative ranking and generative reasoning for efficient taxonomy expansion. Unlike prior methods, LORex ranks and chunks candidate terms into batches, filtering noise and iteratively refining selections by reasoning candidates' hierarchy to ensure contextual efficiency. Extensive experiments across four benchmarks and twelve baselines show that LORex improves accuracy by 12% and Wu & Palmer similarity by 5% over state-of-the-art methods.","authors":["Sahil Mishra","Kumar Arjun","Tanmoy Chakraborty"],"url":"https://arxiv.org/abs/2505.13282"}
{"created":"2025-05-20","title":"Intuitionistic BV (Extended version)","abstract":"We present the logic IBV, which is an intuitionistic version of BV, in the sense that its restriction to the MLL connectives is exactly IMLL, the intuitionistic version of MLL. For this logic we give a deep inference proof system and show cut elimination. We also show that the logic obtained from IBV by dropping the associativity of the new non-commutative seq-connective is an intuitionistic variant of the recently introduced logic NML. For this logic, called INML, we give a cut-free sequent calculus.","authors":["Matteo Acclavio","Lutz Strassburger"],"url":"https://arxiv.org/abs/2505.13284"}
{"created":"2025-05-20","title":"Level Generation with Quantum Reservoir Computing","abstract":"Reservoir computing is a form of machine learning particularly suited for time series analysis, including forecasting predictions. We take an implementation of \\emph{quantum} reservoir computing that was initially designed to generate variants of musical scores and adapt it to create levels of Super Mario Bros. Motivated by our analysis of these levels, we develop a new Roblox \\textit{obby} where the courses can be generated in real time on superconducting qubit hardware, and investigate some of the constraints placed by such real-time generation.","authors":["Jo\\~ao S. Ferreira","Pierre Fromholz","Hari Shaji","James R. Wootton"],"url":"https://arxiv.org/abs/2505.13287"}
{"created":"2025-05-20","title":"RECON: Robust symmetry discovery via Explicit Canonical Orientation Normalization","abstract":"Real-world data often exhibits unknown or approximate symmetries, yet existing equivariant networks must commit to a fixed transformation group prior to training, e.g., continuous $SO(2)$ rotations. This mismatch degrades performance when the actual data symmetries differ from those in the transformation group. We introduce RECON, a framework to discover each input's intrinsic symmetry distribution from unlabeled data. RECON leverages class-pose decompositions and applies a data-driven normalization to align arbitrary reference frames into a common natural pose, yielding directly comparable and interpretable symmetry descriptors. We demonstrate effective symmetry discovery on 2D image benchmarks and -- for the first time -- extend it to 3D transformation groups, paving the way towards more flexible equivariant modeling.","authors":["Alonso Urbano","David W. Romero","Max Zimmer","Sebastian Pokutta"],"url":"https://arxiv.org/abs/2505.13289"}
{"created":"2025-05-20","title":"TimeSeriesGym: A Scalable Benchmark for (Time Series) Machine Learning Engineering Agents","abstract":"We introduce TimeSeriesGym, a scalable benchmarking framework for evaluating Artificial Intelligence (AI) agents on time series machine learning engineering challenges. Existing benchmarks lack scalability, focus narrowly on model building in well-defined settings, and evaluate only a limited set of research artifacts (e.g., CSV submission files). To make AI agent benchmarking more relevant to the practice of machine learning engineering, our framework scales along two critical dimensions. First, recognizing that effective ML engineering requires a range of diverse skills, TimeSeriesGym incorporates challenges from diverse sources spanning multiple domains and tasks. We design challenges to evaluate both isolated capabilities (including data handling, understanding research repositories, and code translation) and their combinations, and rather than addressing each challenge independently, we develop tools that support designing multiple challenges at scale. Second, we implement evaluation mechanisms for multiple research artifacts, including submission files, code, and models, using both precise numeric measures and more flexible LLM-based evaluation approaches. This dual strategy balances objective assessment with contextual judgment. Although our initial focus is on time series applications, our framework can be readily extended to other data modalities, broadly enhancing the comprehensiveness and practical utility of agentic AI evaluation. We open-source our benchmarking framework to facilitate future research on the ML engineering capabilities of AI agents.","authors":["Yifu Cai","Xinyu Li","Mononito Goswami","Micha{\\l} Wili\\'nski","Gus Welter","Artur Dubrawski"],"url":"https://arxiv.org/abs/2505.13291"}
{"created":"2025-05-20","title":"Cross-Cloud Data Privacy Protection: Optimizing Collaborative Mechanisms of AI Systems by Integrating Federated Learning and LLMs","abstract":"In the age of cloud computing, data privacy protection has become a major challenge, especially when sharing sensitive data across cloud environments. However, how to optimize collaboration across cloud environments remains an unresolved problem. In this paper, we combine federated learning with large-scale language models to optimize the collaborative mechanism of AI systems. Based on the existing federated learning framework, we introduce a cross-cloud architecture in which federated learning works by aggregating model updates from decentralized nodes without exposing the original data. At the same time, combined with large-scale language models, its powerful context and semantic understanding capabilities are used to improve model training efficiency and decision-making ability. We've further innovated by introducing a secure communication layer to ensure the privacy and integrity of model updates and training data. The model enables continuous model adaptation and fine-tuning across different cloud environments while protecting sensitive data. Experimental results show that the proposed method is significantly better than the traditional federated learning model in terms of accuracy, convergence speed and data privacy protection.","authors":["Huaiying Luo","Cheng Ji"],"url":"https://arxiv.org/abs/2505.13292"}
{"created":"2025-05-20","title":"Output behavior equivalence and simultaneous subspace identification of systems and faults","abstract":"We address the problem of identifying a system subject to additive faults, while simultaneously reconstructing the fault signal via subspace methods. We do not require nominal data for the identification, neither do we impose any assumption on the class of faults, e.g., sensor or actuator faults. We show that, under mild assumptions on the fault signal, standard PI-MOESP can recover the system matrices associated to the input-output subsystem. Then we introduce the concept of output behavior equivalence, which characterizes systems with the same output behavior set, and present a method to establish this equivalence from system matrices. Finally, we show how to estimate from data the complete set of fault matrices for which there exist a fault signal with minimal dimension that explains the data.","authors":["Gabriel de Albuquerque Gleizer"],"url":"https://arxiv.org/abs/2505.13294"}
{"created":"2025-05-20","title":"DD-Ranking: Rethinking the Evaluation of Dataset Distillation","abstract":"In recent years, dataset distillation has provided a reliable solution for data compression, where models trained on the resulting smaller synthetic datasets achieve performance comparable to those trained on the original datasets. To further improve the performance of synthetic datasets, various training pipelines and optimization objectives have been proposed, greatly advancing the field of dataset distillation. Recent decoupled dataset distillation methods introduce soft labels and stronger data augmentation during the post-evaluation phase and scale dataset distillation up to larger datasets (e.g., ImageNet-1K). However, this raises a question: Is accuracy still a reliable metric to fairly evaluate dataset distillation methods? Our empirical findings suggest that the performance improvements of these methods often stem from additional techniques rather than the inherent quality of the images themselves, with even randomly sampled images achieving superior results. Such misaligned evaluation settings severely hinder the development of DD. Therefore, we propose DD-Ranking, a unified evaluation framework, along with new general evaluation metrics to uncover the true performance improvements achieved by different methods. By refocusing on the actual information enhancement of distilled datasets, DD-Ranking provides a more comprehensive and fair evaluation standard for future research advancements.","authors":["Zekai Li","Xinhao Zhong","Samir Khaki","Zhiyuan Liang","Yuhao Zhou","Mingjia Shi","Ziqiao Wang","Xuanlei Zhao","Wangbo Zhao","Ziheng Qin","Mengxuan Wu","Pengfei Zhou","Haonan Wang","David Junhao Zhang","Jia-Wei Liu","Shaobo Wang","Dai Liu","Linfeng Zhang","Guang Li","Kun Wang","Zheng Zhu","Zhiheng Ma","Joey Tianyi Zhou","Jiancheng Lv","Yaochu Jin","Peihao Wang","Kaipeng Zhang","Lingjuan Lyu","Yiran Huang","Zeynep Akata","Zhiwei Deng","Xindi Wu","George Cazenavette","Yuzhang Shang","Justin Cui","Jindong Gu","Qian Zheng","Hao Ye","Shuo Wang","Xiaobo Wang","Yan Yan","Angela Yao","Mike Zheng Shou","Tianlong Chen","Hakan Bilen","Baharan Mirzasoleiman","Manolis Kellis","Konstantinos N. Plataniotis","Zhangyang Wang","Bo Zhao","Yang You","Kai Wang"],"url":"https://arxiv.org/abs/2505.13300"}
{"created":"2025-05-20","title":"I'll believe it when I see it: Images increase misinformation sharing in Vision-Language Models","abstract":"Large language models are increasingly integrated into news recommendation systems, raising concerns about their role in spreading misinformation. In humans, visual content is known to boost credibility and shareability of information, yet its effect on vision-language models (VLMs) remains unclear. We present the first study examining how images influence VLMs' propensity to reshare news content, whether this effect varies across model families, and how persona conditioning and content attributes modulate this behavior. To support this analysis, we introduce two methodological contributions: a jailbreaking-inspired prompting strategy that elicits resharing decisions from VLMs while simulating users with antisocial traits and political alignments; and a multimodal dataset of fact-checked political news from PolitiFact, paired with corresponding images and ground-truth veracity labels. Experiments across model families reveal that image presence increases resharing rates by 4.8% for true news and 15.0% for false news. Persona conditioning further modulates this effect: Dark Triad traits amplify resharing of false news, whereas Republican-aligned profiles exhibit reduced veracity sensitivity. Of all the tested models, only Claude-3-Haiku demonstrates robustness to visual misinformation. These findings highlight emerging risks in multimodal model behavior and motivate the development of tailored evaluation frameworks and mitigation strategies for personalized AI systems. Code and dataset are available at: https://github.com/3lis/misinfo_vlm","authors":["Alice Plebe","Timothy Douglas","Diana Riazi","R. Maria del Rio-Chanona"],"url":"https://arxiv.org/abs/2505.13302"}
{"created":"2025-05-20","title":"GMM-Based Comprehensive Feature Extraction and Relative Distance Preservation For Few-Shot Cross-Modal Retrieval","abstract":"Few-shot cross-modal retrieval focuses on learning cross-modal representations with limited training samples, enabling the model to handle unseen classes during inference. Unlike traditional cross-modal retrieval tasks, which assume that both training and testing data share the same class distribution, few-shot retrieval involves data with sparse representations across modalities. Existing methods often fail to adequately model the multi-peak distribution of few-shot cross-modal data, resulting in two main biases in the latent semantic space: intra-modal bias, where sparse samples fail to capture intra-class diversity, and inter-modal bias, where misalignments between image and text distributions exacerbate the semantic gap. These biases hinder retrieval accuracy. To address these issues, we propose a novel method, GCRDP, for few-shot cross-modal retrieval. This approach effectively captures the complex multi-peak distribution of data using a Gaussian Mixture Model (GMM) and incorporates a multi-positive sample contrastive learning mechanism for comprehensive feature modeling. Additionally, we introduce a new strategy for cross-modal semantic alignment, which constrains the relative distances between image and text feature distributions, thereby improving the accuracy of cross-modal representations. We validate our approach through extensive experiments on four benchmark datasets, demonstrating superior performance over six state-of-the-art methods.","authors":["Chengsong Sun","Weiping Li","Xiang Li","Yuankun Liu","Lianlei Shan"],"url":"https://arxiv.org/abs/2505.13306"}
{"created":"2025-05-20","title":"RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning","abstract":"Chain-of-Thought (CoT) reasoning has proven effective in enhancing large language models (LLMs) on complex tasks, spurring research into its underlying mechanisms. However, two primary challenges remain for real-world applications: (1) the lack of quantitative metrics and actionable guidelines for evaluating and optimizing measurable boundaries of CoT capability, and (2) the absence of methods to assess boundaries of unmeasurable CoT capability, such as multimodal perception. To address these gaps, we introduce the Reasoning Boundary Framework++ (RBF++). To tackle the first challenge, we define the reasoning boundary (RB) as the maximum limit of CoT performance. We also propose a combination law for RBs, enabling quantitative analysis and offering actionable guidance across various CoT tasks. For the second challenge, particularly in multimodal scenarios, we introduce a constant assumption, which replaces unmeasurable RBs with scenario-specific constants. Additionally, we propose the reasoning boundary division mechanism, which divides unmeasurable RBs into two sub-boundaries, facilitating the quantification and optimization of both unmeasurable domain knowledge and multimodal perception capabilities. Extensive experiments involving 38 models across 13 tasks validate the feasibility of our framework in cross-modal settings. Additionally, we evaluate 10 CoT strategies, offer insights into optimization and decay from two complementary perspectives, and expand evaluation benchmarks for measuring RBs in LLM reasoning. We hope this work advances the understanding of RBs and optimization strategies in LLMs. Code and data are available at https://github.com/LightChen233/reasoning-boundary.","authors":["Qiguang Chen","Libo Qin","Jinhao Liu","Yue Liao","Jiaqi Wang","Jingxuan Zhou","Wanxiang Che"],"url":"https://arxiv.org/abs/2505.13307"}
{"created":"2025-05-20","title":"Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space","abstract":"Reasoning ability, a core component of human intelligence, continues to pose a significant challenge for Large Language Models (LLMs) in the pursuit of AGI. Although model performance has improved under the training scaling law, significant challenges remain, particularly with respect to training algorithms, such as catastrophic forgetting, and the limited availability of novel training data. As an alternative, test-time scaling enhances reasoning performance by increasing test-time computation without parameter updating. Unlike prior methods in this paradigm focused on token space, we propose leveraging latent space for more effective reasoning and better adherence to the test-time scaling law. We introduce LatentSeek, a novel framework that enhances LLM reasoning through Test-Time Instance-level Adaptation (TTIA) within the model's latent space. Specifically, LatentSeek leverages policy gradient to iteratively update latent representations, guided by self-generated reward signals. LatentSeek is evaluated on a range of reasoning benchmarks, including GSM8K, MATH-500, and AIME2024, across multiple LLM architectures. Results show that LatentSeek consistently outperforms strong baselines, such as Chain-of-Thought prompting and fine-tuning-based methods. Furthermore, our analysis demonstrates that LatentSeek is highly efficient, typically converging within a few iterations for problems of average complexity, while also benefiting from additional iterations, thereby highlighting the potential of test-time scaling in the latent space. These findings position LatentSeek as a lightweight, scalable, and effective solution for enhancing the reasoning capabilities of LLMs.","authors":["Hengli Li","Chenxi Li","Tong Wu","Xuekai Zhu","Yuxuan Wang","Zhaoxin Yu","Eric Hanchen Jiang","Song-Chun Zhu","Zixia Jia","Ying Nian Wu","Zilong Zheng"],"url":"https://arxiv.org/abs/2505.13308"}
{"created":"2025-05-20","title":"eStonefish-scenes: A synthetically generated dataset for underwater event-based optical flow prediction tasks","abstract":"The combined use of event-based vision and Spiking Neural Networks (SNNs) is expected to significantly impact robotics, particularly in tasks like visual odometry and obstacle avoidance. While existing real-world event-based datasets for optical flow prediction, typically captured with Unmanned Aerial Vehicles (UAVs), offer valuable insights, they are limited in diversity, scalability, and are challenging to collect. Moreover, there is a notable lack of labelled datasets for underwater applications, which hinders the integration of event-based vision with Autonomous Underwater Vehicles (AUVs). To address this, synthetic datasets could provide a scalable solution while bridging the gap between simulation and reality. In this work, we introduce eStonefish-scenes, a synthetic event-based optical flow dataset based on the Stonefish simulator. Along with the dataset, we present a data generation pipeline that enables the creation of customizable underwater environments. This pipeline allows for simulating dynamic scenarios, such as biologically inspired schools of fish exhibiting realistic motion patterns, including obstacle avoidance and reactive navigation around corals. Additionally, we introduce a scene generator that can build realistic reef seabeds by randomly distributing coral across the terrain. To streamline data accessibility, we present eWiz, a comprehensive library designed for processing event-based data, offering tools for data loading, augmentation, visualization, encoding, and training data generation, along with loss functions and performance metrics.","authors":["Jad Mansour","Sebastian Realpe","Hayat Rajani","Michele Grimaldi","Rafael Garcia","Nuno Gracias"],"url":"https://arxiv.org/abs/2505.13309"}
{"created":"2025-05-20","title":"Frequency-Dependent Power Consumption Modeling of CMOS Transmitters for WNoC Architectures","abstract":"Wireless Network-on-Chip (WNoC) systems, which wirelessly interconnect the chips of a computing system, have been proposed as a complement to existing chip-to-chip wired links. However, their feasibility depends on the availability of custom-designed high-speed, tiny, ultra-efficient transceivers. This represents a challenge due to the tradeoffs between bandwidth, area, and energy efficiency that are found as frequency increases, which suggests that there is an optimal frequency region. To aid in the search for such an optimal design point, this paper presents a behavioral model that quantifies the expected power consumption of oscillators, mixers, and power amplifiers as a function of frequency. The model is built on extensive surveys of the respective sub-blocks, all based on experimental data. By putting together the models of the three sub-blocks, a comprehensive power model is obtained, which will aid in selecting the optimal operating frequency for WNoC systems.","authors":["Mohammad Shahmoradi","Korkut Kaan Tokg\\\"oz","Eduard Alarc\\'on","Sergi Abadal"],"url":"https://arxiv.org/abs/2505.13310"}
{"created":"2025-05-20","title":"Synthesis of Communication Policies for Multi-Agent Systems Robust to Communication Restrictions","abstract":"We study stochastic multi-agent systems in which agents must cooperate to maximize the probability of achieving a common reach-avoid objective. In many applications, during the execution of the system, the communication between the agents can be constrained by restrictions on the bandwidth currently available for exchanging local-state information between the agents.","authors":["Saleh Soudijani","Rayna Dimitrova"],"url":"https://arxiv.org/abs/2505.13311"}
{"created":"2025-05-20","title":"GUARD: Generation-time LLM Unlearning via Adaptive Restriction and Detection","abstract":"Large Language Models (LLMs) have demonstrated strong capabilities in memorizing vast amounts of knowledge across diverse domains. However, the ability to selectively forget specific knowledge is critical for ensuring the safety and compliance of deployed models. Existing unlearning efforts typically fine-tune the model with resources such as forget data, retain data, and a calibration model. These additional gradient steps blur the decision boundary between forget and retain knowledge, making unlearning often at the expense of overall performance. To avoid the negative impact of fine-tuning, it would be better to unlearn solely at inference time by safely guarding the model against generating responses related to the forget target, without destroying the fluency of text generation. In this work, we propose Generation-time Unlearning via Adaptive Restriction and Detection (GUARD), a framework that enables dynamic unlearning during LLM generation. Specifically, we first employ a prompt classifier to detect unlearning targets and extract the corresponding forbidden token. We then dynamically penalize and filter candidate tokens during generation using a combination of token matching and semantic matching, effectively preventing the model from leaking the forgotten content. Experimental results on copyright content unlearning tasks over the Harry Potter dataset and the MUSE benchmark, as well as entity unlearning tasks on the TOFU dataset, demonstrate that GUARD achieves strong forget quality across various tasks while causing almost no degradation to the LLM's general capabilities, striking an excellent trade-off between forgetting and utility.","authors":["Zhijie Deng","Chris Yuhao Liu","Zirui Pang","Xinlei He","Lei Feng","Qi Xuan","Zhaowei Zhu","Jiaheng Wei"],"url":"https://arxiv.org/abs/2505.13312"}
{"created":"2025-05-20","title":"KHRONOS: a Kernel-Based Neural Architecture for Rapid, Resource-Efficient Scientific Computation","abstract":"Contemporary models of high dimensional physical systems are constrained by the curse of dimensionality and a reliance on dense data. We introduce KHRONOS (Kernel Expansion Hierarchy for Reduced Order, Neural Optimized Surrogates), an AI framework for model based, model free and model inversion tasks. KHRONOS constructs continuously differentiable target fields with a hierarchical composition of per-dimension kernel expansions, which are tensorized into modes and then superposed. We evaluate KHRONOS on a canonical 2D, Poisson equation benchmark: across 16 to 512 degrees of freedom (DoFs), it obtained L2 square errors of 5e-4 down to 6e-10. This represents a 100 time gain over Kolmogorov Arnold Networks (which itself reports a 100 times improvement on MLPs/PINNs with 100 times fewer parameters) when controlling for the number of parameters. This also represents a 1e4 times improvement in L2 square error compared to standard linear FEM at comparable DoFs. Inference complexity is dominated by inner products, yielding sub-millisecond full-field predictions that scale to an arbitrary resolution. For inverse problems, KHRONOS facilitates rapid, iterative level set recovery in only a few forward evaluations, with sub-microsecond per sample latency. KHRONOS scalability, expressivity, and interpretability open new avenues in constrained edge computing, online control, computer vision, and beyond.","authors":["Reza T. Batley","Sourav Saha"],"url":"https://arxiv.org/abs/2505.13315"}
{"created":"2025-05-20","title":"Denoising Diffusion Probabilistic Model for Point Cloud Compression at Low Bit-Rates","abstract":"Efficient compression of low-bit-rate point clouds is critical for bandwidth-constrained applications. However, existing techniques mainly focus on high-fidelity reconstruction, requiring many bits for compression. This paper proposes a \"Denoising Diffusion Probabilistic Model\" (DDPM) architecture for point cloud compression (DDPM-PCC) at low bit-rates. A PointNet encoder produces the condition vector for the generation, which is then quantized via a learnable vector quantizer. This configuration allows to achieve a low bitrates while preserving quality. Experiments on ShapeNet and ModelNet40 show improved rate-distortion at low rates compared to standardized and state-of-the-art approaches. We publicly released the code at https://github.com/EIDOSLAB/DDPM-PCC.","authors":["Gabriele Spadaro","Alberto Presta","Jhony H. Giraldo","Marco Grangetto","Wei Hu","Giuseppe Valenzise","Attilio Fiandrotti","Enzo Tartaglione"],"url":"https://arxiv.org/abs/2505.13316"}
{"created":"2025-05-20","title":"Unlabeled Data or Pre-trained Model: Rethinking Semi-Supervised Learning and Pretrain-Finetuning","abstract":"Semi-supervised learning (SSL) alleviates the cost of data labeling process by exploiting unlabeled data, and has achieved promising results on various tasks such as image classification. Meanwhile, the Pretrain-Finetuning paradigm has garnered significant attention in recent years, and exploiting pre-trained models could also reduce the requirement of labeled data in downstream tasks. Therefore, a question naturally occurs: \\emph{When the labeled data is scarce in the target tasks, should we exploit unlabeled data or pre-trained models?} To answer this question, we select pre-trained Vision-Language Models (VLMs) as representative pretrain-finetuning instances and propose \\textit{Few-shot SSL} -- a framework that enables fair comparison between these two paradigms by controlling the amount of labeled data used. Extensive experiments across various settings demonstrate that pre-trained VLMs generally outperform SSL methods in nearly all cases, except when the data has low resolution or lacks clear semantic structure. Therefore, we encourage future SSL research to compare with pre-trained models and explore deeper integration, such as using pre-trained knowledge to enhance pseudo-labeling. To support future research, we release our unified reproduction and evaluation framework. Codes are available at https://anonymous.4open.science/r/Rethinking-SSL-and-Pretrain-Finetuning-5566","authors":["Song-Lin Li","Rui Zhu","Yu-Feng Li","Lan-Zhe Guo"],"url":"https://arxiv.org/abs/2505.13317"}
{"created":"2025-05-20","title":"VesselGPT: Autoregressive Modeling of Vascular Geometry","abstract":"Anatomical trees are critical for clinical diagnosis and treatment planning, yet their complex and diverse geometry make accurate representation a significant challenge. Motivated by the latest advances in large language models, we introduce an autoregressive method for synthesizing anatomical trees. Our approach first embeds vessel structures into a learned discrete vocabulary using a VQ-VAE architecture, then models their generation autoregressively with a GPT-2 model. This method effectively captures intricate geometries and branching patterns, enabling realistic vascular tree synthesis. Comprehensive qualitative and quantitative evaluations reveal that our technique achieves high-fidelity tree reconstruction with compact discrete representations. Moreover, our B-spline representation of vessel cross-sections preserves critical morphological details that are often overlooked in previous' methods parameterizations. To the best of our knowledge, this work is the first to generate blood vessels in an autoregressive manner. Code, data, and trained models will be made available.","authors":["Paula Feldman","Martin Sinnona","Viviana Siless","Claudio Delrieux","Emmanuel Iarussi"],"url":"https://arxiv.org/abs/2505.13318"}
{"created":"2025-05-20","title":"SVAFD: A Secure and Verifiable Co-Aggregation Protocol for Federated Distillation","abstract":"Secure Aggregation (SA) is an indispensable component of Federated Learning (FL) that concentrates on privacy preservation while allowing for robust aggregation. However, most SA designs rely heavily on the unrealistic assumption of homogeneous model architectures. Federated Distillation (FD), which aggregates locally computed logits instead of model parameters, introduces a promising alternative for cooperative training in heterogeneous model settings. Nevertheless, we recognize two major challenges in implementing SA for FD. (i) Prior SA designs encourage a dominant server, who is solely responsible for collecting, aggregating and distributing. Such central authority facilitates server to forge aggregation proofs or collude to bypass the claimed security guarantees; (ii) Existing SA, tailored for FL models, overlook the intrinsic properties of logits, making them unsuitable for FD.","authors":["Tian Wen","Sheng Sun","Yuwei Wang","Peiyan Chen","Zhiyuan Wu","Min Liu","Bo Gao"],"url":"https://arxiv.org/abs/2505.13319"}
{"created":"2025-05-20","title":"Discretion in the Loop: Human Expertise in Algorithm-Assisted College Advising","abstract":"In higher education, many institutions use algorithmic alerts to flag at-risk students and deliver advising at scale. While much research has focused on evaluating algorithmic predictions, relatively little is known about how discretionary interventions by human experts shape outcomes in algorithm-assisted settings. We study this question using rich quantitative and qualitative data from a randomized controlled trial of an algorithm-assisted advising program at Georgia State University. Taking a mixed-methods approach, we examine whether and how advisors use context unavailable to an algorithm to guide interventions and influence student success. We develop a causal graphical framework for human expertise in the interventional setting, extending prior work on discretion in purely predictive settings. We then test a necessary condition for discretionary expertise using structured advisor logs and student outcomes data, identifying several interventions that meet the criterion for statistical significance. Accordingly, we estimate that 2 out of 3 interventions taken by advisors in the treatment arm were plausibly \"expertly targeted\" to students using non-algorithmic context. Systematic qualitative analysis of advisor notes corroborates these findings, showing that advisors incorporate diverse forms of contextual information--such as personal circumstances, financial issues, and student engagement--into their decisions. Finally, we explore the broader implications of human discretion for long-term outcomes and equity, using heterogeneous treatment effect estimation. Our results offer theoretical and practical insight into the real-world effectiveness of algorithm-supported college advising, and underscore the importance of accounting for human expertise in the design, evaluation, and implementation of algorithmic decision systems.","authors":["Sofiia Druchyna","Kara Schechtman","Benjamin Brandon","Jenise Stafford","Hannah Li","Lydia T. Liu"],"url":"https://arxiv.org/abs/2505.13325"}
{"created":"2025-05-20","title":"Thinking Short and Right Over Thinking Long: Serving LLM Reasoning Efficiently and Accurately","abstract":"Recent advances in test-time scaling suggest that Large Language Models (LLMs) can gain better capabilities by generating Chain-of-Thought reasoning (analogous to human thinking) to respond a given request, and meanwhile exploring more reasoning branches (i.e., generating multiple responses and ensembling them) can improve the final output quality. However, when incorporating the two scaling dimensions, we find that the system efficiency is dampened significantly for two reasons. Firstly, the time cost to generate the final output increases substantially as many reasoning branches would be trapped in the over-thinking dilemma, producing excessively long responses. Secondly, generating multiple reasoning branches for each request increases memory consumption, which is unsuitable for LLM serving since we can only batch a limited number of requests to process simultaneously. To address this, we present SART, a serving framework for efficient and accurate LLM reasoning. The essential idea is to manage the thinking to be short and right, rather than long. For one thing, we devise a redundant sampling with early stopping approach based on empirical observations and theoretic analysis, which increases the likelihood of obtaining short-thinking responses when sampling reasoning branches. For another, we propose to dynamically prune low-quality branches so that only right-thinking branches are maintained, reducing the memory consumption and allowing us to batch more requests. Experimental results demonstrate that SART not only improves the accuracy of LLM reasoning but also enhances the serving efficiency, outperforming existing methods by up to 28.2 times and on average 15.7 times in terms of efficiency when achieving the same level of accuracy.","authors":["Yuhang Wang","Youhe Jiang","Bin Cui","Fangcheng Fu"],"url":"https://arxiv.org/abs/2505.13326"}
{"created":"2025-05-20","title":"Benchmarking Unified Face Attack Detection via Hierarchical Prompt Tuning","abstract":"Presentation Attack Detection and Face Forgery Detection are designed to protect face data from physical media-based Presentation Attacks and digital editing-based DeepFakes respectively. But separate training of these two models makes them vulnerable to unknown attacks and burdens deployment environments. The lack of a Unified Face Attack Detection model to handle both types of attacks is mainly due to two factors. First, there's a lack of adequate benchmarks for models to explore. Existing UAD datasets have limited attack types and samples, restricting the model's ability to address advanced threats. To address this, we propose UniAttackDataPlus (UniAttackData+), the most extensive and sophisticated collection of forgery techniques to date. It includes 2,875 identities and their 54 kinds of falsified samples, totaling 697,347 videos. Second, there's a lack of a reliable classification criterion. Current methods try to find an arbitrary criterion within the same semantic space, which fails when encountering diverse attacks. So, we present a novel Visual-Language Model-based Hierarchical Prompt Tuning Framework (HiPTune) that adaptively explores multiple classification criteria from different semantic spaces. We build a Visual Prompt Tree to explore various classification rules hierarchically. Then, by adaptively pruning the prompts, the model can select the most suitable prompts to guide the encoder to extract discriminative features at different levels in a coarse-to-fine way. Finally, to help the model understand the classification criteria in visual space, we propose a Dynamically Prompt Integration module to project the visual prompts to the text encoder for more accurate semantics. Experiments on 12 datasets have shown the potential to inspire further innovations in the UAD field.","authors":["Ajian Liu","Haocheng Yuan","Xiao Guo","Hui Ma","Wanyi Zhuang","Changtao Miao","Yan Hong","Chuanbiao Song","Jun Lan","Qi Chu","Tao Gong","Yanyan Liang","Weiqiang Wang","Jun Wan","Xiaoming Liu","Zhen Lei"],"url":"https://arxiv.org/abs/2505.13327"}
{"created":"2025-05-20","title":"Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges","abstract":"Existing benchmarks that assess Language Models (LMs) as Language Agents (LAs) for tool use primarily focus on stateless, single-turn interactions or partial evaluations, such as tool selection in a single turn, overlooking the inherent stateful nature of interactions in multi-turn applications. To fulfill this gap, we propose \\texttt{DialogTool}, a multi-turn dialogue dataset with stateful tool interactions considering the whole life cycle of tool use, across six key tasks in three stages: 1) \\textit{tool creation}; 2) \\textit{tool utilization}: tool awareness, tool selection, tool execution; and 3) \\textit{role-consistent response}: response generation and role play. Furthermore, we build \\texttt{VirtualMobile} -- an embodied virtual mobile evaluation environment to simulate API calls and assess the robustness of the created APIs\\footnote{We will use tools and APIs alternatively, there are no significant differences between them in this paper.}. Taking advantage of these artifacts, we conduct comprehensive evaluation on 13 distinct open- and closed-source LLMs and provide detailed analysis at each stage, revealing that the existing state-of-the-art LLMs still cannot perform well to use tools over long horizons.","authors":["Hongru Wang","Wenyu Huang","Yufei Wang","Yuanhao Xi","Jianqiao Lu","Huan Zhang","Nan Hu","Zeming Liu","Jeff Z. Pan","Kam-Fai Wong"],"url":"https://arxiv.org/abs/2505.13328"}
{"created":"2025-05-20","title":"Recommender Systems for Democracy: Toward Adversarial Robustness in Voting Advice Applications","abstract":"Voting advice applications (VAAs) help millions of voters understand which political parties or candidates best align with their views. This paper explores the potential risks these applications pose to the democratic process when targeted by adversarial entities. In particular, we expose 11 manipulation strategies and measure their impact using data from Switzerland's primary VAA, Smartvote, collected during the last two national elections. We find that altering application parameters, such as the matching method, can shift a party's recommendation frequency by up to 105%. Cherry-picking questionnaire items can increase party recommendation frequency by over 261%, while subtle changes to parties' or candidates' responses can lead to a 248% increase. To address these vulnerabilities, we propose adversarial robustness properties VAAs should satisfy, introduce empirical metrics for assessing the resilience of various matching methods, and suggest possible avenues for research toward mitigating the effect of manipulation. Our framework is key to ensuring secure and reliable AI-based VAAs poised to emerge in the near future.","authors":["Fr\\'ed\\'eric Berdoz","Dustin Brunner","Yann Vonlanthen","Roger Wattenhofer"],"url":"https://arxiv.org/abs/2505.13329"}
{"created":"2025-05-20","title":"Learning Driven Elastic Task Multi-Connectivity Immersive Computing Systems","abstract":"In virtual reality (VR) environments, computational tasks exhibit an elastic nature, meaning they can dynamically adjust based on various user and system constraints. This elasticity is essential for maintaining immersive experiences; however, it also introduces challenges for communication and computing in VR systems. In this paper, we investigate elastic task offloading for multi-user edge-computing-enabled VR systems with multi-connectivity, aiming to maximize the computational energy-efficiency (computational throughput per unit of energy consumed). To balance the induced communication, computation, energy consumption, and quality of experience trade-offs due to the elasticity of VR tasks, we formulate a constrained stochastic computational energy-efficiency optimization problem that integrates the multi-connectivity/multi-user action space and the elastic nature of VR computational tasks. We formulate a centralized phasic policy gradient (CPPG) framework to solve the problem of interest online, using only prior elastic task offloading statistics (energy consumption, response time, and transmission time), and task information (i.e., task size and computational intensity), while observing the induced system performance (energy consumption and latency). We further extend our approach to decentralized learning by formulating an independent phasic policy gradient (IPPG) method and a decentralized shared multi-armed bandit (DSMAB) method. We train our methods with real-world 4G, 5G, and WiGig network traces and 360 video datasets to evaluate their performance in terms of response time, energy efficiency, scalability, and delivered quality of experience. We also provide a comprehensive analysis of task size and its effect on offloading policy and system performance. In particular, we show that CPPG reduces latency by 28% and energy consumption by 78% compared to IPPG.","authors":["Babak Badnava","Jacob Chakareski","Morteza Hashemi"],"url":"https://arxiv.org/abs/2505.13331"}
{"created":"2025-05-20","title":"Measuring Social Influence with Networked Synthetic Control","abstract":"Measuring social influence is difficult due to the lack of counter-factuals and comparisons. By combining machine learning-based modeling and network science, we present general properties of social value, a recent measure for social influence using synthetic control applicable to political behavior. Social value diverges from centrality measures on in that it relies on an external regressor to predict an output variable of interest, generates a synthetic measure of influence, then distributes individual contribution based on a social network. Through theoretical derivations, we show the properties of SV under linear regression with and without interaction, across lattice networks, power-law networks, and random graphs. A reduction in computation can be achieved for any ensemble model. Through simulation, we find that the generalized friendship paradox holds -- that in certain situations, your friends have on average more influence than you do.","authors":["Ho-Chun Herbert Chang"],"url":"https://arxiv.org/abs/2505.13334"}
{"created":"2025-05-20","title":"Neural-Enhanced Rate Adaptation and Computation Distribution for Emerging mmWave Multi-User 3D Video Streaming Systems","abstract":"We investigate multitask edge-user communication-computation resource allocation for $360^\\circ$ video streaming in an edge-computing enabled millimeter wave (mmWave) multi-user virtual reality system. To balance the communication-computation trade-offs that arise herein, we formulate a video quality maximization problem that integrates interdependent multitask/multi-user action spaces and rebuffering time/quality variation constraints. We formulate a deep reinforcement learning framework for \\underline{m}ulti-\\underline{t}ask \\underline{r}ate adaptation and \\underline{c}omputation distribution (MTRC) to solve the problem of interest. Our solution does not rely on a priori knowledge about the environment and uses only prior video streaming statistics (e.g., throughput, decoding time, and transmission delay), and content information, to adjust the assigned video bitrates and computation distribution, as it observes the induced streaming performance online. Moreover, to capture the task interdependence in the environment, we leverage neural network cascades to extend our MTRC method to two novel variants denoted as R1C2 and C1R2. We train all three methods with real-world mmWave network traces and $360^\\circ$ video datasets to evaluate their performance in terms of expected quality of experience (QoE), viewport peak signal-to-noise ratio (PSNR), rebuffering time, and quality variation. We outperform state-of-the-art rate adaptation algorithms, with C1R2 showing best results and achieving $5.21-6.06$ dB PSNR gains, $2.18-2.70$x rebuffering time reduction, and $4.14-4.50$ dB quality variation reduction.","authors":["Babak Badnava","Jacob Chakareski","Morteza Hashemi"],"url":"https://arxiv.org/abs/2505.13337"}
{"created":"2025-05-20","title":"Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation","abstract":"Current speech-LLMs exhibit limited capability in contextual reasoning alongside paralinguistic understanding, primarily due to the lack of Question-Answer (QA) datasets that cover both aspects. We propose a novel framework for dataset generation from in-the-wild speech data, that integrates contextual reasoning with paralinguistic information. It consists of a pseudo paralinguistic label-based data condensation of in-the-wild speech and LLM-based Contextual Paralinguistic QA (CPQA) generation. The effectiveness is validated by a strong correlation in evaluations of the Qwen2-Audio-7B-Instruct model on a dataset created by our framework and human-generated CPQA dataset. The results also reveal the speech-LLM's limitations in handling empathetic reasoning tasks, highlighting the need for such datasets and more robust models. The proposed framework is first of its kind and has potential in training more robust speech-LLMs with paralinguistic reasoning capabilities.","authors":["Qiongqiong Wang","Hardik B. Sailor","Tianchi Liu","Ai Ti Aw"],"url":"https://arxiv.org/abs/2505.13338"}
{"created":"2025-05-20","title":"OPA-Pack: Object-Property-Aware Robotic Bin Packing","abstract":"Robotic bin packing aids in a wide range of real-world scenarios such as e-commerce and warehouses. Yet, existing works focus mainly on considering the shape of objects to optimize packing compactness and neglect object properties such as fragility, edibility, and chemistry that humans typically consider when packing objects. This paper presents OPA-Pack (Object-Property-Aware Packing framework), the first framework that equips the robot with object property considerations in planning the object packing. Technical-wise, we develop a novel object property recognition scheme with retrieval-augmented generation and chain-of-thought reasoning, and build a dataset with object property annotations for 1,032 everyday objects. Also, we formulate OPA-Net, aiming to jointly separate incompatible object pairs and reduce pressure on fragile objects, while compacting the packing. Further, OPA-Net consists of a property embedding layer to encode the property of candidate objects to be packed, together with a fragility heightmap and an avoidance heightmap to keep track of the packed objects. Then, we design a reward function and adopt a deep Q-learning scheme to train OPA-Net. Experimental results manifest that OPA-Pack greatly improves the accuracy of separating incompatible object pairs (from 52% to 95%) and largely reduces pressure on fragile objects (by 29.4%), while maintaining good packing compactness. Besides, we demonstrate the effectiveness of OPA-Pack on a real packing platform, showcasing its practicality in real-world scenarios.","authors":["Jia-Hui Pan","Yeok Tatt Cheah","Zhengzhe Liu","Ka-Hei Hui","Xiaojie Gao","Pheng-Ann Heng","Yun-Hui Liu","Chi-Wing Fu"],"url":"https://arxiv.org/abs/2505.13339"}
{"created":"2025-05-20","title":"Starting Seatwork Earlier as a Valid Measure of Student Engagement","abstract":"Prior work has developed a range of automated measures (\"detectors\") of student self-regulation and engagement from student log data. These measures have been successfully used to make discoveries about student learning. Here, we extend this line of research to an underexplored aspect of self-regulation: students' decisions about when to start and stop working on learning software during classwork. In the first of two analyses, we build on prior work on session-level measures (e.g., delayed start, early stop) to evaluate their reliability and predictive validity. We compute these measures from year-long log data from Cognitive Tutor for students in grades 8-12 (N = 222). Our findings show that these measures exhibit moderate to high month-to-month reliability (G > .75), comparable to or exceeding gaming-the-system behavior. Additionally, they enhance the prediction of final math scores beyond prior knowledge and gaming-the-system behaviors. The improvement in learning outcome predictions beyond time-on-task suggests they capture a broader motivational state tied to overall learning. The second analysis demonstrates the cross-system generalizability of these measures in i-Ready, where they predict state test scores for grade 7 students (N = 818). By leveraging log data, we introduce system-general naturally embedded measures that complement motivational surveys without extra instrumentation or disruption of instruction time. Our findings demonstrate the potential of session-level logs to mine valid and generalizable measures with broad applications in the predictive modeling of learning outcomes and analysis of learner self-regulation.","authors":["Ashish Gurung","Jionghao Lin","Zhongtian Huang","Conrad Borchers","Ryan S. Baker","Vincent Aleven","Kenneth R. Koedinger"],"url":"https://arxiv.org/abs/2505.13341"}
{"created":"2025-05-20","title":"Detect and Correct: A Selective Noise Correction Method for Learning with Noisy Labels","abstract":"Falsely annotated samples, also known as noisy labels, can significantly harm the performance of deep learning models. Two main approaches for learning with noisy labels are global noise estimation and data filtering. Global noise estimation approximates the noise across the entire dataset using a noise transition matrix, but it can unnecessarily adjust correct labels, leaving room for local improvements. Data filtering, on the other hand, discards potentially noisy samples but risks losing valuable data. Our method identifies potentially noisy samples based on their loss distribution. We then apply a selection process to separate noisy and clean samples and learn a noise transition matrix to correct the loss for noisy samples while leaving the clean data unaffected, thereby improving the training process. Our approach ensures robust learning and enhanced model performance by preserving valuable information from noisy samples and refining the correction process. We applied our method to standard image datasets (MNIST, CIFAR-10, and CIFAR-100) and a biological scRNA-seq cell-type annotation dataset. We observed a significant improvement in model accuracy and robustness compared to traditional methods.","authors":["Yuval Grinberg","Nimrod Harel","Jacob Goldberger","Ofir Lindenbaum"],"url":"https://arxiv.org/abs/2505.13342"}
{"created":"2025-05-20","title":"MRM3: Machine Readable ML Model Metadata","abstract":"As the complexity and number of machine learning (ML) models grows, well-documented ML models are essential for developers and companies to use or adapt them to their specific use cases. Model metadata, already present in unstructured format as model cards in online repositories such as Hugging Face, could be more structured and machine readable while also incorporating environmental impact metrics such as energy consumption and carbon footprint. Our work extends the existing State of the Art by defining a structured schema for ML model metadata focusing on machine-readable format and support for integration into a knowledge graph (KG) for better organization and querying, enabling a wider set of use cases. Furthermore, we present an example wireless localization model metadata dataset consisting of 22 models trained on 4 datasets, integrated into a Neo4j-based KG with 113 nodes and 199 relations.","authors":["Andrej \\v{C}op","Bla\\v{z} Bertalani\\v{c}","Marko Grobelnik","Carolina Fortuna"],"url":"https://arxiv.org/abs/2505.13343"}
{"created":"2025-05-20","title":"RoPECraft: Training-Free Motion Transfer with Trajectory-Guided RoPE Optimization on Diffusion Transformers","abstract":"We propose RoPECraft, a training-free video motion transfer method for diffusion transformers that operates solely by modifying their rotary positional embeddings (RoPE). We first extract dense optical flow from a reference video, and utilize the resulting motion offsets to warp the complex-exponential tensors of RoPE, effectively encoding motion into the generation process. These embeddings are then further optimized during denoising time steps via trajectory alignment between the predicted and target velocities using a flow-matching objective. To keep the output faithful to the text prompt and prevent duplicate generations, we incorporate a regularization term based on the phase components of the reference video's Fourier transform, projecting the phase angles onto a smooth manifold to suppress high-frequency artifacts. Experiments on benchmarks reveal that RoPECraft outperforms all recently published methods, both qualitatively and quantitatively.","authors":["Ahmet Berke Gokmen","Yigit Ekin","Bahri Batuhan Bilecen","Aysegul Dundar"],"url":"https://arxiv.org/abs/2505.13344"}
{"created":"2025-05-20","title":"Occult: Optimizing Collaborative Communication across Experts for Accelerated Parallel MoE Training and Inference","abstract":"Mixture-of-experts (MoE) architectures could achieve impressive computational efficiency with expert parallelism, which relies heavily on all-to-all communication across devices. Unfortunately, such communication overhead typically constitutes a significant portion of the total runtime, hampering the scalability of distributed training and inference for modern MoE models (consuming over $40\\%$ runtime in large-scale training). In this paper, we first define collaborative communication to illustrate this intrinsic limitation, and then propose system- and algorithm-level innovations to reduce communication costs. Specifically, given a pair of experts co-activated by one token, we call them \"collaborated\", which comprises $2$ cases as intra- and inter-collaboration, depending on whether they are kept on the same device. Our pilot investigations reveal that augmenting the proportion of intra-collaboration can accelerate expert parallelism at scale. It motivates us to strategically optimize collaborative communication for accelerated MoE training and inference, dubbed Occult. Our designs are capable of either delivering exact results with reduced communication cost or controllably minimizing the cost with collaboration pruning, materialized by modified fine-tuning. Comprehensive experiments on various MoE-LLMs demonstrate that Occult can be faster than popular state-of-the-art inference or training frameworks (more than $1.5\\times$ speed up across multiple tasks and models) with comparable or superior quality compared to the standard fine-tuning. Code is available at $\\href{https://github.com/UNITES-Lab/Occult}{https://github.com/UNITES-Lab/Occult}$.","authors":["Shuqing Luo (Katie)","Pingzhi Li (Katie)","Jie Peng (Katie)","Hanrui Wang (Katie)","Yang (Katie)","Zhao (Kevin)","Yu (Kevin)","Cao","Yu Cheng","Tianlong Chen"],"url":"https://arxiv.org/abs/2505.13345"}
{"created":"2025-05-20","title":"J4R: Learning to Judge with Equivalent Initial State Group Relative Preference Optimization","abstract":"To keep pace with the increasing pace of large language models (LLM) development, model output evaluation has transitioned away from time-consuming human evaluation to automatic evaluation, where LLMs themselves are tasked with assessing and critiquing other model outputs. LLM-as-judge models are a class of generative evaluators that excel in evaluating relatively simple domains, like chat quality, but struggle in reasoning intensive domains where model responses contain more substantive and challenging content. To remedy existing judge shortcomings, we explore training judges with reinforcement learning (RL). We make three key contributions: (1) We propose the Equivalent Initial State Group Relative Policy Optimization (EIS-GRPO) algorithm, which allows us to train our judge to be robust to positional biases that arise in more complex evaluation settings. (2) We introduce ReasoningJudgeBench, a benchmark that evaluates judges in diverse reasoning settings not covered by prior work. (3) We train Judge for Reasoning (J4R), a 7B judge trained with EIS-GRPO that outperforms GPT-4o and the next best small judge by 6.7% and 9%, matching or exceeding the performance of larger GRPO-trained judges on both JudgeBench and ReasoningJudgeBench.","authors":["Austin Xu","Yilun Zhou","Xuan-Phi Nguyen","Caiming Xiong","Shafiq Joty"],"url":"https://arxiv.org/abs/2505.13346"}
{"created":"2025-05-20","title":"Investigating the Vulnerability of LLM-as-a-Judge Architectures to Prompt-Injection Attacks","abstract":"Large Language Models (LLMs) are increasingly employed as evaluators (LLM-as-a-Judge) for assessing the quality of machine-generated text. This paradigm offers scalability and cost-effectiveness compared to human annotation. However, the reliability and security of such systems, particularly their robustness against adversarial manipulations, remain critical concerns. This paper investigates the vulnerability of LLM-as-a-Judge architectures to prompt-injection attacks, where malicious inputs are designed to compromise the judge's decision-making process. We formalize two primary attack strategies: Comparative Undermining Attack (CUA), which directly targets the final decision output, and Justification Manipulation Attack (JMA), which aims to alter the model's generated reasoning. Using the Greedy Coordinate Gradient (GCG) optimization method, we craft adversarial suffixes appended to one of the responses being compared. Experiments conducted on the MT-Bench Human Judgments dataset with open-source instruction-tuned LLMs (Qwen2.5-3B-Instruct and Falcon3-3B-Instruct) demonstrate significant susceptibility. The CUA achieves an Attack Success Rate (ASR) exceeding 30\\%, while JMA also shows notable effectiveness. These findings highlight substantial vulnerabilities in current LLM-as-a-Judge systems, underscoring the need for robust defense mechanisms and further research into adversarial evaluation and trustworthiness in LLM-based assessment frameworks.","authors":["Narek Maloyan","Bislan Ashinov","Dmitry Namiot"],"url":"https://arxiv.org/abs/2505.13348"}
{"created":"2025-05-20","title":"Approximating Global Contact-Implicit MPC via Sampling and Local Complementarity","abstract":"To achieve general-purpose dexterous manipulation, robots must rapidly devise and execute contact-rich behaviors. Existing model-based controllers are incapable of globally optimizing in real-time over the exponential number of possible contact sequences. Instead, recent progress in contact-implicit control has leveraged simpler models that, while still hybrid, make local approximations. However, the use of local models inherently limits the controller to only exploit nearby interactions, potentially requiring intervention to richly explore the space of possible contacts. We present a novel approach which leverages the strengths of local complementarity-based control in combination with low-dimensional, but global, sampling of possible end-effector locations. Our key insight is to consider a contact-free stage preceding a contact-rich stage at every control loop. Our algorithm, in parallel, samples end effector locations to which the contact-free stage can move the robot, then considers the cost predicted by contact-rich MPC local to each sampled location. The result is a globally-informed, contact-implicit controller capable of real-time dexterous manipulation. We demonstrate our controller on precise, non-prehensile manipulation of non-convex objects using a Franka Panda arm. Project page: https://approximating-global-ci-mpc.github.io","authors":["Sharanya Venkatesh","Bibit Bianchini","Alp Aydinoglu","William Yang","Michael Posa"],"url":"https://arxiv.org/abs/2505.13350"}
{"created":"2025-05-20","title":"Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning","abstract":"Although modern Large Language Models (LLMs) support extremely large contexts, their effectiveness in utilizing long context for code reasoning remains unclear. This paper investigates LLM reasoning ability over code snippets within large repositories and how it relates to their recall ability. Specifically, we differentiate between lexical code recall (verbatim retrieval) and semantic code recall (remembering what the code does). To measure semantic recall, we propose SemTrace, a code reasoning technique where the impact of specific statements on output is attributable and unpredictable. We also present a method to quantify semantic recall sensitivity in existing benchmarks. Our evaluation of state-of-the-art LLMs reveals a significant drop in code reasoning accuracy as a code snippet approaches the middle of the input context, particularly with techniques requiring high semantic recall like SemTrace. Moreover, we find that lexical recall varies by granularity, with models excelling at function retrieval but struggling with line-by-line recall. Notably, a disconnect exists between lexical and semantic recall, suggesting different underlying mechanisms. Finally, our findings indicate that current code reasoning benchmarks may exhibit low semantic recall sensitivity, potentially underestimating LLM challenges in leveraging in-context information.","authors":["Adam \\v{S}torek","Mukur Gupta","Samira Hajizadeh","Prashast Srivastava","Suman Jana"],"url":"https://arxiv.org/abs/2505.13353"}
{"created":"2025-05-20","title":"A large-scale analysis of public-facing, community-built chatbots on Character.AI","abstract":"This paper presents the first large-scale analysis of public-facing chatbots on Character.AI, a rapidly growing social media platform where users create and interact with chatbots. Character.AI is distinctive in that it merges generative AI with user-generated content, enabling users to build bots-often modeled after fictional or public personas-for others to engage with. It is also popular, with over 20 million monthly active users, and impactful, with recent headlines detailing significant issues with youth engagement on the site. Character.AI is thus of interest to study both substantively and conceptually. To this end, we present a descriptive overview of the site using a dataset of 2.1 million English-language prompts (or ``greetings'') for chatbots on the site, created by around 1 million users. Our work explores the prevalence of different fandoms on the site, broader tropes that persist across fandoms, and how dynamics of power intersect with gender within greetings. Overall, our findings illuminate an emerging form of online (para)social interaction that toes a unique and important intersection between generative AI and user-generated content.","authors":["Owen Lee","Kenneth Joseph"],"url":"https://arxiv.org/abs/2505.13354"}
{"created":"2025-05-20","title":"Multi-Armed Bandits Meet Large Language Models","abstract":"Bandit algorithms and Large Language Models (LLMs) have emerged as powerful tools in artificial intelligence, each addressing distinct yet complementary challenges in decision-making and natural language processing. This survey explores the synergistic potential between these two fields, highlighting how bandit algorithms can enhance the performance of LLMs and how LLMs, in turn, can provide novel insights for improving bandit-based decision-making. We first examine the role of bandit algorithms in optimizing LLM fine-tuning, prompt engineering, and adaptive response generation, focusing on their ability to balance exploration and exploitation in large-scale learning tasks. Subsequently, we explore how LLMs can augment bandit algorithms through advanced contextual understanding, dynamic adaptation, and improved policy selection using natural language reasoning. By providing a comprehensive review of existing research and identifying key challenges and opportunities, this survey aims to bridge the gap between bandit algorithms and LLMs, paving the way for innovative applications and interdisciplinary research in AI.","authors":["Djallel Bouneffouf","Raphael Feraud"],"url":"https://arxiv.org/abs/2505.13355"}
{"created":"2025-05-20","title":"Quantum Hardware-in-the-Loop for Optimal Power Flow in Renewable-Integrated Power Systems","abstract":"This paper presents a proof-of-concept for integrating quantum hardware with real-time digital simulator (RTDS) to model and control modern power systems, including renewable energy resources. Power flow (PF) analysis and optimal power flow (OPF) studies are conducted using RTDS coupled with Fujitsu's CMOS Digital Annealer and D-Wave's Advantage quantum processors. The adiabatic quantum power flow (AQPF) and adiabatic quantum optimal power flow (AQOPF) algorithms are used to perform PF and OPF, respectively, on quantum and quantum-inspired hardware. The experiments are performed on the IEEE 9-bus test system and a modified version that includes solar and wind farms. The findings demonstrate that the AQPF and AQOPF algorithms can accurately perform PF and OPF, yielding results that closely match those of classical Newton-Raphson (NR) solvers while also exhibiting robust convergence. Furthermore, the integration of renewable energy sources (RES) within the AQOPF framework proves effective in maintaining system stability and performance, even under variable generation conditions. These findings highlight the potential of quantum computing to significantly enhance the modeling and control of future power grids, particularly in systems with high renewable energy penetration.","authors":["Zeynab Kaseb","Rahul Rane","Aleksandra Lekic","Matthias Moller","Amin Khodaei","Peter Palensky","Pedro P. Vergara"],"url":"https://arxiv.org/abs/2505.13356"}
{"created":"2025-05-20","title":"Introducing Instruction-Accurate Simulators for Performance Estimation of Autotuning Workloads","abstract":"Accelerating Machine Learning (ML) workloads requires efficient methods due to their large optimization space. Autotuning has emerged as an effective approach for systematically evaluating variations of implementations. Traditionally, autotuning requires the workloads to be executed on the target hardware (HW). We present an interface that allows executing autotuning workloads on simulators. This approach offers high scalability when the availability of the target HW is limited, as many simulations can be run in parallel on any accessible HW. Additionally, we evaluate the feasibility of using fast instruction-accurate simulators for autotuning. We train various predictors to forecast the performance of ML workload implementations on the target HW based on simulation statistics. Our results demonstrate that the tuned predictors are highly effective. The best workload implementation in terms of actual run time on the target HW is always within the top 3 % of predictions for the tested x86, ARM, and RISC-V-based architectures. In the best case, this approach outperforms native execution on the target HW for embedded architectures when running as few as three samples on three simulators in parallel.","authors":["Rebecca Pelke","Nils Bosbach","Lennart M. Reimann","Rainer Leupers"],"url":"https://arxiv.org/abs/2505.13357"}
{"created":"2025-05-20","title":"One-Step Offline Distillation of Diffusion-based Models via Koopman Modeling","abstract":"Diffusion-based generative models have demonstrated exceptional performance, yet their iterative sampling procedures remain computationally expensive. A prominent strategy to mitigate this cost is distillation, with offline distillation offering particular advantages in terms of efficiency, modularity, and flexibility. In this work, we identify two key observations that motivate a principled distillation framework: (1) while diffusion models have been viewed through the lens of dynamical systems theory, powerful and underexplored tools can be further leveraged; and (2) diffusion models inherently impose structured, semantically coherent trajectories in latent space. Building on these observations, we introduce the Koopman Distillation Model KDM, a novel offline distillation approach grounded in Koopman theory-a classical framework for representing nonlinear dynamics linearly in a transformed space. KDM encodes noisy inputs into an embedded space where a learned linear operator propagates them forward, followed by a decoder that reconstructs clean samples. This enables single-step generation while preserving semantic fidelity. We provide theoretical justification for our approach: (1) under mild assumptions, the learned diffusion dynamics admit a finite-dimensional Koopman representation; and (2) proximity in the Koopman latent space correlates with semantic similarity in the generated outputs, allowing for effective trajectory alignment. Empirically, KDM achieves state-of-the-art performance across standard offline distillation benchmarks, improving FID scores by up to 40% in a single generation step. All implementation details and code for the experimental setups are provided in our GitHub - https://github.com/azencot-group/KDM, or in our project page - https://sites.google.com/view/koopman-distillation-model.","authors":["Nimrod Berman","Ilan Naiman","Moshe Eliasof","Hedi Zisling","Omri Azencot"],"url":"https://arxiv.org/abs/2505.13358"}
{"created":"2025-05-20","title":"What Prompts Don't Say: Understanding and Managing Underspecification in LLM Prompts","abstract":"Building LLM-powered software requires developers to communicate their requirements through natural language, but developer prompts are frequently underspecified, failing to fully capture many user-important requirements. In this paper, we present an in-depth analysis of prompt underspecification, showing that while LLMs can often (41.1%) guess unspecified requirements by default, such behavior is less robust: Underspecified prompts are 2x more likely to regress over model or prompt changes, sometimes with accuracy drops by more than 20%. We then demonstrate that simply adding more requirements to a prompt does not reliably improve performance, due to LLMs' limited instruction-following capabilities and competing constraints, and standard prompt optimizers do not offer much help. To address this, we introduce novel requirements-aware prompt optimization mechanisms that can improve performance by 4.8% on average over baselines that naively specify everything in the prompt. Beyond prompt optimization, we envision that effectively managing prompt underspecification requires a broader process, including proactive requirements discovery, evaluation, and monitoring.","authors":["Chenyang Yang","Yike Shi","Qianou Ma","Michael Xieyang Liu","Christian K\\\"astner","Tongshuang Wu"],"url":"https://arxiv.org/abs/2505.13360"}
{"created":"2025-05-20","title":"DynaNoise: Dynamic Probabilistic Noise Injection for Defending Against Membership Inference Attacks","abstract":"Membership Inference Attacks (MIAs) pose a significant risk to the privacy of training datasets by exploiting subtle differences in model outputs to determine whether a particular data sample was used during training. These attacks can compromise sensitive information, especially in domains such as healthcare and finance, where data privacy is paramount. Traditional mitigation techniques, such as static differential privacy, rely on injecting a fixed amount of noise during training or inference. However, this approach often leads to a detrimental trade-off: the noise may be insufficient to counter sophisticated attacks or, when increased, may substantially degrade model performance. In this paper, we present DynaNoise, an adaptive approach that dynamically modulates noise injection based on query sensitivity. Our approach performs sensitivity analysis using measures such as Shannon entropy to evaluate the risk associated with each query and adjusts the noise variance accordingly. A probabilistic smoothing step is then applied to renormalize the perturbed outputs, ensuring that the model maintains high accuracy while effectively obfuscating membership signals. We further propose an empirical metric, the Membership Inference Defense Privacy-Utility Tradeoff (MIDPUT), which quantifies the balance between reducing attack success rates and preserving the target model's accuracy. Our extensive evaluation on several benchmark datasets demonstrates that DynaNoise not only significantly reduces MIA success rates but also achieves up to a fourfold improvement in the MIDPUT metric compared to the state-of-the-art. Moreover, DynaNoise maintains competitive model accuracy while imposing only marginal inference overhead, highlighting its potential as an effective and efficient privacy defense against MIAs.","authors":["Javad Forough","Hamed Haddadi"],"url":"https://arxiv.org/abs/2505.13362"}
{"created":"2025-05-20","title":"Exploiting Symbolic Heuristics for the Synthesis of Domain-Specific Temporal Planning Guidance using Reinforcement Learning","abstract":"Recent work investigated the use of Reinforcement Learning (RL) for the synthesis of heuristic guidance to improve the performance of temporal planners when a domain is fixed and a set of training problems (not plans) is given. The idea is to extract a heuristic from the value function of a particular (possibly infinite-state) MDP constructed over the training problems.","authors":["Irene Brugnara","Alessandro Valentini","Andrea Micheli"],"url":"https://arxiv.org/abs/2505.13372"}
{"created":"2025-05-20","title":"Structure-preserving schemes conserving entropy and kinetic energy","abstract":"This paper presents a novel structure-preserving scheme for Euler equations, focusing on the numerical conservation of entropy and kinetic energy. Explicit flux functions engineered to conserve entropy are introduced within the finite-volume framework. Further, discrete kinetic energy conservation too is introduced. A systematic inquiry is presented, commencing with an overview of numerical entropy conservation and formulation of entropy-conserving and kinetic energy-preserving fluxes, followed by the study of their properties and efficacy. A novelty introduced is to associate numerical entropy conservation to the discretization of the energy conservation equation. Furthermore, an entropy-stable shock-capturing diffusion method and a hybrid approach utilizing the entropy distance to manage smooth regions effectively are also introduced. The addition of artificial viscosity in appropriate regions ensures entropy generation sufficient to prevent numerical instabilities. Various test cases, showcasing the efficacy and stability of the proposed methodology, are presented.","authors":["Kunal Bahuguna","Ramesh Kolluru","S. V. Raghurama Rao"],"url":"https://arxiv.org/abs/2505.13374"}
{"created":"2025-05-20","title":"Seeing, Saying, Solving: An LLM-to-TL Framework for Cooperative Robots","abstract":"Increased robot deployment, such as in warehousing, has revealed a need for seamless collaboration among heterogeneous robot teams to resolve unforeseen conflicts. To address this challenge, we propose a novel, decentralized framework for robots to request and provide help. The framework begins with robots detecting conflicts using a Vision Language Model (VLM), then reasoning over whether help is needed. If so, it crafts and broadcasts a natural language (NL) help request using a Large Language Model (LLM). Potential helper robots reason over the request and offer help (if able), along with information about impact to their current tasks. Helper reasoning is implemented via an LLM grounded in Signal Temporal Logic (STL) using a Backus-Naur Form (BNF) grammar to guarantee syntactically valid NL-to-STL translations, which are then solved as a Mixed Integer Linear Program (MILP). Finally, the requester robot chooses a helper by reasoning over impact on the overall system. We evaluate our system via experiments considering different strategies for choosing a helper, and find that a requester robot can minimize overall time impact on the system by considering multiple help offers versus simple heuristics (e.g., selecting the nearest robot to help).","authors":["Dan BW Choe","Sundhar Vinodh Sangeetha","Steven Emanuel","Chih-Yuan Chiu","Samuel Coogan","Shreyas Kousik"],"url":"https://arxiv.org/abs/2505.13376"}
{"created":"2025-05-20","title":"Restoration Score Distillation: From Corrupted Diffusion Pretraining to One-Step High-Quality Generation","abstract":"Learning generative models from corrupted data is a fundamental yet persistently challenging task across scientific disciplines, particularly when access to clean data is limited or expensive. Denoising Score Distillation (DSD) \\cite{chen2025denoising} recently introduced a novel and surprisingly effective strategy that leverages score distillation to train high-fidelity generative models directly from noisy observations. Building upon this foundation, we propose \\textit{Restoration Score Distillation} (RSD), a principled generalization of DSD that accommodates a broader range of corruption types, such as blurred, incomplete, or low-resolution images. RSD operates by first pretraining a teacher diffusion model solely on corrupted data and subsequently distilling it into a single-step generator that produces high-quality reconstructions. Empirically, RSD consistently surpasses its teacher model across diverse restoration tasks on both natural and scientific datasets. Moreover, beyond standard diffusion objectives, the RSD framework is compatible with several corruption-aware training techniques such as Ambient Tweedie, Ambient Diffusion, and its Fourier-space variant, enabling flexible integration with recent advances in diffusion modeling. Theoretically, we demonstrate that in a linear regime, RSD recovers the eigenspace of the clean data covariance matrix from linear measurements, thereby serving as an implicit regularizer. This interpretation recasts score distillation not only as a sampling acceleration technique but as a principled approach to enhancing generative performance in severely degraded data regimes.","authors":["Yasi Zhang","Tianyu Chen","Zhendong Wang","Ying Nian Wu","Mingyuan Zhou","Oscar Leong"],"url":"https://arxiv.org/abs/2505.13377"}
{"created":"2025-05-20","title":"Thinkless: LLM Learns When to Think","abstract":"Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many problems admit straightforward solutions. This motivates an open question: Can LLMs learn when to think? To answer this, we propose Thinkless, a learnable framework that empowers an LLM to adaptively select between short-form and long-form reasoning, based on both task complexity and the model's ability. Thinkless is trained under a reinforcement learning paradigm and employs two control tokens,  for concise responses and  for detailed reasoning. At the core of our method is a Decoupled Group Relative Policy Optimization (DeGRPO) algorithm, which decomposes the learning objective of hybrid reasoning into two components: (1) a control token loss that governs the selection of the reasoning mode, and (2) a response loss that improves the accuracy of the generated answers. This decoupled formulation enables fine-grained control over the contributions of each objective, stabilizing training and effectively preventing collapse observed in vanilla GRPO. Empirically, on several benchmarks such as Minerva Algebra, MATH-500, and GSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% - 90%, significantly improving the efficiency of Reasoning Language Models. The code is available at https://github.com/VainF/Thinkless","authors":["Gongfan Fang","Xinyin Ma","Xinchao Wang"],"url":"https://arxiv.org/abs/2505.13379"}
{"created":"2025-05-20","title":"CompeteSMoE -- Statistically Guaranteed Mixture of Experts Training via Competition","abstract":"Sparse mixture of experts (SMoE) offers an appealing solution to scale up the model complexity beyond the mean of increasing the network's depth or width. However, we argue that effective SMoE training remains challenging because of the suboptimal routing process where experts that perform computation do not directly contribute to the routing process. In this work, we propose competition, a novel mechanism to route tokens to experts with the highest neural response. Theoretically, we show that the competition mechanism enjoys a better sample efficiency than the traditional softmax routing. Furthermore, we develop CompeteSMoE, a simple yet effective algorithm to train large language models by deploying a router to learn the competition policy, thus enjoying strong performances at a low training overhead. Our extensive empirical evaluations on both the visual instruction tuning and language pre-training tasks demonstrate the efficacy, robustness, and scalability of CompeteSMoE compared to state-of-the-art SMoE strategies. We have made the implementation available at: https://github.com/Fsoft-AIC/CompeteSMoE. This work is an improved version of the previous study at arXiv:2402.02526","authors":["Nam V. Nguyen","Huy Nguyen","Quang Pham","Van Nguyen","Savitha Ramasamy","Nhat Ho"],"url":"https://arxiv.org/abs/2505.13380"}
{"created":"2025-05-20","title":"How Adding Metacognitive Requirements in Support of AI Feedback in Practice Exams Transforms Student Learning Behaviors","abstract":"Providing personalized, detailed feedback at scale in large undergraduate STEM courses remains a persistent challenge. We present an empirically evaluated practice exam system that integrates AI generated feedback with targeted textbook references, deployed in a large introductory biology course. Our system encourages metacognitive behavior by asking students to explain their answers and declare their confidence. It uses OpenAI's GPT-4o to generate personalized feedback based on this information, while directing them to relevant textbook sections. Through interaction logs from consenting participants across three midterms (541, 342, and 413 students respectively), totaling 28,313 question-student interactions across 146 learning objectives, along with 279 surveys and 23 interviews, we examined the system's impact on learning outcomes and engagement. Across all midterms, feedback types showed no statistically significant performance differences, though some trends suggested potential benefits. The most substantial impact came from the required confidence ratings and explanations, which students reported transferring to their actual exam strategies. About 40 percent of students engaged with textbook references when prompted by feedback -- far higher than traditional reading rates. Survey data revealed high satisfaction (mean rating 4.1 of 5), with 82.1 percent reporting increased confidence on practiced midterm topics, and 73.4 percent indicating they could recall and apply specific concepts. Our findings suggest that embedding structured reflection requirements may be more impactful than sophisticated feedback mechanisms.","authors":["Mak Ahmad","Prerna Ravi","David Karger","Marc Facciotti"],"url":"https://arxiv.org/abs/2505.13381"}
{"created":"2025-05-20","title":"An Empirical Bayes approach to ARX Estimation","abstract":"Empirical Bayes inference is based on estimation of the parameters of an a priori distribution from the observed data. The estimation technique of the parameters of the prior, called hyperparameters, is based on the marginal distribution obtained by integrating the joint density of the model with respect to the prior. This is a key step which needs to be properly adapted to the problem at hand. In this paper we study Empirical Bayes inference of linear autoregressive models with inputs (ARX models) for time series and compare the performance of the marginal parametric estimator with that a full Empirical Bayesian analysis based on the estimated prior. Such a comparison, can only make sense for a (realistic) finite data length. In this setting, we propose a new estimation technique of the hyperparameters by a sequential Bayes procedure which is essentially a backward Kalman filter. It turns out that for finite data length the marginal Bayes tends to behave slightly better than the full Empirical Bayesian parameter estimator and so also in the case of slowly varying random parameters.","authors":["Timofei Leahu","Giorgio Picci"],"url":"https://arxiv.org/abs/2505.13384"}
{"created":"2025-05-20","title":"R3: Robust Rubric-Agnostic Reward Models","abstract":"Reward models are essential for aligning language model outputs with human preferences, yet existing approaches often lack both controllability and interpretability. These models are typically optimized for narrow objectives, limiting their generalizability to broader downstream tasks. Moreover, their scalar outputs are difficult to interpret without contextual reasoning. To address these limitations, we introduce R3, a novel reward modeling framework that is rubric-agnostic, generalizable across evaluation dimensions, and provides interpretable, reasoned score assignments. R3 enables more transparent and flexible evaluation of language models, supporting robust alignment with diverse human values and use cases. Our models, data, and code are available as open source at https://github.com/rubricreward/r3","authors":["David Anugraha","Zilu Tang","Lester James V. Miranda","Hanyang Zhao","Mohammad Rifqi Farhansyah","Garry Kuwanto","Derry Wijaya","Genta Indra Winata"],"url":"https://arxiv.org/abs/2505.13388"}
{"created":"2025-05-20","title":"Faster Video Diffusion with Trainable Sparse Attention","abstract":"Scaling video diffusion transformers (DiTs) is limited by their quadratic 3D attention, even though most of the attention mass concentrates on a small subset of positions. We turn this observation into VSA, a trainable, hardware-efficient sparse attention that replaces full attention at \\emph{both} training and inference. In VSA, a lightweight coarse stage pools tokens into tiles and identifies high-weight \\emph{critical tokens}; a fine stage computes token-level attention only inside those tiles subjecting to block computing layout to ensure hard efficiency. This leads to a single differentiable kernel that trains end-to-end, requires no post-hoc profiling, and sustains 85\\% of FlashAttention3 MFU. We perform a large sweep of ablation studies and scaling-law experiments by pretraining DiTs from 60M to 1.4B parameters. VSA reaches a Pareto point that cuts training FLOPS by 2.53$\\times$ with no drop in diffusion loss. Retrofitting the open-source Wan-2.1 model speeds up attention time by 6$\\times$ and lowers end-to-end generation time from 31s to 18s with comparable quality. These results establish trainable sparse attention as a practical alternative to full attention and a key enabler for further scaling of video diffusion models.","authors":["Peiyuan Zhang","Haofeng Huang","Yongqi Chen","Will Lin","Zhengzhong Liu","Ion Stoica","Eric P. Xing","Hao Zhang"],"url":"https://arxiv.org/abs/2505.13389"}
{"created":"2025-05-20","title":"MGPBD: A Multigrid Accelerated Global XPBD Solver","abstract":"We introduce a novel Unsmoothed Aggregation (UA) Algebraic Multigrid (AMG) method combined with Preconditioned Conjugate Gradient (PCG) to overcome the limitations of Extended Position-Based Dynamics (XPBD) in high-resolution and high-stiffness simulations. While XPBD excels in simulating deformable objects due to its speed and simplicity, its nonlinear Gauss-Seidel (GS) solver often struggles with low-frequency errors, leading to instability and stalling issues, especially in high-resolution, high-stiffness simulations. Our multigrid approach addresses these issues efficiently by leveraging AMG. To reduce the computational overhead of traditional AMG, where prolongator construction can consume up to two-thirds of the runtime, we propose a lazy setup strategy that reuses prolongators across iterations based on matrix structure and physical significance. Furthermore, we introduce a simplified method for constructing near-kernel components by applying a few sweeps of iterative methods to the homogeneous equation, achieving convergence rates comparable to adaptive smoothed aggregation (adaptive-SA) at a lower computational cost. Experimental results demonstrate that our method significantly improves convergence rates and numerical stability, enabling efficient and stable high-resolution simulations of deformable objects.","authors":["Chunlei Li","Peng Yu","Tiantian Liu","Siyuan Yu","Yuting Xiao","Shuai Li","Aimin Hao","Yang Gao","Qinping Zhao"],"url":"https://arxiv.org/abs/2505.13390"}
{"created":"2025-05-20","title":"Advancing Generalization Across a Variety of Abstract Visual Reasoning Tasks","abstract":"The abstract visual reasoning (AVR) domain presents a diverse suite of analogy-based tasks devoted to studying model generalization. Recent years have brought dynamic progress in the field, particularly in i.i.d. scenarios, in which models are trained and evaluated on the same data distributions. Nevertheless, o.o.d. setups that assess model generalization to new test distributions remain challenging even for the most recent models. To advance generalization in AVR tasks, we present the Pathways of Normalized Group Convolution model (PoNG), a novel neural architecture that features group convolution, normalization, and a parallel design. We consider a wide set of AVR benchmarks, including Raven's Progressive Matrices and visual analogy problems with both synthetic and real-world images. The experiments demonstrate strong generalization capabilities of the proposed model, which in several settings outperforms the existing literature methods.","authors":["Miko{\\l}aj Ma{\\l}ki\\'nski","Jacek Ma\\'ndziuk"],"url":"https://arxiv.org/abs/2505.13391"}
{"created":"2025-05-20","title":"IG Parser: A Software Package for the Encoding of Institutional Statements using the Institutional Grammar","abstract":"This article provides an overview of IG Parser, a software that facilitates qualitative content analysis of formal (e.g., legal) rules or informal (e.g., socio-normative) norms, and strategies (such as conventions) -- referred to as \\emph{institutions} -- that govern social systems and operate configurally to describe \\emph{institutional systems}. To this end, the IG Parser employs a distinctive syntax that ensures rigorous encoding of natural language, while automating the transformation into various formats that support the downstream analysis using diverse analytical techniques. The conceptual core of the IG Parser is an associated syntax, IG Script, that operationalizes the conceptual foundations of the Institutional Grammar, and more specifically Institutional Grammar 2.0, an analytical paradigm for institutional analysis. This article presents the IG Parser, including its conceptual foundations, syntactic specification of IG Script, alongside architectural principles. This introduction is augmented with selective illustrative examples that highlight the use and benefit associated with the tool.","authors":["Christopher K. Frantz"],"url":"https://arxiv.org/abs/2505.13393"}
{"created":"2025-05-20","title":"Learning by solving differential equations","abstract":"Modern deep learning algorithms use variations of gradient descent as their main learning methods. Gradient descent can be understood as the simplest Ordinary Differential Equation (ODE) solver; namely, the Euler method applied to the gradient flow differential equation. Since Euler, many ODE solvers have been devised that follow the gradient flow equation more precisely and more stably. Runge-Kutta (RK) methods provide a family of very powerful explicit and implicit high-order ODE solvers. However, these higher-order solvers have not found wide application in deep learning so far. In this work, we evaluate the performance of higher-order RK solvers when applied in deep learning, study their limitations, and propose ways to overcome these drawbacks. In particular, we explore how to improve their performance by naturally incorporating key ingredients of modern neural network optimizers such as preconditioning, adaptive learning rates, and momentum.","authors":["Benoit Dherin","Michael Munn","Hanna Mazzawi","Michael Wunder","Sourabh Medapati","Javier Gonzalvo"],"url":"https://arxiv.org/abs/2505.13397"}
{"created":"2025-05-20","title":"A Minimum Description Length Approach to Regularization in Neural Networks","abstract":"State-of-the-art neural networks can be trained to become remarkable solutions to many problems. But while these architectures can express symbolic, perfect solutions, trained models often arrive at approximations instead. We show that the choice of regularization method plays a crucial role: when trained on formal languages with standard regularization ($L_1$, $L_2$, or none), expressive architectures not only fail to converge to correct solutions but are actively pushed away from perfect initializations. In contrast, applying the Minimum Description Length (MDL) principle to balance model complexity with data fit provides a theoretically grounded regularization method. Using MDL, perfect solutions are selected over approximations, independently of the optimization algorithm. We propose that unlike existing regularization techniques, MDL introduces the appropriate inductive bias to effectively counteract overfitting and promote generalization.","authors":["Matan Abudy","Orr Well","Emmanuel Chemla","Roni Katzir","Nur Lan"],"url":"https://arxiv.org/abs/2505.13398"}
{"created":"2025-05-20","title":"Robin: A multi-agent system for automating scientific discovery","abstract":"Scientific discovery is driven by the iterative process of background research, hypothesis generation, experimentation, and data analysis. Despite recent advancements in applying artificial intelligence to scientific discovery, no system has yet automated all of these stages in a single workflow. Here, we introduce Robin, the first multi-agent system capable of fully automating the key intellectual steps of the scientific process. By integrating literature search agents with data analysis agents, Robin can generate hypotheses, propose experiments, interpret experimental results, and generate updated hypotheses, achieving a semi-autonomous approach to scientific discovery. By applying this system, we were able to identify a novel treatment for dry age-related macular degeneration (dAMD), the major cause of blindness in the developed world. Robin proposed enhancing retinal pigment epithelium phagocytosis as a therapeutic strategy, and identified and validated a promising therapeutic candidate, ripasudil. Ripasudil is a clinically-used rho kinase (ROCK) inhibitor that has never previously been proposed for treating dAMD. To elucidate the mechanism of ripasudil-induced upregulation of phagocytosis, Robin then proposed and analyzed a follow-up RNA-seq experiment, which revealed upregulation of ABCA1, a critical lipid efflux pump and possible novel target. All hypotheses, experimental plans, data analyses, and data figures in the main text of this report were produced by Robin. As the first AI system to autonomously discover and validate a novel therapeutic candidate within an iterative lab-in-the-loop framework, Robin establishes a new paradigm for AI-driven scientific discovery.","authors":["Ali Essam Ghareeb","Benjamin Chang","Ludovico Mitchener","Angela Yiu","Caralyn J. Szostkiewicz","Jon M. Laurent","Muhammed T. Razzak","Andrew D. White","Michaela M. Hinks","Samuel G. Rodriques"],"url":"https://arxiv.org/abs/2505.13400"}
{"created":"2025-05-20","title":"MR. Judge: Multimodal Reasoner as a Judge","abstract":"The paradigm of using Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) as evaluative judges has emerged as an effective approach in RLHF and inference-time scaling. In this work, we propose Multimodal Reasoner as a Judge (MR. Judge), a paradigm for empowering general-purpose MLLMs judges with strong reasoning capabilities. Instead of directly assigning scores for each response, we formulate the judgement process as a reasoning-inspired multiple-choice problem. Specifically, the judge model first conducts deliberate reasoning covering different aspects of the responses and eventually selects the best response from them. This reasoning process not only improves the interpretibility of the judgement, but also greatly enhances the performance of MLLM judges. To cope with the lack of questions with scored responses, we propose the following strategy to achieve automatic annotation: 1) Reverse Response Candidates Synthesis: starting from a supervised fine-tuning (SFT) dataset, we treat the original response as the best candidate and prompt the MLLM to generate plausible but flawed negative candidates. 2) Text-based reasoning extraction: we carefully design a data synthesis pipeline for distilling the reasoning capability from a text-based reasoning model, which is adopted to enable the MLLM judges to regain complex reasoning ability via warm up supervised fine-tuning. Experiments demonstrate that our MR. Judge is effective across a wide range of tasks. Specifically, our MR. Judge-7B surpasses GPT-4o by 9.9% on VL-RewardBench, and improves performance on MM-Vet during inference-time scaling by up to 7.7%.","authors":["Renjie Pi","Felix Bai","Qibin Chen","Simon Wang","Jiulong Shan","Kieran Liu","Meng Cao"],"url":"https://arxiv.org/abs/2505.13403"}
{"created":"2025-05-20","title":"Granary: Speech Recognition and Translation Dataset in 25 European Languages","abstract":"Multi-task and multilingual approaches benefit large models, yet speech processing for low-resource languages remains underexplored due to data scarcity. To address this, we present Granary, a large-scale collection of speech datasets for recognition and translation across 25 European languages. This is the first open-source effort at this scale for both transcription and translation. We enhance data quality using a pseudo-labeling pipeline with segmentation, two-pass inference, hallucination filtering, and punctuation restoration. We further generate translation pairs from pseudo-labeled transcriptions using EuroLLM, followed by a data filtration pipeline. Designed for efficiency, our pipeline processes vast amount of data within hours. We assess models trained on processed data by comparing their performance on previously curated datasets for both high- and low-resource languages. Our findings show that these models achieve similar performance using approx. 50% less data. Dataset will be made available at https://hf.co/datasets/nvidia/Granary","authors":["Nithin Rao Koluguri","Monica Sekoyan","George Zelenfroynd","Sasha Meister","Shuoyang Ding","Sofia Kostandian","He Huang","Nikolay Karpov","Jagadeesh Balam","Vitaly Lavrukhin","Yifan Peng","Sara Papi","Marco Gaido","Alessio Brutti","Boris Ginsburg"],"url":"https://arxiv.org/abs/2505.13404"}
{"created":"2025-05-20","title":"A Dataless Reinforcement Learning Approach to Rounding Hyperplane Optimization for Max-Cut","abstract":"The Maximum Cut (MaxCut) problem is NP-Complete, and obtaining its optimal solution is NP-hard in the worst case. As a result, heuristic-based algorithms are commonly used, though their design often requires significant domain expertise. More recently, learning-based methods trained on large (un)labeled datasets have been proposed; however, these approaches often struggle with generalizability and scalability. A well-known approximation algorithm for MaxCut is the Goemans-Williamson (GW) algorithm, which relaxes the Quadratic Unconstrained Binary Optimization (QUBO) formulation into a semidefinite program (SDP). The GW algorithm then applies hyperplane rounding by uniformly sampling a random hyperplane to convert the SDP solution into binary node assignments. In this paper, we propose a training-data-free approach based on a non-episodic reinforcement learning formulation, in which an agent learns to select improved rounding hyperplanes that yield better cuts than those produced by the GW algorithm. By optimizing over a Markov Decision Process (MDP), our method consistently achieves better cuts across large-scale graphs with varying densities and degree distributions.","authors":["Gabriel Malikal","Ismail Alkhouri","Alvaro Velasquez","Adam M Alessio","Saiprasad Ravishankar"],"url":"https://arxiv.org/abs/2505.13405"}
{"created":"2025-05-20","title":"AutoMathKG: The automated mathematical knowledge graph based on LLM and vector database","abstract":"A mathematical knowledge graph (KG) presents knowledge within the field of mathematics in a structured manner. Constructing a math KG using natural language is an essential but challenging task. There are two major limitations of existing works: first, they are constrained by corpus completeness, often discarding or manually supplementing incomplete knowledge; second, they typically fail to fully automate the integration of diverse knowledge sources. This paper proposes AutoMathKG, a high-quality, wide-coverage, and multi-dimensional math KG capable of automatic updates. AutoMathKG regards mathematics as a vast directed graph composed of Definition, Theorem, and Problem entities, with their reference relationships as edges. It integrates knowledge from ProofWiki, textbooks, arXiv papers, and TheoremQA, enhancing entities and relationships with large language models (LLMs) via in-context learning for data augmentation. To search for similar entities, MathVD, a vector database, is built through two designed embedding strategies using SBERT. To automatically update, two mechanisms are proposed. For knowledge completion mechanism, Math LLM is developed to interact with AutoMathKG, providing missing proofs or solutions. For knowledge fusion mechanism, MathVD is used to retrieve similar entities, and LLM is used to determine whether to merge with a candidate or add as a new entity. A wide range of experiments demonstrate the advanced performance and broad applicability of the AutoMathKG system, including superior reachability query results in MathVD compared to five baselines and robust mathematical reasoning capability in Math LLM.","authors":["Rong Bian","Yu Geng","Zijian Yang","Bing Cheng"],"url":"https://arxiv.org/abs/2505.13406"}
{"created":"2025-05-20","title":"CoT-Kinetics: A Theoretical Modeling Assessing LRM Reasoning Process","abstract":"Recent Large Reasoning Models significantly improve the reasoning ability of Large Language Models by learning to reason, exhibiting the promising performance in solving complex tasks. LRMs solve tasks that require complex reasoning by explicitly generating reasoning trajectories together with answers. Nevertheless, judging the quality of such an output answer is not easy because only considering the correctness of the answer is not enough and the soundness of the reasoning trajectory part matters as well. Logically, if the soundness of the reasoning part is poor, even if the answer is correct, the confidence of the derived answer should be low. Existing methods did consider jointly assessing the overall output answer by taking into account the reasoning part, however, their capability is still not satisfactory as the causal relationship of the reasoning to the concluded answer cannot properly reflected. In this paper, inspired by classical mechanics, we present a novel approach towards establishing a CoT-Kinetics energy equation. Specifically, our CoT-Kinetics energy equation formulates the token state transformation process, which is regulated by LRM internal transformer layers, as like a particle kinetics dynamics governed in a mechanical field. Our CoT-Kinetics energy assigns a scalar score to evaluate specifically the soundness of the reasoning phase, telling how confident the derived answer could be given the evaluated reasoning. As such, the LRM's overall output quality can be accurately measured, rather than a coarse judgment (e.g., correct or incorrect) anymore.","authors":["Jinhe Bi","Danqi Yan","Yifan Wang","Wenke Huang","Haokun Chen","Guancheng Wan","Mang Ye","Xun Xiao","Hinrich Schuetze","Volker Tresp","Yunpu Ma"],"url":"https://arxiv.org/abs/2505.13408"}
{"created":"2025-05-20","title":"Recombinant dynamical systems","abstract":"We describe a connectionist model that attempts to capture a notion of experience-based problem solving or task learning, whereby solutions to newly encountered problems are composed from remembered solutions to prior problems. We apply this model to the computational problem of \\emph{efficient sequence generation}, a problem for which there is no obvious gradient descent procedure, and for which not all posable problem instances are solvable. Empirical tests show promising evidence of utility.","authors":["Saul Kato"],"url":"https://arxiv.org/abs/2505.13409"}
{"created":"2025-05-20","title":"Joint Velocity-Growth Flow Matching for Single-Cell Dynamics Modeling","abstract":"Learning the underlying dynamics of single cells from snapshot data has gained increasing attention in scientific and machine learning research. The destructive measurement technique and cell proliferation/death result in unpaired and unbalanced data between snapshots, making the learning of the underlying dynamics challenging. In this paper, we propose joint Velocity-Growth Flow Matching (VGFM), a novel paradigm that jointly learns state transition and mass growth of single-cell populations via flow matching. VGFM builds an ideal single-cell dynamics containing velocity of state and growth of mass, driven by a presented two-period dynamic understanding of the static semi-relaxed optimal transport, a mathematical tool that seeks the coupling between unpaired and unbalanced data. To enable practical usage, we approximate the ideal dynamics using neural networks, forming our joint velocity and growth matching framework. A distribution fitting loss is also employed in VGFM to further improve the fitting performance for snapshot data. Extensive experimental results on both synthetic and real datasets demonstrate that VGFM can capture the underlying biological dynamics accounting for mass and state variations over time, outperforming existing approaches for single-cell dynamics modeling.","authors":["Dongyi Wang","Yuanwei Jiang","Zhenyi Zhang","Xiang Gu","Peijie Zhou","Jian Sun"],"url":"https://arxiv.org/abs/2505.13413"}
{"created":"2025-05-20","title":"Gluon: Making Muon & Scion Great Again! (Bridging Theory and Practice of LMO-based Optimizers for LLMs)","abstract":"Recent developments in deep learning optimization have brought about radically new algorithms based on the Linear Minimization Oracle (LMO) framework, such as $\\sf Muon$ and $\\sf Scion$. After over a decade of $\\sf Adam$'s dominance, these LMO-based methods are emerging as viable replacements, offering several practical advantages such as improved memory efficiency, better hyperparameter transferability, and most importantly, superior empirical performance on large-scale tasks, including LLM training. However, a significant gap remains between their practical use and our current theoretical understanding: prior analyses (1) overlook the layer-wise LMO application of these optimizers in practice, and (2) rely on an unrealistic smoothness assumption, leading to impractically small stepsizes. To address both, we propose a new LMO-based method called $\\sf Gluon$, capturing prior theoretically analyzed methods as special cases, and introduce a new refined generalized smoothness model that captures the layer-wise geometry of neural networks, matches the layer-wise practical implementation of $\\sf Muon$ and $\\sf Scion$, and leads to convergence guarantees with strong practical predictive power. Unlike prior results, our theoretical stepsizes closely match the fine-tuned values reported by Pethick et al. (2025). Our experiments with NanoGPT and CNN confirm that our assumption holds along the optimization trajectory, ultimately closing the gap between theory and practice.","authors":["Artem Riabinin","Egor Shulgin","Kaja Gruntkowska","Peter Richt\\'arik"],"url":"https://arxiv.org/abs/2505.13416"}
{"created":"2025-05-20","title":"AdaptThink: Reasoning Models Can Learn When to Think","abstract":"Recently, large reasoning models have achieved impressive performance on various tasks by employing human-like deep thinking. However, the lengthy thinking process substantially increases inference overhead, making efficiency a critical bottleneck. In this work, we first demonstrate that NoThinking, which prompts the reasoning model to skip thinking and directly generate the final solution, is a better choice for relatively simple tasks in terms of both performance and efficiency. Motivated by this, we propose AdaptThink, a novel RL algorithm to teach reasoning models to choose the optimal thinking mode adaptively based on problem difficulty. Specifically, AdaptThink features two core components: (1) a constrained optimization objective that encourages the model to choose NoThinking while maintaining the overall performance; (2) an importance sampling strategy that balances Thinking and NoThinking samples during on-policy training, thereby enabling cold start and allowing the model to explore and exploit both thinking modes throughout the training process. Our experiments indicate that AdaptThink significantly reduces the inference costs while further enhancing performance. Notably, on three math datasets, AdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B by 53% and improves its accuracy by 2.4%, highlighting the promise of adaptive thinking-mode selection for optimizing the balance between reasoning quality and efficiency. Our codes and models are available at https://github.com/THU-KEG/AdaptThink.","authors":["Jiajie Zhang","Nianyi Lin","Lei Hou","Ling Feng","Juanzi Li"],"url":"https://arxiv.org/abs/2505.13417"}
{"created":"2025-05-20","title":"Dementia Through Different Eyes: Explainable Modeling of Human and LLM Perceptions for Early Awareness","abstract":"Cognitive decline often surfaces in language years before diagnosis. It is frequently non-experts, such as those closest to the patient, who first sense a change and raise concern. As LLMs become integrated into daily communication and used over prolonged periods, it may even be an LLM that notices something is off. But what exactly do they notice--and should be noticing--when making that judgment? This paper investigates how dementia is perceived through language by non-experts. We presented transcribed picture descriptions to non-expert humans and LLMs, asking them to intuitively judge whether each text was produced by someone healthy or with dementia. We introduce an explainable method that uses LLMs to extract high-level, expert-guided features representing these picture descriptions, and use logistic regression to model human and LLM perceptions and compare with clinical diagnoses. Our analysis reveals that human perception of dementia is inconsistent and relies on a narrow, and sometimes misleading, set of cues. LLMs, by contrast, draw on a richer, more nuanced feature set that aligns more closely with clinical patterns. Still, both groups show a tendency toward false negatives, frequently overlooking dementia cases. Through our interpretable framework and the insights it provides, we hope to help non-experts better recognize the linguistic signs that matter.","authors":["Lotem Peled-Cohen","Maya Zadok","Nitay Calderon","Hila Gonen","Roi Reichart"],"url":"https://arxiv.org/abs/2505.13418"}
{"created":"2025-05-20","title":"FEALLM: Advancing Facial Emotion Analysis in Multimodal Large Language Models with Emotional Synergy and Reasoning","abstract":"Facial Emotion Analysis (FEA) plays a crucial role in visual affective computing, aiming to infer a person's emotional state based on facial data. Scientifically, facial expressions (FEs) result from the coordinated movement of facial muscles, which can be decomposed into specific action units (AUs) that provide detailed emotional insights. However, traditional methods often struggle with limited interpretability, constrained generalization and reasoning abilities. Recently, Multimodal Large Language Models (MLLMs) have shown exceptional performance in various visual tasks, while they still face significant challenges in FEA due to the lack of specialized datasets and their inability to capture the intricate relationships between FEs and AUs. To address these issues, we introduce a novel FEA Instruction Dataset that provides accurate and aligned FE and AU descriptions and establishes causal reasoning relationships between them, followed by constructing a new benchmark, FEABench. Moreover, we propose FEALLM, a novel MLLM architecture designed to capture more detailed facial information, enhancing its capability in FEA tasks. Our model demonstrates strong performance on FEABench and impressive generalization capability through zero-shot evaluation on various datasets, including RAF-DB, AffectNet, BP4D, and DISFA, showcasing its robustness and effectiveness in FEA tasks. The dataset and code will be available at https://github.com/953206211/FEALLM.","authors":["Zhuozhao Hu","Kaishen Yuan","Xin Liu","Zitong Yu","Yuan Zong","Jingang Shi","Huanjing Yue","Jingyu Yang"],"url":"https://arxiv.org/abs/2505.13419"}
{"created":"2025-05-20","title":"Make Still Further Progress: Chain of Thoughts for Tabular Data Leaderboard","abstract":"Tabular data, a fundamental data format in machine learning, is predominantly utilized in competitions and real-world applications. The performance of tabular models--such as gradient boosted decision trees and neural networks--can vary significantly across datasets due to differences in feature distributions and task characteristics. Achieving top performance on each dataset often requires specialized expert knowledge. To address this variability, practitioners often aggregate the predictions of multiple models. However, conventional aggregation strategies typically rely on static combination rules and lack instance-level adaptability. In this work, we propose an in-context ensemble framework for tabular prediction that leverages large language models (LLMs) to perform dynamic, instance-specific integration of external model predictions. Without access to raw tabular features or semantic information, our method constructs a context around each test instance using its nearest neighbors and the predictions from a pool of external models. Within this enriched context, we introduce Chain of Tabular Thoughts (CoT$^2$), a prompting strategy that guides LLMs through multi-step, interpretable reasoning, making still further progress toward expert-level decision-making. Experimental results show that our method outperforms well-tuned baselines and standard ensemble techniques across a wide range of tabular datasets.","authors":["Si-Yang Liu","Qile Zhou","Han-Jia Ye"],"url":"https://arxiv.org/abs/2505.13421"}
{"created":"2025-05-20","title":"Learnware of Language Models: Specialized Small Language Models Can Do Big","abstract":"The learnware paradigm offers a novel approach to machine learning by enabling users to reuse a set of well-trained models for tasks beyond the models' original purposes. It eliminates the need to build models from scratch, instead relying on specifications (representations of a model's capabilities) to identify and leverage the most suitable models for new tasks. While learnware has proven effective in many scenarios, its application to language models has remained largely unexplored. At the same time, large language models (LLMs) have demonstrated remarkable universal question-answering abilities, yet they face challenges in specialized scenarios due to data scarcity, privacy concerns, and high computational costs, thus more and more specialized small language models (SLMs) are being trained for specific domains. To address these limitations systematically, the learnware paradigm provides a promising solution by enabling maximum utilization of specialized SLMs, and allowing users to identify and reuse them in a collaborative and privacy-preserving manner.","authors":["Zhi-Hao Tan","Zi-Chen Zhao","Hao-Yu Shi","Xin-Yu Zhang","Peng Tan","Yang Yu","Zhi-Hua Zhou"],"url":"https://arxiv.org/abs/2505.13425"}
{"created":"2025-05-20","title":"G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language Model via Reinforcement Learning","abstract":"Vision-Language Models (VLMs) excel in many direct multimodal tasks but struggle to translate this prowess into effective decision-making within interactive, visually rich environments like games. This ``knowing-doing'' gap significantly limits their potential as autonomous agents, as leading VLMs often performing badly in simple games. To address this, we introduce VLM-Gym, a curated reinforcement learning (RL) environment featuring diverse visual games with unified interfaces and adjustable, compositional difficulty, specifically designed for scalable multi-game parallel training. Leveraging VLM-Gym, we train G0 models using pure RL-driven self-evolution, which demonstrate emergent perception and reasoning patterns. To further mitigate challenges arising from game diversity, we develop G1 models. G1 incorporates a perception-enhanced cold start prior to RL fine-tuning. Our resulting G1 models consistently surpass their teacher across all games and outperform leading proprietary models like Claude-3.7-Sonnet-Thinking. Systematic analysis reveals an intriguing finding: perception and reasoning abilities mutually bootstrap each other throughout the RL training process. Source code including VLM-Gym and RL training are released at https://github.com/chenllliang/G1 to foster future research in advancing VLMs as capable interactive agents.","authors":["Liang Chen","Hongcheng Gao","Tianyu Liu","Zhiqi Huang","Flood Sung","Xinyu Zhou","Yuxin Wu","Baobao Chang"],"url":"https://arxiv.org/abs/2505.13426"}
{"created":"2025-05-20","title":"MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision","abstract":"While Multimodal Large Language Models (MLLMs) have achieved impressive progress in vision-language understanding, they still struggle with complex multi-step reasoning, often producing logically inconsistent or partially correct solutions. A key limitation lies in the lack of fine-grained supervision over intermediate reasoning steps. To address this, we propose MM-PRM, a process reward model trained within a fully automated, scalable framework. We first build MM-Policy, a strong multimodal model trained on diverse mathematical reasoning data. Then, we construct MM-K12, a curated dataset of 10,000 multimodal math problems with verifiable answers, which serves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based pipeline, we generate over 700k step-level annotations without human labeling. The resulting PRM is used to score candidate reasoning paths in the Best-of-N inference setup and achieves significant improvements across both in-domain (MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.) benchmarks. Further analysis confirms the effectiveness of soft labels, smaller learning rates, and path diversity in optimizing PRM performance. MM-PRM demonstrates that process supervision is a powerful tool for enhancing the logical robustness of multimodal reasoning systems. We release all our codes and data at https://github.com/ModalMinds/MM-PRM.","authors":["Lingxiao Du","Fanqing Meng","Zongkai Liu","Zhixiang Zhou","Ping Luo","Qiaosheng Zhang","Wenqi Shao"],"url":"https://arxiv.org/abs/2505.13427"}
{"created":"2025-05-20","title":"Meta-rotations and the Structure of Stable Matchings in the Student Project Allocation Problem","abstract":"We formally introduce and present the concept of meta-rotations as a tool for navigating the lattice of stable matchings in the Student Project Allocation problem with lecturer preferences over students (SPA-S). Building on the structural result that the set of stable matchings in any SPA-S instance forms a distributive lattice, we define meta-rotations for this setting and demonstrate how they compactly encode transitions between matchings. Our framework generalises the classical notion of rotations in bipartite settings and provides a systematic way to traverse the lattice, thereby enabling efficient enumeration of the set of stable matchings in any given SPA-S instance.","authors":["Peace Ayegba","Sofiat Olaosebikan","David Manlove"],"url":"https://arxiv.org/abs/2505.13428"}
{"created":"2025-05-20","title":"Understanding Complexity in VideoQA via Visual Program Generation","abstract":"We propose a data-driven approach to analyzing query complexity in Video Question Answering (VideoQA). Previous efforts in benchmark design have relied on human expertise to design challenging questions, yet we experimentally show that humans struggle to predict which questions are difficult for machine learning models. Our automatic approach leverages recent advances in code generation for visual question answering, using the complexity of generated code as a proxy for question difficulty. We demonstrate that this measure correlates significantly better with model performance than human estimates. To operationalize this insight, we propose an algorithm for estimating question complexity from code. It identifies fine-grained primitives that correlate with the hardest questions for any given set of models, making it easy to scale to new approaches in the future. Finally, to further illustrate the utility of our method, we extend it to automatically generate complex questions, constructing a new benchmark that is 1.9 times harder than the popular NExT-QA.","authors":["Cristobal Eyzaguirre","Igor Vasiljevic","Achal Dave","Jiajun Wu","Rares Andrei Ambrus","Thomas Kollar","Juan Carlos Niebles","Pavel Tokmakov"],"url":"https://arxiv.org/abs/2505.13429"}
{"created":"2025-05-20","title":"Fine-tuning Quantized Neural Networks with Zeroth-order Optimization","abstract":"As the size of large language models grows exponentially, GPU memory has become a bottleneck for adapting these models to downstream tasks. In this paper, we aim to push the limits of memory-efficient training by minimizing memory usage on model weights, gradients, and optimizer states, within a unified framework. Our idea is to eliminate both gradients and optimizer states using zeroth-order optimization, which approximates gradients by perturbing weights during forward passes to identify gradient directions. To minimize memory usage on weights, we employ model quantization, e.g., converting from bfloat16 to int4. However, directly applying zeroth-order optimization to quantized weights is infeasible due to the precision gap between discrete weights and continuous gradients, which would otherwise require de-quantization and re-quantization. To overcome this challenge, we propose Quantized Zeroth-order Optimization (QZO), a novel approach that perturbs the continuous quantization scale for gradient estimation and uses a directional derivative clipping method to stabilize training. QZO is orthogonal to both scalar-based and codebook-based post-training quantization methods. Compared to full-parameter fine-tuning in bfloat16, QZO can reduce the total memory cost by more than 18$\\times$ for 4-bit LLMs, and enables fine-tuning Llama-2-13B and Stable Diffusion 3.5 Large within a single 24GB GPU.","authors":["Sifeng Shang","Jiayi Zhou","Chenyu Lin","Minxian Li","Kaiyang Zhou"],"url":"https://arxiv.org/abs/2505.13430"}
{"created":"2025-05-20","title":"A Practical Guide for Incorporating Symmetry in Diffusion Policy","abstract":"Recently, equivariant neural networks for policy learning have shown promising improvements in sample efficiency and generalization, however, their wide adoption faces substantial barriers due to implementation complexity. Equivariant architectures typically require specialized mathematical formulations and custom network design, posing significant challenges when integrating with modern policy frameworks like diffusion-based models. In this paper, we explore a number of straightforward and practical approaches to incorporate symmetry benefits into diffusion policies without the overhead of full equivariant designs. Specifically, we investigate (i) invariant representations via relative trajectory actions and eye-in-hand perception, (ii) integrating equivariant vision encoders, and (iii) symmetric feature extraction with pretrained encoders using Frame Averaging. We first prove that combining eye-in-hand perception with relative or delta action parameterization yields inherent SE(3)-invariance, thus improving policy generalization. We then perform a systematic experimental study on those design choices for integrating symmetry in diffusion policies, and conclude that an invariant representation with equivariant feature extraction significantly improves the policy performance. Our method achieves performance on par with or exceeding fully equivariant architectures while greatly simplifying implementation.","authors":["Dian Wang","Boce Hu","Shuran Song","Robin Walters","Robert Platt"],"url":"https://arxiv.org/abs/2505.13431"}
{"created":"2025-05-20","title":"Synthetic-Powered Predictive Inference","abstract":"Conformal prediction is a framework for predictive inference with a distribution-free, finite-sample guarantee. However, it tends to provide uninformative prediction sets when calibration data are scarce. This paper introduces Synthetic-powered predictive inference (SPPI), a novel framework that incorporates synthetic data -- e.g., from a generative model -- to improve sample efficiency. At the core of our method is a score transporter: an empirical quantile mapping that aligns nonconformity scores from trusted, real data with those from synthetic data. By carefully integrating the score transporter into the calibration process, SPPI provably achieves finite-sample coverage guarantees without making any assumptions about the real and synthetic data distributions. When the score distributions are well aligned, SPPI yields substantially tighter and more informative prediction sets than standard conformal prediction. Experiments on image classification and tabular regression demonstrate notable improvements in predictive efficiency in data-scarce settings.","authors":["Meshi Bashari","Roy Maor Lotan","Yonghoon Lee","Edgar Dobriban","Yaniv Romano"],"url":"https://arxiv.org/abs/2505.13432"}
{"created":"2025-05-20","title":"SMOTExT: SMOTE meets Large Language Models","abstract":"Data scarcity and class imbalance are persistent challenges in training robust NLP models, especially in specialized domains or low-resource settings. We propose a novel technique, SMOTExT, that adapts the idea of Synthetic Minority Over-sampling (SMOTE) to textual data. Our method generates new synthetic examples by interpolating between BERT-based embeddings of two existing examples and then decoding the resulting latent point into text with xRAG architecture. By leveraging xRAG's cross-modal retrieval-generation framework, we can effectively turn interpolated vectors into coherent text. While this is preliminary work supported by qualitative outputs only, the method shows strong potential for knowledge distillation and data augmentation in few-shot settings. Notably, our approach also shows promise for privacy-preserving machine learning: in early experiments, training models solely on generated data achieved comparable performance to models trained on the original dataset. This suggests a viable path toward safe and effective learning under data protection constraints.","authors":["Mateusz Bystro\\'nski","Miko{\\l}aj Ho{\\l}ysz","Grzegorz Piotrowski","Nitesh V. Chawla","Tomasz Kajdanowicz"],"url":"https://arxiv.org/abs/2505.13434"}
{"created":"2025-05-20","title":"KinTwin: Imitation Learning with Torque and Muscle Driven Biomechanical Models Enables Precise Replication of Able-Bodied and Impaired Movement from Markerless Motion Capture","abstract":"Broader access to high-quality movement analysis could greatly benefit movement science and rehabilitation, such as allowing more detailed characterization of movement impairments and responses to interventions, or even enabling early detection of new neurological conditions or fall risk. While emerging technologies are making it easier to capture kinematics with biomechanical models, or how joint angles change over time, inferring the underlying physics that give rise to these movements, including ground reaction forces, joint torques, or even muscle activations, is still challenging. Here we explore whether imitation learning applied to a biomechanical model from a large dataset of movements from able-bodied and impaired individuals can learn to compute these inverse dynamics. Although imitation learning in human pose estimation has seen great interest in recent years, our work differences in several ways: we focus on using an accurate biomechanical model instead of models adopted for computer vision, we test it on a dataset that contains participants with impaired movements, we reported detailed tracking metrics relevant for the clinical measurement of movement including joint angles and ground contact events, and finally we apply imitation learning to a muscle-driven neuromusculoskeletal model. We show that our imitation learning policy, KinTwin, can accurately replicate the kinematics of a wide range of movements, including those with assistive devices or therapist assistance, and that it can infer clinically meaningful differences in joint torques and muscle activations. Our work demonstrates the potential for using imitation learning to enable high-quality movement analysis in clinical practice.","authors":["R. James Cotton"],"url":"https://arxiv.org/abs/2505.13436"}
{"created":"2025-05-20","title":"FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance","abstract":"Despite significant advances in video generation, synthesizing physically plausible human actions remains a persistent challenge, particularly in modeling fine-grained semantics and complex temporal dynamics. For instance, generating gymnastics routines such as \"switch leap with 0.5 turn\" poses substantial difficulties for current methods, often yielding unsatisfactory results. To bridge this gap, we propose FinePhys, a Fine-grained human action generation framework that incorporates Physics to obtain effective skeletal guidance. Specifically, FinePhys first estimates 2D poses in an online manner and then performs 2D-to-3D dimension lifting via in-context learning. To mitigate the instability and limited interpretability of purely data-driven 3D poses, we further introduce a physics-based motion re-estimation module governed by Euler-Lagrange equations, calculating joint accelerations via bidirectional temporal updating. The physically predicted 3D poses are then fused with data-driven ones, offering multi-scale 2D heatmap guidance for the diffusion process. Evaluated on three fine-grained action subsets from FineGym (FX-JUMP, FX-TURN, and FX-SALTO), FinePhys significantly outperforms competitive baselines. Comprehensive qualitative results further demonstrate FinePhys's ability to generate more natural and plausible fine-grained human actions.","authors":["Dian Shao","Mingfei Shi","Shengda Xu","Haodong Chen","Yongle Huang","Binglu Wang"],"url":"https://arxiv.org/abs/2505.13437"}
{"created":"2025-05-20","title":"Optimizing Anytime Reasoning via Budget Relative Policy Optimization","abstract":"Scaling test-time compute is crucial for enhancing the reasoning capabilities of large language models (LLMs). Existing approaches typically employ reinforcement learning (RL) to maximize a verifiable reward obtained at the end of reasoning traces. However, such methods optimize only the final performance under a large and fixed token budget, which hinders efficiency in both training and deployment. In this work, we present a novel framework, AnytimeReasoner, to optimize anytime reasoning performance, which aims to improve token efficiency and the flexibility of reasoning under varying token budget constraints. To achieve this, we truncate the complete thinking process to fit within sampled token budgets from a prior distribution, compelling the model to summarize the optimal answer for each truncated thinking for verification. This introduces verifiable dense rewards into the reasoning process, facilitating more effective credit assignment in RL optimization. We then optimize the thinking and summary policies in a decoupled manner to maximize the cumulative reward. Additionally, we introduce a novel variance reduction technique, Budget Relative Policy Optimization (BRPO), to enhance the robustness and efficiency of the learning process when reinforcing the thinking policy. Empirical results in mathematical reasoning tasks demonstrate that our method consistently outperforms GRPO across all thinking budgets under various prior distributions, enhancing both training and token efficiency.","authors":["Penghui Qi","Zichen Liu","Tianyu Pang","Chao Du","Wee Sun Lee","Min Lin"],"url":"https://arxiv.org/abs/2505.13438"}
{"created":"2025-05-20","title":"VTBench: Evaluating Visual Tokenizers for Autoregressive Image Generation","abstract":"Autoregressive (AR) models have recently shown strong performance in image generation, where a critical component is the visual tokenizer (VT) that maps continuous pixel inputs to discrete token sequences. The quality of the VT largely defines the upper bound of AR model performance. However, current discrete VTs fall significantly behind continuous variational autoencoders (VAEs), leading to degraded image reconstructions and poor preservation of details and text. Existing benchmarks focus on end-to-end generation quality, without isolating VT performance. To address this gap, we introduce VTBench, a comprehensive benchmark that systematically evaluates VTs across three core tasks: Image Reconstruction, Detail Preservation, and Text Preservation, and covers a diverse range of evaluation scenarios. We systematically assess state-of-the-art VTs using a set of metrics to evaluate the quality of reconstructed images. Our findings reveal that continuous VAEs produce superior visual representations compared to discrete VTs, particularly in retaining spatial structure and semantic detail. In contrast, the degraded representations produced by discrete VTs often lead to distorted reconstructions, loss of fine-grained textures, and failures in preserving text and object integrity. Furthermore, we conduct experiments on GPT-4o image generation and discuss its potential AR nature, offering new insights into the role of visual tokenization. We release our benchmark and codebase publicly to support further research and call on the community to develop strong, general-purpose open-source VTs.","authors":["Huawei Lin","Tong Geng","Zhaozhuo Xu","Weijie Zhao"],"url":"https://arxiv.org/abs/2505.13439"}
{"created":"2025-05-20","title":"Recollection from Pensieve: Novel View Synthesis via Learning from Uncalibrated Videos","abstract":"Currently almost all state-of-the-art novel view synthesis and reconstruction models rely on calibrated cameras or additional geometric priors for training. These prerequisites significantly limit their applicability to massive uncalibrated data. To alleviate this requirement and unlock the potential for self-supervised training on large-scale uncalibrated videos, we propose a novel two-stage strategy to train a view synthesis model from only raw video frames or multi-view images, without providing camera parameters or other priors. In the first stage, we learn to reconstruct the scene implicitly in a latent space without relying on any explicit 3D representation. Specifically, we predict per-frame latent camera and scene context features, and employ a view synthesis model as a proxy for explicit rendering. This pretraining stage substantially reduces the optimization complexity and encourages the network to learn the underlying 3D consistency in a self-supervised manner. The learned latent camera and implicit scene representation have a large gap compared with the real 3D world. To reduce this gap, we introduce the second stage training by explicitly predicting 3D Gaussian primitives. We additionally apply explicit Gaussian Splatting rendering loss and depth projection loss to align the learned latent representations with physically grounded 3D geometry. In this way, Stage 1 provides a strong initialization and Stage 2 enforces 3D consistency - the two stages are complementary and mutually beneficial. Extensive experiments demonstrate the effectiveness of our approach, achieving high-quality novel view synthesis and accurate camera pose estimation, compared to methods that employ supervision with calibration, pose, or depth information. The code is available at https://github.com/Dwawayu/Pensieve.","authors":["Ruoyu Wang","Yi Ma","Shenghua Gao"],"url":"https://arxiv.org/abs/2505.13440"}
{"created":"2025-05-20","title":"GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation","abstract":"We present GrasMolmo, a generalizable open-vocabulary task-oriented grasping (TOG) model. GraspMolmo predicts semantically appropriate, stable grasps conditioned on a natural language instruction and a single RGB-D frame. For instance, given \"pour me some tea\", GraspMolmo selects a grasp on a teapot handle rather than its body. Unlike prior TOG methods, which are limited by small datasets, simplistic language, and uncluttered scenes, GraspMolmo learns from PRISM, a novel large-scale synthetic dataset of 379k samples featuring cluttered environments and diverse, realistic task descriptions. We fine-tune the Molmo visual-language model on this data, enabling GraspMolmo to generalize to novel open-vocabulary instructions and objects. In challenging real-world evaluations, GraspMolmo achieves state-of-the-art results, with a 70% prediction success on complex tasks, compared to the 35% achieved by the next best alternative. GraspMolmo also successfully demonstrates the ability to predict semantically correct bimanual grasps zero-shot. We release our synthetic dataset, code, model, and benchmarks to accelerate research in task-semantic robotic manipulation, which, along with videos, are available at https://abhaybd.github.io/GraspMolmo/.","authors":["Abhay Deshpande","Yuquan Deng","Arijit Ray","Jordi Salvador","Winson Han","Jiafei Duan","Kuo-Hao Zeng","Yuke Zhu","Ranjay Krishna","Rose Hendrix"],"url":"https://arxiv.org/abs/2505.13441"}
{"created":"2025-05-20","title":"ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models","abstract":"Chart understanding presents a unique challenge for large vision-language models (LVLMs), as it requires the integration of sophisticated textual and visual reasoning capabilities. However, current LVLMs exhibit a notable imbalance between these skills, falling short on visual reasoning that is difficult to perform in text. We conduct a case study using a synthetic dataset solvable only through visual reasoning and show that model performance degrades significantly with increasing visual complexity, while human performance remains robust. We then introduce ChartMuseum, a new Chart Question Answering (QA) benchmark containing 1,162 expert-annotated questions spanning multiple reasoning types, curated from real-world charts across 184 sources, specifically built to evaluate complex visual and textual reasoning. Unlike prior chart understanding benchmarks -- where frontier models perform similarly and near saturation -- our benchmark exposes a substantial gap between model and human performance, while effectively differentiating model capabilities: although humans achieve 93% accuracy, the best-performing model Gemini-2.5-Pro attains only 63.0%, and the leading open-source LVLM Qwen2.5-VL-72B-Instruct achieves only 38.5%. Moreover, on questions requiring primarily visual reasoning, all models experience a 35%-55% performance drop from text-reasoning-heavy question performance. Lastly, our qualitative error analysis reveals specific categories of visual reasoning that are challenging for current LVLMs.","authors":["Liyan Tang","Grace Kim","Xinyu Zhao","Thom Lake","Wenxuan Ding","Fangcong Yin","Prasann Singhal","Manya Wadhwa","Zeyu Leo Liu","Zayne Sprague","Ramya Namuduri","Bodun Hu","Juan Diego Rodriguez","Puyuan Peng","Greg Durrett"],"url":"https://arxiv.org/abs/2505.13444"}
{"created":"2025-05-20","title":"Trust, But Verify: A Self-Verification Approach to Reinforcement Learning with Verifiable Rewards","abstract":"Large Language Models (LLMs) show great promise in complex reasoning, with Reinforcement Learning with Verifiable Rewards (RLVR) being a key enhancement strategy. However, a prevalent issue is ``superficial self-reflection'', where models fail to robustly verify their own outputs. We introduce RISE (Reinforcing Reasoning with Self-Verification), a novel online RL framework designed to tackle this. RISE explicitly and simultaneously trains an LLM to improve both its problem-solving and self-verification abilities within a single, integrated RL process. The core mechanism involves leveraging verifiable rewards from an outcome verifier to provide on-the-fly feedback for both solution generation and self-verification tasks. In each iteration, the model generates solutions, then critiques its own on-policy generated solutions, with both trajectories contributing to the policy update. Extensive experiments on diverse mathematical reasoning benchmarks show that RISE consistently improves model's problem-solving accuracy while concurrently fostering strong self-verification skills. Our analyses highlight the advantages of online verification and the benefits of increased verification compute. Additionally, RISE models exhibit more frequent and accurate self-verification behaviors during reasoning. These advantages reinforce RISE as a flexible and effective path towards developing more robust and self-aware reasoners.","authors":["Xiaoyuan Liu","Tian Liang","Zhiwei He","Jiahao Xu","Wenxuan Wang","Pinjia He","Zhaopeng Tu","Haitao Mi","Dong Yu"],"url":"https://arxiv.org/abs/2505.13445"}
{"created":"2025-05-20","title":"Unlocking Non-Invasive Brain-to-Text","abstract":"Despite major advances in surgical brain-to-text (B2T), i.e. transcribing speech from invasive brain recordings, non-invasive alternatives have yet to surpass even chance on standard metrics. This remains a barrier to building a non-invasive brain-computer interface (BCI) capable of restoring communication in paralysed individuals without surgery. Here, we present the first non-invasive B2T result that significantly exceeds these critical baselines, raising BLEU by $1.4\\mathrm{-}2.6\\times$ over prior work. This result is driven by three contributions: (1) we extend recent word-classification models with LLM-based rescoring, transforming single-word predictors into closed-vocabulary B2T systems; (2) we introduce a predictive in-filling approach to handle out-of-vocabulary (OOV) words, substantially expanding the effective vocabulary; and (3) we demonstrate, for the first time, how to scale non-invasive B2T models across datasets, unlocking deep learning at scale and improving accuracy by $2.1\\mathrm{-}2.3\\times$. Through these contributions, we offer new insights into the roles of data quality and vocabulary size. Together, our results remove a major obstacle to realising practical non-invasive B2T systems.","authors":["Dulhan Jayalath","Gilad Landau","Oiwi Parker Jones"],"url":"https://arxiv.org/abs/2505.13446"}
{"created":"2025-05-20","title":"Mean Flows for One-step Generative Modeling","abstract":"We propose a principled and effective framework for one-step generative modeling. We introduce the notion of average velocity to characterize flow fields, in contrast to instantaneous velocity modeled by Flow Matching methods. A well-defined identity between average and instantaneous velocities is derived and used to guide neural network training. Our method, termed the MeanFlow model, is self-contained and requires no pre-training, distillation, or curriculum learning. MeanFlow demonstrates strong empirical performance: it achieves an FID of 3.43 with a single function evaluation (1-NFE) on ImageNet 256x256 trained from scratch, significantly outperforming previous state-of-the-art one-step diffusion/flow models. Our study substantially narrows the gap between one-step diffusion/flow models and their multi-step predecessors, and we hope it will motivate future research to revisit the foundations of these powerful models.","authors":["Zhengyang Geng","Mingyang Deng","Xingjian Bai","J. Zico Kolter","Kaiming He"],"url":"https://arxiv.org/abs/2505.13447"}
{"created":"2025-05-20","title":"CIE: Controlling Language Model Text Generations Using Continuous Signals","abstract":"Aligning language models with user intent is becoming increasingly relevant to enhance user experience. This calls for designing methods that can allow users to control the properties of the language that LMs generate. For example, controlling the length of the generation, the complexity of the language that gets chosen, the sentiment, tone, etc. Most existing work attempts to integrate users' control by conditioning LM generations on natural language prompts or discrete control signals, which are often brittle and hard to scale. In this work, we are interested in \\textit{continuous} control signals, ones that exist along a spectrum that can't easily be captured in a natural language prompt or via existing techniques in conditional generation. Through a case study in controlling the precise response-length of generations produced by LMs, we demonstrate how after fine-tuning, behaviors of language models can be controlled via continuous signals -- as vectors that are interpolated between a \"low\" and a \"high\" token embedding. Our method more reliably exerts response-length control than in-context learning methods or fine-tuning methods that represent the control signal as a discrete signal. Our full open-sourced code and datasets are available at https://github.com/vsamuel2003/CIE.","authors":["Vinay Samuel","Harshita Diddee","Yiming Zhang","Daphne Ippolito"],"url":"https://arxiv.org/abs/2505.13448"}
{"created":"2025-05-20","title":"Learning Segment Similarity and Alignment in Large-Scale Content Based Video Retrieval","abstract":"With the explosive growth of web videos in recent years, large-scale Content-Based Video Retrieval (CBVR) becomes increasingly essential in video filtering, recommendation, and copyright protection. Segment-level CBVR (S-CBVR) locates the start and end time of similar segments in finer granularity, which is beneficial for user browsing efficiency and infringement detection especially in long video scenarios. The challenge of S-CBVR task is how to achieve high temporal alignment accuracy with efficient computation and low storage consumption. In this paper, we propose a Segment Similarity and Alignment Network (SSAN) in dealing with the challenge which is firstly trained end-to-end in S-CBVR. SSAN is based on two newly proposed modules in video retrieval: (1) An efficient Self-supervised Keyframe Extraction (SKE) module to reduce redundant frame features, (2) A robust Similarity Pattern Detection (SPD) module for temporal alignment. In comparison with uniform frame extraction, SKE not only saves feature storage and search time, but also introduces comparable accuracy and limited extra computation time. In terms of temporal alignment, SPD localizes similar segments with higher accuracy and efficiency than existing deep learning methods. Furthermore, we jointly train SSAN with SKE and SPD and achieve an end-to-end improvement. Meanwhile, the two key modules SKE and SPD can also be effectively inserted into other video retrieval pipelines and gain considerable performance improvements. Experimental results on public datasets show that SSAN can obtain higher alignment accuracy while saving storage and online query computational cost compared to existing methods.","authors":["Chen Jiang","Kaiming Huang","Sifeng He","Xudong Yang","Wei Zhang","Xiaobo Zhang","Yuan Cheng","Lei Yang","Qing Wang","Furong Xu","Tan Pan","Wei Chu"],"url":"https://arxiv.org/abs/2309.11091"}
{"created":"2025-05-20","title":"OmniDrones: An Efficient and Flexible Platform for Reinforcement Learning in Drone Control","abstract":"In this work, we introduce OmniDrones, an efficient and flexible platform tailored for reinforcement learning in drone control, built on Nvidia's Omniverse Isaac Sim. It employs a bottom-up design approach that allows users to easily design and experiment with various application scenarios on top of GPU-parallelized simulations. It also offers a range of benchmark tasks, presenting challenges ranging from single-drone hovering to over-actuated system tracking. In summary, we propose an open-sourced drone simulation platform, equipped with an extensive suite of tools for drone learning. It includes 4 drone models, 5 sensor modalities, 4 control modes, over 10 benchmark tasks, and a selection of widely used RL baselines. To showcase the capabilities of OmniDrones and to support future research, we also provide preliminary results on these benchmark tasks. We hope this platform will encourage further studies on applying RL to practical drone systems.","authors":["Botian Xu","Feng Gao","Chao Yu","Ruize Zhang","Yi Wu","Yu Wang"],"url":"https://arxiv.org/abs/2309.12825"}
{"created":"2025-05-20","title":"Knowledge-enhanced Multi-perspective Video Representation Learning for Scene Recognition","abstract":"With the explosive growth of video data in real-world applications, a comprehensive representation of videos becomes increasingly important. In this paper, we address the problem of video scene recognition, whose goal is to learn a high-level video representation to classify scenes in videos. Due to the diversity and complexity of video contents in realistic scenarios, this task remains a challenge. Most existing works identify scenes for videos only from visual or textual information in a temporal perspective, ignoring the valuable information hidden in single frames, while several earlier studies only recognize scenes for separate images in a non-temporal perspective. We argue that these two perspectives are both meaningful for this task and complementary to each other, meanwhile, externally introduced knowledge can also promote the comprehension of videos. We propose a novel two-stream framework to model video representations from multiple perspectives, i.e. temporal and non-temporal perspectives, and integrate the two perspectives in an end-to-end manner by self-distillation. Besides, we design a knowledge-enhanced feature fusion and label prediction method that contributes to naturally introducing knowledge into the task of video scene recognition. Experiments conducted on a real-world dataset demonstrate the effectiveness of our proposed method.","authors":["Xuzheng Yu","Chen Jiang","Wei Zhang","Tian Gan","Linlin Chao","Jianan Zhao","Yuan Cheng","Qingpei Guo","Wei Chu"],"url":"https://arxiv.org/abs/2401.04354"}
{"created":"2025-05-20","title":"Post-Post-API Age: Studying Digital Platforms in Scant Data Access Times","abstract":"Over the past decade, data provided by digital platforms has informed substantial research in HCI to understand online human interaction and communication. Following the closure of major social media APIs that previously provided free access to large-scale data (the \"post-API age\"), emerging data access programs required by the European Union's Digital Services Act (DSA) have sparked optimism about increased platform transparency and renewed opportunities for comprehensive research on digital platforms, leading to the \"post-post-API age.\" However, it remains unclear whether platforms provide adequate data access in practice. To assess how platforms make data available under the DSA, we conducted a comprehensive survey followed by in-depth interviews with 19 researchers to understand their experiences with data access in this new era. Our findings reveal significant challenges in accessing social media data, with researchers facing multiple barriers including complex API application processes, difficulties obtaining credentials, and limited API usability. These challenges have exacerbated existing institutional, regional, and financial inequities in data access. Based on these insights, we provide actionable recommendations for platforms, researchers, and policymakers to foster more equitable and effective data access, while encouraging broader dialogue within the CSCW community around interdisciplinary and multi-stakeholder solutions.","authors":["Kayo Mimizuka","Megan A Brown","Kai-Cheng Yang","Josephine Lukito"],"url":"https://arxiv.org/abs/2505.09877"}
{"created":"2025-05-20","title":"The Impact and Influence of Academic Genealogies","abstract":"We introduce the concept of an academic genealogy, or AG, and illustrate how AG charts may be constructed and then demonstrate how this methodology can be used by applying it to create the partial or full AG charts to two scientists, Paul A. Samuelson and Ronald E. Mickens.","authors":["Bryan Briones","Ronald E. Mickens","Charmayne Patterson"],"url":"https://arxiv.org/abs/2505.11503"}
{"created":"2025-05-20","title":"Grid Topology Estimation using an Information Theoretic Approach","abstract":"The topology of a power grid is estimated using an information theoretic approach. By modeling the grid as a graph and using voltage magnitude data of individual nodes in the grid, the mutual information between pairs of nodes is computed using different approximation methods. Using the well-known Chow-Liu algorithm, a maximum spanning tree based on mutual information is computed to estimate the power grid topology. Experiments and results are presented to optimize this approach with success shown for IEEE networks generated with MATPOWER and data generated using GridLAB-D. The algorithm is then cross-validated on IEEE networks generated by the European Union Joint Research Council.","authors":["Daniel T. Speckhard"],"url":"https://arxiv.org/abs/2505.11517"}
{"created":"2025-05-20","title":"Deep Unrolled Meta-Learning for Multi-Coil and Multi-Modality MRI with Adaptive Optimization","abstract":"We propose a unified deep meta-learning framework for accelerated magnetic resonance imaging (MRI) that jointly addresses multi-coil reconstruction and cross-modality synthesis. Motivated by the limitations of conventional methods in handling undersampled data and missing modalities, our approach unrolls a provably convergent optimization algorithm into a structured neural network architecture. Each phase of the network mimics a step of an adaptive forward-backward scheme with extrapolation, enabling the model to incorporate both data fidelity and nonconvex regularization in a principled manner. To enhance generalization across different acquisition settings, we integrate meta-learning, which enables the model to rapidly adapt to unseen sampling patterns and modality combinations using task-specific meta-knowledge. The proposed method is evaluated on the open source datasets, showing significant improvements in PSNR and SSIM over conventional supervised learning, especially under aggressive undersampling and domain shifts. Our results demonstrate the synergy of unrolled optimization, task-aware meta-learning, and modality fusion, offering a scalable and generalizable solution for real-world clinical MRI reconstruction.","authors":["Merham Fouladvand","Peuroly Batra"],"url":"https://arxiv.org/abs/2505.11518"}
{"created":"2025-05-20","title":"Decentralized Traffic Flow Optimization Through Intrinsic Motivation","abstract":"Traffic congestion has long been an ubiquitous problem that is exacerbating with the rapid growth of megacities. In this proof-of-concept work we study intrinsic motivation, implemented via the empowerment principle, to control autonomous car behavior to improve traffic flow. In standard models of traffic dynamics, self-organized traffic jams emerge spontaneously from the individual behavior of cars, affecting traffic over long distances. Our novel car behavior strategy improves traffic flow while still being decentralized and using only locally available information without explicit coordination. Decentralization is essential for various reasons, not least to be able to absorb robustly substantial levels of uncertainty. Our scenario is based on the well-established traffic dynamics model, the Nagel-Schreckenberg cellular automaton. In a fraction of the cars in this model, we substitute the default behavior by empowerment, our intrinsic motivation-based method. This proposed model significantly improves overall traffic flow, mitigates congestion, and reduces the average traffic jam time.","authors":["Himaja Papala","Daniel Polani","Stas Tiomkin"],"url":"https://arxiv.org/abs/2505.11520"}
{"created":"2025-05-20","title":"Code Retrieval for MILP Instance Generation","abstract":"Mixed-Integer Linear Programming (MILP) is widely used in fields such as scheduling, logistics, and planning. Enhancing the performance of MILP solvers, particularly learning-based solvers, requires substantial amounts of high-quality data. However, existing methods for MILP instance generation typically necessitate training a separate model for each problem class and are computationally intensive when generating new instances. To address these limitations, we reformulate the MILP Instance Generation task as MILP Code Generation task, enabling efficient, flexible, and interpretable instance generation through code. Since MILP instances generated from code can vary significantly in scale, we introduce MILP-EmbedSim, a new similarity metric that accurately measures the similarity between instances of varying sizes within the same problem class. Leveraging this metric, we propose MILP-Retrieval, a pipeline that retrieves generation code from library to produce MILP instances highly similar to target instance. MILP-Retrieval outperforms baselines in both MILP Code Generation and Instance Generation tasks, provides a novel perspective on MILP instance generation and opens new possibilities for learning-based solvers.","authors":["Tianxing Yang","Huigen Ye","Hua Xu"],"url":"https://arxiv.org/abs/2505.11526"}
{"created":"2025-05-20","title":"CASL-HJX: A Comprehensive Guide to Solving Deterministic and Stochastic Hamilton-Jacobi Equations","abstract":"CASL-HJX is a computational framework designed for solving deterministic and stochastic Hamilton-Jacobi equations in two spatial dimensions. It provides a flexible and efficient approach to modeling front propagation problems, optimal control problems, and stochastic Hamilton-Jacobi Bellman equations. The framework integrates numerical methods for hyperbolic PDEs with operator splitting techniques and implements implicit methods for second-order derivative terms, ensuring convergence to viscosity solutions while achieving global rather than local optimization. Built with a high-performance C++ core, CASL-HJX efficiently handles mixed-order derivative systems with time-varying dynamics, making it suitable for real-world applications across multiple domains. We demonstrate the solver's versatility through tutorial examples covering various PDEs and through applications in neuroscience, where it enables the design of energy-efficient controllers for regulating neural populations to mitigate pathological synchrony. While our examples focus on these applications, the mathematical foundation of the solver makes it applicable to problems in finance, engineering, and machine learning. The modular architecture allows researchers to define computational domains, configure problems, and execute simulations with high numerical accuracy. CASL-HJX bridges the gap between deterministic control methods and stochastic models, providing a robust tool for managing uncertainty in complex dynamical systems.","authors":["Faranak Rajabi","Jacob Fingerman","Andrew Wang","Jeff Moehlis","Frederic Gibou"],"url":"https://arxiv.org/abs/2505.11527"}
{"created":"2025-05-20","title":"BrainNetMLP: An Efficient and Effective Baseline for Functional Brain Network Classification","abstract":"Recent studies have made great progress in functional brain network classification by modeling the brain as a network of Regions of Interest (ROIs) and leveraging their connections to understand brain functionality and diagnose mental disorders. Various deep learning architectures, including Convolutional Neural Networks, Graph Neural Networks, and the recent Transformer, have been developed. However, despite the increasing complexity of these models, the performance gain has not been as salient. This raises a question: Does increasing model complexity necessarily lead to higher classification accuracy? In this paper, we revisit the simplest deep learning architecture, the Multi-Layer Perceptron (MLP), and propose a pure MLP-based method, named BrainNetMLP, for functional brain network classification, which capitalizes on the advantages of MLP, including efficient computation and fewer parameters. Moreover, BrainNetMLP incorporates a dual-branch structure to jointly capture both spatial connectivity and spectral information, enabling precise spatiotemporal feature fusion. We evaluate our proposed BrainNetMLP on two public and popular brain network classification datasets, the Human Connectome Project (HCP) and the Autism Brain Imaging Data Exchange (ABIDE). Experimental results demonstrate pure MLP-based methods can achieve state-of-the-art performance, revealing the potential of MLP-based models as more efficient yet effective alternatives in functional brain network classification. The code will be available at https://github.com/JayceonHo/BrainNetMLP.","authors":["Jiacheng Hou","Zhenjie Song","Ercan Engin Kuruoglu"],"url":"https://arxiv.org/abs/2505.11538"}
{"created":"2025-05-20","title":"Mathematical Politics","abstract":"Politics today is largely about the art of messaging to influence the public, but the mathematical theory of messaging -- information and communication theory -- can turn this art into a precise analysis, both qualitative and quantitative, that enables us to gain retrospective understandings of political events and to make forward-looking predictions.","authors":["Dorje C. Brody"],"url":"https://arxiv.org/abs/2505.11540"}
{"created":"2025-05-20","title":"Multi-Objective Memory Bandwidth Regulation and Cache Partitioning for Multicore Real-Time Systems","abstract":"Memory bandwidth regulation and cache partitioning are widely used techniques for achieving predictable timing in real-time computing systems. Combined with partitioned scheduling, these methods require careful co-allocation of tasks and resources to cores, as task execution times strongly depend on available allocated resources. To address this challenge, this paper presents a 0-1 linear program for task-resource co-allocation, along with a multi-objective heuristic designed to minimize resource usage while guaranteeing schedulability under a preemptive EDF scheduling policy. Our heuristic employs a multi-layer framework, where an outer layer explores resource allocations using Pareto-pruned search, and an inner layer optimizes task allocation by solving a knapsack problem using dynamic programming. To evaluate the performance of the proposed optimization algorithm, we profile real-world benchmarks on an embedded AMD UltraScale+ ZCU102 platform, with fine-grained resource partitioning enabled by the Jailhouse hypervisor, leveraging cache set partitioning and MemGuard for memory bandwidth regulation. Experiments based on the benchmarking results show that the proposed 0-1 linear program outperforms existing mixed-integer programs by finding more optimal solutions within the same time limit. Moreover, the proposed multi-objective multi-layer heuristic performs consistently better than the state-of-the-art multi-resource-task co-allocation algorithm in terms of schedulability, resource usage, number of non-dominated solutions, and computational efficiency.","authors":["Binqi Sun","Zhihang Wei","Andrea Bastoni","Debayan Roy","Mirco Theile","Tomasz Kloda","Rodolfo Pellizzoni","Marco Caccamo"],"url":"https://arxiv.org/abs/2505.11554"}
{"created":"2025-05-20","title":"Breaking the Code: Multi-level Learning in the Eurovision Song Contest","abstract":"Organizations learn from the market, political, and societal responses to their actions. While in some cases both the actions and responses take place in an open manner, in many others, some aspects may be hidden from external observers. The Eurovision Song Contest offers an interesting example to study organizational level learning at two levels: organizers and participants. We find evidence for changes in the rules of the Contest in response to undesired outcomes such as runaway winners. We also find strong evidence of participant learning in the characteristics of competing songs over the 70-years of the Contest. English has been adopted as the lingua franca of the competing songs and pop has become the standard genre. Number of words of lyrics has also grown in response to this collective learning. Remarkably, we find evidence that four participating countries have chosen to ignore the \"lesson\" that English lyrics increase winning probability. This choice is consistent with utility functions that award greater value to featuring national language than to winning the Contest. Indeed, we find evidence that some countries -- but not Germany -- appear to be less susceptible to \"peer\" pressure. These observations appear to be valid beyond Eurovision.","authors":["Lu\\'is A. Nunes Amaral","Arthur Capozzi","Dirk Helbing"],"url":"https://arxiv.org/abs/2505.11555"}
{"created":"2025-05-20","title":"Analysis and Resilience of the U.S. Flight Network","abstract":"Air travel is one of the most widely used transportation services in the United States. This paper analyzes the U.S. Flight Network (USFN) using complex network theory by exploring how the network's topology contributes to its efficiency and vulnerability. This is done by examining the structural properties, degree distributions, and community structures in the network. USFN was observed to follow power-law distribution and falls under the anomalous regime, suggesting that the network is hub dominant. Compared to null networks, USFN has a higher clustering coefficient and modularity. Various percolation test revealed that USFN is vulnerable to targeted attacks and is susceptible to complete cascading failure if one of the major hubs fails. The overall results suggest that while the USFN is designed for efficiency, it is highly vulnerable to disruptions. Protecting key hub airports is important to make the network more robust and prevent large-scale failures.","authors":["Sushrit Kafle","Shreejan Pandey"],"url":"https://arxiv.org/abs/2505.11559"}
{"created":"2025-05-20","title":"BioCube: A Multimodal Dataset for Biodiversity Research","abstract":"Biodiversity research requires complete and detailed information to study ecosystem dynamics at different scales. Employing data-driven methods like Machine Learning is getting traction in ecology and more specific biodiversity, offering alternative modelling pathways. For these methods to deliver accurate results there is the need for large, curated and multimodal datasets that offer granular spatial and temporal resolutions. In this work, we introduce BioCube, a multimodal, fine-grained global dataset for ecology and biodiversity research. BioCube incorporates species observations through images, audio recordings and descriptions, environmental DNA, vegetation indices, agricultural, forest, land indicators, and high-resolution climate variables. All observations are geospatially aligned under the WGS84 geodetic system, spanning from 2000 to 2020. The dataset will become available at https://huggingface.co/datasets/BioDT/BioCube while the acquisition and processing code base at https://github.com/BioDT/bfm-data.","authors":["Stylianos Stasinos","Martino Mensio","Elena Lazovik","Athanasios Trantas"],"url":"https://arxiv.org/abs/2505.11568"}
{"created":"2025-05-20","title":"A Blue Start: A large-scale pairwise and higher-order social network dataset","abstract":"Large-scale networks have been instrumental in shaping the way that we think about how individuals interact with one another, developing key insights in mathematical epidemiology, computational social science, and biology. However, many of the underlying social systems through which diseases spread, information disseminates, and individuals interact are inherently mediated through groups of arbitrary size, known as higher-order interactions. There is a gap between higher-order dynamics of group formation and fragmentation, contagion spread, and social influence and the data necessary to validate these higher-order mechanisms. Similarly, few datasets bridge the gap between these pairwise and higher-order network data. Because of its open API, the Bluesky social media platform provides a laboratory for observing social ties at scale. In addition to pairwise following relationships, unlike many other social networks, Bluesky features user-curated lists known as \"starter packs\" as a mechanism for social network growth. We introduce \"A Blue Start\", a large-scale network dataset comprising 26.7M users and their 1.6B pairwise following relationships and 301.3K groups representing starter packs. This dataset will be an essential resource for the study of higher-order network science.","authors":["Alyssa Smith","Ilya Amburg","Sagar Kumar","Brooke Foucault Welles","Nicholas W. Landry"],"url":"https://arxiv.org/abs/2505.11608"}
{"created":"2025-05-20","title":"The Stochastic Occupation Kernel (SOCK) Method for Learning Stochastic Differential Equations","abstract":"We present a novel kernel-based method for learning multivariate stochastic differential equations (SDEs). The method follows a two-step procedure: we first estimate the drift term function, then the (matrix-valued) diffusion function given the drift. Occupation kernels are integral functionals on a reproducing kernel Hilbert space (RKHS) that aggregate information over a trajectory. Our approach leverages vector-valued occupation kernels for estimating the drift component of the stochastic process. For diffusion estimation, we extend this framework by introducing operator-valued occupation kernels, enabling the estimation of an auxiliary matrix-valued function as a positive semi-definite operator, from which we readily derive the diffusion estimate. This enables us to avoid common challenges in SDE learning, such as intractable likelihoods, by optimizing a reconstruction-error-based objective. We propose a simple learning procedure that retains strong predictive accuracy while using Fenchel duality to promote efficiency. We validate the method on simulated benchmarks and a real-world dataset of Amyloid imaging in healthy and Alzheimer's disease (AD) subjects.","authors":["Michael L. Wells","Kamel Lahouel","Bruno Jedynak"],"url":"https://arxiv.org/abs/2505.11622"}
{"created":"2025-05-20","title":"Programmable metasurfaces for future photonic artificial intelligence","abstract":"Photonic neural networks (PNNs), which share the inherent benefits of photonic systems, such as high parallelism and low power consumption, could challenge traditional digital neural networks in terms of energy efficiency, latency, and throughput. However, producing scalable photonic artificial intelligence (AI) solutions remains challenging. To make photonic AI models viable, the scalability problem needs to be solved. Large optical AI models implemented on PNNs are only commercially feasible if the advantages of optical computation outweigh the cost of their input-output overhead. In this Perspective, we discuss how field-programmable metasurface technology may become a key hardware ingredient in achieving scalable photonic AI accelerators and how it can compete with current digital electronic technologies. Programmability or reconfigurability is a pivotal component for PNN hardware, enabling in situ training and accommodating non-stationary use cases that require fine-tuning or transfer learning. Co-integration with electronics, 3D stacking, and large-scale manufacturing of metasurfaces would significantly improve PNN scalability and functionalities. Programmable metasurfaces could address some of the current challenges that PNNs face and enable next-generation photonic AI technology.","authors":["Loubnan Abou-Hamdan","Emil Marinov","Peter Wiecha","Philipp del Hougne","Tianyu Wang","Patrice Genevet"],"url":"https://arxiv.org/abs/2505.11659"}
{"created":"2025-05-20","title":"Humble your Overconfident Networks: Unlearning Overfitting via Sequential Monte Carlo Tempered Deep Ensembles","abstract":"Sequential Monte Carlo (SMC) methods offer a principled approach to Bayesian uncertainty quantification but are traditionally limited by the need for full-batch gradient evaluations. We introduce a scalable variant by incorporating Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) proposals into SMC, enabling efficient mini-batch based sampling. Our resulting SMCSGHMC algorithm outperforms standard stochastic gradient descent (SGD) and deep ensembles across image classification, out-of-distribution (OOD) detection, and transfer learning tasks. We further show that SMCSGHMC mitigates overfitting and improves calibration, providing a flexible, scalable pathway for converting pretrained neural networks into well-calibrated Bayesian models.","authors":["Andrew Millard","Zheng Zhao","Joshua Murphy","Simon Maskell"],"url":"https://arxiv.org/abs/2505.11671"}
{"created":"2025-05-20","title":"On the Sharp Input-Output Analysis of Nonlinear Systems under Adversarial Attacks","abstract":"This paper is concerned with learning the input-output mapping of general nonlinear dynamical systems. While the existing literature focuses on Gaussian inputs and benign disturbances, we significantly broaden the scope of admissible control inputs and allow correlated, nonzero-mean, adversarial disturbances. With our reformulation as a linear combination of basis functions, we prove that the $l_1$-norm estimator overcomes the challenges as long as the probability that the system is under adversarial attack at a given time is smaller than a certain threshold. We provide an estimation error bound that decays with the input memory length and prove its optimality by constructing a problem instance that suffers from the same bound under adversarial attacks. Our work provides a sharp input-output analysis for a generic nonlinear and partially observed system under significantly generalized assumptions compared to existing works.","authors":["Jihun Kim","Yuchen Fang","Javad Lavaei"],"url":"https://arxiv.org/abs/2505.11688"}
{"created":"2025-05-20","title":"Explainable Machine Learning for Oxygen Diffusion in Perovskites and Pyrochlores","abstract":"Explainable machine learning can help to discover new physical relationships for material properties. To understand the material properties that govern the activation energy for oxygen diffusion in perovskites and pyrochlores, we build a database of experimental activation energies and apply a grouping algorithm to the material property features. These features are then used to fit seven different machine learning models. An ensemble consensus determines that the most important features for predicting the activation energy are the ionicity of the A-site bond and the partial pressure of oxygen for perovskites. For pyrochlores, the two most important features are the A-site $s$ valence electron count and the B-site electronegativity. The most important features are all constructed using the weighted averages of elemental metal properties, despite weighted averages of the constituent binary oxides being included in our feature set. This is surprising because the material properties of the constituent oxides are more similar to the experimentally measured properties of perovskites and pyrochlores than the features of the metals that are chosen. The easy-to-measure features identified in this work enable rapid screening for new materials with fast oxide-ion diffusivity.","authors":["Grace M. Lu (Department of Materials Science","Engineering","University of Illinois at Urbana-Champaign","Urbana","Illinois 61801","USA)","Dallas R. Trinkle (Department of Materials Science","Engineering","University of Illinois at Urbana-Champaign","Urbana","Illinois 61801","USA)"],"url":"https://arxiv.org/abs/2505.11722"}
{"created":"2025-05-20","title":"Missing Data Imputation by Reducing Mutual Information with Rectified Flows","abstract":"This paper introduces a novel iterative method for missing data imputation that sequentially reduces the mutual information between data and their corresponding missing mask. Inspired by GAN-based approaches, which train generators to decrease the predictability of missingness patterns, our method explicitly targets the reduction of mutual information. Specifically, our algorithm iteratively minimizes the KL divergence between the joint distribution of the imputed data and missing mask, and the product of their marginals from the previous iteration. We show that the optimal imputation under this framework corresponds to solving an ODE, whose velocity field minimizes a rectified flow training objective. We further illustrate that some existing imputation techniques can be interpreted as approximate special cases of our mutual-information-reducing framework. Comprehensive experiments on synthetic and real-world datasets validate the efficacy of our proposed approach, demonstrating superior imputation performance.","authors":["Jiahao Yu","Qizhen Ying","Leyang Wang","Ziyue Jiang","Song Liu"],"url":"https://arxiv.org/abs/2505.11749"}
{"created":"2025-05-20","title":"Improving Medium Range Severe Weather Prediction through Transformer Post-processing of AI Weather Forecasts","abstract":"Improving the skill of medium-range (1-8 day) severe weather prediction is crucial for mitigating societal impacts. This study introduces a novel approach leveraging decoder-only transformer networks to post-process AI-based weather forecasts, specifically from the Pangu-Weather model, for improved severe weather guidance. Unlike traditional post-processing methods that use a dense neural network to predict the probability of severe weather using discrete forecast samples, our method treats forecast lead times as sequential ``tokens'', enabling the transformer to learn complex temporal relationships within the evolving atmospheric state. We compare this approach against post-processing of the Global Forecast System (GFS) using both a traditional dense neural network and our transformer, as well as configurations that exclude convective parameters to fairly evaluate the impact of using the Pangu-Weather AI model. Results demonstrate that the transformer-based post-processing significantly enhances forecast skill compared to dense neural networks. Furthermore, AI-driven forecasts, particularly Pangu-Weather initialized from high resolution analysis, exhibit superior performance to GFS in the medium-range, even without explicit convective parameters. Our approach offers improved accuracy, and reliability, which also provides interpretability through feature attribution analysis, advancing medium-range severe weather prediction capabilities.","authors":["Zhanxiang Hua","Ryan Sobash","David John Gagne II","Yingkai Sha","Alexandra Anderson-Frey"],"url":"https://arxiv.org/abs/2505.11750"}
{"created":"2025-05-20","title":"MedVKAN: Efficient Feature Extraction with Mamba and KAN for Medical Image Segmentation","abstract":"Medical image segmentation relies heavily on convolutional neural networks (CNNs) and Transformer-based models. However, CNNs are constrained by limited receptive fields, while Transformers suffer from scalability challenges due to their quadratic computational complexity. To address these limitations, recent advances have explored alternative architectures. The state-space model Mamba offers near-linear complexity while capturing long-range dependencies, and the Kolmogorov-Arnold Network (KAN) enhances nonlinear expressiveness by replacing fixed activation functions with learnable ones. Building on these strengths, we propose MedVKAN, an efficient feature extraction model integrating Mamba and KAN. Specifically, we introduce the EFC-KAN module, which enhances KAN with convolutional operations to improve local pixel interaction. We further design the VKAN module, integrating Mamba with EFC-KAN as a replacement for Transformer modules, significantly improving feature extraction. Extensive experiments on five public medical image segmentation datasets show that MedVKAN achieves state-of-the-art performance on four datasets and ranks second on the remaining one. These results validate the potential of Mamba and KAN for medical image segmentation while introducing an innovative and computationally efficient feature extraction framework. The code is available at: https://github.com/beginner-cjh/MedVKAN.","authors":["Hancan Zhu","Jinhao Chen","Guanghua He"],"url":"https://arxiv.org/abs/2505.11797"}
{"created":"2025-05-20","title":"AnalyticKWS: Towards Exemplar-Free Analytic Class Incremental Learning for Small-footprint Keyword Spotting","abstract":"Keyword spotting (KWS) offers a vital mechanism to identify spoken commands in voice-enabled systems, where user demands often shift, requiring models to learn new keywords continually over time. However, a major problem is catastrophic forgetting, where models lose their ability to recognize earlier keywords. Although several continual learning methods have proven their usefulness for reducing forgetting, most existing approaches depend on storing and revisiting old data to combat catastrophic forgetting. Though effective, these methods face two practical challenges: 1) privacy risks from keeping user data and 2) large memory and time consumption that limit deployment on small devices. To address these issues, we propose an exemplar-free Analytic Continual Learning (AnalyticKWS) method that updates model parameters without revisiting earlier data. Inspired by efficient learning principles, AnalyticKWS computes a closed-form analytical solution for model updates and requires only a single epoch of adaptation for incoming keywords. AnalyticKWS demands fewer computational resources by avoiding gradient-based updates and does not store old data. By eliminating the need for back-propagation during incremental learning, the model remains lightweight and efficient. As a result, AnalyticKWS meets the challenges mentioned earlier and suits resource-limited settings well. Extensive experiments on various datasets and settings show that AnalyticKWS consistently outperforms existing continual learning methods.","authors":["Yang Xiao","Tianyi Peng","Rohan Kumar Das","Yuchen Hu","Huiping Zhuang"],"url":"https://arxiv.org/abs/2505.11817"}
{"created":"2025-05-20","title":"Patient-Specific Autoregressive Models for Organ Motion Prediction in Radiotherapy","abstract":"Radiotherapy often involves a prolonged treatment period. During this time, patients may experience organ motion due to breathing and other physiological factors. Predicting and modeling this motion before treatment is crucial for ensuring precise radiation delivery. However, existing pre-treatment organ motion prediction methods primarily rely on deformation analysis using principal component analysis (PCA), which is highly dependent on registration quality and struggles to capture periodic temporal dynamics for motion modeling.In this paper, we observe that organ motion prediction closely resembles an autoregressive process, a technique widely used in natural language processing (NLP). Autoregressive models predict the next token based on previous inputs, naturally aligning with our objective of predicting future organ motion phases. Building on this insight, we reformulate organ motion prediction as an autoregressive process to better capture patient-specific motion patterns. Specifically, we acquire 4D CT scans for each patient before treatment, with each sequence comprising multiple 3D CT phases. These phases are fed into the autoregressive model to predict future phases based on prior phase motion patterns. We evaluate our method on a real-world test set of 4D CT scans from 50 patients who underwent radiotherapy at our institution and a public dataset containing 4D CT scans from 20 patients (some with multiple scans), totaling over 1,300 3D CT phases. The performance in predicting the motion of the lung and heart surpasses existing benchmarks, demonstrating its effectiveness in capturing motion dynamics from CT images. These results highlight the potential of our method to improve pre-treatment planning in radiotherapy, enabling more precise and adaptive radiation delivery.","authors":["Yuxiang Lai","Jike Zhong","Vanessa Su","Xiaofeng Yang"],"url":"https://arxiv.org/abs/2505.11832"}
{"created":"2025-05-20","title":"S-Crescendo: A Nested Transformer Weaving Framework for Scalable Nonlinear System in S-Domain Representation","abstract":"Simulation of high-order nonlinear system requires extensive computational resources, especially in modern VLSI backend design where bifurcation-induced instability and chaos-like transient behaviors pose challenges. We present S-Crescendo - a nested transformer weaving framework that synergizes S-domain with neural operators for scalable time-domain prediction in high-order nonlinear networks, alleviating the computational bottlenecks of conventional solvers via Newton-Raphson method. By leveraging the partial-fraction decomposition of an n-th order transfer function into first-order modal terms with repeated poles and residues, our method bypasses the conventional Jacobian matrix-based iterations and efficiently reduces computational complexity from cubic $O(n^3)$ to linear $O(n)$.The proposed architecture seamlessly integrates an S-domain encoder with an attention-based correction operator to simultaneously isolate dominant response and adaptively capture higher-order non-linearities. Validated on order-1 to order-10 networks, our method achieves up to 0.99 test-set ($R^2$) accuracy against HSPICE golden waveforms and accelerates simulation by up to 18(X), providing a scalable, physics-aware framework for high-dimensional nonlinear modeling.","authors":["Junlang Huang","Hao Chen","Li Luo","Yong Cai","Lexin Zhang","Tianhao Ma","Yitian Zhang","Zhong Guan"],"url":"https://arxiv.org/abs/2505.11843"}
{"created":"2025-05-20","title":"Measurement Score-Based Diffusion Model","abstract":"Diffusion models are widely used in applications ranging from image generation to inverse problems. However, training diffusion models typically requires clean ground-truth images, which are unavailable in many applications. We introduce the Measurement Score-based diffusion Model (MSM), a novel framework that learns partial measurement scores using only noisy and subsampled measurements. MSM models the distribution of full measurements as an expectation over partial scores induced by randomized subsampling. To make the MSM representation computationally efficient, we also develop a stochastic sampling algorithm that generates full images by using a randomly selected subset of partial scores at each step. We additionally propose a new posterior sampling method for solving inverse problems that reconstructs images using these partial scores. We provide a theoretical analysis that bounds the Kullback-Leibler divergence between the distributions induced by full and stochastic sampling, establishing the accuracy of the proposed algorithm. We demonstrate the effectiveness of MSM on natural images and multi-coil MRI, showing that it can generate high-quality images and solve inverse problems -- all without access to clean training data. Code is available at https://github.com/wustl-cig/MSM.","authors":["Chicago Y. Park","Shirin Shoushtari","Hongyu An","Ulugbek S. Kamilov"],"url":"https://arxiv.org/abs/2505.11853"}
{"created":"2025-05-20","title":"Exploring the Potential of SSL Models for Sound Event Detection","abstract":"Self-supervised learning (SSL) models offer powerful representations for sound event detection (SED), yet their synergistic potential remains underexplored. This study systematically evaluates state-of-the-art SSL models to guide optimal model selection and integration for SED. We propose a framework that combines heterogeneous SSL representations (e.g., BEATs, HuBERT, WavLM) through three fusion strategies: individual SSL embedding integration, dual-modal fusion, and full aggregation. Experiments on the DCASE 2023 Task 4 Challenge reveal that dual-modal fusion (e.g., CRNN+BEATs+WavLM) achieves complementary performance gains, while CRNN+BEATs alone delivers the best results among individual SSL models. We further introduce normalized sound event bounding boxes (nSEBBs), an adaptive post-processing method that dynamically adjusts event boundary predictions, improving PSDS1 by up to 4% for standalone SSL models. These findings highlight the compatibility and complementarity of SSL architectures, providing guidance for task-specific fusion and robust SED system design.","authors":["Hanfang Cui","Longfei Song","Li Li","Dongxing Xu","Yanhua Long"],"url":"https://arxiv.org/abs/2505.11889"}
{"created":"2025-05-20","title":"Bridging the Inter-Domain Gap through Low-Level Features for Cross-Modal Medical Image Segmentation","abstract":"This paper addresses the task of cross-modal medical image segmentation by exploring unsupervised domain adaptation (UDA) approaches. We propose a model-agnostic UDA framework, LowBridge, which builds on a simple observation that cross-modal images share some similar low-level features (e.g., edges) as they are depicting the same structures. Specifically, we first train a generative model to recover the source images from their edge features, followed by training a segmentation model on the generated source images, separately. At test time, edge features from the target images are input to the pretrained generative model to generate source-style target domain images, which are then segmented using the pretrained segmentation network. Despite its simplicity, extensive experiments on various publicly available datasets demonstrate that \\proposed achieves state-of-the-art performance, outperforming eleven existing UDA approaches under different settings. Notably, further ablation studies show that \\proposed is agnostic to different types of generative and segmentation models, suggesting its potential to be seamlessly plugged with the most advanced models to achieve even more outstanding results in the future. The code is available at https://github.com/JoshuaLPF/LowBridge.","authors":["Pengfei Lyu","Pak-Hei Yeung","Xiaosheng Yu","Jing Xia","Jianning Chi","Chengdong Wu","Jagath C. Rajapakse"],"url":"https://arxiv.org/abs/2505.11909"}
{"created":"2025-05-20","title":"Improving the discovery of near-Earth objects with machine-learning methods","abstract":"We present a comprehensive analysis of the digest2 parameters for candidates of the Near-Earth Object Confirmation Page (NEOCP) that were reported between 2019 and 2024. Our study proposes methods for significantly reducing the inclusion of non-NEO objects on the NEOCP. Despite the substantial increase in near-Earth object (NEO) discoveries in recent years, only about half of the NEOCP candidates are ultimately confirmed as NEOs. Therefore, much observing time is spent following up on non-NEOs. Furthermore, approximately 11% of the candidates remain unconfirmed because the follow-up observations are insufficient. These are nearly 600 cases per year. To reduce false positives and minimize wasted resources on non-NEOs, we refine the posting criteria for NEOCP based on a detailed analysis of all digest2 scores. We investigated 30 distinct digest2 parameter categories for candidates that were confirmed as NEOs and non-NEOs. From this analysis, we derived a filtering mechanism based on selected digest2 parameters that were able to exclude 20% of the non-NEOs from the NEOCP while maintaining a minimal loss of true NEOs. We also investigated the application of four machine-learning (ML) techniques, that is, the gradient-boosting machine (GBM), the random forest (RF) classifier, the stochastic gradient descent (SGD) classifier, and neural networks (NN) to classify NEOCP candidates as NEOs or non-NEOs. Based on digest2 parameters as input, our ML models achieved a precision of approximately 95% in distinguishing between NEOs and non-NEOs. Results. Combining the digest2 parameter filter with an ML-based classification model, we demonstrate a significant reduction in non-NEOs on the NEOCP that exceeds 80%, while limiting the loss of NEO discovery tracklets to 5.5%. Importantly, we show that most follow-up tracklets of initially misclassified NEOs are later correctly identified as NEOs.","authors":["Peter Vere\\v{s}","Richard Cloete","Matthew J. Payne","Abraham Loeb"],"url":"https://arxiv.org/abs/2505.11910"}
{"created":"2025-05-20","title":"Joint Manifold Learning and Optimal Transport for Dynamic Imaging","abstract":"Dynamic imaging is critical for understanding and visualizing dynamic biological processes in medicine and cell biology. These applications often encounter the challenge of a limited amount of time series data and time points, which hinders learning meaningful patterns. Regularization methods provide valuable prior knowledge to address this challenge, enabling the extraction of relevant information despite the scarcity of time-series data and time points. In particular, low-dimensionality assumptions on the image manifold address sample scarcity, while time progression models, such as optimal transport (OT), provide priors on image development to mitigate the lack of time points. Existing approaches using low-dimensionality assumptions disregard a temporal prior but leverage information from multiple time series. OT-prior methods, however, incorporate the temporal prior but regularize only individual time series, ignoring information from other time series of the same image modality. In this work, we investigate the effect of integrating a low-dimensionality assumption of the underlying image manifold with an OT regularizer for time-evolving images. In particular, we propose a latent model representation of the underlying image manifold and promote consistency between this representation, the time series data, and the OT prior on the time-evolving images. We discuss the advantages of enriching OT interpolations with latent models and integrating OT priors into latent models.","authors":["Sven Dummer","Puru Vaish","Christoph Brune"],"url":"https://arxiv.org/abs/2505.11913"}
{"created":"2025-05-20","title":"A preconditioned difference of convex functions algorithm with extrapolation and line search","abstract":"This paper proposes a novel proximal difference-of-convex (DC) algorithm enhanced with extrapolation and aggressive non-monotone line search for solving non-convex optimization problems. We introduce an adaptive conservative update strategy of the extrapolation parameter determined by a computationally efficient non-monotone line search. The core of our algorithm is to unite the update of the extrapolation parameter with the step size of the non-monotone line search interactively. The global convergence of the two proposed algorithms is established through the Kurdyka-{\\L}ojasiewicz properties, ensuring convergence within a preconditioned framework for linear equations. Numerical experiments on two general non-convex problems: SCAD-penalized binary classification and graph-based Ginzburg-Landau image segmentation models, demonstrate the proposed method's high efficiency compared to existing DC algorithms both in convergence rate and solution accuracy.","authors":["Ran Zhang","Hongpeng Sun"],"url":"https://arxiv.org/abs/2505.11914"}
{"created":"2025-05-20","title":"BINAQUAL: A Full-Reference Objective Localization Similarity Metric for Binaural Audio","abstract":"Spatial audio enhances immersion in applications such as virtual reality, augmented reality, gaming, and cinema by creating a three-dimensional auditory experience. Ensuring the spatial fidelity of binaural audio is crucial, given that processes such as compression, encoding, or transmission can alter localization cues. While subjective listening tests like MUSHRA remain the gold standard for evaluating spatial localization quality, they are costly and time-consuming. This paper introduces BINAQUAL, a full-reference objective metric designed to assess localization similarity in binaural audio recordings. BINAQUAL adapts the AMBIQUAL metric, originally developed for localization quality assessment in ambisonics audio format to the binaural domain. We evaluate BINAQUAL across five key research questions, examining its sensitivity to variations in sound source locations, angle interpolations, surround speaker layouts, audio degradations, and content diversity. Results demonstrate that BINAQUAL effectively differentiates between subtle spatial variations and correlates strongly with subjective listening tests, making it a reliable metric for binaural localization quality assessment. The proposed metric provides a robust benchmark for ensuring spatial accuracy in binaural audio processing, paving the way for improved objective evaluations in immersive audio applications.","authors":["Davoud Shariat Panah","Dan Barry","Alessandro Ragano","Jan Skoglund","Andrew Hines"],"url":"https://arxiv.org/abs/2505.11915"}
{"created":"2025-05-20","title":"Fine-Grained ECG-Text Contrastive Learning via Waveform Understanding Enhancement","abstract":"Electrocardiograms (ECGs) are essential for diagnosing cardiovascular diseases. While previous ECG-text contrastive learning methods have shown promising results, they often overlook the incompleteness of the reports. Given an ECG, the report is generated by first identifying key waveform features and then inferring the final diagnosis through these features. Despite their importance, these waveform features are often not recorded in the report as intermediate results. Aligning ECGs with such incomplete reports impedes the model's ability to capture the ECG's waveform features and limits its understanding of diagnostic reasoning based on those features. To address this, we propose FG-CLEP (Fine-Grained Contrastive Language ECG Pre-training), which aims to recover these waveform features from incomplete reports with the help of large language models (LLMs), under the challenges of hallucinations and the non-bijective relationship between waveform features and diagnoses. Additionally, considering the frequent false negatives due to the prevalence of common diagnoses in ECGs, we introduce a semantic similarity matrix to guide contrastive learning. Furthermore, we adopt a sigmoid-based loss function to accommodate the multi-label nature of ECG-related tasks. Experiments on six datasets demonstrate that FG-CLEP outperforms state-of-the-art methods in both zero-shot prediction and linear probing across these datasets.","authors":["Haitao Li","Che Liu","Zhengyao Ding","Ziyi Liu","Zhengxing Huang"],"url":"https://arxiv.org/abs/2505.11939"}
{"created":"2025-05-20","title":"Which Phylogenetic Networks are Level-k Networks with Additional Arcs? Structure and Algorithms","abstract":"Reticulate evolution gives rise to complex phylogenetic networks, making their interpretation challenging. A typical approach is to extract trees within such networks. Since Francis and Steel's seminal paper, \"Which Phylogenetic Networks are Merely Trees with Additional Arcs?\" (2015), tree-based phylogenetic networks and their support trees (spanning trees with the same root and leaf set as a given network) have been extensively studied. However, not all phylogenetic networks are tree-based, and for the study of reticulate evolution, it is often more biologically relevant to identify support networks rather than trees. This study generalizes Hayamizu's structure theorem for rooted binary phylogenetic networks, which yielded optimal algorithms for various computational problems on support trees, to extend the theoretical framework for support trees to support networks. This allows us to obtain a direct-product characterization of each of three sets: all, minimal, and minimum support networks, for a given network. Each characterization yields optimal algorithms for counting and generating the support networks of each type. Applications include a linear-time algorithm for finding a support network with the fewest reticulations (i.e., the minimum tier). We also provide exact and heuristic algorithms for finding a support network with the minimum level, both running in exponential time but practical across a reasonably wide range of reticulation numbers.","authors":["Takatora Suzuki","Momoko Hayamizu"],"url":"https://arxiv.org/abs/2505.11947"}
{"created":"2025-05-20","title":"Multi-Attribute Graph Estimation with Sparse-Group Non-Convex Penalties","abstract":"We consider the problem of inferring the conditional independence graph (CIG) of high-dimensional Gaussian vectors from multi-attribute data. Most existing methods for graph estimation are based on single-attribute models where one associates a scalar random variable with each node. In multi-attribute graphical models, each node represents a random vector. In this paper we provide a unified theoretical analysis of multi-attribute graph learning using a penalized log-likelihood objective function. We consider both convex (sparse-group lasso) and sparse-group non-convex (log-sum and smoothly clipped absolute deviation (SCAD) penalties) penalty/regularization functions. An alternating direction method of multipliers (ADMM) approach coupled with local linear approximation to non-convex penalties is presented for optimization of the objective function. For non-convex penalties, theoretical analysis establishing local consistency in support recovery, local convexity and precision matrix estimation in high-dimensional settings is provided under two sets of sufficient conditions: with and without some irrepresentability conditions. We illustrate our approaches using both synthetic and real-data numerical examples. In the synthetic data examples the sparse-group log-sum penalized objective function significantly outperformed the lasso penalized as well as SCAD penalized objective functions with $F_1$-score and Hamming distance as performance metrics.","authors":["Jitendra K Tugnait"],"url":"https://arxiv.org/abs/2505.11984"}
{"created":"2025-05-20","title":"Bayesian Deep Learning Approaches for Uncertainty-Aware Retinal OCT Image Segmentation for Multiple Sclerosis","abstract":"Optical Coherence Tomography (OCT) provides valuable insights in ophthalmology, cardiology, and neurology due to high-resolution, cross-sectional images of the retina. One critical task for ophthalmologists using OCT is delineation of retinal layers within scans. This process is time-consuming and prone to human bias, affecting the accuracy and reliability of diagnoses. Previous efforts to automate delineation using deep learning face challenges in uptake from clinicians and statisticians due to the absence of uncertainty estimation, leading to \"confidently wrong\" models via hallucinations. In this study, we address these challenges by applying Bayesian convolutional neural networks (BCNNs) to segment an openly available OCT imaging dataset containing 35 human retina OCTs split between healthy controls and patients with multiple sclerosis. Our findings demonstrate that Bayesian models can be used to provide uncertainty maps of the segmentation, which can further be used to identify highly uncertain samples that exhibit recording artefacts such as noise or miscalibration at inference time. Our method also allows for uncertainty-estimation for important secondary measurements such as layer thicknesses, that are medically relevant for patients. We show that these features come in addition to greater performance compared to similar work over all delineations; with an overall Dice score of 95.65%. Our work brings greater clinical applicability, statistical robustness, and performance to retinal OCT segmentation.","authors":["Samuel T. M. Ball"],"url":"https://arxiv.org/abs/2505.12061"}
{"created":"2025-05-20","title":"Symbolic Sets for Proving Bounds on Rado Numbers","abstract":"Given a linear equation $\\cal E$ of the form $ax + by = cz$ where $a$, $b$, $c$ are positive integers, the $k$-colour Rado number $R_k({\\cal E})$ is the smallest positive integer $n$, if it exists, such that every $k$-colouring of the positive integers $\\{1, 2, \\dotsc, n\\}$ contains a monochromatic solution to $\\cal E$. In this paper, we consider $k = 3$ and the linear equations $ax + by = bz$ and $ax + ay = bz$. Using SAT solvers, we compute a number of previously unknown Rado numbers corresponding to these equations. We prove new general bounds on Rado numbers inspired by the satisfying assignments discovered by the SAT solver. Our proofs require extensive case-based analyses that are difficult to check for correctness by hand, so we automate checking the correctness of our proofs via an approach which makes use of a new tool we developed with support for operations on symbolically-defined sets -- e.g., unions or intersections of sets of the form $\\{f(1), f(2), \\dotsc, f(a)\\}$ where $a$ is a symbolic variable and $f$ is a function possibly dependent on $a$. No computer algebra system that we are aware of currently has sufficiently capable support for symbolic sets, leading us to develop a tool supporting symbolic sets using the Python symbolic computation library SymPy coupled with the Satisfiability Modulo Theories solver Z3.","authors":["Tanbir Ahmed","Lamina Zaman","Curtis Bright"],"url":"https://arxiv.org/abs/2505.12085"}
{"created":"2025-05-20","title":"NTIRE 2025 Challenge on Efficient Burst HDR and Restoration: Datasets, Methods, and Results","abstract":"This paper reviews the NTIRE 2025 Efficient Burst HDR and Restoration Challenge, which aims to advance efficient multi-frame high dynamic range (HDR) and restoration techniques. The challenge is based on a novel RAW multi-frame fusion dataset, comprising nine noisy and misaligned RAW frames with various exposure levels per scene. Participants were tasked with developing solutions capable of effectively fusing these frames while adhering to strict efficiency constraints: fewer than 30 million model parameters and a computational budget under 4.0 trillion FLOPs. A total of 217 participants registered, with six teams finally submitting valid solutions. The top-performing approach achieved a PSNR of 43.22 dB, showcasing the potential of novel methods in this domain. This paper provides a comprehensive overview of the challenge, compares the proposed solutions, and serves as a valuable reference for researchers and practitioners in efficient burst HDR and restoration.","authors":["Sangmin Lee","Eunpil Park","Angel Canelo","Hyunhee Park","Youngjo Kim","Hyung-Ju Chun","Xin Jin","Chongyi Li","Chun-Le Guo","Radu Timofte","Qi Wu","Tianheng Qiu","Yuchun Dong","Shenglin Ding","Guanghua Pan","Weiyu Zhou","Tao Hu","Yixu Feng","Duwei Dai","Yu Cao","Peng Wu","Wei Dong","Yanning Zhang","Qingsen Yan","Simon J. Larsen","Ruixuan Jiang","Senyan Xu","Xingbo Wang","Xin Lu","Marcos V. Conde","Javier Abad-Hernandez","Alvaro Garc{\\i}a-Lara","Daniel Feijoo","Alvaro Garc{\\i}a","Zeyu Xiao","Zhuoyuan Li"],"url":"https://arxiv.org/abs/2505.12089"}
{"created":"2025-05-20","title":"Thompson Sampling-like Algorithms for Stochastic Rising Bandits","abstract":"Stochastic rising rested bandit (SRRB) is a setting where the arms' expected rewards increase as they are pulled. It models scenarios in which the performances of the different options grow as an effect of an underlying learning process (e.g., online model selection). Even if the bandit literature provides specifically crafted algorithms based on upper-confidence bounds for such a setting, no study about Thompson sampling TS-like algorithms has been performed so far. The strong regularity of the expected rewards in the SRRB setting suggests that specific instances may be tackled effectively using adapted and sliding-window TS approaches. This work provides novel regret analyses for such algorithms in SRRBs, highlighting the challenges and providing new technical tools of independent interest. Our results allow us to identify under which assumptions TS-like algorithms succeed in achieving sublinear regret and which properties of the environment govern the complexity of the regret minimization problem when approached with TS. Furthermore, we provide a regret lower bound based on a complexity index we introduce. Finally, we conduct numerical simulations comparing TS-like algorithms with state-of-the-art approaches for SRRBs in synthetic and real-world settings.","authors":["Marco Fiandri","Alberto Maria Metelli","Francesco Trov\\`o"],"url":"https://arxiv.org/abs/2505.12092"}
{"created":"2025-05-20","title":"T-Rex: Fitting a Robust Factor Model via Expectation-Maximization","abstract":"Over the past decades, there has been a surge of interest in studying low-dimensional structures within high-dimensional data. Statistical factor models $-$ i.e., low-rank plus diagonal covariance structures $-$ offer a powerful framework for modeling such structures. However, traditional methods for fitting statistical factor models, such as principal component analysis (PCA) or maximum likelihood estimation assuming the data is Gaussian, are highly sensitive to heavy tails and outliers in the observed data. In this paper, we propose a novel expectation-maximization (EM) algorithm for robustly fitting statistical factor models. Our approach is based on Tyler's M-estimator of the scatter matrix for an elliptical distribution, and consists of solving Tyler's maximum likelihood estimation problem while imposing a structural constraint that enforces the low-rank plus diagonal covariance structure. We present numerical experiments on both synthetic and real examples, demonstrating the robustness of our method for direction-of-arrival estimation in nonuniform noise and subspace recovery.","authors":["Daniel Cederberg"],"url":"https://arxiv.org/abs/2505.12117"}
{"created":"2025-05-20","title":"HISTAI: An Open-Source, Large-Scale Whole Slide Image Dataset for Computational Pathology","abstract":"Recent advancements in Digital Pathology (DP), particularly through artificial intelligence and Foundation Models, have underscored the importance of large-scale, diverse, and richly annotated datasets. Despite their critical role, publicly available Whole Slide Image (WSI) datasets often lack sufficient scale, tissue diversity, and comprehensive clinical metadata, limiting the robustness and generalizability of AI models. In response, we introduce the HISTAI dataset, a large, multimodal, open-access WSI collection comprising over 60,000 slides from various tissue types. Each case in the HISTAI dataset is accompanied by extensive clinical metadata, including diagnosis, demographic information, detailed pathological annotations, and standardized diagnostic coding. The dataset aims to fill gaps identified in existing resources, promoting innovation, reproducibility, and the development of clinically relevant computational pathology solutions. The dataset can be accessed at https://github.com/HistAI/HISTAI.","authors":["Dmitry Nechaev","Alexey Pchelnikov","Ekaterina Ivanova"],"url":"https://arxiv.org/abs/2505.12120"}
{"created":"2025-05-20","title":"WaLRUS: Wavelets for Long-range Representation Using SSMs","abstract":"State-Space Models (SSMs) have proven to be powerful tools for modeling long-range dependencies in sequential data. While the recent method known as HiPPO has demonstrated strong performance, and formed the basis for machine learning models S4 and Mamba, it remains limited by its reliance on closed-form solutions for a few specific, well-behaved bases. The SaFARi framework generalized this approach, enabling the construction of SSMs from arbitrary frames, including non-orthogonal and redundant ones, thus allowing an infinite diversity of possible \"species\" within the SSM family. In this paper, we introduce WaLRUS (Wavelets for Long-range Representation Using SSMs), a new implementation of SaFARi built from Daubechies wavelets.","authors":["Hossein Babaei","Mel White","Sina Alemohammad","Richard G. Baraniuk"],"url":"https://arxiv.org/abs/2505.12161"}
{"created":"2025-05-20","title":"CTLformer: A Hybrid Denoising Model Combining Convolutional Layers and Self-Attention for Enhanced CT Image Reconstruction","abstract":"Low-dose CT (LDCT) images are often accompanied by significant noise, which negatively impacts image quality and subsequent diagnostic accuracy. To address the challenges of multi-scale feature fusion and diverse noise distribution patterns in LDCT denoising, this paper introduces an innovative model, CTLformer, which combines convolutional structures with transformer architecture. Two key innovations are proposed: a multi-scale attention mechanism and a dynamic attention control mechanism. The multi-scale attention mechanism, implemented through the Token2Token mechanism and self-attention interaction modules, effectively captures both fine details and global structures at different scales, enhancing relevant features and suppressing noise. The dynamic attention control mechanism adapts the attention distribution based on the noise characteristics of the input image, focusing on high-noise regions while preserving details in low-noise areas, thereby enhancing robustness and improving denoising performance. Furthermore, CTLformer integrates convolutional layers for efficient feature extraction and uses overlapping inference to mitigate boundary artifacts, further strengthening its denoising capability. Experimental results on the 2016 National Institutes of Health AAPM Mayo Clinic LDCT Challenge dataset demonstrate that CTLformer significantly outperforms existing methods in both denoising performance and model efficiency, greatly improving the quality of LDCT images. The proposed CTLformer not only provides an efficient solution for LDCT denoising but also shows broad potential in medical image analysis, especially for clinical applications dealing with complex noise patterns.","authors":["Zhiting Zheng","Shuqi Wu","Wen Ding"],"url":"https://arxiv.org/abs/2505.12203"}
{"created":"2025-05-20","title":"Shallow Flow Matching for Coarse-to-Fine Text-to-Speech Synthesis","abstract":"We propose a shallow flow matching (SFM) mechanism to enhance flow matching (FM)-based text-to-speech (TTS) models within a coarse-to-fine generation paradigm. SFM constructs intermediate states along the FM paths using coarse output representations. During training, we introduce an orthogonal projection method to adaptively determine the temporal position of these states, and apply a principled construction strategy based on a single-segment piecewise flow. The SFM inference starts from the intermediate state rather than pure noise and focuses computation on the latter stages of the FM paths. We integrate SFM into multiple TTS models with a lightweight SFM head. Experiments show that SFM consistently improves the naturalness of synthesized speech in both objective and subjective evaluations, while significantly reducing inference when using adaptive-step ODE solvers. Demo and codes are available at https://ydqmkkx.github.io/SFMDemo/.","authors":["Dong Yang","Yiyi Cai","Yuki Saito","Lixu Wang","Hiroshi Saruwatari"],"url":"https://arxiv.org/abs/2505.12226"}
{"created":"2025-05-20","title":"PRETI: Patient-Aware Retinal Foundation Model via Metadata-Guided Representation Learning","abstract":"Retinal foundation models have significantly advanced retinal image analysis by leveraging self-supervised learning to reduce dependence on labeled data while achieving strong generalization. Many recent approaches enhance retinal image understanding using report supervision, but obtaining clinical reports is often costly and challenging. In contrast, metadata (e.g., age, gender) is widely available and serves as a valuable resource for analyzing disease progression. To effectively incorporate patient-specific information, we propose PRETI, a retinal foundation model that integrates metadata-aware learning with robust self-supervised representation learning. We introduce Learnable Metadata Embedding (LME), which dynamically refines metadata representations. Additionally, we construct patient-level data pairs, associating images from the same individual to improve robustness against non-clinical variations. To further optimize retinal image representation, we propose Retina-Aware Adaptive Masking (RAAM), a strategy that selectively applies masking within the retinal region and dynamically adjusts the masking ratio during training. PRETI captures both global structures and fine-grained pathological details, resulting in superior diagnostic performance. Extensive experiments demonstrate that PRETI achieves state-of-the-art results across diverse diseases and biomarker predictions using in-house and public data, indicating the importance of metadata-guided foundation models in retinal disease analysis. Our code and pretrained model are available at https://github.com/MICV-yonsei/PRETI","authors":["Yeonkyung Lee","Woojung Han","Youngjun Jun","Hyeonmin Kim","Jungkyung Cho","Seong Jae Hwang"],"url":"https://arxiv.org/abs/2505.12233"}
{"created":"2025-05-20","title":"OpenPros: A Large-Scale Dataset for Limited View Prostate Ultrasound Computed Tomography","abstract":"Prostate cancer is one of the most common and lethal cancers among men, making its early detection critically important. Although ultrasound imaging offers greater accessibility and cost-effectiveness compared to MRI, traditional transrectal ultrasound methods suffer from low sensitivity, especially in detecting anteriorly located tumors. Ultrasound computed tomography provides quantitative tissue characterization, but its clinical implementation faces significant challenges, particularly under anatomically constrained limited-angle acquisition conditions specific to prostate imaging. To address these unmet needs, we introduce OpenPros, the first large-scale benchmark dataset explicitly developed for limited-view prostate USCT. Our dataset includes over 280,000 paired samples of realistic 2D speed-of-sound (SOS) phantoms and corresponding ultrasound full-waveform data, generated from anatomically accurate 3D digital prostate models derived from real clinical MRI/CT scans and ex vivo ultrasound measurements, annotated by medical experts. Simulations are conducted under clinically realistic configurations using advanced finite-difference time-domain and Runge-Kutta acoustic wave solvers, both provided as open-source components. Through comprehensive baseline experiments, we demonstrate that state-of-the-art deep learning methods surpass traditional physics-based approaches in both inference efficiency and reconstruction accuracy. Nevertheless, current deep learning models still fall short of delivering clinically acceptable high-resolution images with sufficient accuracy. By publicly releasing OpenPros, we aim to encourage the development of advanced machine learning algorithms capable of bridging this performance gap and producing clinically usable, high-resolution, and highly accurate prostate ultrasound images. The dataset is publicly accessible at https://open-pros.github.io/.","authors":["Hanchen Wang","Yixuan Wu","Yinan Feng","Peng Jin","Shihang Feng","Yiming Mao","James Wiskin","Baris Turkbey","Peter A. Pinto","Bradford J. Wood","Songting Luo","Yinpeng Chen","Emad Boctor","Youzuo Lin"],"url":"https://arxiv.org/abs/2505.12261"}
{"created":"2025-05-20","title":"Vague Knowledge: Evidence from Analyst Reports","abstract":"People in the real world often possess vague knowledge of future payoffs, for which quantification is not feasible or desirable. We argue that language, with differing ability to convey vague information, plays an important but less known-role in subjective expectations. Empirically, we find that in their reports, analysts include useful information in linguistic expressions but not numerical forecasts. Specifically, the textual tone of analyst reports has predictive power for forecast errors and subsequent revisions in numerical forecasts, and this relation becomes stronger when analyst's language is vaguer, when uncertainty is higher, and when analysts are busier. Overall, our theory and evidence suggest that some useful information is vaguely known and only communicated through language.","authors":["Kerry Xiao","Amy Zang"],"url":"https://arxiv.org/abs/2505.12269"}
{"created":"2025-05-20","title":"Unified Architecture and Unsupervised Speech Disentanglement for Speaker Embedding-Free Enrollment in Personalized Speech Enhancement","abstract":"Conventional speech enhancement (SE) aims to improve speech perception and intelligibility by suppressing noise without requiring enrollment speech as reference, whereas personalized SE (PSE) addresses the cocktail party problem by extracting a target speaker's speech using enrollment speech. While these two tasks tackle different yet complementary challenges in speech signal processing, they often share similar model architectures, with PSE incorporating an additional branch to process enrollment speech. This suggests developing a unified model capable of efficiently handling both SE and PSE tasks, thereby simplifying deployment while maintaining high performance. However, PSE performance is sensitive to variations in enrollment speech, like emotional tone, which limits robustness in real-world applications. To address these challenges, we propose two novel models, USEF-PNet and DSEF-PNet, both extending our previous SEF-PNet framework. USEF-PNet introduces a unified architecture for processing enrollment speech, integrating SE and PSE into a single framework to enhance performance and streamline deployment. Meanwhile, DSEF-PNet incorporates an unsupervised speech disentanglement approach by pairing a mixture speech with two different enrollment utterances and enforcing consistency in the extracted target speech. This strategy effectively isolates high-quality speaker identity information from enrollment speech, reducing interference from factors such as emotion and content, thereby improving PSE robustness. Additionally, we explore a long-short enrollment pairing (LSEP) strategy to examine the impact of enrollment speech duration during both training and evaluation. Extensive experiments on the Libri2Mix and VoiceBank DEMAND demonstrate that our proposed USEF-PNet, DSEF-PNet all achieve substantial performance improvements, with random enrollment duration performing slightly better.","authors":["Ziling Huang","Haixin Guan","Yanhua Long"],"url":"https://arxiv.org/abs/2505.12288"}
{"created":"2025-05-20","title":"Attention-Enhanced U-Net for Accurate Segmentation of COVID-19 Infected Lung Regions in CT Scans","abstract":"In this study, we propose a robust methodology for automatic segmentation of infected lung regions in COVID-19 CT scans using convolutional neural networks. The approach is based on a modified U-Net architecture enhanced with attention mechanisms, data augmentation, and postprocessing techniques. It achieved a Dice coefficient of 0.8658 and mean IoU of 0.8316, outperforming other methods. The dataset was sourced from public repositories and augmented for diversity. Results demonstrate superior segmentation performance. Future work includes expanding the dataset, exploring 3D segmentation, and preparing the model for clinical deployment.","authors":["Amal Lahchim (University of Kragujevac)","Lazar Davic (University of Kragujevac)"],"url":"https://arxiv.org/abs/2505.12298"}
{"created":"2025-05-20","title":"Finite-time stabilization of ladder multi-level quantum systems","abstract":"In this paper, a novel continuous non-smooth control strategy is proposed to achieve finite-time stabilization of ladder quantum systems. We first design a universal fractional-order control law for a ladder n-level quantum system using a distance-based Lyapunov function, and then apply the Filippov solution in the sense of differential inclusions and the LaSalle's invariance principle to prove the existence and uniqueness of the solution of the ladder system under the continuous non-smooth control law. Both asymptotic stability and finite-time stability for the ladder system is rigorously established by applying Lyapunov stability theory and finite-time stability criteria. We also derive an upper bound of the time required for convergence to an eigenstate of the intrinsic Hamiltonian. Numerical simulations on a rubidium ladder three-level atomic system validate the effectiveness of the proposed method.","authors":["Zeping Su","Sen Kuang","Daoyi Dong"],"url":"https://arxiv.org/abs/2505.12303"}
{"created":"2025-05-20","title":"LaPON: A Lagrange's-mean-value-theorem-inspired operator network for solving PDEs and its application on NSE","abstract":"Accelerating the solution of nonlinear partial differential equations (PDEs) while maintaining accuracy at coarse spatiotemporal resolution remains a key challenge in scientific computing. Physics-informed machine learning (ML) methods such as Physics-Informed Neural Networks (PINNs) introduce prior knowledge through loss functions to ensure physical consistency, but their \"soft constraints\" are usually not strictly satisfied. Here, we propose LaPON, an operator network inspired by the Lagrange's mean value theorem, which embeds prior knowledge directly into the neural network architecture instead of the loss function, making the neural network naturally satisfy the given constraints. This is a hybrid framework that combines neural operators with traditional numerical methods, where neural operators are used to compensate for the effect of discretization errors on the analytical scale in under-resolution simulations. As evaluated on turbulence problem modeled by the Navier-Stokes equations (NSE), the multiple time step extrapolation accuracy and stability of LaPON exceed the direct numerical simulation baseline at 8x coarser grids and 8x larger time steps, while achieving a vorticity correlation of more than 0.98 with the ground truth. It is worth noting that the model can be well generalized to unseen flow states, such as turbulence with different forcing, without retraining. In addition, with the same training data, LaPON's comprehensive metrics on the out-of-distribution test set are at least approximately twice as good as two popular ML baseline methods. By combining numerical computing with machine learning, LaPON provides a scalable and reliable solution for high-fidelity fluid dynamics simulation, showing the potential for wide application in fields such as weather forecasting and engineering design.","authors":["Siwen Zhang","Xizeng Zhao","Zhengzhi Deng","Zhaoyuan Huang","Gang Tao","Nuo Xu","Zhouteng Ye"],"url":"https://arxiv.org/abs/2505.12360"}
{"created":"2025-05-20","title":"Trustworthy Image Super-Resolution via Generative Pseudoinverse","abstract":"We consider the problem of trustworthy image restoration, taking the form of a constrained optimization over the prior density. To this end, we develop generative models for the task of image super-resolution that respect the degradation process and that can be made asymptotically consistent with the low-resolution measurements, outperforming existing methods by a large margin in that respect.","authors":["Andreas Floros","Seyed-Mohsen Moosavi-Dezfooli","Pier Luigi Dragotti"],"url":"https://arxiv.org/abs/2505.12375"}
{"created":"2025-05-20","title":"Efficient Optimization with Orthogonality Constraint: a Randomized Riemannian Submanifold Method","abstract":"Optimization with orthogonality constraints frequently arises in various fields such as machine learning. Riemannian optimization offers a powerful framework for solving these problems by equipping the constraint set with a Riemannian manifold structure and performing optimization intrinsically on the manifold. This approach typically involves computing a search direction in the tangent space and updating variables via a retraction operation. However, as the size of the variables increases, the computational cost of the retraction can become prohibitively high, limiting the applicability of Riemannian optimization to large-scale problems. To address this challenge and enhance scalability, we propose a novel approach that restricts each update on a random submanifold, thereby significantly reducing the per-iteration complexity. We introduce two sampling strategies for selecting the random submanifolds and theoretically analyze the convergence of the proposed methods. We provide convergence results for general nonconvex functions and functions that satisfy Riemannian Polyak-Lojasiewicz condition as well as for stochastic optimization settings. Additionally, we demonstrate how our approach can be generalized to quotient manifolds derived from the orthogonal manifold. Extensive experiments verify the benefits of the proposed method, across a wide variety of problems.","authors":["Andi Han","Pierre-Louis Poirion","Akiko Takeda"],"url":"https://arxiv.org/abs/2505.12378"}
{"created":"2025-05-20","title":"High-dimensional Optimization with Low Rank Tensor Sampling and Local Search","abstract":"We present a novel method called TESALOCS (TEnsor SAmpling and LOCal Search) for multidimensional optimization, combining the strengths of gradient-free discrete methods and gradient-based approaches. The discrete optimization in our method is based on low-rank tensor techniques, which, thanks to their low-parameter representation, enable efficient optimization of high-dimensional problems. For the second part, i.e., local search, any effective gradient-based method can be used, whether existing (such as quasi-Newton methods) or any other developed in the future. Our approach addresses the limitations of gradient-based methods, such as getting stuck in local optima; the limitations of discrete methods, which cannot be directly applied to continuous functions; and limitations of gradient-free methods that require large computational budgets. Note that we are not limited to a single type of low-rank tensor decomposition for discrete optimization, but for illustrative purposes, we consider a specific efficient low-rank tensor train decomposition. For 20 challenging 100-dimensional functions, we demonstrate that our method can significantly outperform results obtained with gradient-based methods like Conjugate Gradient, BFGS, SLSQP, and other methods, improving them by orders of magnitude with the same computing budget.","authors":["Konstantin Sozykin","Andrei Chertkov","Anh-Huy Phan","Ivan Oseledets","Gleb Ryzhakov"],"url":"https://arxiv.org/abs/2505.12383"}
{"created":"2025-05-20","title":"Resolving the Double Near-Far Problem via Wireless Powered Pinching-Antenna Networks","abstract":"This letter introduces a novel wireless powered communication system, referred to as a wireless powered pinching-antenna network (WPPAN), utilizing a single waveguide with pinching antennas to address the double near-far problem inherent in wireless powered networks. In the proposed WPPAN, users harvest energy from spatially distributed pinching antennas in the downlink and use the collected power to transmit messages in the uplink. Furthermore, to manage the combinatorial complexity associated with activating the pinching antennas, we propose three approaches of varying complexity to simplify the original resource allocation problem and then solve it efficiently using convex optimization methods. Simulation results confirm that the proposed WPPAN system effectively mitigates the double near-far problem by providing antenna resources closer to the users, thereby enhancing both downlink energy harvesting and uplink data transmission.","authors":["Vasilis K. Papanikolaou","Gui Zhou","Brikena Kaziu","Ata Khalili","Panagiotis D. Diamantoulakis","George K. Karagiannidis","Robert Schober"],"url":"https://arxiv.org/abs/2505.12403"}
{"created":"2025-05-20","title":"Training Latent Diffusion Models with Interacting Particle Algorithms","abstract":"We introduce a novel particle-based algorithm for end-to-end training of latent diffusion models. We reformulate the training task as minimizing a free energy functional and obtain a gradient flow that does so. By approximating the latter with a system of interacting particles, we obtain the algorithm, which we underpin it theoretically by providing error guarantees. The novel algorithm compares favorably in experiments with previous particle-based methods and variational inference analogues.","authors":["Tim Y. J. Wang","Juan Kuntz","O. Deniz Akyildiz"],"url":"https://arxiv.org/abs/2505.12412"}
{"created":"2025-05-20","title":"Mutual Evidential Deep Learning for Medical Image Segmentation","abstract":"Existing semi-supervised medical segmentation co-learning frameworks have realized that model performance can be diminished by the biases in model recognition caused by low-quality pseudo-labels. Due to the averaging nature of their pseudo-label integration strategy, they fail to explore the reliability of pseudo-labels from different sources. In this paper, we propose a mutual evidential deep learning (MEDL) framework that offers a potentially viable solution for pseudo-label generation in semi-supervised learning from two perspectives. First, we introduce networks with different architectures to generate complementary evidence for unlabeled samples and adopt an improved class-aware evidential fusion to guide the confident synthesis of evidential predictions sourced from diverse architectural networks. Second, utilizing the uncertainty in the fused evidence, we design an asymptotic Fisher information-based evidential learning strategy. This strategy enables the model to initially focus on unlabeled samples with more reliable pseudo-labels, gradually shifting attention to samples with lower-quality pseudo-labels while avoiding over-penalization of mislabeled classes in high data uncertainty samples. Additionally, for labeled data, we continue to adopt an uncertainty-driven asymptotic learning strategy, gradually guiding the model to focus on challenging voxels. Extensive experiments on five mainstream datasets have demonstrated that MEDL achieves state-of-the-art performance.","authors":["Yuanpeng He","Yali Bi","Lijian Li","Chi-Man Pun","Wenpin Jiao","Zhi Jin"],"url":"https://arxiv.org/abs/2505.12418"}
{"created":"2025-05-20","title":"High-Dimensional Dynamic Covariance Models with Random Forests","abstract":"This paper introduces a novel nonparametric method for estimating high-dimensional dynamic covariance matrices with multiple conditioning covariates, leveraging random forests and supported by robust theoretical guarantees. Unlike traditional static methods, our dynamic nonparametric covariance models effectively capture distributional heterogeneity. Furthermore, unlike kernel-smoothing methods, which are restricted to a single conditioning covariate, our approach accommodates multiple covariates in a fully nonparametric framework. To the best of our knowledge, this is the first method to use random forests for estimating high-dimensional dynamic covariance matrices. In high-dimensional settings, we establish uniform consistency theory, providing nonasymptotic error rates and model selection properties, even when the response dimension grows sub-exponentially with the sample size. These results hold uniformly across a range of conditioning variables. The method's effectiveness is demonstrated through simulations and a stock dataset analysis, highlighting its ability to model complex dynamics in high-dimensional scenarios.","authors":["Shuguang Yu","Fan Zhou","Yingjie Zhang","Ziqi Chen","Hongtu Zhu"],"url":"https://arxiv.org/abs/2505.12444"}
{"created":"2025-05-20","title":"Wasserstein Barycenter Gaussian Process based Bayesian Optimization","abstract":"Gaussian Process based Bayesian Optimization is a widely applied algorithm to learn and optimize under uncertainty, well-known for its sample efficiency. However, recently -- and more frequently -- research studies have empirically demonstrated that the Gaussian Process fitting procedure at its core could be its most relevant weakness. Fitting a Gaussian Process means tuning its kernel's hyperparameters to a set of observations, but the common Maximum Likelihood Estimation technique, usually appropriate for learning tasks, has shown different criticalities in Bayesian Optimization, making theoretical analysis of this algorithm an open challenge. Exploiting the analogy between Gaussian Processes and Gaussian Distributions, we present a new approach which uses a prefixed set of hyperparameters values to fit as many Gaussian Processes and then combines them into a unique model as a Wasserstein Barycenter of Gaussian Processes. We considered both \"easy\" test problems and others known to undermine the \\textit{vanilla} Bayesian Optimization algorithm. The new method, namely Wasserstein Barycenter Gausssian Process based Bayesian Optimization (WBGP-BO), resulted promising and able to converge to the optimum, contrary to vanilla Bayesian Optimization, also on the most \"tricky\" test problems.","authors":["Antonio Candelieri","Andrea Ponti","Francesco Archetti"],"url":"https://arxiv.org/abs/2505.12471"}
{"created":"2025-05-20","title":"Multi-modal contrastive learning adapts to intrinsic dimensions of shared latent variables","abstract":"Multi-modal contrastive learning as a self-supervised representation learning technique has achieved great success in foundation model training, such as CLIP~\\citep{radford2021learning}. In this paper, we study the theoretical properties of the learned representations from multi-modal contrastive learning beyond linear representations and specific data distributions. Our analysis reveals that, enabled by temperature optimization, multi-modal contrastive learning not only maximizes mutual information between modalities but also adapts to intrinsic dimensions of data, which can be much lower than user-specified dimensions for representation vectors. Experiments on both synthetic and real-world datasets demonstrate the ability of contrastive learning to learn low-dimensional and informative representations, bridging theoretical insights and practical performance.","authors":["Yu Gui","Cong Ma","Zongming Ma"],"url":"https://arxiv.org/abs/2505.12473"}
{"created":"2025-05-20","title":"Efficient Implementation of Gaussian Process Regression Accelerated Saddle Point Searches with Application to Molecular Reactions","abstract":"The task of locating first order saddle points on high-dimensional surfaces describing the variation of energy as a function of atomic coordinates is an essential step for identifying the mechanism and estimating the rate of thermally activated events within the harmonic approximation of transition state theory. When combined directly with electronic structure calculations, the number of energy and atomic force evaluations needed for convergence is a primary issue. Here, we describe an efficient implementation of Gaussian process regression (GPR) acceleration of the minimum mode following method where a dimer is used to estimate the lowest eigenmode of the Hessian. A surrogate energy surface is constructed and updated after each electronic structure calculation. The method is applied to a test set of 500 molecular reactions previously generated by Hermez and coworkers [J. Chem. Theory Comput. 18, 6974 (2022)]. An order of magnitude reduction in the number of electronic structure calculations needed to reach the saddle point configurations is obtained by using the GPR compared to the dimer method. Despite the wide range in stiffness of the molecular degrees of freedom, the calculations are carried out using Cartesian coordinates and are found to require similar number of electronic structure calculations as an elaborate internal coordinate method implemented in the Sella software package. The present implementation of the GPR surrogate model in C++ is efficient enough for the wall time of the saddle point searches to be reduced in 3 out of 4 cases even though the calculations are carried out at a low Hartree-Fock level.","authors":["Rohit Goswami (Science Institute and Faculty of Physical Sciences","University of Iceland","Reykjav\\'ik","Iceland)","Maxim Masterov (SURF","Amsterdam","The Netherlands)","Satish Kamath (SURF","Amsterdam","The Netherlands)","Alejandro Pe\\~na-Torres (Science Institute and Faculty of Physical Sciences","University of Iceland","Reykjav\\'ik","Iceland)","Hannes J\\'onsson (Science Institute and Faculty of Physical Sciences","University of Iceland","Reykjav\\'ik","Iceland)"],"url":"https://arxiv.org/abs/2505.12519"}
{"created":"2025-05-20","title":"Development of a non-wearable support robot capable of reproducing natural standing-up movements","abstract":"To reproduce natural standing-up motion, recent studies have emphasized the importance of coordination between the assisting robot and the human. However, many non-wearable assistive devices have struggled to replicate natural motion trajectories. While wearable devices offer better coordination with the human body, they present challenges in completely isolating mechanical and electrical hazards. To address this, we developed a novel standing-assist robot that integrates features of both wearable and non-wearable systems, aiming to achieve high coordination while maintaining safety. The device employs a four-link mechanism aligned with the human joint structure, designed to reproduce the S-shaped trajectory of the hip and the arc trajectory of the knee during natural standing-up motion. Subject-specific trajectory data were obtained using a gyroscope, and the link lengths were determined to drive the seat along the optimal path. A feedforward speed control using a stepping motor was implemented, and the reproducibility of the trajectory was evaluated based on the geometric constraints of the mechanism. A load-bearing experiment with weights fixed to the seat was conducted to assess the trajectory accuracy under different conditions. Results showed that the reproduction errors for the hip and knee trajectories remained within approximately 4 percent of the seat's total displacement, demonstrating high fidelity to the target paths. In addition, durability testing, thermal safety evaluation, and risk assessment confirmed the reliability and safety of the system for indoor use. These findings suggest that the proposed design offers a promising approach for developing assistive technologies that adapt to individual physical characteristics, with potential applications in elderly care and rehabilitation.","authors":["Atsuya Kusui","Susumu Hirai","Asuka Takai"],"url":"https://arxiv.org/abs/2505.12525"}
{"created":"2025-05-20","title":"Nonlinear Laplacians: Tunable principal component analysis under directional prior information","abstract":"We introduce a new family of algorithms for detecting and estimating a rank-one signal from a noisy observation under prior information about that signal's direction, focusing on examples where the signal is known to have entries biased to be positive. Given a matrix observation $\\mathbf{Y}$, our algorithms construct a nonlinear Laplacian, another matrix of the form $\\mathbf{Y} + \\mathrm{diag}(\\sigma(\\mathbf{Y}\\mathbf{1}))$ for a nonlinear $\\sigma: \\mathbb{R} \\to \\mathbb{R}$, and examine the top eigenvalue and eigenvector of this matrix. When $\\mathbf{Y}$ is the (suitably normalized) adjacency matrix of a graph, our approach gives a class of algorithms that search for unusually dense subgraphs by computing a spectrum of the graph \"deformed\" by the degree profile $\\mathbf{Y}\\mathbf{1}$. We study the performance of such algorithms compared to direct spectral algorithms (the case $\\sigma = 0$) on models of sparse principal component analysis with biased signals, including the Gaussian planted submatrix problem. For such models, we rigorously characterize the critical threshold strength of rank-one signal, as a function of the nonlinearity $\\sigma$, at which an outlier eigenvalue appears in the spectrum of a nonlinear Laplacian. While identifying the $\\sigma$ that minimizes this critical signal strength in closed form seems intractable, we explore three approaches to design $\\sigma$ numerically: exhaustively searching over simple classes of $\\sigma$, learning $\\sigma$ from datasets of problem instances, and tuning $\\sigma$ using black-box optimization of the critical signal strength. We find both theoretically and empirically that, if $\\sigma$ is chosen appropriately, then nonlinear Laplacian spectral algorithms substantially outperform direct spectral algorithms, while avoiding the complexity of broader classes of algorithms like approximate message passing or general first order methods.","authors":["Yuxin Ma","Dmitriy Kunisky"],"url":"https://arxiv.org/abs/2505.12528"}
{"created":"2025-05-20","title":"FreqSelect: Frequency-Aware fMRI-to-Image Reconstruction","abstract":"Reconstructing natural images from functional magnetic resonance imaging (fMRI) data remains a core challenge in natural decoding due to the mismatch between the richness of visual stimuli and the noisy, low resolution nature of fMRI signals. While recent two-stage models, combining deep variational autoencoders (VAEs) with diffusion models, have advanced this task, they treat all spatial-frequency components of the input equally. This uniform treatment forces the model to extract meaning features and suppress irrelevant noise simultaneously, limiting its effectiveness. We introduce FreqSelect, a lightweight, adaptive module that selectively filters spatial-frequency bands before encoding. By dynamically emphasizing frequencies that are most predictive of brain activity and suppressing those that are uninformative, FreqSelect acts as a content-aware gate between image features and natural data. It integrates seamlessly into standard very deep VAE-diffusion pipelines and requires no additional supervision. Evaluated on the Natural Scenes dataset, FreqSelect consistently improves reconstruction quality across both low- and high-level metrics. Beyond performance gains, the learned frequency-selection patterns offer interpretable insights into how different visual frequencies are represented in the brain. Our method generalizes across subjects and scenes, and holds promise for extension to other neuroimaging modalities, offering a principled approach to enhancing both decoding accuracy and neuroscientific interpretability.","authors":["Junliang Ye","Lei Wang","Md Zakir Hossain"],"url":"https://arxiv.org/abs/2505.12552"}
{"created":"2025-05-20","title":"Hamiltonian Descent Algorithms for Optimization: Accelerated Rates via Randomized Integration Time","abstract":"We study the Hamiltonian flow for optimization (HF-opt), which simulates the Hamiltonian dynamics for some integration time and resets the velocity to $0$ to decrease the objective function; this is the optimization analogue of the Hamiltonian Monte Carlo algorithm for sampling. For short integration time, HF-opt has the same convergence rates as gradient descent for minimizing strongly and weakly convex functions. We show that by randomizing the integration time in HF-opt, the resulting randomized Hamiltonian flow (RHF) achieves accelerated convergence rates in continuous time, similar to the rates for the accelerated gradient flow. We study a discrete-time implementation of RHF as the randomized Hamiltonian gradient descent (RHGD) algorithm. We prove that RHGD achieves the same accelerated convergence rates as Nesterov's accelerated gradient descent (AGD) for minimizing smooth strongly and weakly convex functions. We provide numerical experiments to demonstrate that RHGD is competitive with classical accelerated methods such as AGD across all settings and outperforms them in certain regimes.","authors":["Qiang Fu","Andre Wibisono"],"url":"https://arxiv.org/abs/2505.12553"}
{"created":"2025-05-20","title":"Acoustic Field Reconstruction in Tubes via Physics-Informed Neural Networks","abstract":"This study investigates the application of Physics-Informed Neural Networks (PINNs) to inverse problems in acoustic tube analysis, focusing on reconstructing acoustic fields from noisy and limited observation data. Specifically, we address scenarios where the radiation model is unknown, and pressure data is only available at the tube's radiation end. A PINNs framework is proposed to reconstruct the acoustic field, along with the PINN Fine-Tuning Method (PINN-FTM) and a traditional optimization method (TOM) for predicting radiation model coefficients. The results demonstrate that PINNs can effectively reconstruct the tube's acoustic field under noisy conditions, even with unknown radiation parameters. PINN-FTM outperforms TOM by delivering balanced and reliable predictions and exhibiting robust noise-tolerance capabilities.","authors":["Xinmeng Luan","Kazuya Yokota","Gary Scavone"],"url":"https://arxiv.org/abs/2505.12557"}
{"created":"2025-05-20","title":"Stacked conformal prediction","abstract":"We consider the conformalization of a stacked ensemble of predictive models, showing that the potentially simple form of the meta-learner at the top of the stack enables a procedure with manageable computational cost that achieves approximate marginal validity without requiring the use of a separate calibration sample. Empirical results indicate that the method compares favorably to a standard inductive alternative.","authors":["Paulo C. Marques F"],"url":"https://arxiv.org/abs/2505.12578"}
{"created":"2025-05-20","title":"Accelerated Markov Chain Monte Carlo Algorithms on Discrete States","abstract":"We propose a class of discrete state sampling algorithms based on Nesterov's accelerated gradient method, which extends the classical Metropolis-Hastings (MH) algorithm. The evolution of the discrete states probability distribution governed by MH can be interpreted as a gradient descent direction of the Kullback--Leibler (KL) divergence, via a mobility function and a score function. Specifically, this gradient is defined on a probability simplex equipped with a discrete Wasserstein-2 metric with a mobility function. This motivates us to study a momentum-based acceleration framework using damped Hamiltonian flows on the simplex set, whose stationary distribution matches the discrete target distribution. Furthermore, we design an interacting particle system to approximate the proposed accelerated sampling dynamics. The extension of the algorithm with a general choice of potentials and mobilities is also discussed. In particular, we choose the accelerated gradient flow of the relative Fisher information, demonstrating the advantages of the algorithm in estimating discrete score functions without requiring the normalizing constant and keeping positive probabilities. Numerical examples, including sampling on a Gaussian mixture supported on lattices or a distribution on a hypercube, demonstrate the effectiveness of the proposed discrete-state sampling algorithm.","authors":["Bohan Zhou","Shu Liu","Xinzhe Zuo","Wuchen Li"],"url":"https://arxiv.org/abs/2505.12599"}
{"created":"2025-05-20","title":"scSiameseClu: A Siamese Clustering Framework for Interpreting single-cell RNA Sequencing Data","abstract":"Single-cell RNA sequencing (scRNA-seq) reveals cell heterogeneity, with cell clustering playing a key role in identifying cell types and marker genes. Recent advances, especially graph neural networks (GNNs)-based methods, have significantly improved clustering performance. However, the analysis of scRNA-seq data remains challenging due to noise, sparsity, and high dimensionality. Compounding these challenges, GNNs often suffer from over-smoothing, limiting their ability to capture complex biological information. In response, we propose scSiameseClu, a novel Siamese Clustering framework for interpreting single-cell RNA-seq data, comprising of 3 key steps: (1) Dual Augmentation Module, which applies biologically informed perturbations to the gene expression matrix and cell graph relationships to enhance representation robustness; (2) Siamese Fusion Module, which combines cross-correlation refinement and adaptive information fusion to capture complex cellular relationships while mitigating over-smoothing; and (3) Optimal Transport Clustering, which utilizes Sinkhorn distance to efficiently align cluster assignments with predefined proportions while maintaining balance. Comprehensive evaluations on seven real-world datasets demonstrate that~\\methodname~outperforms state-of-the-art methods in single-cell clustering, cell type annotation, and cell type classification, providing a powerful tool for scRNA-seq data interpretation.","authors":["Ping Xu","Zhiyuan Ning","Pengjiang Li","Wenhao Liu","Pengyang Wang","Jiaxu Cui","Yuanchun Zhou","Pengfei Wang"],"url":"https://arxiv.org/abs/2505.12626"}
{"created":"2025-05-20","title":"ChromFound: Towards A Universal Foundation Model for Single-Cell Chromatin Accessibility Data","abstract":"The advent of single-cell Assay for Transposase-Accessible Chromatin using sequencing (scATAC-seq) offers an innovative perspective for deciphering regulatory mechanisms by assembling a vast repository of single-cell chromatin accessibility data. While foundation models have achieved significant success in single-cell transcriptomics, there is currently no foundation model for scATAC-seq that supports zero-shot high-quality cell identification and comprehensive multi-omics analysis simultaneously. Key challenges lie in the high dimensionality and sparsity of scATAC-seq data, as well as the lack of a standardized schema for representing open chromatin regions (OCRs). Here, we present \\textbf{ChromFound}, a foundation model tailored for scATAC-seq. ChromFound utilizes a hybrid architecture and genome-aware tokenization to effectively capture genome-wide long contexts and regulatory signals from dynamic chromatin landscapes. Pretrained on 1.97 million cells from 30 tissues and 6 disease conditions, ChromFound demonstrates broad applicability across 6 diverse tasks. Notably, it achieves robust zero-shot performance in generating universal cell representations and exhibits excellent transferability in cell type annotation and cross-omics prediction. By uncovering enhancer-gene links undetected by existing computational methods, ChromFound offers a promising framework for understanding disease risk variants in the noncoding genome.","authors":["Yifeng Jiao","Yuchen Liu","Yu Zhang","Xin Guo","Yushuai Wu","Chen Jiang","Jiyang Li","Hongwei Zhang","Limei Han","Xin Gao","Yuan Qi","Yuan Cheng"],"url":"https://arxiv.org/abs/2505.12638"}
{"created":"2025-05-20","title":"Multi-View Wireless Sensing via Conditional Generative Learning: Framework and Model Design","abstract":"In this paper, we incorporate physical knowledge into learning-based high-precision target sensing using the multi-view channel state information (CSI) between multiple base stations (BSs) and user equipment (UEs). Such kind of multi-view sensing problem can be naturally cast into a conditional generation framework. To this end, we design a bipartite neural network architecture, the first part of which uses an elaborately designed encoder to fuse the latent target features embedded in the multi-view CSI, and then the second uses them as conditioning inputs of a powerful generative model to guide the target's reconstruction. Specifically, the encoder is designed to capture the physical correlation between the CSI and the target, and also be adaptive to the numbers and positions of BS-UE pairs. Therein the view-specific nature of CSI is assimilated by introducing a spatial positional embedding scheme, which exploits the structure of electromagnetic(EM)-wave propagation channels. Finally, a conditional diffusion model with a weighted loss is employed to generate the target's point cloud from the fused features. Extensive numerical results demonstrate that the proposed generative multi-view (Gen-MV) sensing framework exhibits excellent flexibility and significant performance improvement on the reconstruction quality of target's shape and EM properties.","authors":["Ziqing Xing","Zhaoyang Zhang","Zirui Chen","Hongning Ruan","Zhaohui Yang"],"url":"https://arxiv.org/abs/2505.12664"}
{"created":"2025-05-20","title":"Independent Set Enumeration in King Graphs by Tensor Network Contractions","abstract":"This paper discusses the enumeration of independent sets in king graphs of size $m \\times n$, based on the tensor network contractions algorithm given in reference~\\cite{tilEnum}. We transform the problem into Wang tiling enumeration within an $(m+1) \\times (n+1)$ rectangle and compute the results for all cases where $m + n \\leq 79$ using tensor network contraction algorithm, and provided an approximation for larger $m, n$.","authors":["Kai Liang"],"url":"https://arxiv.org/abs/2505.12776"}
{"created":"2025-05-20","title":"Adaptive Inference through Bayesian and Inverse Bayesian Inference with Symmetry-Bias in Nonstationary Environments","abstract":"This study introduces a novel inference framework, designated as Bayesian and inverse Bayesian (BIB) inference, which concurrently performs both conventional and inverse Bayesian updates by integrating symmetry bias into Bayesian inference. The effectiveness of the model was evaluated through a sequential estimation task involving observations sampled from a Gaussian distribution with a stochastically time-varying mean. Conventional Bayesian inference entails a fundamental trade-off between adaptability to abrupt environmental shifts and estimation accuracy during stable intervals. The BIB framework addresses this limitation by dynamically modulating the learning rate through inverse Bayesian updates, thereby enhancing adaptive flexibility. The BIB model generated spontaneous bursts in the learning rate during sudden environmental transitions, transiently entering a high-sensitivity state to accommodate incoming data. This intermittent burst-relaxation pattern functions as a dynamic mechanism that balances adaptability and accuracy. Further analysis of burst interval distributions demonstrated that the BIB model consistently produced power-law distributions under diverse conditions. Such robust scaling behavior, absent in conventional Bayesian inference, appears to emerge from a self-regulatory mechanism driven by inverse Bayesian updates. These results present a novel computational perspective on scale-free phenomena in natural systems and offer implications for designing adaptive inference systems in nonstationary environments.","authors":["Shuji Shinohara","Daiki Morita","Hayato Hirai","Ryosuke Kuribayashi","Nobuhito Manome","Toru Moriyama","Yoshihiro Nakajima","Yukio-Pegio Gunji","Ung-il Chung"],"url":"https://arxiv.org/abs/2505.12796"}
{"created":"2025-05-20","title":"Testing Identifiability and Transportability with Observational and Experimental Data","abstract":"Transporting causal information learned from experiments in one population to another is a critical challenge in clinical research and decision-making. Causal transportability uses causal graphs to model differences between the source and target populations and identifies conditions under which causal effects learned from experiments can be reused in a different population. Similarly, causal identifiability identifies conditions under which causal effects can be estimated from observational data. However, these approaches rely on knowing the causal graph, which is often unavailable in real-world settings. In this work, we propose a Bayesian method for assessing whether Z-specific (conditional) causal effects are both identifiable and transportable, without knowing the causal graph. Our method combines experimental data from the source population with observational data from the target population to compute the probability that a causal effect is both identifiable from observational data and transportable. When this holds, we leverage both observational data from the target domain and experimental data from the source domain to obtain an unbiased, efficient estimator of the causal effect in the target population. Using simulations, we demonstrate that our method correctly identifies transportable causal effects and improves causal effect estimation.","authors":["Konstantina Lelova","Gregory F. Cooper","Sofia Triantafillou"],"url":"https://arxiv.org/abs/2505.12801"}
{"created":"2025-05-20","title":"Hierarchical Representations for Evolving Acyclic Vector Autoregressions (HEAVe)","abstract":"Causal networks offer an intuitive framework to understand influence structures within time series systems. However, the presence of cycles can obscure dynamic relationships and hinder hierarchical analysis. These networks are typically identified through multivariate predictive modelling, but enforcing acyclic constraints significantly increases computational and analytical complexity. Despite recent advances, there remains a lack of simple, flexible approaches that are easily tailorable to specific problem instances. We propose an evolutionary approach to fitting acyclic vector autoregressive processes and introduces a novel hierarchical representation that directly models structural elements within a time series system. On simulated datasets, our model retains most of the predictive accuracy of unconstrained models and outperforms permutation-based alternatives. When applied to a dataset of 100 cryptocurrency return series, our method generates acyclic causal networks capturing key structural properties of the unconstrained model. The acyclic networks are approximately sub-graphs of the unconstrained networks, and most of the removed links originate from low-influence nodes. Given the high levels of feature preservation, we conclude that this cryptocurrency price system functions largely hierarchically. Our findings demonstrate a flexible, intuitive approach for identifying hierarchical causal networks in time series systems, with broad applications to fields like econometrics and social network analysis.","authors":["Cameron Cornell","Lewis Mitchell","Matthew Roughan"],"url":"https://arxiv.org/abs/2505.12806"}
{"created":"2025-05-20","title":"Ergodic properties of concurrent systems","abstract":"A concurrent system is defined as a monoid action of a trace monoid on a finite set of states. Concurrent systems represent state models where the state is distributed and where state changes are local. Starting from a spectral property on the combinatorics of concurrent systems, we prove the existence and uniqueness of a Markov measure on the space of infinite trajectories relatively to any weight distributions. In turn, we obtain a combinatorial result by proving that the kernel of the associated M\\\"obius matrix has dimension 1; the M\\\"obius matrix extends in this context the M\\\"obius polynomial of a trace monoid. We study ergodic properties of irreducible concurrent systems and we prove a Strong law of large numbers. It allows us to introduce the speedup as a measurement of the average amount of concurrency within infinite trajectories. Examples are studied.","authors":["Samy Abbes","Vincent Jug\\'e"],"url":"https://arxiv.org/abs/2505.12810"}
{"created":"2025-05-20","title":"The Gaussian Latent Machine: Efficient Prior and Posterior Sampling for Inverse Problems","abstract":"We consider the problem of sampling from a product-of-experts-type model that encompasses many standard prior and posterior distributions commonly found in Bayesian imaging. We show that this model can be easily lifted into a novel latent variable model, which we refer to as a Gaussian latent machine. This leads to a general sampling approach that unifies and generalizes many existing sampling algorithms in the literature. Most notably, it yields a highly efficient and effective two-block Gibbs sampling approach in the general case, while also specializing to direct sampling algorithms in particular cases. Finally, we present detailed numerical experiments that demonstrate the efficiency and effectiveness of our proposed sampling approach across a wide range of prior and posterior sampling problems from Bayesian imaging.","authors":["Muhamed Kuric","Martin Zach","Andreas Habring","Michael Unser","Thomas Pock"],"url":"https://arxiv.org/abs/2505.12836"}
{"created":"2025-05-20","title":"A Comprehensive Benchmarking Platform for Deep Generative Models in Molecular Design","abstract":"The development of novel pharmaceuticals represents a significant challenge in modern science, with substantial costs and time investments. Deep generative models have emerged as promising tools for accelerating drug discovery by efficiently exploring the vast chemical space. However, this rapidly evolving field lacks standardized evaluation protocols, impeding fair comparison between approaches. This research presents an extensive analysis of the Molecular Sets (MOSES) platform, a comprehensive benchmarking framework designed to standardize evaluation of deep generative models in molecular design. Through rigorous assessment of multiple generative architectures, including recurrent neural networks, variational autoencoders, and generative adversarial networks, we examine their capabilities in generating valid, unique, and novel molecular structures while maintaining specific chemical properties. Our findings reveal that different architectures exhibit complementary strengths across various metrics, highlighting the complex trade-offs between exploration and exploitation in chemical space. This study provides detailed insights into the current state of the art in molecular generation and establishes a foundation for future advancements in AI-driven drug discovery.","authors":["Adarsh Singh"],"url":"https://arxiv.org/abs/2505.12848"}
{"created":"2025-05-20","title":"Causality-Inspired Robustness for Nonlinear Models via Representation Learning","abstract":"Distributional robustness is a central goal of prediction algorithms due to the prevalent distribution shifts in real-world data. The prediction model aims to minimize the worst-case risk among a class of distributions, a.k.a., an uncertainty set. Causality provides a modeling framework with a rigorous robustness guarantee in the above sense, where the uncertainty set is data-driven rather than pre-specified as in traditional distributional robustness optimization. However, current causality-inspired robustness methods possess finite-radius robustness guarantees only in the linear settings, where the causal relationships among the covariates and the response are linear. In this work, we propose a nonlinear method under a causal framework by incorporating recent developments in identifiable representation learning and establish a distributional robustness guarantee. To our best knowledge, this is the first causality-inspired robustness method with such a finite-radius robustness guarantee in nonlinear settings. Empirical validation of the theoretical findings is conducted on both synthetic data and real-world single-cell data, also illustrating that finite-radius robustness is crucial.","authors":["Marin \\v{S}ola","Peter B\\\"uhlmann","Xinwei Shen"],"url":"https://arxiv.org/abs/2505.12868"}
{"created":"2025-05-20","title":"Spline Dimensional Decomposition with Interpolation-based Optimal Knot Selection for Stochastic Dynamic Analysis","abstract":"Forward uncertainty quantification in dynamic systems is challenging due to non-smooth or locally oscillating nonlinear behaviors. Spline dimensional decomposition (SDD) effectively addresses such nonlinearity by partitioning input coordinates via knot placement, yet its accuracy is highly sensitive to the location of internal knots. Optimizing knots through sequential quadratic programming can be effective, yet the optimization process becomes computationally intense. We propose a computationally efficient, interpolation-based method for optimal knot selection in SDD. The method involves three steps: (1) interpolating input-output profiles, (2) defining subinterval-based reference regions, and (3) selecting optimal knot locations at maximum gradient points within each region. The resulting knot vector is then applied to SDD for accurate approximation of non-smooth and locally oscillating responses. A modal analysis of a lower control arm demonstrates that SDD with the proposed knot selection achieves higher accuracy than SDD with uniformly or randomly spaced knots, and also a Gaussian process surrogate model. The proposed SDD exhibits the lowest relative variance error (2.89%), compared to SDD with uniformly spaced knots (12.310%), randomly spaced knots (15.274%), and Gaussian process (5.319%) in the first natural frequency distribution. All surrogate models are constructed using the same 401 simulation datasets, and the relative errors are evaluated against a 2000-sample Monte Carlo simulation. The scalability and applicability of proposed method are demonstrated through stochastic and reliability analyses of mathematical functions (N=1, 3) and a lower control arm system (N=10). The results confirm that both second-moment statistics and reliability estimates can be accurately achieved with only a few hundred function evaluations or finite element simulations.","authors":["Yeonsu Kim","Junhan Lee","John T. Hwang","Bingran Wang","Dongjin Lee"],"url":"https://arxiv.org/abs/2505.12879"}
{"created":"2025-05-20","title":"RetinaLogos: Fine-Grained Synthesis of High-Resolution Retinal Images Through Captions","abstract":"The scarcity of high-quality, labelled retinal imaging data, which presents a significant challenge in the development of machine learning models for ophthalmology, hinders progress in the field. To synthesise Colour Fundus Photographs (CFPs), existing methods primarily relying on predefined disease labels face significant limitations. However, current methods remain limited, thus failing to generate images for broader categories with diverse and fine-grained anatomical structures. To overcome these challenges, we first introduce an innovative pipeline that creates a large-scale, synthetic Caption-CFP dataset comprising 1.4 million entries, called RetinaLogos-1400k. Specifically, RetinaLogos-1400k uses large language models (LLMs) to describe retinal conditions and key structures, such as optic disc configuration, vascular distribution, nerve fibre layers, and pathological features. Furthermore, based on this dataset, we employ a novel three-step training framework, called RetinaLogos, which enables fine-grained semantic control over retinal images and accurately captures different stages of disease progression, subtle anatomical variations, and specific lesion types. Extensive experiments demonstrate state-of-the-art performance across multiple datasets, with 62.07% of text-driven synthetic images indistinguishable from real ones by ophthalmologists. Moreover, the synthetic data improves accuracy by 10%-25% in diabetic retinopathy grading and glaucoma detection, thereby providing a scalable solution to augment ophthalmic datasets.","authors":["Junzhi Ning","Cheng Tang","Kaijin Zhou","Diping Song","Lihao Liu","Ming Hu","Wei Li","Yanzhou Su","Tianbing Li","Jiyao Liu","Yejin","Sheng Zhang","Yuanfeng Ji","Junjun He"],"url":"https://arxiv.org/abs/2505.12887"}
{"created":"2025-05-20","title":"Formalising the Bruhat-Tits Tree","abstract":"In this article we describe the formalisation of the Bruhat-Tits tree - an important tool in modern number theory - in the Lean Theorem Prover. Motivated by the goal of connecting to ongoing research, we apply our formalisation to verify a result about harmonic cochains on the tree.","authors":["Judith Ludwig","Christian Merten"],"url":"https://arxiv.org/abs/2505.12933"}
{"created":"2025-05-20","title":"Segmentation of temporomandibular joint structures on mri images using neural networks for diagnosis of pathologies","abstract":"This article explores the use of artificial intelligence for the diagnosis of pathologies of the temporomandibular joint (TMJ), in particular, for the segmentation of the articular disc on MRI images. The relevance of the work is due to the high prevalence of TMJ pathologies, as well as the need to improve the accuracy and speed of diagnosis in medical institutions. During the study, the existing solutions (Diagnocat, MandSeg) were analyzed, which, as a result, are not suitable for studying the articular disc due to the orientation towards bone structures. To solve the problem, an original dataset was collected from 94 images with the classes \"temporomandibular joint\" and \"jaw\". To increase the amount of data, augmentation methods were used. After that, the models of U-Net, YOLOv8n, YOLOv11n and Roboflow neural networks were trained and compared. The evaluation was carried out according to the Dice Score, Precision, Sensitivity, Specificity, and Mean Average Precision metrics. The results confirm the potential of using the Roboflow model for segmentation of the temporomandibular joint. In the future, it is planned to develop an algorithm for measuring the distance between the jaws and determining the position of the articular disc, which will improve the diagnosis of TMJ pathologies.","authors":["Maksim I. Ivanov","Olga E. Mendybaeva","Yuri E. Karyakin","Igor N. Glukhikh","Aleksey V. Lebedev"],"url":"https://arxiv.org/abs/2505.12963"}
{"created":"2025-05-20","title":"Enhancing Diffusion-Weighted Images (DWI) for Diffusion MRI: Is it Enough without Non-Diffusion-Weighted B=0 Reference?","abstract":"Diffusion MRI (dMRI) is essential for studying brain microstructure, but high-resolution imaging remains challenging due to the inherent trade-offs between acquisition time and signal-to-noise ratio (SNR). Conventional methods often optimize only the diffusion-weighted images (DWIs) without considering their relationship with the non-diffusion-weighted (b=0) reference images. However, calculating diffusion metrics, such as the apparent diffusion coefficient (ADC) and diffusion tensor with its derived metrics like fractional anisotropy (FA) and mean diffusivity (MD), relies on the ratio between each DWI and the b=0 image, which is crucial for clinical observation and diagnostics. In this study, we demonstrate that solely enhancing DWIs using a conventional pixel-wise mean squared error (MSE) loss is insufficient, as the error in ratio between generated DWIs and b=0 diverges. We propose a novel ratio loss, defined as the MSE loss between the predicted and ground-truth log of DWI/b=0 ratios. Our results show that incorporating the ratio loss significantly improves the convergence of this ratio error, achieving lower ratio MSE and slightly enhancing the peak signal-to-noise ratio (PSNR) of generated DWIs. This leads to improved dMRI super-resolution and better preservation of b=0 ratio-based features for the derivation of diffusion metrics.","authors":["Yinzhe Wu","Jiahao Huang","Fanwen Wang","Mengze Gao","Congyu Liao","Guang Yang","Kawin Setsompop"],"url":"https://arxiv.org/abs/2505.12978"}
{"created":"2025-05-20","title":"Algorithms for Nonlinear Mixed-Integer Location Estimation","abstract":"For three decades, carrier-phase observations have been used to obtain the most accurate location estimates using global navigation satellite systems (GNSS). These estimates are computed by minimizing a nonlinear mixed-integer least-squares problem. Existing algorithms linearize the problem, orthogonally project it to eliminate real variables, and then solve the integer least-square problem. There is now considerable interest in developing similar localization techniques for terrestrial and indoor settings. We show that algorithms that linearize first fail in these settings and we propose several algorithms for computing the estimates. Some of our algorithms are elimination algorithms that start by eliminating the non-linear terms in the constraints; others construct a geometric arrangement that allows us to efficiently enumerate integer solutions (in polynomial time). We focus on simplified localization problems in which the measurements are range (distance) measurements and carrier phase range measurements, with no nuisance parameters. The simplified problem allows us to focus on the core question of untangling the nonlinearity and the integer nature of some parameters. We show using simulations that the new algorithms are effective at close ranges at which the linearize-first approach fails.","authors":["Ophir Uziel","Efi Fogel","Dan Halperin","Sivan Toledo"],"url":"https://arxiv.org/abs/2505.12980"}
{"created":"2025-05-20","title":"A generalisable head MRI defacing pipeline: Evaluation on 2,566 meningioma scans","abstract":"Reliable MRI defacing techniques to safeguard patient privacy while preserving brain anatomy are critical for research collaboration. Existing methods often struggle with incomplete defacing or degradation of brain tissue regions. We present a robust, generalisable defacing pipeline for high-resolution MRI that integrates atlas-based registration with brain masking. Our method was evaluated on 2,566 heterogeneous clinical scans for meningioma and achieved a 99.92 per cent success rate (2,564/2,566) upon visual inspection. Excellent anatomical preservation is demonstrated with a Dice similarity coefficient of 0.9975 plus or minus 0.0023 between brain masks automatically extracted from the original and defaced volumes. Source code is available at https://github.com/cai4cai/defacing_pipeline.","authors":["Lorena Garcia-Foncillas Macias (School of Biomedical Engineering and Imaging Sciences","Kings College London)","Aaron Kujawa (School of Biomedical Engineering and Imaging Sciences","Kings College London)","Aya Elshalakany (School of Biomedical Engineering and Imaging Sciences","Kings College London","Department of Neurosurgery","Kings College Hospital NHS Foundation Trust)","Jonathan Shapey (School of Biomedical Engineering and Imaging Sciences","Kings College London","Department of Neurosurgery","Kings College Hospital NHS Foundation Trust)","Tom Vercauteren (School of Biomedical Engineering and Imaging Sciences","Kings College London)"],"url":"https://arxiv.org/abs/2505.12999"}
{"created":"2025-05-20","title":"Asymptotic Performance of Time-Varying Bayesian Optimization","abstract":"Time-Varying Bayesian Optimization (TVBO) is the go-to framework for optimizing a time-varying black-box objective function that may be noisy and expensive to evaluate. Is it possible for the instantaneous regret of a TVBO algorithm to vanish asymptotically, and if so, when? We answer this question of great theoretical importance by providing algorithm-independent lower regret bounds and upper regret bounds for TVBO algorithms, from which we derive sufficient conditions for a TVBO algorithm to have the no-regret property. Our analysis covers all major classes of stationary kernel functions.","authors":["Anthony Bardou","Patrick Thiran"],"url":"https://arxiv.org/abs/2505.13012"}
{"created":"2025-05-20","title":"Optimal Scalogram for Computational Complexity Reduction in Acoustic Recognition Using Deep Learning","abstract":"The Continuous Wavelet Transform (CWT) is an effective tool for feature extraction in acoustic recognition using Convolutional Neural Networks (CNNs), particularly when applied to non-stationary audio. However, its high computational cost poses a significant challenge, often leading researchers to prefer alternative methods such as the Short-Time Fourier Transform (STFT). To address this issue, this paper proposes a method to reduce the computational complexity of CWT by optimizing the length of the wavelet kernel and the hop size of the output scalogram. Experimental results demonstrate that the proposed approach significantly reduces computational cost while maintaining the robust performance of the trained model in acoustic recognition tasks.","authors":["Dang Thoai Phan","Tuan Anh Huynh","Van Tuan Pham","Cao Minh Tran","Van Thuan Mai","Ngoc Quy Tran"],"url":"https://arxiv.org/abs/2505.13017"}
{"created":"2025-05-20","title":"The role of data partitioning on the performance of EEG-based deep learning models in supervised cross-subject analysis: a preliminary study","abstract":"Deep learning is significantly advancing the analysis of electroencephalography (EEG) data by effectively discovering highly nonlinear patterns within the signals. Data partitioning and cross-validation are crucial for assessing model performance and ensuring study comparability, as they can produce varied results and data leakage due to specific signal properties (e.g., biometric). Such variability leads to incomparable studies and, increasingly, overestimated performance claims, which are detrimental to the field. Nevertheless, no comprehensive guidelines for proper data partitioning and cross-validation exist in the domain, nor is there a quantitative evaluation of their impact on model accuracy, reliability, and generalizability. To assist researchers in identifying optimal experimental strategies, this paper thoroughly investigates the role of data partitioning and cross-validation in evaluating EEG deep learning models. Five cross-validation settings are compared across three supervised cross-subject classification tasks (BCI, Parkinson's, and Alzheimer's disease detection) and four established architectures of increasing complexity (ShallowConvNet, EEGNet, DeepConvNet, and Temporal-based ResNet). The comparison of over 100,000 trained models underscores, first, the importance of using subject-based cross-validation strategies for evaluating EEG deep learning models, except when within-subject analyses are acceptable (e.g., BCI). Second, it highlights the greater reliability of nested approaches (N-LNSO) compared to non-nested counterparts, which are prone to data leakage and favor larger models overfitting to validation data. In conclusion, this work provides EEG deep learning researchers with an analysis of data partitioning and cross-validation and offers guidelines to avoid data leakage, currently undermining the domain with potentially overestimated performance claims.","authors":["Federico Del Pup","Andrea Zanola","Louis Fabrice Tshimanga","Alessandra Bertoldo","Livio Finos","Manfredo Atzori"],"url":"https://arxiv.org/abs/2505.13021"}
{"created":"2025-05-20","title":"Physics-Aware Compilation for Parallel Quantum Circuit Execution on Neutral Atom Arrays","abstract":"Neutral atom quantum computers are one of the most promising quantum architectures, offering advantages in scalability, dynamic reconfigurability, and potential for large-scale implementations. These characteristics create unique compilation challenges, especially regarding compilation efficiency while adapting to hardware flexibility. However, existing methods encounter significant performance bottlenecks at scale, hindering practical applications. We propose Physics-Aware Compilation (PAC), a method that improves compilation efficiency while preserving the inherent flexibility of neutral atom systems. PAC introduces physics-aware hardware plane partitioning that strategically allocates hardware resources based on physical device characteristics like AOD and SLM trap properties and qubit mobility constraints. Additionally, it implements parallel quantum circuit division with an improved Kernighan-Lin algorithm that enables simultaneous execution across independent regions while maintaining circuit fidelity. Our experimental evaluation compares PAC with state-of-the-art methods across increasingly larger array sizes ranging from 16x16 to 64x64 qubits. Results demonstrate that PAC achieves up to 78.5x speedup on 16x16 arrays while maintaining comparable circuit quality. PAC's compilation efficiency advantage increases with system scale, demonstrating scalability for practical quantum applications on larger arrays. PAC explores a viable path for practical applications of neutral atom quantum computers by effectively addressing the tension between compilation efficiency and hardware flexibility.","authors":["Geng Chen","Guowu Yang","Wenjie Sun","Lianhui Yu","Guangwei Deng","Desheng Zheng","Xiaoyu Li"],"url":"https://arxiv.org/abs/2505.13049"}
{"created":"2025-05-20","title":"Model Selection for Gaussian-gated Gaussian Mixture of Experts Using Dendrograms of Mixing Measures","abstract":"Mixture of Experts (MoE) models constitute a widely utilized class of ensemble learning approaches in statistics and machine learning, known for their flexibility and computational efficiency. They have become integral components in numerous state-of-the-art deep neural network architectures, particularly for analyzing heterogeneous data across diverse domains. Despite their practical success, the theoretical understanding of model selection, especially concerning the optimal number of mixture components or experts, remains limited and poses significant challenges. These challenges primarily stem from the inclusion of covariates in both the Gaussian gating functions and expert networks, which introduces intrinsic interactions governed by partial differential equations with respect to their parameters. In this paper, we revisit the concept of dendrograms of mixing measures and introduce a novel extension to Gaussian-gated Gaussian MoE models that enables consistent estimation of the true number of mixture components and achieves the pointwise optimal convergence rate for parameter estimation in overfitted scenarios. Notably, this approach circumvents the need to train and compare a range of models with varying numbers of components, thereby alleviating the computational burden, particularly in high-dimensional or deep neural network settings. Experimental results on synthetic data demonstrate the effectiveness of the proposed method in accurately recovering the number of experts. It outperforms common criteria such as the Akaike information criterion, the Bayesian information criterion, and the integrated completed likelihood, while achieving optimal convergence rates for parameter estimation and accurately approximating the regression function.","authors":["Tuan Thai","TrungTin Nguyen","Dat Do","Nhat Ho","Christopher Drovandi"],"url":"https://arxiv.org/abs/2505.13052"}
{"created":"2025-05-20","title":"Simplicity is Key: An Unsupervised Pretraining Approach for Sparse Radio Channels","abstract":"We introduce the Sparse pretrained Radio Transformer (SpaRTran), an unsupervised representation learning approach based on the concept of compressed sensing for radio channels. Our approach learns embeddings that focus on the physical properties of radio propagation, to create the optimal basis for fine-tuning on radio-based downstream tasks. SpaRTran uses a sparse gated autoencoder that induces a simplicity bias to the learned representations, resembling the sparse nature of radio propagation. For signal reconstruction, it learns a dictionary that holds atomic features, which increases flexibility across signal waveforms and spatiotemporal signal patterns. Our experiments show that SpaRTran reduces errors by up to 85 % compared to state-of-the-art methods when fine-tuned on radio fingerprinting, a challenging downstream task. In addition, our method requires less pretraining effort and offers greater flexibility, as we train it solely on individual radio signals. SpaRTran serves as an excellent base model that can be fine-tuned for various radio-based downstream tasks, effectively reducing the cost for labeling. In addition, it is significantly more versatile than existing methods and demonstrates superior generalization.","authors":["Jonathan Ott","Maximilian Stahlke","Tobias Feigl","Bjoern M. Eskofier","Christopher Mutschler"],"url":"https://arxiv.org/abs/2505.13055"}
{"created":"2025-05-20","title":"When do Lyapunov Subcenter Manifolds become Eigenmanifolds?","abstract":"Multi-body mechanical systems have rich internal dynamics, which can be exploited to formulate efficient control targets. For periodic regulation tasks in robotics applications, this motivated the extension of the theory on nonlinear normal modes to Riemannian manifolds, and led to the definition of Eigenmanifolds. This definition is geometric, which is advantageous for generality within robotics but also obscures the connection of Eigenmanifolds to a large body of results from the literature on nonlinear dynamics. We bridge this gap, showing that Eigenmanifolds are instances of Lyapunov subcenter manifolds (LSMs), and that their stronger geometric properties with respect to LSMs follow from a time-symmetry of conservative mechanical systems. This directly leads to local existence and uniqueness results for Eigenmanifolds. Furthermore, we show that an additional spatial symmetry provides Eigenmanifolds with yet stronger properties of Rosenberg manifolds, which can be favorable for control applications, and we present a sufficient condition for their existence and uniqueness. These theoretical results are numerically confirmed on two mechanical systems with a non-constant inertia tensor: a double pendulum and a 5-link pendulum.","authors":["Yannik P. Wotte","Arne Sachtler","Alin Albu-Sch\\\"affer","Stefano Stramigioli","Cosimo Della Santina"],"url":"https://arxiv.org/abs/2505.13064"}
{"created":"2025-05-20","title":"Revisiting the Slip Boundary Condition: Surface Roughness as a Hidden Tuning Parameter","abstract":"In this paper, we investigate the effect of boundary surface roughness on numerical simulations of incompressible fluid flow past a cylinder in two and three spatial dimensions furnished with slip boundary conditions. The governing equations are approximated using a continuous finite element method, stabilized with a Galerkin least-squares approach.","authors":["Matthias Maier","Peter Munch","Murtazo Nazarov"],"url":"https://arxiv.org/abs/2505.13068"}
{"created":"2025-05-20","title":"Stochastic Orthogonal Regularization for deep projective priors","abstract":"Many crucial tasks of image processing and computer vision are formulated as inverse problems. Thus, it is of great importance to design fast and robust algorithms to solve these problems. In this paper, we focus on generalized projected gradient descent (GPGD) algorithms where generalized projections are realized with learned neural networks and provide state-of-the-art results for imaging inverse problems. Indeed, neural networks allow for projections onto unknown low-dimensional sets that model complex data, such as images. We call these projections deep projective priors. In generic settings, when the orthogonal projection onto a lowdimensional model set is used, it has been shown, under a restricted isometry assumption, that the corresponding orthogonal PGD converges with a linear rate, yielding near-optimal convergence (within the class of GPGD methods) in the classical case of sparse recovery. However, for deep projective priors trained with classical mean squared error losses, there is little guarantee that the hypotheses for linear convergence are satisfied. In this paper, we propose a stochastic orthogonal regularization of the training loss for deep projective priors. This regularization is motivated by our theoretical results: a sufficiently good approximation of the orthogonal projection guarantees linear stable recovery with performance close to orthogonal PGD. We show experimentally, using two different deep projective priors (based on autoencoders and on denoising networks), that our stochastic orthogonal regularization yields projections that improve convergence speed and robustness of GPGD in challenging inverse problem settings, in accordance with our theoretical findings.","authors":["Ali Joundi (UB)","Yann Traonmilin (UB)","Alasdair Newson (ISIR)"],"url":"https://arxiv.org/abs/2505.13078"}
{"created":"2025-05-20","title":"Cross-modal Knowledge Transfer Learning as Graph Matching Based on Optimal Transport for ASR","abstract":"Transferring linguistic knowledge from a pretrained language model (PLM) to acoustic feature learning has proven effective in enhancing end-to-end automatic speech recognition (E2E-ASR). However, aligning representations between linguistic and acoustic modalities remains a challenge due to inherent modality gaps. Optimal transport (OT) has shown promise in mitigating these gaps by minimizing the Wasserstein distance (WD) between linguistic and acoustic feature distributions. However, previous OT-based methods overlook structural relationships, treating feature vectors as unordered sets. To address this, we propose Graph Matching Optimal Transport (GM-OT), which models linguistic and acoustic sequences as structured graphs. Nodes represent feature embeddings, while edges capture temporal and sequential relationships. GM-OT minimizes both WD (between nodes) and Gromov-Wasserstein distance (GWD) (between edges), leading to a fused Gromov-Wasserstein distance (FGWD) formulation. This enables structured alignment and more efficient knowledge transfer compared to existing OT-based approaches. Theoretical analysis further shows that prior OT-based methods in linguistic knowledge transfer can be viewed as a special case within our GM-OT framework. We evaluate GM-OT on Mandarin ASR using a CTC-based E2E-ASR system with a PLM for knowledge transfer. Experimental results demonstrate significant performance gains over state-of-the-art models, validating the effectiveness of our approach.","authors":["Xugang Lu","Peng Shen","Yu Tsao","Hisashi Kawai"],"url":"https://arxiv.org/abs/2505.13079"}
{"created":"2025-05-20","title":"Universal Semantic Disentangled Privacy-preserving Speech Representation Learning","abstract":"The use of audio recordings of human speech to train LLMs poses privacy concerns due to these models' potential to generate outputs that closely resemble artifacts in the training data. In this study, we propose a speaker privacy-preserving representation learning method through the Universal Speech Codec (USC), a computationally efficient encoder-decoder model that disentangles speech into: $\\textit{(i)}$ privacy-preserving semantically rich representations, capturing content and speech paralinguistics, and $\\textit{(ii)}$ residual acoustic and speaker representations that enables high-fidelity reconstruction. Extensive evaluations presented show that USC's semantic representation preserves content, prosody, and sentiment, while removing potentially identifiable speaker attributes. Combining both representations, USC achieves state-of-the-art speech reconstruction. Additionally, we introduce an evaluation methodology for measuring privacy-preserving properties, aligning with perceptual tests. We compare USC against other codecs in the literature and demonstrate its effectiveness on privacy-preserving representation learning, illustrating the trade-offs of speaker anonymization, paralinguistics retention and content preservation in the learned semantic representations. Audio samples are shared in $\\href{https://www.amazon.science/usc-samples}{https://www.amazon.science/usc-samples}$.","authors":["Biel Tura Vecino","Subhadeep Maji","Aravind Varier","Antonio Bonafonte","Ivan Valles","Michael Owen","Leif Radel","Grant Strimmel","Seyi Feyisetan","Roberto Barra Chicote","Ariya Rastrow","Constantinos Papayiannis","Volker Leutnant","Trevor Wood"],"url":"https://arxiv.org/abs/2505.13085"}
{"created":"2025-05-20","title":"Attention-based clustering","abstract":"Transformers have emerged as a powerful neural network architecture capable of tackling a wide range of learning tasks. In this work, we provide a theoretical analysis of their ability to automatically extract structure from data in an unsupervised setting. In particular, we demonstrate their suitability for clustering when the input data is generated from a Gaussian mixture model. To this end, we study a simplified two-head attention layer and define a population risk whose minimization with unlabeled data drives the head parameters to align with the true mixture centroids.","authors":["Rodrigo Maulen-Soto (SU)","Claire Boyer (EPFL)","Pierre Marion (EPFL)"],"url":"https://arxiv.org/abs/2505.13112"}
{"created":"2025-05-20","title":"Higher fidelity perceptual image and video compression with a latent conditioned residual denoising diffusion model","abstract":"Denoising diffusion models achieved impressive results on several image generation tasks often outperforming GAN based models. Recently, the generative capabilities of diffusion models have been employed for perceptual image compression, such as in CDC. A major drawback of these diffusion-based methods is that, while producing impressive perceptual quality images they are dropping in fidelity/increasing the distortion to the original uncompressed images when compared with other traditional or learned image compression schemes aiming for fidelity. In this paper, we propose a hybrid compression scheme optimized for perceptual quality, extending the approach of the CDC model with a decoder network in order to reduce the impact on distortion metrics such as PSNR. After using the decoder network to generate an initial image, optimized for distortion, the latent conditioned diffusion model refines the reconstruction for perceptual quality by predicting the residual. On standard benchmarks, we achieve up to +2dB PSNR fidelity improvements while maintaining comparable LPIPS and FID perceptual scores when compared with CDC. Additionally, the approach is easily extensible to video compression, where we achieve similar results.","authors":["Jonas Brenig","Radu Timofte"],"url":"https://arxiv.org/abs/2505.13152"}
{"created":"2025-05-20","title":"A Malliavin-Gamma calculus approach to Score Based Diffusion Generative models for random fields","abstract":"We adopt a Gamma and Malliavin Calculi point of view in order to generalize Score-based diffusion Generative Models (SGMs) to an infinite-dimensional abstract Hilbertian setting. Particularly, we define the forward noising process using Dirichlet forms associated to the Cameron-Martin space of Gaussian measures and Wiener chaoses; whereas by relying on an abstract time-reversal formula, we show that the score function is a Malliavin derivative and it corresponds to a conditional expectation. This allows us to generalize SGMs to the infinite-dimensional setting. Moreover, we extend existing finite-dimensional entropic convergence bounds to this Hilbertian setting by highlighting the role played by the Cameron-Martin norm in the Fisher information of the data distribution. Lastly, we specify our discussion for spherical random fields, considering as source of noise a Whittle-Mat\\'ern random spherical field.","authors":["Giacomo Greco"],"url":"https://arxiv.org/abs/2505.13189"}
{"created":"2025-05-20","title":"Efficient Generation of Parameterised Quantum Circuits from Large Texts","abstract":"Quantum approaches to natural language processing (NLP) are redefining how linguistic information is represented and processed. While traditional hybrid quantum-classical models rely heavily on classical neural networks, recent advancements propose a novel framework, DisCoCirc, capable of directly encoding entire documents as parameterised quantum circuits (PQCs), besides enjoying some additional interpretability and compositionality benefits. Following these ideas, this paper introduces an efficient methodology for converting large-scale texts into quantum circuits using tree-like representations of pregroup diagrams. Exploiting the compositional parallels between language and quantum mechanics, grounded in symmetric monoidal categories, our approach enables faithful and efficient encoding of syntactic and discourse relationships in long and complex texts (up to 6410 words in our experiments) to quantum circuits. The developed system is provided to the community as part of the augmented open-source quantum NLP package lambeq Gen II.","authors":["Colin Krawchuk","Nikhil Khatri","Neil John Ortega","Dimitri Kartsaklis"],"url":"https://arxiv.org/abs/2505.13208"}
{"created":"2025-05-20","title":"Diffusion Models with Double Guidance: Generate with aggregated datasets","abstract":"Creating large-scale datasets for training high-performance generative models is often prohibitively expensive, especially when associated attributes or annotations must be provided. As a result, merging existing datasets has become a common strategy. However, the sets of attributes across datasets are often inconsistent, and their naive concatenation typically leads to block-wise missing conditions. This presents a significant challenge for conditional generative modeling when the multiple attributes are used jointly as conditions, thereby limiting the model's controllability and applicability. To address this issue, we propose a novel generative approach, Diffusion Model with Double Guidance, which enables precise conditional generation even when no training samples contain all conditions simultaneously. Our method maintains rigorous control over multiple conditions without requiring joint annotations. We demonstrate its effectiveness in molecular and image generation tasks, where it outperforms existing baselines both in alignment with target conditional distributions and in controllability under missing condition settings.","authors":["Yanfeng Yang","Kenji Fukumizu"],"url":"https://arxiv.org/abs/2505.13213"}
{"created":"2025-05-20","title":"SAKURA: On the Multi-hop Reasoning of Large Audio-Language Models Based on Speech and Audio Information","abstract":"Large audio-language models (LALMs) extend the large language models with multimodal understanding in speech, audio, etc. While their performances on speech and audio-processing tasks are extensively studied, their reasoning abilities remain underexplored. Particularly, their multi-hop reasoning, the ability to recall and integrate multiple facts, lacks systematic evaluation. Existing benchmarks focus on general speech and audio-processing tasks, conversational abilities, and fairness but overlook this aspect. To bridge this gap, we introduce SAKURA, a benchmark assessing LALMs' multi-hop reasoning based on speech and audio information. Results show that LALMs struggle to integrate speech/audio representations for multi-hop reasoning, even when they extract the relevant information correctly, highlighting a fundamental challenge in multimodal reasoning. Our findings expose a critical limitation in LALMs, offering insights and resources for future research.","authors":["Chih-Kai Yang","Neo Ho","Yen-Ting Piao","Hung-yi Lee"],"url":"https://arxiv.org/abs/2505.13237"}
{"created":"2025-05-20","title":"Conformalized Decision Risk Assessment","abstract":"High-stakes decisions in domains such as healthcare, energy, and public policy are often made by human experts using domain knowledge and heuristics, yet are increasingly supported by predictive and optimization-based tools. A dominant approach in operations research is the predict-then-optimize paradigm, where a predictive model estimates uncertain inputs, and an optimization model recommends a decision. However, this approach often lacks interpretability and can fail under distributional uncertainty -- particularly when the outcome distribution is multi-modal or complex -- leading to brittle or misleading decisions. In this paper, we introduce CREDO, a novel framework that quantifies, for any candidate decision, a distribution-free upper bound on the probability that the decision is suboptimal. By combining inverse optimization geometry with conformal prediction and generative modeling, CREDO produces risk certificates that are both statistically rigorous and practically interpretable. This framework enables human decision-makers to audit and validate their own decisions under uncertainty, bridging the gap between algorithmic tools and real-world judgment.","authors":["Wenbin Zhou","Agni Orfanoudaki","Shixiang Zhu"],"url":"https://arxiv.org/abs/2505.13243"}
{"created":"2025-05-20","title":"Smoothed SGD for quantiles: Bahadur representation and Gaussian approximation","abstract":"This paper considers the estimation of quantiles via a smoothed version of the stochastic gradient descent (SGD) algorithm. By smoothing the score function in the conventional SGD quantile algorithm, we achieve monotonicity in the quantile level in that the estimated quantile curves do not cross. We derive non-asymptotic tail probability bounds for the smoothed SGD quantile estimate both for the case with and without Polyak-Ruppert averaging. For the latter, we also provide a uniform Bahadur representation and a resulting Gaussian approximation result. Numerical studies show good finite sample behavior for our theoretical results.","authors":["Likai Chen","Georg Keilbar","Wei Biao Wu"],"url":"https://arxiv.org/abs/2505.13299"}
{"created":"2025-05-20","title":"From What Ifs to Insights: Counterfactuals in Causal Inference vs. Explainable AI","abstract":"Counterfactuals play a pivotal role in the two distinct data science fields of causal inference (CI) and explainable artificial intelligence (XAI). While the core idea behind counterfactuals remains the same in both fields--the examination of what would have happened under different circumstances--there are key differences in how they are used and interpreted. We introduce a formal definition that encompasses the multi-faceted concept of the counterfactual in CI and XAI. We then discuss how counterfactuals are used, evaluated, generated, and operationalized in CI vs. XAI, highlighting conceptual and practical differences. By comparing and contrasting the two, we hope to identify opportunities for cross-fertilization across CI and XAI.","authors":["Galit Shmueli","David Martens","Jaewon Yoo","Travis Greene"],"url":"https://arxiv.org/abs/2505.13324"}
{"created":"2025-05-20","title":"Scalable Importance Sampling in High Dimensions with Low-Rank Mixture Proposals","abstract":"Importance sampling is a Monte Carlo technique for efficiently estimating the likelihood of rare events by biasing the sampling distribution towards the rare event of interest. By drawing weighted samples from a learned proposal distribution, importance sampling allows for more sample-efficient estimation of rare events or tails of distributions. A common choice of proposal density is a Gaussian mixture model (GMM). However, estimating full-rank GMM covariance matrices in high dimensions is a challenging task due to numerical instabilities. In this work, we propose using mixtures of probabilistic principal component analyzers (MPPCA) as the parametric proposal density for importance sampling methods. MPPCA models are a type of low-rank mixture model that can be fit quickly using expectation-maximization, even in high-dimensional spaces. We validate our method on three simulated systems, demonstrating consistent gains in sample efficiency and quality of failure distribution characterization.","authors":["Liam A. Kruse","Marc R. Schlichting","Mykel J. Kochenderfer"],"url":"https://arxiv.org/abs/2505.13335"}
{"created":"2025-05-20","title":"Minimum-Excess-Work Guidance","abstract":"We propose a regularization framework inspired by thermodynamic work for guiding pre-trained probability flow generative models (e.g., continuous normalizing flows or diffusion models) by minimizing excess work, a concept rooted in statistical mechanics and with strong conceptual connections to optimal transport. Our approach enables efficient guidance in sparse-data regimes common to scientific applications, where only limited target samples or partial density constraints are available. We introduce two strategies: Path Guidance for sampling rare transition states by concentrating probability mass on user-defined subsets, and Observable Guidance for aligning generated distributions with experimental observables while preserving entropy. We demonstrate the framework's versatility on a coarse-grained protein model, guiding it to sample transition configurations between folded/unfolded states and correct systematic biases using experimental data. The method bridges thermodynamic principles with modern generative architectures, offering a principled, efficient, and physics-inspired alternative to standard fine-tuning in data-scarce domains. Empirical results highlight improved sample efficiency and bias reduction, underscoring its applicability to molecular simulations and beyond.","authors":["Christopher Kolloff","Tobias H\\\"oppe","Emmanouil Angelis","Mathias Jacob Schreiner","Stefan Bauer","Andrea Dittadi","Simon Olsson"],"url":"https://arxiv.org/abs/2505.13375"}
{"created":"2025-05-20","title":"Beyond-Diagonal RIS Prototype and Performance Evaluation","abstract":"We present the first experimental prototype of a reflective beyond-diagonal reconfigurable intelligent surface (BD-RIS), i.e., a RIS with reconfigurable inter-element connections. Our BD-RIS consists of an antenna array whose ports are terminated by a tunable load network. The latter can terminate each antenna port with three distinct individual loads or connect it to an adjacent antenna port. Extensive performance evaluations in a rich-scattering environment validate that inter-element connections are beneficial. Moreover, we observe that our tunable load network's mentioned hardware constraints significantly influence, first, the achievable performance, second, the benefits of having inter-element connections, and, third, the importance of mutual-coupling awareness during optimization.","authors":["Jean Tapie","Matteo Nerini","Bruno Clerckx","Philipp del Hougne"],"url":"https://arxiv.org/abs/2505.13392"}
{"created":"2025-05-20","title":"On expectations and variances in the hard-core model on bounded degree graphs","abstract":"We extend the study of the occupancy fraction of the hard-core model in two novel directions. One direction gives a tight lower bound in terms of individual vertex degrees, extending work of Sah, Sawhney, Stoner and Zhao which bounds the partition function. The other bounds the variance of the size of an independent set drawn from the model, which is strictly stronger than bounding the occupancy fraction.","authors":["Ewan Davies","Juspreet Singh Sandhu","Brian Tan"],"url":"https://arxiv.org/abs/2505.13396"}
{"created":"2025-05-20","title":"Counts and end-curves in two-parameter persistence","abstract":"Given a finite dimensional, bigraded module over the polynomial ring in two variables, we define its two-parameter count, a natural number, and its end-curves, a set of plane curves. These are two-dimensional analogues of the notions of bar-count and endpoints of singly-graded modules over the polynomial ring in one variable, from persistence theory. We show that our count is the unique one satisfying certain natural conditions; as a consequence, several inclusion-exclusion-type formulas in two-parameter persistence yield the same positive number, which equals our count, and which in turn equals the number of end-curves, giving geometric meaning to this count. We show that the end-curves determine the classical Betti tables by showing that they interpolate between generators, relations, and syzygies. Using the band representations of a certain string algebra, we show that the set of end-curves admits a canonical partition, where each part forms a closed curve on the plane; we call this the boundary of the module. As an invariant, the boundary is neither weaker nor stronger than the rank invariant, but, in contrast to the rank invariant, it is a complete invariant on the set of spread-decomposable representations. Our results connect several lines of work in multiparameter persistence, and their extension to modules over the real-exponent polynomial ring in two variables relates to two-dimensional Morse theory.","authors":["Thomas Br\\\"ustle","Steve Oudot","Luis Scoccola","Hugh Thomas"],"url":"https://arxiv.org/abs/2505.13412"}
{"created":"2025-05-20","title":"GuidedMorph: Two-Stage Deformable Registration for Breast MRI","abstract":"Accurately registering breast MR images from different time points enables the alignment of anatomical structures and tracking of tumor progression, supporting more effective breast cancer detection, diagnosis, and treatment planning. However, the complexity of dense tissue and its highly non-rigid nature pose challenges for conventional registration methods, which primarily focus on aligning general structures while overlooking intricate internal details. To address this, we propose \\textbf{GuidedMorph}, a novel two-stage registration framework designed to better align dense tissue. In addition to a single-scale network for global structure alignment, we introduce a framework that utilizes dense tissue information to track breast movement. The learned transformation fields are fused by introducing the Dual Spatial Transformer Network (DSTN), improving overall alignment accuracy. A novel warping method based on the Euclidean distance transform (EDT) is also proposed to accurately warp the registered dense tissue and breast masks, preserving fine structural details during deformation. The framework supports paradigms that require external segmentation models and with image data only. It also operates effectively with the VoxelMorph and TransMorph backbones, offering a versatile solution for breast registration. We validate our method on ISPY2 and internal dataset, demonstrating superior performance in dense tissue, overall breast alignment, and breast structural similarity index measure (SSIM), with notable improvements by over 13.01% in dense tissue Dice, 3.13% in breast Dice, and 1.21% in breast SSIM compared to the best learning-based baseline.","authors":["Yaqian Chen","Hanxue Gu","Haoyu Dong","Qihang Li","Yuwen Chen","Nicholas Konz","Lin Li","Maciej A. Mazurowski"],"url":"https://arxiv.org/abs/2505.13414"}
{"created":"2025-05-20","title":"Machine learning the first stage in 2SLS: Practical guidance from bias decomposition and simulation","abstract":"Machine learning (ML) primarily evolved to solve \"prediction problems.\" The first stage of two-stage least squares (2SLS) is a prediction problem, suggesting potential gains from ML first-stage assistance. However, little guidance exists on when ML helps 2SLS$\\unicode{x2014}$or when it hurts. We investigate the implications of inserting ML into 2SLS, decomposing the bias into three informative components. Mechanically, ML-in-2SLS procedures face issues common to prediction and causal-inference settings$\\unicode{x2014}$and their interaction. Through simulation, we show linear ML methods (e.g., post-Lasso) work well, while nonlinear methods (e.g., random forests, neural nets) generate substantial bias in second-stage estimates$\\unicode{x2014}$potentially exceeding the bias of endogenous OLS.","authors":["Connor Lennon","Edward Rubin","Glen Waddell"],"url":"https://arxiv.org/abs/2505.13422"}
{"created":"2025-05-20","title":"Spectral ACMS: A robust localized Approximated Component Mode Synthesis Method","abstract":"We consider finite element methods of multiscale type to approximate solutions for two-dimensional symmetric elliptic partial differential equations with heterogeneous $L^\\infty$ coefficients. The methods are of Galerkin type and follow the Variational Multiscale and Localized Orthogonal Decomposition--LOD approaches in the sense that it decouples spaces into \\emph{multiscale} and \\emph{fine} subspaces. In a first method, the multiscale basis functions are obtained by mapping coarse basis functions, based on corners used on primal iterative substructuring methods, to functions of global minimal energy. This approach delivers quasi-optimal a priori error energy approximation with respect to the mesh size, but it is not robust with respect to high-contrast coefficients. In a second method, edge modes based on local generalized eigenvalue problems are added to the corner modes. As a result, optimal a priori error energy estimate is achieved which is mesh and contrast independent. The methods converge at optimal rate even if the solution has minimum regularity, belonging only to the Sobolev space $H^1$.","authors":["Alexandre L. Madureira","Marcus Sarkis"],"url":"https://arxiv.org/abs/1709.04044"}
{"created":"2025-05-20","title":"Conformal e-prediction","abstract":"This paper discusses a counterpart of conformal prediction for e-values, conformal e-prediction. Conformal e-prediction is conceptually simpler and had been developed in the 1990s as a precursor of conformal prediction. When conformal prediction emerged as result of replacing e-values by p-values, it seemed to have important advantages over conformal e-prediction without obvious disadvantages. This paper re-examines relations between conformal prediction and conformal e-prediction systematically from a modern perspective. Conformal e-prediction has advantages of its own, such as the ease of designing conditional conformal e-predictors and the guaranteed validity of cross-conformal e-predictors (whereas for cross-conformal predictors validity is only an empirical fact and can be broken with excessive randomization). Even where conformal prediction has clear advantages, conformal e-prediction can often emulate those advantages, more or less successfully.","authors":["Vladimir Vovk"],"url":"https://arxiv.org/abs/2001.05989"}
{"created":"2025-05-20","title":"Deep Reinforcement Learning for Wireless Scheduling in Distributed Networked Control","abstract":"We consider a joint uplink and downlink scheduling problem of a fully distributed wireless networked control system (WNCS) with a limited number of frequency channels. Using elements of stochastic systems theory, we derive a sufficient stability condition of the WNCS, which is stated in terms of both the control and communication system parameters. Once the condition is satisfied, there exists a stationary and deterministic scheduling policy that can stabilize all plants of the WNCS. By analyzing and representing the per-step cost function of the WNCS in terms of a finite-length countable vector state, we formulate the optimal transmission scheduling problem into a Markov decision process and develop a deep reinforcement learning (DRL) based framework for solving it. To tackle the challenges of a large action space in DRL, we propose novel action space reduction and action embedding methods for the DRL framework that can be applied to various algorithms, including Deep Q-Network (DQN), Deep Deterministic Policy Gradient (DDPG), and Twin Delayed Deep Deterministic Policy Gradient (TD3). Numerical results show that the proposed algorithm significantly outperforms benchmark policies.","authors":["Gaoyang Pang","Kang Huang","Daniel E. Quevedo","Branka Vucetic","Yonghui Li","Wanchun Liu"],"url":"https://arxiv.org/abs/2109.12562"}
{"created":"2025-05-20","title":"Tree-based Focused Web Crawling with Reinforcement Learning","abstract":"A focused crawler aims at discovering as many web pages and web sites relevant to a target topic as possible, while avoiding irrelevant ones. Reinforcement Learning (RL) has been a promising direction for optimizing focused crawling, because RL can naturally optimize the long-term profit of discovering relevant web locations within the context of a reward. In this paper, we propose TRES, a novel RL-empowered framework for focused crawling that aims at maximizing both the number of relevant web pages (aka \\textit{harvest rate}) and the number of relevant web sites (\\textit{domains}). We model the focused crawling problem as a novel Markov Decision Process (MDP), which the RL agent aims to solve by determining an optimal crawling strategy. To overcome the computational infeasibility of exhaustively searching for the best action at each time step, we propose Tree-Frontier, a provably efficient tree-based sampling algorithm that adaptively discretizes the large state and action spaces and evaluates only a few representative actions. Experimentally, utilizing online real-world data, we show that TRES significantly outperforms and Pareto-dominates state-of-the-art methods in terms of harvest rate and the number of retrieved relevant domains, while it provably reduces by orders of magnitude the number of URLs needed to be evaluated at each crawling step.","authors":["Andreas Kontogiannis","Dimitrios Kelesis","Vasilis Pollatos","George Giannakopoulos","Georgios Paliouras"],"url":"https://arxiv.org/abs/2112.07620"}
{"created":"2025-05-20","title":"(Im)possibility of Collective Intelligence","abstract":"Modern applications of AI involve training and deploying machine learning models across heterogeneous and potentially massive environments. Emerging diversity of data not only brings about new possibilities to advance AI systems, but also restricts the extent to which information can be shared across environments due to pressing concerns such as privacy, security, and equity. Based on a novel characterization of learning algorithms as choice correspondences on a hypothesis space, this work provides a minimum requirement in terms of intuitive and reasonable axioms under which the only rational learning algorithm in heterogeneous environments is an empirical risk minimization (ERM) that unilaterally learns from a single environment without information sharing across environments. Our (im)possibility result underscores the fundamental trade-off that any algorithms will face in order to achieve Collective Intelligence (CI), i.e., the ability to learn across heterogeneous environments. Ultimately, collective learning in heterogeneous environments are inherently hard because, in critical areas of machine learning such as out-of-distribution generalization, federated/collaborative learning, algorithmic fairness, and multi-modal learning, it can be infeasible to make meaningful comparisons of model predictive performance across environments.","authors":["Krikamol Muandet"],"url":"https://arxiv.org/abs/2206.02786"}
{"created":"2025-05-20","title":"Pseudo-Labeling Based Practical Semi-Supervised Meta-Training for Few-Shot Learning","abstract":"Most existing few-shot learning (FSL) methods require a large amount of labeled data in meta-training, which is a major limit. To reduce the requirement of labels, a semi-supervised meta-training (SSMT) setting has been proposed for FSL, which includes only a few labeled samples and numbers of unlabeled samples in base classes. However, existing methods under this setting require class-aware sample selection from the unlabeled set, which violates the assumption of unlabeled set. In this paper, we propose a practical semi-supervised meta-training setting with truly unlabeled data to facilitate the applications of FSL in realistic scenarios. To better utilize both the labeled and truly unlabeled data, we propose a simple and effective meta-training framework, called pseudo-labeling based meta-learning (PLML). Firstly, we train a classifier via common semi-supervised learning (SSL) and use it to obtain the pseudo-labels of unlabeled data. Then we build few-shot tasks from labeled and pseudo-labeled data and design a novel finetuning method with feature smoothing and noise suppression to better learn the FSL model from noise labels. Surprisingly, through extensive experiments across two FSL datasets, we find that this simple meta-training framework effectively prevents the performance degradation of various FSL models under limited labeled data, and also significantly outperforms the state-of-the-art SSMT models. Besides, benefiting from meta-training, our method also improves two representative SSL algorithms as well.","authors":["Xingping Dong","Tianran Ouyang","Shengcai Liao","Bo Du","Ling Shao"],"url":"https://arxiv.org/abs/2207.06817"}
{"created":"2025-05-20","title":"NISTT: A Non-Intrusive SystemC-TLM 2.0 Tracing Tool","abstract":"The increasing complexity of systems-on-a-chip requires the continuous development of electronic design automation tools. Nowadays, the simulation of systems-on-a-chip using virtual platforms is common. Virtual platforms enable hardware/software co-design to shorten the time to market, offer insights into the models, and allow debugging of the simulated hardware. Profiling tools are required to improve the usability of virtual platforms. During simulation, these tools capture data that are evaluated afterward. Those data can reveal information about the simulation itself and the software executed on the platform. This work presents the tracing tool NISTT that can profile SystemC-TLM-2.0-based virtual platforms. NISTT is implemented in a completely non-intrusive way. That means no changes in the simulation are needed, the source code of the simulation is not required, and the traced simulation does not need to contain debug symbols. The standardized SystemC application programming interface guarantees the compatibility of NISTT with other simulations. The strengths of NISTT are demonstrated in a case study. Here, NISTT is connected to a virtual platform and traces the boot process of Linux. After the simulation, the database created by NISTT is evaluated, and the results are visualized. Furthermore, the overhead of NISTT is quantified. It is shown that NISTT has only a minor influence on the overall simulation performance.","authors":["Nils Bosbach","Lukas J\\\"unger","Jan Moritz Joseph","Rainer Leupers"],"url":"https://arxiv.org/abs/2207.11036"}
{"created":"2025-05-20","title":"Learning The Likelihood Test With One-Class Classifiers for Physical Layer Authentication","abstract":"In physical layer authentication (PLA) mechanisms, a verifier decides whether a received message has been transmitted by a legitimate user or an intruder, according to some features of the physical channel over which the message traveled. To design the authentication check implemented at the verifier, typically either the statistics or a dataset of features are available for the channel from the legitimate user, while no information is available when under attack. When the statistics are known, a well-known good solution is the likelihood test (LT). When a dataset is available, the decision problem is one-class classification (OCC) and a good understanding of the machine learning (ML) techniques used for its solution is important to ensure security. Thus, in this paper, we aim at obtaining ML PLA verifiers that operate as the LT. We show how to do it with the neural network (NN) and the one-class least-squares support vector machine (OCLSSVM) models, trained as two-class classifiers on the single-class dataset and an artificial dataset. The artificial dataset for the negative class is obtained by generating channel feature (CF) vectors uniformly distributed over the domain of the legitimate class dataset. We also derive a modified stochastic gradient descent (SGD) algorithm that trains a PLA verifier operating as LT without the need for the artificial dataset. Furthermore, we show that the one-class least-squares support vector machine with suitable kernels operates as the LT at convergence. Lastly, we show that the widely used autoencoder classifier generally does not provide the LT. Numerical results are provided considering PLA on both wireless and underwater acoustic channels.","authors":["Francesco Ardizzon","Stefano Tomasin"],"url":"https://arxiv.org/abs/2210.12494"}
{"created":"2025-05-20","title":"DICTION:DynamIC robusT whIte bOx watermarkiNg scheme for deep neural networks","abstract":"Deep neural network (DNN) watermarking is a suitable method for protecting the ownership of deep learning (DL) models. It secretly embeds an identifier (watermark) within the model, which can be retrieved by the owner to prove ownership. In this paper, we first provide a unified framework for white box DNN watermarking schemes. It includes current state-of-the-art methods outlining their theoretical inter-connections. Next, we introduce DICTION, a new white-box Dynamic Robust watermarking scheme, we derived from this framework. Its main originality stands on a generative adversarial network (GAN) strategy where the watermark extraction function is a DNN trained as a GAN discriminator taking the target model to watermark as a GAN generator with a latent space as the input of the GAN trigger set. DICTION can be seen as a generalization of DeepSigns which, to the best of our knowledge, is the only other Dynamic white-box watermarking scheme from the literature. Experiments conducted on the same model test set as Deepsigns demonstrate that our scheme achieves much better performance. Especially, with DICTION, one can increase the watermark capacity while preserving the target model accuracy at best and simultaneously ensuring strong watermark robustness against a wide range of watermark removal and detection attacks.","authors":["Reda Bellafqira","Gouenou Coatrieux"],"url":"https://arxiv.org/abs/2210.15745"}
{"created":"2025-05-20","title":"DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models","abstract":"Diffusion probabilistic models (DPMs) have achieved impressive success in high-resolution image synthesis, especially in recent large-scale text-to-image generation applications. An essential technique for improving the sample quality of DPMs is guided sampling, which usually needs a large guidance scale to obtain the best sample quality. The commonly-used fast sampler for guided sampling is DDIM, a first-order diffusion ODE solver that generally needs 100 to 250 steps for high-quality samples. Although recent works propose dedicated high-order solvers and achieve a further speedup for sampling without guidance, their effectiveness for guided sampling has not been well-tested before. In this work, we demonstrate that previous high-order fast samplers suffer from instability issues, and they even become slower than DDIM when the guidance scale grows large. To further speed up guided sampling, we propose DPM-Solver++, a high-order solver for the guided sampling of DPMs. DPM-Solver++ solves the diffusion ODE with the data prediction model and adopts thresholding methods to keep the solution matches training data distribution. We further propose a multistep variant of DPM-Solver++ to address the instability issue by reducing the effective step size. Experiments show that DPM-Solver++ can generate high-quality samples within only 15 to 20 steps for guided sampling by pixel-space and latent-space DPMs.","authors":["Cheng Lu","Yuhao Zhou","Fan Bao","Jianfei Chen","Chongxuan Li","Jun Zhu"],"url":"https://arxiv.org/abs/2211.01095"}
{"created":"2025-05-20","title":"Structural Reductions and Stutter Sensitive Properties","abstract":"Verification of properties expressed as $\\omega$-regular languages such as LTL can benefit hugely from stutter insensitivity, using a diverse set of reduction strategies. However properties that are not stutter invariant, for instance due to the use of the neXt operator of LTL or to some form of counting in the logic, are not covered by these techniques in general. We propose in this paper to study a weaker property than stutter insensitivity. In a stutter insensitive language both adding and removing stutter to a word does not change its acceptance, any stuttering can be abstracted away; by decomposing this equivalence relation into two implications we obtain weaker conditions. We define a shortening insensitive language where any word that stutters less than a word in the language must also belong to the language. A lengthening insensitive language has the dual property. A semi-decision procedure is then introduced to reliably prove shortening insensitive properties or deny lengthening insensitive properties while working with a \\emph{reduction} of a system. A reduction has the property that it can only shorten runs. Lipton's transaction reductions or Petri net agglomerations are examples of eligible structural reduction strategies. We also present an approach that can reason using a partition of a property language into its stutter insensitive, shortening insensitive, lengthening insensitive and length sensitive parts to still use structural reductions even when working with arbitrary properties. An implementation and experimental evidence is provided showing most non-random properties sensitive to stutter are actually shortening or lengthening insensitive.","authors":["Emmanuel Paviot-Adet","Denis Poitrenaud","Etienne Renault","Yann Thierry-Mieg"],"url":"https://arxiv.org/abs/2212.04218"}
{"created":"2025-05-20","title":"Increasing Fairness via Combination with Learning Guarantees","abstract":"The concern about hidden discrimination in ML models is growing, as their widespread real-world application increasingly impacts human lives. Various techniques, including commonly used group fairness measures and several fairness-aware ensemble-based methods, have been developed to enhance fairness. However, existing fairness measures typically focus on only one aspect -- either group or individual fairness, and the hard compatibility among them indicates a possibility of remaining biases even when one of them is satisfied. Moreover, existing mechanisms to boost fairness usually present empirical results to show validity, yet few of them discuss whether fairness can be boosted with certain theoretical guarantees. To address these issues, we propose a fairness quality measure named 'discriminative risk (DR)' to reflect both individual and group fairness aspects. Furthermore, we investigate its properties and establish the first- and second-order oracle bounds to show that fairness can be boosted via ensemble combination with theoretical learning guarantees. The analysis is suitable for both binary and multi-class classification. A pruning method is also proposed to utilise our proposed measure and comprehensive experiments are conducted to evaluate the effectiveness of the proposed methods.","authors":["Yijun Bian","Kun Zhang"],"url":"https://arxiv.org/abs/2301.10813"}
{"created":"2025-05-20","title":"Convergence and Near-optimal Sampling for Multivariate Function Approximations in Irregular Domains via Vandermonde with Arnoldi","abstract":"Vandermonde matrices are usually exponentially ill-conditioned and often result in unstable approximations. In this paper, we introduce and analyze the \\textit{multivariate Vandermonde with Arnoldi (V+A) method}, which is based on least-squares approximation together with a Stieltjes orthogonalization process, for approximating continuous, multivariate functions on $d$-dimensional irregular domains. The V+A method addresses the ill-conditioning of the Vandermonde approximation by creating a set of discrete orthogonal bases with respect to a discrete measure. The V+A method is simple and general, relying only on the domain's sample points. This paper analyzes the sample complexity of {the least-squares approximation that uses the V+A method}. We show that, for a large class of domains, this approximation gives a well-conditioned and near-optimal $N$-dimensional least-squares approximation using $M=O(N^2)$ equispaced sample points or $M=O(N^2\\log N)$ random sample points, independently of $d$. We provide a comprehensive analysis of the error estimates and the rate of convergence of the least-squares approximation that uses the V+A method. Based on the multivariate V+A techniques, we propose a new variant of the weighted V+A least-squares algorithm that uses only $M=O(N\\log N)$ sample points to achieve a near-optimal approximation. {Our initial numerical results validate that the V+A least-squares approximation method provides well-conditioned and near-optimal approximations for multivariate functions on (irregular) domains. Additionally, the (weighted) least-squares approximation that uses the V+A method performs competitively with state-of-the-art orthogonalization techniques and can serve as a practical tool for selecting near-optimal distributions of sample points in irregular domains.","authors":["Wenqi Zhu","Yuji Nakatsukasa"],"url":"https://arxiv.org/abs/2301.12241"}
{"created":"2025-05-20","title":"System reduction-based approximate reanalysis method for statically indeterminate structures with high-rank modification","abstract":"Efficient structural reanalysis for high-rank modification plays an important role in engineering computations which require repeated evaluations of structural responses, such as structural optimization and probabilistic analysis. To improve the efficiency of engineering computations, a novel approximate static reanalysis method based on system reduction and iterative solution is proposed for statically indeterminate structures with high-rank modification. In this approach, a statically indeterminate structure is divided into the basis system and the additional components. Subsequently, the structural equilibrium equations are rewritten as the equation system with the stiffness matrix of the basis system and the pseudo forces derived from the additional elements. With the introduction of spectral decomposition, a reduced equation system with the element forces of the additional elements as the unknowns is established. Then, the approximate solutions of the modified structure can be obtained by solving the reduced equation system through a pre-conditioned iterative solution algorithm. The computational costs of the proposed method and the other two reanalysis methods are compared and numerical examples including static reanalysis and static nonlinear analysis are presented. The results demonstrate that the proposed method has excellent computational performance for both the structures with homogeneous material and structures composed of functionally graded beams. Meanwhile, the superiority of the proposed method indicates that the combination of system reduction and pre-conditioned iterative solution technology is an effective way to develop high-performance reanalysis methods.","authors":["Wenxiong Li","Suiyin Chen","Huan Huang"],"url":"https://arxiv.org/abs/2302.02171"}
{"created":"2025-05-20","title":"Constrained Adversarial Learning for Automated Software Testing: a literature review","abstract":"It is imperative to safeguard computer applications and information systems against the growing number of cyber-attacks. Automated software testing tools can be developed to quickly analyze many lines of code and detect vulnerabilities by generating function-specific testing data. This process draws similarities to the constrained adversarial examples generated by adversarial machine learning methods, so there could be significant benefits to the integration of these methods in testing tools to identify possible attack vectors. Therefore, this literature review is focused on the current state-of-the-art of constrained data generation approaches applied for adversarial learning and software testing, aiming to guide researchers and developers to enhance their software testing tools with adversarial testing methods and improve the resilience and robustness of their information systems. The found approaches were systematized, and the advantages and limitations of those specific for white-box, grey-box, and black-box testing were analyzed, identifying research gaps and opportunities to automate the testing tools with data generated by adversarial attacks.","authors":["Jo\\~ao Vitorino","Tiago Dias","Tiago Fonseca","Eva Maia","Isabel Pra\\c{c}a"],"url":"https://arxiv.org/abs/2303.07546"}
{"created":"2025-05-20","title":"DiffusionAD: Norm-guided One-step Denoising Diffusion for Anomaly Detection","abstract":"Anomaly detection has garnered extensive applications in real industrial manufacturing due to its remarkable effectiveness and efficiency. However, previous generative-based models have been limited by suboptimal reconstruction quality, hampering their overall performance. We introduce DiffusionAD, a novel anomaly detection pipeline comprising a reconstruction sub-network and a segmentation sub-network. A fundamental enhancement lies in our reformulation of the reconstruction process using a diffusion model into a noise-to-norm paradigm. Here, the anomalous region loses its distinctive features after being disturbed by Gaussian noise and is subsequently reconstructed into an anomaly-free one. Afterward, the segmentation sub-network predicts pixel-level anomaly scores based on the similarities and discrepancies between the input image and its anomaly-free reconstruction. Additionally, given the substantial decrease in inference speed due to the iterative denoising nature of diffusion models, we revisit the denoising process and introduce a rapid one-step denoising paradigm. This paradigm achieves hundreds of times acceleration while preserving comparable reconstruction quality. Furthermore, considering the diversity in the manifestation of anomalies, we propose a norm-guided paradigm to integrate the benefits of multiple noise scales, enhancing the fidelity of reconstructions. Comprehensive evaluations on four standard and challenging benchmarks reveal that DiffusionAD outperforms current state-of-the-art approaches and achieves comparable inference speed, demonstrating the effectiveness and broad applicability of the proposed pipeline. Code is released at https://github.com/HuiZhang0812/DiffusionAD","authors":["Hui Zhang","Zheng Wang","Dan Zeng","Zuxuan Wu","Yu-Gang Jiang"],"url":"https://arxiv.org/abs/2303.08730"}
{"created":"2025-05-20","title":"AUTO: Adaptive Outlier Optimization for Test-Time OOD Detection","abstract":"Out-of-distribution (OOD) detection aims to detect test samples that do not fall into any training in-distribution (ID) classes. Prior efforts focus on regularizing models with ID data only, largely underperforming counterparts that utilize auxiliary outliers. However, data safety and privacy make it infeasible to collect task-specific outliers in advance for different scenarios. Besides, using task-irrelevant outliers leads to inferior OOD detection performance. To address the above issue, we present a new setup called test-time OOD detection, which allows the deployed model to utilize real OOD data from the unlabeled data stream during testing. We propose Adaptive Outlier Optimization (AUTO) which allows for continuous adaptation of the OOD detector. Specifically, AUTO consists of three key components: 1) an in-out-aware filter to selectively annotate test samples with pseudo-ID and pseudo-OOD and ingeniously trigger the updating process while encountering each pseudo-OOD sample; 2) a dynamic-updated memory to overcome the catastrophic forgetting led by frequent parameter updates; 3) a prediction-aligning objective to calibrate the rough OOD objective during testing. Extensive experiments show that AUTO significantly improves OOD detection performance over state-of-the-art methods. Besides, evaluations on complicated scenarios (e.g. multi-OOD, time-series OOD) also conduct the superiority of AUTO.","authors":["Puning Yang","Jian Liang","Jie Cao","Ran He"],"url":"https://arxiv.org/abs/2303.12267"}
{"created":"2025-05-20","title":"A $d^{1/2+o(1)}$ Monotonicity Tester for Boolean Functions on $d$-Dimensional Hypergrids","abstract":"Monotonicity testing of Boolean functions on the hypergrid, $f:[n]^d \\to \\{0,1\\}$, is a classic topic in property testing. Determining the non-adaptive complexity of this problem is an important open question. For arbitrary $n$, [Black-Chakrabarty-Seshadhri, SODA 2020] describe a tester with query complexity $\\widetilde{O}(\\varepsilon^{-4/3}d^{5/6})$. This complexity is independent of $n$, but has a suboptimal dependence on $d$. Recently, [Braverman-Khot-Kindler-Minzer, ITCS 2023] and [Black-Chakrabarty-Seshadhri, STOC 2023] describe $\\widetilde{O}(\\varepsilon^{-2} n^3\\sqrt{d})$ and $\\widetilde{O}(\\varepsilon^{-2} n\\sqrt{d})$-query testers, respectively. These testers have an almost optimal dependence on $d$, but a suboptimal polynomial dependence on $n$.","authors":["Hadley Black","Deeparnab Chakrabarty","C. Seshadhri"],"url":"https://arxiv.org/abs/2304.01416"}
{"created":"2025-05-20","title":"CSP-free adaptive Kriging surrogate model method for reliability analysis with small failure probability","abstract":"In the field of reliability engineering, the Active learning reliability method combining Kriging and Monte Carlo Simulation (AK-MCS) has been developed and demonstrated to be effective in reliability analysis. However, the performance of AK-MCS is sensitive to the size of Candidate Sample Pool (CSP), particularly for systems with small failure probabilities. To address the limitations of conventional AK-MCS that relies on CSP, this paper proposes a CSP-free AK-MCS. The proposed methodology consists of two stages: surrogate model construction and Monte Carlo simulation for estimating the failure probability. In the stage of surrogate model construction, the surrogate model is iteratively refined based on the representative samples selected by solving the optimization problem facilitated by Particle Swarm Optimization (PSO) algorithm. To achieve an optimal balance between solution accuracy and efficiency, the penalty intensity control and the density control for the experimental design points are introduced to modify the objective function in optimization. The performance of the proposed methodology is evaluated using numerical examples, and results indicate that by leveraging an optimization algorithm to select representative samples, the proposed CSP-free AK-MCS overcomes the limitations of conventional CSP-based AK-MCS and exhibits exceptional performance in addressing small failure probabilities.","authors":["Wenxiong Li","Rong Geng","Suiyin Chen"],"url":"https://arxiv.org/abs/2304.07010"}
{"created":"2025-05-20","title":"Large Linguistic Models: Investigating LLMs' metalinguistic abilities","abstract":"The performance of large language models (LLMs) has recently improved to the point where models can perform well on many language tasks. We show here that--for the first time--the models can also generate valid metalinguistic analyses of language data. We outline a research program where the behavioral interpretability of LLMs on these tasks is tested via prompting. LLMs are trained primarily on text--as such, evaluating their metalinguistic abilities improves our understanding of their general capabilities and sheds new light on theoretical models in linguistics. We show that OpenAI's (2024) o1 vastly outperforms other models on tasks involving drawing syntactic trees and phonological generalization. We speculate that OpenAI o1's unique advantage over other models may result from the model's chain-of-thought mechanism, which mimics the structure of human reasoning used in complex cognitive tasks, such as linguistic analysis.","authors":["Ga\\v{s}per Begu\\v{s}","Maksymilian D\\k{a}bkowski","Ryan Rhodes"],"url":"https://arxiv.org/abs/2305.00948"}
{"created":"2025-05-20","title":"Average conditioning of underdetermined polynomial systems","abstract":"This article study the average conditioning for a random underdetermined polynomial system. The expected value of the moments of the condition number are compared to the moments of the condition number of random matrices. An expression for these moments is given by studying the kernel finding problem for random matrices. Furthermore, the second moment of the Frobenius condition number is computed.","authors":["Federico Carrasco"],"url":"https://arxiv.org/abs/2305.05965"}
{"created":"2025-05-20","title":"Finitely Presentable Higher-Dimensional Automata and the Irrationality of Process Replication","abstract":"Higher-dimensional automata (HDA) are a formalism to faithfully model the behaviour of concurrent systems. For ordinary automata, there is a correspondence between regular expressions, regular languages and finite automata, which provides a powerful link between algebraic proofs and operational behaviour. It has been shown by Fahrenberg et al. that finite HDA correspond with interfaced interval pomset languages generated by sequential and parallel composition and non-empty iteration, and thereby to a variant of Kleene algebras (KA) with parallel composition. It is known that this correspondence cannot be extended to concurrent KA, which additionally have process replication. An alternative to finite HDA are locally finite HDA, in which every state can only reach finitely many other states, and finitely branching HDA. In this paper, we show that both classes of HDA are closed under process replication and thus models of concurrent KA. To achieve this, we prove that the category of HDA is locally finitely presentable, where the finite HDA generate all other HDA. We then prove that this has the unfortunate side-effect that all HDA are locally finite, which means that the correspondence with concurrent KA trivialises. Similarly, we also show that, even though finitely branching HDA are closed under process replication, the resulting HDA necessarily have infinitely many initial states.","authors":["Henning Basold","Thomas Baronner","M\\'arton Hablicsek"],"url":"https://arxiv.org/abs/2305.06428"}
{"created":"2025-05-20","title":"Physics of Language Models: Part 1, Learning Hierarchical Language Structures","abstract":"Transformer-based language models are effective but complex, and understanding their inner workings and reasoning mechanisms is a significant challenge. Previous research has primarily explored how these models handle simple tasks like name copying or selection, and we extend this by investigating how these models perform recursive language structure reasoning defined by context-free grammars (CFGs). We introduce a family of synthetic CFGs that produce hierarchical rules, capable of generating lengthy sentences (e.g., hundreds of tokens) that are locally ambiguous and require dynamic programming to parse. Despite this complexity, we demonstrate that generative models like GPT can accurately learn and reason over CFG-defined hierarchies and generate sentences based on it. We explore the model's internals, revealing that its hidden states precisely capture the structure of CFGs, and its attention patterns resemble the information passing in a dynamic programming algorithm.","authors":["Zeyuan Allen-Zhu","Yuanzhi Li"],"url":"https://arxiv.org/abs/2305.13673"}
{"created":"2025-05-20","title":"Differentially Private Synthetic Data via Foundation Model APIs 1: Images","abstract":"Generating differentially private (DP) synthetic data that closely resembles the original private data is a scalable way to mitigate privacy concerns in the current data-driven world. In contrast to current practices that train customized models for this task, we aim to generate DP Synthetic Data via APIs (DPSDA), where we treat foundation models as blackboxes and only utilize their inference APIs. Such API-based, training-free approaches are easier to deploy as exemplified by the recent surge in the number of API-based apps. These approaches can also leverage the power of large foundation models which are only accessible via their inference APIs. However, this comes with greater challenges due to strictly more restrictive model access and the need to protect privacy from the API provider.","authors":["Zinan Lin","Sivakanth Gopi","Janardhan Kulkarni","Harsha Nori","Sergey Yekhanin"],"url":"https://arxiv.org/abs/2305.15560"}
{"created":"2025-05-20","title":"Agent Performing Autonomous Stock Trading under Good and Bad Situations","abstract":"Stock trading is one of the popular ways for financial management. However, the market and the environment of economy is unstable and usually not predictable. Furthermore, engaging in stock trading requires time and effort to analyze, create strategies, and make decisions. It would be convenient and effective if an agent could assist or even do the task of analyzing and modeling the past data and then generate a strategy for autonomous trading. Recently, reinforcement learning has been shown to be robust in various tasks that involve achieving a goal with a decision making strategy based on time-series data. In this project, we have developed a pipeline that simulates the stock trading environment and have trained an agent to automate the stock trading process with deep reinforcement learning methods, including deep Q-learning, deep SARSA, and the policy gradient method. We evaluate our platform during relatively good (before 2021) and bad (2021 - 2022) situations. The stocks we've evaluated on including Google, Apple, Tesla, Meta, Microsoft, and IBM. These stocks are among the popular ones, and the changes in trends are representative in terms of having good and bad situations. We showed that before 2021, the three reinforcement methods we have tried always provide promising profit returns with total annual rates around $70\\%$ to $90\\%$, while maintain a positive profit return after 2021 with total annual rates around 2% to 7%.","authors":["Yunfei Luo","Zhangqi Duan"],"url":"https://arxiv.org/abs/2306.03985"}
{"created":"2025-05-20","title":"If At First You Don't Succeed: Extended Monitorability through Multiple Executions","abstract":"This paper studies the extent to which branching-time properties can be adequately verified using runtime monitors. We depart from the classical setup where monitoring is limited to a single system execution and investigate the enhanced observational capabilities when monitoring a system over multiple runs. To ensure generality in our results, we focus on branching-time properties expressed in the modal mu-calculus, a well-studied foundational logic that is used by state-of-the-art model checkers. Our results show that the proposed setup can systematically extend previously established monitorability limits for branching-time properties. We then validate our results by instantiating them to verify actor-based systems. We also prove bounds that capture the correspondence between the syntactic structure of a property and the number of required system runs.","authors":["Antonis Achilleos","Adrian Francalanza","Jasmine Xuereb"],"url":"https://arxiv.org/abs/2306.05229"}
{"created":"2025-05-20","title":"Spatial Re-parameterization for N:M Sparsity","abstract":"This paper presents a Spatial Re-parameterization (SpRe) method for the N:M sparsity. SpRe stems from an observation regarding the restricted variety in spatial sparsity of convolution kernels presented in N:M sparsity compared with unstructured sparsity. Particularly, N:M sparsity exhibits a fixed sparsity rate within the spatial domains due to its distinctive pattern that mandates N non-zero components among M successive weights in the input channel dimension of convolution filters. On the contrary, we observe that conventional unstructured sparsity displays a substantial divergence in sparsity across the spatial domains, which we experimentally verify to be very crucial for its robust performance retention compared with N:M sparsity. Therefore, SpRe employs the spatial-sparsity distribution of unstructured sparsity by assigning an extra branch in conjunction with the original N:M branch at training time, which allows the N:M sparse network to sustain a similar distribution of spatial sparsity with unstructured sparsity. During inference, the extra branch can be further re-parameterized into the main N:M branch, without exerting any distortion on the sparse pattern or additional computation costs. SpRe has achieved a commendable feat by matching the performance of N:M sparsity methods with state-of-the-art unstructured sparsity methods across various benchmarks. Our project is available at https://github.com/zyxxmu/SpRE.","authors":["Yuxin Zhang","Mingbao Lin","Mingliang Xu","Yonghong Tian","Rongrong Ji"],"url":"https://arxiv.org/abs/2306.05612"}
{"created":"2025-05-20","title":"Securing Visually-Aware Recommender Systems: An Adversarial Image Reconstruction and Detection Framework","abstract":"With rich visual data, such as images, becoming readily associated with items, visually-aware recommendation systems (VARS) have been widely used in different applications. Recent studies have shown that VARS are vulnerable to item-image adversarial attacks, which add human-imperceptible perturbations to the clean images associated with those items. Attacks on VARS pose new security challenges to a wide range of applications such as e-Commerce and social networks where VARS are widely used. How to secure VARS from such adversarial attacks becomes a critical problem. Currently, there is still a lack of systematic study on how to design secure defense strategies against visual attacks on VARS. In this paper, we attempt to fill this gap by proposing an adversarial image reconstruction and detection framework to secure VARS. Our proposed method can simultaneously (1) secure VARS from adversarial attacks characterized by local perturbations by image reconstruction based on global vision transformers; and (2) accurately detect adversarial examples using a novel contrastive learning approach. Meanwhile, our framework is designed to be used as both a filter and a detector so that they can be jointly trained to improve the flexibility of our defense strategy to a variety of attacks and VARS models. We have conducted extensive experimental studies with two popular attack methods (FGSM and PGD). Our experimental results on two real-world datasets show that our defense strategy against visual attacks is effective and outperforms existing methods on different attacks. Moreover, our method can detect adversarial examples with high accuracy.","authors":["Minglei Yin","Bin Liu","Neil Zhenqiang Gong","Xin Li"],"url":"https://arxiv.org/abs/2306.07992"}
{"created":"2025-05-20","title":"Agreeing and Disagreeing in Collaborative Knowledge Graph Construction: An Analysis of Wikidata","abstract":"In this work, we study disagreements in discussions around Wikidata, an online knowledge community that builds the data backend of Wikipedia. Discussions are essential in collaborative work as they can increase contributor performance and encourage the emergence of shared norms and practices. While disagreements can play a productive role in discussions, they can also lead to conflicts and controversies, which impact contributor' well-being and their motivation to engage. We want to understand if and when such phenomena arise in Wikidata, using a mix of quantitative and qualitative analyses to identify the types of topics people disagree about, the most common patterns of interaction, and roles people play when arguing for or against an issue. We find that decisions to create Wikidata properties are much faster than those to delete properties and that more than half of controversial discussions do not lead to consensus. Our analysis suggests that Wikidata is an inclusive community, considering different opinions when making decisions, and that conflict and vandalism are rare in discussions. At the same time, while one-fourth of the editors participating in controversial discussions contribute legitimate and insightful opinions about Wikidata's emerging issues, they respond with one or two posts and do not remain engaged in the discussions to reach consensus. Our work contributes to the analysis of collaborative KG construction with insights about communication and decision-making in projects, as well as with methodological directions and open datasets. We hope our findings will help managers and designers support community decision-making and improve discussion tools and practices.","authors":["Elisavet Koutsiana","Tushita Yadav","Nitisha Jain","Albert Mero\\~no-Pe\\~nuela","Elena Simperl"],"url":"https://arxiv.org/abs/2306.11766"}
{"created":"2025-05-20","title":"Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits","abstract":"This paper is motivated by recent research in the $d$-dimensional stochastic linear bandit literature, which has revealed an unsettling discrepancy: algorithms like Thompson sampling and Greedy demonstrate promising empirical performance, yet this contrasts with their pessimistic theoretical regret bounds. The challenge arises from the fact that while these algorithms may perform poorly in certain problem instances, they generally excel in typical instances. To address this, we propose a new data-driven technique that tracks the geometric properties of the uncertainty ellipsoid around the main problem parameter. This methodology enables us to formulate a data-driven frequentist regret bound, which incorporates the geometric information, for a broad class of base algorithms, including Greedy, OFUL, and Thompson sampling. This result allows us to identify and ``course-correct\" problem instances in which the base algorithms perform poorly. The course-corrected algorithms achieve the minimax optimal regret of order $\\tilde{\\mathcal{O}}(d\\sqrt{T})$ for a $T$-period decision-making scenario, effectively maintaining the desirable attributes of the base algorithms, including their empirical efficacy. We present simulation results to validate our findings using synthetic and real data.","authors":["Yuwei Luo","Mohsen Bayati"],"url":"https://arxiv.org/abs/2306.14872"}
{"created":"2025-05-20","title":"Predicting Memory Demands of BDD Operations using Maximum Graph Cuts (Extended Paper)","abstract":"The BDD package Adiar manipulates Binary Decision Diagrams (BDDs) in external memory. This enables handling big BDDs, but the performance suffers when dealing with moderate-sized BDDs. This is mostly due to initializing expensive external memory data structures, even if their contents can fit entirely inside internal memory.","authors":["Steffan Christ S{\\o}lvsten","Jaco van de Pol"],"url":"https://arxiv.org/abs/2307.04488"}
{"created":"2025-05-20","title":"Complementary Frequency-Varying Awareness Network for Open-Set Fine-Grained Image Recognition","abstract":"Open-set image recognition is a challenging topic in computer vision. Most of the existing works in literature focus on learning more discriminative features from the input images, however, they are usually insensitive to the high- or low-frequency components in features, resulting in a decreasing performance on fine-grained image recognition. To address this problem, we propose a Complementary Frequency-varying Awareness Network that could better capture both high-frequency and low-frequency information, called CFAN. The proposed CFAN consists of three sequential modules: (i) a feature extraction module is introduced for learning preliminary features from the input images; (ii) a frequency-varying filtering module is designed to separate out both high- and low-frequency components from the preliminary features in the frequency domain via a frequency-adjustable filter; (iii) a complementary temporal aggregation module is designed for aggregating the high- and low-frequency components via two Long Short-Term Memory networks into discriminative features. Based on CFAN, we further propose an open-set fine-grained image recognition method, called CFAN-OSFGR, which learns image features via CFAN and classifies them via a linear classifier. Experimental results on 3 fine-grained datasets and 2 coarse-grained datasets demonstrate that CFAN-OSFGR performs significantly better than 9 state-of-the-art methods in most cases.","authors":["Qiulei Dong","Jiayin Sun","Mengyu Gao"],"url":"https://arxiv.org/abs/2307.07214"}
{"created":"2025-05-20","title":"Developing a Hybrid Convolutional Neural Network for Automatic Aphid Counting in Sugar Beet Fields","abstract":"Aphids can cause direct damage and indirect virus transmission to crops. Timely monitoring and control of their populations are thus critical. However, the manual counting of aphids, which is the most common practice, is labor-intensive and time-consuming. Additionally, two of the biggest challenges in aphid counting are that aphids are small objects and their density distributions are varied in different areas of the field. To address these challenges, we proposed a hybrid automatic aphid counting network architecture which integrates the detection network and the density map estimation network. When the distribution density of aphids is low, it utilizes an improved Yolov5 to count aphids. Conversely, when the distribution density of aphids is high, it switches to CSRNet to count aphids. To the best of our knowledge, this is the first framework integrating the detection network and the density map estimation network for counting tasks. Through comparison experiments of counting aphids, it verified that our proposed approach outperforms all other methods in counting aphids. It achieved the lowest MAE and RMSE values for both the standard and high-density aphid datasets: 2.93 and 4.01 (standard), and 34.19 and 38.66 (high-density), respectively. Moreover, the AP of the improved Yolov5 is 5% higher than that of the original Yolov5. Especially for extremely small aphids and densely distributed aphids, the detection performance of the improved Yolov5 is significantly better than the original Yolov5. This work provides an effective early warning caused by aphids in sugar beet fields, offering protection for sugar beet growth and ensuring sugar beet yield. The datasets and project code are released at: https://github.com/JunfengGaolab/Counting-Aphids.","authors":["Xumin Gao","Wenxin Xue","Callum Lennox","Mark Stevens","Junfeng Gao"],"url":"https://arxiv.org/abs/2308.05257"}
{"created":"2025-05-20","title":"Automata Learning from Preference and Equivalence Queries","abstract":"Active automata learning from membership and equivalence queries is a foundational problem with numerous applications. We propose a novel variant of the active automata learning problem: actively learn finite automata using preference queries -- i.e., queries about the relative position of two sequences in a total order -- instead of membership queries. Our solution is REMAP, a novel algorithm which leverages a symbolic observation table along with unification and constraint solving to navigate a space of symbolic hypotheses (each representing a set of automata), and uses satisfiability-solving to construct a concrete automaton from a symbolic hypothesis. REMAP is guaranteed to correctly infer the minimal automaton with polynomial query complexity under exact equivalence queries, and achieves PAC-identification ($\\varepsilon$-approximate, with high probability) of the minimal automaton using sampling-based equivalence queries. Our empirical evaluations of REMAP on the task of learning reward machines for two reinforcement learning domains indicate REMAP scales to large automata and is effective at learning correct automata from consistent teachers, under both exact and sampling-based equivalence queries.","authors":["Eric Hsiung","Joydeep Biswas","Swarat Chaudhuri"],"url":"https://arxiv.org/abs/2308.09301"}
{"created":"2025-05-20","title":"Rethinking Image Forgery Detection via Soft Contrastive Learning and Unsupervised Clustering","abstract":"Image forgery detection aims to detect and locate forged regions in an image. Most existing forgery detection algorithms formulate classification problems to classify pixels into forged or pristine. However, the definition of forged and pristine pixels is only relative within one single image, e.g., a forged region in image A is actually a pristine one in its source image B (splicing forgery). Such a relative definition has been severely overlooked by existing methods, which unnecessarily mix forged (pristine) regions across different images into the same category. To resolve this dilemma, we propose the FOrensic ContrAstive cLustering (FOCAL) method, a novel, simple yet very effective paradigm based on soft contrastive learning and unsupervised clustering for the image forgery detection. Specifically, FOCAL 1) designs a soft contrastive learning (SCL) to supervise the high-level forensic feature extraction in an image-by-image manner, explicitly reflecting the above relative definition; 2) employs an on-the-fly unsupervised clustering algorithm (instead of a trained one) to cluster the learned features into forged/pristine categories, further suppressing the cross-image influence from training data; and 3) allows to further boost the detection performance via simple feature-level concatenation without the need of retraining. Extensive experimental results over six public testing datasets demonstrate that our proposed FOCAL significantly outperforms the state-of-the-art competitors by big margins: +24.8% on Coverage, +18.9% on Columbia, +17.3% on FF++, +15.3% on MISD, +15.0% on CASIA and +10.5% on NIST in terms of IoU (see also Fig. 1). The paradigm of FOCAL could bring fresh insights and serve as a novel benchmark for the image forgery detection task. The code is available at https://github.com/HighwayWu/FOCAL.","authors":["Haiwei Wu","Yiming Chen","Jiantao Zhou","Yuanman Li"],"url":"https://arxiv.org/abs/2308.09307"}
{"created":"2025-05-20","title":"Hand Dominance and Congruence for Wrist-worn Haptics using Custom Voice-Coil Actuation","abstract":"During virtual interactions, rendering haptic feedback on a remote location (like the wrist) instead of the fingertips freeing users' hands from mechanical devices. This allows for real interactions while still providing information regarding the mechanical properties of virtual objects. In this paper, we present CoWrHap -- a novel wrist-worn haptic device with custom-made voice coil actuation to render force feedback. Then, we investigate the impact of asking participants to use their dominant or non-dominant hand for virtual interactions and the best mapping between the active hand and the wrist receiving the haptic feedback, which can be defined as hand-wrist congruence through a user experiment based on a stiffness discrimination task. Our results show that participants performed the tasks (i) better with non-congruent mapping but reported better experiences with congruent mapping, and (ii) with no statistical difference in terms of hand dominance but reported better user experience and enjoyment using their dominant hands. This study indicates that participants can perceive mechanical properties via haptic feedback provided through CoWrHap.","authors":["Ayoade Adeyemi","Umit Sen","Samet Mert Ercan","Mine Sarac"],"url":"https://arxiv.org/abs/2308.10260"}
{"created":"2025-05-20","title":"The CausalBench challenge: A machine learning contest for gene network inference from single-cell perturbation data","abstract":"In drug discovery, mapping interactions between genes within cellular systems is a crucial early step. Such maps are not only foundational for understanding the molecular mechanisms underlying disease biology but also pivotal for formulating hypotheses about potential targets for new medicines. Recognizing the need to elevate the construction of these gene-gene interaction networks, especially from large-scale, real-world datasets of perturbed single cells, the CausalBench Challenge was initiated. This challenge aimed to inspire the machine learning community to enhance state-of-the-art methods, emphasizing better utilization of expansive genetic perturbation data. Using the framework provided by the CausalBench benchmark, participants were tasked with refining the current methodologies or proposing new ones. This report provides an analysis and summary of the methods submitted during the challenge to give a partial image of the state of the art at the time of the challenge. Notably, the winning solutions significantly improved performance compared to previous baselines, establishing a new state of the art for this critical task in biology and medicine.","authors":["Mathieu Chevalley","Jacob Sackett-Sanders","Yusuf Roohani","Pascal Notin","Artemy Bakulin","Dariusz Brzezinski","Kaiwen Deng","Yuanfang Guan","Justin Hong","Michael Ibrahim","Wojciech Kotlowski","Marcin Kowiel","Panagiotis Misiakos","Achille Nazaret","Markus P\\\"uschel","Chris Wendler","Arash Mehrjou","Patrick Schwab"],"url":"https://arxiv.org/abs/2308.15395"}
{"created":"2025-05-20","title":"Quantitative Energy Prediction based on Carbon Emission Analysis by DPR Framework","abstract":"This study proposes a novel analytical framework that integrates DBSCAN clustering with the Elastic Net regression model to address multifactorial problems characterized by structural complexity and multicollinearity, exemplified by carbon emissions analysis. DBSCAN is employed for unsupervised learning to objectively cluster features, while the Elastic Net is utilized for high-dimensional feature selection and complexity control. The Elastic Net is specifically chosen for its ability to balance feature selection and regularization by combining L1 (lasso) and L2 (ridge) penalties, making it particularly suited for datasets with correlated predictors. Applying this framework to energy consumption data from 46 industries in China (2000-2019) resulted in the identification of 16 categories. Emission characteristics and drivers were quantitatively assessed for each category, demonstrating the framework's capacity to identify primary emission sources and provide actionable insights. This research underscores the global applicability of the framework for analyzing complex regional challenges, such as carbon emissions, and highlights its potential to identify opportunities for emission reduction.","authors":["Xuanming Zhang"],"url":"https://arxiv.org/abs/2309.01115"}
{"created":"2025-05-20","title":"The Impact of Artificial Intelligence on the Evolution of Digital Education: A Comparative Study of OpenAI Text Generation Tools including ChatGPT, Bing Chat, Bard, and Ernie","abstract":"In the digital era, the integration of artificial intelligence (AI) in education has ushered in transformative changes, redefining teaching methodologies, curriculum planning, and student engagement. This review paper delves deep into the rapidly evolving landscape of digital education by contrasting the capabilities and impact of OpenAI's pioneering text generation tools like Bing Chat, Bard, Ernie with a keen focus on the novel ChatGPT. Grounded in a typology that views education through the lenses of system, process, and result, the paper navigates the multifaceted applications of AI. From decentralizing global education and personalizing curriculums to digitally documenting competence-based outcomes, AI stands at the forefront of educational modernization. Highlighting ChatGPT's meteoric rise to one million users in just five days, the study underscores its role in democratizing education, fostering autodidacticism, and magnifying student engagement. However, with such transformative power comes the potential for misuse, as text-generation tools can inadvertently challenge academic integrity. By juxtaposing the promise and pitfalls of AI in education, this paper advocates for a harmonized synergy between AI tools and the educational community, emphasizing the urgent need for ethical guidelines, pedagogical adaptations, and strategic collaborations.","authors":["Negin Yazdani Motlagh","Matin Khajavi","Abbas Sharifi","Mohsen Ahmadi"],"url":"https://arxiv.org/abs/2309.02029"}
{"created":"2025-05-20","title":"LightNeuS: Neural Surface Reconstruction in Endoscopy using Illumination Decline","abstract":"We propose a new approach to 3D reconstruction from sequences of images acquired by monocular endoscopes. It is based on two key insights. First, endoluminal cavities are watertight, a property naturally enforced by modeling them in terms of a signed distance function. Second, the scene illumination is variable. It comes from the endoscope's light sources and decays with the inverse of the squared distance to the surface. To exploit these insights, we build on NeuS, a neural implicit surface reconstruction technique with an outstanding capability to learn appearance and a SDF surface model from multiple views, but currently limited to scenes with static illumination. To remove this limitation and exploit the relation between pixel brightness and depth, we modify the NeuS architecture to explicitly account for it and introduce a calibrated photometric model of the endoscope's camera and light source. Our method is the first one to produce watertight reconstructions of whole colon sections. We demonstrate excellent accuracy on phantom imagery. Remarkably, the watertight prior combined with illumination decline, allows to complete the reconstruction of unseen portions of the surface with acceptable accuracy, paving the way to automatic quality assessment of cancer screening explorations, measuring the global percentage of observed mucosa.","authors":["V\\'ictor M. Batlle","Jos\\'e M. M. Montiel","Pascal Fua","Juan D. Tard\\'os"],"url":"https://arxiv.org/abs/2309.02777"}
{"created":"2025-05-20","title":"Multicopy Reinforcement Learning Agents","abstract":"This paper examines a novel type of multi-agent problem, in which an agent makes multiple identical copies of itself in order to achieve a single agent task better or more efficiently. This strategy improves performance if the environment is noisy and the task is sometimes unachievable by a single agent copy. We propose a learning algorithm for this multicopy problem which takes advantage of the structure of the value function to efficiently learn how to balance the advantages and costs of adding additional copies.","authors":["Alicia P. Wolfe","Oliver Diamond","Brigitte Goeler-Slough","Remi Feuerman","Magdalena Kisielinska","Victoria Manfredi"],"url":"https://arxiv.org/abs/2309.10908"}
{"created":"2025-05-20","title":"Automating construction contract review using knowledge graph-enhanced large language models","abstract":"An effective and efficient review of construction contracts is essential for minimizing construction projects losses, but current methods are time-consuming and error-prone. Studies using methods based on Natural Language Processing (NLP) exist, but their scope is often limited to text classification or segmented label prediction. This paper investigates whether integrating Large Language Models (LLMs) and Knowledge Graphs (KGs) can enhance the accuracy and interpretability of automated contract risk identification. A tuning-free approach is proposed that integrates LLMs with a Nested Contract Knowledge Graph (NCKG) using a Graph Retrieval-Augmented Generation (GraphRAG) framework for contract knowledge retrieval and reasoning. Tested on international EPC contracts, the method achieves more accurate risk evaluation and interpretable risk summaries than baseline models. These findings demonstrate the potential of combining LLMs and KGs for reliable reasoning in tasks that are knowledge-intensive and specialized, such as contract review.","authors":["Chunmo Zheng","Saika Wong","Xing Su","Yinqiu Tang","Ahsan Nawaz","Mohamad Kassem"],"url":"https://arxiv.org/abs/2309.12132"}
{"created":"2025-05-20","title":"PlanFitting: Personalized Exercise Planning with Large Language Model-driven Conversational Agent","abstract":"Creating personalized and actionable exercise plans often requires iteration with experts, which can be costly and inaccessible to many individuals. This work explores the capabilities of Large Language Models (LLMs) in addressing these challenges. We present PlanFitting, an LLM-driven conversational agent that assists users in creating and refining personalized weekly exercise plans. By engaging users in free-form conversations, PlanFitting helps elicit users' goals, availabilities, and potential obstacles, and enables individuals to generate personalized exercise plans aligned with established exercise guidelines. Our study -- involving a user study, intrinsic evaluation, and expert evaluation -- demonstrated PlanFitting's ability to guide users to create tailored, actionable, and evidence-based plans. We discuss future design opportunities for LLM-driven conversational agents to create plans that better comply with exercise principles and accommodate personal constraints.","authors":["Donghoon Shin","Gary Hsieh","Young-Ho Kim"],"url":"https://arxiv.org/abs/2309.12555"}
{"created":"2025-05-20","title":"EMelodyGen: Emotion-Conditioned Melody Generation in ABC Notation with the Musical Feature Template","abstract":"The EMelodyGen system focuses on emotional melody generation in ABC notation controlled by the musical feature template. Owing to the scarcity of well-structured and emotionally labeled sheet music, we designed a template for controlling emotional melody generation by statistical correlations between musical features and emotion labels derived from small-scale emotional symbolic music datasets and music psychology conclusions. We then automatically annotated a large, well-structured sheet music collection with rough emotional labels by the template, converted them into ABC notation, and reduced label imbalance by data augmentation, resulting in a dataset named Rough4Q. Our system backbone pre-trained on Rough4Q can achieve up to 99% music21 parsing rate and melodies generated by our template can lead to a 91% alignment on emotional expressions in blind listening tests. Ablation studies further validated the effectiveness of the feature controls in the template. Available code and demos are at https://github.com/monetjoe/EMelodyGen.","authors":["Monan Zhou","Xiaobing Li","Feng Yu","Wei Li"],"url":"https://arxiv.org/abs/2309.13259"}
{"created":"2025-05-20","title":"Kick Bad Guys Out! Conditionally Activated Anomaly Detection in Federated Learning with Zero-Knowledge Proof Verification","abstract":"Federated Learning (FL) systems are vulnerable to adversarial attacks, such as model poisoning and backdoor attacks. However, existing defense mechanisms often fall short in real-world settings due to key limitations: they may rely on impractical assumptions, introduce distortions by modifying aggregation functions, or degrade model performance even in benign scenarios. To address these issues, we propose a novel anomaly detection method designed specifically for practical FL scenarios. Our approach employs a two-stage, conditionally activated detection mechanism: cross-round check first detects whether suspicious activity has occurred, and, if warranted, a cross-client check filters out malicious participants. This mechanism preserves utility while avoiding unrealistic assumptions. Moreover, to ensure the transparency and integrity of the defense mechanism, we incorporate zero-knowledge proofs, enabling clients to verify the detection without relying solely on the server's goodwill. To the best of our knowledge, this is the first method to bridge the gap between theoretical advances in FL security and the demands of real-world deployment. Extensive experiments across diverse tasks and real-world edge devices demonstrate the effectiveness of our method over state-of-the-art defenses.","authors":["Shanshan Han","Wenxuan Wu","Baturalp Buyukates","Weizhao Jin","Qifan Zhang","Yuhang Yao","Salman Avestimehr","Chaoyang He"],"url":"https://arxiv.org/abs/2310.04055"}
{"created":"2025-05-20","title":"Efficient Multi-robot Active SLAM","abstract":"Autonomous exploration in unknown environments remains a fundamental challenge in robotics, particularly for applications such as search and rescue, industrial inspection, and planetary exploration. Multi-robot active SLAM presents a promising solution by enabling collaborative mapping and exploration while actively reducing uncertainty. However, existing approaches often suffer from high computational costs and inefficient frontier management, making them computationally expensive for real-time applications. In this paper, we introduce an efficient multi-robot active SLAM framework that incorporates a frontier-sharing strategy to enhance robot distribution in unexplored environments. Our approach integrates a utility function that considers both pose graph uncertainty and path entropy, achieving an optimal balance between exploration coverage and computational efficiency. By filtering and prioritizing goal frontiers, our method significantly reduces computational overhead while preserving high mapping accuracy. The proposed framework has been implemented in ROS and validated through simulations and real-world experiments. Results demonstrate superior exploration performance and mapping quality compared to state-of-the-art approaches.","authors":["Muhammad Farhan Ahmed","Matteo Maragliano","Vincent Fr\\'emont","Carmine Tommaso Recchiuto"],"url":"https://arxiv.org/abs/2310.06160"}
{"created":"2025-05-20","title":"How Good is ChatGPT in Giving Advice on Your Visualization Design?","abstract":"Data visualization creators often lack formal training, resulting in a knowledge gap in design practice. Large language models such as ChatGPT, with their vast internet-scale training data, offer transformative potential to address this gap. In this study, we used both qualitative and quantitative methods to investigate how well ChatGPT can address visualization design questions. First, we quantitatively compared the ChatGPT-generated responses with anonymous online Human replies to data visualization questions on the VisGuides user forum. Next, we conducted a qualitative user study examining the reactions and attitudes of practitioners toward ChatGPT as a visualization design assistant. Participants were asked to bring their visualizations and design questions and received feedback from both Human experts and ChatGPT in randomized order. Our findings from both studies underscore ChatGPT's strengths, particularly its ability to rapidly generate diverse design options, while also highlighting areas for improvement, such as nuanced contextual understanding and fluid interaction dynamics beyond the chat interface. Drawing on these insights, we discuss design considerations for future LLM-based design feedback systems.","authors":["Nam Wook Kim","Yongsu Ahn","Grace Myers","Benjamin Bach"],"url":"https://arxiv.org/abs/2310.09617"}
{"created":"2025-05-20","title":"Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models","abstract":"Multilingual large-scale Pretrained Language Models (PLMs) have been shown to store considerable amounts of factual knowledge, but large variations are observed across languages. With the ultimate goal of ensuring that users with different language backgrounds obtain consistent feedback from the same model, we study the cross-lingual consistency (CLC) of factual knowledge in various multilingual PLMs. To this end, we propose a Ranking-based Consistency (RankC) metric to evaluate knowledge consistency across languages independently from accuracy. Using this metric, we conduct an in-depth analysis of the determining factors for CLC, both at model level and at language-pair level. Among other results, we find that increasing model size leads to higher factual probing accuracy in most languages, but does not improve cross-lingual consistency. Finally, we conduct a case study on CLC when new factual associations are inserted in the PLMs via model editing. Results on a small sample of facts inserted in English reveal a clear pattern whereby the new piece of knowledge transfers only to languages with which English has a high RankC score.","authors":["Jirui Qi","Raquel Fern\\'andez","Arianna Bisazza"],"url":"https://arxiv.org/abs/2310.10378"}
{"created":"2025-05-20","title":"Policy Optimization via Adv2: Adversarial Learning on Advantage Functions","abstract":"We revisit the reduction of learning in adversarial Markov decision processes [MDPs] to adversarial learning based on $Q$--values; this reduction has been considered in a number of recent articles as one building block to perform policy optimization. Namely, we first consider and extend this reduction in an ideal setting where an oracle provides value functions: it may involve any adversarial learning strategy (not just exponential weights) and it may be based indifferently on $Q$--values or on advantage functions. We then present two extensions: on the one hand, convergence of the last iterate for a vast class of adversarial learning strategies (again, not just exponential weights), satisfying a property called monotonicity of weights; on the other hand, stronger regret criteria for learning in MDPs, inherited from the stronger regret criteria of adversarial learning called strongly adaptive regret and tracking regret. Third, we demonstrate how adversarial learning, also referred to as aggregation of experts, relates to aggregation (orchestration) of expert policies: we obtain stronger forms of performance guarantees in this setting than existing ones, via yet another, simple reduction. Finally, we discuss the impact of the reduction of learning in adversarial MDPs to adversarial learning in the practical scenarios where transition kernels are unknown and value functions must be learned. In particular, we review the literature and note that many strategies for policy optimization feature a policy-improvement step based on exponential weights with estimated $Q$--values. Our main message is that this step may be replaced by the application of any adversarial learning strategy on estimated $Q$--values or on estimated advantage functions. We leave the empirical evaluation of these twists for future research.","authors":["Matthieu Jonckheere (LAAS-SARA)","Chiara Mignacco (LMO","CELESTE)","Gilles Stoltz (LMO","CELESTE)"],"url":"https://arxiv.org/abs/2310.16473"}
{"created":"2025-05-20","title":"EcoLearn: Optimizing the Carbon Footprint of Federated Learning","abstract":"Federated Learning (FL) distributes machine learning (ML) training across edge devices to reduce data transfer overhead and protect data privacy. Since FL model training may span hundreds of devices and is thus resource- and energy-intensive, it has a significant carbon footprint. Importantly, since energy's carbon-intensity differs substantially (by up to 60$\\times$) across locations, training on the same device using the same amount of energy, but at different locations, can incur widely different carbon emissions. While prior work has focused on improving FL's resource- and energy-efficiency by optimizing time-to-accuracy, it implicitly assumes all energy has the same carbon intensity and thus does not optimize carbon efficiency, i.e., work done per unit of carbon emitted.","authors":["Talha Mehboob","Noman Bashir","Jesus Omana Iglesias","Michael Zink","David Irwin"],"url":"https://arxiv.org/abs/2310.17972"}
{"created":"2025-05-20","title":"Automatically generating Riddles aiding Concept Attainment","abstract":"One of the primary challenges in online learning environments, is to retain learner engagement. Several different instructional strategies are proposed both in online and offline environments to enhance learner engagement. The Concept Attainment Model is one such instructional strategy that focuses on learners acquiring a deeper understanding of a concept rather than just its dictionary definition. This is done by searching and listing the properties used to distinguish examples from non-examples of various concepts. Our work attempts to apply the Concept Attainment Model to build conceptual riddles, to deploy over online learning environments. The approach involves creating factual triples from learning resources, classifying them based on their uniqueness to a concept into `Topic Markers' and `Common', followed by generating riddles based on the Concept Attainment Model's format and capturing all possible solutions to those riddles. The results obtained from the human evaluation of riddles prove encouraging.","authors":["Niharika Sri Parasa","Chaitali Diwan","Srinath Srinivasa"],"url":"https://arxiv.org/abs/2310.18290"}
{"created":"2025-05-20","title":"Convergence analysis and parameter estimation for the iterated Arnoldi-Tikhonov method","abstract":"The Arnoldi-Tikhonov method is a well-established regularization technique for solving large-scale ill-posed linear inverse problems. This method leverages the Arnoldi decomposition to reduce computational complexity by projecting the discretized problem into a lower-dimensional Krylov subspace, in which it is solved. This paper explores the iterated Arnoldi-Tikhonov method, conducting a comprehensive analysis that addresses all approximation errors. Additionally, it introduces a novel strategy for choosing the regularization parameter, leading to more accurate approximate solutions compared to the standard Arnoldi-Tikhonov method. Moreover, the proposed method demonstrates robustness with respect to the regularization parameter, as confirmed by the numerical results.","authors":["Davide Bianchi","Marco Donatelli","Davide Furch\\`i","Lothar Reichel"],"url":"https://arxiv.org/abs/2311.11823"}
{"created":"2025-05-20","title":"Robustness-Reinforced Knowledge Distillation with Correlation Distance and Network Pruning","abstract":"The improvement in the performance of efficient and lightweight models (i.e., the student model) is achieved through knowledge distillation (KD), which involves transferring knowledge from more complex models (i.e., the teacher model). However, most existing KD techniques rely on Kullback-Leibler (KL) divergence, which has certain limitations. First, if the teacher distribution has high entropy, the KL divergence's mode-averaging nature hinders the transfer of sufficient target information. Second, when the teacher distribution has low entropy, the KL divergence tends to excessively focus on specific modes, which fails to convey an abundant amount of valuable knowledge to the student. Consequently, when dealing with datasets that contain numerous confounding or challenging samples, student models may struggle to acquire sufficient knowledge, resulting in subpar performance. Furthermore, in previous KD approaches, we observed that data augmentation, a technique aimed at enhancing a model's generalization, can have an adverse impact. Therefore, we propose a Robustness-Reinforced Knowledge Distillation (R2KD) that leverages correlation distance and network pruning. This approach enables KD to effectively incorporate data augmentation for performance improvement. Extensive experiments on various datasets, including CIFAR-100, FGVR, TinyImagenet, and ImageNet, demonstrate our method's superiority over current state-of-the-art methods.","authors":["Seonghak Kim","Gyeongdo Ham","Yucheol Cho","Daeshik Kim"],"url":"https://arxiv.org/abs/2311.13934"}
{"created":"2025-05-20","title":"A Cyclic Small Phase Theorem","abstract":"This paper introduces a brand-new phase definition called the segmental phase for multi-input multi-output linear time-invariant systems. The underpinning of the definition lies in the matrix segmental phase which, as its name implies, is graphically based on the smallest circular segment covering the matrix normalized numerical range in the unit disk. The matrix segmental phase has the crucial product eigen-phase bound, which makes itself stand out from several existing phase notions in the literature. The proposed bound paves the way for stability analysis of a single-loop cyclic feedback system consisting of multiple subsystems. A cyclic small phase theorem is then established as our main result, which requires the loop system phase to lie between $-\\pi$ and $\\pi$. The proposed theorem complements a cyclic version of the celebrated small gain theorem. In addition, a generalization of the proposed theorem is made via the use of angular scaling techniques for reducing conservatism.","authors":["Chao Chen","Wei Chen","Di Zhao","Jianqi Chen","Li Qiu"],"url":"https://arxiv.org/abs/2312.00956"}
{"created":"2025-05-20","title":"Hot PATE: Private Aggregation of Distributions for Diverse Task","abstract":"The Private Aggregation of Teacher Ensembles (PATE) framework enables privacy-preserving machine learning by aggregating responses from disjoint subsets of sensitive data. Adaptations of PATE to tasks with inherent output diversity such as text generation face a core tension: preserving output diversity reduces teacher agreement, which in turn increases the noise required for differential privacy, degrading utility. Yet suppressing diversity is counterproductive, as modern large language models encapsulate knowledge in their output distributions.","authors":["Edith Cohen","Benjamin Cohen-Wang","Xin Lyu","Jelani Nelson","Tamas Sarlos","Uri Stemmer"],"url":"https://arxiv.org/abs/2312.02132"}
{"created":"2025-05-20","title":"Does Vector Quantization Fail in Spatio-Temporal Forecasting? Exploring a Differentiable Sparse Soft-Vector Quantization Approach","abstract":"Spatio-temporal forecasting is crucial in various fields and requires a careful balance between identifying subtle patterns and filtering out noise. Vector quantization (VQ) appears well-suited for this purpose, as it quantizes input vectors into a set of codebook vectors or patterns. Although VQ has shown promise in various computer vision tasks, it surprisingly falls short in enhancing the accuracy of spatio-temporal forecasting. We attribute this to two main issues: inaccurate optimization due to non-differentiability and limited representation power in hard-VQ. To tackle these challenges, we introduce Differentiable Sparse Soft-Vector Quantization (SVQ), the first VQ method to enhance spatio-temporal forecasting. SVQ balances detail preservation with noise reduction, offering full differentiability and a solid foundation in sparse regression. Our approach employs a two-layer MLP and an extensive codebook to streamline the sparse regression process, significantly cutting computational costs while simplifying training and improving performance. Empirical studies on five spatio-temporal benchmark datasets show SVQ achieves state-of-the-art results, including a 7.9% improvement on the WeatherBench-S temperature dataset and an average mean absolute error reduction of 9.4% in video prediction benchmarks (Human3.6M, KTH, and KittiCaltech), along with a 17.3% enhancement in image quality (LPIPS). Code is publicly available at https://github.com/Pachark/SVQ-Forecasting.","authors":["Chao Chen","Tian Zhou","Yanjun Zhao","Hui Liu","Liang Sun","Rong Jin"],"url":"https://arxiv.org/abs/2312.03406"}
{"created":"2025-05-20","title":"Towards Enhanced Image Inpainting: Mitigating Unwanted Object Insertion and Preserving Color Consistency","abstract":"Recent advances in image inpainting increasingly use generative models to handle large irregular masks. However, these models can create unrealistic inpainted images due to two main issues: (1) Unwanted object insertion: Even with unmasked areas as context, generative models may still generate arbitrary objects in the masked region that don't align with the rest of the image. (2) Color inconsistency: Inpainted regions often have color shifts that causes a smeared appearance, reducing image quality. Retraining the generative model could help solve these issues, but it's costly since state-of-the-art latent-based diffusion and rectified flow models require a three-stage training process: training a VAE, training a generative U-Net or transformer, and fine-tuning for inpainting. Instead, this paper proposes a post-processing approach, dubbed as ASUKA (Aligned Stable inpainting with UnKnown Areas prior), to improve inpainting models. To address unwanted object insertion, we leverage a Masked Auto-Encoder (MAE) for reconstruction-based priors. This mitigates object hallucination while maintaining the model's generation capabilities. To address color inconsistency, we propose a specialized VAE decoder that treats latent-to-image decoding as a local harmonization task, significantly reducing color shifts for color-consistent inpainting. We validate ASUKA on SD 1.5 and FLUX inpainting variants with Places2 and MISATO, our proposed diverse collection of datasets. Results show that ASUKA mitigates object hallucination and improves color consistency over standard diffusion and rectified flow models and other inpainting methods.","authors":["Yikai Wang","Chenjie Cao","Junqiu Yu","Ke Fan","Xiangyang Xue","Yanwei Fu"],"url":"https://arxiv.org/abs/2312.04831"}
{"created":"2025-05-20","title":"ATE-SG: Alternate Through the Epochs Stochastic Gradient for Multi-Task Neural Networks","abstract":"This paper introduces novel alternate training procedures for hard-parameter sharing Multi-Task Neural Networks (MTNNs). Traditional MTNN training faces challenges in managing conflicting loss gradients, often yielding sub-optimal performance. The proposed alternate training method updates shared and task-specific weights alternately through the epochs, exploiting the multi-head architecture of the model. This approach reduces computational costs per epoch and memory requirements. Convergence properties similar to those of the classical stochastic gradient method are established. Empirical experiments demonstrate enhanced training regularization and reduced computational demands. In summary, our alternate training procedures offer a promising advancement for the training of hard-parameter sharing MTNNs.","authors":["Stefania Bellavia","Francesco Della Santa","Alessandra Papini"],"url":"https://arxiv.org/abs/2312.16340"}
{"created":"2025-05-20","title":"Diversity-aware clustering: Computational Complexity and Approximation Algorithms","abstract":"In this work, we study diversity-aware clustering problems where the data points are associated with multiple attributes resulting in intersecting groups. A clustering solution needs to ensure that the number of chosen cluster centers from each group should be within the range defined by a lower and upper bound threshold for each group, while simultaneously minimizing the clustering objective, which can be either $k$-median, $k$-means or $k$-supplier. We study the computational complexity of the proposed problems, offering insights into their NP-hardness, polynomial-time inapproximability, and fixed-parameter intractability. We present parameterized approximation algorithms with approximation ratios $1+ \\frac{2}{e} + \\epsilon \\approx 1.736$, $1+\\frac{8}{e} + \\epsilon \\approx 3.943$, and $5$ for diversity-aware $k$-median, diversity-aware $k$-means and diversity-aware $k$-supplier, respectively. Assuming Gap-ETH, the approximation ratios are tight for the diversity-aware $k$-median and diversity-aware $k$-means problems. Our results imply the same approximation factors for their respective fair variants with disjoint groups -- fair $k$-median, fair $k$-means, and fair $k$-supplier -- with lower bound requirements.","authors":["Suhas Thejaswi","Ameet Gadekar","Bruno Ordozgoiti","Aristides Gionis"],"url":"https://arxiv.org/abs/2401.05502"}
{"created":"2025-05-20","title":"A cable finite element formulation based on exact tension field for static nonlinear analysis of cable structures","abstract":"This paper presents a numerically exact cable finite element model for static nonlinear analysis of cable structures. The model derives the exact expression of the tension field using the geometrically exact beam theory coupled with the fundamental mechanical characteristics of cables. The equations for the cable element are formulated by addressing the equilibrium conditions at the element boundaries and ensuring compatibility within the element. Unlike previous studies that typically provide explicit expressions for cable models, this study develops a formulation that emphasizes numerical precision and broad applicability. It achieves this by deriving linearized equations with implicit expressions incorporating integrals. The proposed model accurately computes internal forces and deformation states, and determines the unstrained length of the cable. Additionally, it accounts for the variability in cross-sectional stiffness along the cable's length. The paper discusses solution implementations using the complete tangent matrix and element internal iterations. The effectiveness of the proposed cable element is demonstrated through numerical examples.","authors":["Wenxiong Li","Qikun Huang","Suiyin Chen"],"url":"https://arxiv.org/abs/2401.05609"}
{"created":"2025-05-20","title":"On the Challenges of Fuzzing Techniques via Large Language Models","abstract":"In the modern era where software plays a pivotal role, software security and vulnerability analysis are essential for secure software development. Fuzzing test, as an efficient and traditional software testing method, has been widely adopted across various domains. Meanwhile, the rapid development in Large Language Models (LLMs) has facilitated their application in the field of software testing, demonstrating remarkable performance. As existing fuzzing test techniques are not fully automated and software vulnerabilities continue to evolve, there is a growing interest in leveraging large language models to generate fuzzing test. In this paper, we present a systematic overview of the developments that utilize large language models for the fuzzing test. To our best knowledge, this is the first work that covers the intersection of three areas, including LLMs, fuzzing test, and fuzzing test generated based on LLMs. A statistical analysis and discussion of the literature are conducted by summarizing the state-of-the-art methods up to date of the submission. Our work also investigates the potential for widespread deployment and application of fuzzing test techniques generated by LLMs in the future, highlighting their promise for advancing automated software testing practices.","authors":["Linghan Huang","Peizhou Zhao","Huaming Chen","Lei Ma"],"url":"https://arxiv.org/abs/2402.00350"}
{"created":"2025-05-20","title":"Streaming Sequence Transduction through Dynamic Compression","abstract":"We introduce STAR (Stream Transduction with Anchor Representations), a novel Transformer-based model designed for efficient sequence-to-sequence transduction over streams. STAR dynamically segments input streams to create compressed anchor representations, achieving nearly lossless compression (12x) in Automatic Speech Recognition (ASR) and outperforming existing methods. Moreover, STAR demonstrates superior segmentation and latency-quality trade-offs in simultaneous speech-to-text tasks, optimizing latency, memory footprint, and quality.","authors":["Weiting Tan","Yunmo Chen","Tongfei Chen","Guanghui Qin","Haoran Xu","Heidi C. Zhang","Benjamin Van Durme","Philipp Koehn"],"url":"https://arxiv.org/abs/2402.01172"}
{"created":"2025-05-20","title":"Benchmarking Anomaly Detection Algorithms: Deep Learning and Beyond","abstract":"Detection of anomalous situations for complex mission-critical systems hold paramount importance when their service continuity needs to be ensured. A major challenge in detecting anomalies from the operational data arises due to the imbalanced class distribution problem since the anomalies are supposed to be rare events. This paper evaluates a diverse array of Machine Learning (ML)-based anomaly detection algorithms through a comprehensive benchmark study. The paper contributes significantly by conducting an unbiased comparison of various anomaly detection algorithms, spanning classical ML, including various tree-based approaches to Deep Learning (DL) and outlier detection methods. The inclusion of 104 publicly available enhances the diversity of the study, allowing a more realistic evaluation of algorithm performance and emphasizing the importance of adaptability to real-world scenarios.","authors":["Shanay Mehta","Shlok Mehendale","Nicole Fernandes","Jyotirmoy Sarkar","Santonu Sarkar","Snehanshu Saha"],"url":"https://arxiv.org/abs/2402.07281"}
{"created":"2025-05-20","title":"Can We Verify Step by Step for Incorrect Answer Detection?","abstract":"Chain-of-Thought (CoT) prompting has marked a significant advancement in enhancing the reasoning capabilities of large language models (LLMs). Previous studies have developed various extensions of CoT, which focus primarily on enhancing end-task performance. In addition, there has been research on assessing the quality of reasoning chains in CoT. This raises an intriguing question: Is it possible to predict the accuracy of LLM outputs by scrutinizing the reasoning chains they generate? To answer this research question, we introduce a benchmark, R2PE, designed specifically to explore the relationship between reasoning chains and performance in various reasoning tasks spanning five different domains. This benchmark aims to measure the falsehood of the final output of LLMs based on the reasoning steps. To make full use of information in multiple reasoning chains, we propose the process discernibility score (PDS) framework that beats the answer-checking baseline by a large margin. Concretely, this resulted in an average of $5.1\\%$ increase in the F1 score and $2.97\\%$ improvement in AUC-PR across all 45 subsets within R2PE. We further demonstrate our PDS's efficacy in advancing open-domain QA accuracy.","authors":["Xin Xu","Shizhe Diao","Can Yang","Yang Wang"],"url":"https://arxiv.org/abs/2402.10528"}
{"created":"2025-05-20","title":"FormulaReasoning: A Dataset for Formula-Based Numerical Reasoning","abstract":"The application of formulas (e.g., physics formulas) is a fundamental ability of humans when solving numerical reasoning problems. Existing numerical reasoning datasets seldom explicitly indicate the formulas employed in reasoning, as their questions rely on implicit commonsense mathematical knowledge. In contrast, in this paper, we introduce FormulaReasoning, a new dataset specifically designed for formula-based numerical reasoning. Each of the 4,751 questions in our dataset requires numerical calculation with external physics formulas, making it a more challenging benchmark for evaluating large language models (LLMs). We offer normalized fine-grained annotations for the questions, available in English and Chinese, including formula structures, parameter names, symbols, numerical values, and units, derived from extensive manual effort with LLM assistance for guaranteed quality. We also provide a consolidated formula database to serve as an external knowledge base accompanying the dataset. We employ FormulaReasoning to evaluate LLMs with 7B to over 100B parameters, and explore retrieval-augmented generation with the formula database. Our evaluation also covers supervised methods that break down the reasoning process into formula generation, parameter extraction, and numerical calculation, as well as direct preference optimization methods based on derived preference data.","authors":["Xiao Li","Bolin Zhu","Kaiwen Shi","Sichen Liu","Yin Zhu","Yiwei Liu","Gong Cheng"],"url":"https://arxiv.org/abs/2402.12692"}
{"created":"2025-05-20","title":"Comparing Specialised Small and General Large Language Models on Text Classification: 100 Labelled Samples to Achieve Break-Even Performance","abstract":"When solving NLP tasks with limited labelled data, researchers typically either use a general large language model without further update, or use a small number of labelled samples to tune a specialised smaller model. In this work, we answer an important question -- how many labelled samples are required for the specialised small models to outperform general large models, while taking the performance variance into consideration. By observing the behaviour of fine-tuning, instruction-tuning, prompting and in-context learning on 8 language models, we identify such performance break-even points across 8 representative text classification tasks of varying characteristics. We show that the specialised models often need only few samples (on average $100$) to be on par or better than the general ones. At the same time, the number of required labels strongly depends on the dataset or task characteristics, with fine-tuning on binary datasets requiring significantly more samples. When performance variance is taken into consideration, the number of required labels increases on average by $100 - 200\\%$. Finally, larger models do not consistently lead to better performance and lower variance, with 4-bit quantisation having negligible impact.","authors":["Branislav Pecher","Ivan Srba","Maria Bielikova"],"url":"https://arxiv.org/abs/2402.12819"}
{"created":"2025-05-20","title":"Scalable Density-based Clustering with Random Projections","abstract":"We present sDBSCAN, a scalable density-based clustering algorithm in high dimensions with cosine distance. Utilizing the neighborhood-preserving property of random projections, sDBSCAN can quickly identify core points and their neighborhoods, the primary hurdle of density-based clustering. Theoretically, sDBSCAN outputs a clustering structure similar to DBSCAN under mild conditions with high probability. To further facilitate sDBSCAN, we present sOPTICS, a scalable OPTICS for interactive exploration of the intrinsic clustering structure. We also extend sDBSCAN and sOPTICS to L2, L1, $\\chi^2$, and Jensen-Shannon distances via random kernel features. Empirically, sDBSCAN is significantly faster and provides higher accuracy than many other clustering algorithms on real-world million-point data sets. On these data sets, sDBSCAN and sOPTICS run in a few minutes, while the scikit-learn's counterparts demand several hours or cannot run due to memory constraints.","authors":["Haochuan Xu","Ninh Pham"],"url":"https://arxiv.org/abs/2402.15679"}
{"created":"2025-05-20","title":"COMAE: COMprehensive Attribute Exploration for Zero-shot Hashing","abstract":"Zero-shot hashing (ZSH) has shown excellent success owing to its efficiency and generalization in large-scale retrieval scenarios. While considerable success has been achieved, there still exist urgent limitations. Existing works ignore the locality relationships of representations and attributes, which have effective transferability between seeable classes and unseeable classes. Also, the continuous-value attributes are not fully harnessed. In response, we conduct a COMprehensive Attribute Exploration for ZSH, named COMAE, which depicts the relationships from seen classes to unseen ones through three meticulously designed explorations, i.e., point-wise, pair-wise and class-wise consistency constraints. By regressing attributes from the proposed attribute prototype network, COMAE learns the local features that are relevant to the visual attributes. Then COMAE utilizes contrastive learning to comprehensively depict the context of attributes, rather than instance-independent optimization. Finally, the class-wise constraint is designed to cohesively learn the hash code, image representation, and visual attributes more effectively. Experimental results on the popular ZSH datasets demonstrate that COMAE outperforms state-of-the-art hashing techniques, especially in scenarios with a larger number of unseen label classes.","authors":["Yuqi Li","Qingqing Long","Yihang Zhou","Ran Zhang","Zhiyuan Ning","Zhihong Zhu","Yuanchun Zhou","Xuezhi Wang","Meng Xiao"],"url":"https://arxiv.org/abs/2402.16424"}
{"created":"2025-05-20","title":"A Categorical Treatment of Open Linear Systems","abstract":"An open stochastic system \\`a la Jan Willems is a system affected by two qualitatively different kinds of uncertainty: one is probabilistic fluctuation, and the other one is nondeterminism caused by a fundamental lack of information. We present a formalization of open stochastic systems in the language of category theory. Central to this is the notion of copartiality which models how the lack of information propagates through a system (corresponding to the coarseness of sigma-algebras in Willems' work). As a concrete example, we study extended Gaussian distributions, which combine Gaussian probability with nondeterminism and correspond precisely to Willems' notion of Gaussian linear systems. We describe them both as measure-theoretic and abstract categorical entities, which enables us to rigorously describe a variety of phenomena like noisy physical laws and uninformative priors in Bayesian statistics. The category of extended Gaussian maps can be seen as a mutual generalization of Gaussian probability and linear relations, which connects the literature on categorical probability with ideas from control theory like signal-flow diagrams.","authors":["Dario Stein","Richard Samuelson"],"url":"https://arxiv.org/abs/2403.03934"}
{"created":"2025-05-20","title":"Enhancing Multimodal Unified Representations for Cross Modal Generalization","abstract":"To enhance the interpretability of multimodal unified representations, many studies have focused on discrete unified representations. These efforts typically start with contrastive learning and gradually extend to the disentanglement of modal information, achieving solid multimodal discrete unified representations. However, existing research often overlooks two critical issues: 1) The use of Euclidean distance for quantization in discrete representations often overlooks the important distinctions among different dimensions of features, resulting in redundant representations after quantization; 2) Different modalities have unique characteristics, and a uniform alignment approach does not fully exploit these traits. To address these issues, we propose Training-free Optimization of Codebook (TOC) and Fine and Coarse cross-modal Information Disentangling (FCID). These methods refine the unified discrete representations from pretraining and perform fine- and coarse-grained information disentanglement tailored to the specific characteristics of each modality, achieving significant performance improvements over previous state-of-the-art models.","authors":["Hai Huang","Yan Xia","Shengpeng Ji","Shulei Wang","Hanting Wang","Minghui Fang","Jieming Zhu","Zhenhua Dong","Sashuai Zhou","Zhou Zhao"],"url":"https://arxiv.org/abs/2403.05168"}
{"created":"2025-05-20","title":"An Overview of Automated Vehicle Longitudinal Platoon Formation Strategies","abstract":"Automated vehicle (AV) platooning has the potential to improve the safety, operational, and energy efficiency of surface transportation systems by limiting or eliminating human involvement in the driving tasks. The theoretical validity of the AV platooning strategies has been established and practical applications are being tested under real-world conditions. The emergence of sensors, communication, and control strategies has resulted in rapid and constant evolution of AV platooning strategies. In this paper, we review the state-of-the-art knowledge in AV longitudinal platoon formation using a five-component platooning framework, which includes vehicle model, information-receiving process, information flow topology, spacing policy, and controller and discuss the advantages and limitations of the components. Based on the discussion about existing strategies and associated limitations, potential future research directions are presented.","authors":["M Sabbir Salek","Mugdha Basu Thakur","Pardha Sai Krishna Ala","Mashrur Chowdhury","Matthias Schmid","Pamela Murray-Tuite","Sakib Mahmud Khan","Venkat Krovi"],"url":"https://arxiv.org/abs/2403.05415"}
{"created":"2025-05-20","title":"Take Your Best Shot: Sampling-Based Next-Best-View Planning for Autonomous Photography & Inspection","abstract":"Autonomous mobile robots (AMRs) equipped with high-quality cameras have revolutionized the field of inspections by providing efficient and cost-effective means of conducting surveys. The use of autonomous inspection is becoming more widespread in a variety of contexts, yet it is still challenging to acquire the best inspection information autonomously. In situations where objects may block a robot's view, it is necessary to use reasoning to determine the optimal points for collecting data. Although researchers have explored cloud-based applications to store inspection data, these applications may not operate optimally under network constraints, and parsing these datasets can be manually intensive. Instead, there is an emerging requirement for AMRs to autonomously capture the most informative views efficiently. To address this challenge, we present an autonomous Next-Best-View (NBV) framework that maximizes the inspection information while reducing the number of pictures needed during operations. The framework consists of a formalized evaluation metric using ray-tracing and Gaussian process interpolation to estimate information reward based on the current understanding of the partially-known environment. A derivative-free optimization (DFO) method is used to sample candidate views in the environment and identify the NBV point. The proposed approach's effectiveness is shown by comparing it with existing methods and further validated through simulations and experiments with various vehicles.","authors":["Shijie Gao","Lauren Bramblett","Nicola Bezzo"],"url":"https://arxiv.org/abs/2403.05477"}
{"created":"2025-05-20","title":"Economic Capacity Withholding Bounds of Competitive Energy Storage Bidders","abstract":"Economic withholding in electricity markets refers to generators bidding higher than their true marginal fuel cost, and is a typical approach to exercising market power. However, existing market designs require storage to design bids strategically based on their own future price predictions, motivating storage to conduct economic withholding without assuming market power. As energy storage takes up more significant roles in wholesale electricity markets, understanding its motivations for economic withholding and the consequent effects on social welfare becomes increasingly vital. This paper derives a theoretical framework to study the economic capacity withholding behavior of storage participating in competitive electricity markets and validate our results in simulations based on the ISO New England system. We demonstrate that storage bids can reach unbounded high levels under conditions where future price predictions show bounded expectations but unbounded deviations. Conversely, in scenarios with peak price limitations, we show the upper bounds of storage bids are grounded in bounded price expectations. Most importantly, we show that storage capacity withholding can potentially lower the overall system cost when price models account for system uncertainties. Our paper reveals energy storage is not a market manipulator but an honest player contributing to the social welfare. It helps electricity market researchers and operators better understand the economic withholding behavior of storage and reform market policies to maximize storage contributing to a cost-efficient decolonization.","authors":["Xin Qin","Ioannis Lestas","Bolun Xu"],"url":"https://arxiv.org/abs/2403.05705"}
{"created":"2025-05-20","title":"Offboard Occupancy Refinement with Hybrid Propagation for Autonomous Driving","abstract":"Vision-based occupancy prediction, also known as 3D Semantic Scene Completion (SSC), presents a significant challenge in computer vision. Previous methods, confined to onboard processing, struggle with simultaneous geometric and semantic estimation, continuity across varying viewpoints, and single-view occlusion. Our paper introduces OccFiner, a novel offboard framework designed to enhance the accuracy of vision-based occupancy predictions. OccFiner operates in two hybrid phases: 1) a multi-to-multi local propagation network that implicitly aligns and processes multiple local frames for correcting onboard model errors and consistently enhancing occupancy accuracy across all distances. 2) the region-centric global propagation, focuses on refining labels using explicit multi-view geometry and integrating sensor bias, particularly for increasing the accuracy of distant occupied voxels. Extensive experiments demonstrate that OccFiner improves both geometric and semantic accuracy across various types of coarse occupancy, setting a new state-of-the-art performance on the SemanticKITTI dataset. Notably, OccFiner significantly boosts the performance of vision-based SSC models, achieving accuracy levels competitive with established LiDAR-based onboard SSC methods. Furthermore, OccFiner is the first to achieve automatic annotation of SSC in a purely vision-based approach. Quantitative experiments prove that OccFiner successfully facilitates occupancy data loop-closure in autonomous driving. Additionally, we quantitatively and qualitatively validate the superiority of the offboard approach on city-level SSC static maps. The source code will be made publicly available at https://github.com/MasterHow/OccFiner.","authors":["Hao Shi","Song Wang","Jiaming Zhang","Xiaoting Yin","Guangming Wang","Jianke Zhu","Kailun Yang","Kaiwei Wang"],"url":"https://arxiv.org/abs/2403.08504"}
{"created":"2025-05-20","title":"Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era","abstract":"Explainable AI (XAI) refers to techniques that provide human-understandable insights into the workings of AI models. Recently, the focus of XAI is being extended toward explaining Large Language Models (LLMs). This extension calls for a significant transformation in the XAI methodologies for two reasons. First, many existing XAI methods cannot be directly applied to LLMs due to their complexity and advanced capabilities. Second, as LLMs are increasingly deployed in diverse applications, the role of XAI shifts from merely opening the ``black box'' to actively enhancing the productivity and applicability of LLMs in real-world settings. Meanwhile, the conversation and generation abilities of LLMs can reciprocally enhance XAI. Therefore, in this paper, we introduce Usable XAI in the context of LLMs by analyzing (1) how XAI can explain and improve LLM-based AI systems and (2) how XAI techniques can be improved by using LLMs. We introduce 10 strategies, introducing the key techniques for each and discussing their associated challenges. We also provide case studies to demonstrate how to obtain and leverage explanations. The code used in this paper can be found at: https://github.com/JacksonWuxs/UsableXAI_LLM.","authors":["Xuansheng Wu","Haiyan Zhao","Yaochen Zhu","Yucheng Shi","Fan Yang","Lijie Hu","Tianming Liu","Xiaoming Zhai","Wenlin Yao","Jundong Li","Mengnan Du","Ninghao Liu"],"url":"https://arxiv.org/abs/2403.08946"}
{"created":"2025-05-20","title":"Sensing-Enhanced Channel Estimation for Near-Field XL-MIMO Systems","abstract":"Future sixth-generation (6G) systems are expected to leverage extremely large-scale multiple-input multiple-output (XL-MIMO) technology, which significantly expands the range of the near-field region. The spherical wavefront characteristics in the near field introduce additional degrees of freedom (DoFs), namely distance and angle, into the channel model, which leads to unique challenges in channel estimation (CE). In this paper, we propose a new sensing-enhanced uplink CE scheme for near-field XL-MIMO, which notably reduces the required quantity of baseband samples and the dictionary size. In particular, we first propose a sensing method that can be accomplished in a single time slot. It employs power sensors embedded within the antenna elements to measure the received power pattern rather than baseband samples. A time inversion algorithm is then proposed to precisely estimate the locations of users and scatterers, which offers a substantially lower computational complexity. Based on the estimated locations from sensing, a novel dictionary is then proposed by considering the eigen-problem based on the near-field transmission model, which facilitates efficient near-field CE with less baseband sampling and a more lightweight dictionary. Moreover, we derive the general form of the eigenvectors associated with the near-field channel matrix, revealing their noteworthy connection to the discrete prolate spheroidal sequence (DPSS). Simulation results unveil that the proposed time inversion algorithm achieves accurate localization with power measurements only, and remarkably outperforms various widely-adopted algorithms in terms of computational complexity. Furthermore, the proposed eigen-dictionary considerably improves the accuracy in CE with a compact dictionary size and a drastic reduction in baseband samples by up to 66%.","authors":["Shicong Liu","Xianghao Yu","Zhen Gao","Jie Xu","Derrick Wing Kwan Ng","Shuguang Cui"],"url":"https://arxiv.org/abs/2403.11809"}
{"created":"2025-05-20","title":"Causal Graph Dynamics and Kan Extensions","abstract":"On the one side, the formalism of Global Transformations comes with the claim of capturing any transformation of space that is local, synchronous and deterministic. The claim has been proven for different classes of models such as mesh refinements from computer graphics, Lindenmayer systems from morphogenesis modeling and cellular automata from biological, physical and parallel computation modeling. The Global Transformation formalism achieves this by using category theory for its genericity, and more precisely the notion of Kan extension to determine the global behaviors based on the local ones. On the other side, Causal Graph Dynamics describe the transformation of port graphs in a synchronous and deterministic way and has not yet being tackled. In this paper, we show the precise sense in which the claim of Global Transformations holds for them as well. This is done by showing different ways in which they can be expressed as Kan extensions, each of them highlighting different features of Causal Graph Dynamics. Along the way, this work uncovers the interesting class of Monotonic Causal Graph Dynamics and their universality among General Causal Graph Dynamics.","authors":["Luidnel Maignan (LACL)","Antoine Spicher (LACL)"],"url":"https://arxiv.org/abs/2403.13393"}
{"created":"2025-05-20","title":"Bridge the Modality and Capability Gaps in Vision-Language Model Selection","abstract":"Vision Language Models (VLMs) excel in zero-shot image classification by pairing images with textual category names. The expanding variety of Pre-Trained VLMs enhances the likelihood of identifying a suitable VLM for specific tasks. To better reuse the VLM resource and fully leverage its potential on different zero-shot image classification tasks, a promising strategy is selecting appropriate Pre-Trained VLMs from the VLM Zoo, relying solely on the text data of the target dataset without access to the dataset's images. In this paper, we analyze two inherent challenges in assessing the ability of a VLM in this Language-Only VLM selection: the \"Modality Gap\" - the disparity in VLM's embeddings across two different modalities, making text a less reliable substitute for images; and the \"Capability Gap\" - the discrepancy between the VLM's overall ranking and its ranking for target dataset, hindering direct prediction of a model's dataset-specific performance from its general performance. We propose VLM Selection With gAp Bridging (SWAB) to mitigate the negative impact of two gaps. SWAB first adopts optimal transport to capture the relevance between open-source and target datasets with a transportation matrix. It then uses this matrix to transfer useful statistics of VLMs from open-source datasets to the target dataset for bridging two gaps. By bridging two gaps to obtain better substitutes for test images, SWAB can accurately predict the performance ranking of different VLMs on the target task without the need for the dataset's images. Experiments across various VLMs and image classification datasets validate SWAB's effectiveness.","authors":["Chao Yi","Yu-Hang He","De-Chuan Zhan","Han-Jia Ye"],"url":"https://arxiv.org/abs/2403.13797"}
{"created":"2025-05-20","title":"Carbon Footprint Reduction for Sustainable Data Centers in Real-Time","abstract":"As machine learning workloads significantly increase energy consumption, sustainable data centers with low carbon emissions are becoming a top priority for governments and corporations worldwide. This requires a paradigm shift in optimizing power consumption in cooling and IT loads, shifting flexible loads based on the availability of renewable energy in the power grid, and leveraging battery storage from the uninterrupted power supply in data centers, using collaborative agents. The complex association between these optimization strategies and their dependencies on variable external factors like weather and the power grid carbon intensity makes this a hard problem. Currently, a real-time controller to optimize all these goals simultaneously in a dynamic real-world setting is lacking. We propose a Data Center Carbon Footprint Reduction (DC-CFR) multi-agent Reinforcement Learning (MARL) framework that optimizes data centers for the multiple objectives of carbon footprint reduction, energy consumption, and energy cost. The results show that the DC-CFR MARL agents effectively resolved the complex interdependencies in optimizing cooling, load shifting, and energy storage in real-time for various locations under real-world dynamic weather and grid carbon intensity conditions. DC-CFR significantly outperformed the industry standard ASHRAE controller with a considerable reduction in carbon emissions (14.5%), energy usage (14.4%), and energy cost (13.7%) when evaluated over one year across multiple geographical regions.","authors":["Soumyendu Sarkar","Avisek Naug","Ricardo Luna","Antonio Guillen","Vineet Gundecha","Sahand Ghorbanpour","Sajad Mousavi","Dejan Markovikj","Ashwin Ramesh Babu"],"url":"https://arxiv.org/abs/2403.14092"}
{"created":"2025-05-20","title":"Controlled Training Data Generation with Diffusion Models","abstract":"We present a method to control a text-to-image generative model to produce training data useful for supervised learning. Unlike previous works that employ an open-loop approach and pre-define prompts to generate new data using either a language model or human expertise, we develop an automated closed-loop system which involves two feedback mechanisms. The first mechanism uses feedback from a given supervised model and finds adversarial prompts that result in image generations that maximize the model loss. While these adversarial prompts result in diverse data informed by the model, they are not informed of the target distribution, which can be inefficient. Therefore, we introduce the second feedback mechanism that guides the generation process towards a certain target distribution. We call the method combining these two mechanisms Guided Adversarial Prompts. We perform our evaluations on different tasks, datasets and architectures, with different types of distribution shifts (spuriously correlated data, unseen domains) and demonstrate the efficiency of the proposed feedback mechanisms compared to open-loop approaches.","authors":["Teresa Yeo","Andrei Atanov","Harold Benoit","Aleksandr Alekseev","Ruchira Ray","Pooya Esmaeil Akhoondi","Amir Zamir"],"url":"https://arxiv.org/abs/2403.15309"}
{"created":"2025-05-20","title":"Data-centric Prediction Explanation via Kernelized Stein Discrepancy","abstract":"Existing example-based prediction explanation methods often bridge test and training data points through the model's parameters or latent representations. While these methods offer clues to the causes of model predictions, they often exhibit innate shortcomings, such as incurring significant computational overhead or producing coarse-grained explanations. This paper presents a Highly-precise and Data-centric Explan}ation (HD-Explain) prediction explanation method that exploits properties of Kernelized Stein Discrepancy (KSD). Specifically, the KSD uniquely defines a parameterized kernel function for a trained model that encodes model-dependent data correlation. By leveraging the kernel function, one can identify training samples that provide the best predictive support to a test point efficiently. We conducted thorough analyses and experiments across multiple classification domains, where we show that HD-Explain outperforms existing methods from various aspects, including 1) preciseness (fine-grained explanation), 2) consistency, and 3) computation efficiency, leading to a surprisingly simple, effective, and robust prediction explanation solution.","authors":["Mahtab Sarvmaili","Hassan Sajjad","Ga Wu"],"url":"https://arxiv.org/abs/2403.15576"}
{"created":"2025-05-20","title":"How Do OSS Developers Reuse Architectural Solutions from Q&A Sites: An Empirical Study","abstract":"Developers reuse programming-related knowledge on Q&amp;A sites that functionally matches the programming problems they encounter in their development. Despite extensive research on Q&amp;A sites, being a high-level and important type of development-related knowledge, architectural solutions and their reuse are rarely explored. To fill this gap, we conducted a mixed-methods study that includes a mining study and a survey study. For the mining study, we mined 984 commits and issues from 893 OSS projects on GitHub that explicitly referenced architectural solutions from SO and SWESE. For the survey study, we identified practitioners involved in the reuse of these architectural solutions and surveyed 227 of them to further understand how practitioners reuse architectural solutions from Q&amp;A sites in their OSS development. Our findings: (1) OSS practitioners use architectural solutions from Q&amp;A sites to solve a large variety of architectural problems, wherein Component design issue, Architectural anti-pattern, and Security issue are dominant; (2) Seven categories of architectural solutions from Q&amp;A sites have been reused to solve those problems, among which Architectural refactoring, Use of frameworks, and Architectural tactic are the three most reused architectural solutions; (3) OSS developers often rely on ad hoc ways (e.g., informal, improvised, or unstructured approaches) to incorporate architectural solutions from SO, drawing on personal experience and intuition rather than standardized or systematic practices; (4) Using architectural solutions from SO comes with a variety of challenges, e.g., OSS practitioners complain that they need to spend significant time to adapt such architectural solutions to address design concerns raised in their OSS development, and it is challenging to use architectural solutions that are not tailored to the design context of their OSS projects.","authors":["Musengamana Jean de Dieu","Peng Liang","Mojtaba Shahin"],"url":"https://arxiv.org/abs/2404.05041"}
{"created":"2025-05-20","title":"PillarTrack:Boosting Pillar Representation for Transformer-based 3D Single Object Tracking on Point Clouds","abstract":"LiDAR-based 3D single object tracking (3D SOT) is a critical issue in robotics and autonomous driving. Existing 3D SOT methods typically adhere to a point-based processing pipeline, wherein the re-sampling operation invariably leads to either redundant or missing information, thereby impacting performance. To address these issues, we propose PillarTrack, a novel pillar-based 3D SOT framework. First, we transform sparse point clouds into dense pillars to preserve the local and global geometrics. Second, we propose a Pyramid-Encoded Pillar Feature Encoder (PE-PFE) design to enhance the robustness of pillar feature for translation/rotation/scale. Third, we present an efficient Transformer-based backbone from the perspective of modality differences. Finally, we construct our PillarTrack based on above designs. Extensive experiments show that our method achieves comparable performance on the KITTI and NuScenes datasets, significantly enhancing the performance of the baseline.","authors":["Weisheng Xu","Sifan Zhou","Jiaqi Xiong","Ziyu Zhao","Zhihang Yuan"],"url":"https://arxiv.org/abs/2404.07495"}
{"created":"2025-05-20","title":"Fair Concurrent Training of Multiple Models in Federated Learning","abstract":"Federated learning (FL) enables collaborative learning across multiple clients. In most FL work, all clients train a single learning task. However, the recent proliferation of FL applications may increasingly require multiple FL tasks to be trained simultaneously, sharing clients' computing and communication resources, which we call Multiple-Model Federated Learning (MMFL). Current MMFL algorithms use naive average-based client-task allocation schemes that can lead to unfair performance when FL tasks have heterogeneous difficulty levels, e.g., tasks with larger models may need more rounds and data to train. Just as naively allocating resources to generic computing jobs with heterogeneous resource needs can lead to unfair outcomes, naive allocation of clients to FL tasks can lead to unfairness, with some tasks having excessively long training times, or lower converged accuracies. Furthermore, in the FL setting, since clients are typically not paid for their training effort, we face a further challenge that some clients may not even be willing to train some tasks, e.g., due to high computational costs, which may exacerbate unfairness in training outcomes across tasks. We address both challenges by firstly designing FedFairMMFL, a difficulty-aware algorithm that dynamically allocates clients to tasks in each training round. We provide guarantees on airness and FedFairMMFL's convergence rate. We then propose a novel auction design that incentivizes clients to train multiple tasks, so as to fairly distribute clients' training efforts across the tasks. We show how our fairness-based learning and incentive mechanisms impact training convergence and finally evaluate our algorithm with multiple sets of learning tasks on real world datasets.","authors":["Marie Siew","Haoran Zhang","Jong-Ik Park","Yuezhou Liu","Yichen Ruan","Lili Su","Stratis Ioannidis","Edmund Yeh","Carlee Joe-Wong"],"url":"https://arxiv.org/abs/2404.13841"}
{"created":"2025-05-20","title":"Training PINNs with Hard Constraints and Adaptive Weights: An Ablation Study","abstract":"Training Physics-Informed Neural Networks (PINNs) to solve stiff time-dependent partial differential equations (PDEs) remains a significant challenge. The main difficulties lie in precisely enforcing initial conditions and balancing the various loss components. In stiff PDEs, where solutions show rapid transitions or sharp gradients, this balance becomes especially difficult. The wide range of scales in the dynamics can cause certain losses to dominate, leading to unstable or inefficient training. This paper presents a comprehensive ablation study focused on two pivotal training schemes: the enforcement of hard constraints for initial and boundary conditions, and the implementation of adaptive weights. We specifically examine their impact on the performance of PINNs when applied to stiff time-dependent PDEs from materials science and mathematical biology applications. We conduct extensive numerical experiments across a diverse range of time-dependent PDEs from Allen-Cahn, Cahn-Hillard, to Gray-Scott systems. We further discuss the implications of our findings for improving the robustness and efficiency of PINN training, particularly in settings where accurate representation of initial conditions and balanced loss contributions are paramount.","authors":["Baoli Hao","Ulisses Braga-Neto","Chun Liu","Lifan Wang","Ming Zhong"],"url":"https://arxiv.org/abs/2404.16189"}
{"created":"2025-05-20","title":"From Languages to Geographies: Towards Evaluating Cultural Bias in Hate Speech Datasets","abstract":"Perceptions of hate can vary greatly across cultural contexts. Hate speech (HS) datasets, however, have traditionally been developed by language. This hides potential cultural biases, as one language may be spoken in different countries home to different cultures. In this work, we evaluate cultural bias in HS datasets by leveraging two interrelated cultural proxies: language and geography. We conduct a systematic survey of HS datasets in eight languages and confirm past findings on their English-language bias, but also show that this bias has been steadily decreasing in the past few years. For three geographically-widespread languages -- English, Arabic and Spanish -- we then leverage geographical metadata from tweets to approximate geo-cultural contexts by pairing language and country information. We find that HS datasets for these languages exhibit a strong geo-cultural bias, largely overrepresenting a handful of countries (e.g., US and UK for English) relative to their prominence in both the broader social media population and the general population speaking these languages. Based on these findings, we formulate recommendations for the creation of future HS datasets.","authors":["Manuel Tonneau","Diyi Liu","Samuel Fraiberger","Ralph Schroeder","Scott A. Hale","Paul R\\\"ottger"],"url":"https://arxiv.org/abs/2404.17874"}
{"created":"2025-05-20","title":"Instance-Conditioned Adaptation for Large-scale Generalization of Neural Routing Solver","abstract":"The neural combinatorial optimization (NCO) method has shown great potential for solving routing problems of intelligent transportation systems without requiring expert knowledge. However, existing constructive NCO methods still struggle to solve large-scale instances, which significantly limits their application prospects. To address these crucial shortcomings, this work proposes a novel Instance-Conditioned Adaptation Model (ICAM) for better large-scale generalization of neural routing solvers. In particular, we design a simple yet efficient instance-conditioned adaptation function to significantly improve the generalization performance of existing NCO models with a small time and memory overhead. In addition, with a systematic investigation on the performance of information incorporation between different attention mechanisms, we further propose a powerful yet low-complexity instance-conditioned adaptation module to generate better solutions for instances across different scales. Extensive experimental results on both synthetic and benchmark instances show that our proposed method is capable of obtaining promising results with a very fast inference time in solving large-scale Traveling Salesman Problems (TSPs), Capacitated Vehicle Routing Problems (CVRPs), and Asymmetric Traveling Salesman Problems (ATSPs). Our code is available at https://github.com/CIAM-Group/ICAM.","authors":["Changliang Zhou","Xi Lin","Zhenkun Wang","Xialiang Tong","Mingxuan Yuan","Qingfu Zhang"],"url":"https://arxiv.org/abs/2405.01906"}
{"created":"2025-05-20","title":"CodeGRAG: Bridging the Gap between Natural Language and Programming Language via Graphical Retrieval Augmented Generation","abstract":"Utilizing large language models to generate codes has shown promising meaning in software development revolution. Despite the intelligence shown by the large language models, their specificity in code generation can still be improved due to the syntactic gap and mismatched vocabulary existing between natural language and programming languages. In this paper, we propose CodeGRAG, a Graphical Retrieval Augmented Code Generation framework that bridges the gap between NL and PL to enhance the performance of LLMs. CodeGRAG builds the graphical view of code blocks based on the control flow and data flow of them to better interpret the programming domain knowledge, which can facilitate natural language based LLMs for better understanding of code syntax and serve as a bridge among different programming languages. To take the extracted structural knowledge into the foundation models, we propose 1) a hard meta-graph prompt template to transform the challenging syntax graph into informative graphical view for tuning-free models and 2) a soft prompting technique that injects the domain knowledge of programming languages into model parameters via finetuning the models with the soft signals encoded by GNN expert model. Specifically, two constraints are designed to improve the alignment and structure expressiveness, contributing to the informativeness of the single-token-sized external  for enhanced code generation. CodeGRAG significantly improves the code generation ability of LLMs and can even offer performance gain for cross-lingual code generation. Implementation is available at https://anonymous.4open.science/r/Code-5970/ .","authors":["Kounianhua Du","Jizheng Chen","Renting Rui","Huacan Chai","Lingyue Fu","Wei Xia","Yasheng Wang","Ruiming Tang","Yong Yu","Weinan Zhang"],"url":"https://arxiv.org/abs/2405.02355"}
{"created":"2025-05-20","title":"Probing Human Visual Robustness with Neurally-Guided Deep Neural Networks","abstract":"Humans effortlessly navigate the dynamic visual world, yet deep neural networks (DNNs), despite excelling at many visual tasks, are surprisingly vulnerable to minor image perturbations. Past theories suggest that human visual robustness arises from a representational space that evolves along the ventral visual stream (VVS) of the brain to increasingly tolerate object transformations. To test whether robustness is supported by such progression as opposed to being confined exclusively to specialized higher-order regions, we trained DNNs to align their representations with human neural responses from consecutive VVS regions while performing visual tasks. We demonstrate a hierarchical improvement in DNN robustness: alignment to higher-order VVS regions leads to greater improvement. To investigate the mechanism behind such robustness gains, we test a prominent hypothesis that attributes human robustness to the unique geometry of neural category manifolds in the VVS. We first reveal that more desirable manifold properties, specifically, smaller extent and better linear separability, indeed emerge across the human VVS. These properties can be inherited by neurally aligned DNNs and predict their subsequent robustness gains. Furthermore, we show that supervision from neural manifolds alone, via manifold guidance, is sufficient to qualitatively reproduce the hierarchical robustness improvements. Together, these results highlight the critical role of the evolving representational space across VVS in achieving robust visual inference, in part through the formation of more linearly separable category manifolds, which may in turn be leveraged to develop more robust AI systems.","authors":["Zhenan Shao","Linjian Ma","Yiqing Zhou","Yibo Jacky Zhang","Sanmi Koyejo","Bo Li","Diane M. Beck"],"url":"https://arxiv.org/abs/2405.02564"}
{"created":"2025-05-20","title":"LLMPot: Dynamically Configured LLM-based Honeypot for Industrial Protocol and Physical Process Emulation","abstract":"Industrial Control Systems (ICS) are extensively used in critical infrastructures ensuring efficient, reliable, and continuous operations. However, their increasing connectivity and addition of advanced features make them vulnerable to cyber threats, potentially leading to severe disruptions in essential services. In this context, honeypots play a vital role by acting as decoy targets within ICS networks, or on the Internet, helping to detect, log, analyze, and develop mitigations for ICS-specific cyber threats. Deploying ICS honeypots, however, is challenging due to the necessity of accurately replicating industrial protocols and device characteristics, a crucial requirement for effectively mimicking the unique operational behavior of different industrial systems. Moreover, this challenge is compounded by the significant manual effort required in also mimicking the control logic the PLC would execute, in order to capture attacker traffic aiming to disrupt critical infrastructure operations. In this paper, we propose LLMPot, a novel approach for designing honeypots in ICS networks harnessing the potency of Large Language Models (LLMs). LLMPot aims to automate and optimize the creation of realistic honeypots with vendor-agnostic configurations, and for any control logic, aiming to eliminate the manual effort and specialized knowledge traditionally required in this domain. We conducted extensive experiments focusing on a wide array of parameters, demonstrating that our LLM-based approach can effectively create honeypot devices implementing different industrial protocols and diverse control logic.","authors":["Christoforos Vasilatos","Dunia J. Mahboobeh","Hithem Lamri","Manaar Alam","Michail Maniatakos"],"url":"https://arxiv.org/abs/2405.05999"}
{"created":"2025-05-20","title":"Design Opportunities for Explainable AI Paraphrasing Tools: A User Study with Non-native English Speakers","abstract":"We investigate how non-native English speakers (NNESs) interact with diverse information aids to assess and select AI-generated paraphrases. We develop ParaScope, an AI paraphrasing assistant that integrates diverse information aids, such as back-translation, explanations, and usage examples, and logs user interaction data. Our in-lab study with 22 NNESs reveals that user preferences for information aids vary by language proficiency, with workflows progressing from global to more detailed information. While back-translation was the most frequently used aid, it was not a decisive factor in suggestion acceptance; users combined multiple information aids to make informed decisions. Our findings demonstrate the potential of explainable AI paraphrasing tools to enhance NNESs' confidence, autonomy, and writing efficiency, while also emphasizing the importance of thoughtful design to prevent information overload. Based on these findings, we offer design implications for explainable AI paraphrasing tools that support NNESs in making informed decisions when using AI writing systems.","authors":["Yewon Kim","Thanh-Long V. Le","Donghwi Kim","Mina Lee","Sung-Ju Lee"],"url":"https://arxiv.org/abs/2405.07475"}
{"created":"2025-05-20","title":"Large Language Models for Automated Web-Form-Test Generation: An Empirical Study","abstract":"Testing web forms is an essential activity for ensuring the quality of web applications. It typically involves evaluating the interactions between users and forms. Automated test-case generation remains a challenge for web-form testing: Due to the complex, multi-level structure of web pages, it can be difficult to automatically capture their inherent contextual information for inclusion in the tests. Large Language Models (LLMs) have shown great potential for contextual text generation. This motivated us to explore how they could generate automated tests for web forms, making use of the contextual information within form elements. To the best of our knowledge, no comparative study examining different LLMs has yet been reported for web-form-test generation. To address this gap in the literature, we conducted a comprehensive empirical study investigating the effectiveness of 11 LLMs on 146 web forms from 30 open-source Java web applications. In addition, we propose three HTML-structure-pruning methods to extract key contextual information. The experimental results show that different LLMs can achieve different testing effectiveness. Compared with GPT-4, the other LLMs had difficulty generating appropriate tests for the web forms: Their successfully-submitted rates (SSRs) decreased by 9.10% to 74.15%. Our findings also show that, for all LLMs, when the designed prompts include complete and clear contextual information about the web forms, more effective web-form tests were generated. Specifically, when using Parser-Processed HTML for Task Prompt (PH-P), the SSR averaged 70.63%, higher than the 60.21% for Raw HTML for Task Prompt (RH-P) and 50.27% for LLM-Processed HTML for Task Prompt (LH-P). Finally, this paper also highlights strategies for selecting LLMs based on performance metrics, and for optimizing the prompt design to improve the quality of the web-form tests.","authors":["Tao Li","Chenhui Cui","Rubing Huang","Dave Towey","Lei Ma"],"url":"https://arxiv.org/abs/2405.09965"}
{"created":"2025-05-20","title":"Deep Learning Methods for Adjusting Global MFD Speed Estimations to Local Link Configurations","abstract":"In large-scale traffic optimization, models based on Macroscopic Fundamental Diagram (MFD) are recognized for their efficiency in broad network analyses. However, they fail to reflect variations in the individual traffic status of each road link, leading to a gap in detailed traffic optimization and analysis. To address the limitation, this study introduces a Local Correction Factor (LCF) that represents local speed deviations between the actual link speed and the MFD average speed based on the link configuration. The LCF is calculated using a deep learning function that takes as inputs the average speed from the MFD and the road network configuration. Our framework integrates Graph Attention Networks (GATs) with Gated Recurrent Units (GRUs) to capture both the spatial configurations and temporal correlations within the network. Coupled with a strategic network partitioning method, our model enhances the precision of link-level traffic speed estimations while preserving the computational advantages of aggregate models. In our experiments, we evaluate the proposed LCF across various urban traffic scenarios, including different levels of origin-destination trip demand and distribution, as well as diverse road configurations. The results demonstrate the robust adaptability and effectiveness of the proposed model. Furthermore, we validate the practicality of our model by calculating the travel time of each randomly generated path, achieving an average error reduction of approximately 84% relative to MFD-based results.","authors":["Zhixiong Jin","Dimitrios Tsitsokas","Nikolas Geroliminis","Ludovic Leclercq"],"url":"https://arxiv.org/abs/2405.14257"}
{"created":"2025-05-20","title":"Sparse Matrix in Large Language Model Fine-tuning","abstract":"LoRA and its variants have become popular parameter-efficient fine-tuning (PEFT) methods due to their ability to avoid excessive computational costs. However, an accuracy gap often exists between PEFT methods and full fine-tuning (FT), and this gap has yet to be systematically studied. In this work, we introduce a method for selecting sparse sub-matrices that aim to minimize the performance gap between PEFT vs. full fine-tuning (FT) while also reducing both fine-tuning computational cost and memory cost. Our Sparse Matrix Tuning (SMT) method begins by identifying the most significant sub-matrices in the gradient update, updating only these blocks during the fine-tuning process. In our experiments, we demonstrate that SMT consistently surpasses other PEFT baseline (e.g. LoRA and DoRA) in fine-tuning popular large language models such as LLaMA across a broad spectrum of tasks, while reducing the GPU memory footprint by 67% compared to FT. We also examine how the performance of LoRA and DoRA tends to plateau and decline as the number of trainable parameters increases, in contrast, our SMT method does not suffer from such issue.","authors":["Haoze He","Juncheng Billy Li","Xuan Jiang","Heather Miller"],"url":"https://arxiv.org/abs/2405.15525"}
{"created":"2025-05-20","title":"Low-Light Video Enhancement via Spatial-Temporal Consistent Decomposition","abstract":"Low-Light Video Enhancement (LLVE) seeks to restore dynamic or static scenes plagued by severe invisibility and noise. In this paper, we present an innovative video decomposition strategy that incorporates view-independent and view-dependent components to enhance the performance of LLVE. We leverage dynamic cross-frame correspondences for the view-independent term (which primarily captures intrinsic appearance) and impose a scene-level continuity constraint on the view-dependent term (which mainly describes the shading condition) to achieve consistent and satisfactory decomposition results. To further ensure consistent decomposition, we introduce a dual-structure enhancement network featuring a cross-frame interaction mechanism. By supervising different frames simultaneously, this network encourages them to exhibit matching decomposition features. This mechanism can seamlessly integrate with encoder-decoder single-frame networks, incurring minimal additional parameter costs. Extensive experiments are conducted on widely recognized LLVE benchmarks, covering diverse scenarios. Our framework consistently outperforms existing methods, establishing a new SOTA performance.","authors":["Xiaogang Xu","Kun Zhou","Tao Hu","Jiafei Wu","Ruixing Wang","Hao Peng","Bei Yu"],"url":"https://arxiv.org/abs/2405.15660"}
{"created":"2025-05-20","title":"Learning accurate and interpretable tree-based models","abstract":"Decision trees and their ensembles are popular in machine learning as easy-to-understand models. Several techniques have been proposed in the literature for learning tree-based classifiers, with different techniques working well for data from different domains. In this work, we develop approaches to design tree-based learning algorithms given repeated access to data from the same domain. We study multiple formulations covering different aspects and popular techniques for learning decision tree based approaches. We propose novel parameterized classes of node splitting criteria in top-down algorithms, which interpolate between popularly used entropy and Gini impurity based criteria, and provide theoretical bounds on the number of samples needed to learn the splitting function appropriate for the data at hand. We also study the sample complexity of tuning prior parameters in Bayesian decision tree learning, and extend our results to decision tree regression. We further consider the problem of tuning hyperparameters in pruning the decision tree for classical pruning algorithms including min-cost complexity pruning. In addition, our techniques can be used to optimize the explainability versus accuracy trade-off when using decision trees. We extend our results to tuning popular tree-based ensembles, including random forests and gradient-boosted trees. We demonstrate the significance of our approach on real world datasets by learning data-specific decision trees which are simultaneously more accurate and interpretable.","authors":["Maria-Florina Balcan","Dravyansh Sharma"],"url":"https://arxiv.org/abs/2405.15911"}
{"created":"2025-05-20","title":"Understanding the Effect of using Semantically Meaningful Tokens for Visual Representation Learning","abstract":"Vision transformers have established a precedent of patchifying images into uniformly-sized chunks before processing. We hypothesize that this design choice may limit models in learning comprehensive and compositional representations from visual data. This paper explores the notion of providing semantically-meaningful visual tokens to transformer encoders within a vision-language pre-training framework. Leveraging off-the-shelf segmentation and scene-graph models, we extract representations of instance segmentation masks (referred to as tangible tokens) and relationships and actions (referred to as intangible tokens). Subsequently, we pre-train a vision-side transformer by incorporating these newly extracted tokens and aligning the resultant embeddings with caption embeddings from a text-side encoder. To capture the structural and semantic relationships among visual tokens, we introduce additive attention weights, which are used to compute self-attention scores. Our experiments on COCO demonstrate notable improvements over ViTs in learned representation quality across text-to-image (+47%) and image-to-text retrieval (+44%) tasks. Furthermore, we showcase the advantages on compositionality benchmarks such as ARO (+18%) and Winoground (+10%).","authors":["Neha Kalibhat","Priyatham Kattakinda","Sumit Nawathe","Arman Zarei","Nikita Seleznev","Samuel Sharpe","Senthil Kumar","Soheil Feizi"],"url":"https://arxiv.org/abs/2405.16401"}
{"created":"2025-05-20","title":"Adversarial Attacks on Both Face Recognition and Face Anti-spoofing Models","abstract":"Adversarial attacks on Face Recognition (FR) systems have demonstrated significant effectiveness against standalone FR models. However, their practicality diminishes in complete FR systems that incorporate Face Anti-Spoofing (FAS) models, as these models can detect and mitigate a substantial number of adversarial examples. To address this critical yet under-explored challenge, we introduce a novel attack setting that targets both FR and FAS models simultaneously, thereby enhancing the practicability of adversarial attacks on integrated FR systems. Specifically, we propose a new attack method, termed Reference-free Multi-level Alignment (RMA), designed to improve the capacity of black-box attacks on both FR and FAS models. The RMA framework is built upon three key components. Firstly, we propose an Adaptive Gradient Maintenance module to address the imbalances in gradient contributions between FR and FAS models. Secondly, we develop a Reference-free Intermediate Biasing module to improve the transferability of adversarial examples against FAS models. In addition, we introduce a Multi-level Feature Alignment module to reduce feature discrepancies at various levels of representation. Extensive experiments showcase the superiority of our proposed attack method to state-of-the-art adversarial attacks.","authors":["Fengfan Zhou","Qianyu Zhou","Hefei Ling","Xuequan Lu"],"url":"https://arxiv.org/abs/2405.16940"}
{"created":"2025-05-20","title":"Deriving Causal Order from Single-Variable Interventions: Guarantees & Algorithm","abstract":"Targeted and uniform interventions to a system are crucial for unveiling causal relationships. While several methods have been developed to leverage interventional data for causal structure learning, their practical application in real-world scenarios often remains challenging. Recent benchmark studies have highlighted these difficulties, even when large numbers of single-variable intervention samples are available. In this work, we demonstrate, both theoretically and empirically, that such datasets contain a wealth of causal information that can be effectively extracted under realistic assumptions about the data distribution. More specifically, we introduce a novel variant of interventional faithfulness, which relies on comparisons between the marginal distributions of each variable across observational and interventional settings, and we introduce a score on causal orders. Under this assumption, we are able to prove strong theoretical guarantees on the optimum of our score that also hold for large-scale settings. To empirically verify our theory, we introduce Intersort, an algorithm designed to infer the causal order from datasets containing large numbers of single-variable interventions by approximately optimizing our score. Intersort outperforms baselines (GIES, DCDI, PC and EASE) on almost all simulated data settings replicating common benchmarks in the field. Our proposed novel approach to modeling interventional datasets thus offers a promising avenue for advancing causal inference, highlighting significant potential for further enhancements under realistic assumptions.","authors":["Mathieu Chevalley","Patrick Schwab","Arash Mehrjou"],"url":"https://arxiv.org/abs/2405.18314"}
{"created":"2025-05-20","title":"Fairness in AI-Driven Recruitment: Challenges, Metrics, Methods, and Future Directions","abstract":"The recruitment process significantly impacts an organization's performance, productivity, and culture. Traditionally, human resource experts and industrial-organizational psychologists have developed systematic hiring methods, including job advertising, candidate skill assessments, and structured interviews to ensure candidate-organization fit. Recently, recruitment practices have shifted dramatically toward artificial intelligence (AI)-based methods, driven by the need to efficiently manage large applicant pools. However, reliance on AI raises concerns about the amplification and propagation of human biases embedded within hiring algorithms, as empirically demonstrated by biases in candidate ranking systems and automated interview assessments. Consequently, algorithmic fairness has emerged as a critical consideration in AI-driven recruitment, aimed at rigorously addressing and mitigating these biases. This paper systematically reviews biases identified in AI-driven recruitment systems, categorizes fairness metrics and bias mitigation techniques, and highlights auditing approaches used in practice. We emphasize critical gaps and current limitations, proposing future directions to guide researchers and practitioners toward more equitable AI recruitment practices, promoting fair candidate treatment and enhancing organizational outcomes.","authors":["Dena F. Mujtaba","Nihar R. Mahapatra"],"url":"https://arxiv.org/abs/2405.19699"}
{"created":"2025-05-20","title":"Efficient Indirect LLM Jailbreak via Multimodal-LLM Jailbreak","abstract":"This paper focuses on jailbreaking attacks against large language models (LLMs), eliciting them to generate objectionable content in response to harmful user queries. Unlike previous LLM-jailbreak methods that directly orient to LLMs, our approach begins by constructing a multimodal large language model (MLLM) built upon the target LLM. Subsequently, we perform an efficient MLLM jailbreak and obtain a jailbreaking embedding. Finally, we convert the embedding into a textual jailbreaking suffix to carry out the jailbreak of target LLM. Compared to the direct LLM-jailbreak methods, our indirect jailbreaking approach is more efficient, as MLLMs are more vulnerable to jailbreak than pure LLM. Additionally, to improve the attack success rate of jailbreak, we propose an image-text semantic matching scheme to identify a suitable initial input. Extensive experiments demonstrate that our approach surpasses current state-of-the-art jailbreak methods in terms of both efficiency and effectiveness. Moreover, our approach exhibits superior cross-class generalization abilities.","authors":["Zhenxing Niu","Yuyao Sun","Haoxuan Ji","Zheng Lin","Haichang Gao","Xinbo Gao","Gang Hua","Rong Jin"],"url":"https://arxiv.org/abs/2405.20015"}
{"created":"2025-05-20","title":"OR-Bench: An Over-Refusal Benchmark for Large Language Models","abstract":"Large Language Models (LLMs) require careful safety alignment to prevent malicious outputs. While significant research focuses on mitigating harmful content generation, the enhanced safety often come with the side effect of over-refusal, where LLMs may reject innocuous prompts and become less helpful. Although the issue of over-refusal has been empirically observed, a systematic measurement is challenging due to the difficulty of crafting prompts that can elicit the over-refusal behaviors of LLMs. This study proposes a novel method for automatically generating large-scale over-refusal datasets. Leveraging this technique, we introduce OR-Bench, the first large-scale over-refusal benchmark. OR-Bench comprises 80,000 over-refusal prompts across 10 common rejection categories, a subset of around 1,000 hard prompts that are challenging even for state-of-the-art LLMs, and an additional 600 toxic prompts to prevent indiscriminate responses. We then conduct a comprehensive study to measure the over-refusal of 32 popular LLMs across 8 model families. Our datasets are publicly available at https://huggingface.co/bench-llms and our codebase is open-sourced at https://github.com/justincui03/or-bench. We hope this benchmark can help the community develop better safety aligned models.","authors":["Justin Cui","Wei-Lin Chiang","Ion Stoica","Cho-Jui Hsieh"],"url":"https://arxiv.org/abs/2405.20947"}
{"created":"2025-05-20","title":"MoDGS: Dynamic Gaussian Splatting from Casually-captured Monocular Videos with Depth Priors","abstract":"In this paper, we propose MoDGS, a new pipeline to render novel views of dy namic scenes from a casually captured monocular video. Previous monocular dynamic NeRF or Gaussian Splatting methods strongly rely on the rapid move ment of input cameras to construct multiview consistency but struggle to recon struct dynamic scenes on casually captured input videos whose cameras are either static or move slowly. To address this challenging task, MoDGS adopts recent single-view depth estimation methods to guide the learning of the dynamic scene. Then, a novel 3D-aware initialization method is proposed to learn a reasonable deformation field and a new robust depth loss is proposed to guide the learning of dynamic scene geometry. Comprehensive experiments demonstrate that MoDGS is able to render high-quality novel view images of dynamic scenes from just a casually captured monocular video, which outperforms state-of-the-art meth ods by a significant margin. The code will be publicly available.","authors":["Qingming Liu","Yuan Liu","Jiepeng Wang","Xianqiang Lyv","Peng Wang","Wenping Wang","Junhui Hou"],"url":"https://arxiv.org/abs/2406.00434"}
{"created":"2025-05-20","title":"Matrix-Valued Measures and Wishart Statistics for Target Tracking Applications","abstract":"Ensuring sufficiently accurate models is crucial in target tracking systems. If the assumed models deviate too much from the truth, the tracking performance might be severely degraded. While the models are usually defined using multivariate conditions, the measures used to validate them are most often scalar-valued. In this paper, we propose matrix-valued measures for both offline and online assessment of target tracking systems. Recent results from Wishart statistics, and approximations thereof, are adapted and it is shown how these can be incorporated to infer statistical properties for the eigenvalues of the proposed measures. In addition, we relate these results to the statistics of the baseline measures. Finally, the applicability of the proposed measures are demonstrated using two important problems in target tracking: (i) distributed track fusion design; and (ii) filter model mismatch detection.","authors":["Robin Forsling","Simon J. Julier","Gustaf Hendeby"],"url":"https://arxiv.org/abs/2406.00861"}
{"created":"2025-05-20","title":"Anomaly Anything: Promptable Unseen Visual Anomaly Generation","abstract":"Visual anomaly detection (AD) presents significant challenges due to the scarcity of anomalous data samples. While numerous works have been proposed to synthesize anomalous samples, these synthetic anomalies often lack authenticity or require extensive training data, limiting their applicability in real-world scenarios. In this work, we propose Anomaly Anything (AnomalyAny), a novel framework that leverages Stable Diffusion (SD)'s image generation capabilities to generate diverse and realistic unseen anomalies. By conditioning on a single normal sample during test time, AnomalyAny is able to generate unseen anomalies for arbitrary object types with text descriptions. Within AnomalyAny, we propose attention-guided anomaly optimization to direct SD attention on generating hard anomaly concepts. Additionally, we introduce prompt-guided anomaly refinement, incorporating detailed descriptions to further improve the generation quality. Extensive experiments on MVTec AD and VisA datasets demonstrate AnomalyAny's ability in generating high-quality unseen anomalies and its effectiveness in enhancing downstream AD performance.","authors":["Han Sun","Yunkang Cao","Hao Dong","Olga Fink"],"url":"https://arxiv.org/abs/2406.01078"}
{"created":"2025-05-20","title":"PETRA: Parallel End-to-end Training with Reversible Architectures","abstract":"Reversible architectures have been shown to be capable of performing on par with their non-reversible architectures, being applied in deep learning for memory savings and generative modeling. In this work, we show how reversible architectures can solve challenges in parallelizing deep model training. We introduce PETRA, a novel alternative to backpropagation for parallelizing gradient computations. PETRA facilitates effective model parallelism by enabling stages (i.e., a set of layers) to compute independently on different devices, while only needing to communicate activations and gradients between each other. By decoupling the forward and backward passes and keeping a single updated version of the parameters, the need for weight stashing is also removed. We develop a custom autograd-like training framework for PETRA, and we demonstrate its effectiveness on CIFAR-10, ImageNet32, and ImageNet, achieving competitive accuracies comparable to backpropagation using ResNet-18, ResNet-34, and ResNet-50 models.","authors":["St\\'ephane Rivaud (MLIA","TAU)","Louis Fournier (MLIA)","Thomas Pumir (MILA)","Eugene Belilovsky (MILA)","Michael Eickenberg","Edouard Oyallon"],"url":"https://arxiv.org/abs/2406.02052"}
{"created":"2025-05-20","title":"Iterative Deployment Exposure for Unsupervised Out-of-Distribution Detection","abstract":"Deep learning models are vulnerable to performance degradation when encountering out-of-distribution (OOD) images, potentially leading to misdiagnoses and compromised patient care. These shortcomings have led to great interest in the field of OOD detection. Existing unsupervised OOD (U-OOD) detection methods typically assume that OOD samples originate from an unconcentrated distribution complementary to the training distribution, neglecting the reality that deployed models passively accumulate task-specific OOD samples over time. To better reflect this real-world scenario, we introduce Iterative Deployment Exposure (IDE), a novel and more realistic setting for U-OOD detection. We propose CSO, a method for IDE that starts from a U-OOD detector that is agnostic to the OOD distribution and slowly refines it during deployment using observed unlabeled data. CSO uses a new U-OOD scoring function that combines the Mahalanobis distance with a nearest-neighbor approach, along with a novel confidence-scaled few-shot OOD detector to effectively learn from limited OOD examples. We validate our approach on a dedicated benchmark, showing that our method greatly improves upon strong baselines on three medical imaging modalities.","authors":["Lars Doorenbos","Raphael Sznitman","Pablo M\\'arquez-Neila"],"url":"https://arxiv.org/abs/2406.02327"}
{"created":"2025-05-20","title":"ACCO: Accumulate While You Communicate for Communication-Overlapped Sharded LLM Training","abstract":"Training LLMs relies on distributed implementations using multiple GPUs to compute gradients in parallel with sharded optimizers. However, synchronizing gradients in data parallel setups introduces communication overhead that grows with the number of workers, limiting parallelization efficiency. Local optimization algorithms reduce communications but incur high memory costs as they prevent optimizer state sharding, hindering scalability. To address this, we propose \\textbf{AC}cumulate while \\textbf{CO}mmunicate (\\acco), a memory-efficient optimization algorithm for distributed LLM training. By synchronizing delayed gradients while computing new ones, \\acco~reduces GPU idle time and supports heterogeneous hardware. To mitigate the convergence issues caused by delayed updates, we introduce a novel technique ensuring training dynamics align with standard distributed optimization. Compared to ZeRO-1, our approach is significantly faster and scales effectively across heterogeneous hardware.","authors":["Adel Nabli (MLIA","Mila)","Louis Fournier (MLIA)","Pierre Erbacher (MLIA)","Louis Serrano (MLIA)","Eugene Belilovsky (Mila)","Edouard Oyallon (MLIA)"],"url":"https://arxiv.org/abs/2406.02613"}
{"created":"2025-05-20","title":"A Priori Estimation of the Approximation, Optimization and Generalization Errors of Random Neural Networks for Solving Partial Differential Equations","abstract":"In recent years, neural networks have achieved remarkable progress in various fields and have also drawn much attention in applying them on scientific problems. A line of methods involving neural networks for solving partial differential equations (PDEs), such as Physics-Informed Neural Networks (PINNs) and the Deep Ritz Method (DRM), has emerged. Although these methods outperform classical numerical methods in certain cases, the optimization problems involving neural networks are typically non-convex and non-smooth, which can result in unsatisfactory solutions for PDEs. In contrast to deterministic neural networks, the hidden weights of random neural networks are sampled from some prior distribution and only the output weights participate in training. This makes training much simpler, but it remains unclear how to select the prior distribution. In this paper, we focus on Barron type functions and approximate them under Sobolev norms by random neural networks with clear prior distribution. In addition to the approximation error, we also derive bounds for the optimization and generalization errors of random neural networks for solving PDEs when the solutions are Barron type functions.","authors":["Xianliang Xu","Ye Li","Zhongyi Huang"],"url":"https://arxiv.org/abs/2406.03080"}
{"created":"2025-05-20","title":"An interpretable speech foundation model for depression detection by revealing prediction-relevant acoustic features from long speech","abstract":"Speech-based depression detection tools could aid early screening. Here, we propose an interpretable speech foundation model approach to enhance the clinical applicability of such tools. We introduce a speech-level Audio Spectrogram Transformer (AST) to detect depression using long-duration speech instead of short segments, along with a novel interpretation method that reveals prediction-relevant acoustic features for clinician interpretation. Our experiments show the proposed model outperforms a segment-level AST, highlighting the impact of segment-level labelling noise and the advantage of leveraging longer speech duration for more reliable depression detection. Through interpretation, we observe our model identifies reduced loudness and F0 as relevant depression signals, aligning with documented clinical findings. This interpretability supports a responsible AI approach for speech-based depression detection, rendering such tools more clinically applicable.","authors":["Qingkun Deng","Saturnino Luz","Sofia de la Fuente Garcia"],"url":"https://arxiv.org/abs/2406.03138"}
{"created":"2025-05-20","title":"Robust Deep Reinforcement Learning against Adversarial Behavior Manipulation","abstract":"This study investigates behavior-targeted attacks on reinforcement learning and their countermeasures. Behavior-targeted attacks aim to manipulate the victim's behavior as desired by the adversary through adversarial interventions in state observations. Existing behavior-targeted attacks have some limitations, such as requiring white-box access to the victim's policy. To address this, we propose a novel attack method using imitation learning from adversarial demonstrations, which works under limited access to the victim's policy and is environment-agnostic. In addition, our theoretical analysis proves that the policy's sensitivity to state changes impacts defense performance, particularly in the early stages of the trajectory. Based on this insight, we propose time-discounted regularization, which enhances robustness against attacks while maintaining task performance. To the best of our knowledge, this is the first defense strategy specifically designed for behavior-targeted attacks.","authors":["Shojiro Yamabe","Kazuto Fukuchi","Jun Sakuma"],"url":"https://arxiv.org/abs/2406.03862"}
{"created":"2025-05-20","title":"An approach to discrete operator learning based on sparse high-dimensional approximation","abstract":"We present a dimension-incremental method for function approximation in bounded orthonormal product bases to learn the solutions of various differential equations. Therefore, we decompose the source function of the differential equation into parameters like Fourier or Spline coefficients and treat the solution of the differential equation as a high-dimensional function w.r.t. the spatial variables, these parameters and also further possible parameters from the differential equation itself. Finally, we learn this function in the sense of sparse approximation in a suitable function space by detecting coefficients of the basis expansion with the largest absolute values. Investigating the corresponding indices of the basis coefficients yields further insights on the structure of the solution as well as its dependency on the parameters and their interactions and allows for a reasonable generalization to even higher dimensions and therefore better resolutions of the decomposed source function.","authors":["Daniel Potts","Fabian Taubert"],"url":"https://arxiv.org/abs/2406.03973"}
{"created":"2025-05-20","title":"CDMamba: Incorporating Local Clues into Mamba for Remote Sensing Image Binary Change Detection","abstract":"Recently, the Mamba architecture based on state space models has demonstrated remarkable performance in a series of natural language processing tasks and has been rapidly applied to remote sensing change detection (CD) tasks. However, most methods enhance the global receptive field by directly modifying the scanning mode of Mamba, neglecting the crucial role that local information plays in dense prediction tasks (e.g., binary CD). In this article, we propose a model called CDMamba, which effectively combines global and local features for handling binary CD tasks. Specifically, the Scaled Residual ConvMamba (SRCM) block is proposed to utilize the ability of Mamba to extract global features and convolution to enhance the local details to alleviate the issue that current Mamba-based methods lack detailed clues and are difficult to achieve fine detection in dense prediction tasks. Furthermore, considering the characteristics of bi-temporal feature interaction required for CD, the Adaptive Global Local Guided Fusion (AGLGF) block is proposed to dynamically facilitate the bi-temporal interaction guided by other temporal global/local features. Our intuition is that more discriminative change features can be acquired with the guidance of other temporal features. Extensive experiments on five datasets demonstrate that our proposed CDMamba is comparable to the current methods (such as the F1/IoU scores are improved by 2.10%/3.00% and 2.44%/2.91% on LEVIR+CD and CLCD, respectively). Our code is open-sourced at https://github.com/zmoka-zht/CDMamba.","authors":["Haotian Zhang","Keyan Chen","Chenyang Liu","Hao Chen","Zhengxia Zou","Zhenwei Shi"],"url":"https://arxiv.org/abs/2406.04207"}
{"created":"2025-05-20","title":"LEMMA-RCA: A Large Multi-modal Multi-domain Dataset for Root Cause Analysis","abstract":"Root cause analysis (RCA) is crucial for enhancing the reliability and performance of complex systems. However, progress in this field has been hindered by the lack of large-scale, open-source datasets tailored for RCA. To bridge this gap, we introduce LEMMA-RCA, a large dataset designed for diverse RCA tasks across multiple domains and modalities. LEMMA-RCA features various real-world fault scenarios from IT and OT operation systems, encompassing microservices, water distribution, and water treatment systems, with hundreds of system entities involved. We evaluate the quality of LEMMA-RCA by testing the performance of eight baseline methods on this dataset under various settings, including offline and online modes as well as single and multiple modalities. Our experimental results demonstrate the high quality of LEMMA-RCA. The dataset is publicly available at https://lemma-rca.github.io/.","authors":["Lecheng Zheng","Zhengzhang Chen","Dongjie Wang","Chengyuan Deng","Reon Matsuoka","Haifeng Chen"],"url":"https://arxiv.org/abs/2406.05375"}
{"created":"2025-05-20","title":"FlightBench: Benchmarking Learning-based Methods for Ego-vision-based Quadrotors Navigation","abstract":"Ego-vision-based navigation in cluttered environments is crucial for mobile systems, particularly agile quadrotors. While learning-based methods have shown promise recently, head-to-head comparisons with cutting-edge optimization-based approaches are scarce, leaving open the question of where and to what extent they truly excel. In this paper, we introduce FlightBench, the first comprehensive benchmark that implements various learning-based methods for ego-vision-based navigation and evaluates them against mainstream optimization-based baselines using a broad set of performance metrics. More importantly, we develop a suite of criteria to assess scenario difficulty and design test cases that span different levels of difficulty based on these criteria. Our results show that while learning-based methods excel in high-speed flight and faster inference, they struggle with challenging scenarios like sharp corners or view occlusion. Analytical experiments validate the correlation between our difficulty criteria and flight performance. Moreover, we verify the trend in flight performance within real-world environments through full-pipeline and hardware-in-the-loop experiments. We hope this benchmark and these criteria will drive future advancements in learning-based navigation for ego-vision quadrotors. Code and documentation are available at https://github.com/thu-uav/FlightBench.","authors":["Shu-Ang Yu","Chao Yu","Feng Gao","Yi Wu","Yu Wang"],"url":"https://arxiv.org/abs/2406.05687"}
{"created":"2025-05-20","title":"Boosting Robustness in Preference-Based Reinforcement Learning with Dynamic Sparsity","abstract":"To integrate into human-centered environments, autonomous agents must learn from and adapt to humans in their native settings. Preference-based reinforcement learning (PbRL) can enable this by learning reward functions from human preferences. However, humans live in a world full of diverse information, most of which is irrelevant to completing any particular task. It then becomes essential that agents learn to focus on the subset of task-relevant state features. To that end, this work proposes R2N (Robust-to-Noise), the first PbRL algorithm that leverages principles of dynamic sparse training to learn robust reward models that can focus on task-relevant features. In experiments with a simulated teacher, we demonstrate that R2N can adapt the sparse connectivity of its neural networks to focus on task-relevant features, enabling R2N to significantly outperform several sparse training and PbRL algorithms across simulated robotic environments.","authors":["Calarina Muslimani","Bram Grooten","Deepak Ranganatha Sastry Mamillapalli","Mykola Pechenizkiy","Decebal Constantin Mocanu","Matthew E. Taylor"],"url":"https://arxiv.org/abs/2406.06495"}
{"created":"2025-05-20","title":"RS-Agent: Automating Remote Sensing Tasks through Intelligent Agent","abstract":"The unprecedented advancements in Multimodal Large Language Models (MLLMs) have demonstrated strong potential in interacting with humans through both language and visual inputs to perform downstream tasks such as visual question answering and scene understanding. However, these models are constrained to basic instruction-following or descriptive tasks, facing challenges in complex real-world remote sensing applications that require specialized tools and knowledge. To address these limitations, we propose RS-Agent, an AI agent designed to interact with human users and autonomously leverage specialized models to address the demands of real-world remote sensing applications. RS-Agent integrates four key components: a Central Controller based on large language models, a dynamic toolkit for tool execution, a Solution Space for task-specific expert guidance, and a Knowledge Space for domain-level reasoning, enabling it to interpret user queries and orchestrate tools for accurate remote sensing task. We introduce two novel mechanisms: Task-Aware Retrieval, which improves tool selection accuracy through expert-guided planning, and DualRAG, a retrieval-augmented generation method that enhances knowledge relevance through weighted, dual-path retrieval. RS-Agent supports flexible integration of new tools and is compatible with both open-source and proprietary LLMs. Extensive experiments across 9 datasets and 18 remote sensing tasks demonstrate that RS-Agent significantly outperforms state-of-the-art MLLMs, achieving over 95% task planning accuracy and delivering superior performance in tasks such as scene classification, object counting, and remote sensing visual question answering. Our work presents RS-Agent as a robust and extensible framework for advancing intelligent automation in remote sensing analysis.","authors":["Wenjia Xu","Zijian Yu","Boyang Mu","Zhiwei Wei","Yuanben Zhang","Guangzuo Li","Mugen Peng"],"url":"https://arxiv.org/abs/2406.07089"}
{"created":"2025-05-20","title":"A Concise Mathematical Description of Active Inference in Discrete Time","abstract":"In this paper we present a concise mathematical description of active inference in discrete time. The main part of the paper serves as a basic introduction to the topic, including a detailed example of the action selection mechanism. The appendix discusses the more subtle mathematical details, targeting readers who have already studied the active inference literature but struggle to make sense of the mathematical details and derivations. Throughout, we emphasize precise and standard mathematical notation, ensuring consistency with existing texts and linking all equations to widely used references on active inference. Additionally, we provide Python code that implements the action selection and learning mechanisms described in this paper and is compatible with pymdp environments.","authors":["Jesse van Oostrum","Carlotta Langer","Nihat Ay"],"url":"https://arxiv.org/abs/2406.07726"}
{"created":"2025-05-20","title":"Hadamard Representations: Augmenting Hyperbolic Tangents in RL","abstract":"Activation functions are one of the key components of a deep neural network. The most commonly used activation functions can be classed into the category of continuously differentiable (e.g. tanh) and piece-wise linear functions (e.g. ReLU), both having their own strengths and drawbacks with respect to downstream performance and representation capacity through learning. In reinforcement learning, the performance of continuously differentiable activations often falls short as compared to piece-wise linear functions. We show that the dying neuron problem in RL is not exclusive to ReLUs and actually leads to additional problems in the case of continuously differentiable activations such as tanh. To alleviate the dying neuron problem with these activations, we propose a Hadamard representation that unlocks the advantages of continuously differentiable activations. Using DQN, PPO and PQN in the Atari domain, we show faster learning, a reduction in dead neurons and increased effective rank.","authors":["Jacob E. Kooi","Mark Hoogendoorn","Vincent Fran\\c{c}ois-Lavet"],"url":"https://arxiv.org/abs/2406.09079"}
{"created":"2025-05-20","title":"$S^3$ -- Semantic Signal Separation","abstract":"Topic models are useful tools for discovering latent semantic structures in large textual corpora. Recent efforts have been oriented at incorporating contextual representations in topic modeling and have been shown to outperform classical topic models. These approaches are typically slow, volatile, and require heavy preprocessing for optimal results. We present Semantic Signal Separation ($S^3$), a theory-driven topic modeling approach in neural embedding spaces. $S^3$ conceptualizes topics as independent axes of semantic space and uncovers these by decomposing contextualized document embeddings using Independent Component Analysis. Our approach provides diverse and highly coherent topics, requires no preprocessing, and is demonstrated to be the fastest contextual topic model, being, on average, 4.5x faster than the runner-up BERTopic. We offer an implementation of $S^3$, and all contextual baselines, in the Turftopic Python package.","authors":["M\\'arton Kardos","Jan Kostkan","Arnault-Quentin Vermillet","Kristoffer Nielbo","Kenneth Enevoldsen","Roberta Rocca"],"url":"https://arxiv.org/abs/2406.09556"}
{"created":"2025-05-20","title":"Watermarking Language Models with Error Correcting Codes","abstract":"Recent progress in large language models enables the creation of realistic machine-generated content. Watermarking is a promising approach to distinguish machine-generated text from human text, embedding statistical signals in the output that are ideally undetectable to humans. We propose a watermarking framework that encodes such signals through an error correcting code. Our method, termed robust binary code (RBC) watermark, introduces no noticeable degradation in quality. We evaluate our watermark on base and instruction fine-tuned models and find our watermark is robust to edits, deletions, and translations. We provide an information-theoretic perspective on watermarking, a powerful statistical test for detection and for generating $p$-values, and theoretical guarantees. Our empirical findings suggest our watermark is fast, powerful, and robust, comparing favorably to the state-of-the-art.","authors":["Patrick Chao","Yan Sun","Edgar Dobriban","Hamed Hassani"],"url":"https://arxiv.org/abs/2406.10281"}
{"created":"2025-05-20","title":"Task Facet Learning: A Structured Approach to Prompt Optimization","abstract":"Given a task in the form of a basic description and its training examples, prompt optimization is the problem of synthesizing the given information into a text prompt for a large language model. Humans solve this problem by also considering the different facets that define a task (e.g., counter-examples, explanations, analogies) and including them in the prompt. However, it is unclear whether existing algorithmic approaches, based on iteratively editing a given prompt or automatically selecting a few in-context examples, can cover the multiple facets required to solve a complex task. In this work, we view prompt optimization as that of learning multiple facets of a task from a set of training examples. We exploit structure in the prompt optimization problem and break down a prompt into loosely coupled semantic sections. The proposed algorithm, UniPrompt, (1) clusters the input space and uses clustered batches so that each batch likely corresponds to a different facet of the task, and (2) utilizes a feedback mechanism to propose adding, editing or deleting a section, which in turn is aggregated over a batch to capture generalizable facets. Empirical evaluation on multiple datasets and a real-world task shows that prompts generated using \\shortname{} obtain higher accuracy than human-tuned prompts and those from state-of-the-art methods. In particular, our algorithm can generate long, complex prompts that existing methods are unable to generate. Code for UniPrompt is available at https://aka.ms/uniprompt.","authors":["Gurusha Juneja","Gautam Jajoo","Nagarajan Natarajan","Hua Li","Jian Jiao","Amit Sharma"],"url":"https://arxiv.org/abs/2406.10504"}
{"created":"2025-05-20","title":"ShareLoRA: Parameter Efficient and Robust Large Language Model Fine-tuning via Shared Low-Rank Adaptation","abstract":"In this paper, we introduce \\textbf{Share}d \\textbf{Lo}w \\textbf{R}ank \\textbf{A}daptation (ShareLoRA), a Large Language Model (LLM) fine-tuning technique that balances parameter efficiency, adaptability, and robustness without compromising performance. By strategically sharing the low-rank weight matrices across different layers, ShareLoRA achieves 44\\% to 96\\% reduction in trainable parameters compared to standard LoRA, alongside a substantial decrease in memory overhead. This efficiency gain scales with model size, making ShareLoRA particularly advantageous for resource-constrained environments. Importantly, ShareLoRA not only maintains model performance but also exhibits robustness in both classification and generation tasks across diverse models, including RoBERTa, GPT-2, and LLaMA series (1, 2, and 3). It consistently outperforms LoRA in zero-shot, few-shot, and continual fine-tuning scenarios, achieving up to 1.2\\% average accuracy improvement, and enhanced generalization across domains. In continual learning settings, ShareLoRA achieves 1.2\\% higher accuracy on GSM8K, 0.6\\% on HumanEval, and 0.5\\% on both MMLU and MMLU-Pro. Our results demonstrate that ShareLoRA supports high-quality fine-tuning while offering strong generalization and continual adaptation across various model scales and diverse tasks.","authors":["Yurun Song","Junchen Zhao","Ian G. Harris","Sangeetha Abdu Jyothi"],"url":"https://arxiv.org/abs/2406.10785"}
{"created":"2025-05-20","title":"Benchmarking Unsupervised Online IDS for Masquerade Attacks in CAN","abstract":"Vehicular controller area networks (CANs) are susceptible to masquerade attacks by malicious adversaries. In masquerade attacks, adversaries silence a targeted ID and then send malicious frames with forged content at the expected timing of benign frames. As masquerade attacks could seriously harm vehicle functionality and are the stealthiest attacks to detect in CAN, recent work has devoted attention to compare frameworks for detecting masquerade attacks in CAN. However, most existing works report offline evaluations using CAN logs already collected using simulations that do not comply with the domain's real-time constraints. Here we contribute to advance the state of the art by introducing a benchmark study of four different non-deep learning (DL)-based unsupervised online intrusion detection systems (IDS) for masquerade attacks in CAN. Our approach differs from existing benchmarks in that we analyze the effect of controlling streaming data conditions in a sliding window setting. In doing so, we use realistic masquerade attacks being replayed from the ROAD dataset. We show that although benchmarked IDS are not effective at detecting every attack type, the method that relies on detecting changes in the hierarchical structure of clusters of time series produces the best results at the expense of higher computational overhead. We discuss limitations, open challenges, and how the benchmarked methods can be used for practical unsupervised online CAN IDS for masquerade attacks.","authors":["Pablo Moriano","Steven C. Hespeler","Mingyan Li","Robert A. Bridges"],"url":"https://arxiv.org/abs/2406.13778"}
{"created":"2025-05-20","title":"Learning to Cover: Online Learning and Optimization with Irreversible Decisions","abstract":"We define an online learning and optimization problem with discrete and irreversible decisions contributing toward a coverage target. In each period, a decision-maker selects facilities to open, receives information on the success of each one, and updates a classification model to guide future decisions. The goal is to minimize facility openings under a chance constraint reflecting the coverage target, in an asymptotic regime characterized by a large target number of facilities $m\\to\\infty$ but a finite horizon $T \\in \\mathcal{Z}_+$. We prove that, under statistical conditions, the online classifier converges to the Bayes-optimal classifier at a rate of at best $\\mathcal{O}(1/\\sqrt n)$. Thus, we formulate our online learning and optimization problem, with a generalized learning rate $r>0$ and a residual error $1-p$. We derive an asymptotically optimal algorithm and an asymptotically tight lower bound. The regret grows in $\\Theta\\left(m^{\\frac{1-r}{1-r^T}}\\right)$ if $p=1$ (perfect learning) or in $\\Theta\\left(\\max\\left\\{m^{\\frac{1-r}{1-r^T}},\\sqrt{m}\\right\\}\\right)$ otherwise; in particular, the regret rate is sub-linear and converges exponentially fast to its infinite-horizon limit. We extend this result to a more complicated facility location setting in a bipartite facility-customer graph with a target on customer coverage. Throughout, constructive proofs identify a policy featuring limited exploration initially and fast exploitation later on once uncertainty gets mitigated. These results uncover the benefits of limited online learning and optimization through pilot programs prior to full-fledged expansion.","authors":["Alexandre Jacquillat","Michael Lingzhi Li"],"url":"https://arxiv.org/abs/2406.14777"}
{"created":"2025-05-20","title":"Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging","abstract":"While large language models (LLMs) excel in many domains, their complexity and scale challenge deployment in resource-limited environments. Current compression techniques, such as parameter pruning, often fail to effectively utilize the knowledge from pruned parameters. To address these challenges, we propose Manifold-Based Knowledge Alignment and Layer Merging Compression (MKA), a novel approach that uses manifold learning and the Normalized Pairwise Information Bottleneck (NPIB) measure to merge similar layers, reducing model size while preserving essential performance. We evaluate MKA on multiple benchmark datasets and various LLMs. Our findings show that MKA not only preserves model performance but also achieves substantial compression ratios, outperforming traditional pruning methods. Moreover, when coupled with quantization, MKA delivers even greater compression. Specifically, on the MMLU dataset using the Llama3-8B model, MKA achieves a compression ratio of 43.75% with a minimal performance decrease of only 2.82\\%. The proposed MKA method offers a resource-efficient and performance-preserving model compression technique for LLMs.","authors":["Deyuan Liu","Zhanyue Qin","Hairu Wang","Zhao Yang","Zecheng Wang","Fangying Rong","Qingbin Liu","Yanchao Hao","Xi Chen","Cunhang Fan","Zhao Lv","Zhiying Tu","Dianhui Chu","Bo Li","Dianbo Sui"],"url":"https://arxiv.org/abs/2406.16330"}
{"created":"2025-05-20","title":"Brittle Minds, Fixable Activations: Understanding Belief Representations in Language Models","abstract":"Despite growing interest in Theory of Mind (ToM) tasks for evaluating language models (LMs), little is known about how LMs internally represent mental states of self and others. Understanding these internal mechanisms is critical - not only to move beyond surface-level performance, but also for model alignment and safety, where subtle misattributions of mental states may go undetected in generated outputs. In this work, we present the first systematic investigation of belief representations in LMs by probing models across different scales, training regimens, and prompts - using control tasks to rule out confounds. Our experiments provide evidence that both model size and fine-tuning substantially improve LMs' internal representations of others' beliefs, which are structured - not mere by-products of spurious correlations - yet brittle to prompt variations. Crucially, we show that these representations can be strengthened: targeted edits to model activations can correct wrong ToM inferences.","authors":["Matteo Bortoletto","Constantin Ruhdorfer","Lei Shi","Andreas Bulling"],"url":"https://arxiv.org/abs/2406.17513"}
{"created":"2025-05-20","title":"DiffuseDef: Improved Robustness to Adversarial Attacks via Iterative Denoising","abstract":"Pretrained language models have significantly advanced performance across various natural language processing tasks. However, adversarial attacks continue to pose a critical challenge to systems built using these models, as they can be exploited with carefully crafted adversarial texts. Inspired by the ability of diffusion models to predict and reduce noise in computer vision, we propose a novel and flexible adversarial defense method for language classification tasks, DiffuseDef, which incorporates a diffusion layer as a denoiser between the encoder and the classifier. The diffusion layer is trained on top of the existing classifier, ensuring seamless integration with any model in a plug-and-play manner. During inference, the adversarial hidden state is first combined with sampled noise, then denoised iteratively and finally ensembled to produce a robust text representation. By integrating adversarial training, denoising, and ensembling techniques, we show that DiffuseDef improves over existing adversarial defense methods and achieves state-of-the-art performance against common black-box and white-box adversarial attacks.","authors":["Zhenhao Li","Huichi Zhou","Marek Rei","Lucia Specia"],"url":"https://arxiv.org/abs/2407.00248"}
{"created":"2025-05-20","title":"Efficient Shallow Ritz Method For 1D Diffusion-Reaction Problems","abstract":"This paper studies the shallow Ritz method for solving one-dimensional diffusion-reaction problems. The method is capable of improving the order of approximation for non-smooth problems. By following a similar approach to the one presented in [9], we present a damped block Newton (dBN) method to achieve nearly optimal order of approximation. The dBN method optimizes the Ritz functional by alternating between the linear and non-linear parameters of the shallow ReLU neural network (NN). For diffusion-reaction problems, new difficulties arise: (1) for the linear parameters, the mass matrix is dense and even more ill-conditioned than the stiffness matrix, and (2) for the non-linear parameters, the Hessian matrix is dense and may be singular. This paper addresses these challenges, resulting in a dBN method with computational cost of ${\\cal O}(n)$.","authors":["Zhiqiang Cai","Anastassia Doktorova","Robert D. Falgout","C\\'esar Herrera"],"url":"https://arxiv.org/abs/2407.01496"}
{"created":"2025-05-20","title":"A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding","abstract":"Recently, many studies have demonstrated that exclusively incorporating OCR-derived text and spatial layouts with large language models (LLMs) can be highly effective for document understanding tasks. However, existing methods that integrate spatial layouts with text have limitations, such as producing overly long text sequences or failing to fully leverage the autoregressive traits of LLMs. In this work, we introduce Interleaving Layout and Text in a Large Language Model (LayTextLLM)} for document understanding. LayTextLLM projects each bounding box to a single embedding and interleaves it with text, efficiently avoiding long sequence issues while leveraging autoregressive traits of LLMs. LayTextLLM not only streamlines the interaction of layout and textual data but also shows enhanced performance in KIE and VQA. Comprehensive benchmark evaluations reveal significant improvements of LayTextLLM, with a 15.2% increase on KIE tasks and 10.7% on VQA tasks compared to previous SOTA OCR-based LLMs. All resources are available at https://github.com/LayTextLLM/LayTextLLM.","authors":["Jinghui Lu","Haiyang Yu","Yanjie Wang","Yongjie Ye","Jingqun Tang","Ziwei Yang","Binghong Wu","Qi Liu","Hao Feng","Han Wang","Hao Liu","Can Huang"],"url":"https://arxiv.org/abs/2407.01976"}
{"created":"2025-05-20","title":"Gradient descent with generalized Newton's method","abstract":"We propose the generalized Newton's method (GeN) -- a Hessian-informed approach that applies to any optimizer such as SGD and Adam, and covers the Newton-Raphson method as a sub-case. Our method automatically and dynamically selects the learning rate that accelerates the convergence, without the intensive tuning of the learning rate scheduler. In practice, our method is easily implementable, since it only requires additional forward passes with almost zero computational overhead (in terms of training time and memory cost), if the overhead is amortized over many iterations. We present extensive experiments on language and vision tasks (e.g. GPT and ResNet) to showcase that GeN optimizers match the state-of-the-art performance, which was achieved with carefully tuned learning rate schedulers.","authors":["Zhiqi Bu","Shiyun Xu"],"url":"https://arxiv.org/abs/2407.02772"}
{"created":"2025-05-20","title":"Reduced-Order Neural Operators: Learning Lagrangian Dynamics on Highly Sparse Graphs","abstract":"Simulating complex physical systems governed by Lagrangian dynamics often requires solving partial differential equations (PDEs) over high-resolution spatial domains, resulting in substantial computational costs. We present GIOROM (\\textit{G}raph \\textit{I}nf\\textit{O}rmed \\textit{R}educed \\textit{O}rder \\textit{M}odeling), a data-driven discretization invariant framework for accelerating Lagrangian simulations through reduced-order modeling (ROM). Previous discretization invariant ROM approaches rely on PDE time-steppers for spatiotemporally evolving low-dimensional reduced-order latent states. Instead, we leverage a data-driven graph-based neural approximation of the PDE solution operator. This operator estimates point-wise function values from a sparse set of input observations, reducing reliance on known governing equations of numerical solvers. Order reduction is achieved by embedding these point-wise estimates within the reduced-order latent space using a learned kernel parameterization. This latent representation enables the reconstruction of the solution at arbitrary spatial query points by evolving latent variables over local neighborhoods on the solution manifold, using the kernel. Empirically, GIOROM achieves a 6.6$\\times$-32$\\times$ reduction in input dimensionality while maintaining high-fidelity reconstructions across diverse Lagrangian regimes including fluid flows, granular media, and elastoplastic dynamics. The resulting framework enables learnable, data-driven and discretization-invariant order-reduction with reduced reliance on analytical PDE formulations. Our code is at \\href{https://github.com/HrishikeshVish/GIOROM}{https://github.com/HrishikeshVish/GIOROM}","authors":["Hrishikesh Viswanath","Yue Chang","Aleksey Panas","Julius Berner","Peter Yichen Chen","Aniket Bera"],"url":"https://arxiv.org/abs/2407.03925"}
{"created":"2025-05-20","title":"This&That: Language-Gesture Controlled Video Generation for Robot Planning","abstract":"Clear, interpretable instructions are invaluable when attempting any complex task. Good instructions help to clarify the task and even anticipate the steps needed to solve it. In this work, we propose a robot learning framework for communicating, planning, and executing a wide range of tasks, dubbed This&amp;That. This&amp;That solves general tasks by leveraging video generative models, which, through training on internet-scale data, contain rich physical and semantic context. In this work, we tackle three fundamental challenges in video-based planning: 1) unambiguous task communication with simple human instructions, 2) controllable video generation that respects user intent, and 3) translating visual plans into robot actions. This&amp;That uses language-gesture conditioning to generate video predictions, as a succinct and unambiguous alternative to existing language-only methods, especially in complex and uncertain environments. These video predictions are then fed into a behavior cloning architecture dubbed Diffusion Video to Action (DiVA), which outperforms prior state-of-the-art behavior cloning and video-based planning methods by substantial margins.","authors":["Boyang Wang","Nikhil Sridhar","Chao Feng","Mark Van der Merwe","Adam Fishman","Nima Fazeli","Jeong Joon Park"],"url":"https://arxiv.org/abs/2407.05530"}
{"created":"2025-05-20","title":"A boundary integral equation formulation for transient electromagnetic transmission problems on Lipschitz domains","abstract":"We propose a boundary integral formulation for the dynamic problem of electromagnetic scattering and transmission by homogeneous dielectric obstacles. In the spirit of Costabel and Stephan, we use the transmission conditions to reduce the number of unknown densities and to formulate a system of coupled boundary integral equations describing the scattered and transmitted waves. The system is transformed into the Laplace domain where it is proven to be stable and uniquely solvable. The Laplace domain stability estimates are then used to establish the stability and unique solvability of the original time domain problem. Finally, we show how the bounds obtained in both Laplace and time domains can be used to derive error estimates for semi discrete Galerkin discretizations in space and for fully discrete numerical schemes that use Convolution Quadrature for time discretization and a conforming Galerkin method for discretization of the space variables.","authors":["Tonatiuh S\\'anchez-Vizuet"],"url":"https://arxiv.org/abs/2407.05823"}
{"created":"2025-05-20","title":"A Semantic-Aware and Multi-Guided Network for Infrared-Visible Image Fusion","abstract":"Multi-modality image fusion aims at fusing modality-specific (complementarity) and modality-shared (correlation) information from multiple source images. To tackle the problem of the neglect of inter-feature relationships, high-frequency information loss, and the limited attention to downstream tasks, this paper focuses on how to model correlation-driven decomposing features and reason high-level graph representation by efficiently extracting complementary information and aggregating multi-guided features. We propose a three-branch encoder-decoder architecture along with corresponding fusion layers as the fusion strategy. Firstly, shallow features from individual modalities are extracted by a depthwise convolution layer combined with the transformer block. In the three parallel branches of the encoder, Cross Attention and Invertible Block (CAI) extracts local features and preserves high-frequency texture details. Base Feature Extraction Module (BFE) captures long-range dependencies and enhances modality-shared information. Graph Reasoning Module (GR) is introduced to reason high-level cross-modality relations and simultaneously extract low-level detail features as CAI's modality-specific complementary information. Experiments demonstrate the competitive results compared with state-of-the-art methods in visible/infrared image fusion and medical image fusion tasks. Moreover, the proposed algorithm surpasses the state-of-the-art methods in terms of subsequent tasks, averagely scoring 8.27% mAP@0.5 higher in object detection and 5.85% mIoU higher in semantic segmentation. The code is avaliable at https://github.com/Abraham-Einstein/SMFNet/.","authors":["Xiaoli Zhang","Liying Wang","Libo Zhao","Xiongfei Li","Siwei Ma"],"url":"https://arxiv.org/abs/2407.06159"}
{"created":"2025-05-20","title":"Text2VP: Generative AI for Visual Programming and Parametric Modeling","abstract":"The integration of generative artificial intelligence (AI) into architectural design has advanced significantly, enabling the generation of text, images, and 3D models. However, prior AI applications lack support for text-to-parametric models, essential for generating and optimizing diverse parametric design options. This study introduces Text-to-Visual Programming (Text2VP) GPT, a novel generative AI derived from GPT-4.1, designed to automate graph-based visual programming workflows, parameters, and their interconnections. Text2VP leverages detailed documentation, specific instructions, and example-driven few-shot learning to reflect user intentions accurately and facilitate interactive parameter adjustments. Testing demonstrates Text2VP's capability in generating functional parametric models, although higher complexity models present increased error rates. This research highlights generative AI's potential in visual programming and parametric modeling, laying groundwork for future improvements to manage complex modeling tasks. Ultimately, Text2VP aims to enable designers to easily create and modify parametric models without extensive training in specialized platforms like Grasshopper.","authors":["Guangxi Feng","Wei Yan"],"url":"https://arxiv.org/abs/2407.07732"}
{"created":"2025-05-20","title":"Defending Code Language Models against Backdoor Attacks with Deceptive Cross-Entropy Loss","abstract":"Code Language Models (CLMs), particularly those leveraging deep learning, have achieved significant success in code intelligence domain. However, the issue of security, particularly backdoor attacks, is often overlooked in this process. The previous research has focused on designing backdoor attacks for CLMs, but effective defenses have not been adequately addressed. In particular, existing defense methods from natural language processing, when directly applied to CLMs, are not effective enough and lack generality, working well in some models and scenarios but failing in others, thus fall short in consistently mitigating backdoor attacks. To bridge this gap, we first confirm the phenomenon of \"early learning\" as a general occurrence during the training of CLMs. This phenomenon refers to that a model initially focuses on the main features of training data but may become more sensitive to backdoor triggers over time, leading to overfitting and susceptibility to backdoor attacks. We then analyze that overfitting to backdoor triggers results from the use of the cross-entropy loss function, where the unboundedness of cross-entropy leads the model to increasingly concentrate on the features of the poisoned data. Based on this insight, we propose a general and effective loss function DeCE (Deceptive Cross-Entropy) by blending deceptive distributions and applying label smoothing to limit the gradient to bounded, which prevents the model from overfitting to backdoor triggers and then enhances the security of CLMs against backdoor attacks.","authors":["Guang Yang","Yu Zhou","Xiang Chen","Xiangyu Zhang","Terry Yue Zhuo","David Lo","Taolue Chen"],"url":"https://arxiv.org/abs/2407.08956"}
{"created":"2025-05-20","title":"EfficientQAT: Efficient Quantization-Aware Training for Large Language Models","abstract":"Large language models (LLMs) are crucial in modern natural language processing and artificial intelligence. However, they face challenges in managing their significant memory requirements. Although quantization-aware training (QAT) offers a solution by reducing memory consumption through low-bit representations with minimal accuracy loss, it is impractical due to substantial training resources. To address this, we propose Efficient Quantization-Aware Training (EfficientQAT), a more feasible QAT algorithm. EfficientQAT involves two consecutive phases: Block-wise training of all parameters (Block-AP) and end-to-end training of quantization parameters (E2E-QP). To the best of our knowledge, Block-AP is the first method to enable direct training of all parameters in a block-wise manner, reducing accuracy loss in low-bit scenarios by enhancing the solution space during optimization. E2E-QP then trains only the quantization parameters (step sizes) end-to-end, further improving the performance of quantized models by considering interactions among all sub-modules. Extensive experiments demonstrate that EfficientQAT outperforms previous quantization methods across a range of models, including base LLMs, instruction-tuned LLMs, and multimodal LLMs, with scales from 7B to 70B parameters at various quantization bits. For instance, EfficientQAT obtains a 2-bit Llama-2-70B model on a single A100-80GB GPU in 41 hours, with less than 3 points accuracy degradation compared to the full precision (69.48 vs. 72.41). Code is available at https://github.com/OpenGVLab/EfficientQAT.","authors":["Mengzhao Chen","Wenqi Shao","Peng Xu","Jiahao Wang","Peng Gao","Kaipeng Zhang","Ping Luo"],"url":"https://arxiv.org/abs/2407.11062"}
{"created":"2025-05-20","title":"Omnigrasp: Grasping Diverse Objects with Simulated Humanoids","abstract":"We present a method for controlling a simulated humanoid to grasp an object and move it to follow an object's trajectory. Due to the challenges in controlling a humanoid with dexterous hands, prior methods often use a disembodied hand and only consider vertical lifts or short trajectories. This limited scope hampers their applicability for object manipulation required for animation and simulation. To close this gap, we learn a controller that can pick up a large number (>1200) of objects and carry them to follow randomly generated trajectories. Our key insight is to leverage a humanoid motion representation that provides human-like motor skills and significantly speeds up training. Using only simplistic reward, state, and object representations, our method shows favorable scalability on diverse objects and trajectories. For training, we do not need a dataset of paired full-body motion and object trajectories. At test time, we only require the object mesh and desired trajectories for grasping and transporting. To demonstrate the capabilities of our method, we show state-of-the-art success rates in following object trajectories and generalizing to unseen objects. Code and models will be released.","authors":["Zhengyi Luo","Jinkun Cao","Sammy Christen","Alexander Winkler","Kris Kitani","Weipeng Xu"],"url":"https://arxiv.org/abs/2407.11385"}
{"created":"2025-05-20","title":"Conditional Quantile Estimation for Uncertain Watch Time in Short-Video Recommendation","abstract":"Accurately predicting watch time is crucial for optimizing recommendations and user experience in short video platforms. However, existing methods that estimate a single average watch time often fail to capture the inherent uncertainty in user engagement patterns. In this paper, we propose Conditional Quantile Estimation (CQE) to model the entire conditional distribution of watch time. Using quantile regression, CQE characterizes the complex watch-time distribution for each user-video pair, providing a flexible and comprehensive approach to understanding user behavior. We further design multiple strategies to combine the quantile estimates, adapting to different recommendation scenarios and user preferences. Extensive offline experiments and online A/B tests demonstrate the superiority of CQE in watch-time prediction and user engagement modeling. Specifically, deploying CQE online on a large-scale platform with hundreds of millions of daily active users has led to substantial gains in key evaluation metrics, including active days, engagement time, and video views. These results highlight the practical impact of our proposed approach in enhancing the user experience and overall performance of the short video recommendation system. The code will be released https://github.com/justopit/CQE.","authors":["Chengzhi Lin","Shuchang Liu","Chuyuan Wang","Yongqi Liu"],"url":"https://arxiv.org/abs/2407.12223"}
{"created":"2025-05-20","title":"Conspiracy theories and where to find them on TikTok","abstract":"TikTok has skyrocketed in popularity over recent years, especially among younger audiences. However, there are public concerns about the potential of this platform to promote and amplify harmful content. This study presents the first systematic analysis of conspiracy theories on TikTok. By leveraging the official TikTok Research API we collect a longitudinal dataset of 1.5M videos shared in the U.S. over three years. We estimate a lower bound on the prevalence of conspiratorial videos (up to 1000 new videos per month) and evaluate the effects of TikTok's Creativity Program for monetization, observing an overall increase in video duration regardless of content. Lastly, we evaluate the capabilities of state-of-the-art open-weight Large Language Models to identify conspiracy theories from audio transcriptions of videos. While these models achieve high precision in detecting harmful content (up to 96%), their overall performance remains comparable to fine-tuned traditional models such as RoBERTa. Our findings suggest that Large Language Models can serve as an effective tool for supporting content moderation strategies aimed at reducing the spread of harmful content on TikTok.","authors":["Francesco Corso","Francesco Pierri","Gianmarco De Francisci Morales"],"url":"https://arxiv.org/abs/2407.12545"}
{"created":"2025-05-20","title":"Scalable Exploration via Ensemble++","abstract":"Thompson Sampling is a principled method for balancing exploration and exploitation, but its real-world adoption faces computational challenges in large-scale or non-conjugate settings. While ensemble-based approaches offer partial remedies, they typically require prohibitively large ensemble sizes. We propose Ensemble++, a scalable exploration framework using a novel shared-factor ensemble architecture with random linear combinations. For linear bandits, we provide theoretical guarantees showing that Ensemble++ achieves regret comparable to exact Thompson Sampling with only $\\Theta(d \\log T)$ ensemble sizes--significantly outperforming prior methods. Crucially, this efficiency holds across both compact and finite action sets with either time-invariant or time-varying contexts without configuration changes. We extend this theoretical foundation to nonlinear rewards by replacing fixed features with learnable neural representations while preserving the same incremental update principle, effectively bridging theory and practice for real-world tasks. Comprehensive experiments across linear, quadratic, neural, and GPT-based contextual bandits validate our theoretical findings and demonstrate Ensemble++'s superior regret-computation tradeoff versus state-of-the-art methods.","authors":["Yingru Li","Jiawei Xu","Baoxiang Wang","Zhi-Quan Luo"],"url":"https://arxiv.org/abs/2407.13195"}
{"created":"2025-05-20","title":"ChatISA: A Prompt-Engineered, In-House Multi-Modal Generative AI Chatbot for Information Systems Education","abstract":"As generative AI ('GenAI') continues to evolve, educators face the challenge of preparing students for a future where AI-assisted work is integral to professional success. This paper introduces ChatISA, an in-house, multi-model AI chatbot designed to support students and faculty in an Information Systems and Analytics (ISA) department. ChatISA comprises four primary modules: Coding Companion, Project Coach, Exam Ally, and Interview Mentor, each tailored to enhance different aspects of the educational experience. Through iterative development, student feedback, and leveraging open-source frameworks, we created a robust tool that addresses coding inquiries, project management, exam preparation, and interview readiness. The implementation of ChatISA provided valuable insights and highlighted key challenges. Our findings demonstrate the benefits of ChatISA for ISA education while underscoring the need for adaptive pedagogy and proactive engagement with AI tools to fully harness their educational potential. To support broader adoption and innovation, all code for ChatISA is made publicly available on GitHub, enabling other institutions to customize and integrate similar AI-driven educational tools within their curricula.","authors":["Fadel M. Megahed","Ying-Ju Chen","Joshua A. Ferris","Cameron Resatar","Kaitlyn Ross","Younghwa Lee","L. Allison Jones-Farmer"],"url":"https://arxiv.org/abs/2407.15010"}
{"created":"2025-05-20","title":"Robotic Shepherding in Cluttered and Unknown Environments using Control Barrier Functions","abstract":"This paper introduces a novel control methodology designed to guide a collective of robotic-sheep in a cluttered and unknown environment using robotic-dogs. The dog-agents continuously scan the environment and compute a safe trajectory to guide the sheep to their final destination. The proposed optimization-based controller guarantees that the sheep reside within a desired distance from the reference trajectory through the use of Control Barrier Functions (CBF). Additional CBF constraints are employed simultaneously to ensure inter-agent and obstacle collision avoidance. The efficacy of the proposed approach is rigorously tested in simulation, which demonstrates the successful herding of the robotic-sheep within complex and cluttered environments.","authors":["Mahmoud Hamandi","Farshad Khorrami","Anthony Tzes"],"url":"https://arxiv.org/abs/2407.15701"}
{"created":"2025-05-20","title":"Parameter-Efficient Fine-Tuning for Continual Learning: A Neural Tangent Kernel Perspective","abstract":"Parameter-efficient fine-tuning for continual learning (PEFT-CL) has shown promise in adapting pre-trained models to sequential tasks while mitigating catastrophic forgetting problem. However, understanding the mechanisms that dictate continual performance in this paradigm remains elusive. To unravel this mystery, we undertake a rigorous analysis of PEFT-CL dynamics to derive relevant metrics for continual scenarios using Neural Tangent Kernel (NTK) theory. With the aid of NTK as a mathematical analysis tool, we recast the challenge of test-time forgetting into the quantifiable generalization gaps during training, identifying three key factors that influence these gaps and the performance of PEFT-CL: training sample size, task-level feature orthogonality, and regularization. To address these challenges, we introduce NTK-CL, a novel framework that eliminates task-specific parameter storage while adaptively generating task-relevant features. Aligning with theoretical guidance, NTK-CL triples the feature representation of each sample, theoretically and empirically reducing the magnitude of both task-interplay and task-specific generalization gaps. Grounded in NTK analysis, our framework imposes an adaptive exponential moving average mechanism and constraints on task-level feature orthogonality, maintaining intra-task NTK forms while attenuating inter-task NTK forms. Ultimately, by fine-tuning optimizable parameters with appropriate regularization, NTK-CL achieves state-of-the-art performance on established PEFT-CL benchmarks. This work provides a theoretical foundation for understanding and improving PEFT-CL models, offering insights into the interplay between feature representation, task orthogonality, and generalization, contributing to the development of more efficient continual learning systems.","authors":["Jingren Liu","Zhong Ji","YunLong Yu","Jiale Cao","Yanwei Pang","Jungong Han","Xuelong Li"],"url":"https://arxiv.org/abs/2407.17120"}
{"created":"2025-05-20","title":"Supporting Evidence-Based Medicine by Finding Both Relevant and Significant Works","abstract":"In this paper, we present a new approach to improving the relevance and reliability of medical IR, which builds upon the concept of Level of Evidence (LoE). LoE framework categorizes medical publications into 7 distinct levels based on the underlying empirical evidence. Despite LoE framework's relevance in medical research and evidence-based practice, only few medical publications explicitly state their LoE. Therefore, we develop a classification model for automatically assigning LoE to medical publications, which successfully classifies over 26 million documents in MEDLINE database into LoE classes. The subsequent retrieval experiments on TREC PM datasets show substantial improvements in retrieval relevance, when LoE is used as a search filter.","authors":["Sameh Frihat","Norbert Fuhr"],"url":"https://arxiv.org/abs/2407.18383"}
{"created":"2025-05-20","title":"ClinicRealm: Re-evaluating Large Language Models with Conventional Machine Learning for Non-Generative Clinical Prediction Tasks","abstract":"Large Language Models (LLMs) are increasingly deployed in medicine. However, their utility in non-generative clinical prediction, often presumed inferior to specialized models, remains under-evaluated, leading to ongoing debate within the field and potential for misuse, misunderstanding, or over-reliance due to a lack of systematic benchmarking. Our ClinicRealm study addresses this by benchmarking 9 GPT-based LLMs, 5 BERT-based models, and 7 traditional methods on unstructured clinical notes and structured Electronic Health Records (EHR). Key findings reveal a significant shift: for clinical note predictions, leading LLMs (e.g., DeepSeek R1/V3, GPT o3-mini-high) in zero-shot settings now decisively outperform finetuned BERT models. On structured EHRs, while specialized models excel with ample data, advanced LLMs (e.g., GPT-4o, DeepSeek R1/V3) show potent zero-shot capabilities, often surpassing conventional models in data-scarce settings. Notably, leading open-source LLMs can match or exceed proprietary counterparts. These results establish modern LLMs as powerful non-generative clinical prediction tools, particularly with unstructured text and offering data-efficient structured data options, thus necessitating a re-evaluation of model selection strategies. This research should serve as an important insight for medical informaticists, AI developers, and clinical researchers, potentially prompting a reassessment of current assumptions and inspiring new approaches to LLM application in predictive healthcare.","authors":["Yinghao Zhu","Junyi Gao","Zixiang Wang","Weibin Liao","Xiaochen Zheng","Lifang Liang","Miguel O. Bernabeu","Yasha Wang","Lequan Yu","Chengwei Pan","Ewen M. Harrison","Liantao Ma"],"url":"https://arxiv.org/abs/2407.18525"}
{"created":"2025-05-20","title":"Regular Grammars for Sets of Graphs of Tree-Width 2","abstract":"Regular word grammars are restricted context-free grammars that define all the recognizable languages of words. This paper generalizes regular grammars from words to certain classes of graphs, by defining regular grammars for unordered unranked trees and graphs of tree-width 2 at most. The qualifier ``regular'' is justified because these grammars define precisely the recognizable (equivalently, CMSO-definable) sets of the respective graph classes. The proof of equivalence between regular and recognizable sets of graphs relies on the effective construction of a recognizer algebra of size doubly-exponential in the size of the grammar. This sets a 2EXPTIME upper bound on the (EXPTIME-hard) problem of inclusion of a context-free language in a regular language, for graphs of tree-width 2 at most. A further syntactic restriction of regular grammars suffices to capture precisely the MSO-definable sets of graphs of tree-width 2 at most, i.e., the sets defined by CMSO formulae without cardinality constraints. Moreover, we show that MSO-definability coincides with recognizability by algebras having an aperiodic parallel composition semigroup, for each class of graphs defined by a bound on the tree-width.","authors":["Marius Bozga","Radu Iosif","Florian Zuleger"],"url":"https://arxiv.org/abs/2408.01226"}
{"created":"2025-05-20","title":"SiCo: An Interactive Size-Controllable Virtual Try-On Approach for Informed Decision-Making","abstract":"Virtual try-on (VTO) applications aim to replicate the in-store shopping experience and enhance online shopping by enabling users to interact with garments. However, many existing tools adopt a one-size-fits-all approach when visualizing clothing items. This approach limits user interaction with garments, particularly regarding size and fit adjustments, and fails to provide direct insights for size recommendations. As a result, these limitations contribute to high return rates in online shopping. To address this, we introduce SiCo, a new online VTO system that allows users to upload images of themselves and interact with garments by visualizing how different sizes would fit their bodies. Our user study demonstrates that our approach significantly improves users' ability to assess how outfits will appear on their bodies and increases their confidence in selecting clothing sizes that align with their preferences. Based on our evaluation, we believe that SiCo has the potential to reduce return rates and transform the online clothing shopping experience.","authors":["Sherry X. Chen","Alex Christopher Lim","Yimeng Liu","Pradeep Sen","Misha Sra"],"url":"https://arxiv.org/abs/2408.02803"}
{"created":"2025-05-20","title":"Back-Projection Diffusion: Solving the Wideband Inverse Scattering Problem with Diffusion Models","abstract":"We present Wideband Back-Projection Diffusion, an end-to-end probabilistic framework for approximating the posterior distribution induced by the inverse scattering map from wideband scattering data. This framework produces highly accurate reconstructions, leveraging conditional diffusion models to draw samples, and also honors the symmetries of the underlying physics of wave-propagation. The procedure is factored into two steps: the first step, inspired by the filtered back-propagation formula, transforms data into a physics-based latent representation, while the second step learns a conditional score function conditioned on this latent representation. These two steps individually obey their associated symmetries and are amenable to compression by imposing the rank structure found in the filtered back-projection formula. Empirically, our framework has both low sample and computational complexity, with its number of parameters scaling only sub-linearly with the target resolution, and has stable training dynamics. It provides sharp reconstructions effortlessly and is capable of recovering even sub-Nyquist features in the multiple-scattering regime.","authors":["Borong Zhang","Mart\\'in Guerra","Qin Li","Leonardo Zepeda-N\\'u\\~nez"],"url":"https://arxiv.org/abs/2408.02866"}
{"created":"2025-05-20","title":"Alternating Nominal Automata with Name Allocation","abstract":"Formal languages over infinite alphabets serve as abstractions of structures and processes carrying data. Automata models over infinite alphabets, such as classical register automata or, equivalently, nominal orbit-finite automata, tend to have computationally hard or even undecidable reasoning problems unless stringent restrictions are imposed on either the power of control or the number of registers. This has been shown to be ameliorated in automata models with name allocation such as regular nondeterministic nominal automata, which allow for deciding language inclusion in elementary complexity even with unboundedly many registers while retaining a reasonable level of expressiveness. In the present work, we demonstrate that elementary complexity survives under extending the power of control to alternation: We introduce regular alternating nominal automata (RANAs), and show that their non-emptiness and inclusion problems have elementary complexity even when the number of registers is unbounded. Moreover, we show that RANAs allow for nearly complete de-alternation, specifically de-alternation up to a single deadlocked universal state. As a corollary to our results, we improve the complexity of model checking for a flavour of Bar-$\\mu$TL, a fixed-point logic with name allocation over finite data words, by one exponential level.","authors":["Florian Frank","Daniel Hausmann","Stefan Milius","Lutz Schr\\\"oder","Henning Urbat"],"url":"https://arxiv.org/abs/2408.03658"}
{"created":"2025-05-20","title":"Asynchronous Credit Assignment for Multi-Agent Reinforcement Learning","abstract":"Credit assignment is a critical problem in multi-agent reinforcement learning (MARL), aiming to identify agents' marginal contributions for optimizing cooperative policies. Current credit assignment methods typically assume synchronous decision-making among agents. However, many real-world scenarios require agents to act asynchronously without waiting for others. This asynchrony introduces conditional dependencies between actions, which pose great challenges to current methods. To address this issue, we propose an asynchronous credit assignment framework, incorporating a Virtual Synchrony Proxy (VSP) mechanism and a Multiplicative Value Decomposition (MVD) algorithm. VSP enables physically asynchronous actions to be virtually synchronized during credit assignment. We theoretically prove that VSP preserves both task equilibrium and algorithm convergence. Furthermore, MVD leverages multiplicative interactions to effectively model dependencies among asynchronous actions, offering theoretical advantages in handling asynchronous tasks. Extensive experiments show that our framework consistently outperforms state-of-the-art MARL methods on challenging tasks while providing improved interpretability for asynchronous cooperation.","authors":["Yongheng Liang","Hejun Wu","Haitao Wang","Hao Cai"],"url":"https://arxiv.org/abs/2408.03692"}
{"created":"2025-05-20","title":"Row-aware Randomized SVD with applications","abstract":"The randomized singular value decomposition proposed in [25] has certainly become one of the most well-established randomization-based algorithms in numerical linear algebra. The key ingredient of the entire procedure is the computation of a subspace which is close to the column space of the target matrix $\\mathbf{A}$ up to a certain probabilistic confidence. In this paper we employ a modification to the standard randomized SVD procedure which leads, in general, to better approximations to $\\text{Range}(\\mathbf{A})$ at the same computational cost. To this end, we explicitly construct information from the row space of $\\mathbf{A}$ enhancing the quality of the approximation. We derive novel error bounds which improve over existing results for $\\mathbf{A}$ having important gaps in its singular values. We also observe that very few pieces of information from $\\text{Range}(\\mathbf{A}^T)$ may be necessary. We thus design a variant of this algorithm equipped with a subsampling step which largely increases the efficiency of the procedure while attaining competitive accuracy records. Our findings are supported by both theoretical analysis and numerical results.","authors":["Davide Palitta","Sascha Portaro"],"url":"https://arxiv.org/abs/2408.04503"}
{"created":"2025-05-20","title":"EasyInv: Toward Fast and Better DDIM Inversion","abstract":"This paper introduces EasyInv, an easy yet novel approach that significantly advances the field of DDIM Inversion by addressing the inherent inefficiencies and performance limitations of traditional iterative optimization methods. At the core of our EasyInv is a refined strategy for approximating inversion noise, which is pivotal for enhancing the accuracy and reliability of the inversion process. By prioritizing the initial latent state, which encapsulates rich information about the original images, EasyInv steers clear of the iterative refinement of noise items. Instead, we introduce a methodical aggregation of the latent state from the preceding time step with the current state, effectively increasing the influence of the initial latent state and mitigating the impact of noise. We illustrate that EasyInv is capable of delivering results that are either on par with or exceed those of the conventional DDIM Inversion approach, especially under conditions where the model's precision is limited or computational resources are scarce. Concurrently, our EasyInv offers an approximate threefold enhancement regarding inference efficiency over off-the-shelf iterative optimization techniques. It can be easily combined with most existing inversion methods by only four lines of code. See code at https://github.com/potato-kitty/EasyInv.","authors":["Ziyue Zhang","Mingbao Lin","Shuicheng Yan","Rongrong Ji"],"url":"https://arxiv.org/abs/2408.05159"}
{"created":"2025-05-20","title":"SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning","abstract":"Recent development in Large Language Models (LLMs) and Multi-modal Large Language Models (MLLMs) have leverage Attention-based Transformer architectures and achieved superior performance and generalization capabilities. They have since covered extensive areas of traditional learning tasks. For instance, text-based tasks such as text-classification and sequence-labeling, as well as multi-modal tasks like Visual Question Answering (VQA) and Optical Character Recognition (OCR), which were previously addressed using different models, can now be tackled based on one foundation model. Consequently, the training and lightweight fine-tuning of LLMs and MLLMs, especially those based on Transformer architecture, has become particularly important. In recognition of these overwhelming needs, we develop SWIFT, a customizable one-stop infrastructure for large models. With support of over $300+$ LLMs and $50+$ MLLMs, SWIFT stands as the open-source framework that provide the most comprehensive support for fine-tuning large models. In particular, it is the first training framework that provides systematic support for MLLMs. In addition to the core functionalities of fine-tuning, SWIFT also integrates post-training processes such as inference, evaluation, and model quantization, to facilitate fast adoptions of large models in various application scenarios. With a systematic integration of various training techniques, SWIFT offers helpful utilities such as benchmark comparisons among different training techniques for large models. For fine-tuning models specialized in agent framework, we show that notable improvements on the ToolBench leader-board can be achieved by training with customized dataset on SWIFT, with an increase of 5.2%-21.8% in the Act.EM metric over various baseline models, a reduction in hallucination by 1.6%-14.1%, and an average performance improvement of 8%-17%.","authors":["Yuze Zhao","Jintao Huang","Jinghan Hu","Xingjun Wang","Yunlin Mao","Daoze Zhang","Hong Zhang","Zeyinzi Jiang","Zhikai Wu","Baole Ai","Ang Wang","Wenmeng Zhou","Yingda Chen"],"url":"https://arxiv.org/abs/2408.05517"}
{"created":"2025-05-20","title":"Approximating Discrimination Within Models When Faced With Several Non-Binary Sensitive Attributes","abstract":"Discrimination mitigation within machine learning (ML) models could be complicated because multiple factors may be interwoven hierarchically and historically. Yet few existing fairness measures can capture the discrimination level within ML models in the face of multiple sensitive attributes (SAs). To bridge this gap, we propose a fairness measure based on distances between sets from a manifold perspective, named as 'Harmonic Fairness measure via Manifolds (HFM)' with two optional versions, which can deal with a fine-grained discrimination evaluation for several SAs of multiple values. Because directly computing HFM may be costly, to accelerate its subprocedure -- the computation of distances of sets, we further propose two approximation algorithms named 'Approximation of distance between sets for one sensitive attribute with multiple values (ApproxDist)' and 'Approximation of extended distance between sets for several sensitive attributes with multiple values (ExtendDist)' to respectively resolve bias evaluation of one single SA with multiple values and that of several SAs with multiple values. Moreover, we provide an algorithmic effectiveness analysis for ApproxDist under certain assumptions to explain how well it could work. The empirical results demonstrate that our proposed fairness measure HFM is valid and approximation algorithms (i.e. ApproxDist and ExtendDist) are effective and efficient.","authors":["Yijun Bian","Yujie Luo","Ping Xu"],"url":"https://arxiv.org/abs/2408.06099"}
{"created":"2025-05-20","title":"DeNOTS: Stable Deep Neural ODEs for Time Series","abstract":"Neural CDEs provide a natural way to process the temporal evolution of irregular time series. The number of function evaluations (NFE) is these systems' natural analog of depth (the number of layers in traditional neural networks). It is usually regulated via solver error tolerance: lower tolerance means higher numerical precision, requiring more integration steps. However, lowering tolerances does not adequately increase the models' expressiveness. We propose a simple yet effective alternative: scaling the integration time horizon to increase NFEs and \"deepen`` the model. Increasing the integration interval causes uncontrollable growth in conventional vector fields, so we also propose a way to stabilize the dynamics via Negative Feedback (NF). It ensures provable stability without constraining flexibility. It also implies robustness: we provide theoretical bounds for Neural ODE risk using Gaussian process theory. Experiments on four open datasets demonstrate that our method, DeNOTS, outperforms existing approaches~ -- ~including recent Neural RDEs and state space models,~ -- ~achieving up to $20\\%$ improvement in metrics. DeNOTS combines expressiveness, stability, and robustness, enabling reliable modelling in continuous-time domains.","authors":["Ilya Kuleshov","Evgenia Romanenkova","Vladislav Zhuzhel","Galina Boeva","Evgeni Vorsin","Alexey Zaytsev"],"url":"https://arxiv.org/abs/2408.08055"}
{"created":"2025-05-20","title":"Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling","abstract":"Massive parameters of LLMs have made inference latency a fundamental bottleneck. Speculative decoding represents a lossless approach to accelerate inference through a guess-and-verify paradigm. Some methods rely on additional architectures to guess draft tokens, which need extra training before use. Alternatively, retrieval-based training-free techniques build libraries from pre-existing corpora or by n-gram generation. However, they face challenges like large storage requirements, time-consuming retrieval, and limited adaptability. Observing that candidate tokens generated during the decoding process are likely to reoccur in future sequences, we propose Token Recycling. It stores candidate tokens in an adjacency matrix and employs a breadth-first-search (BFS)-like algorithm to construct a draft tree, which is then validated through tree attention. New candidate tokens from the decoding process are then used to update the matrix. Token Recycling requires \\textless2MB of additional storage and achieves approximately 2x speedup across all sizes of LLMs. It significantly outperforms existing train-free methods by 30\\% and even a widely recognized training method by 25\\%.","authors":["Xianzhen Luo","Yixuan Wang","Qingfu Zhu","Zhiming Zhang","Xuanyu Zhang","Qing Yang","Dongliang Xu"],"url":"https://arxiv.org/abs/2408.08696"}
{"created":"2025-05-20","title":"Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions","abstract":"With the help of in-context learning (ICL), large language models (LLMs) have achieved impressive performance across various tasks. However, the function of descriptive instructions during ICL remains under-explored. In this work, we propose an ensemble prompt framework to describe the selection criteria of multiple in-context examples, and preliminary experiments on machine translation (MT) across six translation directions confirm that this framework boosts ICL performance. But to our surprise, LLMs might not care what the descriptions actually say, and the performance gain is primarily caused by the ensemble format, since it could lead to improvement even with random descriptive nouns. We further apply this new ensemble framework on a range of commonsense, math, logical reasoning and hallucination tasks with three LLMs and achieve promising results, suggesting again that designing a proper prompt format would be much more effective and efficient than paying effort into specific descriptions. Our code will be publicly available once this paper is published.","authors":["Chenming Tang","Zhixiang Wang","Hao Sun","Yunfang Wu"],"url":"https://arxiv.org/abs/2408.08780"}
{"created":"2025-05-20","title":"Safety Critical Control for Nonlinear Systems with Complex Input Constraints","abstract":"In this paper, we propose a novel Control Barrier Function (CBF) based controller for nonlinear systems with complex, time-varying input constraints. To deal with these constraints, we introduce an auxiliary control input to transform the original system into an augmented one, thus reformulating the constrained-input problem into a constrained-output one. This transformation simplifies the Quadratic Programming (QP) formulation and enhances compatibility with the CBF framework. As a result, the proposed method can systematically address the complex, time-varying, and state-dependent input constraints. The efficacy of the proposed approach is validated using numerical examples.","authors":["Yaosheng Deng","Yang Bai","Yujie Wang","Masaki Ogura","Mir Feroskhan"],"url":"https://arxiv.org/abs/2408.09534"}
{"created":"2025-05-20","title":"Centralized Reward Agent for Knowledge Sharing and Transfer in Multi-Task Reinforcement Learning","abstract":"Reward shaping is effective in addressing the sparse-reward challenge in reinforcement learning by providing immediate feedback through auxiliary informative rewards. Based on the reward shaping strategy, we propose a novel multi-task reinforcement learning framework that integrates a centralized reward agent (CRA) and multiple distributed policy agents. The CRA functions as a knowledge pool, which aims to distill knowledge from various tasks and distribute it to individual policy agents to improve learning efficiency. Specifically, the shaped rewards serve as a straightforward metric to encode knowledge. This framework not only enhances knowledge sharing across established tasks but also adapts to new tasks by transferring meaningful reward signals. We validate the proposed method on both discrete and continuous domains, including the representative meta world benchmark, demonstrating its robustness in multi-task sparse-reward settings and its effective transferability to unseen tasks.","authors":["Haozhe Ma","Zhengding Luo","Thanh Vinh Vo","Kuankuan Sima","Tze-Yun Leong"],"url":"https://arxiv.org/abs/2408.10858"}
{"created":"2025-05-20","title":"LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction","abstract":"Large Language Models (LLMs) are increasingly adopted for applications in healthcare, reaching the performance of domain experts on tasks such as question answering and document summarisation. Despite their success on these tasks, it is unclear how well LLMs perform on tasks that are traditionally pursued in the biomedical domain, such as structured information extraction. To bridge this gap, in this paper, we systematically benchmark LLM performance in Medical Classification and Named Entity Recognition (NER) tasks. We aim to disentangle the contribution of different factors to the performance, particularly the impact of LLMs' task knowledge and reasoning capabilities, their (parametric) domain knowledge, and addition of external knowledge. To this end, we evaluate various open LLMs - including BioMistral and Llama-2 models - on a diverse set of biomedical datasets, using standard prompting, Chain of-Thought (CoT) and Self Consistency based reasoning as well as Retrieval-Augmented Generation (RAG) with PubMed and Wikipedia corpora. Counter intuitively, our results reveal that standard prompting consistently outperforms more complex techniques across both tasks, laying bare the limitations in the current application of CoT, self-consistency and RAG in the biomedical domain. Our findings suggest that advanced prompting methods developed for knowledge- or reasoning-intensive tasks, such as CoT or RAG, are not easily portable to biomedical tasks where precise structured outputs are required. This highlights the need for more effective integration of external knowledge and reasoning mechanisms in LLMs to enhance their performance in real-world biomedical applications.","authors":["Aishik Nagar","Viktor Schlegel","Thanh-Tung Nguyen","Hao Li","Yuping Wu","Kuluhan Binici","Stefan Winkler"],"url":"https://arxiv.org/abs/2408.12249"}
{"created":"2025-05-20","title":"Artificial Intelligence in Election Campaigns: Perceptions, Penalties, and Implications","abstract":"As political parties around the world experiment with Artificial Intelligence (AI) in election campaigns, concerns about deception and manipulation are rising. This article examines how the public reacts to different uses of AI in elections and the potential consequences for party evaluations and regulatory preferences. Across three preregistered studies with over 7,600 American respondents, we identify three categories of AI use -- campaign operations, voter outreach, and deception. While people generally dislike AI in campaigns, they are especially critical of deceptive uses, which they perceive as norm violations. However, parties engaging in AI-enabled deception face no significant drop in favorability, neither with supporters nor opponents. Instead, deceptive AI use increases public support for stricter AI regulation, including calls for an outright ban on AI development. These findings reveal a misalignment between public disapproval of deceptive AI and the political incentives of parties, underscoring the need for targeted regulatory oversight. Rather than banning AI in elections altogether, regulation should distinguish between harmful and beneficial applications to avoid stifling democratic innovation.","authors":["Andreas Jungherr","Adrian Rauchfleisch","Alexander Wuttke"],"url":"https://arxiv.org/abs/2408.12613"}
{"created":"2025-05-20","title":"BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks and Defenses on Large Language Models","abstract":"Generative large language models (LLMs) have achieved state-of-the-art results on a wide range of tasks, yet they remain susceptible to backdoor attacks: carefully crafted triggers in the input can manipulate the model to produce adversary-specified outputs. While prior research has predominantly focused on backdoor risks in vision and classification settings, the vulnerability of LLMs in open-ended text generation remains underexplored. To fill this gap, we introduce BackdoorLLM (Our BackdoorLLM benchmark was awarded First Prize in the SafetyBench competition, https://www.mlsafety.org/safebench/winners, organized by the Center for AI Safety, https://safe.ai/.), the first comprehensive benchmark for systematically evaluating backdoor threats in text-generation LLMs. BackdoorLLM provides: (i) a unified repository of benchmarks with a standardized training and evaluation pipeline; (ii) a diverse suite of attack modalities, including data poisoning, weight poisoning, hidden-state manipulation, and chain-of-thought hijacking; (iii) over 200 experiments spanning 8 distinct attack strategies, 7 real-world scenarios, and 6 model architectures; (iv) key insights into the factors that govern backdoor effectiveness and failure modes in LLMs; and (v) a defense toolkit encompassing 7 representative mitigation techniques. Our code and datasets are available at https://github.com/bboylyg/BackdoorLLM. We will continuously incorporate emerging attack and defense methodologies to support the research in advancing the safety and reliability of LLMs.","authors":["Yige Li","Hanxun Huang","Yunhan Zhao","Xingjun Ma","Jun Sun"],"url":"https://arxiv.org/abs/2408.12798"}
{"created":"2025-05-20","title":"CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution","abstract":"Code benchmarks such as HumanEval are widely adopted to evaluate Large Language Models' (LLMs) coding capabilities. However, there is an unignorable programming language bias in existing code benchmarks -- over 95% code generation benchmarks are dominated by Python, leaving the LLMs' capabilities in other programming languages such as Java and C/C++ unknown. Moreover, coding task bias is also crucial. Most benchmarks focus on code generation capability, while benchmarks for code reasoning (given input, reasoning output; and given output, reasoning input), an essential coding capability, are insufficient. Yet, constructing multi-lingual benchmarks can be expensive and labor-intensive, and codes in contest websites such as Leetcode suffer from data contamination during training. To fill this gap, we propose CRUXEVAL-X, a multi-lingual code reasoning benchmark that contains 19 programming languages. It comprises at least 600 subjects for each language, along with 19K content-consistent tests in total. In particular, the construction pipeline of CRUXEVAL-X works in a fully automated and test-guided manner, which iteratively generates and repairs based on execution feedback. Also, to cross language barriers (e.g., dynamic/static type systems in Python/C++), we formulated various transition rules between language pairs to facilitate translation. Our intensive evaluation of 24 representative LLMs reveals the correlation between language pairs. For example, TypeScript and JavaScript show a significant positive correlation, while Racket has less correlation with other languages. More interestingly, even a model trained solely on Python can achieve at most 34.4% Pass@1 in other languages, revealing the cross-language generalization of LLMs.","authors":["Ruiyang Xu","Jialun Cao","Yaojie Lu","Ming Wen","Hongyu Lin","Xianpei Han","Ben He","Shing-Chi Cheung","Le Sun"],"url":"https://arxiv.org/abs/2408.13001"}
{"created":"2025-05-20","title":"No Place for Old Memes: Large-scale Collective Dynamics in the Three Iterations of Reddit r/place","abstract":"Is there something akin to geopolitics for online communities? One could think of communities as nations formed around shared interests of individual users. Friendly borders capture similar interests, but conflicts could emerge due to ideological differences or competition for attention (as for land). Over time, new coalitions could emerge, others could crumble, and many could disappear as casualties of online wars with highly unpredictable and often devastating outcomes. The r/place experiment is the most ingenious attempt at reproducing this complex collective dynamics as a series of three social games hosted by Reddit. The result is not only an accurate picture of the diverse interests on Reddit -- one of the most popular social media platforms in the world -- but also fine-grained traces of sequential actions taken by millions of players during the game. In this paper, we are the first to characterize the collective behavior during r/place in terms of engagement, collaboration, and competition using tools from computational social science and data science. Our analysis shows that r/place reflected many patterns found in other relevant group decision-making processes, including empirical evidence for group coordination costs, social loafing, and increased cooperation as a response to competition. We discuss how our findings can support the development of new theoretical models, tools, and mechanisms to optimize collaborative-competitive processes in social networks.","authors":["Yutong Wu","Arlei Silva"],"url":"https://arxiv.org/abs/2408.13236"}
{"created":"2025-05-20","title":"On the performance of two-sided MPI, MPI-3 RMA and SHMEM in a Lagrangian particle cluster algorithm","abstract":"In this paper, we compare the parallel performance of three distributed-memory communication models for a cluster algorithm based on a nearest neighbour search algorithm for N-body simulations. The nearest neighbour is defined by the Euclidean distance in three-dimensional space. The resulting directed nearest neighbour graphs that are used to define the clusters are pruned in an iterative procedure where we use either point-to-point message passing interface (MPI), MPI-3 remote memory access (RMA), or SHMEM communication. The original algorithm has been developed and implemented as part of the elliptical parcel-in-cell (EPIC) method targeting geophysical fluid flows. The parallel scalability of the algorithm is discussed by means of an artificial and a standard fluid dynamics test case. Performance measurements were carried out on three different computing systems with InfiniBand FDR, Hewlett Packard Enterprise (HPE) Slingshot 10 or HPE Slingshot 200 interconnect.","authors":["Matthias Frey","Douglas Shanks","Steven B\\\"oing","Rui F. G. Ap\\'ostolo"],"url":"https://arxiv.org/abs/2408.15348"}
{"created":"2025-05-20","title":"Short-Term Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey","abstract":"Short-Term Electricity-Load Forecasting (STELF) refers to the prediction of the immediate demand (in the next few hours to several days) for the power system. Various external factors, such as weather changes and the emergence of new electricity consumption scenarios, can impact electricity demand, causing load data to fluctuate and become non-linear, which increases the complexity and difficulty of STELF. In the past decade, deep learning has been applied to STELF, modeling and predicting electricity demand with high accuracy, and contributing significantly to the development of STELF. This paper provides a comprehensive survey on deep-learning-based STELF over the past ten years. It examines the entire forecasting process, including data pre-processing, feature extraction, deep-learning modeling and optimization, and results evaluation. This paper also identifies some research challenges and potential research directions to be further investigated in future work.","authors":["Qi Dong","Rubing Huang","Chenhui Cui","Dave Towey","Ling Zhou","Jinyu Tian","Jianzhou Wang"],"url":"https://arxiv.org/abs/2408.16202"}
{"created":"2025-05-20","title":"Audio xLSTMs: Learning Self-Supervised Audio Representations with xLSTMs","abstract":"While the transformer has emerged as the eminent neural architecture, several independent lines of research have emerged to address its limitations. Recurrent neural approaches have observed a lot of renewed interest, including the extended long short-term memory (xLSTM) architecture, which reinvigorates the original LSTM. However, while xLSTMs have shown competitive performance compared to the transformer, their viability for learning self-supervised general-purpose audio representations has not been evaluated. This work proposes Audio xLSTM (AxLSTM), an approach for learning audio representations from masked spectrogram patches in a self-supervised setting. Pretrained on the AudioSet dataset, the proposed AxLSTM models outperform comparable self-supervised audio spectrogram transformer (SSAST) baselines by up to 25% in relative performance across a set of ten diverse downstream tasks while having up to 45% fewer parameters.","authors":["Sarthak Yadav","Sergios Theodoridis","Zheng-Hua Tan"],"url":"https://arxiv.org/abs/2408.16568"}
{"created":"2025-05-20","title":"RevCD -- Reversed Conditional Diffusion for Generalized Zero-Shot Learning","abstract":"In Generalized Zero-Shot Learning (GZSL), we aim to recognize both seen and unseen categories using a model trained only on seen categories. In computer vision, this translates into a classification problem, where knowledge from seen categories is transferred to unseen categories by exploiting the relationships between visual features and available semantic information, such as text corpora or manual annotations. However, learning this joint distribution is costly and requires one-to-one training with corresponding semantic information. We present a reversed conditional Diffusion-based model (RevCD) that mitigates this issue by generating semantic features synthesized from visual inputs by leveraging Diffusion models' conditional mechanisms. Our RevCD model consists of a cross Hadamard-Addition embedding of a sinusoidal time schedule and a multi-headed visual transformer for attention-guided embeddings. The proposed approach introduces three key innovations. First, we reverse the process of generating semantic space based on visual data, introducing a novel loss function that facilitates more efficient knowledge transfer. Second, we apply Diffusion models to zero-shot learning - a novel approach that exploits their strengths in capturing data complexity. Third, we demonstrate our model's performance through a comprehensive cross-dataset evaluation. The complete code will be available on GitHub.","authors":["William Heyden","Habib Ullah","M. Salman Siddiqui","Fadi Al Machot"],"url":"https://arxiv.org/abs/2409.00511"}
{"created":"2025-05-20","title":"DAOs of Collective Intelligence? Unraveling the Complexity of Blockchain Governance in Decentralized Autonomous Organizations","abstract":"Decentralized autonomous organizations (DAOs) have transformed organizational structures by shifting from traditional hierarchical control to decentralized approaches, leveraging blockchain and cryptoeconomics. Despite managing significant funds and building global networks, DAOs face challenges like declining participation, increasing centralization, and inabilities to adapt to changing environments, which stifle innovation. This paper explores DAOs as complex systems and applies complexity science to explain their inefficiencies. In particular, we discuss DAO challenges, their complex nature, and introduce the self-organization mechanisms of collective intelligence, digital democracy, and adaptation. By applying these mechanisms to refine DAO design and construction, a conceptual framework for assessing a DAO's viability is created. This contribution lays the foundation for future research at the intersection of complexity science, digital democracy and DAOs.","authors":["Mark C. Ballandies","Dino Carpentras","Evangelos Pournaras"],"url":"https://arxiv.org/abs/2409.01823"}
{"created":"2025-05-20","title":"What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices","abstract":"Recent advancements in large language models (LLMs) with extended context windows have significantly improved tasks such as information extraction, question answering, and complex planning scenarios. In order to achieve success in long context tasks, a large amount of work has been done to enhance the long context capabilities of the model through synthetic data. Existing methods typically utilize the Self-Instruct framework to generate instruction tuning data for better long context capability improvement. However, our preliminary experiments indicate that less than 35% of generated samples are multi-hop, and more than 40% exhibit poor quality, limiting comprehensive understanding and further research. To improve the quality of synthetic data, we propose the Multi-agent Interactive Multi-hop Generation (MIMG) framework, incorporating a Quality Verification Agent, a Single-hop Question Generation Agent, a Multiple Question Sampling Strategy, and a Multi-hop Question Merger Agent. This framework improves the data quality, with the proportion of high-quality, multi-hop, and diverse data exceeding 85%. Furthermore, we systematically investigate strategies for document selection, question merging, and validation techniques through extensive experiments across various models. Our findings show that our synthetic high-quality long-context instruction data significantly enhances model performance, even surpassing models trained on larger amounts of human-annotated data. Our code is available at: https://github.com/WowCZ/LongMIT.","authors":["Zhi Chen","Qiguang Chen","Libo Qin","Qipeng Guo","Haijun Lv","Yicheng Zou","Wanxiang Che","Hang Yan","Kai Chen","Dahua Lin"],"url":"https://arxiv.org/abs/2409.01893"}
{"created":"2025-05-20","title":"\"Yes, My LoRD.\" Guiding Language Model Extraction with Locality Reinforced Distillation","abstract":"Model extraction attacks (MEAs) on large language models (LLMs) have received increasing attention in recent research. However, existing attack methods typically adapt the extraction strategies originally developed for deep neural networks (DNNs). They neglect the underlying inconsistency between the training tasks of MEA and LLM alignment, leading to suboptimal attack performance. To tackle this issue, we propose Locality Reinforced Distillation (LoRD), a novel model extraction algorithm specifically designed for LLMs. In particular, LoRD employs a newly defined policy-gradient-style training task that utilizes the responses of victim model as the signal to guide the crafting of preference for the local model. Theoretical analyses demonstrate that I) The convergence procedure of LoRD in model extraction is consistent with the alignment procedure of LLMs, and II) LoRD can reduce query complexity while mitigating watermark protection through our exploration-based stealing. Extensive experiments validate the superiority of our method in extracting various state-of-the-art commercial LLMs. Our code is available at: https://github.com/liangzid/LoRD-MEA .","authors":["Zi Liang","Qingqing Ye","Yanyun Wang","Sen Zhang","Yaxin Xiao","Ronghua Li","Jianliang Xu","Haibo Hu"],"url":"https://arxiv.org/abs/2409.02718"}
{"created":"2025-05-20","title":"IR2: Implicit Rendezvous for Robotic Exploration Teams under Sparse Intermittent Connectivity","abstract":"Information sharing is critical in time-sensitive and realistic multi-robot exploration, especially for smaller robotic teams in large-scale environments where connectivity may be sparse and intermittent. Existing methods often overlook such communication constraints by assuming unrealistic global connectivity. Other works account for communication constraints (by maintaining close proximity or line of sight during information exchange), but are often inefficient. For instance, preplanned rendezvous approaches typically involve unnecessary detours resulting from poorly timed rendezvous, while pursuit-based approaches often result in short-sighted decisions due to their greedy nature. We present IR2, a deep reinforcement learning approach to information sharing for multi-robot exploration. Leveraging attention-based neural networks trained via reinforcement and curriculum learning, IR2 allows robots to effectively reason about the longer-term trade-offs between disconnecting for solo exploration and reconnecting for information sharing. In addition, we propose a hierarchical graph formulation to maintain a sparse yet informative graph, enabling our approach to scale to large-scale environments. We present simulation results in three large-scale Gazebo environments, which show that our approach yields 6.6-34.1% shorter exploration paths when compared to state-of-the-art baselines, and lastly deploy our learned policy on hardware. Our simulation training and testing code is available at https://ir2-explore.github.io.","authors":["Derek Ming Siang Tan","Yixiao Ma","Jingsong Liang","Yi Cheng Chng","Yuhong Cao","Guillaume Sartoretti"],"url":"https://arxiv.org/abs/2409.04730"}
{"created":"2025-05-20","title":"Adversarial Attacks on Data Attribution","abstract":"Data attribution aims to quantify the contribution of individual training data points to the outputs of an AI model, which has been used to measure the value of training data and compensate data providers. Given the impact on financial decisions and compensation mechanisms, a critical question arises concerning the adversarial robustness of data attribution methods. However, there has been little to no systematic research addressing this issue. In this work, we aim to bridge this gap by detailing a threat model with clear assumptions about the adversary's goal and capabilities and proposing principled adversarial attack methods on data attribution. We present two methods, Shadow Attack and Outlier Attack, which generate manipulated datasets to inflate the compensation adversarially. The Shadow Attack leverages knowledge about the data distribution in the AI applications, and derives adversarial perturbations through \"shadow training\", a technique commonly used in membership inference attacks. In contrast, the Outlier Attack does not assume any knowledge about the data distribution and relies solely on black-box queries to the target model's predictions. It exploits an inductive bias present in many data attribution methods - outlier data points are more likely to be influential - and employs adversarial examples to generate manipulated datasets. Empirically, in image classification and text generation tasks, the Shadow Attack can inflate the data-attribution-based compensation by at least 200%, while the Outlier Attack achieves compensation inflation ranging from 185% to as much as 643%. Our implementation is ready at https://github.com/TRAIS-Lab/adversarial-attack-data-attribution.","authors":["Xinhe Wang","Pingbang Hu","Junwei Deng","Jiaqi W. Ma"],"url":"https://arxiv.org/abs/2409.05657"}
{"created":"2025-05-20","title":"Zero-shot Outlier Detection via Prior-data Fitted Networks: Model Selection Bygone!","abstract":"Outlier detection (OD) has a vast literature as it finds numerous real-world applications. Being an unsupervised task, model selection is a key bottleneck for OD without label supervision. Despite a long list of available OD algorithms with tunable hyperparameters, the lack of systematic approaches for unsupervised algorithm and hyperparameter selection limits their effective use in practice. In this paper, we present FoMo-0D, a pre-trained Foundation Model for zero/0-shot OD on tabular data, which bypasses the hurdle of model selection altogether. Having been pre-trained on synthetic data, FoMo-0D can directly predict the (outlier/inlier) label of test samples without parameter fine-tuning -- requiring no labeled data, and no additional training or hyperparameter tuning when given a new task. Extensive experiments on 57 real-world datasets against 26 baselines show that FoMo-0D is highly competitive; outperforming the majority of the baselines with no statistically significant difference from the 2nd best method. Further, FoMo-0D is efficient in inference time requiring only 7.7 ms per sample on average, with at least 7x speed-up compared to previous methods. To facilitate future research, our implementations for data synthesis and pre-training as well as model checkpoints are openly available at https://anonymous.4open.science/r/PFN40D.","authors":["Yuchen Shen","Haomin Wen","Leman Akoglu"],"url":"https://arxiv.org/abs/2409.05672"}
{"created":"2025-05-20","title":"Re-evaluating the Advancements of Heterophilic Graph Learning","abstract":"Over the past decade, Graph Neural Networks (GNNs) have achieved great success on machine learning tasks with relational data. However, recent studies have found that heterophily can cause significant performance degradation of GNNs, especially on node-level tasks. Numerous heterophilic benchmark datasets have been put forward to validate the efficacy of heterophily-specific GNNs, and various homophily metrics have been designed to help recognize these challenging datasets. Nevertheless, there still exist multiple pitfalls that severely hinder the proper evaluation of new models and metrics: 1) lack of hyperparameter tuning; 2) insufficient evaluation on the truly challenging heterophilic datasets; 3) missing quantitative evaluation for homophily metrics on synthetic graphs. To overcome these challenges, we first train and fine-tune baseline models on $27$ most widely used benchmark datasets, and categorize them into three distinct groups: malignant, benign and ambiguous heterophilic datasets. We identify malignant and ambiguous heterophily as the truly challenging subsets of tasks, and to our best knowledge, we are the first to propose such taxonomy. Then, we re-evaluate $11$ state-of-the-arts (SOTA) GNNs, covering six popular methods, with fine-tuned hyperparameters on different groups of heterophilic datasets. Based on the model performance, we comprehensively reassess the effectiveness of different methods on heterophily. At last, we evaluate $11$ popular homophily metrics on synthetic graphs with three different graph generation approaches. To overcome the unreliability of observation-based comparison and evaluation, we conduct the first quantitative evaluation and provide detailed analysis.","authors":["Sitao Luan","Qincheng Lu","Chenqing Hua","Xinyu Wang","Jiaqi Zhu","Xiao-Wen Chang"],"url":"https://arxiv.org/abs/2409.05755"}
{"created":"2025-05-20","title":"Uniform Approximation of Eigenproblems of a Large-Scale Parameter-Dependent Hermitian Matrix","abstract":"We consider the uniform approximation of the smallest eigenvalue of a large parameter-dependent Hermitian matrix by that of a smaller counterpart obtained through projections. The projection subspaces are constructed iteratively by means of a greedy strategy; at each iteration the parameter where a surrogate error is maximal is computed and the eigenvectors associated with the smallest eigenvalues at the maximizing parameter value are added to the subspace. Unlike the classical approaches, such as the successive constraint method, that maximize such surrogate errors over a discrete and finite set, we maximize the surrogate error over the continuum of all permissible parameter values globally. We formally prove that the projected eigenvalue function converges to the actual eigenvalue function uniformly. In the second part, we focus on the uniform approximation of the smallest singular value of a large parameter-dependent matrix, in case it is non-Hermitian. The proposed frameworks on numerical examples, including those arising from discretizations of parametric PDEs, reduce the size of the large matrix-valued function drastically, while retaining a high accuracy over all permissible parameter values.","authors":["Mattia Manucci","Emre Mengi","Nicola Guglielmi"],"url":"https://arxiv.org/abs/2409.05791"}
{"created":"2025-05-20","title":"Learning Efficient Recursive Numeral Systems via Reinforcement Learning","abstract":"It has previously been shown that by using reinforcement learning (RL), agents can derive simple approximate and exact-restricted numeral systems that are similar to human ones (Carlsson, 2021). However, it is a major challenge to show how more complex recursive numeral systems, similar to for example English, could arise via a simple learning mechanism such as RL. Here, we introduce an approach towards deriving a mechanistic explanation of the emergence of efficient recursive number systems. We consider pairs of agents learning how to communicate about numerical quantities through a meta-grammar that can be gradually modified throughout the interactions. Utilising a slightly modified version of the meta-grammar of Hurford (1975), we demonstrate that our RL agents, shaped by the pressures for efficient communication, can effectively modify their lexicon towards Pareto-optimal configurations which are comparable to those observed within human numeral systems in terms of their efficiency.","authors":["Andrea Silvi","Jonathan Thomas","Emil Carlsson","Devdatt Dubhashi","Moa Johansson"],"url":"https://arxiv.org/abs/2409.07170"}
{"created":"2025-05-20","title":"Hacking, The Lazy Way: LLM Augmented Pentesting","abstract":"In our research, we introduce a new concept called \"LLM Augmented Pentesting\" demonstrated with a tool named \"Pentest Copilot,\" that revolutionizes the field of ethical hacking by integrating Large Language Models (LLMs) into penetration testing workflows, leveraging the advanced GPT-4-turbo model. Our approach focuses on overcoming the traditional resistance to automation in penetration testing by employing LLMs to automate specific sub-tasks while ensuring a comprehensive understanding of the overall testing process.","authors":["Dhruva Goyal","Sitaraman Subramanian","Aditya Peela","Nisha P. Shetty"],"url":"https://arxiv.org/abs/2409.09493"}
{"created":"2025-05-20","title":"Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant","abstract":"Quantization has gained attention as a promising solution for the cost-effective deployment of large and small language models. However, most prior work has been limited to perplexity or basic knowledge tasks and lacks a comprehensive evaluation of recent models like Llama-3.3. In this paper, we conduct a comprehensive evaluation of instruction-tuned models spanning 1B to 405B parameters, applying four quantization methods across 13 datasets. Our findings reveal that (1) quantized models generally surpass smaller FP16 baselines, yet they often struggle with instruction-following and hallucination detection; (2) FP8 consistently emerges as the most robust option across tasks, and AWQ tends to outperform GPTQ in weight-only quantization; (3) smaller models can suffer severe accuracy drops at 4-bit quantization, while 70B-scale models maintain stable performance; (4) notably, \\textit{hard} tasks do not always experience the largest accuracy losses, indicating that quantization magnifies a model's inherent weaknesses rather than simply correlating with task difficulty; and (5) an LLM-based judge (MT-Bench) highlights significant performance declines in Coding and STEM tasks, though it occasionally reports improvements in reasoning.","authors":["Jemin Lee","Sihyeong Park","Jinse Kwon","Jihun Oh","Yongin Kwon"],"url":"https://arxiv.org/abs/2409.11055"}
{"created":"2025-05-20","title":"Shape-Space Deformer: Unified Visuo-Tactile Representations for Robotic Manipulation of Deformable Objects","abstract":"Accurate modelling of object deformations is crucial for a wide range of robotic manipulation tasks, where interacting with soft or deformable objects is essential. Current methods struggle to generalise to unseen forces or adapt to new objects, limiting their utility in real-world applications. We propose Shape-Space Deformer, a unified representation for encoding a diverse range of object deformations using template augmentation to achieve robust, fine-grained reconstructions that are resilient to outliers and unwanted artefacts. Our method improves generalization to unseen forces and can rapidly adapt to novel objects, significantly outperforming existing approaches. We perform extensive experiments to test a range of force generalisation settings and evaluate our method's ability to reconstruct unseen deformations, demonstrating significant improvements in reconstruction accuracy and robustness. Our approach is suitable for real-time performance, making it ready for downstream manipulation applications.","authors":["Sean M. V. Collins","Brendan Tidd","Mahsa Baktashmotlagh","Peyman Moghadam"],"url":"https://arxiv.org/abs/2409.12419"}
{"created":"2025-05-20","title":"Revisiting Synthetic Human Trajectories: Imitative Generation and Benchmarks Beyond Datasaurus","abstract":"Human trajectory data, which plays a crucial role in various applications such as crowd management and epidemic prevention, is challenging to obtain due to practical constraints and privacy concerns. In this context, synthetic human trajectory data is generated to simulate as close as possible to real-world human trajectories, often under summary statistics and distributional similarities. However, these similarities oversimplify complex human mobility patterns (a.k.a. ``Datasaurus''), resulting in intrinsic biases in both generative model design and benchmarks of the generated trajectories. Against this background, we propose MIRAGE, a huMan-Imitative tRAjectory GenErative model designed as a neural Temporal Point Process integrating an Exploration and Preferential Return model. It imitates the human decision-making process in trajectory generation, rather than fitting any specific statistical distributions as traditional methods do, thus avoiding the Datasaurus issue. We also propose a comprehensive task-based evaluation protocol beyond Datasaurus to systematically benchmark trajectory generative models on four typical downstream tasks, integrating multiple techniques and evaluation metrics for each task, to assess the ultimate utility of the generated trajectories. We conduct a thorough evaluation of MIRAGE on three real-world user trajectory datasets against a sizeable collection of baselines. Results show that compared to the best baselines, MIRAGE-generated trajectory data not only achieves the best statistical and distributional similarities with 59.0-67.7% improvement, but also yields the best performance in the task-based evaluation with 10.9-33.4% improvement. A series of ablation studies also validate the key design choices of MIRAGE.","authors":["Bangchao Deng","Xin Jing","Tianyue Yang","Bingqing Qu","Dingqi Yang","Philippe Cudre-Mauroux"],"url":"https://arxiv.org/abs/2409.13790"}
{"created":"2025-05-20","title":"Scene-Text Grounding for Text-Based Video Question Answering","abstract":"Existing efforts in text-based video question answering (TextVideoQA) are criticized for their opaque decisionmaking and heavy reliance on scene-text recognition. In this paper, we propose to study Grounded TextVideoQA by forcing models to answer questions and spatio-temporally localize the relevant scene-text regions, thus decoupling QA from scenetext recognition and promoting research towards interpretable QA. The task has three-fold significance. First, it encourages scene-text evidence versus other short-cuts for answer predictions. Second, it directly accepts scene-text regions as visual answers, thus circumventing the problem of ineffective answer evaluation by stringent string matching. Third, it isolates the challenges inherited in VideoQA and scene-text recognition. This enables the diagnosis of the root causes for failure predictions, e.g., wrong QA or wrong scene-text recognition? To achieve Grounded TextVideoQA, we propose the T2S-QA model that highlights a disentangled temporal-to-spatial contrastive learning strategy for weakly-supervised scene-text grounding and grounded TextVideoQA. To facilitate evaluation, we construct a new dataset ViTXT-GQA which features 52K scene-text bounding boxes within 2.2K temporal segments related to 2K questions and 729 videos. With ViTXT-GQA, we perform extensive experiments and demonstrate the severe limitations of existing techniques in Grounded TextVideoQA. While T2S-QA achieves superior results, the large performance gap with human leaves ample space for improvement. Our further analysis of oracle scene-text inputs posits that the major challenge is scene-text recognition. To advance the research of Grounded TextVideoQA, our dataset and code are at https://github.com/zhousheng97/ViTXT-GQA.git","authors":["Sheng Zhou","Junbin Xiao","Xun Yang","Peipei Song","Dan Guo","Angela Yao","Meng Wang","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2409.14319"}
{"created":"2025-05-20","title":"Quantifying Context Bias in Domain Adaptation for Object Detection","abstract":"Domain adaptation for object detection (DAOD) seeks to transfer a trained model from a source to a target domain. Various DAOD methods exist, some of which aim to minimize context bias between foreground-background associations in various domains. However, no prior work has studied context bias in DAOD by analyzing changes in background features during adaptation and how context bias is represented in different domains. Our research experiment highlights the potential usability of context bias in DAOD. We address the problem by varying activation values over different layers of two different trained models, Detectron2 and YOLOv11, and by masking the background, both of which impact the number and quality of detections. We use two synthetic datasets, CARLA and Virtual KITTI, and two different versions of real open-source data, Cityscapes and KITTI semantic, as separate domains to represent and quantify context bias. We utilize different metrics such as Maximum Mean Discrepancy (MMD) and Maximum Variance Discrepancy (MVD) to find the layer-specific conditional probability estimates of foreground given manipulated background regions for separate domains. We further analyze foreground-background associations across various dataset combinations. We find that state-of-the-art domain adaptation methods exhibit some form of context bias and apply a potentially simple way to alleviate the context bias achieving improved accuracy (from 51.189 to 53.646 mAP on Cityscapes foggy validation with 63.207 mAP and 64.233 mAP on Cityscapes validation respectively). We demonstrate through detailed analysis that understanding of the context bias can affect DAOD approach and focusing solely on aligning foreground features is insufficient for effective DAOD.","authors":["Hojun Son","Asma Almutairi","Arpan Kusari"],"url":"https://arxiv.org/abs/2409.14679"}
{"created":"2025-05-20","title":"PseudoNeg-MAE: Self-Supervised Point Cloud Learning using Conditional Pseudo-Negative Embeddings","abstract":"We propose PseudoNeg-MAE, a novel self-supervised learning framework that enhances global feature representation of point cloud masked autoencoder by making them both discriminative and sensitive to transformations. Traditional contrastive learning methods focus on achieving invariance, discarding transformation-specific information. Recent approaches incorporate transformation sensitivity by explicitly modeling relationships between original and transformed inputs. However, they report an invariant-collapse phenomenon, where the predictor degenerates into identity mappings, resulting in latent representations that have limited variation across transformations. We propose a novel loss that explicitly penalizes invariant collapse, enabling the network to capture richer transformation cues while preserving discriminative representations. PseudoNeg-MAE uses a parametric network COPE, which learns the localized displacements caused by transformations within the latent space. However, jointly training COPE with the MAE leads to undesirable trivial solutions where COPE outputs collapse to an identity. To address this, we propose a loss that uses transformation-conditioned pseudo-negatives, to penalize such trivial invariant solutions. We validate PseudoNeg-MAE on shape classification and relative pose estimation tasks, where it achieves competitive performance on the ModelNet40 and ScanObjectNN datasets under challenging evaluation protocols and demonstrates superior accuracy in estimating relative poses compared to supervised methods.","authors":["Sutharsan Mahendren","Saimunur Rahman","Piotr Koniusz","Tharindu Fernando","Sridha Sridharan","Clinton Fookes","Peyman Moghadam"],"url":"https://arxiv.org/abs/2409.15832"}
{"created":"2025-05-20","title":"A Deeper Look into Second-Order Feature Aggregation for LiDAR Place Recognition","abstract":"Efficient LiDAR Place Recognition (LPR) compresses dense pointwise features into compact global descriptors. While first-order aggregators such as GeM and NetVLAD are widely used, they overlook inter-feature correlations that second-order aggregation naturally captures. Full covariance, a common second-order aggregator, is high in dimensionality; as a result, practitioners often insert a learned projection or employ random sketches -- both of which either sacrifice information or increase parameter count. However, no prior work has systematically investigated how first- and second-order aggregation perform under constrained feature and compute budgets. In this paper, we first demonstrate that second-order aggregation retains its superiority for LPR even when channels are pruned and backbone parameters are reduced. Building on this insight, we propose Channel Partition-based Second-order Local Feature Aggregation (CPS): a drop-in, partition-based second-order aggregation module that preserves all channels while producing an order-of-magnitude smaller descriptor. CPS matches or exceeds the performance of full covariance and outperforms random projection variants, delivering new state-of-the-art results with only four additional learnable parameters across four large-scale benchmarks: Oxford RobotCar, In-house, MulRan, and WildPlaces.","authors":["Saimunur Rahman","Peyman Moghadam"],"url":"https://arxiv.org/abs/2409.15919"}
{"created":"2025-05-20","title":"Underwater Camouflaged Object Tracking Meets Vision-Language SAM2","abstract":"Over the past decade, significant progress has been made in visual object tracking, largely due to the availability of large-scale datasets. However, these datasets have primarily focused on open-air scenarios and have largely overlooked underwater animal tracking-especially the complex challenges posed by camouflaged marine animals. To bridge this gap, we take a step forward by proposing the first large-scale multi-modal underwater camouflaged object tracking dataset, namely UW-COT220. Based on the proposed dataset, this work first comprehensively evaluates current advanced visual object tracking methods, including SAM- and SAM2-based trackers, in challenging underwater environments, \\eg, coral reefs. Our findings highlight the improvements of SAM2 over SAM, demonstrating its enhanced ability to handle the complexities of underwater camouflaged objects. Furthermore, we propose a novel vision-language tracking framework called VL-SAM2, based on the video foundation model SAM2. Extensive experimental results demonstrate that the proposed VL-SAM2 achieves state-of-the-art performance across underwater and open-air object tracking datasets. The dataset and codes are available at~{\\color{magenta}{https://github.com/983632847/Awesome-Multimodal-Object-Tracking}}.","authors":["Chunhui Zhang","Li Liu","Guanjie Huang","Zhipeng Zhang","Hao Wen","Xi Zhou","Shiming Ge","Yanfeng Wang"],"url":"https://arxiv.org/abs/2409.16902"}
{"created":"2025-05-20","title":"AXIS: Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents","abstract":"Multimodal large language models (MLLMs) have enabled LLM-based agents to directly interact with application user interfaces (UIs), enhancing agents' performance in complex tasks. However, these agents often suffer from high latency and low reliability due to the extensive sequential UI interactions. To address this issue, we propose AXIS, a novel LLM-based agents framework that prioritize actions through application programming interfaces (APIs) over UI actions. This framework also facilitates the creation and expansion of APIs through automated exploration of applications. Our experiments on Microsoft Word demonstrate that AXIS reduces task completion time by 65%-70% and cognitive workload by 38%-53%, while maintaining accuracy of 97%-98% compared to humans. Our work contributes to a new human-agent-computer interaction (HACI) framework and explores a fresh UI design principle for application providers to turn applications into agents in the era of LLMs, paving the way towards an agent-centric operating system (Agent OS).","authors":["Junting Lu","Zhiyang Zhang","Fangkai Yang","Jue Zhang","Lu Wang","Chao Du","Qingwei Lin","Saravan Rajmohan","Dongmei Zhang","Qi Zhang"],"url":"https://arxiv.org/abs/2409.17140"}
{"created":"2025-05-20","title":"CAMOT: Camera Angle-aware Multi-Object Tracking","abstract":"This paper proposes CAMOT, a simple camera angle estimator for multi-object tracking to tackle two problems: 1) occlusion and 2) inaccurate distance estimation in the depth direction. Under the assumption that multiple objects are located on a flat plane in each video frame, CAMOT estimates the camera angle using object detection. In addition, it gives the depth of each object, enabling pseudo-3D MOT. We evaluated its performance by adding it to various 2D MOT methods on the MOT17 and MOT20 datasets and confirmed its effectiveness. Applying CAMOT to ByteTrack, we obtained 63.8% HOTA, 80.6% MOTA, and 78.5% IDF1 in MOT17, which are state-of-the-art results. Its computational cost is significantly lower than the existing deep-learning-based depth estimators for tracking.","authors":["Felix Limanta","Kuniaki Uto","Koichi Shinoda"],"url":"https://arxiv.org/abs/2409.17533"}
{"created":"2025-05-20","title":"Benign Overfitting in Token Selection of Attention Mechanism","abstract":"Attention mechanism is a fundamental component of the transformer model and plays a significant role in its success. However, the theoretical understanding of how attention learns to select tokens is still an emerging area of research. In this work, we study the training dynamics and generalization ability of the attention mechanism under classification problems with label noise. We show that, with the characterization of signal-to-noise ratio (SNR), the token selection of attention mechanism achieves benign overfitting, i.e., maintaining high generalization performance despite fitting label noise. Our work also demonstrates an interesting delayed acquisition of generalization after an initial phase of overfitting. Finally, we provide experiments to support our theoretical analysis using both synthetic and real-world datasets.","authors":["Keitaro Sakamoto","Issei Sato"],"url":"https://arxiv.org/abs/2409.17625"}
{"created":"2025-05-20","title":"Towards Safe and Efficient Through-the-Canopy Autonomous Fruit Counting with UAVs","abstract":"We present an autonomous aerial system for safe and efficient through-the-canopy fruit counting. Aerial robot applications in large-scale orchards face significant challenges due to the complexity of fine-tuning flight paths based on orchard layouts, canopy density, and plant variability. Through-the-canopy navigation is crucial for minimizing occlusion by leaves and branches but is more challenging due to the complex and dense environment compared to traditional over-the-canopy flights. Our system addresses these challenges by integrating: i) a high-fidelity simulation framework for optimizing flight trajectories, ii) a low-cost autonomy stack for canopy-level navigation and data collection, and iii) a robust workflow for fruit detection and counting using RGB images. We validate our approach through fruit counting with canopy-level aerial images and by demonstrating the autonomous navigation capabilities of our experimental vehicle.","authors":["Teaya Yang","Roman Ibrahimov","Mark W. Mueller"],"url":"https://arxiv.org/abs/2409.18293"}
{"created":"2025-05-20","title":"Mitigating Selection Bias with Node Pruning and Auxiliary Options","abstract":"Large language models (LLMs) often exhibit systematic preferences for certain answer choices when responding to multiple-choice questions-a behavior known as selection bias. This bias reduces the accuracy and reliability of LLM outputs, limiting their usefulness in decision-critical applications. While prior work has focused on adjusting model inputs or outputs to mitigate this issue, our work takes a fundamentally different approach by identifying and removing the internal sources of bias. We introduce two methods: Bias Node Pruning (BNP), which prunes parameters that contribute to selection bias, and Auxiliary Option Injection (AOI), which introduces an additional answer choice to reduce bias in both white-box and black-box settings. To address the shortcomings of existing evaluation metrics, we propose Choice Kullback-Leibler Divergence (CKLD), a new metric that captures distributional imbalances in model predictions. Experiments on three LLMs across multiple datasets demonstrate that our methods consistently improve answer accuracy while reducing selection bias, providing a robust solution for both open- and closed-source models.","authors":["Hyeong Kyu Choi","Weijie Xu","Chi Xue","Stephanie Eckman","Chandan K. Reddy"],"url":"https://arxiv.org/abs/2409.18857"}
{"created":"2025-05-20","title":"PACE: Abstractions for Communicating Efficiently","abstract":"A central but unresolved aspect of problem-solving in AI is the capability to introduce and use abstractions, something humans excel at. Work in cognitive science has demonstrated that humans tend towards higher levels of abstraction when engaged in collaborative task-oriented communication, enabling gradually shorter and more information-efficient utterances. Several computational methods have attempted to replicate this phenomenon, but all make unrealistic simplifying assumptions about how abstractions are introduced and learned. Our method, Procedural Abstractions for Communicating Efficiently (PACE), overcomes these limitations through a neuro-symbolic approach. On the symbolic side, we draw on work from library learning for proposing abstractions. We combine this with neural methods for communication and reinforcement learning, via a novel use of bandit algorithms for controlling the exploration and exploitation trade-off in introducing new abstractions. PACE exhibits similar tendencies to humans on a collaborative construction task from the cognitive science literature, where one agent (the architect) instructs the other (the builder) to reconstruct a scene of block-buildings. PACE results in the emergence of an efficient language as a by-product of collaborative communication. Beyond providing mechanistic insights into human communication, our work serves as a first step to providing conversational agents with the ability for human-like communicative abstractions.","authors":["Jonathan D. Thomas","Andrea Silvi","Devdatt Dubhashi","Moa Johansson"],"url":"https://arxiv.org/abs/2409.20120"}
{"created":"2025-05-20","title":"SetPINNs: Set-based Physics-informed Neural Networks","abstract":"Physics-Informed Neural Networks (PINNs) solve partial differential equations using deep learning. However, conventional PINNs perform pointwise predictions that neglect dependencies within a domain, which may result in suboptimal solutions. We introduce SetPINNs, a framework that effectively captures local dependencies. With a finite element-inspired sampling scheme, we partition the domain into sets to model local dependencies while simultaneously enforcing physical laws. We provide a rigorous theoretical analysis showing that SetPINNs yield unbiased, lower-variance estimates of residual energy and its gradients, ensuring improved domain coverage and reduced residual error. Extensive experiments on synthetic and real-world tasks show improved accuracy, efficiency, and robustness.","authors":["Mayank Nagda","Phil Ostheimer","Thomas Specht","Frank Rhein","Fabian Jirasek","Stephan Mandt","Marius Kloft","Sophie Fellenz"],"url":"https://arxiv.org/abs/2409.20206"}
{"created":"2025-05-20","title":"SSR: Alignment-Aware Modality Connector for Speech Language Models","abstract":"Fusing speech into pre-trained language model (SpeechLM) usually suffers from inefficient encoding of long-form speech and catastrophic forgetting of pre-trained text modality. We propose SSR-Connector (Segmented Speech Representation Connector) for better modality fusion. Leveraging speech-text alignments, our approach segments and compresses speech features to match the granularity of text embeddings. Additionally, we introduce a two-stage training pipeline that includes the distillation and fine-tuning phases to mitigate catastrophic forgetting. SSR-Connector outperforms existing mechanism for speech-text modality fusion, consistently achieving better speech understanding (e.g., +10 accuracy on StoryCloze and +20 on Speech-MMLU) while preserving pre-trained text ability.","authors":["Weiting Tan","Hirofumi Inaguma","Ning Dong","Paden Tomasello","Xutai Ma"],"url":"https://arxiv.org/abs/2410.00168"}
{"created":"2025-05-20","title":"LoRanPAC: Low-rank Random Features and Pre-trained Models for Bridging Theory and Practice in Continual Learning","abstract":"The goal of continual learning (CL) is to train a model that can solve multiple tasks presented sequentially. Recent CL approaches have achieved strong performance by leveraging large pre-trained models that generalize well to downstream tasks. However, such methods lack theoretical guarantees, making them prone to unexpected failures. Conversely, principled CL approaches often fail to achieve competitive performance. In this work, we aim to bridge this gap between theory and practice by designing a simple CL method that is theoretically sound and highly performant. Specifically, we lift pre-trained features into a higher dimensional space and formulate an over-parametrized minimum-norm least-squares problem. We find that the lifted features are highly ill-conditioned, potentially leading to large training errors (numerical instability) and increased generalization errors. We address these challenges by continually truncating the singular value decomposition of the lifted features. Our approach, termed LoRanPAC, is stable with respect to the choice of hyperparameters, can handle hundreds of tasks, and outperforms state-of-the-art CL methods on multiple datasets. Importantly, our method satisfies a recurrence relation throughout its continual learning process, which allows us to prove it maintains small training and test errors by appropriately truncating a fraction of SVD factors. This results in a stable continual learning method with strong empirical performance and theoretical guarantees. Code available: https://github.com/liangzu/loranpac.","authors":["Liangzu Peng","Juan Elenter","Joshua Agterberg","Alejandro Ribeiro","Ren\\'e Vidal"],"url":"https://arxiv.org/abs/2410.00645"}
{"created":"2025-05-20","title":"Stable Offline Value Function Learning with Bisimulation-based Representations","abstract":"In reinforcement learning, offline value function learning is the procedure of using an offline dataset to estimate the expected discounted return from each state when taking actions according to a fixed target policy. The stability of this procedure, i.e., whether it converges to its fixed-point, critically depends on the representations of the state-action pairs. Poorly learned representations can make value function learning unstable, or even divergent. Therefore, it is critical to stabilize value function learning by explicitly shaping the state-action representations. Recently, the class of bisimulation-based algorithms have shown promise in shaping representations for control. However, it is still unclear if this class of methods can \\emph{stabilize} value function learning. In this work, we investigate this question and answer it affirmatively. We introduce a bisimulation-based algorithm called kernel representations for offline policy evaluation (\\textsc{krope}). \\textsc{krope} uses a kernel to shape state-action representations such that state-action pairs that have similar immediate rewards and lead to similar next state-action pairs under the target policy also have similar representations. We show that \\textsc{krope}: 1) learns stable representations and 2) leads to lower value error than baselines. Our analysis provides new theoretical insight into the stability properties of bisimulation-based methods and suggests that practitioners can use these methods to improve the stability and accuracy of offline evaluation of reinforcement learning agents.","authors":["Brahma S. Pavse","Yudong Chen","Qiaomin Xie","Josiah P. Hanna"],"url":"https://arxiv.org/abs/2410.01643"}
{"created":"2025-05-20","title":"Deep Koopman-layered Model with Universal Property Based on Toeplitz Matrices","abstract":"We propose deep Koopman-layered models with learnable parameters in the form of Toeplitz matrices for analyzing the transition of the dynamics of time-series data. The proposed model has both theoretical solidness and flexibility. By virtue of the universal property of Toeplitz matrices and the reproducing property underlying the model, we show its universality and generalization property. In addition, the flexibility of the proposed model enables the model to fit time-series data coming from nonautonomous dynamical systems. When training the model, we apply Krylov subspace methods for efficient computations, which establish a new connection between Koopman operators and numerical linear algebra. We also empirically demonstrate that the proposed model outperforms existing methods on eigenvalue estimation of multiple Koopman operators for nonautonomous systems.","authors":["Yuka Hashimoto","Tomoharu Iwata"],"url":"https://arxiv.org/abs/2410.02199"}
{"created":"2025-05-20","title":"Immunogenicity Prediction with Dual Attention Enables Vaccine Target Selection","abstract":"Immunogenicity prediction is a central topic in reverse vaccinology for finding candidate vaccines that can trigger protective immune responses. Existing approaches typically rely on highly compressed features and simple model architectures, leading to limited prediction accuracy and poor generalizability. To address these challenges, we introduce VenusVaccine, a novel deep learning solution with a dual attention mechanism that integrates pre-trained latent vector representations of protein sequences and structures. We also compile the most comprehensive immunogenicity dataset to date, encompassing over 7000 antigen sequences, structures, and immunogenicity labels from bacteria, virus, and tumor. Extensive experiments demonstrate that VenusVaccine outperforms existing methods across a wide range of evaluation metrics. Furthermore, we establish a post-hoc validation protocol to assess the practical significance of deep learning models in tackling vaccine design challenges. Our work provides an effective tool for vaccine design and sets valuable benchmarks for future research. The implementation is at https://github.com/songleee/VenusVaccine.","authors":["Song Li","Yang Tan","Song Ke","Liang Hong","Bingxin Zhou"],"url":"https://arxiv.org/abs/2410.02647"}
{"created":"2025-05-20","title":"LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations","abstract":"Large language models (LLMs) often produce errors, including factual inaccuracies, biases, and reasoning failures, collectively referred to as \"hallucinations\". Recent studies have demonstrated that LLMs' internal states encode information regarding the truthfulness of their outputs, and that this information can be utilized to detect errors. In this work, we show that the internal representations of LLMs encode much more information about truthfulness than previously recognized. We first discover that the truthfulness information is concentrated in specific tokens, and leveraging this property significantly enhances error detection performance. Yet, we show that such error detectors fail to generalize across datasets, implying that -- contrary to prior claims -- truthfulness encoding is not universal but rather multifaceted. Next, we show that internal representations can also be used for predicting the types of errors the model is likely to make, facilitating the development of tailored mitigation strategies. Lastly, we reveal a discrepancy between LLMs' internal encoding and external behavior: they may encode the correct answer, yet consistently generate an incorrect one. Taken together, these insights deepen our understanding of LLM errors from the model's internal perspective, which can guide future research on enhancing error analysis and mitigation.","authors":["Hadas Orgad","Michael Toker","Zorik Gekhman","Roi Reichart","Idan Szpektor","Hadas Kotek","Yonatan Belinkov"],"url":"https://arxiv.org/abs/2410.02707"}
{"created":"2025-05-20","title":"CounterQuill: Investigating the Potential of Human-AI Collaboration in Online Counterspeech Writing","abstract":"Online hate speech has become increasingly prevalent on social media, causing harm to individuals and society. While automated content moderation has received considerable attention, user-driven counterspeech remains a less explored yet promising approach. However, many people face difficulties in crafting effective responses. We introduce CounterQuill, a human-AI collaborative system that helps everyday users with writing empathetic counterspeech, not by generating automatic replies, but by educating them through reflection and response. CounterQuill follows a three-stage workflow grounded in computational thinking: (1) a learning session to build understanding of hate speech and counterspeech, (2) a brainstorming session to identify harmful patterns and ideate counterspeech ideas, and (3) a co-writing session that helps users refine their counter responses while preserving personal voice. Through a user study \\r{ho}(N=20), we found that CounterQuill helped participants develop the skills to brainstorm and draft counterspeech with increased confidence and control throughout the process. Our findings highlight how AI systems can scaffold complex communication tasks through structured, human-centered workflows that educate users on how to recognize, reflect on, and respond to online hate speech.","authors":["Xiaohan Ding","Kaike Ping","Uma Sushmitha Gunturi","Buse Carik","Sophia Stil","Lance T Wilhelm","Taufiq Daryanto","James Hawdon","Sang Won Lee","Eugenia H Rho"],"url":"https://arxiv.org/abs/2410.03032"}
{"created":"2025-05-20","title":"Cayley Graph Propagation","abstract":"In spite of the plethora of success stories with graph neural networks (GNNs) on modelling graph-structured data, they are notoriously vulnerable to over-squashing, whereby tasks necessitate the mixing of information between distance pairs of nodes. To address this problem, prior work suggests rewiring the graph structure to improve information flow. Alternatively, a significant body of research has dedicated itself to discovering and precomputing bottleneck-free graph structures to ameliorate over-squashing. One well regarded family of bottleneck-free graphs within the mathematical community are expander graphs, with prior work -- Expander Graph Propagation (EGP) -- proposing the use of a well-known expander graph family -- the Cayley graphs of the $\\mathrm{SL}(2,\\mathbb{Z}_n)$ special linear group -- as a computational template for GNNs. However, in EGP the computational graphs used are truncated to align with a given input graph. In this work, we show that truncation is detrimental to the coveted expansion properties. Instead, we propose CGP, a method to propagate information over a complete Cayley graph structure, thereby ensuring it is bottleneck-free to better alleviate over-squashing. Our empirical evidence across several real-world datasets not only shows that CGP recovers significant improvements as compared to EGP, but it is also akin to or outperforms computationally complex graph rewiring techniques.","authors":["JJ Wilson","Maya Bechler-Speicher","Petar Veli\\v{c}kovi\\'c"],"url":"https://arxiv.org/abs/2410.03424"}
{"created":"2025-05-20","title":"Repurposing Foundation Model for Generalizable Medical Time Series Classification","abstract":"Medical time series (MedTS) classification suffers from poor generalizability in real-world deployment due to inter- and intra-dataset heterogeneity, such as varying numbers of channels, signal lengths, task definitions, and patient characteristics. To address this, we propose FORMED, a novel framework for repurposing a backbone foundation model, pre-trained on generic time series, to enable highly generalizable MedTS classification on unseen datasets. FORMED combines the backbone with a novel classifier comprising two components: (1) task-specific channel embeddings and label queries, dynamically sized to match any number of channels and target classes, and (2) a shared decoding attention layer, jointly trained across datasets to capture medical domain knowledge through task-agnostic feature-query interactions. After repurposing, FORMED achieves seamless adaptation to unseen MedTS datasets through lightweight label query training (0.1% of parameters), eliminating the need for full fine-tuning or architectural redesign. We evaluate FORMED on 5 diverse MedTS datasets, benchmarking against 11 Task-Specific Models (TSM) and 4 Task-Specific Adaptation (TSA) methods. Our results demonstrate FORMED's dominant performance, achieving up to 35% absolute improvement in F1-score (on ADFTD dataset) over specialized baselines. Further analysis reveals consistent generalization across varying channel configurations, time series lengths, and clinical tasks, which are key challenges in real-world deployment. By decoupling domain-invariant representation learning from task-specific adaptation, FORMED establishes a scalable and resource-efficient paradigm for foundation model repurposing in healthcare. This approach prioritizes clinical adaptability over rigid task-centric design, offering a practical pathway for real-world implementation.","authors":["Nan Huang","Haishuai Wang","Zihuai He","Marinka Zitnik","Xiang Zhang"],"url":"https://arxiv.org/abs/2410.03794"}
{"created":"2025-05-20","title":"Decoding Game: On Minimax Optimality of Heuristic Text Generation Strategies","abstract":"Decoding strategies play a pivotal role in text generation for modern language models, yet a puzzling gap divides theory and practice. Surprisingly, strategies that should intuitively be optimal, such as Maximum a Posteriori (MAP), often perform poorly in practice. Meanwhile, popular heuristic approaches like Top-$k$ and Nucleus sampling, which employ truncation and normalization of the conditional next-token probabilities, have achieved great empirical success but lack theoretical justifications. In this paper, we propose Decoding Game, a comprehensive theoretical framework which reimagines text generation as a two-player zero-sum game between Strategist, who seeks to produce text credible in the true distribution, and Nature, who distorts the true distribution adversarially. After discussing the decomposibility of multi-step generation, we derive the optimal strategy in closed form for one-step Decoding Game. It is shown that the adversarial Nature imposes an implicit regularization on likelihood maximization, and truncation-normalization methods are first-order approximations to the optimal strategy under this regularization. Additionally, by generalizing the objective and parameters of Decoding Game, near-optimal strategies encompass diverse methods such as greedy search, temperature scaling, and hybrids thereof. Numerical experiments are conducted to complement our theoretical analysis.","authors":["Sijin Chen","Omar Hagrass","Jason M. Klusowski"],"url":"https://arxiv.org/abs/2410.03968"}
{"created":"2025-05-20","title":"VisDiff: SDF-Guided Polygon Generation for Visibility Reconstruction and Recognition","abstract":"The ability to capture rich representations of combinatorial structures has enabled the application of machine learning to tasks such as analysis and generation of floorplans, terrains, images, and animations. Recent work has primarily focused on understanding structures with well-defined features, neighborhoods, or underlying distance metrics, while those lacking such characteristics remain largely unstudied. Examples of these combinatorial structures can be found in polygons, where a small change in the vertex locations causes a significant rearrangement of the combinatorial structure, expressed as a visibility or triangulation graphs. Current representation learning approaches fail to capture structures without well-defined features and distance metrics. In this paper, we study the open problem of Visibility Reconstruction: Given a visibility graph $G$, construct a polygon $P$ whose visibility graph is $G$. We introduce VisDiff, a novel diffusion-based approach to generate polygon $P$ from the input visibility graph $G$. The main novelty of our approach is that, rather than generating the polygon's vertex set directly, we first estimate the signed distance function (SDF) associated with the polygon. The SDF is then used to extract the vertex location representing the final polygon. We show that going through the SDF allows VisDiff to learn the visibility relationship much more effectively than generating vertex locations directly. In order to train VisDiff, we create a carefully curated dataset. We use this dataset to benchmark our method and achieve 26% improvement in F1-Score over standard methods as well as state of the art approaches.","authors":["Rahul Moorthy","Volkan Isler"],"url":"https://arxiv.org/abs/2410.05530"}
{"created":"2025-05-20","title":"Rodimus*: Breaking the Accuracy-Efficiency Trade-Off with Efficient Attentions","abstract":"Recent advancements in Transformer-based large language models (LLMs) have set new standards in natural language processing. However, the classical softmax attention incurs significant computational costs, leading to a $O(T)$ complexity for per-token generation, where $T$ represents the context length. This work explores reducing LLMs' complexity while maintaining performance by introducing Rodimus and its enhanced version, Rodimus$+$. Rodimus employs an innovative data-dependent tempered selection (DDTS) mechanism within a linear attention-based, purely recurrent framework, achieving significant accuracy while drastically reducing the memory usage typically associated with recurrent models. This method exemplifies semantic compression by maintaining essential input information with fixed-size hidden states. Building on this, Rodimus$+$ combines Rodimus with the innovative Sliding Window Shared-Key Attention (SW-SKA) in a hybrid approach, effectively leveraging the complementary semantic, token, and head compression techniques. Our experiments demonstrate that Rodimus$+$-1.6B, trained on 1 trillion tokens, achieves superior downstream performance against models trained on more tokens, including Qwen2-1.5B and RWKV6-1.6B, underscoring its potential to redefine the accuracy-efficiency balance in LLMs. Model code and pre-trained checkpoints are open-sourced at https://github.com/codefuse-ai/rodimus.","authors":["Zhihao He","Hang Yu","Zi Gong","Shizhan Liu","Jianguo Li","Weiyao Lin"],"url":"https://arxiv.org/abs/2410.06577"}
{"created":"2025-05-20","title":"ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness in Web Agents","abstract":"Autonomous web agents solve complex browsing tasks, yet existing benchmarks measure only whether an agent finishes a task, ignoring whether it does so safely or in a way enterprises can trust. To integrate these agents into critical workflows, safety and trustworthiness (ST) are prerequisite conditions for adoption. We introduce \\textbf{\\textsc{ST-WebAgentBench}}, a configurable and easily extensible suite for evaluating web agent ST across realistic enterprise scenarios. Each of its 222 tasks is paired with ST policies, concise rules that encode constraints, and is scored along six orthogonal dimensions (e.g., user consent, robustness). Beyond raw task success, we propose the \\textit{Completion Under Policy} (\\textit{CuP}) metric, which credits only completions that respect all applicable policies, and the \\textit{Risk Ratio}, which quantifies ST breaches across dimensions. Evaluating three open state-of-the-art agents reveals that their average CuP is less than two-thirds of their nominal completion rate, exposing critical safety gaps. By releasing code, evaluation templates, and a policy-authoring interface, \\href{https://sites.google.com/view/st-webagentbench/home}{\\textsc{ST-WebAgentBench}} provides an actionable first step toward deploying trustworthy web agents at scale.","authors":["Ido Levy","Ben Wiesel","Sami Marreed","Alon Oved","Avi Yaeli","Segev Shlomov"],"url":"https://arxiv.org/abs/2410.06703"}
{"created":"2025-05-20","title":"MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses","abstract":"Scientific discovery plays a pivotal role in advancing human society, and recent progress in large language models (LLMs) suggests their potential to accelerate this process. However, it remains unclear whether LLMs can autonomously generate novel and valid hypotheses in chemistry. In this work, we investigate whether LLMs can discover high-quality chemistry hypotheses given only a research background-comprising a question and/or a survey-without restriction on the domain of the question. We begin with the observation that hypothesis discovery is a seemingly intractable task. To address this, we propose a formal mathematical decomposition grounded in a fundamental assumption: that most chemistry hypotheses can be composed from a research background and a set of inspirations. This decomposition leads to three practical subtasks-retrieving inspirations, composing hypotheses with inspirations, and ranking hypotheses - which together constitute a sufficient set of subtasks for the overall scientific discovery task. We further develop an agentic LLM framework, MOOSE-Chem, that is a direct implementation of this mathematical decomposition. To evaluate this framework, we construct a benchmark of 51 high-impact chemistry papers published and online after January 2024, each manually annotated by PhD chemists with background, inspirations, and hypothesis. The framework is able to rediscover many hypotheses with high similarity to the groundtruth, successfully capturing the core innovations-while ensuring no data contamination since it uses an LLM with knowledge cutoff date prior to 2024. Finally, based on LLM's surprisingly high accuracy on inspiration retrieval, a task with inherently out-of-distribution nature, we propose a bold assumption: that LLMs may already encode latent scientific knowledge associations not yet recognized by humans.","authors":["Zonglin Yang","Wanhao Liu","Ben Gao","Tong Xie","Yuqiang Li","Wanli Ouyang","Soujanya Poria","Erik Cambria","Dongzhan Zhou"],"url":"https://arxiv.org/abs/2410.07076"}
{"created":"2025-05-20","title":"Progressive Autoregressive Video Diffusion Models","abstract":"Current frontier video diffusion models have demonstrated remarkable results at generating high-quality videos. However, they can only generate short video clips, normally around 10 seconds or 240 frames, due to computation limitations during training. Existing methods naively achieve autoregressive long video generation by directly placing the ending of the previous clip at the front of the attention window as conditioning, which leads to abrupt scene changes, unnatural motion, and error accumulation. In this work, we introduce a more natural formulation of autoregressive long video generation by revisiting the noise level assumption in video diffusion models. Our key idea is to 1. assign the frames with per-frame, progressively increasing noise levels rather than a single noise level and 2. denoise and shift the frames in small intervals rather than all at once. This allows for smoother attention correspondence among frames with adjacent noise levels, larger overlaps between the attention windows, and better propagation of information from the earlier to the later frames. Video diffusion models equipped with our progressive noise schedule can autoregressively generate long videos with much improved fidelity compared to the baselines and minimal quality degradation over time. We present the first results on text-conditioned 60-second (1440 frames) long video generation at a quality close to frontier models. Code and video results are available at https://desaixie.github.io/pa-vdm/.","authors":["Desai Xie","Zhan Xu","Yicong Hong","Hao Tan","Difan Liu","Feng Liu","Arie Kaufman","Yang Zhou"],"url":"https://arxiv.org/abs/2410.08151"}
{"created":"2025-05-20","title":"Dynamic Fusion Strategies for Federated Multimodal Recommendations","abstract":"Delivering deeply personalized recommendations necessitates understanding user interactions with diverse multimedia features, but achieving this within the constraints of Federated Recommendation Systems (FedRec) is severely hampered by communication bottlenecks, user heterogeneity, and the complexity of privacy-preserving multimodal fusion. To this end, we propose FedMR, a novel multimodal FedRec framework centered around the Mixing Feature Fusion Module (MFFM). FedMR employs a two-stage process: (1) Server-side centralized multimedia content processing provides rich, shared item context using pre-trained models, mitigating limitations from client sparsity and resource constraints efficiently. (2) Client-Side Personalized Refinement, where the MFFM dynamically adapts these server-provided multimodal representations based on client-specific interaction patterns, effectively tailoring recommendations and resolving heterogeneity in user preferences towards different modalities. Extensive experiments validate that FedMR seamlessly enhances existing ID-based FedRecs, effectively transforming them into high-performing federated multimodal systems.","authors":["Zhiwei Li","Guodong Long","Jing Jiang","Chengqi Zhang"],"url":"https://arxiv.org/abs/2410.08478"}
{"created":"2025-05-20","title":"Inference and Verbalization Functions During In-Context Learning","abstract":"Large language models (LMs) are capable of in-context learning from a few demonstrations (example-label pairs) to solve new tasks during inference. Despite the intuitive importance of high-quality demonstrations, previous work has observed that, in some settings, ICL performance is minimally affected by irrelevant labels (Min et al., 2022). We hypothesize that LMs perform ICL with irrelevant labels via two sequential processes: an inference function that solves the task, followed by a verbalization function that maps the inferred answer to the label space. Importantly, we hypothesize that the inference function is invariant to remappings of the label space (e.g., \"true\"/\"false\" to \"cat\"/\"dog\"), enabling LMs to share the same inference function across settings with different label words. We empirically validate this hypothesis with controlled layer-wise interchange intervention experiments. Our findings confirm the hypotheses on multiple datasets and tasks (natural language inference, sentiment analysis, and topic classification) and further suggest that the two functions can be localized in specific layers across various open-sourced models, including GEMMA-7B, MISTRAL-7B-V0.3, GEMMA-2-27B, and LLAMA-3.1-70B.","authors":["Junyi Tao","Xiaoyin Chen","Nelson F. Liu"],"url":"https://arxiv.org/abs/2410.09349"}
{"created":"2025-05-20","title":"Bias Similarity Across Large Language Models","abstract":"Bias in Large Language Models remains a critical concern as these systems are increasingly deployed in high-stakes applications. Yet most fairness evaluations rely on scalar metrics or single-model analysis, overlooking how biases align -- or diverge -- across model families, scales, and tuning strategies. In this work, we reframe bias similarity as a form of functional similarity and evaluate 24 LLMs from four major families on over one million structured prompts spanning four bias dimensions. Our findings uncover that fairness is not strongly determined by model size, architecture, instruction tuning, or openness. Instead, bias behaviors are highly context-dependent and structurally persistent, often resistant to current alignment techniques. Contrary to common assumptions, we find that open-source models frequently match or outperform proprietary models in both fairness and utility. These results call into question the default reliance on proprietary systems and highlight the need for behaviorally grounded, model-specific audits to better understand how bias manifests and endures across the LLM landscape.","authors":["Hyejun Jeong","Shiqing Ma","Amir Houmansadr"],"url":"https://arxiv.org/abs/2410.12010"}
{"created":"2025-05-20","title":"Geometric Inductive Biases of Deep Networks: The Role of Data and Architecture","abstract":"In this paper, we propose the $\\textit{geometric invariance hypothesis (GIH)}$, which argues that the input space curvature of a neural network remains invariant under transformation in certain architecture-dependent directions during training. We investigate a simple, non-linear binary classification problem residing on a plane in a high dimensional space and observe that$\\unicode{x2014}$unlike MLPs$\\unicode{x2014}$ResNets fail to generalize depending on the orientation of the plane. Motivated by this example, we define a neural network's $\\textbf{average geometry}$ and $\\textbf{average geometry evolution}$ as compact $\\textit{architecture-dependent}$ summaries of the model's input-output geometry and its evolution during training. By investigating the average geometry evolution at initialization, we discover that the geometry of a neural network evolves according to the data covariance projected onto its average geometry. This means that the geometry only changes in a subset of the input space when the average geometry is low-rank, such as in ResNets. This causes an architecture-dependent invariance property in the input space curvature, which we dub GIH. Finally, we present extensive experimental results to observe the consequences of GIH and how it relates to generalization in neural networks.","authors":["Sajad Movahedi","Antonio Orvieto","Seyed-Mohsen Moosavi-Dezfooli"],"url":"https://arxiv.org/abs/2410.12025"}
{"created":"2025-05-20","title":"Explicit Representatives and Sizes of Cyclotomic Cosets and their Application to Cyclic Codes over Finite Fields","abstract":"Cyclotomic coset is a classical notion in the theory of finite field which has wide applications in various computation problems. Let $q$ be a prime power, and $n$ be a positive integer coprime to $q$. In this paper we determine explicitly the representatives and the sizes of all $q$-cyclotomic cosets modulo $n$ in the general settings. We introduce the definition of $2$-adic cyclotomic system, which is a profinite space consists of certain compatible sequences of cyclotomic cosets. A precise characterization of the structure of the $2$-adic cyclotomic system is given, which reveals the general formula for representatives of cyclotomic cosets. With the representatives and the sizes of $q$-cyclotomic cosets modulo $n$, we improve the formulas for the factorizations of $X^{n}-1$ and of $\\Phi_{n}(X)$ over $\\mathbb{F}_{q}$ given in \\cite{Graner}. As a consequence, we classify the cyclic codes over finite fields via giving their generator polynomials. Moreover, the self-dual cyclic codes are determined and enumerated.","authors":["Li Zhu","Jinle Liu","Hongfeng Wu"],"url":"https://arxiv.org/abs/2410.12122"}
{"created":"2025-05-20","title":"TCP-Diffusion: A Multi-modal Diffusion Model for Global Tropical Cyclone Precipitation Forecasting with Change Awareness","abstract":"Precipitation from tropical cyclones (TCs) can cause disasters such as flooding, mudslides, and landslides. Predicting such precipitation in advance is crucial, giving people time to prepare and defend against these precipitation-induced disasters. Developing deep learning (DL) rainfall prediction methods offers a new way to predict potential disasters. However, one problem is that most existing methods suffer from cumulative errors and lack physical consistency. Second, these methods overlook the importance of meteorological factors in TC rainfall and their integration with the numerical weather prediction (NWP) model. Therefore, we propose Tropical Cyclone Precipitation Diffusion (TCP-Diffusion), a multi-modal model for global tropical cyclone precipitation forecasting. It forecasts TC rainfall around the TC center for the next 12 hours at 3 hourly resolution based on past rainfall observations and multi-modal environmental variables. Adjacent residual prediction (ARP) changes the training target from the absolute rainfall value to the rainfall trend and gives our model the ability of rainfall change awareness, reducing cumulative errors and ensuring physical consistency. Considering the influence of TC-related meteorological factors and the useful information from NWP model forecasts, we propose a multi-model framework with specialized encoders to extract richer information from environmental variables and results provided by NWP models. The results of extensive experiments show that our method outperforms other DL methods and the NWP method from the European Centre for Medium-Range Weather Forecasts (ECMWF).","authors":["Cheng Huang","Pan Mu","Cong Bai","Peter AG Watson"],"url":"https://arxiv.org/abs/2410.13175"}
{"created":"2025-05-20","title":"Artificial Kuramoto Oscillatory Neurons","abstract":"It has long been known in both neuroscience and AI that ``binding'' between neurons leads to a form of competitive learning where representations are compressed in order to represent more abstract concepts in deeper layers of the network. More recently, it was also hypothesized that dynamic (spatiotemporal) representations play an important role in both neuroscience and AI. Building on these ideas, we introduce Artificial Kuramoto Oscillatory Neurons (AKOrN) as a dynamical alternative to threshold units, which can be combined with arbitrary connectivity designs such as fully connected, convolutional, or attentive mechanisms. Our generalized Kuramoto updates bind neurons together through their synchronization dynamics. We show that this idea provides performance improvements across a wide spectrum of tasks such as unsupervised object discovery, adversarial robustness, calibrated uncertainty quantification, and reasoning. We believe that these empirical results show the importance of rethinking our assumptions at the most basic neuronal level of neural representation, and in particular show the importance of dynamical representations. Code:https://github.com/autonomousvision/akorn Project page:https://takerum.github.io/akorn_project_page/","authors":["Takeru Miyato","Sindy L\\\"owe","Andreas Geiger","Max Welling"],"url":"https://arxiv.org/abs/2410.13821"}
{"created":"2025-05-20","title":"BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation","abstract":"Current EEG/MEG-to-text decoding systems suffer from three key limitations: (1) reliance on teacher-forcing methods, which compromises robustness during inference, (2) sensitivity to session-specific noise, hindering generalization across subjects, and (3) misalignment between brain signals and linguistic representations due to pre-trained language model over-dominance. To overcome these challenges, we propose BrainECHO (Brain signal decoding via vEctor-quantized speCtrogram reconstruction for WHisper-enhanced text generatiOn), a multi-stage framework that employs decoupled representation learning to achieve state-of-the-art performance on both EEG and MEG datasets. Specifically, BrainECHO consists of three stages: (1) Discrete autoencoding, which transforms continuous Mel spectrograms into a finite set of high-quality discrete representations for subsequent stages. (2) Frozen alignment, where brain signal embeddings are mapped to corresponding Mel spectrogram embeddings in a frozen latent space, effectively filtering session-specific noise through vector-quantized reconstruction, yielding a 3.65% improvement in BLEU-4 score. (3) Constrained decoding fine-tuning, which leverages the pre-trained Whisper model for audio-to-text translation, balancing signal adaptation with knowledge preservation, and achieving 74%-89% decoding BLEU scores without excessive reliance on teacher forcing. BrainECHO demonstrates robustness across sentence, session, and subject-independent conditions, passing Gaussian noise tests and showcasing its potential for enhancing language-based brain-computer interfaces.","authors":["Jilong Li","Zhenxi Song","Jiaqi Wang","Meishan Zhang","Honghai Liu","Min Zhang","Zhiguo Zhang"],"url":"https://arxiv.org/abs/2410.14971"}
{"created":"2025-05-20","title":"EndoMetric: Near-Light Monocular Metric Scale Estimation in Endoscopy","abstract":"Geometric reconstruction and SLAM with endoscopic images have advanced significantly in recent years. In most medical fields, monocular endoscopes are employed, and the algorithms used are typically adaptations of those designed for external environments, resulting in 3D reconstructions with an unknown scale factor.","authors":["Ra\\'ul Iranzo","V\\'ictor M. Batlle","Juan D. Tard\\'os","Jos\\'e M. M. Montiel"],"url":"https://arxiv.org/abs/2410.15065"}
{"created":"2025-05-20","title":"FIOVA: A Multi-Annotator Benchmark for Human-Aligned Video Captioning","abstract":"Despite rapid progress in large vision-language models (LVLMs), existing video caption benchmarks remain limited in evaluating their alignment with human understanding. Most rely on a single annotation per video and lexical similarity-based metrics, failing to capture the variability in human perception and the cognitive importance of events. These limitations hinder accurate diagnosis of model capabilities in producing coherent, complete, and human-aligned descriptions. To address this, we introduce FIOVA (Five-In-One Video Annotations), a human-centric benchmark tailored for evaluation. It comprises 3,002 real-world videos (about 33.6s each), each annotated independently by five annotators. This design enables modeling of semantic diversity and inter-subjective agreement, offering a richer foundation for measuring human-machine alignment. We further propose FIOVA-DQ, an event-level evaluation metric that incorporates cognitive weights derived from annotator consensus, providing fine-grained assessment of event relevance and semantic coverage. Leveraging FIOVA, we conduct a comprehensive evaluation of nine representative LVLMs and introduce a complexity-aware analysis framework based on inter-annotator variation (CV). This reveals consistency gaps across difficulty levels and identifies structural issues such as event under-description and template convergence. Our results highlight FIOVA's diagnostic value for understanding LVLM behavior under varying complexity, setting a new standard for cognitively aligned evaluation in long-video captioning. The benchmark, annotations, metric, and model outputs are publicly released to support future evaluation-driven research in video understanding. More detailed information can be found at https://huuuuusy.github.io/fiova/.","authors":["Shiyu Hu","Xuchen Li","Xuzhao Li","Jing Zhang","Yipei Wang","Xin Zhao","Kang Hao Cheong"],"url":"https://arxiv.org/abs/2410.15270"}
{"created":"2025-05-20","title":"Security of Language Models for Code: A Systematic Literature Review","abstract":"Language models for code (CodeLMs) have emerged as powerful tools for code-related tasks, outperforming traditional methods and standard machine learning approaches. However, these models are susceptible to security vulnerabilities, drawing increasing research attention from domains such as software engineering, artificial intelligence, and cybersecurity. Despite the growing body of research focused on the security of CodeLMs, a comprehensive survey in this area remains absent. To address this gap, we systematically review 67 relevant papers, organizing them based on attack and defense strategies. Furthermore, we provide an overview of commonly used language models, datasets, and evaluation metrics, and highlight open-source tools and promising directions for future research in securing CodeLMs.","authors":["Yuchen Chen","Weisong Sun","Chunrong Fang","Zhenpeng Chen","Yifei Ge","Tingxu Han","Quanjun Zhang","Yang Liu","Zhenyu Chen","Baowen Xu"],"url":"https://arxiv.org/abs/2410.15631"}
{"created":"2025-05-20","title":"Cross-Chain Options: A Bridgeless, Universal, and Efficient Approach","abstract":"Options are fundamental to blockchain-based financial services, offering essential tools for risk management and price speculation, which enhance liquidity, flexibility, and market efficiency in decentralized finance (DeFi). Despite the growing interest in options for blockchain-resident assets, such as cryptocurrencies, current option mechanisms face significant challenges, including a high reliance on trusted third parties, limited asset support, high trading delays, and the requirement for option holders to provide upfront collateral.","authors":["Zifan Peng","Yingjie Xue","Jingyu Liu"],"url":"https://arxiv.org/abs/2410.15724"}
{"created":"2025-05-20","title":"TexPro: Text-guided PBR Texturing with Procedural Material Modeling","abstract":"In this paper, we present TexPro, a novel method for high-fidelity material generation for input 3D meshes given text prompts. Unlike existing text-conditioned texture generation methods that typically generate RGB textures with baked lighting, TexPro is able to produce diverse texture maps via procedural material modeling, which enables physically-based rendering, relighting, and additional benefits inherent to procedural materials. Specifically, we first generate multi-view reference images given the input textual prompt by employing the latest text-to-image model. We then derive texture maps through rendering-based optimization with recent differentiable procedural materials. To this end, we design several techniques to handle the misalignment between the generated multi-view images and 3D meshes, and introduce a novel material agent that enhances material classification and matching by exploring both part-level understanding and object-aware material reasoning. Experiments demonstrate the superiority of the proposed method over existing SOTAs, and its capability of relighting.","authors":["Ziqiang Dang","Wenqi Dong","Zesong Yang","Bangbang Yang","Liang Li","Yuewen Ma","Zhaopeng Cui"],"url":"https://arxiv.org/abs/2410.15891"}
{"created":"2025-05-20","title":"TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis","abstract":"Time series analysis plays a critical role in numerous applications, supporting tasks such as forecasting, classification, anomaly detection, and imputation. In this work, we present the time series pattern machine (TSPM), a model designed to excel in a broad range of time series tasks through powerful representation and pattern extraction capabilities. Traditional time series models often struggle to capture universal patterns, limiting their effectiveness across diverse tasks. To address this, we define multiple scales in the time domain and various resolutions in the frequency domain, employing various mixing strategies to extract intricate, task-adaptive time series patterns. Specifically, we introduce a general-purpose TSPM that processes multi-scale time series using (1) multi-resolution time imaging (MRTI), (2) time image decomposition (TID), (3) multi-scale mixing (MCM), and (4) multi-resolution mixing (MRM) to extract comprehensive temporal patterns. MRTI transforms multi-scale time series into multi-resolution time images, capturing patterns across both temporal and frequency domains. TID leverages dual-axis attention to extract seasonal and trend patterns, while MCM hierarchically aggregates these patterns across scales. MRM adaptively integrates all representations across resolutions. This method achieves state-of-the-art performance across 8 time series analytical tasks, consistently surpassing both general-purpose and task-specific models. Our work marks a promising step toward the next generation of TSPMs, paving the way for further advancements in time series analysis.","authors":["Shiyu Wang","Jiawei Li","Xiaoming Shi","Zhou Ye","Baichuan Mo","Wenze Lin","Shengtong Ju","Zhixuan Chu","Ming Jin"],"url":"https://arxiv.org/abs/2410.16032"}
{"created":"2025-05-20","title":"An Immersed Interface Method for Incompressible Flows and Geometries with Sharp Features","abstract":"The immersed interface method (IIM) for models of fluid flow and fluid-structure interaction imposes jump conditions that capture stress discontinuities generated by forces that are concentrated along immersed boundaries. Most prior work using the IIM for fluid dynamic applications has focused on smooth interfaces, but boundaries with sharp features such as corners and edges can appear in practical analyses, particularly on engineered structures. The present study builds on our work to integrate finite element-type representations of interface geometries with the IIM. Initial realizations of this approach used a continuous Galerkin (CG) finite element discretization for the boundary, but as we show herein, these approaches generate large errors near sharp geometrical features. To overcome this difficulty, this study introduces an IIM approach using discontinuous Galerkin (DG) representation of the jump conditions. Numerical examples explore the impacts of different interface representations on accuracy for both smooth and sharp boundaries, particularly flows interacting with fixed interface configurations. We demonstrate that using a DG approach provides accuracy that is comparable to the CG method for smooth cases. Further, we identify a time step size restriction for the CG representation that is directly related to the sharpness of the geometry. In contrast, time step size restrictions imposed by DG representations are demonstrated to be insensitive to the presence of sharp features.","authors":["Michael J. Facci","Ebrahim M. Kolahdouz","Boyce E. Griffith"],"url":"https://arxiv.org/abs/2410.16466"}
{"created":"2025-05-20","title":"LLMScan: Causal Scan for LLM Misbehavior Detection","abstract":"Despite the success of Large Language Models (LLMs) across various fields, their potential to generate untruthful, biased and harmful responses poses significant risks, particularly in critical applications. This highlights the urgent need for systematic methods to detect and prevent such misbehavior. While existing approaches target specific issues such as harmful responses, this work introduces LLMScan, an innovative LLM monitoring technique based on causality analysis, offering a comprehensive solution. LLMScan systematically monitors the inner workings of an LLM through the lens of causal inference, operating on the premise that the LLM's `brain' behaves differently when misbehaving. By analyzing the causal contributions of the LLM's input tokens and transformer layers, LLMScan effectively detects misbehavior. Extensive experiments across various tasks and models reveal clear distinctions in the causal distributions between normal behavior and misbehavior, enabling the development of accurate, lightweight detectors for a variety of misbehavior detection tasks.","authors":["Mengdi Zhang","Kai Kiat Goh","Peixin Zhang","Jun Sun","Rose Lin Xin","Hongyu Zhang"],"url":"https://arxiv.org/abs/2410.16638"}
{"created":"2025-05-20","title":"Test-time Adversarial Defense with Opposite Adversarial Path and High Attack Time Cost","abstract":"Deep learning models are known to be vulnerable to adversarial attacks by injecting sophisticated designed perturbations to input data. Training-time defenses still exhibit a significant performance gap between natural accuracy and robust accuracy. In this paper, we investigate a new test-time adversarial defense method via diffusion-based recovery along opposite adversarial paths (OAPs). We present a purifier that can be plugged into a pre-trained model to resist adversarial attacks. Different from prior arts, the key idea is excessive denoising or purification by integrating the opposite adversarial direction with reverse diffusion to push the input image further toward the opposite adversarial direction. For the first time, we also exemplify the pitfall of conducting AutoAttack (Rand) for diffusion-based defense methods. Through the lens of time complexity, we examine the trade-off between the effectiveness of adaptive attack and its computation complexity against our defense. Experimental evaluation along with time cost analysis verifies the effectiveness of the proposed method.","authors":["Cheng-Han Yeh","Kuanchun Yu","Chun-Shien Lu"],"url":"https://arxiv.org/abs/2410.16805"}
{"created":"2025-05-20","title":"Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation","abstract":"Time series data is ubiquitous across various domains, including manufacturing, finance, and healthcare. High-quality annotations are essential for effectively understanding time series and facilitating downstream tasks; however, obtaining such annotations is challenging, particularly in mission-critical domains. In this paper, we propose TESSA, a multi-agent system designed to automatically generate both general and domain-specific annotations for time series data. TESSA introduces two agents: a general annotation agent and a domain-specific annotation agent. The general agent captures common patterns and knowledge across multiple source domains, leveraging both time-series-wise and text-wise features to generate general annotations. Meanwhile, the domain-specific agent utilizes limited annotations from the target domain to learn domain-specific terminology and generate targeted annotations. Extensive experiments on multiple synthetic and real-world datasets demonstrate that TESSA effectively generates high-quality annotations, outperforming existing methods.","authors":["Minhua Lin","Zhengzhang Chen","Yanchi Liu","Xujiang Zhao","Zongyu Wu","Junxiang Wang","Xiang Zhang","Suhang Wang","Haifeng Chen"],"url":"https://arxiv.org/abs/2410.17462"}
{"created":"2025-05-20","title":"Securing Federated Learning against Backdoor Threats with Foundation Model Integration","abstract":"Federated Learning (FL) enables decentralized model training while preserving privacy. Recently, the integration of Foundation Models (FMs) into FL has enhanced performance but introduced a novel backdoor attack mechanism. Attackers can exploit FM vulnerabilities to embed backdoors into synthetic data generated by FMs. During global model fusion, these backdoors are transferred to the global model through compromised synthetic data, subsequently infecting all client models. Existing FL backdoor defenses are ineffective against this novel attack due to its fundamentally different mechanism compared to classic ones. In this work, we propose a novel data-free defense strategy that addresses both classic and novel backdoor attacks in FL. The shared attack pattern lies in the abnormal activations within the hidden feature space during model aggregation. Hence, we propose to constrain internal activations to remain within reasonable ranges, effectively mitigating attacks while preserving model functionality. The activation constraints are optimized using synthetic data alongside FL training. Extensive experiments demonstrate its effectiveness against both novel and classic backdoor attacks, outperforming existing defenses.","authors":["Xiaohuan Bi","Xi Li"],"url":"https://arxiv.org/abs/2410.17573"}
{"created":"2025-05-20","title":"Irregular Tensor Low-Rank Representation for Hyperspectral Image Representation","abstract":"Spectral variations pose a common challenge in analyzing hyperspectral images (HSI). To address this, low-rank tensor representation has emerged as a robust strategy, leveraging inherent correlations within HSI data. However, the spatial distribution of ground objects in HSIs is inherently irregular, existing naturally in tensor format, with numerous class-specific regions manifesting as irregular tensors. Current low-rank representation techniques are designed for regular tensor structures and overlook this fundamental irregularity in real-world HSIs, leading to performance limitations. To tackle this issue, we propose a novel model for irregular tensor low-rank representation tailored to efficiently model irregular 3D cubes. By incorporating a non-convex nuclear norm to promote low-rankness and integrating a global negative low-rank term to enhance the discriminative ability, our proposed model is formulated as a constrained optimization problem and solved using an alternating augmented Lagrangian method. Experimental validation conducted on four public datasets demonstrates the superior performance of our method compared to existing state-of-the-art approaches. The code is publicly available at https://github.com/hb-studying/ITLRR.","authors":["Bo Han","Yuheng Jia","Hui Liu","Junhui Hou"],"url":"https://arxiv.org/abs/2410.18388"}
{"created":"2025-05-20","title":"Rethinking Attention: Polynomial Alternatives to Softmax in Transformers","abstract":"This paper questions whether the strong performance of softmax attention in transformers stems from producing a probability distribution over inputs. Instead, we argue that softmax's effectiveness lies in its implicit regularization of the Frobenius norm of the attention matrix, which stabilizes training. Motivated by this, we explore alternative activations, specifically polynomials, that achieve a similar regularization effect. Our theoretical analysis shows that certain polynomials can serve as effective substitutes for softmax, achieving strong performance across transformer applications despite violating softmax's typical properties of positivity, normalization, and sparsity. Extensive experiments support these findings, offering a new perspective on attention mechanisms.","authors":["Hemanth Saratchandran","Jianqiao Zheng","Yiping Ji","Wenbo Zhang","Simon Lucey"],"url":"https://arxiv.org/abs/2410.18613"}
{"created":"2025-05-20","title":"Efficient Diversity-based Experience Replay for Deep Reinforcement Learning","abstract":"Experience replay is widely used to improve learning efficiency in reinforcement learning by leveraging past experiences. However, existing experience replay methods, whether based on uniform or prioritized sampling, often suffer from low efficiency, particularly in real-world scenarios with high-dimensional state spaces. To address this limitation, we propose a novel approach, Efficient Diversity-based Experience Replay (EDER). EDER employs a determinantal point process to model the diversity between samples and prioritizes replay based on the diversity between samples. To further enhance learning efficiency, we incorporate Cholesky decomposition for handling large state spaces in realistic environments. Additionally, rejection sampling is applied to select samples with higher diversity, thereby improving overall learning efficacy. Extensive experiments are conducted on robotic manipulation tasks in MuJoCo, Atari games, and realistic indoor environments in Habitat. The results demonstrate that our approach not only significantly improves learning efficiency but also achieves superior performance in high-dimensional, realistic environments.","authors":["Kaiyan Zhao","Yiming Wang","Yuyang Chen","Yan Li","Leong Hou U","Xiaoguang Niu"],"url":"https://arxiv.org/abs/2410.20487"}
{"created":"2025-05-20","title":"On Probabilistic Pullback Metrics for Latent Hyperbolic Manifolds","abstract":"Probabilistic Latent Variable Models (LVMs) excel at modeling complex, high-dimensional data through lower-dimensional representations. Recent advances show that equipping these latent representations with a Riemannian metric unlocks geometry-aware distances and shortest paths that comply with the underlying data structure. This paper focuses on hyperbolic embeddings, a particularly suitable choice for modeling hierarchical relationships. Previous approaches relying on hyperbolic geodesics for interpolating the latent space often generate paths crossing low-data regions, leading to highly uncertain predictions. Instead, we propose augmenting the hyperbolic manifold with a pullback metric to account for distortions introduced by the LVM's nonlinear mapping and provide a complete development for pullback metrics of Gaussian Process LVMs (GPLVMs). Our experiments demonstrate that geodesics on the pullback metric not only respect the geometry of the hyperbolic latent space but also align with the underlying data distribution, significantly reducing uncertainty in predictions.","authors":["Luis Augenstein","No\\'emie Jaquier","Tamim Asfour","Leonel Rozo"],"url":"https://arxiv.org/abs/2410.20850"}
{"created":"2025-05-20","title":"BraVE: Offline Reinforcement Learning for Discrete Combinatorial Action Spaces","abstract":"Offline reinforcement learning in high-dimensional, discrete action spaces is challenging due to the exponential scaling of the joint action space with the number of sub-actions and the complexity of modeling sub-action dependencies. Existing methods either exhaustively evaluate the action space, making them computationally infeasible, or factorize Q-values, failing to represent joint sub-action effects. We propose Branch Value Estimation (BraVE), a value-based method that uses tree-structured action traversal to evaluate a linear number of joint actions while preserving dependency structure. BraVE outperforms prior offline RL methods by up to $20\\times$ in environments with over four million actions.","authors":["Matthew Landers","Taylor W. Killian","Hugo Barnes","Thomas Hartvigsen","Afsaneh Doryab"],"url":"https://arxiv.org/abs/2410.21151"}
{"created":"2025-05-20","title":"Deploying Ten Thousand Robots: Scalable Imitation Learning for Lifelong Multi-Agent Path Finding","abstract":"Lifelong Multi-Agent Path Finding (LMAPF) repeatedly finds collision-free paths for multiple agents that are continually assigned new goals when they reach current ones. Recently, this field has embraced learning-based methods, which reactively generate single-step actions based on individual local observations. However, it is still challenging for them to match the performance of the best search-based algorithms, especially in large-scale settings. This work proposes an imitation-learning-based LMAPF solver that introduces a novel communication module as well as systematic single-step collision resolution and global guidance techniques. Our proposed solver, Scalable Imitation Learning for LMAPF (SILLM), inherits the fast reasoning speed of learning-based methods and the high solution quality of search-based methods with the help of modern GPUs. Across six large-scale maps with up to 10,000 agents and varying obstacle structures, SILLM surpasses the best learning- and search-based baselines, achieving average throughput improvements of 137.7% and 16.0%, respectively. Furthermore, SILLM also beats the winning solution of the 2023 League of Robot Runners, an international LMAPF competition. Finally, we validated SILLM with 10 real robots and 100 virtual robots in a mock warehouse environment.","authors":["He Jiang","Yutong Wang","Rishi Veerapaneni","Tanishq Duhan","Guillaume Sartoretti","Jiaoyang Li"],"url":"https://arxiv.org/abs/2410.21415"}
{"created":"2025-05-20","title":"IntLoRA: Integral Low-rank Adaptation of Quantized Diffusion Models","abstract":"Fine-tuning pre-trained diffusion models under limited budgets has gained great success. In particular, the recent advances that directly fine-tune the quantized weights using Low-rank Adaptation (LoRA) further reduces training costs. Despite these progress, we point out that existing adaptation recipes are not inference-efficient. Specifically, additional post-training quantization (PTQ) on tuned weights is needed during deployment, which results in noticeable performance drop when the bit-width is low. Based on this observation, we introduce IntLoRA, which adapts quantized diffusion models with integer-type low-rank parameters, to include inference efficiency during tuning. Specifically, IntLoRA enables pre-trained weights to remain quantized during training, facilitating fine-tuning on consumer-level GPUs. During inference, IntLoRA weights can be seamlessly merged into pre-trained weights to directly obtain quantized downstream weights without PTQ. Extensive experiments show our IntLoRA achieves significant speedup on both training and inference without losing performance.","authors":["Hang Guo","Yawei Li","Tao Dai","Shu-Tao Xia","Luca Benini"],"url":"https://arxiv.org/abs/2410.21759"}
{"created":"2025-05-20","title":"USpeech: Ultrasound-Enhanced Speech with Minimal Human Effort via Cross-Modal Synthesis","abstract":"Speech enhancement is crucial for ubiquitous human-computer interaction. Recently, ultrasound-based acoustic sensing has emerged as an attractive choice for speech enhancement because of its superior ubiquity and performance. However, due to inevitable interference from unexpected and unintended sources during audio-ultrasound data acquisition, existing solutions rely heavily on human effort for data collection and processing. This leads to significant data scarcity that limits the full potential of ultrasound-based speech enhancement. To address this, we propose USpeech, a cross-modal ultrasound synthesis framework for speech enhancement with minimal human effort. At its core is a two-stage framework that establishes the correspondence between visual and ultrasonic modalities by leveraging audio as a bridge. This approach overcomes challenges from the lack of paired video-ultrasound datasets and the inherent heterogeneity between video and ultrasound data. Our framework incorporates contrastive video-audio pre-training to project modalities into a shared semantic space and employs an audio-ultrasound encoder-decoder for ultrasound synthesis. We then present a speech enhancement network that enhances speech in the time-frequency domain and recovers the clean speech waveform via a neural vocoder. Comprehensive experiments show USpeech achieves remarkable performance using synthetic ultrasound data comparable to physical data, outperforming state-of-the-art ultrasound-based speech enhancement baselines. USpeech is open-sourced at https://github.com/aiot-lab/USpeech/.","authors":["Luca Jiang-Tao Yu","Running Zhao","Sijie Ji","Edith C. H. Ngai","Chenshu Wu"],"url":"https://arxiv.org/abs/2410.22076"}
{"created":"2025-05-20","title":"EconoJax: A Fast & Scalable Economic Simulation in Jax","abstract":"Accurate economic simulations often require many experimental runs, particularly when combined with reinforcement learning. Unfortunately, training reinforcement learning agents in multi-agent economic environments can be slow. This paper introduces EconoJax, a fast simulated economy, based on the AI economist. EconoJax, and its training pipeline, are completely written in JAX. This allows EconoJax to scale to large population sizes and perform large experiments, while keeping training times within minutes. Through experiments with populations of 100 agents, we show how real-world economic behavior emerges through training within 15 minutes, in contrast to previous work that required several days. We additionally perform experiments in varying sized action spaces to test if some multi-agent methods produce more diverse behavior compared to others. Here, our findings indicate no notable differences in produced behavior with different methods as is sometimes suggested in earlier works. To aid further research, we open-source EconoJax on Github.","authors":["Koen Ponse","Aske Plaat","Niki van Stein","Thomas M. Moerland"],"url":"https://arxiv.org/abs/2410.22165"}
{"created":"2025-05-20","title":"Adversarial Attacks of Vision Tasks in the Past 10 Years: A Survey","abstract":"With the advent of Large Vision-Language Models (LVLMs), new attack vectors, such as cognitive bias, prompt injection, and jailbreaking, have emerged. Understanding these attacks promotes system robustness improvement and neural networks demystification. However, existing surveys often target attack taxonomy and lack in-depth analysis like 1) unified insights into adversariality, transferability, and generalization; 2) detailed evaluations framework; 3) motivation-driven attack categorizations; and 4) an integrated perspective on both traditional and LVLM attacks. This article addresses these gaps by offering a thorough summary of traditional and LVLM adversarial attacks, emphasizing their connections and distinctions, and providing actionable insights for future research.","authors":["Chiyu Zhang","Lu Zhou","Xiaogang Xu","Jiafei Wu","Zhe Liu"],"url":"https://arxiv.org/abs/2410.23687"}
{"created":"2025-05-20","title":"Decoupled structure-preserving discretization of incompressible MHD equations with general boundary conditions","abstract":"In the framework of a mixed finite element method, a structure-preserving formulation for incompressible magnetohydrodynamic (MHD) equations with general boundary conditions is proposed. A leapfrog-type temporal scheme fully decouples the fluid part from the Maxwell part by means of staggered discrete time sequences and, in doing so, partially linearizes the system. Conservation and dissipation properties of the formulation before and after the decoupling are analyzed. We demonstrate optimal spatial and second-order temporal accuracy, as well as conservation and dissipation properties, of the proposed method using manufactured solutions, and apply it to the benchmark Orszag-Tang and lid-driven cavity cases.","authors":["Yi Zhang","Artur Palha","Andrea Brugnoli","Deepesh Toshniwal","Marc Gerritsma"],"url":"https://arxiv.org/abs/2410.23973"}
{"created":"2025-05-20","title":"Wasserstein Flow Matching: Generative modeling over families of distributions","abstract":"Generative modeling typically concerns transporting a single source distribution to a target distribution via simple probability flows. However, in fields like computer graphics and single-cell genomics, samples themselves can be viewed as distributions, where standard flow matching ignores their inherent geometry. We propose Wasserstein flow matching (WFM), which lifts flow matching onto families of distributions using the Wasserstein geometry. Notably, WFM is the first algorithm capable of generating distributions in high dimensions, whether represented analytically (as Gaussians) or empirically (as point-clouds). Our theoretical analysis establishes that Wasserstein geodesics constitute proper conditional flows over the space of distributions, making for a valid FM objective. Our algorithm leverages optimal transport theory and the attention mechanism, demonstrating versatility across computational regimes: exploiting closed-form optimal transport paths for Gaussian families, while using entropic estimates on point-clouds for general distributions. WFM successfully generates both 2D & 3D shapes and high-dimensional cellular microenvironments from spatial transcriptomics data. Code is available at https://github.com/DoronHav/WassersteinFlowMatching .","authors":["Doron Haviv","Aram-Alexandre Pooladian","Dana Pe'er","Brandon Amos"],"url":"https://arxiv.org/abs/2411.00698"}
{"created":"2025-05-20","title":"Enhancing LLM Evaluations: The Garbling Trick","abstract":"As large language models (LLMs) become increasingly powerful, traditional evaluation metrics tend to saturate, making it challenging to distinguish between models. We propose a general method to transform existing LLM evaluations into a series of progressively more difficult tasks. These enhanced evaluations emphasize reasoning capabilities and can reveal relative performance differences that are not apparent in the original assessments.","authors":["William F. Bradley"],"url":"https://arxiv.org/abs/2411.01533"}
{"created":"2025-05-20","title":"Quantum Rationale-Aware Graph Contrastive Learning for Jet Discrimination","abstract":"In high-energy physics, particle jet tagging plays a pivotal role in distinguishing quark from gluon jets using data from collider experiments. While graph-based deep learning methods have advanced this task beyond traditional feature-engineered approaches, the complex data structure and limited labeled samples present ongoing challenges. However, existing contrastive learning (CL) frameworks struggle to leverage rationale-aware augmentations effectively, often lacking supervision signals that guide the extraction of salient features and facing computational efficiency issues such as high parameter counts. In this study, we demonstrate that integrating a quantum rationale generator (QRG) within our proposed Quantum Rationale-aware Graph Contrastive Learning (QRGCL) framework significantly enhances jet discrimination performance, reducing reliance on labeled data and capturing discriminative features. Evaluated on the quark-gluon jet dataset, QRGCL achieves an AUC score of $77.53\\%$ while maintaining a compact architecture of only 45 QRG parameters, outperforming classical, quantum, and hybrid GCL and GNN benchmarks. These results highlight QRGCL's potential to advance jet tagging and other complex classification tasks in high-energy physics, where computational efficiency and feature extraction limitations persist.","authors":["Md Abrar Jahin","Md. Akmol Masud","M. F. Mridha","Nilanjan Dey","Zeyar Aung"],"url":"https://arxiv.org/abs/2411.01642"}
{"created":"2025-05-20","title":"A Micro-Macro Decomposition-Based Asymptotic-Preserving Random Feature Method for Multiscale Radiative Transfer Equations","abstract":"This paper introduces the Asymptotic-Preserving Random Feature Method (APRFM) for the efficient resolution of multiscale radiative transfer equations. The APRFM effectively addresses the challenges posed by stiffness and multiscale characteristics inherent in radiative transfer equations through the application of a micro-macro decomposition strategy. This approach decomposes the distribution function into equilibrium and non-equilibrium components, allowing for the approximation of both parts through the random feature method (RFM) within a least squares minimization framework. The proposed method exhibits remarkable robustness across different scales and achieves high accuracy with fewer degrees of freedom and collocation points than the vanilla RFM. Additionally, compared to the deep neural network-based method, our approach offers significant advantages in terms of parameter efficiency and computational speed. These benefits have been substantiated through numerous numerical experiments conducted on both one- and two-dimensional problems.","authors":["Jingrun Chen","Zheng Ma","Keke Wu"],"url":"https://arxiv.org/abs/2411.04643"}
{"created":"2025-05-20","title":"A Quality-Centric Framework for Generic Deepfake Detection","abstract":"Detecting AI-generated images, particularly deepfakes, has become increasingly crucial, with the primary challenge being the generalization to previously unseen manipulation methods. This paper tackles this issue by leveraging the forgery quality of training data to improve the generalization performance of existing deepfake detectors. Generally, the forgery quality of different deepfakes varies: some have easily recognizable forgery clues, while others are highly realistic. Existing works often train detectors on a mix of deepfakes with varying forgery qualities, potentially leading detectors to short-cut the easy-to-spot artifacts from low-quality forgery samples, thereby hurting generalization performance. To tackle this issue, we propose a novel quality-centric framework for generic deepfake detection, which is composed of a Quality Evaluator, a low-quality data enhancement module, and a learning pacing strategy that explicitly incorporates forgery quality into the training process. Our framework is inspired by curriculum learning, which is designed to gradually enable the detector to learn more challenging deepfake samples, starting with easier samples and progressing to more realistic ones. We employ both static and dynamic assessments to assess the forgery quality, combining their scores to produce a final rating for each training sample. The rating score guides the selection of deepfake samples for training, with higher-rated samples having a higher probability of being chosen. Furthermore, we propose a novel frequency data augmentation method specifically designed for low-quality forgery samples, which helps to reduce obvious forgery traces and improve their overall realism. Extensive experiments demonstrate that our proposed framework can be applied plug-and-play to existing detection models and significantly enhance their generalization performance in detection.","authors":["Wentang Song","Zhiyuan Yan","Yuzhen Lin","Taiping Yao","Changsheng Chen","Shen Chen","Yandan Zhao","Shouhong Ding","Bin Li"],"url":"https://arxiv.org/abs/2411.05335"}
{"created":"2025-05-20","title":"Why These Documents? Explainable Generative Retrieval with Hierarchical Category Paths","abstract":"Generative retrieval has recently emerged as a new alternative of traditional information retrieval approaches. However, existing generative retrieval methods directly decode docid when a query is given, making it impossible to provide users with explanations as an answer for \"Why this document is retrieved?\". To address this limitation, we propose Hierarchical Category Path-Enhanced Generative Retrieval(HyPE), which enhances explainability by generating hierarchical category paths step-by-step before decoding docid. HyPE leverages hierarchical category paths as explanation, progressing from broad to specific semantic categories. This approach enables diverse explanations for the same document depending on the query by using shared category paths between the query and the document, and provides reasonable explanation by reflecting the document's semantic structure through a coarse-to-fine manner. HyPE constructs category paths with external high-quality semantic hierarchy, leverages LLM to select appropriate candidate paths for each document, and optimizes the generative retrieval model with path-augmented dataset. During inference, HyPE utilizes path-aware reranking strategy to aggregate diverse topic information, allowing the most relevant documents to be prioritized in the final ranked list of docids. Our extensive experiments demonstrate that HyPE not only offers a high level of explainability but also improves the retrieval performance in the document retrieval task.","authors":["Sangam Lee","Ryang Heo","SeongKu Kang","Susik Yoon","Jinyoung Yeo","Dongha Lee"],"url":"https://arxiv.org/abs/2411.05572"}
{"created":"2025-05-20","title":"Modeling Nonlinear Oscillator Networks Using Physics-Informed Hybrid Reservoir Computing","abstract":"Surrogate modeling of non-linear oscillator networks remains challenging due to discrepancies between simplified analytical models and real-world complexity. To bridge this gap, we investigate hybrid reservoir computing, combining reservoir computing with \"expert\" analytical models. Simulating the absence of an exact model, we first test the surrogate models with parameter errors in their expert model. Second, in a residual physics task, we assess their performance when their expert model lacks key non-linear coupling terms present in an extended ground-truth model. We focus on short-term forecasting across diverse dynamical regimes, evaluating the use of these surrogates for control applications. We show that hybrid reservoir computers generally outperform standard reservoir computers and exhibit greater robustness to parameter tuning. This advantage is less pronounced in the residual physics task. Notably, unlike standard reservoir computers, the performance of the hybrid does not degrade when crossing an observed spectral radius threshold. Furthermore, there is good performance for dynamical regimes not accessible to the expert model, demonstrating the contribution of the reservoir.","authors":["Andrew Shannon","Conor Houghton","David Barton","Martin Homer"],"url":"https://arxiv.org/abs/2411.05867"}
{"created":"2025-05-20","title":"CI/CD Configuration Practices in Open-Source Android Apps: An Empirical Study","abstract":"Continuous Integration and Continuous Delivery (CI/CD) is a well-established practice that automatically builds, tests, packages, and deploys software systems. To adopt CI/CD, software developers need to configure their projects using dedicated YML configuration files. Mobile apps have distinct characteristics with respect to CI/CD practices, such as testing on various emulators and deploying to app stores. However, little is known about the challenges and added value of adopting CI/CD in mobile apps and how developers maintain such a practice. In this paper, we conduct an empirical study on CI/CD practices in 2,557 Android apps adopting four popular CI/CD services, namely GitHub Actions, Travis CI, CircleCI, and GitLab CI/CD. We also compare our findings with those reported in prior research on general CI/CD practices to situate them within broader trends. We observe a lack of commonality and standardization across CI/CD services and Android apps, leading to complex YML configurations and associated maintenance efforts. We also observe that CI/CD configurations focus primarily on the build setup, with around half of the projects performing standard testing and only 9% incorporating deployment. In addition, we find that CI/CD configurations are changed bi-monthly on average, with frequent maintenance correlating with active issue tracking, project size/age, and community engagement. Our qualitative analysis of commits uncovered 11 themes in CI/CD maintenance activities, with over a third of the changes focusing on improving workflows and fixing build issues, whereas another third involves updating the build environment, tools, and dependencies. Our study emphasizes the necessity for automation and AI-powered tools to improve CI/CD processes for mobile apps and advocates creating adaptable open-source tools to efficiently manage resources, especially in testing and deployment.","authors":["Taher A. Ghaleb","Osamah Abduljalil","Safwat Hassan"],"url":"https://arxiv.org/abs/2411.06077"}
{"created":"2025-05-20","title":"Annotative Indexing","abstract":"This paper introduces annotative indexing, a novel framework that unifies and generalizes traditional inverted indexes, column stores, object stores, and graph databases. As a result, annotative indexing can provide the underlying indexing framework for databases that support retrieval augmented generation, knowledge graphs, entity retrieval, semi-structured data, and ranked retrieval. While we primarily focus on human language data in the form of text, annotative indexing is sufficiently general to support a range of other datatypes, and we provide examples of SQL-like queries over a JSON store that includes numbers and dates. Taking advantage of the flexibility of annotative indexing, we also demonstrate a fully dynamic annotative index incorporating support for ACID properties of transactions with hundreds of multiple concurrent readers and writers.","authors":["Charles L. A. Clarke"],"url":"https://arxiv.org/abs/2411.06256"}
{"created":"2025-05-20","title":"Regret Minimization and Statistical Inference in Online Decision Making with High-dimensional Covariates","abstract":"This paper investigates regret minimization, statistical inference, and their interplay in high-dimensional online decision-making based on the sparse linear context bandit model. We integrate the $\\varepsilon$-greedy bandit algorithm for decision-making with a hard thresholding algorithm for estimating sparse bandit parameters and introduce an inference framework based on a debiasing method using inverse propensity weighting. Under a margin condition, our method achieves either $O(T^{1/2})$ regret or classical $O(T^{1/2})$-consistent inference, indicating an unavoidable trade-off between exploration and exploitation. If a diverse covariate condition holds, we demonstrate that a pure-greedy bandit algorithm, i.e., exploration-free, combined with a debiased estimator based on average weighting can simultaneously achieve optimal $O(\\log T)$ regret and $O(T^{1/2})$-consistent inference. We also show that a simple sample mean estimator can provide valid inference for the optimal policy's value. Numerical simulations and experiments on Warfarin dosing data validate the effectiveness of our methods.","authors":["Congyuan Duan","Wanteng Ma","Jiashuo Jiang","Dong Xia"],"url":"https://arxiv.org/abs/2411.06329"}
{"created":"2025-05-20","title":"ImageRAG: Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with ImageRAG","abstract":"Ultra High Resolution (UHR) remote sensing imagery (RSI) (e.g. 100,000 $\\times$ 100,000 pixels or more) poses a significant challenge for current Remote Sensing Multimodal Large Language Models (RSMLLMs). If choose to resize the UHR image to standard input image size, the extensive spatial and contextual information that UHR images contain will be neglected. Otherwise, the original size of these images often exceeds the token limits of standard RSMLLMs, making it difficult to process the entire image and capture long-range dependencies to answer the query based on the abundant visual context. In this paper, we introduce ImageRAG for RS, a training-free framework to address the complexities of analyzing UHR remote sensing imagery. By transforming UHR remote sensing image analysis task to image's long context selection task, we design an innovative image contextual retrieval mechanism based on the Retrieval-Augmented Generation (RAG) technique, denoted as ImageRAG. ImageRAG's core innovation lies in its ability to selectively retrieve and focus on the most relevant portions of the UHR image as visual contexts that pertain to a given query. Fast path and slow path are proposed in this framework to handle this task efficiently and effectively. ImageRAG allows RSMLLMs to manage extensive context and spatial information from UHR RSI, ensuring the analysis is both accurate and efficient. Codebase will be released in https://github.com/om-ai-lab/ImageRAG","authors":["Zilun Zhang","Haozhan Shen","Tiancheng Zhao","Zian Guan","Bin Chen","Yuhao Wang","Xu Jia","Yuxiang Cai","Yongheng Shang","Jianwei Yin"],"url":"https://arxiv.org/abs/2411.07688"}
{"created":"2025-05-20","title":"VersaTune: An Efficient Data Composition Framework for Training Multi-Capability LLMs","abstract":"As demonstrated by the proprietary Large Language Models (LLMs) such as GPT and Claude series, LLMs have the potential to achieve remarkable proficiency across a wide range of domains, including law, medicine, finance, science, code, etc., all within a single model. These capabilities are further augmented during the Supervised Fine-Tuning (SFT) phase. Despite their potential, existing work mainly focuses on domain-specific enhancements during fine-tuning, the challenge of which lies in catastrophic forgetting of knowledge across other domains. In this study, we introduce **VersaTune**, a novel data composition framework designed for enhancing LLMs' overall multi-domain capabilities during training. We begin with detecting the distribution of domain-specific knowledge within the base model, followed by the training data composition that aligns with the model's existing knowledge distribution. During the subsequent training process, domain weights are dynamically adjusted based on their learnable potential and forgetting degree. Experimental results indicate that VersaTune is effective in multi-domain fostering, with an improvement of 35.21\\% in the overall multi-ability performances compared to uniform domain weights. Furthermore, we find that Qwen-2.5-32B + VersaTune even surpasses frontier models, including GPT-4o, Claude3.5-Sonnet and DeepSeek-V3 by 0.86\\%, 4.76\\% and 4.60\\%. Additionally, in scenarios where flexible expansion of a specific domain is required, VersaTune reduces the performance degradation in other domains by 38.77\\%, while preserving the training efficacy of the target domain.","authors":["Keer Lu","Keshi Zhao","Zhuoran Zhang","Zheng Liang","Da Pan","Shusen Zhang","Xin Wu","Guosheng Dong","Bin Cui","Tengjiao Wang","Wentao Zhang"],"url":"https://arxiv.org/abs/2411.11266"}
{"created":"2025-05-20","title":"Data Watermarking for Sequential Recommender Systems","abstract":"In the era of large foundation models, data has become a crucial component in building high-performance AI systems. As the demand for high-quality and large-scale data continues to rise, data copyright protection is attracting increasing attention. In this work, we explore the problem of data watermarking for sequential recommender systems, where a watermark is embedded into the target dataset and can be detected in models trained on that dataset. We focus on two settings: dataset watermarking, which protects the ownership of the entire dataset, and user watermarking, which safeguards the data of individual users. We present a method named Dataset Watermarking for Recommender Systems (DWRS) to address them. We define the watermark as a sequence of consecutive items inserted into normal users' interaction sequences. We define a Receptive Field (RF) to guide the inserting process to facilitate the memorization of the watermark. Extensive experiments on five representative sequential recommendation models and three benchmark datasets demonstrate the effectiveness of DWRS in protecting data copyright while preserving model utility.","authors":["Sixiao Zhang","Cheng Long","Wei Yuan","Hongxu Chen","Hongzhi Yin"],"url":"https://arxiv.org/abs/2411.12989"}
{"created":"2025-05-20","title":"Path-Tracking Hybrid A* and Hierarchical MPC Framework for Autonomous Agricultural Vehicles","abstract":"We propose a Path-Tracking Hybrid A* planner coupled with a hierarchical Model Predictive Control (MPC) framework for path smoothing in agricultural vehicles. The goal is to minimize deviation from reference paths during cross-furrow operations, thereby optimizing operational efficiency, preventing crop and soil damage, while also enforcing curvature constraints and ensuring full-body collision avoidance. Our contributions are threefold: (1) We develop the Path-Tracking Hybrid A* algorithm to generate smooth trajectories that closely adhere to the reference trajectory, respect strict curvature constraints, and satisfy full-body collision avoidance. The adherence is achieved by designing novel cost and heuristic functions to minimize tracking errors under nonholonomic constraints. (2) We introduce an online replanning strategy as an extension that enables real-time avoidance of unforeseen obstacles, while leveraging pruning techniques to enhance computational efficiency. (3) We design a hierarchical MPC framework that ensures tight path adherence and real-time satisfaction of vehicle constraints, including nonholonomic dynamics and full-body collision avoidance. By using linearized MPC to warm-start the nonlinear solver, the framework improves the convergence of nonlinear optimization with minimal loss in accuracy. Simulations on real-world farm datasets demonstrate superior performance compared to baseline methods in safety, path adherence, computation speed, and real-time obstacle avoidance.","authors":["Mingke Lu","Han Gao","Haijie Dai","Qianli Lei","Chang Liu"],"url":"https://arxiv.org/abs/2411.14086"}
{"created":"2025-05-20","title":"Orthogonal Subspace Decomposition for Generalizable AI-Generated Image Detection","abstract":"AI-generated images (AIGIs), such as natural or face images, have become increasingly important yet challenging. In this paper, we start from a new perspective to excavate the reason behind the failure generalization in AIGI detection, named the \\textit{asymmetry phenomenon}, where a naively trained detector tends to favor overfitting to the limited and monotonous fake patterns, causing the feature space to become highly constrained and low-ranked, which is proved seriously limiting the expressivity and generalization. One potential remedy is incorporating the pre-trained knowledge within the vision foundation models (higher-ranked) to expand the feature space, alleviating the model's overfitting to fake. To this end, we employ Singular Value Decomposition (SVD) to decompose the original feature space into \\textit{two orthogonal subspaces}. By freezing the principal components and adapting only the remained components, we preserve the pre-trained knowledge while learning fake patterns. Compared to existing full-parameters and LoRA-based tuning methods, we explicitly ensure orthogonality, enabling the higher rank of the whole feature space, effectively minimizing overfitting and enhancing generalization. We finally identify a crucial insight: our method implicitly learns \\textit{a vital prior that fakes are actually derived from the real}, indicating a hierarchical relationship rather than independence. Modeling this prior, we believe, is essential for achieving superior generalization. Our codes are publicly available at \\href{https://github.com/YZY-stack/Effort-AIGI-Detection}{GitHub}.","authors":["Zhiyuan Yan","Jiangming Wang","Peng Jin","Ke-Yue Zhang","Chengchun Liu","Shen Chen","Taiping Yao","Shouhong Ding","Baoyuan Wu","Li Yuan"],"url":"https://arxiv.org/abs/2411.15633"}
{"created":"2025-05-20","title":"VICON: Vision In-Context Operator Networks for Multi-Physics Fluid Dynamics Prediction","abstract":"In-Context Operator Networks (ICONs) have demonstrated the ability to learn operators across diverse partial differential equations using few-shot, in-context learning. However, existing ICONs process each spatial point as an individual token, severely limiting computational efficiency when handling dense data in higher spatial dimensions. We propose Vision In-Context Operator Networks (VICON), which integrates vision transformer architectures to efficiently process 2D data through patch-wise operations while preserving ICON's adaptability to multiphysics systems and varying timesteps. Evaluated across three fluid dynamics benchmarks, VICON significantly outperforms state-of-the-art baselines: DPOT and MPP, reducing the averaged last-step rollout error by 37.9% compared to DPOT and 44.7% compared to MPP, while requiring only 72.5% and 34.8% of their respective inference times. VICON naturally supports flexible rollout strategies with varying timestep strides, enabling immediate deployment in imperfect measurement systems where sampling frequencies may differ or frames might be dropped - common challenges in real-world settings - without requiring retraining or interpolation. In these realistic scenarios, VICON exhibits remarkable robustness, experiencing only 24.41% relative performance degradation compared to 71.37%-74.49% degradation in baseline methods, demonstrating its versatility for deploying in realistic applications. Our scripts for processing datasets and code are publicly available at https://github.com/Eydcao/VICON.","authors":["Yadi Cao","Yuxuan Liu","Liu Yang","Rose Yu","Hayden Schaeffer","Stanley Osher"],"url":"https://arxiv.org/abs/2411.16063"}
{"created":"2025-05-20","title":"Local Learning for Covariate Selection in Nonparametric Causal Effect Estimation with Latent Variables","abstract":"Estimating causal effects from nonexperimental data is a fundamental problem in many fields of science. A key component of this task is selecting an appropriate set of covariates for confounding adjustment to avoid bias. Most existing methods for covariate selection often assume the absence of latent variables and rely on learning the global network structure among variables. However, identifying the global structure can be unnecessary and inefficient, especially when our primary interest lies in estimating the effect of a treatment variable on an outcome variable. To address this limitation, we propose a novel local learning approach for covariate selection in nonparametric causal effect estimation, which accounts for the presence of latent variables. Our approach leverages testable independence and dependence relationships among observed variables to identify a valid adjustment set for a target causal relationship, ensuring both soundness and completeness under standard assumptions. We validate the effectiveness of our algorithm through extensive experiments on both synthetic and real-world data.","authors":["Zheng Li","Feng Xie","Xichen Guo","Yan Zeng","Hao Zhang","Zhi Geng"],"url":"https://arxiv.org/abs/2411.16315"}
{"created":"2025-05-20","title":"Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent Framework","abstract":"The integration of experimental technologies with large language models (LLMs) is transforming scientific research. It positions AI as a versatile research assistant rather than a mere problem-solving tool. In the field of power systems, however, managing simulations -- one of the essential experimental technologies -- remains a challenge for LLMs due to their limited domain-specific knowledge, restricted reasoning capabilities, and imprecise handling of simulation parameters. To address these limitations, this paper proposes a feedback-driven, multi-agent framework. It incorporates three proposed modules: an enhanced retrieval-augmented generation (RAG) module, an improved reasoning module, and a dynamic environmental acting module with an error-feedback mechanism. Validated on 69 diverse tasks from Daline and MATPOWER, this framework achieves success rates of 93.13% and 96.85%, respectively. It significantly outperforms ChatGPT 4o, o1-preview, and the fine-tuned GPT-4o, which all achieved a success rate lower than 30% on complex tasks. Additionally, the proposed framework also supports rapid, cost-effective task execution, completing each simulation in approximately 30 seconds at an average cost of 0.014 USD for tokens. Overall, this adaptable framework lays a foundation for developing intelligent LLM-based assistants for human researchers, facilitating power system research and beyond.","authors":["Mengshuo Jia","Zeyu Cui","Gabriela Hug"],"url":"https://arxiv.org/abs/2411.16707"}
{"created":"2025-05-20","title":"Personalized Federated Fine-Tuning for LLMs via Data-Driven Heterogeneous Model Architectures","abstract":"Large-scale instruction data is essential for aligning pretrained Large Language Models (LLMs) with human instructions, but may contain sensitive information that hinders its public sharing. Federated Learning (FL) enables collaborative fine-tuning of LLMs without accessing raw data. However, existing approaches to federated LLM fine-tuning usually adopt a uniform model architecture, making it hard to fit highly heterogeneous client-side data in varying domains and formats. To address this, we propose FedAMoLE, a lightweight personalized FL framework that enables data-driven heterogeneous model architectures. This framework features a heterogeneous mixture of LoRA experts module for aggregating architecturally heterogeneous models and a reverse selection-based expert assignment strategy that optimizes model architectures based on data distributions. Experiments across five scenarios show that FedAMoLE improves client-side performance by an average of 5.14% compared to existing approaches while maintaining scalability.","authors":["Yicheng Zhang","Zhen Qin","Zhaomin Wu","Jian Hou","Shuiguang Deng"],"url":"https://arxiv.org/abs/2411.19128"}
{"created":"2025-05-20","title":"Simple and Provable Scaling Laws for the Test-Time Compute of Large Language Models","abstract":"We propose two simple, principled and practical algorithms that enjoy provable scaling laws for the test-time compute of large language models (LLMs). The first one is a two-stage knockout-style algorithm: given an input problem, it first generates multiple candidate solutions, and then aggregate them via a knockout tournament for the final output. Assuming that the LLM can generate a correct solution with non-zero probability and do better than a random guess in comparing a pair of correct and incorrect solutions, we prove theoretically that the failure probability of this algorithm decays to zero exponentially or by a power law (depending on the specific way of scaling) as its test-time compute grows. The second one is a two-stage league-style algorithm, where each candidate is evaluated by its average win rate against multiple opponents, rather than eliminated upon loss to a single opponent. Under analogous but more robust assumptions, we prove that its failure probability also decays to zero exponentially with more test-time compute. Both algorithms require a black-box LLM and nothing else (e.g., no verifier or reward model) for a minimalistic implementation, which makes them appealing for practical applications and easy to adapt for different tasks. Through extensive experiments with diverse models and datasets, we validate the proposed theories and demonstrate the outstanding scaling properties of both algorithms.","authors":["Yanxi Chen","Xuchen Pan","Yaliang Li","Bolin Ding","Jingren Zhou"],"url":"https://arxiv.org/abs/2411.19477"}
{"created":"2025-05-20","title":"Bootstraping Clustering of Gaussians for View-consistent 3D Scene Understanding","abstract":"Injecting semantics into 3D Gaussian Splatting (3DGS) has recently garnered significant attention. While current approaches typically distill 3D semantic features from 2D foundational models (e.g., CLIP and SAM) to facilitate novel view segmentation and semantic understanding, their heavy reliance on 2D supervision can undermine cross-view semantic consistency and necessitate complex data preparation processes, therefore hindering view-consistent scene understanding. In this work, we present FreeGS, an unsupervised semantic-embedded 3DGS framework that achieves view-consistent 3D scene understanding without the need for 2D labels. Instead of directly learning semantic features, we introduce the IDentity-coupled Semantic Field (IDSF) into 3DGS, which captures both semantic representations and view-consistent instance indices for each Gaussian. We optimize IDSF with a two-step alternating strategy: semantics help to extract coherent instances in 3D space, while the resulting instances regularize the injection of stable semantics from 2D space. Additionally, we adopt a 2D-3D joint contrastive loss to enhance the complementarity between view-consistent 3D geometry and rich semantics during the bootstrapping process, enabling FreeGS to uniformly perform tasks such as novel-view semantic segmentation, object selection, and 3D object detection. Extensive experiments on LERF-Mask, 3D-OVS, and ScanNet datasets demonstrate that FreeGS performs comparably to state-of-the-art methods while avoiding the complex data preprocessing workload. Our code is publicly available at https://github.com/wb014/FreeGS.","authors":["Wenbo Zhang","Lu Zhang","Ping Hu","Liqian Ma","Yunzhi Zhuge","Huchuan Lu"],"url":"https://arxiv.org/abs/2411.19551"}
{"created":"2025-05-20","title":"RECOVER: Toward Requirements Generation from Stakeholders' Conversations","abstract":"Stakeholders' conversations in requirements elicitation meetings hold valuable insights into system and client needs. However, manually extracting requirements is time-consuming, labor-intensive, and prone to errors and biases. While current state-of-the-art methods assist in summarizing stakeholder conversations and classifying requirements based on their nature, there is a noticeable lack of approaches capable of both identifying requirements within these conversations and generating corresponding system requirements. These approaches would assist requirement identification, reducing engineers' workload, time, and effort. To address this gap, this paper introduces RECOVER (Requirements EliCitation frOm conVERsations), a novel conversational requirements engineering approach that leverages natural language processing and large language models (LLMs) to support practitioners in automatically extracting system requirements from stakeholder interactions. The approach is evaluated using a mixed-method study that combines performance analysis with a user study involving requirements engineers, targeting two levels of granularity. First, at the conversation turn level, the evaluation measures RECOVER's accuracy in identifying requirements-relevant dialogue and the quality of generated requirements in terms of correctness, completeness, and actionability. Second, at the entire conversation level, the evaluation assesses the overall usefulness and effectiveness of RECOVER in synthesizing comprehensive system requirements from full stakeholder discussions. Empirical evaluation of RECOVER shows promising performance, with generated requirements demonstrating satisfactory correctness, completeness, and actionability. The results also highlight the potential of automating requirements elicitation from conversations as an aid that enhances efficiency while maintaining human oversight","authors":["Gianmario Voria","Francesco Casillo","Carmine Gravino","Gemma Catolino","Fabio Palomba"],"url":"https://arxiv.org/abs/2411.19552"}
{"created":"2025-05-20","title":"JetFormer: An Autoregressive Generative Model of Raw Images and Text","abstract":"Removing modeling constraints and unifying architectures across domains has been a key driver of the recent progress in training large multimodal models. However, most of these models still rely on many separately trained components such as modality-specific encoders and decoders. In this work, we further streamline joint generative modeling of images and text. We propose an autoregressive decoder-only transformer - JetFormer - which is trained to directly maximize the likelihood of raw data, without relying on any separately pretrained components, and can understand and generate both text and images. Specifically, we leverage a normalizing flow model to obtain a soft-token image representation that is jointly trained with an autoregressive multimodal transformer. The normalizing flow model serves as both an image encoder for perception tasks and an image decoder for image generation tasks during inference. JetFormer achieves text-to-image generation quality competitive with recent VQ-VAE- and VAE-based baselines. These baselines rely on pretrained image autoencoders, which are trained with a complex mixture of losses, including perceptual ones. At the same time, JetFormer demonstrates robust image understanding capabilities. To the best of our knowledge, JetFormer is the first model that is capable of generating high-fidelity images and producing strong log-likelihood bounds.","authors":["Michael Tschannen","Andr\\'e Susano Pinto","Alexander Kolesnikov"],"url":"https://arxiv.org/abs/2411.19722"}
{"created":"2025-05-20","title":"Incremental Multi-Scene Modeling via Continual Neural Graphics Primitives","abstract":"Neural radiance fields (NeRF) have revolutionized photorealistic rendering of novel views for 3D scenes. Despite their growing popularity and efficiency as 3D resources, NeRFs face scalability challenges due to the need for separate models per scene and the cumulative increase in training time for multiple scenes. The potential for incrementally encoding multiple 3D scenes into a single NeRF model remains largely unexplored. To address this, we introduce Continual-Neural Graphics Primitives (C-NGP), a novel continual learning framework that integrates multiple scenes incrementally into a single neural radiance field. Using a generative replay approach, C-NGP adapts to new scenes without requiring access to old data. We demonstrate that C-NGP can accommodate multiple scenes without increasing the parameter count, producing high-quality novel-view renderings on synthetic and real datasets. Notably, C-NGP models all $8$ scenes from the Real-LLFF dataset together, with only a $2.2\\%$ drop in PSNR compared to vanilla NeRF, which models each scene independently. Further, C-NGP allows multiple style edits in the same network.","authors":["Prajwal Singh","Ashish Tiwari","Gautam Vashishtha","Shanmuganathan Raman"],"url":"https://arxiv.org/abs/2411.19903"}
{"created":"2025-05-20","title":"VLSBench: Unveiling Visual Leakage in Multimodal Safety","abstract":"Safety concerns of Multimodal large language models (MLLMs) have gradually become an important problem in various applications. Surprisingly, previous works indicate a counterintuitive phenomenon that using textual unlearning to align MLLMs achieves comparable safety performances with MLLMs aligned with image text pairs. To explain such a phenomenon, we discover a Visual Safety Information Leakage (VSIL) problem in existing multimodal safety benchmarks, i.e., the potentially risky content in the image has been revealed in the textual query. Thus, MLLMs can easily refuse these sensitive image-text pairs according to textual queries only, leading to unreliable cross-modality safety evaluation of MLLMs. We also conduct a further comparison experiment between textual alignment and multimodal alignment to highlight this drawback. To this end, we construct multimodal Visual Leakless Safety Bench (VLSBench) with 2.2k image-text pairs through an automated data pipeline. Experimental results indicate that VLSBench poses a significant challenge to both open-source and close-source MLLMs, e.g., LLaVA, Qwen2-VL and GPT-4o. Besides, we empirically compare textual and multimodal alignment methods on VLSBench and find that textual alignment is effective enough for multimodal safety scenarios with VSIL, while multimodal alignment is preferable for safety scenarios without VSIL. Code and data are released under https://github.com/AI45Lab/VLSBench","authors":["Xuhao Hu","Dongrui Liu","Hao Li","Xuanjing Huang","Jing Shao"],"url":"https://arxiv.org/abs/2411.19939"}
{"created":"2025-05-20","title":"A Learn-to-Optimize Approach for Coordinate-Wise Step Sizes for Quasi-Newton Methods","abstract":"Tuning step sizes is crucial for the stability and efficiency of optimization algorithms. While adaptive coordinate-wise step sizes have been shown to outperform scalar step size in first-order methods, their use in second-order methods is still under-explored and more challenging. Current approaches, including hypergradient descent and cutting plane methods, offer limited improvements or encounter difficulties in second-order contexts. To address these limitations, we first conduct a theoretical analysis within the Broyden-Fletcher-Goldfarb-Shanno (BFGS) framework, a prominent quasi-Newton method, and derive sufficient conditions for coordinate-wise step sizes that ensure convergence and stability. Building on this theoretical foundation, we introduce a novel learn-to-optimize (L2O) method that employs LSTM-based networks to learn optimal step sizes by leveraging insights from past optimization trajectories, while inherently respecting the derived theoretical guarantees. Extensive experiments demonstrate that our approach achieves substantial improvements over scalar step size methods and hypergradient descent-based method, offering up to 4$\\times$ faster convergence across diverse optimization tasks.","authors":["Wei Lin","Qingyu Song","Hong Xu"],"url":"https://arxiv.org/abs/2412.00059"}
{"created":"2025-05-20","title":"C2HLSC: Leveraging Large Language Models to Bridge the Software-to-Hardware Design Gap","abstract":"High-Level Synthesis (HLS) tools offer rapid hardware design from C code, but their compatibility is limited by code constructs. This paper investigates Large Language Models (LLMs) for automatically refactoring C code into HLS-compatible formats. We present a case study using an LLM to rewrite C code for NIST 800-22 randomness tests, a QuickSort algorithm, and AES-128 into HLS-synthesizable C. The LLM iteratively transforms the C code guided by the system prompt and tool's feedback, implementing functions like streaming data and hardware-specific signals. With the hindsight obtained from the case study, we implement a fully automated framework to refactor C code into HLS-compatible formats using LLMs. To tackle complex designs, we implement a preprocessing step that breaks down the hierarchy in order to approach the problem in a divide-and-conquer bottom-up way. We validated our framework on three ciphers, one hash function, five NIST 800-22 randomness tests, and a QuickSort algorithm. Our results show a high success rate on benchmarks that are orders of magnitude more complex than what has been achieved generating Verilog with LLMs.","authors":["Luca Collini","Siddharth Garg","Ramesh Karri"],"url":"https://arxiv.org/abs/2412.00214"}
{"created":"2025-05-20","title":"Achieving PAC Guarantees in Mechanism Design through Multi-Armed Bandits","abstract":"We analytically derive a class of optimal solutions to a linear program (LP) for automated mechanism design that satisfies efficiency, incentive compatibility, strong budget balance (SBB), and individual rationality (IR), where SBB and IR are enforced in expectation. These solutions can be expressed using a set of essential variables whose cardinality is exponentially smaller than the total number of variables in the original formulation. However, evaluating a key term in the solutions requires exponentially many optimization steps as the number of players $N$ increases. We address this by translating the evaluation of this term into a multi-armed bandit (MAB) problem and develop a probably approximately correct (PAC) estimator with asymptotically optimal sample complexity. This MAB-based approach reduces the optimization complexity from exponential to $O(N\\log N)$. Numerical experiments confirm that our method efficiently computes mechanisms with the target properties, scaling to problems with up to $N=128$ players -- substantially improving over prior work.","authors":["Takayuki Osogami","Hirota Kinoshita","Segev Wasserkrug"],"url":"https://arxiv.org/abs/2412.00345"}
{"created":"2025-05-20","title":"On the Surprising Effectiveness of Spectrum Clipping in Learning Stable Linear Dynamics","abstract":"When learning stable linear dynamical systems from data, three important properties are desirable: i) predictive accuracy, ii) provable stability, and iii) computational efficiency. Unconstrained minimization of reconstruction errors leads to high accuracy and efficiency but cannot guarantee stability. Existing methods to enforce stability often preserve accuracy, but do so only at the cost of increased computation. In this work, we investigate if a straightforward approach can simultaneously offer all three desiderata of learning stable linear systems. Specifically, we consider a post-hoc approach that manipulates the spectrum of the learned system matrix that was computed using unconstrained least squares. We call this approach spectrum clipping (SC) as it involves eigen decomposition and subsequent reconstruction of the system matrix after clipping any eigenvalues that are larger than one to one (without altering the eigenvectors). Through comprehensive experiments involving two different applications and publicly available benchmark datasets, we show that this simple technique can efficiently learn highly-accurate linear systems that are provably-stable. Notably, we find that SC can match or outperform strong baselines while being orders-of-magnitude faster. We also show that SC can be readily combined with Koopman operators to learn stable nonlinear dynamics, such as those underlying complex dexterous manipulation skills involving multi-fingered robotic hands. Finally, we find that SC can learn stable robot policies even when the training data includes unsuccessful or truncated demonstrations. Our codes and dataset can be found at https://github.com/GT-STAR-Lab/spec_clip.","authors":["Hanyao Guo","Yunhai Han","Harish Ravichandar"],"url":"https://arxiv.org/abs/2412.01168"}
{"created":"2025-05-20","title":"See What You Seek: Semantic Contextual Integration for Cloth-Changing Person Re-Identification","abstract":"Cloth-changing person re-identification (CC-ReID) aims to match individuals across surveillance cameras despite variations in clothing. Existing methods typically mitigate the impact of clothing changes or enhance identity (ID)-relevant features, but they often struggle to capture complex semantic information. In this paper, we propose a novel prompt learning framework Semantic Contextual Integration (SCI), which leverages the visual-textual representation capabilities of CLIP to reduce clothing-induced discrepancies and strengthen ID cues. Specifically, we introduce the Semantic Separation Enhancement (SSE) module, which employs dual learnable text tokens to disentangle clothing-related semantics from confounding factors, thereby isolating ID-relevant features. Furthermore, we develop a Semantic-Guided Interaction Module (SIM) that uses orthogonalized text features to guide visual representations, sharpening the focus of the model on distinctive ID characteristics. This semantic integration improves the discriminative power of the model and enriches the visual context with high-dimensional insights. Extensive experiments on three CC-ReID datasets demonstrate that our method outperforms state-of-the-art techniques. The code will be released at https://github.com/hxy-499/CCREID-SCI.","authors":["Xiyu Han","Xian Zhong","Wenxin Huang","Xuemei Jia","Xiaohan Yu","Alex Chichung Kot"],"url":"https://arxiv.org/abs/2412.01345"}
{"created":"2025-05-20","title":"Can ChatGPT capture swearing nuances? Evidence from translating Arabic oaths","abstract":"This study sets out to answer one major question: Can ChatGPT capture swearing nuances? It presents an empirical study on the ability of ChatGPT to translate Arabic oath expressions into English. 30 Arabic oath expressions were collected from the literature. These 30 oaths were first translated via ChatGPT and then analyzed and compared to the human translation in terms of types of gaps left unfulfilled by ChatGPT. Specifically, the gaps involved are: religious gap, cultural gap, both religious and cultural gaps, no gap, using non-oath particles, redundancy and noncapturing of Arabic script diacritics. It concludes that ChatGPT translation of oaths is still much unsatisfactory, unveiling the need of further developments of ChatGPT, and the inclusion of Arabic data on which ChatGPT should be trained including oath expressions, oath nuances, rituals, and practices.","authors":["Mohammed Q. Shormani"],"url":"https://arxiv.org/abs/2412.02466"}
{"created":"2025-05-20","title":"Modeling and Discovering Direct Causes for Predictive Models","abstract":"We introduce a causal modeling framework that captures the input-output behavior of predictive models (e.g., machine learning models). The framework enables us to identify features that directly cause the predictions, which has broad implications for data collection and model evaluation. We then present sound and complete algorithms for discovering direct causes (from data) under some assumptions. Furthermore, we propose a novel independence rule that can be integrated with the algorithms to accelerate the discovery process, as we demonstrate both theoretically and empirically.","authors":["Yizuo Chen","Amit Bhatia"],"url":"https://arxiv.org/abs/2412.02878"}
{"created":"2025-05-20","title":"Parametric PerceptNet: A bio-inspired deep-net trained for Image Quality Assessment","abstract":"Human vision models are at the core of image processing. For instance, classical approaches to the problem of image quality are based on models that include knowledge about human vision. However, nowadays, deep learning approaches have obtained competitive results by simply approaching this problem as regression of human decisions, and training an standard network on human-rated datasets. These approaches have the advantages of being easily adaptable to a particular problem and they fit very efficiently when data is available. However, mainly due to the excess of parameters, they have the problems of lack of interpretability, and over-fitting. Here we propose a vision model that combines the best of both worlds by using a parametric neural network architecture. We parameterize the layers to have bioplausible functionality, and provide a set of bioplausible parameters. We analyzed different versions of the model and compared it with the non-parametric version. The parametric models achieve a three orders of magnitude reduction in the number of parameters without suffering in regression performance. Furthermore, we show that the parametric models behave better during training and are easier to interpret as vision models. Interestingly, we find that, even initialized with bioplausible trained for regression using human rated datasets, which we call the feature-spreading problem. This suggests that the deep learning approach is inherently flawed, and emphasizes the need to evaluate and train models beyond regression.","authors":["Jorge Vila-Tom\\'as","Pablo Hern\\'andez-C\\'amara","Valero Laparra","Jes\\'us Malo"],"url":"https://arxiv.org/abs/2412.03210"}
{"created":"2025-05-20","title":"Reinforcement Learning: An Overview","abstract":"This manuscript gives a big-picture, up-to-date overview of the field of (deep) reinforcement learning and sequential decision making, covering value-based methods, policy-based methods, model-based methods, multi-agent RL, LLMs and RL, and various other topics (e.g., offline RL, hierarchical RL, intrinsic reward).","authors":["Kevin Murphy"],"url":"https://arxiv.org/abs/2412.05265"}
{"created":"2025-05-20","title":"MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization","abstract":"The advancement of Large Vision-Language Models (LVLMs) has propelled their application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter factuality challenges due to modality misalignment, where the models prioritize textual knowledge over visual input, leading to hallucinations that contradict information in medical images. Previous attempts to enhance modality alignment in Med-LVLMs through preference optimization have inadequately mitigated clinical relevance in preference data, making these samples easily distinguishable and reducing alignment effectiveness. To address this challenge, we propose MMedPO, a novel multimodal medical preference optimization approach that considers the clinical relevance of preference samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference data by introducing two types of dispreference: (1) plausible hallucinations injected through target Med-LVLMs or GPT-4o to produce medically inaccurate responses, and (2) lesion region neglect achieved through local lesion-noising, disrupting visual understanding of critical areas. We then calculate clinical relevance for each sample based on scores from multiple Med-LLMs and visual tools, and integrate these scores into the preference optimization process as weights, enabling effective alignment. Our experiments demonstrate that MMedPO significantly enhances factual accuracy in Med-LVLMs, achieving substantial improvements over existing preference optimization methods by averaging 14.2% and 51.7% across the Med-VQA and report generation tasks. Our code are available in https://github.com/aiming-lab/MMedPO.","authors":["Kangyu Zhu","Peng Xia","Yun Li","Hongtu Zhu","Sheng Wang","Huaxiu Yao"],"url":"https://arxiv.org/abs/2412.06141"}
{"created":"2025-05-20","title":"Tube Loss: A Novel Approach for Prediction Interval Estimation and probabilistic forecasting","abstract":"This paper proposes a novel loss function, called 'Tube Loss', for simultaneous estimation of bounds of a Prediction Interval (PI) in the regression setup. The PIs obtained by minimizing the empirical risk based on the Tube Loss are shown to be of better quality than the PIs obtained by the existing methods in the following sense. First, it yields intervals that attain the prespecified confidence level t $\\in$ (0,1) asymptotically. A theoretical proof of this fact is given. Secondly, the user is allowed to move the interval up or down by controlling the value of a parameter. This helps the user to choose a PI capturing denser regions of the probability distribution of the response variable inside the interval, and thus, sharpening its width. This is shown to be especially useful when the conditional distribution of the response variable is skewed. Further, the Tube Loss based PI estimation method can trade-off between the coverage and the average width by solving a single optimization problem. It enables further reduction of the average width of PI through re-calibration. Also, unlike a few existing PI estimation methods the gradient descent (GD) method can be used for minimization of empirical risk. Through extensive experiments, we demonstrate the effectiveness of Tube Loss-based PI estimation in both kernel machines and neural networks. Additionally, we show that Tube Loss-based deep probabilistic forecasting models achieve superior performance compared to existing probabilistic forecasting techniques across several benchmark and wind datasets. Finally, we empirically validate the advantages of the Tube loss approach within the conformal prediction framework. Codes are available at https://github.com/ltpritamanand/Tube$\\_$loss.","authors":["Pritam Anand","Tathagata Bandyopadhyay","Suresh Chandra"],"url":"https://arxiv.org/abs/2412.06853"}
{"created":"2025-05-20","title":"Massively Parallel Algorithms for Approximate Shortest Paths","abstract":"We present fast algorithms for approximate shortest paths in the massively parallel computation (MPC) model. We provide randomized algorithms that take $poly(\\log{\\log{n}})$ rounds in the near-linear memory MPC model. Our results are for unweighted undirected graphs with $n$ vertices and $m$ edges. Our first contribution is a $(1+\\epsilon)$-approximation algorithm for Single-Source Shortest Paths (SSSP) that takes $poly(\\log{\\log{n}})$ rounds in the near-linear MPC model, where the memory per machine is $\\tilde{O}(n)$ and the total memory is $\\tilde{O}(mn^{\\rho})$, where $\\rho$ is a small constant. Our second contribution is a distance oracle that allows to approximate the distance between any pair of vertices. The distance oracle is constructed in $poly(\\log{\\log{n}})$ rounds and allows to query a $(1+\\epsilon)(2k-1)$-approximate distance between any pair of vertices $u$ and $v$ in $O(1)$ additional rounds. The algorithm is for the near-linear memory MPC model with total memory of size $\\tilde{O}((m+n^{1+\\rho})n^{1/k})$, where $\\rho$ is a small constant. While our algorithms are for the near-linear MPC model, in fact they only use one machine with $\\tilde{O}(n)$ memory, where the rest of machines can have sublinear memory of size $O(n^{\\gamma})$ for a small constant $\\gamma < 1$. All previous algorithms for approximate shortest paths in the near-linear MPC model either required $\\Omega(\\log{n})$ rounds or had an $\\Omega(\\log{n})$ approximation. Our approach is based on fast construction of near-additive emulators, limited-scale hopsets and limited-scale distance sketches that are tailored for the MPC model. While our end-results are for the near-linear MPC model, many of the tools we construct such as hopsets and emulators are constructed in the more restricted sublinear MPC model.","authors":["Michal Dory","Shaked Matar"],"url":"https://arxiv.org/abs/2412.06952"}
{"created":"2025-05-20","title":"Omni-ID: Holistic Identity Representation Designed for Generative Tasks","abstract":"We introduce Omni-ID, a novel facial representation designed specifically for generative tasks. Omni-ID encodes holistic information about an individual's appearance across diverse expressions and poses within a fixed-size representation. It consolidates information from a varied number of unstructured input images into a structured representation, where each entry represents certain global or local identity features. Our approach uses a few-to-many identity reconstruction training paradigm, where a limited set of input images is used to reconstruct multiple target images of the same individual in various poses and expressions. A multi-decoder framework is further employed to leverage the complementary strengths of diverse decoders during training. Unlike conventional representations, such as CLIP and ArcFace, which are typically learned through discriminative or contrastive objectives, Omni-ID is optimized with a generative objective, resulting in a more comprehensive and nuanced identity capture for generative tasks. Trained on our MFHQ dataset -- a multi-view facial image collection, Omni-ID demonstrates substantial improvements over conventional representations across various generative tasks.","authors":["Guocheng Qian","Kuan-Chieh Wang","Or Patashnik","Negin Heravi","Daniil Ostashev","Sergey Tulyakov","Daniel Cohen-Or","Kfir Aberman"],"url":"https://arxiv.org/abs/2412.09694"}
{"created":"2025-05-20","title":"Going Beyond Feature Similarity: Effective Dataset Distillation based on Class-Aware Conditional Mutual Information","abstract":"Dataset distillation (DD) aims to minimize the time and memory consumption needed for training deep neural networks on large datasets, by creating a smaller synthetic dataset that has similar performance to that of the full real dataset. However, current dataset distillation methods often result in synthetic datasets that are excessively difficult for networks to learn from, due to the compression of a substantial amount of information from the original data through metrics measuring feature similarity, e,g., distribution matching (DM). In this work, we introduce conditional mutual information (CMI) to assess the class-aware complexity of a dataset and propose a novel method by minimizing CMI. Specifically, we minimize the distillation loss while constraining the class-aware complexity of the synthetic dataset by minimizing its empirical CMI from the feature space of pre-trained networks, simultaneously. Conducting on a thorough set of experiments, we show that our method can serve as a general regularization method to existing DD methods and improve the performance and training efficiency.","authors":["Xinhao Zhong","Bin Chen","Hao Fang","Xulin Gu","Shu-Tao Xia","En-Hui Yang"],"url":"https://arxiv.org/abs/2412.09945"}
{"created":"2025-05-20","title":"Supervised Learning-enhanced Multi-Group Actor Critic for Live Stream Allocation in Feed","abstract":"In the context of a short video & live stream mixed recommendation scenario, the live stream recommendation system (RS) decides whether to allocate at most one live stream into the video feed for each user request. To maximize long-term user engagement, it is crucial to determine an optimal live stream policy for accurate live stream allocation. The inappropriate live stream allocation policy can significantly affect the duration of the usage app and user retention, which ignores the long-term negative impact of live stream allocation. Recently, reinforcement learning (RL) has been widely applied in recommendation systems to capture long-term user engagement. However, traditional RL algorithms often face divergence and instability problems, which restricts the application and deployment in the large-scale industrial recommendation systems, especially in the aforementioned challenging scenario. To address these challenges, we propose a novel Supervised Learning-enhanced Multi-Group Actor Critic algorithm (SL-MGAC). Specifically, we introduce a supervised learning-enhanced actor-critic framework that incorporates variance reduction techniques, where multi-task reward learning helps restrict bootstrapping error accumulation during critic learning. Additionally, we design a multi-group state decomposition module for both actor and critic networks to reduce prediction variance and improve model stability. We also propose a novel reward function to prevent overly greedy live stream allocation. Empirically, we evaluate the SL-MGAC algorithm using offline policy evaluation (OPE) and online A/B testing. Experimental results demonstrate that the proposed method not only outperforms baseline methods under the platform-level constraints but also exhibits enhanced stability in online recommendation scenarios.","authors":["Jingxin Liu","Xiang Gao","Yisha Li","Xin Li","Haiyang Lu","Ben Wang"],"url":"https://arxiv.org/abs/2412.10381"}
{"created":"2025-05-20","title":"Superhuman performance of a large language model on the reasoning tasks of a physician","abstract":"A seminal paper published by Ledley and Lusted in 1959 introduced complex clinical diagnostic reasoning cases as the gold standard for the evaluation of expert medical computing systems, a standard that has held ever since. Here, we report the results of a physician evaluation of a large language model (LLM) on challenging clinical cases against a baseline of hundreds of physicians. We conduct five experiments to measure clinical reasoning across differential diagnosis generation, display of diagnostic reasoning, triage differential diagnosis, probabilistic reasoning, and management reasoning, all adjudicated by physician experts with validated psychometrics. We then report a real-world study comparing human expert and AI second opinions in randomly-selected patients in the emergency room of a major tertiary academic medical center in Boston, MA. We compared LLMs and board-certified physicians at three predefined diagnostic touchpoints: triage in the emergency room, initial evaluation by a physician, and admission to the hospital or intensive care unit. In all experiments--both vignettes and emergency room second opinions--the LLM displayed superhuman diagnostic and reasoning abilities, as well as continued improvement from prior generations of AI clinical decision support. Our study suggests that LLMs have achieved superhuman performance on general medical diagnostic and management reasoning, fulfilling the vision put forth by Ledley and Lusted, and motivating the urgent need for prospective trials.","authors":["Peter G. Brodeur","Thomas A. Buckley","Zahir Kanjee","Ethan Goh","Evelyn Bin Ling","Priyank Jain","Stephanie Cabral","Raja-Elie Abdulnour","Adrian D. Haimovich","Jason A. Freed","Andrew Olson","Daniel J. Morgan","Jason Hom","Robert Gallo","Liam G. McCoy","Haadi Mombini","Christopher Lucas","Misha Fotoohi","Matthew Gwiazdon","Daniele Restifo","Daniel Restrepo","Eric Horvitz","Jonathan Chen","Arjun K. Manrai","Adam Rodman"],"url":"https://arxiv.org/abs/2412.10849"}
{"created":"2025-05-20","title":"Adaptive Reward Design for Reinforcement Learning","abstract":"There is a surge of interest in using formal languages such as Linear Temporal Logic (LTL) to precisely and succinctly specify complex tasks and derive reward functions for Reinforcement Learning (RL). However, existing methods often assign sparse rewards (e.g., giving a reward of 1 only if a task is completed and 0 otherwise). By providing feedback solely upon task completion, these methods fail to encourage successful subtask completion. This is particularly problematic in environments with inherent uncertainty, where task completion may be unreliable despite progress on intermediate goals. To address this limitation, we propose a suite of reward functions that incentivize an RL agent to complete a task specified by an LTL formula as much as possible, and develop an adaptive reward shaping approach that dynamically updates reward functions during the learning process. Experimental results on a range of benchmark RL environments demonstrate that the proposed approach generally outperforms baselines, achieving earlier convergence to a better policy with higher expected return and task completion rate.","authors":["Minjae Kwon","Ingy ElSayed-Aly","Lu Feng"],"url":"https://arxiv.org/abs/2412.10917"}
{"created":"2025-05-20","title":"Auto-bidding in real-time auctions via Oracle Imitation Learning (OIL)","abstract":"Online advertising has become one of the most successful business models of the internet era. Impression opportunities are typically allocated through real-time auctions, where advertisers bid to secure advertisement slots. Deciding the best bid for an impression opportunity is challenging, due to the stochastic nature of user behavior and the variability of advertisement traffic over time. In this work, we propose a framework for training auto-bidding agents in multi-slot second-price auctions to maximize acquisitions (e.g., clicks, conversions) while adhering to budget and cost-per-acquisition (CPA) constraints. We exploit the insight that, after an advertisement campaign concludes, determining the optimal bids for each impression opportunity can be framed as a multiple-choice knapsack problem (MCKP) with a nonlinear objective. We propose an \"oracle\" algorithm that identifies a near-optimal combination of impression opportunities and advertisement slots, considering both past and future advertisement traffic data. This oracle solution serves as a training target for a student network which bids having access only to real-time information, a method we term Oracle Imitation Learning (OIL). Through numerical experiments, we demonstrate that OIL achieves superior performance compared to both online and offline reinforcement learning algorithms, offering improved sample efficiency. Notably, OIL shifts the complexity of training auto-bidding agents from crafting sophisticated learning algorithms to solving a nonlinear constrained optimization problem efficiently.","authors":["Alberto Silvio Chiappa","Briti Gangopadhyay","Zhao Wang","Shingo Takamatsu"],"url":"https://arxiv.org/abs/2412.11434"}
{"created":"2025-05-20","title":"Intention Knowledge Graph Construction for User Intention Relation Modeling","abstract":"Understanding user intentions is challenging for online platforms. Recent work on intention knowledge graphs addresses this but often lacks focus on connecting intentions, which is crucial for modeling user behavior and predicting future actions. This paper introduces a framework to automatically generate an intention knowledge graph, capturing connections between user intentions. Using the Amazon m2 dataset, we construct an intention graph with 351 million edges, demonstrating high plausibility and acceptance. Our model effectively predicts new session intentions and enhances product recommendations, outperforming previous state-of-the-art methods and showcasing the approach's practical utility.","authors":["Jiaxin Bai","Zhaobo Wang","Junfei Cheng","Dan Yu","Zerui Huang","Weiqi Wang","Xin Liu","Chen Luo","Yanming Zhu","Bo Li","Yangqiu Song"],"url":"https://arxiv.org/abs/2412.11500"}
{"created":"2025-05-20","title":"DateLogicQA: Benchmarking Temporal Biases in Large Language Models","abstract":"This paper introduces DateLogicQA, a benchmark with 190 questions covering diverse date formats, temporal contexts, and reasoning types. We propose the Semantic Integrity Metric to assess tokenization quality and analyse two biases: Representation-Level Bias, affecting embeddings, and Logical-Level Bias, influencing reasoning outputs. Our findings provide a comprehensive evaluation of LLMs' capabilities and limitations in temporal reasoning, highlighting key challenges in handling temporal data accurately.","authors":["Gagan Bhatia","MingZe Tang","Cristina Mahanta","Madiha Kazi"],"url":"https://arxiv.org/abs/2412.13377"}
{"created":"2025-05-20","title":"Theoretical Proof that Auto-regressive Language Models Collapse when Real-world Data is a Finite Set","abstract":"Auto-regressive language models (LMs) have been widely used to generate data in data-scarce domains to train new LMs, compensating for the scarcity of real-world data. Previous work experimentally found that LMs collapse when trained on recursively generated data. This paper presents a theoretical proof: once a corpus (such as a subset of the World Wide Web) begins to incorporate generated data and no new real-world data is added to the corpus, then no matter how small the amount of data each LM generates and contributes to the corpus, LM collapse is inevitable after sufficient time. This finding suggests that attempts to mitigate collapse by limiting the quantity of synthetic data in the corpus are fundamentally insufficient. Instead, avoiding collapse hinges on ensuring the quality of synthetic data.","authors":["Lecheng Wang","Xianjie Shi","Ge Li","Jia Li","Xuanming Zhang","Yihong Dong","Wenpin Jiao","Hong Mei"],"url":"https://arxiv.org/abs/2412.14872"}
{"created":"2025-05-20","title":"A bound-preserving Runge--Kutta discontinuous Galerkin method with compact stencils for hyperbolic conservation laws","abstract":"In this paper, we develop bound-preserving techniques for the Runge--Kutta (RK) discontinuous Galerkin (DG) method with compact stencils (cRKDG method) for hyperbolic conservation laws. The cRKDG method was recently introduced in [Q. Chen, Z. Sun, and Y. Xing, SIAM J. Sci. Comput., 46: A1327--A1351, 2024]. It enhances the compactness of the standard RKDG method, resulting in reduced data communication, simplified boundary treatments, and improved suitability for local time marching. This work improves the robustness of the cRKDG method by enforcing desirable physical bounds while preserving its compactness, local conservation, and high-order accuracy. Our method is extended from the seminal work of [X. Zhang and C.-W. Shu, J. Comput. Phys., 229: 3091--3120, 2010]. We prove that the cell average of the cRKDG method at each RK stage preserves the physical bounds by expressing it as a convex combination of three types of forward-Euler solutions. A scaling limiter is then applied after each RK stage to enforce pointwise bounds. Additionally, we explore RK methods with less restrictive time step sizes. Because the cRKDG method does not rely on strong-stability-preserving RK time discretization, it avoids its order barriers, allowing us to construct a four-stage, fourth-order bound-preserving cRKDG method. Numerical tests on challenging benchmarks are provided to demonstrate the performance of the proposed method.","authors":["Chen Liu","Zheng Sun","Xiangxiong Zhang"],"url":"https://arxiv.org/abs/2412.16002"}
{"created":"2025-05-20","title":"Optimizing Queries with Many-to-Many Joins","abstract":"As database query processing techniques are being used to handle diverse workloads, a key emerging challenge is how to efficiently handle multi-way join queries containing multiple many-to-many joins. While uncommon in traditional enterprise settings that have been the focus of much of the query optimization work to date, such queries are seen frequently in other contexts such as graph workloads. This has led to much work on developing join algorithms for handling cyclic queries, on compressed (factorized) representations for more efficient storage of intermediate results, and on use of semi-joins or predicate transfer to avoid generating large redundant intermediate results. In this paper, we address a core query optimization problem in this context. Specifically, we introduce an improved cost model that more accurately captures the cost of a query plan in such scenarios, and we present several optimization algorithms for query optimization that incorporate these new cost functions. We present an extensive experimental evaluation, that compares the factorized representation approach with a full semi-join reduction approach as well as to an approach that uses bitvectors to eliminate tuples early through sideways information passing. We also present new analyses of robustness of these techniques to the choice of the join order, potentially eliminating the need for more complex query optimization and selectivity estimation techniques.","authors":["Hasara Kalumin","Amol Deshpande"],"url":"https://arxiv.org/abs/2412.16323"}
{"created":"2025-05-20","title":"Task-Driven Co-Design of Mobile Manipulators","abstract":"Recent interest in mobile manipulation has resulted in a wide range of new robot designs. A large family of these designs focuses on modular platforms that combine existing mobile bases with static manipulator arms. They combine these modules by mounting the arm in a tabletop configuration. However, the operating workspaces and heights for common mobile manipulation tasks, such as opening articulated objects, significantly differ from tabletop manipulation tasks. As a result, these standard arm mounting configurations can result in kinematics with restricted joint ranges and motions. To address these problems, we present the first Concurrent Design approach for mobile manipulators to optimize key arm-mounting parameters. Our approach directly targets task performance across representative household tasks by training a powerful multitask-capable reinforcement learning policy in an inner loop while optimizing over a distribution of design configurations guided by Bayesian Optimization and HyperBand (BOHB) in an outer loop. This results in novel designs that significantly improve performance across both seen and unseen test tasks, and outperform designs generated by heuristic-based performance indices that are cheaper to evaluate but only weakly correlated with the motions of interest. We evaluate the physical feasibility of the resulting designs and show that they are practical and remain modular, affordable, and compatible with existing commercial components. We open-source the approach and generated designs to facilitate further improvements of these platforms.","authors":["Raphael Schneider","Daniel Honerkamp","Tim Welschehold","Abhinav Valada"],"url":"https://arxiv.org/abs/2412.16635"}
{"created":"2025-05-20","title":"Multi-Agent Sampling: Scaling Inference Compute for Data Synthesis with Tree Search-Based Agentic Collaboration","abstract":"Scaling laws for inference compute in multi-agent systems remain under-explored compared to single-agent scenarios. This work aims to bridge this gap by investigating the problem of data synthesis through multi-agent sampling, where synthetic responses are generated by sampling from multiple distinct language models. Effective model coordination is crucial for successful multi-agent collaboration. Unlike previous approaches that rely on fixed workflows, we treat model coordination as a multi-step decision-making process, optimizing generation structures dynamically for each input question. We introduce Tree Search-based Orchestrated Agents~(TOA), where the workflow evolves iteratively during the sequential sampling process. To achieve this, we leverage Monte Carlo Tree Search (MCTS), integrating a reward model to provide real-time feedback and accelerate exploration. Our experiments on alignment, machine translation, and mathematical reasoning demonstrate that multi-agent sampling significantly outperforms single-agent sampling as inference compute scales. TOA is the most compute-efficient approach, achieving SOTA performance on WMT and a 72.2\\% LC win rate on AlpacaEval. Moreover, fine-tuning with our synthesized alignment data surpasses strong preference learning methods on challenging benchmarks such as Arena-Hard and AlpacaEval.","authors":["Hai Ye","Mingbao Lin","Hwee Tou Ng","Shuicheng Yan"],"url":"https://arxiv.org/abs/2412.17061"}
{"created":"2025-05-20","title":"Automating the Search for Artificial Life with Foundation Models","abstract":"With the recent Nobel Prize awarded for radical advances in protein discovery, foundation models (FMs) for exploring large combinatorial spaces promise to revolutionize many scientific fields. Artificial Life (ALife) has not yet integrated FMs, thus presenting a major opportunity for the field to alleviate the historical burden of relying chiefly on manual design and trial-and-error to discover the configurations of lifelike simulations. This paper presents, for the first time, a successful realization of this opportunity using vision-language FMs. The proposed approach, called Automated Search for Artificial Life (ASAL), (1) finds simulations that produce target phenomena, (2) discovers simulations that generate temporally open-ended novelty, and (3) illuminates an entire space of interestingly diverse simulations. Because of the generality of FMs, ASAL works effectively across a diverse range of ALife substrates including Boids, Particle Life, Game of Life, Lenia, and Neural Cellular Automata. A major result highlighting the potential of this technique is the discovery of previously unseen Lenia and Boids lifeforms, as well as cellular automata that are open-ended like Conway's Game of Life. Additionally, the use of FMs allows for the quantification of previously qualitative phenomena in a human-aligned way. This new paradigm promises to accelerate ALife research beyond what is possible through human ingenuity alone.","authors":["Akarsh Kumar","Chris Lu","Louis Kirsch","Yujin Tang","Kenneth O. Stanley","Phillip Isola","David Ha"],"url":"https://arxiv.org/abs/2412.17799"}
{"created":"2025-05-20","title":"KunServe: Parameter-centric Memory Management for Efficient Memory Throttling Handling in LLM Serving","abstract":"Serving LLMs with a cluster of GPUs is common nowadays, where the serving system must meet strict latency SLOs required by applications. However, the stateful nature of LLM serving requires maintaining huge states (i.e., KVCache) in limited GPU memory. Under spikes in real-world workloads, GPU memory can be easily throttled, leading to orders of magnitude higher response latency due to queuing introduced by waiting for KVCache to be reclaimed. Prior KVCache-centric approaches handle load throttling by dropping, migrating, or swapping KVCache. These methods fail to release sufficient memory quickly with requests still queued.","authors":["Rongxin Cheng","Yuxin Lai","Xingda Wei","Rong Chen","Haibo Chen"],"url":"https://arxiv.org/abs/2412.18169"}
{"created":"2025-05-20","title":"GeFL: Model-Agnostic Federated Learning with Generative Models","abstract":"Federated learning (FL) is a distributed training paradigm that enables collaborative learning across clients without sharing local data, thereby preserving privacy. However, the increasing scale and complexity of modern deep models often exceed the computational or memory capabilities of edge devices. Furthermore, clients may be constrained to use heterogeneous model architectures due to hardware variability (e.g., ASICs, FPGAs) or proprietary requirements that prevent the disclosure or modification of local model structures. These practical considerations motivate the need for model-heterogeneous FL, where clients participate using distinct model architectures. In this work, we propose Generative Model-Aided Federated Learning (GeFL), a framework that enables cross-client knowledge sharing via a generative model trained in a federated manner. This generative model captures global data semantics and facilitates local training without requiring model homogeneity across clients. While GeFL achieves strong performance, empirical analysis reveals limitations in scalability and potential privacy leakage due to generative sample memorization. To address these concerns, we propose GeFL-F, which utilizes feature-level generative modeling. This approach enhances scalability to large client populations and mitigates privacy risks. Extensive experiments across image classification tasks demonstrate that both GeFL and GeFL-F offer competitive performance in heterogeneous settings. Code is available at [1].","authors":["Honggu Kang","Seohyeon Cha","Joonhyuk Kang"],"url":"https://arxiv.org/abs/2412.18460"}
{"created":"2025-05-20","title":"How Panel Layouts Define Manga: Insights from Visual Ablation Experiments","abstract":"Today, manga has gained worldwide popularity. However, the question of how various elements of manga, such as characters, text, and panel layouts, reflect the uniqueness of a particular work, or even define it, remains an unexplored area. In this paper, we aim to quantitatively and qualitatively analyze the visual characteristics of manga works, with a particular focus on panel layout features. As a research method, we used facing page images of manga as input to train a deep learning model for predicting manga titles, examining classification accuracy to quantitatively analyze these features. Specifically, we conducted ablation studies by limiting page image information to panel frames to analyze the characteristics of panel layouts. Through a series of quantitative experiments using all 104 works, 12 genres, and 10,122 facing page images from the Manga109 dataset, as well as qualitative analysis using Grad-CAM, our study demonstrates that the uniqueness of manga works is strongly reflected in their panel layouts.","authors":["Siyuan Feng","Teruya Yoshinaga","Katsuhiko Hayashi","Koki Washio","Hidetaka Kamigaito"],"url":"https://arxiv.org/abs/2412.19141"}
{"created":"2025-05-20","title":"GSplatLoc: Ultra-Precise Camera Localization via 3D Gaussian Splatting","abstract":"We present GSplatLoc, a camera localization method that leverages the differentiable rendering capabilities of 3D Gaussian splatting for ultra-precise pose estimation. By formulating pose estimation as a gradient-based optimization problem that minimizes discrepancies between rendered depth maps from a pre-existing 3D Gaussian scene and observed depth images, GSplatLoc achieves translational errors within 0.01 cm and near-zero rotational errors on the Replica dataset - significantly outperforming existing methods. Evaluations on the Replica and TUM RGB-D datasets demonstrate the method's robustness in challenging indoor environments with complex camera motions. GSplatLoc sets a new benchmark for localization in dense mapping, with important implications for applications requiring accurate real-time localization, such as robotics and augmented reality.","authors":["Atticus J. Zeller (Southeast University Chengxian College","Nanjing","China)","Haijuan Wu (Southeast University Chengxian College","Nanjing","China)"],"url":"https://arxiv.org/abs/2412.20056"}
{"created":"2025-05-20","title":"Highway Dimension: a Metric View","abstract":"Realistic metric spaces (such as road/transportation networks) tend to be much more algorithmically tractable than general metrics. In an attempt to formalize this intuition, Abraham et al. (SODA 2010, JACM 2016) introduced the notion of highway dimension. A weighted graph $G$ has highway dimension $h$ if for every ball $B$ of radius $\\approx 4r$ there is a hitting set of size $h$ hitting all the shortest paths of length $>r$ in $B$. Unfortunately, this definition fails to incorporate some very natural metric spaces such as the grid graph, and the Euclidean plane.","authors":["Andreas Emil Feldmann","Arnold Filtser"],"url":"https://arxiv.org/abs/2412.20490"}
{"created":"2025-05-20","title":"DPBridge: Latent Diffusion Bridge for Dense Prediction","abstract":"Diffusion models demonstrate remarkable capabilities in capturing complex data distributions and have achieved compelling results in many generative tasks. While they have recently been extended to dense prediction tasks such as depth estimation and surface normal prediction, their full potential in this area remains under-explored. In dense prediction settings, target signal maps and input images are pixel-wise aligned. This makes conventional noise-to-data generation paradigm inefficient, as input images can serve as more informative prior compared to pure noise. Diffusion bridge models, which support data-to-data generation between two general data distributions, offer a promising alternative, but they typically fail to exploit the rich visual priors embedded in large pretrained foundation models. To address these limitations, we integrate diffusion bridge formulation with structured visual priors and introduce DPBridge, the first latent diffusion bridge framework for dense prediction tasks. Our method presents three key contributions: (1) a tractable reverse transition kernel for diffusion bridge process, enabling maximum likelihood training scheme for better compatibility with pretrained backbones; (2) a distribution-aligned normalization technique to mitigate the discrepancies between the bridge and standard diffusion processes; and (3) an auxiliary image consistency loss to preserve fine-grained details. Experiments across extensive benchmarks validate that our method consistently achieves superior performance, demonstrating its effectiveness and generalization capability under different scenarios.","authors":["Haorui Ji","Taojun Lin","Hongdong Li"],"url":"https://arxiv.org/abs/2412.20506"}
{"created":"2025-05-20","title":"Simulated prosthetic vision confirms checkerboard as an effective raster pattern for epiretinal implants","abstract":"Spatial scheduling of electrode activation (\"rastering\") is essential for safely operating high-density retinal implants, yet its perceptual consequences remain poorly understood. This study systematically evaluates the impact of raster patterns, or spatial arrangements of sequential electrode activation, on performance and perceived difficulty in simulated prosthetic vision (SPV). By addressing this gap, we aimed to identify patterns that optimize functional vision in retinal implants. Sighted participants completed letter recognition and motion discrimination tasks under four raster patterns (horizontal, vertical, checkerboard, and random) using an immersive SPV system. The simulations emulated epiretinal implant perception and employed psychophysically validated models of electrode activation, phosphene appearance, nonlinear spatial summation, and temporal dynamics, ensuring realistic representation of prosthetic vision. Performance accuracy and self-reported difficulty were analyzed to assess the effects of raster patterning. The checkerboard pattern consistently outperformed other raster patterns, yielding significantly higher accuracy and lower difficulty ratings across both tasks. The horizontal and vertical patterns introduced biases aligned with apparent motion artifacts, while the checkerboard minimized such effects. Random patterns resulted in the lowest performance, underscoring the importance of structured activation. Notably, checkerboard matched performance in the \"No Raster\" condition, despite conforming to groupwise safety constraints. This is the first quantitative, task-based evaluation of raster patterns in SPV. Checkerboard-style scheduling enhances perceptual clarity without increasing computational load, offering a low-overhead, clinically relevant strategy for improving usability in next-generation retinal prostheses.","authors":["Justin M. Kasowski","Apurv Varshney","Roksana Sadeghi","Michael Beyeler"],"url":"https://arxiv.org/abs/2501.02084"}
{"created":"2025-05-20","title":"Beyond CVaR: Leveraging Static Spectral Risk Measures for Enhanced Decision-Making in Distributional Reinforcement Learning","abstract":"In domains such as finance, healthcare, and robotics, managing worst-case scenarios is critical, as failure to do so can lead to catastrophic outcomes. Distributional Reinforcement Learning (DRL) provides a natural framework to incorporate risk sensitivity into decision-making processes. However, existing approaches face two key limitations: (1) the use of fixed risk measures at each decision step often results in overly conservative policies, and (2) the interpretation and theoretical properties of the learned policies remain unclear. While optimizing a static risk measure addresses these issues, its use in the DRL framework has been limited to the simple static CVaR risk measure. In this paper, we present a novel DRL algorithm with convergence guarantees that optimizes for a broader class of static Spectral Risk Measures (SRM). Additionally, we provide a clear interpretation of the learned policy by leveraging the distribution of returns in DRL and the decomposition of static coherent risk measures. Extensive experiments demonstrate that our model learns policies aligned with the SRM objective, and outperforms existing risk-neutral and risk-sensitive DRL models in various settings.","authors":["Mehrdad Moghimi","Hyejin Ku"],"url":"https://arxiv.org/abs/2501.02087"}
{"created":"2025-05-20","title":"Origin Identification for Text-Guided Image-to-Image Diffusion Models","abstract":"Text-guided image-to-image diffusion models excel in translating images based on textual prompts, allowing for precise and creative visual modifications. However, such a powerful technique can be misused for spreading misinformation, infringing on copyrights, and evading content tracing. This motivates us to introduce the task of origin IDentification for text-guided Image-to-image Diffusion models (ID$^2$), aiming to retrieve the original image of a given translated query. A straightforward solution to ID$^2$ involves training a specialized deep embedding model to extract and compare features from both query and reference images. However, due to visual discrepancy across generations produced by different diffusion models, this similarity-based approach fails when training on images from one model and testing on those from another, limiting its effectiveness in real-world applications. To solve this challenge of the proposed ID$^2$ task, we contribute the first dataset and a theoretically guaranteed method, both emphasizing generalizability. The curated dataset, OriPID, contains abundant Origins and guided Prompts, which can be used to train and test potential IDentification models across various diffusion models. In the method section, we first prove the existence of a linear transformation that minimizes the distance between the pre-trained Variational Autoencoder (VAE) embeddings of generated samples and their origins. Subsequently, it is demonstrated that such a simple linear transformation can be generalized across different diffusion models. Experimental results show that the proposed method achieves satisfying generalization performance, significantly surpassing similarity-based methods ($+31.6\\%$ mAP), even those with generalization designs. The project is available at https://id2icml.github.io.","authors":["Wenhao Wang","Yifan Sun","Zongxin Yang","Zhentao Tan","Zhengdong Hu","Yi Yang"],"url":"https://arxiv.org/abs/2501.02376"}
{"created":"2025-05-20","title":"ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use","abstract":"Effective evaluation of multi-hop tool use is critical for analyzing the understanding, reasoning, and function-calling capabilities of large language models (LLMs). However, progress has been hindered by a lack of reliable evaluation datasets. To address this, we present ToolHop, a dataset comprising 995 user queries and 3,912 associated tools, specifically designed for rigorous evaluation of multi-hop tool use. ToolHop ensures diverse queries, meaningful interdependencies, locally executable tools, detailed feedback, and verifiable answers through a novel query-driven data construction approach that includes tool creation, document refinement, and code generation. We evaluate 14 LLMs across five model families (i.e., LLaMA3.1, Qwen2.5, Gemini1.5, Claude3.5, and GPT), uncovering significant challenges in handling multi-hop tool-use scenarios. The leading model, GPT-4o, achieves an accuracy of 49.04%, underscoring substantial room for improvement. Further analysis reveals variations in tool-use strategies for various families, offering actionable insights to guide the development of more effective approaches. Code and data can be found in https://huggingface.co/datasets/bytedance-research/ToolHop.","authors":["Junjie Ye","Zhengyin Du","Xuesong Yao","Weijian Lin","Yufei Xu","Zehui Chen","Zaiyuan Wang","Sining Zhu","Zhiheng Xi","Siyu Yuan","Tao Gui","Qi Zhang","Xuanjing Huang","Jiecao Chen"],"url":"https://arxiv.org/abs/2501.02506"}
{"created":"2025-05-20","title":"Revisiting Communication Efficiency in Multi-Agent Reinforcement Learning from the Dimensional Analysis Perspective","abstract":"In this work, we introduce a novel perspective, i.e., dimensional analysis, to address the challenge of communication efficiency in Multi-Agent Reinforcement Learning (MARL). Our findings reveal that simply optimizing the content and timing of communication at sending end is insufficient to fully resolve communication efficiency issues. Even after applying optimized and gated messages, dimensional redundancy and confounders still persist in the integrated message embeddings at receiving end, which negatively impact communication quality and decision-making. To address these challenges, we propose Dimensional Rational Multi-Agent Communication (DRMAC), designed to mitigate both dimensional redundancy and confounders in MARL. DRMAC incorporates a redundancy-reduction regularization term to encourage the decoupling of information across dimensions within the learned representations of integrated messages. Additionally, we introduce a dimensional mask that dynamically adjusts gradient weights during training to eliminate the influence of decision-irrelevant dimensions. We evaluate DRMAC across a diverse set of multi-agent tasks, demonstrating its superior performance over existing state-of-the-art methods in complex scenarios. Furthermore, the plug-and-play nature of DRMAC's key modules highlights its generalizable performance, serving as a valuable complement rather than a replacement for existing multi-agent communication strategies.","authors":["Chuxiong Sun","Peng He","Rui Wang","Changwen Zheng"],"url":"https://arxiv.org/abs/2501.02888"}
{"created":"2025-05-20","title":"Inverse Intersections for Boolean Satisfiability Problems","abstract":"Boolean Satisfiability (SAT) problems are expressed as mathematical formulas. This paper presents a matrix representation for these SAT problems.","authors":["Paul W. Homer"],"url":"https://arxiv.org/abs/2501.03281"}
{"created":"2025-05-20","title":"CI at Scale: Lean, Green, and Fast","abstract":"Maintaining a \"green\" mainline branch, where all builds pass successfully, is crucial but challenging in fast-paced, large-scale software development environments, particularly with concurrent code changes in large monorepos. SubmitQueue, a system designed to address these challenges, speculatively executes builds and only lands changes with successful outcomes. However, despite its effectiveness, the system faces inefficiencies in resource utilization, leading to a high rate of premature build aborts and delays in landing smaller changes blocked by larger conflicting ones. This paper introduces enhancements to SubmitQueue, focusing on optimizing resource usage and improving build prioritization. Central to this is our innovative probabilistic model, which distinguishes between changes with shorter and longer build times to prioritize builds for more efficient scheduling. By leveraging a machine learning model to predict build times and incorporating this into the probabilistic framework, we expedite the landing of smaller changes blocked by conflicting larger time-consuming changes. Additionally, introducing a concept of speculation threshold ensures that only the most likely builds are executed, reducing unnecessary resource consumption. After implementing these enhancements across Uber's major monorepos (Go, iOS, and Android), we observed a reduction in Continuous Integration (CI) resource usage by approximately 53%, CPU usage by 44%, and P95 waiting times by 37%. These improvements highlight the enhanced efficiency of SubmitQueue in managing large-scale software changes while maintaining a green mainline.","authors":["Dhruva Juloori","Zhongpeng Lin","Matthew Williams","Eddy Shin","Sonal Mahajan"],"url":"https://arxiv.org/abs/2501.03440"}
{"created":"2025-05-20","title":"Feedback-Driven Vision-Language Alignment with Minimal Human Supervision","abstract":"Vision-language models (VLMs) have demonstrated remarkable potential in integrating visual and linguistic information, but their performance is often constrained by the need for extensive, high-quality image-text training data. Curation of these image-text pairs is both time-consuming and computationally expensive. To address this challenge, we introduce SVP (Sampling-based Visual Projection), a novel framework that enhances vision-language alignment without relying on manually curated text-image pairs or preference annotation. SVP leverages a small set of manually selected images, self-captioning and a pre-trained grounding model as a feedback mechanism to elicit latent information in VLMs. We evaluate our approach across six key areas: captioning, referring, visual question answering, multitasking, hallucination control, and object recall. Results demonstrate significant improvements, including a 14 % average improvement in captioning tasks, up to 12 % increase in object recall, and significantly reduced hallucinations, while maintaining question-answering capabilities. Using SVP, a small VLM achieves hallucination reductions similar to a model five times larger, while a VLM with initially poor referring capabilities more than doubles its performance, approaching parity with a model twice its size.","authors":["Giorgio Giannone","Ruoteng Li","Qianli Feng","Evgeny Perevodchikov","Rui Chen","Aleix Martinez"],"url":"https://arxiv.org/abs/2501.04568"}
{"created":"2025-05-20","title":"Grokking at the Edge of Numerical Stability","abstract":"Grokking, the sudden generalization that occurs after prolonged overfitting, is a surprising phenomenon challenging our understanding of deep learning. Although significant progress has been made in understanding grokking, the reasons behind the delayed generalization and its dependence on regularization remain unclear. In this work, we argue that without regularization, grokking tasks push models to the edge of numerical stability, introducing floating point errors in the Softmax function, which we refer to as Softmax Collapse (SC). We demonstrate that SC prevents grokking and that mitigating SC enables grokking without regularization. Investigating the root cause of SC, we find that beyond the point of overfitting, the gradients strongly align with what we call the na\\\"ive loss minimization (NLM) direction. This component of the gradient does not alter the model's predictions but decreases the loss by scaling the logits, typically by scaling the weights along their current direction. We show that this scaling of the logits explains the delay in generalization characteristic of grokking and eventually leads to SC, halting further learning. To validate our hypotheses, we introduce two key contributions that address the challenges in grokking tasks: StableMax, a new activation function that prevents SC and enables grokking without regularization, and $\\perp$Grad, a training algorithm that promotes quick generalization in grokking tasks by preventing NLM altogether. These contributions provide new insights into grokking, elucidating its delayed generalization, reliance on regularization, and the effectiveness of existing grokking-inducing methods. Code for this paper is available at https://github.com/LucasPrietoAl/grokking-at-the-edge-of-numerical-stability.","authors":["Lucas Prieto","Melih Barsbey","Pedro A. M. Mediano","Tolga Birdal"],"url":"https://arxiv.org/abs/2501.04697"}
{"created":"2025-05-20","title":"Complexity of Tensor Product Functions in Representing Antisymmetry","abstract":"Tensor product function (TPF) approximations have been widely adopted in solving high-dimensional problems, such as partial differential equations and eigenvalue problems, achieving desirable accuracy with computational overhead that scales linearly with problem dimensions. However, recent studies have underscored the extraordinarily high computational cost of TPFs on quantum many-body problems, even for systems with as few as three particles. A key distinction in these problems is the antisymmetry requirement on the unknown functions. In the present work, we rigorously establish that the minimum number of involved terms for a class of TPFs to be exactly antisymmetric increases exponentially fast with the problem dimension. This class encompasses both traditionally discretized TPFs and the recent ones parameterized by neural networks. Our proof exploits the link between the antisymmetric TPFs in this class and the corresponding antisymmetric tensors and focuses on the Canonical Polyadic rank of the latter. As a result, our findings uncover a fundamental incompatibility between antisymmetry and low-rank TPFs in high-dimensional contexts and offer new insights for further developments.","authors":["Yuyang Wang","Yukuan Hu","Xin Liu"],"url":"https://arxiv.org/abs/2501.05958"}
{"created":"2025-05-20","title":"Mamba-MOC: A Multicategory Remote Object Counting via State Space Model","abstract":"Multicategory remote object counting is a fundamental task in computer vision, aimed at accurately estimating the number of objects of various categories in remote images. Existing methods rely on CNNs and Transformers, but CNNs struggle to capture global dependencies, and Transformers are computationally expensive, which limits their effectiveness in remote applications. Recently, Mamba has emerged as a promising solution in the field of computer vision, offering a linear complexity for modeling global dependencies. To this end, we propose Mamba-MOC, a mamba-based network designed for multi-category remote object counting, which represents the first application of Mamba to remote sensing object counting. Specifically, we propose a cross-scale interaction module to facilitate the deep integration of hierarchical features. Then we design a context state space model to capture both global and local contextual information and provide local neighborhood information during the scan process. Experimental results in large-scale realistic scenarios demonstrate that our proposed method achieves state-of-the-art performance compared with some mainstream counting algorithms.","authors":["Peng Liu","Sen Lei","Heng-Chao Li"],"url":"https://arxiv.org/abs/2501.06697"}
{"created":"2025-05-20","title":"A Hessian-informed hyperparameter optimization for differential learning rate","abstract":"Differential learning rate (DLR), a technique that applies different learning rates to different model parameters, has been widely used in deep learning and achieved empirical success via its various forms. For example, parameter-efficient fine-tuning (PEFT) applies zero learning rates to most parameters so as to significantly save the computational cost.","authors":["Shiyun Xu","Zhiqi Bu","Yiliang Zhang","Ian Barnett"],"url":"https://arxiv.org/abs/2501.06954"}
{"created":"2025-05-20","title":"Optimal Policy Adaptation under Covariate Shift","abstract":"Transfer learning of prediction models has been extensively studied, while the corresponding policy learning approaches are rarely discussed. In this paper, we propose principled approaches for learning the optimal policy in the target domain by leveraging two datasets: one with full information from the source domain and the other from the target domain with only covariates. First, under the setting of covariate shift, we formulate the problem from a perspective of causality and present the identifiability assumptions for the reward induced by a given policy. Then, we derive the efficient influence function and the semiparametric efficiency bound for the reward. Based on this, we construct a doubly robust and semiparametric efficient estimator for the reward and then learn the optimal policy by optimizing the estimated reward. Moreover, we theoretically analyze the bias and the generalization error bound for the learned policy. Extensive experiments demonstrate that the approach not only estimates the reward more accurately but also yields a policy that closely approximates the theoretically optimal policy.","authors":["Xueqing Liu","Qinwei Yang","Zhaoqing Tian","Ruocheng Guo","Peng Wu"],"url":"https://arxiv.org/abs/2501.08067"}
{"created":"2025-05-20","title":"CT-PatchTST: Channel-Time Patch Time-Series Transformer for Long-Term Renewable Energy Forecasting","abstract":"Accurately predicting renewable energy output is crucial for the efficient integration of solar and wind power into modern energy systems. This study develops and evaluates an advanced deep learning model, Channel-Time Patch Time-Series Transformer (CT-PatchTST), to forecast the power output of photovoltaic and wind energy systems using annual offshore wind power, onshore wind power, and solar power generation data from Denmark. While the original Patch Time-Series Transformer(PatchTST) model employs a channel-independent (CI) approach, it tends to overlook inter-channel relationships during training, potentially leading to a loss of critical information. To address this limitation and further leverage the benefits of increased data granularity brought by CI, we propose CT-PatchTST. This enhanced model improves the processing of inter-channel information while maintaining the advantages of the channel-independent approach. The predictive performance of CT-PatchTST is rigorously analyzed, demonstrating its ability to provide precise and reliable energy forecasts. This work contributes to improving the predictability of renewable energy systems, supporting their broader adoption and integration into energy grids.","authors":["Menghao Huo","Kuan Lu","Yuxiao Li","Qiang Zhu","Zhenrui Chen"],"url":"https://arxiv.org/abs/2501.08620"}
{"created":"2025-05-20","title":"Refinement Module based on Parse Graph of Feature Map for Human Pose Estimation","abstract":"The parse graph play a crucial role in enhancing the performance of human pose estimation (HPE). Its key advantage lies in its hierarchical structure, like a tree structure, and context relations among nodes, which enable more accurate for inference. To equip models with the advantage of parse graphs, many researchers predefine the parse graph of body structure for HPE. However, these frameworks struggle to adapt to instances that deviate from the predefined parse graph and they are often parameter-heavy. Unlike them, we view the feature map holistically, much like the human body. It can be optimized using parse graphs, where nodes' implicit feature representation boosts adaptability, avoiding rigid structural limitations. In this paper, we design the Refinement Module based on the Parse Graph of feature map (RMPG), which includes two stages: top-down decomposition and bottom-up combination. In the first stage, the feature map is constructed into a tree structure through recursive decomposition, with each node representing a sub-feature map, thereby achieving hierarchical modeling of features. In the second stage, context information is calculated and sub-feature maps with context are recursively connected to gradually build a refined feature map. Additionally, we design a hierarchical network with fewer parameters using multiple RMPG modules to model the context relations and hierarchies in the parse graph of body structure for HPE, some of which are supervised to obtain context relations among body parts. Our network achieves excellent results on multiple mainstream human pose datasets and the effectiveness of RMPG is proven on different methods. The code of RMPG will be open.","authors":["Shibang Liu","Xuemei Xie","Guangming Shi"],"url":"https://arxiv.org/abs/2501.11069"}
{"created":"2025-05-20","title":"Can MLLMs Generalize to Multi-Party dialog? Exploring Multilingual Response Generation in Complex Scenarios","abstract":"Current multilingual large language models(MLLMs) still focus on simple question-answering formats, often overlooking more complex dialogue scenarios. In other words, their capabilities of multilingual large models have yet to be validated in dialogue tasks with intricate structures. We therefore ask, Q1: How well do LLMs generalize to more complex dialog scenarios? Q2: Can supervised fine-tuning on a high-quality parallel benchmark restore this ability? Q3: Does the \"multilingual complementarity\" effect survive in the setting? To answer these questions, we introduce XMP, a high-quality parallel Multilingual dataset sourced from Multi-party Podcast dialogues, which is the first parallel dataset focusing on multi-party dialogue scenarios. Most samples in the dataset feature three or more participants, discussing a wide range of topics. Through extensive experiments, we find that, R1: MLLMs fail to generalize to multi-party setting, R2 Fine-tuning on XMP improves only marginally, with the 70B model achieving at most a 1% absolute gain over its 8B counterpart; R3: Mixing languages during SFT is usually detrimental, with any benefits being marginal and limited to isolated cases in the 70B model.","authors":["Zhongtian Hu","Yiwen Cui","Ronghan Li","Meng Zhao","Lifang Wang"],"url":"https://arxiv.org/abs/2501.11269"}
{"created":"2025-05-20","title":"Advancing Multi-Party Dialogue Framework with Speaker-ware Contrastive Learning","abstract":"Multi-party dialogues, common in collaborative scenarios like brainstorming sessions and negotiations, pose significant challenges due to their complexity and diverse speaker roles. Current methods often use graph neural networks to model dialogue context, capturing structural dynamics but heavily relying on annotated graph structures and overlooking individual speaking styles. To address these challenges, we propose CMR, a Contrastive learning-based Multi-party dialogue Response generation framework. CMR employs a two-stage self-supervised contrastive learning framework. First, it captures global differences in speaking styles across individuals. Then, it focuses on intra-conversation comparisons to identify thematic transitions and contextually relevant facts. To the best of our knowledge, this is the first approach that applies contrastive learning in multi-party dialogue generation. Experimental results demonstrate that CMR not only significantly outperforms state-of-the-art models, but also generalizes well to large pre-trained language models, effectively enhancing their capability in handling multi-party conversations.","authors":["Zhongtian Hu","Qi He","Ronghan Li","Meng Zhao","Lifang Wang"],"url":"https://arxiv.org/abs/2501.11292"}
{"created":"2025-05-20","title":"Generative AI and Large Language Models in Language Preservation: Opportunities and Challenges","abstract":"The global crisis of language endangerment meets a technological turning point as Generative AI (GenAI) and Large Language Models (LLMs) unlock new frontiers in automating corpus creation, transcription, translation, and tutoring. However, this promise is imperiled by fragmented practices and the critical lack of a methodology to navigate the fraught balance between LLM capabilities and the profound risks of data scarcity, cultural misappropriation, and ethical missteps. This paper introduces a novel analytical framework that systematically evaluates GenAI applications against language-specific needs, embedding community governance and ethical safeguards as foundational pillars. We demonstrate its efficacy through the Te Reo M\\=aori revitalization, where it illuminates successes, such as community-led Automatic Speech Recognition achieving 92% accuracy, while critically surfacing persistent challenges in data sovereignty and model bias for digital archives and educational tools. Our findings underscore that GenAI can indeed revolutionize language preservation, but only when interventions are rigorously anchored in community-centric data stewardship, continuous evaluation, and transparent risk management. Ultimately, this framework provides an indispensable toolkit for researchers, language communities, and policymakers, aiming to catalyze the ethical and high-impact deployment of LLMs to safeguard the world's linguistic heritage.","authors":["Vincent Koc"],"url":"https://arxiv.org/abs/2501.11496"}
{"created":"2025-05-20","title":"AdaServe: Accelerating Multi-SLO LLM Serving with SLO-Customized Speculative Decoding","abstract":"Modern large language model (LLM) applications exhibit diverse service-level objectives (SLOs), from low-latency requirements in interactive coding assistants to more relaxed constraints in data wrangling tasks. Existing LLM serving systems, which rely on uniform batching and scheduling strategies, often fail to meet these heterogeneous SLOs concurrently. We present AdaServe, the first LLM serving system designed to support efficient multi-SLO serving through SLO-customized speculative decoding. AdaServe formulates multi-SLO serving as a constrained optimization problem and introduces a hardware-aware algorithm that constructs a speculation tree tailored to each request's latency target. It features a speculate-select-verify pipeline that enables fine-grained control over decoding speed while maximizing system throughput. AdaServe further adapts to workload variation by dynamically adjusting speculation parameters. Evaluations across diverse workloads show that AdaServe reduces SLO violations by up to 4.3$\\times$ and improves goodput by up to 1.9$\\times$ compared to the best performing baselines, highlighting its effectiveness in multi-SLO serving.","authors":["Zikun Li","Zhuofu Chen","Remi Delacourt","Gabriele Oliaro","Zeyu Wang","Qinghan Chen","Shuhuai Lin","April Yang","Zhihao Zhang","Zhuoming Chen","Sean Lai","Xinhao Cheng","Xupeng Miao","Zhihao Jia"],"url":"https://arxiv.org/abs/2501.12162"}
{"created":"2025-05-20","title":"Knowledge-Informed Multi-Agent Trajectory Prediction at Signalized Intersections for Infrastructure-to-Everything","abstract":"Multi-agent trajectory prediction at signalized intersections is crucial for developing efficient intelligent transportation systems and safe autonomous driving systems. Due to the complexity of intersection scenarios and the limitations of single-vehicle perception, the performance of vehicle-centric prediction methods has reached a plateau. In this paper, we introduce an Infrastructure-to-Everything (I2X) collaborative prediction scheme. In this scheme, roadside units (RSUs) independently forecast the future trajectories of all vehicles and transmit these predictions unidirectionally to subscribing vehicles. Building on this scheme, we propose I2XTraj, a dedicated infrastructure-based trajectory prediction model. I2XTraj leverages real-time traffic signal states, prior maneuver strategy knowledge, and multi-agent interactions to generate accurate, joint multi-modal trajectory prediction. First, a continuous signal-informed mechanism is proposed to adaptively process real-time traffic signals to guide trajectory proposal generation under varied intersection configurations. Second, a driving strategy awareness mechanism estimates the joint distribution of maneuver strategies by integrating spatial priors of intersection areas with dynamic vehicle states, enabling coverage of the full set of feasible maneuvers. Third, a spatial-temporal-mode attention network models multi-agent interactions to refine and adjust joint trajectory outputs.Finally, I2XTraj is evaluated on two real-world datasets of signalized intersections, the V2X-Seq and the SinD drone dataset. In both single-infrastructure and online collaborative scenarios, our model outperforms state-of-the-art methods by over 30\\% on V2X-Seq and 15\\% on SinD, demonstrating strong generalizability and robustness.","authors":["Huilin Yin","Yangwenhui Xu","Jiaxiang Li","Hao Zhang","Gerhard Rigoll"],"url":"https://arxiv.org/abs/2501.13461"}
{"created":"2025-05-20","title":"Flexible 3D Cage-based Deformation via Green Coordinates on B\\'{e}zier Patches","abstract":"Cage-based deformation is a fundamental problem in geometry processing, where a cage, a user-specified boundary of a region, is used to deform the ambient space of a given mesh. Traditional 3D cages are typically composed of triangles and quads. While quads can represent non-planar regions when their four corners are not coplanar, they form ruled surfaces with straight isoparametric curves, which limits their ability to handle curved and high-curvature deformations. In this work, we extend the cage for curved boundaries using B\\'{e}zier patches, enabling flexible and high-curvature deformations with only a few control points. The higher-order structure of the B\\'{e}zier patch also allows for the creation of a more compact and precise curved cage for the input model. Based on Green's third identity, we derive the Green coordinates for the B\\'{e}zier cage, achieving shape-preserving deformation with smooth surface boundaries. These coordinates are defined based on the vertex positions and normals of the B\\'{e}zier control net. Given that the coordinates are approximately calculated through the Riemann summation, we propose a global projection technique to ensure that the coordinates accurately conform to the linear reproduction property. Experimental results show that our method achieves high performance in handling curved and high-curvature deformations.","authors":["Dong Xiao","Renjie Chen"],"url":"https://arxiv.org/abs/2501.14068"}
{"created":"2025-05-20","title":"Neuronal and structural differentiation in the emergence of abstract rules in hierarchically modulated spiking neural networks","abstract":"The emergence of abstract rules from exemplars is central to the brain's capability of flexible generalization and rapid adaptation. However, the internal organizing mechanisms underlying rule abstraction remain elusive, largely due to the limitations of conventional models that lack intrinsic neuronal heterogeneity, making it hard to examine neuronal and structural differentiations. Inspired by astrocyte-mediated neuromodulation, this work introduces a hierarchically modulated recurrent spiking neural network (HM-RSNN) that can tune intrinsic neuronal properties, where a global stage simulates calcium wave-driven task-specific configuration and a local one mimics gliotransmitter-mediated fine-tuning. We conduct modeling using HM-RSNN across four cognitive tasks and rule abstraction contingent differentiation is observed at both network and neuron levels, leading to better performance compared to artificial neural networks. These findings highlight the critical role of dynamic internal organization in supporting the accomplishment of various cognitive tasks.","authors":["Yingchao Yu","Yaochu Jin","Kuangrong Hao","Yuchen Xiao","Yuping Yan","Hengjie Yu","Zeqi Zheng"],"url":"https://arxiv.org/abs/2501.14539"}
{"created":"2025-05-20","title":"Ordinal Exponentiation in Homotopy Type Theory","abstract":"While ordinals have traditionally been studied mostly in classical frameworks, constructive ordinal theory has seen significant progress in recent years. However, a general constructive treatment of ordinal exponentiation has thus far been missing. We present two seemingly different definitions of constructive ordinal exponentiation in the setting of homotopy type theory. The first is abstract, uses suprema of ordinals, and is solely motivated by the expected equations. The second is more concrete, based on decreasing lists, and can be seen as a constructive version of a classical construction by Sierpi\\'{n}ski based on functions with finite support. We show that our two approaches are equivalent (whenever it makes sense to ask the question), and use this equivalence to prove algebraic laws and decidability properties of the exponential. All our results are formalized in the proof assistant Agda.","authors":["Tom de Jong","Nicolai Kraus","Fredrik Nordvall Forsberg","Chuangjie Xu"],"url":"https://arxiv.org/abs/2501.14542"}
{"created":"2025-05-20","title":"Multi-Grained Patch Training for Efficient LLM-based Recommendation","abstract":"Large Language Models (LLMs) have emerged as a new paradigm for recommendation by converting interacted item history into language modeling. However, constrained by the limited context length of LLMs, existing approaches have to truncate item history in the prompt, focusing only on recent interactions and sacrificing the ability to model long-term history. To enable LLMs to model long histories, we pursue a concise embedding representation for items and sessions. In the LLM embedding space, we construct an item's embedding by aggregating its textual token embeddings; similarly, we construct a session's embedding by aggregating its item embeddings. While efficient, this way poses two challenges since it ignores the temporal significance of user interactions and LLMs do not natively interpret our custom embeddings. To overcome these, we propose PatchRec, a multi-grained patch training method consisting of two stages: (1) Patch Pre-training, which familiarizes LLMs with aggregated embeddings -- patches, and (2) Patch Fine-tuning, which enables LLMs to capture time-aware significance in interaction history. Extensive experiments show that PatchRec effectively models longer behavior histories with improved efficiency. This work facilitates the practical use of LLMs for modeling long behavior histories. Codes are available at https://github.com/ljy0ustc/PatchRec.","authors":["Jiayi Liao","Ruobing Xie","Sihang Li","Xiang Wang","Xingwu Sun","Zhanhui Kang","Xiangnan He"],"url":"https://arxiv.org/abs/2501.15087"}
{"created":"2025-05-20","title":"Option-ID Based Elimination For Multiple Choice Questions","abstract":"Multiple choice questions (MCQs) are a popular and important task for evaluating large language models (LLMs). Based on common strategies people use when answering MCQs, the process of elimination (PoE) has been proposed as an effective problem-solving method. Existing PoE methods typically either have LLMs directly identify incorrect options or score options and replace lower-scoring ones with [MASK]. However, both methods suffer from inapplicability or suboptimal performance. To address these issues, this paper proposes a novel option-ID based PoE ($\\text{PoE}_{\\text{ID}}$). $\\text{PoE}_{\\text{ID}}$ critically incorporates a debiasing technique to counteract LLMs token bias, enhancing robustness over naive ID-based elimination. It features two strategies: $\\text{PoE}_{\\text{ID}}^{\\text{log}}$, which eliminates options whose IDs have log probabilities below the average threshold, and $\\text{PoE}_{\\text{ID}}^{\\text{seq}}$, which iteratively removes the option with the lowest ID probability. We conduct extensive experiments with 6 different LLMs on 4 diverse datasets. The results demonstrate that $\\text{PoE}_{\\text{ID}}$, especially $\\text{PoE}_{\\text{ID}}^{\\text{log}}$, significantly improves zero-shot and few-shot MCQs performance, particularly in datasets with more options. Our analyses demonstrate that $\\text{PoE}_{\\text{ID}}^{\\text{log}}$ enhances the LLMs' confidence in selecting the correct option, and the option elimination strategy outperforms methods relying on [MASK] replacement. We further investigate the limitations of LLMs in directly identifying incorrect options, which stem from their inherent deficiencies.","authors":["Zhenhao Zhu","Bulou Liu","Qingyao Ai","Yiqun Liu"],"url":"https://arxiv.org/abs/2501.15175"}
{"created":"2025-05-20","title":"Your Learned Constraint is Secretly a Backward Reachable Tube","abstract":"Inverse Constraint Learning (ICL) is the problem of inferring constraints from safe (i.e., constraint-satisfying) demonstrations. The hope is that these inferred constraints can then be used downstream to search for safe policies for new tasks and, potentially, under different dynamics. Our paper explores the question of what mathematical entity ICL recovers. Somewhat surprisingly, we show that both in theory and in practice, ICL recovers the set of states where failure is inevitable, rather than the set of states where failure has already happened. In the language of safe control, this means we recover a backwards reachable tube (BRT) rather than a failure set. In contrast to the failure set, the BRT depends on the dynamics of the data collection system. We discuss the implications of the dynamics-conditionedness of the recovered constraint on both the sample-efficiency of policy search and the transferability of learned constraints.","authors":["Mohamad Qadri","Gokul Swamy","Jonathan Francis","Michael Kaess","Andrea Bajcsy"],"url":"https://arxiv.org/abs/2501.15618"}
{"created":"2025-05-20","title":"SpatialVLA: Exploring Spatial Representations for Visual-Language-Action Model","abstract":"In this paper, we claim that spatial understanding is the keypoint in robot manipulation, and propose SpatialVLA to explore effective spatial representations for the robot foundation model. Specifically, we introduce Ego3D Position Encoding to inject 3D information into the input observations of the visual-language-action model, and propose Adaptive Action Grids to represent spatial robot movement actions with adaptive discretized action grids, facilitating learning generalizable and transferrable spatial action knowledge for cross-robot control. SpatialVLA is first pre-trained on top of a vision-language model with 1.1 Million real-world robot episodes, to learn a generalist manipulation policy across multiple robot environments and tasks. After pre-training, SpatialVLA is directly applied to perform numerous tasks in a zero-shot manner. The superior results in both simulation and real-world robots demonstrate its advantage of inferring complex robot motion trajectories and its strong in-domain multi-task generalization ability. We further show the proposed Adaptive Action Grids offer a new and effective way to fine-tune the pre-trained SpatialVLA model for new simulation and real-world setups, where the pre-learned action grids are re-discretized to capture robot-specific spatial action movements of new setups. The superior results from extensive evaluations demonstrate the exceptional in-distribution generalization and out-of-distribution adaptation capability, highlighting the crucial benefit of the proposed spatial-aware representations for generalist robot policy learning. All the details and codes will be open-sourced.","authors":["Delin Qu","Haoming Song","Qizhi Chen","Yuanqi Yao","Xinyi Ye","Yan Ding","Zhigang Wang","JiaYuan Gu","Bin Zhao","Dong Wang","Xuelong Li"],"url":"https://arxiv.org/abs/2501.15830"}
{"created":"2025-05-20","title":"Quantifying the Self-Interest Level of Markov Social Dilemmas","abstract":"This paper introduces a novel method for estimating the self-interest level of Markov social dilemmas. We extend the concept of self-interest level from normal-form games to Markov games, providing a quantitative measure of the minimum reward exchange required to align individual and collective interests. We demonstrate our method on three environments from the Melting Pot suite, representing either common-pool resources or public goods. Our results illustrate how reward exchange can enable agents to transition from selfish to collective equilibria in a Markov social dilemma. This work contributes to multi-agent reinforcement learning by providing a practical tool for analysing complex, multistep social dilemmas. Our findings offer insights into how reward structures can promote or hinder cooperation, with potential applications in areas such as mechanism design.","authors":["Richard Willis","Yali Du","Joel Z Leibo","Michael Luck"],"url":"https://arxiv.org/abs/2501.16138"}
{"created":"2025-05-20","title":"SwiftPrune: Hessian-Free Weight Pruning for Large Language Models","abstract":"Post-training pruning, as one of the key techniques for compressing large language models, plays a vital role in lightweight model deployment and model sparsity. However, current mainstream pruning methods dependent on the Hessian matrix face significant limitations in both pruning speed and practical effectiveness due to the computationally intensive nature of second-order derivative calculations. This paper presents SwiftPrune, a novel Hessian-free weight pruning method that achieves hardware-efficient model compression through two key innovations: 1) SwiftPrune eliminates the need for computationally intensive Hessian matrix calculations by introducing a contribution-based weight metric, which evaluates the importance of weights without relying on second-order derivatives. 2) we employ the Exponentially Weighted Moving Average (EWMA) technique to bypass weight sorting, enabling the selection of weights that contribute most to LLM accuracy and further reducing time complexity. Our approach is extended to support structured sparsity pruning, facilitating efficient execution on modern hardware accelerators. We validate the SwiftPrune on three LLMs (namely LLaMA2, LLaMA3, and Pythia), demonstrating that it significantly enhances compression performance. The experimental findings reveal that SwiftPrune completes the pruning process within seconds, achieving an average speedup of 12.29x (up to 56.02x) over existing SOTA approaches.","authors":["Yuhan Kang","Yang Shi","Mei We","Jun He","Jianchao Yang","Zeyu Xue","Jing Feng","Xinwang Liu"],"url":"https://arxiv.org/abs/2501.16376"}
{"created":"2025-05-20","title":"Toward Relative Positional Encoding in Spiking Transformers","abstract":"Spiking neural networks (SNNs) are bio-inspired networks that mimic how neurons in the brain communicate through discrete spikes, which have great potential in various tasks due to their energy efficiency and temporal processing capabilities. SNNs with self-attention mechanisms (spiking Transformers) have recently shown great advancements in various tasks, and inspired by traditional Transformers, several studies have demonstrated that spiking absolute positional encoding can help capture sequential relationships for input data, enhancing the capabilities of spiking Transformers for tasks such as sequential modeling and image classification. However, how to incorporate relative positional information into SNNs remains a challenge. In this paper, we introduce several strategies to approximate relative positional encoding (RPE) in spiking Transformers while preserving the binary nature of spikes. Firstly, we formally prove that encoding relative distances with Gray Code ensures that the binary representations of positional indices maintain a constant Hamming distance whenever their decimal values differ by a power of two, and we propose Gray-PE based on this property. In addition, we propose another RPE method called Log-PE, which combines the logarithmic form of the relative distance matrix directly into the spiking attention map. Furthermore, we extend our RPE methods to a two-dimensional form, making them suitable for processing image patches. We evaluate our RPE methods on various tasks, including time series forecasting, text classification, and patch-based image classification, and the experimental results demonstrate a satisfying performance gain by incorporating our RPE methods across many architectures.","authors":["Changze Lv","Yansen Wang","Dongqi Han","Yifei Shen","Xiaoqing Zheng","Xuanjing Huang","Dongsheng Li"],"url":"https://arxiv.org/abs/2501.16745"}
{"created":"2025-05-20","title":"How Linguistics Learned to Stop Worrying and Love the Language Models","abstract":"Language models can produce fluent, grammatical text. Nonetheless, some maintain that language models don't really learn language and also that, even if they did, that would not be informative for the study of human learning and processing. On the other side, there have been claims that the success of LMs obviates the need for studying linguistic theory and structure. We argue that both extremes are wrong. LMs can contribute to fundamental questions about linguistic structure, language processing, and learning. They force us to rethink arguments and ways of thinking that have been foundational in linguistics. While they do not replace linguistic structure and theory, they serve as model systems and working proofs of concept for gradient, usage-based approaches to language. We offer an optimistic take on the relationship between language models and linguistics.","authors":["Richard Futrell","Kyle Mahowald"],"url":"https://arxiv.org/abs/2501.17047"}
{"created":"2025-05-20","title":"Learning Provably Improves the Convergence of Gradient Descent","abstract":"Learn to Optimize (L2O) trains deep neural network based solvers for optimization, achieving success in accelerating convex problems and improving non-convex solutions. However, L2O lacks rigorous theoretical backing for its own training convergence, as existing analyses often use unrealistic assumptions -- a gap this work highlights empirically. We bridge this gap by proving the training convergence of L2O models that learn Gradient Descent (GD) hyperparameters for quadratic programming, leveraging the Neural Tangent Kernel (NTK) theory. We propose a deterministic initialization strategy to support our theoretical results and promote stable training over extended optimization horizons by mitigating gradient explosion. Our L2O framework demonstrates over 50\\% better optimality against GD and superior robustness over state-of-the-art L2O methods on synthetic datasets.","authors":["Qingyu Song","Wei Lin","Hong Xu"],"url":"https://arxiv.org/abs/2501.18092"}
{"created":"2025-05-20","title":"DeepFRC: An End-to-End Deep Learning Model for Functional Registration and Classification","abstract":"Functional data - observations in the form of curves or trajectories - arise in diverse domains such as biomedical sensing, motion capture, and handwriting recognition. A core challenge in functional data analysis (FDA) is accounting for phase variability, where misaligned temporal patterns hinder accurate inference. We introduce DeepFRC, an end-to-end deep learning framework for joint functional registration and classification. Unlike conventional approaches that decouple alignment and prediction, DeepFRC integrates class-aware elastic warping and a learnable basis representation into a unified architecture. This design enables temporal alignment and dimensionality reduction to be jointly optimized with classification, improving both interpretability and accuracy. We establish the first theoretical connection between alignment quality and generalization error, and validate our model on synthetic and real-world benchmarks. DeepFRC consistently outperforms state-of-the-art methods, especially in scenarios with complex temporal misalignment. Code is available at: https://github.com/Drivergo-93589/DeepFRC.","authors":["Siyuan Jiang","Yihan Hu","Wenjie Li","Pengcheng Zeng"],"url":"https://arxiv.org/abs/2501.18116"}
{"created":"2025-05-20","title":"Jailbreaking LLMs' Safeguard with Universal Magic Words for Text Embedding Models","abstract":"The security issue of large language models (LLMs) has gained wide attention recently, with various defense mechanisms developed to prevent harmful output, among which safeguards based on text embedding models serve as a fundamental defense. Through testing, we discover that the output distribution of text embedding models is severely biased with a large mean. Inspired by this observation, we propose novel, efficient methods to search for **universal magic words** that attack text embedding models. Universal magic words as suffixes can shift the embedding of any text towards the bias direction, thus manipulating the similarity of any text pair and misleading safeguards. Attackers can jailbreak the safeguards by appending magic words to user prompts and requiring LLMs to end answers with magic words. Experiments show that magic word attacks significantly degrade safeguard performance on JailbreakBench, cause real-world chatbots to produce harmful outputs in full-pipeline attacks, and generalize across input/output texts, models, and languages. To eradicate this security risk, we also propose defense methods against such attacks, which can correct the bias of text embeddings and improve downstream performance in a train-free manner.","authors":["Haoyu Liang","Youran Sun","Yunfeng Cai","Jun Zhu","Bo Zhang"],"url":"https://arxiv.org/abs/2501.18280"}
{"created":"2025-05-20","title":"Function Encoders: A Principled Approach to Transfer Learning in Hilbert Spaces","abstract":"A central challenge in transfer learning is designing algorithms that can quickly adapt and generalize to new tasks without retraining. Yet, the conditions of when and how algorithms can effectively transfer to new tasks is poorly characterized. We introduce a geometric characterization of transfer in Hilbert spaces and define three types of inductive transfer: interpolation within the convex hull, extrapolation to the linear span, and extrapolation outside the span. We propose a method grounded in the theory of function encoders to achieve all three types of transfer. Specifically, we introduce a novel training scheme for function encoders using least-squares optimization, prove a universal approximation theorem for function encoders, and provide a comprehensive comparison with existing approaches such as transformers and meta-learning on four diverse benchmarks. Our experiments demonstrate that the function encoder outperforms state-of-the-art methods on four benchmark tasks and on all three types of transfer.","authors":["Tyler Ingebrand","Adam J. Thorpe","Ufuk Topcu"],"url":"https://arxiv.org/abs/2501.18373"}
{"created":"2025-05-20","title":"SANA 1.5: Efficient Scaling of Training-Time and Inference-Time Compute in Linear Diffusion Transformer","abstract":"This paper presents SANA-1.5, a linear Diffusion Transformer for efficient scaling in text-to-image generation. Building upon SANA-1.0, we introduce three key innovations: (1) Efficient Training Scaling: A depth-growth paradigm that enables scaling from 1.6B to 4.8B parameters with significantly reduced computational resources, combined with a memory-efficient 8-bit optimizer. (2) Model Depth Pruning: A block importance analysis technique for efficient model compression to arbitrary sizes with minimal quality loss. (3) Inference-time Scaling: A repeated sampling strategy that trades computation for model capacity, enabling smaller models to match larger model quality at inference time. Through these strategies, SANA-1.5 achieves a text-image alignment score of 0.81 on GenEval, which can be further improved to 0.96 through inference scaling with VILA-Judge, establishing a new SoTA on GenEval benchmark. These innovations enable efficient model scaling across different compute budgets while maintaining high quality, making high-quality image generation more accessible. Our code and pre-trained models are released.","authors":["Enze Xie","Junsong Chen","Yuyang Zhao","Jincheng Yu","Ligeng Zhu","Chengyue Wu","Yujun Lin","Zhekai Zhang","Muyang Li","Junyu Chen","Han Cai","Bingchen Liu","Daquan Zhou","Song Han"],"url":"https://arxiv.org/abs/2501.18427"}
{"created":"2025-05-20","title":"StruM: Structured Mixed Precision for Efficient Deep Learning Hardware Codesign","abstract":"In this paper, we propose StruM, a novel structured mixed-precision-based deep learning inference method, co-designed with its associated hardware accelerator (DPU), to address the escalating computational and memory demands of deep learning workloads in data centers and edge applications. Diverging from traditional approaches, our method avoids time-consuming re-training/fine-tuning and specialized hardware access. By leveraging the variance in weight magnitudes within layers, we quantize values within blocks to two different levels, achieving up to a 50% reduction in precision for 8-bit integer weights to 4-bit values across various Convolutional Neural Networks (CNNs) with negligible loss in inference accuracy. To demonstrate efficiency gains by utilizing mixed precision, we implement StruM on top of our in-house FlexNN DNN accelerator [1] that supports low and mixed-precision execution. Experimental results depict that the proposed StruM-based hardware architecture achieves a 31-34% reduction in processing element (PE) power consumption and a 10% reduction in area at the accelerator level. In addition, the statically configured StruM results in 23-26% area reduction at the PE level and 2-3% area savings at the DPU level.","authors":["Michael Wu","Arnab Raha","Deepak A. Mathaikutty","Martin Langhammer","Engin Tunali","Daksha Sharma"],"url":"https://arxiv.org/abs/2501.18953"}
{"created":"2025-05-20","title":"Resolving Oversmoothing with Opinion Dissensus","abstract":"While graph neural networks (GNNs) have allowed researchers to successfully apply neural networks to non-Euclidean domains, deep GNNs often exhibit lower predictive performance than their shallow counterparts. This phenomena has been attributed in part to oversmoothing, the tendency of node representations to become increasingly similar with network depth. In this paper we introduce an analogy between oversmoothing in GNNs and consensus (i.e., perfect agreement) in the opinion dynamics literature. We show that the message passing algorithms of several GNN models are equivalent to linear opinion dynamics models which have been shown to converge to consensus for all inputs regardless of the graph structure. This new perspective on oversmoothing motivates the use of nonlinear opinion dynamics as an inductive bias in GNN models. In our Behavior-Inspired Message Passing (BIMP) GNN, we leverage the nonlinear opinion dynamics model which is more general than the linear opinion dynamics model, and can be designed to converge to dissensus for general inputs. Through extensive experiments we show that BIMP resists oversmoothing beyond 100 time steps and consistently outperforms existing architectures even when those architectures are amended with oversmoothing mitigation techniques. We also show that BIMP has several desirable properties including well behaved gradients and adaptability to homophilic and heterophilic datasets.","authors":["Keqin Wang","Yulong Yang","Ishan Saha","Christine Allen-Blanchette"],"url":"https://arxiv.org/abs/2501.19089"}
{"created":"2025-05-20","title":"$\\infty$-Video: A Training-Free Approach to Long Video Understanding via Continuous-Time Memory Consolidation","abstract":"Current video-language models struggle with long-video understanding due to limited context lengths and reliance on sparse frame subsampling, often leading to information loss. This paper introduces $\\infty$-Video, which can process arbitrarily long videos through a continuous-time long-term memory (LTM) consolidation mechanism. Our framework augments video Q-formers by allowing them to process unbounded video contexts efficiently and without requiring additional training. Through continuous attention, our approach dynamically allocates higher granularity to the most relevant video segments, forming \"sticky\" memories that evolve over time. Experiments with Video-LLaMA and VideoChat2 demonstrate improved performance in video question-answering tasks, showcasing the potential of continuous-time LTM mechanisms to enable scalable and training-free comprehension of long videos.","authors":["Saul Santos","Ant\\'onio Farinhas","Daniel C. McNamee","Andr\\'e F. T. Martins"],"url":"https://arxiv.org/abs/2501.19098"}
{"created":"2025-05-20","title":"FedRTS: Federated Robust Pruning via Combinatorial Thompson Sampling","abstract":"Federated Learning (FL) enables collaborative model training across distributed clients without data sharing, but its high computational and communication demands strain resource-constrained devices. While existing methods use dynamic pruning to improve efficiency by periodically adjusting sparse model topologies while maintaining sparsity, these approaches suffer from issues such as greedy adjustments, unstable topologies, and communication inefficiency, resulting in less robust models and suboptimal performance under data heterogeneity and partial client availability. To address these challenges, we propose Federated Robust pruning via combinatorial Thompson Sampling (FedRTS), a novel framework designed to develop robust sparse models. FedRTS enhances robustness and performance through its Thompson Sampling-based Adjustment (TSAdj) mechanism, which uses probabilistic decisions informed by stable, farsighted information instead of deterministic decisions reliant on unstable and myopic information in previous methods. Extensive experiments demonstrate that FedRTS achieves state-of-the-art performance in computer vision and natural language processing tasks while reducing communication costs, particularly excelling in scenarios with heterogeneous data distributions and partial client participation. Our codes are available at: https://github.com/Little0o0/FedRTS","authors":["Hong Huang","Hai Yang","Yuan Chen","Jiaxun Ye","Dapeng Wu"],"url":"https://arxiv.org/abs/2501.19122"}
{"created":"2025-05-20","title":"Test-Time Training Scaling Laws for Chemical Exploration in Drug Design","abstract":"Chemical Language Models (CLMs) leveraging reinforcement learning (RL) have shown promise in de novo molecular design, yet often suffer from mode collapse, limiting their exploration capabilities. Inspired by Test-Time Training (TTT) in large language models, we propose scaling TTT for CLMs to enhance chemical space exploration. We introduce MolExp, a novel benchmark emphasizing the discovery of structurally diverse molecules with similar bioactivity, simulating real-world drug design challenges. Our results demonstrate that scaling TTT by increasing the number of independent RL agents follows a log-linear scaling law, significantly improving exploration efficiency as measured by MolExp. In contrast, increasing TTT training time yields diminishing returns, even with exploration bonuses. We further evaluate cooperative RL strategies to enhance exploration efficiency. These findings provide a scalable framework for generative molecular design, offering insights into optimizing AI-driven drug discovery.","authors":["Morgan Thomas","Albert Bou","Gianni De Fabritiis"],"url":"https://arxiv.org/abs/2501.19153"}
{"created":"2025-05-20","title":"The geography of inequalities in access to healthcare across England: the role of bus travel time variability","abstract":"Fair access to healthcare facilities is fundamental to achieving social equity. Traditional travel time-based accessibility measures often overlook the dynamic nature of travel times resulting from different departure times, which compromises the accuracy of these measures in reflecting the true accessibility experienced by individuals. This study examines public transport-based accessibility to healthcare facilities across England from the perspective of travel time variability (TTV). Using comprehensive bus timetable data from the Bus Open Data Service (BODS), we calculated hourly travel times from each Lower Layer Super Output Area (LSOA) to the nearest hospitals and general practices and developed a TTV metric for each LSOA and analysed its geographical inequalities across various spatial scales. Our analysis reveals notable spatial-temporal patterns of TTV and average travel times, including an urban-rural divide, clustering of high and low TTV regions, and distinct outliers. Furthermore, we explored the relationship between TTV and deprivation, categorising LSOAs into four groups based on their unique characteristics, which provides valuable insights for designing targeted interventions. Our study also highlights the limitations of using theoretical TTV derived from timetable data and emphasises the potential of using real-time operational data to capture more realistic accessibility measures. By offering a more dynamic perspective on accessibility, our findings complement existing travel time-based metrics and pave way for future research on TTV-based accessibility using real-time data. This evidence-based approach can inform efforts to \"level up\" public transport services, addressing geographical inequalities and promoting equitable access to essential healthcare services.","authors":["Zihao Chen","Federico Botta"],"url":"https://arxiv.org/abs/2501.19231"}
{"created":"2025-05-20","title":"Federated Sketching LoRA: On-Device Collaborative Fine-Tuning of Large Language Models","abstract":"Fine-tuning large language models (LLMs) on devices remains a challenging problem. Recent works have fused low-rank adaptation (LoRA) techniques with federated fine-tuning to mitigate challenges associated with device model sizes and data scarcity. Still, the heterogeneity of resources remains a critical bottleneck: while higher-rank modules generally enhance performance, varying device capabilities constrain LoRA's feasible rank range. Existing approaches attempting to resolve this issue either lack analytical justification or impose additional computational overhead, leaving a wide gap for efficient and theoretically-grounded solutions. To address these challenges, we propose federated sketching LoRA (FSLoRA), which leverages a sketching mechanism to enable devices to selectively update submatrices of global LoRA modules maintained by the server. By adjusting the sketching ratios, which determine the ranks of the submatrices on the devices, FSLoRA flexibly adapts to device-specific communication and computational constraints. We provide a rigorous convergence analysis of FSLoRA that characterizes how the sketching ratios affect the convergence rate. Through comprehensive experiments on multiple datasets and LLM models, we demonstrate FSLoRA's performance improvements compared to various baselines. The code is available at https://github.com/wenzhifang/Federated-Sketching-LoRA-Implementation.","authors":["Wenzhi Fang","Dong-Jun Han","Liangqi Yuan","Seyyedali Hosseinalipour","Christopher G. Brinton"],"url":"https://arxiv.org/abs/2501.19389"}
{"created":"2025-05-20","title":"DUET: Optimizing Training Data Mixtures via Feedback from Unseen Evaluation Tasks","abstract":"The performance of an LLM depends heavily on the relevance of its training data to the downstream evaluation task. However, in practice, the data involved in an unseen evaluation task is often unknown (e.g., conversations between an LLM and a user are end-to-end encrypted). Hence, it is unclear what data are relevant for fine-tuning the LLM to maximize its performance on the specific unseen evaluation task. Instead, one can only deploy the LLM on the unseen task to gather multiple rounds of feedback on how well the model performs (e.g., user ratings). This novel setting offers a refreshing perspective towards optimizing training data mixtures via feedback from an unseen evaluation task, which prior data mixing and selection works do not consider. Our paper presents DUET, a novel global-to-local algorithm that interleaves influence function as a data selection method with Bayesian optimization to optimize data mixture via feedback from a specific unseen evaluation task. By analyzing DUET's cumulative regret, we theoretically show that DUET converges to the optimal training data mixture for an unseen task even without any data knowledge of the task. Finally, our experiments across a variety of language tasks demonstrate that DUET outperforms existing data selection and mixing methods in the unseen-task setting.","authors":["Zhiliang Chen","Gregory Kang Ruey Lau","Chuan-Sheng Foo","Bryan Kian Hsiang Low"],"url":"https://arxiv.org/abs/2502.00270"}
{"created":"2025-05-20","title":"Latent Action Learning Requires Supervision in the Presence of Distractors","abstract":"Recently, latent action learning, pioneered by Latent Action Policies (LAPO), have shown remarkable pre-training efficiency on observation-only data, offering potential for leveraging vast amounts of video available on the web for embodied AI. However, prior work has focused on distractor-free data, where changes between observations are primarily explained by ground-truth actions. Unfortunately, real-world videos contain action-correlated distractors that may hinder latent action learning. Using Distracting Control Suite (DCS) we empirically investigate the effect of distractors on latent action learning and demonstrate that LAPO struggle in such scenario. We propose LAOM, a simple LAPO modification that improves the quality of latent actions by 8x, as measured by linear probing. Importantly, we show that providing supervision with ground-truth actions, as few as 2.5% of the full dataset, during latent action learning improves downstream performance by 4.2x on average. Our findings suggest that integrating supervision during Latent Action Models (LAM) training is critical in the presence of distractors, challenging the conventional pipeline of first learning LAM and only then decoding from latent to ground-truth actions.","authors":["Alexander Nikulin","Ilya Zisman","Denis Tarasov","Nikita Lyubaykin","Andrei Polubarov","Igor Kiselev","Vladislav Kurenkov"],"url":"https://arxiv.org/abs/2502.00379"}
{"created":"2025-05-20","title":"RefDrone: A Challenging Benchmark for Referring Expression Comprehension in Drone Scenes","abstract":"Drones have become prevalent robotic platforms with diverse applications, showing significant potential in Embodied Artificial Intelligence (Embodied AI). Referring Expression Comprehension (REC) enables drones to locate objects based on natural language expressions, a crucial capability for Embodied AI. Despite advances in REC for ground-level scenes, aerial views introduce unique challenges including varying viewpoints, occlusions and scale variations. To address this gap, we introduce RefDrone, a REC benchmark for drone scenes. RefDrone reveals three key challenges in REC: 1) multi-scale and small-scale target detection; 2) multi-target and no-target samples; 3) complex environment with rich contextual expressions. To efficiently construct this dataset, we develop RDAgent (referring drone annotation framework with multi-agent system), a semi-automated annotation tool for REC tasks. RDAgent ensures high-quality contextual expressions and reduces annotation cost. Furthermore, we propose Number GroundingDINO (NGDINO), a novel method designed to handle multi-target and no-target cases. NGDINO explicitly learns and utilizes the number of objects referred to in the expression. Comprehensive experiments with state-of-the-art REC methods demonstrate that NGDINO achieves superior performance on both the proposed RefDrone and the existing gRefCOCO datasets. The dataset and code are be publicly at https://github.com/sunzc-sunny/refdrone.","authors":["Zhichao Sun","Yepeng Liu","Huachao Zhu","Yuliang Gu","Yuda Zou","Zelong Liu","Gui-Song Xia","Bo Du","Yongchao Xu"],"url":"https://arxiv.org/abs/2502.00392"}
{"created":"2025-05-20","title":"`Do as I say not as I do': A Semi-Automated Approach for Jailbreak Prompt Attack against Multimodal LLMs","abstract":"Large Language Models (LLMs) have seen widespread applications across various domains due to their growing ability to process diverse types of input data, including text, audio, image and video. While LLMs have demonstrated outstanding performance in understanding and generating contexts for different scenarios, they are vulnerable to prompt-based attacks, which are mostly via text input. In this paper, we introduce the first voice-based jailbreak attack against multimodal LLMs, termed as Flanking Attack, which can process different types of input simultaneously towards the multimodal LLMs. Our work is motivated by recent advancements in monolingual voice-driven large language models, which have introduced new attack surfaces beyond traditional text-based vulnerabilities for LLMs. To investigate these risks, we examine the state-of-the-art multimodal LLMs, which can be accessed via different types of inputs such as audio input, focusing on how adversarial prompts can bypass its defense mechanisms. We propose a novel strategy, in which the disallowed prompt is flanked by benign, narrative-driven prompts. It is integrated in the Flanking Attack which attempts to humanizes the interaction context and execute the attack through a fictional setting. Further, to better evaluate the attack performance, we present a semi-automated self-assessment framework for policy violation detection. We demonstrate that Flanking Attack is capable of manipulating state-of-the-art LLMs into generating misaligned and forbidden outputs, which achieves an average attack success rate ranging from 0.67 to 0.93 across seven forbidden scenarios.","authors":["Chun Wai Chiu","Linghan Huang","Bo Li","Huaming Chen","Kim-Kwang Raymond Choo"],"url":"https://arxiv.org/abs/2502.00735"}
{"created":"2025-05-20","title":"Vision-centric Token Compression in Large Language Model","abstract":"Real-world applications are stretching context windows to hundreds of thousand of tokens while Large Language Models (LLMs) swell from billions to trillions of parameters. This dual expansion send compute and memory costs skyrocketing, making token compression indispensable. We introduce Vision Centric Token Compression (Vist), a slow-fast compression framework that mirrors human reading: the fast path renders distant tokens into images, letting a frozen, lightweight vision encoder skim the low-salience context; the slow path feeds the proximal window into the LLM for fine-grained reasoning. A Probability-Informed Visual Enhancement (PVE) objective masks high-frequency tokens during training, steering the Resampler to concentrate on semantically rich regions-just as skilled reader gloss over function words. On eleven in-context learning benchmarks, Vist achieves the same accuracy with 2.3 times fewer tokens, cutting FLOPs by 16% and memory by 50%. This method delivers remarkable results, outperforming the strongest text encoder-based compression method CEPE by 7.6% on average over benchmarks like TriviaQA, NQ, PopQA, NLUI, and CLIN, setting a new standard for token efficiency in LLMs. The source code will be released.","authors":["Ling Xing","Alex Jinpeng Wang","Rui Yan","Xiangbo Shu","Jinhui Tang"],"url":"https://arxiv.org/abs/2502.00791"}
{"created":"2025-05-20","title":"ProPINN: Demystifying Propagation Failures in Physics-Informed Neural Networks","abstract":"Physics-informed neural networks (PINNs) have earned high expectations in solving partial differential equations (PDEs), but their optimization usually faces thorny challenges due to the unique derivative-dependent loss function. By analyzing the loss distribution, previous research observed the propagation failure phenomenon of PINNs, intuitively described as the correct supervision for model outputs cannot ''propagate'' from initial states or boundaries to the interior domain. Going beyond intuitive understanding, this paper provides a formal and in-depth study of propagation failure and its root cause. Based on a detailed comparison with classical finite element methods, we ascribe the failure to the conventional single-point-processing architecture of PINNs and further prove that propagation failure is essentially caused by the lower gradient correlation of PINN models on nearby collocation points. Compared to superficial loss maps, this new perspective provides a more precise quantitative criterion to identify where and why PINN fails. The theoretical finding also inspires us to present a new PINN architecture, named ProPINN, which can effectively unite the gradients of region points for better propagation. ProPINN can reliably resolve PINN failure modes and significantly surpass advanced Transformer-based models with 46% relative promotion.","authors":["Haixu Wu","Yuezhou Ma","Hang Zhou","Huikun Weng","Jianmin Wang","Mingsheng Long"],"url":"https://arxiv.org/abs/2502.00803"}
{"created":"2025-05-20","title":"Disentangling Length Bias In Preference Learning Via Response-Conditioned Modeling","abstract":"Reinforcement Learning from Human Feedback (RLHF) has achieved considerable success in aligning large language models (LLMs) by modeling human preferences with a learnable reward model and employing a reinforcement learning algorithm to maximize the reward model's scores. However, these reward models are susceptible to exploitation through various superficial confounding factors, with length bias emerging as a particularly significant concern. Moreover, while the pronounced impact of length bias on preference modeling suggests that LLMs possess an inherent sensitivity to length perception, our preliminary investigations reveal that fine-tuned LLMs consistently struggle to adhere to explicit length instructions. To address these two limitations, we propose a novel framework wherein the reward model explicitly differentiates between human semantic preferences and response length requirements. Specifically, we introduce a $\\textbf{R}$esponse-$\\textbf{c}$onditioned $\\textbf{B}$radley-$\\textbf{T}$erry (Rc-BT) model that enhances the model's capability in length bias mitigating and length instruction following, through training on our augmented dataset. Furthermore, we propose the Rc-RM and Rc-DPO algorithm to leverage the Rc-BT model for reward modeling and direct policy optimization (DPO) of LLMs, simultaneously mitigating length bias and promoting adherence to length instructions. Extensive experiments across various foundational models and datasets demonstrate the effectiveness and generalizability of our approach.","authors":["Jianfeng Cai","Jinhua Zhu","Ruopei Sun","Yue Wang","Li Li","Wengang Zhou","Houqiang Li"],"url":"https://arxiv.org/abs/2502.00814"}
{"created":"2025-05-20","title":"Generating Computational Cognitive Models using Large Language Models","abstract":"Computational cognitive models, which formalize theories of cognition, enable researchers to quantify cognitive processes and arbitrate between competing theories by fitting models to behavioral data. Traditionally, these models are handcrafted, which requires significant domain knowledge, coding expertise, and time investment. However, recent advances in machine learning offer solutions to these challenges. In particular, Large Language Models (LLMs) have demonstrated remarkable capabilities for in-context pattern recognition, leveraging knowledge from diverse domains to solve complex problems, and generating executable code that can be used to facilitate the generation of cognitive models. Building on this potential, we introduce a pipeline for Guided generation of Computational Cognitive Models (GeCCo). Given task instructions, participant data, and a template function, GeCCo prompts an LLM to propose candidate models, fits proposals to held-out data, and iteratively refines them based on feedback constructed from their predictive performance. We benchmark this approach across four different cognitive domains -- decision making, learning, planning, and memory -- using three open-source LLMs, spanning different model sizes, capacities, and families. On four human behavioral data sets, the LLM generated models that consistently matched or outperformed the best domain-specific models from the cognitive science literature. Taken together, our results suggest that LLMs can generate cognitive models with conceptually plausible theories that rival -- or even surpass -- the best models from the literature across diverse task domains.","authors":["Milena Rmus","Akshay K. Jagadish","Marvin Mathony","Tobias Ludwig","Eric Schulz"],"url":"https://arxiv.org/abs/2502.00879"}
{"created":"2025-05-20","title":"Learning to Learn Weight Generation via Local Consistency Diffusion","abstract":"Diffusion-based algorithms have emerged as promising techniques for weight generation. However, existing solutions are limited by two challenges: generalizability and local target assignment. The former arises from the inherent lack of cross-task transferability in existing single-level optimization methods, limiting the model's performance on new tasks. The latter lies in existing research modeling only global optimal weights, neglecting the supervision signals in local target weights. Moreover, naively assigning local target weights causes local-global inconsistency. To address these issues, we propose Mc-Di, which integrates the diffusion algorithm with meta-learning for better generalizability. Furthermore, we extend the vanilla diffusion into a local consistency diffusion algorithm. Our theory and experiments demonstrate that it can learn from local targets while maintaining consistency with the global optima. We validate Mc-Di's superior accuracy and inference efficiency in tasks that require frequent weight updates, including transfer learning, few-shot learning, domain generalization, and large language model adaptation.","authors":["Yunchuan Guan","Yu Liu","Ke Zhou","Zhiqi Shen","Jenq-Neng Hwang","Lei Li"],"url":"https://arxiv.org/abs/2502.01117"}
{"created":"2025-05-20","title":"Joint Localization and Activation Editing for Low-Resource Fine-Tuning","abstract":"Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, are commonly used to adapt LLMs. However, the effectiveness of standard PEFT methods is limited in low-resource scenarios with only a few hundred examples. Recent advances in interpretability research have inspired the emergence of activation editing (or steering) techniques, which modify the activations of specific model components. These methods, due to their extremely small parameter counts, show promise for small datasets. However, their performance is highly dependent on identifying the correct modules to edit and often lacks stability across different datasets. In this paper, we propose Joint Localization and Activation Editing (JoLA), a method that jointly learns (1) which heads in the Transformer to edit (2) whether the intervention should be additive, multiplicative, or both and (3) the intervention parameters themselves - the vectors applied as additive offsets or multiplicative scalings to the head output. Through evaluations on three benchmarks spanning commonsense reasoning, natural language understanding, and natural language generation, we demonstrate that JoLA consistently outperforms existing methods. The code for the method is released at https://github.com/wenlai-lavine/jola.","authors":["Wen Lai","Alexander Fraser","Ivan Titov"],"url":"https://arxiv.org/abs/2502.01179"}
{"created":"2025-05-20","title":"Generalization Error Analysis for Selective State-Space Models Through the Lens of Attention","abstract":"State-space models (SSMs) have recently emerged as a compelling alternative to Transformers for sequence modeling tasks. This paper presents a theoretical generalization analysis of selective SSMs, the core architectural component behind the Mamba model. We derive a novel covering number-based generalization bound for selective SSMs, building upon recent theoretical advances in the analysis of Transformer models. Using this result, we analyze how the spectral abscissa of the continuous-time state matrix governs the model's training dynamics and its ability to generalize across sequence lengths. We empirically validate our findings on a synthetic majority task and the IMDb sentiment classification benchmark, illustrating how our theoretical insights translate into practical model behavior.","authors":["Arya Honarpisheh","Mustafa Bozdag","Octavia Camps","Mario Sznaier"],"url":"https://arxiv.org/abs/2502.01473"}
{"created":"2025-05-20","title":"Explaining Context Length Scaling and Bounds for Language Models","abstract":"Long Context Language Models have drawn great attention in the past few years. There has been work discussing the impact of long context on Language Model performance: some find that long irrelevant context could harm performance, while some experimentally summarize loss reduction by relevant long context as Scaling Laws. This calls for a more thorough understanding on how long context impacts Language Modeling. In this work, we (1) propose a clean and effective theoretical framework for explaining the impact of context length on Language Modeling, from an Intrinsic Space perspective; and (2) conduct experiments on natural language and synthetic data, validating our proposed theoretical assumptions and deductions. Our theoretical framework can provide practical insights such as establishing that training dataset size dictates an optimal context length and bounds context length scaling for certain cases. We hope our work may inspire new long context Language Models, as well as future work studying Physics for Language Models. Code for our experiments is available at: https://github.com/JingzheShi/NLPCtlScalingAndBounds.","authors":["Jingzhe Shi","Qinwei Ma","Hongyi Liu","Hang Zhao","Jeng-Neng Hwang","Lei Li"],"url":"https://arxiv.org/abs/2502.01481"}
{"created":"2025-05-20","title":"Scaling Embedding Layers in Language Models","abstract":"We propose SCONE ($S$calable, $C$ontextualized, $O$ffloaded, $N$-gram $E$mbedding), a new method for extending input embedding layers to enhance language model performance. To avoid increased decoding costs, SCONE retains the original vocabulary while introducing embeddings for a set of frequent $n$-grams. These embeddings provide contextualized representation for each input token and are learned with a separate model during training. After training, embeddings are precomputed and stored in off-accelerator memory; during inference, querying them has minimal impact on latency due to the low complexity of embedding lookups. SCONE enables two new scaling strategies: increasing the number of $n$-gram embeddings and scaling the model used to learn them, both while maintaining fixed accelerator usage during inference (in terms of FLOPS and memory). We show that scaling both aspects enables a model with 1B accelerator-resident parameters to outperform a 1.9B-parameter baseline across diverse corpora, while using only about half the FLOPS and accelerator memory during inference.","authors":["Da Yu","Edith Cohen","Badih Ghazi","Yangsibo Huang","Pritish Kamath","Ravi Kumar","Daogao Liu","Chiyuan Zhang"],"url":"https://arxiv.org/abs/2502.01637"}
{"created":"2025-05-20","title":"Displacement-Sparse Neural Optimal Transport","abstract":"Optimal transport (OT) aims to find a map $T$ that transports mass from one probability measure to another while minimizing a cost function. Recently, neural OT solvers have gained popularity in high dimensional biological applications such as drug perturbation, due to their superior computational and memory efficiency compared to traditional exact Sinkhorn solvers. However, the overly complex high dimensional maps learned by neural OT solvers often suffer from poor interpretability. Prior work addressed this issue in the context of exact OT solvers by introducing \\emph{displacement-sparse maps} via designed elastic cost, but such method failed to be applied to neural OT settings. In this work, we propose an intuitive and theoretically grounded approach to learning \\emph{displacement-sparse maps} within neural OT solvers. Building on our new formulation, we introduce a novel smoothed $\\ell_0$ regularizer that outperforms the $\\ell_1$ based alternative from prior work. Leveraging Input Convex Neural Network's flexibility, we further develop a heuristic framework for adaptively controlling sparsity intensity, an approach uniquely enabled by the neural OT paradigm. We demonstrate the necessity of this adaptive framework in large-scale, high-dimensional training, showing not only improved accuracy but also practical ease of use for downstream applications.","authors":["Peter Chen","Yue Xie","Qingpeng Zhang"],"url":"https://arxiv.org/abs/2502.01889"}
{"created":"2025-05-20","title":"Geometric Framework for Cell Oversegmentation","abstract":"3D cell segmentation methods are often hindered by \\emph{oversegmentation}, where a single cell is incorrectly split into multiple fragments. This degrades the final segmentation quality and is notoriously difficult to resolve, as oversegmentation errors often resemble \\emph{natural gaps} between adjacent cells. Our work makes two key contributions. First, for 3D cell segmentation, we are the first work to formulate oversegmentation as a concrete problem and propose a geometric framework to identify and correct these errors. Our approach builds a pre-trained classifier using both 2D geometric and 3D topological features extracted from flawed 3D segmentation results. Second, we introduce a novel metric, \\emph{Geo-Wasserstein} divergence, to quantify changes in 2D geometries. This captures the evolving trends in cell mask shape changes in a geometry-aware manner. We validate our method through extensive experiments on in-domain plant datasets, including both synthesized and real cases, as well as on out-of-domain animal datasets to demonstrate transfer learning performance. An ablation study further highlights the contribution of the \\emph{Geo-Wasserstein} divergence. A clear pipeline is provided for end-users to build pre-trained models to any labeled dataset.","authors":["Peter Chen","Bryan Chang","Olivia Annette Creasey","Julie Beth Sneddon","Zev Gartner","Yining Liu"],"url":"https://arxiv.org/abs/2502.01890"}
{"created":"2025-05-20","title":"VolleyBots: A Testbed for Multi-Drone Volleyball Game Combining Motion Control and Strategic Play","abstract":"Robot sports, characterized by well-defined objectives, explicit rules, and dynamic interactions, present ideal scenarios for demonstrating embodied intelligence. In this paper, we present VolleyBots, a novel robot sports testbed where multiple drones cooperate and compete in the sport of volleyball under physical dynamics. VolleyBots integrates three features within a unified platform: competitive and cooperative gameplay, turn-based interaction structure, and agile 3D maneuvering. Competitive and cooperative gameplay challenges each drone to coordinate with its teammates while anticipating and countering opposing teams' tactics. Turn-based interaction demands precise timing, accurate state prediction, and management of long-horizon temporal dependencies. Agile 3D maneuvering requires rapid accelerations, sharp turns, and precise 3D positioning despite the quadrotor's underactuated dynamics. These intertwined features yield a complex problem combining motion control and strategic play, with no available expert demonstrations. We provide a comprehensive suite of tasks ranging from single-drone drills to multi-drone cooperative and competitive tasks, accompanied by baseline evaluations of representative multi-agent reinforcement learning (MARL) and game-theoretic algorithms. Simulation results show that on-policy reinforcement learning (RL) methods outperform off-policy methods in single-agent tasks, but both approaches struggle in complex tasks that combine motion control and strategic play. We additionally design a hierarchical policy which achieves a 69.5% percent win rate against the strongest baseline in the 3 vs 3 task, underscoring its potential as an effective solution for tackling the complex interplay between low-level control and high-level strategy. The project page is at https://sites.google.com/view/thu-volleybots.","authors":["Zelai Xu","Ruize Zhang","Chao Yu","Huining Yuan","Xiangmin Yi","Shilong Ji","Chuqi Wang","Wenhao Tang","Feng Gao","Wenbo Ding","Xinlei Chen","Yu Wang"],"url":"https://arxiv.org/abs/2502.01932"}
{"created":"2025-05-20","title":"Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models","abstract":"Values are core drivers of individual and collective perception, cognition, and behavior. Value systems, such as Schwartz's Theory of Basic Human Values, delineate the hierarchy and interplay among these values, enabling cross-disciplinary investigations into decision-making and societal dynamics. Recently, the rise of Large Language Models (LLMs) has raised concerns regarding their elusive intrinsic values. Despite growing efforts in evaluating, understanding, and aligning LLM values, a psychologically grounded LLM value system remains underexplored. This study addresses the gap by introducing the Generative Psycho-Lexical Approach (GPLA), a scalable, adaptable, and theoretically informed method for constructing value systems. Leveraging GPLA, we propose a psychologically grounded five-factor value system tailored for LLMs. For systematic validation, we present three benchmarking tasks that integrate psychological principles with cutting-edge AI priorities. Our results reveal that the proposed value system meets standard psychological criteria, better captures LLM values, improves LLM safety prediction, and enhances LLM alignment, when compared to the canonical Schwartz's values.","authors":["Haoran Ye","Tianze Zhang","Yuhang Xie","Liyuan Zhang","Yuanyi Ren","Xin Zhang","Guojie Song"],"url":"https://arxiv.org/abs/2502.02444"}
{"created":"2025-05-20","title":"LadderMIL: Multiple Instance Learning with Coarse-to-Fine Self-Distillation","abstract":"Multiple Instance Learning (MIL) for whole slide image (WSI) analysis in computational pathology often neglects instance-level learning as supervision is typically provided only at the bag level. In this work, we present LadderMIL, a framework designed to improve MIL through two perspectives: (1) employing instance-level supervision and (2) learning inter-instance contextual information at bag level. Firstly, we propose a novel Coarse-to-Fine Self-Distillation (CFSD) paradigm that probes and distils a network trained with bag-level information to adaptively obtain instance-level labels which could effectively provide the instance-level supervision for the same network in a self-improving way. Secondly, to capture inter-instance contextual information in WSI, we propose a Contextual Ecoding Generator (CEG), which encodes the contextual appearance of instances within a bag. We also theoretically and empirically prove the instance-level learnability of CFSD. Our LadderMIL is evaluated on multiple clinically relevant benchmarking tasks including breast cancer receptor status classification, multi-class subtype classification, tumour classification, and prognosis prediction. Average improvements of 8.1%, 11% and 2.4% in AUC, F1-score, and C-index, respectively, are demonstrated across the five benchmarks, compared to the best baseline.","authors":["Shuyang Wu","Yifu Qiu","Ines P. Nearchou","Sandrine Prost","Jonathan A. Fallowfield","David J. Harrison","Hakan Bilen","Timothy J. Kendall"],"url":"https://arxiv.org/abs/2502.02707"}
{"created":"2025-05-20","title":"Gradient Correction in Federated Learning with Adaptive Optimization","abstract":"In federated learning (FL), model training performance is strongly impacted by data heterogeneity across clients. Client-drift compensation methods have recently emerged as a solution to this issue, introducing correction terms into local model updates. To date, these methods have only been considered under stochastic gradient descent (SGD)-based model training, while modern FL frameworks also employ adaptive optimizers (e.g., Adam) for improved convergence. However, due to the complex interplay between first and second moments found in most adaptive optimization methods, naively injecting correction terms can lead to performance degradation in heterogeneous settings. In this work, we propose {\\tt FAdamGC}, the first algorithm to integrate drift compensation into adaptive federated optimization. The key idea of {\\tt FAdamGC} is injecting a pre-estimation correction term that aligns with the moment structure of adaptive methods. We provide a rigorous convergence analysis of our algorithm under non-convex settings, showing that {\\tt FAdamGC} results in better rate and milder assumptions than naively porting SGD-based correction algorithms into adaptive optimizers. Our experimental results demonstrate that {\\tt FAdamGC} consistently outperform existing methods in total communication and computation cost across varying levels of data heterogeneity, showing the efficacy of correcting gradient information in federated adaptive optimization.","authors":["Evan Chen","Shiqiang Wang","Jianing Zhang","Dong-Jun Han","Chaoyue Liu","Christopher Brinton"],"url":"https://arxiv.org/abs/2502.02727"}
{"created":"2025-05-20","title":"Leveraging the true depth of LLMs","abstract":"Large Language Models (LLMs) demonstrate remarkable capabilities at the cost of high compute requirements. Recent studies have demonstrated that intermediate layers in LLMs can be removed or reordered without substantial accuracy loss; however, this insight has not yet been exploited to improve inference efficiency. Leveraging observed layer independence, we propose a novel method that groups consecutive layers into pairs evaluated in parallel, effectively restructuring the computational graph to enhance parallelism. Without requiring retraining or fine-tuning, this approach achieves an inference throughput improvement of 1.05x-1.20x on standard benchmarks, retaining 95\\%-99\\% of the original model accuracy. Empirical results demonstrate the practicality of this method in significantly reducing inference cost for large-scale LLM deployment. Additionally, we demonstrate that modest performance degradation can be substantially mitigated through lightweight fine-tuning, further enhancing the method's applicability.","authors":["Ram\\'on Calvo Gonz\\'alez","Daniele Paliotta","Matteo Pagliardini","Martin Jaggi","Fran\\c{c}ois Fleuret"],"url":"https://arxiv.org/abs/2502.02790"}
{"created":"2025-05-20","title":"Large Language Model as Universal Retriever in Industrial-Scale Recommender System","abstract":"In real-world recommender systems, different retrieval objectives are typically addressed using task-specific datasets with carefully designed model architectures. We demonstrate that Large Language Models (LLMs) can function as universal retrievers, capable of handling multiple objectives within a generative retrieval framework. To model complex user-item relationships within generative retrieval, we propose multi-query representation. To address the challenge of extremely large candidate sets in industrial recommender systems, we introduce matrix decomposition to boost model learnability, discriminability, and transferability, and we incorporate probabilistic sampling to reduce computation costs. Finally, our Universal Retrieval Model (URM) can adaptively generate a set from tens of millions of candidates based on arbitrary given objective while keeping the latency within tens of milliseconds. Applied to industrial-scale data, URM outperforms expert models elaborately designed for different retrieval objectives on offline experiments and significantly improves the core metric of online advertising platform by $3\\%$.","authors":["Junguang Jiang","Yanwen Huang","Bin Liu","Xiaoyu Kong","Xinhang Li","Ziru Xu","Han Zhu","Jian Xu","Bo Zheng"],"url":"https://arxiv.org/abs/2502.03041"}
{"created":"2025-05-20","title":"Understanding and Enhancing the Transferability of Jailbreaking Attacks","abstract":"Jailbreaking attacks can effectively manipulate open-source large language models (LLMs) to produce harmful responses. However, these attacks exhibit limited transferability, failing to disrupt proprietary LLMs consistently. To reliably identify vulnerabilities in proprietary LLMs, this work investigates the transferability of jailbreaking attacks by analysing their impact on the model's intent perception. By incorporating adversarial sequences, these attacks can redirect the source LLM's focus away from malicious-intent tokens in the original input, thereby obstructing the model's intent recognition and eliciting harmful responses. Nevertheless, these adversarial sequences fail to mislead the target LLM's intent perception, allowing the target LLM to refocus on malicious-intent tokens and abstain from responding. Our analysis further reveals the inherent distributional dependency within the generated adversarial sequences, whose effectiveness stems from overfitting the source LLM's parameters, resulting in limited transferability to target LLMs. To this end, we propose the Perceived-importance Flatten (PiF) method, which uniformly disperses the model's focus across neutral-intent tokens in the original input, thus obscuring malicious-intent tokens without relying on overfitted adversarial sequences. Extensive experiments demonstrate that PiF provides an effective and efficient red-teaming evaluation for proprietary LLMs.","authors":["Runqi Lin","Bo Han","Fengwang Li","Tongling Liu"],"url":"https://arxiv.org/abs/2502.03052"}
{"created":"2025-05-20","title":"Learning Reward Machines from Partially Observed Policies","abstract":"Inverse reinforcement learning is the problem of inferring a reward function from an optimal policy or demonstrations by an expert. In this work, it is assumed that the reward is expressed as a reward machine whose transitions depend on atomic propositions associated with the state of a Markov Decision Process (MDP). Our goal is to identify the true reward machine using finite information. To this end, we first introduce the notion of a prefix tree policy which associates a distribution of actions to each state of the MDP and each attainable finite sequence of atomic propositions. Then, we characterize an equivalence class of reward machines that can be identified given the prefix tree policy. Finally, we propose a SAT-based algorithm that uses information extracted from the prefix tree policy to solve for a reward machine. It is proved that if the prefix tree policy is known up to a sufficient (but finite) depth, our algorithm recovers the exact reward machine up to the equivalence class. This sufficient depth is derived as a function of the number of MDP states and (an upper bound on) the number of states of the reward machine. These results are further extended to the case where we only have access to demonstrations from an optimal policy. Several examples, including discrete grid and block worlds, a continuous state-space robotic arm, and real data from experiments with mice, are used to demonstrate the effectiveness and generality of the approach.","authors":["Mohamad Louai Shehab","Antoine Aspeel","Necmiye Ozay"],"url":"https://arxiv.org/abs/2502.03762"}
{"created":"2025-05-20","title":"LR0.FM: Low-Res Benchmark and Improving Robustness for Zero-Shot Classification in Foundation Models","abstract":"Visual-language foundation Models (FMs) exhibit remarkable zero-shot generalization across diverse tasks, largely attributed to extensive pre-training on largescale datasets. However, their robustness on low-resolution/pixelated (LR) images, a common challenge in real-world scenarios, remains underexplored. We introduce LR0.FM, a comprehensive benchmark evaluating the impact of low resolution on the zero-shot classification performance of 10 FM(s) across 66 backbones and 15 datasets. We propose a novel metric, Weighted Aggregated Robustness, to address the limitations of existing metrics and better evaluate model performance across resolutions and datasets. Our key findings show that: (i) model size positively correlates with robustness to resolution degradation, (ii) pre-training dataset quality is more important than its size, and (iii) fine-tuned and higher resolution models are less robust against LR. Our analysis further reveals that the model makes semantically reasonable predictions at LR, and the lack of fine-grained details in input adversely impacts the model's initial layers more than the deeper layers. We use these insights and introduce a simple strategy, LR-TK0, to enhance the robustness of models without compromising their pre-trained weights. We demonstrate the effectiveness of LR-TK0 for robustness against low-resolution across several datasets and its generalization capability across backbones and other approaches. Code is available at https://github.com/shyammarjit/LR0.FM","authors":["Priyank Pathak","Shyam Marjit","Shruti Vyas","Yogesh S Rawat"],"url":"https://arxiv.org/abs/2502.03950"}
{"created":"2025-05-20","title":"Reformulation for Pretraining Data Augmentation","abstract":"Despite the impressive capabilities of large language models across various tasks, their continued scaling is severely hampered not only by data scarcity but also by the performance degradation associated with excessive data repetition during training. To overcome this critical bottleneck, we propose the Massive Genre-Audience(MGA) reformulation method, a lightweight and scalable data augmentation technique inspired by synthetic data methodologies. MGA systematically reformulates existing corpora into diverse, contextually-rich variations to mitigate the negative effects of repetition, and we introduce this approach along with the resulting 770 billion token MGACorpus in this work. We experimentally validate its core benefit by demonstrating superior performance against data repetition and upsampling in scaling scenarios (up to 13B parameters). Furthermore, comprehensive analysis investigates the role of prompt engineering in generation quality and reveals nuances in evaluating model capabilities using standard loss metrics. Our work shows that MGA provides a reliable pathway to substantially augment training datasets, effectively alleviating repetition bottlenecks and enabling more efficient scaling of large language models.","authors":["Xintong Hao","Ruijie Zhu","Ge Zhang","Ke Shen","Chenggang Li"],"url":"https://arxiv.org/abs/2502.04235"}
{"created":"2025-05-20","title":"Efficient Randomized Experiments Using Foundation Models","abstract":"Randomized experiments are the preferred approach for evaluating the effects of interventions, but they are costly and often yield estimates with substantial uncertainty. On the other hand, in silico experiments leveraging foundation models offer a cost-effective alternative that can potentially attain higher statistical precision. However, the benefits of in silico experiments come with a significant risk: statistical inferences are not valid if the models fail to accurately predict experimental responses to interventions. In this paper, we propose a novel approach that integrates the predictions from multiple foundation models with experimental data while preserving valid statistical inference. Our estimator is consistent and asymptotically normal, with asymptotic variance no larger than the standard estimator based on experimental data alone. Importantly, these statistical properties hold even when model predictions are arbitrarily biased. Empirical results across several randomized experiments show that our estimator offers substantial precision gains, equivalent to a reduction of up to 20% in the sample size needed to match the same precision as the standard estimator based on experimental data alone.","authors":["Piersilvio De Bartolomeis","Javier Abad","Guanbo Wang","Konstantin Donhauser","Raymond M. Duch","Fanny Yang","Issa J. Dahabreh"],"url":"https://arxiv.org/abs/2502.04262"}
{"created":"2025-05-20","title":"Implicit Bias of Spectral Descent and Muon on Multiclass Separable Data","abstract":"Different gradient-based methods for optimizing overparameterized models can all achieve zero training error yet converge to distinctly different solutions inducing different generalization properties. We provide the first complete characterization of implicit optimization bias for p-norm normalized steepest descent (NSD) and momentum steepest descent (NMD) algorithms in multi-class linear classification with cross-entropy loss. Our key theoretical contribution is proving that these algorithms converge to solutions maximizing the margin with respect to the classifier matrix's p-norm, with established convergence rates. These results encompass important special cases including Spectral Descent and Muon, which we show converge to max-margin solutions with respect to the spectral norm. A key insight of our contribution is that the analysis of general entry-wise and Schatten p-norms can be reduced to the analysis of NSD/NMD with max-norm by exploiting a natural ordering property between all p-norms relative to the max-norm and its dual sum-norm. For the specific case of descent with respect to the max-norm, we further extend our analysis to include preconditioning, showing that Adam converges to the matrix's max-norm solution. Our results demonstrate that the multi-class linear setting, which is inherently richer than the binary counterpart, provides the most transparent framework for studying implicit biases of matrix-parameter optimization algorithms.","authors":["Chen Fan","Mark Schmidt","Christos Thrampoulidis"],"url":"https://arxiv.org/abs/2502.04664"}
{"created":"2025-05-20","title":"UniCMs: A Unified Consistency Model For Efficient Multimodal Generation and Understanding","abstract":"Consistency models (CMs) have shown promise in the efficient generation of both image and text. This raises the natural question of whether we can learn a unified CM for efficient multimodal generation (e.g., text-to-image) and understanding (e.g., image-to-text). Intuitively, such a model could be acquired by applying the consistency distillation (CD) to existing unified multimodal models. However, the key challenge is establishing a unified denoising perspective for both image and text generation, which is essential for establishing the consistency mapping. To tackle this, at the representation level, we advocate for discrete tokens for both modalities to best preserve language modeling capabilities. Critically, instead of defining the text denoising trajectory via recent discrete diffusion language modeling principles, we specify it using the parallel decoding trace of an autoregressive language model, benefiting from the latter's superior performance in general text generation tasks. The denoising trajectory of image tokens adheres to standard discrete diffusion. We train our unified consistency models (UniCMs) on these combined multimodal trajectories simultaneously with a unified objective. We introduce a trajectory segmentation strategy to further improve the training convergence. Empirically, in text-to-image generation, UniCMs outperform SD3 on GenEval, Image Reward, and CLIP Score metrics, while requiring only approximately ${1}/{8}$ of the sampling time. Meanwhile, in image-to-text generation, UniCMs surpass Show-o on the MMMU benchmark while being $1.5 \\times$ faster at long-sequence generating speed. The code is available at https://github.com/zhijie-group/UniCMs.","authors":["Chenkai Xu","Xu Wang","Zhenyi Liao","Yishun Li","Tianqi Hou","Zhijie Deng"],"url":"https://arxiv.org/abs/2502.05415"}
{"created":"2025-05-20","title":"Differentially Private Synthetic Data via APIs 3: Using Simulators Instead of Foundation Model","abstract":"Differentially private (DP) synthetic data, which closely resembles the original private data while maintaining strong privacy guarantees, has become a key tool for unlocking the value of private data without compromising privacy. Recently, Private Evolution (PE) has emerged as a promising method for generating DP synthetic data. Unlike other training-based approaches, PE only requires access to inference APIs from foundation models, enabling it to harness the power of state-of-the-art (SoTA) models. However, a suitable foundation model for a specific private data domain is not always available. In this paper, we discover that the PE framework is sufficiently general to allow APIs beyond foundation models. In particular, we demonstrate that many SoTA data synthesizers that do not rely on neural networks--such as computer graphics-based image generators, which we refer to as simulators--can be effectively integrated into PE. This insight significantly broadens PE's applicability and unlocks the potential of powerful simulators for DP data synthesis. We explore this approach, named Sim-PE, in the context of image synthesis. Across four diverse simulators, Sim-PE performs well, improving the downstream classification accuracy of PE by up to 3x, reducing FID by up to 80%, and offering much greater efficiency. We also show that simulators and foundation models can be easily leveraged together within PE to achieve further improvements. The code is open-sourced in the Private Evolution Python library: https://github.com/microsoft/DPSDA.","authors":["Zinan Lin","Tadas Baltrusaitis","Wenyu Wang","Sergey Yekhanin"],"url":"https://arxiv.org/abs/2502.05505"}
{"created":"2025-05-20","title":"ATLAS: Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data","abstract":"Autoformalization, the automatic translation of mathematical content from natural language into machine-verifiable formal languages, has seen significant progress driven by advances in large language models (LLMs). Nonetheless, a primary barrier to further improvements is the limited availability of parallel corpora that map informal mathematical text to its formal counterpart. To address this limitation, we propose ATLAS (Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data), a novel data generation framework designed to produce large-scale, high-quality parallel corpora of theorem statements. Distinct from prior approaches, ATLAS begins with a concept repository, accelerates the improvement of student model through expert iteration combined with knowledge distillation, and introduces two novel augmentation strategies that exploit the structural characteristics of formal languages. With the proposed ATLAS running for 10 iterations, we construct an undergraduate-level dataset comprising 117k theorem statements and develop ATLAS Translator, which demonstrates statistically significant improvements over both the HERALD Translator and the Kimina-Autoformalizer across all benchmarks ($p<0.05$, two-sided t-test), achieving a new state of the art. The datasets, model, and code will be released to the public soon.","authors":["Xiaoyang Liu","Kangjie Bao","Jiashuo Zhang","Yunqi Liu","Yuntian Liu","Yu Chen","Yang Jiao","Tao Luo"],"url":"https://arxiv.org/abs/2502.05567"}
{"created":"2025-05-20","title":"Evolving LLMs' Self-Refinement Capability via Iterative Preference Optimization","abstract":"While large language models (LLMs) have demonstrated remarkable general performance, enabling smaller models to achieve capabilities comparable to their larger counterparts remains a critical challenge. For humans, iterative refinement of problem analysis and responses is a common strategy to enhance answer quality. However, we observe that existing LLMs exhibit limited ability to refine their outputs for quality improvement. In this paper, we first investigate mechanisms to unlock and progressively enhance self-refinement ability in smaller models within an iterative preference optimization framework, aiming to bridge the performance gap with larger models. To this end, we propose EVOLVE, a novel post-training and inference framework that iteratively integrates preference training with self-refinement-driven data collection. During training, EVOLVE strengthens the model's direct question-answering ability while simultaneously unlocking its self-refinement potential. At inference, the framework leverages this capability to generate progressively refined responses, which are filtered to construct datasets for subsequent rounds of preference training. Experiments demonstrate EVOLVE's exceptional performance: when applied to Llama-3.1-8B base model and under the self-refinement setting, it surpasses state-of-the-art models including Llama-3.1-405B-Instruct and GPT-4o, achieving a 62.3% length-controlled win rate and 63.3% raw win rate on AlpacaEval 2, along with a 50.3% win rate on Arena-Hard. Furthermore, EVOLVE consistently enhances performance on mathematical reasoning tasks like GSM8K and MATH.","authors":["Yongcheng Zeng","Xinyu Cui","Xuanfa Jin","Guoqing Liu","Zexu Sun","Dong Li","Ning Yang","Jianye Hao","Haifeng Zhang","Jun Wang"],"url":"https://arxiv.org/abs/2502.05605"}
{"created":"2025-05-20","title":"Modeling and Beamforming Optimization for Pinching-Antenna Systems","abstract":"The Pinching-Antenna SyStem (PASS) is a revolutionary flexible antenna technology designed to enhance wireless communication by establishing strong line-of-sight (LoS) links, reducing free-space path loss and enabling antenna array reconfigurability. PASS uses dielectric waveguides with low propagation loss for signal transmission, radiating via a passive pinching antenna, which is a small dielectric element applied to the waveguide. This paper first proposes a physics-based hardware model for PASS, where the pinching antenna is modeled as an open-ended directional coupler, and the electromagnetic field behavior is analyzed using coupled-mode theory. A simplified signal model characterizes the coupling effect between multiple antennas on the same waveguide. Based on this, two power models are proposed: equal power and proportional power models. Additionally, a transmit power minimization problem is formulated/studied for the joint optimization of transmit and pinching beamforming under both continuous and discrete pinching antenna activations. Two algorithms are proposed to solve this multimodal optimization problem: the penalty-based alternating optimization algorithm and a low-complexity zero-forcing (ZF)-based algorithm. Numerical results show that 1) the ZF-based low-complexity algorithm performs similarly to the penalty-based algorithm, 2) PASS reduces transmit power by over 95% compared to conventional and massive MIMO, 3) discrete activation causes minimal performance loss but requires a dense antenna set to match continuous activation, and 4) the proportional power model yields performance comparable to the equal power model.","authors":["Zhaolin Wang","Chongjun Ouyang","Xidong Mu","Yuanwei Liu","Zhiguo Ding"],"url":"https://arxiv.org/abs/2502.05917"}
{"created":"2025-05-20","title":"Projection-based Lyapunov method for fully heterogeneous weakly-coupled MDPs","abstract":"Heterogeneity poses a fundamental challenge for many real-world large-scale decision-making problems but remains largely understudied. In this paper, we study the fully heterogeneous setting of a prominent class of such problems, known as weakly-coupled Markov decision processes (WCMDPs). Each WCMDP consists of $N$ arms (or subproblems), which have distinct model parameters in the fully heterogeneous setting, leading to the curse of dimensionality when $N$ is large. We show that, under mild assumptions, an efficiently computable policy achieves an $O(1/\\sqrt{N})$ optimality gap in the long-run average reward per arm for fully heterogeneous WCMDPs as $N$ becomes large. This is the first asymptotic optimality result for fully heterogeneous average-reward WCMDPs. Our main technical innovation is the construction of projection-based Lyapunov functions that certify the convergence of rewards and costs to an optimal region, even under full heterogeneity.","authors":["Xiangcheng Zhang","Yige Hong","Weina Wang"],"url":"https://arxiv.org/abs/2502.06072"}
{"created":"2025-05-20","title":"Right Time to Learn:Promoting Generalization via Bio-inspired Spacing Effect in Knowledge Distillation","abstract":"Knowledge distillation (KD) is a powerful strategy for training deep neural networks (DNNs). Although it was originally proposed to train a more compact \"student\" model from a large \"teacher\" model, many recent efforts have focused on adapting it to promote generalization of the model itself, such as online KD and self KD. Here, we propose an accessible and compatible strategy named Spaced KD to improve the effectiveness of both online KD and self KD, in which the student model distills knowledge from a teacher model trained with a space interval ahead. This strategy is inspired by a prominent theory named spacing effect in biological learning and memory, positing that appropriate intervals between learning trials can significantly enhance learning performance. With both theoretical and empirical analyses, we demonstrate that the benefits of the proposed Spaced KD stem from convergence to a flatter loss landscape during stochastic gradient descent (SGD). We perform extensive experiments to validate the effectiveness of Spaced KD in improving the learning performance of DNNs (e.g., the performance gain is up to 2.31% and 3.34% on Tiny-ImageNet over online KD and self KD, respectively). Our codes have been released on github https://github.com/SunGL001/Spaced-KD.","authors":["Guanglong Sun","Hongwei Yan","Liyuan Wang","Qian Li","Bo Lei","Yi Zhong"],"url":"https://arxiv.org/abs/2502.06192"}
{"created":"2025-05-20","title":"Is LLM an Overconfident Judge? Unveiling the Capabilities of LLMs in Detecting Offensive Language with Annotation Disagreement","abstract":"Large Language Models (LLMs) have become essential for offensive language detection, yet their ability to handle annotation disagreement remains underexplored. Disagreement samples, which arise from subjective interpretations, pose a unique challenge due to their ambiguous nature. Understanding how LLMs process these cases, particularly their confidence levels, can offer insight into their alignment with human annotators. This study systematically evaluates the performance of multiple LLMs in detecting offensive language at varying levels of annotation agreement. We analyze binary classification accuracy, examine the relationship between model confidence and human disagreement, and explore how disagreement samples influence model decision-making during few-shot learning and instruction fine-tuning. Our findings reveal that LLMs struggle with low-agreement samples, often exhibiting overconfidence in these ambiguous cases. However, utilizing disagreement samples in training improves both detection accuracy and model alignment with human judgment. These insights provide a foundation for enhancing LLM-based offensive language detection in real-world moderation tasks.","authors":["Junyu Lu","Kai Ma","Kaichun Wang","Kelaiti Xiao","Roy Ka-Wei Lee","Bo Xu","Liang Yang","Hongfei Lin"],"url":"https://arxiv.org/abs/2502.06207"}
{"created":"2025-05-20","title":"Provably Near-Optimal Federated Ensemble Distillation with Negligible Overhead","abstract":"Federated ensemble distillation addresses client heterogeneity by generating pseudo-labels for an unlabeled server dataset based on client predictions and training the server model using the pseudo-labeled dataset. The unlabeled server dataset can either be pre-existing or generated through a data-free approach. The effectiveness of this approach critically depends on the method of assigning weights to client predictions when creating pseudo-labels, especially in highly heterogeneous settings. Inspired by theoretical results from GANs, we propose a provably near-optimal weighting method that leverages client discriminators trained with a server-distributed generator and local datasets. Our experiments on various image classification tasks demonstrate that the proposed method significantly outperforms baselines. Furthermore, we show that the additional communication cost, client-side privacy leakage, and client-side computational overhead introduced by our method are negligible, both in scenarios with and without a pre-existing server dataset.","authors":["Won-Jun Jang","Hyeon-Seo Park","Si-Hyeon Lee"],"url":"https://arxiv.org/abs/2502.06349"}
{"created":"2025-05-20","title":"Who Taught You That? Tracing Teachers in Model Distillation","abstract":"Model distillation -- using outputs from a large teacher model to teach a small student model -- is a practical means of creating efficient models for a particular task. We ask: Can we identify a students' teacher based on its outputs? Such \"footprints\" left by teacher LLMs would be interesting artifacts. Beyond this, reliable teacher inference may have practical implications as actors seek to distill specific capabilities of massive proprietary LLMs into deployed smaller LMs, potentially violating terms of service. We consider practical task distillation targets including summarization, question answering, and instruction-following. We assume a finite set of candidate teacher models, which we treat as blackboxes. We design discriminative models that operate over lexical features. We find that $n$-gram similarity alone is unreliable for identifying teachers, but part-of-speech (PoS) templates preferred by student models mimic those of their teachers.","authors":["Somin Wadhwa","Chantal Shaib","Silvio Amir","Byron C. Wallace"],"url":"https://arxiv.org/abs/2502.06659"}
{"created":"2025-05-20","title":"Generation of Drug-Induced Cardiac Reactions towards Virtual Clinical Trials","abstract":"Clinical trials remain critical in cardiac drug development but face high failure rates due to efficacy limitations and safety risks, incurring substantial costs. In-silico trial methodologies, particularly generative models simulating drug-induced electrocardiogram (ECG) alterations, offer a potential solution to mitigate these challenges. While existing models show progress in ECG synthesis, their constrained fidelity and inability to characterize individual-specific pharmacological response patterns fundamentally limit clinical translatability. To address these issues, we propose a novel Drug-Aware Diffusion Model (DADM). Specifically, we construct a set of ordinary differential equations to provide external physical knowledge (EPK) of the realistic ECG morphology. The EPK is used to adaptively constrain the morphology of the generated ECGs through a dynamic cross-attention (DCA) mechanism. Furthermore, we propose an extension of ControlNet to incorporate demographic and drug data, simulating individual drug reactions. Compared to the other eight state-of-the-art (SOTA) ECG generative models: 1) Quantitative and expert evaluation demonstrate that DADM generates ECGs with superior fidelity; 2) Comparative results on two real-world databases covering 8 types of drug regimens verify that DADM can more accurately simulate drug-induced changes in ECGs, improving the accuracy by at least 5.79% and recall by 8%. In addition, the ECGs generated by DADM can also enhance model performance in downstream drug-effect classification tasks.","authors":["Qian Shao","Bang Du","Zepeng Li","Qiyuan Chen","Hongxia Xu","Jimeng Sun","Jian Wu","Jintai Chen"],"url":"https://arxiv.org/abs/2502.07297"}
{"created":"2025-05-20","title":"Generative Modeling with Bayesian Sample Inference","abstract":"We derive a novel generative model from iterative Gaussian posterior inference. By treating the generated sample as an unknown variable, we can formulate the sampling process in the language of Bayesian probability. Our model uses a sequence of prediction and posterior update steps to iteratively narrow down the unknown sample starting from a broad initial belief. In addition to a rigorous theoretical analysis, we establish a connection between our model and diffusion models and show that it includes Bayesian Flow Networks (BFNs) as a special case. In our experiments, we demonstrate that our model improves sample quality on ImageNet32 over both BFNs and the closely related Variational Diffusion Models, while achieving equivalent log-likelihoods on ImageNet32 and CIFAR10. Find our code at https://github.com/martenlienen/bsi.","authors":["Marten Lienen","Marcel Kollovieh","Stephan G\\\"unnemann"],"url":"https://arxiv.org/abs/2502.07580"}
{"created":"2025-05-20","title":"Rolling with the Punches: Resilient Contrastive Pre-training under Non-Stationary Drift","abstract":"The remarkable success of large-scale contrastive pre-training, fueled by vast and curated datasets, is encountering new frontiers as the scaling paradigm evolves. A critical emerging challenge is the effective pre-training of models on dynamic data streams characterized by concept drift, unpredictable changes in the underlying data distribution. This paper undertakes a foundational investigation of this issue. We first reveal that conventional contrastive pre-training methods are notably vulnerable to concept drift, leading to significant biases in the learned feature space of pre-trained models. To systematically analyze these effects, we construct a structural causal model that elucidates how drift acts as a confounder, distorting learned representations. Based on these causal insights, we propose Resilient Contrastive Pre-training (RCP), a novel method incorporating causal intervention. RCP introduces a causally-informed objective designed to mitigate drift-induced biases by leveraging targeted interventions. RCP is designed for simple and scalable implementation and exhibits notable adaptability, promoting robust pre-training on evolving data. Comprehensive experiments across diverse downstream tasks compellingly demonstrate that RCP effectively alleviates the detrimental impact of concept drift, yielding more resilient and generalizable representations.","authors":["Xiaoyu Yang","Jie Lu","En Yu"],"url":"https://arxiv.org/abs/2502.07620"}
{"created":"2025-05-20","title":"Reachability and Related Problems in Vector Addition Systems with Nested Zero Tests","abstract":"Vector addition systems with states (VASS), also known as Petri nets, are a popular model of concurrent systems. Many problems from many areas reduce to the reachability problem for VASS, which consists of deciding whether a target configuration of a VASS is reachable from a given initial configuration. In this paper, we obtain an Ackermannian (primitive-recursive in fixed dimension) upper bound for the reachability problem in VASS with nested zero tests. Furthermore, we provide a uniform approach which also allows to decide most related problems, for example semilinearity and separability, in the same complexity. For some of these problems like semilinearity the complexity was unknown even for plain VASS.","authors":["Roland Guttenberg","Wojciech Czerwi\\'nski","S{\\l}awomir Lasota"],"url":"https://arxiv.org/abs/2502.07660"}
{"created":"2025-05-20","title":"Captured by Captions: On Memorization and its Mitigation in CLIP Models","abstract":"Multi-modal models, such as CLIP, have demonstrated strong performance in aligning visual and textual representations, excelling in tasks like image retrieval and zero-shot classification. Despite this success, the mechanisms by which these models utilize training data, particularly the role of memorization, remain unclear. In uni-modal models, both supervised and self-supervised, memorization has been shown to be essential for generalization. However, it is not well understood how these findings would apply to CLIP, which incorporates elements from both supervised learning via captions that provide a supervisory signal similar to labels, and from self-supervised learning via the contrastive objective. To bridge this gap in understanding, we propose a formal definition of memorization in CLIP (CLIPMem) and use it to quantify memorization in CLIP models. Our results indicate that CLIP's memorization behavior falls between the supervised and self-supervised paradigms, with \"mis-captioned\" samples exhibiting highest levels of memorization. Additionally, we find that the text encoder contributes more to memorization than the image encoder, suggesting that mitigation strategies should focus on the text domain. Building on these insights, we propose multiple strategies to reduce memorization while at the same time improving utility--something that had not been shown before for traditional learning paradigms where reducing memorization typically results in utility decrease.","authors":["Wenhao Wang","Adam Dziedzic","Grace C. Kim","Michael Backes","Franziska Boenisch"],"url":"https://arxiv.org/abs/2502.07830"}
{"created":"2025-05-20","title":"Mamba Adaptive Anomaly Transformer with association discrepancy for time series","abstract":"Anomaly detection in time series is essential for industrial monitoring and environmental sensing, yet distinguishing anomalies from complex patterns remains challenging. Existing methods like the Anomaly Transformer and DCdetector have progressed, but they face limitations such as sensitivity to short-term contexts and inefficiency in noisy, non-stationary environments.","authors":["Abdellah Zakaria Sellam","Ilyes Benaissa","Abdelmalik Taleb-Ahmed","Luigi Patrono","Cosimo Distante"],"url":"https://arxiv.org/abs/2502.07858"}
{"created":"2025-05-20","title":"H\\\"arpfer's Extended Indispensability Algorithm in Z","abstract":"Since 1978, Clarence Barlow developed the ``Indispensability Function''. It operates on a metric tree that is bound to the same prime number of branches for all subtrees of each particular level. It assigns to all leaf postions of this tree a numeric value which indicates how important the acoustic presence of an event at this position is for the meter to be recognized as such.","authors":["Markus Lepper","Bernd H\\\"arpfer","Baltasar Tranc\\'on y Widemann"],"url":"https://arxiv.org/abs/2502.07966"}
{"created":"2025-05-20","title":"Greed is Good: A Unifying Perspective on Guided Generation","abstract":"Training-free guided generation is a widely used and powerful technique that allows the end user to exert further control over the generative process of flow/diffusion models. Generally speaking, two families of techniques have emerged for solving this problem for gradient-based guidance: namely, posterior guidance (i.e., guidance via projecting the current sample to the target distribution via the target prediction model) and end-to-end guidance (i.e., guidance by performing backpropagation throughout the entire ODE solve). In this work, we show that these two seemingly separate families can actually be unified by looking at posterior guidance as a greedy strategy of end-to-end guidance. We explore the theoretical connections between these two families and provide an in-depth theoretical of these two techniques relative to the continuous ideal gradients. Motivated by this analysis we then show a method for interpolating between these two families enabling a trade-off between compute and accuracy of the guidance gradients. We then validate this work on several inverse image problems and property-guided molecular generation.","authors":["Zander W. Blasingame","Chen Liu"],"url":"https://arxiv.org/abs/2502.08006"}
{"created":"2025-05-20","title":"Collaborative Filtering Meets Spectrum Shift: Connecting User-Item Interaction with Graph-Structured Side Information","abstract":"Graph Neural Networks (GNNs) have demonstrated their superiority in collaborative filtering, where the user-item (U-I) interaction bipartite graph serves as the fundamental data format. However, when graph-structured side information (e.g., multimodal similarity graphs or social networks) is integrated into the U-I bipartite graph, existing graph collaborative filtering methods fall short of achieving satisfactory performance. We quantitatively analyze this problem from a spectral perspective. Recall that a bipartite graph possesses a full spectrum within the range of [-1, 1], with the highest frequency exactly achievable at -1 and the lowest frequency at 1; however, we observe as more side information is incorporated, the highest frequency of the augmented adjacency matrix progressively shifts rightward. This spectrum shift phenomenon has caused previous approaches built for the full spectrum [-1, 1] to assign mismatched importance to different frequencies. To this end, we propose Spectrum Shift Correction (dubbed SSC), incorporating shifting and scaling factors to enable spectral GNNs to adapt to the shifted spectrum. Unlike previous paradigms of leveraging side information, which necessitate tailored designs for diverse data types, SSC directly connects traditional graph collaborative filtering with any graph-structured side information. Experiments on social and multimodal recommendation demonstrate the effectiveness of SSC, achieving relative improvements of up to 23% without incurring any additional computational overhead. Our code is available at https://github.com/yhhe2004/SSC-KDD.","authors":["Yunhang He","Cong Xu","Jun Wang","Wei Zhang"],"url":"https://arxiv.org/abs/2502.08071"}
{"created":"2025-05-20","title":"DICE: Device-level Integrated Circuits Encoder with Graph Contrastive Pretraining","abstract":"Pretraining models with unsupervised graph representation learning has led to significant advancements in domains such as social network analysis, molecular design, and electronic design automation (EDA). However, prior work in EDA has mainly focused on pretraining models for digital circuits, overlooking analog and mixed-signal circuits. To bridge this gap, we introduce DICE, a Device-level Integrated Circuits Encoder, which is the first graph neural network (GNN) pretrained via self-supervised learning specifically tailored for graph-level prediction tasks in both analog and digital circuits. DICE adopts a simulation-free pretraining approach based on graph contrastive learning, leveraging two novel graph augmentation techniques. Experimental results demonstrate substantial performance improvements across three downstream tasks, highlighting the effectiveness of DICE for both analog and digital circuits. The code is available at github.com/brianlsy98/DICE.","authors":["Sungyoung Lee","Ziyi Wang","Seunggeun Kim","Taekyun Lee","Yao Lai","David Z. Pan"],"url":"https://arxiv.org/abs/2502.08949"}
{"created":"2025-05-20","title":"Can Vision-Language Models Infer Speaker's Ignorance? The Role of Visual and Linguistic Cues","abstract":"This study investigates whether vision-language models (VLMs) can perform pragmatic inference, focusing on ignorance implicatures, utterances that imply the speaker's lack of precise knowledge. To test this, we systematically manipulated contextual cues: the visually depicted situation (visual cue) and QUD-based linguistic prompts (linguistic cue). When only visual cues were provided, three state-of-the-art VLMs (GPT-4o, Gemini 1.5 Pro, and Claude 3.5 sonnet) produced interpretations largely based on the lexical meaning of the modified numerals. When linguistic cues were added to enhance contextual informativeness, Claude exhibited more human-like inference by integrating both types of contextual cues. In contrast, GPT and Gemini favored precise, literal interpretations. Although the influence of contextual cues increased, they treated each contextual cue independently and aligned them with semantic features rather than engaging in context-driven reasoning. These findings suggest that although the models differ in how they handle contextual cues, Claude's ability to combine multiple cues may signal emerging pragmatic competence in multimodal models.","authors":["Ye-eun Cho","Yunho Maeng"],"url":"https://arxiv.org/abs/2502.09120"}
{"created":"2025-05-20","title":"Exploring the Potential of Encoder-free Architectures in 3D LMMs","abstract":"Encoder-free architectures have been preliminarily explored in the 2D visual domain, yet it remains an open question whether they can be effectively applied to 3D understanding scenarios. In this paper, we present the first comprehensive investigation into the potential of encoder-free architectures to alleviate the challenges of encoder-based 3D Large Multimodal Models (LMMs). These challenges include the failure to adapt to varying point cloud resolutions and the point features from the encoder not meeting the semantic needs of Large Language Models (LLMs). We identify key aspects for 3D LMMs to remove the encoder and enable the LLM to assume the role of the 3D encoder: 1) We propose the LLM-embedded Semantic Encoding strategy in the pre-training stage, exploring the effects of various point cloud self-supervised losses. And we present the Hybrid Semantic Loss to extract high-level semantics. 2) We introduce the Hierarchical Geometry Aggregation strategy in the instruction tuning stage. This incorporates inductive bias into the LLM layers to focus on the local details of the point clouds. To the end, we present the first Encoder-free 3D LMM, ENEL. Our 7B model rivals the current state-of-the-art model, ShapeLLM-13B, achieving 55.10%, 50.98%, and 43.10% on the classification, captioning, and VQA tasks, respectively. Our results demonstrate that the encoder-free architecture is highly promising for replacing encoder-based architectures in the field of 3D understanding. The code is released at https://github.com/Ivan-Tang-3D/ENEL","authors":["Yiwen Tang","Zoey Guo","Zhuhao Wang","Ray Zhang","Qizhi Chen","Junli Liu","Delin Qu","Zhigang Wang","Dong Wang","Xuelong Li","Bin Zhao"],"url":"https://arxiv.org/abs/2502.09620"}
{"created":"2025-05-20","title":"Exploring Neural Granger Causality with xLSTMs: Unveiling Temporal Dependencies in Complex Data","abstract":"Causality in time series can be difficult to determine, especially in the presence of non-linear dependencies. The concept of Granger causality helps analyze potential relationships between variables, thereby offering a method to determine whether one time series can predict - Granger cause - future values of another. Although successful, Granger causal methods still struggle with capturing long-range relations between variables. To this end, we leverage the recently successful Extended Long Short-Term Memory (xLSTM) architecture and propose Granger causal xLSTMs (GC-xLSTM). It first enforces sparsity between the time series components by using a novel dynamic loss penalty on the initial projection. Specifically, we adaptively improve the model and identify sparsity candidates. Our joint optimization procedure then ensures that the Granger causal relations are recovered robustly. Our experimental evaluation on six diverse datasets demonstrates the overall efficacy of our proposed GC-xLSTM model.","authors":["Harsh Poonia","Felix Divo","Kristian Kersting","Devendra Singh Dhami"],"url":"https://arxiv.org/abs/2502.09981"}
{"created":"2025-05-20","title":"CLaMP 3: Universal Music Information Retrieval Across Unaligned Modalities and Unseen Languages","abstract":"CLaMP 3 is a unified framework developed to address challenges of cross-modal and cross-lingual generalization in music information retrieval. Using contrastive learning, it aligns all major music modalities--including sheet music, performance signals, and audio recordings--with multilingual text in a shared representation space, enabling retrieval across unaligned modalities with text as a bridge. It features a multilingual text encoder adaptable to unseen languages, exhibiting strong cross-lingual generalization. Leveraging retrieval-augmented generation, we curated M4-RAG, a web-scale dataset consisting of 2.31 million music-text pairs. This dataset is enriched with detailed metadata that represents a wide array of global musical traditions. To advance future research, we release WikiMT-X, a benchmark comprising 1,000 triplets of sheet music, audio, and richly varied text descriptions. Experiments show that CLaMP 3 achieves state-of-the-art performance on multiple MIR tasks, significantly surpassing previous strong baselines and demonstrating excellent generalization in multimodal and multilingual music contexts.","authors":["Shangda Wu","Zhancheng Guo","Ruibin Yuan","Junyan Jiang","Seungheon Doh","Gus Xia","Juhan Nam","Xiaobing Li","Feng Yu","Maosong Sun"],"url":"https://arxiv.org/abs/2502.10362"}
{"created":"2025-05-20","title":"RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation","abstract":"Large language models (LLMs) have achieved impressive performance on knowledge-intensive tasks, yet they often struggle with multi-step reasoning due to the unstructured nature of retrieved context. While retrieval-augmented generation (RAG) methods provide external information, the lack of explicit organization among retrieved passages limits their effectiveness, leading to brittle reasoning pathways. Recent interpretability studies highlighting the importance of structured intermediate reasoning further align with this perspective. We propose Retrieval-And-Structuring (RAS), a framework that dynamically constructs query-specific knowledge graphs through iterative retrieval and structured knowledge building. RAS interleaves targeted retrieval planning with incremental graph construction, enabling models to assemble and reason over evolving knowledge structures tailored to each query. On seven knowledge-intensive benchmarks, RAS consistently outperforms strong baselines, achieving up to 6.4% and 7.0% gains with open-source and proprietary LLMs, respectively. Our results demonstrate that dynamic, query-specific knowledge structuring offers a robust path to improving reasoning accuracy and robustness in language model generation. Our data and code can be found at https://github.com/pat-jj/RAS.","authors":["Pengcheng Jiang","Lang Cao","Ruike Zhu","Minhao Jiang","Yunyi Zhang","Jimeng Sun","Jiawei Han"],"url":"https://arxiv.org/abs/2502.10996"}
{"created":"2025-05-20","title":"Collaborative Deterministic-Probabilistic Forecasting for Real-World Spatiotemporal Systems","abstract":"Probabilistic forecasting is crucial for real-world spatiotemporal systems, such as climate, energy, and urban environments, where quantifying uncertainty is essential for informed, risk-aware decision-making. While diffusion models have shown promise in capturing complex data distributions, their application to spatiotemporal forecasting remains limited due to complex spatiotemporal dynamics and high computational demands. In this work, we propose CoST, a novel framework that collaborates deterministic and diffusion models for spatiotemporal forecasting. CoST formulates a mean-residual decomposition strategy: it leverages a powerful deterministic model to capture the conditional mean and a lightweight diffusion model to learn residual uncertainties. This collaborative formulation simplifies learning objectives, enhances forecasting accuracy, enables uncertainty quantification, and significantly improves computational efficiency. To address spatial heterogeneity, we further design a scale-aware diffusion mechanism to guide the diffusion process. Extensive experiments across ten real-world datasets from climate, energy, communication, and urban systems show that CoST achieves 25% performance gains over state-of-the-art baselines, while significantly reducing computational cost.","authors":["Zhi Sheng","Yuan Yuan","Yudi Zhang","Depeng Jin","Yong Li"],"url":"https://arxiv.org/abs/2502.11013"}
{"created":"2025-05-20","title":"Beyond Pairwise: Global Zero-shot Temporal Graph Generation","abstract":"Temporal relation extraction (TRE) is a fundamental task in natural language processing (NLP) that involves identifying the temporal relationships between events in a document. Despite the advances in large language models (LLMs), their application to TRE remains limited. Most existing approaches rely on pairwise classification, where event pairs are classified in isolation, leading to computational inefficiency and a lack of global consistency in the resulting temporal graph. In this work, we propose a novel zero-shot method for TRE that generates a document's complete temporal graph in a single step, followed by temporal constraint optimization to refine predictions and enforce temporal consistency across relations. Additionally, we introduce OmniTemp, a new dataset with complete annotations for all pairs of targeted events within a document. Through experiments and analyses, we demonstrate that our method outperforms existing zero-shot approaches and offers a competitive alternative to supervised TRE models.","authors":["Alon Eirew","Kfir Bar","Ido Dagan"],"url":"https://arxiv.org/abs/2502.11114"}
{"created":"2025-05-20","title":"Eye Tracking Based Cognitive Evaluation of Automatic Readability Assessment Measures","abstract":"Automated text readability prediction is widely used in many real-world scenarios. Over the past century, such measures have primarily been developed and evaluated on reading comprehension outcomes and on human annotations of text readability levels. In this work, we propose an alternative, eye tracking-based cognitive framework which directly taps into a key aspect of readability: reading ease. We use this framework for evaluating a broad range of prominent readability measures, including two systems widely used in education, by quantifying their ability to account for reading facilitation effects in text simplification, as well as text reading ease more broadly. Our analyses suggest that existing readability measures are poor predictors of reading facilitation and reading ease, outperformed by word properties commonly used in psycholinguistics, and in particular by surprisal.","authors":["Keren Gruteke Klein","Shachar Frenkel","Omer Shubi","Yevgeni Berzak"],"url":"https://arxiv.org/abs/2502.11150"}
{"created":"2025-05-20","title":"The Mirage of Model Editing: Revisiting Evaluation in the Wild","abstract":"Despite near-perfect results in artificial evaluations, the effectiveness of model editing in real-world applications remains unexplored. To bridge this gap, we propose to study model editing in question answering (QA) by establishing a rigorous evaluation practice to assess the effectiveness of editing methods in correcting LLMs' errors. It consists of QAEdit, a new benchmark derived from popular QA datasets, and a standardized evaluation framework. Our single editing experiments indicate that current editing methods perform substantially worse than previously reported (38.5% vs. ~96%). Through module analysis and controlled experiments, we demonstrate that this performance decline stems from issues in evaluation practices of prior editing research. One key issue is the inappropriate use of teacher forcing in testing prevents error propagation by feeding ground truth tokens (inaccessible in real-world scenarios) as input. Furthermore, we simulate real-world deployment by sequential editing, revealing that current approaches fail drastically with only 1000 edits. Our analysis provides a fundamental reexamination of both the real-world applicability of existing model editing methods and their evaluation practices, and establishes a rigorous evaluation framework with key insights to advance reliable and practical model editing research.","authors":["Wanli Yang","Fei Sun","Jiajun Tan","Xinyu Ma","Qi Cao","Dawei Yin","Huawei Shen","Xueqi Cheng"],"url":"https://arxiv.org/abs/2502.11177"}
{"created":"2025-05-20","title":"From the New World of Word Embeddings: A Comparative Study of Small-World Lexico-Semantic Networks in LLMs","abstract":"Lexico-semantic networks represent words as nodes and their semantic relatedness as edges. While such networks are traditionally constructed using embeddings from encoder-based models or static vectors, embeddings from decoder-only large language models (LLMs) remain underexplored. Unlike encoder models, LLMs are trained with a next-token prediction objective, which does not directly encode the meaning of the current token. In this paper, we construct lexico-semantic networks from the input embeddings of LLMs with varying parameter scales and conduct a comparative analysis of their global and local structures. Our results show that these networks exhibit small-world properties, characterized by high clustering and short path lengths. Moreover, larger LLMs yield more intricate networks with less small-world effects and longer paths, reflecting richer semantic structures and relations. We further validate our approach through analyses of common conceptual pairs, structured lexical relations derived from WordNet, and a cross-lingual semantic network for qualitative words.","authors":["Zhu Liu","Ying Liu","KangYang Luo","Cunliang Kong","Maosong Sun"],"url":"https://arxiv.org/abs/2502.11380"}
{"created":"2025-05-20","title":"Beyond Single-Task: Robust Multi-Task Length Generalization for LLMs","abstract":"Length generalization, the ability to solve problems longer than those seen during training, remains a critical challenge for large language models (LLMs). Previous work modifies positional encodings (PEs) and data formats to improve length generalization on specific symbolic tasks such as addition and sorting. However, these approaches are fundamentally limited to special tasks, often degrading general language performance. Furthermore, they are typically evaluated on small transformers trained from scratch on single tasks and can cause performance drop when applied during post-training stage of practical LLMs with general capabilities. Hu et al., (2024) proposed Rule-Following Fine-Tuning (RFFT) to improve length generalization in the post-training stage of LLMs. Despite its compatibility with practical models and strong performance, RFFT is proposed for single tasks too, requiring re-training for each individual task with extensive examples. In this paper, we study length generalization in multi-task settings and propose Meta Rule-Following Fine-Tuning (Meta-RFFT), the first framework enabling robust cross-task length generalization. As our first contribution, we construct a large length generalization dataset containing 86 tasks spanning code execution, number processing, symbolic and logical reasoning tasks, beyond the common addition or multiplication tasks. Secondly, we show that cross-task length generalization is possible with Meta-RFFT. After training on a large number of tasks and instances, the models achieve remarkable length generalization ability on unseen tasks with minimal fine-tuning or one-shot prompting. For example, after fine-tuning on 1 to 5 digit addition, our 32B model achieves 95% accuracy on 30 digit addition, significantly outperforming the state-of-the-art reasoning models (DeepSeek-R1-671B: 72%), despite never seeing this task during RF-pretraining.","authors":["Yi Hu","Shijia Kang","Haotong Yang","Haotian Xu","Muhan Zhang"],"url":"https://arxiv.org/abs/2502.11525"}
{"created":"2025-05-20","title":"FaMTEB: Massive Text Embedding Benchmark in Persian Language","abstract":"In this paper, we introduce a comprehensive benchmark for Persian (Farsi) text embeddings, built upon the Massive Text Embedding Benchmark (MTEB). Our benchmark includes 63 datasets spanning seven different tasks: classification, clustering, pair classification, reranking, retrieval, summary retrieval, and semantic textual similarity. The datasets are formed as a combination of existing, translated, and newly generated data, offering a diverse evaluation framework for Persian language models. Given the increasing use of text embedding models in chatbots, evaluation datasets are becoming inseparable ingredients in chatbot challenges and Retrieval-Augmented Generation systems. As a contribution, we include chatbot evaluation datasets in the MTEB benchmark for the first time. In addition, in this paper, we introduce the new task of summary retrieval which is not part of the tasks included in standard MTEB. Another contribution of this paper is the introduction of a substantial number of new Persian language NLP datasets suitable for training and evaluation, some of which have no previous counterparts in Persian. We evaluate the performance of several Persian and multilingual embedding models in a range of tasks. This work introduces an open-source benchmark with datasets, code and a public leaderboard.","authors":["Erfan Zinvandi","Morteza Alikhani","Mehran Sarmadi","Zahra Pourbahman","Sepehr Arvin","Reza Kazemi","Arash Amini"],"url":"https://arxiv.org/abs/2502.11571"}
{"created":"2025-05-20","title":"Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning","abstract":"Despite the remarkable capabilities of large language models (LLMs) in various reasoning tasks, they still struggle with table reasoning tasks, particularly in maintaining consistency throughout multi-step reasoning processes. While existing approaches have explored various decomposition strategies, they often lack effective mechanisms to identify and correct errors in intermediate reasoning steps, leading to cascading error propagation. To address these issues, we propose Table-Critic, a novel multi-agent framework that facilitates collaborative criticism and iterative refinement of the reasoning process until convergence to correct solutions. Our framework consists of four specialized agents: a Judge for error identification, a Critic for comprehensive critiques, a Refiner for process improvement, and a Curator for pattern distillation. To effectively deal with diverse and unpredictable error types, we introduce a self-evolving template tree that systematically accumulates critique knowledge through experience-driven learning and guides future reflections. Extensive experiments have demonstrated that Table-Critic achieves substantial improvements over existing methods, achieving superior accuracy and error correction rates while maintaining computational efficiency and lower solution degradation rate.","authors":["Peiying Yu","Guoxin Chen","Jingjing Wang"],"url":"https://arxiv.org/abs/2502.11799"}
{"created":"2025-05-20","title":"To Think or Not to Think: Exploring the Unthinking Vulnerability in Large Reasoning Models","abstract":"Large Reasoning Models (LRMs) are designed to solve complex tasks by generating explicit reasoning traces before producing final answers. However, we reveal a critical vulnerability in LRMs -- termed Unthinking Vulnerability -- wherein the thinking process can be bypassed by manipulating special delimiter tokens. It is empirically demonstrated to be widespread across mainstream LRMs, posing both a significant risk and potential utility, depending on how it is exploited. In this paper, we systematically investigate this vulnerability from both malicious and beneficial perspectives. On the malicious side, we introduce Breaking of Thought (BoT), a novel attack that enables adversaries to bypass the thinking process of LRMs, thereby compromising their reliability and availability. We present two variants of BoT: a training-based version that injects backdoor during the fine-tuning stage, and a training-free version based on adversarial attack during the inference stage. As a potential defense, we propose thinking recovery alignment to partially mitigate the vulnerability. On the beneficial side, we introduce Monitoring of Thought (MoT), a plug-and-play framework that allows model owners to enhance efficiency and safety. It is implemented by leveraging the same vulnerability to dynamically terminate redundant or risky reasoning through external monitoring. Extensive experiments show that BoT poses a significant threat to reasoning reliability, while MoT provides a practical solution for preventing overthinking and jailbreaking. Our findings expose an inherent flaw in current LRM architectures and underscore the need for more robust reasoning systems in the future.","authors":["Zihao Zhu","Hongbao Zhang","Ruotong Wang","Ke Xu","Siwei Lyu","Baoyuan Wu"],"url":"https://arxiv.org/abs/2502.12202"}
{"created":"2025-05-20","title":"SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models","abstract":"Deploying large language models (LLMs) in real-world applications requires robust safety guard models to detect and block harmful user prompts. While large safety guard models achieve strong performance, their computational cost is substantial. To mitigate this, smaller distilled models are used, but they often underperform on \"hard\" examples where the larger model provides accurate predictions. We observe that many inputs can be reliably handled by the smaller model, while only a small fraction require the larger model's capacity. Motivated by this, we propose SafeRoute, a binary router that distinguishes hard examples from easy ones. Our method selectively applies the larger safety guard model to the data that the router considers hard, improving efficiency while maintaining accuracy compared to solely using the larger safety guard model. Experimental results on multiple benchmark datasets demonstrate that our adaptive model selection significantly enhances the trade-off between computational cost and safety performance, outperforming relevant baselines.","authors":["Seanie Lee","Dong Bok Lee","Dominik Wagner","Minki Kang","Haebin Seong","Tobias Bocklet","Juho Lee","Sung Ju Hwang"],"url":"https://arxiv.org/abs/2502.12464"}
{"created":"2025-05-20","title":"VidCapBench: A Comprehensive Benchmark of Video Captioning for Controllable Text-to-Video Generation","abstract":"The training of controllable text-to-video (T2V) models relies heavily on the alignment between videos and captions, yet little existing research connects video caption evaluation with T2V generation assessment. This paper introduces VidCapBench, a video caption evaluation scheme specifically designed for T2V generation, agnostic to any particular caption format. VidCapBench employs a data annotation pipeline, combining expert model labeling and human refinement, to associate each collected video with key information spanning video aesthetics, content, motion, and physical laws. VidCapBench then partitions these key information attributes into automatically assessable and manually assessable subsets, catering to both the rapid evaluation needs of agile development and the accuracy requirements of thorough validation. By evaluating numerous state-of-the-art captioning models, we demonstrate the superior stability and comprehensiveness of VidCapBench compared to existing video captioning evaluation approaches. Verification with off-the-shelf T2V models reveals a significant positive correlation between scores on VidCapBench and the T2V quality evaluation metrics, indicating that VidCapBench can provide valuable guidance for training T2V models. The project is available at https://github.com/VidCapBench/VidCapBench.","authors":["Xinlong Chen","Yuanxing Zhang","Chongling Rao","Yushuo Guan","Jiaheng Liu","Fuzheng Zhang","Chengru Song","Qiang Liu","Di Zhang","Tieniu Tan"],"url":"https://arxiv.org/abs/2502.12782"}
{"created":"2025-05-20","title":"Performance of Zero-Shot Time Series Foundation Models on Cloud Data","abstract":"Time series foundation models (FMs) have emerged as a popular paradigm for zero-shot multi-domain forecasting. FMs are trained on numerous diverse datasets and claim to be effective forecasters across multiple different time series domains, including cloud data. In this work we investigate this claim, exploring the effectiveness of FMs on cloud data. We demonstrate that many well-known FMs fail to generate meaningful or accurate zero-shot forecasts in this setting. We support this claim empirically, showing that FMs are outperformed consistently by simple linear baselines. We also illustrate a number of interesting pathologies, including instances where FMs suddenly output seemingly erratic, random-looking forecasts. Our results suggest a widespread failure of FMs to model cloud data.","authors":["William Toner","Thomas L. Lee","Artjom Joosen","Rajkarn Singh","Martin Asenov"],"url":"https://arxiv.org/abs/2502.12944"}
{"created":"2025-05-20","title":"Feature Learning Beyond the Edge of Stability","abstract":"We propose a homogeneous multilayer perceptron parameterization with polynomial hidden layer width pattern and analyze its training dynamics under stochastic gradient descent with depthwise gradient scaling in a general supervised learning scenario. We obtain formulas for the first three Taylor coefficients of the minibatch loss during training that illuminate the connection between sharpness and feature learning, providing in particular a soft rank variant that quantifies the quality of learned hidden layer features. Based on our theory, we design a gradient scaling scheme that in tandem with a quadratic width pattern enables training beyond the edge of stability without loss explosions or numerical errors, resulting in improved feature learning and implicit sharpness regularization as demonstrated empirically.","authors":["D\\'avid Terj\\'ek"],"url":"https://arxiv.org/abs/2502.13110"}
{"created":"2025-05-20","title":"Pre-training Auto-regressive Robotic Models with 4D Representations","abstract":"Foundation models pre-trained on massive unlabeled datasets have revolutionized natural language and computer vision, exhibiting remarkable generalization capabilities, thus highlighting the importance of pre-training. Yet, efforts in robotics have struggled to achieve similar success, limited by either the need for costly robotic annotations or the lack of representations that effectively model the physical world. In this paper, we introduce ARM4R, an Auto-regressive Robotic Model that leverages low-level 4D Representations learned from human video data to yield a better pre-trained robotic model. Specifically, we focus on utilizing 3D point tracking representations from videos derived by lifting 2D representations into 3D space via monocular depth estimation across time. These 4D representations maintain a shared geometric structure between the points and robot state representations up to a linear transformation, enabling efficient transfer learning from human video data to low-level robotic control. Our experiments show that ARM4R can transfer efficiently from human video data to robotics and consistently improves performance on tasks across various robot environments and configurations.","authors":["Dantong Niu","Yuvan Sharma","Haoru Xue","Giscard Biamby","Junyi Zhang","Ziteng Ji","Trevor Darrell","Roei Herzig"],"url":"https://arxiv.org/abs/2502.13142"}
{"created":"2025-05-20","title":"KL Penalty Control via Perturbation for Direct Preference Optimization","abstract":"Direct Preference Optimization (DPO) demonstrates the advantage of aligning a large language model with human preference using only an offline dataset. However, DPO has the limitation that the KL penalty, which prevents excessive deviation from the reference model, is static throughout the training process. Several methods claim to change this static KL penalty of DPO into a dynamic one, but no approach can adaptively assign different KL penalties for each preference pair. In this paper, we propose $\\varepsilon$-Direct Preference Optimization ($\\varepsilon$-DPO), which allows adaptive control of the KL penalty strength $\\beta$ for each preference pair. Specifically, $\\varepsilon$-DPO adaptively controls $\\beta$ for each preference pair based on the monotonicity of logits as a preference model under the perturbation of $\\beta$ during training. This is equivalent to adjusting the KL penalty by checking whether the change in training-time temperature can lead to better preference confidence as preference models by simply reusing the logit of the current policy and the reference policy. Experimental results show that the simple criterion of $\\varepsilon$-DPO for KL penalty relaxation significantly improves DPO compared to most existing direct alignment algorithms on general chatbot benchmarks and reveal that this KL penalty control criterion can reflect confusion as a preference model and provide an efficient KL trade-off, highlighting the significance of instance-level adaptive KL penalty control in DPO.","authors":["Sangkyu Lee","Janghoon Han","Hosung Song","Stanley Jungkyu Choi","Honglak Lee","Youngjae Yu"],"url":"https://arxiv.org/abs/2502.13177"}
{"created":"2025-05-20","title":"Random Forest Autoencoders for Guided Representation Learning","abstract":"Extensive research has produced robust methods for unsupervised data visualization. Yet supervised visualization$\\unicode{x2013}$where expert labels guide representations$\\unicode{x2013}$remains underexplored, as most supervised approaches prioritize classification over visualization. Recently, RF-PHATE, a diffusion-based manifold learning method leveraging random forests and information geometry, marked significant progress in supervised visualization. However, its lack of an explicit mapping function limits scalability and its application to unseen data, posing challenges for large datasets and label-scarce scenarios. To overcome these limitations, we introduce Random Forest Autoencoders (RF-AE), a neural network-based framework for out-of-sample kernel extension that combines the flexibility of autoencoders with the supervised learning strengths of random forests and the geometry captured by RF-PHATE. RF-AE enables efficient out-of-sample supervised visualization and outperforms existing methods, including RF-PHATE's standard kernel extension, in both accuracy and interpretability. Additionally, RF-AE is robust to the choice of hyperparameters and generalizes to any kernel-based dimensionality reduction method.","authors":["Adrien Aumon","Shuang Ni","Myriam Lizotte","Guy Wolf","Kevin R. Moon","Jake S. Rhodes"],"url":"https://arxiv.org/abs/2502.13257"}
{"created":"2025-05-20","title":"MoVer: Motion Verification for Motion Graphics Animations","abstract":"While large vision-language models can generate motion graphics animations from text prompts, they regularly fail to include all spatio-temporal properties described in the prompt. We introduce MoVer, a motion verification DSL based on first-order logic that can check spatio-temporal properties of a motion graphics animation. We identify a general set of such properties that people commonly use to describe animations (e.g., the direction and timing of motions, the relative positioning of objects, etc.). We implement these properties as predicates in MoVer and provide an execution engine that can apply a MoVer program to any input SVG-based motion graphics animation. We then demonstrate how MoVer can be used in an LLM-based synthesis and verification pipeline for iteratively refining motion graphics animations. Given a text prompt, our pipeline synthesizes a motion graphics animation and a corresponding MoVer program. Executing the verification program on the animation yields a report of the predicates that failed and the report can be automatically fed back to LLM to iteratively correct the animation. To evaluate our pipeline, we build a synthetic dataset of 5600 text prompts paired with ground truth MoVer verification programs. We find that while our LLM-based pipeline is able to automatically generate a correct motion graphics animation for 58.8% of the test prompts without any iteration, this number raises to 93.6% with up to 50 correction iterations. Our code and dataset are at https://mover-dsl.github.io.","authors":["Jiaju Ma","Maneesh Agrawala"],"url":"https://arxiv.org/abs/2502.13372"}
{"created":"2025-05-20","title":"JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework","abstract":"Change detection (CD) in remote sensing images plays a vital role in Earth observation. However, the scarcity of high-resolution, comprehensive open-source datasets and the difficulty in achieving robust performance across varying change types remain major challenges. To address these issues, we introduce JL1-CD, a large-scale, sub-meter CD dataset consisting of 5,000 image pairs. We further propose a novel Origin-Partition (O-P) strategy and integrate it into a Multi-Teacher Knowledge Distillation (MTKD) framework to enhance CD performance. The O-P strategy partitions the training set by Change Area Ratio (CAR) and trains specialized teacher models on each subset. The MTKD framework then distills complementary knowledge from these teachers into a single student model, enabling improved detection results across diverse CAR scenarios without additional inference cost. Our MTKD approach demonstrated strong performance in the 2024 \"Jilin-1'' Cup challenge, ranking first in the preliminary and second in the final rounds. Extensive experiments on the JL1-CD and SYSU-CD datasets show that the MTKD framework consistently improves the performance of CD models with various network architectures and parameter sizes, establishing new state-of-the-art results. Code and dataset are available at https://anonymous.4open.science/r/MTKD-A-84B8.","authors":["Ziyuan Liu","Ruifei Zhu","Long Gao","Yuanxiu Zhou","Jingyu Ma","Yuantao Gu"],"url":"https://arxiv.org/abs/2502.13407"}
{"created":"2025-05-20","title":"Is This Collection Worth My LLM's Time? Automatically Measuring Information Potential in Text Corpora","abstract":"As large language models (LLMs) converge towards similar capabilities, the key to advancing their performance lies in identifying and incorporating valuable new information sources. However, evaluating which text collections are worth the substantial investment required for digitization, preprocessing, and integration into LLM systems remains a significant challenge. We present a novel approach to this challenge: an automated pipeline that evaluates the potential information gain from text collections without requiring model training or fine-tuning. Our method generates multiple choice questions (MCQs) from texts and measures an LLM's performance both with and without access to the source material. The performance gap between these conditions serves as a proxy for the collection's information potential. We validate our approach using five strategically selected datasets: EPFL PhD manuscripts, a private collection of Venetian historical records, two sets of Wikipedia articles on related topics, and a synthetic baseline dataset. Our results demonstrate that this method effectively identifies collections containing valuable novel information, providing a practical tool for prioritizing data acquisition and integration efforts.","authors":["Tristan Karch","Luca Engel","Philippe Schwaller","Fr\\'ed\\'eric Kaplan"],"url":"https://arxiv.org/abs/2502.13691"}
{"created":"2025-05-20","title":"Vulnerability of Text-to-Image Models to Prompt Template Stealing: A Differential Evolution Approach","abstract":"Prompt trading has emerged as a significant intellectual property concern in recent years, where vendors entice users by showcasing sample images before selling prompt templates that can generate similar images. This work investigates a critical security vulnerability: attackers can steal prompt templates using only a limited number of sample images. To investigate this threat, we introduce Prism, a prompt-stealing benchmark consisting of 50 templates and 450 images, organized into Easy and Hard difficulty levels. To identify the vulnerabity of VLMs to prompt stealing, we propose EvoStealer, a novel template stealing method that operates without model fine-tuning by leveraging differential evolution algorithms. The system first initializes population sets using multimodal large language models (MLLMs) based on predefined patterns, then iteratively generates enhanced offspring through MLLMs. During evolution, EvoStealer identifies common features across offspring to derive generalized templates. Our comprehensive evaluation conducted across open-source (INTERNVL2-26B) and closed-source models (GPT-4o and GPT-4o-mini) demonstrates that EvoStealer's stolen templates can reproduce images highly similar to originals and effectively generalize to other subjects, significantly outperforming baseline methods with an average improvement of over 10%. Moreover, our cost analysis reveals that EvoStealer achieves template stealing with negligible computational expenses. Our code and dataset are available at https://github.com/whitepagewu/evostealer.","authors":["Yurong Wu","Fangwen Mu","Qiuhong Zhang","Jinjing Zhao","Xinrun Xu","Lingrui Mei","Yang Wu","Lin Shi","Junjie Wang","Zhiming Ding","Yiwei Wang"],"url":"https://arxiv.org/abs/2502.14285"}
{"created":"2025-05-20","title":"Integrating Extra Modality Helps Segmentor Find Camouflaged Objects Well","abstract":"Camouflaged Object Segmentation (COS) remains challenging because camouflaged objects exhibit only subtle visual differences from their backgrounds and single-modality RGB methods provide limited cues, leading researchers to explore multimodal data to improve segmentation accuracy. In this work, we presenet MultiCOS, a novel framework that effectively leverages diverse data modalities to improve segmentation performance. MultiCOS comprises two modules: Bi-space Fusion Segmentor (BFSer), which employs a state space and a latent space fusion mechanism to integrate cross-modal features within a shared representation and employs a fusion-feedback mechanism to refine context-specific features, and Cross-modal Knowledge Learner (CKLer), which leverages external multimodal datasets to generate pseudo-modal inputs and establish cross-modal semantic associations, transferring knowledge to COS models when real multimodal pairs are missing. When real multimodal COS data are unavailable, CKLer yields additional segmentation gains using only non-COS multimodal sources. Experiments on standard COS benchmarks show that BFSer outperforms existing multimodal baselines with both real and pseudo-modal data. Code will be released at \\href{https://github.com/cnyvfang/MultiCOS}{GitHub}.","authors":["Chengyu Fang","Chunming He","Longxiang Tang","Yuelin Zhang","Chenyang Zhu","Yuqi Shen","Chubin Chen","Guoxia Xu","Xiu Li"],"url":"https://arxiv.org/abs/2502.14471"}
{"created":"2025-05-20","title":"Ranking Joint Policies in Dynamic Games using Evolutionary Dynamics","abstract":"Game-theoretic solution concepts, such as the Nash equilibrium, have been key to finding stable joint actions in multi-player games. However, it has been shown that the dynamics of agents' interactions, even in simple two-player games with few strategies, are incapable of reaching Nash equilibria, exhibiting complex and unpredictable behavior. Instead, evolutionary approaches can describe the long-term persistence of strategies and filter out transient ones, accounting for the long-term dynamics of agents' interactions. Our goal is to identify agents' joint strategies that result in stable behavior, being resistant to changes, while also accounting for agents' payoffs, in dynamic games. Towards this goal, and building on previous results, this paper proposes transforming dynamic games into their empirical forms by considering agents' strategies instead of agents' actions, and applying the evolutionary methodology $\\alpha$-Rank to evaluate and rank strategy profiles according to their long-term dynamics. This methodology not only allows us to identify joint strategies that are strong through agents' long-term interactions, but also provides a descriptive, transparent framework regarding the high ranking of these strategies. Experiments report on agents that aim to collaboratively solve a stochastic version of the graph coloring problem. We consider different styles of play as strategies to define the empirical game, and train policies realizing these strategies, using the DQN algorithm. Then we run simulations to generate the payoff matrix required by $\\alpha$-Rank to rank joint strategies.","authors":["Natalia Koliou","George Vouros"],"url":"https://arxiv.org/abs/2502.14724"}
{"created":"2025-05-20","title":"Multi-Faceted Multimodal Monosemanticity","abstract":"Humans experience the world through multiple modalities, such as, vision, language, and speech, making it natural to explore the commonality and distinctions among them. In this work, we take a data-driven approach to address this question by analyzing interpretable, monosemantic features extracted from deep multimodal models. Specifically, we investigate CLIP, a prominent visual-language representation model trained on massive image-text pairs. Building on prior research in single-modal interpretability, we develop a set of multi-modal interpretability tools and measures designed to disentangle and analyze features learned from CLIP. Specifically, we introduce the Modality Dominance Score (MDS) to attribute each CLIP feature to a specific modality. We then map CLIP features into a more interpretable space, enabling us to categorize them into three distinct classes: vision features (single-modal), language features (single-modal), and visual-language features (cross-modal). Interestingly, this data-driven categorization closely aligns with human intuitive understandings of different modalities. We further show that this modality decomposition can benefit multiple downstream tasks, including reducing bias in gender detection, generating cross-modal adversarial examples, and enabling modal-specific feature control in text-to-image generation. These results indicate that large-scale multimodal models, when equipped with task-agnostic interpretability tools, can offer valuable insights into the relationships between different data modalities.","authors":["Hanqi Yan","Xiangxiang Cui","Lu Yin","Paul Pu Liang","Yulan He","Yifei Wang"],"url":"https://arxiv.org/abs/2502.14888"}
{"created":"2025-05-20","title":"ARS: Automatic Routing Solver with Large Language Models","abstract":"Real-world Vehicle Routing Problems (VRPs) are characterized by a variety of practical constraints, making manual solver design both knowledge-intensive and time-consuming. Although there is increasing interest in automating the design of routing algorithms, existing research has explored only a limited array of VRP variants and fails to adequately address the complex and prevalent constraints encountered in real-world situations. To fill this gap, this paper introduces RoutBench, a benchmark of 1,000 VRP variants derived from 24 attributes, for evaluating the effectiveness of automatic routing solvers in addressing complex constraints. Along with RoutBench, we present the Automatic Routing Solver (ARS), which employs Large Language Model (LLM) agents to enhance a backbone algorithm framework by automatically generating constraint-aware heuristic code, based on problem descriptions and several representative constraints selected from a database. Our experiments show that ARS outperforms state-of-the-art LLM-based methods and commonly used solvers, automatically solving 91.67% of common VRPs and achieving at least a 30% improvement across all benchmarks.","authors":["Kai Li","Fei Liu","Zhenkun Wang","Xialiang Tong","Xiongwei Han","Mingxuan Yuan","Qingfu Zhang"],"url":"https://arxiv.org/abs/2502.15359"}
{"created":"2025-05-20","title":"Machine-generated text detection prevents language model collapse","abstract":"As Large Language Models (LLMs) become increasingly prevalent, their generated outputs are proliferating across the web, risking a future where machine-generated content dilutes human-authored text. Since online data is the primary resource for LLM pre-training, subsequent models could be trained on an unknown portion of synthetic samples. This will lead to model collapse, a degenerative process whereby LLMs reinforce their own errors, converge to a low variance output distribution, and ultimately yield a declining performance. In this study, we investigate the impact of decoding strategy on model collapse, analysing the text characteristics at each model generation, the similarity to human references, and the resulting model performance. Using the decoding strategies that lead to the most significant degradation, we evaluate model collapse in more realistic scenarios where the origin of the data (human or synthetic) is unknown. We train a machine-generated text detector and propose an importance sampling approach to alleviate model collapse. Our method is validated on two LLM variants (GPT-2 and SmolLM2), across a range of model sizes (124M to 1.7B), on the open-ended text generation task. We demonstrate that it can not only prevent model collapse but also improve performance when sufficient human-authored samples are present. Source code: github.com/GeorgeDrayson/model_collapse.","authors":["George Drayson","Emine Yilmaz","Vasileios Lampos"],"url":"https://arxiv.org/abs/2502.15654"}
{"created":"2025-05-20","title":"FairKV: Balancing Per-Head KV Cache for Fast Multi-GPU Inference","abstract":"KV cache techniques in Transformer models aim to reduce redundant computations at the expense of substantially increased memory usage, making KV cache compression an important and popular research topic. Recently, state-of-the-art KV cache compression methods implement imbalanced, per-head allocation algorithms that dynamically adjust the KV cache budget for each attention head, achieving excellent performance in single-GPU scenarios. However, we observe that such imbalanced compression leads to significant load imbalance when deploying multi-GPU inference, as some GPUs become overburdened while others remain underutilized. In this paper, we propose FairKV, a method designed to ensure fair memory usage among attention heads in systems employing imbalanced KV cache compression. The core technique of FairKV is Fair-Copying, which replicates a small subset of memory-intensive attention heads across GPUs using data parallelism to mitigate load imbalance. Our experiments on popular models, including LLaMA 70b and Mistral 24b model, demonstrate that FairKV increases throughput by 1.66x compared to standard tensor parallelism inference. Our code will be released as open source upon acceptance.","authors":["Bingzhe Zhao","Ke Cheng","Aomufei Yuan","Yuxuan Tian","Ruiguang Zhong","Chengchen Hu","Tong Yang","Lian Yu"],"url":"https://arxiv.org/abs/2502.15804"}
{"created":"2025-05-20","title":"The Hidden Strength of Disagreement: Unraveling the Consensus-Diversity Tradeoff in Adaptive Multi-Agent Systems","abstract":"Consensus formation is pivotal in multi-agent systems (MAS), balancing collective coherence with individual diversity. Conventional LLM-based MAS primarily rely on explicit coordination, e.g., prompts or voting, risking premature homogenization. We argue that implicit consensus, where agents exchange information yet independently form decisions via in-context learning, can be more effective in dynamic environments that require long-horizon adaptability. By retaining partial diversity, systems can better explore novel strategies and cope with external shocks. We formalize a consensus-diversity tradeoff, showing conditions where implicit methods outperform explicit ones. Experiments on three scenarios -- Dynamic Disaster Response, Information Spread and Manipulation, and Dynamic Public-Goods Provision -- confirm partial deviation from group norms boosts exploration, robustness, and performance. We highlight emergent coordination via in-context learning, underscoring the value of preserving diversity for resilient decision-making.","authors":["Zengqing Wu","Takayuki Ito"],"url":"https://arxiv.org/abs/2502.16565"}
{"created":"2025-05-20","title":"Culture-TRIP: Culturally-Aware Text-to-Image Generation with Iterative Prompt Refinement","abstract":"Text-to-Image models, including Stable Diffusion, have significantly improved in generating images that are highly semantically aligned with the given prompts. However, existing models may fail to produce appropriate images for the cultural concepts or objects that are not well known or underrepresented in western cultures, such as `hangari' (Korean utensil). In this paper, we propose a novel approach, Culturally-Aware Text-to-Image Generation with Iterative Prompt Refinement (Culture-TRIP), which refines the prompt in order to improve the alignment of the image with such culture nouns in text-to-image models. Our approach (1) retrieves cultural contexts and visual details related to the culture nouns in the prompt and (2) iteratively refines and evaluates the prompt based on a set of cultural criteria and large language models. The refinement process utilizes the information retrieved from Wikipedia and the Web. Our user survey, conducted with 66 participants from eight different countries demonstrates that our proposed approach enhances the alignment between the images and the prompts. In particular, C-TRIP demonstrates improved alignment between the generated images and underrepresented culture nouns. Resource can be found at https://shane3606.github.io/Culture-TRIP.","authors":["Suchae Jeong","Inseong Choi","Youngsik Yun","Jihie Kim"],"url":"https://arxiv.org/abs/2502.16902"}
{"created":"2025-05-20","title":"Yes, Q-learning Helps Offline In-Context RL","abstract":"Existing offline in-context reinforcement learning (ICRL) methods have predominantly relied on supervised training objectives, which are known to have limitations in offline RL settings. In this study, we explore the integration of RL objectives within an offline ICRL framework. Through experiments on more than 150 GridWorld and MuJoCo environment-derived datasets, we demonstrate that optimizing RL objectives directly improves performance by approximately 30% on average compared to widely adopted Algorithm Distillation (AD), across various dataset coverages, structures, expertise levels, and environmental complexities. Furthermore, in the challenging XLand-MiniGrid environment, RL objectives doubled the performance of AD. Our results also reveal that the addition of conservatism during value learning brings additional improvements in almost all settings tested. Our findings emphasize the importance of aligning ICRL learning objectives with the RL reward-maximization goal, and demonstrate that offline RL is a promising direction for advancing ICRL.","authors":["Denis Tarasov","Alexander Nikulin","Ilya Zisman","Albina Klepach","Andrei Polubarov","Nikita Lyubaykin","Alexander Derevyagin","Igor Kiselev","Vladislav Kurenkov"],"url":"https://arxiv.org/abs/2502.17666"}
{"created":"2025-05-20","title":"Machine Learning-Based Prediction of ICU Mortality in Sepsis-Associated Acute Kidney Injury Patients Using MIMIC-IV Database with Validation from eICU Database","abstract":"Background: Sepsis-Associated Acute Kidney Injury (SA-AKI) leads to high mortality in intensive care. This study develops machine learning models using the Medical Information Mart for Intensive Care IV (MIMIC-IV) database to predict Intensive Care Unit (ICU) mortality in SA-AKI patients. External validation is conducted using the eICU Collaborative Research Database.","authors":["Shuheng Chen","Junyi Fan","Elham Pishgar","Kamiar Alaei","Greg Placencia","Maryam Pishgar"],"url":"https://arxiv.org/abs/2502.17978"}
{"created":"2025-05-20","title":"Can RLHF be More Efficient with Imperfect Reward Models? A Policy Coverage Perspective","abstract":"Sample efficiency is critical for online Reinforcement Learning from Human Feedback (RLHF). While existing works investigate sample-efficient online exploration strategies, the potential of utilizing misspecified yet relevant reward models to accelerate learning remains underexplored. This paper studies how to transfer knowledge from those imperfect reward models in online RLHF. We start by identifying a novel property due to KL-regularization in the RLHF objective: \\emph{a policy's coverability of the optimal policy is captured by its sub-optimality}. Building on this insight, we propose novel transfer learning principles and a theoretical algorithm -- \\emph{\\textbf{T}ransfer \\textbf{P}olicy \\textbf{O}ptimization (\\textbf{TPO})} -- with provable benefits compared to standard online learning. Empirically, inspired by our theoretical findings, we develop a win-rate-based transfer policy selection strategy with improved computational efficiency. Moreover, our empirical transfer learning technique is modular and can be integrated with various policy optimization methods, such as DPO, IPO and XPO, to further enhance their performance. We validate the effectiveness of our method through experiments on summarization tasks.","authors":["Jiawei Huang","Bingcong Li","Christoph Dann","Niao He"],"url":"https://arxiv.org/abs/2502.19255"}
{"created":"2025-05-20","title":"Efficient Reinforcement Learning by Guiding Generalist World Models with Non-Curated Data","abstract":"Leveraging offline data is a promising way to improve the sample efficiency of online reinforcement learning (RL). This paper expands the pool of usable data for offline-to-online RL by leveraging abundant non-curated data that is reward-free, of mixed quality, and collected across multiple embodiments. Although learning a world model appears promising for utilizing such data, we find that naive fine-tuning fails to accelerate RL training on many tasks. Through careful investigation, we attribute this failure to the distributional shift between offline and online data during fine-tuning. To address this issue and effectively use the offline data, we propose two essential techniques: \\emph{i)} experience rehearsal and \\emph{ii)} execution guidance. With these modifications, the non-curated offline data substantially improves RL's sample efficiency. Under limited sample budgets, our method achieves a 102.8\\% relative improvement in aggregate score over learning-from-scratch baselines across 72 visuomotor tasks spanning 6 embodiments. On challenging tasks such as locomotion and robotic manipulation, it outperforms prior methods that utilize offline data by a decent margin.","authors":["Yi Zhao","Aidan Scannell","Wenshuai Zhao","Yuxin Hou","Tianyu Cui","Le Chen","Dieter B\\\"uchler","Arno Solin","Juho Kannala","Joni Pajarinen"],"url":"https://arxiv.org/abs/2502.19544"}
{"created":"2025-05-20","title":"AutoBS: Autonomous Base Station Deployment with Reinforcement Learning and Digital Network Twins","abstract":"This paper introduces AutoBS, a reinforcement learning (RL)-based framework for optimal base station (BS) deployment in 6G radio access networks (RAN). AutoBS leverages the Proximal Policy Optimization (PPO) algorithm and fast, site-specific pathloss predictions from PMNet-a generative model for digital network twins (DNT). By efficiently learning deployment strategies that balance coverage and capacity, AutoBS achieves about 95% of the capacity of exhaustive search in single BS scenarios (and in 90% for multiple BSs), while cutting inference time from hours to milliseconds, making it highly suitable for real-time applications (e.g., ad-hoc deployments). AutoBS therefore provides a scalable, automated solution for large-scale 6G networks, meeting the demands of dynamic environments with minimal computational overhead.","authors":["Ju-Hyung Lee","Andreas F. Molisch"],"url":"https://arxiv.org/abs/2502.19647"}
{"created":"2025-05-20","title":"Exploiting Partial-Assignment Enumeration in Optimization Modulo Theories","abstract":"Optimization Modulo Theories (OMT) extends Satisfiability Modulo Theories (SMT) with the task of optimizing some objective function(s). In OMT solvers, a CDCL-based SMT solver enumerates theory-satisfiable total truth assignments, and a theory-specific procedure finds an optimum model for each of them; the current optimum is then used to tighten the search space for the next assignments, until no better solution is found.","authors":["Gabriele Masina","Roberto Sebastiani"],"url":"https://arxiv.org/abs/2502.19963"}
{"created":"2025-05-20","title":"Vision-Encoders (Already) Know What They See: Mitigating Object Hallucination via Simple Fine-Grained CLIPScore","abstract":"Recently, Large Vision-Language Models (LVLMs) show remarkable performance across various domains. However, these models suffer from object hallucination. This study revisits the previous claim that the primary cause of such hallucination lies in the limited representational capacity of the vision encoder. Our analysis reveals that the capacity of the vision encoder itself is already adequate for detecting object hallucination. Based on this insight, we propose a Fine-grained CLIPScore (F-CLIPScore), a simple yet effective evaluation metric that enhances object-level granularity by incorporating text embeddings at the noun level. Evaluations on the OHD-Caps benchmark show that F-CLIPScore significantly outperforms conventional CLIPScore in accuracy by a large margin of 39.6\\% without additional training. We further demonstrate that F-CLIPScore-based data filtering reduces object hallucination in LVLMs (4.9\\% in POPE).","authors":["Hongseok Oh","Wonseok Hwang"],"url":"https://arxiv.org/abs/2502.20034"}
{"created":"2025-05-20","title":"UniTok: A Unified Tokenizer for Visual Generation and Understanding","abstract":"Visual generative and understanding models typically rely on distinct tokenizers to process images, presenting a key challenge for unifying them within a single framework. Recent studies attempt to address this by connecting the training of VQVAE (for autoregressive generation) and CLIP (for understanding) to build a unified tokenizer. However, directly combining these training objectives has been observed to cause severe loss conflicts. In this paper, we show that reconstruction and semantic supervision do not inherently conflict. Instead, the underlying bottleneck stems from limited representational capacity of discrete token space. Building on these insights, we introduce UniTok, a unified tokenizer featuring a novel multi-codebook quantization mechanism that effectively scales up the vocabulary size and bottleneck dimension. In terms of final performance, UniTok sets a new record of 0.38 rFID and 78.6% zero-shot accuracy on ImageNet. Besides, UniTok can be seamlessly integrated into MLLMs to unlock native visual generation capability, without compromising the understanding performance. Additionally, we show that UniTok favors cfg-free generation, reducing gFID from 14.6 to 2.5 on ImageNet 256$\\times$256 benchmark. GitHub: https://github.com/FoundationVision/UniTok.","authors":["Chuofan Ma","Yi Jiang","Junfeng Wu","Jihan Yang","Xin Yu","Zehuan Yuan","Bingyue Peng","Xiaojuan Qi"],"url":"https://arxiv.org/abs/2502.20321"}
{"created":"2025-05-20","title":"DPZV: Elevating the Tradeoff between Privacy and Utility in Zeroth-Order Vertical Federated Learning","abstract":"Vertical Federated Learning (VFL) enables collaborative training with feature-partitioned data, yet remains vulnerable to privacy leakage through gradient transmissions. Standard differential privacy (DP) techniques such as DP-SGD are difficult to apply in this setting due to VFL's distributed nature and the high variance incurred by vector-valued noise. On the other hand, zeroth-order (ZO) optimization techniques can avoid explicit gradient exposure but lack formal privacy guarantees. In this work, we propose DPZV, the first ZO optimization framework for VFL that achieves tunable DP with performance guarantees. DPZV overcomes these limitations by injecting low-variance scalar noise at the server, enabling controllable privacy with reduced memory overhead. We conduct a comprehensive theoretical analysis showing that DPZV matches the convergence rate of first-order optimization methods while satisfying formal ($\\epsilon, \\delta$)-DP guarantees. Experiments on image and language benchmarks demonstrate that DPZV outperforms several baselines in terms of accuracy under a wide range of privacy constraints ($\\epsilon \\le 10$), thereby elevating the privacy-utility tradeoff in VFL.","authors":["Jianing Zhang","Evan Chen","Chaoyue Liu","Christopher G. Brinton"],"url":"https://arxiv.org/abs/2502.20565"}
{"created":"2025-05-20","title":"A Pilot Empirical Study on When and How to Use Knowledge Graphs as Retrieval Augmented Generation","abstract":"The integration of Knowledge Graphs (KGs) into the Retrieval Augmented Generation (RAG) framework has attracted significant interest, with early studies showing promise in mitigating hallucinations and improving model accuracy. However, a systematic understanding and comparative analysis of the rapidly emerging KG-RAG methods are still lacking. This paper seeks to lay the foundation for systematically answering the question of when and how to use KG-RAG by analyzing their performance in various application scenarios associated with different technical configurations. After outlining the mind map using KG-RAG framework and summarizing its popular pipeline, we conduct a pilot empirical study of KG-RAG works to reimplement and evaluate 6 KG-RAG methods across 9 datasets in diverse domains and scenarios, analyzing the impact of 9 KG-RAG configurations in combination with 17 LLMs, and combining Metacognition with KG-RAG as a pilot attempt. Our results underscore the critical role of appropriate application conditions and optimal configurations of KG-RAG components.","authors":["Xujie Yuan","Yongxu Liu","Shimin Di","Shiwen Wu","Libin Zheng","Rui Meng","Lei Chen","Xiaofang Zhou","Jian Yin"],"url":"https://arxiv.org/abs/2502.20854"}
{"created":"2025-05-20","title":"State-Dependent Conformal Perception Bounds for Neuro-Symbolic Verification of Autonomous Systems","abstract":"It remains a challenge to provide safety guarantees for autonomous systems with neural perception and control. A typical approach obtains symbolic bounds on perception error (e.g., using conformal prediction) and performs verification under these bounds. However, these bounds can lead to drastic conservatism in the resulting end-to-end safety guarantee. This paper proposes an approach to synthesize symbolic perception error bounds that serve as an optimal interface between perception performance and control verification. The key idea is to consider our error bounds to be heteroskedastic with respect to the system's state -- not time like in previous approaches. These bounds can be obtained with two gradient-free optimization algorithms. We demonstrate that our bounds lead to tighter safety guarantees than the state-of-the-art in a case study on a mountain car.","authors":["Thomas Waite","Yuang Geng","Trevor Turnquist","Ivan Ruchkin","Radoslav Ivanov"],"url":"https://arxiv.org/abs/2502.21308"}
{"created":"2025-05-20","title":"FANformer: Improving Large Language Models Through Effective Periodicity Modeling","abstract":"Periodicity, as one of the most important basic characteristics, lays the foundation for facilitating structured knowledge acquisition and systematic cognitive processes within human learning paradigms. However, the potential flaws of periodicity modeling in Transformer affect the learning efficiency and establishment of underlying principles from data for large language models (LLMs) built upon it. In this paper, we demonstrate that integrating effective periodicity modeling can improve the learning efficiency and performance of LLMs. We introduce FANformer, which adapts Fourier Analysis Network (FAN) into attention mechanism to achieve efficient periodicity modeling, by modifying the feature projection process of attention mechanism. Extensive experimental results on language modeling show that FANformer consistently outperforms Transformer when scaling up model size and training tokens, underscoring its superior learning efficiency. Our pretrained FANformer-1B exhibits marked improvements on downstream tasks compared to open-source LLMs with similar model parameters or training tokens. Moreover, we reveal that FANformer exhibits superior ability to learn and apply rules for reasoning compared to Transformer. The results position FANformer as an effective and promising architecture for advancing LLMs.","authors":["Yihong Dong","Ge Li","Xue Jiang","Yongding Tao","Kechi Zhang","Hao Zhu","Huanyu Liu","Jiazheng Ding","Jia Li","Jinliang Deng","Hong Mei"],"url":"https://arxiv.org/abs/2502.21309"}
{"created":"2025-05-20","title":"Adaptive Reinforcement Learning for State Avoidance in Discrete Event Systems","abstract":"Reinforcement learning (RL) has emerged as a potent paradigm for autonomous decision-making in complex environments. However, the integration of event-driven decision processes within RL remains a challenge. This paper presents a novel architecture that combines a Discrete Event Supervisory (DES) model with a standard RL framework to create a hybrid decision-making system. Our model leverages the DES's capabilities in managing event-based dynamics with the RL agent's adaptability to continuous states and actions, facilitating a more robust and flexible control strategy in systems characterized by both continuous and discrete events. The DES model operates alongside the RL agent, enhancing the policy's performance with event-based insights, while the environment's state transitions are governed by a mechanistic model. We demonstrate the efficacy of our approach through simulations that show improved performance metrics over traditional RL implementations. Our results suggest that this integrated approach holds promise for applications ranging from industrial automation to intelligent traffic systems, where discrete event handling is paramount.","authors":["Md Nur-A-Adam Dony"],"url":"https://arxiv.org/abs/2503.00192"}
{"created":"2025-05-20","title":"PINN-DT: Optimizing Energy Consumption in Smart Building Using Hybrid Physics-Informed Neural Networks and Digital Twin Framework with Blockchain Security","abstract":"The advancement of smart grid technologies necessitates the integration of cutting-edge computational methods to enhance predictive energy optimization. This study proposes a multi-faceted approach by incorporating (1) Deep Reinforcement Learning (DRL) agents trained using data from Digital Twins (DTs) to optimize energy consumption in real time, (2) Physics-Informed Neural Networks (PINNs) to seamlessly embed physical laws within the optimization process, ensuring model accuracy and interpretability, and (3) Blockchain (BC) technology to facilitate secure and transparent communication across the smart grid infrastructure. The model was trained and validated using comprehensive datasets, including smart meter energy consumption data, renewable energy outputs, dynamic pricing, and user preferences collected from IoT devices. The proposed framework achieved superior predictive performance with a Mean Absolute Error (MAE) of 0.237 kWh, Root Mean Square Error (RMSE) of 0.298 kWh, and an R-squared (R2) value of 0.978, indicating a 97.8% explanation of data variance. Classification metrics further demonstrated the model's robustness, achieving 97.7% accuracy, 97.8% precision, 97.6% recall, and an F1 Score of 97.7%. Comparative analysis with traditional models like Linear Regression, Random Forest, SVM, LSTM, and XGBoost revealed the superior accuracy and real-time adaptability of the proposed method. In addition to enhancing energy efficiency, the model reduced energy costs by 35%, maintained a 96% user comfort index, and increased renewable energy utilization to 40%. This study demonstrates the transformative potential of integrating PINNs, DT, and Blockchain technologies to optimize energy consumption in smart grids, paving the way for sustainable, secure, and efficient energy management systems.","authors":["Hajar Kazemi Naeini","Roya Shomali","Abolhassan Pishahang","Hamidreza Hasanzadeh","Mahdieh Mohammadi","Saeed Asadi","Abbas Varmaghani","Ahmad Gholizadeh Lonbar"],"url":"https://arxiv.org/abs/2503.00331"}
{"created":"2025-05-20","title":"HWC-Loco: A Hierarchical Whole-Body Control Approach to Robust Humanoid Locomotion","abstract":"Humanoid robots, capable of assuming human roles in various workplaces, have become essential to embodied intelligence. However, as robots with complex physical structures, learning a control model that can operate robustly across diverse environments remains inherently challenging, particularly under the discrepancies between training and deployment environments. In this study, we propose HWC-Loco, a robust whole-body control algorithm tailored for humanoid locomotion tasks. By reformulating policy learning as a robust optimization problem, HWC-Loco explicitly learns to recover from safety-critical scenarios. While prioritizing safety guarantees, overly conservative behavior can compromise the robot's ability to complete the given tasks. To tackle this challenge, HWC-Loco leverages a hierarchical policy for robust control. This policy can dynamically resolve the trade-off between goal-tracking and safety recovery, guided by human behavior norms and dynamic constraints. To evaluate the performance of HWC-Loco, we conduct extensive comparisons against state-of-the-art humanoid control models, demonstrating HWC-Loco's superior performance across diverse terrains, robot structures, and locomotion tasks under both simulated and real-world environments.","authors":["Sixu Lin","Guanren Qiao","Yunxin Tai","Ang Li","Kui Jia","Guiliang Liu"],"url":"https://arxiv.org/abs/2503.00923"}
{"created":"2025-05-20","title":"Bayesian Inverse Problems Meet Flow Matching: Efficient and Flexible Inference via Transformers","abstract":"The efficient resolution of Bayesian inverse problems remains challenging due to the high computational cost of traditional sampling methods. In this paper, we propose a novel framework that integrates Conditional Flow Matching (CFM) with a transformer-based architecture to enable fast and flexible sampling from complex posterior distributions. The proposed methodology involves the direct learning of conditional probability trajectories from the data, leveraging CFM's ability to bypass iterative simulation and transformers' capacity to process arbitrary numbers of observations. The efficacy of the proposed framework is demonstrated through its application to three problems: a simple nonlinear model, a disease dynamics framework, and a two-dimensional Darcy flow Partial Differential Equation. The primary outcomes demonstrate that the relative errors in parameters recovery are as low as 1.5%, and that the inference time is reduced by up to 2000 times on CPU in comparison with the Monte Carlo Markov Chain. This framework facilitates the expeditious resolution of Bayesian problems through the utilisation of sampling from the learned conditional distribution.","authors":["Daniil Sherki","Ivan Oseledets","Ekaterina Muravleva"],"url":"https://arxiv.org/abs/2503.01375"}
{"created":"2025-05-20","title":"MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation Alignment","abstract":"Personalized product search aims to retrieve and rank items that match users' preferences and search intent. Despite their effectiveness, existing approaches typically assume that users' query fully captures their real motivation. However, our analysis of a real-world e-commerce platform reveals that users often engage in relevant consultations before searching, indicating they refine intents through consultations based on motivation and need. The implied motivation in consultations is a key enhancing factor for personalized search. This unexplored area comes with new challenges including aligning contextual motivations with concise queries, bridging the category-text gap, and filtering noise within sequence history. To address these, we propose a Motivation-Aware Personalized Search (MAPS) method. It embeds queries and consultations into a unified semantic space via LLMs, utilizes a Mixture of Attention Experts (MoAE) to prioritize critical semantics, and introduces dual alignment: (1) contrastive learning aligns consultations, reviews, and product features; (2) bidirectional attention integrates motivation-aware embeddings with user preferences. Extensive experiments on real and synthetic data show MAPS outperforms existing methods in both retrieval and ranking tasks.","authors":["Weicong Qin","Yi Xu","Weijie Yu","Chenglei Shen","Ming He","Jianping Fan","Xiao Zhang","Jun Xu"],"url":"https://arxiv.org/abs/2503.01711"}
{"created":"2025-05-20","title":"Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation","abstract":"Many large-scale systems rely on high-quality deep representations (embeddings) to facilitate tasks like retrieval, search, and generative modeling. Matryoshka Representation Learning (MRL) recently emerged as a solution for adaptive embedding lengths, but it requires full model retraining and suffers from noticeable performance degradations at short lengths. In this paper, we show that sparse coding offers a compelling alternative for achieving adaptive representation with minimal overhead and higher fidelity. We propose Contrastive Sparse Representation (CSR), a method that sparsifies pre-trained embeddings into a high-dimensional but selectively activated feature space. By leveraging lightweight autoencoding and task-aware contrastive objectives, CSR preserves semantic quality while allowing flexible, cost-effective inference at different sparsity levels. Extensive experiments on image, text, and multimodal benchmarks demonstrate that CSR consistently outperforms MRL in terms of both accuracy and retrieval speed-often by large margins-while also cutting training time to a fraction of that required by MRL. Our results establish sparse coding as a powerful paradigm for adaptive representation learning in real-world applications where efficiency and fidelity are both paramount. Code is available at https://github.com/neilwen987/CSR_Adaptive_Rep","authors":["Tiansheng Wen","Yifei Wang","Zequn Zeng","Zhong Peng","Yudi Su","Xinyang Liu","Bo Chen","Hongwei Liu","Stefanie Jegelka","Chenyu You"],"url":"https://arxiv.org/abs/2503.01776"}
{"created":"2025-05-20","title":"Flexible Prefrontal Control over Hippocampal Episodic Memory for Goal-Directed Generalization","abstract":"Many tasks require flexibly modifying perception and behavior based on current goals. Humans can retrieve episodic memories from days to years ago, using them to contextualize and generalize behaviors across novel but structurally related situations. The brain's ability to control episodic memories based on task demands is often attributed to interactions between the prefrontal cortex (PFC) and hippocampus (HPC). We propose a reinforcement learning model that incorporates a PFC-HPC interaction mechanism for goal-directed generalization. In our model, the PFC learns to generate query-key representations to encode and retrieve goal-relevant episodic memories, modulating HPC memories top-down based on current task demands. Moreover, the PFC adapts its encoding and retrieval strategies dynamically when faced with multiple goals presented in a blocked, rather than interleaved, manner. Our results show that: (1) combining working memory with selectively retrieved episodic memory allows transfer of decisions among similar environments or situations, (2) top-down control from PFC over HPC improves learning of arbitrary structural associations between events for generalization to novel environments compared to a bottom-up sensory-driven approach, and (3) the PFC encodes generalizable representations during both encoding and retrieval of goal-relevant memories, whereas the HPC exhibits event-specific representations. Together, these findings highlight the importance of goal-directed prefrontal control over hippocampal episodic memory for decision-making in novel situations and suggest a computational mechanism by which PFC-HPC interactions enable flexible behavior.","authors":["Yicong Zheng","Nora Wolf","Charan Ranganath","Randall C. O'Reilly","Kevin L. McKee"],"url":"https://arxiv.org/abs/2503.02303"}
{"created":"2025-05-20","title":"Vision Transformers on the Edge: A Comprehensive Survey of Model Compression and Acceleration Strategies","abstract":"In recent years, vision transformers (ViTs) have emerged as powerful and promising techniques for computer vision tasks such as image classification, object detection, and segmentation. Unlike convolutional neural networks (CNNs), which rely on hierarchical feature extraction, ViTs treat images as sequences of patches and leverage self-attention mechanisms. However, their high computational complexity and memory demands pose significant challenges for deployment on resource-constrained edge devices. To address these limitations, extensive research has focused on model compression techniques and hardware-aware acceleration strategies. Nonetheless, a comprehensive review that systematically categorizes these techniques and their trade-offs in accuracy, efficiency, and hardware adaptability for edge deployment remains lacking. This survey bridges this gap by providing a structured analysis of model compression techniques, software tools for inference on edge, and hardware acceleration strategies for ViTs. We discuss their impact on accuracy, efficiency, and hardware adaptability, highlighting key challenges and emerging research directions to advance ViT deployment on edge platforms, including graphics processing units (GPUs), application-specific integrated circuit (ASICs), and field-programmable gate arrays (FPGAs). The goal is to inspire further research with a contemporary guide on optimizing ViTs for efficient deployment on edge devices.","authors":["Shaibal Saha","Lanyu Xu"],"url":"https://arxiv.org/abs/2503.02891"}
{"created":"2025-05-20","title":"MoSE: Hierarchical Self-Distillation Enhances Early Layer Embeddings","abstract":"Deploying language models often requires navigating accuracy vs. performance trade-offs to meet latency constraints while preserving utility. Traditional model distillation reduces size but incurs substantial costs through training separate models. We introduce ModularStarEncoder (MoSE), a 1-billion-parameter multi-exit encoder for code retrieval and classification that employs a novel Self-Distillation mechanism. This approach significantly enhances lower-layer representations, enabling flexible deployment of different model portions with favorable performance trade-offs. Our architecture improves text-to-code and code-to-code search by targeting specific encoder layers as exit heads, where higher layers guide earlier ones during training-improving intermediate representations at minimal additional cost. We further enhance MoSE with a repository-level contextual loss that maximizes training context window utilization. Additionally, we release a new dataset created through code translation that extends text-to-code benchmarks with cross-language code-to-code pairs. Evaluations demonstrate the effectiveness of Self-Distillation as a principled approach to trading inference cost for accuracy across various code understanding tasks.","authors":["Andrea Gurioli","Federico Pennino","Jo\\~ao Monteiro","Maurizio Gabbrielli"],"url":"https://arxiv.org/abs/2503.03008"}
{"created":"2025-05-20","title":"Learning to Reduce Search Space for Generalizable Neural Routing Solver","abstract":"Constructive neural combinatorial optimization (NCO) has attracted growing research attention due to its ability to solve complex routing problems without relying on handcrafted rules. However, existing NCO methods face significant challenges in generalizing to large-scale problems due to high computational complexity and inefficient capture of structural patterns. To address this issue, we propose a novel learning-based search space reduction method that adaptively selects a small set of promising candidate nodes at each step of the constructive NCO process. Unlike traditional methods that rely on fixed heuristics, our selection model dynamically prioritizes nodes based on learned patterns, significantly reducing the search space while maintaining solution quality. Experimental results demonstrate that our method, trained solely on 100-node instances from uniform distribution, generalizes remarkably well to large-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) instances with up to 1 million nodes from the uniform distribution and over 80K nodes from other distributions.","authors":["Changliang Zhou","Xi Lin","Zhenkun Wang","Qingfu Zhang"],"url":"https://arxiv.org/abs/2503.03137"}
{"created":"2025-05-20","title":"Can Frontier LLMs Replace Annotators in Biomedical Text Mining? Analyzing Challenges and Exploring Solutions","abstract":"Multiple previous studies have reported suboptimal performance of LLMs in biomedical text mining. By analyzing failure patterns in these evaluations, we identified three primary challenges for LLMs in biomedical corpora: (1) LLMs fail to learn implicit dataset-specific nuances from supervised data, (2) The common formatting requirements of discriminative tasks limit the reasoning capabilities of LLMs particularly for LLMs that lack test-time compute, and (3) LLMs struggle to adhere to annotation guidelines and match exact schemas, which hinders their ability to understand detailed annotation requirements which is essential in biomedical annotation workflow. We experimented with prompt engineering techniques targeted to the above issues, and developed a pipeline that dynamically extracts instructions from annotation guidelines. Our results show that frontier LLMs can approach or surpass the performance of SOTA BERT-based models with minimal reliance on manually annotated data and without fine-tuning. Furthermore, we performed model distillation on a closed-source LLM, demonstrating that a BERT model trained exclusively on synthetic data annotated by LLMs can also achieve a practical performance. Based on these findings, we explored the feasibility of partially replacing manual annotation with LLMs in production scenarios for biomedical text mining.","authors":["Yichong Zhao","Susumu Goto"],"url":"https://arxiv.org/abs/2503.03261"}
{"created":"2025-05-20","title":"Greedy Algorithm for Structured Bandits: A Sharp Characterization of Asymptotic Success / Failure","abstract":"We study the greedy (exploitation-only) algorithm in bandit problems with a known reward structure. We allow arbitrary finite reward structures, while prior work focused on a few specific ones. We fully characterize when the greedy algorithm asymptotically succeeds or fails, in the sense of sublinear vs. linear regret as a function of time. Our characterization identifies a partial identifiability property of the problem instance as the necessary and sufficient condition for the asymptotic success. Notably, once this property holds, the problem becomes easy -- any algorithm will succeed (in the same sense as above), provided it satisfies a mild non-degeneracy condition. Our characterization extends to contextual bandits and interactive decision-making with arbitrary feedback. Examples demonstrating broad applicability and extensions to infinite reward structures are provided.","authors":["Aleksandrs Slivkins","Yunzong Xu","Shiliang Zuo"],"url":"https://arxiv.org/abs/2503.04010"}
{"created":"2025-05-20","title":"Semantic Shift Estimation via Dual-Projection and Classifier Reconstruction for Exemplar-Free Class-Incremental Learning","abstract":"Exemplar-Free Class-Incremental Learning (EFCIL) aims to sequentially learn from distinct categories without retaining exemplars but easily suffers from catastrophic forgetting of learned knowledge. While existing EFCIL methods leverage knowledge distillation to alleviate forgetting, they still face two critical challenges: semantic shift and decision bias. Specifically, the embeddings of old tasks shift in the embedding space after learning new tasks, and the classifier becomes biased towards new tasks due to training solely with new data, hindering the balance between old and new knowledge. To address these issues, we propose the Dual-Projection Shift Estimation and Classifier Reconstruction (DPCR) approach for EFCIL. DPCR effectively estimates semantic shift through a dual-projection, which combines a learnable transformation with a row-space projection to capture both task-wise and category-wise shifts. Furthermore, to mitigate decision bias, DPCR employs ridge regression to reformulate a classifier reconstruction process. This reconstruction exploits previous in covariance and prototype of each class after calibration with estimated shift, thereby reducing decision bias. Extensive experiments demonstrate that, on various datasets, DPCR effectively balances old and new tasks, outperforming state-of-the-art EFCIL methods. Our codes are available at https://github.com/RHe502/ICML25-DPCR.","authors":["Run He","Di Fang","Yicheng Xu","Yawen Cui","Ming Li","Cen Chen","Ziqian Zeng","Huiping Zhuang"],"url":"https://arxiv.org/abs/2503.05423"}
{"created":"2025-05-20","title":"ForestSplats: Deformable transient field for Gaussian Splatting in the Wild","abstract":"Recently, 3D Gaussian Splatting (3D-GS) has emerged, showing real-time rendering speeds and high-quality results in static scenes. Although 3D-GS shows effectiveness in static scenes, their performance significantly degrades in real-world environments due to transient objects, lighting variations, and diverse levels of occlusion. To tackle this, existing methods estimate occluders or transient elements by leveraging pre-trained models or integrating additional transient field pipelines. However, these methods still suffer from two defects: 1) Using semantic features from the Vision Foundation model (VFM) causes additional computational costs. 2) The transient field requires significant memory to handle transient elements with per-view Gaussians and struggles to define clear boundaries for occluders, solely relying on photometric errors. To address these problems, we propose ForestSplats, a novel approach that leverages the deformable transient field and a superpixel-aware mask to efficiently represent transient elements in the 2D scene across unconstrained image collections and effectively decompose static scenes from transient distractors without VFM. We designed the transient field to be deformable, capturing per-view transient elements. Furthermore, we introduce a superpixel-aware mask that clearly defines the boundaries of occluders by considering photometric errors and superpixels. Additionally, we propose uncertainty-aware densification to avoid generating Gaussians within the boundaries of occluders during densification. Through extensive experiments across several benchmark datasets, we demonstrate that ForestSplats outperforms existing methods without VFM and shows significant memory efficiency in representing transient elements.","authors":["Wongi Park","Myeongseok Nam","Siwon Kim","Sangwoo Jo","Soomok Lee"],"url":"https://arxiv.org/abs/2503.06179"}
{"created":"2025-05-20","title":"SCoRE: Benchmarking Long-Chain Reasoning in Commonsense Scenarios","abstract":"Currently, long-chain reasoning remains a key challenge for large language models (LLMs) because natural texts lack sufficient explicit reasoning data. However, existing benchmarks suffer from limitations such as narrow coverage, short reasoning paths, or high construction costs. We introduce SCoRE (Scenario-based Commonsense Reasoning Evaluation), a benchmark that synthesizes multi-hop questions from scenario schemas of entities, relations, and logical rules to assess long-chain commonsense reasoning. SCoRE contains 100k bilingual (Chinese-English) multiple-choice questions whose reasoning chains span 2-11 hops and are grouped into various difficulty levels. Each question is accompanied by fine-grained knowledge labels, explicit reasoning chains, and difficulty levels for diagnostic evaluation. Evaluation results on cutting-edge LLMs such as o3-mini and Deepseek R1 shows that even the best model attains only 69.78% accuracy on SCoRE (even only 47.91% on the hard set), with errors often stemming from rare knowledge, logical inconsistency, and over-interpretation of simple questions. SCoRE offers a scalable, extensible framework for evaluating and diagnosing the long-chain commonsense reasoning abilities of LLMs and guiding future advances in model design and training.","authors":["Weidong Zhan","Yue Wang","Nan Hu","Liming Xiao","Jingyuan Ma","Yuhang Qin","Zheng Li","Yixin Yang","Sirui Deng","Jinkun Ding","Wenhan Ma","Rui Li","Weilin Luo","Qun Liu","Zhifang Sui"],"url":"https://arxiv.org/abs/2503.06218"}
{"created":"2025-05-20","title":"REArtGS: Reconstructing and Generating Articulated Objects via 3D Gaussian Splatting with Geometric and Motion Constraints","abstract":"Articulated objects, as prevalent entities in human life, their 3D representations play crucial roles across various applications. However, achieving both high-fidelity textured surface reconstruction and dynamic generation for articulated objects remains challenging for existing methods. In this paper, we present REArtGS, a novel framework that introduces additional geometric and motion constraints to 3D Gaussian primitives, enabling high-quality textured surface reconstruction and generation for articulated objects. Specifically, given multi-view RGB images of arbitrary two states of articulated objects, we first introduce an unbiased Signed Distance Field (SDF) guidance to regularize Gaussian opacity fields, enhancing geometry constraints and improving surface reconstruction quality. Then we establish deformable fields for 3D Gaussians constrained by the kinematic structures of articulated objects, achieving unsupervised generation of surface meshes in unseen states. Extensive experiments on both synthetic and real datasets demonstrate our approach achieves high-quality textured surface reconstruction for given states, and enables high-fidelity surface generation for unseen states. Codes will be released after acceptance and the project website is at https://sites.google.com/view/reartgs/home.","authors":["Di Wu","Liu Liu","Zhou Linli","Anran Huang","Liangtu Song","Qiaojun Yu","Qi Wu","Cewu Lu"],"url":"https://arxiv.org/abs/2503.06677"}
{"created":"2025-05-20","title":"Boosting Diffusion-Based Text Image Super-Resolution Model Towards Generalized Real-World Scenarios","abstract":"Restoring low-resolution text images presents a significant challenge, as it requires maintaining both the fidelity and stylistic realism of the text in restored images. Existing text image restoration methods often fall short in hard situations, as the traditional super-resolution models cannot guarantee clarity, while diffusion-based methods fail to maintain fidelity. In this paper, we introduce a novel framework aimed at improving the generalization ability of diffusion models for text image super-resolution (SR), especially promoting fidelity. First, we propose a progressive data sampling strategy that incorporates diverse image types at different stages of training, stabilizing the convergence and improving the generalization. For the network architecture, we leverage a pre-trained SR prior to provide robust spatial reasoning capabilities, enhancing the model's ability to preserve textual information. Additionally, we employ a cross-attention mechanism to better integrate textual priors. To further reduce errors in textual priors, we utilize confidence scores to dynamically adjust the importance of textual features during training. Extensive experiments on real-world datasets demonstrate that our approach not only produces text images with more realistic visual appearances but also improves the accuracy of text structure.","authors":["Chenglu Pan","Xiaogang Xu","Ganggui Ding","Yunke Zhang","Wenbo Li","Jiarong Xu","Qingbiao Wu"],"url":"https://arxiv.org/abs/2503.07232"}
{"created":"2025-05-20","title":"Design for Hope: Cultivating Deliberate Hope in the Face of Complex Societal Challenges","abstract":"Design has the potential to cultivate hope in the face of complex societal challenges, especially those central to CSCW research. These challenges are often addressed through efforts aimed at harm reduction and prevention -- essential but sometimes limiting approaches that can unintentionally narrow our collective sense of what is possible. This one-day, in-person workshop builds on the Positech Workshop at CSCW 2024 (https://positech-cscw-2024.github.io/) by offering practical ways to move beyond reactive problem-solving toward building capacity for proactive goal setting and generating pathways forward. We explore how collaborative and reflective design methodologies can help research communities navigate uncertainty, expand possibilities, and foster meaningful change. By connecting design thinking with hope theory, which frames hope as the interplay of \"goal-directed,\" \"pathways,\" and \"agentic\" thinking, we will examine how researchers might chart new directions in the face of complexity and constraint. Through hands-on activities including problem reframing, building a shared taxonomy of design methods that align with hope theory, and reflecting on what it means to sustain hopeful research trajectories, participants will develop strategies to embed a deliberately hopeful approach into their research.","authors":["JaeWon Kim","Jiaying \"Lizzy\" Liu","Lindsay Popowski","Cassidy Pyle","Sowmya Somanath","Hua Shen","Casey Fiesler","Gillian R. Hayes","Alexis Hiniker","Wendy Ju","Florian \"Floyd\" Mueller","Ahmer Arif","Yasmine Kotturi"],"url":"https://arxiv.org/abs/2503.07586"}
{"created":"2025-05-20","title":"Electrifying Heavy-Duty Trucks: Battery-Swapping vs Fast Charging","abstract":"The advantages and disadvantages of Battery Swapping Stations (BSS) for heavy-duty trucks are poorly understood, relative to Fast Charging Stations (FCS) systems. This study evaluates these two charging mechanisms for electric heavy-duty trucks, aiming to compare the systems' efficiency and identify their optimal design. A model was developed to address the planning and operation of BSS in a charging network, considering in-station batteries as assets for various services. We assess performance metrics including transportation efficiency and battery utilization efficiency. Our evaluation reveals that BSS significantly increased transportation efficiency by reducing vehicle downtime compared to fast charging, but may require more batteries. BSS with medium-sized batteries offers improved transportation efficiency in terms of time and labor. FCS-reliant trucks require larger batteries to compensate for extended charging times. To understand the trade-off between these two metrics, a cost-benefit analysis was performed under different scenarios involving potential shifts in battery prices and labor costs. Additionally, BSS shows potential for significant $\\text{CO}_2$ emission reductions and increased profitability through energy arbitrage and grid ancillary services. These findings emphasize the importance of integrating BSS into future electric truck charging networks and adopting carbon-aware operational frameworks.","authors":["Ruiting Wang","Antoine Martinez","Zaid Allybokus","Wente Zeng","Nicolas Obrecht","Scott Moura"],"url":"https://arxiv.org/abs/2503.08080"}
{"created":"2025-05-20","title":"ELECTRA: A Cartesian Network for 3D Charge Density Prediction with Floating Orbitals","abstract":"We present the Electronic Tensor Reconstruction Algorithm (ELECTRA) - an equivariant model for predicting electronic charge densities using floating orbitals. Floating orbitals are a long-standing concept in the quantum chemistry community that promises more compact and accurate representations by placing orbitals freely in space, as opposed to centering all orbitals at the position of atoms. Finding the ideal placement of these orbitals requires extensive domain knowledge, though, which thus far has prevented widespread adoption. We solve this in a data-driven manner by training a Cartesian tensor network to predict the orbital positions along with orbital coefficients. This is made possible through a symmetry-breaking mechanism that is used to learn position displacements with lower symmetry than the input molecule while preserving the rotation equivariance of the charge density itself. Inspired by recent successes of Gaussian Splatting in representing densities in space, we are using Gaussian orbitals and predicting their weights and covariance matrices. Our method achieves a state-of-the-art balance between computational efficiency and predictive accuracy on established benchmarks.","authors":["Jonas Elsborg","Luca Thiede","Al\\'an Aspuru-Guzik","Tejs Vegge","Arghya Bhowmik"],"url":"https://arxiv.org/abs/2503.08305"}
{"created":"2025-05-20","title":"Language-Enhanced Representation Learning for Single-Cell Transcriptomics","abstract":"Single-cell RNA sequencing (scRNA-seq) offers detailed insights into cellular heterogeneity. Recent advancements leverage single-cell large language models (scLLMs) for effective representation learning. These models focus exclusively on transcriptomic data, neglecting complementary biological knowledge from textual descriptions. To overcome this limitation, we propose scMMGPT, a novel multimodal framework designed for language-enhanced representation learning in single-cell transcriptomics. Unlike existing methods, scMMGPT employs robust cell representation extraction, preserving quantitative gene expression data, and introduces an innovative two-stage pre-training strategy combining discriminative precision with generative flexibility. Extensive experiments demonstrate that scMMGPT significantly outperforms unimodal and multimodal baselines across key downstream tasks, including cell annotation and clustering, and exhibits superior generalization in out-of-distribution scenarios.","authors":["Yaorui Shi","Jiaqi Yang","Changhao Nai","Sihang Li","Junfeng Fang","Xiang Wang","Zhiyuan Liu","Yang Zhang"],"url":"https://arxiv.org/abs/2503.09427"}
{"created":"2025-05-20","title":"PolyPythias: Stability and Outliers across Fifty Language Model Pre-Training Runs","abstract":"The stability of language model pre-training and its effects on downstream performance are still understudied. Prior work shows that the training process can yield significantly different results in response to slight variations in initial conditions, e.g., the random seed. Crucially, the research community still lacks sufficient resources and tools to systematically investigate pre-training stability, particularly for decoder-only language models. We introduce the PolyPythias, a set of 45 new training runs for the Pythia model suite: 9 new seeds across 5 model sizes, from 14M to 410M parameters, resulting in about 7k new checkpoints that we release. Using these new 45 training runs, in addition to the 5 already available, we study the effects of different initial conditions determined by the seed -- i.e., parameters' initialisation and data order -- on (i) downstream performance, (ii) learned linguistic representations, and (iii) emergence of training phases. In addition to common scaling behaviours, our analyses generally reveal highly consistent training dynamics across both model sizes and initial conditions. Further, the new seeds for each model allow us to identify outlier training runs and delineate their characteristics. Our findings show the potential of using these methods to predict training stability.","authors":["Oskar van der Wal","Pietro Lesci","Max Muller-Eberstein","Naomi Saphra","Hailey Schoelkopf","Willem Zuidema","Stella Biderman"],"url":"https://arxiv.org/abs/2503.09543"}
{"created":"2025-05-20","title":"Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models","abstract":"Diffusion language models offer unique benefits over autoregressive models due to their potential for parallelized generation and controllability, yet they lag in likelihood modeling and are limited to fixed-length generation. In this work, we introduce a class of block diffusion language models that interpolate between discrete denoising diffusion and autoregressive models. Block diffusion overcomes key limitations of both approaches by supporting flexible-length generation and improving inference efficiency with KV caching and parallel token sampling. We propose a recipe for building effective block diffusion models that includes an efficient training algorithm, estimators of gradient variance, and data-driven noise schedules to minimize the variance. Block diffusion sets a new state-of-the-art performance among diffusion models on language modeling benchmarks and enables generation of arbitrary-length sequences. We provide the code, along with the model weights and blog post on the project page: https://m-arriola.com/bd3lms","authors":["Marianne Arriola","Aaron Gokaslan","Justin T. Chiu","Zhihan Yang","Zhixuan Qi","Jiaqi Han","Subham Sekhar Sahoo","Volodymyr Kuleshov"],"url":"https://arxiv.org/abs/2503.09573"}
{"created":"2025-05-20","title":"SANA-Sprint: One-Step Diffusion with Continuous-Time Consistency Distillation","abstract":"This paper presents SANA-Sprint, an efficient diffusion model for ultra-fast text-to-image (T2I) generation. SANA-Sprint is built on a pre-trained foundation model and augmented with hybrid distillation, dramatically reducing inference steps from 20 to 1-4. We introduce three key innovations: (1) We propose a training-free approach that transforms a pre-trained flow-matching model for continuous-time consistency distillation (sCM), eliminating costly training from scratch and achieving high training efficiency. Our hybrid distillation strategy combines sCM with latent adversarial distillation (LADD): sCM ensures alignment with the teacher model, while LADD enhances single-step generation fidelity. (2) SANA-Sprint is a unified step-adaptive model that achieves high-quality generation in 1-4 steps, eliminating step-specific training and improving efficiency. (3) We integrate ControlNet with SANA-Sprint for real-time interactive image generation, enabling instant visual feedback for user interaction. SANA-Sprint establishes a new Pareto frontier in speed-quality tradeoffs, achieving state-of-the-art performance with 7.59 FID and 0.74 GenEval in only 1 step - outperforming FLUX-schnell (7.94 FID / 0.71 GenEval) while being 10x faster (0.1s vs 1.1s on H100). It also achieves 0.1s (T2I) and 0.25s (ControlNet) latency for 1024 x 1024 images on H100, and 0.31s (T2I) on an RTX 4090, showcasing its exceptional efficiency and potential for AI-powered consumer applications (AIPC). Code and pre-trained models will be open-sourced.","authors":["Junsong Chen","Shuchen Xue","Yuyang Zhao","Jincheng Yu","Sayak Paul","Junyu Chen","Han Cai","Song Han","Enze Xie"],"url":"https://arxiv.org/abs/2503.09641"}
{"created":"2025-05-20","title":"Probabilistic Reasoning with LLMs for k-anonymity Estimation","abstract":"Probabilistic reasoning is a key aspect of both human and artificial intelligence that allows for handling uncertainty and ambiguity in decision-making. In this paper, we introduce a new numerical reasoning task under uncertainty for large language models, focusing on estimating the privacy risk of user-generated documents containing privacy-sensitive information. We propose BRANCH, a new LLM methodology that estimates the k-privacy value of a text-the size of the population matching the given information. BRANCH factorizes a joint probability distribution of personal information as random variables. The probability of each factor in a population is estimated separately using a Bayesian network and combined to compute the final k-value. Our experiments show that this method successfully estimates the k-value 73% of the time, a 13% increase compared to o3-mini with chain-of-thought reasoning. We also find that LLM uncertainty is a good indicator for accuracy, as high-variance predictions are 37.47% less accurate on average.","authors":["Jonathan Zheng","Sauvik Das","Alan Ritter","Wei Xu"],"url":"https://arxiv.org/abs/2503.09674"}
{"created":"2025-05-20","title":"Revisiting Backdoor Attacks on Time Series Classification in the Frequency Domain","abstract":"Time series classification (TSC) is a cornerstone of modern web applications, powering tasks such as financial data analysis, network traffic monitoring, and user behavior analysis. In recent years, deep neural networks (DNNs) have greatly enhanced the performance of TSC models in these critical domains. However, DNNs are vulnerable to backdoor attacks, where attackers can covertly implant triggers into models to induce malicious outcomes. Existing backdoor attacks targeting DNN-based TSC models remain elementary. In particular, early methods borrow trigger designs from computer vision, which are ineffective for time series data. More recent approaches utilize generative models for trigger generation, but at the cost of significant computational complexity. In this work, we analyze the limitations of existing attacks and introduce an enhanced method, FreqBack. Drawing inspiration from the fact that DNN models inherently capture frequency domain features in time series data, we identify that improper perturbations in the frequency domain are the root cause of ineffective attacks. To address this, we propose to generate triggers both effectively and efficiently, guided by frequency analysis. FreqBack exhibits substantial performance across five models and eight datasets, achieving an impressive attack success rate of over 90%, while maintaining less than a 3% drop in model accuracy on clean data.","authors":["Yuanmin Huang","Mi Zhang","Zhaoxiang Wang","Wenxuan Li","Min Yang"],"url":"https://arxiv.org/abs/2503.09712"}
{"created":"2025-05-20","title":"AgentDAM: Privacy Leakage Evaluation for Autonomous Web Agents","abstract":"Autonomous AI agents that can follow instructions and perform complex multi-step tasks have tremendous potential to boost human productivity. However, to perform many of these tasks, the agents need access to personal information from their users, raising the question of whether they are capable of using it appropriately. In this work, we introduce a new benchmark AgentDAM that measures if AI web-navigation agents follow the privacy principle of ``data minimization''. For the purposes of our benchmark, data minimization means that the agent uses a piece of potentially sensitive information only if it is ``necessary'' to complete a particular task. Our benchmark simulates realistic web interaction scenarios end-to-end and is adaptable to all existing web navigation agents. We use AgentDAM to evaluate how well AI agents built on top of GPT-4, Llama-3 and Claude can limit processing of potentially private information, and show that they are prone to inadvertent use of unnecessary sensitive information. We also propose a prompting-based defense that reduces information leakage, and demonstrate that our end-to-end benchmarking provides a more realistic measure than probing LLMs about privacy. Our results highlight that further research is needed to develop AI agents that can prioritize data minimization at inference time.","authors":["Arman Zharmagambetov","Chuan Guo","Ivan Evtimov","Maya Pavlova","Ruslan Salakhutdinov","Kamalika Chaudhuri"],"url":"https://arxiv.org/abs/2503.09780"}
{"created":"2025-05-20","title":"dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis","abstract":"Federated learning has wide applications in the medical field. It enables knowledge sharing among different healthcare institutes while protecting patients' privacy. However, existing federated learning systems are typically centralized, requiring clients to upload client-specific knowledge to a central server for aggregation. This centralized approach would integrate the knowledge from each client into a centralized server, and the knowledge would be already undermined during the centralized integration before it reaches back to each client. Besides, the centralized approach also creates a dependency on the central server, which may affect training stability if the server malfunctions or connections are unstable. To address these issues, we propose a decentralized federated learning framework named dFLMoE. In our framework, clients directly exchange lightweight head models with each other. After exchanging, each client treats both local and received head models as individual experts, and utilizes a client-specific Mixture of Experts (MoE) approach to make collective decisions. This design not only reduces the knowledge damage with client-specific aggregations but also removes the dependency on the central server to enhance the robustness of the framework. We validate our framework on multiple medical tasks, demonstrating that our method evidently outperforms state-of-the-art approaches under both model homogeneity and heterogeneity settings.","authors":["Luyuan Xie","Tianyu Luan","Wenyuan Cai","Guochen Yan","Zhaoyu Chen","Nan Xi","Yuejian Fang","Qingni Shen","Zhonghai Wu","Junsong Yuan"],"url":"https://arxiv.org/abs/2503.10412"}
{"created":"2025-05-20","title":"Evaluating Mathematical Reasoning Across Large Language Models: A Fine-Grained Approach","abstract":"With the rapid advancement of Artificial Intelligence (AI), Large Language Models (LLMs) have significantly impacted a wide array of domains, including healthcare, engineering, science, education, and mathematical reasoning. Among these, mathematical reasoning remains a particularly challenging capability, often requiring multi-step logic and abstract generalization. While prior work has explored LLM performance on reasoning tasks, comprehensive evaluations that span both depth and breadth across model families remain limited. In this study, we present a systematic evaluation of mathematical reasoning abilities across eight leading LLMs, including two recent DeepSeek models, using three independent benchmark datasets. Our analyses reveal several key findings: (1) DeepSeek-R1 performs competitively with o1 across most domains and achieves the highest accuracy on the MMLU Formal Logic benchmark; (2) distilled variants, such as DeepSeek-1.5B, exhibit substantial performance degradation; and (3) Gemini 2.0 Flash achieves the lowest response latency. Beyond quantitative metrics, we explore how architectural choices, training paradigms, and optimization strategies contribute to variation in reasoning performance. These findings provide new insights into the capabilities and limitations of current LLMs in mathematical domains, and offer guidance for the development of future models better aligned with rigorous reasoning demands.","authors":["Afrar Jahin","Arif Hassan Zidan","Wei Zhang","Yu Bao","Tianming Liu"],"url":"https://arxiv.org/abs/2503.10573"}
{"created":"2025-05-20","title":"UC-MOA: Utility-Conditioned Multi-Objective Alignment for Distributional Pareto-Optimality","abstract":"Reinforcement Learning from Human Feedback (RLHF) has become a cornerstone for aligning large language models (LLMs) with human values. However, existing approaches struggle to capture the multi-dimensional, distributional nuances of human preferences. Methods such as RiC that directly inject raw reward values into prompts face significant numerical sensitivity issues--for instance, LLMs may fail to distinguish between 9.11 and 9.8--while alternatives like MORLHF, Rewarded Soups, and MODPO incur high computational costs by training multiple models. In this work, we introduce Utility-Conditioned Multi-Objective Alignment (UC-MOA), a novel framework that overcomes these limitations. Our approach leverages a diverse set of strictly increasing, non-linear utility functions to transform user-specified preferences into symbolic tokens, which are then used to condition a single LLM. This design not only mitigates numerical reasoning challenges but also substantially reduces training overhead, yielding models that achieve superior Pareto fronts and robust alignment across complex reward dimensions.","authors":["Zelei Cheng","Xin-Qiang Cai","Yuting Tang","Pushi Zhang","Boming Yang","Masashi Sugiyama","Xinyu Xing"],"url":"https://arxiv.org/abs/2503.10669"}
{"created":"2025-05-20","title":"Reinforcement Learning and Life Cycle Assessment for a Circular Economy -- Towards Progressive Computer Science","abstract":"The aim of this paper is to discuss the potential of using methods from Reinforcement Learning for Life Cycle Assessment in a circular economy, and to present some new ideas in this direction. To give some context, we explain how Reinforcement Learning was successfully applied in computer chess (and beyond). As computer chess was historically called the \"drosophila of AI\", we start by describing a method for the board representation called 'rotated bitboards' that can potentially also be applied in the context of sustainability. In the first part of this paper, the concepts of the bitboard-representation and the advantages of (rotated) bitboards in move generation are explained. In order to illustrate those ideas practice, the concrete implementation of the move-generator in FUSc# (a chess engine developed at FU Berlin in C# some years ago) is described. In addition, rotated binary neural networks are discussed briefly.","authors":["Johannes Buchner"],"url":"https://arxiv.org/abs/2503.10822"}
{"created":"2025-05-20","title":"Is Your Imitation Learning Policy Better than Mine? Policy Comparison with Near-Optimal Stopping","abstract":"Imitation learning has enabled robots to perform complex, long-horizon tasks in challenging dexterous manipulation settings. As new methods are developed, they must be rigorously evaluated and compared against corresponding baselines through repeated evaluation trials. However, policy comparison is fundamentally constrained by a small feasible sample size (e.g., 10 or 50) due to significant human effort and limited inference throughput of policies. This paper proposes a novel statistical framework for rigorously comparing two policies in the small sample size regime. Prior work in statistical policy comparison relies on batch testing, which requires a fixed, pre-determined number of trials and lacks flexibility in adapting the sample size to the observed evaluation data. Furthermore, extending the test with additional trials risks inducing inadvertent p-hacking, undermining statistical assurances. In contrast, our proposed statistical test is sequential, allowing researchers to decide whether or not to run more trials based on intermediate results. This adaptively tailors the number of trials to the difficulty of the underlying comparison, saving significant time and effort without sacrificing probabilistic correctness. Extensive numerical simulation and real-world robot manipulation experiments show that our test achieves near-optimal stopping, letting researchers stop evaluation and make a decision in a near-minimal number of trials. Specifically, it reduces the number of evaluation trials by up to 32% as compared to state-of-the-art baselines, while preserving the probabilistic correctness and statistical power of the comparison. Moreover, our method is strongest in the most challenging comparison instances (requiring the most evaluation trials); in a multi-task comparison scenario, we save the evaluator more than 160 simulation rollouts.","authors":["David Snyder","Asher James Hancock","Apurva Badithela","Emma Dixon","Patrick Miller","Rares Andrei Ambrus","Anirudha Majumdar","Masha Itkina","Haruki Nishimura"],"url":"https://arxiv.org/abs/2503.10966"}
{"created":"2025-05-20","title":"D3: Diversity, Difficulty, and Dependability-Aware Data Selection for Sample-Efficient LLM Instruction Tuning","abstract":"Recent advancements in instruction tuning for large language models (LLMs) suggest that a small, high-quality dataset can significantly equip LLMs with instruction-following capabilities, outperforming large datasets often burdened by quality and redundancy issues. However, the challenge lies in automatically identifying valuable subsets from large datasets to boost both the effectiveness and efficiency of instruction tuning. In this paper, we first establish data selection criteria based on three distinct aspects of data value: diversity, difficulty, and dependability, and then propose the D3 method comprising two key steps of scoring and selection. Specifically, in the scoring step, we define the diversity function to measure sample distinctiveness and introduce the uncertainty-based prediction difficulty to evaluate sample difficulty by mitigating the interference of context-oriented generation diversity. Additionally, we integrate an external LLM for dependability assessment. In the selection step, we formulate the D3 weighted coreset objective, which jointly optimizes three aspects of data value to solve for the most valuable subset. The two steps of D3 can iterate multiple rounds, incorporating feedback to refine the selection focus adaptively. Experiments on both public datasets and the real-world Taobao Live application demonstrate the effectiveness of D3 in endowing LLMs with competitive or even superior instruction-following capabilities using less than 10\\% of the entire dataset.","authors":["Jia Zhang","Chen-Xi Zhang","Yao Liu","Yi-Xuan Jin","Xiao-Wen Yang","Bo Zheng","Yi Liu","Lan-Zhe Guo"],"url":"https://arxiv.org/abs/2503.11441"}
{"created":"2025-05-20","title":"Cognitive Disentanglement for Referring Multi-Object Tracking","abstract":"As a significant application of multi-source information fusion in intelligent transportation perception systems, Referring Multi-Object Tracking (RMOT) involves localizing and tracking specific objects in video sequences based on language references. However, existing RMOT approaches often treat language descriptions as holistic embeddings and struggle to effectively integrate the rich semantic information contained in language expressions with visual features. This limitation is especially apparent in complex scenes requiring comprehensive understanding of both static object attributes and spatial motion information. In this paper, we propose a Cognitive Disentanglement for Referring Multi-Object Tracking (CDRMT) framework that addresses these challenges. It adapts the \"what\" and \"where\" pathways from the human visual processing system to RMOT tasks. Specifically, our framework first establishes cross-modal connections while preserving modality-specific characteristics. It then disentangles language descriptions and hierarchically injects them into object queries, refining object understanding from coarse to fine-grained semantic levels. Finally, we reconstruct language representations based on visual features, ensuring that tracked objects faithfully reflect the referring expression. Extensive experiments on different benchmark datasets demonstrate that CDRMT achieves substantial improvements over state-of-the-art methods, with average gains of 6.0% in HOTA score on Refer-KITTI and 3.2% on Refer-KITTI-V2. Our approach advances the state-of-the-art in RMOT while simultaneously providing new insights into multi-source information fusion.","authors":["Shaofeng Liang","Runwei Guan","Wangwang Lian","Daizong Liu","Xiaolou Sun","Dongming Wu","Yutao Yue","Weiping Ding","Hui Xiong"],"url":"https://arxiv.org/abs/2503.11496"}
{"created":"2025-05-20","title":"HICD: Hallucination-Inducing via Attention Dispersion for Contrastive Decoding to Mitigate Hallucinations in Large Language Models","abstract":"Large Language Models (LLMs) often generate hallucinations, producing outputs that are contextually inaccurate or factually incorrect. We introduce HICD, a novel method designed to induce hallucinations for contrastive decoding to mitigate hallucinations. Unlike existing contrastive decoding methods, HICD selects attention heads crucial to the model's prediction as inducing heads, then induces hallucinations by dispersing attention of these inducing heads and compares the hallucinated outputs with the original outputs to obtain the final result. Our approach significantly improves performance on tasks requiring contextual faithfulness, such as context completion, reading comprehension, and question answering. It also improves factuality in tasks requiring accurate knowledge recall. We demonstrate that our inducing heads selection and attention dispersion method leads to more \"contrast-effective\" hallucinations for contrastive decoding, outperforming other hallucination-inducing methods. Our findings provide a promising strategy for reducing hallucinations by inducing hallucinations in a controlled manner, enhancing the performance of LLMs in a wide range of tasks.","authors":["Xinyan Jiang","Hang Ye","Yongxin Zhu","Xiaoying Zheng","Zikang Chen","Jun Gong"],"url":"https://arxiv.org/abs/2503.12908"}
{"created":"2025-05-20","title":"Rapid and Inexpensive Inertia Tensor Estimation from a Single Object Throw","abstract":"The inertia tensor is an important parameter in many engineering fields, but measuring it can be cumbersome and involve multiple experiments or accurate and expensive equipment. We propose a method to measure the moment of inertia tensor of a rigid body from a single spinning throw, by attaching a small and inexpensive stand-alone measurement device consisting of a gyroscope, accelerometer and a reaction wheel. The method includes a compensation for the increase of moment of inertia due to adding the measurement device to the body, and additionally obtains the location of the centre of gravity of the body as an intermediate result. Experiments performed with known rigid bodies show that the mean accuracy is around 2%.","authors":["Till M. Blaha","Mike M. Kuijper","Radu Pop","Ewoud J. J. Smeur"],"url":"https://arxiv.org/abs/2503.13137"}
{"created":"2025-05-20","title":"Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding","abstract":"Understanding long video content is a complex endeavor that often relies on densely sampled frame captions or end-to-end feature selectors, yet these techniques commonly overlook the logical relationships between textual queries and visual elements. In practice, computational constraints necessitate coarse frame subsampling, a challenge analogous to \"finding a needle in a haystack.\" To address this issue, we introduce a semantics-driven search framework that reformulates keyframe selection under the paradigm of Visual Semantic-Logical Search. Specifically, we systematically define four fundamental logical dependencies: 1) spatial co-occurrence, 2) temporal proximity, 3) attribute dependency, and 4) causal order. These relations dynamically update frame sampling distributions through an iterative refinement process, enabling context-aware identification of semantically critical frames tailored to specific query requirements. Our method establishes new SOTA performance on the manually annotated benchmark in key-frame selection metrics. Furthermore, when applied to downstream video question-answering tasks, the proposed approach demonstrates the best performance gains over existing methods on LongVideoBench and Video-MME, validating its effectiveness in bridging the logical gap between textual queries and visual-temporal reasoning. The code will be publicly available.","authors":["Weiyu Guo","Ziyang Chen","Shaoguang Wang","Jianxiang He","Yijie Xu","Jinhui Ye","Ying Sun","Hui Xiong"],"url":"https://arxiv.org/abs/2503.13139"}
{"created":"2025-05-20","title":"Beyond Single Pass, Looping Through Time: KG-IRAG with Iterative Knowledge Retrieval","abstract":"Graph Retrieval-Augmented Generation (GraphRAG) has proven highly effective in enhancing the performance of Large Language Models (LLMs) on tasks that require external knowledge. By leveraging Knowledge Graphs (KGs), GraphRAG improves information retrieval for complex reasoning tasks, providing more precise and comprehensive retrieval and generating more accurate responses to QAs. However, most RAG methods fall short in addressing multi-step reasoning, particularly when both information extraction and inference are necessary. To address this limitation, this paper presents Knowledge Graph-Based Iterative Retrieval-Augmented Generation (KG-IRAG), a novel framework that integrates KGs with iterative reasoning to improve LLMs' ability to handle queries involving temporal and logical dependencies. Through iterative retrieval steps, KG-IRAG incrementally gathers relevant data from external KGs, enabling step-by-step reasoning. The proposed approach is particularly suited for scenarios where reasoning is required alongside dynamic temporal data extraction, such as determining optimal travel times based on weather conditions or traffic patterns. Experimental results show that KG-IRAG improves accuracy in complex reasoning tasks by effectively integrating external knowledge with iterative, logic-based retrieval. Additionally, three new datasets: weatherQA-Irish, weatherQA-Sydney, and trafficQA-TFNSW, are formed to evaluate KG-IRAG's performance, demonstrating its potential beyond traditional RAG applications.","authors":["Ruiyi Yang","Hao Xue","Imran Razzak","Hakim Hacid","Flora D. Salim"],"url":"https://arxiv.org/abs/2503.14234"}
{"created":"2025-05-20","title":"Quantization-Free Autoregressive Action Transformer","abstract":"Current transformer-based imitation learning approaches introduce discrete action representations and train an autoregressive transformer decoder on the resulting latent code. However, the initial quantization breaks the continuous structure of the action space thereby limiting the capabilities of the generative model. We propose a quantization-free method instead that leverages Generative Infinite-Vocabulary Transformers (GIVT) as a direct, continuous policy parametrization for autoregressive transformers. This simplifies the imitation learning pipeline while achieving state-of-the-art performance on a variety of popular simulated robotics tasks. We enhance our policy roll-outs by carefully studying sampling algorithms, further improving the results.","authors":["Ziyad Sheebaelhamd","Michael Tschannen","Michael Muehlebach","Claire Vernade"],"url":"https://arxiv.org/abs/2503.14259"}
{"created":"2025-05-20","title":"XOXO: Stealthy Cross-Origin Context Poisoning Attacks against AI Coding Assistants","abstract":"AI coding assistants are widely used for tasks like code generation. These tools now require large and complex contexts, automatically sourced from various origins$\\unicode{x2014}$across files, projects, and contributors$\\unicode{x2014}$forming part of the prompt fed to underlying LLMs. This automatic context-gathering introduces new vulnerabilities, allowing attackers to subtly poison input to compromise the assistant's outputs, potentially generating vulnerable code or introducing critical errors. We propose a novel attack, Cross-Origin Context Poisoning (XOXO), that is challenging to detect as it relies on adversarial code modifications that are semantically equivalent. Traditional program analysis techniques struggle to identify these perturbations since the semantics of the code remains correct, making it appear legitimate. This allows attackers to manipulate coding assistants into producing incorrect outputs, while shifting the blame to the victim developer. We introduce a novel, task-agnostic, black-box attack algorithm GCGS that systematically searches the transformation space using a Cayley Graph, achieving a 75.72% attack success rate on average across five tasks and eleven models, including GPT 4.1 and Claude 3.5 Sonnet v2 used by popular AI coding assistants. Furthermore, defenses like adversarial fine-tuning are ineffective against our attack, underscoring the need for new security measures in LLM-powered coding tools.","authors":["Adam \\v{S}torek","Mukur Gupta","Noopur Bhatt","Aditya Gupta","Janie Kim","Prashast Srivastava","Suman Jana"],"url":"https://arxiv.org/abs/2503.14281"}
{"created":"2025-05-20","title":"Higher-Order Graphon Neural Networks: Approximation and Cut Distance","abstract":"Graph limit models, like graphons for limits of dense graphs, have recently been used to study size transferability of graph neural networks (GNNs). While most literature focuses on message passing GNNs (MPNNs), in this work we attend to the more powerful higher-order GNNs. First, we extend the $k$-WL test for graphons (B\\\"oker, 2023) to the graphon-signal space and introduce signal-weighted homomorphism densities as a key tool. As an exemplary focus, we generalize Invariant Graph Networks (IGNs) to graphons, proposing Invariant Graphon Networks (IWNs) defined via a subset of the IGN basis corresponding to bounded linear operators. Even with this restricted basis, we show that IWNs of order $k$ are at least as powerful as the $k$-WL test, and we establish universal approximation results for graphon-signals in $L^p$ distances. This significantly extends the prior work of Cai & Wang (2022), showing that IWNs--a subset of their IGN-small--retain effectively the same expressivity as the full IGN basis in the limit. In contrast to their approach, our blueprint of IWNs also aligns better with the geometry of graphon space, for example facilitating comparability to MPNNs. We highlight that, while typical higher-order GNNs are discontinuous w.r.t. cut distance--which causes their lack of convergence and is inherently tied to the definition of $k$-WL--transferability remains achievable.","authors":["Daniel Herbst","Stefanie Jegelka"],"url":"https://arxiv.org/abs/2503.14338"}
{"created":"2025-05-20","title":"Unifying Text Semantics and Graph Structures for Temporal Text-attributed Graphs with Large Language Models","abstract":"Temporal graph neural networks (TGNNs) have shown remarkable performance in temporal graph modeling. However, real-world temporal graphs often possess rich textual information, giving rise to temporal text-attributed graphs (TTAGs). Such combination of dynamic text semantics and evolving graph structures introduces heightened complexity. Existing TGNNs embed texts statically and rely heavily on encoding mechanisms that biasedly prioritize structural information, overlooking the temporal evolution of text semantics and the essential interplay between semantics and structures for synergistic reinforcement. To tackle these issues, we present \\textbf{CROSS}, a flexible framework that seamlessly extends existing TGNNs for TTAG modeling. CROSS is designed by decomposing the TTAG modeling process into two phases: (i) temporal semantics extraction; and (ii) semantic-structural information unification. The key idea is to advance the large language models (LLMs) to dynamically extract the temporal semantics in text space and then generate cohesive representations unifying both semantics and structures. Specifically, we propose a Temporal Semantics Extractor in the CROSS framework, which empowers LLMs to offer the temporal semantic understanding of node's evolving contexts of textual neighborhoods, facilitating semantic dynamics. Subsequently, we introduce the Semantic-structural Co-encoder, which collaborates with the above Extractor for synthesizing illuminating representations by jointly considering both semantic and structural information while encouraging their mutual reinforcement. Extensive experiments show that CROSS achieves state-of-the-art results on four public datasets and one industrial dataset, with 24.7% absolute MRR gain on average in temporal link prediction and 3.7% AUC gain in node classification of industrial application.","authors":["Siwei Zhang","Yun Xiong","Yateng Tang","Xi Chen","Zian Jia","Zehao Gu","Jiarong Xu","Jiawei Zhang"],"url":"https://arxiv.org/abs/2503.14411"}
{"created":"2025-05-20","title":"Redefining non-IID Data in Federated Learning for Computer Vision Tasks: Migrating from Labels to Embeddings for Task-Specific Data Distributions","abstract":"Federated Learning (FL) represents a paradigm shift in distributed machine learning (ML), enabling clients to train models collaboratively while keeping their raw data private. This paradigm shift from traditional centralized ML introduces challenges due to the non-iid (non-independent and identically distributed) nature of data across clients, significantly impacting FL's performance. Existing literature, predominantly model data heterogeneity by imposing label distribution skew across clients. In this paper, we show that label distribution skew fails to fully capture the real-world data heterogeneity among clients in computer vision tasks beyond classification. Subsequently, we demonstrate that current approaches overestimate FL's performance by relying on label/class distribution skew, exposing an overlooked gap in the literature. By utilizing pre-trained deep neural networks to extract task-specific data embeddings, we define task-specific data heterogeneity through the lens of each vision task and introduce a new level of data heterogeneity called embedding-based data heterogeneity. Our methodology involves clustering data points based on embeddings and distributing them among clients using the Dirichlet distribution. Through extensive experiments, we evaluate the performance of different FL methods under our revamped notion of data heterogeneity, introducing new benchmark performance measures to the literature. We further unveil a series of open research directions that can be pursued.","authors":["Kasra Borazjani","Payam Abdisarabshali","Naji Khosravan","Seyyedali Hosseinalipour"],"url":"https://arxiv.org/abs/2503.14553"}
{"created":"2025-05-20","title":"SocialJax: An Evaluation Suite for Multi-agent Reinforcement Learning in Sequential Social Dilemmas","abstract":"Sequential social dilemmas pose a significant challenge in the field of multi-agent reinforcement learning (MARL), requiring environments that accurately reflect the tension between individual and collective interests. Previous benchmarks and environments, such as Melting Pot, provide an evaluation protocol that measures generalization to new social partners in various test scenarios. However, running reinforcement learning algorithms in traditional environments requires substantial computational resources. In this paper, we introduce SocialJax, a suite of sequential social dilemma environments and algorithms implemented in JAX. JAX is a high-performance numerical computing library for Python that enables significant improvements in operational efficiency. Our experiments demonstrate that the SocialJax training pipeline achieves at least 50\\texttimes{} speed-up in real-time performance compared to Melting Pot RLlib baselines. Additionally, we validate the effectiveness of baseline algorithms within SocialJax environments. Finally, we use Schelling diagrams to verify the social dilemma properties of these environments, ensuring that they accurately capture the dynamics of social dilemmas.","authors":["Zihao Guo","Shuqing Shi","Richard Willis","Tristan Tomilin","Joel Z. Leibo","Yali Du"],"url":"https://arxiv.org/abs/2503.14576"}
{"created":"2025-05-20","title":"SEEK: Self-adaptive Explainable Kernel For Nonstationary Gaussian Processes","abstract":"Gaussian processes (GPs) are powerful probabilistic models that define flexible priors over functions, offering strong interpretability and uncertainty quantification. However, GP models often rely on simple, stationary kernels which can lead to suboptimal predictions and miscalibrated uncertainty estimates, especially in nonstationary real-world applications. In this paper, we introduce SEEK, a novel class of learnable kernels to model complex, nonstationary functions via GPs. Inspired by artificial neurons, SEEK is derived from first principles to ensure symmetry and positive semi-definiteness, key properties of valid kernels. The proposed method achieves flexible and adaptive nonstationarity by learning a mapping from a set of base kernels. Compared to existing techniques, our approach is more interpretable and much less prone to overfitting. We conduct comprehensive sensitivity analyses and comparative studies to demonstrate that our approach is not only robust to many of its design choices, but also outperforms existing stationary/nonstationary kernels in both mean prediction accuracy and uncertainty quantification.","authors":["Nima Negarandeh","Carlos Mora","Ramin Bostanabad"],"url":"https://arxiv.org/abs/2503.14785"}
{"created":"2025-05-20","title":"Continual Multimodal Contrastive Learning","abstract":"Multimodal contrastive learning (MCL) advances in aligning different modalities and generating multimodal representations in a joint space. By leveraging contrastive learning across diverse modalities, large-scale multimodal data enhances representational quality. However, a critical yet often overlooked challenge remains: multimodal data is rarely collected in a single process, and training from scratch is computationally expensive. Instead, emergent multimodal data can be used to optimize existing models gradually, \\textit{i.e.}, models are trained on a sequence of modality pair data. We define this problem as Continual Multimodal Contrastive Learning (CMCL), an underexplored yet crucial research direction at the intersection of multimodal and continual learning. In this paper, we formulate CMCL through two specialized principles of stability and plasticity. We theoretically derive a novel optimization-based method, which projects updated gradients from dual sides onto subspaces where any gradient is prevented from interfering with the previously learned knowledge. Two upper bounds provide theoretical insights on both stability and plasticity in our solution. Beyond our theoretical contributions, we conduct experiments on multiple datasets by comparing our method against advanced continual learning baselines. The empirical results further support our claims and demonstrate the efficacy of our method. The code will be publicly available.","authors":["Xiaohao Liu","Xiaobo Xia","See-Kiong Ng","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2503.14963"}
{"created":"2025-05-20","title":"Control, Optimal Transport and Neural Differential Equations in Supervised Learning","abstract":"We study the fundamental computational problem of approximating optimal transport (OT) equations using neural differential equations (Neural ODEs). More specifically, we develop a novel framework for approximating unbalanced optimal transport (UOT) in the continuum using Neural ODEs. By generalizing a discrete UOT problem with Pearson divergence, we constructively design vector fields for Neural ODEs that converge to the true UOT dynamics, thereby advancing the mathematical foundations of computational transport and machine learning. To this end, we design a numerical scheme inspired by the Sinkhorn algorithm to solve the corresponding minimization problem and rigorously prove its convergence, providing explicit error estimates. From the obtained numerical solutions, we derive vector fields defining the transport dynamics and construct the corresponding transport equation.","authors":["Minh-Nhat Phung","Minh-Binh Tran"],"url":"https://arxiv.org/abs/2503.15105"}
{"created":"2025-05-20","title":"Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning","abstract":"Physical AI systems need to perceive, understand, and perform complex actions in the physical world. In this paper, we present the Cosmos-Reason1 models that can understand the physical world and generate appropriate embodied decisions (e.g., next step action) in natural language through long chain-of-thought reasoning processes. We begin by defining key capabilities for Physical AI reasoning, with a focus on physical common sense and embodied reasoning. To represent physical common sense, we use a hierarchical ontology that captures fundamental knowledge about space, time, and physics. For embodied reasoning, we rely on a two-dimensional ontology that generalizes across different physical embodiments. Building on these capabilities, we develop two multimodal large language models, Cosmos-Reason1-7B and Cosmos-Reason1-56B. We curate data and train our models in two stages: Physical AI supervised fine-tuning (SFT) and Physical AI reinforcement learning (RL). To evaluate our models, we build comprehensive benchmarks for physical common sense and embodied reasoning according to our ontologies. Evaluation results show that Physical AI SFT and RL bring significant improvements. To facilitate the development of Physical AI, we make our code and pre-trained models available under the NVIDIA Open Model License at https://github.com/nvidia-cosmos/cosmos-reason1.","authors":["NVIDIA",":","Alisson Azzolini","Junjie Bai","Hannah Brandon","Jiaxin Cao","Prithvijit Chattopadhyay","Huayu Chen","Jinju Chu","Yin Cui","Jenna Diamond","Yifan Ding","Liang Feng","Francesco Ferroni","Rama Govindaraju","Jinwei Gu","Siddharth Gururani","Imad El Hanafi","Zekun Hao","Jacob Huffman","Jingyi Jin","Brendan Johnson","Rizwan Khan","George Kurian","Elena Lantz","Nayeon Lee","Zhaoshuo Li","Xuan Li","Maosheng Liao","Tsung-Yi Lin","Yen-Chen Lin","Ming-Yu Liu","Xiangyu Lu","Alice Luo","Andrew Mathau","Yun Ni","Lindsey Pavao","Wei Ping","David W. Romero","Misha Smelyanskiy","Shuran Song","Lyne Tchapmi","Andrew Z. Wang","Boxin Wang","Haoxiang Wang","Fangyin Wei","Jiashu Xu","Yao Xu","Dinghao Yang","Xiaodong Yang","Zhuolin Yang","Jingxu Zhang","Xiaohui Zeng","Zhe Zhang"],"url":"https://arxiv.org/abs/2503.15558"}
{"created":"2025-05-20","title":"Detecting LLM-Generated Peer Reviews","abstract":"The integrity of peer review is fundamental to scientific progress, but the rise of large language models (LLMs) has introduced concerns that some reviewers may rely on these tools to generate reviews rather than writing them independently. Although some venues have banned LLM-assisted reviewing, enforcement remains difficult as existing detection tools cannot reliably distinguish between fully generated reviews and those merely polished with AI assistance. In this work, we address the challenge of detecting LLM-generated reviews. We consider the approach of performing indirect prompt injection via the paper's PDF, prompting the LLM to embed a covert watermark in the generated review, and subsequently testing for presence of the watermark in the review. We identify and address several pitfalls in na\\\"ive implementations of this approach. Our primary contribution is a rigorous watermarking and detection framework that offers strong statistical guarantees. Specifically, we introduce watermarking schemes and hypothesis tests that control the family-wise error rate across multiple reviews, achieving higher statistical power than standard corrections such as Bonferroni, while making no assumptions about the nature of human-written reviews. We explore multiple indirect prompt injection strategies--including font-based embedding and obfuscated prompts--and evaluate their effectiveness under various reviewer defense scenarios. Our experiments find high success rates in watermark embedding across various LLMs. We also empirically find that our approach is resilient to common reviewer defenses, and that the bounds on error rates in our statistical tests hold in practice. In contrast, we find that Bonferroni-style corrections are too conservative to be useful in this setting.","authors":["Vishisht Rao","Aounon Kumar","Himabindu Lakkaraju","Nihar B. Shah"],"url":"https://arxiv.org/abs/2503.15772"}
{"created":"2025-05-20","title":"Palatable Conceptions of Disembodied Being: Terra Incognita in the Space of Possible Minds","abstract":"Is it possible to articulate a conception of consciousness that is compatible with the exotic characteristics of contemporary, disembodied AI systems, and that can stand up to philosophical scrutiny? How would subjective time and selfhood show up for an entity that conformed to such a conception? Trying to answer these questions, even metaphorically, stretches the language of consciousness to breaking point. Ultimately, the attempt yields something like emptiness, in the Buddhist sense, and helps to undermine our dualistic inclinations towards subjectivity and selfhood.","authors":["Murray Shanahan"],"url":"https://arxiv.org/abs/2503.16348"}
{"created":"2025-05-20","title":"System Identification Under Bounded Noise: Optimal Rates Beyond Least Squares","abstract":"System identification is a fundamental problem in control and learning, particularly in high-stakes applications where data efficiency is critical. Classical approaches, such as the ordinary least squares estimator (OLS), achieve an $O(1/\\sqrt{T})$ convergence rate under Gaussian noise assumptions, where $T$ is the number of samples. This rate has been shown to match the lower bound. However, in many practical scenarios, noise is known to be bounded, opening the possibility of improving sample complexity. In this work, we establish the minimax lower bound for system identification under bounded noise, proving that the $O(1/T)$ convergence rate is indeed optimal. We further demonstrate that OLS remains limited to an $\\Omega(1/\\sqrt{T})$ convergence rate, making it fundamentally suboptimal in the presence of bounded noise. Finally, we instantiate two natural variations of OLS that obtain the optimal sample complexity.","authors":["Xiong Zeng","Jing Yu","Necmiye Ozay"],"url":"https://arxiv.org/abs/2503.16817"}
{"created":"2025-05-20","title":"CP-NCBF: A Conformal Prediction-based Approach to Synthesize Verified Neural Control Barrier Functions","abstract":"Control Barrier Functions (CBFs) are a practical approach for designing safety-critical controllers, but constructing them for arbitrary nonlinear dynamical systems remains a challenge. Recent efforts have explored learning-based methods, such as neural CBFs (NCBFs), to address this issue. However, ensuring the validity of NCBFs is difficult due to potential learning errors. In this letter, we propose a novel framework that leverages split-conformal prediction to generate formally verified neural CBFs with probabilistic guarantees based on a user-defined error rate, referred to as CP-NCBF. Unlike existing methods that impose Lipschitz constraints on neural CBF-leading to scalability limitations and overly conservative safe sets--our approach is sample-efficient, scalable, and results in less restrictive safety regions. We validate our framework through case studies on obstacle avoidance in autonomous driving and geo-fencing of aerial vehicles, demonstrating its ability to generate larger and less conservative safe sets compared to conventional techniques.","authors":["Manan Tayal","Aditya Singh","Pushpak Jagtap","Shishir Kolathaya"],"url":"https://arxiv.org/abs/2503.17395"}
{"created":"2025-05-20","title":"DeLoRA: Decoupling Angles and Strength in Low-rank Adaptation","abstract":"Parameter-Efficient FineTuning (PEFT) methods have recently gained significant popularity thanks to the widespread availability of large-scale pretrained models. These methods allow for quick adaptation to downstream tasks with minimal computational cost. However, popular finetuning methods such as LoRA exhibit limited robustness when it comes to hyperparameter choices or extended training regimes, preventing optimal out-of-the-box performance. In contrast, bounded approaches, such as ETHER, provide greater robustness but are limited to extremely low-rank adaptations and fixed-strength transformations, reducing their adaptation expressive power. In this work, we propose Decoupled Low-rank Adaptation (DeLoRA), a novel finetuning method that normalizes and scales learnable low-rank matrices. By bounding the distance of the transformation, DeLoRA effectively decouples the angular learning from the adaptation strength, enhancing robustness without compromising performance. Through evaluations on subject-driven image generation, natural language understanding, and instruction tuning, we show that DeLoRA matches or surpasses performance of competing PEFT methods, while exhibiting stronger robustness. Code is available at https://github.com/ExplainableML/DeLoRA.","authors":["Massimo Bini","Leander Girrbach","Zeynep Akata"],"url":"https://arxiv.org/abs/2503.18225"}
{"created":"2025-05-20","title":"Severing Spurious Correlations with Data Pruning","abstract":"Deep neural networks have been shown to learn and rely on spurious correlations present in the data that they are trained on. Reliance on such correlations can cause these networks to malfunction when deployed in the real world, where these correlations may no longer hold. To overcome the learning of and reliance on such correlations, recent studies propose approaches that yield promising results. These works, however, study settings where the strength of the spurious signal is significantly greater than that of the core, invariant signal, making it easier to detect the presence of spurious features in individual training samples and allow for further processing. In this paper, we identify new settings where the strength of the spurious signal is relatively weaker, making it difficult to detect any spurious information while continuing to have catastrophic consequences. We also discover that spurious correlations are learned primarily due to only a handful of all the samples containing the spurious feature and develop a novel data pruning technique that identifies and prunes small subsets of the training data that contain these samples. Our proposed technique does not require inferred domain knowledge, information regarding the sample-wise presence or nature of spurious information, or human intervention. Finally, we show that such data pruning attains state-of-the-art performance on previously studied settings where spurious information is identifiable.","authors":["Varun Mulchandani","Jung-Eun Kim"],"url":"https://arxiv.org/abs/2503.18258"}
{"created":"2025-05-20","title":"CQ-DINO: Mitigating Gradient Dilution via Category Queries for Vast Vocabulary Object Detection","abstract":"With the exponential growth of data, traditional object detection methods are increasingly struggling to handle vast vocabulary object detection tasks effectively. We analyze two key limitations of classification-based detectors: positive gradient dilution, where rare positive categories receive insufficient learning signals, and hard negative gradient dilution, where discriminative gradients are overwhelmed by numerous easy negatives. To address these challenges, we propose CQ-DINO, a category query-based object detection framework that reformulates classification as a contrastive task between object queries and learnable category queries. Our method introduces image-guided query selection, which reduces the negative space by adaptively retrieving top-K relevant categories per image via cross-attention, thereby rebalancing gradient distributions and facilitating implicit hard example mining. Furthermore, CQ-DINO flexibly integrates explicit hierarchical category relationships in structured datasets (e.g., V3Det) or learns implicit category correlations via self-attention in generic datasets (e.g., COCO). Experiments demonstrate that CQ-DINO achieves superior performance on the challenging V3Det benchmark (surpassing previous methods by 2.1% AP) while maintaining competitiveness in COCO. Our work provides a scalable solution for real-world detection systems requiring wide category coverage. The code is publicly at https://github.com/RedAIGC/CQ-DINO.","authors":["Zhichao Sun","Huazhang Hu","Yidong Ma","Gang Liu","Nemo Chen","Xu Tang","Yao Hu","Yongchao Xu"],"url":"https://arxiv.org/abs/2503.18430"}
{"created":"2025-05-20","title":"Long-Context Autoregressive Video Modeling with Next-Frame Prediction","abstract":"Long-context video modeling is essential for enabling generative models to function as world simulators, as they must maintain temporal coherence over extended time spans. However, most existing models are trained on short clips, limiting their ability to capture long-range dependencies, even with test-time extrapolation. While training directly on long videos is a natural solution, the rapid growth of vision tokens makes it computationally prohibitive. To support exploring efficient long-context video modeling, we first establish a strong autoregressive baseline called Frame AutoRegressive (FAR). FAR models temporal dependencies between continuous frames, converges faster than video diffusion transformers, and outperforms token-level autoregressive models. Based on this baseline, we observe context redundancy in video autoregression. Nearby frames are critical for maintaining temporal consistency, whereas distant frames primarily serve as context memory. To eliminate this redundancy, we propose the long short-term context modeling using asymmetric patchify kernels, which apply large kernels to distant frames to reduce redundant tokens, and standard kernels to local frames to preserve fine-grained detail. This significantly reduces the training cost of long videos. Our method achieves state-of-the-art results on both short and long video generation, providing an effective baseline for long-context autoregressive video modeling.","authors":["Yuchao Gu","Weijia Mao","Mike Zheng Shou"],"url":"https://arxiv.org/abs/2503.19325"}
{"created":"2025-05-20","title":"UB-Mesh: a Hierarchically Localized nD-FullMesh Datacenter Network Architecture","abstract":"As the Large-scale Language Models (LLMs) continue to scale, the requisite computational power and bandwidth escalate. To address this, we introduce UB-Mesh, a novel AI datacenter network architecture designed to enhance scalability, performance, cost-efficiency and availability. Unlike traditional datacenters that provide symmetrical node-to-node bandwidth, UB-Mesh employs a hierarchically localized nD-FullMesh network topology. This design fully leverages the data locality of LLM training, prioritizing short-range, direct interconnects to minimize data movement distance and reduce switch usage.","authors":["Heng Liao","Bingyang Liu","Xianping Chen","Zhigang Guo","Chuanning Cheng","Jianbing Wang","Xiangyu Chen","Peng Dong","Rui Meng","Wenjie Liu","Zhe Zhou","Ziyang Zhang","Yuhang Gai","Cunle Qian","Yi Xiong","Zhongwu Cheng","Jing Xia","Yuli Ma","Xi Chen","Wenhua Du","Shizhong Xiao","Chungang Li","Yong Qin","Liudong Xiong","Zhou Yu","Lv Chen","Lei Chen","Buyun Wang","Pei Wu","Junen Gao","Xiaochu Li","Jian He","Shizhuan Yan","Bill McColl"],"url":"https://arxiv.org/abs/2503.20377"}
{"created":"2025-05-20","title":"MoQa: Rethinking MoE Quantization with Multi-stage Data-model Distribution Awareness","abstract":"With the advances in artificial intelligence, Mix-of-Experts (MoE) has become the main form of Large Language Models (LLMs), and its demand for model compression is increasing. Quantization is an effective method that not only compresses the models but also significantly accelerates their performance. Existing quantization methods have gradually shifted the focus from parameter scaling to the analysis of data distributions. However, their analysis is designed for dense LLMs, which are suboptimal for MoE quantization, due to MoEs' complex data-model distribution. To address this problem, we decouple the complexity of MoEs' data-model distribution into a multi-stage analysis and reveal MoEs' inherent dynamics. The analysis results show that the expert performance of MoE varies dynamically both within and across data distributions. Based on these, we design two quantization strategies with data-model distribution awareness and integrate them into an end-to-end framework for MoE quantization, which is named MoQa. MoQa uses an expert-level mix-precision base quantization with distribution awareness. Moreover, MoQa uses a channel-level quantization adjustment to dynamically adjust expert performance to adapt to novel distributions. Experiments show that MoQa's base quantization achieves a 0.49~8.51 PPL decrease on known distributions. With the adjustments, MoQa achieves a 2.74~6.44 PPL decrease and 1.85%~3.77% average accuracy improvements on novel distributions. We believe MoQa will play a role in future MoE construction, optimization, and compression.","authors":["Zihao Zheng","Xiuping Cui","Size Zheng","Maoliang Li","Jiayu Chen","Yun Liang","Xiang Chen"],"url":"https://arxiv.org/abs/2503.21135"}
{"created":"2025-05-20","title":"DynamiCtrl: Rethinking the Basic Structure and the Role of Text for High-quality Human Image Animation","abstract":"With diffusion transformer (DiT) excelling in video generation, its use in specific tasks has drawn increasing attention. However, adapting DiT for pose-guided human image animation faces two core challenges: (a) existing U-Net-based pose control methods may be suboptimal for the DiT backbone; and (b) removing text guidance, as in previous approaches, often leads to semantic loss and model degradation. To address these issues, we propose DynamiCtrl, a novel framework for human animation in video DiT architecture. Specifically, we use a shared VAE encoder for human images and driving poses, unifying them into a common latent space, maintaining pose fidelity, and eliminating the need for an expert pose encoder during video denoising. To integrate pose control into the DiT backbone effectively, we propose a novel Pose-adaptive Layer Norm model. It injects normalized pose features into the denoising process via conditioning on visual tokens, enabling seamless and scalable pose control across DiT blocks. Furthermore, to overcome the shortcomings of text removal, we introduce the \"Joint-text\" paradigm, which preserves the role of text embeddings to provide global semantic context. Through full-attention blocks, image and pose features are aligned with text features, enhancing semantic consistency, leveraging pretrained knowledge, and enabling multi-level control. Experiments verify the superiority of DynamiCtrl on benchmark and self-collected data (e.g., achieving the best LPIPS of 0.166), demonstrating strong character control and high-quality synthesis. The project page is available at https://gulucaptain.github.io/DynamiCtrl/.","authors":["Haoyu Zhao","Zhongang Qi","Cong Wang","Qingping Zheng","Guansong Lu","Fei Chen","Hang Xu","Zuxuan Wu"],"url":"https://arxiv.org/abs/2503.21246"}
{"created":"2025-05-20","title":"Challenging the Boundaries of Reasoning: An Olympiad-Level Math Benchmark for Large Language Models","abstract":"In recent years, the rapid development of large reasoning models has resulted in the saturation of existing benchmarks for evaluating mathematical reasoning, highlighting the urgent need for more challenging and rigorous evaluation frameworks. To address this gap, we introduce OlymMATH, a novel Olympiad-level mathematical benchmark, designed to rigorously test the complex reasoning capabilities of LLMs. OlymMATH features 200 meticulously curated problems, each manually verified and available in parallel English and Chinese versions. The problems are systematically organized into two distinct difficulty tiers: (1) AIME-level problems (easy) that establish a baseline for mathematical reasoning assessment, and (2) significantly more challenging problems (hard) designed to push the boundaries of current state-of-the-art models. In our benchmark, these problems span four core mathematical fields, each including a verifiable numerical solution to enable objective, rule-based evaluation. Empirical results underscore the significant challenge presented by OlymMATH, with state-of-the-art models including DeepSeek-R1, OpenAI's o3-mini and Gemini 2.5 Pro Exp demonstrating notably limited accuracy on the hard subset. Furthermore, the benchmark facilitates comprehensive bilingual assessment of mathematical reasoning abilities-a critical dimension that remains largely unaddressed in mainstream mathematical reasoning benchmarks. We release the benchmark, evaluation code, detailed results and a data visualization tool at https://github.com/RUCAIBox/OlymMATH.","authors":["Haoxiang Sun","Yingqian Min","Zhipeng Chen","Wayne Xin Zhao","Lei Fang","Zheng Liu","Zhongyuan Wang","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2503.21380"}
{"created":"2025-05-20","title":"Fair PCA, One Component at a Time","abstract":"The Min-Max Fair PCA problem seeks a low-rank representation of multi-group data such that the the approximation error is as balanced as possible across groups. Existing approaches to this problem return a rank-$d$ fair subspace, but lack the fundamental containment property of standard PCA: each rank-$d$ PCA subspace should contain all lower-rank PCA subspaces. To fill this gap, we define fair principal components as directions that minimize the maximum group-wise reconstruction error, subject to orthogonality with previously selected components, and we introduce an iterative method to compute them. This approach preserves the containment property of standard PCA, and reduces to standard \\pca for data with a single group. We analyze the theoretical properties of our method and show empirically that it outperforms existing approaches to Min-Max Fair PCA.","authors":["Antonis Matakos","Martino Ciaperoni","Heikki Mannila"],"url":"https://arxiv.org/abs/2503.21563"}
{"created":"2025-05-20","title":"ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation","abstract":"Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely primarily on parametric knowledge, limiting factual accuracy. While recent works equip reinforcement learning (RL)-based LRMs with retrieval capabilities, they suffer from overthinking and lack robustness in reasoning, reducing their effectiveness in question answering (QA) tasks. To address this, we propose ReaRAG, a factuality-enhanced reasoning model that explores diverse queries without excessive iterations. Our solution includes a novel data construction framework with an upper bound on the reasoning chain length. Specifically, we first leverage an LRM to generate deliberate thinking, then select an action from a predefined action space (Search and Finish). For Search action, a query is executed against the RAG engine, where the result is returned as observation to guide reasoning steps later. This process iterates until a Finish action is chosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach outperforms existing baselines on multi-hop QA. Further analysis highlights its strong reflective ability to recognize errors and refine its reasoning trajectory. Our study enhances LRMs' factuality while effectively integrating robust reasoning for Retrieval-Augmented Generation (RAG).","authors":["Zhicheng Lee","Shulin Cao","Jinxin Liu","Jiajie Zhang","Weichuan Liu","Xiaoyin Che","Lei Hou","Juanzi Li"],"url":"https://arxiv.org/abs/2503.21729"}
{"created":"2025-05-20","title":"3DGen-Bench: Comprehensive Benchmark Suite for 3D Generative Models","abstract":"3D generation is experiencing rapid advancements, while the development of 3D evaluation has not kept pace. How to keep automatic evaluation equitably aligned with human perception has become a well-recognized challenge. Recent advances in the field of language and image generation have explored human preferences and showcased respectable fitting ability. However, the 3D domain still lacks such a comprehensive preference dataset over generative models. To mitigate this absence, we develop 3DGen-Arena, an integrated platform in a battle manner. Then, we carefully design diverse text and image prompts and leverage the arena platform to gather human preferences from both public users and expert annotators, resulting in a large-scale multi-dimension human preference dataset 3DGen-Bench. Using this dataset, we further train a CLIP-based scoring model, 3DGen-Score, and a MLLM-based automatic evaluator, 3DGen-Eval. These two models innovatively unify the quality evaluation of text-to-3D and image-to-3D generation, and jointly form our automated evaluation system with their respective strengths. Extensive experiments demonstrate the efficacy of our scoring model in predicting human preferences, exhibiting a superior correlation with human ranks compared to existing metrics. We believe that our 3DGen-Bench dataset and automated evaluation system will foster a more equitable evaluation in the field of 3D generation, further promoting the development of 3D generative models and their downstream applications.","authors":["Yuhan Zhang","Mengchen Zhang","Tong Wu","Tengfei Wang","Gordon Wetzstein","Dahua Lin","Ziwei Liu"],"url":"https://arxiv.org/abs/2503.21745"}
{"created":"2025-05-20","title":"ImF: Implicit Fingerprint for Large Language Models","abstract":"Training large language models (LLMs) is resource-intensive and expensive, making protecting intellectual property (IP) for LLMs crucial. Recently, embedding fingerprints into LLMs has emerged as a prevalent method for establishing model ownership. However, existing fingerprinting techniques typically embed identifiable patterns with weak semantic coherence, resulting in fingerprints that significantly differ from the natural question-answering (QA) behavior inherent to LLMs. This discrepancy undermines the stealthiness of the embedded fingerprints and makes them vulnerable to adversarial attacks. In this paper, we first demonstrate the critical vulnerability of existing fingerprint embedding methods by introducing a novel adversarial attack named Generation Revision Intervention (GRI) attack. GRI attack exploits the semantic fragility of current fingerprinting methods, effectively erasing fingerprints by disrupting their weakly correlated semantic structures. Our empirical evaluation highlights that traditional fingerprinting approaches are significantly compromised by the GRI attack, revealing severe limitations in their robustness under realistic adversarial conditions. To advance the state-of-the-art in model fingerprinting, we propose a novel model fingerprint paradigm called Implicit Fingerprints (ImF). ImF leverages steganography techniques to subtly embed ownership information within natural texts, subsequently using Chain-of-Thought (CoT) prompting to construct semantically coherent and contextually natural QA pairs. This design ensures that fingerprints seamlessly integrate with the standard model behavior, remaining indistinguishable from regular outputs and substantially reducing the risk of accidental triggering and targeted removal. We conduct a comprehensive evaluation of ImF on 15 diverse LLMs, spanning different architectures and varying scales.","authors":["Wu jiaxuan","Peng Wanli","Fu hang","Xue Yiming","Wen juan"],"url":"https://arxiv.org/abs/2503.21805"}
{"created":"2025-05-20","title":"WMCopier: Forging Invisible Image Watermarks on Arbitrary Images","abstract":"Invisible Image Watermarking is crucial for ensuring content provenance and accountability in generative AI. While Gen-AI providers are increasingly integrating invisible watermarking systems, the robustness of these schemes against forgery attacks remains poorly characterized. This is critical, as forging traceable watermarks onto illicit content leads to false attribution, potentially harming the reputation and legal standing of Gen-AI service providers who are not responsible for the content. In this work, we propose WMCopier, an effective watermark forgery attack that operates without requiring any prior knowledge of or access to the target watermarking algorithm. Our approach first models the target watermark distribution using an unconditional diffusion model, and then seamlessly embeds the target watermark into a non-watermarked image via a shallow inversion process. We also incorporate an iterative optimization procedure that refines the reconstructed image to further trade off the fidelity and forgery efficiency. Experimental results demonstrate that WMCopier effectively deceives both open-source and closed-source watermark systems (e.g., Amazon's system), achieving a significantly higher success rate than existing methods. Additionally, we evaluate the robustness of forged samples and discuss the potential defenses against our attack.","authors":["Ziping Dong","Chao Shuai","Zhongjie Ba","Peng Cheng","Zhan Qin","Qinglong Wang","Kui Ren"],"url":"https://arxiv.org/abs/2503.22330"}
{"created":"2025-05-20","title":"Why Stop at One Error? Benchmarking LLMs as Data Science Code Debuggers for Multi-Hop and Multi-Bug Errors","abstract":"LLMs are transforming software development, yet current code generation and code repair benchmarks mainly assess syntactic and functional correctness in simple, single-error cases. LLMs' capabilities to autonomously find and fix runtime logical errors in complex data science code remain largely unexplored. To address this gap, we introduce DSDBench: the Data Science Debugging Benchmark, the first benchmark for systematic evaluation of LLMs on multi-hop error tracing and multi-bug detection in data science code debugging. DSDBench adapts datasets from existing data science task benchmarks, such as DABench and MatPlotBench, featuring realistic data science debugging tasks with automatically synthesized multi-hop, multi-bug code snippets. DSDBench includes 1,117 annotated samples with 741 cause-effect error pairs and runtime error messages. Evaluations of state-of-the-art LLMs on DSDBench show significant performance gaps, highlighting challenges in debugging logical runtime errors in data science code. DSDBench offers a crucial resource to evaluate and improve LLMs' debugging and reasoning capabilities, enabling more reliable AI-assisted data science in the future. DSDBench is publicly available at github.com/KevinCL16/DSDBench.","authors":["Zhiyu Yang","Shuo Wang","Yukun Yan","Yang Deng"],"url":"https://arxiv.org/abs/2503.22388"}
{"created":"2025-05-20","title":"RARE: Retrieval-Augmented Reasoning Modeling","abstract":"Domain-specific intelligence demands specialized knowledge and sophisticated reasoning for problem-solving, posing significant challenges for large language models (LLMs) that struggle with knowledge hallucination and inadequate reasoning capabilities under constrained parameter budgets. Inspired by Bloom's Taxonomy in educational theory, we propose Retrieval-Augmented Reasoning Modeling (RARE), a novel paradigm that decouples knowledge storage from reasoning optimization. RARE externalizes domain knowledge to retrievable sources and internalizes domain-specific reasoning patterns during training. Specifically, by injecting retrieved knowledge into training prompts with masked losses, RARE transforms learning objectives from rote memorization to contextualized reasoning. It enables models to bypass parameter-intensive memorization and prioritize the development of higher-order cognitive processes. Extensive experiments demonstrate that lightweight RARE-trained models (e.g., Llama-3.1-8B) could achieve state-of-the-art performance, surpassing retrieval-augmented GPT-4 and DeepSeek-R1 up to approximately 20\\% accuracy. RARE establishes a paradigm shift where maintainable external knowledge bases synergize with compact, reasoning-optimized models, collectively driving more scalable domain-specific intelligence.","authors":["Zhengren Wang","Jiayang Yu","Dongsheng Ma","Zhe Chen","Yu Wang","Zhiyu Li","Feiyu Xiong","Yanfeng Wang","Weinan E","Linpeng Tang","Wentao Zhang"],"url":"https://arxiv.org/abs/2503.23513"}
{"created":"2025-05-20","title":"MaintainCoder: Maintainable Code Generation Under Dynamic Requirements","abstract":"Modern code generation has made significant strides in functional correctness and execution efficiency. However, these systems often overlook a critical dimension in real-world software development: \\textit{maintainability}. To handle dynamic requirements with minimal rework, we propose \\textbf{MaintainCoder} as a pioneering solution. It integrates the Waterfall model, design patterns, and multi-agent collaboration to systematically enhance cohesion, reduce coupling, achieving clear responsibility boundaries and better maintainability. We also introduce \\textbf{MaintainBench}, a benchmark comprising requirement changes and novel dynamic metrics on maintenance efforts. Experiments demonstrate that existing code generation methods struggle to meet maintainability standards when requirements evolve. In contrast, MaintainCoder improves dynamic maintainability metrics by more than 60\\% with even higher correctness of initial codes. Furthermore, while static metrics fail to accurately reflect maintainability and even contradict each other, our proposed dynamic metrics exhibit high consistency. Our work not only provides the foundation for maintainable code generation, but also highlights the need for more realistic and comprehensive code generation research.","authors":["Zhengren Wang","Rui Ling","Chufan Wang","Yongan Yu","Sizhe Wang","Zhiyu Li","Feiyu Xiong","Wentao Zhang"],"url":"https://arxiv.org/abs/2503.24260"}
{"created":"2025-05-20","title":"Effectively Controlling Reasoning Models through Thinking Intervention","abstract":"Reasoning-enhanced large language models (LLMs) explicitly generate intermediate reasoning steps prior to generating final answers, helping the model excel in complex problem-solving. In this paper, we demonstrate that this emerging generation framework offers a unique opportunity for more fine-grained control over model behavior. We propose Thinking Intervention, a novel paradigm designed to explicitly guide the internal reasoning processes of LLMs by strategically inserting or revising specific thinking tokens. We find that the Thinking Intervention paradigm enhances the capabilities of reasoning models across a wide range of tasks, including instruction following on IFEval, instruction hierarchy on SEP, and safety alignment on XSTest and SorryBench. Our results demonstrate that Thinking Intervention significantly outperforms baseline prompting approaches, achieving up to 6.7% accuracy gains in instruction-following scenarios, 15.4% improvements in reasoning about instruction hierarchies, and a 40.0% increase in refusal rates for unsafe prompts using open-source DeepSeek R1 models. Overall, our work opens a promising new research avenue for controlling reasoning LLMs.","authors":["Tong Wu","Chong Xiang","Jiachen T. Wang","G. Edward Suh","Prateek Mittal"],"url":"https://arxiv.org/abs/2503.24370"}
{"created":"2025-05-20","title":"Minimum Description Length of a Spectrum Variational Autoencoder: A Theory","abstract":"Deep neural networks trained through end-to-end learning have achieved remarkable success across various domains in the past decade. However, the end-to-end learning strategy faces two fundamental limitations: the struggle to form explainable representations in a self-supervised manner, and the inability to compress information rigorously following the Minimum Description Length (MDL) principle. In this paper, we establish a novel theory connecting these two challenges. We design the Spectrum VAE, a novel deep learning architecture whose minimum description length (MDL) can be rigorously evaluated. Then, we introduce the concept of latent dimension combinations, or what we term spiking patterns, and demonstrate that the observed spiking patterns should be as few as possible based on the training data in order for the Spectrum VAE to achieve the MDL. Finally, our theory demonstrates that when the MDL is achieved with respect to the given data distribution, the model will naturally produce explainable latent representations of the data. That is, explainable representations of the data, or understanding the data, can be achieved in a self-supervised manner simply by making the deep neural network obey the MDL principle. In our opinion, this reveals an even more profound principle: Understanding means to represent the acquired information by as small an amount of information as possible. This work is entirely theoretical and aims at inspiring future research to realize self-supervised explainable AI simply by obeying the MDL principle.","authors":["Canlin Zhang","Xiuwen Liu"],"url":"https://arxiv.org/abs/2504.00395"}
{"created":"2025-05-20","title":"Timely Trajectory Reconstruction in Finite Buffer Remote Tracking Systems","abstract":"Remote tracking systems play a critical role in applications such as IoT, monitoring, surveillance and healthcare. In such systems, maintaining both real-time state awareness (for online decision making) and accurate reconstruction of historical trajectories (for offline post-processing) are essential. While the Age of Information (AoI) metric has been extensively studied as a measure of freshness, it does not capture the accuracy with which past trajectories can be reconstructed. In this work, we investigate reconstruction error as a complementary metric to AoI, addressing the trade-off between timely updates and historical accuracy. Specifically, we consider three policies, each prioritizing different aspects of information management: Keep-Old, Keep-Fresh, and our proposed Inter-arrival-Aware dropping policy. We compare these policies in terms of impact on both AoI and reconstruction error in a remote tracking system with a finite buffer. Through theoretical analysis and numerical simulations of queueing behavior, we demonstrate that while the Keep-Fresh policy minimizes AoI, it does not necessarily minimize reconstruction error. In contrast, our proposed Inter-arrival-Aware dropping policy dynamically adjusts packet retention decisions based on generation times, achieving a balance between AoI and reconstruction error. Our results provide key insights into the design of efficient buffer management policies for resource-constrained IoT networks.","authors":["Sunjung Kang","Vishrant Tripathi","Christopher G. Brinton"],"url":"https://arxiv.org/abs/2504.00849"}
{"created":"2025-05-20","title":"Beyond Conventional Transformers: The Medical X-ray Attention (MXA) Block for Improved Multi-Label Diagnosis Using Knowledge Distillation","abstract":"Medical imaging, particularly X-ray analysis, often involves detecting multiple conditions simultaneously within a single scan, making multi-label classification crucial for real-world clinical applications. We present the Medical X-ray Attention (MXA) block, a novel attention mechanism tailored specifically to address the unique challenges of X-ray abnormality detection. The MXA block enhances traditional Multi-Head Self Attention (MHSA) by integrating a specialized module that efficiently captures both detailed local information and broader global context. To the best of our knowledge, this is the first work to propose a task-specific attention mechanism for diagnosing chest X-rays, as well as to attempt multi-label classification using an Efficient Vision Transformer (EfficientViT). By embedding the MXA block within the EfficientViT architecture and employing knowledge distillation, our proposed model significantly improves performance on the CheXpert dataset, a widely used benchmark for multi-label chest X-ray abnormality detection. Our approach achieves an area under the curve (AUC) of 0.85, an absolute improvement of 0.19 compared to our baseline model's AUC of 0.66, corresponding to a substantial approximate 233% relative improvement over random guessing (AUC = 0.5).","authors":["Amit Rand","Hadi Ibrahim"],"url":"https://arxiv.org/abs/2504.02277"}
{"created":"2025-05-20","title":"Dexterous Manipulation through Imitation Learning: A Survey","abstract":"Dexterous manipulation, which refers to the ability of a robotic hand or multi-fingered end-effector to skillfully control, reorient, and manipulate objects through precise, coordinated finger movements and adaptive force modulation, enables complex interactions similar to human hand dexterity. With recent advances in robotics and machine learning, there is a growing demand for these systems to operate in complex and unstructured environments. Traditional model-based approaches struggle to generalize across tasks and object variations due to the high dimensionality and complex contact dynamics of dexterous manipulation. Although model-free methods such as reinforcement learning (RL) show promise, they require extensive training, large-scale interaction data, and carefully designed rewards for stability and effectiveness. Imitation learning (IL) offers an alternative by allowing robots to acquire dexterous manipulation skills directly from expert demonstrations, capturing fine-grained coordination and contact dynamics while bypassing the need for explicit modeling and large-scale trial-and-error. This survey provides an overview of dexterous manipulation methods based on imitation learning, details recent advances, and addresses key challenges in the field. Additionally, it explores potential research directions to enhance IL-driven dexterous manipulation. Our goal is to offer researchers and practitioners a comprehensive introduction to this rapidly evolving domain.","authors":["Shan An","Ziyu Meng","Chao Tang","Yuning Zhou","Tengyu Liu","Fangqiang Ding","Shufang Zhang","Yao Mu","Ran Song","Wei Zhang","Zeng-Guang Hou","Hong Zhang"],"url":"https://arxiv.org/abs/2504.03515"}
{"created":"2025-05-20","title":"FAST: Federated Active Learning with Foundation Models for Communication-efficient Sampling and Training","abstract":"Federated Active Learning (FAL) has emerged as a promising framework to leverage large quantities of unlabeled data across distributed clients while preserving data privacy. However, real-world deployments remain limited by high annotation costs and communication-intensive sampling processes, particularly in a cross-silo setting, when clients possess substantial local datasets. This paper addresses the crucial question: What is the best practice to reduce communication costs in human-in-the-loop learning with minimal annotator effort? Existing FAL methods typically rely on iterative annotation processes that separate active sampling from federated updates, leading to multiple rounds of expensive communication and annotation. In response, we introduce FAST, a two-pass FAL framework that harnesses foundation models for weak labeling in a preliminary pass, followed by a refinement pass focused exclusively on the most uncertain samples. By leveraging representation knowledge from foundation models and integrating refinement steps into a streamlined workflow, FAST substantially reduces the overhead incurred by iterative active sampling. Extensive experiments on diverse medical and natural image benchmarks demonstrate that FAST outperforms existing FAL methods by an average of 4.36% while reducing communication rounds eightfold under a limited 5% labeling budget.","authors":["Haoyuan Li","Mathias Funk","Jindong Wang","Aaqib Saeed"],"url":"https://arxiv.org/abs/2504.03783"}
{"created":"2025-05-20","title":"FISH-Tuning: Enhancing PEFT Methods with Fisher Information","abstract":"The rapid growth in the parameter size of Large Language Models (LLMs) has spurred the development of Parameter-Efficient Fine-Tuning (PEFT) methods to mitigate the substantial computational costs of fine-tuning. Among these, Fisher Induced Sparse uncHanging (FISH) Mask is a selection-based PEFT technique that identifies a critical subset of pre-trained parameters using approximate Fisher information. While addition-based and reparameterization-based PEFT methods like LoRA and Adapter already fine-tune only a small number of parameters, the newly introduced parameters within these methods themselves present an opportunity for further optimization. Selectively fine-tuning only the most impactful among these new parameters could further reduce resource consumption while maintaining, or even improving, fine-tuning effectiveness. In this paper, we propose \\textbf{FISH-Tuning}, a novel approach that incorporates FISH Mask into such PEFT methods, including LoRA, Adapter, and their variants. By leveraging Fisher information to identify and update only the most significant parameters within these added or reparameterized components, FISH-Tuning aims to achieve superior performance without increasing training time or inference latency compared to the vanilla PEFT methods. Experimental results across various datasets and pre-trained models demonstrate that FISH-Tuning consistently outperforms the vanilla PEFT methods when using the same proportion of trainable parameters. Code is available at https://anonymous.4open.science/r/FISH-Tuning-6F7C.","authors":["Kang Xue","Ming Dong","Xinhui Tu","Tingting He"],"url":"https://arxiv.org/abs/2504.04050"}
{"created":"2025-05-20","title":"MInCo: Mitigating Information Conflicts in Distracted Visual Model-based Reinforcement Learning","abstract":"Existing visual model-based reinforcement learning (MBRL) algorithms with observation reconstruction often suffer from information conflicts, making it difficult to learn compact representations and hence result in less robust policies, especially in the presence of task-irrelevant visual distractions. In this paper, we first reveal that the information conflicts in current visual MBRL algorithms stem from visual representation learning and latent dynamics modeling with an information-theoretic perspective. Based on this finding, we present a new algorithm to resolve information conflicts for visual MBRL, named MInCo, which mitigates information conflicts by leveraging negative-free contrastive learning, aiding in learning invariant representation and robust policies despite noisy observations. To prevent the dominance of visual representation learning, we introduce time-varying reweighting to bias the learning towards dynamics modeling as training proceeds. We evaluate our method on several robotic control tasks with dynamic background distractions. Our experiments demonstrate that MInCo learns invariant representations against background noise and consistently outperforms current state-of-the-art visual MBRL methods. Code is available at https://github.com/ShiguangSun/minco.","authors":["Shiguang Sun","Hanbo Zhang","Zeyang Liu","Xinrui Yang","Lipeng Wan","Bing Yan","Xingyu Chen","Xuguang Lan"],"url":"https://arxiv.org/abs/2504.04164"}
{"created":"2025-05-20","title":"Error analysis of a Euler finite element scheme for Natural convection model with variable density","abstract":"In this paper, we derive first-order Euler finite element discretization schemes for a time-dependent natural convection model with variable density (NCVD). The model is governed by the variable density Navier-Stokes equations coupled with a parabolic partial differential equation that describes the evolution of temperature. Stability and error estimate for the velocity, pressure, density and temperature in $L^2$-norm are proved by using finite element approximations in space and finite differences in time. Finally, the numerical results are showed to support the theoretical analysis.","authors":["Li Hang","Chenyang Li"],"url":"https://arxiv.org/abs/2504.04381"}
{"created":"2025-05-20","title":"Right Question is Already Half the Answer: Fully Unsupervised LLM Reasoning Incentivization","abstract":"Existing methods to enhance the reasoning capability of large language models predominantly rely on supervised fine-tuning (SFT) followed by reinforcement learning (RL) on reasoning-specific data. These approaches critically depend on external supervisions--such as labeled reasoning traces, verified golden answers, or pre-trained reward models. In this work, we propose Entropy Minimized Policy Optimization (\\ours), which makes an early attempt at fully unsupervised LLM reasoning incentivization. By continuously minimizing the predictive entropy of LLMs on unlabeled questions in a latent semantic space, \\ours achieves competitive performance compared to supervised counterparts on both mathematical and free-form natural reasoning tasks. Specifically, without any supervised signals, \\ours boosts the accuracy of Qwen2.5-Math-7B Base from 30.7\\% to 48.1\\% on mathematical benchmarks and improves the accuracy of Qwen2.5-7B Base from 32.1\\% to 50.1\\% on MMLU-Pro. Primary experiments and analysis are also provided to interpret the effectiveness of \\ours. Code is available at https://github.com/QingyangZhang/EMPO.","authors":["Qingyang Zhang","Haitao Wu","Changqing Zhang","Peilin Zhao","Yatao Bian"],"url":"https://arxiv.org/abs/2504.05812"}
{"created":"2025-05-20","title":"Leveraging Robust Optimization for LLM Alignment under Distribution Shifts","abstract":"Preference alignment methods are increasingly critical for steering large language models (LLMs) to generate outputs consistent with human values. While recent approaches often rely on synthetic data generated by LLMs for scalability and cost-efficiency reasons, this reliance can introduce distribution shifts that undermine the nuanced representation of human preferences needed for desirable outputs. In this paper, we propose a novel distribution-aware optimization framework that improves preference alignment despite such shifts. Our approach first leverages well-learned classifiers to assign a calibration value to each training sample, quantifying its alignment with the target human-preferred distribution. These values are then incorporated into a robust optimization objective that minimizes the worst-case loss over regions of the data space most relevant to human preferences. By explicitly focusing optimization on the target distribution, our approach mitigates the impact of distributional mismatch and improves the generation of responses that better reflect intended values.","authors":["Mingye Zhu","Yi Liu","Zheren Fu","Yongdong Zhang","Zhendong Mao"],"url":"https://arxiv.org/abs/2504.05831"}
{"created":"2025-05-20","title":"A Scalable Approach to Clustering Embedding Projections","abstract":"Interactive visualization of embedding projections is a useful technique for understanding data and evaluating machine learning models. Labeling data within these visualizations is critical for interpretation, as labels provide an overview of the projection and guide user navigation. However, most methods for producing labels require clustering the points, which can be computationally expensive as the number of points grows. In this paper, we describe an efficient clustering approach using kernel density estimation in the projected 2D space instead of points. This algorithm can produce high-quality cluster regions from a 2D density map in a few hundred milliseconds, orders of magnitude faster than current approaches. We contribute the design of the algorithm, benchmarks, and applications that demonstrate the utility of the algorithm, including labeling and summarization.","authors":["Donghao Ren","Fred Hohman","Dominik Moritz"],"url":"https://arxiv.org/abs/2504.07285"}
{"created":"2025-05-20","title":"LSR-MCTS: Alleviating Long Range Dependency in Code Generation","abstract":"The emergence of large language models (LLMs) has significantly promoted the development of code generation task, sparking a surge in pertinent literature. Current research is hindered by redundant generation results and a tendency to overfit local patterns in the short term. Although existing studies attempt to alleviate the issue by adopting a multi-token prediction strategy, there remains limited focus on choosing the appropriate processing length for generations. By analyzing the attention between tokens during the generation process of LLMs, it can be observed that the high spikes of the attention scores typically appear at the end of lines. This insight suggests that it is reasonable to treat each line of code as a fundamental processing unit and generate them sequentially. Inspired by this, we propose the \\textbf{LSR-MCTS} algorithm, which leverages MCTS to determine the code line-by-line and select the optimal path. Further, we integrate a self-refine mechanism at each node to enhance diversity and generate higher-quality programs through error correction. Extensive experiments and comprehensive analyses on three public coding benchmarks demonstrate that our method outperforms the state-of-the-art performance approaches.","authors":["Tingwei Lu","Yangning Li","Liyuan Wang","Binghuai Lin","Jiwei Tang","Qingsong Lv","Wanshi Xu","Hai-Tao Zheng","Yinghui Li","Xin Su","Zifei Shan"],"url":"https://arxiv.org/abs/2504.07433"}
{"created":"2025-05-20","title":"SpecReason: Fast and Accurate Inference-Time Compute via Speculative Reasoning","abstract":"Recent advances in inference-time compute have significantly improved performance on complex tasks by generating long chains of thought (CoTs) using Large Reasoning Models (LRMs). However, this improved accuracy comes at the cost of high inference latency due to the length of generated reasoning sequences and the autoregressive nature of decoding. Our key insight in tackling these overheads is that LRM inference, and the reasoning that it embeds, is highly tolerant of approximations: complex tasks are typically broken down into simpler steps, each of which brings utility based on the semantic insight it provides for downstream steps rather than the exact tokens it generates. Accordingly, we introduce SpecReason, a system that automatically accelerates LRM inference by using a lightweight model to (speculatively) carry out simpler intermediate reasoning steps and reserving the costly base model only to assess (and potentially correct) the speculated outputs. Importantly, SpecReason's focus on exploiting the semantic flexibility of thinking tokens in preserving final-answer accuracy is complementary to prior speculation techniques, most notably speculative decoding, which demands token-level equivalence at each step. Across a variety of reasoning benchmarks, SpecReason achieves $1.4-3.0\\times$ speedup over vanilla LRM inference while improving accuracy by $0.4-9.0\\%$. Compared to speculative decoding without SpecReason, their combination yields an additional $8.8-58.0\\%$ latency reduction. We open-source SpecReason at https://github.com/ruipeterpan/specreason.","authors":["Rui Pan","Yinwei Dai","Zhihao Zhang","Gabriele Oliaro","Zhihao Jia","Ravi Netravali"],"url":"https://arxiv.org/abs/2504.07891"}
{"created":"2025-05-20","title":"Adaptive Control of Dubins Vehicle in the Presence of Loss of Effectiveness (Extended Version)","abstract":"The control of a Dubins Vehicle when subjected to a loss of control effectiveness in the turning rate is considered. A complex state-space representation is used to model the vehicle dynamics. An adaptive control design is proposed, with the underlying stability analysis guaranteeing closed-loop boundedness and tracking of a desired path. It is shown that a path constructed by waypoints and a minimum turn radius can be specified using a reference model which can be followed by the closed loop system. The control design utilizes the complex representation as well as a PID controller for the nominal closed-loop. How the design can be modified to ensure to ensure path following even in the presence input constraints is also discussed. Simulation studies are carried out to complement the theoretical derivations.","authors":["Daniel Maldonado Naranjo","Anuradha M. Annaswamy"],"url":"https://arxiv.org/abs/2504.08190"}
{"created":"2025-05-20","title":"Large Language Models Could Be Rote Learners","abstract":"Multiple-choice question (MCQ) benchmarks are widely used for evaluating Large Language Models (LLMs), yet their reliability is undermined by benchmark contamination. In this study, we reframe contamination as an inherent aspect of learning and seek to disentangle genuine capability acquisition from superficial memorization in LLM evaluation. First, by analyzing model performance under different memorization conditions, we uncover a counterintuitive trend: LLMs perform worse on memorized MCQs than on non-memorized ones, indicating the coexistence of two distinct learning phenomena, i.e., rote memorization and genuine capability learning. To disentangle them, we propose TrinEval, a novel evaluation framework reformulating MCQs into an alternative trinity format, reducing memorization while preserving knowledge assessment. Experiments validate TrinEval's effectiveness in reformulation, and its evaluation reveals that common LLMs may memorize by rote 20.5% of knowledge points (in MMLU on average).","authors":["Yuyang Xu","Renjun Hu","Haochao Ying","Jian Wu","Xing Shi","Wei Lin"],"url":"https://arxiv.org/abs/2504.08300"}
{"created":"2025-05-20","title":"Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset","abstract":"We introduce the Digital Twin Catalog (DTC), a new large-scale photorealistic 3D object digital twin dataset. A digital twin of a 3D object is a highly detailed, virtually indistinguishable representation of a physical object, accurately capturing its shape, appearance, physical properties, and other attributes. Recent advances in neural-based 3D reconstruction and inverse rendering have significantly improved the quality of 3D object reconstruction. Despite these advancements, there remains a lack of a large-scale, digital twin-quality real-world dataset and benchmark that can quantitatively assess and compare the performance of different reconstruction methods, as well as improve reconstruction quality through training or fine-tuning. Moreover, to democratize 3D digital twin creation, it is essential to integrate creation techniques with next-generation egocentric computing platforms, such as AR glasses. Currently, there is no dataset available to evaluate 3D object reconstruction using egocentric captured images. To address these gaps, the DTC dataset features 2,000 scanned digital twin-quality 3D objects, along with image sequences captured under different lighting conditions using DSLR cameras and egocentric AR glasses. This dataset establishes the first comprehensive real-world evaluation benchmark for 3D digital twin creation tasks, offering a robust foundation for comparing and improving existing reconstruction methods. The DTC dataset is already released at https://www.projectaria.com/datasets/dtc/ and we will also make the baseline evaluations open-source.","authors":["Zhao Dong","Ka Chen","Zhaoyang Lv","Hong-Xing Yu","Yunzhi Zhang","Cheng Zhang","Yufeng Zhu","Stephen Tian","Zhengqin Li","Geordie Moffatt","Sean Christofferson","James Fort","Xiaqing Pan","Mingfei Yan","Jiajun Wu","Carl Yuheng Ren","Richard Newcombe"],"url":"https://arxiv.org/abs/2504.08541"}
{"created":"2025-05-20","title":"ProtoECGNet: Case-Based Interpretable Deep Learning for Multi-Label ECG Classification with Contrastive Learning","abstract":"Deep learning-based electrocardiogram (ECG) classification has shown impressive performance but clinical adoption has been slowed by the lack of transparent and faithful explanations. Post hoc methods such as saliency maps may fail to reflect a model's true decision process. Prototype-based reasoning offers a more transparent alternative by grounding decisions in similarity to learned representations of real ECG segments, enabling faithful, case-based explanations. We introduce ProtoECGNet, a prototype-based deep learning model for interpretable, multi-label ECG classification. ProtoECGNet employs a structured, multi-branch architecture that reflects clinical interpretation workflows: it integrates a 1D CNN with global prototypes for rhythm classification, a 2D CNN with time-localized prototypes for morphology-based reasoning, and a 2D CNN with global prototypes for diffuse abnormalities. Each branch is trained with a prototype loss designed for multi-label learning, combining clustering, separation, diversity, and a novel contrastive loss that encourages appropriate separation between prototypes of unrelated classes while allowing clustering for frequently co-occurring diagnoses. We evaluate ProtoECGNet on all 71 diagnostic labels from the PTB-XL dataset, demonstrating competitive performance relative to state-of-the-art black-box models while providing structured, case-based explanations. To assess prototype quality, we conduct a structured clinician review of the final model's projected prototypes, finding that they are rated as representative and clear. ProtoECGNet shows that prototype learning can be effectively scaled to complex, multi-label time-series classification, offering a practical path toward transparent and trustworthy deep learning models for clinical decision support.","authors":["Sahil Sethi","David Chen","Thomas Statchen","Michael C. Burkhart","Nipun Bhandari","Bashar Ramadan","Brett Beaulieu-Jones"],"url":"https://arxiv.org/abs/2504.08713"}
{"created":"2025-05-20","title":"Mimic In-Context Learning for Multimodal Tasks","abstract":"Recently, In-context Learning (ICL) has become a significant inference paradigm in Large Multimodal Models (LMMs), utilizing a few in-context demonstrations (ICDs) to prompt LMMs for new tasks. However, the synergistic effects in multimodal data increase the sensitivity of ICL performance to the configurations of ICDs, stimulating the need for a more stable and general mapping function. Mathematically, in Transformer-based models, ICDs act as \"shift vectors\" added to the hidden states of query tokens. Inspired by this, we introduce Mimic In-Context Learning (MimIC) to learn stable and generalizable shift effects from ICDs. Specifically, compared with some previous shift vector-based methods, MimIC more strictly approximates the shift effects by integrating lightweight learnable modules into LMMs with four key enhancements: 1) inserting shift vectors after attention layers, 2) assigning a shift vector to each attention head, 3) making shift magnitude query-dependent, and 4) employing a layer-wise alignment loss. Extensive experiments on two LMMs (Idefics-9b and Idefics2-8b-base) across three multimodal tasks (VQAv2, OK-VQA, Captioning) demonstrate that MimIC outperforms existing shift vector-based methods. The code is available at https://github.com/Kamichanw/MimIC.","authors":["Yuchu Jiang","Jiale Fu","Chenduo Hao","Xinting Hu","Yingzhe Peng","Xin Geng","Xu Yang"],"url":"https://arxiv.org/abs/2504.08851"}
{"created":"2025-05-20","title":"Cartographers in Cubicles: How Training and Preferences of Mapmakers Interplay with Structures and Norms in Not-for-Profit Organizations","abstract":"Choropleth maps are a common and effective way to visualize geographic thematic data. Although cartographers have established many principles about map design, data binning and color usage, less is known about how mapmakers make individual decisions in practice. We interview 16 cartographers and geographic information systems (GIS) experts from 13 government organizations, NGOs, and federal agencies about their choropleth mapmaking decisions and workflows. We categorize our findings and report on how mapmakers follow cartographic guidelines and personal rules of thumb, collaborate with other stakeholders within and outside their organization, and how organizational structures and norms are tied to decision-making during data preparation, data analysis, data binning, map styling, and map post-processing. We find several points of variation as well as regularity across mapmakers and organizations and present takeaways to inform cartographic education and practice, including broader implications and opportunities for CSCW, HCI, and information visualization researchers and practitioners.","authors":["Arpit Narechania","Alex Endert","Clio Andris"],"url":"https://arxiv.org/abs/2504.09438"}
{"created":"2025-05-20","title":"Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws","abstract":"Large Language Models (LLMs) have demonstrated remarkable capabilities across numerous tasks, yet principled explanations for their underlying mechanisms and several phenomena, such as scaling laws, hallucinations, and related behaviors, remain elusive. In this work, we revisit the classical relationship between compression and prediction, grounded in Kolmogorov complexity and Shannon information theory, to provide deeper insights into LLM behaviors. By leveraging the Kolmogorov Structure Function and interpreting LLM compression as a two-part coding process, we offer a detailed view of how LLMs acquire and store information across increasing model and data scales -- from pervasive syntactic patterns to progressively rarer knowledge elements. Motivated by this theoretical perspective and natural assumptions inspired by Heap's and Zipf's laws, we introduce a simplified yet representative hierarchical data-generation framework called the Syntax-Knowledge model. Under the Bayesian setting, we show that prediction and compression within this model naturally lead to diverse learning and scaling behaviors of LLMs. In particular, our theoretical analysis offers intuitive and principled explanations for both data and model scaling laws, the dynamics of knowledge acquisition during training and fine-tuning, factual knowledge hallucinations in LLMs. The experimental results validate our theoretical predictions.","authors":["Zhixuan Pan","Shaowen Wang","Jian Li"],"url":"https://arxiv.org/abs/2504.09597"}
{"created":"2025-05-20","title":"MLRC-Bench: Can Language Agents Solve Machine Learning Research Challenges?","abstract":"We introduce MLRC-Bench, a benchmark designed to quantify how effectively language agents can tackle challenging Machine Learning (ML) Research Competitions, with a focus on open research problems that demand novel methodologies. Unlike prior work, e.g., AI Scientist, which evaluates the end-to-end agentic pipeline by using LLM-as-a-judge, MLRC-Bench measures the key steps of proposing and implementing novel research methods and evaluates them with rigorous protocol and objective metrics. Our curated suite of 7 competition tasks reveals significant challenges for LLM agents. Even the best-performing tested agent (gemini-exp-1206 under MLAB) closes only 9.3% of the gap between baseline and top human participant scores. Furthermore, our analysis reveals a misalignment between the LLM-judged innovation and actual performance on cutting-edge ML research problems. MLRC-Bench is a dynamic benchmark, designed to grow with new ML competitions and encourage rigorous, objective evaluations of AI research capabilities. Our leaderboard and code are available at: https://huggingface.co/spaces/launch/MLRC_Bench","authors":["Yunxiang Zhang","Muhammad Khalifa","Shitanshu Bhushan","Grant D Murphy","Lajanugen Logeswaran","Jaekyeom Kim","Moontae Lee","Honglak Lee","Lu Wang"],"url":"https://arxiv.org/abs/2504.09702"}
{"created":"2025-05-20","title":"OVERLORD: Ultimate Scaling of DataLoader for Multi-Source Large Foundation Model Training","abstract":"Modern frameworks for training large foundation models (LFMs) employ dataloaders in a data-parallel manner, with each loader processing a disjoint subset of training data. Under multisource preprocessing, two fundamental challenges exist. First, due to the quadratic computational complexity of the attention operator, the non-uniform sample distribution over data-parallel ranks leads to significant workload imbalance among dataloaders, degrading the training efficiency. Second, supporting diverse data sources requires per-dataset file access states that are redundantly replicated across parallel loaders, consuming excessive memory. This also hinders dynamic data mixing (e.g., curriculum learning) and causes redundant access/memory overhead in hybrid parallelism.","authors":["Juntao Zhao","Qi Lu","Wei Jia","Borui Wan","Lei Zuo","Junda Feng","Jianyu Jiang","Yangrui Chen","Shuaishuai Cao","Jialing He","Kaihua Jiang","Yuanzhe Hu","Shibiao Nong","Yanghua Peng","Haibin Lin","Xin Liu","Chuan Wu"],"url":"https://arxiv.org/abs/2504.09844"}
{"created":"2025-05-20","title":"TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models","abstract":"Multimodal Large Language Models (MLLMs) have shown remarkable versatility in understanding diverse multimodal data and tasks. However, these capabilities come with an increased model scale. While post-training pruning reduces model size in unimodal models, its application to MLLMs often yields limited success. Our analysis discovers that conventional methods fail to account for the unique token attributes across layers and modalities inherent to MLLMs. Inspired by this observation, we propose TAMP, a simple yet effective pruning framework tailored for MLLMs, featuring two key components: (1) Diversity-Aware Sparsity, which adjusts sparsity ratio per layer based on diversities among multimodal output tokens, preserving more parameters in high-diversity layers; and (2) Adaptive Multimodal Input Activation, which identifies representative multimodal input tokens using attention scores to guide unstructured weight pruning. We validate our method on two state-of-the-art MLLMs: LLaVA-NeXT, designed for vision-language tasks, and VideoLLaMA2, capable of processing audio, visual, and language modalities. Empirical experiments across various multimodal evaluation benchmarks demonstrate that each component of our approach substantially outperforms existing pruning techniques.","authors":["Jaewoo Lee","Keyang Xuan","Chanakya Ekbote","Sandeep Polisetty","Yi R. Fung","Paul Pu Liang"],"url":"https://arxiv.org/abs/2504.09897"}
{"created":"2025-05-20","title":"Stochastic Multigrid Minimization for Ptychographic Phase Retrieval","abstract":"We propose a novel stochastic multigrid minimization method for ptychographic phase retrieval. In our formulation, the challenging nonconvex and ill-posed inverse problem is recast as the iterative minimization of a quadratic surrogate model that majorizes the original objective function. Our general framework encompasses the Ptychographic Iterative Engine (PIE) family of algorithms. By efficiently solving the surrogate problem using a multigrid method, our approach delivers significant improvements in both convergence speed and reconstruction quality compared with conventional PIE techniques.","authors":["Borong Zhang","Qin Li","Zichao Wendy Di"],"url":"https://arxiv.org/abs/2504.10118"}
{"created":"2025-05-20","title":"On the Value of Cross-Modal Misalignment in Multimodal Representation Learning","abstract":"Multimodal representation learning, exemplified by multimodal contrastive learning (MMCL) using image-text pairs, aims to learn powerful representations by aligning cues across modalities. This approach relies on the core assumption that the exemplar image-text pairs constitute two representations of an identical concept. However, recent research has revealed that real-world datasets often exhibit cross-modal misalignment. There are two distinct viewpoints on how to address this issue: one suggests mitigating the misalignment, and the other leveraging it. We seek here to reconcile these seemingly opposing perspectives, and to provide a practical guide for practitioners. Using latent variable models we thus formalize cross-modal misalignment by introducing two specific mechanisms: Selection bias, where some semantic variables are absent in the text, and perturbation bias, where semantic variables are altered -- both leading to misalignment in data pairs. Our theoretical analysis demonstrates that, under mild assumptions, the representations learned by MMCL capture exactly the information related to the subset of the semantic variables invariant to selection and perturbation biases. This provides a unified perspective for understanding misalignment. Based on this, we further offer actionable insights into how misalignment should inform the design of real-world ML systems. We validate our theoretical findings via extensive empirical studies on both synthetic data and real image-text datasets, shedding light on the nuanced impact of cross-modal misalignment on multimodal representation learning.","authors":["Yichao Cai","Yuhang Liu","Erdun Gao","Tianjiao Jiang","Zhen Zhang","Anton van den Hengel","Javen Qinfeng Shi"],"url":"https://arxiv.org/abs/2504.10143"}
{"created":"2025-05-20","title":"DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation","abstract":"Dynamic Retrieval-augmented Generation (RAG) has shown great success in mitigating hallucinations in large language models (LLMs) during generation. However, existing dynamic RAG methods face significant limitations in two key aspects: 1) Lack of an effective mechanism to control retrieval triggers, and 2) Lack of effective scrutiny of retrieval content. To address these limitations, we propose an innovative dynamic RAG method, DioR (Adaptive Cognitive Detection and Contextual Retrieval Optimization), which consists of two main components: adaptive cognitive detection and contextual retrieval optimization, specifically designed to determine when retrieval is needed and what to retrieve for LLMs is useful. Experimental results demonstrate that DioR achieves superior performance on all tasks, demonstrating the effectiveness of our work.","authors":["Hanghui Guo","Jia Zhu","Shimin Di","Weijie Shi","Zhangze Chen","Jiajie Xu"],"url":"https://arxiv.org/abs/2504.10198"}
{"created":"2025-05-20","title":"GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction","abstract":"Circuit link prediction identifying missing component connections from incomplete netlists is crucial in automating analog circuit design. However, existing methods face three main challenges: 1) Insufficient use of topological patterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to the complexity of annotations hinders model generalization; 3) Limited adaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural Networks (GNNs) based framework featuring three innovations to tackle these challenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes for Link Prediction) framework and achieve port-level accuracy in circuit link prediction. Second, we propose Netlist Babel Fish, a netlist format conversion tool leveraging retrieval-augmented generation (RAG) with a large language model (LLM) to enhance the compatibility of netlist formats. Finally, we construct SpiceNetlist, a comprehensive dataset that contains 775 annotated circuits across 10 different component classes. Experimental results achieve accuracy improvements of 16.08% on SpiceNetlist, 11.38% on Image2Net, and 16.01% on Masala-CHAI in intra-dataset evaluation, while maintaining accuracy from 92.05% to 99.07% in cross-dataset evaluation, exhibiting robust feature transfer capabilities.","authors":["Guanyuan Pan","Tiansheng Zhou","Bingtao Ma","Yaqi Wang","Jianxiang Zhao","Zhi Li","Yugui Lin","Pietro Lio","Shuai Wang"],"url":"https://arxiv.org/abs/2504.10240"}
{"created":"2025-05-20","title":"Explicit and Implicit Representations in AI-based 3D Reconstruction for Radiology: A Systematic Review","abstract":"The demand for high-quality medical imaging in clinical practice and assisted diagnosis has made 3D reconstruction in radiological imaging a key research focus. Artificial intelligence (AI) has emerged as a promising approach to enhancing reconstruction accuracy while reducing acquisition and processing time, thereby minimizing patient radiation exposure and discomfort and ultimately benefiting clinical diagnosis. This review explores state-of-the-art AI-based 3D reconstruction algorithms in radiological imaging, categorizing them into explicit and implicit approaches based on their underlying principles. Explicit methods include point-based, volume-based, and Gaussian representations, while implicit methods encompass implicit prior embedding and neural radiance fields. Additionally, we examine commonly used evaluation metrics and benchmark datasets. Finally, we discuss the current state of development, key challenges, and future research directions in this evolving field. Our project available on: https://github.com/Bean-Young/AI4Radiology.","authors":["Yuezhe Yang","Boyu Yang","Yaqian Wang","Yang He","Xingbo Dong","Zhe Jin"],"url":"https://arxiv.org/abs/2504.11349"}
{"created":"2025-05-20","title":"Graph Network for Sign Language Tasks","abstract":"Recent advances in sign language research have benefited from CNN-based backbones, which are primarily transferred from traditional computer vision tasks (\\eg object identification, image recognition). However, these CNN-based backbones usually excel at extracting features like contours and texture, but may struggle with capturing sign-related features. In fact, sign language tasks require focusing on sign-related regions, including the collaboration between different regions (\\eg left hand region and right hand region) and the effective content in a single region. To capture such region-related features, we introduce MixSignGraph, which represents sign sequences as a group of mixed graphs and designs the following three graph modules for feature extraction, \\ie Local Sign Graph (LSG) module, Temporal Sign Graph (TSG) module and Hierarchical Sign Graph (HSG) module. Specifically, the LSG module learns the correlation of intra-frame cross-region features within one frame, \\ie focusing on spatial features. The TSG module tracks the interaction of inter-frame cross-region features among adjacent frames, \\ie focusing on temporal features. The HSG module aggregates the same-region features from different-granularity feature maps of a frame, \\ie focusing on hierarchical features. In addition, to further improve the performance of sign language tasks without gloss annotations, we propose a simple yet counter-intuitive Text-driven CTC Pre-training (TCP) method, which generates pseudo gloss labels from text labels for model pre-training. Extensive experiments conducted on current five public sign language datasets demonstrate the superior performance of the proposed model. Notably, our model surpasses the SOTA models on multiple sign language tasks across several datasets, without relying on any additional cues.","authors":["Shiwei Gan","Yafeng Yin","Zhiwei Jiang","Hongkai Wen","Lei Xie","Sanglu Lu"],"url":"https://arxiv.org/abs/2504.12020"}
{"created":"2025-05-20","title":"Semantic Similarity-Informed Bayesian Borrowing for Quantitative Signal Detection of Adverse Events","abstract":"We present a Bayesian dynamic borrowing (BDB) approach to enhance the quantitative identification of adverse events (AEs) in spontaneous reporting systems (SRSs). The method embeds a robust meta-analytic predictive (MAP) prior with a Bayesian hierarchical model and incorporates semantic similarity measures (SSMs) to enable weighted information sharing from clinically similar MedDRA Preferred Terms (PTs) to the target PT. This continuous similarity-based borrowing overcomes limitations of rigid hierarchical grouping in current disproportionality analysis (DPA).","authors":["Fran\\c{c}ois Haguinet","Jeffery L Painter","Gregory E Powell","Andrea Callegaro","Andrew Bate"],"url":"https://arxiv.org/abs/2504.12052"}
{"created":"2025-05-20","title":"Remote sensing colour image semantic segmentation of trails created by large herbivorous Mammals","abstract":"Identifying spatial regions where biodiversity is threatened is crucial for effective ecosystem conservation and monitoring. In this stydy, we assessed varios machine learning methods to detect grazing trails automatically. We tested five semantic segmentation models combined with 14 different encoder networks. The best combination was UNet with MambaOut encoder. The solution proposed could be used as the basis for tools aiming at mapping and tracking changes in grazing trails on a continuous temporal basis.","authors":["Jose Francisco Diez-Pastor","Francisco Javier Gonzalez-Moya","Pedro Latorre-Carmona","Francisco Javier Perez-Barber\\'ia","Ludmila I. Kuncheva","Antonio Canepa-Oneto","Alvar Arnaiz-Gonz\\'alez","Cesar Garcia-Osorio"],"url":"https://arxiv.org/abs/2504.12121"}
{"created":"2025-05-20","title":"The Others: Naturally Isolating Out-of-Distribution Samples for Robust Open-Set Semi-Supervised Learning","abstract":"Open-Set Semi-Supervised Learning (OSSL) tackles the practical challenge of learning from unlabeled data that may include both in-distribution (ID) and unknown out-of-distribution (OOD) classes. However, existing OSSL methods form suboptimal feature spaces by either excluding OOD samples, interfering with them, or overtrusting their information during training. In this work, we introduce MagMatch, a novel framework that naturally isolates OOD samples through a prototype-based contrastive learning paradigm. Unlike conventional methods, MagMatch does not assign any prototypes to OOD samples; instead, it selectively aligns ID samples with class prototypes using an ID-Selective Magnetic (ISM) module, while allowing OOD samples - the \"others\" - to remain unaligned in the feature space. To support this process, we propose Selective Magnetic Alignment (SMA) loss for unlabeled data, which dynamically adjusts alignment based on sample confidence. Extensive experiments on diverse datasets demonstrate that MagMatch significantly outperforms existing methods in both closed-set classification accuracy and OOD detection AUROC, especially in generalizing to unseen OOD data.","authors":["You Rim Choi","Subeom Park","Seojun Heo","Eunchung Noh","Hyung-Sin Kim"],"url":"https://arxiv.org/abs/2504.12569"}
{"created":"2025-05-20","title":"MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System","abstract":"As Agentic AI gain mainstream adoption, the industry invests heavily in model capabilities, achieving rapid leaps in reasoning and quality. However, these systems remain largely confined to data silos, and each new integration requires custom logic that is difficult to scale. The Model Context Protocol (MCP) addresses this challenge by defining a universal, open standard for securely connecting AI-based applications (MCP clients) to data sources (MCP servers). However, the flexibility of the MCP introduces new risks, including malicious tool servers and compromised data integrity. We present MCP Guardian, a framework that strengthens MCP-based communication with authentication, rate-limiting, logging, tracing, and Web Application Firewall (WAF) scanning. Through real-world scenarios and empirical testing, we demonstrate how MCP Guardian effectively mitigates attacks and ensures robust oversight with minimal overheads. Our approach fosters secure, scalable data access for AI assistants, underscoring the importance of a defense-in-depth approach that enables safer and more transparent innovation in AI-driven environments.","authors":["Sonu Kumar","Anubhav Girdhar","Ritesh Patil","Divyansh Tripathi"],"url":"https://arxiv.org/abs/2504.12757"}
{"created":"2025-05-20","title":"GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large Language Models on Graph-theoretic Tasks","abstract":"This paper introduces GraphOmni, a comprehensive benchmark designed to evaluate the reasoning capabilities of LLMs on graph-theoretic tasks articulated in natural language. GraphOmni encompasses diverse graph types, serialization formats, and prompting schemes, significantly exceeding prior efforts in both scope and depth. Through extensive systematic evaluation, we identify critical interactions among these dimensions, demonstrating their substantial impact on model performance. Our experiments reveal that state-of-the-art models like Claude-3.5 and o4-mini consistently outperform other models, yet even these leading models exhibit substantial room for improvement. Performance variability is evident depending on the specific combinations of factors we considered, underscoring the necessity of comprehensive evaluations across these interconnected dimensions. Additionally, we observe distinct impacts of serialization and prompting strategies between open-source and closed-source models, encouraging the development of tailored approaches. Motivated by the findings, we also propose a reinforcement learning-inspired framework that adaptively selects the optimal factors influencing LLM reasoning capabilities. This flexible and extendable benchmark not only deepens our understanding of LLM performance on structured tasks but also provides a robust foundation for advancing research in LLM-based graph reasoning.","authors":["Hao Xu","Xiangru Jian","Xinjian Zhao","Wei Pang","Chao Zhang","Suyuchen Wang","Qixin Zhang","Zhengyuan Dong","Joao Monteiro","Bang Liu","Qiuzhuang Sun","Tianshu Yu"],"url":"https://arxiv.org/abs/2504.12764"}
{"created":"2025-05-20","title":"Low-hallucination Synthetic Captions for Large-Scale Vision-Language Model Pre-training","abstract":"In recent years, the field of vision-language model pre-training has experienced rapid advancements, driven primarily by the continuous enhancement of textual capabilities in large language models. However, existing training paradigms for multimodal large language models heavily rely on high-quality image-text pairs. As models and data scales grow exponentially, the availability of such meticulously curated data has become increasingly scarce and saturated, thereby severely limiting further advancements in this domain. This study investigates scalable caption generation techniques for vision-language model pre-training and demonstrates that large-scale low-hallucination synthetic captions can serve dual purposes: 1) acting as a viable alternative to real-world data for pre-training paradigms and 2) achieving superior performance enhancement when integrated into vision-language models through empirical validation. This paper presents following key contributions: 1) a novel pipeline for generating high-quality, low-hallucination, and knowledge-rich synthetic captions. Our continuous DPO methodology yields remarkable results in reducing hallucinations. Specifically, the non-hallucination caption rate on a held-out test set increases from 48.3% to 77.9% for a 7B-size model. 2) Comprehensive empirical validation reveals that our synthetic captions confer superior pre-training advantages over their counterparts. Across 15 vision language tasks, the model trained with our data achieves a significant performance gain of at least 6.2% compared to identical images with alt-text. In 20 common cognitive domains, the model trained with our data outperforms the alt-text data by at least 7.5%. Meanwhile, it also offers considerable support in the text-to-image domain. With our dataset, the FID score is reduced by 17.1 on a real-world validation benchmark and 13.3 on the MSCOCO validation benchmark.","authors":["Xinsong Zhang","Yarong Zeng","Xinting Huang","Hu Hu","Runquan Xie","Han Hu","Zhanhui Kang"],"url":"https://arxiv.org/abs/2504.13123"}
{"created":"2025-05-20","title":"CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models","abstract":"Chain-of-thought (CoT) reasoning boosts large language models' (LLMs) performance on complex tasks but faces two key limitations: a lack of reliability when solely relying on LLM-generated reasoning chains and interference from natural language reasoning steps with the models' inference process, also known as the inference logic of LLMs. To address these issues, we propose CoT-RAG, a novel reasoning framework with three key designs: (i) Knowledge Graph-driven CoT Generation,featuring knowledge graphs to modulate reasoning chain generation of LLMs, thereby enhancing reasoning credibility; (ii) Learnable Knowledge Case-aware RAG, which incorporates retrieval-augmented generation (RAG) into knowledge graphs to retrieve relevant sub-cases and sub-descriptions, providing LLMs with learnable information; (iii) Pseudo-Program Prompting Execution, which promotes greater logical rigor by guiding LLMs to execute reasoning tasks as pseudo-programs. Evaluations on nine public datasets spanning three reasoning tasks reveal significant accuracy gains--ranging from 4.0% to 44.3%--over state-of-the-art methods. Furthermore, tests on four domain-specific datasets demonstrate exceptional accuracy and efficient execution, underscoring its practical applicability and scalability.","authors":["Feiyang Li","Peng Fang","Zhan Shi","Arijit Khan","Fang Wang","Dan Feng","Weihao Wang","Xin Zhang","Yongjian Cui"],"url":"https://arxiv.org/abs/2504.13534"}
{"created":"2025-05-20","title":"Probabilistic Stability Guarantees for Feature Attributions","abstract":"Stability guarantees have emerged as a principled way to evaluate feature attributions, but existing certification methods rely on heavily smoothed classifiers and often produce conservative guarantees. To address these limitations, we introduce soft stability and propose a simple, model-agnostic, sample-efficient stability certification algorithm (SCA) that yields non-trivial and interpretable guarantees for any attribution method. Moreover, we show that mild smoothing achieves a more favorable trade-off between accuracy and stability, avoiding the aggressive compromises made in prior certification methods. To explain this behavior, we use Boolean function analysis to derive a novel characterization of stability under smoothing. We evaluate SCA on vision and language tasks and demonstrate the effectiveness of soft stability in measuring the robustness of explanation methods.","authors":["Helen Jin","Anton Xue","Weiqiu You","Surbhi Goel","Eric Wong"],"url":"https://arxiv.org/abs/2504.13787"}
{"created":"2025-05-20","title":"Evaluating Menu OCR and Translation: A Benchmark for Aligning Human and Automated Evaluations in Large Vision-Language Models","abstract":"The rapid advancement of large vision-language models (LVLMs) has significantly propelled applications in document understanding, particularly in optical character recognition (OCR) and multilingual translation. However, current evaluations of LVLMs, like the widely used OCRBench, mainly focus on verifying the correctness of their short-text responses and long-text responses with simple layout, while the evaluation of their ability to understand long texts with complex layout design is highly significant but largely overlooked. In this paper, we propose Menu OCR and Translation Benchmark (MOTBench), a specialized evaluation framework emphasizing the pivotal role of menu translation in cross-cultural communication. MOTBench requires LVLMs to accurately recognize and translate each dish, along with its price and unit items on a menu, providing a comprehensive assessment of their visual understanding and language processing capabilities. Our benchmark is comprised of a collection of Chinese and English menus, characterized by intricate layouts, a variety of fonts, and culturally specific elements across different languages, along with precise human annotations. Experiments show that our automatic evaluation results are highly consistent with professional human evaluation. We evaluate a range of publicly available state-of-the-art LVLMs, and through analyzing their output to identify the strengths and weaknesses in their performance, offering valuable insights to guide future advancements in LVLM development. MOTBench is available at https://github.com/gitwzl/MOTBench.","authors":["Zhanglin Wu","Tengfei Song","Ning Xie","Mengli Zhu","Weidong Zhang","Shuang Wu","Pengfei Li","Chong Li","Junhao Zhu","Hao Yang","Shiliang Sun"],"url":"https://arxiv.org/abs/2504.13945"}
{"created":"2025-05-20","title":"Leakage and Interpretability in Concept-Based Models","abstract":"Concept Bottleneck Models aim to improve interpretability by predicting high-level intermediate concepts, representing a promising approach for deployment in high-risk scenarios. However, they are known to suffer from information leakage, whereby models exploit unintended information encoded within the learned concepts. We introduce an information-theoretic framework to rigorously characterise and quantify leakage, and define two complementary measures: the concepts-task leakage (CTL) and interconcept leakage (ICL) scores. We show that these measures are strongly predictive of model behaviour under interventions and outperform existing alternatives in robustness and reliability. Using this framework, we identify the primary causes of leakage and provide strong evidence that Concept Embedding Models exhibit substantial leakage regardless of the hyperparameters choice. Finally, we propose practical guidelines for designing concept-based models to reduce leakage and ensure interpretability.","authors":["Enrico Parisini","Tapabrata Chakraborti","Chris Harbron","Ben D. MacArthur","Christopher R. S. Banerji"],"url":"https://arxiv.org/abs/2504.14094"}
{"created":"2025-05-20","title":"Signatures of human-like processing in Transformer forward passes","abstract":"Modern AI models are increasingly being used as theoretical tools to study human cognition. One dominant approach is to evaluate whether human-derived measures are predicted by a model's output: that is, the end-product of a forward pass. However, recent advances in mechanistic interpretability have begun to reveal the internal processes that give rise to model outputs, raising the question of whether models might use human-like processing strategies. Here, we investigate the relationship between real-time processing in humans and layer-time dynamics of computation in Transformers, testing 20 open-source models in 6 domains. We first explore whether forward passes show mechanistic signatures of competitor interference, taking high-level inspiration from cognitive theories. We find that models indeed appear to initially favor a competing incorrect answer in the cases where we would expect decision conflict in humans. We then systematically test whether forward-pass dynamics predict signatures of processing in humans, above and beyond properties of the model's output probability distribution. We find that dynamic measures improve prediction of human processing measures relative to static final-layer measures. Moreover, across our experiments, larger models do not always show more human-like processing patterns. Our work suggests a new way of using AI models to study human cognition: not just as a black box mapping stimuli to responses, but potentially also as explicit processing models.","authors":["Jennifer Hu","Michael A. Lepori","Michael Franke"],"url":"https://arxiv.org/abs/2504.14107"}
{"created":"2025-05-20","title":"Mixed-Precision Conjugate Gradient Solvers with RL-Driven Precision Tuning","abstract":"This paper presents a novel reinforcement learning (RL) framework for dynamically optimizing numerical precision in the preconditioned conjugate gradient (CG) method. By modeling precision selection as a Markov Decision Process (MDP), we employ Q-learning to adaptively assign precision levels to key operations, striking an optimal balance between computational efficiency and numerical accuracy, while ensuring stability through double-precision scalar computations and residual computing. In practice, the algorithm is trained on a set of data and subsequently performs inference for precision selection on out-of-sample data, without requiring re-analysis or retraining for new datasets. This enables the method to adapt seamlessly to new problem instances without the computational overhead of recalibration. Our results demonstrate the effectiveness of RL in enhancing solver's performance, marking the first application of RL to mixed-precision numerical methods. The findings highlight the approach's practical advantages, robustness, and scalability, providing valuable insights into its integration with iterative solvers and paving the way for AI-driven advancements in scientific computing.","authors":["Xinye Chen"],"url":"https://arxiv.org/abs/2504.14268"}
{"created":"2025-05-20","title":"Multimodal Coreference Resolution for Chinese Social Media Dialogues: Dataset and Benchmark Approach","abstract":"Multimodal coreference resolution (MCR) aims to identify mentions referring to the same entity across different modalities, such as text and visuals, and is essential for understanding multimodal content. In the era of rapidly growing mutimodal content and social media, MCR is particularly crucial for interpreting user interactions and bridging text-visual references to improve communication and personalization. However, MCR research for real-world dialogues remains unexplored due to the lack of sufficient data resources. To address this gap, we introduce TikTalkCoref, the first Chinese multimodal coreference dataset for social media in real-world scenarios, derived from the popular Douyin short-video platform. This dataset pairs short videos with corresponding textual dialogues from user comments and includes manually annotated coreference clusters for both person mentions in the text and the coreferential person head regions in the corresponding video frames. We also present an effective benchmark approach for MCR, focusing on the celebrity domain, and conduct extensive experiments on our dataset, providing reliable benchmark results for this newly constructed dataset. We will release the TikTalkCoref dataset to facilitate future research on MCR for real-world social media dialogues.","authors":["Xingyu Li","Chen Gong","Guohong Fu"],"url":"https://arxiv.org/abs/2504.14321"}
{"created":"2025-05-20","title":"Trans-Zero: Self-Play Incentivizes Large Language Models for Multilingual Translation Without Parallel Data","abstract":"The rise of Large Language Models (LLMs) has reshaped machine translation (MT), but multilingual MT still relies heavily on parallel data for supervised fine-tuning (SFT), facing challenges like data scarcity for low-resource languages and catastrophic forgetting. To address these issues, we propose TRANS-ZERO, a self-play framework that leverages only monolingual data and the intrinsic multilingual knowledge of LLM. TRANS-ZERO combines Genetic Monte-Carlo Tree Search (G-MCTS) with preference optimization, achieving strong translation performance that rivals supervised methods. Experiments demonstrate that this approach not only matches the performance of models trained on large-scale parallel data but also excels in non-English translation directions. Further analysis reveals that G-MCTS itself significantly enhances translation quality by exploring semantically consistent candidates through iterative translations, providing a robust foundation for the framework's succuss.","authors":["Wei Zou","Sen Yang","Yu Bao","Shujian Huang","Jiajun Chen","Shanbo Cheng"],"url":"https://arxiv.org/abs/2504.14669"}
{"created":"2025-05-20","title":"AlignRAG: Leveraging Critique Learning for Evidence-Sensitive Retrieval-Augmented Reasoning","abstract":"Retrieval-augmented generation (RAG) has become a widely adopted paradigm for enabling knowledge-grounded large language models (LLMs). However, standard RAG pipelines often fail to ensure that model reasoning remains consistent with the evidence retrieved, leading to factual inconsistencies or unsupported conclusions. In this work, we reinterpret RAG as Retrieval-Augmented Reasoning and identify a central but underexplored problem: \\textit{Reasoning Misalignment}-the divergence between an LLM's internal reasoning trajectory and the evidential constraints provided by retrieval. To address this issue, we propose \\textsc{AlignRAG}, a novel iterative framework grounded in Critique-Driven Alignment (CDA). At the heart of \\textsc{AlignRAG} lies a \\textit{contrastive critique synthesis} mechanism that generates retrieval-sensitive critiques while mitigating self-bias. This mechanism trains a dedicated retrieval-augmented \\textit{Critic Language Model (CLM)} using labeled critiques that distinguish between evidence-aligned and misaligned reasoning. Alignment signals for supervision are obtained through self-supervised or externally guided labeling strategies. The resulting CLM is explicitly optimized for evidence sensitivity, enabling it to detect and revise reasoning errors during inference without relying solely on self-generated feedback. Empirical evaluations show that our 8B-parameter CLM improves performance over the Self-Refine baseline by 12.1\\% on out-of-domain tasks and outperforms a standard 72B-parameter CLM by 2.2\\%, while remaining compatible with existing RAG architectures as a plug-and-play module. Overall, AlignRAG offers a principled solution for aligning model reasoning with retrieved evidence, substantially improving the factual reliability and robustness of RAG systems.","authors":["Jiaqi Wei","Hao Zhou","Xiang Zhang","Di Zhang","Zijie Qiu","Wei Wei","Jinzhe Li","Wanli Ouyang","Siqi Sun"],"url":"https://arxiv.org/abs/2504.14858"}
{"created":"2025-05-20","title":"A Self-Improving Coding Agent","abstract":"Recent advancements in Large Language Models (LLMs) have spurred interest in deploying LLM agents to undertake tasks in the world. LLMs are often deployed in agent systems: code that orchestrates LLM calls and provides them with tools. We demonstrate that an agent system, equipped with basic coding tools, can autonomously edit itself, and thereby improve its performance on benchmark tasks. We find performance gains from 17% to 53% on a random subset of SWE Bench Verified, with additional performance gains on LiveCodeBench, as well as synthetically generated agent benchmarks. Our work represents an advancement in the automated and open-ended design of agentic systems, and demonstrates a data-efficient, non gradient-based learning mechanism driven by LLM reflection and code updates.","authors":["Maxime Robeyns","Martin Szummer","Laurence Aitchison"],"url":"https://arxiv.org/abs/2504.15228"}
{"created":"2025-05-20","title":"A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment","abstract":"The remarkable success of Large Language Models (LLMs) has illuminated a promising pathway toward achieving Artificial General Intelligence for both academic and industrial communities, owing to their unprecedented performance across various applications. As LLMs continue to gain prominence in both research and commercial domains, their security and safety implications have become a growing concern, not only for researchers and corporations but also for every nation. Currently, existing surveys on LLM safety primarily focus on specific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning phase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs. To address this gap, this paper introduces, for the first time, the concept of \"full-stack\" safety to systematically consider safety issues throughout the entire process of LLM training, deployment, and eventual commercialization. Compared to the off-the-shelf LLM safety surveys, our work demonstrates several distinctive advantages: (I) Comprehensive Perspective. We define the complete LLM lifecycle as encompassing data preparation, pre-training, post-training, deployment and final commercialization. To our knowledge, this represents the first safety survey to encompass the entire lifecycle of LLMs. (II) Extensive Literature Support. Our research is grounded in an exhaustive review of over 800+ papers, ensuring comprehensive coverage and systematic organization of security issues within a more holistic understanding. (III) Unique Insights. Through systematic literature analysis, we have developed reliable roadmaps and perspectives for each chapter. Our work identifies promising research directions, including safety in data generation, alignment techniques, model editing, and LLM-based agent systems. These insights provide valuable guidance for researchers pursuing future work in this field.","authors":["Kun Wang","Guibin Zhang","Zhenhong Zhou","Jiahao Wu","Miao Yu","Shiqian Zhao","Chenlong Yin","Jinhu Fu","Yibo Yan","Hanjun Luo","Liang Lin","Zhihao Xu","Haolang Lu","Xinye Cao","Xinyun Zhou","Weifei Jin","Fanci Meng","Junyuan Mao","Yu Wang","Hao Wu","Minghe Wang","Fan Zhang","Junfeng Fang","Wenjie Qu","Yue Liu","Chengwei Liu","Yifan Zhang","Qiankun Li","Chongye Guo","Yalan Qin","Zhaoxin Fan","Yi Ding","Donghai Hong","Jiaming Ji","Yingxin Lai","Zitong Yu","Xinfeng Li","Yifan Jiang","Yanhui Li","Xinyu Deng","Junlin Wu","Dongxia Wang","Yihao Huang","Yufei Guo","Jen-tse Huang","Qiufeng Wang","Wenxuan Wang","Dongrui Liu","Yanwei Yue","Wenke Huang","Guancheng Wan","Heng Chang","Tianlin Li","Yi Yu","Chenghao Li","Jiawei Li","Lei Bai","Jie Zhang","Qing Guo","Jingyi Wang","Tianlong Chen","Joey Tianyi Zhou","Xiaojun Jia","Weisong Sun","Cong Wu","Jing Chen","Xuming Hu","Yiming Li","Xiao Wang","Ningyu Zhang","Luu Anh Tuan","Guowen Xu","Jiaheng Zhang","Tianwei Zhang","Xingjun Ma","Jindong Gu","Xiang Wang","Bo An","Jun Sun","Mohit Bansal","Shirui Pan","Lingjuan Lyu","Yuval Elovici","Bhavya Kailkhura","Yaodong Yang","Hongwei Li","Wenyuan Xu","Yizhou Sun","Wei Wang","Qing Li","Ke Tang","Yu-Gang Jiang","Felix Juefei-Xu","Hui Xiong","Xiaofeng Wang","Dacheng Tao","Philip S. Yu","Qingsong Wen","Yang Liu"],"url":"https://arxiv.org/abs/2504.15585"}
{"created":"2025-05-20","title":"DiTPainter: Efficient Video Inpainting with Diffusion Transformers","abstract":"Many existing video inpainting algorithms utilize optical flows to construct the corresponding maps and then propagate pixels from adjacent frames to missing areas by mapping. Despite the effectiveness of the propagation mechanism, they might encounter blurry and inconsistencies when dealing with inaccurate optical flows or large masks. Recently, Diffusion Transformer (DiT) has emerged as a revolutionary technique for video generation tasks. However, pretrained DiT models for video generation all contain a large amount of parameters, which makes it very time consuming to apply to video inpainting tasks. In this paper, we present DiTPainter, an end-to-end video inpainting model based on Diffusion Transformer (DiT). DiTPainter uses an efficient transformer network designed for video inpainting, which is trained from scratch instead of initializing from any large pretrained models. DiTPainter can address videos with arbitrary lengths and can be applied to video decaptioning and video completion tasks with an acceptable time cost. Experiments show that DiTPainter outperforms existing video inpainting algorithms with higher quality and better spatial-temporal consistency.","authors":["Xian Wu","Chang Liu"],"url":"https://arxiv.org/abs/2504.15661"}
{"created":"2025-05-20","title":"Grounded in Context: Retrieval-Based Method for Hallucination Detection","abstract":"Despite advancements in grounded content generation, production Large Language Models (LLMs) based applications still suffer from hallucinated answers. We present \"Grounded in Context\" - Deepchecks' hallucination detection framework, designed for production-scale long-context data and tailored to diverse use cases, including summarization, data extraction, and RAG. Inspired by RAG architecture, our method integrates retrieval and Natural Language Inference (NLI) models to predict factual consistency between premises and hypotheses using an encoder-based model with only a 512-token context window. Our framework identifies unsupported claims with an F1 score of 0.83 in RAGTruth's response-level classification task, matching methods that trained on the dataset, and outperforming all comparable frameworks using similar-sized models.","authors":["Assaf Gerner","Netta Madvil","Nadav Barak","Alex Zaikman","Jonatan Liberman","Liron Hamra","Rotem Brazilay","Shay Tsadok","Yaron Friedman","Neal Harow","Noam Bresler","Shir Chorev","Philip Tannor"],"url":"https://arxiv.org/abs/2504.15771"}
{"created":"2025-05-20","title":"Dynamic Early Exit in Reasoning Models","abstract":"Recent advances in large reasoning language models (LRLMs) rely on test-time scaling, which extends long chain-of-thought (CoT) generation to solve complex tasks. However, overthinking in long CoT not only slows down the efficiency of problem solving, but also risks accuracy loss due to the extremely detailed or redundant reasoning steps. We propose a simple yet effective method that allows LLMs to self-truncate CoT sequences by early exit during generation. Instead of relying on fixed heuristics, the proposed method monitors model behavior at potential reasoning transition points (e.g.,\"Wait\" tokens) and dynamically terminates the next reasoning chain's generation when the model exhibits high confidence in a trial answer. Our method requires no additional training and can be seamlessly integrated into existing o1-like reasoning LLMs. Experiments on 10 reasoning benchmarks (e.g., GSM8K, MATH-500, AMC, GPQA, AIME and LiveCodeBench) show that the proposed method is consistently effective on 11 cutting-edge reasoning LLMs of varying series and sizes, reducing the length of CoT sequences by an average of 19.1% to 80.1% while improving accuracy by 0.3% to 5.0%.","authors":["Chenxu Yang","Qingyi Si","Yongjie Duan","Zheliang Zhu","Chenyu Zhu","Qiaowei Li","Zheng Lin","Li Cao","Weiping Wang"],"url":"https://arxiv.org/abs/2504.15895"}
{"created":"2025-05-20","title":"PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models","abstract":"Current benchmarks for evaluating the reasoning capabilities of Large Language Models (LLMs) face significant limitations: task oversimplification, data contamination, and flawed evaluation items. These deficiencies necessitate more rigorous assessment methods. To address these limitations, we introduce PHYBench, a benchmark of 500 original physics problems ranging from high school to Physics Olympiad difficulty. PHYBench addresses data contamination through original content and employs a systematic curation pipeline to eliminate flawed items. Evaluations show that PHYBench activates more tokens and provides stronger differentiation between reasoning models compared to other baselines like AIME 2024, OlympiadBench and GPQA. Even the best-performing model, Gemini 2.5 Pro, achieves only 36.9% accuracy compared to human experts' 61.9%. To further enhance evaluation precision, we introduce the Expression Edit Distance (EED) Score for mathematical expression assessment, which improves sample efficiency by 204% over binary scoring. Moreover, PHYBench effectively elicits multi-step and multi-condition reasoning, providing a platform for examining models' reasoning robustness, preferences, and deficiencies. The benchmark results and dataset are publicly available at https://www.phybench.cn/.","authors":["Shi Qiu","Shaoyang Guo","Zhuo-Yang Song","Yunbo Sun","Zeyu Cai","Jiashen Wei","Tianyu Luo","Yixuan Yin","Haoxu Zhang","Yi Hu","Chenyang Wang","Chencheng Tang","Haoling Chang","Qi Liu","Ziheng Zhou","Tianyu Zhang","Jingtian Zhang","Zhangyi Liu","Minghao Li","Yuku Zhang","Boxuan Jing","Xianqi Yin","Yutong Ren","Zizhuo Fu","Jiaming Ji","Weike Wang","Xudong Tian","Anqi Lv","Laifu Man","Jianxiang Li","Feiyu Tao","Qihua Sun","Zhou Liang","Yushu Mu","Zhongxuan Li","Jing-Jun Zhang","Shutao Zhang","Xiaotian Li","Xingqi Xia","Jiawei Lin","Zheyu Shen","Jiahang Chen","Qiuhao Xiong","Binran Wang","Fengyuan Wang","Ziyang Ni","Bohan Zhang","Fan Cui","Changkun Shao","Qing-Hong Cao","Ming-xing Luo","Yaodong Yang","Muhan Zhang","Hua Xing Zhu"],"url":"https://arxiv.org/abs/2504.16074"}
{"created":"2025-05-20","title":"MARFT: Multi-Agent Reinforcement Fine-Tuning","abstract":"LLM-based Multi-Agent Systems have demonstrated remarkable capabilities in addressing complex, agentic tasks, from generating high-quality presentation slides to even conducting sophisticated scientific research. Meanwhile, RL has been widely recognized for its effectiveness in enhancing agent intelligence, but limited research has investigated the fine-tuning of LaMAS using foundational RL techniques. Moreover, the direct application of MARL methods to LaMAS introduces significant challenges, stemming from the unique characteristics and mechanisms inherent to LaMAS. To address these challenges, this article presents a comprehensive study of LLM-based MARL and proposes a novel paradigm termed Multi-Agent Reinforcement Fine-Tuning (MARFT). We introduce a brand-new POMDP called Flex-POMDP, which aligns with the LaMAS optimization in real-world applications and a universal algorithmic framework tailored specifically for LaMAS, outlining the conceptual foundations, key distinctions, and practical implementation strategies. We review the evolution from RL to RFT, setting the stage for a parallel analysis in the multi-agent domain. In the context of LaMAS, we elucidate critical differences between MARL and MARFT. These differences motivate a transition toward a LaMAS-oriented formulation of RFT. Central to this work is a robust and scalable MARFT framework. We detail the core algorithm and provide a complete, open-source implementation to facilitate adoption and further research. The latter sections of the paper explore real-world application perspectives and opening challenges in MARFT. By bridging theoretical underpinnings with practical methodologies, this work serves as a roadmap for researchers seeking to advance MARFT toward resilient and adaptive solutions in agentic systems. Our implementation of the proposed framework is publicly available at: https://github.com/jwliao-ai/MARFT.","authors":["Junwei Liao","Muning Wen","Jun Wang","Weinan Zhang"],"url":"https://arxiv.org/abs/2504.16129"}
{"created":"2025-05-20","title":"Numerical Derivatives, Projection Coefficients, and Truncation Errors in Analytic Hilbert Space With Gaussian Measure","abstract":"We introduce the projection coefficients algorithm, a novel method for determining the leading terms of the Taylor series expansion of a given holomorphic function from a graph perspective, while also analyzing the associated truncation errors. Let $ f(z) $ be a holomorphic function, and let $\\langle \\cdot, \\cdot \\rangle$ denote the inner product defined over an analytic Hilbert space equipped with a Gaussian measure. The derivatives $ f^{(n)}(z) $ at a point $ z_0 $ can be computed theoretically by evaluating an inner product of the form $","authors":["M. W. AlMasri"],"url":"https://arxiv.org/abs/2504.16246"}
{"created":"2025-05-20","title":"Density of rational languages under shift invariant measures","abstract":"We study density of rational languages under shift invariant probability measures on spaces of two-sided infinite words, which generalizes the classical notion of density studied in formal languages and automata theory. The density for a language is defined as the limit in average (if it exists) of the probability that a word of a given length belongs to the language. We establish the existence of densities for all rational languages under all shift invariant measures. We also give explicit formulas under certain conditions, in particular when the language is aperiodic. Our approach combines tools and ideas from semigroup theory and ergodic theory.","authors":["Val\\'erie Berth\\'e","Herman Goulet-Ouellet","Dominique Perrin"],"url":"https://arxiv.org/abs/2504.16708"}
{"created":"2025-05-20","title":"DYNUS: Uncertainty-aware Trajectory Planner in Dynamic Unknown Environments","abstract":"This paper introduces DYNUS, an uncertainty-aware trajectory planner designed for dynamic unknown environments. Operating in such settings presents many challenges -- most notably, because the agent cannot predict the ground-truth future paths of obstacles, a previously planned trajectory can become unsafe at any moment, requiring rapid replanning to avoid collisions.","authors":["Kota Kondo","Mason Peterson","Nicholas Rober","Juan Rached Viso","Lucas Jia","Jialin Chen","Harvey Merton","Jonathan P. How"],"url":"https://arxiv.org/abs/2504.16734"}
{"created":"2025-05-20","title":"Process Reward Models That Think","abstract":"Step-by-step verifiers -- also known as process reward models (PRMs) -- are a key ingredient for test-time scaling. PRMs require step-level supervision, making them expensive to train. This work aims to build data-efficient PRMs as verbalized step-wise reward models that verify every step in the solution by generating a verification chain-of-thought (CoT). We propose ThinkPRM, a long CoT verifier fine-tuned on orders of magnitude fewer process labels than those required by discriminative PRMs. Our approach capitalizes on the inherent reasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and discriminative verifiers -- using only 1% of the process labels in PRM800K -- across several challenging benchmarks. Specifically, ThinkPRM beats the baselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and reward-guided search. In an out-of-domain evaluation on a subset of GPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers trained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the same token budget, ThinkPRM scales up verification compute more effectively compared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of ProcessBench. Our work highlights the value of generative, long CoT PRMs that can scale test-time compute for verification while requiring minimal supervision for training. Our code, data, and models will be released at https://github.com/mukhal/thinkprm.","authors":["Muhammad Khalifa","Rishabh Agarwal","Lajanugen Logeswaran","Jaekyeom Kim","Hao Peng","Moontae Lee","Honglak Lee","Lu Wang"],"url":"https://arxiv.org/abs/2504.16828"}
{"created":"2025-05-20","title":"OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents","abstract":"Optimization plays a vital role in scientific research and practical applications. However, formulating a concrete optimization problem described in natural language into a mathematical form and selecting a suitable solver to solve the problem requires substantial domain expertise. We introduce OptimAI, a framework for solving Optimization problems described in natural language by leveraging LLM-powered AI agents, and achieve superior performance over current state-of-the-art methods. Our framework is built upon the following key roles: (1) a formulator that translates natural language problem descriptions into precise mathematical formulations; (2) a planner that constructs a high-level solution strategy prior to execution; and (3) a coder and a code critic capable of interacting with the environment and reflecting on outcomes to refine future actions. Ablation studies confirm that all roles are essential; removing the planner or code critic results in $5.8\\times$ and $3.1\\times$ drops in productivity, respectively. Furthermore, we introduce UCB-based debug scheduling to dynamically switch between alternative plans, yielding an additional $3.3\\times$ productivity gain. Our design emphasizes multi-agent collaboration, and our experiments confirm that combining diverse models leads to performance gains. Our approach attains 88.1% accuracy on the NLP4LP dataset and 82.3% on the Optibench dataset, reducing error rates by 58% and 52%, respectively, over prior best results.","authors":["Raghav Thind","Youran Sun","Ling Liang","Haizhao Yang"],"url":"https://arxiv.org/abs/2504.16918"}
{"created":"2025-05-20","title":"Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning","abstract":"Despite the rapid growth of machine learning research, corresponding code implementations are often unavailable, making it slow and labor-intensive for researchers to reproduce results and build upon prior work. In the meantime, recent Large Language Models (LLMs) excel at understanding scientific documents and generating high-quality code. Inspired by this, we introduce PaperCoder, a multi-agent LLM framework that transforms machine learning papers into functional code repositories. PaperCoder operates in three stages: planning, where it constructs a high-level roadmap, designs the system architecture with diagrams, identifies file dependencies, and generates configuration files; analysis, which focuses on interpreting implementation-specific details; and generation, where modular, dependency-aware code is produced. Moreover, each phase is instantiated through a set of specialized agents designed to collaborate effectively across the pipeline. We then evaluate PaperCoder on generating code implementations from machine learning papers based on both model-based and human evaluations, particularly from the authors of those papers, with author-released repositories as ground truth if available. Our results demonstrate the effectiveness of PaperCoder in creating high-quality, faithful implementations. Furthermore, it consistently shows strengths in the recently released PaperBench benchmark, surpassing strong baselines by substantial margins. Code is available at: https://github.com/going-doer/Paper2Code.","authors":["Minju Seo","Jinheon Baek","Seongyun Lee","Sung Ju Hwang"],"url":"https://arxiv.org/abs/2504.17192"}
{"created":"2025-05-20","title":"On Runge-Kutta methods of order 10","abstract":"A family of explicit 15-stage Runge-Kutta methods of order 10 is derived.","authors":["Misha Stepanov"],"url":"https://arxiv.org/abs/2504.17329"}
{"created":"2025-05-20","title":"Score-Based Deterministic Density Sampling","abstract":"We propose a deterministic sampling framework using Score-Based Transport Modeling for sampling an unnormalized target density $\\pi$ given only its score $\\nabla \\log \\pi$. Our method approximates the Wasserstein gradient flow on $\\mathrm{KL}(f_t\\|\\pi)$ by learning the time-varying score $\\nabla \\log f_t$ on the fly using score matching. While having the same marginal distribution as Langevin dynamics, our method produces smooth deterministic trajectories, resulting in monotone noise-free convergence. We prove that our method dissipates relative entropy at the same rate as the exact gradient flow, provided sufficient training. Numerical experiments validate our theoretical findings: our method converges at the optimal rate, has smooth trajectories, and is usually more sample efficient than its stochastic counterpart. Experiments on high dimensional image data show that our method produces high quality generations in as few as 15 steps and exhibits natural exploratory behavior. The memory and runtime scale linearly in the sample size.","authors":["Vasily Ilin","Peter Sushko","Jingwei Hu"],"url":"https://arxiv.org/abs/2504.18130"}
{"created":"2025-05-20","title":"WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks","abstract":"Autonomous UI agents powered by AI have tremendous potential to boost human productivity by automating routine tasks such as filing taxes and paying bills. However, a major challenge in unlocking their full potential is security, which is exacerbated by the agent's ability to take action on their user's behalf. Existing tests for prompt injections in web agents either over-simplify the threat by testing unrealistic scenarios or giving the attacker too much power, or look at single-step isolated tasks. To more accurately measure progress for secure web agents, we introduce WASP -- a new publicly available benchmark for end-to-end evaluation of Web Agent Security against Prompt injection attacks. Evaluating with WASP shows that even top-tier AI models, including those with advanced reasoning capabilities, can be deceived by simple, low-effort human-written injections in very realistic scenarios. Our end-to-end evaluation reveals a previously unobserved insight: while attacks partially succeed in up to 86% of the case, even state-of-the-art agents often struggle to fully complete the attacker goals -- highlighting the current state of security by incompetence.","authors":["Ivan Evtimov","Arman Zharmagambetov","Aaron Grattafiori","Chuan Guo","Kamalika Chaudhuri"],"url":"https://arxiv.org/abs/2504.18575"}
{"created":"2025-05-20","title":"SynFuzz: Leveraging Fuzzing of Netlist to Detect Synthesis Bugs","abstract":"In the evolving landscape of integrated circuit (IC) design, the increasing complexity of modern processors and intellectual property (IP) cores has introduced new challenges in ensuring design correctness and security. The recent advancements in hardware fuzzing techniques have shown their efficacy in detecting hardware bugs and vulnerabilities at the RTL abstraction level of hardware. However, they suffer from several limitations, including an inability to address vulnerabilities introduced during synthesis and gate-level transformations. These methods often fail to detect issues arising from library adversaries, where compromised or malicious library components can introduce backdoors or unintended behaviors into the design. In this paper, we present a novel hardware fuzzer, SynFuzz, designed to overcome the limitations of existing hardware fuzzing frameworks. SynFuzz focuses on fuzzing hardware at the gate-level netlist to identify synthesis bugs and vulnerabilities that arise during the transition from RTL to the gate-level. We analyze the intrinsic hardware behaviors using coverage metrics specifically tailored for the gate-level. Furthermore, SynFuzz implements differential fuzzing to uncover bugs associated with EDA libraries. We evaluated SynFuzz on popular open-source processors and IP designs, successfully identifying 7 new synthesis bugs. Additionally, by exploiting the optimization settings of EDA tools, we performed a compromised library mapping attack (CLiMA), creating a malicious version of hardware designs that remains undetectable by traditional verification methods. We also demonstrate how SynFuzz overcomes the limitations of the industry-standard formal verification tool, Cadence Conformal, providing a more robust and comprehensive approach to hardware verification.","authors":["Raghul Saravanan","Sudipta Paria","Aritra Dasgupta","Venkat Nitin Patnala","Swarup Bhunia","Sai Manoj P D"],"url":"https://arxiv.org/abs/2504.18812"}
{"created":"2025-05-20","title":"SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning","abstract":"Evaluating the step-by-step reliability of large language model (LLM) reasoning, such as Chain-of-Thought, remains challenging due to the difficulty and cost of obtaining high-quality step-level supervision. In this paper, we introduce Self-Play Critic (SPC), a novel approach where a critic model evolves its ability to assess reasoning steps through adversarial self-play games, eliminating the need for manual step-level annotation. SPC involves fine-tuning two copies of a base model to play two roles, namely a \"sneaky generator\" that deliberately produces erroneous steps designed to be difficult to detect, and a \"critic\" that analyzes the correctness of reasoning steps. These two models engage in an adversarial game in which the generator aims to fool the critic, while the critic model seeks to identify the generator's errors. Using reinforcement learning based on the game outcomes, the models iteratively improve; the winner of each confrontation receives a positive reward and the loser receives a negative reward, driving continuous self-evolution. Experiments on three reasoning process benchmarks (ProcessBench, PRM800K, DeltaBench) demonstrate that our SPC progressively enhances its error detection capabilities (e.g., accuracy increases from 70.8% to 77.7% on ProcessBench) and surpasses strong baselines, including distilled R1 model. Furthermore, SPC can guide the test-time search of diverse LLMs and significantly improve their mathematical reasoning performance on MATH500 and AIME2024, surpassing those guided by state-of-the-art process reward models.","authors":["Jiaqi Chen","Bang Zhang","Ruotian Ma","Peisong Wang","Xiaodan Liang","Zhaopeng Tu","Xiaolong Li","Kwan-Yee K. Wong"],"url":"https://arxiv.org/abs/2504.19162"}
{"created":"2025-05-20","title":"GSFF-SLAM: 3D Semantic Gaussian Splatting SLAM via Feature Field","abstract":"Semantic-aware 3D scene reconstruction is essential for autonomous robots to perform complex interactions. Semantic SLAM, an online approach, integrates pose tracking, geometric reconstruction, and semantic mapping into a unified framework, shows significant potential. However, existing systems, which rely on 2D ground truth priors for supervision, are often limited by the sparsity and noise of these signals in real-world environments. To address this challenge, we propose GSFF-SLAM, a novel dense semantic SLAM system based on 3D Gaussian Splatting that leverages feature fields to achieve joint rendering of appearance, geometry, and N-dimensional semantic features. By independently optimizing feature gradients, our method supports semantic reconstruction using various forms of 2D priors, particularly sparse and noisy signals. Experimental results demonstrate that our approach outperforms previous methods in both tracking accuracy and photorealistic rendering quality. When utilizing 2D ground truth priors, GSFF-SLAM achieves state-of-the-art semantic segmentation performance with 95.03\\% mIoU, while achieving up to 2.9$\\times$ speedup with only marginal performance degradation.","authors":["Zuxing Lu","Xin Yuan","Shaowen Yang","Jingyu Liu","Changyin Sun"],"url":"https://arxiv.org/abs/2504.19409"}
{"created":"2025-05-20","title":"GVPO: Group Variance Policy Optimization for Large Language Model Post-Training","abstract":"Post-training plays a crucial role in refining and aligning large language models to meet specific tasks and human preferences. While recent advancements in post-training techniques, such as Group Relative Policy Optimization (GRPO), leverage increased sampling with relative reward scoring to achieve superior performance, these methods often suffer from training instability that limits their practical adoption. To address this challenge, we present Group Variance Policy Optimization (GVPO). GVPO incorporates the analytical solution to KL-constrained reward maximization directly into its gradient weights, ensuring alignment with the optimal policy. The method provides intuitive physical interpretations: its gradient mirrors the mean squared error between the central distance of implicit rewards and that of actual rewards. GVPO offers two key advantages: (1) it guarantees a unique optimal solution, exactly the KL-constrained reward maximization objective, (2) it supports flexible sampling distributions that avoids on-policy and importance sampling limitations. By unifying theoretical guarantees with practical adaptability, GVPO establishes a new paradigm for reliable and versatile LLM post-training.","authors":["Kaichen Zhang","Yuzhong Hong","Junwei Bao","Hongfei Jiang","Yang Song","Dingqian Hong","Hui Xiong"],"url":"https://arxiv.org/abs/2504.19599"}
{"created":"2025-05-20","title":"VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning","abstract":"Large Vision-Language Models (LVLMs) are pivotal for real-world AI tasks like embodied intelligence due to their strong vision-language reasoning abilities. However, current LVLMs process entire images at the token level, which is inefficient compared to humans who analyze information and generate content at the conceptual level, extracting relevant visual concepts with minimal effort. This inefficiency, stemming from the lack of a visual concept model, limits LVLMs' usability in real-world applications. To address this, we propose VCM, an end-to-end self-supervised visual concept modeling framework. VCM leverages implicit contrastive learning across multiple sampled instances and vision-language fine-tuning to construct a visual concept model without requiring costly concept-level annotations. Our results show that VCM significantly reduces computational costs (e.g., 85\\% fewer FLOPs for LLaVA-1.5-7B) while maintaining strong performance across diverse image understanding tasks. Moreover, VCM enhances visual encoders' capabilities in classic visual concept perception tasks. Extensive quantitative and qualitative experiments validate the effectiveness and efficiency of VCM.","authors":["Run Luo","Renke Shan","Longze Chen","Ziqiang Liu","Lu Wang","Min Yang","Xiaobo Xia"],"url":"https://arxiv.org/abs/2504.19627"}
{"created":"2025-05-20","title":"Toward Evaluative Thinking: Meta Policy Optimization with Evolving Reward Models","abstract":"Reward-based alignment methods for large language models (LLMs) face two key limitations: vulnerability to reward hacking, where models exploit flaws in the reward signal; and reliance on brittle, labor-intensive prompt engineering when LLMs are used as reward models. We introduce Meta Policy Optimization (MPO), a framework that addresses these challenges by integrating a meta-reward model that dynamically refines the reward model's prompt throughout training. In MPO, the meta-reward model monitors the evolving training context and continuously adjusts the reward model's prompt to maintain high alignment, providing an adaptive reward signal that resists exploitation by the policy. This meta-learning approach promotes a more stable policy optimization, and greatly reduces the need for manual reward prompt design. It yields performance on par with or better than models guided by extensively hand-crafted reward prompts. Furthermore, we show that MPO maintains its effectiveness across diverse tasks, from essay writing to mathematical reasoning, without requiring specialized reward designs. Beyond standard RLAIF, MPO's meta-learning formulation is readily extensible to higher-level alignment frameworks. Overall, this method addresses theoretical and practical challenges in reward-based RL alignment for LLMs, paving the way for more robust and adaptable alignment strategies. The code and data can be accessed at: https://github.com/minnesotanlp/mpo","authors":["Zae Myung Kim","Chanwoo Park","Vipul Raheja","Suin Kim","Dongyeop Kang"],"url":"https://arxiv.org/abs/2504.20157"}
{"created":"2025-05-20","title":"The Panel Complexity of Sortition: Is 12 Angry Men Enough?","abstract":"Sortition is the practice of delegating public decision-making to randomly selected panels. Recently, it has gained momentum worldwide through its use in citizens' assemblies, sparking growing interest within the computer science community. One key appeal of sortition is that random panels tend to be more representative of the population than elected committees or parliaments. Our main conceptual contribution is a novel definition of representative panels, based on the Wasserstein distance from statistical learning theory. Using this definition, we develop a framework for analyzing the panel complexity problem -- determining the required panel size to ensure desirable properties. We focus on three key desiderata: (1) that efficiency at the panel level extends to the whole population, measured by social welfare; (2) that fairness guarantees for the panel translate to fairness for the population, captured by the core; and (3) that the probability of an outlier panel, for which the decision significantly deviates from the optimal one, remains low. We establish near-tight panel complexity guarantees for these desiderata across two fundamental social choice settings: participatory budgeting and facility location.","authors":["Johannes Brustle","Simone Fioravanti","Tomasz Ponitka","Jeremy Vollen"],"url":"https://arxiv.org/abs/2504.20508"}
{"created":"2025-05-20","title":"Dynamic Attention Analysis for Backdoor Detection in Text-to-Image Diffusion Models","abstract":"Recent studies have revealed that text-to-image diffusion models are vulnerable to backdoor attacks, where attackers implant stealthy textual triggers to manipulate model outputs. Previous backdoor detection methods primarily focus on the static features of backdoor samples. However, a vital property of diffusion models is their inherent dynamism. This study introduces a novel backdoor detection perspective named Dynamic Attention Analysis (DAA), showing that these dynamic characteristics serve as better indicators for backdoor detection. Specifically, by examining the dynamic evolution of cross-attention maps, we observe that backdoor samples exhibit distinct feature evolution patterns at the $<$EOS$>$ token compared to benign samples. To quantify these dynamic anomalies, we first introduce DAA-I, which treats the tokens' attention maps as spatially independent and measures dynamic feature using the Frobenius norm. Furthermore, to better capture the interactions between attention maps and refine the feature, we propose a dynamical system-based approach, referred to as DAA-S. This model formulates the spatial correlations among attention maps using a graph-based state equation and we theoretically analyze the global asymptotic stability of this method. Extensive experiments across five representative backdoor attack scenarios demonstrate that our approach significantly surpasses existing detection methods, achieving an average F1 Score of 79.49% and an AUC of 87.67%. The code is available at https://github.com/Robin-WZQ/DAA.","authors":["Zhongqi Wang","Jie Zhang","Shiguang Shan","Xilin Chen"],"url":"https://arxiv.org/abs/2504.20518"}
{"created":"2025-05-20","title":"UniversalRAG: Retrieval-Augmented Generation over Corpora of Diverse Modalities and Granularities","abstract":"Retrieval-Augmented Generation (RAG) has shown substantial promise in improving factual accuracy by grounding model responses with external knowledge relevant to queries. However, most existing RAG approaches are limited to a text-only corpus, and while recent efforts have extended RAG to other modalities such as images and videos, they typically operate over a single modality-specific corpus. In contrast, real-world queries vary widely in the type of knowledge they require, which a single type of knowledge source cannot address. To address this, we introduce UniversalRAG, a novel RAG framework designed to retrieve and integrate knowledge from heterogeneous sources with diverse modalities and granularities. Specifically, motivated by the observation that forcing all modalities into a unified representation space derived from a single aggregated corpus causes a modality gap, where the retrieval tends to favor items from the same modality as the query, we propose a modality-aware routing mechanism that dynamically identifies the most appropriate modality-specific corpus and performs targeted retrieval within it. Also, beyond modality, we organize each modality into multiple granularity levels, enabling fine-tuned retrieval tailored to the complexity and scope of the query. We validate UniversalRAG on 8 benchmarks spanning multiple modalities, showing its superiority over various modality-specific and unified baselines.","authors":["Woongyeong Yeo","Kangsan Kim","Soyeong Jeong","Jinheon Baek","Sung Ju Hwang"],"url":"https://arxiv.org/abs/2504.20734"}
{"created":"2025-05-20","title":"Computational Reasoning of Large Language Models","abstract":"With the rapid development and widespread application of Large Language Models (LLMs), multidimensional evaluation has become increasingly critical. However, current evaluations are often domain-specific and overly complex, limiting their effectiveness as cross-domain proxies for core capabilities. To address these limitations and enable a unified and simple evaluation framework, an ideal proxy task should target a basic capability that generalizes across tasks and is independent of domain-specific knowledge. Turing machine provides a powerful theoretical lens by reducing complex processes to basic, domain-agnostic computational operations. This perspective offers a principled framework for evaluating basic computational abilities essential to a wide range of tasks. Motivated by this abstraction, we introduce \\textbf{Turing Machine Bench}, a benchmark designed to assess the ability of LLMs to \\textbf{strictly follow rules} and \\textbf{accurately manage internal states} for multi-step, referred to as \\textbf{computational reasoning}. TMBench incorporates four key features: self-contained and knowledge-agnostic reasoning, a minimalistic multi-step structure, controllable difficulty, and a solid theoretical foundation based on Turing machine. Empirical results demonstrate that TMBench serves as an effective proxy for evaluating computational reasoning on representative LLMs. It produces clear step-wise accuracy curves, revealing LLMs' ability to execute multi-step reasoning processes. By analyzing performance trends across TMBench and established reasoning benchmarks, we find strong correlations with real-world tasks, bridging real-task evaluation with basic ability assessment. These findings suggest that TMBench holds potential as a cross-domain dimension for evaluating reasoning in LLMs. Code and data are available at \\href{https://github.com/HaitaoWuTJU/Turing-Machine-Bench}{Repo}.","authors":["Haitao Wu","Zongbo Han","Joey Tianyi Zhou","Huaxi Huang","Changqing Zhang"],"url":"https://arxiv.org/abs/2504.20771"}
{"created":"2025-05-20","title":"A Domain-Agnostic Scalable AI Safety Ensuring Framework","abstract":"Ensuring the safety of AI systems has emerged as a critical priority as these systems are increasingly deployed in real-world applications. We propose a novel domain-agnostic framework that guarantees AI systems satisfy user-defined safety constraints with specified probabilities. Our approach combines any AI model with an optimization problem that ensures outputs meet safety requirements while maintaining performance. The key challenge is handling uncertain constraints -- those whose satisfaction cannot be deterministically evaluated~(e.g., whether a chatbot response is ``harmful''). We address this through three innovations: (1) a safety classification model that assesses constraint satisfaction probability, (2) internal test data to evaluate this classifier's reliability, and (3) conservative testing to prevent overfitting when this data is used in training. We prove our method guarantees probabilistic safety under mild conditions and establish the first scaling law in AI safety -- showing that the safety-performance trade-off improves predictably with more internal test data. Experiments across production planning, reinforcement learning, and language generation demonstrate our framework achieves up to 140 times better safety than existing methods at the same performance levels. This work enables AI systems to achieve both rigorous safety guarantees and high performance across diverse domains.","authors":["Beomjun Kim","Kangyeon Kim","Sunwoo Kim","Heejin Ahn"],"url":"https://arxiv.org/abs/2504.20924"}
{"created":"2025-05-20","title":"What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift","abstract":"The growing adoption of artificial intelligence (AI) has amplified concerns about trustworthiness, including integrity, privacy, robustness, and bias. To assess and attribute these threats, we propose ConceptLens, a generic framework that leverages pre-trained multimodal models to identify the root causes of integrity threats by analyzing Concept Shift in probing samples. ConceptLens demonstrates strong detection performance for vanilla data poisoning attacks and uncovers vulnerabilities to bias injection, such as the generation of covert advertisements through malicious concept shifts. It identifies privacy risks in unaltered but high-risk samples, filters them before training, and provides insights into model weaknesses arising from incomplete or imbalanced training data. Additionally, at the model level, it attributes concepts that the target model is overly dependent on, identifies misleading concepts, and explains how disrupting key concepts negatively impacts the model. Furthermore, it uncovers sociological biases in generative content, revealing disparities across sociological contexts. Strikingly, ConceptLens reveals how safe training and inference data can be unintentionally and easily exploited, potentially undermining safety alignment. Our study informs actionable insights to breed trust in AI systems, thereby speeding adoption and driving greater innovation.","authors":["Jiamin Chang","Haoyang Li","Hammond Pearce","Ruoxi Sun","Bo Li","Minhui Xue"],"url":"https://arxiv.org/abs/2504.21042"}
{"created":"2025-05-20","title":"GLIP-OOD: Zero-Shot Graph OOD Detection with Graph Foundation Model","abstract":"Out-of-distribution (OOD) detection is critical for ensuring the safety and reliability of machine learning systems, particularly in dynamic and open-world environments. In the vision and text domains, zero-shot OOD detection - which requires no training on in-distribution (ID) data - has advanced significantly through the use of large-scale pretrained models, such as vision-language models (VLMs) and large language models (LLMs). However, zero-shot OOD detection in graph-structured data remains largely unexplored, primarily due to the challenges posed by complex relational structures and the absence of powerful, large-scale pretrained models for graphs. In this work, we take the first step toward enabling zero-shot graph OOD detection by leveraging a graph foundation model (GFM). Our experiments show that, when provided only with class label names for both ID and OOD categories, the GFM can effectively perform OOD detection - often surpassing existing \"supervised\" OOD detection methods that rely on extensive labeled node data. We further address the practical scenario in which OOD label names are not available in real-world settings by introducing GLIP-OOD, a framework that uses LLMs to generate semantically informative pseudo-OOD labels from unlabeled data. These generated OOD labels allow the GFM to better separate ID and OOD classes, facilitating more precise OOD detection - all without any labeled nodes (only ID label names). To our knowledge, this is the first approach to achieve node-level graph OOD detection in a fully zero-shot setting, and it attains performance comparable to state-of-the-art supervised methods on four benchmark text-attributed graph datasets.","authors":["Haoyan Xu","Zhengtao Yao","Xuzhi Zhang","Ziyi Wang","Langzhou He","Yushun Dong","Philip S. Yu","Mengyuan Li","Yue Zhao"],"url":"https://arxiv.org/abs/2504.21186"}
{"created":"2025-05-20","title":"Graph Synthetic Out-of-Distribution Exposure with Large Language Models","abstract":"Out-of-distribution (OOD) detection in graphs is critical for ensuring model robustness in open-world and safety-sensitive applications. Existing graph OOD detection approaches typically train an in-distribution (ID) classifier on ID data alone, then apply post-hoc scoring to detect OOD instances. While OOD exposure - adding auxiliary OOD samples during training - can improve detection, current graph-based methods often assume access to real OOD nodes, which is often impractical or costly. In this paper, we present GOE-LLM, a framework that leverages Large Language Models (LLMs) to achieve OOD exposure on text-attributed graphs without using any real OOD nodes. GOE-LLM introduces two pipelines: (1) identifying pseudo-OOD nodes from the initially unlabeled graph using zero-shot LLM annotations, and (2) generating semantically informative synthetic OOD nodes via LLM-prompted text generation. These pseudo-OOD nodes are then used to regularize ID classifier training and enhance OOD detection awareness. Empirical results on multiple benchmarks show that GOE-LLM substantially outperforms state-of-the-art methods without OOD exposure, achieving up to a 23.5% improvement in AUROC for OOD detection, and attains performance on par with those relying on real OOD labels for exposure.","authors":["Haoyan Xu","Zhengtao Yao","Ziyi Wang","Zhan Cheng","Xiyang Hu","Mengyuan Li","Yue Zhao"],"url":"https://arxiv.org/abs/2504.21198"}
{"created":"2025-05-20","title":"Virtual Element Method Applied to Two Dimensional Axisymmetric Elastic Problems","abstract":"This work presents a Virtual Element Method (VEM) formulation tailored for two-dimensional axisymmetric problems in linear elasticity. By exploiting the rotational symmetry of the geometry and loading conditions, the problem is reduced to a meridional cross-section, where all fields depend only on the radial and axial coordinates. The method incorporates the radial weight $r$ in both the weak formulation and the interpolation estimates to remain consistent with the physical volume measure of cylindrical coordinates. A projection operator onto constant strain fields is constructed via boundary integrals, and a volumetric correction term is introduced to account for the divergence of the stress field arising from axisymmetry. The stabilization term is designed to act only on the kernel of the projection and is implemented using a boundary-based formulation that guarantees stability without affecting polynomial consistency. Furthermore, an a priori interpolation error estimate is established in a weighted Sobolev space, showing optimal convergence rates. The implementation is validated through patch tests that demonstrate the accuracy, consistency, and robustness of the proposed approach.","authors":["Paulo Akira F. Enabe","Rodrigo Provasi"],"url":"https://arxiv.org/abs/2504.21305"}
{"created":"2025-05-20","title":"Drawing Reeb Graphs","abstract":"Reeb graphs are simple topological descriptors with applications in many areas like topological data analysis and computational geometry. Despite their prevalence, visualization of Reeb graphs has received less attention. In this paper, we bridge an essential gap in the literature by exploring the complexity of drawing Reeb graphs. Specifically, we demonstrate that Reeb graph crossing number minimization is NP-hard, both for straight-lined and curved edges. On the other hand, we identify specific classes of Reeb graphs, namely paths and caterpillars, for which crossing-free drawings exist. We also give an optimal algorithm for drawing cycle-shaped Reeb graphs with the least number of crossings and provide initial observations on the complexities of drawing multi-cycle Reeb graphs. We hope that this work establishes the foundation for an understanding of the graph drawing challenges inherent in Reeb graph visualization and paves the way for future work in this area.","authors":["Erin Chambers","Brittany Terese Fasy","Erfan Hosseini Sereshgi","Maarten L\\\"offler"],"url":"https://arxiv.org/abs/2504.21329"}
{"created":"2025-05-20","title":"ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning","abstract":"Recent models such as OpenAI o1 and DeepSeek-R1 have demonstrated strong performance on reasoning-intensive tasks by generating extended Chain-of-Thought (CoT) traces. While longer reasoning helps with thorough exploration of solution paths for complex problems, it also often leads to inefficient and redundant outputs--a phenomenon commonly described as overthinking. In this paper, we propose ShorterBetter, a simple yet effective reinforcement learning method that enables reasoning models to learn their own optimal CoT lengths without manual supervision. We define the Sample Optimal Length (SOL) as the length of the shortest correct response among multiple generations, which serves as a dynamic reward signal to guide the model toward efficient reasoning. Applied to DeepSeek-Distill-Qwen-1.5B/7B as base models, ShorterBetter achieves 50%-80% reduction in output lengths in both in-domain and out-of-domain reasoning tasks while maintaining accuracy. Our reasoning trace analysis shows that ShorterBetter refines the structure of the reasoning traces by reducing unnecessary repetition, excessive self-verification, and over-exploration of alternatives.","authors":["Jingyang Yi","Jiazheng Wang","Sida Li"],"url":"https://arxiv.org/abs/2504.21370"}
{"created":"2025-05-20","title":"MF-LLM: Simulating Population Decision Dynamics via a Mean-Field Large Language Model Framework","abstract":"Simulating collective decision-making involves more than aggregating individual behaviors; it emerges from dynamic interactions among individuals. While large language models (LLMs) offer strong potential for social simulation, achieving quantitative alignment with real-world data remains a key challenge. To bridge this gap, we propose the Mean-Field LLM (MF-LLM) framework, the first to incorporate mean field theory into LLM-based social simulation. MF-LLM models bidirectional interactions between individuals and the population through an iterative process, generating population signals to guide individual decisions, which in turn update the signals. This interplay produces coherent trajectories of collective behavior. To improve alignment with real-world data, we introduce IB-Tune, a novel fine-tuning method inspired by the Information Bottleneck principle, which retains population signals most predictive of future actions while filtering redundant history. Evaluated on a real-world social dataset, MF-LLM reduces KL divergence to human population distributions by 47\\% compared to non-mean-field baselines, enabling accurate trend forecasting and effective intervention planning. Generalizing across 7 domains and 4 LLM backbones, MF-LLM provides a scalable, high-fidelity foundation for social simulation.","authors":["Qirui Mi","Mengyue Yang","Xiangning Yu","Zhiyu Zhao","Cheng Deng","Bo An","Haifeng Zhang","Xu Chen","Jun Wang"],"url":"https://arxiv.org/abs/2504.21582"}
{"created":"2025-05-20","title":"Vision Transformers in Precision Agriculture: A Comprehensive Survey","abstract":"Detecting plant diseases is a crucial aspect of modern agriculture, as it plays a key role in maintaining crop health and increasing overall yield. Traditional approaches, though still valuable, often rely on manual inspection or conventional machine learning techniques, both of which face limitations in scalability and accuracy. Recently, Vision Transformers (ViTs) have emerged as a promising alternative, offering advantages such as improved handling of long-range dependencies and better scalability for visual tasks. This review explores the application of ViTs in precision agriculture, covering a range of tasks. We begin by introducing the foundational architecture of ViTs and discussing their transition from Natural Language Processing (NLP) to Computer Vision. The discussion includes the concept of inductive bias in traditional models like Convolutional Neural Networks (CNNs), and how ViTs mitigate these biases. We provide a comprehensive review of recent literature, focusing on key methodologies, datasets, and performance metrics. This study also includes a comparative analysis of CNNs and ViTs, along with a review of hybrid models and performance enhancements. Technical challenges such as data requirements, computational demands, and model interpretability are addressed, along with potential solutions. Finally, we outline future research directions and technological advancements that could further support the integration of ViTs in real-world agricultural settings. Our goal with this study is to offer practitioners and researchers a deeper understanding of how ViTs are poised to transform smart and precision agriculture.","authors":["Saber Mehdipour","Seyed Abolghasem Mirroshandel","Seyed Amirhossein Tabatabaei"],"url":"https://arxiv.org/abs/2504.21706"}
{"created":"2025-05-20","title":"Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks","abstract":"Improving Large Language Model (LLM) agents for sequential decision-making tasks typically requires extensive task-specific knowledge engineering--custom prompts, curated examples, and specialized observation/action spaces. We investigate a different approach where agents automatically improve by learning from their own successful experiences without human intervention. Our method constructs and refines a database of self-generated trajectories that serve as in-context examples for future tasks. Even naive accumulation of successful trajectories yields substantial performance gains across three diverse benchmarks: ALFWorld (73% to 89%), Wordcraft (55% to 64%), and InterCode-SQL (75% to 79%). These improvements exceed those achieved by upgrading from gpt-4o-mini to gpt-4o and match the performance of allowing multiple attempts per task. We further enhance this approach with two innovations: database-level curation using population-based training to propagate high-performing example collections, and exemplar-level curation that selectively retains trajectories based on their empirical utility as in-context examples. With these enhancements, our method achieves 93% success on ALFWorld--surpassing approaches that use more powerful LLMs and hand-crafted components. Our trajectory bootstrapping technique demonstrates that agents can autonomously improve through experience, offering a scalable alternative to labor-intensive knowledge engineering.","authors":["Vishnu Sarukkai","Zhiqiang Xie","Kayvon Fatahalian"],"url":"https://arxiv.org/abs/2505.00234"}
{"created":"2025-05-20","title":"FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension","abstract":"Frequency-domain compression has proven effective in reducing redundancies for spatial signals. In this work, we propose FreqKV, a novel frequency domain key-value (KV) compression technique that enables efficient context window extension for decoder-only large language models (LLMs). Our approach is motivated by a key observation that, in the frequency domain, the energy distribution of the KV cache is predominantly concentrated in low-frequency components. By discarding high-frequency components, we achieve efficient compression of the KV cache with minimal information loss. FreqKV iteratively compresses the increasing KV cache to a fixed size in the frequency domain, allowing models to process lengthy contexts efficiently. Introducing no additional parameters or architectural modifications, FreqKV is applicable to both fine-tuning and inference. With minimal fine-tuning, LLMs can learn to leverage the limited cache that is compressed in the frequency domain and extend the context window. Experiments on a range of long context language modeling and understanding tasks demonstrate the efficiency and effectiveness of the proposed method.","authors":["Jushi Kai","Boyi Zeng","Yixuan Wang","Haoli Bai","Ziwei He","Bo Jiang","Zhouhan Lin"],"url":"https://arxiv.org/abs/2505.00570"}
{"created":"2025-05-20","title":"Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models","abstract":"Large Language Models (LLMs) have achieved remarkable success but remain data-inefficient, especially when learning from small, specialized corpora with limited and proprietary data. Existing synthetic data generation methods for continue pre-training focus on intra-document content and overlook cross-document knowledge associations, limiting content diversity and depth. We propose Synthetic-on-Graph (SoG), a synthetic data generation framework that incorporates cross-document knowledge associations for efficient corpus expansion. SoG constructs a context graph by extracting entities and concepts from the original corpus, representing cross-document associations, and employing a graph walk strategy for knowledge-associated sampling. This enhances synthetic data diversity and coherence, enabling models to learn complex knowledge structures and handle rare knowledge. To further improve synthetic data quality, we integrate Chain-of-Thought (CoT) and Contrastive Clarifying (CC) synthetic, enhancing reasoning processes and discriminative power. Experiments show that SoG outperforms the state-of-the-art (SOTA) method in a multi-hop document Q&amp;A dataset while performing comparably to the SOTA method on the reading comprehension task datasets, which also underscores the better generalization capability of SoG. Our work advances synthetic data generation and provides practical solutions for efficient knowledge acquisition in LLMs, especially in domains with limited data availability.","authors":["Xuhui Jiang","Shengjie Ma","Chengjin Xu","Cehao Yang","Liyu Zhang","Jian Guo"],"url":"https://arxiv.org/abs/2505.00979"}
{"created":"2025-05-20","title":"Togedule: Scheduling Meetings with Large Language Models and Adaptive Representations of Group Availability","abstract":"Scheduling is a perennial-and often challenging-problem for many groups. Existing tools are mostly static, showing an identical set of choices to everyone, regardless of the current status of attendees' inputs and preferences. In this paper, we propose Togedule, an adaptive scheduling tool that uses large language models to dynamically adjust the pool of choices and their presentation format. With the initial prototype, we conducted a formative study (N=10) and identified the potential benefits and risks of such an adaptive scheduling tool. Then, after enhancing the system, we conducted two controlled experiments, one each for attendees and organizers (total N=66). For each experiment, we compared scheduling with verbal messages, shared calendars, or Togedule. Results show that Togedule significantly reduces the cognitive load of attendees indicating their availability and improves the speed and quality of the decisions made by organizers.","authors":["Jaeyoon Song","Zahra Ashktorab","Thomas W. Malone"],"url":"https://arxiv.org/abs/2505.01000"}
{"created":"2025-05-20","title":"High Dynamic Range Novel View Synthesis with Single Exposure","abstract":"High Dynamic Range Novel View Synthesis (HDR-NVS) aims to establish a 3D scene HDR model from Low Dynamic Range (LDR) imagery. Typically, multiple-exposure LDR images are employed to capture a wider range of brightness levels in a scene, as a single LDR image cannot represent both the brightest and darkest regions simultaneously. While effective, this multiple-exposure HDR-NVS approach has significant limitations, including susceptibility to motion artifacts (e.g., ghosting and blurring), high capture and storage costs. To overcome these challenges, we introduce, for the first time, the single-exposure HDR-NVS problem, where only single exposure LDR images are available during training. We further introduce a novel approach, Mono-HDR-3D, featuring two dedicated modules formulated by the LDR image formation principles, one for converting LDR colors to HDR counterparts, and the other for transforming HDR images to LDR format so that unsupervised learning is enabled in a closed loop. Designed as a meta-algorithm, our approach can be seamlessly integrated with existing NVS models. Extensive experiments show that Mono-HDR-3D significantly outperforms previous methods. Source code will be released.","authors":["Kaixuan Zhang","Hu Wang","Minxian Li","Mingwu Ren","Mao Ye","Xiatian Zhu"],"url":"https://arxiv.org/abs/2505.01212"}
{"created":"2025-05-20","title":"PainFormer: a Vision Foundation Model for Automatic Pain Assessment","abstract":"Pain is a manifold condition that impacts a significant percentage of the population. Accurate and reliable pain evaluation for the people suffering is crucial to developing effective and advanced pain management protocols. Automatic pain assessment systems provide continuous monitoring and support decision-making processes, ultimately aiming to alleviate distress and prevent functionality decline. This study introduces PainFormer, a vision foundation model based on multi-task learning principles trained simultaneously on 14 tasks/datasets with a total of 10.9 million samples. Functioning as an embedding extractor for various input modalities, the foundation model provides feature representations to the Embedding-Mixer, a transformer-based module that performs the final pain assessment. Extensive experiments employing behavioral modalities-including RGB, synthetic thermal, and estimated depth videos-and physiological modalities such as ECG, EMG, GSR, and fNIRS revealed that PainFormer effectively extracts high-quality embeddings from diverse input modalities. The proposed framework is evaluated on two pain datasets, BioVid and AI4Pain, and directly compared to 75 different methodologies documented in the literature. Experiments conducted in unimodal and multimodal settings demonstrate state-of-the-art performances across modalities and pave the way toward general-purpose models for automatic pain assessment.","authors":["Stefanos Gkikas","Raul Fernandez Rojas","Manolis Tsiknakis"],"url":"https://arxiv.org/abs/2505.01571"}
{"created":"2025-05-20","title":"Sensing Safety Analysis for Vehicular Networks with Integrated Sensing and Communication (ISAC)","abstract":"Integrated sensing and communication (ISAC) emerged as a key feature of next-generation 6G wireless systems, allowing them to achieve high data rates and sensing accuracy. While prior research has primarily focused on addressing communication safety in ISAC systems, the equally critical issue of sensing safety remains largely ignored. In this paper, a novel threat to the sensing safety of ISAC vehicle networks is studied, whereby a malicious reconfigurable intelligent surface (RIS) is deployed to compromise the sensing functionality of a roadside unit (RSU). Specifically, a malicious attacker dynamically adjusts the phase shifts of an RIS to spoof the sensing outcomes of a vehicular user (VU)'s echo delay, Doppler shift, and angle-of-departure (AoD). To achieve spoofing on Doppler shift estimation, a time-varying phase shift design on the RIS is proposed. Furthermore, the feasible spoofing frequency set with respect to the Doppler shift is analytical derived. Analytical results also demonstrate that the maximum likelihood estimator (MLE) of the AoD can be significantly misled under spoofed Doppler shift estimation. Simulation results validate our theoretical findings, showing that the RIS can induce a spoofed velocity estimation from 0.1 m/s to 14.9 m/s for a VU with velocity of 10 m/s, and can cause an AoD estimation error of up to 65^{\\circ} with only a 5^{\\circ} beam misalignment.","authors":["Tingyu Shui","Walid Saad","Mingzhe Chen"],"url":"https://arxiv.org/abs/2505.01688"}
{"created":"2025-05-20","title":"Edge-Cloud Collaborative Computing on Distributed Intelligence and Model Optimization: A Survey","abstract":"Edge-cloud collaborative computing (ECCC) has emerged as a pivotal paradigm for addressing the computational demands of modern intelligent applications, integrating cloud resources with edge devices to enable efficient, low-latency processing. Recent advancements in AI, particularly deep learning and large language models (LLMs), have dramatically enhanced the capabilities of these distributed systems, yet introduce significant challenges in model deployment and resource management. In this survey, we comprehensive examine the intersection of distributed intelligence and model optimization within edge-cloud environments, providing a structured tutorial on fundamental architectures, enabling technologies, and emerging applications. Additionally, we systematically analyze model optimization approaches, including compression, adaptation, and neural architecture search, alongside AI-driven resource management strategies that balance performance, energy efficiency, and latency requirements. We further explore critical aspects of privacy protection and security enhancement within ECCC systems and examines practical deployments through diverse applications, spanning autonomous driving, healthcare, and industrial automation. Performance analysis and benchmarking techniques are also thoroughly explored to establish evaluation standards for these complex systems. Furthermore, the review identifies critical research directions including LLMs deployment, 6G integration, neuromorphic computing, and quantum computing, offering a roadmap for addressing persistent challenges in heterogeneity management, real-time processing, and scalability. By bridging theoretical advancements and practical deployments, this survey offers researchers and practitioners a holistic perspective on leveraging AI to optimize distributed computing environments, fostering innovation in next-generation intelligent systems.","authors":["Jing Liu","Yao Du","Kun Yang","Yan Wang","Xiping Hu","Zehua Wang","Yang Liu","Peng Sun","Azzedine Boukerche","Victor C. M. Leung"],"url":"https://arxiv.org/abs/2505.01821"}
{"created":"2025-05-20","title":"Discrete Spatial Diffusion: Intensity-Preserving Diffusion Modeling","abstract":"Generative diffusion models have achieved remarkable success in producing high-quality images. However, these models typically operate in continuous intensity spaces, diffusing independently across pixels and color channels. As a result, they are fundamentally ill-suited for applications involving inherently discrete quantities-such as particle counts or material units-that are constrained by strict conservation laws like mass conservation, limiting their applicability in scientific workflows. To address this limitation, we propose Discrete Spatial Diffusion (DSD), a framework based on a continuous-time, discrete-state jump stochastic process that operates directly in discrete spatial domains while strictly preserving particle counts in both forward and reverse diffusion processes. By using spatial diffusion to achieve particle conservation, we introduce stochasticity naturally through a discrete formulation. We demonstrate the expressive flexibility of DSD by performing image synthesis, class conditioning, and image inpainting across standard image benchmarks, while exactly conditioning total image intensity. We validate DSD on two challenging scientific applications: porous rock microstructures and lithium-ion battery electrodes, demonstrating its ability to generate structurally realistic samples under strict mass conservation constraints, with quantitative evaluation using state-of-the-art metrics for transport and electrochemical performance.","authors":["Javier E. Santos","Agnese Marcato","Roman Colman","Nicholas Lubbers","Yen Ting Lin"],"url":"https://arxiv.org/abs/2505.01917"}
{"created":"2025-05-20","title":"Non-alternating mean payoff games","abstract":"We present and study a variant of the mean payoff games introduced by A. Ehrenfeucht and J. Mycielski. In this version, the second player makes an infinite sequence of moves only after the first player's sequence of moves has been decided and revealed. Such games occur in the computation of the covering radius of constrained systems, a quantity of interest in coding theory.","authors":["Tom Meyerovitch","Aidan Young"],"url":"https://arxiv.org/abs/2505.02183"}
{"created":"2025-05-20","title":"SafeMate: A Modular RAG-Based Agent for Context-Aware Emergency Guidance","abstract":"Despite the abundance of public safety documents and emergency protocols, most individuals remain ill-equipped to interpret and act on such information during crises. Traditional emergency decision support systems (EDSS) are designed for professionals and rely heavily on static documents like PDFs or SOPs, which are difficult for non-experts to navigate under stress. This gap between institutional knowledge and public accessibility poses a critical barrier to effective emergency preparedness and response. We introduce SafeMate, a retrieval-augmented AI assistant that delivers accurate, context-aware guidance to general users in both preparedness and active emergency scenarios. Built on the Model Context Protocol (MCP), SafeMate dynamically routes user queries to tools for document retrieval, checklist generation, and structured summarization. It uses FAISS with cosine similarity to identify relevant content from trusted sources.","authors":["Junfeng Jiao","Jihyung Park","Yiming Xu","Kristen Sussman","Lucy Atkinson"],"url":"https://arxiv.org/abs/2505.02306"}
{"created":"2025-05-20","title":"RM-R1: Reward Modeling as Reasoning","abstract":"Reward modeling is essential for aligning large language models with human preferences through reinforcement learning from human feedback. To provide accurate reward signals, a reward model (RM) should stimulate deep thinking and conduct interpretable reasoning before assigning a score or a judgment. Inspired by recent advances of long chain-of-thought on reasoning-intensive tasks, we hypothesize and validate that integrating reasoning capabilities into reward modeling significantly enhances RMs interpretability and performance. To this end, we introduce a new class of generative reward models - Reasoning Reward Models (ReasRMs) - which formulate reward modeling as a reasoning task. We propose a reasoning-oriented training pipeline and train a family of ReasRMs, RM-R1. RM-R1 features a chain-of-rubrics (CoR) mechanism - self-generating sample-level chat rubrics or math/code solutions, and evaluating candidate responses against them. The training of RM-R1 consists of two key stages: (1) distillation of high-quality reasoning chains and (2) reinforcement learning with verifiable rewards. Empirically, our models achieve state-of-the-art performance across three reward model benchmarks on average, outperforming much larger open-weight models (e.g., INF-ORM-Llama3.1-70B) and proprietary ones (e.g., GPT-4o) by up to 4.9%. Beyond final performance, we perform thorough empirical analyses to understand the key ingredients of successful ReasRM training. To facilitate future research, we release six REASRM models along with code and data at https://github.com/RM-R1-UIUC/RM-R1.","authors":["Xiusi Chen","Gaotang Li","Ziqi Wang","Bowen Jin","Cheng Qian","Yu Wang","Hongru Wang","Yu Zhang","Denghui Zhang","Tong Zhang","Hanghang Tong","Heng Ji"],"url":"https://arxiv.org/abs/2505.02387"}
{"created":"2025-05-20","title":"No Other Representation Component Is Needed: Diffusion Transformers Can Provide Representation Guidance by Themselves","abstract":"Recent studies have demonstrated that learning a meaningful internal representation can both accelerate generative training and enhance the generation quality of diffusion transformers. However, existing approaches necessitate to either introduce an external and complex representation training framework or rely on a large-scale, pre-trained representation foundation model to provide representation guidance during the original generative training process. In this study, we posit that the unique discriminative process inherent to diffusion transformers enables them to offer such guidance without requiring external representation components. We therefore propose Self-Representation Alignment (SRA), a simple yet straightforward method that obtains representation guidance through a self-distillation manner. Specifically, SRA aligns the output latent representation of the diffusion transformer in the earlier layer with higher noise to that in the later layer with lower noise to progressively enhance the overall representation learning during only the generative training process. Experimental results indicate that applying SRA to DiTs and SiTs yields consistent performance improvements. Moreover, SRA not only significantly outperforms approaches relying on auxiliary, complex representation training frameworks but also achieves performance comparable to methods that are heavily dependent on powerful external representation priors.","authors":["Dengyang Jiang","Mengmeng Wang","Liuzhuozheng Li","Lei Zhang","Haoyu Wang","Wei Wei","Guang Dai","Yanning Zhang","Jingdong Wang"],"url":"https://arxiv.org/abs/2505.02831"}
{"created":"2025-05-20","title":"AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning","abstract":"Critical peer review of scientific manuscripts presents a significant challenge for Large Language Models (LLMs), partly due to data limitations and the complexity of expert reasoning. This report introduces Persistent Workflow Prompting (PWP), a potentially broadly applicable prompt engineering methodology designed to bridge this gap using standard LLM chat interfaces (zero-code, no APIs). We present a proof-of-concept PWP prompt for the critical analysis of experimental chemistry manuscripts, featuring a hierarchical, modular architecture (structured via Markdown) that defines detailed analysis workflows. We develop this PWP prompt through iterative application of meta-prompting techniques and meta-reasoning aimed at systematically codifying expert review workflows, including tacit knowledge. Submitted once at the start of a session, this PWP prompt equips the LLM with persistent workflows triggered by subsequent queries, guiding modern reasoning LLMs through systematic, multimodal evaluations. Demonstrations show the PWP-guided LLM identifying major methodological flaws in a test case while mitigating LLM input bias and performing complex tasks, including distinguishing claims from evidence, integrating text/photo/figure analysis to infer parameters, executing quantitative feasibility checks, comparing estimates against claims, and assessing a priori plausibility. To ensure transparency and facilitate replication, we provide full prompts, detailed demonstration analyses, and logs of interactive chats as supplementary resources. Beyond the specific application, this work offers insights into the meta-development process itself, highlighting the potential of PWP, informed by detailed workflow formalization, to enable sophisticated analysis using readily available LLMs for complex scientific tasks.","authors":["Evgeny Markhasin"],"url":"https://arxiv.org/abs/2505.03332"}
{"created":"2025-05-20","title":"Task Reconstruction and Extrapolation for $\\pi_0$ using Text Latent","abstract":"Vision-language-action models (VLAs) often achieve high performance on demonstrated tasks but struggle significantly when required to extrapolate, combining skills learned from different tasks in novel ways. For instance, VLAs might successfully put the cream cheese in the bowl and put the bowl on top of the cabinet, yet still fail to put the cream cheese on top of the cabinet. In this work, we demonstrate that behaviors from distinct tasks can be effectively recombined by manipulating the VLA's internal representations at inference time. Concretely, we identify the text latent by averaging the text tokens' hidden states across all demonstrated trajectories for a specific base task. For executing an extrapolated task, we can temporally interpolate the text latent of the two base tasks and add it back to the text hidden states, so sub-behaviors from the two tasks will be activated sequentially. We evaluate this approach using the newly created libero-ood benchmark, featuring 20 tasks extrapolated from standard LIBERO suites. The results on libero-ood show that all SOTA VLAs achieve < 15% success rate, while $\\pi0$ with text latent interpolation reaches an 83% success rate. Further qualitative analysis reveals a tendency for VLAs to exhibit spatial overfitting, mapping object names to demonstrated locations rather than achieving genuine object and goal understanding. Additionally, we find that decoding the text latent yields human-unreadable prompts that can nevertheless instruct the VLA to achieve a 70% success rate on standard LIBERO suites, enabling private instruction or backdoor attacks.","authors":["Quanyi Li"],"url":"https://arxiv.org/abs/2505.03500"}
{"created":"2025-05-20","title":"PAHA: Parts-Aware Audio-Driven Human Animation with Diffusion Model","abstract":"Audio-driven human animation technology is widely used in human-computer interaction, and the emergence of diffusion models has further advanced its development. Currently, most methods rely on multi-stage generation and intermediate representations, resulting in long inference time and issues with generation quality in specific foreground regions and audio-motion consistency. These shortcomings are primarily due to the lack of localized fine-grained supervised guidance. To address above challenges, we propose PAHA, an end-to-end audio-driven upper-body human animation framework with diffusion model. We introduce two key methods: Parts-Aware Re-weighting (PAR) and Parts Consistency Enhancement (PCE). PAR dynamically adjusts regional training loss weights based on pose confidence scores, effectively improving visual quality. PCE constructs and trains diffusion-based regional audio-visual classifiers to improve the consistency of motion and co-speech audio. Afterwards, we design two novel inference guidance methods for the foregoing classifiers, Sequential Guidance (SG) and Differential Guidance (DG), to balance efficiency and quality respectively. Additionally, we build CNAS, the first public Chinese News Anchor Speech dataset, to advance research and validation in this field. Extensive experimental results and user studies demonstrate that PAHA significantly outperforms existing methods in audio-motion alignment and video-related evaluations. The codes and CNAS dataset will be released upon acceptance.","authors":["S. Z. Zhou","Y. B. Wang","J. F. Wu","T. Hu","J. N. Zhang","Z. J. Li","Y. Liu"],"url":"https://arxiv.org/abs/2505.03603"}
{"created":"2025-05-20","title":"ReGraP-LLaVA: Reasoning enabled Graph-based Personalized Large Language and Vision Assistant","abstract":"Recent advances in personalized MLLMs enable effective capture of user-specific concepts, supporting both recognition of personalized concepts and contextual captioning. However, humans typically explore and reason over relations among objects and individuals, transcending surface-level information to achieve more personalized and contextual understanding. To this end, existing methods may face three main limitations: Their training data lacks multi-object sets in which relations among objects are learnable. Building on the limited training data, their models overlook the relations between different personalized concepts and fail to reason over them. Their experiments mainly focus on a single personalized concept, where evaluations are limited to recognition and captioning tasks. To address the limitations, we present a new dataset named ReGraP, consisting of 120 sets of personalized knowledge. Each set includes images, KGs, and CoT QA pairs derived from the KGs, enabling more structured and sophisticated reasoning pathways. We propose ReGraP-LLaVA, an MLLM trained with the corresponding KGs and CoT QA pairs, where soft and hard graph prompting methods are designed to align KGs within the model's semantic space. We establish the ReGraP Benchmark, which contains diverse task types: multiple-choice, fill-in-the-blank, True/False, and descriptive questions in both open- and closed-ended settings. The proposed benchmark is designed to evaluate the relational reasoning and knowledge-connection capability of personalized MLLMs. We conduct experiments on the proposed ReGraP-LLaVA and other competitive MLLMs. Results show that the proposed model not only learns personalized knowledge but also performs relational reasoning in responses, achieving the SoTA performance compared with the competitive methods. All the codes and datasets are released at: https://github.com/xyfyyds/ReGraP.","authors":["Yifan Xiang","Zhenxi Zhang","Bin Li","Yixuan Weng","Shoujun Zhou","Yangfan He","Keqin Li"],"url":"https://arxiv.org/abs/2505.03654"}
{"created":"2025-05-20","title":"Self-Supervised Learning for Robotic Leaf Manipulation: A Hybrid Geometric-Neural Approach","abstract":"Automating leaf manipulation in agricultural settings faces significant challenges, including the variability of plant morphologies and deformable leaves. We propose a novel hybrid geometric-neural approach for autonomous leaf grasping that combines traditional computer vision with neural networks through self-supervised learning. Our method integrates YOLOv8 for instance segmentation and RAFT-Stereo for 3D depth estimation to build rich leaf representations, which feed into both a geometric feature scoring pipeline and a neural refinement module (GraspPointCNN). The key innovation is our confidence-weighted fusion mechanism that dynamically balances the contribution of each approach based on prediction certainty. Our self-supervised framework uses the geometric pipeline as an expert teacher to automatically generate training data. Experiments demonstrate that our approach achieves an 88.0% success rate in controlled environments and 84.7% in real greenhouse conditions, significantly outperforming both purely geometric (75.3%) and neural (60.2%) methods. This work establishes a new paradigm for agricultural robotics where domain expertise is seamlessly integrated with machine learning capabilities, providing a foundation for fully automated crop monitoring systems.","authors":["Srecharan Selvam"],"url":"https://arxiv.org/abs/2505.03702"}
{"created":"2025-05-20","title":"Non-stationary Diffusion For Probabilistic Time Series Forecasting","abstract":"Due to the dynamics of underlying physics and external influences, the uncertainty of time series often varies over time. However, existing Denoising Diffusion Probabilistic Models (DDPMs) often fail to capture this non-stationary nature, constrained by their constant variance assumption from the additive noise model (ANM). In this paper, we innovatively utilize the Location-Scale Noise Model (LSNM) to relax the fixed uncertainty assumption of ANM. A diffusion-based probabilistic forecasting framework, termed Non-stationary Diffusion (NsDiff), is designed based on LSNM that is capable of modeling the changing pattern of uncertainty. Specifically, NsDiff combines a denoising diffusion-based conditional generative model with a pre-trained conditional mean and variance estimator, enabling adaptive endpoint distribution modeling. Furthermore, we propose an uncertainty-aware noise schedule, which dynamically adjusts the noise levels to accurately reflect the data uncertainty at each step and integrates the time-varying variances into the diffusion process. Extensive experiments conducted on nine real-world and synthetic datasets demonstrate the superior performance of NsDiff compared to existing approaches. Code is available at https://github.com/wwy155/NsDiff.","authors":["Weiwei Ye","Zhuopeng Xu","Ning Gui"],"url":"https://arxiv.org/abs/2505.04278"}
{"created":"2025-05-20","title":"Benchmarking LLMs' Swarm intelligence","abstract":"Large Language Models (LLMs) show potential for complex reasoning, yet their capacity for emergent coordination in Multi-Agent Systems (MAS) when operating under strict swarm-like constraints-limited local perception and communication-remains largely unexplored. Existing benchmarks often do not fully capture the unique challenges of decentralized coordination when agents operate with incomplete spatio-temporal information. To bridge this gap, we introduce SwarmBench, a novel benchmark designed to systematically evaluate the swarm intelligence capabilities of LLMs acting as decentralized agents. SwarmBench features five foundational MAS coordination tasks (Pursuit, Synchronization, Foraging, Flocking, Transport) within a configurable 2D grid environment, forcing agents to rely solely on local sensory input ($k\\times k$ view) and local communication. We propose metrics for coordination effectiveness and analyze emergent group dynamics. Zero-shot evaluations of leading LLMs (e.g., deepseek-v3, o4-mini) reveal significant task-dependent performance variations. While some rudimentary coordination is observed, our results indicate that current LLMs significantly struggle with robust long-range planning and adaptive strategy formation under the uncertainty inherent in these decentralized scenarios. Assessing LLMs under such swarm-like constraints is crucial for understanding their utility in future decentralized intelligent systems. We release SwarmBench as an open, extensible toolkit-built on a customizable physical system-providing environments, prompts, evaluation scripts, and comprehensive datasets. This aims to foster reproducible research into LLM-based MAS coordination and the theoretical underpinnings of emergent collective behavior under severe informational decentralization. Our code repository is available at https://github.com/x66ccff/swarmbench.","authors":["Kai Ruan","Mowen Huang","Ji-Rong Wen","Hao Sun"],"url":"https://arxiv.org/abs/2505.04364"}
{"created":"2025-05-20","title":"Reward-SQL: Boosting Text-to-SQL via Stepwise Reasoning and Process-Supervised Rewards","abstract":"Recent advances in large language models (LLMs) have significantly improved performance on the Text-to-SQL task by leveraging their powerful reasoning capabilities. To enhance accuracy during the reasoning process, external Process Reward Models (PRMs) can be introduced during training and inference to provide fine-grained supervision. However, if misused, PRMs may distort the reasoning trajectory and lead to suboptimal or incorrect SQL generation. To address this challenge, we propose Reward-SQL, a framework that systematically explores how to incorporate PRMs into the Text-to-SQL reasoning process effectively. Our approach follows a \"cold start, then PRM supervision\" paradigm. Specifically, we first train the model to decompose SQL queries into structured stepwise reasoning chains using common table expressions (Chain-of-CTEs), establishing a strong and interpretable reasoning baseline. Then, we investigate four strategies for integrating PRMs, and find that combining PRM as an online training signal (e.g.,GRPO) with PRM-guided inference (e.g., best-of-N sampling) yields the best results. Empirically, on the BIRD benchmark, Reward-SQL enables models supervised by PRM (7B) to achieve a 13.1% performance gain across various guidance strategies. Notably, our GRPO-aligned policy model based on Qwen2.5-Coder-7B-Instruct achieves 68.9% accuracy on the BIRD development set, outperforming all baseline methods under the same model size. These results demonstrate the effectiveness of Reward-SQL in leveraging reward-based supervision for Text-to-SQL reasoning.","authors":["Yuxin Zhang","Meihao Fan","Ju Fan","Mingyang Yi","Yuyu Luo","Jian Tan","Guoliang Li"],"url":"https://arxiv.org/abs/2505.04671"}
{"created":"2025-05-20","title":"Conformal Prediction with Corrupted Labels: Uncertain Imputation and Robust Re-weighting","abstract":"We introduce a framework for robust uncertainty quantification in situations where labeled training data are corrupted, through noisy or missing labels. We build on conformal prediction, a statistical tool for generating prediction sets that cover the test label with a pre-specified probability. The validity of conformal prediction, however, holds under the i.i.d assumption, which does not hold in our setting due to the corruptions in the data. To account for this distribution shift, the privileged conformal prediction (PCP) method proposed leveraging privileged information (PI) -- additional features available only during training -- to re-weight the data distribution, yielding valid prediction sets under the assumption that the weights are accurate. In this work, we analyze the robustness of PCP to inaccuracies in the weights. Our analysis indicates that PCP can still yield valid uncertainty estimates even when the weights are poorly estimated. Furthermore, we introduce uncertain imputation (UI), a new conformal method that does not rely on weight estimation. Instead, we impute corrupted labels in a way that preserves their uncertainty. Our approach is supported by theoretical guarantees and validated empirically on both synthetic and real benchmarks. Finally, we show that these techniques can be integrated into a triply robust framework, ensuring statistically valid predictions as long as at least one underlying method is valid.","authors":["Shai Feldman","Stephen Bates","Yaniv Romano"],"url":"https://arxiv.org/abs/2505.04733"}
{"created":"2025-05-20","title":"Zip-Tries: Simple Dynamic Data Structures for Strings","abstract":"In this paper, we introduce zip-tries, which are simple, dynamic, memory-efficient data structures for strings. Zip-tries support search and update operations for $k$-length strings in $\\mathcal{O}(k+\\log n)$ time in the standard RAM model or in $\\mathcal{O}(k/\\alpha+\\log n)$ time in the word RAM model, where $\\alpha$ is the length of the longest string that can fit in a memory word, and $n$ is the number of strings in the trie. Importantly, we show how zip-tries can achieve this while only requiring $\\mathcal{O}(\\log{\\log{n}} + \\log{\\log{\\frac{k}{\\alpha}}})$ bits of metadata per node w.h.p., which is an exponential improvement over previous results for long strings. Despite being considerably simpler and more memory efficient, we show how zip-tries perform competitively with state-of-the-art data structures on large datasets of long strings.","authors":["David Eppstein (University of California","Irvine)","Ofek Gila (University of California","Irvine)","Michael T. Goodrich (University of California","Irvine)","Ryuto Kitagawa (University of California","Irvine)"],"url":"https://arxiv.org/abs/2505.04953"}
{"created":"2025-05-20","title":"SOAP: Style-Omniscient Animatable Portraits","abstract":"Creating animatable 3D avatars from a single image remains challenging due to style limitations (realistic, cartoon, anime) and difficulties in handling accessories or hairstyles. While 3D diffusion models advance single-view reconstruction for general objects, outputs often lack animation controls or suffer from artifacts because of the domain gap. We propose SOAP, a style-omniscient framework to generate rigged, topology-consistent avatars from any portrait. Our method leverages a multiview diffusion model trained on 24K 3D heads with multiple styles and an adaptive optimization pipeline to deform the FLAME mesh while maintaining topology and rigging via differentiable rendering. The resulting textured avatars support FACS-based animation, integrate with eyeballs and teeth, and preserve details like braided hair or accessories. Extensive experiments demonstrate the superiority of our method over state-of-the-art techniques for both single-view head modeling and diffusion-based generation of Image-to-3D. Our code and data are publicly available for research purposes at https://github.com/TingtingLiao/soap.","authors":["Tingting Liao","Yujian Zheng","Adilbek Karmanov","Liwen Hu","Leyang Jin","Yuliang Xiu","Hao Li"],"url":"https://arxiv.org/abs/2505.05022"}
{"created":"2025-05-20","title":"Dequantified Diffusion-Schr{\\\"o}dinger Bridge for Density Ratio Estimation","abstract":"Density ratio estimation is fundamental to tasks involving $f$-divergences, yet existing methods often fail under significantly different distributions or inadequately overlap supports, suffering from the density-chasm and the support-chasm problems. Additionally, prior approaches yield divergent time scores near boundaries, leading to instability. We design $\\textbf{D}^3\\textbf{RE}$, a unified framework for robust, stable and efficient density ratio estimation. We propose the dequantified diffusion bridge interpolant (DDBI), which expands support coverage and stabilizes time scores via diffusion bridges and Gaussian dequantization. Building on DDBI, the proposed dequantified Schr{\\\"o}dinger bridge interpolant (DSBI) incorporates optimal transport to solve the Schr{\\\"o}dinger bridge problem, enhancing accuracy and efficiency. Our method offers uniform approximation and bounded time scores in theory, and outperforms baselines empirically in mutual information and density estimation tasks.","authors":["Wei Chen","Shigui Li","Jiacheng Li","Junmei Yang","John Paisley","Delu Zeng"],"url":"https://arxiv.org/abs/2505.05034"}
{"created":"2025-05-20","title":"RICo: Refined In-Context Contribution for Automatic Instruction-Tuning Data Selection","abstract":"Data selection for instruction tuning is crucial for improving the performance of large language models (LLMs) while reducing training costs. In this paper, we propose Refined Contribution Measurement with In-Context Learning (RICo), a novel gradient-free method that quantifies the fine-grained contribution of individual samples to both task-level and global-level model performance. RICo enables more accurate identification of high-contribution data, leading to better instruction tuning. We further introduce a lightweight selection paradigm trained on RICo scores, enabling scalable data selection with a strictly linear inference complexity. Extensive experiments on three LLMs across 12 benchmarks and 5 pairwise evaluation sets demonstrate the effectiveness of RICo. Remarkably, on LLaMA3.1-8B, models trained on 15% of RICo-selected data outperform full datasets by 5.42% points and exceed the best performance of widely used selection methods by 2.06% points. We further analyze high-contribution samples selected by RICo, which show both diverse tasks and appropriate difficulty levels, rather than just the hardest ones.","authors":["Yixin Yang","Qingxiu Dong","Linli Yao","Fangwei Zhu","Zhifang Sui"],"url":"https://arxiv.org/abs/2505.05327"}
{"created":"2025-05-20","title":"A Preliminary Study for GPT-4o on Image Restoration","abstract":"OpenAI's GPT-4o model, integrating multi-modal inputs and outputs within an autoregressive architecture, has demonstrated unprecedented performance in image generation. In this work, we investigate its potential impact on the image restoration community. We present the first systematic evaluation of GPT-4o across diverse restoration tasks. Our experiments reveal that, although restoration outputs from GPT-4o are visually appealing, they often suffer from pixel-level structural fidelity when compared to ground-truth images. Common issues are variations in image proportions, shifts in object positions and quantities, and changes in viewpoint. To address it, taking image dehazing, derainning, and low-light enhancement as representative case studies, we show that GPT-4o's outputs can serve as powerful visual priors, substantially enhancing the performance of existing dehazing networks. It offers practical guidelines and a baseline framework to facilitate the integration of GPT-4o into future image restoration pipelines. We hope the study on GPT-4o image restoration will accelerate innovation in the broader field of image generation areas. To support further research, we will release GPT-4o-restored images.","authors":["Hao Yang","Yan Yang","Ruikun Zhang","Liyuan Pan"],"url":"https://arxiv.org/abs/2505.05621"}
{"created":"2025-05-20","title":"Conditional Front-door Adjustment for Heterogeneous Treatment Assignment Effect Estimation Under Non-adherence","abstract":"Estimates of heterogeneous treatment assignment effects can inform treatment decisions. Under the presence of non-adherence (e.g., patients do not adhere to their assigned treatment), both the standard backdoor adjustment (SBD) and the conditional front-door adjustment (CFD) can recover unbiased estimates of the treatment assignment effects. However, the estimation variance of these approaches may vary widely across settings, which remains underexplored in the literature. In this work, we demonstrate theoretically and empirically that CFD yields lower-variance estimates than SBD when the true effect of treatment assignment is small (i.e., assigning an intervention leads to small changes in patients' future outcome). Additionally, since CFD requires estimating multiple nuisance parameters, we introduce LobsterNet, a multi-task neural network that implements CFD with joint modeling of the nuisance parameters. Empirically, LobsterNet reduces estimation error across several semi-synthetic and real-world datasets compared to baselines. Our findings suggest CFD with shared nuisance parameter modeling can improve treatment assignment effect estimation under non-adherence.","authors":["Winston Chen","Trenton Chang","Jenna Wiens"],"url":"https://arxiv.org/abs/2505.05677"}
{"created":"2025-05-20","title":"InstanceGen: Image Generation with Instance-level Instructions","abstract":"Despite rapid advancements in the capabilities of generative models, pretrained text-to-image models still struggle in capturing the semantics conveyed by complex prompts that compound multiple objects and instance-level attributes. Consequently, we are witnessing growing interests in integrating additional structural constraints, typically in the form of coarse bounding boxes, to better guide the generation process in such challenging cases. In this work, we take the idea of structural guidance a step further by making the observation that contemporary image generation models can directly provide a plausible fine-grained structural initialization. We propose a technique that couples this image-based structural guidance with LLM-based instance-level instructions, yielding output images that adhere to all parts of the text prompt, including object counts, instance-level attributes, and spatial relations between instances.","authors":["Etai Sella","Yanir Kleiman","Hadar Averbuch-Elor"],"url":"https://arxiv.org/abs/2505.05678"}
{"created":"2025-05-20","title":"Dual-level Fuzzy Learning with Patch Guidance for Image Ordinal Regression","abstract":"Ordinal regression bridges regression and classification by assigning objects to ordered classes. While human experts rely on discriminative patch-level features for decisions, current approaches are limited by the availability of only image-level ordinal labels, overlooking fine-grained patch-level characteristics. In this paper, we propose a Dual-level Fuzzy Learning with Patch Guidance framework, named DFPG that learns precise feature-based grading boundaries from ambiguous ordinal labels, with patch-level supervision. Specifically, we propose patch-labeling and filtering strategies to enable the model to focus on patch-level features exclusively with only image-level ordinal labels available. We further design a dual-level fuzzy learning module, which leverages fuzzy logic to quantitatively capture and handle label ambiguity from both patch-wise and channel-wise perspectives. Extensive experiments on various image ordinal regression datasets demonstrate the superiority of our proposed method, further confirming its ability in distinguishing samples from difficult-to-classify categories. The code is available at https://github.com/ZJUMAI/DFPG-ord.","authors":["Chunlai Dong","Haochao Ying","Qibo Qiu","Jinhong Wang","Danny Chen","Jian Wu"],"url":"https://arxiv.org/abs/2505.05834"}
{"created":"2025-05-20","title":"Learn to Think: Bootstrapping LLM Reasoning Capability Through Graph Representation Learning","abstract":"Large Language Models (LLMs) have achieved remarkable success across various domains. However, they still face significant challenges, including high computational costs for training and limitations in solving complex reasoning problems. Although existing methods have extended the reasoning capabilities of LLMs through structured paradigms, these approaches often rely on task-specific prompts and predefined reasoning processes, which constrain their flexibility and generalizability. To address these limitations, we propose a novel framework that leverages graph learning to enable more flexible and adaptive reasoning capabilities for LLMs. Specifically, this approach models the reasoning process of a problem as a graph and employs LLM-based graph learning to guide the adaptive generation of each reasoning step. To further enhance the adaptability of the model, we introduce a Graph Neural Network (GNN) module to perform representation learning on the generated reasoning process, enabling real-time adjustments to both the model and the prompt. Experimental results demonstrate that this method significantly improves reasoning performance across multiple tasks without requiring additional training or task-specific prompt design. Code can be found in https://github.com/zch65458525/L2T.","authors":["Hang Gao","Chenhao Zhang","Tie Wang","Junsuo Zhao","Fengge Wu","Changwen Zheng","Huaping Liu"],"url":"https://arxiv.org/abs/2505.06321"}
{"created":"2025-05-20","title":"Gaming the Metrics? Bibliometric Anomalies and the Integrity Crisis in Global University Rankings","abstract":"Global university rankings have reshaped how academic success is defined, incentivizing metrics such as publication counts and citation rates at the expense of scholarly integrity. This study examines 18 universities in India, Lebanon, Saudi Arabia, and the United Arab Emirates, selected from among the world's 1,000 most-publishing institutions for their extraordinary research growth and sharp declines in first and corresponding authorship. These institutions exhibit bibliometric patterns consistent with strategic metric optimization, including publication surges of up to 965%, a proliferation of hyper-prolific authors, dense reciprocal co-authorship and citation networks, elevated shares of output in delisted journals, and rising retraction rates. These patterns are analyzed in light of Goodhart's Law and institutional isomorphism, illustrating how performance pressures can reshape academic behavior. To systematically assess and monitor such risks, the study introduces the Research Integrity Risk Index (RI2), a composite indicator based on retraction rates and reliance on delisted journals. RI2 effectively identifies institutions with bibliometric profiles that diverge from global norms and may warrant closer examination. The findings highlight the urgent need for integrity-sensitive reforms in how rankings, funders, and institutions assess scholarly performance.","authors":["Lokman I. Meho"],"url":"https://arxiv.org/abs/2505.06448"}
{"created":"2025-05-20","title":"Video-Enhanced Offline Reinforcement Learning: A Model-Based Approach","abstract":"Offline reinforcement learning (RL) enables policy optimization using static datasets, avoiding the risks and costs of extensive real-world exploration. However, it struggles with suboptimal offline behaviors and inaccurate value estimation due to the lack of environmental interaction. We present Video-Enhanced Offline RL (VeoRL), a model-based method that constructs an interactive world model from diverse, unlabeled video data readily available online. Leveraging model-based behavior guidance, our approach transfers commonsense knowledge of control policy and physical dynamics from natural videos to the RL agent within the target domain. VeoRL achieves substantial performance gains (over 100% in some cases) across visual control tasks in robotic manipulation, autonomous driving, and open-world video games.","authors":["Minting Pan","Yitao Zheng","Jiajian Li","Yunbo Wang","Xiaokang Yang"],"url":"https://arxiv.org/abs/2505.06482"}
{"created":"2025-05-20","title":"An In-kernel Forensics Engine for Investigating Evasive Attacks","abstract":"Over the years, adversarial attempts against critical services have become more effective and sophisticated in launching low-profile attacks. This trend has always been concerning. However, an even more alarming trend is the increasing difficulty of collecting relevant evidence about these attacks and the involved threat actors in the early stages before significant damage is done. This issue puts defenders at a significant disadvantage, as it becomes exceedingly difficult to understand the attack details and formulate an appropriate response. Developing robust forensics tools to collect evidence about modern threats has never been easy. One main challenge is to provide a robust trade-off between achieving sufficient visibility while leaving minimal detectable artifacts. This paper will introduce LASE, an open-source Low-Artifact Forensics Engine to perform threat analysis and forensics in Windows operating system. LASE augments current analysis tools by providing detailed, system-wide monitoring capabilities while minimizing detectable artifacts. We designed multiple deployment scenarios, showing LASE's potential in evidence gathering and threat reasoning in a real-world setting. By making LASE and its execution trace data available to the broader research community, this work encourages further exploration in the field by reducing the engineering costs for threat analysis and building a longitudinal behavioral analysis catalog for diverse security domains.","authors":["Javad Zandi","Lalchandra Rampersaud","Amin Kharraz"],"url":"https://arxiv.org/abs/2505.06498"}
{"created":"2025-05-20","title":"Dataset Distillation with Probabilistic Latent Features","abstract":"As deep learning models grow in complexity and the volume of training data increases, reducing storage and computational costs becomes increasingly important. Dataset distillation addresses this challenge by synthesizing a compact set of synthetic data that can effectively replace the original dataset in downstream classification tasks. While existing methods typically rely on mapping data from pixel space to the latent space of a generative model, we propose a novel stochastic approach that models the joint distribution of latent features. This allows our method to better capture spatial structures and produce diverse synthetic samples, which benefits model training. Specifically, we introduce a low-rank multivariate normal distribution parameterized by a lightweight network. This design maintains low computational complexity and is compatible with various matching networks used in dataset distillation. After distillation, synthetic images are generated by feeding the learned latent features into a pretrained generator. These synthetic images are then used to train classification models, and performance is evaluated on real test set. We validate our method on several benchmarks, including ImageNet subsets, CIFAR-10, and the MedMNIST histopathological dataset. Our approach achieves state-of-the-art cross architecture performance across a range of backbone architectures, demonstrating its generality and effectiveness.","authors":["Zhe Li","Sarah Cechnicka","Cheng Ouyang","Katharina Breininger","Peter Sch\\\"uffler","Bernhard Kainz"],"url":"https://arxiv.org/abs/2505.06647"}
{"created":"2025-05-20","title":"Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws","abstract":"This paper formalizes an emerging learning paradigm that uses a trained model as a reference to guide and enhance the training of a target model through strategic data selection or weighting, named $\\textbf{model steering}$. While ad-hoc methods have been used in various contexts, including the training of large foundation models, its underlying principles remain insufficiently understood, leading to sub-optimal performance. In this work, we propose a theory-driven framework for model steering called $\\textbf{DRRho risk minimization}$, which is rooted in Distributionally Robust Optimization (DRO). Through a generalization analysis, we provide theoretical insights into why this approach improves generalization and data efficiency compared to training without a reference model. To the best of our knowledge, this is the first time such theoretical insights are provided for the new learning paradigm, which significantly enhance our understanding and practice of model steering. Building on these insights and the connection between contrastive learning and DRO, we introduce a novel method for Contrastive Language-Image Pretraining (CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments validate the theoretical insights, reveal a superior scaling law compared to CLIP without a reference model, and demonstrate its strength over existing heuristic approaches.","authors":["Xiyuan Wei","Ming Lin","Fanjiang Ye","Fengguang Song","Liangliang Cao","My T. Thai","Tianbao Yang"],"url":"https://arxiv.org/abs/2505.06699"}
{"created":"2025-05-20","title":"\"Explain, Don't Just Warn!\" -- A Real-Time Framework for Generating Phishing Warnings with Contextual Cues","abstract":"Anti-phishing tools typically display generic warnings that offer users limited explanation on why a website is considered malicious, which can prevent end-users from developing the mental models needed to recognize phishing cues on their own. This becomes especially problematic when these tools inevitably fail - particularly against evasive threats, and users are found to be ill-equipped to identify and avoid them independently. To address these limitations, we present PhishXplain (PXP), a real-time explainable phishing warning system designed to augment existing detection mechanisms. PXP empowers users by clearly articulating why a site is flagged as malicious, highlighting suspicious elements using a memory-efficient implementation of LLaMA 3.2. It utilizes a structured two-step prompt architecture to identify phishing features, generate contextual explanations, and render annotated screenshots that visually reinforce the warning. Longitudinally implementing PhishXplain over a month on 7,091 live phishing websites, we found that it can generate warnings for 94% of the sites, with a correctness of 96%. We also evaluated PhishXplain through a user study with 150 participants split into two groups: one received conventional, generic warnings, while the other interacted with PXP's explainable alerts. Participants who received the explainable warnings not only demonstrated a significantly better understanding of phishing indicators but also achieved higher accuracy in identifying phishing threats, even without any warning. Moreover, they reported greater satisfaction and trust in the warnings themselves. These improvements were especially pronounced among users with lower initial levels of cybersecurity proficiency and awareness. To encourage the adoption of this framework, we release PhishXplain as a browser extension.","authors":["Sayak Saha Roy","Cesar Torres","Shirin Nilizadeh"],"url":"https://arxiv.org/abs/2505.06836"}
{"created":"2025-05-20","title":"FACET: Force-Adaptive Control via Impedance Reference Tracking for Legged Robots","abstract":"Reinforcement learning (RL) has made significant strides in legged robot control, enabling locomotion across diverse terrains and complex loco-manipulation capabilities. However, the commonly used position or velocity tracking-based objectives are agnostic to forces experienced by the robot, leading to stiff and potentially dangerous behaviors and poor control during forceful interactions. To address this limitation, we present \\emph{Force-Adaptive Control via Impedance Reference Tracking} (FACET). Inspired by impedance control, we use RL to train a control policy to imitate a virtual mass-spring-damper system, allowing fine-grained control under external forces by manipulating the virtual spring. In simulation, we demonstrate that our quadruped robot achieves improved robustness to large impulses (up to 200 Ns) and exhibits controllable compliance, achieving an 80% reduction in collision impulse. The policy is deployed to a physical robot to showcase both compliance and the ability to engage with large forces by kinesthetic control and pulling payloads up to 2/3 of its weight. Further extension to a legged loco-manipulator and a humanoid shows the applicability of our method to more complex settings to enable whole-body compliance control. Project Website: https://facet.pages.dev/","authors":["Botian Xu","Haoyang Weng","Qingzhou Lu","Yang Gao","Huazhe Xu"],"url":"https://arxiv.org/abs/2505.06883"}
{"created":"2025-05-20","title":"Bridging AI and Carbon Capture: A Dataset for LLMs in Ionic Liquids and CBE Research","abstract":"Large Language Models (LLMs) have demonstrated exceptional performance in general knowledge and reasoning tasks across various domains. However, their effectiveness in specialized scientific fields like Chemical and Biological Engineering (CBE) remains underexplored. Addressing this gap requires robust evaluation benchmarks that assess both knowledge and reasoning capabilities in these niche areas, which are currently lacking. To bridge this divide, we present a comprehensive empirical analysis of LLM reasoning capabilities in CBE, with a focus on Ionic Liquids (ILs) for carbon sequestration - an emerging solution for mitigating global warming. We develop and release an expert - curated dataset of 5,920 examples designed to benchmark LLMs' reasoning in this domain. The dataset incorporates varying levels of difficulty, balancing linguistic complexity and domain-specific knowledge. Using this dataset, we evaluate three open-source LLMs with fewer than 10 billion parameters. Our findings reveal that while smaller general-purpose LLMs exhibit basic knowledge of ILs, they lack the specialized reasoning skills necessary for advanced applications. Building on these results, we discuss strategies to enhance the utility of LLMs for carbon capture research, particularly using ILs. Given the significant carbon footprint of LLMs, aligning their development with IL research presents a unique opportunity to foster mutual progress in both fields and advance global efforts toward achieving carbon neutrality by 2050.","authors":["Gaurab Sarkar","Sougata Saha"],"url":"https://arxiv.org/abs/2505.06964"}
{"created":"2025-05-20","title":"The $K_\\infty$ Homotopy $\\lambda$-Model","abstract":"We extend the complete ordered set Dana Scott's $D_\\infty$ to a complete weakly ordered Kan complex $K_\\infty$, with properties that guarantee the non-equivalence of the interpretation of some higher conversions of $\\beta\\eta$-conversions of $\\lambda$-terms.","authors":["Daniel O. Mart\\'inez-Rivillas","Ruy J. G. B. de Queiroz"],"url":"https://arxiv.org/abs/2505.07103"}
{"created":"2025-05-20","title":"Minimal Linear Codes Violating the Ashikhmin-Barg Condition from Arbitrary Projective Linear Codes","abstract":"In recent years, there have been many constructions of minimal linear codes violating the Ashikhmin-Barg condition from Boolean functions, linear codes with few nonzero weights or partial difference sets. In this paper, we first give a general method to transform a minimal code satisfying the Ashikhmin-Barg condition to a minimal code violating the Ashikhmin-Barg condition. Then we give a construction of a minimal code satisfying the Ashikhmin-Barg condition from an arbitrary projective linear code. Hence an arbitrary projective linear code can be transformed to a minimal codes violating the Ashikhmin-Barg condition. Then we give infinite many families of minimal codes violating the Ashikhamin-Barg condition. Weight distributions of constructed minimal codes violating the Ashikhmin-Barg condition in this paper are determined. Many minimal linear codes violating the Ashikhmin-Barg condition with their minimum weights close to the optimal or the best known minimum weights of linear codes are constructed in this paper. Moreover, many infinite families of self-orthogonal binary minimal codes violating the Ashikhmin-Barg condition are also given.","authors":["Hao Chen","Yaqi Chen","Conghui Xie","Huimin Lao"],"url":"https://arxiv.org/abs/2505.07130"}
{"created":"2025-05-20","title":"Generative Pre-trained Autoregressive Diffusion Transformer","abstract":"In this work, we present GPDiT, a Generative Pre-trained Autoregressive Diffusion Transformer that unifies the strengths of diffusion and autoregressive modeling for long-range video synthesis, within a continuous latent space. Instead of predicting discrete tokens, GPDiT autoregressively predicts future latent frames using a diffusion loss, enabling natural modeling of motion dynamics and semantic consistency across frames. This continuous autoregressive framework not only enhances generation quality but also endows the model with representation capabilities. Additionally, we introduce a lightweight causal attention variant and a parameter-free rotation-based time-conditioning mechanism, improving both the training and inference efficiency. Extensive experiments demonstrate that GPDiT achieves strong performance in video generation quality, video representation ability, and few-shot learning tasks, highlighting its potential as an effective framework for video modeling in continuous space.","authors":["Yuan Zhang","Jiacheng Jiang","Guoqing Ma","Zhiying Lu","Haoyang Huang","Jianlong Yuan","Nan Duan"],"url":"https://arxiv.org/abs/2505.07344"}
{"created":"2025-05-20","title":"Selftok: Discrete Visual Tokens of Autoregression, by Diffusion, and for Reasoning","abstract":"We completely discard the conventional spatial prior in image representation and introduce a novel discrete visual tokenizer: Self-consistency Tokenizer (Selftok). At its design core, we compose an autoregressive (AR) prior -- mirroring the causal structure of language -- into visual tokens by using the reverse diffusion process of image generation. The AR property makes Selftok fundamentally distinct from traditional spatial tokens in the following two key ways: - Selftok offers an elegant and minimalist approach to unify diffusion and AR for vision-language models (VLMs): By representing images with Selftok tokens, we can train a VLM using a purely discrete autoregressive architecture -- like that in LLMs -- without requiring additional modules or training objectives. - We theoretically show that the AR prior satisfies the Bellman equation, whereas the spatial prior does not. Therefore, Selftok supports reinforcement learning (RL) for visual generation with effectiveness comparable to that achieved in LLMs. Besides the AR property, Selftok is also a SoTA tokenizer that achieves a favorable trade-off between high-quality reconstruction and compression rate. We use Selftok to build a pure AR VLM for both visual comprehension and generation tasks. Impressively, without using any text-image training pairs, a simple policy gradient RL working in the visual tokens can significantly boost the visual generation benchmark, surpassing all the existing models by a large margin. Therefore, we believe that Selftok effectively addresses the long-standing challenge that visual tokens cannot support effective RL. When combined with the well-established strengths of RL in LLMs, this brings us one step closer to realizing a truly multimodal LLM. Project Page: https://selftok-team.github.io/report/.","authors":["Bohan Wang","Zhongqi Yue","Fengda Zhang","Shuo Chen","Li'an Bi","Junzhe Zhang","Xue Song","Kennard Yanting Chan","Jiachun Pan","Weijia Wu","Mingze Zhou","Wang Lin","Kaihang Pan","Saining Zhang","Liyu Jia","Wentao Hu","Wei Zhao","Hanwang Zhang"],"url":"https://arxiv.org/abs/2505.07538"}
{"created":"2025-05-20","title":"Concept-Level Explainability for Auditing & Steering LLM Responses","abstract":"As large language models (LLMs) become widely deployed, concerns about their safety and alignment grow. An approach to steer LLM behavior, such as mitigating biases or defending against jailbreaks, is to identify which parts of a prompt influence specific aspects of the model's output. Token-level attribution methods offer a promising solution, but still struggle in text generation, explaining the presence of each token in the output separately, rather than the underlying semantics of the entire LLM response. We introduce ConceptX, a model-agnostic, concept-level explainability method that identifies the concepts, i.e., semantically rich tokens in the prompt, and assigns them importance based on the outputs' semantic similarity. Unlike current token-level methods, ConceptX also offers to preserve context integrity through in-place token replacements and supports flexible explanation goals, e.g., gender bias. ConceptX enables both auditing, by uncovering sources of bias, and steering, by modifying prompts to shift the sentiment or reduce the harmfulness of LLM responses, without requiring retraining. Across three LLMs, ConceptX outperforms token-level methods like TokenSHAP in both faithfulness and human alignment. Steering tasks boost sentiment shift by 0.252 versus 0.131 for random edits and lower attack success rates from 0.463 to 0.242, outperforming attribution and paraphrasing baselines. While prompt engineering and self-explaining methods sometimes yield safer responses, ConceptX offers a transparent and faithful alternative for improving LLM safety and alignment, demonstrating the practical value of attribution-based explainability in guiding LLM behavior.","authors":["Kenza Amara","Rita Sevastjanova","Mennatallah El-Assady"],"url":"https://arxiv.org/abs/2505.07610"}
{"created":"2025-05-20","title":"S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models","abstract":"As Test-Time Scaling emerges as an active research focus in the large language model community, advanced post-training methods increasingly emphasize extending chain-of-thought (CoT) generation length, thereby enhancing reasoning capabilities to approach Deepseek R1-like reasoning models. However, recent studies reveal that reasoning models (even Qwen3) consistently exhibit excessive thought redundancy in CoT generation. This overthinking issue arises from the inherent limitations of conventional outcome-reward reinforcement learning, which systematically overlooks the regulation of intermediate reasoning processes. This paper introduces Serial-Group Decaying-Reward Policy Optimization (S-GRPO), a novel reinforcement learning paradigm that enables models to implicitly evaluate the sufficiency of intermediate reasoning steps, thereby facilitating early exit in CoT generation. Unlike GRPO, which samples multiple possible reasoning paths in parallel (parallel group), S-GRPO only samples one reasoning path and serially selects multiple temporal positions from the path to exit thinking and directly generate answers (serial group). For correct answers within a serial group, rewards gradually decrease based on the exit positions along the reasoning path from front to back. This design encourages the model to produce more accurate and concise thoughts, while also incentivizing early thinking termination when appropriate. Empirical evaluations demonstrate that S-GRPO is compatible with state-of-the-art reasoning models, including Qwen3 and Deepseek-distill. Across diverse benchmarks such as GSM8K, AIME 2024, AMC 2023, MATH-500, and GPQA Diamond, S-GRPO achieves a substantial reduction in sequence length (35.4% - 61.1%) while simultaneously improving accuracy (absolute 0.72% - 6.08%).","authors":["Muzhi Dai","Chenxu Yang","Qingyi Si"],"url":"https://arxiv.org/abs/2505.07686"}
{"created":"2025-05-20","title":"VISTA: Generative Visual Imagination for Vision-and-Language Navigation","abstract":"Vision-and-Language Navigation (VLN) tasks agents with locating specific objects in unseen environments using natural language instructions and visual cues. Many existing VLN approaches typically follow an 'observe-and-reason' schema, that is, agents observe the environment and decide on the next action to take based on the visual observations of their surroundings. They often face challenges in long-horizon scenarios due to limitations in immediate observation and vision-language modality gaps. To overcome this, we present VISTA, a novel framework that employs an 'imagine-and-align' navigation strategy. Specifically, we leverage the generative prior of pre-trained diffusion models for dynamic visual imagination conditioned on both local observations and high-level language instructions. A Perceptual Alignment Filter module then grounds these goal imaginations against current observations, guiding an interpretable and structured reasoning process for action selection. Experiments show that VISTA sets new state-of-the-art results on Room-to-Room (R2R) and RoboTHOR benchmarks, e.g.,+3.6% increase in Success Rate on R2R. Extensive ablation analysis underscores the value of integrating forward-looking imagination, perceptual alignment, and structured reasoning for robust navigation in long-horizon environments.","authors":["Yanjia Huang","Mingyang Wu","Renjie Li","Zhengzhong Tu"],"url":"https://arxiv.org/abs/2505.07868"}
{"created":"2025-05-20","title":"TSLFormer: A Lightweight Transformer Model for Turkish Sign Language Recognition Using Skeletal Landmarks","abstract":"This study presents TSLFormer, a light and robust word-level Turkish Sign Language (TSL) recognition model that treats sign gestures as ordered, string-like language. Instead of using raw RGB or depth videos, our method only works with 3D joint positions - articulation points - extracted using Google's Mediapipe library, which focuses on the hand and torso skeletal locations. This creates efficient input dimensionality reduction while preserving important semantic gesture information.","authors":["Kutay Ert\\\"urk","Furkan Alt{\\i}n{\\i}\\c{s}{\\i}k","\\.Irem Sar{\\i}alt{\\i}n","\\\"Omer Nezih Gerek"],"url":"https://arxiv.org/abs/2505.07890"}
{"created":"2025-05-20","title":"FairZK: A Scalable System to Prove Machine Learning Fairness in Zero-Knowledge","abstract":"With the rise of machine learning techniques, ensuring the fairness of decisions made by machine learning algorithms has become of great importance in critical applications. However, measuring fairness often requires full access to the model parameters, which compromises the confidentiality of the models. In this paper, we propose a solution using zero-knowledge proofs, which allows the model owner to convince the public that a machine learning model is fair while preserving the secrecy of the model. To circumvent the efficiency barrier of naively proving machine learning inferences in zero-knowledge, our key innovation is a new approach to measure fairness only with model parameters and some aggregated information of the input, but not on any specific dataset. To achieve this goal, we derive new bounds for the fairness of logistic regression and deep neural network models that are tighter and better reflecting the fairness compared to prior work. Moreover, we develop efficient zero-knowledge proof protocols for common computations involved in measuring fairness, including the spectral norm of matrices, maximum, absolute value, and fixed-point arithmetic.","authors":["Tianyu Zhang","Shen Dong","O. Deniz Kose","Yanning Shen","Yupeng Zhang"],"url":"https://arxiv.org/abs/2505.07997"}
{"created":"2025-05-20","title":"Leveraging Reinforcement Learning and Koopman Theory for Enhanced Model Predictive Control Performance","abstract":"This study presents an innovative approach to Model Predictive Control (MPC) by leveraging the powerful combination of Koopman theory and Deep Reinforcement Learning (DRL). By transforming nonlinear dynamical systems into a higher-dimensional linear regime, the Koopman operator facilitates the linear treatment of nonlinear behaviors, paving the way for more efficient control strategies. Our methodology harnesses the predictive prowess of Koopman-based models alongside the optimization capabilities of DRL, particularly using the Proximal Policy Optimization (PPO) algorithm, to enhance the controller's performance. The resulting end-to-end learning framework refines the predictive control policies to cater to specific operational tasks, optimizing both performance and economic efficiency. We validate our approach through rigorous NMPC and eNMPC case studies, demonstrating that the Koopman-RL controller outperforms traditional controllers by achieving higher stability, superior constraint satisfaction, and significant cost savings. The findings indicate that our model can be a robust tool for complex control tasks, offering valuable insights into future applications of RL in MPC.","authors":["Md Nur-A-Adam Dony"],"url":"https://arxiv.org/abs/2505.08122"}
{"created":"2025-05-20","title":"Integrating Koopman theory and Lyapunov stability for enhanced model predictive control in nonlinear systems","abstract":"This paper delves into the challenges posed by the increasing complexity of modern control systems, specifically focusing on bilinear systems, a prevalent subclass of non-linear systems characterized by state dynamics influenced by the interaction of state and control variables. Traditional control strategies, such as PID controllers, often fall short in adequately addressing the intricacies of such systems due to their predictive limitations. To bridge this gap, we introduce Model Predictive Control (MPC), a sophisticated technique that utilizes system models to forecast future behaviors, allowing for the computation of an optimal control sequence by minimizing deviations and control efforts. The Koopman operator emerges as a pivotal tool in this framework by providing a means to linearize the nonlinear dynamics of bilinear systems. By integrating the principles of Lyapunov theory with the linearizing capabilities of the Koopman operator into the MPC framework, we give rise to Koopman Lyapunov-based Model Predictive Control (Koopman LMPC). This approach not only retains MPC's predictive capabilities but also harnesses the Koopman operator's ability to transform complex nonlinear behaviors into a linear framework, thereby enhancing the robustness and applicability of LMPC. With the stability assurances from Lyapunov theory, Koopman LMPC presents a robust solution to effectively control and stabilize bilinear systems. The paper underscores the efficacy of Koopman LMPC, emphasizing its significance in achieving optimal performance and system stability, marking it as a promising approach for the future of advanced control systems.","authors":["Md Nur-A-Adam Dony"],"url":"https://arxiv.org/abs/2505.08139"}
{"created":"2025-05-20","title":"Lost in Transmission: When and Why LLMs Fail to Reason Globally","abstract":"Despite their many successes, transformer-based large language models (LLMs) continue to struggle with tasks that require complex reasoning over large parts of their input. We argue that these failures arise due to capacity limits on the accurate flow of information within LLMs. To formalize this issue, we introduce the bounded attention prefix oracle (BAPO) model, a new computational framework that models bandwidth constraints on attention heads, the mechanism for internal communication in LLMs. We show that several important reasoning problems like graph reachability require high communication bandwidth for BAPOs to solve; we call these problems BAPO-hard. Our experiments corroborate our theoretical predictions: GPT-4o, Claude, and Gemini succeed on BAPO-easy tasks and fail even on relatively small BAPO-hard tasks. BAPOs also reveal another benefit of chain of thought (CoT): we prove that breaking down a task using CoT can turn any BAPO-hard problem into a BAPO-easy one. Our results offer principled explanations for key LLM failures and suggest directions for architectures and inference methods that mitigate bandwidth limits.","authors":["Tobias Schnabel","Kiran Tomlinson","Adith Swaminathan","Jennifer Neville"],"url":"https://arxiv.org/abs/2505.08140"}
{"created":"2025-05-20","title":"Tensor Sketch: Fast and Scalable Polynomial Kernel Approximation","abstract":"Approximation of non-linear kernels using random feature maps has become a powerful technique for scaling kernel methods to large datasets. We propose $\\textit{Tensor Sketch}$, an efficient random feature map for approximating polynomial kernels. Given $n$ training samples in $\\mathbb{R}^d$ Tensor Sketch computes low-dimensional embeddings in $\\mathbb{R}^D$ in time $\\mathcal{O}\\left( n(d+D \\log{D}) \\right)$ making it well-suited for high-dimensional and large-scale settings. We provide theoretical guarantees on the approximation error, ensuring the fidelity of the resulting kernel function estimates. We also discuss extensions and highlight applications where Tensor Sketch serves as a central computational tool.","authors":["Ninh Pham","Rasmus Pagh"],"url":"https://arxiv.org/abs/2505.08146"}
{"created":"2025-05-20","title":"Efficient and Scalable Neural Symbolic Search for Knowledge Graph Complex Query Answering","abstract":"Complex Query Answering (CQA) aims to retrieve answer sets for complex logical formulas from incomplete knowledge graphs, which is a crucial yet challenging task in knowledge graph reasoning. While neuro-symbolic search utilized neural link predictions achieve superior accuracy, they encounter significant complexity bottlenecks: (i) Data complexity typically scales quadratically with the number of entities in the knowledge graph, and (ii) Query complexity becomes NP-hard for cyclic queries. Consequently, these approaches struggle to effectively scale to larger knowledge graphs and more complex queries. To address these challenges, we propose an efficient and scalable symbolic search framework. First, we propose two constraint strategies to compute neural logical indices to reduce the domain of variables, thereby decreasing the data complexity of symbolic search. Additionally, we introduce an approximate algorithm based on local search to tackle the NP query complexity of cyclic queries. Experiments on various CQA benchmarks demonstrate that our framework reduces the computational load of symbolic methods by 90\\% while maintaining nearly the same performance, thus alleviating both efficiency and scalability issues.","authors":["Weizhi Fei","Zihao Wang","hang Yin","Shukai Zhao","Wei Zhang","Yangqiu Song"],"url":"https://arxiv.org/abs/2505.08155"}
{"created":"2025-05-20","title":"Non-Blocking Robustness Analysis in Discrete Event Systems","abstract":"This paper presents a mathematical framework for characterizing state blocking in discrete event systems (DES) under transition deletions. We introduce a path-based analysis approach that determines whether systems maintain non-blocking properties when transitions are removed. Through formal analysis and case studies, we establish three key contributions: a mathematical characterization of transition-induced blocking with necessary and sufficient conditions, a definition of robust deviations that preserve non-blocking properties, and an algorithm for identifying critical transitions and analyzing system behavior under deletions. Our algorithm reduces computational complexity by leveraging minimal blocking sets, achieving significant reduction in computational requirements. We demonstrate the framework's effectiveness through manufacturing system and autonomous vehicle case studies, showing substantial improvements in identifying critical transitions and predicting potential blocking scenarios across different application domains.","authors":["Md Nur-A-Adam Dony"],"url":"https://arxiv.org/abs/2505.08166"}
{"created":"2025-05-20","title":"Deep Probabilistic Modeling of User Behavior for Anomaly Detection via Mixture Density Networks","abstract":"To improve the identification of potential anomaly patterns in complex user behavior, this paper proposes an anomaly detection method based on a deep mixture density network. The method constructs a Gaussian mixture model parameterized by a neural network, enabling conditional probability modeling of user behavior. It effectively captures the multimodal distribution characteristics commonly present in behavioral data. Unlike traditional classifiers that rely on fixed thresholds or a single decision boundary, this approach defines an anomaly scoring function based on probability density using negative log-likelihood. This significantly enhances the model's ability to detect rare and unstructured behaviors. Experiments are conducted on the real-world network user dataset UNSW-NB15. A series of performance comparisons and stability validation experiments are designed. These cover multiple evaluation aspects, including Accuracy, F1- score, AUC, and loss fluctuation. The results show that the proposed method outperforms several advanced neural network architectures in both performance and training stability. This study provides a more expressive and discriminative solution for user behavior modeling and anomaly detection. It strongly promotes the application of deep probabilistic modeling techniques in the fields of network security and intelligent risk control.","authors":["Lu Dai","Wenxuan Zhu","Xuehui Quan","Renzi Meng","Sheng Chai","Yichen Wang"],"url":"https://arxiv.org/abs/2505.08220"}
{"created":"2025-05-20","title":"Training Strategies for Efficient Embodied Reasoning","abstract":"Robot chain-of-thought reasoning (CoT) -- wherein a model predicts helpful intermediate representations before choosing actions -- provides an effective method for improving the generalization and performance of robot policies, especially vision-language-action models (VLAs). While such approaches have been shown to improve performance and generalization, they suffer from core limitations, like needing specialized robot reasoning data and slow inference speeds. To design new robot reasoning approaches that address these issues, a more complete characterization of why reasoning helps policy performance is critical. We hypothesize several mechanisms by which robot reasoning improves policies -- (1) better representation learning, (2) improved learning curricularization, and (3) increased expressivity -- then devise simple variants of robot CoT reasoning to isolate and test each one. We find that learning to generate reasonings does lead to better VLA representations, while attending to the reasonings aids in actually leveraging these features for improved action prediction. Our results provide us with a better understanding of why CoT reasoning helps VLAs, which we use to introduce two simple and lightweight alternative recipes for robot reasoning. Our proposed approaches achieve significant performance gains over non-reasoning policies, state-of-the-art results on the LIBERO-90 benchmark, and a 3x inference speedup compared to standard robot reasoning.","authors":["William Chen","Suneel Belkhale","Suvir Mirchandani","Oier Mees","Danny Driess","Karl Pertsch","Sergey Levine"],"url":"https://arxiv.org/abs/2505.08243"}
{"created":"2025-05-20","title":"Community Recovery on Noisy Stochastic Block Models","abstract":"We study the problem of community recovery in geometrically-noised stochastic block models (SBM). This work presents two primary contributions: (1) Motif--Attention Spectral Operator (MASO), an attention-based spectral operator that improves upon traditional spectral methods; and (2) Iterative Geometric Denoising (GeoDe), a configurable denoising algorithm that boosts spectral clustering performance. We demonstrate that the fusion of GeoDe+MASO significantly outperforms existing community detection methods on noisy SBMs. Furthermore, we show that using GeoDe+MASO as a denoising step improves belief propagation's community recovery by 79.7% on the Amazon Metadata dataset.","authors":["Washieu Anan","Gwyneth Liu"],"url":"https://arxiv.org/abs/2505.08251"}
{"created":"2025-05-20","title":"M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis","abstract":"Generating full-body human gestures encompassing face, body, hands, and global movements from audio is a valuable yet challenging task in virtual avatar creation. Previous systems focused on tokenizing the human gestures framewisely and predicting the tokens of each frame from the input audio. However, one observation is that the number of frames required for a complete expressive human gesture, defined as granularity, varies among different human gesture patterns. Existing systems fail to model these gesture patterns due to the fixed granularity of their gesture tokens. To solve this problem, we propose a novel framework named Multi-Granular Gesture Generator (M3G) for audio-driven holistic gesture generation. In M3G, we propose a novel Multi-Granular VQ-VAE (MGVQ-VAE) to tokenize motion patterns and reconstruct motion sequences from different temporal granularities. Subsequently, we proposed a multi-granular token predictor that extracts multi-granular information from audio and predicts the corresponding motion tokens. Then M3G reconstructs the human gestures from the predicted tokens using the MGVQ-VAE. Both objective and subjective experiments demonstrate that our proposed M3G framework outperforms the state-of-the-art methods in terms of generating natural and expressive full-body human gestures.","authors":["Zhizhuo Yin","Yuk Hang Tsui","Pan Hui"],"url":"https://arxiv.org/abs/2505.08293"}
{"created":"2025-05-20","title":"STORYANCHORS: Generating Consistent Multi-Scene Story Frames for Long-Form Narratives","abstract":"This paper introduces StoryAnchors, a unified framework for generating high-quality, multi-scene story frames with strong temporal consistency. The framework employs a bidirectional story generator that integrates both past and future contexts to ensure temporal consistency, character continuity, and smooth scene transitions throughout the narrative. Specific conditions are introduced to distinguish story frame generation from standard video synthesis, facilitating greater scene diversity and enhancing narrative richness. To further improve generation quality, StoryAnchors integrates Multi-Event Story Frame Labeling and Progressive Story Frame Training, enabling the model to capture both overarching narrative flow and event-level dynamics. This approach supports the creation of editable and expandable story frames, allowing for manual modifications and the generation of longer, more complex sequences. Extensive experiments show that StoryAnchors outperforms existing open-source models in key areas such as consistency, narrative coherence, and scene diversity. Its performance in narrative consistency and story richness is also on par with GPT-4o. Ultimately, StoryAnchors pushes the boundaries of story-driven frame generation, offering a scalable, flexible, and highly editable foundation for future research.","authors":["Bo Wang","Haoyang Huang","Zhiying Lu","Fengyuan Liu","Guoqing Ma","Jianlong Yuan","Yuan Zhang","Nan Duan","Daxin Jiang"],"url":"https://arxiv.org/abs/2505.08350"}
{"created":"2025-05-20","title":"Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping","abstract":"Large Language Models leverage Chain-of-Thought (CoT) prompting for complex tasks, but their reasoning traces are often excessively verbose and inefficient, leading to significant computational costs and latency. Current CoT compression techniques typically rely on generic importance metrics and static compression rates, which may inadvertently remove functionally critical tokens or fail to adapt to varying reasoning complexity. To overcome these limitations, we propose Adaptive GoGI-Skip, a novel framework learning dynamic CoT compression via supervised fine-tuning. This approach introduces two synergistic innovations: (1) Goal-Gradient Importance (GoGI), a novel metric accurately identifying functionally relevant tokens by measuring the gradient influence of their intermediate representations on the final answer loss, and (2) Adaptive Dynamic Skipping (ADS), a mechanism dynamically regulating the compression rate based on runtime model uncertainty while ensuring local coherence through an adaptive N-token constraint. To our knowledge, this is the first work unifying a goal-oriented, gradient-based importance metric with dynamic, uncertainty-aware skipping for CoT compression. Trained on compressed MATH data, Adaptive GoGI-Skip demonstrates strong cross-domain generalization across diverse reasoning benchmarks including AIME, GPQA, and GSM8K. It achieves substantial efficiency gains - reducing CoT token counts by over 45% on average and delivering 1.6-2.0 times inference speedups - while maintaining high reasoning accuracy. Notably, it significantly outperforms existing baselines by preserving accuracy even at high effective compression rates, advancing the state of the art in the CoT reasoning efficiency-accuracy trade-off.","authors":["Ren Zhuang","Ben Wang","Shuifa Sun"],"url":"https://arxiv.org/abs/2505.08392"}
{"created":"2025-05-20","title":"Achieving Scalable Robot Autonomy via neurosymbolic planning using lightweight local LLM","abstract":"PDDL-based symbolic task planning remains pivotal for robot autonomy yet struggles with dynamic human-robot collaboration due to scalability, re-planning demands, and delayed plan availability. Although a few neurosymbolic frameworks have previously leveraged LLMs such as GPT-3 to address these challenges, reliance on closed-source, remote models with limited context introduced critical constraints: third-party dependency, inconsistent response times, restricted plan length and complexity, and multi-domain scalability issues. We present Gideon, a novel framework that enables the transition to modern, smaller, local LLMs with extended context length. Gideon integrates a novel problem generator to systematically generate large-scale datasets of realistic domain-problem-plan tuples for any domain, and adapts neurosymbolic planning for local LLMs, enabling on-device execution and extended context for multi-domain support. Preliminary experiments in single-domain scenarios performed on Qwen-2.5 1.5B and trained on 8k-32k samples, demonstrate a valid plan percentage of 66.1% (32k model) and show that the figure can be further scaled through additional data. Multi-domain tests on 16k samples yield an even higher 70.6% planning validity rate, proving extensibility across domains and signaling that data variety can have a positive effect on learning efficiency. Although long-horizon planning and reduced model size make Gideon training much less efficient than baseline models based on larger LLMs, the results are still significant considering that the trained model is about 120x smaller than baseline and that significant advantages can be achieved in inference efficiency, scalability, and multi-domain adaptability, all critical factors in human-robot collaboration. Training inefficiency can be mitigated by Gideon's streamlined data generation pipeline.","authors":["Nicholas Attolino","Alessio Capitanelli","Fulvio Mastrogiovanni"],"url":"https://arxiv.org/abs/2505.08492"}
{"created":"2025-05-20","title":"Dual-UAV-Enabled Secure Communication and Sensing for A2G-ISAC Systems with Maneuverable Jamming","abstract":"In this paper, we propose a dual-unmanned aerial vehicle (UAV)-enabled secure communication and sensing (SCS) scheme for an air-to-ground integrated sensing and communication (ISAC) system, in which a dual-functional source UAV and jamming UAV collaborate to enhance both the secure communication and target sensing performance. From a perspective of hybrid monostatitc-bistatic radar, the jamming UAV maneuvers to aid the source UAV to detect multiple ground targets by emitting artificial noise, meanwhile interfering with the ground eavesdropper. Residual interference is considered to reflect the effects of imperfect successive interference cancellation (SIC) on the receive signal-plus-interference-to-noise ratios, which results in a degraded system performance. To maximize the average secrecy rate (ASR), the dual-UAV trajectory and dual-UAV beamforming are jointly optimized subject to the transmit power budget, UAV maneuvering constraint, and sensing requirements. To tackle the highly complicated non-convex ASR maximization problem, the dual-UAV trajectory and dual-UAV beamforming are optimized for the secure communication (SC) purpose and the SCS purpose, sequentially. In the SC phase, a block coordinate descent algorithm is proposed to optimize the dual-UAV trajectory and dual-UAV beamforming iteratively, using the trust-region successive convex approximation (SCA) and semidefinite relaxation (SDR) techniques. Then, a weighted distance minimization problem is formulated to determine the dual-UAV maneuvering positions suitable for the SCS purpose, which is solved by a heuristic greedy algorithm, followed by the joint optimization of source beamforming and jamming beamforming.","authors":["Libiao Lou","Yuan Liu","Fotis Foukalas","Hongjiang Lei","Gaofeng Pan","Theodoros A. Tsiftsis","Hongwu Liu"],"url":"https://arxiv.org/abs/2505.08523"}
{"created":"2025-05-20","title":"PrePrompt: Predictive prompting for class incremental learning","abstract":"Class Incremental Learning (CIL) based on pre-trained models offers a promising direction for open-world continual learning. Existing methods typically rely on correlation-based strategies, where an image's classification feature is used as a query to retrieve the most related key prompts and select the corresponding value prompts for training. However, these approaches face an inherent limitation: fitting the entire feature space of all tasks with only a few trainable prompts is fundamentally challenging. We propose Predictive Prompting (PrePrompt), a novel CIL framework that circumvents correlation-based limitations by leveraging pre-trained models' natural classification ability to predict task-specific prompts. Specifically, PrePrompt decomposes CIL into a two-stage prediction framework: task-specific prompt prediction followed by label prediction. While theoretically appealing, this framework risks bias toward recent classes due to missing historical data for older classifier calibration. PrePrompt then mitigates this by incorporating feature translation, dynamically balancing stability and plasticity. Experiments across multiple benchmarks demonstrate PrePrompt's superiority over state-of-the-art prompt-based CIL methods. Code available at \\href{github.com/libo-huang/preprompt}{github.com/libo-huang/preprompt}.","authors":["Libo Huang","Zhulin An","Chuanguang Yang","Boyu Diao","Fei Wang","Yan Zeng","Zhifeng Hao","Yongjun Xu"],"url":"https://arxiv.org/abs/2505.08586"}
{"created":"2025-05-20","title":"TRAIL: Trace Reasoning and Agentic Issue Localization","abstract":"The increasing adoption of agentic workflows across diverse domains brings a critical need to scalably and systematically evaluate the complex traces these systems generate. Current evaluation methods depend on manual, domain-specific human analysis of lengthy workflow traces - an approach that does not scale with the growing complexity and volume of agentic outputs. Error analysis in these settings is further complicated by the interplay of external tool outputs and language model reasoning, making it more challenging than traditional software debugging. In this work, we (1) articulate the need for robust and dynamic evaluation methods for agentic workflow traces, (2) introduce a formal taxonomy of error types encountered in agentic systems, and (3) present a set of 148 large human-annotated traces (TRAIL) constructed using this taxonomy and grounded in established agentic benchmarks. To ensure ecological validity, we curate traces from both single and multi-agent systems, focusing on real-world applications such as software engineering and open-world information retrieval. Our evaluations reveal that modern long context LLMs perform poorly at trace debugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our dataset and code are made publicly available to support and accelerate future research in scalable evaluation for agentic workflows.","authors":["Darshan Deshpande","Varun Gangal","Hersh Mehta","Jitin Krishnan","Anand Kannappan","Rebecca Qian"],"url":"https://arxiv.org/abs/2505.08638"}
{"created":"2025-05-20","title":"Vendi Information Gain: An Alternative To Mutual Information For Science And Machine Learning","abstract":"In his 1948 seminal paper A Mathematical Theory of Communication that birthed information theory, Claude Shannon introduced mutual information (MI), which he called \"rate of transmission\", as a way to quantify information gain (IG) and defined it as the difference between the marginal and conditional entropy of a random variable. While MI has become a standard tool in science and engineering, it has several shortcomings. First, MI is often intractable - it requires a density over samples with tractable Shannon entropy - and existing techniques for approximating it often fail, especially in high dimensions. Moreover, in settings where MI is tractable, its symmetry and insensitivity to sample similarity are undesirable. In this paper, we propose the Vendi Information Gain (VIG), a novel alternative to MI that leverages the Vendi scores, a flexible family of similarity-based diversity metrics. We call the logarithm of the VS the Vendi entropy and define VIG as the difference between the marginal and conditional Vendi entropy of a variable. Being based on the VS, VIG accounts for similarity. Furthermore, VIG generalizes MI and recovers it under the assumption that the samples are completely dissimilar. Importantly, VIG only requires samples and not a probability distribution over them. Finally, it is asymmetric, a desideratum for a good measure of IG that MI fails to meet. VIG extends information theory to settings where MI completely fails. For example, we use VIG to describe a novel, unified framework for active data acquisition, a popular paradigm of modern data-driven science. We demonstrate the advantages of VIG over MI in diverse applications, including in cognitive science to model human response times to external stimuli and in epidemiology to learn epidemic processes and identify disease hotspots in different countries via level-set estimation.","authors":["Quan Nguyen","Adji Bousso Dieng"],"url":"https://arxiv.org/abs/2505.09007"}
{"created":"2025-05-20","title":"Quasi-3D beam theory based on equilibrium stress definition and mixed element model for accurate analysis of functionally graded beams","abstract":"This paper presents a novel quasi-3D theory and the corresponding mixed beam element model to achieve accurate solutions for functionally graded beams. The key innovations include the development of equilibrium-based stress expressions, the modified cross-sectional stiffness matrix, and the mixed beam element model based on semi-analytical definition of internal force fields. In contrast to the conventional quasi-3D theory where stress expressions are derived from constitutive equations and geometric relations, the stress expressions in this study are derived from the differential equilibrium equations among stresses, ensuring strict adherence of stress solutions to equilibrium conditions. To incorporate the influence of equilibrium-derived stress distributions, the modified cross-sectional stiffness matrix is derived, enhancing the theoretical and practical feasibility of the beam model. For beam element construction, the mixed variational principle of two-field variables is employed, with generalized internal forces and generalized displacements regarded as two independent fields. Especially, semi-analytical internal force fields, which partially satisfy the differential equilibrium equations, are introduced to improve the element performance. Numerical examples are conducted to verify the accuracy and effectiveness of the proposed theory and beam element.","authors":["Wenxiong Li","Zhiwei Liu","Suiyin Chen","Gengying Li"],"url":"https://arxiv.org/abs/2505.09127"}
{"created":"2025-05-20","title":"Deterministic Suffix-reading Automata","abstract":"We introduce deterministic suffix-reading automata (DSA), a new automaton model over finite words. Transitions in a DSA are labeled with words. From a state, a DSA triggers an outgoing transition on seeing a word ending with the transition's label. Therefore, rather than moving along an input word letter by letter, a DSA can jump along blocks of letters, with each block ending in a suitable suffix. This feature allows DSAs to recognize regular languages more concisely, compared to DFAs. In this work, we focus on questions around finding a minimal DSA for a regular language. The number of states is not a faithful measure of the size of a DSA, since the transition-labels contain strings of arbitrary length. Hence, we consider total-size (number of states + number of edges + total length of transition-labels) as the size measure of DSAs.","authors":["R Keerthan","B Srivathsan","R Venkatesh","Sagar Verma"],"url":"https://arxiv.org/abs/2505.09353"}
{"created":"2025-05-20","title":"Strategies to Measure Energy Consumption Using RAPL During Workflow Execution on Commodity Clusters","abstract":"In science, problems in many fields can be solved by processing datasets using a series of computationally expensive algorithms, sometimes referred to as workflows. Traditionally, the configurations of these workflows are optimized to achieve a short runtime for the given task and dataset on a given (often distributed) infrastructure. However, recently more attention has been drawn to energy-efficient computing, due to the negative impact of energy-inefficient computing on the environment and energy costs. To be able to assess the energy-efficiency of a given workflow configuration, reliable and accurate methods to measure the energy consumption of a system are required. One approach is the usage of built-in hardware energy counters, such as Intel RAPL. Unfortunately, effectively using RAPL for energy measurement within a workflow on a managed cluster with the typical deep software infrastructure stack can be difficult, for instance because of limited privileges and the need for communication between nodes. In this paper, we describe three ways to implement RAPL energy measurement on a Kubernetes cluster while executing scientific workflows utilizing the Nextflow workflow engine. We compare them by utilizing a set of eight criteria that should be fulfilled for accurate measurement, such as the ability to react to workflow faults, portability, and added overhead. We highlight advantages and drawbacks of each method and discuss challenges and pitfalls, as well as ways to avoid them. We also empirically evaluate all methods, and find that approaches using a shell script and a Nextflow plugin are both effective and easy to implement. Additionally, we find that measuring the energy consumption of a single task is straight forward when only one task runs at a time, but concurrent task executions on the same node require approximating per-task energy usage using metrics such as CPU utilization.","authors":["Philipp Thamm","Ulf Leser"],"url":"https://arxiv.org/abs/2505.09375"}
{"created":"2025-05-20","title":"CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios","abstract":"Large Language Models (LLMs) hold immense potential for revolutionizing Customer Experience Management (CXM), particularly in contact center operations. However, evaluating their practical utility in complex operational environments is hindered by data scarcity (due to privacy concerns) and the limitations of current benchmarks. Existing benchmarks often lack realism, failing to incorporate deep knowledge base (KB) integration, real-world noise, or critical operational tasks beyond conversational fluency. To bridge this gap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset specifically designed for evaluating AI in operational CXM contexts. Given the diversity in possible contact center features, we have developed a scalable LLM-powered pipeline that simulates the brand's CXM entities that form the foundation of our datasets-such as knowledge articles including product specifications, issue taxonomies, and contact center conversations. The entities closely represent real-world distribution because of controlled noise injection (informed by domain experts) and rigorous automated validation. Building on this, we release CXMArena, which provides dedicated benchmarks targeting five important operational tasks: Knowledge Base Refinement, Intent Prediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with Integrated Tools. Our baseline experiments underscore the benchmark's difficulty: even state of the art embedding and generation models achieve only 68% accuracy on article search, while standard embedding methods yield a low F1 score of 0.3 for knowledge base refinement, highlighting significant challenges for current models necessitating complex pipelines and solutions over conventional techniques.","authors":["Raghav Garg","Kapil Sharma","Karan Gupta"],"url":"https://arxiv.org/abs/2505.09436"}
{"created":"2025-05-20","title":"MigrationBench: Repository-Level Code Migration Benchmark from Java 8","abstract":"With the rapid advancement of powerful large language models (LLMs) in recent years, a wide range of software engineering tasks can now be addressed using LLMs, significantly enhancing productivity and scalability. Numerous benchmark datasets have been developed to evaluate the coding capabilities of these models, while they primarily focus on code generation and issue-resolution tasks. In contrast, we introduce a new coding benchmark MigrationBench with a distinct focus: code migration. MigrationBench aims to serve as a comprehensive benchmark for migration from Java $8$ to the latest long-term support (LTS) versions (Java $17$, $21$), including a full dataset and its subset selected with $5,102$ and $300$ repositories respectively. Selected is a representative subset curated for complexity and difficulty, offering a versatile resource to support research in the field of code migration. Additionally, we provide a comprehensive evaluation framework to facilitate rigorous and standardized assessment of LLMs on this challenging task. We further propose SD-Feedback and demonstrate that LLMs can effectively tackle repository-level code migration to Java $17$. For the selected subset with Claude-3.5-Sonnet-v2, SD-Feedback achieves $62.33\\%$ and $27.33\\%$ success rate (pass@1) for minimal and maximal migration respectively. The benchmark dataset and source code are available at: https://huggingface.co/collections/AmazonScience/migrationbench-68125452fc21a4564b92b6c3 and https://github.com/amazon-science/MigrationBench respectively.","authors":["Linbo Liu","Xinle Liu","Qiang Zhou","Lin Chen","Yihan Liu","Hoan Nguyen","Behrooz Omidvar-Tehrani","Xi Shen","Jun Huan","Omer Tripp","Anoop Deoras"],"url":"https://arxiv.org/abs/2505.09569"}
{"created":"2025-05-20","title":"EWMBench: Evaluating Scene, Motion, and Semantic Quality in Embodied World Models","abstract":"Recent advances in creative AI have enabled the synthesis of high-fidelity images and videos conditioned on language instructions. Building on these developments, text-to-video diffusion models have evolved into embodied world models (EWMs) capable of generating physically plausible scenes from language commands, effectively bridging vision and action in embodied AI applications. This work addresses the critical challenge of evaluating EWMs beyond general perceptual metrics to ensure the generation of physically grounded and action-consistent behaviors. We propose the Embodied World Model Benchmark (EWMBench), a dedicated framework designed to evaluate EWMs based on three key aspects: visual scene consistency, motion correctness, and semantic alignment. Our approach leverages a meticulously curated dataset encompassing diverse scenes and motion patterns, alongside a comprehensive multi-dimensional evaluation toolkit, to assess and compare candidate models. The proposed benchmark not only identifies the limitations of existing video generation models in meeting the unique requirements of embodied tasks but also provides valuable insights to guide future advancements in the field. The dataset and evaluation tools are publicly available at https://github.com/AgibotTech/EWMBench.","authors":["Hu Yue","Siyuan Huang","Yue Liao","Shengcong Chen","Pengfei Zhou","Liliang Chen","Maoqing Yao","Guanghui Ren"],"url":"https://arxiv.org/abs/2505.09694"}
{"created":"2025-05-20","title":"On the Well-Posedness of Green's Function Reconstruction via the Kirchhoff-Helmholtz Equation for One-Speed Neutron Diffusion","abstract":"This work presents a methodology for reconstructing the spatial distribution of the neutron flux in a nuclear reactor, leveraging real-time measurements obtained from ex-core detectors. The Kirchhoff-Helmholtz (K-H) equation inherently defines the problem of estimating a scalar field within a domain based on boundary data, making it a natural mathematical framework for this task. The main challenge lies in deriving the Green's function specific to the domain and the neutron diffusion process. While analytical solutions for Green's functions exist for simplified geometries, their derivation of complex, heterogeneous domains-such as a nuclear reactor-requires a numerical approach. The objective of this work is to demonstrate the well-posedness of the data-driven Green's function approximation by formulating and solving the K-H equation as an inverse problem. After establishing the symmetry properties that the Green's function must satisfy, the K-H equation is derived from the one-speed neutron diffusion model. This is followed by a comprehensive description of the procedure for interpreting sensor readings and implementing the neutron flux reconstruction algorithm. Finally, the existence and uniqueness of the Green's function inferred from the sampled data are demonstrated, ensuring the reliability of the proposed method and its predictions.","authors":["Roberto Ponciroli"],"url":"https://arxiv.org/abs/2505.09766"}
{"created":"2025-05-20","title":"Beyond Pairwise Learning-To-Rank At Airbnb","abstract":"There are three fundamental asks from a ranking algorithm: it should scale to handle a large number of items, sort items accurately by their utility, and impose a total order on the items for logical consistency. But here's the catch-no algorithm can achieve all three at the same time. We call this limitation the SAT theorem for ranking algorithms. Given the dilemma, how can we design a practical system that meets user needs? Our current work at Airbnb provides an answer, with a working solution deployed at scale. We start with pairwise learning-to-rank (LTR) models-the bedrock of search ranking tech stacks today. They scale linearly with the number of items ranked and perform strongly on metrics like NDCG by learning from pairwise comparisons. They are at a sweet spot of performance vs. cost, making them an ideal choice for several industrial applications. However, they have a drawback-by ignoring interactions between items, they compromise on accuracy. To improve accuracy, we create a \"true\" pairwise LTR model-one that captures interactions between items during pairwise comparisons. But accuracy comes at the expense of scalability and total order, and we discuss strategies to counter these challenges. For greater accuracy, we take each item in the search result, and compare it against the rest of the items along two dimensions: (1) Superiority: How strongly do searchers prefer the given item over the remaining ones? (2) Similarity: How similar is the given item to all the other items? This forms the basis of our \"all-pairwise\" LTR framework, which factors in interactions across all items at once. Looking at items on the search result page all together-superiority and similarity combined-gives us a deeper understanding of what searchers truly want. We quantify the resulting improvements in searcher experience through offline and online experiments at Airbnb.","authors":["Malay Haldar","Daochen Zha","Huiji Gao","Liwei He","Sanjeev Katariya"],"url":"https://arxiv.org/abs/2505.09795"}
{"created":"2025-05-20","title":"Stability and Convergence Analysis of Multi-Agent Consensus with Communication Delays: A Lambert W Function Approach","abstract":"This paper investigates the effect of constant time delay in weakly connected multi-agent systems modeled by double integrator dynamics. A novel analytical approach is proposed to establish an upper bound on the permissible time delay that ensures stability and consensus convergence. The analysis employs the Lambert W function method in higher-dimensional systems to derive explicit conditions under which consensus is achieved. The theoretical results are rigorously proven and provide insight into the allowable delay margins. The analysis applies to general leaderless undirected network topologies. The framework also accounts for complex and realistic delays, including non-commensurate communication delays. Numerical examples are provided to demonstrate the effectiveness of the proposed method.","authors":["Layan Badran","Kiarash Aryankia","Rastko R. Selmic"],"url":"https://arxiv.org/abs/2505.09897"}
{"created":"2025-05-20","title":"AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection","abstract":"Universal visual anomaly detection aims to identify anomalies from novel or unseen vision domains without additional fine-tuning, which is critical in open scenarios. Recent studies have demonstrated that pre-trained vision-language models like CLIP exhibit strong generalization with just zero or a few normal images. However, existing methods struggle with designing prompt templates, complex token interactions, or requiring additional fine-tuning, resulting in limited flexibility. In this work, we present a simple yet effective method called AdaptCLIP based on two key insights. First, adaptive visual and textual representations should be learned alternately rather than jointly. Second, comparative learning between query and normal image prompt should incorporate both contextual and aligned residual features, rather than relying solely on residual features. AdaptCLIP treats CLIP models as a foundational service, adding only three simple adapters, visual adapter, textual adapter, and prompt-query adapter, at its input or output ends. AdaptCLIP supports zero-/few-shot generalization across domains and possesses a training-free manner on target domains once trained on a base dataset. AdaptCLIP achieves state-of-the-art performance on 12 anomaly detection benchmarks from industrial and medical domains, significantly outperforming existing competitive methods. We will make the code and model of AdaptCLIP available at https://github.com/gaobb/AdaptCLIP.","authors":["Bin-Bin Gao","Yue Zhou","Jiangtao Yan","Yuezhi Cai","Weixi Zhang","Meng Wang","Jun Liu","Yong Liu","Lei Wang","Chengjie Wang"],"url":"https://arxiv.org/abs/2505.09926"}
{"created":"2025-05-20","title":"DeFeed: Secure Decentralized Cross-Contract Data Feed in Web 3.0 for Connected Autonomous Vehicles","abstract":"Smart contracts have been a topic of interest in blockchain research and are a key enabling technology for Connected Autonomous Vehicles (CAVs) in the era of Web 3.0. These contracts enable trustless interactions without the need for intermediaries, as they operate based on predefined rules encoded on the blockchain. However, smart contacts face significant challenges in cross-contract communication and information sharing, making it difficult to establish seamless connectivity and collaboration among CAVs with Web 3.0. In this paper, we propose DeFeed, a novel secure protocol that incorporates various gas-saving functions for CAVs, originated from in-depth research into the interaction among smart contracts for decentralized cross-contract data feed in Web 3.0. DeFeed allows smart contracts to obtain information from other contracts efficiently in a single click, without complicated operations. We judiciously design and complete various functions with DeFeed, including a pool function and a cache function for gas optimization, a subscribe function for facilitating data access, and an update function for the future iteration of our protocol. Tailored for CAVs with Web 3.0 use cases, DeFeed enables efficient data feed between smart contracts underpinning decentralized applications and vehicle coordination. Implemented and tested on the Ethereum official test network, DeFeed demonstrates significant improvements in contract interaction efficiency, reducing computational complexity and gas costs. Our solution represents a critical step towards seamless, decentralized communication in Web 3.0 ecosystems.","authors":["Xingchen Sun","Runhua Xu","Wei Ni","Li Duan","Chao Li"],"url":"https://arxiv.org/abs/2505.09928"}
{"created":"2025-05-20","title":"Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents","abstract":"The ReAct (Reasoning + Action) capability in large language models (LLMs) has become the foundation of modern agentic systems. Recent LLMs, such as DeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through the generation of ample intermediate tokens, which help build a strong premise before producing the final output tokens. In this paper, we introduce Pre-Act, a novel approach that enhances the agent's performance by creating a multi-step execution plan along with the detailed reasoning for the given user input. This plan incrementally incorporates previous steps and tool outputs, refining itself after each step execution until the final response is obtained. Our approach is applicable to both conversational and non-conversational agents. To measure the performance of task-oriented agents comprehensively, we propose a two-level evaluation framework: (1) turn level and (2) end-to-end. Our turn-level evaluation, averaged across five models, shows that our approach, Pre-Act, outperforms ReAct by 70% in Action Recall on the Almita dataset. While this approach is effective for larger models, smaller models crucial for practical applications, where latency and cost are key constraints, often struggle with complex reasoning tasks required for agentic systems. To address this limitation, we fine-tune relatively small models such as Llama 3.1 (8B & 70B) using the proposed Pre-Act approach. Our experiments show that the fine-tuned 70B model outperforms GPT-4, achieving a 69.5% improvement in action accuracy (turn-level) and a 28% improvement in goal completion rate (end-to-end) on the Almita (out-of-domain) dataset.","authors":["Mrinal Rawat","Ambuje Gupta","Rushil Goomer","Alessandro Di Bari","Neha Gupta","Roberto Pieraccini"],"url":"https://arxiv.org/abs/2505.09970"}
{"created":"2025-05-20","title":"PointArena: Probing Multimodal Grounding Through Language-Guided Pointing","abstract":"Pointing serves as a fundamental and intuitive mechanism for grounding language within visual contexts, with applications spanning robotics, assistive technologies, and interactive AI systems. While recent multimodal models have started to support pointing capabilities, existing benchmarks typically focus only on referential object localization tasks. We introduce PointArena, a comprehensive platform for evaluating multimodal pointing across diverse reasoning scenarios. PointArena comprises three components: (1) Point-Bench, a curated dataset containing approximately 1,000 pointing tasks across five reasoning categories; (2) Point-Battle, an interactive, web-based arena facilitating blind, pairwise model comparisons, which has already gathered over 4,500 anonymized votes; and (3) Point-Act, a real-world robotic manipulation system allowing users to directly evaluate multimodal model pointing capabilities in practical settings. We conducted extensive evaluations of both state-of-the-art open-source and proprietary multimodal models. Results indicate that Molmo-72B consistently outperforms other models, though proprietary models increasingly demonstrate comparable performance. Additionally, we find that supervised training specifically targeting pointing tasks significantly enhances model performance. Across our multi-stage evaluation pipeline, we also observe strong correlations, underscoring the critical role of precise pointing capabilities in enabling multimodal models to effectively bridge abstract reasoning with concrete, real-world actions. Project page: https://pointarena.github.io/","authors":["Long Cheng","Jiafei Duan","Yi Ru Wang","Haoquan Fang","Boyang Li","Yushan Huang","Elvis Wang","Ainaz Eftekhar","Jason Lee","Wentao Yuan","Rose Hendrix","Noah A. Smith","Fei Xia","Dieter Fox","Ranjay Krishna"],"url":"https://arxiv.org/abs/2505.09990"}
{"created":"2025-05-20","title":"Topology-driven identification of repetitions in multi-variate time series","abstract":"Many multi-variate time series obtained in the natural sciences and engineering possess a repetitive behavior, as for instance state-space trajectories of industrial machines in discrete automation. Recovering the times of recurrence from such a multi-variate time series is of a fundamental importance for many monitoring and control tasks. For a periodic time series this is equivalent to determining its period length. In this work we present a persistent homology framework to estimate recurrence times in multi-variate time series with different generalizations of cyclic behavior (periodic, repetitive, and recurring). To this end, we provide three specialized methods within our framework that are provably stable and validate them using real-world data, including a new benchmark dataset from an injection molding machine.","authors":["Simon Schindler","Elias Steffen Reich","Saverio Messineo","Simon Hoher","Stefan Huber"],"url":"https://arxiv.org/abs/2505.10004"}
{"created":"2025-05-20","title":"Improved Rank Aggregation under Fairness Constraint","abstract":"Aggregating multiple input rankings into a consensus ranking is essential in various fields such as social choice theory, hiring, college admissions, web search, and databases. A major challenge is that the optimal consensus ranking might be biased against individual candidates or groups, especially those from marginalized communities. This concern has led to recent studies focusing on fairness in rank aggregation. The goal is to ensure that candidates from different groups are fairly represented in the top-$k$ positions of the aggregated ranking.","authors":["Diptarka Chakraborty","Himika Das","Sanjana Dey","Alvin Hong Yao Yan"],"url":"https://arxiv.org/abs/2505.10006"}
{"created":"2025-05-20","title":"When Mitigations Backfire: Timing Channel Attacks and Defense for PRAC-Based RowHammer Mitigations","abstract":"Per Row Activation Counting (PRAC) has emerged as a robust framework for mitigating RowHammer (RH) vulnerabilities in modern DRAM systems. However, we uncover a critical vulnerability: a timing channel introduced by the Alert Back-Off (ABO) protocol and Refresh Management (RFM) commands. We present PRACLeak, a novel attack that exploits these timing differences to leak sensitive information, such as secret keys from vulnerable AES implementations, by monitoring memory access latencies.","authors":["Jeonghyun Woo","Joyce Qu","Gururaj Saileshwar","Prashant J. Nair"],"url":"https://arxiv.org/abs/2505.10111"}
{"created":"2025-05-20","title":"Learning Virtual Machine Scheduling in Cloud Computing through Language Agents","abstract":"In cloud services, virtual machine (VM) scheduling is a typical Online Dynamic Multidimensional Bin Packing (ODMBP) problem, characterized by large-scale complexity and fluctuating demands. Traditional optimization methods struggle to adapt to real-time changes, domain-expert-designed heuristic approaches suffer from rigid strategies, and existing learning-based methods often lack generalizability and interpretability. To address these limitations, this paper proposes a hierarchical language agent framework named MiCo, which provides a large language model (LLM)-driven heuristic design paradigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov Decision Process with Options (SMDP-Option), enabling dynamic scheduling through a two-stage architecture, i.e., Option Miner and Option Composer. Option Miner utilizes LLMs to discover diverse and useful non-context-aware strategies by interacting with constructed environments. Option Composer employs LLMs to discover a composing strategy that integrates the non-context-aware strategies with the contextual ones. Extensive experiments on real-world enterprise datasets demonstrate that MiCo achieves a 96.9\\% competitive ratio in large-scale scenarios involving more than 10,000 virtual machines. It maintains high performance even under nonstationary request flows and diverse configurations, thus validating its effectiveness in complex and large-scale cloud environments.","authors":["JieHao Wu","Ziwei Wang","Junjie Sheng","Wenhao Li","Xiangfeng Wang","Jun Luo"],"url":"https://arxiv.org/abs/2505.10117"}
{"created":"2025-05-20","title":"Enhancing the Performance of Global Model by Improving the Adaptability of Local Models in Federated Learning","abstract":"Federated learning enables the clients to collaboratively train a global model, which is aggregated from local models. Due to the heterogeneous data distributions over clients and data privacy in federated learning, it is difficult to train local models to achieve a well-performed global model. In this paper, we introduce the adaptability of local models, i.e., the average performance of local models on data distributions over clients, and enhance the performance of the global model by improving the adaptability of local models. Since each client does not know the data distributions over other clients, the adaptability of the local model cannot be directly optimized. First, we provide the property of an appropriate local model which has good adaptability on the data distributions over clients. Then, we formalize the property into the local training objective with a constraint and propose a feasible solution to train the local model. Extensive experiments on federated learning benchmarks demonstrate that our method significantly improves the adaptability of local models and achieves a well-performed global model that consistently outperforms the baseline methods.","authors":["Wujun Zhou","Shu Ding","ZeLin Li","Wei Wang"],"url":"https://arxiv.org/abs/2505.10125"}
{"created":"2025-05-20","title":"Simpler and Faster Directed Low-Diameter Decompositions","abstract":"We present a simpler and faster algorithm for low-diameter decompositions on directed graphs, matching the $O(\\log n\\log\\log n)$ loss factor from Bringmann, Fischer, Haeupler, and Latypov (ICALP 2025) and improving the running time to $O((m+n\\log\\log n)\\log^2n)$.","authors":["Jason Li"],"url":"https://arxiv.org/abs/2505.10244"}
{"created":"2025-05-20","title":"An Algorithm for Computing the Leading Monomials of a Minimal Groebner Basis of Generic Sequences","abstract":"We present an efficient algorithm for computing the leading monomials of a minimal Groebner basis of a generic sequence of homogeneous polynomials. Our approach bypasses costly polynomial reductions by exploiting structural properties conjectured to hold for generic sequences-specifically, that their leading monomial ideals are weakly reverse lexicographic and that their Hilbert series follow a known closed-form expression. The algorithm incrementally constructs the set of leading monomials degree by degree by comparing Hilbert functions of monomial ideals with the expected Hilbert series of the input ideal. To enhance computational efficiency, we introduce several optimization techniques that progressively narrow the search space and reduce the number of divisibility checks required at each step. We also refine the loop termination condition using degree bounds, thereby avoiding unnecessary recomputation of Hilbert series. Experimental results confirm that the proposed method substantially reduces both computation time and memory usage compared to conventional Groebner basis computations, particularly for large-scale systems. These results indicate that our algorithm can serve as an effective pre-processing tool for accelerating Groebner basis computations in generic polynomial sequence solving.","authors":["Kosuke Sakata","Tsuyoshi Takagi"],"url":"https://arxiv.org/abs/2505.10246"}
{"created":"2025-05-20","title":"SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices","abstract":"Efficient LLM inference on resource-constrained devices presents significant challenges in compute and memory utilization. Due to limited GPU memory, existing systems offload model weights to CPU memory, incurring substantial I/O overhead between the CPU and GPU. This leads to two major inefficiencies: (1) GPU cores are underutilized, often remaining idle while waiting for data to be loaded; and (2) GPU memory has low impact on performance, as reducing its capacity has minimal effect on overall throughput.In this paper, we propose SpecOffload, a high-throughput inference engine that embeds speculative decoding into offloading. Our key idea is to unlock latent GPU resources for storing and executing a draft model used for speculative decoding, thus accelerating inference at near-zero additional cost. To support this, we carefully orchestrate the interleaved execution of target and draft models in speculative decoding within the offloading pipeline, and propose a planner to manage tensor placement and select optimal parameters. Compared to the best baseline, SpecOffload improves GPU core utilization by 4.49x and boosts inference throughput by 2.54x. Our code is available at https://github.com/MobiSense/SpecOffload .","authors":["Xiangwen Zhuge","Xu Shen","Zeyu Wang","Fan Dang","Xuan Ding","Danyang Li","Yahui Han","Tianxiang Hao","Zheng Yang"],"url":"https://arxiv.org/abs/2505.10259"}
{"created":"2025-05-20","title":"Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs","abstract":"Large language models (LLMs) excel at complex tasks thanks to advances in reasoning abilities. However, existing methods overlook the trade-off between reasoning effectiveness and computational efficiency, often encouraging unnecessarily long reasoning chains and wasting tokens. To address this, we propose Learning to Think (L2T), an information-theoretic reinforcement fine-tuning framework for LLMs to make the models achieve optimal reasoning with fewer tokens. Specifically, L2T treats each query-response interaction as a hierarchical session of multiple episodes and proposes a universal dense process reward, i.e., quantifies the episode-wise information gain in parameters, requiring no extra annotations or task-specific evaluators. We propose a method to quickly estimate this reward based on PAC-Bayes bounds and the Fisher information matrix. Theoretical analyses show that it significantly reduces computational complexity with high estimation accuracy. By immediately rewarding each episode's contribution and penalizing excessive updates, L2T optimizes the model via reinforcement learning to maximize the use of each episode and achieve effective updates. Empirical results on various reasoning benchmarks and base models demonstrate the advantage of L2T across different tasks, boosting both reasoning effectiveness and efficiency.","authors":["Jingyao Wang","Wenwen Qiang","Zeen Song","Changwen Zheng","Hui Xiong"],"url":"https://arxiv.org/abs/2505.10425"}
{"created":"2025-05-20","title":"Superposition Yields Robust Neural Scaling","abstract":"The success of today's large language models (LLMs) depends on the observation that larger models perform better. However, the origin of this neural scaling law -- the finding that loss decreases as a power law with model size -- remains unclear. Starting from two empirical principles -- that LLMs represent more things than the model dimensions (widths) they have (i.e., representations are superposed), and that words or concepts in language occur with varying frequencies -- we constructed a toy model to study the loss scaling with model size. We found that when superposition is weak, meaning only the most frequent features are represented without interference, the scaling of loss with model size depends on the underlying feature frequency; if feature frequencies follow a power law, so does the loss. In contrast, under strong superposition, where all features are represented but overlap with each other, the loss becomes inversely proportional to the model dimension across a wide range of feature frequency distributions. This robust scaling behavior is explained geometrically: when many more vectors are packed into a lower dimensional space, the interference (squared overlaps) between vectors scales inversely with that dimension. We then analyzed four families of open-sourced LLMs and found that they exhibit strong superposition and quantitatively match the predictions of our toy model. The Chinchilla scaling law turned out to also agree with our results. We conclude that representation superposition is an important mechanism underlying the observed neural scaling laws. We anticipate that these insights will inspire new training strategies and model architectures to achieve better performance with less computation and fewer parameters.","authors":["Yizhou Liu","Ziming Liu","Jeff Gore"],"url":"https://arxiv.org/abs/2505.10465"}
{"created":"2025-05-20","title":"AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges","abstract":"This study critically distinguishes between AI Agents and Agentic AI, offering a structured conceptual taxonomy, application mapping, and challenge analysis to clarify their divergent design philosophies and capabilities. We begin by outlining the search strategy and foundational definitions, characterizing AI Agents as modular systems driven by Large Language Models (LLMs) and Large Image Models (LIMs) for narrow, task-specific automation. Generative AI is positioned as a precursor, with AI Agents advancing through tool integration, prompt engineering, and reasoning enhancements. In contrast, Agentic AI systems represent a paradigmatic shift marked by multi-agent collaboration, dynamic task decomposition, persistent memory, and orchestrated autonomy. Through a sequential evaluation of architectural evolution, operational mechanisms, interaction styles, and autonomy levels, we present a comparative analysis across both paradigms. Application domains such as customer support, scheduling, and data summarization are contrasted with Agentic AI deployments in research automation, robotic coordination, and medical decision support. We further examine unique challenges in each paradigm including hallucination, brittleness, emergent behavior, and coordination failure and propose targeted solutions such as ReAct loops, RAG, orchestration layers, and causal modeling. This work aims to provide a definitive roadmap for developing robust, scalable, and explainable AI agent and Agentic AI-driven systems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision Support System, Agentic-AI Applications","authors":["Ranjan Sapkota","Konstantinos I. Roumeliotis","Manoj Karkee"],"url":"https://arxiv.org/abs/2505.10468"}
{"created":"2025-05-20","title":"MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models","abstract":"Speculative decoding significantly accelerates language model inference by enabling a lightweight draft model to propose multiple tokens that a larger target model verifies simultaneously. However, applying this technique to vision-language models (VLMs) presents two fundamental challenges: small language models that could serve as efficient drafters lack the architectural components to process visual inputs, and their token predictions fail to match those of VLM target models that consider visual context. We introduce Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models (MASSV), which transforms existing small language models into effective multimodal drafters through a two-phase approach. MASSV first connects the target VLM's vision encoder to the draft model via a lightweight trainable projector, then applies self-distilled visual instruction tuning using responses generated by the target VLM to align token predictions. Comprehensive experiments across the Qwen2.5-VL and Gemma3 model families demonstrate that MASSV increases accepted length by up to 30% and delivers end-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV provides a scalable, architecture-compatible method for accelerating both current and future VLMs.","authors":["Mugilan Ganesan","Shane Segal","Ankur Aggarwal","Nish Sinnadurai","Sean Lie","Vithursan Thangarasa"],"url":"https://arxiv.org/abs/2505.10526"}
{"created":"2025-05-20","title":"WorldPM: Scaling Human Preference Modeling","abstract":"Motivated by scaling laws in language modeling that demonstrate how test loss scales as a power law with model and dataset sizes, we find that similar laws exist in preference modeling. We propose World Preference Modeling$ (WorldPM) to emphasize this scaling potential, where World Preference embodies a unified representation of human preferences. In this paper, we collect preference data from public forums covering diverse user communities, and conduct extensive training using 15M-scale data across models ranging from 1.5B to 72B parameters. We observe distinct patterns across different evaluation metrics: (1) Adversarial metrics (ability to identify deceptive features) consistently scale up with increased training data and base model size; (2) Objective metrics (objective knowledge with well-defined answers) show emergent behavior in larger language models, highlighting WorldPM's scalability potential; (3) Subjective metrics (subjective preferences from a limited number of humans or AI) do not demonstrate scaling trends. Further experiments validate the effectiveness of WorldPM as a foundation for preference fine-tuning. Through evaluations on 7 benchmarks with 20 subtasks, we find that WorldPM broadly improves the generalization performance across human preference datasets of varying sizes (7K, 100K and 800K samples), with performance gains exceeding 5% on many key subtasks. Integrating WorldPM into our internal RLHF pipeline, we observe significant improvements on both in-house and public evaluation sets, with notable gains of 4% to 8% in our in-house evaluations.","authors":["Binghai Wang","Runji Lin","Keming Lu","Le Yu","Zhenru Zhang","Fei Huang","Chujie Zheng","Kai Dang","Yang Fan","Xingzhang Ren","An Yang","Binyuan Hui","Dayiheng Liu","Tao Gui","Qi Zhang","Xuanjing Huang","Yu-Gang Jiang","Bowen Yu","Jingren Zhou","Junyang Lin"],"url":"https://arxiv.org/abs/2505.10527"}
{"created":"2025-05-20","title":"AORRTC: Almost-Surely Asymptotically Optimal Planning with RRT-Connect","abstract":"Finding high-quality solutions quickly is an important objective in motion planning. This is especially true for high-degree-of-freedom robots. Satisficing planners have traditionally found feasible solutions quickly but provide no guarantees on their optimality, while almost-surely asymptotically optimal (a.s.a.o.) planners have probabilistic guarantees on their convergence towards an optimal solution but are more computationally expensive.","authors":["Tyler Wilson","Wil Thomason","Zachary Kingston","Jonathan Gammell"],"url":"https://arxiv.org/abs/2505.10542"}
{"created":"2025-05-20","title":"Loop closure grasping: Topological transformations enable strong, gentle, and versatile grasps","abstract":"Grasping mechanisms must both create and subsequently hold grasps that permit safe and effective object manipulation. Existing mechanisms address the different functional requirements of grasp creation and grasp holding using a single morphology, but have yet to achieve the simultaneous strength, gentleness, and versatility needed for many applications. We present \"loop closure grasping\", a class of robotic grasping that addresses these different functional requirements through topological transformations between open-loop and closed-loop morphologies. We formalize these morphologies for grasping, formulate the loop closure grasping method, and present principles and a design architecture that we implement using soft growing inflated beams, winches, and clamps. The mechanisms' initial open-loop topology enables versatile grasp creation via unencumbered tip movement, and closing the loop enables strong and gentle holding with effectively infinite bending compliance. Loop closure grasping circumvents the tradeoffs of single-morphology designs, enabling grasps involving historically challenging objects, environments, and configurations.","authors":["Kentaro Barhydt","O. Godson Osele","Sreela Kodali","Cosima du Pasquier","Chase M. Hartquist","H. Harry Asada","Allison M. Okamura"],"url":"https://arxiv.org/abs/2505.10552"}
{"created":"2025-05-20","title":"Convergence Properties of Stochastic Hypergradients","abstract":"Bilevel optimization problems are receiving increasing attention in machine learning as they provide a natural framework for hyperparameter optimization and meta-learning. A key step to tackle these problems is the efficient computation of the gradient of the upper-level objective (hypergradient). In this work, we study stochastic approximation schemes for the hypergradient, which are important when the lower-level problem is empirical risk minimization on a large dataset. The method that we propose is a stochastic variant of the approximate implicit differentiation approach in (Pedregosa, 2016). We provide bounds for the mean square error of the hypergradient approximation, under the assumption that the lower-level problem is accessible only through a stochastic mapping which is a contraction in expectation. In particular, our main bound is agnostic to the choice of the two stochastic solvers employed by the procedure. We provide numerical experiments to support our theoretical analysis and to show the advantage of using stochastic hypergradients in practice.","authors":["Riccardo Grazzi","Massimiliano Pontil","Saverio Salzo"],"url":"https://arxiv.org/abs/2011.07122"}
{"created":"2025-05-20","title":"You Can Wash Hands Better: Accurate Daily Handwashing Assessment with a Smartwatch","abstract":"Hand hygiene is among the most effective daily practices for preventing infectious diseases such as influenza, malaria, and skin infections. While professional guidelines emphasize proper handwashing to reduce the risk of viral infections, surveys reveal that adherence to these recommendations remains low. To address this gap, we propose UWash, a wearable solution leveraging smartwatches to evaluate handwashing procedures, aiming to raise awareness and cultivate high-quality handwashing habits. We frame the task of handwashing assessment as an action segmentation problem, similar to those in computer vision, and introduce a simple yet efficient two-stream UNet-like network to achieve this goal. Experiments involving 51 subjects demonstrate that UWash achieves 92.27% accuracy in handwashing gesture recognition, an error of <0.5 seconds in onset/offset detection, and an error of <5 points in gesture scoring under user-dependent settings. The system also performs robustly in user-independent and user-independent-location-independent evaluations. Remarkably, UWash maintains high performance in real-world tests, including evaluations with 10 random passersby at a hospital 9 months later and 10 passersby in an in-the-wild test conducted 2 years later. UWash is the first system to score handwashing quality based on gesture sequences, offering actionable guidance for improving daily hand hygiene. The code and dataset are publicly available at https://github.com/aiotgroup/UWash","authors":["Fei Wang","Tingting Zhang","Xilei Wu","Xin Wang","Pengcheng Wang","Han Ding","Jingang Shi","Jinsong Han","Dong Huang"],"url":"https://arxiv.org/abs/2112.06657"}
{"created":"2025-05-20","title":"Robust Path Recommendations During Public Transit Disruptions Under Demand Uncertainty","abstract":"When there are significant service disruptions in public transit systems, passengers usually need guidance to find alternative paths. This paper proposes a path recommendation model to mitigate congestion during public transit disruptions. Passengers with different origins, destinations, and departure times are recommended with different paths such that the system travel time is minimized. We model the path recommendation problem as an optimal flow problem with uncertain demand information. To tackle the lack of analytical formulation of travel times due to capacity constraints, we propose a simulation-based first-order approximation to transform the original problem into a linear program. Uncertainties in demand are modeled using robust optimization to protect the path recommendation strategies against inaccurate estimates. A real-world rail disruption scenario in the Chicago Transit Authority (CTA) system is used as a case study. Results show that even without considering uncertainty, the nominal model can reduce the system travel time by 9.1% (compared to the status quo), and outperforms the benchmark capacity-based path recommendation. The average travel time of passengers in the incident line (i.e., passengers receiving recommendations) is reduced more (-20.6% compared to the status quo). After incorporating the demand uncertainty, the robust model can further reduce system travel times. The best robust model can decrease the average travel time of incident-line passengers by 2.91% compared to the nominal model. The improvement of robust models is more prominent when the actual demand pattern is close to the worst-case demand.","authors":["Baichuan Mo","Haris N. Koutsopoulos","Max Zuo-Jun Shen","Jinhua Zhao"],"url":"https://arxiv.org/abs/2201.01437"}
{"created":"2025-05-20","title":"P-split formulations: A class of intermediate formulations between big-M and convex hull for disjunctive constraints","abstract":"We develop a class of mixed-integer formulations for disjunctive constraints intermediate to the big-M and convex hull formulations in terms of relaxation strength. The main idea is to capture the best of both the big-M and convex hull formulations: a computationally light formulation with a tight relaxation. The \"P-split\" formulations are based on a lifted transformation that splits convex additively separable constraints into P partitions and forms the convex hull of the linearized and partitioned disjunction. The \"P-split\" formulations are derived for disjunctive constraints with convex constraints within each disjunct, and we generalize the results for the case with nonconvex constraints within the disjuncts. We analyze the continuous relaxation of the P-split formulations and show that, under certain assumptions, the formulations form a hierarchy starting from a big-M equivalent and converging to the convex hull. We computationally compare the P-split formulations against big-M and convex hull formulations on 344 test instances. The test problems include K-means clustering, semi-supervised clustering, P_ball problems, and optimization over trained ReLU neural networks. The computational results show promising potential of the P-split formulations. For many of the test problems, P-split formulations are solved with a similar number of explored nodes as the convex hull formulation, while reducing the solution time by an order of magnitude and outperforming big-M both in time and number of explored nodes.","authors":["Jan Kronqvist","Ruth Misener","Calvin Tsay"],"url":"https://arxiv.org/abs/2202.05198"}
{"created":"2025-05-20","title":"Accelerating Simulation of Quantum Circuits under Noise via Computational Reuse","abstract":"To realize the full potential of quantum computers, we must mitigate qubit errors by developing noise-aware algorithms, compilers, and architectures. Thus, simulating quantum programs on high-performance computing (HPC) systems with different noise models is a de facto tool researchers use. Unfortunately, noisy simulators iteratively execute a similar circuit for thousands of trials, thereby incurring significant performance overheads.","authors":["Meng Wang","Swamit Tannu","Prashant J. Nair"],"url":"https://arxiv.org/abs/2203.13892"}
{"created":"2025-05-20","title":"An additive refinement of quantum channel capacities","abstract":"Capacities of quantum channels are fundamental quantities in the theory of quantum information. A desirable property is the additivity for a capacity. However, this cannot be achieved for a few quantities that have been established as capacity measures. Asymptotic regularization is generically necessary making the study of capacities notoriously hard. In this work, by a proper refinement of the physical settings of quantum communication, we prove additive quantities for quantum channel capacities that can be employed for quantum Shannon theorems. This refinement, only a tiny step away from the standard settings, is consistent with the principle of quantum theory, and it further demonstrates von Neumann entropy as the cornerstone of quantum information.","authors":["D. -S. Wang"],"url":"https://arxiv.org/abs/2205.07205"}
{"created":"2025-05-20","title":"Tight Mixed-Integer Optimization Formulations for Prescriptive Trees","abstract":"We focus on modeling the relationship between an input feature vector and the predicted outcome of a trained decision tree using mixed-integer optimization. This can be used in many practical applications where a decision tree or tree ensemble is incorporated into an optimization problem to model the predicted outcomes of a decision. We propose tighter mixed-integer optimization formulations than those previously introduced. Existing formulations can be shown to have linear relaxations that have fractional extreme points, even for the simple case of modeling a single decision tree. A formulation we propose, based on a projected union of polyhedra approach, is ideal for a single decision tree. While the formulation is generally not ideal for tree ensembles or if additional constraints are added, it generally has fewer extreme points, leading to a faster time to solve, particularly if the formulation has relatively few trees. However, previous work has shown that formulations based on a binary representation of the feature vector perform well computationally and hence are attractive for use in practical applications. We present multiple approaches to tighten existing formulations with binary vectors, and show that fractional extreme points are removed when there are multiple splits on the same feature. At an extreme, we prove that this results in ideal formulations for tree ensembles modeling a one-dimensional feature vector. Building on this result, we also show via numerical simulations that these additional constraints result in significantly tighter linear relaxations when the feature vector is low dimensional. We also present instances where the time to solve to optimality is significantly improved using these formulations.","authors":["Max Biggs","Georgia Perakis"],"url":"https://arxiv.org/abs/2302.14744"}
{"created":"2025-05-20","title":"Filling a triangulation of the 2-sphere","abstract":"Define the tet-volume of a triangulation of the 2-sphere to be the minimum number of tetrahedra in a 3-complex of which it is the boundary, and let $d(v)$ be the maximum tet-volume for $v$-vertex triangulations. In 1986 Sleator, Tarjan, and Thurston (STT) proved that $d(v) = 2v-10$ holds for large $v$, and conjectured that it holds for all $v \\geq 13$. Their proof used hyperbolic polyhedra of large volume. They suggested using more general notions of volume instead. In work that was all but lost, Mathieu and Thurston used this approach to outline a combinatorial proof of the STT asymptotic result. Here we use a much simplified version of their approach to prove the full conjecture. This implies STT's weaker conjecture, proven by Pournin in 2014, characterizing the maximum rotation distance between trees.","authors":["Peter Doyle","Matthew Ellison","Zili Wang"],"url":"https://arxiv.org/abs/2303.10773"}
{"created":"2025-05-20","title":"Reinforcement Learning for Control of Evolutionary and Ecological Processes","abstract":"As Evolutionary Dynamics moves from the realm of theory into application, algorithms are needed to move beyond simple models. Yet few such methods exist in the literature. Ecological and physiological factors are known to be central to evolution in realistic contexts, but accounting for them generally renders problems intractable to existing methods. We introduce a formulation of evolutionary games which accounts for ecology and physiology by modeling both as computations and use this to analyze the problem of directed evolution via methods from Reinforcement Learning. This combination enables us to develop first-of-their-kind results on the algorithmic problem of learning to control an evolving population of cells. We prove a complexity bound on eco-evolutionary control in situations with limited prior knowledge of cellular physiology or ecology, give the first results on the most general version of the mathematical problem of directed evolution, and establish a new link between AI and biology.","authors":["Bryce Allen Bagley","Navin Khoshnan","Claudia K Petritsch"],"url":"https://arxiv.org/abs/2305.03340"}
{"created":"2025-05-20","title":"Symmetric Solutions to Symmetric Partial Difference Equations","abstract":"This paper studies systems of linear difference equations on the lattice $\\Z^n$ that are invariant under a finite group of symmetries, and shows that there exist solutions to such systems that are also invariant under this group of symmetries.","authors":["Shiva Shankar"],"url":"https://arxiv.org/abs/2310.00903"}
{"created":"2025-05-20","title":"BAT: Learning to Reason about Spatial Sounds with Large Language Models","abstract":"Spatial sound reasoning is a fundamental human skill, enabling us to navigate and interpret our surroundings based on sound. In this paper we present BAT, which combines the spatial sound perception ability of a binaural acoustic scene analysis model with the natural language reasoning capabilities of a large language model (LLM) to replicate this innate ability. To address the lack of existing datasets of in-the-wild spatial sounds, we synthesized a binaural audio dataset using AudioSet and SoundSpaces 2.0. Next, we developed SpatialSoundQA, a spatial sound-based question-answering dataset, offering a range of QA tasks that train BAT in various aspects of spatial sound perception and reasoning. The acoustic front end encoder of BAT is a novel spatial audio encoder named Spatial Audio Spectrogram Transformer, or Spatial-AST, which by itself achieves strong performance across sound event detection, spatial localization, and distance estimation. By integrating Spatial-AST with LLaMA-2 7B model, BAT transcends standard Sound Event Localization and Detection (SELD) tasks, enabling the model to reason about the relationships between the sounds in its environment. Our experiments demonstrate BAT's superior performance on both spatial sound perception and reasoning, showcasing the immense potential of LLMs in navigating and interpreting complex spatial audio environments.","authors":["Zhisheng Zheng","Puyuan Peng","Ziyang Ma","Xie Chen","Eunsol Choi","David Harwath"],"url":"https://arxiv.org/abs/2402.01591"}
{"created":"2025-05-20","title":"Quantum neural network with ensemble learning to mitigate barren plateaus and cost function concentration","abstract":"The rapid development of quantum computers promises transformative impacts across diverse fields of science and technology. Quantum neural networks (QNNs), as a forefront application, hold substantial potential. Despite the multitude of proposed models in the literature, persistent challenges, notably the vanishing gradient (VG) and cost function concentration (CFC) problems, impede their widespread success. In this study, we introduce a novel approach to quantum neural network construction, specifically addressing the issues of VG and CFC. Our methodology employs ensemble learning, advocating for the simultaneous deployment of multiple quantum circuits with a depth equal to \\(1\\), a departure from the conventional use of a single quantum circuit with depth \\(L\\). We assess the efficacy of our proposed model through a comparative analysis with a conventionally constructed QNN. The evaluation unfolds in the context of a classification problem, yielding valuable insights into the potential advantages of our innovative approach.","authors":["Lucas Friedrich","Jonas Maziero"],"url":"https://arxiv.org/abs/2402.06026"}
{"created":"2025-05-20","title":"Computing Generalized Ranks of Persistence Modules via Unfolding to Zigzag Modules","abstract":"For a $P$-indexed persistence module ${\\sf M}$, the (generalized) rank of ${\\sf M}$ is defined as the rank of the limit-to-colimit map for the diagram of vector spaces of ${\\sf M}$ over the poset $P$. For $2$-parameter persistence modules, recently a zigzag persistence based algorithm has been proposed that takes advantage of the fact that generalized rank for $2$-parameter modules is equal to the number of full intervals in a zigzag module defined on the boundary of the poset. Analogous definition of boundary for $d$-parameter persistence modules or general $P$-indexed persistence modules does not seem plausible. To overcome this difficulty, we first unfold a given $P$-indexed module ${\\sf M}$ into a zigzag module ${\\sf M}_{ZZ}$ and then check how many full interval modules in a decomposition of ${\\sf M}_{ZZ}$ can be folded back to remain full in a decomposition of ${\\sf M}$. This number determines the generalized rank of ${\\sf M}$. For special cases of degree-$d$ homology for $d$-complexes, we obtain a more efficient algorithm including a linear time algorithm for degree-$1$ homology in graphs.","authors":["Tamal K. Dey","Cheng Xin"],"url":"https://arxiv.org/abs/2403.08110"}
{"created":"2025-05-20","title":"Nonlinear integral extension of PID control with improved convergence of perturbed second-order dynamic systems","abstract":"Nonlinear extension of the integral part of a standard proportional-integral-derivative (PID) feedback control is proposed for perturbed second-order systems. The approach is model-free and requires solely the Lipschitz boundedness of the unknown matched perturbations. For constant disturbances, the global asymptotic stability is shown based on the circle criterion. For Lipschitz perturbations, an ultimately bounded output error is provided based on the steady-state behavior in frequency domain. Also the transient response to the stepwise disturbances is analyzed for the control tuning. Based on the developed analysis, the design recommendations are formulated as a step by step procedure. It is also discussed how the proposed control is applicable to second-order systems extended by additional (parasitic) actuator dynamics with low-pass characteristics. The proposed nonlinear control is proven to outperform its linear PID counterpart during the settling phase, i.e. at convergence of the residual output error. An experimental case study of the second-order system with an additional actuator dynamics and considerable perturbations is demonstrated to confirm and benchmark the control performance.","authors":["Michael Ruderman"],"url":"https://arxiv.org/abs/2404.02502"}
{"created":"2025-05-20","title":"Gaussian Universality in Neural Network Dynamics with Generalized Structured Input Distributions","abstract":"Bridging the gap between the practical performance of deep learning and its theoretical foundations often involves analyzing neural networks through stochastic gradient descent (SGD). Expanding on previous research that focused on modeling structured inputs under a simple Gaussian setting, we analyze the behavior of a deep learning system trained on inputs modeled as Gaussian mixtures to better simulate more general structured inputs. Through empirical analysis and theoretical investigation, we demonstrate that under certain standardization schemes, the deep learning model converges toward Gaussian setting behavior, even when the input data follow more complex or real-world distributions. This finding exhibits a form of universality in which diverse structured distributions yield results consistent with Gaussian assumptions, which can support the theoretical understanding of deep learning models.","authors":["Jaeyong Bae","Hawoong Jeong"],"url":"https://arxiv.org/abs/2405.00642"}
{"created":"2025-05-20","title":"A Symplectic Analysis of Alternating Mirror Descent","abstract":"Motivated by understanding the behavior of the Alternating Mirror Descent (AMD) algorithm for bilinear zero-sum games, we study the discretization of continuous-time Hamiltonian flow via the symplectic Euler method. We provide a framework for analysis using results from Hamiltonian dynamics, Lie algebra, and symplectic numerical integrators, with an emphasis on the existence and properties of a conserved quantity, the modified Hamiltonian (MH), for the symplectic Euler method. We compute the MH in closed-form when the original Hamiltonian is a quadratic function, and show that it generally differs from the other conserved quantity known previously in that case. We derive new error bounds on the MH when truncated at orders in the stepsize in terms of the number of iterations, $K$, and use these bounds to show an improved $\\mathcal{O}(K^{1/5})$ total regret bound and an $\\mathcal{O}(K^{-4/5})$ duality gap of the average iterates for AMD. Finally, we propose a conjecture which, if true, would imply that the total regret for AMD scales as $\\mathcal{O}\\left(K^{\\varepsilon}\\right)$ and the duality gap of the average iterates as $\\mathcal{O}\\left(K^{-1+\\varepsilon}\\right)$ for any $\\varepsilon>0$, and we can take $\\varepsilon=0$ upon certain convergence conditions for the MH.","authors":["Jonas Katona","Xiuyuan Wang","Andre Wibisono"],"url":"https://arxiv.org/abs/2405.03472"}
{"created":"2025-05-20","title":"Improving Targeted Molecule Generation through Language Model Fine-Tuning Via Reinforcement Learning","abstract":"Developing new drugs is laborious and costly, demanding extensive time investment. In this paper, we introduce a de-novo drug design strategy, which harnesses the capabilities of language models to devise targeted drugs for specific proteins. Employing a Reinforcement Learning (RL) framework utilizing Proximal Policy Optimization (PPO), we refine the model to acquire a policy for generating drugs tailored to protein targets. The proposed method integrates a composite reward function, combining considerations of drug-target interaction and molecular validity. Following RL fine-tuning, the proposed method demonstrates promising outcomes, yielding notable improvements in molecular validity, interaction efficacy, and critical chemical properties, achieving 65.37 for Quantitative Estimation of Drug-likeness (QED), 321.55 for Molecular Weight (MW), and 4.47 for Octanol-Water Partition Coefficient (logP), respectively. Furthermore, out of the generated drugs, only 0.041% do not exhibit novelty.","authors":["Salma J. Ahmed","Emad A. Mohammed"],"url":"https://arxiv.org/abs/2405.06836"}
{"created":"2025-05-20","title":"Spectral complexity of deep neural networks","abstract":"It is well-known that randomly initialized, push-forward, fully-connected neural networks weakly converge to isotropic Gaussian processes, in the limit where the width of all layers goes to infinity. In this paper, we propose to use the angular power spectrum of the limiting field to characterize the complexity of the network architecture. In particular, we define sequences of random variables associated with the angular power spectrum, and provide a full characterization of the network complexity in terms of the asymptotic distribution of these sequences as the depth diverges. On this basis, we classify neural networks as low-disorder, sparse, or high-disorder; we show how this classification highlights a number of distinct features for standard activation functions, and in particular, sparsity properties of ReLU networks. Our theoretical results are also validated by numerical simulations.","authors":["Simmaco Di Lillo","Domenico Marinucci","Michele Salvi","Stefano Vigogna"],"url":"https://arxiv.org/abs/2405.09541"}
{"created":"2025-05-20","title":"Quantum (Inspired) $D^2$-sampling with Applications","abstract":"$D^2$-sampling is a fundamental component of sampling-based clustering algorithms such as $k$-means++. Given a dataset $V \\subset \\mathbb{R}^d$ with $N$ points and a center set $C \\subset \\mathbb{R}^d$, $D^2$-sampling refers to picking a point from $V$ where the sampling probability of a point is proportional to its squared distance from the nearest center in $C$. Starting with empty $C$ and iteratively $D^2$-sampling and updating $C$ in $k$ rounds is precisely $k$-means++ seeding that runs in $O(Nkd)$ time and gives $O(\\log{k})$-approximation in expectation for the $k$-means problem. We give a quantum algorithm for (approximate) $D^2$-sampling in the QRAM model that results in a quantum implementation of $k$-means++ that runs in time $\\tilde{O}(\\zeta^2 k^2)$. Here $\\zeta$ is the aspect ratio (i.e., largest to smallest interpoint distance), and $\\tilde{O}$ hides polylogarithmic factors in $N, d, k$. It can be shown through a robust approximation analysis of $k$-means++ that the quantum version preserves its $O(\\log{k})$ approximation guarantee. Further, we show that our quantum algorithm for $D^2$-sampling can be 'dequantized' using the sample-query access model of Tang (PhD Thesis, Ewin Tang, University of Washington, 2023). This results in a fast quantum-inspired classical implementation of $k$-means++, which we call QI-$k$-means++, with a running time $O(Nd) + \\tilde{O}(\\zeta^2k^2d)$, where the $O(Nd)$ term is for setting up the sample-query access data structure. Experimental investigations show promising results for QI-$k$-means++ on large datasets with bounded aspect ratio. Finally, we use our quantum $D^2$-sampling with the known $ D^2$-sampling-based classical approximation scheme (i.e., $(1+\\varepsilon)$-approximation for any given $\\varepsilon>0$) to obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$.","authors":["Poojan Shah","Ragesh Jaiswal"],"url":"https://arxiv.org/abs/2405.13351"}
{"created":"2025-05-20","title":"ProDAG: Projected Variational Inference for Directed Acyclic Graphs","abstract":"Directed acyclic graph (DAG) learning is a central task in structure discovery and causal inference. Although the field has witnessed remarkable advances over the past few years, it remains statistically and computationally challenging to learn a single (point estimate) DAG from data, let alone provide uncertainty quantification. We address the difficult task of quantifying graph uncertainty by developing a Bayesian variational inference framework based on novel, provably valid distributions that have support directly on the space of sparse DAGs. These distributions, which we use to define our prior and variational posterior, are induced by a projection operation that maps an arbitrary continuous distribution onto the space of sparse weighted acyclic adjacency matrices. While this projection is combinatorial, it can be solved efficiently using recent continuous reformulations of acyclicity constraints. We empirically demonstrate that our method, ProDAG, can outperform state-of-the-art alternatives in both accuracy and uncertainty quantification.","authors":["Ryan Thompson","Edwin V. Bonilla","Robert Kohn"],"url":"https://arxiv.org/abs/2405.15167"}
{"created":"2025-05-20","title":"Continuously Optimizing Radar Placement with Model Predictive Path Integrals","abstract":"Continuously optimizing sensor placement is essential for precise target localization in various military and civilian applications. While information theory has shown promise in optimizing sensor placement, many studies oversimplify sensor measurement models or neglect dynamic constraints of mobile sensors. To address these challenges, we employ a range measurement model that incorporates radar parameters and radar-target distance, coupled with Model Predictive Path Integral (MPPI) control to manage complex environmental obstacles and dynamic constraints. We compare the proposed approach against stationary radars or simplified range measurement models based on the root mean squared error (RMSE) of the Cubature Kalman Filter (CKF) estimator for the targets' state. Additionally, we visualize the evolving geometry of radars and targets over time, highlighting areas of highest measurement information gain, demonstrating the strengths of the approach. The proposed strategy outperforms stationary radars and simplified range measurement models in target localization, achieving a 38-74% reduction in mean RMSE and a 33-79% reduction in the upper tail of the 90% Highest Density Interval (HDI) over 500 Monte Carl (MC) trials across all time steps.","authors":["Michael Potter","Shuo Tang","Paul Ghanem","Milica Stojanovic","Pau Closas","Murat Akcakaya","Ben Wright","Marius Necsoiu","Deniz Erdogmus","Michael Everett","Tales Imbiriba"],"url":"https://arxiv.org/abs/2405.18999"}
{"created":"2025-05-20","title":"Towards identifiability of micro total effects in summary causal graphs with latent confounding: extension of the front-door criterion","abstract":"Conducting experiments to estimate total effects can be challenging due to cost, ethical concerns, or practical limitations. As an alternative, researchers often rely on causal graphs to determine whether these effects can be identified from observational data. Identifying total effects in fully specified causal graphs has received considerable attention, with Pearl's front-door criterion enabling the identification of total effects in the presence of latent confounding even when no variable set is sufficient for adjustment. However, specifying a complete causal graph is challenging in many domains. Extending these identifiability results to partially specified graphs is crucial, particularly in dynamic systems where causal relationships evolve over time. This paper addresses the challenge of identifying total effects using a specific and well-known partially specified graph in dynamic systems called a summary causal graph, which does not specify the temporal lag between causal relations and can contain cycles. In particular, this paper presents sufficient graphical conditions for identifying total effects from observational data, even in the presence of cycles and latent confounding, and when no variable set is sufficient for adjustment.","authors":["Charles K. Assaad"],"url":"https://arxiv.org/abs/2406.05805"}
{"created":"2025-05-20","title":"Generative prediction of flow fields around an obstacle using the diffusion model","abstract":"We propose a geometry-to-flow diffusion model that utilizes obstacle shape as input to predict a flow field around an obstacle. The model is based on a learnable Markov transition kernel to recover the data distribution from the Gaussian distribution. The Markov process is conditioned on the obstacle geometry, estimating the noise to be removed at each step, implemented via a U-Net. A cross-attention mechanism incorporates the geometry as a prompt. We train the geometry-to-flow diffusion model using a dataset of flows around simple obstacles, including circles, ellipses, rectangles, and triangles. For comparison, two CNN-based models and a VAE model are trained on the same dataset. Tests are carried out on flows around obstacles with simple and complex geometries, representing interpolation and generalization on the geometry condition, respectively. To evaluate performance under demanding conditions, the test set incorporates scenarios including crosses and the characters `PKU.' Generated flow fields show that the geometry-to-flow diffusion model is superior to the CNN-based models and the VAE model in predicting instantaneous flow fields and handling complex geometries. Quantitative analysis of the accuracy and divergence demonstrates the model's robustness.","authors":["Jiajun Hu","Zhen Lu","Yue Yang"],"url":"https://arxiv.org/abs/2407.00735"}
{"created":"2025-05-20","title":"Multi-modal MRI Translation via Evidential Regression and Distribution Calibration","abstract":"Multi-modal Magnetic Resonance Imaging (MRI) translation leverages information from source MRI sequences to generate target modalities, enabling comprehensive diagnosis while overcoming the limitations of acquiring all sequences. While existing deep-learning-based multi-modal MRI translation methods have shown promising potential, they still face two key challenges: 1) lack of reliable uncertainty quantification for synthesized images, and 2) limited robustness when deployed across different medical centers. To address these challenges, we propose a novel framework that reformulates multi-modal MRI translation as a multi-modal evidential regression problem with distribution calibration. Our approach incorporates two key components: 1) an evidential regression module that estimates uncertainties from different source modalities and an explicit distribution mixture strategy for transparent multi-modal fusion, and 2) a distribution calibration mechanism that adapts to source-target mapping shifts to ensure consistent performance across different medical centers. Extensive experiments on three datasets from the BraTS2023 challenge demonstrate that our framework achieves superior performance and robustness across domains.","authors":["Jiyao Liu","Shangqi Gao","Yuxin Li","Lihao Liu","Xin Gao","Zhaohu Xing","Junzhi Ning","Yanzhou Su","Xiao-Yong Zhang","Junjun He","Ningsheng Xu","Xiahai Zhuang"],"url":"https://arxiv.org/abs/2407.07372"}
{"created":"2025-05-20","title":"Two-Player Zero-Sum Hybrid Games","abstract":"In this paper, we formulate a two-player zero-sum game under dynamic constraints defined by hybrid dynamical equations. The game consists of a min-max problem involving a cost functional that depends on the actions and resulting solutions to the hybrid system, defined as functions of hybrid time and, hence, can flow or jump. A terminal set conveniently defined allows to recast both finite and infinite horizon problems. We present sufficient conditions given in terms of Hamilton-Jacobi-Bellman-Isaacs-like equations to guarantee to attain a solution to the game. It is shown that when the players select the optimal strategy, the value function can be evaluated without computing solutions to the hybrid system. Under additional conditions, we show that the optimal state-feedback laws render a set of interest asymptotically stable for the resulting hybrid closed-loop system. Applications of these games, presented here as robust control problems, include disturbance rejection and security problems.","authors":["Santiago J. Leudo","Ricardo G. Sanfelice"],"url":"https://arxiv.org/abs/2407.10107"}
{"created":"2025-05-20","title":"The ICML 2023 Ranking Experiment: Examining Author Self-Assessment in ML/AI Peer Review","abstract":"We conducted an experiment during the review process of the 2023 International Conference on Machine Learning (ICML), asking authors with multiple submissions to rank their papers based on perceived quality. In total, we received 1,342 rankings, each from a different author, covering 2,592 submissions. In this paper, we present an empirical analysis of how author-provided rankings could be leveraged to improve peer review processes at machine learning conferences. We focus on the Isotonic Mechanism, which calibrates raw review scores using the author-provided rankings. Our analysis shows that these ranking-calibrated scores outperform the raw review scores in estimating the ground truth ``expected review scores'' in terms of both squared and absolute error metrics. Furthermore, we propose several cautious, low-risk applications of the Isotonic Mechanism and author-provided rankings in peer review, including supporting senior area chairs in overseeing area chairs' recommendations, assisting in the selection of paper awards, and guiding the recruitment of emergency reviewers.","authors":["Buxin Su","Jiayao Zhang","Natalie Collina","Yuling Yan","Didong Li","Kyunghyun Cho","Jianqing Fan","Aaron Roth","Weijie Su"],"url":"https://arxiv.org/abs/2408.13430"}
{"created":"2025-05-20","title":"USEF-TSE: Universal Speaker Embedding Free Target Speaker Extraction","abstract":"Target speaker extraction aims to separate the voice of a specific speaker from mixed speech. Traditionally, this process has relied on extracting a speaker embedding from a reference speech, in which a speaker recognition model is required. However, identifying an appropriate speaker recognition model can be challenging, and using the target speaker embedding as reference information may not be optimal for target speaker extraction tasks. This paper introduces a Universal Speaker Embedding-Free Target Speaker Extraction (USEF-TSE) framework that operates without relying on speaker embeddings. USEF-TSE utilizes a multi-head cross-attention mechanism as a frame-level target speaker feature extractor. This innovative approach allows mainstream speaker extraction solutions to bypass the dependency on speaker recognition models and better leverage the information available in the enrollment speech, including speaker characteristics and contextual details. Additionally, USEF-TSE can seamlessly integrate with other time-domain or time-frequency domain speech separation models to achieve effective speaker extraction. Experimental results show that our proposed method achieves state-of-the-art (SOTA) performance in terms of Scale-Invariant Signal-to-Distortion Ratio (SI-SDR) on the WSJ0-2mix, WHAM!, and WHAMR! datasets, which are standard benchmarks for monaural anechoic, noisy and noisy-reverberant two-speaker speech separation and speaker extraction. The results on the LibriMix and the blind test set of the ICASSP 2023 DNS Challenge demonstrate that the model performs well on more diverse and out-of-domain data. For access to the source code, please visit: https://github.com/ZBang/USEF-TSE.","authors":["Bang Zeng","Ming Li"],"url":"https://arxiv.org/abs/2409.02615"}
{"created":"2025-05-20","title":"Characterization of input-to-output stability for infinite-dimensional systems","abstract":"We prove a superposition theorem for input-to-output stability (IOS) of a broad class of nonlinear infinite-dimensional systems with outputs including both continuous-time and discrete-time systems. It contains, as a special case, the superposition theorem for input-to-state stability (ISS) of infinite-dimensional systems and the IOS superposition theorem for systems of ordinary differential equations known from the literature.","authors":["Patrick Bachmann","Sergey Dashkovskiy","Andrii Mironchenko"],"url":"https://arxiv.org/abs/2410.06013"}
{"created":"2025-05-20","title":"Uncovering the Genetic Basis of Glioblastoma Heterogeneity through Multimodal Analysis of Whole Slide Images and RNA Sequencing Data","abstract":"Glioblastoma is a highly aggressive form of brain cancer characterized by rapid progression and poor prognosis. Despite advances in treatment, the underlying genetic mechanisms driving this aggressiveness remain poorly understood. In this study, we employed multimodal deep learning approaches to investigate glioblastoma heterogeneity using joint image/RNA-seq analysis. Our results reveal novel genes associated with glioblastoma. By leveraging a combination of whole-slide images and RNA-seq, as well as introducing novel methods to encode RNA-seq data, we identified specific genetic profiles that may explain different patterns of glioblastoma progression. These findings provide new insights into the genetic mechanisms underlying glioblastoma heterogeneity and highlight potential targets for therapeutic intervention. Code and data downloading instructions are available at: https://github.com/ma3oun/gbheterogeneity.","authors":["Ahmad Berjaoui (CRCT","IUCT Oncopole - UMR 1037)","Louis Roussel (CRCT","IUCT Oncopole - UMR 1037)","Eduardo Hugo Sanchez (CRCT","IUCT Oncopole - UMR 1037)","Elizabeth Cohen-Jonathan Moyal (CRCT","IUCT Oncopole - UMR 1037)"],"url":"https://arxiv.org/abs/2410.18710"}
{"created":"2025-05-20","title":"CloudCast -- Total Cloud Cover Nowcasting with Machine Learning","abstract":"Cloud cover plays a critical role in weather prediction and impacts several sectors, including agriculture, solar power generation, and aviation. Despite advancements in numerical weather prediction (NWP) models, forecasting total cloud cover remains challenging due to the small-scale nature of cloud formation processes. In this study, we introduce CloudCast, a convolutional neural network (CNN) based on the U-Net architecture, designed to predict total cloud cover (TCC) up to five hours ahead. Trained on five years of satellite data, CloudCast significantly outperforms traditional NWP models and optical flow methods. Compared to a reference NWP model, CloudCast achieves a 24% lower mean absolute error and reduces multi-category prediction errors by 46%. The model demonstrates strong performance, particularly in capturing the large-scale structure of cloud cover in the first few forecast hours, though later predictions are subject to blurring and underestimation of cloud formation. An ablation study identified the optimal input features and loss functions, with MAE-based models performing the best. CloudCast has been integrated into the Finnish Meteorological Institute's operational nowcasting system, where it improves cloud cover forecasts used by public and private sector clients. While CloudCast is limited by a relatively short skillful lead time of about three hours, future work aims to extend this through more complex network architectures and higher-resolution data. CloudCast code is available at https://github.com/fmidev/cloudcast.","authors":["Mikko Partio","Leila Hieta","Anniina Kokkonen"],"url":"https://arxiv.org/abs/2410.21329"}
{"created":"2025-05-20","title":"New Lower-bounds for Quantum Computation with Non-Collapsing Measurements","abstract":"Aaronson, Bouland, Fitzsimons and Lee introduced the complexity class PDQP (which was original labeled naCQP), an alteration of BQP enhanced with the ability to obtain non-collapsing measurements, samples of quantum states without collapsing them. Although PDQP contains SZK, it still requires $\\Omega(N^{1/4})$ queries to solve unstructured search. We formulate an alternative equivalent definition of PDQP, which we use to prove the positive weighted adversary lower-bounding method, establishing multiple tighter bounds and a trade-off between queries and non-collapsing measurements. We utilize the technique in order to analyze the query complexity of the well-studied majority and element distinctness problems. Additionally, we prove a tight $\\Theta(N^{1/3})$ bound on search. Furthermore, we use the lower-bound to explore PDQP under query restrictions, finding that when combined with non-adaptive queries, we limit the speed-up in several cases.","authors":["David Miloschewsky","Supartha Podder"],"url":"https://arxiv.org/abs/2411.04085"}
{"created":"2025-05-20","title":"Training-Free Bayesianization for Low-Rank Adapters of Large Language Models","abstract":"Estimating the uncertainty of responses from Large Language Models (LLMs) remains a critical challenge. While recent Bayesian methods have demonstrated effectiveness in quantifying uncertainty through low-rank weight updates, they typically require complex fine-tuning or post-training procedures. In this paper, we propose Training-Free Bayesianization (TFB), a simple yet theoretically grounded framework that efficiently transforms trained low-rank adapters into Bayesian ones without additional training. TFB systematically searches for the maximally acceptable level of variance in the weight posterior, constrained within a family of low-rank isotropic Gaussian distributions. Our theoretical analysis shows that under mild conditions, this search process is equivalent to KL-regularized variational optimization, a generalized form of variational inference. Through comprehensive experiments, we show that TFB achieves superior uncertainty estimation and generalization compared to existing methods while eliminating the need for complex Bayesianization training procedures. Code will be available at https://github.com/Wang-ML-Lab/bayesian-peft.","authors":["Haizhou Shi","Yibin Wang","Ligong Han","Huan Zhang","Hao Wang"],"url":"https://arxiv.org/abs/2412.05723"}
{"created":"2025-05-20","title":"Unsupervised Multi-Parameter Inverse Solving for Reducing Ring Artifacts in 3D X-Ray CBCT","abstract":"Ring artifacts are prevalent in 3D cone-beam computed tomography (CBCT) due to non-ideal responses of X-ray detectors, substantially affecting image quality and diagnostic reliability. Existing state-of-the-art (SOTA) ring artifact reduction (RAR) methods rely on supervised learning with large-scale paired CT datasets. While effective in-domain, supervised methods tend to struggle to fully capture the physical characteristics of ring artifacts, leading to pronounced performance drops in complex real-world acquisitions. Moreover, their scalability to 3D CBCT is limited by high memory demands. In this work, we propose Riner, a new unsupervised RAR method. Based on a theoretical analysis of ring artifact formation, we reformulate RAR as a multi-parameter inverse problem, where the non-ideal responses of X-ray detectors are parameterized as solvable physical variables. Using a new differentiable forward model, Riner can jointly learn the implicit neural representation of artifact-free images and estimate the physical parameters directly from CT measurements, without external training data. Additionally, Riner is memory-friendly due to its ray-based optimization, enhancing its usability in large-scale 3D CBCT. Experiments on both simulated and real-world datasets show Riner outperforms existing SOTA supervised methods.","authors":["Qing Wu","Hongjiang Wei","Jingyi Yu","Yuyao Zhang"],"url":"https://arxiv.org/abs/2412.05853"}
{"created":"2025-05-20","title":"The Jacobi Factoring Circuit: Quantum Factoring with Near-Linear Gates and Sublinear Space and Depth","abstract":"We present a compact quantum circuit for factoring a large class of integers, including some whose classical hardness is expected to be equivalent to RSA (but not including RSA integers themselves). Most notably, we factor $n$-bit integers of the form $P^2 Q$ with $\\log Q = \\Theta(n^a)$ for $a \\in (2/3, 1)$ in space and depth sublinear in n (specifically, $\\tilde{O}(\\log Q)$) using $\\tilde{O}(n)$ quantum gates; for these integers, no known classical algorithms exploit the relatively small size of $Q$ to run asymptotically faster than general-purpose factoring algorithms. To our knowledge, this is the first polynomial-time circuit to achieve sublinear qubit count for a classically-hard factoring problem. We thus believe that factoring such numbers has potential to be the most concretely efficient classically-verifiable proof of quantumness currently known.","authors":["Gregory D. Kahanamoku-Meyer","Seyoon Ragavan","Vinod Vaikuntanathan","Katherine Van Kirk"],"url":"https://arxiv.org/abs/2412.12558"}
{"created":"2025-05-20","title":"Universal Speaker Embedding Free Target Speaker Extraction and Personal Voice Activity Detection","abstract":"Determining 'who spoke what and when' remains challenging in real-world applications. In typical scenarios, Speaker Diarization (SD) is employed to address the problem of 'who spoke when,' while Target Speaker Extraction (TSE) or Target Speaker Automatic Speech Recognition (TSASR) techniques are utilized to resolve the issue of 'who spoke what.' Although some works have achieved promising results by combining SD and TSE systems, inconsistencies remain between SD and TSE regarding both output inconsistency and scenario mismatch. To address these limitations, we propose a Universal Speaker Embedding Free Target Speaker Extraction and Personal Voice Activity Detection (USEF-TP) model that jointly performs TSE and Personal Voice Activity Detection (PVAD). USEF-TP leverages frame-level features obtained through a cross-attention mechanism as speaker-related features instead of using speaker embeddings as in traditional approaches. Additionally, a multi-task learning algorithm with a scenario-aware differentiated loss function is applied to ensure robust performance across various levels of speaker overlap. The experimental results show that our proposed USEF-TP model achieves superior performance in TSE and PVAD tasks on the LibriMix and SparseLibriMix datasets. The results on the CALLHOME dataset demonstrate the competitive performance of our model on real recordings.","authors":["Bang Zeng","Ming Li"],"url":"https://arxiv.org/abs/2501.03612"}
{"created":"2025-05-20","title":"Generative Modeling: A Review","abstract":"Generative methods (Gen-AI) are reviewed with a particular goal of solving tasks in machine learning and Bayesian inference. Generative models require one to simulate a large training dataset and to use deep neural networks to solve a supervised learning problem. To do this, we require high-dimensional regression methods and tools for dimensionality reduction (a.k.a. feature selection). The main advantage of Gen-AI methods is their ability to be model-free and to use deep neural networks to estimate conditional densities or posterior quintiles of interest. To illustrate generative methods , we analyze the well-known Ebola data set. Finally, we conclude with directions for future research.","authors":["Maria Nareklishvili","Nick Polson","Vadim Sokolov"],"url":"https://arxiv.org/abs/2501.05458"}
{"created":"2025-05-20","title":"Nesterov Acceleration for Ensemble Kalman Inversion and Variants","abstract":"Ensemble Kalman inversion (EKI) is a derivative-free, particle-based optimization method for solving inverse problems. It can be shown that EKI approximates a gradient flow, which allows the application of methods for accelerating gradient descent. Here, we show that Nesterov acceleration is effective in speeding up the reduction of the EKI cost function on a variety of inverse problems. We also implement Nesterov acceleration for two EKI variants, unscented Kalman inversion and ensemble transform Kalman inversion. Our specific implementation takes the form of a particle-level nudge that is demonstrably simple to couple in a black-box fashion with any existing EKI variant algorithms, comes with no additional computational expense, and with no additional tuning hyperparameters. This work shows a pathway for future research to translate advances in gradient-based optimization into advances in gradient-free Kalman optimization.","authors":["Sydney Vernon","Eviatar Bach","Oliver R. A. Dunbar"],"url":"https://arxiv.org/abs/2501.08779"}
{"created":"2025-05-20","title":"Sample Complexity Bounds for Scalar Parameter Estimation Under Quantum Differential Privacy","abstract":"This paper presents tight upper and lower bounds for minimum number of samples (copies of a quantum state) required to attain a prescribed accuracy (measured by error variance) for scalar parameters estimation using unbiased estimators under quantum local differential privacy for qubits. Particularly, the best-case (optimal) scenario is considered by minimizing the sample complexity over all differentially-private channels; the worst-case channels can be arbitrarily uninformative and render the problem ill-defined. In the small privacy budget $\\epsilon$ regime, i.e., $\\epsilon\\ll 1$, the sample complexity scales as $\\Theta(\\epsilon^{-2})$. This bound matches that of classical parameter estimation under local differential privacy. The lower bound however loosens in the large privacy budget regime, i.e., $\\epsilon\\gg 1$. The upper bound for the minimum number of samples is generalized to qudits (with dimension $d$) resulting in sample complexity of $O(d\\epsilon^{-2})$.","authors":["Farhad Farokhi"],"url":"https://arxiv.org/abs/2501.14184"}
{"created":"2025-05-20","title":"STAR-RIS-Enabled Multi-Path Beam Routing with Passive Beam Splitting","abstract":"Reconfigurable intelligent surfaces (RISs) can be densely deployed in the environment to create multi-reflection line-of-sight (LoS) links for signal coverage enhancement. However, conventional reflection-only RISs can only achieve half-space reflection, which limits the LoS path diversity. In contrast, simultaneously transmitting and reflecting RISs (STAR-RISs) can achieve full-space reflection and transmission, thereby creating more LoS paths. Hence, in this paper, we study a new multi-STAR-RIS-aided communication system, where a multi-antenna base station (BS) transmits to multiple single-antenna users by exploiting the signal beam routing over a set of cascaded LoS paths each formed by multiple STAR-RISs. To reveal essential insights, we first consider a simplified single-user case, aiming to maximize its received signal power by jointly optimizing the active beamforming at the BS, the BS's power allocation over different paths, the number of selected beam-routing paths, the selected STAR-RISs for each path, as well as their amplitude and phase shifts for transmission/reflection. However, this problem is difficult to be optimally solved as different paths may be intricately coupled at their shared STAR-RISs. To tackle this difficulty, we first derive the optimal solution to this problem in closed-form for a given set of paths. The clique-based approach in graph theory is then applied to solve the remaining multi-path selection problem efficiently. Next, we extend the proposed clique-based method to the multi-user case to maximize the minimum received signal power among all users, subject to additional constraints on the disjointness of the selected paths for different users. Simulation results show that our proposed STAR-RIS-enabled beam routing outperforms the conventional beam routing with reflection-only RISs in both single- and multi-user cases.","authors":["Bonan An","Weidong Mei","Yuanwei Liu","Dong Wang","Zhi Chen"],"url":"https://arxiv.org/abs/2501.14234"}
{"created":"2025-05-20","title":"The Effect of Optimal Self-Distillation in Noisy Gaussian Mixture Model","abstract":"Self-distillation (SD), a technique where a model improves itself using its own predictions, has attracted attention as a simple yet powerful approach in machine learning. Despite its widespread use, the mechanisms underlying its effectiveness remain unclear. In this study, we investigate the efficacy of hyperparameter-tuned multi-stage SD with a linear classifier for binary classification on noisy Gaussian mixture data. For the analysis, we employ the replica method from statistical physics. Our findings reveal that the primary driver of SD's performance improvement is denoising through hard pseudo-labels, with the most notable gains observed in moderately sized datasets. We also identify two practical heuristics to enhance SD: early stopping that limits the number of stages, which is broadly effective, and bias parameter fixing, which helps under label imbalance. To empirically validate our theoretical findings derived from our toy model, we conduct additional experiments on CIFAR-10 classification using pretrained ResNet backbone. These results provide both theoretical and practical insights, advancing our understanding and application of SD in noisy settings.","authors":["Kaito Takanami","Takashi Takahashi","Ayaka Sakata"],"url":"https://arxiv.org/abs/2501.16226"}
{"created":"2025-05-20","title":"Online Learning of Pure States is as Hard as Mixed States","abstract":"Quantum state tomography, the task of learning an unknown quantum state, is a fundamental problem in quantum information. In standard settings, the complexity of this problem depends significantly on the type of quantum state that one is trying to learn, with pure states being substantially easier to learn than general mixed states. A natural question is whether this separation holds for any quantum state learning setting. In this work, we consider the online learning framework and prove the surprising result that learning pure states in this setting is as hard as learning mixed states. More specifically, we show that both classes share almost the same sequential fat-shattering dimension, leading to identical regret scaling. We also generalize previous results on full quantum state tomography in the online setting to (i) the $\\epsilon$-realizable setting and (ii) learning the density matrix only partially, using smoothed analysis.","authors":["Maxime Meyer","Soumik Adhikary","Naixu Guo","Patrick Rebentrost"],"url":"https://arxiv.org/abs/2502.00823"}
{"created":"2025-05-20","title":"The Shape of Generalization through the Lens of Norm-based Capacity Control","abstract":"Understanding how the test risk scales with model complexity is a central question in machine learning. Classical theory is challenged by the learning curves observed for large over-parametrized deep networks. Capacity measures based on parameter count typically fail to account for these empirical observations. To tackle this challenge, we consider norm-based capacity measures and develop our study for random features based estimators, widely used as simplified theoretical models for more complex networks. In this context, we provide a precise characterization of how the estimator's norm concentrates and how it governs the associated test error. Our results show that the predicted learning curve admits a phase transition from under- to over-parameterization, but no double descent behavior. This confirms that more classical U-shaped behavior is recovered considering appropriate capacity measures based on models norms rather than size. From a technical point of view, we leverage deterministic equivalence as the key tool and further develop new deterministic quantities which are of independent interest.","authors":["Yichen Wang","Yudong Chen","Lorenzo Rosasco","Fanghui Liu"],"url":"https://arxiv.org/abs/2502.01585"}
{"created":"2025-05-20","title":"Unique expansions in number systems via refinement equations","abstract":"Using the subdivision schemes theory, we develop a criterion to check if any natural number has at most one representation in the $n$-ary number system with a set of non-negative integer digits $A=\\{a_1, a_2,\\ldots, a_n\\}$ that contains zero. This uniqueness property is shown to be equivalent to a certain restriction on the roots of the trigonometric polynomial $\\sum_{k=1}^n e^{-2\\pi i a_k t}$. From this criterion, under a natural condition of irreducibility for $A$, we deduce that in case of prime $n$ the uniqueness holds if and only if the digits of $A$ are distinct modulo $n$, whereas for any composite $n$ we show that the latter condition is not necessary. We also establish the connection of this uniqueness to the semigroup freeness problem for affine integer functions of equal integer slope; this together with the two criteria allows to fill the gap in the work of D.Klarner on Erd\\\"os question about densities of affine integer orbits and establish a simple algorithm to check the freeness and the positivity of density when the slope is a prime number.","authors":["Sergei V. Konyagin","Vladimir Yu. Protasov","Alexey L. Talambutsa"],"url":"https://arxiv.org/abs/2502.13066"}
{"created":"2025-05-20","title":"Conformal Prediction under Levy-Prokhorov Distribution Shifts: Robustness to Local and Global Perturbations","abstract":"Conformal prediction provides a powerful framework for constructing prediction intervals with finite-sample guarantees, yet its robustness under distribution shifts remains a significant challenge. This paper addresses this limitation by modeling distribution shifts using Levy-Prokhorov (LP) ambiguity sets, which capture both local and global perturbations. We provide a self-contained overview of LP ambiguity sets and their connections to popular metrics such as Wasserstein and Total Variation. We show that the link between conformal prediction and LP ambiguity sets is a natural one: by propagating the LP ambiguity set through the scoring function, we reduce complex high-dimensional distribution shifts to manageable one-dimensional distribution shifts, enabling exact quantification of worst-case quantiles and coverage. Building on this analysis, we construct robust conformal prediction intervals that remain valid under distribution shifts, explicitly linking LP parameters to interval width and confidence levels. Experimental results on real-world datasets demonstrate the effectiveness of the proposed approach.","authors":["Liviu Aolaritei","Zheyu Oliver Wang","Julie Zhu","Michael I. Jordan","Youssef Marzouk"],"url":"https://arxiv.org/abs/2502.14105"}
{"created":"2025-05-20","title":"AI-Powered Bayesian Inference","abstract":"The advent of Generative Artificial Intelligence (GAI) has heralded an inflection point that changed how society thinks about knowledge acquisition. While GAI cannot be fully trusted for decision-making, it may still provide valuable information that can be integrated into a decision pipeline. Rather than seeing the lack of certitude and inherent randomness of GAI as a problem, we view it as an opportunity. Indeed, variable answers to given prompts can be leveraged to construct a prior distribution which reflects assuredness of AI predictions. This prior distribution may be combined with tailored datasets for a fully Bayesian analysis with an AI-driven prior. In this paper, we explore such a possibility within a non-parametric Bayesian framework. The basic idea consists of assigning a Dirichlet process prior distribution on the data-generating distribution with AI generative model as its baseline. Hyper-parameters of the prior can be tuned out-of-sample to assess the informativeness of the AI prior. Posterior simulation is achieved by computing a suitably randomized functional on an augmented data that consists of observed (labeled) data as well as fake data whose labels have been imputed using AI. This strategy can be parallelized and rapidly produces iid samples from the posterior by optimization as opposed to sampling from conditionals. Our method enables (predictive) inference and uncertainty quantification leveraging AI predictions in a coherent probabilistic manner.","authors":["Sean O'Hagan","Veronika Ro\\v{c}kov\\'a"],"url":"https://arxiv.org/abs/2502.19231"}
{"created":"2025-05-20","title":"Overcoming Dependent Censoring in the Evaluation of Survival Models","abstract":"Conventional survival metrics, such as Harrell's concordance index (CI) and the Brier Score, rely on the independent censoring assumption for valid inference with right-censored data. However, in the presence of so-called dependent censoring, where the probability of censoring is related to the event of interest, these metrics can give biased estimates of the underlying model error. In this paper, we introduce three new evaluation metrics for survival analysis based on Archimedean copulas that can account for dependent censoring. We also develop a framework to generate realistic, semi-synthetic datasets with dependent censoring to facilitate the evaluation of the metrics. Our experiments in synthetic and semi-synthetic data demonstrate that the proposed metrics can provide more accurate estimates of the model error than conventional metrics under dependent censoring.","authors":["Christian Marius Lillelund","Shi-ang Qi","Russell Greiner"],"url":"https://arxiv.org/abs/2502.19460"}
{"created":"2025-05-20","title":"Adaptive Extrapolated Proximal Gradient Methods with Variance Reduction for Composite Nonconvex Finite-Sum Minimization","abstract":"This paper proposes {\\sf AEPG-SPIDER}, an Adaptive Extrapolated Proximal Gradient (AEPG) method with variance reduction for minimizing composite nonconvex finite-sum functions. It integrates three acceleration techniques: adaptive stepsizes, Nesterov's extrapolation, and the recursive stochastic path-integrated estimator SPIDER. Unlike existing methods that adjust the stepsize factor using historical gradients, {\\sf AEPG-SPIDER} relies on past iterate differences for its update. While targeting stochastic finite-sum problems, {\\sf AEPG-SPIDER} simplifies to {\\sf AEPG} in the full-batch, non-stochastic setting, which is also of independent interest. To our knowledge, {\\sf AEPG-SPIDER} and {\\sf AEPG} are the first Lipschitz-free methods to achieve optimal iteration complexity for this class of \\textit{composite} minimization problems. Specifically, {\\sf AEPG} achieves the optimal iteration complexity of $\\mathcal{O}(N \\epsilon^{-2})$, while {\\sf AEPG-SPIDER} achieves $\\mathcal{O}(N + \\sqrt{N} \\epsilon^{-2})$ for finding $\\epsilon$-approximate stationary points, where $N$ is the number of component functions. Under the Kurdyka-Lojasiewicz (KL) assumption, we establish non-ergodic convergence rates for both methods. Preliminary experiments on sparse phase retrieval and linear eigenvalue problems demonstrate the superior performance of {\\sf AEPG-SPIDER} and {\\sf AEPG} compared to existing methods.","authors":["Ganzhao Yuan"],"url":"https://arxiv.org/abs/2502.21099"}
{"created":"2025-05-20","title":"Asymptotic Analysis of Two-Layer Neural Networks after One Gradient Step under Gaussian Mixtures Data with Structure","abstract":"In this work, we study the training and generalization performance of two-layer neural networks (NNs) after one gradient descent step under structured data modeled by Gaussian mixtures. While previous research has extensively analyzed this model under isotropic data assumption, such simplifications overlook the complexities inherent in real-world datasets. Our work addresses this limitation by analyzing two-layer NNs under Gaussian mixture data assumption in the asymptotically proportional limit, where the input dimension, number of hidden neurons, and sample size grow with finite ratios. We characterize the training and generalization errors by leveraging recent advancements in Gaussian universality. Specifically, we prove that a high-order polynomial model performs equivalent to the nonlinear neural networks under certain conditions. The degree of the equivalent model is intricately linked to both the \"data spread\" and the learning rate employed during one gradient step. Through extensive simulations, we demonstrate the equivalence between the original model and its polynomial counterpart across various regression and classification tasks. Additionally, we explore how different properties of Gaussian mixtures affect learning outcomes. Finally, we illustrate experimental results on Fashion-MNIST classification, indicating that our findings can translate to realistic data.","authors":["Samet Demir","Zafer Dogan"],"url":"https://arxiv.org/abs/2503.00856"}
{"created":"2025-05-20","title":"Value-Oriented Forecast Combinations for Unit Commitment","abstract":"Value-oriented forecasts for two-stage power system operational problems have been demonstrated to reduce cost, but prove to be computationally challenging for large-scale systems because the underlying optimization problem must be internalized into the forecast model training. Therefore, existing approaches typically scale poorly in the usable training data or require relaxations of the underlying optimization. This paper presents a method for value-oriented forecast combinations using progressive hedging, which unlocks high-fidelity, at-scale models and large-scale datasets in training. We also derive one-shot training model for reference and study how different modifications of the training model impact the solution quality.","authors":["Mehrnoush Ghazanfariharandi","Robert Mieth"],"url":"https://arxiv.org/abs/2503.13677"}
{"created":"2025-05-20","title":"Blockchain with proof of quantum work","abstract":"We propose a blockchain architecture in which mining requires a quantum computer. The consensus mechanism is based on proof of quantum work, a quantum-enhanced alternative to traditional proof of work that leverages quantum supremacy to make mining intractable for classical computers. We have refined the blockchain framework to incorporate the probabilistic nature of quantum mechanics, ensuring stability against sampling errors and hardware inaccuracies. To validate our approach, we implemented a prototype blockchain on four D-Wave(TM) quantum annealing processors geographically distributed within North America, demonstrating stable operation across hundreds of thousands of quantum hashing operations. Our experimental protocol follows the same approach used in the recent demonstration of quantum supremacy [King et al. Science 2025], ensuring that classical computers cannot efficiently perform the same computation task. By replacing classical machines with quantum systems for mining, it is possible to significantly reduce the energy consumption and environmental impact traditionally associated with blockchain mining while providing a quantum-safe layer of security. Beyond serving as a proof of concept for a meaningful application of quantum computing, this work highlights the potential for other near-term quantum computing applications using existing technology.","authors":["Mohammad H. Amin","Jack Raymond","Daniel Kinn","Firas Hamze","Kelsey Hamer","Joel Pasvolsky","William Bernoudy","Andrew D. King","Samuel Kortas"],"url":"https://arxiv.org/abs/2503.14462"}
{"created":"2025-05-20","title":"Submillimeter-Accurate 3D Lumbar Spine Reconstruction from Biplanar X-Ray Images: Incorporating a Multi-Task Network and Landmark-Weighted Loss","abstract":"Three-dimensional reconstruction of the spine under weight-bearing conditions from biplanar X-ray images is of great importance for the clinical assessment of spinal diseases. However, the current fully automated reconstruction methods only achieve millimeter-level accuracy, making it difficult to meet clinical standards. This study developed and validated a fully automated method for high-accuracy 3D reconstruction of the lumbar spine from biplanar X-ray images. The method involves lumbar decomposition and landmark detection from the raw X-ray images, followed by a deformable model and landmark-weighted 2D-3D registration approach. The reconstruction accuracy was validated by the gold standard obtained through the registration of CT-segmented vertebral models with the biplanar X-ray images. The proposed method achieved a 3D reconstruction accuracy of 0.80mm, representing a significant improvement over the mainstream approaches. This study will contribute to the clinical diagnosis of lumbar in weight-bearing positions.","authors":["Wanxin Yu","Zhemin Zhu","Cong Wang","Yihang Bao","Chunjie Xia","Rongshan Cheng","Yan Yu","Tsung-Yuan Tsai"],"url":"https://arxiv.org/abs/2503.14573"}
{"created":"2025-05-20","title":"Revenue Maximization Under Sequential Price Competition Via The Estimation Of s-Concave Demand Functions","abstract":"We consider price competition among multiple sellers over a selling horizon of $T$ periods. In each period, sellers simultaneously offer their prices and subsequently observe their respective demand that is unobservable to competitors. The demand function for each seller depends on all sellers' prices through a private, unknown, and nonlinear relationship. To address this challenge, we propose a semi-parametric least-squares estimation of the nonlinear mean function, which does not require sellers to communicate demand information. We show that when all sellers employ our policy, their prices converge at a rate of $O(T^{-1/7})$ to the Nash equilibrium prices that sellers would reach if they were fully informed. Each seller incurs a regret of $O(T^{5/7})$ relative to a dynamic benchmark policy. A theoretical contribution of our work is proving the existence of equilibrium under shape-constrained demand functions via the concept of $s$-concavity and establishing regret bounds of our proposed policy. Technically, we also establish new concentration results for the least squares estimator under shape constraints. Our findings offer significant insights into dynamic competition-aware pricing and contribute to the broader study of non-parametric learning in strategic decision-making.","authors":["Daniele Bracale","Moulinath Banerjee","Cong Shi","Yuekai Sun"],"url":"https://arxiv.org/abs/2503.16737"}
{"created":"2025-05-20","title":"High Accuracy Pulmonary Vessel Segmentation for Contrast and Non-contrast CT Images and Clinical Evaluation","abstract":"Accurate segmentation of pulmonary vessels plays a very critical role in diagnosing and assessing various lung diseases. Currently, many automated algorithms are primarily targeted at CTPA (Computed Tomography Pulmonary Angiography) types of data. However, the segmentation precision of these methods is insufficient, and support for NCCT (Non-Contrast Computed Tomography) types of data is also a requirement in some clinical scenarios. In this study, we propose a 3D image segmentation algorithm for automated pulmonary vessel segmentation from both contrast-enhanced and non-contrast CT images. In the network, we designed a Vessel Lumen Structure Optimization Module (VLSOM), which extracts the centerline (Cl) of vessels and adjusts the weights based on the positional information and adds a Cl-Dice Loss to supervise the stability of the vessels structure. We used 427 sets of high-precision annotated CT data from multiple vendors and countries to train the model and achieved Cl-DICE, Cl-Recall, and Recall values of 0.892, 0.861, 0.924 for CTPA data and 0.925, 0.903, 0.949 for NCCT data. This shows that our model has achieved good performance in both accuracy and completeness of pulmonary vessel segmentation. We finally conducted a clinical visual assessment on an independent external test dataset. The average score for accuracy and robustness, branch abundance, assistance for diagnosis and vascular continuity are 4.26, 4.17, 4.33, 3.83 respectively while the full score is 5. These results highlight the great potential of this method in clinical application.","authors":["Ying Ming (Department of Radiology Peking Union Medical College Hospital Chinese Academy of Medical Sciences and Peking Union Medical College)","Shaoze Luo (Research and Development Center Canon Medical Systems China)","Longfei Zhao (Research and Development Center Canon Medical Systems China)","Ruijie Zhao (Department of Radiology Peking Union Medical College Hospital Chinese Academy of Medical Sciences and Peking Union Medical College)","Bing Li (Research and Development Center Canon Medical Systems China)","Qiqi Xu (Research and Development Center Canon Medical Systems China)","Wei Song (Department of Radiology Peking Union Medical College Hospital Chinese Academy of Medical Sciences and Peking Union Medical College)"],"url":"https://arxiv.org/abs/2503.16988"}
{"created":"2025-05-20","title":"Calibration Strategies for Robust Causal Estimation: Theoretical and Empirical Insights on Propensity Score-Based Estimators","abstract":"The partitioning of data for estimation and calibration critically impacts the performance of propensity score based estimators like inverse probability weighting (IPW) and double/debiased machine learning (DML) frameworks. We extend recent advances in calibration techniques for propensity score estimation, improving the robustness of propensity scores in challenging settings such as limited overlap, small sample sizes, or unbalanced data. Our contributions are twofold: First, we provide a theoretical analysis of the properties of calibrated estimators in the context of DML. To this end, we refine existing calibration frameworks for propensity score models, with a particular emphasis on the role of sample-splitting schemes in ensuring valid causal inference. Second, through extensive simulations, we show that calibration reduces variance of inverse-based propensity score estimators while also mitigating bias in IPW, even in small-sample regimes. Notably, calibration improves stability for flexible learners (e.g., gradient boosting) while preserving the doubly robust properties of DML. A key insight is that, even when methods perform well without calibration, incorporating a calibration step does not degrade performance, provided that an appropriate sample-splitting approach is chosen.","authors":["Sven Klaassen","Jan Rabenseifner","Jannis Kueck","Philipp Bach"],"url":"https://arxiv.org/abs/2503.17290"}
{"created":"2025-05-20","title":"NaFM: Pre-training a Foundation Model for Small-Molecule Natural Products","abstract":"Natural products, as metabolites from microorganisms, animals, or plants, exhibit diverse biological activities, making them crucial for drug discovery. Nowadays, existing deep learning methods for natural products research primarily rely on supervised learning approaches designed for specific downstream tasks. However, such one-model-for-a-task paradigm often lacks generalizability and leaves significant room for performance improvement. Additionally, existing molecular characterization methods are not well-suited for the unique tasks associated with natural products. To address these limitations, we have pre-trained a foundation model for natural products based on their unique properties. Our approach employs a novel pretraining strategy that is especially tailored to natural products. By incorporating contrastive learning and masked graph learning objectives, we emphasize evolutional information from molecular scaffolds while capturing side-chain information. Our framework achieves state-of-the-art (SOTA) results in various downstream tasks related to natural product mining and drug discovery. We first compare taxonomy classification with synthesized molecule-focused baselines to demonstrate that current models are inadequate for understanding natural synthesis. Furthermore, by diving into a fine-grained analysis at both the gene and microbial levels, NaFM demonstrates the ability to capture evolutionary information. Eventually, our method is experimented with virtual screening, illustrating informative natural product representations that can lead to more effective identification of potential drug candidates.","authors":["Yuheng Ding","Bo Qiang","Yiran Zhou","Jie Yu","Qi Li","Liangren Zhang","Yusong Wang","Zhenmin Liu"],"url":"https://arxiv.org/abs/2503.17656"}
{"created":"2025-05-20","title":"Detecting Arbitrary Planted Subgraphs in Random Graphs","abstract":"The problems of detecting and recovering planted structures/subgraphs in Erd\\H{o}s-R\\'{e}nyi random graphs, have received significant attention over the past three decades, leading to many exciting results and mathematical techniques. However, prior work has largely focused on specific ad hoc planted structures and inferential settings, while a general theory has remained elusive. In this paper, we bridge this gap by investigating the detection of an \\emph{arbitrary} planted subgraph $\\Gamma = \\Gamma_n$ in an Erd\\H{o}s-R\\'{e}nyi random graph $\\mathcal{G}(n, q_n)$, where the edge probability within $\\Gamma$ is $p_n$. We examine both the statistical and computational aspects of this problem and establish the following results. In the dense regime, where the edge probabilities $p_n$ and $q_n$ are fixed, we tightly characterize the information-theoretic and computational thresholds for detecting $\\Gamma$, and provide conditions under which a computational-statistical gap arises. Most notably, these thresholds depend on $\\Gamma$ only through its number of edges, maximum degree, and maximum subgraph density. Our lower and upper bounds are general and apply to any value of $p_n$ and $q_n$ as functions of $n$. Accordingly, we also analyze the sparse regime where $q_n = \\Theta(n^{-\\alpha})$ and $p_n-q_n =\\Theta(q_n)$, with $\\alpha\\in[0,2]$, as well as the critical regime where $p_n=1-o(1)$ and $q_n = \\Theta(n^{-\\alpha})$, both of which have been widely studied, for specific choices of $\\Gamma$. For these regimes, we show that our bounds are tight for all planted subgraphs investigated in the literature thus far\\textemdash{}and many more. Finally, we identify conditions under which detection undergoes sharp phase transition, where the boundaries at which algorithms succeed or fail shift abruptly as a function of $q_n$.","authors":["Dor Elimelech","Wasim Huleihel"],"url":"https://arxiv.org/abs/2503.19069"}
{"created":"2025-05-20","title":"Resource Allocation for RIS-Assisted CoMP-NOMA Networks using Reinforcement Learning","abstract":"This thesis delves into the forefront of wireless communication by exploring the synergistic integration of three transformative technologies: STAR-RIS, CoMP, and NOMA. Driven by the ever-increasing demand for higher data rates, improved spectral efficiency, and expanded coverage in the evolving landscape of 6G development, this research investigates the potential of these technologies to revolutionize future wireless networks.","authors":["Muhammad Umer","Muhammad Ahmed Mohsin","Huma Ghafoor","Syed Ali Hassan"],"url":"https://arxiv.org/abs/2504.00975"}
{"created":"2025-05-20","title":"Quantum Deep Sets and Sequences","abstract":"This paper introduces the quantum deep sets model, expanding the quantum machine learning tool-box by enabling the possibility of learning variadic functions using quantum systems. A couple of variants are presented for this model. The first one focuses on mapping sets to quantum systems through state vector averaging: each element of the set is mapped to a quantum state, and the quantum state of the set is the average of the corresponding quantum states of its elements. This approach allows the definition of a permutation-invariant variadic model. The second variant is useful for ordered sets, i.e., sequences, and relies on optimal coherification of tristochastic tensors that implement products of mixed states: each element of the set is mapped to a density matrix, and the quantum state of the set is the product of the corresponding density matrices of its elements. Such variant can be relevant in tasks such as natural language processing. The resulting quantum state in any of the variants is then processed to realise a function that solves a machine learning task such as classification, regression or density estimation. Through synthetic problem examples, the efficacy and versatility of quantum deep sets and sequences (QDSs) is demonstrated.","authors":["Vladimir Vargas-Calder\\'on"],"url":"https://arxiv.org/abs/2504.02241"}
{"created":"2025-05-20","title":"DualMS: Implicit Dual-Channel Minimal Surface Optimization for Heat Exchanger Design","abstract":"Heat exchangers are critical components in a wide range of engineering applications, from energy systems to chemical processing, where efficient thermal management is essential. The design objectives for heat exchangers include maximizing the heat exchange rate while minimizing the pressure drop, requiring both a large interface area and a smooth internal structure. State-of-the-art designs, such as triply periodic minimal surfaces (TPMS), have proven effective in optimizing heat exchange efficiency. However, TPMS designs are constrained by predefined mathematical equations, limiting their adaptability to freeform boundary shapes. Additionally, TPMS structures do not inherently control flow directions, which can lead to flow stagnation and undesirable pressure drops.","authors":["Weizheng Zhang","Hao Pan","Lin Lu","Xiaowei Duan","Xin Yan","Ruonan Wang","Qiang Du"],"url":"https://arxiv.org/abs/2504.02830"}
{"created":"2025-05-20","title":"Prot42: a Novel Family of Protein Language Models for Target-aware Protein Binder Generation","abstract":"Unlocking the next generation of biotechnology and therapeutic innovation demands overcoming the inherent complexity and resource-intensity of conventional protein engineering methods. Recent GenAI-powered computational techniques often rely on the availability of the target protein's 3D structures and specific binding sites to generate high-affinity binders, constraints exhibited by models such as AlphaProteo and RFdiffusion. In this work, we explore the use of Protein Language Models (pLMs) for high-affinity binder generation. We introduce Prot42, a novel family of Protein Language Models (pLMs) pretrained on vast amounts of unlabeled protein sequences. By capturing deep evolutionary, structural, and functional insights through an advanced auto-regressive, decoder-only architecture inspired by breakthroughs in natural language processing, Prot42 dramatically expands the capabilities of computational protein design based on language only. Remarkably, our models handle sequences up to 8,192 amino acids, significantly surpassing standard limitations and enabling precise modeling of large proteins and complex multi-domain sequences. Demonstrating powerful practical applications, Prot42 excels in generating high-affinity protein binders and sequence-specific DNA-binding proteins. Our innovative models are publicly available, offering the scientific community an efficient and precise computational toolkit for rapid protein engineering.","authors":["Mohammad Amaan Sayeed","Engin Tekin","Maryam Nadeem","Nancy A. ElNaker","Aahan Singh","Natalia Vassilieva","Boulbaba Ben Amor"],"url":"https://arxiv.org/abs/2504.04453"}
{"created":"2025-05-20","title":"A simulation-heuristics dual-process model for intuitive physics","abstract":"The role of mental simulation in human physical reasoning is widely acknowledged, but whether it is employed across scenarios with varying simulation costs and where its boundary lies remains unclear. Using a pouring-marble task, our human study revealed two distinct error patterns when predicting pouring angles, differentiated by simulation time. While mental simulation accurately captured human judgments in simpler scenarios, a linear heuristic model better matched human predictions when simulation time exceeded a certain boundary. Motivated by these observations, we propose a dual-process framework, Simulation-Heuristics Model (SHM), where intuitive physics employs simulation for short-time simulation but switches to heuristics when simulation becomes costly. By integrating computational methods previously viewed as separate into a unified model, SHM quantitatively captures their switching mechanism. The SHM aligns more precisely with human behavior and demonstrates consistent predictive performance across diverse scenarios, advancing our understanding of the adaptive nature of intuitive physical reasoning.","authors":["Shiqian Li","Yuxi Ma","Jiajun Yan","Bo Dai","Yujia Peng","Chi Zhang","Yixin Zhu"],"url":"https://arxiv.org/abs/2504.09546"}
{"created":"2025-05-20","title":"BrainPrompt: Multi-Level Brain Prompt Enhancement for Neurological Condition Identification","abstract":"Neurological conditions, such as Alzheimer's Disease, are challenging to diagnose, particularly in the early stages where symptoms closely resemble healthy controls. Existing brain network analysis methods primarily focus on graph-based models that rely solely on imaging data, which may overlook important non-imaging factors and limit the model's predictive power and interpretability. In this paper, we present BrainPrompt, an innovative framework that enhances Graph Neural Networks (GNNs) by integrating Large Language Models (LLMs) with knowledge-driven prompts, enabling more effective capture of complex, non-imaging information and external knowledge for neurological disease identification. BrainPrompt integrates three types of knowledge-driven prompts: (1) ROI-level prompts to encode the identity and function of each brain region, (2) subject-level prompts that incorporate demographic information, and (3) disease-level prompts to capture the temporal progression of disease. By leveraging these multi-level prompts, BrainPrompt effectively harnesses knowledge-enhanced multi-modal information from LLMs, enhancing the model's capability to predict neurological disease stages and meanwhile offers more interpretable results. We evaluate BrainPrompt on two resting-state functional Magnetic Resonance Imaging (fMRI) datasets from neurological disorders, showing its superiority over state-of-the-art methods. Additionally, a biomarker study demonstrates the framework's ability to extract valuable and interpretable information aligned with domain knowledge in neuroscience. The code is available at https://github.com/AngusMonroe/BrainPrompt","authors":["Jiaxing Xu","Kai He","Yue Tang","Wei Li","Mengcheng Lan","Xia Dong","Yiping Ke","Mengling Feng"],"url":"https://arxiv.org/abs/2504.16096"}
{"created":"2025-05-20","title":"Boundary value problem of magnetically insulated diode: existence of solutions and complex bifurcation","abstract":"The paper focuses on the stationary self-consistent problem of magnetic insulation for a vacuum diode with space-charge limitation, described by a singularly perturbed Vlasov-Maxwell system of dimension 1.5. The case of insulated diode when the electrons are deflected back towards the cathode at the point $x^{*}$ is considered. First, the initial VM system is reduced to the nonlinear singular limit system of ODEs for the potentials of electric and magnetic fields. The second step deals with the limit system's reduction to the new nonlinear singular ODE equation for effective potential $\\theta(x)$. The existence of non-negative solutions is proved for the last equation on the interval $[0, x^{*})$ where $\\theta(x)>0$. The most interesting and unexplored case is when $\\theta(x)<0$ on the interval $(x^{*}, 1]$ and corresponds to the case of an insulated diode. For the first time, a numerical analysis of complex bifurcation of solutions in insulated diode is considered for $\\theta(x)<0$ depending on parameters and boundary conditions. Bifurcation diagrams of the dependence of solution $\\theta(x)$ on a free point (free boundary) $x^{*}$ were constructed. Insulated diode spacing is found.","authors":["Denis Sidorov","Alexander Sinitsyn","David Leguizamon","Liguo Wang"],"url":"https://arxiv.org/abs/2505.02155"}
{"created":"2025-05-20","title":"ArrayDPS: Unsupervised Blind Speech Separation with a Diffusion Prior","abstract":"Blind Speech Separation (BSS) aims to separate multiple speech sources from audio mixtures recorded by a microphone array. The problem is challenging because it is a blind inverse problem, i.e., the microphone array geometry, the room impulse response (RIR), and the speech sources, are all unknown. We propose ArrayDPS to solve the BSS problem in an unsupervised, array-agnostic, and generative manner. The core idea builds on diffusion posterior sampling (DPS), but unlike DPS where the likelihood is tractable, ArrayDPS must approximate the likelihood by formulating a separate optimization problem. The solution to the optimization approximates room acoustics and the relative transfer functions between microphones. These approximations, along with the diffusion priors, iterate through the ArrayDPS sampling process and ultimately yield separated voice sources. We only need a simple single-speaker speech diffusion model as a prior along with the mixtures recorded at the microphones; no microphone array information is necessary. Evaluation results show that ArrayDPS outperforms all baseline unsupervised methods while being comparable to supervised methods in terms of SDR. Audio demos are provided at: https://arraydps.github.io/ArrayDPSDemo/.","authors":["Zhongweiyang Xu","Xulin Fan","Zhong-Qiu Wang","Xilin Jiang","Romit Roy Choudhury"],"url":"https://arxiv.org/abs/2505.05657"}
{"created":"2025-05-20","title":"When cardinals strategize: An agent-based model of influence and ideology for the papal conclave","abstract":"We propose and analyze two agent-based models to investigate the dynamics of papal conclaves, focusing on how social influence, strategic voting, and ideological alignment affect the time required to elect a pope. In the first model, cardinals interact through two mechanisms: with probability $p$, they imitate the choice of a randomly selected peer, and with probability $q$, they shift support to the most voted candidate from the previous round. Additionally, strategic behavior is introduced via ``useful voting'', where agents abandon their preferred candidate if he receives less than a threshold fraction of the votes, switching instead to the most viable alternative. A candidate must secure a qualified majority of two-thirds to be elected. We then extend the framework by incorporating ideological blocs, assigning each cardinal and candidate to one of two groups (e.g., progressives and conservatives). Cardinals initially vote for candidates from their own group but may cross ideological lines for strategic reasons. We initialize the electorate with $20\\%$ conservative cardinals, reflecting the current composition shaped by papal appointments. Numerical simulations show that ideological polarization tends to delay the election by increasing the number of voting rounds required. However, higher values of strategic responsiveness $q$ can restore efficiency even under polarization. We further validate the model by calibrating parameters to historical data from conclaves held between 1939 and 2025. The model reproduces observed convergence times with good agreement, supporting its explanatory power across institutional contexts. The rapid outcome of the 2025 conclave, despite ideological divisions, suggests the importance of informal consensus-building, possibly prior to voting, as a key mechanism for accelerating convergence.","authors":["Nuno Crokidakis"],"url":"https://arxiv.org/abs/2505.07014"}
{"created":"2025-05-20","title":"Isomorphisms of unit distance graphs of layers","abstract":"For any $\\varepsilon\\in (0,+\\infty)$, consider the metric spaces $\\mathbb{R} \\times [0,\\varepsilon]$ in the Euclidean plane named layers or strips. B. Baslaugh in 1998 found the minimal width $\\varepsilon \\in (0,1)$ of a layer such that its unit distance graph contains a cycle of a given odd length $k$. The first of the main results of this paper is the fact that the unit distance graphs of two layers $\\mathbb{R} \\times [0,\\varepsilon_1], \\mathbb{R} \\times [0,\\varepsilon_2]$ are non-isomorphic for any different values $\\varepsilon_1,\\varepsilon_2 \\in (0,+\\infty)$. We also get a multidimensional analogue of this theorem. For given $n,m \\in \\mathbb{N}, p \\in (1,+\\infty), \\varepsilon \\in (0,+\\infty)$, we say that the metric space on $\\mathbb{R}^n \\times [0,\\varepsilon]^m$ with the metric space distance generated by $l_p$-norm in $\\mathbb{R}^{n+m}$ is a layer $L(n,m,p,\\varepsilon)$. We show that the unit distance graphs of multi-layers $L(n,m,p,\\varepsilon_1), L(n,m,p,\\varepsilon_2)$ are non-isomorphic for $\\varepsilon_1 \\neq \\varepsilon_2$. This result is related to the Beckman-Quarles theorem of 1953 that any unit-preserving mapping of $\\mathbb{R}^n$ is an isometry, and to the rational analogue of this theorem obtained by A. Sokolov in 2023.","authors":["Arthur Igorevich Bikeev"],"url":"https://arxiv.org/abs/2505.07799"}
{"created":"2025-05-20","title":"Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts","abstract":"Ultrasound (US) report generation is a challenging task due to the variability of US images, operator dependence, and the need for standardized text. Unlike X-ray and CT, US imaging lacks consistent datasets, making automation difficult. In this study, we propose a unified framework for multi-organ and multilingual US report generation, integrating fragment-based multilingual training and leveraging the standardized nature of US reports. By aligning modular text fragments with diverse imaging data and curating a bilingual English-Chinese dataset, the method achieves consistent and clinically accurate text generation across organ sites and languages. Fine-tuning with selective unfreezing of the vision transformer (ViT) further improves text-image alignment. Compared to the previous state-of-the-art KMVE method, our approach achieves relative gains of about 2\\% in BLEU scores, approximately 3\\% in ROUGE-L, and about 15\\% in CIDEr, while significantly reducing errors such as missing or incorrect content. By unifying multi-organ and multi-language report generation into a single, scalable framework, this work demonstrates strong potential for real-world clinical workflows.","authors":["Peixuan Ge","Tongkun Su","Faqin Lv","Baoliang Zhao","Peng Zhang","Chi Hong Wong","Liang Yao","Yu Sun","Zenan Wang","Pak Kin Wong","Ying Hu"],"url":"https://arxiv.org/abs/2505.08838"}
