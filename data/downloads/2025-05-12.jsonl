{"created":"2025-05-12","title":"Evolutionary Optimization for the Classification of Small Molecules Regulating the Circadian Rhythm Period: A Reliable Assessment","abstract":"The circadian rhythm plays a crucial role in regulating biological processes, and its disruption is linked to various health issues. Identifying small molecules that influence the circadian period is essential for developing targeted therapies. This study explores the use of evolutionary optimization techniques to enhance the classification of these molecules. We applied an evolutionary algorithm to optimize feature selection and classification performance. Several machine learning classifiers were employed, and performance was evaluated using accuracy and generalization ability. The findings demonstrate that the proposed evolutionary optimization method improves classification accuracy and reduces overfitting compared to baseline models. Additionally, the use of variance in accuracy as a penalty factor may enhance the model's reliability for real-world applications. Our study confirms that evolutionary optimization is an effective strategy for classifying small molecules regulating the circadian rhythm. The proposed approach not only improves predictive performance but also ensures a more robust model.","authors":["Antonio Arauzo-Azofra","Jose Molina-Baena","Maria Luque-Rodriguez"],"url":"https://arxiv.org/abs/2505.05485"}
{"created":"2025-05-12","title":"FedAvgen: Metadata for Model Aggregation In Communication Systems","abstract":"To improve business efficiency and minimize costs, Artificial Intelligence (AI) practitioners have adopted a shift from formulating models from scratch towards sharing pretrained models. The pretrained models are then aggregated into a global model with higher generalization capabilities, which is afterwards distributed to the client devices. This approach is known as federated learning and inherently utilizes different techniques to select the candidate client models averaged to obtain the global model. This approach, in the case of communication systems, faces challenges arising from the existential diversity in device profiles. The multiplicity in profiles motivates our conceptual assessment of a metaheuristic algorithm (FedAvgen), which relates each pretrained model with its weight space as metadata, to a phenotype and genotype, respectively. This parent-child genetic evolution characterizes the global averaging step in federated learning. We then compare the results of our approach to two widely adopted baseline federated learning algorithms like Federated Averaging (FedAvg) and Federated Stochastic Gradient Descent (FedSGD).","authors":["Anthony Kiggundu","Dennis Krummacker","Hans D. Schotten"],"url":"https://arxiv.org/abs/2505.05486"}
{"created":"2025-05-12","title":"Data extraction and processing methods to aid the study of driving behaviors at intersections in naturalistic driving","abstract":"Naturalistic driving studies use devices in participants' own vehicles to record daily driving over many months. Due to diverse and extensive amounts of data recorded, automated processing is necessary. This report describes methods to extract and characterize driver head scans at intersections from data collected from an in-car recording system that logged vehicle speed, GPS location, scene videos, and cabin videos. Custom tools were developed to mark the intersections, synchronize location and video data, and clip the cabin and scene videos for +/-100 meters from the intersection location. A custom-developed head pose detection AI model for wide angle head turns was run on the cabin videos to estimate the driver head pose, from which head scans >20 deg were computed in the horizontal direction. The scene videos were processed using a YOLO object detection model to detect traffic lights, stop signs, pedestrians, and other vehicles on the road. Turning maneuvers were independently detected using vehicle self-motion patterns. Stop lines on the road surface were detected using changing intensity patterns over time as the vehicle moved. The information obtained from processing the scene videos, along with the speed data was used in a rule-based algorithm to infer the intersection type, maneuver, and bounds. We processed 190 intersections from 3 vehicles driven in cities and suburban areas from Massachusetts and California. The automated video processing algorithm correctly detected intersection signage and maneuvers in 100% and 94% of instances, respectively. The median [IQR] error in detecting vehicle entry into the intersection was 1.1[0.4-4.9] meters and 0.2[0.1-0.54] seconds. The median overlap between ground truth and estimated intersection bounds was 0.88[0.82-0.93].","authors":["Shrinivas Pundlik","Seonggyu Choe","Patrick Baker","Chen-Yuan Lee","Naser Al-Madi","Alex R. Bowers","Gang Luo"],"url":"https://arxiv.org/abs/2505.05487"}
{"created":"2025-05-12","title":"From Events to Enhancement: A Survey on Event-Based Imaging Technologies","abstract":"Event cameras offering high dynamic range and low latency have emerged as disruptive technologies in imaging. Despite growing research on leveraging these benefits for different imaging tasks, a comprehensive study of recently advances and challenges are still lacking. This limits the broader understanding of how to utilize events in universal imaging applications. In this survey, we first introduce a physical model and the characteristics of different event sensors as the foundation. Following this, we highlight the advancement and interaction of image/video enhancement tasks with events. Additionally, we explore advanced tasks, which capture richer light information with events, \\eg~light field estimation, multi-view generation, and photometric. Finally, we discuss new challenges and open questions offering a perspective for this rapidly evolving field. More continuously updated resources are at this link: https://github.com/yunfanLu/Awesome-Event-Imaging","authors":["Yunfan Lu","Xiaogang Xu","Pengteng Li","Yusheng Wang","Yi Cui","Huizai Yao","Hui Xiong"],"url":"https://arxiv.org/abs/2505.05488"}
{"created":"2025-05-12","title":"Akkumula: Evidence accumulation driver models with Spiking Neural Networks","abstract":"Processes of evidence accumulation for motor control contribute to the ecological validity of driver models. According to established theories of cognition, drivers make control adjustments when a process of accumulation of perceptual inputs reaches a decision boundary. Unfortunately, there is not a standard way for building such models, limiting their use. Current implementations are hand-crafted, lack adaptability, and rely on inefficient optimization techniques that do not scale well with large datasets. This paper introduces Akkumula, an evidence accumulation modelling framework built using deep learning techniques to leverage established coding libraries, gradient optimization, and large batch training. The core of the library is based on Spiking Neural Networks, whose operation mimic the evidence accumulation process in the biological brain. The model was tested on data collected during a test-track experiment. Results are promising. The model fits well the time course of vehicle control (brake, accelerate, steering) based on vehicle sensor data. The perceptual inputs are extracted by a dedicated neural network, increasing the context-awareness of the model in dynamic scenarios. Akkumula integrates with existing machine learning architectures, benefits from continuous advancements in deep learning, efficiently processes large datasets, adapts to diverse driving scenarios, and maintains a degree of transparency in its core mechanisms.","authors":["Alberto Morando"],"url":"https://arxiv.org/abs/2505.05489"}
{"created":"2025-05-12","title":"MDDFNet: Mamba-based Dynamic Dual Fusion Network for Traffic Sign Detection","abstract":"The Detection of small objects, especially traffic signs, is a critical sub-task in object detection and autonomous driving. Despite signficant progress in previous research, two main challenges remain. First, the issue of feature extraction being too singular. Second, the detection process struggles to efectively handle objects of varying sizes or scales. These problems are also prevalent in general object detection tasks. To address these challenges, we propose a novel object detection network, Mamba-based Dynamic Dual Fusion Network (MDDFNet), for traffic sign detection. The network integrates a dynamic dual fusion module and a Mamba-based backbone to simultaneously tackle the aforementioned issues. Specifically, the dynamic dual fusion module utilizes multiple branches to consolidate various spatial and semantic information, thus enhancing feature diversity. The Mamba-based backbone leverages global feature fusion and local feature interaction, combining features in an adaptive manner to generate unique classification characteristics. Extensive experiments conducted on the TT100K (Tsinghua-Tencent 100K) datasets demonstrate that MDDFNet outperforms other state-of-the-art detectors, maintaining real-time processing capabilities of single-stage models while achieving superior performance. This confirms the efectiveness of MDDFNet in detecting small traffic signs.","authors":["TianYi Yu"],"url":"https://arxiv.org/abs/2505.05491"}
{"created":"2025-05-12","title":"DetoxAI: a Python Toolkit for Debiasing Deep Learning Models in Computer Vision","abstract":"While machine learning fairness has made significant progress in recent years, most existing solutions focus on tabular data and are poorly suited for vision-based classification tasks, which rely heavily on deep learning. To bridge this gap, we introduce DetoxAI, an open-source Python library for improving fairness in deep learning vision classifiers through post-hoc debiasing. DetoxAI implements state-of-the-art debiasing algorithms, fairness metrics, and visualization tools. It supports debiasing via interventions in internal representations and includes attribution-based visualization tools and quantitative algorithmic fairness metrics to show how bias is mitigated. This paper presents the motivation, design, and use cases of DetoxAI, demonstrating its tangible value to engineers and researchers.","authors":["Ignacy St\\k{e}pka","Lukasz Sztukiewicz","Micha{\\l} Wili\\'nski","Jerzy Stefanowski"],"url":"https://arxiv.org/abs/2505.05492"}
{"created":"2025-05-12","title":"An Automated LLM-based Pipeline for Asset-Level Database Creation to Assess Deforestation Impact","abstract":"The European Union Deforestation Regulation (EUDR) requires companies to prove their products do not contribute to deforestation, creating a critical demand for precise, asset-level environmental impact data. Current databases lack the necessary detail, relying heavily on broad financial metrics and manual data collection, which limits regulatory compliance and accurate environmental modeling. This study presents an automated, end-to-end data extraction pipeline that uses LLMs to create, clean, and validate structured databases, specifically targeting sectors with a high risk of deforestation. The pipeline introduces Instructional, Role-Based, Zero-Shot Chain-of-Thought (IRZ-CoT) prompting to enhance data extraction accuracy and a Retrieval-Augmented Validation (RAV) process that integrates real-time web searches for improved data reliability. Applied to SEC EDGAR filings in the Mining, Oil & Gas, and Utilities sectors, the pipeline demonstrates significant improvements over traditional zero-shot prompting approaches, particularly in extraction accuracy and validation coverage. This work advances NLP-driven automation for regulatory compliance, CSR (Corporate Social Responsibility), and ESG, with broad sectoral applicability.","authors":["Avanija Menon","Ovidiu Serban"],"url":"https://arxiv.org/abs/2505.05494"}
{"created":"2025-05-12","title":"Learning 3D Persistent Embodied World Models","abstract":"The ability to simulate the effects of future actions on the world is a crucial ability of intelligent embodied agents, enabling agents to anticipate the effects of their actions and make plans accordingly. While a large body of existing work has explored how to construct such world models using video models, they are often myopic in nature, without any memory of a scene not captured by currently observed images, preventing agents from making consistent long-horizon plans in complex environments where many parts of the scene are partially observed. We introduce a new persistent embodied world model with an explicit memory of previously generated content, enabling much more consistent long-horizon simulation. During generation time, our video diffusion model predicts RGB-D video of the future observations of the agent. This generation is then aggregated into a persistent 3D map of the environment. By conditioning the video model on this 3D spatial map, we illustrate how this enables video world models to faithfully simulate both seen and unseen parts of the world. Finally, we illustrate the efficacy of such a world model in downstream embodied applications, enabling effective planning and policy learning.","authors":["Siyuan Zhou","Yilun Du","Yuncong Yang","Lei Han","Peihao Chen","Dit-Yan Yeung","Chuang Gan"],"url":"https://arxiv.org/abs/2505.05495"}
{"created":"2025-05-12","title":"An Overview of the Prospects and Challenges of Using Artificial Intelligence for Energy Management Systems in Microgrids","abstract":"Microgrids have emerged as a pivotal solution in the quest for a sustainable and energy-efficient future. While microgrids offer numerous advantages, they are also prone to issues related to reliably forecasting renewable energy demand and production, protecting against cyberattacks, controlling operational costs, optimizing power flow, and regulating the performance of energy management systems (EMS). Tackling these energy management challenges is essential to facilitate microgrid applications and seamlessly incorporate renewable energy resources. Artificial intelligence (AI) has recently demonstrated immense potential for optimizing energy management in microgrids, providing efficient and reliable solutions. This paper highlights the combined benefits of enabling AI-based methodologies in the energy management systems of microgrids by examining the applicability and efficiency of AI-based EMS in achieving specific technical and economic objectives. The paper also points out several future research directions that promise to spearhead AI-driven EMS, namely the development of self-healing microgrids, integration with blockchain technology, use of Internet of things (IoT), and addressing interpretability, data privacy, scalability, and the prospects to generative AI in the context of future AI-based EMS.","authors":["Noor ul Misbah Khanum","Hayssam Dahrouj","Ramesh C. Bansal","Hissam Mouayad Tawfik"],"url":"https://arxiv.org/abs/2505.05498"}
{"created":"2025-05-12","title":"Preliminary Explorations with GPT-4o(mni) Native Image Generation","abstract":"Recently, the visual generation ability by GPT-4o(mni) has been unlocked by OpenAI. It demonstrates a very remarkable generation capability with excellent multimodal condition understanding and varied task instructions. In this paper, we aim to explore the capabilities of GPT-4o across various tasks. Inspired by previous study, we constructed a task taxonomy along with a carefully curated set of test samples to conduct a comprehensive qualitative test. Benefiting from GPT-4o's powerful multimodal comprehension, its image-generation process demonstrates abilities surpassing those of traditional image-generation tasks. Thus, regarding the dimensions of model capabilities, we evaluate its performance across six task categories: traditional image generation tasks, discriminative tasks, knowledge-based generation, commonsense-based generation, spatially-aware image generation, and temporally-aware image generation. These tasks not only assess the quality and conditional alignment of the model's outputs but also probe deeper into GPT-4o's understanding of real-world concepts. Our results reveal that GPT-4o performs impressively well in general-purpose synthesis tasks, showing strong capabilities in text-to-image generation, visual stylization, and low-level image processing. However, significant limitations remain in its ability to perform precise spatial reasoning, instruction-grounded generation, and consistent temporal prediction. Furthermore, when faced with knowledge-intensive or domain-specific scenarios, such as scientific illustrations or mathematical plots, the model often exhibits hallucinations, factual errors, or structural inconsistencies. These findings suggest that while GPT-4o marks a substantial advancement in unified multimodal generation, there is still a long way to go before it can be reliably applied to professional or safety-critical domains.","authors":["Pu Cao","Feng Zhou","Junyi Ji","Qingye Kong","Zhixiang Lv","Mingjian Zhang","Xuekun Zhao","Siqi Wu","Yinghui Lin","Qing Song","Lu Yang"],"url":"https://arxiv.org/abs/2505.05501"}
{"created":"2025-05-12","title":"Apply Hierarchical-Chain-of-Generation to Complex Attributes Text-to-3D Generation","abstract":"Recent text-to-3D models can render high-quality assets, yet they still stumble on objects with complex attributes. The key obstacles are: (1) existing text-to-3D approaches typically lift text-to-image models to extract semantics via text encoders, while the text encoder exhibits limited comprehension ability for long descriptions, leading to deviated cross-attention focus, subsequently wrong attribute binding in generated results. (2) Occluded object parts demand a disciplined generation order and explicit part disentanglement. Though some works introduce manual efforts to alleviate the above issues, their quality is unstable and highly reliant on manual information. To tackle above problems, we propose a automated method Hierarchical-Chain-of-Generation (HCoG). It leverages a large language model to decompose the long description into blocks representing different object parts, and orders them from inside out according to occlusions, forming a hierarchical chain. Within each block we first coarsely create components, then precisely bind attributes via target-region localization and corresponding 3D Gaussian kernel optimization. Between blocks, we introduce Gaussian Extension and Label Elimination to seamlessly generate new parts by extending new Gaussian kernels, re-assigning semantic labels, and eliminating unnecessary kernels, ensuring that only relevant parts are added without disrupting previously optimized parts. Experiments confirm that HCoG yields structurally coherent, attribute-faithful 3D objects with complex attributes. The code is available at https://github.com/Wakals/GASCOL .","authors":["Yiming Qin","Zhu Xu","Yang Liu"],"url":"https://arxiv.org/abs/2505.05505"}
{"created":"2025-05-12","title":"Silicon Sovereigns: Artificial Intelligence, International Law, and the Tech-Industrial Complex","abstract":"Artificial intelligence is reshaping science, society, and power. Yet many debates over its likely impact remain fixated on extremes: utopian visions of universal benefit and dystopian fears of existential doom, or an arms race between the U.S. and China, or the Global North and Global South. What's missing is a serious conversation about distribution - who gains, who loses, and who decides. The global AI landscape is increasingly defined not just by geopolitical divides, but by the deepening imbalance between public governance and private control. As governments struggle to keep up, power is consolidating in the hands of a few tech firms whose influence now rivals that of states. If the twentieth century saw the rise of international institutions, the twenty-first may be witnessing their eclipse - replaced not by a new world order, but by a digital oligarchy. This essay explores what that shift means for international law, global equity, and the future of democratic oversight in an age of silicon sovereignty.","authors":["Simon Chesterman"],"url":"https://arxiv.org/abs/2505.05506"}
{"created":"2025-05-12","title":"VIMPPI: Enhancing Model Predictive Path Integral Control with Variational Integration for Underactuated Systems","abstract":"This paper presents VIMPPI, a novel control approach for underactuated double pendulum systems developed for the AI Olympics competition. We enhance the Model Predictive Path Integral framework by incorporating variational integration techniques, enabling longer planning horizons without additional computational cost. Operating at 500-700 Hz with control interpolation and disturbance detection mechanisms, VIMPPI substantially outperforms both baseline methods and alternative MPPI implementations","authors":["Igor Alentev","Lev Kozlov","Ivan Domrachev","Simeon Nedelchev"],"url":"https://arxiv.org/abs/2505.05507"}
{"created":"2025-05-12","title":"How to Train Your Metamorphic Deep Neural Network","abstract":"Neural Metamorphosis (NeuMeta) is a recent paradigm for generating neural networks of varying width and depth. Based on Implicit Neural Representation (INR), NeuMeta learns a continuous weight manifold, enabling the direct generation of compressed models, including those with configurations not seen during training. While promising, the original formulation of NeuMeta proves effective only for the final layers of the undelying model, limiting its broader applicability. In this work, we propose a training algorithm that extends the capabilities of NeuMeta to enable full-network metamorphosis with minimal accuracy degradation. Our approach follows a structured recipe comprising block-wise incremental training, INR initialization, and strategies for replacing batch normalization. The resulting metamorphic networks maintain competitive accuracy across a wide range of compression ratios, offering a scalable solution for adaptable and efficient deployment of deep models. The code is available at: https://github.com/TSommariva/HTTY_NeuMeta.","authors":["Thomas Sommariva","Simone Calderara","Angelo Porrello"],"url":"https://arxiv.org/abs/2505.05510"}
{"created":"2025-05-12","title":"Economic Analysis and Optimization of Energy Storage Configuration for Park Power Systems Based on Random Forest and Genetic Algorithm","abstract":"This study aims to analyze the economic performance of various parks under different conditions, particularly focusing on the operational costs and power load balancing before and after the deployment of energy storage systems. Firstly, the economic performance of the parks without energy storage was analyzed using a random forest model. Taking Park A as an example, it was found that the cost had the greatest correlation with electricity purchase, followed by photovoltaic output, indicating that solar and wind power output are key factors affecting economic performance. Subsequently, the operation of the parks after the configuration of a 50kW/100kWh energy storage system was simulated, and the total cost and operation strategy of the energy storage system were calculated. The results showed that after the deployment of energy storage, the amount of wind and solar power curtailment in each park decreased, and the operational costs were reduced. Finally, a genetic algorithm was used to optimize the energy storage configuration of each park. The energy storage operation strategy was optimized through fitness functions, crossover operations, and mutation operations. After optimization, the economic indicators of Parks A, B, and C all improved. The research results indicate that by optimizing energy storage configuration, each park can reduce costs, enhance economic benefits, and achieve sustainable development of the power system.","authors":["Yanghui Song","Aoqi Li","Lilei Huo"],"url":"https://arxiv.org/abs/2505.05511"}
{"created":"2025-05-12","title":"Occupancy World Model for Robots","abstract":"Understanding and forecasting the scene evolutions deeply affect the exploration and decision of embodied agents. While traditional methods simulate scene evolutions through trajectory prediction of potential instances, current works use the occupancy world model as a generative framework for describing fine-grained overall scene dynamics. However, existing methods cluster on the outdoor structured road scenes, while ignoring the exploration of forecasting 3D occupancy scene evolutions for robots in indoor scenes. In this work, we explore a new framework for learning the scene evolutions of observed fine-grained occupancy and propose an occupancy world model based on the combined spatio-temporal receptive field and guided autoregressive transformer to forecast the scene evolutions, called RoboOccWorld. We propose the Conditional Causal State Attention (CCSA), which utilizes camera poses of next state as conditions to guide the autoregressive transformer to adapt and understand the indoor robotics scenarios. In order to effectively exploit the spatio-temporal cues from historical observations, Hybrid Spatio-Temporal Aggregation (HSTA) is proposed to obtain the combined spatio-temporal receptive field based on multi-scale spatio-temporal windows. In addition, we restructure the OccWorld-ScanNet benchmark based on local annotations to facilitate the evaluation of the indoor 3D occupancy scene evolution prediction task. Experimental results demonstrate that our RoboOccWorld outperforms state-of-the-art methods in indoor 3D occupancy scene evolution prediction task. The code will be released soon.","authors":["Zhang Zhang","Qiang Zhang","Wei Cui","Shuai Shi","Yijie Guo","Gang Han","Wen Zhao","Jingkai Sun","Jiahang Cao","Jiaxu Wang","Hao Cheng","Xiaozhu Ju","Zhengping Che","Renjing Xu","Jian Tang"],"url":"https://arxiv.org/abs/2505.05512"}
{"created":"2025-05-12","title":"Exploring Convolutional Neural Networks for Rice Grain Classification: An Explainable AI Approach","abstract":"Rice is an essential staple food worldwide that is important in promoting international trade, economic growth, and nutrition. Asian countries such as China, India, Pakistan, Thailand, Vietnam, and Indonesia are notable for their significant contribution to the cultivation and utilization of rice. These nations are also known for cultivating different rice grains, including short and long grains. These sizes are further classified as basmati, jasmine, kainat saila, ipsala, arborio, etc., catering to diverse culinary preferences and cultural traditions. For both local and international trade, inspecting and maintaining the quality of rice grains to satisfy customers and preserve a country's reputation is necessary. Manual quality check and classification is quite a laborious and time-consuming process. It is also highly prone to mistakes. Therefore, an automatic solution must be proposed for the effective and efficient classification of different varieties of rice grains. This research paper presents an automatic framework based on a convolutional neural network (CNN) for classifying different varieties of rice grains. We evaluated the proposed model based on performance metrics such as accuracy, recall, precision, and F1-Score. The CNN model underwent rigorous training and validation, achieving a remarkable accuracy rate and a perfect area under each class's Receiver Operating Characteristic (ROC) curve. The confusion matrix analysis confirmed the model's effectiveness in distinguishing between the different rice varieties, indicating minimal misclassifications. Additionally, the integration of explainability techniques such as LIME (Local Interpretable Model-agnostic Explanations) and SHAP (SHapley Additive exPlanations) provided valuable insights into the model's decision-making process, revealing how specific features of the rice grains influenced classification outcomes.","authors":["Muhammad Junaid Asif","Hamza Khan","Rabia Tehseen","Syed Tahir Hussain Rizvi","Mujtaba Asad","Shazia Saqib","Rana Fayyaz Ahmad"],"url":"https://arxiv.org/abs/2505.05513"}
{"created":"2025-05-12","title":"Web2Grasp: Learning Functional Grasps from Web Images of Hand-Object Interactions","abstract":"Functional grasp is essential for enabling dexterous multi-finger robot hands to manipulate objects effectively. However, most prior work either focuses on power grasping, which simply involves holding an object still, or relies on costly teleoperated robot demonstrations to teach robots how to grasp each object functionally. Instead, we propose extracting human grasp information from web images since they depict natural and functional object interactions, thereby bypassing the need for curated demonstrations. We reconstruct human hand-object interaction (HOI) 3D meshes from RGB images, retarget the human hand to multi-finger robot hands, and align the noisy object mesh with its accurate 3D shape. We show that these relatively low-quality HOI data from inexpensive web sources can effectively train a functional grasping model. To further expand the grasp dataset for seen and unseen objects, we use the initially-trained grasping policy with web data in the IsaacGym simulator to generate physically feasible grasps while preserving functionality. We train the grasping model on 10 object categories and evaluate it on 9 unseen objects, including challenging items such as syringes, pens, spray bottles, and tongs, which are underrepresented in existing datasets. The model trained on the web HOI dataset, achieving a 75.8% success rate on seen objects and 61.8% across all objects in simulation, with a 6.7% improvement in success rate and a 1.8x increase in functionality ratings over baselines. Simulator-augmented data further boosts performance from 61.8% to 83.4%. The sim-to-real transfer to the LEAP Hand achieves a 85% success rate. Project website is at: https://webgrasp.github.io/.","authors":["Hongyi Chen","Yunchao Yao","Yufei Ye","Zhixuan Xu","Homanga Bharadhwaj","Jiashun Wang","Shubham Tulsiani","Zackory Erickson","Jeffrey Ichnowski"],"url":"https://arxiv.org/abs/2505.05517"}
{"created":"2025-05-12","title":"Real-Time Privacy Preservation for Robot Visual Perception","abstract":"Many robots (e.g., iRobot's Roomba) operate based on visual observations from live video streams, and such observations may inadvertently include privacy-sensitive objects, such as personal identifiers. Existing approaches for preserving privacy rely on deep learning models, differential privacy, or cryptography. They lack guarantees for the complete concealment of all sensitive objects. Guaranteeing concealment requires post-processing techniques and thus is inadequate for real-time video streams. We develop a method for privacy-constrained video streaming, PCVS, that conceals sensitive objects within real-time video streams. PCVS takes a logical specification constraining the existence of privacy-sensitive objects, e.g., never show faces when a person exists. It uses a detection model to evaluate the existence of these objects in each incoming frame. Then, it blurs out a subset of objects such that the existence of the remaining objects satisfies the specification. We then propose a conformal prediction approach to (i) establish a theoretical lower bound on the probability of the existence of these objects in a sequence of frames satisfying the specification and (ii) update the bound with the arrival of each subsequent frame. Quantitative evaluations show that PCVS achieves over 95 percent specification satisfaction rate in multiple datasets, significantly outperforming other methods. The satisfaction rate is consistently above the theoretical bounds across all datasets, indicating that the established bounds hold. Additionally, we deploy PCVS on robots in real-time operation and show that the robots operate normally without being compromised when PCVS conceals objects.","authors":["Minkyu Choi","Yunhao Yang","Neel P. Bhatt","Kushagra Gupta","Sahil Shah","Aditya Rai","David Fridovich-Keil","Ufuk Topcu","Sandeep P. Chinchali"],"url":"https://arxiv.org/abs/2505.05519"}
{"created":"2025-05-12","title":"GaMNet: A Hybrid Network with Gabor Fusion and NMamba for Efficient 3D Glioma Segmentation","abstract":"Gliomas are aggressive brain tumors that pose serious health risks. Deep learning aids in lesion segmentation, but CNN and Transformer-based models often lack context modeling or demand heavy computation, limiting real-time use on mobile medical devices. We propose GaMNet, integrating the NMamba module for global modeling and a multi-scale CNN for efficient local feature extraction. To improve interpretability and mimic the human visual system, we apply Gabor filters at multiple scales. Our method achieves high segmentation accuracy with fewer parameters and faster computation. Extensive experiments show GaMNet outperforms existing methods, notably reducing false positives and negatives, which enhances the reliability of clinical diagnosis.","authors":["Chengwei Ye","Huanzhen Zhang","Yufei Lin","Kangsheng Wang","Linuo Xu","Shuyan Liu"],"url":"https://arxiv.org/abs/2505.05520"}
{"created":"2025-05-12","title":"Model-Based Closed-Loop Control Algorithm for Stochastic Partial Differential Equation Control","abstract":"Neural operators have demonstrated promise in modeling and controlling systems governed by Partial Differential Equations (PDEs). Beyond PDEs, Stochastic Partial Differential Equations (SPDEs) play a critical role in modeling systems influenced by randomness, with applications in finance, physics, and beyond. However, controlling SPDE-governed systems remains a significant challenge. On the one hand, the regularity of the system's state (which can be intuitively understood as smoothness) deteriorates, making modeling and generalization more challenging. On the other hand, this stochasticity also renders control more unstable and thus less accurate. To address this gap, we propose the Model-Based Closed-Loop Control Algorithm (MB-CC), the first model-based closed-loop control method for SPDEs. MB-CC introduces two key innovations to enhance control robustness and efficiency: a Regularity Feature (RF) block and a closed-loop strategy with an operator-encoded policy network. The RF block, inspired by the regularity structure theory of SPDEs, addresses noise-induced irregularities by transforming the network's input, including the system state and noise-perturbed external forces, into a refined feature space for improved forward prediction. Compared to previous works using regularity features, we introduce a new parameterization, data augmentation, and extend the RF block as a plug-and-play component. Additionally, to achieve closed-loop control, we introduce an operator-encoded policy network to map the current state to optimal control, which integrates physical priors and swiftly makes decisions based on states returned by the environment. We conduct a systematic evaluation of MB-CC on two notable SPDEs, showcasing its effectiveness and efficiency. The ablation studies show its ability to handle stochasticity more effectively.","authors":["Peiyan Hu","Haodonog Feng","Yue Wang","Zhiming Ma"],"url":"https://arxiv.org/abs/2505.05521"}
{"created":"2025-05-12","title":"Continuous Thought Machines","abstract":"Biological brains demonstrate complex neural activity, where the timing and interplay between neurons is critical to how brains process information. Most deep learning architectures simplify neural activity by abstracting away temporal dynamics. In this paper we challenge that paradigm. By incorporating neuron-level processing and synchronization, we can effectively reintroduce neural timing as a foundational element. We present the Continuous Thought Machine (CTM), a model designed to leverage neural dynamics as its core representation. The CTM has two core innovations: (1) neuron-level temporal processing, where each neuron uses unique weight parameters to process a history of incoming signals; and (2) neural synchronization employed as a latent representation. The CTM aims to strike a balance between oversimplified neuron abstractions that improve computational efficiency, and biological realism. It operates at a level of abstraction that effectively captures essential temporal dynamics while remaining computationally tractable for deep learning. We demonstrate the CTM's strong performance and versatility across a range of challenging tasks, including ImageNet-1K classification, solving 2D mazes, sorting, parity computation, question-answering, and RL tasks. Beyond displaying rich internal representations and offering a natural avenue for interpretation owing to its internal process, the CTM is able to perform tasks that require complex sequential reasoning. The CTM can also leverage adaptive compute, where it can stop earlier for simpler tasks, or keep computing when faced with more challenging instances. The goal of this work is to share the CTM and its associated innovations, rather than pushing for new state-of-the-art results. To that end, we believe the CTM represents a significant step toward developing more biologically plausible and powerful artificial intelligence systems.","authors":["Luke Darlow","Ciaran Regan","Sebastian Risi","Jeffrey Seely","Llion Jones"],"url":"https://arxiv.org/abs/2505.05522"}
{"created":"2025-05-12","title":"A critical assessment of reinforcement learning methods for microswimmer navigation in complex flows","abstract":"Navigating in a fluid flow while being carried by it, using only information accessible from on-board sensors, is a problem commonly faced by small planktonic organisms. It is also directly relevant to autonomous robots deployed in the oceans. In the last ten years, the fluid mechanics community has widely adopted reinforcement learning, often in the form of its simplest implementations, to address this challenge. But it is unclear how good are the strategies learned by these algorithms. In this paper, we perform a quantitative assessment of reinforcement learning methods applied to navigation in partially observable flows. We first introduce a well-posed problem of directional navigation for which a quasi-optimal policy is known analytically. We then report on the poor performance and robustness of commonly used algorithms (Q-Learning, Advantage Actor Critic) in flows regularly encountered in the literature: Taylor-Green vortices, Arnold-Beltrami-Childress flow, and two-dimensional turbulence. We show that they are vastly surpassed by PPO (Proximal Policy Optimization), a more advanced algorithm that has established dominance across a wide range of benchmarks in the reinforcement learning community. In particular, our custom implementation of PPO matches the theoretical quasi-optimal performance in turbulent flow and does so in a robust manner. Reaching this result required the use of several additional techniques, such as vectorized environments and generalized advantage estimation, as well as hyperparameter optimization. This study demonstrates the importance of algorithm selection, implementation details, and fine-tuning for discovering truly smart autonomous navigation strategies in complex flows.","authors":["Selim Mecanna","Aurore Loisy","Christophe Eloy"],"url":"https://arxiv.org/abs/2505.05525"}
{"created":"2025-05-12","title":"ADMM-Based Training for Spiking Neural Networks","abstract":"In recent years, spiking neural networks (SNNs) have gained momentum due to their high potential in time-series processing combined with minimal energy consumption. However, they still lack a dedicated and efficient training algorithm. The popular backpropagation with surrogate gradients, adapted from stochastic gradient descent (SGD)-derived algorithms, has several drawbacks when used as an optimizer for SNNs. Specifically, it suffers from low scalability and numerical imprecision. In this paper, we propose a novel SNN training method based on the alternating direction method of multipliers (ADMM). Our ADMM-based training aims to solve the problem of the SNN step function's non-differentiability. We formulate the problem, derive closed-form updates, and empirically show the optimizer's convergence properties, great potential, and possible new research directions to improve the method in a simulated proof-of-concept.","authors":["Giovanni Perin","Cesare Bidini","Riccardo Mazzieri","Michele Rossi"],"url":"https://arxiv.org/abs/2505.05527"}
{"created":"2025-05-12","title":"X-Transfer Attacks: Towards Super Transferable Adversarial Attacks on CLIP","abstract":"As Contrastive Language-Image Pre-training (CLIP) models are increasingly adopted for diverse downstream tasks and integrated into large vision-language models (VLMs), their susceptibility to adversarial perturbations has emerged as a critical concern. In this work, we introduce \\textbf{X-Transfer}, a novel attack method that exposes a universal adversarial vulnerability in CLIP. X-Transfer generates a Universal Adversarial Perturbation (UAP) capable of deceiving various CLIP encoders and downstream VLMs across different samples, tasks, and domains. We refer to this property as \\textbf{super transferability}--a single perturbation achieving cross-data, cross-domain, cross-model, and cross-task adversarial transferability simultaneously. This is achieved through \\textbf{surrogate scaling}, a key innovation of our approach. Unlike existing methods that rely on fixed surrogate models, which are computationally intensive to scale, X-Transfer employs an efficient surrogate scaling strategy that dynamically selects a small subset of suitable surrogates from a large search space. Extensive evaluations demonstrate that X-Transfer significantly outperforms previous state-of-the-art UAP methods, establishing a new benchmark for adversarial transferability across CLIP models. The code is publicly available in our \\href{https://github.com/HanxunH/XTransferBench}{GitHub repository}.","authors":["Hanxun Huang","Sarah Erfani","Yige Li","Xingjun Ma","James Bailey"],"url":"https://arxiv.org/abs/2505.05528"}
{"created":"2025-05-12","title":"Low-bit Model Quantization for Deep Neural Networks: A Survey","abstract":"With unprecedented rapid development, deep neural networks (DNNs) have deeply influenced almost all fields. However, their heavy computation costs and model sizes are usually unacceptable in real-world deployment. Model quantization, an effective weight-lighting technique, has become an indispensable procedure in the whole deployment pipeline. The essence of quantization acceleration is the conversion from continuous floating-point numbers to discrete integer ones, which significantly speeds up the memory I/O and calculation, i.e., addition and multiplication. However, performance degradation also comes with the conversion because of the loss of precision. Therefore, it has become increasingly popular and critical to investigate how to perform the conversion and how to compensate for the information loss. This article surveys the recent five-year progress towards low-bit quantization on DNNs. We discuss and compare the state-of-the-art quantization methods and classify them into 8 main categories and 24 sub-categories according to their core techniques. Furthermore, we shed light on the potential research opportunities in the field of model quantization. A curated list of model quantization is provided at https://github.com/Kai-Liu001/Awesome-Model-Quantization.","authors":["Kai Liu","Qian Zheng","Kaiwen Tao","Zhiteng Li","Haotong Qin","Wenbo Li","Yong Guo","Xianglong Liu","Linghe Kong","Guihai Chen","Yulun Zhang","Xiaokang Yang"],"url":"https://arxiv.org/abs/2505.05530"}
{"created":"2025-05-12","title":"OXSeg: Multidimensional attention UNet-based lip segmentation using semi-supervised lip contours","abstract":"Lip segmentation plays a crucial role in various domains, such as lip synchronization, lipreading, and diagnostics. However, the effectiveness of supervised lip segmentation is constrained by the availability of lip contour in the training phase. A further challenge with lip segmentation is its reliance on image quality , lighting, and skin tone, leading to inaccuracies in the detected boundaries. To address these challenges, we propose a sequential lip segmentation method that integrates attention UNet and multidimensional input. We unravel the micro-patterns in facial images using local binary patterns to build multidimensional inputs. Subsequently, the multidimensional inputs are fed into sequential attention UNets, where the lip contour is reconstructed. We introduce a mask generation method that uses a few anatomical landmarks and estimates the complete lip contour to improve segmentation accuracy. This mask has been utilized in the training phase for lip segmentation. To evaluate the proposed method, we use facial images to segment the upper lips and subsequently assess lip-related facial anomalies in subjects with fetal alcohol syndrome (FAS). Using the proposed lip segmentation method, we achieved a mean dice score of 84.75%, and a mean pixel accuracy of 99.77% in upper lip segmentation. To further evaluate the method, we implemented classifiers to identify those with FAS. Using a generative adversarial network (GAN), we reached an accuracy of 98.55% in identifying FAS in one of the study populations. This method could be used to improve lip segmentation accuracy, especially around Cupid's bow, and shed light on distinct lip-related characteristics of FAS.","authors":["Hanie Moghaddasi","Christina Chambers","Sarah N. Mattson","Jeffrey R. Wozniak","Claire D. Coles","Raja Mukherjee","Michael Suttie"],"url":"https://arxiv.org/abs/2505.05531"}
{"created":"2025-05-12","title":"Rethinking Graph Contrastive Learning through Relative Similarity Preservation","abstract":"Graph contrastive learning (GCL) has achieved remarkable success by following the computer vision paradigm of preserving absolute similarity between augmented views. However, this approach faces fundamental challenges in graphs due to their discrete, non-Euclidean nature -- view generation often breaks semantic validity and similarity verification becomes unreliable. Through analyzing 11 real-world graphs, we discover a universal pattern transcending the homophily-heterophily dichotomy: label consistency systematically diminishes as structural distance increases, manifesting as smooth decay in homophily graphs and oscillatory decay in heterophily graphs. We establish theoretical guarantees for this pattern through random walk theory, proving label distribution convergence and characterizing the mechanisms behind different decay behaviors. This discovery reveals that graphs naturally encode relative similarity patterns, where structurally closer nodes exhibit collectively stronger semantic relationships. Leveraging this insight, we propose RELGCL, a novel GCL framework with complementary pairwise and listwise implementations that preserve these inherent patterns through collective similarity objectives. Extensive experiments demonstrate that our method consistently outperforms 20 existing approaches across both homophily and heterophily graphs, validating the effectiveness of leveraging natural relative similarity over artificial absolute similarity.","authors":["Zhiyuan Ning","Pengfei Wang","Ziyue Qiao","Pengyang Wang","Yuanchun Zhou"],"url":"https://arxiv.org/abs/2505.05533"}
{"created":"2025-05-12","title":"KPI Poisoning: An Attack in Open RAN Near Real-Time Control Loop","abstract":"Open Radio Access Network (Open RAN) is a new paradigm to provide fundamental features for supporting next-generation mobile networks. Disaggregation, virtualisation, closed-loop data-driven control, and open interfaces bring flexibility and interoperability to the network deployment. However, these features also create a new surface for security threats. In this paper, we introduce Key Performance Indicators (KPIs) poisoning attack in Near Real-Time control loops as a new form of threat that can have significant effects on the Open RAN functionality. This threat can arise from traffic spoofing on the E2 interface or compromised E2 nodes. The role of KPIs is explored in the use cases of Near Real-Time control loops. Then, the potential impacts of the attack are analysed. An ML-based approach is proposed to detect poisoned KPI values before using them in control loops. Emulations are conducted to generate KPI reports and inject anomalies into the values. A Long Short-Term Memory (LSTM) neural network model is used to detect anomalies. The results show that more amplified injected values are more accessible to detect, and using more report sequences leads to better performance in anomaly detection, with detection rates improving from 62% to 99%.","authors":["Hamed Alimohammadi","Sotiris Chatzimiltis","Samara Mayhoub","Mohammad Shojafar","Seyed Ahmad Soleymani","Ayhan Akbas","Chuan Heng Foh"],"url":"https://arxiv.org/abs/2505.05537"}
{"created":"2025-05-12","title":"Cardioformer: Advancing AI in ECG Analysis with Multi-Granularity Patching and ResNet","abstract":"Electrocardiogram (ECG) classification is crucial for automated cardiac disease diagnosis, yet existing methods often struggle to capture local morphological details and long-range temporal dependencies simultaneously. To address these challenges, we propose Cardioformer, a novel multi-granularity hybrid model that integrates cross-channel patching, hierarchical residual learning, and a two-stage self-attention mechanism. Cardioformer first encodes multi-scale token embeddings to capture fine-grained local features and global contextual information and then selectively fuses these representations through intra- and inter-granularity self-attention. Extensive evaluations on three benchmark ECG datasets under subject-independent settings demonstrate that model consistently outperforms four state-of-the-art baselines. Our Cardioformer model achieves the AUROC of 96.34$\\pm$0.11, 89.99$\\pm$0.12, and 95.59$\\pm$1.66 in MIMIC-IV, PTB-XL and PTB dataset respectively outperforming PatchTST, Reformer, Transformer, and Medformer models. It also demonstrates strong cross-dataset generalization, achieving 49.18% AUROC on PTB and 68.41% on PTB-XL when trained on MIMIC-IV. These findings underscore the potential of Cardioformer to advance automated ECG analysis, paving the way for more accurate and robust cardiovascular disease diagnosis. We release the source code at https://github.com/KMobin555/Cardioformer.","authors":["Md Kamrujjaman Mobin","Md Saiful Islam","Sadik Al Barid","Md Masum"],"url":"https://arxiv.org/abs/2505.05538"}
{"created":"2025-05-12","title":"Benchmarking Vision, Language, & Action Models in Procedurally Generated, Open Ended Action Environments","abstract":"Vision-language-action (VLA) models represent an important step toward general-purpose robotic systems by integrating visual perception, language understanding, and action execution. However, systematic evaluation of these models, particularly their zero-shot generalization capabilities in out-of-distribution (OOD) environments, remains limited. In this paper, we introduce MultiNet v0.2, a comprehensive benchmark designed to evaluate and analyze the generalization performance of state-of-the-art VLM and VLA models-including GPT-4o, GPT-4.1, OpenVLA,Pi0 Base, and Pi0 FAST-on diverse procedural tasks from the Procgen benchmark. Our analysis reveals several critical insights: (1) all evaluated models exhibit significant limitations in zero-shot generalization to OOD tasks, with performance heavily influenced by factors such as action representation and task complexit; (2) VLAs generally outperform other models due to their robust architectural design; and (3) VLM variants demonstrate substantial improvements when constrained appropriately, highlighting the sensitivity of model performance to precise prompt engineering.","authors":["Pranav Guruprasad","Yangyue Wang","Sudipta Chowdhury","Harshvardhan Sikka"],"url":"https://arxiv.org/abs/2505.05540"}
{"created":"2025-05-12","title":"Safety by Measurement: A Systematic Literature Review of AI Safety Evaluation Methods","abstract":"As frontier AI systems advance toward transformative capabilities, we need a parallel transformation in how we measure and evaluate these systems to ensure safety and inform governance. While benchmarks have been the primary method for estimating model capabilities, they often fail to establish true upper bounds or predict deployment behavior. This literature review consolidates the rapidly evolving field of AI safety evaluations, proposing a systematic taxonomy around three dimensions: what properties we measure, how we measure them, and how these measurements integrate into frameworks. We show how evaluations go beyond benchmarks by measuring what models can do when pushed to the limit (capabilities), the behavioral tendencies exhibited by default (propensities), and whether our safety measures remain effective even when faced with subversive adversarial AI (control). These properties are measured through behavioral techniques like scaffolding, red teaming and supervised fine-tuning, alongside internal techniques such as representation analysis and mechanistic interpretability. We provide deeper explanations of some safety-critical capabilities like cybersecurity exploitation, deception, autonomous replication, and situational awareness, alongside concerning propensities like power-seeking and scheming. The review explores how these evaluation methods integrate into governance frameworks to translate results into concrete development decisions. We also highlight challenges to safety evaluations - proving absence of capabilities, potential model sandbagging, and incentives for \"safetywashing\" - while identifying promising research directions. By synthesizing scattered resources, this literature review aims to provide a central reference point for understanding AI safety evaluations.","authors":["Markov Grey","Charbel-Rapha\\\"el Segerie"],"url":"https://arxiv.org/abs/2505.05541"}
{"created":"2025-05-12","title":"A Common Interface for Automatic Differentiation","abstract":"For scientific machine learning tasks with a lot of custom code, picking the right Automatic Differentiation (AD) system matters. Our Julia package DifferentiationInterface.jl provides a common frontend to a dozen AD backends, unlocking easy comparison and modular development. In particular, its built-in preparation mechanism leverages the strengths of each backend by amortizing one-time computations. This is key to enabling sophisticated features like sparsity handling without putting additional burdens on the user.","authors":["Guillaume Dalle","Adrian Hill"],"url":"https://arxiv.org/abs/2505.05542"}
{"created":"2025-05-12","title":"Would You Rely on an Eerie Agent? A Systematic Review of the Impact of the Uncanny Valley Effect on Trust in Human-Agent Interaction","abstract":"Trust is a fundamental component of human-agent interaction. With the increasing presence of artificial agents in daily life, it is essential to understand how people perceive and trust these agents. One of the key challenges affecting this perception is the Uncanny Valley Effect (UVE), where increasingly human-like artificial beings can be perceived as eerie or repelling. Despite growing interest in trust and the UVE, existing research varies widely in terms of how these concepts are defined and operationalized. This inconsistency raises important questions about how and under what conditions the UVE influences trust in agents. A systematic understanding of their relationship is currently lacking. This review aims to examine the impact of the UVE on human trust in agents and to identify methodological patterns, limitations, and gaps in the existing empirical literature. Following PRISMA guidelines, a systematic search identified 53 empirical studies that investigated both UVE-related constructs and trust or trust-related outcomes. Studies were analyzed based on a structured set of categories, including types of agents and interactions, methodological and measurement approaches, and key findings. The results of our systematic review reveal that most studies rely on static images or hypothetical scenarios with limited real-time interaction, and the majority use subjective trust measures. This review offers a novel framework for classifying trust measurement approaches with regard to the best-practice criteria for empirically investigating the UVE. As the first systematic attempt to map the intersection of UVE and trust, this review contributes to a deeper understanding of their interplay and offers a foundation for future research. Keywords: the uncanny valley effect, trust, human-likeness, affinity response, human-agent interaction","authors":["Ahdiyeh Alipour","Tilo Hartmann","Maryam Alimardani"],"url":"https://arxiv.org/abs/2505.05543"}
{"created":"2025-05-12","title":"Barrier Function Overrides For Non-Convex Fixed Wing Flight Control and Self-Driving Cars","abstract":"Reinforcement Learning (RL) has enabled vast performance improvements for robotics systems. To achieve these results though, the agent often must randomly explore the environment, which for safety critical systems presents a significant challenge. Barrier functions can solve this challenge by enabling an override that approximates the RL control input as closely as possible without violating a safety constraint. Unfortunately, this override can be computationally intractable in cases where the dynamics are not convex in the control input or when time is discrete, as is often the case when training RL systems. We therefore consider these cases, developing novel barrier functions for two non-convex systems (fixed wing aircraft and self-driving cars performing lane merging with adaptive cruise control) in discrete time. Although solving for an online and optimal override is in general intractable when the dynamics are nonconvex in the control input, we investigate approximate solutions, finding that these approximations enable performance commensurate with baseline RL methods with zero safety violations. In particular, even without attempting to solve for the optimal override at all, performance is still competitive with baseline RL performance. We discuss the tradeoffs of the approximate override solutions including performance and computational tractability.","authors":["Eric Squires","Phillip Odom","Zsolt Kira"],"url":"https://arxiv.org/abs/2505.05548"}
{"created":"2025-05-12","title":"Griffin: Towards a Graph-Centric Relational Database Foundation Model","abstract":"We introduce Griffin, the first foundation model attemptation designed specifically for Relational Databases (RDBs). Unlike previous smaller models focused on single RDB tasks, Griffin unifies the data encoder and task decoder to handle diverse tasks. Additionally, we enhance the architecture by incorporating a cross-attention module and a novel aggregator. Griffin utilizes pretraining on both single-table and RDB datasets, employing advanced encoders for categorical, numerical, and metadata features, along with innovative components such as cross-attention modules and enhanced message-passing neural networks (MPNNs) to capture the complexities of relational data. Evaluated on large-scale, heterogeneous, and temporal graphs extracted from RDBs across various domains (spanning over 150 million nodes), Griffin demonstrates superior or comparable performance to individually trained models, excels in low-data scenarios, and shows strong transferability with similarity and diversity in pretraining across new datasets and tasks, highlighting its potential as a universally applicable foundation model for RDBs. Code available at https://github.com/yanxwb/Griffin.","authors":["Yanbo Wang","Xiyuan Wang","Quan Gan","Minjie Wang","Qibin Yang","David Wipf","Muhan Zhang"],"url":"https://arxiv.org/abs/2505.05568"}
{"created":"2025-05-12","title":"Prompt to Polyp: Clinically-Aware Medical Image Synthesis with Diffusion Models","abstract":"The generation of realistic medical images from text descriptions has significant potential to address data scarcity challenges in healthcare AI while preserving patient privacy. This paper presents a comprehensive study of text-to-image synthesis in the medical domain, comparing two distinct approaches: (1) fine-tuning large pre-trained latent diffusion models and (2) training small, domain-specific models. We introduce a novel model named MSDM, an optimized architecture based on Stable Diffusion that integrates a clinical text encoder, variational autoencoder, and cross-attention mechanisms to better align medical text prompts with generated images. Our study compares two approaches: fine-tuning large pre-trained models (FLUX, Kandinsky) versus training compact domain-specific models (MSDM). Evaluation across colonoscopy (MedVQA-GI) and radiology (ROCOv2) datasets reveals that while large models achieve higher fidelity, our optimized MSDM delivers comparable quality with lower computational costs. Quantitative metrics and qualitative evaluations by medical experts reveal strengths and limitations of each approach.","authors":["Mikhail Chaichuk","Sushant Gautam","Steven Hicks","Elena Tutubalina"],"url":"https://arxiv.org/abs/2505.05573"}
{"created":"2025-05-12","title":"PyTDC: A multimodal machine learning training, evaluation, and inference platform for biomedical foundation models","abstract":"Existing biomedical benchmarks do not provide end-to-end infrastructure for training, evaluation, and inference of models that integrate multimodal biological data and a broad range of machine learning tasks in therapeutics. We present PyTDC, an open-source machine-learning platform providing streamlined training, evaluation, and inference software for multimodal biological AI models. PyTDC unifies distributed, heterogeneous, continuously updated data sources and model weights and standardizes benchmarking and inference endpoints. This paper discusses the components of PyTDC's architecture and, to our knowledge, the first-of-its-kind case study on the introduced single-cell drug-target nomination ML task. We find state-of-the-art methods in graph representation learning and domain-specific methods from graph theory perform poorly on this task. Though we find a context-aware geometric deep learning method that outperforms the evaluated SoTA and domain-specific baseline methods, the model is unable to generalize to unseen cell types or incorporate additional modalities, highlighting PyTDC's capacity to facilitate an exciting avenue of research developing multimodal, context-aware, foundation models for open problems in biomedical AI.","authors":["Alejandro Velez-Arce","Marinka Zitnik"],"url":"https://arxiv.org/abs/2505.05577"}
{"created":"2025-05-12","title":"LaZagna: An Open-Source Framework for Flexible 3D FPGA Architectural Exploration","abstract":"While 3D IC technology has been extensively explored for ASICs, their application to FPGAs remains limited. Existing studies on 3D FPGAs are often constrained to fixed prototypes, narrow architectural templates, and simulation-only evaluations. In this work, we present LaZagna, the first open-source framework for automated, end-to-end 3D FPGA architecture generation and evaluation. LaZagna supports high-level architectural specification, synthesizable RTL generation, and bitstream production, enabling comprehensive validation of 3D FPGA designs beyond simulation. It significantly broadens the design space compared to prior work by introducing customizable vertical interconnect patterns, novel 3D switch block designs, and support for heterogeneous logic layers. The framework also incorporates practical design constraints such as inter-layer via density and vertical interconnect delay. We demonstrate the capabilities of LaZagna by generating synthesizable RTL that can be taken through full physical design flows for fabric generation, along with functionally correct bitstreams. Furthermore, we conduct five case studies that explore various architectural parameters and evaluate their impact on wirelength, critical path delay, and routing runtime. These studies showcase the framework's scalability, flexibility, and effectiveness in guiding future 3D FPGA architectural and packaging decisions. LaZagna is fully open-source and available on GitHub.","authors":["Ismael Youssef","Hang Yang","Cong Hao"],"url":"https://arxiv.org/abs/2505.05579"}
{"created":"2025-05-12","title":"KG-HTC: Integrating Knowledge Graphs into LLMs for Effective Zero-shot Hierarchical Text Classification","abstract":"Hierarchical Text Classification (HTC) involves assigning documents to labels organized within a taxonomy. Most previous research on HTC has focused on supervised methods. However, in real-world scenarios, employing supervised HTC can be challenging due to a lack of annotated data. Moreover, HTC often faces issues with large label spaces and long-tail distributions. In this work, we present Knowledge Graphs for zero-shot Hierarchical Text Classification (KG-HTC), which aims to address these challenges of HTC in applications by integrating knowledge graphs with Large Language Models (LLMs) to provide structured semantic context during classification. Our method retrieves relevant subgraphs from knowledge graphs related to the input text using a Retrieval-Augmented Generation (RAG) approach. Our KG-HTC can enhance LLMs to understand label semantics at various hierarchy levels. We evaluate KG-HTC on three open-source HTC datasets: WoS, DBpedia, and Amazon. Our experimental results show that KG-HTC significantly outperforms three baselines in the strict zero-shot setting, particularly achieving substantial improvements at deeper levels of the hierarchy. This evaluation demonstrates the effectiveness of incorporating structured knowledge into LLMs to address HTC's challenges in large label spaces and long-tailed label distributions. Our code is available at: https://github.com/QianboZang/KG-HTC.","authors":["Qianbo Zang","Christophe Zgrzendek","Igor Tchappi","Afshin Khadangi","Johannes Sedlmeir"],"url":"https://arxiv.org/abs/2505.05583"}
{"created":"2025-05-12","title":"PRIMG : Efficient LLM-driven Test Generation Using Mutant Prioritization","abstract":"Mutation testing is a widely recognized technique for assessing and enhancing the effectiveness of software test suites by introducing deliberate code mutations. However, its application often results in overly large test suites, as developers generate numerous tests to kill specific mutants, increasing computational overhead. This paper introduces PRIMG (Prioritization and Refinement Integrated Mutation-driven Generation), a novel framework for incremental and adaptive test case generation for Solidity smart contracts. PRIMG integrates two core components: a mutation prioritization module, which employs a machine learning model trained on mutant subsumption graphs to predict the usefulness of surviving mutants, and a test case generation module, which utilizes Large Language Models (LLMs) to generate and iteratively refine test cases to achieve syntactic and behavioral correctness.","authors":["Mohamed Salah Bouafif","Mohammad Hamdaqa","Edward Zulkoski"],"url":"https://arxiv.org/abs/2505.05584"}
{"created":"2025-05-12","title":"Steepest Descent Density Control for Compact 3D Gaussian Splatting","abstract":"3D Gaussian Splatting (3DGS) has emerged as a powerful technique for real-time, high-resolution novel view synthesis. By representing scenes as a mixture of Gaussian primitives, 3DGS leverages GPU rasterization pipelines for efficient rendering and reconstruction. To optimize scene coverage and capture fine details, 3DGS employs a densification algorithm to generate additional points. However, this process often leads to redundant point clouds, resulting in excessive memory usage, slower performance, and substantial storage demands - posing significant challenges for deployment on resource-constrained devices. To address this limitation, we propose a theoretical framework that demystifies and improves density control in 3DGS. Our analysis reveals that splitting is crucial for escaping saddle points. Through an optimization-theoretic approach, we establish the necessary conditions for densification, determine the minimal number of offspring Gaussians, identify the optimal parameter update direction, and provide an analytical solution for normalizing off-spring opacity. Building on these insights, we introduce SteepGS, incorporating steepest density control, a principled strategy that minimizes loss while maintaining a compact point cloud. SteepGS achieves a ~50% reduction in Gaussian points without compromising rendering quality, significantly enhancing both efficiency and scalability.","authors":["Peihao Wang","Yuehao Wang","Dilin Wang","Sreyas Mohan","Zhiwen Fan","Lemeng Wu","Ruisi Cai","Yu-Ying Yeh","Zhangyang Wang","Qiang Liu","Rakesh Ranjan"],"url":"https://arxiv.org/abs/2505.05587"}
{"created":"2025-05-12","title":"Flight Validation of Learning-Based Trajectory Optimization for the Astrobee Free-Flyer","abstract":"Although widely used in commercial and industrial robotics, trajectory optimization has seen limited use in space applications due to its high computational demands. In this work, we present flight results from experiments with the Astrobee free-flying robot on board the International Space Station (ISS), that demonstrate how machine learning can accelerate on-board trajectory optimization while preserving theoretical solver guarantees. To the best of the authors' knowledge, this is the first-ever demonstration of learning-based control on the ISS. Our approach leverages the GuSTO sequential convex programming framework and uses a neural network, trained offline, to map problem parameters to effective initial ``warm-start'' trajectories, paving the way for faster real-time optimization on resource-constrained space platforms.","authors":["Somrita Banerjee","Abhishek Cauligi","Marco Pavone"],"url":"https://arxiv.org/abs/2505.05588"}
{"created":"2025-05-12","title":"ReactDance: Progressive-Granular Representation for Long-Term Coherent Reactive Dance Generation","abstract":"Reactive dance generation (RDG) produces follower movements conditioned on guiding dancer and music while ensuring spatial coordination and temporal coherence. However, existing methods overemphasize global constraints and optimization, overlooking local information, such as fine-grained spatial interactions and localized temporal context. Therefore, we present ReactDance, a novel diffusion-based framework for high-fidelity RDG with long-term coherence and multi-scale controllability. Unlike existing methods that struggle with interaction fidelity, synchronization, and temporal consistency in duet synthesis, our approach introduces two key innovations: 1)Group Residual Finite Scalar Quantization (GRFSQ), a multi-scale disentangled motion representation that captures interaction semantics from coarse body rhythms to fine-grained joint dynamics, and 2)Blockwise Local Context (BLC), a sampling strategy eliminating error accumulation in long sequence generation via local block causal masking and periodic positional encoding. Built on the decoupled multi-scale GRFSQ representation, we implement a diffusion model withLayer-Decoupled Classifier-free Guidance (LDCFG), allowing granular control over motion semantics across scales. Extensive experiments on standard benchmarks demonstrate that ReactDance surpasses existing methods, achieving state-of-the-art performance.","authors":["Jingzhong Lin","Yuanyuan Qi","Xinru Li","Wenxuan Huang","Xiangfeng Xu","Bangyan Li","Xuejiao Wang","Gaoqi He"],"url":"https://arxiv.org/abs/2505.05589"}
{"created":"2025-05-12","title":"QuickSplat: Fast 3D Surface Reconstruction via Learned Gaussian Initialization","abstract":"Surface reconstruction is fundamental to computer vision and graphics, enabling applications in 3D modeling, mixed reality, robotics, and more. Existing approaches based on volumetric rendering obtain promising results, but optimize on a per-scene basis, resulting in a slow optimization that can struggle to model under-observed or textureless regions. We introduce QuickSplat, which learns data-driven priors to generate dense initializations for 2D gaussian splatting optimization of large-scale indoor scenes. This provides a strong starting point for the reconstruction, which accelerates the convergence of the optimization and improves the geometry of flat wall structures. We further learn to jointly estimate the densification and update of the scene parameters during each iteration; our proposed densifier network predicts new Gaussians based on the rendering gradients of existing ones, removing the needs of heuristics for densification. Extensive experiments on large-scale indoor scene reconstruction demonstrate the superiority of our data-driven optimization. Concretely, we accelerate runtime by 8x, while decreasing depth errors by up to 48% in comparison to state of the art methods.","authors":["Yueh-Cheng Liu","Lukas H\\\"ollein","Matthias Nie{\\ss}ner","Angela Dai"],"url":"https://arxiv.org/abs/2505.05591"}
{"created":"2025-05-12","title":"Learning to Drive Anywhere with Model-Based Reannotation11","abstract":"Developing broadly generalizable visual navigation policies for robots is a significant challenge, primarily constrained by the availability of large-scale, diverse training data. While curated datasets collected by researchers offer high quality, their limited size restricts policy generalization. To overcome this, we explore leveraging abundant, passively collected data sources, including large volumes of crowd-sourced teleoperation data and unlabeled YouTube videos, despite their potential for lower quality or missing action labels. We propose Model-Based ReAnnotation (MBRA), a framework that utilizes a learned short-horizon, model-based expert model to relabel or generate high-quality actions for these passive datasets. This relabeled data is then distilled into LogoNav, a long-horizon navigation policy conditioned on visual goals or GPS waypoints. We demonstrate that LogoNav, trained using MBRA-processed data, achieves state-of-the-art performance, enabling robust navigation over distances exceeding 300 meters in previously unseen indoor and outdoor environments. Our extensive real-world evaluations, conducted across a fleet of robots (including quadrupeds) in six cities on three continents, validate the policy's ability to generalize and navigate effectively even amidst pedestrians in crowded settings.","authors":["Noriaki Hirose","Lydia Ignatova","Kyle Stachowicz","Catherine Glossop","Sergey Levine","Dhruv Shah"],"url":"https://arxiv.org/abs/2505.05592"}
{"created":"2025-05-12","title":"Anticipating Gaming to Incentivize Improvement: Guiding Agents in (Fair) Strategic Classification","abstract":"As machine learning algorithms increasingly influence critical decision making in different application areas, understanding human strategic behavior in response to these systems becomes vital. We explore individuals' choice between genuinely improving their qualifications (``improvement'') vs. attempting to deceive the algorithm by manipulating their features (``manipulation'') in response to an algorithmic decision system. We further investigate an algorithm designer's ability to shape these strategic responses, and its fairness implications. Specifically, we formulate these interactions as a Stackelberg game, where a firm deploys a (fair) classifier, and individuals strategically respond. Our model incorporates both different costs and stochastic efficacy for manipulation and improvement. The analysis reveals different potential classes of agent responses, and characterizes optimal classifiers accordingly. Based on these, we highlight the impact of the firm's anticipation of strategic behavior, identifying when and why a (fair) strategic policy can not only prevent manipulation, but also incentivize agents to opt for improvement.","authors":["Sura Alhanouti","Parinaz Naghizadeh"],"url":"https://arxiv.org/abs/2505.05594"}
{"created":"2025-05-12","title":"This part looks alike this: identifying important parts of explained instances and prototypes","abstract":"Although prototype-based explanations provide a human-understandable way of representing model predictions they often fail to direct user attention to the most relevant features. We propose a novel approach to identify the most informative features within prototypes, termed alike parts. Using feature importance scores derived from an agnostic explanation method, it emphasizes the most relevant overlapping features between an instance and its nearest prototype. Furthermore, the feature importance score is incorporated into the objective function of the prototype selection algorithms to promote global prototypes diversity. Through experiments on six benchmark datasets, we demonstrate that the proposed approach improves user comprehension while maintaining or even increasing predictive accuracy.","authors":["Jacek Karolczak","Jerzy Stefanowski"],"url":"https://arxiv.org/abs/2505.05597"}
{"created":"2025-05-12","title":"Optimal transfer operators in algebraic two-level methods for nonsymmetric and indefinite problems","abstract":"Consider an algebraic two-level method applied to the $n$-dimensional linear system $A \\mathbf{x} = \\mathbf{b}$ using fine-space preconditioner (i.e., ``relaxation'' or ``smoother'' in the context of multigrid) $M$, with $M \\approx A$, restriction and interpolation $R$ and $P$, and algebraic coarse-space operator ${A_c := R^*AP}$. Then, what are the the best possible transfer operators $R$ and $P$ of a given dimension $n_c < n$? Brannick et al. (2018) showed that when $A$ and $M$ are Hermitian positive definite (HPD), the optimal interpolation is such that its range contains the $n_c$ smallest generalized eigenvectors of the matrix pencil $(A, M)$. Recently, Ali et al. (2025) generalized this framework to the non-HPD setting, by considering both right (interpolation) and left (restriction) generalized eigenvectors of $(A, M)$, but were unable to show norm-based convergence or optimality. Moreover, the transfer operators as derived therein are typically complex valued, which is not practical for real-valued problems, as usually arise in the context of numerical partial differential equations, for example. Here we significantly strengthen the results from Ali et al., first characterizing all inner products in which the resulting coarse-space correction defined by these transfer operators is orthogonal. We then develop tight two-level convergence bounds in these norms, and prove that the underlying transfer operators are genuinely optimal in these norms. As a special case, our theory both recovers and extends the HPD results from Brannick et al. Finally, we show how to construct optimal, real-valued transfer operators in the case of that $A$ and $M$ are real valued, but are not symmetric positive definite. Numerical examples arising from discretized advection and wave-equation problems are used to verify and illustrate the theory.","authors":["Oliver A. Krzysik","Ben S. Southworth","Golo A. Wimmer"],"url":"https://arxiv.org/abs/2505.05598"}
{"created":"2025-05-12","title":"Enhancing Satellite Object Localization with Dilated Convolutions and Attention-aided Spatial Pooling","abstract":"Object localization in satellite imagery is particularly challenging due to the high variability of objects, low spatial resolution, and interference from noise and dominant features such as clouds and city lights. In this research, we focus on three satellite datasets: upper atmospheric Gravity Waves (GW), mesospheric Bores (Bore), and Ocean Eddies (OE), each presenting its own unique challenges. These challenges include the variability in the scale and appearance of the main object patterns, where the size, shape, and feature extent of objects of interest can differ significantly. To address these challenges, we introduce YOLO-DCAP, a novel enhanced version of YOLOv5 designed to improve object localization in these complex scenarios. YOLO-DCAP incorporates a Multi-scale Dilated Residual Convolution (MDRC) block to capture multi-scale features at scale with varying dilation rates, and an Attention-aided Spatial Pooling (AaSP) module to focus on the global relevant spatial regions, enhancing feature selection. These structural improvements help to better localize objects in satellite imagery. Experimental results demonstrate that YOLO-DCAP significantly outperforms both the YOLO base model and state-of-the-art approaches, achieving an average improvement of 20.95% in mAP50 and 32.23% in IoU over the base model, and 7.35% and 9.84% respectively over state-of-the-art alternatives, consistently across all three satellite datasets. These consistent gains across all three satellite datasets highlight the robustness and generalizability of the proposed approach. Our code is open sourced at https://github.com/AI-4-atmosphere-remote-sensing/satellite-object-localization.","authors":["Seraj Al Mahmud Mostafa","Chenxi Wang","Jia Yue","Yuta Hozumi","Jianwu Wang"],"url":"https://arxiv.org/abs/2505.05599"}
{"created":"2025-05-12","title":"Enhancing Large Language Models with Faster Code Preprocessing for Vulnerability Detection","abstract":"The application of Artificial Intelligence has become a powerful approach to detecting software vulnerabilities. However, effective vulnerability detection relies on accurately capturing the semantic structure of code and its contextual relationships. Given that the same functionality can be implemented in various forms, a preprocessing tool that standardizes code representation is important. This tool must be efficient, adaptable across programming languages, and capable of supporting new transformations. To address this challenge, we build on the existing SCoPE framework and introduce SCoPE2, an enhanced version with improved performance. We compare both versions in terms of processing time and memory usage and evaluate their impact on a Large Language Model (LLM) for vulnerability detection. Our results show a 97.3\\% reduction in processing time with SCoPE2, along with an improved F1-score for the LLM, solely due to the refined preprocessing approach.","authors":["Jos\\'e Gon\\c{c}alves","Miguel Silva","Eva Maia","Isabel Pra\\c{c}a"],"url":"https://arxiv.org/abs/2505.05600"}
{"created":"2025-05-12","title":"HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics","abstract":"As Large Language Models (LLMs) and other AI systems evolve, robustly estimating their capabilities from inherently stochastic outputs while systematically quantifying uncertainty in these estimates becomes increasingly important. Further, advanced AI evaluations often have a nested hierarchical structure, exhibit high levels of complexity, and come with high costs in testing the most advanced AI systems. To address these challenges, we introduce HiBayES, a generalizable Hierarchical Bayesian modeling framework for AI Evaluation Statistics. HiBayES supports robust inferences in classical question-answer benchmarks and advanced agentic evaluations, particularly in low-data scenarios (e.g., < 20 data points per evaluation). Built on Generalized Linear Models (GLMs), Bayesian data analysis, and formal model comparison, HiBayES provides principled uncertainty quantification and robust parameter estimation. This paper offers a comprehensive introduction to HiBayES, including illustrative examples, comparisons to conventional statistical methods, and practical guidance for implementing multilevel Bayesian GLMs. Additionally, we provide a HiBayES software package [4] (Beta version) for out-of-the-box implementation.","authors":["Lennart Luettgau","Harry Coppock","Magda Dubois","Christopher Summerfield","Cozmin Ududec"],"url":"https://arxiv.org/abs/2505.05602"}
{"created":"2025-05-12","title":"The Evolution of Embedding Table Optimization and Multi-Epoch Training in Pinterest Ads Conversion","abstract":"Deep learning for conversion prediction has found widespread applications in online advertising. These models have become more complex as they are trained to jointly predict multiple objectives such as click, add-to-cart, checkout and other conversion types. Additionally, the capacity and performance of these models can often be increased with the use of embedding tables that encode high cardinality categorical features such as advertiser, user, campaign, and product identifiers (IDs). These embedding tables can be pre-trained, but also learned end-to-end jointly with the model to directly optimize the model objectives. Training these large tables is challenging due to: gradient sparsity, the high cardinality of the categorical features, the non-uniform distribution of IDs and the very high label sparsity. These issues make training prone to both slow convergence and overfitting after the first epoch. Previous works addressed the multi-epoch overfitting issue by using: stronger feature hashing to reduce cardinality, filtering of low frequency IDs, regularization of the embedding tables, re-initialization of the embedding tables after each epoch, etc. Some of these techniques reduce overfitting at the expense of reduced model performance if used too aggressively. In this paper, we share key learnings from the development of embedding table optimization and multi-epoch training in Pinterest Ads Conversion models. We showcase how our Sparse Optimizer speeds up convergence, and how multi-epoch overfitting varies in severity between different objectives in a multi-task model depending on label sparsity. We propose a new approach to deal with multi-epoch overfitting: the use of a frequency-adaptive learning rate on the embedding tables and compare it to embedding re-initialization. We evaluate both methods offline using an industrial large-scale production dataset.","authors":["Andrew Qiu","Shubham Barhate","Hin Wai Lui","Runze Su","Rafael Rios M\\\"uller","Kungang Li","Ling Leng","Han Sun","Shayan Ehsani","Zhifang Liu"],"url":"https://arxiv.org/abs/2505.05605"}
{"created":"2025-05-12","title":"On Corruption-Robustness in Performative Reinforcement Learning","abstract":"In performative Reinforcement Learning (RL), an agent faces a policy-dependent environment: the reward and transition functions depend on the agent's policy. Prior work on performative RL has studied the convergence of repeated retraining approaches to a performatively stable policy. In the finite sample regime, these approaches repeatedly solve for a saddle point of a convex-concave objective, which estimates the Lagrangian of a regularized version of the reinforcement learning problem. In this paper, we aim to extend such repeated retraining approaches, enabling them to operate under corrupted data. More specifically, we consider Huber's $\\epsilon$-contamination model, where an $\\epsilon$ fraction of data points is corrupted by arbitrary adversarial noise. We propose a repeated retraining approach based on convex-concave optimization under corrupted gradients and a novel problem-specific robust mean estimator for the gradients. We prove that our approach exhibits last-iterate convergence to an approximately stable policy, with the approximation error linear in $\\sqrt{\\epsilon}$. We experimentally demonstrate the importance of accounting for corruption in performative RL.","authors":["Vasilis Pollatos","Debmalya Mandal","Goran Radanovic"],"url":"https://arxiv.org/abs/2505.05609"}
{"created":"2025-05-12","title":"scDrugMap: Benchmarking Large Foundation Models for Drug Response Prediction","abstract":"Drug resistance presents a major challenge in cancer therapy. Single cell profiling offers insights into cellular heterogeneity, yet the application of large-scale foundation models for predicting drug response in single cell data remains underexplored. To address this, we developed scDrugMap, an integrated framework featuring both a Python command-line interface and a web server for drug response prediction. scDrugMap evaluates a wide range of foundation models, including eight single-cell models and two large language models, using a curated dataset of over 326,000 cells in the primary collection and 18,800 cells in the validation set, spanning 36 datasets and diverse tissue and cancer types. We benchmarked model performance under pooled-data and cross-data evaluation settings, employing both layer freezing and Low-Rank Adaptation (LoRA) fine-tuning strategies. In the pooled-data scenario, scFoundation achieved the best performance, with mean F1 scores of 0.971 (layer freezing) and 0.947 (fine-tuning), outperforming the lowest-performing model by over 50%. In the cross-data setting, UCE excelled post fine-tuning (mean F1: 0.774), while scGPT led in zero-shot learning (mean F1: 0.858). Overall, scDrugMap provides the first large-scale benchmark of foundation models for drug response prediction in single-cell data and serves as a user-friendly, flexible platform for advancing drug discovery and translational research.","authors":["Qing Wang","Yining Pan","Minghao Zhou","Zijia Tang","Yanfei Wang","Guangyu Wang","Qianqian Song"],"url":"https://arxiv.org/abs/2505.05612"}
{"created":"2025-05-12","title":"Leveraging Large Language Models for enzymatic reaction prediction and characterization","abstract":"Predicting enzymatic reactions is crucial for applications in biocatalysis, metabolic engineering, and drug discovery, yet it remains a complex and resource-intensive task. Large Language Models (LLMs) have recently demonstrated remarkable success in various scientific domains, e.g., through their ability to generalize knowledge, reason over complex structures, and leverage in-context learning strategies. In this study, we systematically evaluate the capability of LLMs, particularly the Llama-3.1 family (8B and 70B), across three core biochemical tasks: Enzyme Commission number prediction, forward synthesis, and retrosynthesis. We compare single-task and multitask learning strategies, employing parameter-efficient fine-tuning via LoRA adapters. Additionally, we assess performance across different data regimes to explore their adaptability in low-data settings. Our results demonstrate that fine-tuned LLMs capture biochemical knowledge, with multitask learning enhancing forward- and retrosynthesis predictions by leveraging shared enzymatic information. We also identify key limitations, for example challenges in hierarchical EC classification schemes, highlighting areas for further improvement in LLM-driven biochemical modeling.","authors":["Lorenzo Di Fruscia","Jana Marie Weber"],"url":"https://arxiv.org/abs/2505.05616"}
{"created":"2025-05-12","title":"LiteLMGuard: Seamless and Lightweight On-Device Prompt Filtering for Safeguarding Small Language Models against Quantization-induced Risks and Vulnerabilities","abstract":"The growing adoption of Large Language Models (LLMs) has influenced the development of their lighter counterparts-Small Language Models (SLMs)-to enable on-device deployment across smartphones and edge devices. These SLMs offer enhanced privacy, reduced latency, server-free functionality, and improved user experience. However, due to resource constraints of on-device environment, SLMs undergo size optimization through compression techniques like quantization, which can inadvertently introduce fairness, ethical and privacy risks. Critically, quantized SLMs may respond to harmful queries directly, without requiring adversarial manipulation, raising significant safety and trust concerns.","authors":["Kalyan Nakka","Jimmy Dani","Ausmit Mondal","Nitesh Saxena"],"url":"https://arxiv.org/abs/2505.05619"}
{"created":"2025-05-12","title":"A Preliminary Study for GPT-4o on Image Restoration","abstract":"OpenAI's GPT-4o model, integrating multi-modal inputs and outputs within an autoregressive architecture, has demonstrated unprecedented performance in image generation. In this work, we investigate its potential impact on the image restoration community. We present the first systematic evaluation of GPT-4o across diverse restoration tasks. Our experiments reveal that, although restoration outputs from GPT-4o are visually appealing, they often suffer from pixel-level structural fidelity when compared to ground-truth images. Common issues are variations in image proportions, shifts in object positions and quantities, and changes in viewpoint.To address it, taking image dehazing, derainning, and low-light enhancement as representative case studies, we show that GPT-4o's outputs can serve as powerful visual priors, substantially enhancing the performance of existing dehazing networks. It offers practical guidelines and a baseline framework to facilitate the integration of GPT-4o into future image restoration pipelines. We hope the study on GPT-4o image restoration will accelerate innovation in the broader field of image generation areas. To support further research, we will release GPT-4o-restored images from over 10 widely used image restoration datasets.","authors":["Hao Yang","Yan Yang","Ruikun Zhang","Liyuan Pan"],"url":"https://arxiv.org/abs/2505.05621"}
{"created":"2025-05-12","title":"CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory","abstract":"Aerial vision-and-language navigation (VLN), requiring drones to interpret natural language instructions and navigate complex urban environments, emerges as a critical embodied AI challenge that bridges human-robot interaction, 3D spatial reasoning, and real-world deployment. Although existing ground VLN agents achieved notable results in indoor and outdoor settings, they struggle in aerial VLN due to the absence of predefined navigation graphs and the exponentially expanding action space in long-horizon exploration. In this work, we propose \\textbf{CityNavAgent}, a large language model (LLM)-empowered agent that significantly reduces the navigation complexity for urban aerial VLN. Specifically, we design a hierarchical semantic planning module (HSPM) that decomposes the long-horizon task into sub-goals with different semantic levels. The agent reaches the target progressively by achieving sub-goals with different capacities of the LLM. Additionally, a global memory module storing historical trajectories into a topological graph is developed to simplify navigation for visited targets. Extensive benchmark experiments show that our method achieves state-of-the-art performance with significant improvement. Further experiments demonstrate the effectiveness of different modules of CityNavAgent for aerial VLN in continuous city environments. The code is available at \\href{https://github.com/VinceOuti/CityNavAgent}{link}.","authors":["Weichen Zhang","Chen Gao","Shiquan Yu","Ruiying Peng","Baining Zhao","Qian Zhang","Jinqiang Cui","Xinlei Chen","Yong Li"],"url":"https://arxiv.org/abs/2505.05622"}
{"created":"2025-05-12","title":"Characterizing GPU Energy Usage in Exascale-Ready Portable Science Applications","abstract":"We characterize the GPU energy usage of two widely adopted exascale-ready applications representing two classes of particle and mesh solvers: (i) QMCPACK, a quantum Monte Carlo package, and (ii) AMReX-Castro, an adaptive mesh astrophysical code. We analyze power, temperature, utilization, and energy traces from double-/single (mixed)-precision benchmarks on NVIDIA's A100 and H100 and AMD's MI250X GPUs using queries in NVML and rocm smi lib, respectively. We explore application-specific metrics to provide insights on energy vs. performance trade-offs. Our results suggest that mixed-precision energy savings range between 6-25% on QMCPACK and 45% on AMReX-Castro. Also there are still gaps in the AMD tooling on Frontier GPUs that need to be understood, while query resolutions on NVML have little variability between 1 ms and 1 s. Overall, application level knowledge is crucial to define energy-cost/science-benefit opportunities for the codesign of future supercomputer architectures in the post-Moore era.","authors":["William F. Godoy","Oscar Hernandez","Paul R. C. Kent","Maria Patrou","Kazi Asifuzzaman","Narasinga Rao Miniskar","Pedro Valero-Lara","Jeffrey S. Vetter","Matthew D. Sinclair","Jason Lowe-Power","Bobby R. Bruce"],"url":"https://arxiv.org/abs/2505.05623"}
{"created":"2025-05-12","title":"Stability analyses of divergence and vorticity damping on gnomonic cubed-sphere grids","abstract":"Divergence and vorticity damping are explicit diffusion mechanisms used in dynamical cores to ensure numerical stability. There is a mesh-dependent upper bound on the corresponding diffusion coefficient, else the diffusion itself becomes a source of instability. This work considers such stability limits for three gnomonic cubed-sphere meshes -- 1) equidistant, 2) equiangular, and 3) equi-edge mappings. Von Neumann analysis is used to derive linear stability limits, which show that the stability of divergence and vorticity damping depends on the cell areas and aspect ratios of the cubed-sphere grid. The linear theory is compared to practical divergence and vorticity damping limits in the CAM-FV3 dynamical core, using a baroclinic wave test case on the equiangular and equi-edge grids. For divergence damping, both the magnitude of maximum stable coefficients and the locations of instability agree with linear theory. Due to implicit vorticity diffusion from the transport scheme, practical limits for vorticity damping are lower than the explicit stability limits. The maximum allowable vorticity damping coefficient varies with the choice of horizontal transport scheme for the equi-edge grid; it is hypothesised that this indicates the relative implicit diffusion of the transport scheme in this test.","authors":["Timothy C. Andrews","Christiane Jablonowski"],"url":"https://arxiv.org/abs/2505.05624"}
{"created":"2025-05-12","title":"SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation","abstract":"Estimating rate constants from complex chemical reactions is essential for advancing detailed chemistry. However, the stiffness inherent in real-world atmospheric chemistry systems poses severe challenges, leading to training instability and poor convergence that hinder effective rate constant estimation using learning-based approaches. To address this, we propose a Stiff Physics-Informed Neural ODE framework (SPIN-ODE) for chemical reaction modelling. Our method introduces a three-stage optimisation process: first, a latent neural ODE learns the continuous and differentiable trajectory between chemical concentrations and their time derivatives; second, an explicit Chemical Reaction Neural Network (CRNN) extracts the underlying rate coefficients based on the learned dynamics; and third, fine-tune CRNN using a neural ODE solver to further improve rate coefficient estimation. Extensive experiments on both synthetic and newly proposed real-world datasets validate the effectiveness and robustness of our approach. As the first work on stiff Neural ODEs for chemical rate coefficient discovery, our study opens promising directions for integrating neural networks with detailed chemistry.","authors":["Wenqing Peng","Zhi-Song Liu","Michael Boy"],"url":"https://arxiv.org/abs/2505.05625"}
{"created":"2025-05-12","title":"Looking Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models","abstract":"Achieving deep alignment between vision and language remains a central challenge for Multimodal Large Language Models (MLLMs). These models often fail to fully leverage visual input, defaulting to strong language priors. Our approach first provides insights into how MLLMs internally build visual understanding of image regions and then introduces techniques to amplify this capability. Specifically, we explore techniques designed both to deepen the model's understanding of visual content and to ensure that these visual insights actively guide language generation. We demonstrate the superior multimodal understanding of our resultant model through a detailed upstream analysis quantifying its ability to predict visually-dependent tokens as well as 10 pt boost on visually challenging tasks.","authors":["Aarti Ghatkesar","Uddeshya Upadhyay","Ganesh Venkatesh"],"url":"https://arxiv.org/abs/2505.05626"}
{"created":"2025-05-12","title":"VR-RAG: Open-vocabulary Species Recognition with RAG-Assisted Large Multi-Modal Models","abstract":"Open-vocabulary recognition remains a challenging problem in computer vision, as it requires identifying objects from an unbounded set of categories. This is particularly relevant in nature, where new species are discovered every year. In this work, we focus on open-vocabulary bird species recognition, where the goal is to classify species based on their descriptions without being constrained to a predefined set of taxonomic categories. Traditional benchmarks like CUB-200-2011 and Birdsnap have been evaluated in a closed-vocabulary paradigm, limiting their applicability to real-world scenarios where novel species continually emerge. We show that the performance of current systems when evaluated under settings closely aligned with open-vocabulary drops by a huge margin. To address this gap, we propose a scalable framework integrating structured textual knowledge from Wikipedia articles of 11,202 bird species distilled via GPT-4o into concise, discriminative summaries. We propose Visual Re-ranking Retrieval-Augmented Generation(VR-RAG), a novel, retrieval-augmented generation framework that uses visual similarities to rerank the top m candidates retrieved by a set of multimodal vision language encoders. This allows for the recognition of unseen taxa. Extensive experiments across five established classification benchmarks show that our approach is highly effective. By integrating VR-RAG, we improve the average performance of state-of-the-art Large Multi-Modal Model QWEN2.5-VL by 15.4% across five benchmarks. Our approach outperforms conventional VLM-based approaches, which struggle with unseen species. By bridging the gap between encyclopedic knowledge and visual recognition, our work advances open-vocabulary recognition, offering a flexible, scalable solution for biodiversity monitoring and ecological research.","authors":["Faizan Farooq Khan","Jun Chen","Youssef Mohamed","Chun-Mei Feng","Mohamed Elhoseiny"],"url":"https://arxiv.org/abs/2505.05635"}
{"created":"2025-05-12","title":"Closing the Loop: Motion Prediction Models beyond Open-Loop Benchmarks","abstract":"Fueled by motion prediction competitions and benchmarks, recent years have seen the emergence of increasingly large learning based prediction models, many with millions of parameters, focused on improving open-loop prediction accuracy by mere centimeters. However, these benchmarks fail to assess whether such improvements translate to better performance when integrated into an autonomous driving stack. In this work, we systematically evaluate the interplay between state-of-the-art motion predictors and motion planners. Our results show that higher open-loop accuracy does not always correlate with better closed-loop driving behavior and that other factors, such as temporal consistency of predictions and planner compatibility, also play a critical role. Furthermore, we investigate downsized variants of these models, and, surprisingly, find that in some cases models with up to 86% fewer parameters yield comparable or even superior closed-loop driving performance. Our code is available at https://github.com/continental/pred2plan.","authors":["Mohamed-Khalil Bouzidi","Christian Schlauch","Nicole Scheuerer","Yue Yao","Nadja Klein","Daniel G\\\"ohring","J\\\"org Reichardt"],"url":"https://arxiv.org/abs/2505.05638"}
{"created":"2025-05-12","title":"Designing 3D Anisotropic Frame Fields with Odeco Tensors","abstract":"This paper introduces a method to synthesize a 3D tensor field within a constrained geometric domain represented as a tetrahedral mesh. Whereas previous techniques optimize for isotropic fields, we focus on anisotropic tensor fields that are smooth and aligned with the domain boundary or user guidance. The key ingredient of our method is a novel computational design framework, built on top of the symmetric orthogonally decomposable (odeco) tensor representation, to optimize the stretching ratios and orientations for each tensor in the domain. In contrast to past techniques designed only for isotropic tensors, we demonstrate the efficacy of our approach in generating smooth volumetric tensor fields with high anisotropy and shape conformity, especially for the domain with complex shapes. We apply these anisotropic tensor fields to various applications, such as anisotropic meshing, structural mechanics, and fabrication.","authors":["Haikuan Zhu","Hongbo Li","Hsueh-Ti Derek Liu","Wenping Wang","Jing Hua","Zichun Zhong"],"url":"https://arxiv.org/abs/2505.05639"}
{"created":"2025-05-12","title":"Semantic Style Transfer for Enhancing Animal Facial Landmark Detection","abstract":"Neural Style Transfer (NST) is a technique for applying the visual characteristics of one image onto another while preserving structural content. Traditionally used for artistic transformations, NST has recently been adapted, e.g., for domain adaptation and data augmentation. This study investigates the use of this technique for enhancing animal facial landmark detectors training. As a case study, we use a recently introduced Ensemble Landmark Detector for 48 anatomical cat facial landmarks and the CatFLW dataset it was trained on, making three main contributions. First, we demonstrate that applying style transfer to cropped facial images rather than full-body images enhances structural consistency, improving the quality of generated images. Secondly, replacing training images with style-transferred versions raised challenges of annotation misalignment, but Supervised Style Transfer (SST) - which selects style sources based on landmark accuracy - retained up to 98% of baseline accuracy. Finally, augmenting the dataset with style-transferred images further improved robustness, outperforming traditional augmentation methods. These findings establish semantic style transfer as an effective augmentation strategy for enhancing the performance of facial landmark detection models for animals and beyond. While this study focuses on cat facial landmarks, the proposed method can be generalized to other species and landmark detection models.","authors":["Anadil Hussein","Anna Zamansky","George Martvel"],"url":"https://arxiv.org/abs/2505.05640"}
{"created":"2025-05-12","title":"The Moon's Many Faces: A Single Unified Transformer for Multimodal Lunar Reconstruction","abstract":"Multimodal learning is an emerging research topic across multiple disciplines but has rarely been applied to planetary science. In this contribution, we identify that reflectance parameter estimation and image-based 3D reconstruction of lunar images can be formulated as a multimodal learning problem. We propose a single, unified transformer architecture trained to learn shared representations between multiple sources like grayscale images, digital elevation models, surface normals, and albedo maps. The architecture supports flexible translation from any input modality to any target modality. Predicting DEMs and albedo maps from grayscale images simultaneously solves the task of 3D reconstruction of planetary surfaces and disentangles photometric parameters and height information. Our results demonstrate that our foundation model learns physically plausible relations across these four modalities. Adding more input modalities in the future will enable tasks such as photometric normalization and co-registration.","authors":["Tom Sander","Moritz Tenthoff","Kay Wohlfarth","Christian W\\\"ohler"],"url":"https://arxiv.org/abs/2505.05644"}
{"created":"2025-05-12","title":"Privacy-Preserving Transformers: SwiftKey's Differential Privacy Implementation","abstract":"In this paper we train a transformer using differential privacy (DP) for language modeling in SwiftKey. We run multiple experiments to balance the trade-off between the model size, run-time speed and accuracy. We show that we get small and consistent gains in the next-word-prediction and accuracy with graceful increase in memory and speed compared to the production GRU. This is obtained by scaling down a GPT2 architecture to fit the required size and a two stage training process that builds a seed model on general data and DP finetunes it on typing data. The transformer is integrated using ONNX offering both flexibility and efficiency.","authors":["Abdelrahman Abouelenin","Mohamed Abdelrehim","Raffy Fahim","Amr Hendy","Mohamed Afify"],"url":"https://arxiv.org/abs/2505.05648"}
{"created":"2025-05-12","title":"EquiHGNN: Scalable Rotationally Equivariant Hypergraph Neural Networks","abstract":"Molecular interactions often involve high-order relationships that cannot be fully captured by traditional graph-based models limited to pairwise connections. Hypergraphs naturally extend graphs by enabling multi-way interactions, making them well-suited for modeling complex molecular systems. In this work, we introduce EquiHGNN, an Equivariant HyperGraph Neural Network framework that integrates symmetry-aware representations to improve molecular modeling. By enforcing the equivariance under relevant transformation groups, our approach preserves geometric and topological properties, leading to more robust and physically meaningful representations. We examine a range of equivariant architectures and demonstrate that integrating symmetry constraints leads to notable performance gains on large-scale molecular datasets. Experiments on both small and large molecules show that high-order interactions offer limited benefits for small molecules but consistently outperform 2D graphs on larger ones. Adding geometric features to these high-order structures further improves the performance, emphasizing the value of spatial information in molecular learning. Our source code is available at https://github.com/HySonLab/EquiHGNN/","authors":["Tien Dang","Truong-Son Hy"],"url":"https://arxiv.org/abs/2505.05650"}
{"created":"2025-05-12","title":"Invariant-Based Cryptography","abstract":"We propose a new symmetric cryptographic scheme based on functional invariants defined over discrete oscillatory functions with hidden parameters. The scheme encodes a secret integer through a four-point algebraic identity preserved under controlled parameterization. Security arises not from algebraic inversion but from structural coherence: the transmitted values satisfy an invariant that is computationally hard to forge or invert without knowledge of the shared secret. We develop the full analytic and modular framework, prove exact identities, define index-recovery procedures, and analyze security assumptions, including oscillator construction, hash binding, and invertibility conditions. The result is a compact, self-verifying mechanism suitable for secure authentication, parameter exchange, and lightweight communication protocols.","authors":["Stanislav Semenov"],"url":"https://arxiv.org/abs/2505.05653"}
{"created":"2025-05-12","title":"Toward a Sparse and Interpretable Audio Codec","abstract":"Most widely-used modern audio codecs, such as Ogg Vorbis and MP3, as well as more recent \"neural\" codecs like Meta's Encodec or the Descript Audio Codec are based on block-coding; audio is divided into overlapping, fixed-size \"frames\" which are then compressed. While they often yield excellent reproductions and can be used for downstream tasks such as text-to-audio, they do not produce an intuitive, directly-interpretable representation. In this work, we introduce a proof-of-concept audio encoder that represents audio as a sparse set of events and their times-of-occurrence. Rudimentary physics-based assumptions are used to model attack and the physical resonance of both the instrument being played and the room in which a performance occurs, hopefully encouraging a sparse, parsimonious, and easy-to-interpret representation.","authors":["John Vinyard"],"url":"https://arxiv.org/abs/2505.05654"}
{"created":"2025-05-12","title":"Projection-free approximation of flows of harmonic maps with quadratic constraint accuracy and variable step sizes","abstract":"We construct and analyze a projection-free linearly implicit method for the approximation of flows of harmonic maps into spheres. The proposed method is unconditionally energy stable and, under a sharp discrete regularity condition, achieves second order accuracy with respect to the constraint violation. Furthermore, the method accommodates variable step sizes to speed up the convergence to stationary points and to improve the accuracy of the numerical solutions near singularities, without affecting the unconditional energy stability and the constraint violation property. We illustrate the accuracy in approximating the unit-length constraint and the performance of the method through a series of numerical experiments, and compare it with the linearly implicit Euler and two-step BDF methods.","authors":["Georgios Akrivis","S\\\"oren Bartels","Michele Ruggeri","Jilu Wang"],"url":"https://arxiv.org/abs/2505.05655"}
{"created":"2025-05-12","title":"A Critique of Lin's \"On $\\text{NP}$ versus $\\text{coNP}$ and Frege Systems\"","abstract":"In this paper, we examine Lin's \"On NP versus coNP and Frege Systems\" [Lin25]. Lin claims to prove that $\\text{NP} \\neq \\text{coNP}$ by constructing a language $L_d$ such that $L_d \\in \\text{NP}$ but $L_d \\notin \\text{coNP}$. We present a flaw in Lin's construction of $D$ (a nondeterministic Turing machine that supposedly recognizes $L_d$ in polynomial time). We also provide a proof that $L_d \\not\\in \\text{NP}$. In doing so, we demonstrate that Lin's claim that $\\text{NP} \\neq \\text{coNP}$ is not established by his paper. In addition, we note that a number of further results that Lin claims are not validly established by his paper.","authors":["Nicholas DeJesse","Spencer Lyudovyk","Dhruv Pai","Michael Reidy"],"url":"https://arxiv.org/abs/2505.05658"}
{"created":"2025-05-12","title":"Not Like Us, Hunty: Measuring Perceptions and Behavioral Effects of Minoritized Anthropomorphic Cues in LLMs","abstract":"As large language models (LLMs) increasingly adapt and personalize to diverse sets of users, there is an increased risk of systems appropriating sociolects, i.e., language styles or dialects that are associated with specific minoritized lived experiences (e.g., African American English, Queer slang). In this work, we examine whether sociolect usage by an LLM agent affects user reliance on its outputs and user perception (satisfaction, frustration, trust, and social presence). We designed and conducted user studies where 498 African American English (AAE) speakers and 487 Queer slang speakers performed a set of question-answering tasks with LLM-based suggestions in either standard American English (SAE) or their self-identified sociolect. Our findings showed that sociolect usage by LLMs influenced both reliance and perceptions, though in some surprising ways. Results suggest that both AAE and Queer slang speakers relied more on the SAE agent, and had more positive perceptions of the SAE agent. Yet, only Queer slang speakers felt more social presence from the Queer slang agent over the SAE one, whereas only AAE speakers preferred and trusted the SAE agent over the AAE one. These findings emphasize the need to test for behavioral outcomes rather than simply assume that personalization would lead to a better and safer reliance outcome. They also highlight the nuanced dynamics of minoritized language in machine interactions, underscoring the need for LLMs to be carefully designed to respect cultural and linguistic boundaries while fostering genuine user engagement and trust.","authors":["Jeffrey Basoah","Daniel Chechelnitsky","Tao Long","Katharina Reinecke","Chrysoula Zerva","Kaitlyn Zhou","Mark D\\'iaz","Maarten Sap"],"url":"https://arxiv.org/abs/2505.05660"}
{"created":"2025-05-12","title":"Smart Starts: Accelerating Convergence through Uncommon Region Exploration","abstract":"Initialization profoundly affects evolutionary algorithm (EA) efficacy by dictating search trajectories and convergence. This study introduces a hybrid initialization strategy combining empty-space search algorithm (ESA) and opposition-based learning (OBL). OBL initially generates a diverse population, subsequently augmented by ESA, which identifies under-explored regions. This synergy enhances population diversity, accelerates convergence, and improves EA performance on complex, high-dimensional optimization problems. Benchmark results demonstrate the proposed method's superiority in solution quality and convergence speed compared to conventional initialization techniques.","authors":["Xinyu Zhang","M\\'ario Antunes","Tyler Estro","Erez Zadok","Klaus Mueller"],"url":"https://arxiv.org/abs/2505.05661"}
{"created":"2025-05-12","title":"Adaptive Stress Testing Black-Box LLM Planners","abstract":"Large language models (LLMs) have recently demonstrated success in generalizing across decision-making tasks including planning, control and prediction, but their tendency to hallucinate unsafe and undesired outputs poses risks. We argue that detecting such failures is necessary, especially in safety-critical scenarios. Existing black-box methods often detect hallucinations by identifying inconsistencies across multiple samples. Many of these approaches typically introduce prompt perturbations like randomizing detail order or generating adversarial inputs, with the intuition that a confident model should produce stable outputs. We first perform a manual case study showing that other forms of perturbations (e.g., adding noise, removing sensor details) cause LLMs to hallucinate in a driving environment. We then propose a novel method for efficiently searching the space of prompt perturbations using Adaptive Stress Testing (AST) with Monte-Carlo Tree Search (MCTS). Our AST formulation enables discovery of scenarios and prompts that cause language models to act with high uncertainty. By generating MCTS prompt perturbation trees across diverse scenarios, we show that offline analyses can be used at runtime to automatically generate prompts that influence model uncertainty, and to inform real-time trust assessments of an LLM.","authors":["Neeloy Chakraborty","John Pohovey","Melkior Ornik","Katherine Driggs-Campbell"],"url":"https://arxiv.org/abs/2505.05665"}
{"created":"2025-05-12","title":"Lost in OCR Translation? Vision-Based Approaches to Robust Document Retrieval","abstract":"Retrieval-Augmented Generation (RAG) has become a popular technique for enhancing the reliability and utility of Large Language Models (LLMs) by grounding responses in external documents. Traditional RAG systems rely on Optical Character Recognition (OCR) to first process scanned documents into text. However, even state-of-the-art OCRs can introduce errors, especially in degraded or complex documents. Recent vision-language approaches, such as ColPali, propose direct visual embedding of documents, eliminating the need for OCR. This study presents a systematic comparison between a vision-based RAG system (ColPali) and more traditional OCR-based pipelines utilizing Llama 3.2 (90B) and Nougat OCR across varying document qualities. Beyond conventional retrieval accuracy metrics, we introduce a semantic answer evaluation benchmark to assess end-to-end question-answering performance. Our findings indicate that while vision-based RAG performs well on documents it has been fine-tuned on, OCR-based RAG is better able to generalize to unseen documents of varying quality. We highlight the key trade-offs between computational efficiency and semantic accuracy, offering practical guidance for RAG practitioners in selecting between OCR-dependent and vision-based document retrieval systems in production environments.","authors":["Alexander Most","Joseph Winjum","Ayan Biswas","Shawn Jones","Nishath Rajiv Ranasinghe","Dan O'Malley","Manish Bhattarai"],"url":"https://arxiv.org/abs/2505.05666"}
{"created":"2025-05-12","title":"TeGA: Texture Space Gaussian Avatars for High-Resolution Dynamic Head Modeling","abstract":"Sparse volumetric reconstruction and rendering via 3D Gaussian splatting have recently enabled animatable 3D head avatars that are rendered under arbitrary viewpoints with impressive photorealism. Today, such photoreal avatars are seen as a key component in emerging applications in telepresence, extended reality, and entertainment. Building a photoreal avatar requires estimating the complex non-rigid motion of different facial components as seen in input video images; due to inaccurate motion estimation, animatable models typically present a loss of fidelity and detail when compared to their non-animatable counterparts, built from an individual facial expression. Also, recent state-of-the-art models are often affected by memory limitations that reduce the number of 3D Gaussians used for modeling, leading to lower detail and quality. To address these problems, we present a new high-detail 3D head avatar model that improves upon the state of the art, largely increasing the number of 3D Gaussians and modeling quality for rendering at 4K resolution. Our high-quality model is reconstructed from multiview input video and builds on top of a mesh-based 3D morphable model, which provides a coarse deformation layer for the head. Photoreal appearance is modelled by 3D Gaussians embedded within the continuous UVD tangent space of this mesh, allowing for more effective densification where most needed. Additionally, these Gaussians are warped by a novel UVD deformation field to capture subtle, localized motion. Our key contribution is the novel deformable Gaussian encoding and overall fitting procedure that allows our head model to preserve appearance detail, while capturing facial motion and other transient high-frequency features such as skin wrinkling.","authors":["Gengyan Li","Paulo Gotardo","Timo Bolkart","Stephan Garbin","Kripasindhu Sarkar","Abhimitra Meka","Alexandros Lattas","Thabo Beeler"],"url":"https://arxiv.org/abs/2505.05672"}
{"created":"2025-05-12","title":"An Efficient Transport-Based Dissimilarity Measure for Time Series Classification under Warping Distortions","abstract":"Time Series Classification (TSC) is an important problem with numerous applications in science and technology. Dissimilarity-based approaches, such as Dynamic Time Warping (DTW), are classical methods for distinguishing time series when time deformations are confounding information. In this paper, starting from a deformation-based model for signal classes we define a problem statement for time series classification problem. We show that, under theoretically ideal conditions, a continuous version of classic 1NN-DTW method can solve the stated problem, even when only one training sample is available. In addition, we propose an alternative dissimilarity measure based on Optimal Transport and show that it can also solve the aforementioned problem statement at a significantly reduced computational cost. Finally, we demonstrate the application of the newly proposed approach in simulated and real time series classification data, showing the efficacy of the method.","authors":["Akram Aldroubi","Roc\\'io D\\'iaz Mart\\'in","Ivan Medri","Kristofor E. Pas","Gustavo K. Rohde","Abu Hasnat Mohammad Rubaiyat"],"url":"https://arxiv.org/abs/2505.05676"}
{"created":"2025-05-12","title":"Conditional Front-door Adjustment for Heterogeneous Treatment Assignment Effect Estimation Under Non-adherence","abstract":"Estimates of heterogeneous treatment assignment effects can inform treatment decisions. Under the presence of non-adherence (e.g., patients do not adhere to their assigned treatment), both the standard backdoor adjustment (SBD) and the conditional front-door adjustment (CFD) can recover unbiased estimates of the treatment assignment effects. However, the estimation variance of these approaches may vary widely across settings, which remains underexplored in the literature. In this work, we demonstrate theoretically and empirically that CFD yields lower-variance estimates than SBD when the true effect of treatment assignment is small (i.e., assigning an intervention leads to small changes in patients' future outcome). Additionally, since CFD requires estimating multiple nuisance parameters, we introduce LobsterNet, a multi-task neural network that implements CFD with joint modeling of the nuisance parameters. Empirically, LobsterNet reduces estimation error across several semi-synthetic and real-world datasets compared to baselines. Our findings suggest CFD with shared nuisance parameter modeling can improve treatment assignment effect estimation under non-adherence.","authors":["Winston Chen","Trenton Chang","Jenna Wiens"],"url":"https://arxiv.org/abs/2505.05677"}
{"created":"2025-05-12","title":"InstanceGen: Image Generation with Instance-level Instructions","abstract":"Despite rapid advancements in the capabilities of generative models, pretrained text-to-image models still struggle in capturing the semantics conveyed by complex prompts that compound multiple objects and instance-level attributes. Consequently, we are witnessing growing interests in integrating additional structural constraints, %leveraging additional structural inputs typically in the form of coarse bounding boxes, to better guide the generation process in such challenging cases. In this work, we take the idea of structural guidance a step further by making the observation that contemporary image generation models can directly provide a plausible \\emph{fine-grained} structural initialization. We propose a technique that couples this image-based structural guidance with LLM-based instance-level instructions, yielding output images that adhere to all parts of the text prompt, including object counts, instance-level attributes, and spatial relations between instances.","authors":["Etai Sella","Yanir Kleiman","Hadar Averbuch-Elor"],"url":"https://arxiv.org/abs/2505.05678"}
{"created":"2025-05-12","title":"From Bias To Improved Prompts: A Case Study of Bias Mitigation of Clone Detection Models","abstract":"The issue of clone code has persisted in software engineering, primarily because developers often copy and paste code segments. This common practice has elevated the importance of clone code detection, garnering attention from both software engineering researchers and industry professionals. Their collective concern arises from the potential negative impacts that clone code can have on software quality. The emergence of powerful Generative Large Language Models (LLMs) like ChatGPT has exacerbated the clone code problem. These advanced models possess code generation capabilities that can inadvertently create code clones. As a result, the need to detect clone code has become more critical than ever before. In this study, we assess the suitability of LLMs for clone code detection. Our results demonstrate that the Palm model achieved a high F1 score of 89.30 for the avatar dataset and 86.41 for the poolC dataset. A known issue with LLMs is their susceptibility to prompt bias, where the performance of these models fluctuates based on the input prompt provided. In our research, we delve deeper into the reasons behind these fluctuations and propose a framework to mitigate prompt bias for clone detection. Our analysis identifies eight distinct categories of prompt bias, and our devised approach leveraging these biases yields a significant improvement of up to 10.81% in the F1 score. These findings underscore the substantial impact of prompt bias on the performance of LLMs and highlight the potential for leveraging model errors to alleviate this bias.","authors":["QiHong Chen","Lianghao Jiang","Iftekhar Ahmed"],"url":"https://arxiv.org/abs/2505.05679"}
{"created":"2025-05-12","title":"Fine-Tuning Video-Text Contrastive Model for Primate Behavior Retrieval from Unlabeled Raw Videos","abstract":"Video recordings of nonhuman primates in their natural habitat are a common source for studying their behavior in the wild. We fine-tune pre-trained video-text foundational models for the specific domain of capuchin monkeys, with the goal of developing useful computational models to help researchers to retrieve useful clips from videos. We focus on the challenging problem of training a model based solely on raw, unlabeled video footage, using weak audio descriptions sometimes provided by field collaborators. We leverage recent advances in Multimodal Large Language Models (MLLMs) and Vision-Language Models (VLMs) to address the extremely noisy nature of both video and audio content. Specifically, we propose a two-folded approach: an agentic data treatment pipeline and a fine-tuning process. The data processing pipeline automatically extracts clean and semantically aligned video-text pairs from the raw videos, which are subsequently used to fine-tune a pre-trained Microsoft's X-CLIP model through Low-Rank Adaptation (LoRA). We obtained an uplift in $Hits@5$ of $167\\%$ for the 16 frames model and an uplift of $114\\%$ for the 8 frame model on our domain data. Moreover, based on $NDCG@K$ results, our model is able to rank well most of the considered behaviors, while the tested raw pre-trained models are not able to rank them at all. The code will be made available upon acceptance.","authors":["Giulio Cesare Mastrocinque Santo","Patr\\'icia Izar","Irene Delval","Victor de Napole Gregolin","Nina S. T. Hirata"],"url":"https://arxiv.org/abs/2505.05681"}
{"created":"2025-05-12","title":"Interactive Diabetes Risk Prediction Using Explainable Machine Learning: A Dash-Based Approach with SHAP, LIME, and Comorbidity Insights","abstract":"This study presents a web-based interactive health risk prediction tool designed to assess diabetes risk using machine learning models. Built on the 2015 CDC BRFSS dataset, the study evaluates models including Logistic Regression, Random Forest, XGBoost, LightGBM, KNN, and Neural Networks under original, SMOTE, and undersampling strategies. LightGBM with undersampling achieved the best recall, making it ideal for risk detection. The tool integrates SHAP and LIME to explain predictions and highlights comorbidity correlations using Pearson analysis. A Dash-based UI enables user-friendly interaction with model predictions, personalized suggestions, and feature insights, supporting data-driven health awareness.","authors":["Udaya Allani"],"url":"https://arxiv.org/abs/2505.05683"}
{"created":"2025-05-12","title":"Prompted Meta-Learning for Few-shot Knowledge Graph Completion","abstract":"Few-shot knowledge graph completion (KGC) has obtained significant attention due to its practical applications in real-world scenarios, where new knowledge often emerges with limited available data. While most existing methods for few-shot KGC have predominantly focused on leveraging relational information, rich semantics inherent in KGs have been largely overlooked. To address this gap, we propose a novel prompted meta-learning (PromptMeta) framework that seamlessly integrates meta-semantics with relational information for few-shot KGC. PrompMeta has two key innovations: (1) a meta-semantic prompt pool that captures and consolidates high-level meta-semantics, enabling effective knowledge transfer and adaptation to rare and newly emerging relations. (2) a learnable fusion prompt that dynamically combines meta-semantic information with task-specific relational information tailored to different few-shot tasks. Both components are optimized together with model parameters within a meta-learning framework. Extensive experiments on two benchmark datasets demonstrate the effectiveness of our approach.","authors":["Han Wu","Jie Yin"],"url":"https://arxiv.org/abs/2505.05684"}
{"created":"2025-05-12","title":"Zippy: The smallest power-autonomous bipedal robot","abstract":"Miniaturizing legged robot platforms is challenging due to hardware limitations that constrain the number, power density, and precision of actuators at that size. By leveraging design principles of quasi-passive walking robots at any scale, stable locomotion and steering can be achieved with simple mechanisms and open-loop control. Here, we present the design and control of \"Zippy\", the smallest self-contained bipedal walking robot at only 3.6 cm tall. Zippy has rounded feet, a single motor without feedback control, and is capable of turning, skipping, and ascending steps. At its fastest pace, the robot achieves a forward walking speed of 25 cm/s, which is 10 leg lengths per second, the fastest biped robot of any size by that metric. This work explores the design and performance of the robot and compares it to similar dynamic walking robots at larger scales.","authors":["Steven Man","Soma Narita","Josef Macera","Naomi Oke","Aaron M. Johnson","Sarah Bergbreiter"],"url":"https://arxiv.org/abs/2505.05686"}
{"created":"2025-05-12","title":"Exploration of COVID-19 Discourse on Twitter: American Politician Edition","abstract":"The advent of the COVID-19 pandemic has undoubtedly affected the political scene worldwide and the introduction of new terminology and public opinions regarding the virus has further polarized partisan stances. Using a collection of tweets gathered from leading American political figures online (Republican and Democratic), we explored the partisan differences in approach, response, and attitude towards handling the international crisis. Implementation of the bag-of-words, bigram, and TF-IDF models was used to identify and analyze keywords, topics, and overall sentiments from each party. Results suggest that Democrats are more concerned with the casualties of the pandemic, and give more medical precautions and recommendations to the public whereas Republicans are more invested in political responsibilities such as keeping the public updated through media and carefully watching the progress of the virus. We propose a systematic approach to predict and distinguish a tweet's political stance (left or right leaning) based on its COVID-19 related terms using different classification algorithms on different language models.","authors":["Cindy Kim","Daniela Puchall","Jiangyi Liang","Jiwon Kim"],"url":"https://arxiv.org/abs/2505.05687"}
{"created":"2025-05-12","title":"Physics-informed Temporal Difference Metric Learning for Robot Motion Planning","abstract":"The motion planning problem involves finding a collision-free path from a robot's starting to its target configuration. Recently, self-supervised learning methods have emerged to tackle motion planning problems without requiring expensive expert demonstrations. They solve the Eikonal equation for training neural networks and lead to efficient solutions. However, these methods struggle in complex environments because they fail to maintain key properties of the Eikonal equation, such as optimal value functions and geodesic distances. To overcome these limitations, we propose a novel self-supervised temporal difference metric learning approach that solves the Eikonal equation more accurately and enhances performance in solving complex and unseen planning tasks. Our method enforces Bellman's principle of optimality over finite regions, using temporal difference learning to avoid spurious local minima while incorporating metric learning to preserve the Eikonal equation's essential geodesic properties. We demonstrate that our approach significantly outperforms existing self-supervised learning methods in handling complex environments and generalizing to unseen environments, with robot configurations ranging from 2 to 12 degrees of freedom (DOF).","authors":["Ruiqi Ni","Zherong Pan","Ahmed H Qureshi"],"url":"https://arxiv.org/abs/2505.05691"}
{"created":"2025-05-12","title":"Design of a molecular Field Effect Transistor (mFET)","abstract":"Field Effect Transistors (FETs) are ubiquitous in electronics. As we scale FETs to ever smaller sizes, it becomes natural to ask how small a practical FET might be. We propose and analyze an atomically precise molecular FET (herein referred to as an \"mFET\") with 7,694 atoms made only of hydrogen and carbon atoms. It uses metallic (4,4) carbon nanotubes as the conductive leads, a linear segment of Lonsdaleite (hexagonal diamond) as the channel, Lonsdaleite as the insulating layer between the channel and the gate, and a (20,20) metallic carbon nanotube as the surrounding gate. The (4,4) nanotube leads are bonded to the channel using a mix of 5- and 6-membered rings, and to the gate using 5-, 6- and 7-membered rings. Issues of component design assessment and optimization using quantum chemical methods are discussed throughout. A 10 watt sugar-cube-sized computer made with $10^{18}$ such mFETs could deliver $\\sim 10^{25}$ switching operations per second.","authors":["Ralph C. Merkle","Robert A. Freitas Jr.","Damian G. Allis"],"url":"https://arxiv.org/abs/2505.05693"}
{"created":"2025-05-12","title":"Extending Stress Detection Reproducibility to Consumer Wearable Sensors","abstract":"Wearable sensors are widely used to collect physiological data and develop stress detection models. However, most studies focus on a single dataset, rarely evaluating model reproducibility across devices, populations, or study conditions. We previously assessed the reproducibility of stress detection models across multiple studies, testing models trained on one dataset against others using heart rate (with R-R interval) and electrodermal activity (EDA). In this study, we extended our stress detection reproducibility to consumer wearable sensors. We compared validated research-grade devices, to consumer wearables - Biopac MP160, Polar H10, Empatica E4, to the Garmin Forerunner 55s, assessing device-specific stress detection performance by conducting a new stress study on undergraduate students. Thirty-five students completed three standardized stress-induction tasks in a lab setting. Biopac MP160 performed the best, being consistent with our expectations of it as the gold standard, though performance varied across devices and models. Combining heart rate variability (HRV) and EDA enhanced stress prediction across most scenarios. However, Empatica E4 showed variability; while HRV and EDA improved stress detection in leave-one-subject-out (LOSO) evaluations (AUROC up to 0.953), device-specific limitations led to underperformance when tested with our pre-trained stress detection tool (AUROC 0.723), highlighting generalizability challenges related to hardware-model compatibility. Garmin Forerunner 55s demonstrated strong potential for real-world stress monitoring, achieving the best mental arithmetic stress detection performance in LOSO (AUROC up to 0.961) comparable to research-grade devices like Polar H10 (AUROC 0.954), and Empatica E4 (AUROC 0.905 with HRV-only model and AUROC 0.953 with HRV+EDA model), with the added advantage of consumer-friendly wearability for free-living contexts.","authors":["Ohida Binte Amin","Varun Mishra","Tinashe M. Tapera","Robert Volpe","Aarti Sathyanarayana"],"url":"https://arxiv.org/abs/2505.05694"}
{"created":"2025-05-12","title":"Bringing Forensic Readiness to Modern Computer Firmware","abstract":"Today's computer systems come with a pre-installed tiny operating system, which is also known as UEFI. UEFI has slowly displaced the former legacy PC-BIOS while the main task has not changed: It is responsible for booting the actual operating system. However, features like the network stack make it also useful for other applications. This paper introduces UEberForensIcs, a UEFI application that makes it easy to acquire memory from the firmware, similar to the well-known cold boot attacks. There is even UEFI code called by the operating system during runtime, and we demonstrate how to utilize this for forensic purposes.","authors":["Tobias Latzo","Florian Hantke","Lukas Kotschi","Felix Freiling"],"url":"https://arxiv.org/abs/2505.05697"}
{"created":"2025-05-12","title":"Pretraining a Shared Q-Network for Data-Efficient Offline Reinforcement Learning","abstract":"Offline reinforcement learning (RL) aims to learn a policy from a static dataset without further interactions with the environment. Collecting sufficiently large datasets for offline RL is exhausting since this data collection requires colossus interactions with environments and becomes tricky when the interaction with the environment is restricted. Hence, how an agent learns the best policy with a minimal static dataset is a crucial issue in offline RL, similar to the sample efficiency problem in online RL. In this paper, we propose a simple yet effective plug-and-play pretraining method to initialize a feature of a $Q$-network to enhance data efficiency in offline RL. Specifically, we introduce a shared $Q$-network structure that outputs predictions of the next state and $Q$-value. We pretrain the shared $Q$-network through a supervised regression task that predicts a next state and trains the shared $Q$-network using diverse offline RL methods. Through extensive experiments, we empirically demonstrate that our method enhances the performance of existing popular offline RL methods on the D4RL, Robomimic and V-D4RL benchmarks. Furthermore, we show that our method significantly boosts data-efficient offline RL across various data qualities and data distributions trough D4RL and ExoRL benchmarks. Notably, our method adapted with only 10% of the dataset outperforms standard algorithms even with full datasets.","authors":["Jongchan Park","Mingyu Park","Donghwan Lee"],"url":"https://arxiv.org/abs/2505.05701"}
{"created":"2025-05-12","title":"Hypergraph Neural Sheaf Diffusion: A Symmetric Simplicial Set Framework for Higher-Order Learning","abstract":"The absence of intrinsic adjacency relations and orientation systems in hypergraphs creates fundamental challenges for constructing sheaf Laplacians of arbitrary degrees. We resolve these limitations through symmetric simplicial sets derived directly from hypergraphs, which encode all possible oriented subrelations within each hyperedge as ordered tuples. This construction canonically defines adjacency via facet maps while inherently preserving hyperedge provenance. We establish that the normalized degree zero sheaf Laplacian on our induced symmetric simplicial set reduces exactly to the traditional graph normalized sheaf Laplacian when restricted to graphs, validating its mathematical consistency with prior graph-based sheaf theory. Furthermore, the induced structure preserves all structural information from the original hypergraph, ensuring that every multi-way relational detail is faithfully retained. Leveraging this framework, we introduce Hypergraph Neural Sheaf Diffusion (HNSD), the first principled extension of Neural Sheaf Diffusion (NSD) to hypergraphs. HNSD operates via normalized degree zero sheaf Laplacians over symmetric simplicial sets, resolving orientation ambiguity and adjacency sparsity inherent to hypergraph learning. Experimental evaluations demonstrate HNSD's competitive performance across established benchmarks.","authors":["Seongjin Choi","Gahee Kim","Yong-Geun Oh"],"url":"https://arxiv.org/abs/2505.05702"}
{"created":"2025-05-12","title":"Assessing Robustness to Spurious Correlations in Post-Training Language Models","abstract":"Supervised and preference-based fine-tuning techniques have become popular for aligning large language models (LLMs) with user intent and correctness criteria. However, real-world training data often exhibits spurious correlations -- arising from biases, dataset artifacts, or other \"shortcut\" features -- that can compromise a model's performance or generalization. In this paper, we systematically evaluate three post-training algorithms -- Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and KTO (Kahneman-Tversky Optimization) -- across a diverse set of synthetic tasks and spuriousness conditions. Our tasks span mathematical reasoning, constrained instruction-following, and document-grounded question answering. We vary the degree of spurious correlation (10% vs. 90%) and investigate two forms of artifacts: \"Feature Ambiguity\" and \"Distributional Narrowness.\" Our results show that the models often but not always degrade under higher spuriousness. The preference-based methods (DPO/KTO) can demonstrate relative robustness in mathematical reasoning tasks. By contrast, SFT maintains stronger performance in complex, context-intensive tasks. These findings highlight that no single post-training strategy universally outperforms in all scenarios; the best choice depends on the type of target task and the nature of spurious correlations.","authors":["Julia Shuieh","Prasann Singhal","Apaar Shanker","John Heyer","George Pu","Samuel Denton"],"url":"https://arxiv.org/abs/2505.05704"}
{"created":"2025-05-12","title":"Crowding Out The Noise: Algorithmic Collective Action Under Differential Privacy","abstract":"The integration of AI into daily life has generated considerable attention and excitement, while also raising concerns about automating algorithmic harms and re-entrenching existing social inequities. While the responsible deployment of trustworthy AI systems is a worthy goal, there are many possible ways to realize it, from policy and regulation to improved algorithm design and evaluation. In fact, since AI trains on social data, there is even a possibility for everyday users, citizens, or workers to directly steer its behavior through Algorithmic Collective Action, by deliberately modifying the data they share with a platform to drive its learning process in their favor. This paper considers how these grassroots efforts to influence AI interact with methods already used by AI firms and governments to improve model trustworthiness. In particular, we focus on the setting where the AI firm deploys a differentially private model, motivated by the growing regulatory focus on privacy and data protection. We investigate how the use of Differentially Private Stochastic Gradient Descent (DPSGD) affects the collective's ability to influence the learning process. Our findings show that while differential privacy contributes to the protection of individual data, it introduces challenges for effective algorithmic collective action. We characterize lower bounds on the success of algorithmic collective action under differential privacy as a function of the collective's size and the firm's privacy parameters, and verify these trends experimentally by simulating collective action during the training of deep neural network classifiers across several datasets.","authors":["Rushabh Solanki","Meghana Bhange","Ulrich A\\\"ivodji","Elliot Creager"],"url":"https://arxiv.org/abs/2505.05707"}
{"created":"2025-05-12","title":"Discrete Budget Aggregation: Truthfulness and Proportionality","abstract":"We study a budget aggregation setting where voters express their preferred allocation of a fixed budget over a set of alternatives, and a mechanism aggregates these preferences into a single output allocation. Motivated by scenarios in which the budget is not perfectly divisible, we depart from the prevailing literature by restricting the mechanism to output allocations that assign integral amounts. This seemingly minor deviation has significant implications for the existence of truthful mechanisms. Specifically, when voters can propose fractional allocations, we demonstrate that the Gibbard-Satterthwaite theorem can be extended to our setting. In contrast, when voters are restricted to integral ballots, we identify a class of truthful mechanisms by adapting moving-phantom mechanisms to our context. Moreover, we show that while a weak form of proportionality can be achieved alongside truthfulness, (stronger) proportionality notions derived from approval-based committee voting are incompatible with truthfulness.","authors":["Ulrike Schmidt-Kraepelin","Warut Suksompong","Markus Utke"],"url":"https://arxiv.org/abs/2505.05708"}
{"created":"2025-05-12","title":"HyperspectralMAE: The Hyperspectral Imagery Classification Model using Fourier-Encoded Dual-Branch Masked Autoencoder","abstract":"Hyperspectral imagery provides rich spectral detail but poses unique challenges because of its high dimensionality in both spatial and spectral domains. We propose \\textit{HyperspectralMAE}, a Transformer-based foundation model for hyperspectral data that employs a \\textit{dual masking} strategy: during pre-training we randomly occlude 50\\% of spatial patches and 50\\% of spectral bands. This forces the model to learn representations capable of reconstructing missing information across both dimensions. To encode spectral order, we introduce learnable harmonic Fourier positional embeddings based on wavelength. The reconstruction objective combines mean-squared error (MSE) with the spectral angle mapper (SAM) to balance pixel-level accuracy and spectral-shape fidelity.","authors":["Wooyoung Jeong","Hyun Jae Park","Seonghun Jeong","Jong Wook Jang","Tae Hoon Lim","Dae Seoung Kim"],"url":"https://arxiv.org/abs/2505.05710"}
{"created":"2025-05-12","title":"DiGIT: Multi-Dilated Gated Encoder and Central-Adjacent Region Integrated Decoder for Temporal Action Detection Transformer","abstract":"In this paper, we examine a key limitation in query-based detectors for temporal action detection (TAD), which arises from their direct adaptation of originally designed architectures for object detection. Despite the effectiveness of the existing models, they struggle to fully address the unique challenges of TAD, such as the redundancy in multi-scale features and the limited ability to capture sufficient temporal context. To address these issues, we propose a multi-dilated gated encoder and central-adjacent region integrated decoder for temporal action detection transformer (DiGIT). Our approach replaces the existing encoder that consists of multi-scale deformable attention and feedforward network with our multi-dilated gated encoder. Our proposed encoder reduces the redundant information caused by multi-level features while maintaining the ability to capture fine-grained and long-range temporal information. Furthermore, we introduce a central-adjacent region integrated decoder that leverages a more comprehensive sampling strategy for deformable cross-attention to capture the essential information. Extensive experiments demonstrate that DiGIT achieves state-of-the-art performance on THUMOS14, ActivityNet v1.3, and HACS-Segment. Code is available at: https://github.com/Dotori-HJ/DiGIT","authors":["Ho-Joong Kim","Yearang Lee","Jung-Ho Hong","Seong-Whan Lee"],"url":"https://arxiv.org/abs/2505.05711"}
{"created":"2025-05-12","title":"LLM-Text Watermarking based on Lagrange Interpolation","abstract":"The rapid advancement of LLMs (Large Language Models) has established them as a foundational technology for many AI and ML powered human computer interactions. A critical challenge in this context is the attribution of LLM-generated text, either to the specific language model used or to the individual user who generated it. This is essential for combating misinformation, fake news, misinterpretation, and plagiarism. One of the key techniques for addressing this issue is watermarking.","authors":["Jaros{\\l}aw Janas","Pawe{\\l} Morawiecki","Josef Pieprzyk"],"url":"https://arxiv.org/abs/2505.05712"}
{"created":"2025-05-12","title":"Understanding Stragglers in Large Model Training Using What-if Analysis","abstract":"Large language model (LLM) training is one of the most demanding distributed computations today, often requiring thousands of GPUs with frequent synchronization across machines. Such a workload pattern makes it susceptible to stragglers, where the training can be stalled by few slow workers. At ByteDance we find stragglers are not trivially always caused by hardware failures, but can arise from multiple complex factors. This work aims to present a comprehensive study on the straggler issues in LLM training, using a five-month trace collected from our ByteDance LLM training cluster. The core methodology is what-if analysis that simulates the scenario without any stragglers and contrasts with the actual case. We use this method to study the following questions: (1) how often do stragglers affect training jobs, and what effect do they have on job performance; (2) do stragglers exhibit temporal or spatial patterns; and (3) what are the potential root causes for stragglers?","authors":["Jinkun Lin","Ziheng Jiang","Zuquan Song","Sida Zhao","Menghan Yu","Zhanghan Wang","Chenyuan Wang","Zuocheng Shi","Xiang Shi","Wei Jia","Zherui Liu","Shuguang Wang","Haibin Lin","Xiu Liu","Aurojit Panda","Jinyang Li"],"url":"https://arxiv.org/abs/2505.05713"}
{"created":"2025-05-12","title":"TopicVD: A Topic-Based Dataset of Video-Guided Multimodal Machine Translation for Documentaries","abstract":"Most existing multimodal machine translation (MMT) datasets are predominantly composed of static images or short video clips, lacking extensive video data across diverse domains and topics. As a result, they fail to meet the demands of real-world MMT tasks, such as documentary translation. In this study, we developed TopicVD, a topic-based dataset for video-supported multimodal machine translation of documentaries, aiming to advance research in this field. We collected video-subtitle pairs from documentaries and categorized them into eight topics, such as economy and nature, to facilitate research on domain adaptation in video-guided MMT. Additionally, we preserved their contextual information to support research on leveraging the global context of documentaries in video-guided MMT. To better capture the shared semantics between text and video, we propose an MMT model based on a cross-modal bidirectional attention module. Extensive experiments on the TopicVD dataset demonstrate that visual information consistently improves the performance of the NMT model in documentary translation. However, the MMT model's performance significantly declines in out-of-domain scenarios, highlighting the need for effective domain adaptation methods. Additionally, experiments demonstrate that global context can effectively improve translation performance. % Dataset and our implementations are available at https://github.com/JinzeLv/TopicVD","authors":["Jinze Lv","Jian Chen","Zi Long","Xianghua Fu","Yin Chen"],"url":"https://arxiv.org/abs/2505.05714"}
{"created":"2025-05-12","title":"JustinANN: Realistic Test Generation for Java Programs Driven by Annotations","abstract":"Automated test case generation is important. However, the automatically generated test input does not always make sense, and the automated assertion is difficult to validate against the program under test. In this paper, we propose JustinANN, a flexible and scalable tool to generate test cases for Java programs, providing realistic test inputs and assertions. We have observed that, in practice, Java programs contain a large number of annotations from programs, which can be considered as part of the user specification. We design a systematic annotation set with 7 kinds of annotations and 4 combination rules based on them to modify complex Java objects. Annotations that modify the fields or return variables of methods can be used to generate assertions that represent the true intent of the program, and the ones that modify the input parameters can be used to generate test inputs that match the real business requirement. We have conducted experiments to evaluate the approach on open source Java programs. The results show that the annotations and their combinations designed in this paper are compatible with existing annotations; our approach is easier to generate test data in, on and outside the boundaries of the requirement domain; and it also helps to find program defects.","authors":["Baoquan Cui","Rong Qu","Jian Zhang"],"url":"https://arxiv.org/abs/2505.05715"}
{"created":"2025-05-12","title":"Robust Management of Airport Security Queues Considering Passenger Non-compliance with Chance-Constrained Optimization","abstract":"The long waiting time at airport security has become an emergent issue as demand for air travel continues to grow. Not only does queuing at security cause passengers to miss their flights, but also reduce the amount of time passengers spend at the airport post-security, potentially leading to less revenue for the airport operator. One of the key issues to address to reduce waiting time is the management of arrival priority. As passengers on later flights can arrive before passengers on earlier flights, the security system does not always process passengers in the order of the degree of urgency. In this paper, we propose a chance-constrained optimization model that decides in which time slot passengers should be recommended to arrive. We use chance constraints to obtain solutions that take the uncertainty in passenger non-compliance into account. The experimental results, based on a sample day of flight schedules at the Barcelona airport, show a reduction of 85% in the total waiting time. Compared to the deterministic case, in which passengers are assumed to fully comply with the recommendations, we see a 30% increase in the reduction of the total waiting time. This highlights the importance of considering variation in passenger compliance in the management of airport security queues.","authors":["Shangqing Cao","Aparimit Kasliwal","Huangyi Zheng","Masoud Reihanifar","Francesc Robuste","Mark Hansen"],"url":"https://arxiv.org/abs/2505.05717"}
{"created":"2025-05-12","title":"Semantic-Space-Intervened Diffusive Alignment for Visual Classification","abstract":"Cross-modal alignment is an effective approach to improving visual classification. Existing studies typically enforce a one-step mapping that uses deep neural networks to project the visual features to mimic the distribution of textual features. However, they typically face difficulties in finding such a projection due to the two modalities in both the distribution of class-wise samples and the range of their feature values. To address this issue, this paper proposes a novel Semantic-Space-Intervened Diffusive Alignment method, termed SeDA, models a semantic space as a bridge in the visual-to-textual projection, considering both types of features share the same class-level information in classification. More importantly, a bi-stage diffusion framework is developed to enable the progressive alignment between the two modalities. Specifically, SeDA first employs a Diffusion-Controlled Semantic Learner to model the semantic features space of visual features by constraining the interactive features of the diffusion model and the category centers of visual features. In the later stage of SeDA, the Diffusion-Controlled Semantic Translator focuses on learning the distribution of textual features from the semantic space. Meanwhile, the Progressive Feature Interaction Network introduces stepwise feature interactions at each alignment step, progressively integrating textual information into mapped features. Experimental results show that SeDA achieves stronger cross-modal feature alignment, leading to superior performance over existing methods across multiple scenarios.","authors":["Zixuan Li","Lei Meng","Guoqing Chao","Wei Wu","Xiaoshuo Yan","Yimeng Yang","Zhuang Qi","Xiangxu Meng"],"url":"https://arxiv.org/abs/2505.05721"}
{"created":"2025-05-12","title":"You Are Your Best Teacher: Semi-Supervised Surgical Point Tracking with Cycle-Consistent Self-Distillation","abstract":"Synthetic datasets have enabled significant progress in point tracking by providing large-scale, densely annotated supervision. However, deploying these models in real-world domains remains challenging due to domain shift and lack of labeled data-issues that are especially severe in surgical videos, where scenes exhibit complex tissue deformation, occlusion, and lighting variation. While recent approaches adapt synthetic-trained trackers to natural videos using teacher ensembles or augmentation-heavy pseudo-labeling pipelines, their effectiveness in high-shift domains like surgery remains unexplored. This work presents SurgTracker, a semi-supervised framework for adapting synthetic-trained point trackers to surgical video using filtered self-distillation. Pseudo-labels are generated online by a fixed teacher-identical in architecture and initialization to the student-and are filtered using a cycle consistency constraint to discard temporally inconsistent trajectories. This simple yet effective design enforces geometric consistency and provides stable supervision throughout training, without the computational overhead of maintaining multiple teachers. Experiments on the STIR benchmark show that SurgTracker improves tracking performance using only 80 unlabeled videos, demonstrating its potential for robust adaptation in high-shift, data-scarce domains.","authors":["Valay Bundele","Mehran Hosseinzadeh","Hendrik Lensch"],"url":"https://arxiv.org/abs/2505.05722"}
{"created":"2025-05-12","title":"Unfitted finite element modelling of surface-bulk viscous flows in animal cells","abstract":"This work presents a novel unfitted finite element framework to simulate coupled surface-bulk problems in time-dependent domains, focusing on fluid-fluid interactions in animal cells between the actomyosin cortex and the cytoplasm. The cortex, a thin layer beneath the plasma membrane, provides structural integrity and drives shape changes by generating surface contractile forces akin to tension. Cortical contractions generate Marangoni-like surface flows and induce intracellular cytoplasmic flows that are essential for processes such as cell division, migration, and polarization, particularly in large animal cells. Despite its importance, the spatiotemporal regulation of cortex-cytoplasm interactions remains poorly understood and computational modelling can be very challenging because surface-bulk dynamics often lead to large cell deformations. To address these challenges, we propose a sharp-interface framework that uniquely combines the trace finite element method for surface flows with the aggregated finite element method for bulk flows. This approach enables accurate and stable simulations on fixed Cartesian grids without remeshing. The model also incorporates mechanochemical feedback through the surface transport of a molecular regulator of active tension. We solve the resulting mixed-dimensional system on a fixed Cartesian grid using a level-set-based method to track the evolving surface. Numerical experiments validate the accuracy and stability of the method, capturing phenomena such as self-organised pattern formation, curvature-driven relaxation, and cell cleavage. This novel framework offers a powerful and extendable tool for investigating increasingly complex morphogenetic processes in animal cells.","authors":["Eric Neiva","Herv\\'e Turlier"],"url":"https://arxiv.org/abs/2505.05723"}
{"created":"2025-05-12","title":"Towards Secure Semantic Transmission In the Era of GenAI: A Diffusion-based Framework","abstract":"Semantic communication, due to its focus on the transmitting meaning rather than the raw bit data, poses unique security challenges compared to the traditional communication systems. In particular, semantic communication systems are vulnerable to the malicious attacks that focus on the semantic layer, with the intention of understanding or distorting the intended meaning of the transmitted privacy data. Diffusion models, a class of generative artificial intelligence (GenAI), are well-suited for ensuring data security to attack. Through iteratively adding and then removing noise, diffusion models can generate meaningful information despite the presence of the unknown noise. This article proposes a diffusion-based framework to enhance the security of semantic transmission for the attacks including eavesdropping and jamming. Specifically, the proposed framework incorporates both the artificial noise and natural channel noise into the forward process of the diffusion models during the semantic transmission, with the reverse process used to remove noise at the legitimate receiver. In the eavesdropping scenarios, the artificial noise is the friendly noise designed to prevent semantic eavesdropping. In the jamming scenarios, the artificial noise is the malicious jamming generated by the jammer, which disrupts the semantic transmission. The case studies show that the proposed diffusion-based framework is promising in securing the semantic transmission. We also consolidate several broad research directions associated with the proposed framework.","authors":["Boxiang He","Zihan Chen","Junshan Luo","Chuanhong Liu","Shilian Wang","Fanggang Wang","Tony Q. S. Quek"],"url":"https://arxiv.org/abs/2505.05724"}
{"created":"2025-05-12","title":"Quantitative Hardness Assessment with Vision-based Tactile Sensing for Fruit Classification and Grasping","abstract":"Accurate estimation of fruit hardness is essential for automated classification and handling systems, particularly in determining fruit variety, assessing ripeness, and ensuring proper harvesting force. This study presents an innovative framework for quantitative hardness assessment utilizing vision-based tactile sensing, tailored explicitly for robotic applications in agriculture. The proposed methodology derives normal force estimation from a vision-based tactile sensor, and, based on the dynamics of this normal force, calculates the hardness. This approach offers a rapid, non-destructive evaluation through single-contact interaction. The integration of this framework into robotic systems enhances real-time adaptability of grasping forces, thereby reducing the likelihood of fruit damage. Moreover, the general applicability of this approach, through a universal criterion based on average normal force dynamics, ensures its effectiveness across a wide variety of fruit types and sizes. Extensive experimental validation conducted across different fruit types and ripeness-tracking studies demonstrates the efficacy and robustness of the framework, marking a significant advancement in the domain of automated fruit handling.","authors":["Zhongyuan Liao","Yipai Du","Jianghua Duan","Haobo Liang","Michael Yu Wang"],"url":"https://arxiv.org/abs/2505.05725"}
{"created":"2025-05-12","title":"Connected C-Core Hybrid SRMs for EV Applications","abstract":"This paper proposes a new class of permanent magnet-assisted three-phase switched reluctance motors (PM-SRMs) designed to achieve significantly higher torque density for electric vehicle (EV) propulsion systems. Eight distinct motor topologies are systematically investigated, including a non-PM baseline design, three innovative PM arrangement strategies, and two optimized rotor/stator teeth configurations (22-pole and 26-pole variants). The study presents analytical models including magnetic equivalent circuits (MECs), detailed operating principles, and generalized design formulations that account for both electromagnetic and structural considerations. A key contribution is the introduction of the point-of-conversion (PoC) concept, which optimizes PM placement by minimizing magnetic path reluctance. Comparative analysis demonstrates torque density improvements over conventional SRMs and existing PM-assisted designs while maintaining structural robustness. Experimental validation confirms that the proposed 24/22 configuration with inter-phase PMs delivers higher torque per PM volume compared to state-of-the-art designs. The findings provide insights for EV motor designers seeking to balance performance, cost, and reliability.","authors":["Gholamreza Davarpanah","Sajjad Mohammadi"],"url":"https://arxiv.org/abs/2505.05726"}
{"created":"2025-05-12","title":"A High-Dimensional Feature Selection Algorithm Based on Multiobjective Differential Evolution","abstract":"Multiobjective feature selection seeks to determine the most discriminative feature subset by simultaneously optimizing two conflicting objectives: minimizing the number of selected features and the classification error rate. The goal is to enhance the model's predictive performance and computational efficiency. However, feature redundancy and interdependence in high-dimensional data present considerable obstacles to the search efficiency of optimization algorithms and the quality of the resulting solutions. To tackle these issues, we propose a high-dimensional feature selection algorithm based on multiobjective differential evolution. First, a population initialization strategy is designed by integrating feature weights and redundancy indices, where the population is divided into four subpopulations to improve the diversity and uniformity of the initial population. Then, a multiobjective selection mechanism is developed, in which feature weights guide the mutation process. The solution quality is further enhanced through nondominated sorting, with preference given to solutions with lower classification error, effectively balancing global exploration and local exploitation. Finally, an adaptive grid mechanism is applied in the objective space to identify densely populated regions and detect duplicated solutions. Experimental results on 11 UCI datasets of varying difficulty demonstrate that the proposed method significantly outperforms several state-of-the-art multiobjective feature selection approaches regarding feature selection performance.","authors":["Zhenxing Zhang","Qianxiang An","Yilei Wang","Chenfeng Wu","Baoling Dong","Chunjie Zhou"],"url":"https://arxiv.org/abs/2505.05727"}
{"created":"2025-05-12","title":"Automated Learning of Semantic Embedding Representations for Diffusion Models","abstract":"Generative models capture the true distribution of data, yielding semantically rich representations. Denoising diffusion models (DDMs) exhibit superior generative capabilities, though efficient representation learning for them are lacking. In this work, we employ a multi-level denoising autoencoder framework to expand the representation capacity of DDMs, which introduces sequentially consistent Diffusion Transformers and an additional timestep-dependent encoder to acquire embedding representations on the denoising Markov chain through self-conditional diffusion learning. Intuitively, the encoder, conditioned on the entire diffusion process, compresses high-dimensional data into directional vectors in latent under different noise levels, facilitating the learning of image embeddings across all timesteps. To verify the semantic adequacy of embeddings generated through this approach, extensive experiments are conducted on various datasets, demonstrating that optimally learned embeddings by DDMs surpass state-of-the-art self-supervised representation learning methods in most cases, achieving remarkable discriminative semantic representation quality. Our work justifies that DDMs are not only suitable for generative tasks, but also potentially advantageous for general-purpose deep learning applications.","authors":["Limai Jiang","Yunpeng Cai"],"url":"https://arxiv.org/abs/2505.05732"}
{"created":"2025-05-12","title":"All-to-All Communication with Mobile Edge Adversary: Almost Linearly More Faults, For Free","abstract":"Resilient computation in all-to-all-communication models has attracted tremendous attention over the years. Most of these works assume the classical faulty model which restricts the total number of corrupted edges (or vertices) by some integer fault parameter $f$. A recent work by [Bodwin, Haeupler and Parter, SODA 2024] introduced a stronger notion of fault-tolerance, in the context of graph sparsification, which restricts the degree of the failing edge set $F$, rather than its cardinality. For a subset of faulty edges $F$, the faulty-degree $\\mathrm{deg}(F)$ is the largest number of faults in $F$ incident to any given node.","authors":["Orr Fischer","Merav Parter"],"url":"https://arxiv.org/abs/2505.05735"}
{"created":"2025-05-12","title":"Accurate and Efficient Multivariate Time Series Forecasting via Offline Clustering","abstract":"Accurate and efficient multivariate time series (MTS) forecasting is essential for applications such as traffic management and weather prediction, which depend on capturing long-range temporal dependencies and interactions between entities. Existing methods, particularly those based on Transformer architectures, compute pairwise dependencies across all time steps, leading to a computational complexity that scales quadratically with the length of the input. To overcome these challenges, we introduce the Forecaster with Offline Clustering Using Segments (FOCUS), a novel approach to MTS forecasting that simplifies long-range dependency modeling through the use of prototypes extracted via offline clustering. These prototypes encapsulate high-level events in the real-world system underlying the data, summarizing the key characteristics of similar time segments. In the online phase, FOCUS dynamically adapts these patterns to the current input and captures dependencies between the input segment and high-level events, enabling both accurate and efficient forecasting. By identifying prototypes during the offline clustering phase, FOCUS reduces the computational complexity of modeling long-range dependencies in the online phase to linear scaling. Extensive experiments across diverse benchmarks demonstrate that FOCUS achieves state-of-the-art accuracy while significantly reducing computational costs.","authors":["Yiming Niu","Jinliang Deng","Lulu Zhang","Zimu Zhou","Yongxin Tong"],"url":"https://arxiv.org/abs/2505.05738"}
{"created":"2025-05-12","title":"Deep-ICE: The first globally optimal algorithm for empirical risk minimization of two-layer maxout and ReLU networks","abstract":"This paper introduces the first globally optimal algorithm for the empirical risk minimization problem of two-layer maxout and ReLU networks, i.e., minimizing the number of misclassifications. The algorithm has a worst-case time complexity of $O\\left(N^{DK+1}\\right)$, where $K$ denotes the number of hidden neurons and $D$ represents the number of features. It can be can be generalized to accommodate arbitrary computable loss functions without affecting its computational complexity. Our experiments demonstrate that the proposed algorithm provides provably exact solutions for small-scale datasets. To handle larger datasets, we introduce a novel coreset selection method that reduces the data size to a manageable scale, making it feasible for our algorithm. This extension enables efficient processing of large-scale datasets and achieves significantly improved performance, with a 20-30\\% reduction in misclassifications for both training and prediction, compared to state-of-the-art approaches (neural networks trained using gradient descent and support vector machines), when applied to the same models (two-layer networks with fixed hidden nodes and linear models).","authors":["Xi He","Yi Miao","Max A. Little"],"url":"https://arxiv.org/abs/2505.05740"}
{"created":"2025-05-12","title":"Dome-DETR: DETR with Density-Oriented Feature-Query Manipulation for Efficient Tiny Object Detection","abstract":"Tiny object detection plays a vital role in drone surveillance, remote sensing, and autonomous systems, enabling the identification of small targets across vast landscapes. However, existing methods suffer from inefficient feature leverage and high computational costs due to redundant feature processing and rigid query allocation. To address these challenges, we propose Dome-DETR, a novel framework with Density-Oriented Feature-Query Manipulation for Efficient Tiny Object Detection. To reduce feature redundancies, we introduce a lightweight Density-Focal Extractor (DeFE) to produce clustered compact foreground masks. Leveraging these masks, we incorporate Masked Window Attention Sparsification (MWAS) to focus computational resources on the most informative regions via sparse attention. Besides, we propose Progressive Adaptive Query Initialization (PAQI), which adaptively modulates query density across spatial areas for better query allocation. Extensive experiments demonstrate that Dome-DETR achieves state-of-the-art performance (+3.3 AP on AI-TOD-V2 and +2.5 AP on VisDrone) while maintaining low computational complexity and a compact model size. Code will be released upon acceptance.","authors":["Zhangchi Hu","Peixi Wu","Jie Chen","Huyue Zhu","Yijun Wang","Yansong Peng","Hebei Li","Xiaoyan Sun"],"url":"https://arxiv.org/abs/2505.05741"}
{"created":"2025-05-12","title":"A Feedback Control Framework for Incentivised Suburban Parking Utilisation and Urban Core Traffic Relief","abstract":"Urban traffic congestion, exacerbated by inefficient parking management and cruising for parking, significantly hampers mobility and sustainability in smart cities. Drivers often face delays searching for parking spaces, influenced by factors such as accessibility, cost, distance, and available services such as charging facilities in the case of electric vehicles. These inefficiencies contribute to increased urban congestion, fuel consumption, and environmental impact. Addressing these challenges, this paper proposes a feedback control incentivisation-based system that aims to better distribute vehicles between city and suburban parking facilities offering park-and-charge/-ride services. Individual driver behaviours are captured via discrete choice models incorporating factors of importance to parking location choice among drivers, such as distance to work, public transport connectivity, charging infrastructure availability, and amount of incentive offered; and are regulated through principles of ergodic control theory. The proposed framework is applied to an electric vehicle park-and-charge/-ride problem, and demonstrates how predictable long-term behaviour of the system can be guaranteed.","authors":["Abdul Baseer Satti","James Saunderson","Wynita Griggs","S. M. Nawazish Ali","Nameer Al Khafaf","Saman Ahmadi","Mahdi Jalili","Jakub Marecek","Robert Shorten"],"url":"https://arxiv.org/abs/2505.05742"}
{"created":"2025-05-12","title":"Harnessing LLMs Explanations to Boost Surrogate Models in Tabular Data Classification","abstract":"Large Language Models (LLMs) have shown remarkable ability in solving complex tasks, making them a promising tool for enhancing tabular learning. However, existing LLM-based methods suffer from high resource requirements, suboptimal demonstration selection, and limited interpretability, which largely hinder their prediction performance and application in the real world. To overcome these problems, we propose a novel in-context learning framework for tabular prediction. The core idea is to leverage the explanations generated by LLMs to guide a smaller, locally deployable Surrogate Language Model (SLM) to make interpretable tabular predictions. Specifically, our framework mainly involves three stages: (i) Post Hoc Explanation Generation, where LLMs are utilized to generate explanations for question-answer pairs in candidate demonstrations, providing insights into the reasoning behind the answer. (ii) Post Hoc Explanation-Guided Demonstrations Selection, which utilizes explanations generated by LLMs to guide the process of demonstration selection from candidate demonstrations. (iii) Post Hoc Explanation-Guided Interpretable SLM Prediction, which utilizes the demonstrations obtained in step (ii) as in-context and merges corresponding explanations as rationales to improve the performance of SLM and guide the model to generate interpretable outputs. Experimental results highlight the framework's effectiveness, with an average accuracy improvement of 5.31% across various tabular datasets in diverse domains.","authors":["Ruxue Shi","Hengrui Gu","Xu Shen","Xin Wang"],"url":"https://arxiv.org/abs/2505.05744"}
{"created":"2025-05-12","title":"kFuse: A novel density based agglomerative clustering","abstract":"Agglomerative clustering has emerged as a vital tool in data analysis due to its intuitive and flexible characteristics. However, existing agglomerative clustering methods often involve additional parameters for sub-cluster partitioning and inter-cluster similarity assessment. This necessitates different parameter settings across various datasets, which is undoubtedly challenging in the absence of prior knowledge. Moreover, existing agglomerative clustering techniques are constrained by the calculation method of connection distance, leading to unstable clustering results. To address these issues, this paper introduces a novel density-based agglomerative clustering method, termed kFuse. kFuse comprises four key components: (1) sub-cluster partitioning based on natural neighbors; (2) determination of boundary connectivity between sub-clusters through the computation of adjacent samples and shortest distances; (3) assessment of density similarity between sub-clusters via the calculation of mean density and variance; and (4) establishment of merging rules between sub-clusters based on boundary connectivity and density similarity. kFuse requires the specification of the number of clusters only at the final merging stage. Additionally, by comprehensively considering adjacent samples, distances, and densities among different sub-clusters, kFuse significantly enhances accuracy during the merging phase, thereby greatly improving its identification capability. Experimental results on both synthetic and real-world datasets validate the effectiveness of kFuse.","authors":["Huan Yan","Junjie Hu"],"url":"https://arxiv.org/abs/2505.05748"}
{"created":"2025-05-12","title":"Efficient Full-Stack Private Federated Deep Learning with Post-Quantum Security","abstract":"Federated learning (FL) enables collaborative model training while preserving user data privacy by keeping data local. Despite these advantages, FL remains vulnerable to privacy attacks on user updates and model parameters during training and deployment. Secure aggregation protocols have been proposed to protect user updates by encrypting them, but these methods often incur high computational costs and are not resistant to quantum computers. Additionally, differential privacy (DP) has been used to mitigate privacy leakages, but existing methods focus on secure aggregation or DP, neglecting their potential synergies. To address these gaps, we introduce Beskar, a novel framework that provides post-quantum secure aggregation, optimizes computational overhead for FL settings, and defines a comprehensive threat model that accounts for a wide spectrum of adversaries. We also integrate DP into different stages of FL training to enhance privacy protection in diverse scenarios. Our framework provides a detailed analysis of the trade-offs between security, performance, and model accuracy, representing the first thorough examination of secure aggregation protocols combined with various DP approaches for post-quantum secure FL. Beskar aims to address the pressing privacy and security issues FL while ensuring quantum-safety and robust performance.","authors":["Yiwei Zhang","Rouzbeh Behnia","Attila A. Yavuz","Reza Ebrahimi","Elisa Bertino"],"url":"https://arxiv.org/abs/2505.05751"}
{"created":"2025-05-12","title":"Automating Infrastructure Surveying: A Framework for Geometric Measurements and Compliance Assessment Using Point Cloud Data","abstract":"Automation can play a prominent role in improving efficiency, accuracy, and scalability in infrastructure surveying and assessing construction and compliance standards. This paper presents a framework for automation of geometric measurements and compliance assessment using point cloud data. The proposed approach integrates deep learning-based detection and segmentation, in conjunction with geometric and signal processing techniques, to automate surveying tasks. As a proof of concept, we apply this framework to automatically evaluate the compliance of curb ramps with the Americans with Disabilities Act (ADA), demonstrating the utility of point cloud data in survey automation. The method leverages a newly collected, large annotated dataset of curb ramps, made publicly available as part of this work, to facilitate robust model training and evaluation. Experimental results, including comparison with manual field measurements of several ramps, validate the accuracy and reliability of the proposed method, highlighting its potential to significantly reduce manual effort and improve consistency in infrastructure assessment. Beyond ADA compliance, the proposed framework lays the groundwork for broader applications in infrastructure surveying and automated construction evaluation, promoting wider adoption of point cloud data in these domains. The annotated database, manual ramp survey data, and developed algorithms are publicly available on the project's GitHub page: https://github.com/Soltanilara/SurveyAutomation.","authors":["Amin Ghafourian","Andrew Lee","Dechen Gao","Tyler Beer","Kin Yen","Iman Soltani"],"url":"https://arxiv.org/abs/2505.05752"}
{"created":"2025-05-12","title":"Towards Embodiment Scaling Laws in Robot Locomotion","abstract":"Developing generalist agents that can operate across diverse tasks, environments, and physical embodiments is a grand challenge in robotics and artificial intelligence. In this work, we focus on the axis of embodiment and investigate embodiment scaling laws$\\unicode{x2013}$the hypothesis that increasing the number of training embodiments improves generalization to unseen ones. Using robot locomotion as a test bed, we procedurally generate a dataset of $\\sim$1,000 varied embodiments, spanning humanoids, quadrupeds, and hexapods, and train generalist policies capable of handling diverse observation and action spaces on random subsets. We find that increasing the number of training embodiments improves generalization to unseen ones, and scaling embodiments is more effective in enabling embodiment-level generalization than scaling data on small, fixed sets of embodiments. Notably, our best policy, trained on the full dataset, zero-shot transfers to novel embodiments in the real world, such as Unitree Go2 and H1. These results represent a step toward general embodied intelligence, with potential relevance to adaptive control for configurable robots, co-design of morphology and control, and beyond.","authors":["Bo Ai","Liu Dai","Nico Bohlinger","Dichen Li","Tongzhou Mu","Zhanxin Wu","K. Fay","Henrik I. Christensen","Jan Peters","Hao Su"],"url":"https://arxiv.org/abs/2505.05753"}
{"created":"2025-05-12","title":"Insertion Language Models: Sequence Generation with Arbitrary-Position Insertions","abstract":"Autoregressive models (ARMs), which predict subsequent tokens one-by-one ``from left to right,'' have achieved significant success across a wide range of sequence generation tasks. However, they struggle to accurately represent sequences that require satisfying sophisticated constraints or whose sequential dependencies are better addressed by out-of-order generation. Masked Diffusion Models (MDMs) address some of these limitations, but the process of unmasking multiple tokens simultaneously in MDMs can introduce incoherences, and MDMs cannot handle arbitrary infilling constraints when the number of tokens to be filled in is not known in advance. In this work, we introduce Insertion Language Models (ILMs), which learn to insert tokens at arbitrary positions in a sequence -- that is, they select jointly both the position and the vocabulary element to be inserted. By inserting tokens one at a time, ILMs can represent strong dependencies between tokens, and their ability to generate sequences in arbitrary order allows them to accurately model sequences where token dependencies do not follow a left-to-right sequential structure. To train ILMs, we propose a tailored network parameterization and use a simple denoising objective. Our empirical evaluation demonstrates that ILMs outperform both ARMs and MDMs on common planning tasks. Furthermore, we show that ILMs outperform MDMs and perform on par with ARMs in an unconditional text generation task while offering greater flexibility than MDMs in arbitrary-length text infilling.","authors":["Dhruvesh Patel","Aishwarya Sahoo","Avinash Amballa","Tahira Naseem","Tim G. J. Rudner","Andrew McCallum"],"url":"https://arxiv.org/abs/2505.05755"}
{"created":"2025-05-12","title":"Evolutionary thoughts: integration of large language models and evolutionary algorithms","abstract":"Large Language Models (LLMs) have unveiled remarkable capabilities in understanding and generating both natural language and code, but LLM reasoning is prone to hallucination and struggle with complex, novel scenarios, often getting stuck on partial or incorrect solutions. However, the inherent ability of Evolutionary Algorithms (EAs) to explore extensive and complex search spaces makes them particularly effective in scenarios where traditional optimization methodologies may falter. However, EAs explore a vast search space when applied to complex problems.","authors":["Antonio Jimeno Yepes","Pieter Barnard"],"url":"https://arxiv.org/abs/2505.05756"}
{"created":"2025-05-12","title":"APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning","abstract":"Formal reasoning and automated theorem proving constitute a challenging subfield of machine learning, in which machines are tasked with proving mathematical theorems using formal languages like Lean. A formal verification system can check whether a formal proof is correct or not almost instantaneously, but generating a completely correct formal proof with large language models (LLMs) remains a formidable task. The usual approach in the literature is to prompt the LLM many times (up to several thousands) until one of the generated proofs passes the verification system. In this work, we present APOLLO (Automated PrOof repair via LLM and Lean cOllaboration), a modular, model-agnostic pipeline that combines the strengths of the Lean compiler with an LLM's reasoning abilities to achieve better proof-generation results at a low sampling budget. Apollo directs a fully automated process in which the LLM generates proofs for theorems, a set of agents analyze the proofs, fix the syntax errors, identify the mistakes in the proofs using Lean, isolate failing sub-lemmas, utilize automated solvers, and invoke an LLM on each remaining goal with a low top-K budget. The repaired sub-proofs are recombined and reverified, iterating up to a user-controlled maximum number of attempts. On the miniF2F benchmark, we establish a new state-of-the-art accuracy of 75.0% among 7B-parameter models while keeping the sampling budget below one thousand. Moreover, Apollo raises the state-of-the-art accuracy for Goedel-Prover-SFT to 65.6% while cutting sample complexity from 25,600 to a few hundred. General-purpose models (o3-mini, o4-mini) jump from 3-7% to over 40% accuracy. Our results demonstrate that targeted, compiler-guided repair of LLM outputs yields dramatic gains in both efficiency and correctness, suggesting a general paradigm for scalable automated theorem proving.","authors":["Azim Ospanov","Roozbeh Yousefzadeh"],"url":"https://arxiv.org/abs/2505.05758"}
{"created":"2025-05-12","title":"A review of advancements in low-light image enhancement using deep learning","abstract":"In low-light environments, the performance of computer vision algorithms often deteriorates significantly, adversely affecting key vision tasks such as segmentation, detection, and classification. With the rapid advancement of deep learning, its application to low-light image processing has attracted widespread attention and seen significant progress in recent years. However, there remains a lack of comprehensive surveys that systematically examine how recent deep-learning-based low-light image enhancement methods function and evaluate their effectiveness in enhancing downstream vison tasks. To address this gap, this review provides a detailed elaboration on how various recent approaches (from 2020) operate and their enhancement mechanisms, supplemented with clear illustrations. It also investigates the impact of different enhancement techniques on subsequent vision tasks, critically analyzing their strengths and limitations. Additionally, it proposes future research directions. This review serves as a useful reference for determining low-light image enhancement techniques and optimizing vision task performance in low-light conditions.","authors":["Fangxue Liu","Lei Fan"],"url":"https://arxiv.org/abs/2505.05759"}
{"created":"2025-05-12","title":"Multi-Agent Systems for Robotic Autonomy with LLMs","abstract":"Since the advent of Large Language Models (LLMs), various research based on such models have maintained significant academic attention and impact, especially in AI and robotics. In this paper, we propose a multi-agent framework with LLMs to construct an integrated system for robotic task analysis, mechanical design, and path generation. The framework includes three core agents: Task Analyst, Robot Designer, and Reinforcement Learning Designer. Outputs are formatted as multimodal results, such as code files or technical reports, for stronger understandability and usability. To evaluate generalizability comparatively, we conducted experiments with models from both GPT and DeepSeek. Results demonstrate that the proposed system can design feasible robots with control strategies when appropriate task inputs are provided, exhibiting substantial potential for enhancing the efficiency and accessibility of robotic system development in research and industrial applications.","authors":["Junhong Chen","Ziqi Yang","Haoyuan G Xu","Dandan Zhang","George Mylonas"],"url":"https://arxiv.org/abs/2505.05762"}
{"created":"2025-05-12","title":"BMMDetect: A Multimodal Deep Learning Framework for Comprehensive Biomedical Misconduct Detection","abstract":"Academic misconduct detection in biomedical research remains challenging due to algorithmic narrowness in existing methods and fragmented analytical pipelines. We present BMMDetect, a multimodal deep learning framework that integrates journal metadata (SJR, institutional data), semantic embeddings (PubMedBERT), and GPT-4o-mined textual attributes (methodological statistics, data anomalies) for holistic manuscript evaluation. Key innovations include: (1) multimodal fusion of domain-specific features to reduce detection bias; (2) quantitative evaluation of feature importance, identifying journal authority metrics (e.g., SJR-index) and textual anomalies (e.g., statistical outliers) as dominant predictors; and (3) the BioMCD dataset, a large-scale benchmark with 13,160 retracted articles and 53,411 controls. BMMDetect achieves 74.33% AUC, outperforming single-modality baselines by 8.6%, and demonstrates transferability across biomedical subfields. This work advances scalable, interpretable tools for safeguarding research integrity.","authors":["Yize Zhou","Jie Zhang","Meijie Wang","Lun Yu"],"url":"https://arxiv.org/abs/2505.05763"}
{"created":"2025-05-12","title":"Distance Preservation Games","abstract":"We introduce and analyze distance preservation games (DPGs). In DPGs, agents express ideal distances to other agents and need to choose locations in the unit interval while preserving their ideal distances as closely as possible. We analyze the existence and computation of location profiles that are jump stable (i.e., no agent can benefit by moving to another location) or welfare optimal for DPGs, respectively. Specifically, we prove that there are DPGs without jump stable location profiles and identify important cases where such outcomes always exist and can be computed efficiently. Similarly, we show that finding welfare optimal location profiles is NP-complete and present approximation algorithms for finding solutions with social welfare close to optimal. Finally, we prove that DPGs have a price of anarchy of at most $2$.","authors":["Haris Aziz","Hau Chan","Patrick Lederer","Shivika Narang","Toby Walsh"],"url":"https://arxiv.org/abs/2505.05765"}
{"created":"2025-05-12","title":"Sparse Attention Remapping with Clustering for Efficient LLM Decoding on PIM","abstract":"Transformer-based models are the foundation of modern machine learning, but their execution, particularly during autoregressive decoding in large language models (LLMs), places significant pressure on memory systems due to frequent memory accesses and growing key-value (KV) caches. This creates a bottleneck in memory bandwidth, especially as context lengths increase. Processing-in-memory (PIM) architectures are a promising solution, offering high internal bandwidth and compute parallelism near memory. However, current PIM designs are primarily optimized for dense attention and struggle with the dynamic, irregular access patterns introduced by modern KV cache sparsity techniques. Consequently, they suffer from workload imbalance, reducing throughput and resource utilization. In this work, we propose STARC, a novel sparsity-optimized data mapping scheme tailored specifically for efficient LLM decoding on PIM architectures. STARC clusters KV pairs by semantic similarity and maps them to contiguous memory regions aligned with PIM bank structures. During decoding, queries retrieve relevant tokens at cluster granularity by matching against precomputed centroids, enabling selective attention and parallel processing without frequent reclustering or data movement overhead. Experiments on the HBM-PIM system show that, compared to common token-wise sparsity methods, STARC reduces attention-layer latency by 19%--31% and energy consumption by 19%--27%. Under a KV cache budget of 1024, it achieves up to 54%--74% latency reduction and 45%--67% energy reduction compared to full KV cache retrieval. Meanwhile, STARC maintains model accuracy comparable to state-of-the-art sparse attention methods, demonstrating its effectiveness in enabling efficient and hardware-friendly long-context LLM inference on PIM architectures.","authors":["Zehao Fan","Garrett Gagnon","Zhenyu Liu","Liu Liu"],"url":"https://arxiv.org/abs/2505.05772"}
{"created":"2025-05-12","title":"Human-Robot Collaboration for the Remote Control of Mobile Humanoid Robots with Torso-Arm Coordination","abstract":"Recently, many humanoid robots have been increasingly deployed in various facilities, including hospitals and assisted living environments, where they are often remotely controlled by human operators. Their kinematic redundancy enhances reachability and manipulability, enabling them to navigate complex, cluttered environments and perform a wide range of tasks. However, this redundancy also presents significant control challenges, particularly in coordinating the movements of the robot's macro-micro structure (torso and arms). Therefore, we propose various human-robot collaborative (HRC) methods for coordinating the torso and arm of remotely controlled mobile humanoid robots, aiming to balance autonomy and human input to enhance system efficiency and task execution. The proposed methods include human-initiated approaches, where users manually control torso movements, and robot-initiated approaches, which autonomously coordinate torso and arm based on factors such as reachability, task goal, or inferred human intent. We conducted a user study with N=17 participants to compare the proposed approaches in terms of task performance, manipulability, and energy efficiency, and analyzed which methods were preferred by participants.","authors":["Nikita Boguslavskii","Lorena Maria Genua","Zhi Li"],"url":"https://arxiv.org/abs/2505.05773"}
{"created":"2025-05-12","title":"persiansort: an alternative to mergesort inspired by persian rug","abstract":"This paper introduces persiansort, new stable sorting algorithm inspired by Persian rug. Persiansort does not have the weaknesses of mergesort under scenarios involving nearly sorted and partially sorted data, also utilizing less auxiliary memory than mergesort and take advantage of runs. Initial experimental showed, this method is flexible, powerful and works better than mergesort in almost all types of data. Persiansort offers several advantages over merge methods, make it a potential replacement.","authors":["Parviz Afereidoon"],"url":"https://arxiv.org/abs/2505.05775"}
{"created":"2025-05-12","title":"PyResBugs: A Dataset of Residual Python Bugs for Natural Language-Driven Fault Injection","abstract":"This paper presents PyResBugs, a curated dataset of residual bugs, i.e., defects that persist undetected during traditional testing but later surface in production, collected from major Python frameworks. Each bug in the dataset is paired with its corresponding fault-free (fixed) version and annotated with multi-level natural language (NL) descriptions. These NL descriptions enable natural language-driven fault injection, offering a novel approach to simulating real-world faults in software systems. By bridging the gap between software fault injection techniques and real-world representativeness, PyResBugs provides researchers with a high-quality resource for advancing AI-driven automated testing in Python systems.","authors":["Domenico Cotroneo","Giuseppe De Rosa","Pietro Liguori"],"url":"https://arxiv.org/abs/2505.05777"}
{"created":"2025-05-12","title":"DeepSync: A Learning Framework for Pervasive Localization using Code Synchronization on Compressed Cellular Spectrum","abstract":"Pervasive localization is essential for continuous tracking applications, yet existing solutions face challenges in balancing power consumption and accuracy. GPS, while precise, is impractical for continuous tracking of micro-assets due to high power requirements. Recent advances in non-linear compressed spectrum sensing offer low-power alternatives, but existing implementations achieve only coarse positioning through Received Signal Strength Indicator (RSSI) measurements. We present DeepSync, a deep learning framework that enables precise localization using compressed cellular spectrum. Our key technical insight lies in formulating sub-sample timing estimation as a template matching problem, solved through a novel architecture combining temporal CNN encoders for multi-frame processing with cross-attention mechanisms. The system processes non-linear inter-modulated spectrum through hierarchical feature extraction, achieving robust performance at SNR levels below -10dB -- a regime where conventional timing estimation fails. By integrating real cellular infrastructure data with physics-based ray-tracing simulations, DeepSync achieves 2.128-meter median accuracy while consuming significantly less power than conventional systems. Real-world evaluations demonstrate 10x improvement over existing compressed spectrum approaches, establishing a new paradigm for ultra-low-power localization.","authors":["Aritrik Ghosh","Nakul Garg","Nirupam Roy"],"url":"https://arxiv.org/abs/2505.05783"}
{"created":"2025-05-12","title":"Rethinking Graph Out-Of-Distribution Generalization: A Learnable Random Walk Perspective","abstract":"Out-Of-Distribution (OOD) generalization has gained increasing attentions for machine learning on graphs, as graph neural networks (GNNs) often exhibit performance degradation under distribution shifts. Existing graph OOD methods tend to follow the basic ideas of invariant risk minimization and structural causal models, interpreting the invariant knowledge across datasets under various distribution shifts as graph topology or graph spectrum. However, these interpretations may be inconsistent with real-world scenarios, as neither invariant topology nor spectrum is assured. In this paper, we advocate the learnable random walk (LRW) perspective as the instantiation of invariant knowledge, and propose LRW-OOD to realize graph OOD generalization learning. Instead of employing fixed probability transition matrix (i.e., degree-normalized adjacency matrix), we parameterize the transition matrix with an LRW-sampler and a path encoder. Furthermore, we propose the kernel density estimation (KDE)-based mutual information (MI) loss to generate random walk sequences that adhere to OOD principles. Extensive experiment demonstrates that our model can effectively enhance graph OOD generalization under various types of distribution shifts and yield a significant accuracy improvement of 3.87% over state-of-the-art graph OOD generalization baselines.","authors":["Henan Sun","Xunkai Li","Lei Zhu","Junyi Han","Guang Zeng","Ronghua Li","Guoren Wang"],"url":"https://arxiv.org/abs/2505.05785"}
{"created":"2025-05-12","title":"A Day in Their Shoes: Using LLM-Based Perspective-Taking Interactive Fiction to Reduce Stigma Toward Dirty Work","abstract":"Occupations referred to as \"dirty work\" often face entrenched social stigma, which adversely affects the mental health of workers in these fields and impedes occupational equity. In this study, we propose a novel Interactive Fiction (IF) framework powered by Large Language Models (LLMs) to encourage perspective-taking and reduce biases against these stigmatized yet essential roles. Through an experiment with participants (n = 100) across four such occupations, we observed a significant increase in participants' understanding of these occupations, as well as a high level of empathy and a strong sense of connection to individuals in these roles. Additionally, qualitative interviews with participants (n = 15) revealed that the LLM-based perspective-taking IF enhanced immersion, deepened emotional resonance and empathy toward \"dirty work,\" and allowed participants to experience a sense of professional fulfillment in these occupations. However, participants also highlighted ongoing challenges, such as limited contextual details generated by the LLM and the unintentional reinforcement of existing stereotypes. Overall, our findings underscore that an LLM-based perspective-taking IF framework offers a promising and scalable strategy for mitigating stigma and promoting social equity in marginalized professions.","authors":["Xiangzhe Yuan","Jiajun Wang","Qian Wan","Siying Hu"],"url":"https://arxiv.org/abs/2505.05786"}
{"created":"2025-05-12","title":"Demystifying Diffusion Policies: Action Memorization and Simple Lookup Table Alternatives","abstract":"Diffusion policies have demonstrated remarkable dexterity and robustness in intricate, high-dimensional robot manipulation tasks, while training from a small number of demonstrations. However, the reason for this performance remains a mystery. In this paper, we offer a surprising hypothesis: diffusion policies essentially memorize an action lookup table -- and this is beneficial. We posit that, at runtime, diffusion policies find the closest training image to the test image in a latent space, and recall the associated training action sequence, offering reactivity without the need for action generalization. This is effective in the sparse data regime, where there is not enough data density for the model to learn action generalization. We support this claim with systematic empirical evidence. Even when conditioned on wildly out of distribution (OOD) images of cats and dogs, the Diffusion Policy still outputs an action sequence from the training data. With this insight, we propose a simple policy, the Action Lookup Table (ALT), as a lightweight alternative to the Diffusion Policy. Our ALT policy uses a contrastive image encoder as a hash function to index the closest corresponding training action sequence, explicitly performing the computation that the Diffusion Policy implicitly learns. We show empirically that for relatively small datasets, ALT matches the performance of a diffusion model, while requiring only 0.0034 of the inference time and 0.0085 of the memory footprint, allowing for much faster closed-loop inference with resource constrained robots. We also train our ALT policy to give an explicit OOD flag when the distance between the runtime image is too far in the latent space from the training images, giving a simple but effective runtime monitor. More information can be found at: https://stanfordmsl.github.io/alt/.","authors":["Chengyang He","Xu Liu","Gadiel Sznaier Camps","Guillaume Sartoretti","Mac Schwager"],"url":"https://arxiv.org/abs/2505.05787"}
{"created":"2025-05-12","title":"On the Stability Barrier of Hermite Type Discretizations of Advection Equations","abstract":"In this paper we establish a stability barrier of a class of high-order Hermite-type discretization of 1D advection equations underlying the hybrid-variable (HV) and active flux (AF) methods. These methods seek numerical approximations to both cell-averages and nodal solutions and evolves them in time simultaneously. It was shown in earlier work that the HV methods are supraconvergent, providing that the discretization uses more unknowns in the upwind direction than the downwind one, similar to the \"upwind condition\" of classical finite-difference schemes. Although it is well known that the stencil of finite-difference methods could not be too biased towards the upwind direction for stability consideration, known as \"stability barrier\", such a barrier has not been established for Hermite-type methods. In this work, we first show by numerical evidence that a similar barrier exists for HV methods and make a conjecture on the sharp bound on the stencil. Next, we prove the existence of stability barrier by showing that the semi-discretized HV methods are unstable given a stencil sufficiently biased towards the upwind direction. Tighter barriers are then proved using combinatorical tools, and finally we extend the analysis to studying other Hermite-type methods built on approximating nodal solutions and derivatives, such as those widely used in Hermite WENO methods.","authors":["Xianyi Zeng"],"url":"https://arxiv.org/abs/2505.05792"}
{"created":"2025-05-12","title":"What Is Next for LLMs? Next-Generation AI Computing Hardware Using Photonic Chips","abstract":"Large language models (LLMs) are rapidly pushing the limits of contemporary computing hardware. For example, training GPT-3 has been estimated to consume around 1300 MWh of electricity, and projections suggest future models may require city-scale (gigawatt) power budgets. These demands motivate exploration of computing paradigms beyond conventional von Neumann architectures. This review surveys emerging photonic hardware optimized for next-generation generative AI computing. We discuss integrated photonic neural network architectures (e.g., Mach-Zehnder interferometer meshes, lasers, wavelength-multiplexed microring resonators) that perform ultrafast matrix operations. We also examine promising alternative neuromorphic devices, including spiking neural network circuits and hybrid spintronic-photonic synapses, which combine memory and processing. The integration of two-dimensional materials (graphene, TMDCs) into silicon photonic platforms is reviewed for tunable modulators and on-chip synaptic elements. Transformer-based LLM architectures (self-attention and feed-forward layers) are analyzed in this context, identifying strategies and challenges for mapping dynamic matrix multiplications onto these novel hardware substrates. We then dissect the mechanisms of mainstream LLMs, such as ChatGPT, DeepSeek, and LLaMA, highlighting their architectural similarities and differences. We synthesize state-of-the-art components, algorithms, and integration methods, highlighting key advances and open issues in scaling such systems to mega-sized LLM models. We find that photonic computing systems could potentially surpass electronic processors by orders of magnitude in throughput and energy efficiency, but require breakthroughs in memory, especially for long-context windows and long token sequences, and in storage of ultra-large datasets.","authors":["Renjie Li","Wenjie Wei","Qi Xin","Xiaoli Liu","Sixuan Mao","Erik Ma","Zijian Chen","Malu Zhang","Haizhou Li","Zhaoyu Zhang"],"url":"https://arxiv.org/abs/2505.05794"}
{"created":"2025-05-12","title":"Formation Maneuver Control Based on the Augmented Laplacian Method","abstract":"This paper proposes a novel formation maneuver control method for both 2-D and 3-D space, which enables the formation to translate, scale, and rotate with arbitrary orientation. The core innovation is the novel design of weights in the proposed augmented Laplacian matrix. Instead of using scalars, we represent weights as matrices, which are designed based on a specified rotation axis and allow the formation to perform rotation in 3-D space. To further improve the flexibility and scalability of the formation, the rotational axis adjustment approach and dynamic agent reconfiguration method are developed, allowing formations to rotate around arbitrary axes in 3-D space and new agents to join the formation. Theoretical analysis is provided to show that the proposed approach preserves the original configuration of the formation. The proposed method maintains the advantages of the complex Laplacian-based method, including reduced neighbor requirements and no reliance on generic or convex nominal configurations, while achieving arbitrary orientation rotations via a more simplified implementation. Simulations in both 2-D and 3-D space validate the effectiveness of the proposed method.","authors":["Xinzhe Zhou","Xuyang Wang","Xiaoming Duan","Yuzhu Bai","Jianping He"],"url":"https://arxiv.org/abs/2505.05795"}
{"created":"2025-05-12","title":"Human-in-the-Loop AI for HVAC Management Enhancing Comfort and Energy Efficiency","abstract":"Heating, Ventilation, and Air Conditioning (HVAC) systems account for approximately 38% of building energy consumption globally, making them one of the most energy-intensive services. The increasing emphasis on energy efficiency and sustainability, combined with the need for enhanced occupant comfort, presents a significant challenge for traditional HVAC systems. These systems often fail to dynamically adjust to real-time changes in electricity market rates or individual comfort preferences, leading to increased energy costs and reduced comfort. In response, we propose a Human-in-the-Loop (HITL) Artificial Intelligence framework that optimizes HVAC performance by incorporating real-time user feedback and responding to fluctuating electricity prices. Unlike conventional systems that require predefined information about occupancy or comfort levels, our approach learns and adapts based on ongoing user input. By integrating the occupancy prediction model with reinforcement learning, the system improves operational efficiency and reduces energy costs in line with electricity market dynamics, thereby contributing to demand response initiatives. Through simulations, we demonstrate that our method achieves significant cost reductions compared to baseline approaches while maintaining or enhancing occupant comfort. This feedback-driven approach ensures personalized comfort control without the need for predefined settings, offering a scalable solution that balances individual preferences with economic and environmental goals.","authors":["Xinyu Liang","Frits de Nijs","Buser Say","Hao Wang"],"url":"https://arxiv.org/abs/2505.05796"}
{"created":"2025-05-12","title":"Improving Generalizability of Kolmogorov-Arnold Networks via Error-Correcting Output Codes","abstract":"Kolmogorov-Arnold Networks (KAN) offer universal function approximation using univariate spline compositions without nonlinear activations. In this work, we integrate Error-Correcting Output Codes (ECOC) into the KAN framework to transform multi-class classification into multiple binary tasks, improving robustness via Hamming-distance decoding. Our proposed KAN with ECOC method outperforms vanilla KAN on a challenging blood cell classification dataset, achieving higher accuracy under diverse hyperparameter settings. Ablation studies further confirm that ECOC consistently enhances performance across FastKAN and FasterKAN variants. These results demonstrate that ECOC integration significantly boosts KAN generalizability in critical healthcare AI applications. To the best of our knowledge, this is the first integration of ECOC with KAN for enhancing multi-class medical image classification performance.","authors":["Youngjoon Lee","Jinu Gong","Joonhyuk Kang"],"url":"https://arxiv.org/abs/2505.05798"}
{"created":"2025-05-12","title":"MxMoE: Mixed-precision Quantization for MoE with Accuracy and Performance Co-Design","abstract":"Mixture-of-Experts (MoE) models face deployment challenges due to their large parameter counts and computational demands. We explore quantization for MoE models and highlight two key insights: 1) linear blocks exhibit varying quantization sensitivity, and 2) divergent expert activation frequencies create heterogeneous computational characteristics. Based on these observations, we introduce MxMoE, a mixed-precision optimization framework for MoE models that considers both algorithmic and system perspectives. MxMoE navigates the design space defined by parameter sensitivity, expert activation dynamics, and hardware resources to derive efficient mixed-precision configurations. Additionally, MxMoE automatically generates optimized mixed-precision GroupGEMM kernels, enabling parallel execution of GEMMs with different precisions. Evaluations show that MxMoE outperforms existing methods, achieving 2.4 lower Wikitext-2 perplexity than GPTQ at 2.25-bit and delivering up to 3.4x speedup over full precision, as well as up to 29.4% speedup over uniform quantization at equivalent accuracy with 5-bit weight-activation quantization. Our code is available at https://github.com/cat538/MxMoE.","authors":["Haojie Duanmu","Xiuhong Li","Zhihang Yuan","Size Zheng","Jiangfei Duan","Xingcheng Zhang","Dahua Lin"],"url":"https://arxiv.org/abs/2505.05799"}
{"created":"2025-05-12","title":"3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks","abstract":"Robotic manipulation in 3D requires learning an $N$ degree-of-freedom joint space trajectory of a robot manipulator. Robots must possess semantic and visual perception abilities to transform real-world mappings of their workspace into the low-level control necessary for object manipulation. Recent work has demonstrated the capabilities of fine-tuning large Vision-Language Models (VLMs) to learn the mapping between RGB images, language instructions, and joint space control. These models typically take as input RGB images of the workspace and language instructions, and are trained on large datasets of teleoperated robot demonstrations. In this work, we explore methods to improve the scene context awareness of a popular recent Vision-Language-Action model by integrating chain-of-thought reasoning, depth perception, and task-oriented region of interest detection. Our experiments in the LIBERO simulation environment show that our proposed model, 3D-CAVLA, improves the success rate across various LIBERO task suites, achieving an average success rate of 98.1$\\%$. We also evaluate the zero-shot capabilities of our method, demonstrating that 3D scene awareness leads to robust learning and adaptation for completely unseen tasks. 3D-CAVLA achieves an absolute improvement of 8.8$\\%$ on unseen tasks. We will open-source our code and the unseen tasks dataset to promote community-driven research here: https://3d-cavla.github.io","authors":["Vineet Bhat","Yu-Hsiang Lan","Prashanth Krishnamurthy","Ramesh Karri","Farshad Khorrami"],"url":"https://arxiv.org/abs/2505.05800"}
{"created":"2025-05-12","title":"A novel Neural-ODE model for the state of health estimation of lithium-ion battery using charging curve","abstract":"The state of health (SOH) of lithium-ion batteries (LIBs) is crucial for ensuring the safe and reliable operation of electric vehicles. Nevertheless, the prevailing SOH estimation methods often have limited generalizability. This paper introduces a data-driven approach for estimating the SOH of LIBs, which is designed to improve generalization. We construct a hybrid model named ACLA, which integrates the attention mechanism, convolutional neural network (CNN), and long short-term memory network (LSTM) into the augmented neural ordinary differential equation (ANODE) framework. This model employs normalized charging time corresponding to specific voltages in the constant current charging phase as input and outputs the SOH as well as remaining useful of life. The model is trained on NASA and Oxford datasets and validated on the TJU and HUST datasets. Compared to the benchmark models NODE and ANODE, ACLA exhibits higher accuracy with root mean square errors (RMSE) for SOH estimation as low as 1.01% and 2.24% on the TJU and HUST datasets, respectively.","authors":["Yiming Li","Man He","Jiapeng Liu"],"url":"https://arxiv.org/abs/2505.05803"}
{"created":"2025-05-12","title":"Describe Anything in Medical Images","abstract":"Localized image captioning has made significant progress with models like the Describe Anything Model (DAM), which can generate detailed region-specific descriptions without explicit region-text supervision. However, such capabilities have yet to be widely applied to specialized domains like medical imaging, where diagnostic interpretation relies on subtle regional findings rather than global understanding. To mitigate this gap, we propose MedDAM, the first comprehensive framework leveraging large vision-language models for region-specific captioning in medical images. MedDAM employs medical expert-designed prompts tailored to specific imaging modalities and establishes a robust evaluation benchmark comprising a customized assessment protocol, data pre-processing pipeline, and specialized QA template library. This benchmark evaluates both MedDAM and other adaptable large vision-language models, focusing on clinical factuality through attribute-level verification tasks, thereby circumventing the absence of ground-truth region-caption pairs in medical datasets. Extensive experiments on the VinDr-CXR, LIDC-IDRI, and SkinCon datasets demonstrate MedDAM's superiority over leading peers (including GPT-4o, Claude 3.7 Sonnet, LLaMA-3.2 Vision, Qwen2.5-VL, GPT-4Rol, and OMG-LLaVA) in the task, revealing the importance of region-level semantic alignment in medical image understanding and establishing MedDAM as a promising foundation for clinical vision-language integration.","authors":["Xi Xiao","Yunbei Zhang","Thanh-Huy Nguyen","Ba-Thinh Lam","Janet Wang","Jihun Hamm","Tianyang Wang","Xingjian Li","Xiao Wang","Hao Xu","Tianming Liu","Min Xu"],"url":"https://arxiv.org/abs/2505.05804"}
{"created":"2025-05-12","title":"Image Segmentation via Variational Model Based Tailored UNet: A Deep Variational Framework","abstract":"Traditional image segmentation methods, such as variational models based on partial differential equations (PDEs), offer strong mathematical interpretability and precise boundary modeling, but often suffer from sensitivity to parameter settings and high computational costs. In contrast, deep learning models such as UNet, which are relatively lightweight in parameters, excel in automatic feature extraction but lack theoretical interpretability and require extensive labeled data. To harness the complementary strengths of both paradigms, we propose Variational Model Based Tailored UNet (VM_TUNet), a novel hybrid framework that integrates the fourth-order modified Cahn-Hilliard equation with the deep learning backbone of UNet, which combines the interpretability and edge-preserving properties of variational methods with the adaptive feature learning of neural networks. Specifically, a data-driven operator is introduced to replace manual parameter tuning, and we incorporate the tailored finite point method (TFPM) to enforce high-precision boundary preservation. Experimental results on benchmark datasets demonstrate that VM_TUNet achieves superior segmentation performance compared to existing approaches, especially for fine boundary delineation.","authors":["Kaili Qi","Wenli Yang","Ye Li","Zhongyi Huang"],"url":"https://arxiv.org/abs/2505.05806"}
{"created":"2025-05-12","title":"Best of Both Worlds Guarantees for Equitable Allocations","abstract":"Equitability is a well-studied fairness notion in fair division, where an allocation is equitable if all agents receive equal utility from their allocation. For indivisible items, an exactly equitable allocation may not exist, and a natural relaxation is EQ1, which stipulates that any inequitability should be resolved by the removal of a single item. In this paper, we study equitability in the context of randomized allocations. Specifically, we aim to achieve equitability in expectation (ex ante EQ) and require that each deterministic outcome in the support satisfies ex post EQ1. Such an allocation is commonly known as a `Best of Both Worlds' allocation, and has been studied, e.g., for envy-freeness and MMS.","authors":["Umang Bhaskar","Vishwa Prakash HV","Aditi Sethia","Rakshitha"],"url":"https://arxiv.org/abs/2505.05809"}
{"created":"2025-05-12","title":"Intrusion Detection System Using Deep Learning for Network Security","abstract":"As the number of cyberattacks and their particualr nature escalate, the need for effective intrusion detection systems (IDS) has become indispensable for ensuring the security of contemporary networks. Adaptive and more sophisticated threats are often beyond the reach of traditional approaches to intrusion detection and access control. This paper proposes an experimental evaluation of IDS models based on deep learning techniques, focusing on the classification of network traffic into malicious and benign categories. We analyze and retrain an assortment of architectures, such as Convolutional Neural Networks (CNN), Artificial Neural Networks (ANN), and LSTM models. Each model was tested based on a real dataset simulated in a multi-faceted and everchanging network traffic environment. Among the tested models, the best achieved an accuracy of 96 percent, underscoring the potential of deep learning models in improving efficiency and rapid response in IDS systems. The goal of the research is to demonstrate the effectiveness of distinct architectures and their corresponding trade-offs to enhance framework development for adaptive IDS solutions and improve overall network security.","authors":["Soham Chatterjee","Satvik Chaudhary","Aswani Kumar Cherukuri"],"url":"https://arxiv.org/abs/2505.05810"}
{"created":"2025-05-12","title":"Unsupervised Anomaly Detection for Autonomous Robots via Mahalanobis SVDD with Audio-IMU Fusion","abstract":"Reliable anomaly detection is essential for ensuring the safety of autonomous robots, particularly when conventional detection systems based on vision or LiDAR become unreliable in adverse or unpredictable conditions. In such scenarios, alternative sensing modalities are needed to provide timely and robust feedback. To this end, we explore the use of audio and inertial measurement unit (IMU) sensors to detect underlying anomalies in autonomous mobile robots, such as collisions and internal mechanical faults. Furthermore, to address the challenge of limited labeled anomaly data, we propose an unsupervised anomaly detection framework based on Mahalanobis Support Vector Data Description (M-SVDD). In contrast to conventional SVDD methods that rely on Euclidean distance and assume isotropic feature distributions, our approach employs the Mahalanobis distance to adaptively scale feature dimensions and capture inter-feature correlations, enabling more expressive decision boundaries. In addition, a reconstruction-based auxiliary branch is introduced to preserve feature diversity and prevent representation collapse, further enhancing the robustness of anomaly detection. Extensive experiments on a collected mobile robot dataset and four public datasets demonstrate the effectiveness of the proposed method, as shown in the video https://youtu.be/yh1tn6DDD4A. Code and dataset are available at https://github.com/jamesyang7/M-SVDD.","authors":["Yizhuo Yang","Jiulin Zhao","Xinhang Xu","Kun Cao","Shenghai Yuan","Lihua Xie"],"url":"https://arxiv.org/abs/2505.05811"}
{"created":"2025-05-12","title":"BCE vs. CE in Deep Feature Learning","abstract":"When training classification models, it expects that the learned features are compact within classes, and can well separate different classes. As the dominant loss function for training classification models, minimizing cross-entropy (CE) loss maximizes the compactness and distinctiveness, i.e., reaching neural collapse (NC). The recent works show that binary CE (BCE) performs also well in multi-class tasks. In this paper, we compare BCE and CE in deep feature learning. For the first time, we prove that BCE can also maximize the intra-class compactness and inter-class distinctiveness when reaching its minimum, i.e., leading to NC. We point out that CE measures the relative values of decision scores in the model training, implicitly enhancing the feature properties by classifying samples one-by-one. In contrast, BCE measures the absolute values of decision scores and adjust the positive/negative decision scores across all samples to uniformly high/low levels. Meanwhile, the classifier biases in BCE present a substantial constraint on the decision scores to explicitly enhance the feature properties in the training. The experimental results are aligned with above analysis, and show that BCE could improve the classification and leads to better compactness and distinctiveness among sample features. The codes will be released.","authors":["Qiufu Li","Huibin Xiao","Linlin Shen"],"url":"https://arxiv.org/abs/2505.05813"}
{"created":"2025-05-12","title":"Tell Me Who Your Students Are: GPT Can Generate Valid Multiple-Choice Questions When Students' (Mis)Understanding Is Hinted","abstract":"The primary goal of this study is to develop and evaluate an innovative prompting technique, AnaQuest, for generating multiple-choice questions (MCQs) using a pre-trained large language model. In AnaQuest, the choice items are sentence-level assertions about complex concepts. The technique integrates formative and summative assessments. In the formative phase, students answer open-ended questions for target concepts in free text. For summative assessment, AnaQuest analyzes these responses to generate both correct and incorrect assertions. To evaluate the validity of the generated MCQs, Item Response Theory (IRT) was applied to compare item characteristics between MCQs generated by AnaQuest, a baseline ChatGPT prompt, and human-crafted items. An empirical study found that expert instructors rated MCQs generated by both AI models to be as valid as those created by human instructors. However, IRT-based analysis revealed that AnaQuest-generated questions - particularly those with incorrect assertions (foils) - more closely resembled human-crafted items in terms of difficulty and discrimination than those produced by ChatGPT.","authors":["Machi Shimmei","Masaki Uto","Yuichiroh Matsubayashi","Kentaro Inui","Aditi Mallavarapu","Noboru Matsuda"],"url":"https://arxiv.org/abs/2505.05815"}
{"created":"2025-05-12","title":"On the Price of Differential Privacy for Spectral Clustering over Stochastic Block Models","abstract":"We investigate privacy-preserving spectral clustering for community detection within stochastic block models (SBMs). Specifically, we focus on edge differential privacy (DP) and propose private algorithms for community recovery. Our work explores the fundamental trade-offs between the privacy budget and the accurate recovery of community labels. Furthermore, we establish information-theoretic conditions that guarantee the accuracy of our methods, providing theoretical assurances for successful community recovery under edge DP.","authors":["Antti Koskela","Mohamed Seif","Andrea J. Goldsmith"],"url":"https://arxiv.org/abs/2505.05816"}
{"created":"2025-05-12","title":"The Experience of Running: Recommending Routes Using Sensory Mapping in Urban Environments","abstract":"Depending on the route, runners may experience frustration, freedom, or fulfilment. However, finding routes that are conducive to the psychological experience of running remains an unresolved task in the literature. In a mixed-method study, we interviewed 7 runners to identify themes contributing to running experience, and quantitatively examined these themes in an online survey with 387 runners. Using Principal Component Analysis on the survey responses, we developed a short experience sampling questionnaire that captures the three most important dimensions of running experience: \\emph{performance \\& achievement}, \\emph{environment}, and \\emph{mind \\& social connectedness}. Using path preferences obtained from the online survey, we clustered them into two types of routes: \\emph{scenic} (associated with nature and greenery) and \\emph{urban} (characterized by the presence of people); and developed a routing engine for path recommendations. We discuss challenges faced in developing the routing engine, and provide guidelines to integrate it into mobile and wearable running apps.","authors":["Katrin H\\\"ansel","Luca Maria Aiello","Daniele Quercia","Rossano Schifanella","Krisztian Zsolt Varga","Linus W. Dietz","Marios Constantinides"],"url":"https://arxiv.org/abs/2505.05817"}
{"created":"2025-05-12","title":"New Statistical and Computational Results for Learning Junta Distributions","abstract":"We study the problem of learning junta distributions on $\\{0, 1\\}^n$, where a distribution is a $k$-junta if its probability mass function depends on a subset of at most $k$ variables. We make two main contributions:","authors":["Lorenzo Beretta"],"url":"https://arxiv.org/abs/2505.05819"}
{"created":"2025-05-12","title":"An empathic GPT-based chatbot to talk about mental disorders with Spanish teenagers","abstract":"This paper presents a chatbot-based system to engage young Spanish people in the awareness of certain mental disorders through a self-disclosure technique. The study was carried out in a population of teenagers aged between 12 and 18 years. The dialogue engine mixes closed and open conversations, so certain controlled messages are sent to focus the chat on a specific disorder, which will change over time. Once a set of trial questions is answered, the system can initiate the conversation on the disorder under the focus according to the user's sensibility to that disorder, in an attempt to establish a more empathetic communication. Then, an open conversation based on the GPT-3 language model is initiated, allowing the user to express themselves with more freedom. The results show that these systems are of interest to young people and could help them become aware of certain mental disorders.","authors":["Alba Mar\\'ia M\\'armol-Romero","Manuel Garc\\'ia-Vega","Miguel \\'Angel Garc\\'ia-Cumbreras","Arturo Montejo-R\\'aez"],"url":"https://arxiv.org/abs/2505.05828"}
{"created":"2025-05-12","title":"Accelerating Diffusion Transformer via Increment-Calibrated Caching with Channel-Aware Singular Value Decomposition","abstract":"Diffusion transformer (DiT) models have achieved remarkable success in image generation, thanks for their exceptional generative capabilities and scalability. Nonetheless, the iterative nature of diffusion models (DMs) results in high computation complexity, posing challenges for deployment. Although existing cache-based acceleration methods try to utilize the inherent temporal similarity to skip redundant computations of DiT, the lack of correction may induce potential quality degradation. In this paper, we propose increment-calibrated caching, a training-free method for DiT acceleration, where the calibration parameters are generated from the pre-trained model itself with low-rank approximation. To deal with the possible correction failure arising from outlier activations, we introduce channel-aware Singular Value Decomposition (SVD), which further strengthens the calibration effect. Experimental results show that our method always achieve better performance than existing naive caching methods with a similar computation resource budget. When compared with 35-step DDIM, our method eliminates more than 45% computation and improves IS by 12 at the cost of less than 0.06 FID increase. Code is available at https://github.com/ccccczzy/icc.","authors":["Zhiyuan Chen","Keyi Li","Yifan Jia","Le Ye","Yufei Ma"],"url":"https://arxiv.org/abs/2505.05829"}
{"created":"2025-05-12","title":"Oh F**k! How Do People Feel about Robots that Leverage Profanity?","abstract":"Profanity is nearly as old as language itself, and cursing has become particularly ubiquitous within the last century. At the same time, robots in personal and service applications are often overly polite, even though past work demonstrates the potential benefits of robot norm-breaking. Thus, we became curious about robots using curse words in error scenarios as a means for improving social perceptions by human users. We investigated this idea using three phases of exploratory work: an online video-based study (N = 76) with a student pool, an online video-based study (N = 98) in the general U.S. population, and an in-person proof-of-concept deployment (N = 52) in a campus space, each of which included the following conditions: no-speech, non-expletive error response, and expletive error response. A surprising result in the outcomes for all three studies was that although verbal acknowledgment of an error was typically beneficial (as expected based on prior work), few significant differences appeared between the non-expletive and expletive error acknowledgment conditions (counter to our expectations). Within the cultural context of our work, the U.S., it seems that many users would likely not mind if robots curse, and may even find it relatable and humorous. This work signals a promising and mischievous design space that challenges typical robot character design.","authors":["Madison R. Shippy","Brian J. Zhang","Naomi T. Fitter"],"url":"https://arxiv.org/abs/2505.05831"}
{"created":"2025-05-12","title":"Augmented Body Communicator: Enhancing daily body expression for people with upper limb limitations through LLM and a robotic arm","abstract":"Individuals with upper limb movement limitations face challenges in interacting with others. Although robotic arms are currently used primarily for functional tasks, there is considerable potential to explore ways to enhance users' body language capabilities during social interactions. This paper introduces an Augmented Body Communicator system that integrates robotic arms and a large language model. Through the incorporation of kinetic memory, disabled users and their supporters can collaboratively design actions for the robot arm. The LLM system then provides suggestions on the most suitable action based on contextual cues during interactions. The system underwent thorough user testing with six participants who have conditions affecting upper limb mobility. Results indicate that the system improves users' ability to express themselves. Based on our findings, we offer recommendations for developing robotic arms that support disabled individuals with body language capabilities and functional tasks.","authors":["Songchen Zhou","Mark Armstrong","Giulia Barbareschi","Toshihiro Ajioka","Zheng Hu","Ryoichi Ando","Kentaro Yoshifuji","Masatane Muto","Kouta Minamizawa"],"url":"https://arxiv.org/abs/2505.05832"}
{"created":"2025-05-12","title":"Dual-level Fuzzy Learning with Patch Guidance for Image Ordinal Regression","abstract":"Ordinal regression bridges regression and classification by assigning objects to ordered classes. While human experts rely on discriminative patch-level features for decisions, current approaches are limited by the availability of only image-level ordinal labels, overlooking fine-grained patch-level characteristics. In this paper, we propose a Dual-level Fuzzy Learning with Patch Guidance framework, named DFPG that learns precise feature-based grading boundaries from ambiguous ordinal labels, with patch-level supervision. Specifically, we propose patch-labeling and filtering strategies to enable the model to focus on patch-level features exclusively with only image-level ordinal labels available. We further design a dual-level fuzzy learning module, which leverages fuzzy logic to quantitatively capture and handle label ambiguity from both patch-wise and channel-wise perspectives. Extensive experiments on various image ordinal regression datasets demonstrate the superiority of our proposed method, further confirming its ability in distinguishing samples from difficult-to-classify categories. The code is available at https://github.com/ZJUMAI/DFPG-ord.","authors":["Chunlai Dong","Haochao Ying","Qibo Qiu","Jinhong Wang","Danny Chen","Jian Wu"],"url":"https://arxiv.org/abs/2505.05834"}
{"created":"2025-05-12","title":"Automatic Basis Function Selection in Iterative Learning Control: A Sparsity-Promoting Approach Applied to an Industrial Printer","abstract":"Iterative learning control (ILC) techniques are capable of improving the tracking performance of control systems that repeatedly perform similar tasks by utilizing data from past iterations. The aim of this paper is to design a systematic approach for learning parameterized feedforward signals with limited complexity. The developed method involves an iterative learning control in conjunction with a data-driven sparse subset selection procedure for basis function selection. The ILC algorithm that employs sparse optimization is able to automatically select relevant basis functions and is validated on an industrial flatbed printer.","authors":["Tjeerd Ickenroth","Max van Haren","Johan Kon","Max van Meer","Jilles van hulst","Tom Oomen"],"url":"https://arxiv.org/abs/2505.05835"}
{"created":"2025-05-12","title":"Versatile Distributed Maneuvering with Generalized Formations using Guiding Vector Fields","abstract":"This paper presents a unified approach to realize versatile distributed maneuvering with generalized formations. Specifically, we decompose the robots' maneuvers into two independent components, i.e., interception and enclosing, which are parameterized by two independent virtual coordinates. Treating these two virtual coordinates as dimensions of an abstract manifold, we derive the corresponding singularity-free guiding vector field (GVF), which, along with a distributed coordination mechanism based on the consensus theory, guides robots to achieve various motions (i.e., versatile maneuvering), including (a) formation tracking, (b) target enclosing, and (c) circumnavigation. Additional motion parameters can generate more complex cooperative robot motions. Based on GVFs, we design a controller for a nonholonomic robot model. Besides the theoretical results, extensive simulations and experiments are performed to validate the effectiveness of the approach.","authors":["Yang Lu","Sha Luo","Pengming Zhu","Weijia Yao","Hector Garcia de Marina","Xinglong Zhang","Xin Xu"],"url":"https://arxiv.org/abs/2505.05840"}
{"created":"2025-05-12","title":"DaringFed: A Dynamic Bayesian Persuasion Pricing for Online Federated Learning under Two-sided Incomplete Information","abstract":"Online Federated Learning (OFL) is a real-time learning paradigm that sequentially executes parameter aggregation immediately for each random arriving client. To motivate clients to participate in OFL, it is crucial to offer appropriate incentives to offset the training resource consumption. However, the design of incentive mechanisms in OFL is constrained by the dynamic variability of Two-sided Incomplete Information (TII) concerning resources, where the server is unaware of the clients' dynamically changing computational resources, while clients lack knowledge of the real-time communication resources allocated by the server. To incentivize clients to participate in training by offering dynamic rewards to each arriving client, we design a novel Dynamic Bayesian persuasion pricing for online Federated learning (DaringFed) under TII. Specifically, we begin by formulating the interaction between the server and clients as a dynamic signaling and pricing allocation problem within a Bayesian persuasion game, and then demonstrate the existence of a unique Bayesian persuasion Nash equilibrium. By deriving the optimal design of DaringFed under one-sided incomplete information, we further analyze the approximate optimal design of DaringFed with a specific bound under TII. Finally, extensive evaluation conducted on real datasets demonstrate that DaringFed optimizes accuracy and converges speed by 16.99%, while experiments with synthetic datasets validate the convergence of estimate unknown values and the effectiveness of DaringFed in improving the server's utility by up to 12.6%.","authors":["Yun Xin","Jianfeng Lu","Shuqin Cao","Gang Li","Haozhao Wang","Guanghui Wen"],"url":"https://arxiv.org/abs/2505.05842"}
{"created":"2025-05-12","title":"Enhancing Noisy Functional Encryption for Privacy-Preserving Machine Learning","abstract":"Functional encryption (FE) has recently attracted interest in privacy-preserving machine learning (PPML) for its unique ability to compute specific functions on encrypted data. A related line of work focuses on noisy FE, which ensures differential privacy in the output while keeping the data encrypted. We extend the notion of noisy multi-input functional encryption (NMIFE) to (dynamic) noisy multi-client functional encryption ((Dy)NMCFE), which allows for more flexibility in the number of data holders and analyses, while protecting the privacy of the data holder with fine-grained access through the usage of labels. Following our new definition of DyNMCFE, we present DyNo, a concrete inner-product DyNMCFE scheme. Our scheme captures all the functionalities previously introduced in noisy FE schemes, while being significantly more efficient in terms of space and runtime and fulfilling a stronger security notion by allowing the corruption of clients. To further prove the applicability of DyNMCFE, we present a protocol for PPML based on DyNo. According to this protocol, we train a privacy-preserving logistic regression.","authors":["Linda Scheu-Hachtel","Jasmin Zalonis"],"url":"https://arxiv.org/abs/2505.05843"}
{"created":"2025-05-12","title":"Automated Knot Detection and Pairing for Wood Analysis in the Timber Industry","abstract":"Knots in wood are critical to both aesthetics and structural integrity, making their detection and pairing essential in timber processing. However, traditional manual annotation was labor-intensive and inefficient, necessitating automation. This paper proposes a lightweight and fully automated pipeline for knot detection and pairing based on machine learning techniques. In the detection stage, high-resolution surface images of wooden boards were collected using industrial-grade cameras, and a large-scale dataset was manually annotated and preprocessed. After the transfer learning, the YOLOv8l achieves an mAP@0.5 of 0.887. In the pairing stage, detected knots were analyzed and paired based on multidimensional feature extraction. A triplet neural network was used to map the features into a latent space, enabling clustering algorithms to identify and pair corresponding knots. The triplet network with learnable weights achieved a pairing accuracy of 0.85. Further analysis revealed that he distances from the knot's start and end points to the bottom of the wooden board, and the longitudinal coordinates play crucial roles in achieving high pairing accuracy. Our experiments validate the effectiveness of the proposed solution, demonstrating the potential of AI in advancing wood science and industry.","authors":["Guohao Lin","Shidong Pan","Rasul Khanbayov","Changxi Yang","Ani Khaloian-Sarnaghi","Andriy Kovryga"],"url":"https://arxiv.org/abs/2505.05845"}
{"created":"2025-05-12","title":"Smaller and More Flexible Cuckoo Filters","abstract":"Cuckoo filters are space-efficient approximate set membership data structures with a controllable false positive rate (FPR) and zero false negatives, similar to Bloom filters. In contrast to Bloom filters, Cuckoo filters store multi-bit fingerprints of keys in a hash table using variants of Cuckoo hashing, allowing each fingerprint to be stored at a small number of possible locations. Existing Cuckoo filters use fingerprints of $(k+3)$ bits per key and an additional space overhead factor of at least $1.05$ to achieve an FPR of $2^{-k}$. For $k=10$, this amounts to $1.365\\, kn$ bits to store $n$ keys, which is better than $1.443\\, kn$ bits for Bloom filters. The $+3$ for the fingerprint size is required to balance out the multiplied FPR caused by looking for the fingerprint at several locations. In the original Cuckoo filter, the number of hash table buckets is restricted to a power of 2, which may lead to much larger space overheads, up to $2.1\\, (1+3/k)\\, kn$ bits.","authors":["Johanna Elena Schmitz","Jens Zentgraf","Sven Rahmann"],"url":"https://arxiv.org/abs/2505.05847"}
{"created":"2025-05-12","title":"RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects","abstract":"Modern 3D reconstruction and novel view synthesis approaches have demonstrated strong performance on scenes with opaque Lambertian objects. However, most assume straight light paths and therefore cannot properly handle refractive and reflective materials. Moreover, datasets specialized for these effects are limited, stymieing efforts to evaluate performance and develop suitable techniques. In this work, we introduce a synthetic RefRef dataset and benchmark for reconstructing scenes with refractive and reflective objects from posed images. Our dataset has 50 such objects of varying complexity, from single-material convex shapes to multi-material non-convex shapes, each placed in three different background types, resulting in 150 scenes. We also propose an oracle method that, given the object geometry and refractive indices, calculates accurate light paths for neural rendering, and an approach based on this that avoids these assumptions. We benchmark these against several state-of-the-art methods and show that all methods lag significantly behind the oracle, highlighting the challenges of the task and dataset.","authors":["Yue Yin","Enze Tao","Weijian Deng","Dylan Campbell"],"url":"https://arxiv.org/abs/2505.05848"}
{"created":"2025-05-12","title":"AgentXploit: End-to-End Redteaming of Black-Box AI Agents","abstract":"The strong planning and reasoning capabilities of Large Language Models (LLMs) have fostered the development of agent-based systems capable of leveraging external tools and interacting with increasingly complex environments. However, these powerful features also introduce a critical security risk: indirect prompt injection, a sophisticated attack vector that compromises the core of these agents, the LLM, by manipulating contextual information rather than direct user prompts. In this work, we propose a generic black-box fuzzing framework, AgentXploit, designed to automatically discover and exploit indirect prompt injection vulnerabilities across diverse LLM agents. Our approach starts by constructing a high-quality initial seed corpus, then employs a seed selection algorithm based on Monte Carlo Tree Search (MCTS) to iteratively refine inputs, thereby maximizing the likelihood of uncovering agent weaknesses. We evaluate AgentXploit on two public benchmarks, AgentDojo and VWA-adv, where it achieves 71% and 70% success rates against agents based on o3-mini and GPT-4o, respectively, nearly doubling the performance of baseline attacks. Moreover, AgentXploit exhibits strong transferability across unseen tasks and internal LLMs, as well as promising results against defenses. Beyond benchmark evaluations, we apply our attacks in real-world environments, successfully misleading agents to navigate to arbitrary URLs, including malicious sites.","authors":["Zhun Wang","Vincent Siu","Zhe Ye","Tianneng Shi","Yuzhou Nie","Xuandong Zhao","Chenguang Wang","Wenbo Guo","Dawn Song"],"url":"https://arxiv.org/abs/2505.05849"}
{"created":"2025-05-12","title":"Collecting Human Motion Data in Large and Occlusion-Prone Environments using Ultra-Wideband Localization","abstract":"With robots increasingly integrating into human environments, understanding and predicting human motion is essential for safe and efficient interactions. Modern human motion and activity prediction approaches require high quality and quantity of data for training and evaluation, usually collected from motion capture systems, onboard or stationary sensors. Setting up these systems is challenging due to the intricate setup of hardware components, extensive calibration procedures, occlusions, and substantial costs. These constraints make deploying such systems in new and large environments difficult and limit their usability for in-the-wild measurements. In this paper we investigate the possibility to apply the novel Ultra-Wideband (UWB) localization technology as a scalable alternative for human motion capture in crowded and occlusion-prone environments. We include additional sensing modalities such as eye-tracking, onboard robot LiDAR and radar sensors, and record motion capture data as ground truth for evaluation and comparison. The environment imitates a museum setup, with up to four active participants navigating toward random goals in a natural way, and offers more than 130 minutes of multi-modal data. Our investigation provides a step toward scalable and accurate motion data collection beyond vision-based systems, laying a foundation for evaluating sensing modalities like UWB in larger and complex environments like warehouses, airports, or convention centers.","authors":["Janik Kaden","Maximilian Hilger","Tim Schreiter","Marius Schaab","Thomas Graichen","Andrey Rudenko","Ulrich Heinkel","Achim J. Lilienthal"],"url":"https://arxiv.org/abs/2505.05851"}
{"created":"2025-05-12","title":"PICD: Versatile Perceptual Image Compression with Diffusion Rendering","abstract":"Recently, perceptual image compression has achieved significant advancements, delivering high visual quality at low bitrates for natural images. However, for screen content, existing methods often produce noticeable artifacts when compressing text. To tackle this challenge, we propose versatile perceptual screen image compression with diffusion rendering (PICD), a codec that works well for both screen and natural images. More specifically, we propose a compression framework that encodes the text and image separately, and renders them into one image using diffusion model. For this diffusion rendering, we integrate conditional information into diffusion models at three distinct levels: 1). Domain level: We fine-tune the base diffusion model using text content prompts with screen content. 2). Adaptor level: We develop an efficient adaptor to control the diffusion model using compressed image and text as input. 3). Instance level: We apply instance-wise guidance to further enhance the decoding process. Empirically, our PICD surpasses existing perceptual codecs in terms of both text accuracy and perceptual quality. Additionally, without text conditions, our approach serves effectively as a perceptual codec for natural images.","authors":["Tongda Xu","Jiahao Li","Bin Li","Yan Wang","Ya-Qin Zhang","Yan Lu"],"url":"https://arxiv.org/abs/2505.05853"}
{"created":"2025-05-12","title":"Decoupling Multi-Contrast Super-Resolution: Pairing Unpaired Synthesis with Implicit Representations","abstract":"Magnetic Resonance Imaging (MRI) is critical for clinical diagnostics but is often limited by long acquisition times and low signal-to-noise ratios, especially in modalities like diffusion and functional MRI. The multi-contrast nature of MRI presents a valuable opportunity for cross-modal enhancement, where high-resolution (HR) modalities can serve as references to boost the quality of their low-resolution (LR) counterparts-motivating the development of Multi-Contrast Super-Resolution (MCSR) techniques. Prior work has shown that leveraging complementary contrasts can improve SR performance; however, effective feature extraction and fusion across modalities with varying resolutions remains a major challenge. Moreover, existing MCSR methods often assume fixed resolution settings and all require large, perfectly paired training datasets-conditions rarely met in real-world clinical environments. To address these challenges, we propose a novel Modular Multi-Contrast Super-Resolution (MCSR) framework that eliminates the need for paired training data and supports arbitrary upscaling. Our method decouples the MCSR task into two stages: (1) Unpaired Cross-Modal Synthesis (U-CMS), which translates a high-resolution reference modality into a synthesized version of the target contrast, and (2) Unsupervised Super-Resolution (U-SR), which reconstructs the final output using implicit neural representations (INRs) conditioned on spatial coordinates. This design enables scale-agnostic and anatomically faithful reconstruction by bridging un-paired cross-modal synthesis with unsupervised resolution enhancement. Experiments show that our method achieves superior performance at 4x and 8x upscaling, with improved fidelity and anatomical consistency over existing baselines. Our framework demonstrates strong potential for scalable, subject-specific, and data-efficient MCSR in real-world clinical settings.","authors":["Hongyu Rui","Yinzhe Wu","Fanwen Wang","Jiahao Huang","Liutao Yang","Zi Wang","Guang Yang"],"url":"https://arxiv.org/abs/2505.05855"}
{"created":"2025-05-12","title":"DawnPiper: A Memory-scablable Pipeline Parallel Training Framework","abstract":"Pipeline parallelism is a crucial paradigm for large-scale model training. However, imbalances in memory footprint across stages can lead to significant GPU memory wastage, limiting the model sizes that pipeline parallelism can effectively support. In this paper, we introduce DawnPiper, a memory-scalable pipeline parallel training framework. Firstly, we develop a DL compilation-based profiling method that transforms the model into a fine-grained computation graph. This refinement gives us a finer granularity of model partitioning and memory optimization while facilitating automatic code generation. Based on observed memory usage characteristics, we derive a performance-optimal theorem for pipeline parallel partitioning that substantially reduces the partition search space. Secondly, we propose a binary pipeline partitioning algorithm and utilize a cost-model based memory optimization approach to efficiently identify nearly optimal pipeline parallel strategy. DawnPiper achieves up to a 4x and 11x increase in trainable maximum batch size compared to vPipe and PipeDream, respectively, and provides up to a 1.5x performance speedup compared to vPipe.","authors":["Xuan Peng","Xuanhua Shi","Haolin Zhang","Yunfei Zhao","Xuehai Qian"],"url":"https://arxiv.org/abs/2505.05856"}
{"created":"2025-05-12","title":"Mixed-Integer Optimization for Responsible Machine Learning","abstract":"In the last few decades, Machine Learning (ML) has achieved significant success across domains ranging from healthcare, sustainability, and the social sciences, to criminal justice and finance. But its deployment in increasingly sophisticated, critical, and sensitive areas affecting individuals, the groups they belong to, and society as a whole raises critical concerns around fairness, transparency, robustness, and privacy, among others. As the complexity and scale of ML systems and of the settings in which they are deployed grow, so does the need for responsible ML methods that address these challenges while providing guaranteed performance in deployment.","authors":["Nathan Justin","Qingshi Sun","Andr\\'es G\\'omez","Phebe Vayanos"],"url":"https://arxiv.org/abs/2505.05857"}
{"created":"2025-05-12","title":"Integrating Building Thermal Flexibility Into Distribution System: A Privacy-Preserved Dispatch Approach","abstract":"The inherent thermal storage capacity of buildings brings considerable thermal flexibility to the heating/cooling loads, which are promising demand response resources for power systems. It is widely believed that integrating the thermal flexibility of buildings into the distribution system can improve the operating economy and reliability of the system. However, the private information of the buildings needs to be transferred to the distribution system operator (DSO) to achieve a coordinated optimization, bringing serious privacy concerns to users. Given this issue, we propose a novel privacy-preserved optimal dispatch approach for the distribution system incorporating buildings. Using it, the DSO can exploit the thermal flexibility of buildings without accessing their private information, such as model parameters and indoor temperature profiles. Specifically, we first develop an optimal dispatch model for the distribution system integrating buildings, which can be extended to other storage-like flexibility resources. Second, we reveal that the privacy-preserved integration of buildings is a joint privacy preservation problem for both parameters and state variables and then design a privacy-preserved algorithm based on transformation-based encryption, constraint relaxation, and constraint extension techniques. Besides, we implement a detailed privacy analysis for the proposed method, considering both semi-honest adversaries and external eavesdroppers. Case studies demonstrate the accuracy, privacy-preserved performance, and computational efficiency of the proposed method.","authors":["Shuai Lu","Zeyin Hou","Wei Gu","Yijun Xu"],"url":"https://arxiv.org/abs/2505.05859"}
{"created":"2025-05-12","title":"Symbol-based entity marker highlighting for enhanced text mining in materials science with generative AI","abstract":"The construction of experimental datasets is essential for expanding the scope of data-driven scientific discovery. Recent advances in natural language processing (NLP) have facilitated automatic extraction of structured data from unstructured scientific literature. While existing approaches-multi-step and direct methods-offer valuable capabilities, they also come with limitations when applied independently. Here, we propose a novel hybrid text-mining framework that integrates the advantages of both methods to convert unstructured scientific text into structured data. Our approach first transforms raw text into entity-recognized text, and subsequently into structured form. Furthermore, beyond the overall data structuring framework, we also enhance entity recognition performance by introducing an entity marker-a simple yet effective technique that uses symbolic annotations to highlight target entities. Specifically, our entity marker-based hybrid approach not only consistently outperforms previous entity recognition approaches across three benchmark datasets (MatScholar, SOFC, and SOFC slot NER) but also improve the quality of final structured data-yielding up to a 58% improvement in entity-level F1 score and up to 83% improvement in relation-level F1 score compared to direct approach.","authors":["Junhyeong Lee","Jong Min Yuk","Chan-Woo Lee"],"url":"https://arxiv.org/abs/2505.05864"}
{"created":"2025-05-12","title":"Independence Under Incomplete Information","abstract":"We initiate an investigation how the fundamental concept of independence can be represented effectively in the presence of incomplete information. The concepts of possible and certain independence are proposed, and first results regarding the axiomatisability and computational complexity of implication problems associated with these concepts are established. In addition, several results for the data and the combined complexity of model checking are presented. The findings help reduce computational overheads associated with the processing of updates and answering of queries.","authors":["Miika Hannula","Minna Hirvonen","Juha Kontinen","Sebastian Link"],"url":"https://arxiv.org/abs/2505.05866"}
{"created":"2025-05-12","title":"Open Set Label Shift with Test Time Out-of-Distribution Reference","abstract":"Open set label shift (OSLS) occurs when label distributions change from a source to a target distribution, and the target distribution has an additional out-of-distribution (OOD) class. In this work, we build estimators for both source and target open set label distributions using a source domain in-distribution (ID) classifier and an ID/OOD classifier. With reasonable assumptions on the ID/OOD classifier, the estimators are assembled into a sequence of three stages: 1) an estimate of the source label distribution of the OOD class, 2) an EM algorithm for Maximum Likelihood estimates (MLE) of the target label distribution, and 3) an estimate of the target label distribution of OOD class under relaxed assumptions on the OOD classifier. The sampling errors of estimates in 1) and 3) are quantified with a concentration inequality. The estimation result allows us to correct the ID classifier trained on the source distribution to the target distribution without retraining. Experiments on a variety of open set label shift settings demonstrate the effectiveness of our model. Our code is available at https://github.com/ChangkunYe/OpenSetLabelShift.","authors":["Changkun Ye","Russell Tsuchida","Lars Petersson","Nick Barnes"],"url":"https://arxiv.org/abs/2505.05868"}
{"created":"2025-05-12","title":"Generative Discovery of Partial Differential Equations by Learning from Math Handbooks","abstract":"Data driven discovery of partial differential equations (PDEs) is a promising approach for uncovering the underlying laws governing complex systems. However, purely data driven techniques face the dilemma of balancing search space with optimization efficiency. This study introduces a knowledge guided approach that incorporates existing PDEs documented in a mathematical handbook to facilitate the discovery process. These PDEs are encoded as sentence like structures composed of operators and basic terms, and used to train a generative model, called EqGPT, which enables the generation of free form PDEs. A loop of generation evaluation optimization is constructed to autonomously identify the most suitable PDE. Experimental results demonstrate that this framework can recover a variety of PDE forms with high accuracy and computational efficiency, particularly in cases involving complex temporal derivatives or intricate spatial terms, which are often beyond the reach of conventional methods. The approach also exhibits generalizability to irregular spatial domains and higher dimensional settings. Notably, it succeeds in discovering a previously unreported PDE governing strongly nonlinear surface gravity waves propagating toward breaking, based on real world experimental data, highlighting its applicability to practical scenarios and its potential to support scientific discovery.","authors":["Hao Xu","Yuntian Chen","Rui Cao","Tianning Tang","Mengge Du","Jian Li","Adrian H. Callaghan","Dongxiao Zhang"],"url":"https://arxiv.org/abs/2505.05869"}
{"created":"2025-05-12","title":"Towards Facial Image Compression with Consistency Preserving Diffusion Prior","abstract":"With the widespread application of facial image data across various domains, the efficient storage and transmission of facial images has garnered significant attention. However, the existing learned face image compression methods often produce unsatisfactory reconstructed image quality at low bit rates. Simply adapting diffusion-based compression methods to facial compression tasks results in reconstructed images that perform poorly in downstream applications due to insufficient preservation of high-frequency information. To further explore the diffusion prior in facial image compression, we propose Facial Image Compression with a Stable Diffusion Prior (FaSDiff), a method that preserves consistency through frequency enhancement. FaSDiff employs a high-frequency-sensitive compressor in an end-to-end framework to capture fine image details and produce robust visual prompts. Additionally, we introduce a hybrid low-frequency enhancement module that disentangles low-frequency facial semantics and stably modulates the diffusion prior alongside visual prompts. The proposed modules allow FaSDiff to leverage diffusion priors for superior human visual perception while minimizing performance loss in machine vision due to semantic inconsistency. Extensive experiments show that FaSDiff outperforms state-of-the-art methods in balancing human visual quality and machine vision accuracy. The code will be released after the paper is accepted.","authors":["Yimin Zhou","Yichong Xia","Bin Chen","Baoyi An","Haoqian Wang","Zhi Wang","Yaowei Wang","Zikun Zhou"],"url":"https://arxiv.org/abs/2505.05870"}
{"created":"2025-05-12","title":"A Taxonomy of Attacks and Defenses in Split Learning","abstract":"Split Learning (SL) has emerged as a promising paradigm for distributed deep learning, allowing resource-constrained clients to offload portions of their model computation to servers while maintaining collaborative learning. However, recent research has demonstrated that SL remains vulnerable to a range of privacy and security threats, including information leakage, model inversion, and adversarial attacks. While various defense mechanisms have been proposed, a systematic understanding of the attack landscape and corresponding countermeasures is still lacking. In this study, we present a comprehensive taxonomy of attacks and defenses in SL, categorizing them along three key dimensions: employed strategies, constraints, and effectiveness. Furthermore, we identify key open challenges and research gaps in SL based on our systematization, highlighting potential future directions.","authors":["Aqsa Shabbir","Halil \\.Ibrahim Kanpak","Alptekin K\\\"up\\c{c}\\\"u","Sinem Sav"],"url":"https://arxiv.org/abs/2505.05872"}
{"created":"2025-05-12","title":"A 3D pocket-aware and evolutionary conserved interaction guided diffusion model for molecular optimization","abstract":"Generating molecules that bind to specific protein targets via diffusion models has shown good promise for structure-based drug design and molecule optimization. Especially, the diffusion models with binding interaction guidance enables molecule generation with high affinity through forming favorable interaction within protein pocket. However, the generated molecules may not form interactions with the highly conserved residues, which are important for protein functions and bioactivities of the ligands. Herein, we developed a new 3D target-aware diffusion model DiffDecip, which explicitly incorporates the protein-ligand binding interactions and evolutionary conservation information of protein residues into both diffusion and sampling process, for molecule optimization through scaffold decoration. The model performance revealed that DiffDecip outperforms baseline model DiffDec on molecule optimization towards higher affinity through forming more non-covalent interactions with highly conserved residues in the protein pocket.","authors":["Anjie Qiao","Hao Zhang","Qianmu Yuan","Qirui Deng","Jingtian Su","Weifeng Huang","Huihao Zhou","Guo-Bo Li","Zhen Wang","Jinping Lei"],"url":"https://arxiv.org/abs/2505.05874"}
{"created":"2025-05-12","title":"Multi-Modal Molecular Representation Learning via Structure Awareness","abstract":"Accurate extraction of molecular representations is a critical step in the drug discovery process. In recent years, significant progress has been made in molecular representation learning methods, among which multi-modal molecular representation methods based on images, and 2D/3D topologies have become increasingly mainstream. However, existing these multi-modal approaches often directly fuse information from different modalities, overlooking the potential of intermodal interactions and failing to adequately capture the complex higher-order relationships and invariant features between molecules. To overcome these challenges, we propose a structure-awareness-based multi-modal self-supervised molecular representation pre-training framework (MMSA) designed to enhance molecular graph representations by leveraging invariant knowledge between molecules. The framework consists of two main modules: the multi-modal molecular representation learning module and the structure-awareness module. The multi-modal molecular representation learning module collaboratively processes information from different modalities of the same molecule to overcome intermodal differences and generate a unified molecular embedding. Subsequently, the structure-awareness module enhances the molecular representation by constructing a hypergraph structure to model higher-order correlations between molecules. This module also introduces a memory mechanism for storing typical molecular representations, aligning them with memory anchors in the memory bank to integrate invariant knowledge, thereby improving the model generalization ability. Extensive experiments have demonstrated the effectiveness of MMSA, which achieves state-of-the-art performance on the MoleculeNet benchmark, with average ROC-AUC improvements ranging from 1.8% to 9.6% over baseline methods.","authors":["Rong Yin","Ruyue Liu","Xiaoshuai Hao","Xingrui Zhou","Yong Liu","Can Ma","Weiping Wang"],"url":"https://arxiv.org/abs/2505.05877"}
{"created":"2025-05-12","title":"Combining Abstract Argumentation and Machine Learning for Efficiently Analyzing Low-Level Process Event Streams","abstract":"Monitoring and analyzing process traces is a critical task for modern companies and organizations. In scenarios where there is a gap between trace events and reference business activities, this entails an interpretation problem, amounting to translating each event of any ongoing trace into the corresponding step of the activity instance. Building on a recent approach that frames the interpretation problem as an acceptance problem within an Abstract Argumentation Framework (AAF), one can elegantly analyze plausible event interpretations (possibly in an aggregated form), as well as offer explanations for those that conflict with prior process knowledge. Since, in settings where event-to-activity mapping is highly uncertain (or simply under-specified) this reasoning-based approach may yield lowly-informative results and heavy computation, one can think of discovering a sequencetagging model, trained to suggest highly-probable candidate event interpretations in a context-aware way. However, training such a model optimally may require using a large amount of manually-annotated example traces. Considering the urgent need of developing Green AI solutions enabling environmental and societal sustainability (with reduced labor/computational costs and carbon footprint), we propose a data/computation-efficient neuro-symbolic approach to the problem, where the candidate interpretations returned by the example-driven sequence tagger is refined by the AAF-based reasoner. This allows us to also leverage prior knowledge to compensate for the scarcity of example data, as confirmed by experimental results; clearly, this property is particularly useful in settings where data annotation and model optimization costs are subject to stringent constraints.","authors":["Bettina Fazzinga","Sergio Flesca","Filippo Furfaro","Luigi Pontieri","Francesco Scala"],"url":"https://arxiv.org/abs/2505.05880"}
{"created":"2025-05-12","title":"Cost-Effective, Low Latency Vector Search with Azure Cosmos DB","abstract":"Vector indexing enables semantic search over diverse corpora and has become an important interface to databases for both users and AI agents. Efficient vector search requires deep optimizations in database systems. This has motivated a new class of specialized vector databases that optimize for vector search quality and cost. Instead, we argue that a scalable, high-performance, and cost-efficient vector search system can be built inside a cloud-native operational database like Azure Cosmos DB while leveraging the benefits of a distributed database such as high availability, durability, and scale. We do this by deeply integrating DiskANN, a state-of-the-art vector indexing library, inside Azure Cosmos DB NoSQL. This system uses a single vector index per partition stored in existing index trees, and kept in sync with underlying data. It supports < 20ms query latency over an index spanning 10 million of vectors, has stable recall over updates, and offers nearly 15x and 41x lower query cost compared to Zilliz and Pinecone serverless enterprise products. It also scales out to billions of vectors via automatic partitioning. This convergent design presents a point in favor of integrating vector indices into operational databases in the context of recent debates on specialized vector databases, and offers a template for vector indexing in other databases.","authors":["Nitish Upreti","Krishnan Sundaram","Hari Sudan Sundar","Samer Boshra","Balachandar Perumalswamy","Shivam Atri","Martin Chisholm","Revti Raman Singh","Greg Yang","Subramanyam Pattipaka","Tamara Hass","Nitesh Dudhey","James Codella","Mark Hildebrand","Magdalen Manohar","Jack Moffitt","Haiyang Xu","Naren Datha","Suryansh Gupta","Ravishankar Krishnaswamy","Prashant Gupta","Abhishek Sahu","Ritika Mor","Santosh Kulkarni","Hemeswari Varada","Sudhanshu Barthwal","Amar Sagare","Dinesh Billa","Zishan Fu","Neil Deshpande","Shaun Cooper","Kevin Pilch","Simon Moreno","Aayush Kataria","Vipul Vishal","Harsha Vardhan Simhadri"],"url":"https://arxiv.org/abs/2505.05885"}
{"created":"2025-05-12","title":"Shortlisting Protection Configurations for HVDC Grids and Electrical Energy Hubs","abstract":"This paper proposes a methodology for shortlisting protection system configurations for large HVDC switching stations, which are expected in multiterminal HVDC grids and electrical energy hubs (or energy islands). This novel approach focuses on the configuration of protection equipment and the arrangement of lines and converters in various protection zones, instead of expert decisions on protection strategies based on numerous simulations. A graph-based approach that allows high-level evaluation of possible DC fault impacts is presented. This fault impact evaluation method can evaluate many possible protection configurations allowing the selection of less obvious choices, as experts cannot consider all possible configurations, especially when the switching station size increases. A filtering process is applied to reduce the number of possible configurations based on multiple protection performance metrics which are evaluated for different power flow scenarios. The results for these performance metrics can be compared for configurations with different numbers of HVDC circuit breakers to assess the benefit of increasing the amount of protection equipment in different network topologies. It is also shown that, through continued filtering using additional performance metrics or fault scenarios, the number of possible breaker, cable and converter configurations can be further reduced, leading to a protection design that is well suited for many operational scenarios. The results of the shortlisting process provide insights on the required number of HVDC circuit breakers to limit fault impacts to a given value. Moreover, observed trends in the results could, in future studies, contribute to new design principles and priorities, allowing system developers to more effectively design HVDC protection systems for different operational scenarios and possible investment levels.","authors":["Merijn Van Deyck","Geraint Chaffey","Dirk Van Hertem"],"url":"https://arxiv.org/abs/2505.05886"}
{"created":"2025-05-12","title":"Register and CLS tokens yield a decoupling of local and global features in large ViTs","abstract":"Recent work has shown that the attention maps of the widely popular DINOv2 model exhibit artifacts, which hurt both model interpretability and performance on dense image tasks. These artifacts emerge due to the model repurposing patch tokens with redundant local information for the storage of global image information. To address this problem, additional register tokens have been incorporated in which the model can store such information instead. We carefully examine the influence of these register tokens on the relationship between global and local image features, showing that while register tokens yield cleaner attention maps, these maps do not accurately reflect the integration of local image information in large models. Instead, global information is dominated by information extracted from register tokens, leading to a disconnect between local and global features. Inspired by these findings, we show that the CLS token itself, which can be interpreted as a register, leads to a very similar phenomenon in models without explicit register tokens. Our work shows that care must be taken when interpreting attention maps of large ViTs. Further, by clearly attributing the faulty behaviour to register and CLS tokens, we show a path towards more interpretable vision models.","authors":["Alexander Lappe","Martin A. Giese"],"url":"https://arxiv.org/abs/2505.05892"}
{"created":"2025-05-12","title":"LightNobel: Improving Sequence Length Limitation in Protein Structure Prediction Model via Adaptive Activation Quantization","abstract":"Recent advances in Protein Structure Prediction Models (PPMs), such as AlphaFold2 and ESMFold, have revolutionized computational biology by achieving unprecedented accuracy in predicting three-dimensional protein folding structures. However, these models face significant scalability challenges, particularly when processing proteins with long amino acid sequences (e.g., sequence length > 1,000). The primary bottleneck that arises from the exponential growth in activation sizes is driven by the unique data structure in PPM, which introduces an additional dimension that leads to substantial memory and computational demands. These limitations have hindered the effective scaling of PPM for real-world applications, such as analyzing large proteins or complex multimers with critical biological and pharmaceutical relevance.","authors":["Seunghee Han","Soongyu Choi","Joo-Young Kim"],"url":"https://arxiv.org/abs/2505.05893"}
{"created":"2025-05-12","title":"Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI","abstract":"Modern automotive infotainment systems require intelligent and adaptive solutions to handle frequent User Interface (UI) updates and diverse design variations. We introduce a vision-language framework for understanding and interacting with automotive infotainment systems, enabling seamless adaptation across different UI designs. To further support research in this field, we release AutomotiveUI-Bench-4K, an open-source dataset of 998 images with 4,208 annotations. Additionally, we present a synthetic data pipeline to generate training data. We fine-tune a Molmo-7B-based model using Low-Rank Adaptation (LoRa) and incorporating reasoning generated by our pipeline, along with visual grounding and evaluation capabilities. The fine-tuned Evaluative Large Action Model (ELAM) achieves strong performance on AutomotiveUI-Bench-4K (model and dataset are available on Hugging Face) and demonstrating strong cross-domain generalization, including a +5.2% improvement on ScreenSpot over the baseline model. Notably, our approach achieves 80.4% average accuracy on ScreenSpot, closely matching or even surpassing specialized models for desktop, mobile, and web, such as ShowUI, despite being trained for the infotainment domain. This research investigates how data collection and subsequent fine-tuning can lead to AI-driven progress within automotive UI understanding and interaction. The applied method is cost-efficient and fine-tuned models can be deployed on consumer-grade GPUs.","authors":["Benjamin Raphael Ernhofer","Daniil Prokhorov","Jannica Langner","Dominik Bollmann"],"url":"https://arxiv.org/abs/2505.05895"}
{"created":"2025-05-12","title":"Consequences of the Moosbauer-Poole Algorithms","abstract":"Moosbauer and Poole have recently shown that the multiplication of two $5\\times 5$ matrices requires no more than 93 multiplications in the (possibly non-commutative) coefficient ring, and that the multiplication of two $6\\times 6$ matrices requires no more than 153 multiplications. Taking these multiplication schemes as starting points, we found improved matrix multiplication schemes for various rectangular matrix formats using a flip graph search.","authors":["Manuel Kauers","Isaac Wood"],"url":"https://arxiv.org/abs/2505.05896"}
{"created":"2025-05-12","title":"Exploring the Susceptibility to Fraud of Monetary Incentive Mechanisms for Strengthening FOSS Projects","abstract":"Free and open source software (FOSS) is ubiquitous on modern IT systems, accelerating the speed of software engineering over the past decades. With its increasing importance and historical reliance on uncompensated contributions, questions have been raised regarding the continuous maintenance of FOSS and its implications from a security perspective. In recent years, different funding programs have emerged to provide external incentives to reinforce community FOSS' sustainability. Past research primarily focused on analyses what type of projects have been funded and for what reasons. However, it has neither been considered whether there is a need for such external incentives, nor whether the incentive mechanisms, especially with the development of decentralized approaches, are susceptible to fraud. In this study, we explore the need for funding through a literature review and compare the susceptibility to fraud of centralized and decentralized incentive programs by performing case studies on the Sovereign Tech Fund (STF) and the tea project. We find non-commercial incentives to fill an important gap, ensuring longevity and sustainability of projects. Furthermore, we find the STF to be able to achieve a high resilience against fraud attempts, while tea is highly susceptible to fraud, as evidenced by revelation of an associated sybil attack on npm. Our results imply that special considerations must be taken into account when utilizing quantitative repository metrics regardless whether spoofing is expected.","authors":["Ben Swierzy","Timo Pohl","Marc Ohm","Michael Meier"],"url":"https://arxiv.org/abs/2505.05897"}
{"created":"2025-05-12","title":"Examining the Source of Defects from a Mechanical Perspective for 3D Anomaly Detection","abstract":"In this paper, we go beyond identifying anomalies only in structural terms and think about better anomaly detection motivated by anomaly causes. Most anomalies are regarded as the result of unpredictable defective forces from internal and external sources, and their opposite forces are sought to correct the anomalies. We introduced a Mechanics Complementary framework for 3D anomaly detection (MC4AD) to generate internal and external Corrective forces for each point. A Diverse Anomaly-Generation (DA-Gen) module is first proposed to simulate various anomalies. Then, we present a Corrective Force Prediction Network (CFP-Net) with complementary representations for point-level representation to simulate the different contributions of internal and external corrective forces. A combined loss was proposed, including a new symmetric loss and an overall loss, to constrain the corrective forces properly. As a highlight, we consider 3D anomaly detection in industry more comprehensively, creating a hierarchical quality control strategy based on a three-way decision and contributing a dataset named Anomaly-IntraVariance with intraclass variance to evaluate the model. On the proposed and existing five datasets, we obtained nine state-of-the-art performers with the minimum parameters and the fastest inference speed. The source is available at https://github.com/hzzzzzhappy/MC4AD","authors":["Hanzhe Liang","Aoran Wang","Jie Zhou","Xin Jin","Can Gao","Jinbao Wang"],"url":"https://arxiv.org/abs/2505.05901"}
{"created":"2025-05-12","title":"Adaptive Robot Localization with Ultra-wideband Novelty Detection","abstract":"Ultra-wideband (UWB) technology has shown remarkable potential as a low-cost general solution for robot localization. However, limitations of the UWB signal for precise positioning arise from the disturbances caused by the environment itself, due to reflectance, multi-path effect, and Non-Line-of-Sight (NLOS) conditions. This problem is emphasized in cluttered indoor spaces where service robotic platforms usually operate. Both model-based and learning-based methods are currently under investigation to precisely predict the UWB error patterns. Despite the great capability in approximating strong non-linearity, learning-based methods often do not consider environmental factors and require data collection and re-training for unseen data distributions, making them not practically feasible on a large scale. The goal of this research is to develop a robust and adaptive UWB localization method for indoor confined spaces. A novelty detection technique is used to recognize outlier conditions from nominal UWB range data with a semi-supervised autoencoder. Then, the obtained novelty scores are combined with an Extended Kalman filter, leveraging a dynamic estimation of covariance and bias error for each range measurement received from the UWB anchors. The resulting solution is a compact, flexible, and robust system which enables the localization system to adapt the trustworthiness of UWB data spatially and temporally in the environment. The extensive experimentation conducted with a real robot in a wide range of testing scenarios demonstrates the advantages and benefits of the proposed solution in indoor cluttered spaces presenting NLoS conditions, reaching an average improvement of almost 60% and greater than 25cm of absolute positioning error.","authors":["Umberto Albertin","Mauro Martini","Alessandro Navone","Marcello Chiaberge"],"url":"https://arxiv.org/abs/2505.05903"}
{"created":"2025-05-12","title":"Taming Offload Overheads in a Massively Parallel Open-Source RISC-V MPSoC: Analysis and Optimization","abstract":"Heterogeneous multi-core architectures combine on a single chip a few large, general-purpose host cores, optimized for single-thread performance, with (many) clusters of small, specialized, energy-efficient accelerator cores for data-parallel processing. Offloading a computation to the many-core acceleration fabric implies synchronization and communication overheads which can hamper overall performance and efficiency, particularly for small and fine-grained parallel tasks. In this work, we present a detailed, cycle-accurate quantitative analysis of the offload overheads on Occamy, an open-source massively parallel RISC-V based heterogeneous MPSoC. We study how the overheads scale with the number of accelerator cores. We explore an approach to drastically reduce these overheads by co-designing the hardware and the offload routines. Notably, we demonstrate that by incorporating multicast capabilities into the Network-on-Chip of a large (200+ cores) accelerator fabric we can improve offloaded application runtimes by as much as 2.3x, restoring more than 70% of the ideally attainable speedups. Finally, we propose a quantitative model to estimate the runtime of selected applications accounting for the offload overheads, with an error consistently below 15%.","authors":["Luca Colagrande","Luca Benini"],"url":"https://arxiv.org/abs/2505.05911"}
{"created":"2025-05-12","title":"DFEN: Dual Feature Equalization Network for Medical Image Segmentation","abstract":"Current methods for medical image segmentation primarily focus on extracting contextual feature information from the perspective of the whole image. While these methods have shown effective performance, none of them take into account the fact that pixels at the boundary and regions with a low number of class pixels capture more contextual feature information from other classes, leading to misclassification of pixels by unequal contextual feature information. In this paper, we propose a dual feature equalization network based on the hybrid architecture of Swin Transformer and Convolutional Neural Network, aiming to augment the pixel feature representations by image-level equalization feature information and class-level equalization feature information. Firstly, the image-level feature equalization module is designed to equalize the contextual information of pixels within the image. Secondly, we aggregate regions of the same class to equalize the pixel feature representations of the corresponding class by class-level feature equalization module. Finally, the pixel feature representations are enhanced by learning weights for image-level equalization feature information and class-level equalization feature information. In addition, Swin Transformer is utilized as both the encoder and decoder, thereby bolstering the ability of the model to capture long-range dependencies and spatial correlations. We conducted extensive experiments on Breast Ultrasound Images (BUSI), International Skin Imaging Collaboration (ISIC2017), Automated Cardiac Diagnosis Challenge (ACDC) and PH$^2$ datasets. The experimental results demonstrate that our method have achieved state-of-the-art performance. Our code is publicly available at https://github.com/JianJianYin/DFEN.","authors":["Jianjian Yin","Yi Chen","Chengyu Li","Zhichao Zheng","Yanhui Gu","Junsheng Zhou"],"url":"https://arxiv.org/abs/2505.05913"}
{"created":"2025-05-12","title":"Mechanical Power Modeling and Energy Efficiency Maximization for Movable Antenna Systems","abstract":"Movable antennas (MAs) have recently garnered significant attention in wireless communications due to their capability to reshape wireless channels via local antenna movement within a confined region. However, to achieve accurate antenna movement, MA drivers introduce non-negligible mechanical power consumption, rendering energy efficiency (EE) optimization more critical compared to conventional fixed-position antenna (FPA) systems. To address this problem, we develop in this paper a fundamental power consumption model for stepper motor-driven MA systems by resorting to basic electric motor theory. Based on this model, we formulate an EE maximization problem by jointly optimizing an MA's position, moving speed, and transmit power. However, this problem is difficult to solve optimally due to the intricate relationship between the mechanical power consumption and the design variables. To tackle this issue, we first uncover a hidden monotonicity of the EE performance with respect to the MA's moving speed. Then, we apply the Dinkelbach algorithm to obtain the optimal transmit power in a semi-closed form for any given MA position, followed by an enumeration to determine the optimal MA position. Numerical results demonstrate that despite the additional mechanical power consumption, the MA system can outperform the conventional FPA system in terms of EE.","authors":["Xin Wei","Weidong Mei","Xuan Huang","Zhi Chen","Boyu Ning"],"url":"https://arxiv.org/abs/2505.05914"}
{"created":"2025-05-12","title":"IRNN: Innovation-driven Recurrent Neural Network for Time-Series Data Modeling and Prediction","abstract":"Many real-world datasets are time series that are sequentially collected and contain rich temporal information. Thus, a common interest in practice is to capture dynamics of time series and predict their future evolutions. To this end, the recurrent neural network (RNN) has been a prevalent and effective machine learning option, which admits a nonlinear state-space model representation. Motivated by the resemblance between RNN and Kalman filter (KF) for linear state-space models, we propose in this paper Innovation-driven RNN (IRNN), a novel RNN architecture tailored to time-series data modeling and prediction tasks. By adapting the concept of \"innovation\" from KF to RNN, past prediction errors are adopted as additional input signals to update hidden states of RNN and boost prediction performance. Since innovation data depend on network parameters, existing training algorithms for RNN do not apply to IRNN straightforwardly. Thus, a tailored training algorithm dubbed input updating-based back-propagation through time (IU-BPTT) is further proposed, which alternates between updating innovations and optimizing network parameters via gradient descent. Experiments on real-world benchmark datasets show that the integration of innovations into various forms of RNN leads to remarkably improved prediction accuracy of IRNN without increasing the training cost substantially.","authors":["Yifan Zhou","Yibo Wang","Chao Shang"],"url":"https://arxiv.org/abs/2505.05916"}
{"created":"2025-05-12","title":"Design and Application of Energy-saving Sub-Optimal Sliding Mode Control","abstract":"The recently introduced energy-saving extension of the sub-optimal sliding mode control (SOSMC), which is known in the literature for the last two and half decades, incorporates a control-off mode that allows for saving energy during the finite-time convergence process. This novel energy-saving algorithm (denoted by ES-SOSMC) assumes the systems with relative degree two between the sliding variable and the switching control with a bounded magnitude, while the matched upper-bounded perturbations are not necessarily continuous. The design and practical application of the ES-SOSMC are the subject of this chapter. A method for parameterizing the ES-SOSMC through a constrained minimization of the energy cost function is recalled which guarantees the total energy consumption is lower than that of the conventional SOSMC. Also the residual steady-state oscillations (chattering), occurring when additional (actuator) dynamics are taken into account, are addressed. An application example for scanning and machining a rough surface, both of which require a stiff position control in contact with a moving surface, demonstrates practical suitability of the control. Here, ES-SOSMC is compared with SOSMC by showing an equivalent tracking and stabilization performance and evaluating the energy-saving operation with respect to a fuel consumption norm.","authors":["Michael Ruderman"],"url":"https://arxiv.org/abs/2505.05918"}
{"created":"2025-05-12","title":"Privacy-Preserving Credit Card Approval Using Homomorphic SVM: Toward Secure Inference in FinTech Applications","abstract":"The growing use of machine learning in cloud environments raises critical concerns about data security and privacy, especially in finance. Fully Homomorphic Encryption (FHE) offers a solution by enabling computations on encrypted data, but its high computational cost limits practicality. In this paper, we propose PP-FinTech, a privacy-preserving scheme for financial applications that employs a CKKS-based encrypted soft-margin SVM, enhanced with a hybrid kernel for modeling non-linear patterns and an adaptive thresholding mechanism for robust encrypted classification. Experiments on the Credit Card Approval dataset demonstrate comparable performance to the plaintext models, highlighting PP-FinTech's ability to balance privacy, and efficiency in secure financial ML systems.","authors":["Faneela","Baraq Ghaleb","Jawad Ahmad","William J. Buchanan","Sana Ullah Jan"],"url":"https://arxiv.org/abs/2505.05920"}
{"created":"2025-05-12","title":"CAPE: Context-Aware Prompt Perturbation Mechanism with Differential Privacy","abstract":"Large Language Models (LLMs) have gained significant popularity due to their remarkable capabilities in text understanding and generation. However, despite their widespread deployment in inference services such as ChatGPT, concerns about the potential leakage of sensitive user data have arisen. Existing solutions primarily rely on privacy-enhancing technologies to mitigate such risks, facing the trade-off among efficiency, privacy, and utility. To narrow this gap, we propose Cape, a context-aware prompt perturbation mechanism based on differential privacy, to enable efficient inference with an improved privacy-utility trade-off. Concretely, we introduce a hybrid utility function that better captures the token similarity. Additionally, we propose a bucketized sampling mechanism to handle large sampling space, which might lead to long-tail phenomenons. Extensive experiments across multiple datasets, along with ablation studies, demonstrate that Cape achieves a better privacy-utility trade-off compared to prior state-of-the-art works.","authors":["Haoqi Wu","Wei Dai","Li Wang","Qiang Yan"],"url":"https://arxiv.org/abs/2505.05922"}
{"created":"2025-05-12","title":"Human causal perception in a cube-stacking task","abstract":"In intuitive physics the process of stacking cubes has become a paradigmatic, canonical task. Even though it gets employed in various shades and complexities, the very fundamental setting with two cubes has not been thoroughly investigated. Furthermore, the majority of settings feature only a reduced, one dimensional (1D) decision space. In this paper an experiment is conducted in which participants judge the stability of two cubes stacked on top of each other. It is performed in the full 3D setting which features a 2D decision surface. The analysis yield a shape of a rotated square for the perceived stability area instead of the commonly reported safety margin in 1D. This implies a more complex decision behavior in human than previously assumed.","authors":["Nikolai Bahr","Christoph Zetzsche","Jaime Maldonado"],"url":"https://arxiv.org/abs/2505.05923"}
{"created":"2025-05-12","title":"Autoencoder-Based Hybrid Replay for Class-Incremental Learning","abstract":"In class-incremental learning (CIL), effective incremental learning strategies are essential to mitigate task confusion and catastrophic forgetting, especially as the number of tasks $t$ increases. Current exemplar replay strategies impose $\\mathcal{O}(t)$ memory/compute complexities. We propose an autoencoder-based hybrid replay (AHR) strategy that leverages our new hybrid autoencoder (HAE) to function as a compressor to alleviate the requirement for large memory, achieving $\\mathcal{O}(0.1 t)$ at the worst case with the computing complexity of $\\mathcal{O}(t)$ while accomplishing state-of-the-art performance. The decoder later recovers the exemplar data stored in the latent space, rather than in raw format. Additionally, HAE is designed for both discriminative and generative modeling, enabling classification and replay capabilities, respectively. HAE adopts the charged particle system energy minimization equations and repulsive force algorithm for the incremental embedding and distribution of new class centroids in its latent space. Our results demonstrate that AHR consistently outperforms recent baselines across multiple benchmarks while operating with the same memory/compute budgets. The source code is included in the supplementary material and will be open-sourced upon publication.","authors":["Milad Khademi Nori","Il-Min Kim","Guanghui Wang"],"url":"https://arxiv.org/abs/2505.05926"}
{"created":"2025-05-12","title":"An Autonomy Loop for Dynamic HPC Job Time Limit Adjustment","abstract":"High Performance Computing (HPC) systems rely on fixed user-provided estimates of job time limits. These estimates are often inaccurate, resulting in inefficient resource use and the loss of unsaved work if a job times out shortly before reaching its next checkpoint. This work proposes a novel feedback-driven autonomy loop that dynamically adjusts HPC job time limits based on checkpoint progress reported by applications. Our approach monitors checkpoint intervals and queued jobs, enabling informed decisions to either early cancel a job after its last completed checkpoint or extend the time limit sufficiently to accommodate the next checkpoint. The objective is to minimize tail waste, that is, the computation that occurs between the last checkpoint and the termination of a job, which is not saved and hence wasted. Through experiments conducted on a subset of a production workload trace, we show a 95% reduction of tail waste, which equates to saving approximately 1.3% of the total CPU time that would otherwise be wasted. We propose various policies that combine early cancellation and time limit extension, achieving tail waste reduction while improving scheduling metrics such as weighted average job wait time. This work contributes an autonomy loop for improved scheduling in HPC environments, where system job schedulers and applications collaborate to significantly reduce resource waste and improve scheduling performance.","authors":["Thomas Jakobsche","Osman Seckin Simsek","Jim Brandt","Ann Gentile","Florina M. Ciorba"],"url":"https://arxiv.org/abs/2505.05927"}
{"created":"2025-05-12","title":"Priority-Driven Safe Model Predictive Control Approach to Autonomous Driving Applications","abstract":"This paper demonstrates the applicability of the safe model predictive control (SMPC) framework to autonomous driving scenarios, focusing on the design of adaptive cruise control (ACC) and automated lane-change systems. Building on the SMPC approach with priority-driven constraint softening -- which ensures the satisfaction of \\emph{hard} constraints under external disturbances by selectively softening a predefined subset of adjustable constraints -- we show how the algorithm dynamically relaxes lower-priority, comfort-related constraints in response to unexpected disturbances while preserving critical safety requirements such as collision avoidance and lane-keeping. A learning-based algorithm approximating the time consuming SMPC is introduced to enable real-time execution. Simulations in real-world driving scenarios subject to unpredicted disturbances confirm that this prioritized softening mechanism consistently upholds stringent safety constraints, underscoring the effectiveness of the proposed method.","authors":["Francesco Prignoli","Ying Shuai Quan","Mohammad Jeddi","Jonas Sj\\\"oberg","Paolo Falcone"],"url":"https://arxiv.org/abs/2505.05933"}
{"created":"2025-05-12","title":"Cryptanalysis of a Lattice-Based PIR Scheme for Arbitrary Database Sizes","abstract":"Private Information Retrieval (PIR) schemes enable users to securely retrieve files from a server without disclosing the content of their queries, thereby preserving their privacy. In 2008, Melchor and Gaborit proposed a PIR scheme that achieves a balance between communication overhead and server-side computational cost. However, for particularly small databases, Liu and Bi identified a vulnerability in the scheme using lattice-based methods. Nevertheless, the rapid increase in computational cost associated with the attack limited its practical applicability, leaving the scheme's overall security largely intact. In this paper, we present a novel two-stage attack that extends the work of Liu and Bi to databases of arbitrary sizes. To this end, we employ a binary-search-like preprocessing technique, which enables a significant reduction in the number of lattice problems that need to be considered. Specifically, we demonstrate how to compromise the scheme in a matter of minutes using an ordinary laptop. Our findings are substantiated through both rigorous analytical proofs and comprehensive numerical experiments.","authors":["Svenja Lage"],"url":"https://arxiv.org/abs/2505.05934"}
{"created":"2025-05-12","title":"List-Recovery of Random Linear Codes over Small Fields","abstract":"We study list-recoverability of random linear codes over small fields, both from errors and from erasures. We consider codes of rate $\\epsilon$-close to capacity, and aim to bound the dependence of the output list size $L$ on $\\epsilon$, the input list size $\\ell$, and the alphabet size $q$. Prior to our work, the best upper bound was $L = q^{O(\\ell/\\epsilon)}$ (Zyablov and Pinsker, Prob. Per. Inf. 1981).","authors":["Dean Doron","Jonathan Mosheiff","Nicolas Resch","Jo\\~ao Ribeiro"],"url":"https://arxiv.org/abs/2505.05935"}
{"created":"2025-05-12","title":"CGTrack: Cascade Gating Network with Hierarchical Feature Aggregation for UAV Tracking","abstract":"Recent advancements in visual object tracking have markedly improved the capabilities of unmanned aerial vehicle (UAV) tracking, which is a critical component in real-world robotics applications. While the integration of hierarchical lightweight networks has become a prevalent strategy for enhancing efficiency in UAV tracking, it often results in a significant drop in network capacity, which further exacerbates challenges in UAV scenarios, such as frequent occlusions and extreme changes in viewing angles. To address these issues, we introduce a novel family of UAV trackers, termed CGTrack, which combines explicit and implicit techniques to expand network capacity within a coarse-to-fine framework. Specifically, we first introduce a Hierarchical Feature Cascade (HFC) module that leverages the spirit of feature reuse to increase network capacity by integrating the deep semantic cues with the rich spatial information, incurring minimal computational costs while enhancing feature representation. Based on this, we design a novel Lightweight Gated Center Head (LGCH) that utilizes gating mechanisms to decouple target-oriented coordinates from previously expanded features, which contain dense local discriminative information. Extensive experiments on three challenging UAV tracking benchmarks demonstrate that CGTrack achieves state-of-the-art performance while running fast. Code will be available at https://github.com/Nightwatch-Fox11/CGTrack.","authors":["Weihong Li","Xiaoqiong Liu","Heng Fan","Libo Zhang"],"url":"https://arxiv.org/abs/2505.05936"}
{"created":"2025-05-12","title":"MER-CLIP: AU-Guided Vision-Language Alignment for Micro-Expression Recognition","abstract":"As a critical psychological stress response, micro-expressions (MEs) are fleeting and subtle facial movements revealing genuine emotions. Automatic ME recognition (MER) holds valuable applications in fields such as criminal investigation and psychological diagnosis. The Facial Action Coding System (FACS) encodes expressions by identifying activations of specific facial action units (AUs), serving as a key reference for ME analysis. However, current MER methods typically limit AU utilization to defining regions of interest (ROIs) or relying on specific prior knowledge, often resulting in limited performance and poor generalization. To address this, we integrate the CLIP model's powerful cross-modal semantic alignment capability into MER and propose a novel approach namely MER-CLIP. Specifically, we convert AU labels into detailed textual descriptions of facial muscle movements, guiding fine-grained spatiotemporal ME learning by aligning visual dynamics and textual AU-based representations. Additionally, we introduce an Emotion Inference Module to capture the nuanced relationships between ME patterns and emotions with higher-level semantic understanding. To mitigate overfitting caused by the scarcity of ME data, we put forward LocalStaticFaceMix, an effective data augmentation strategy blending facial images to enhance facial diversity while preserving critical ME features. Finally, comprehensive experiments on four benchmark ME datasets confirm the superiority of MER-CLIP. Notably, UF1 scores on CAS(ME)3 reach 0.7832, 0.6544, and 0.4997 for 3-, 4-, and 7-class classification tasks, significantly outperforming previous methods.","authors":["Shifeng Liu","Xinglong Mao","Sirui Zhao","Peiming Li","Tong Xu","Enhong Chen"],"url":"https://arxiv.org/abs/2505.05937"}
{"created":"2025-05-12","title":"Fast Differentiable Modal Simulation of Non-linear Strings, Membranes, and Plates","abstract":"Modal methods for simulating vibrations of strings, membranes, and plates are widely used in acoustics and physically informed audio synthesis. However, traditional implementations, particularly for non-linear models like the von K\\'arm\\'an plate, are computationally demanding and lack differentiability, limiting inverse modelling and real-time applications. We introduce a fast, differentiable, GPU-accelerated modal framework built with the JAX library, providing efficient simulations and enabling gradient-based inverse modelling. Benchmarks show that our approach significantly outperforms CPU and GPU-based implementations, particularly for simulations with many modes. Inverse modelling experiments demonstrate that our approach can recover physical parameters, including tension, stiffness, and geometry, from both synthetic and experimental data. Although fitting physical parameters is more sensitive to initialisation compared to other methods, it provides greater interpretability and more compact parameterisation. The code is released as open source to support future research and applications in differentiable physical modelling and sound synthesis.","authors":["Rodrigo Diaz","Mark Sandler"],"url":"https://arxiv.org/abs/2505.05940"}
{"created":"2025-05-12","title":"Achieving 3D Attention via Triplet Squeeze and Excitation Block","abstract":"The emergence of ConvNeXt and its variants has reaffirmed the conceptual and structural suitability of CNN-based models for vision tasks, re-establishing them as key players in image classification in general, and in facial expression recognition (FER) in particular. In this paper, we propose a new set of models that build on these advancements by incorporating a new set of attention mechanisms that combines Triplet attention with Squeeze-and-Excitation (TripSE) in four different variants. We demonstrate the effectiveness of these variants by applying them to the ResNet18, DenseNet and ConvNext architectures to validate their versatility and impact. Our study shows that incorporating a TripSE block in these CNN models boosts their performances, particularly for the ConvNeXt architecture, indicating its utility. We evaluate the proposed mechanisms and associated models across four datasets, namely CIFAR100, ImageNet, FER2013 and AffectNet datasets, where ConvNext with TripSE achieves state-of-the-art results with an accuracy of \\textbf{78.27\\%} on the popular FER2013 dataset, a new feat for this dataset.","authors":["Maan Alhazmi","Abdulrahman Altahhan"],"url":"https://arxiv.org/abs/2505.05943"}
{"created":"2025-05-12","title":"Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2","abstract":"This technical report describes an experiment on autoregressive pre-training of Gemma2 2 billion parameter large language model (LLM) with 10\\% on the Lithuanian language component of CulturaX from the point of view of continual learning. We apply elastic weight consolidation (EWC) to the full set of the model's parameters and investigate language understanding benchmarks, consisting of Arc, Belebele, Gsm8K, Hellaswag, MMLU, TruthfulQA, and Winogrande sets (both in English and Lithuanian versions), and perplexity benchmarks. We empirically demonstrate that EWC regularisation allows us not only to mitigate catastrophic forgetting effects but also that it is potentially beneficial for learning of the new task with LLMs.","authors":["Vytenis \\v{S}liogeris","Povilas Daniu\\v{s}is","Art\\=uras Nakvosas"],"url":"https://arxiv.org/abs/2505.05946"}
{"created":"2025-05-12","title":"Summarisation of German Judgments in conjunction with a Class-based Evaluation","abstract":"The automated summarisation of long legal documents can be a great aid for legal experts in their daily work. We automatically create summaries (guiding principles) of German judgments by fine-tuning a decoder-based large language model. We enrich the judgments with information about legal entities before the training. For the evaluation of the created summaries, we define a set of evaluation classes which allows us to measure their language, pertinence, completeness and correctness. Our results show that employing legal entities helps the generative model to find the relevant content, but the quality of the created summaries is not yet sufficient for a use in practice.","authors":["Bianca Steffes","Nils Torben Wiedemann","Alexander Gratz","Pamela Hochreither","Jana Elina Meyer","Katharina Luise Schilke"],"url":"https://arxiv.org/abs/2505.05947"}
{"created":"2025-05-12","title":"NeoQA: Evidence-based Question Answering with Generated News Events","abstract":"Evaluating Retrieval-Augmented Generation (RAG) in large language models (LLMs) is challenging because benchmarks can quickly become stale. Questions initially requiring retrieval may become answerable from pretraining knowledge as newer models incorporate more recent information during pretraining, making it difficult to distinguish evidence-based reasoning from recall. We introduce NeoQA (News Events for Out-of-training Question Answering), a benchmark designed to address this issue. To construct NeoQA, we generated timelines and knowledge bases of fictional news events and entities along with news articles and Q\\&amp;A pairs to prevent LLMs from leveraging pretraining knowledge, ensuring that no prior evidence exists in their training data. We propose our dataset as a new platform for evaluating evidence-based question answering, as it requires LLMs to generate responses exclusively from retrieved evidence and only when sufficient evidence is available. NeoQA enables controlled evaluation across various evidence scenarios, including cases with missing or misleading details. Our findings indicate that LLMs struggle to distinguish subtle mismatches between questions and evidence, and suffer from short-cut reasoning when key information required to answer a question is missing from the evidence, underscoring key limitations in evidence-based reasoning.","authors":["Max Glockner","Xiang Jiang","Leonardo F. R. Ribeiro","Iryna Gurevych","Markus Dreyer"],"url":"https://arxiv.org/abs/2505.05949"}
{"created":"2025-05-12","title":"FloE: On-the-Fly MoE Inference","abstract":"With the widespread adoption of Mixture-of-Experts (MoE) models, there is a growing demand for efficient inference on memory-constrained devices. While offloading expert parameters to CPU memory and loading activated experts on demand has emerged as a potential solution, the large size of activated experts overburdens the limited PCIe bandwidth, hindering the effectiveness in latency-sensitive scenarios. To mitigate this, we propose FloE, an on-the-fly MoE inference system on memory-constrained GPUs. FloE is built on the insight that there exists substantial untapped redundancy within sparsely activated experts. It employs various compression techniques on the expert's internal parameter matrices to reduce the data movement load, combined with low-cost sparse prediction, achieving perceptible inference acceleration in wall-clock time on resource-constrained devices. Empirically, FloE achieves a 9.3x compression of parameters per expert in Mixtral-8x7B; enables deployment on a GPU with only 11GB VRAM, reducing the memory footprint by up to 8.5x; and delivers a 48.7x inference speedup compared to DeepSpeed-MII on a single GeForce RTX 3090.","authors":["Yuxin Zhou","Zheng Li","Jun Zhang","Jue Wang","Yiping Wang","Zhongle Xie","Ke Chen","Lidan Shou"],"url":"https://arxiv.org/abs/2505.05950"}
{"created":"2025-05-12","title":"Towards Quantum Resilience: Data-Driven Migration Strategy Design","abstract":"The advancements in quantum computing are a threat to classical cryptographic systems. The traditional cryptographic methods that utilize factorization-based or discrete-logarithm-based algorithms, such as RSA and ECC, are some of these. This paper thoroughly investigates the vulnerabilities of traditional cryptographic methods against quantum attacks and provides a decision-support framework to help organizations in recommending mitigation plans and determining appropriate transition strategies to post-quantum cryptography. A semi-synthetic dataset, consisting of key features such as key size, network complexity, and sensitivity levels, is crafted, with each configuration labeled according to its recommended mitigation plan. Using decision tree and random forest models, a classifier is trained to recommend appropriate mitigation/transition plans such as continuous monitoring, scheduled transitions, and immediate hybrid implementation. The proposed approach introduces a data-driven and dynamic solution for organizations to assess the scale of the migration, specifying a structured roadmap toward quantum resilience. The results highlight important features that influence strategy decisions and support actionable recommendations for cryptographic modernization based on system context.","authors":["Nahid Aliyev","Ozan Cetin","Emil Huseynov"],"url":"https://arxiv.org/abs/2505.05959"}
{"created":"2025-05-12","title":"A Noise-Resilient Semi-Supervised Graph Autoencoder for Overlapping Semantic Community Detection","abstract":"Community detection in networks with overlapping structures remains a significant challenge, particularly in noisy real-world environments where integrating topology, node attributes, and prior information is critical. To address this, we propose a semi-supervised graph autoencoder that combines graph multi-head attention and modularity maximization to robustly detect overlapping communities. The model learns semantic representations by fusing structural, attribute, and prior knowledge while explicitly addressing noise in node features. Key innovations include a noise-resistant architecture and a semantic semi-supervised design optimized for community quality through modularity constraints. Experiments demonstrate superior performance the model outperforms state-of-the-art methods in overlapping community detection (improvements in NMI and F1-score) and exhibits exceptional robustness to attribute noise, maintaining stable performance under 60\\% feature corruption. These results highlight the importance of integrating attribute semantics and structural patterns for accurate community discovery in complex networks.","authors":["Abdelfateh Bekkair","Slimane Bellaouar","Slimane Oulad-Naoui"],"url":"https://arxiv.org/abs/2505.05965"}
{"created":"2025-05-12","title":"Learning Power Control Protocol for In-Factory 6G Subnetworks","abstract":"In-X Subnetworks are envisioned to meet the stringent demands of short-range communication in diverse 6G use cases. In the context of In-Factory scenarios, effective power control is critical to mitigating the impact of interference resulting from potentially high subnetwork density. Existing approaches to power control in this domain have predominantly emphasized the data plane, often overlooking the impact of signaling overhead. Furthermore, prior work has typically adopted a network-centric perspective, relying on the assumption of complete and up-to-date channel state information (CSI) being readily available at the central controller. This paper introduces a novel multi-agent reinforcement learning (MARL) framework designed to enable access points to autonomously learn both signaling and power control protocols in an In-Factory Subnetwork environment. By formulating the problem as a partially observable Markov decision process (POMDP) and leveraging multi-agent proximal policy optimization (MAPPO), the proposed approach achieves significant advantages. The simulation results demonstrate that the learning-based method reduces signaling overhead by a factor of 8 while maintaining a buffer flush rate that lags the ideal \"Genie\" approach by only 5%.","authors":["Uyoata E. Uyoata","Gilberto Berardinelli","Ramoni Adeogun"],"url":"https://arxiv.org/abs/2505.05967"}
{"created":"2025-05-12","title":"Offline Multi-agent Reinforcement Learning via Score Decomposition","abstract":"Offline multi-agent reinforcement learning (MARL) faces critical challenges due to distributional shifts, further exacerbated by the high dimensionality of joint action spaces and the diversity in coordination strategies and quality among agents. Conventional approaches, including independent learning frameworks and value decomposition methods based on pessimistic principles, remain susceptible to out-of-distribution (OOD) joint actions and often yield suboptimal performance. Through systematic analysis of prevalent offline MARL benchmarks, we identify that this limitation primarily stems from the inherently multimodal nature of joint collaborative policies induced by offline data collection. To address these challenges, we propose a novel two-stage framework: First, we employ a diffusion-based generative model to explicitly capture the complex behavior policy, enabling accurate modeling of diverse multi-agent coordination patterns. Second, we introduce a sequential score function decomposition mechanism to regularize individual policies and enable decentralized execution. Extensive experiments on continuous control tasks demonstrate state-of-the-art performance across multiple standard offline MARL benchmarks, outperforming existing methods by 26.3\\% in normalized returns. Our approach provides new insights into offline coordination and equilibrium selection in cooperative multi-agent systems.","authors":["Dan Qiao","Wenhao Li","Shanchao Yang","Hongyuan Zha","Baoxiang Wang"],"url":"https://arxiv.org/abs/2505.05968"}
{"created":"2025-05-12","title":"Minimal $L^p$-congestion spanning trees on weighted graphs","abstract":"A generalization of the notion of spanning tree congestion for weighted graphs is introduced. The $L^p$ congestion of a spanning tree is defined as the $L^p$ norm of the edge congestion of that tree. In this context, the classical congestion is the $L^\\infty$-congestion. Explicit estimations of the minimal spanning tree $L^p$ congestion for some families of graphs are given. In addition, we introduce a polynomial-time algorithm for approximating the minimal $L^p$-congestion spanning tree in any weighted graph and another two similar algorithms for weighted planar graphs. The performance of these algorithms is tested in several graphs.","authors":["Alberto Castej\\'on Lafuente","Emilio Est\\'evez","Carlos Meni\\~no Cot\\'on","M. Carmen Somoza"],"url":"https://arxiv.org/abs/2505.05969"}
{"created":"2025-05-12","title":"Towards Developmentally Plausible Rewards: Communicative Success as a Learning Signal for Interactive Language Models","abstract":"We propose a method for training language models in an interactive setting inspired by child language acquisition. In our setting, a speaker attempts to communicate some information to a listener in a single-turn dialogue and receives a reward if communicative success is achieved. Unlike earlier related work using image--caption data for interactive reference games, we operationalize communicative success in a more abstract language-only question--answering setting. First, we present a feasibility study demonstrating that our reward provides an indirect signal about grammaticality. Second, we conduct experiments using reinforcement learning to fine-tune language models. We observe that cognitively plausible constraints on the communication channel lead to interpretable changes in speaker behavior. However, we do not yet see improvements on linguistic evaluations from our training regime. We outline potential modifications to the task design and training configuration that could better position future work to use our methodology to observe the benefits of interaction on language learning in computational cognitive models.","authors":["Lennart St\\\"opler","Rufat Asadli","Mitja Nikolaus","Ryan Cotterell","Alex Warstadt"],"url":"https://arxiv.org/abs/2505.05970"}
{"created":"2025-05-12","title":"An Exploratory Analysis on the Explanatory Potential of Embedding-Based Measures of Semantic Transparency for Malay Word Recognition","abstract":"Studies of morphological processing have shown that semantic transparency is crucial for word recognition. Its computational operationalization is still under discussion. Our primary objectives are to explore embedding-based measures of semantic transparency, and assess their impact on reading. First, we explored the geometry of complex words in semantic space. To do so, we conducted a t-distributed Stochastic Neighbor Embedding clustering analysis on 4,226 Malay prefixed words. Several clusters were observed for complex words varied by their prefix class. Then, we derived five simple measures, and investigated whether they were significant predictors of lexical decision latencies. Two sets of Linear Discriminant Analyses were run in which the prefix of a word is predicted from either word embeddings or shift vectors (i.e., a vector subtraction of the base word from the derived word). The accuracy with which the model predicts the prefix of a word indicates the degree of transparency of the prefix. Three further measures were obtained by comparing embeddings between each word and all other words containing the same prefix (i.e., centroid), between each word and the shift from their base word, and between each word and the predicted word of the Functional Representations of Affixes in Compositional Semantic Space model. In a series of Generalized Additive Mixed Models, all measures predicted decision latencies after accounting for word frequency, word length, and morphological family size. The model that included the correlation between each word and their centroid as a predictor provided the best fit to the data.","authors":["M. Maziyah Mohamed (University of Tuebingen)","R. H. Baayen (University of Tuebingen)"],"url":"https://arxiv.org/abs/2505.05973"}
{"created":"2025-05-12","title":"Pseudo-Boolean d-DNNF Compilation for Expressive Feature Modeling Constructs","abstract":"Configurable systems typically consist of reusable assets that have dependencies between each other. To specify such dependencies, feature models are commonly used. As feature models in practice are often complex, automated reasoning is typically employed to analyze the dependencies. Here, the de facto standard is translating the feature model to conjunctive normal form (CNF) to enable employing off-the-shelf tools, such as SAT or #SAT solvers. However, modern feature-modeling dialects often contain constructs, such as cardinality constraints, that are ill-suited for conversion to CNF. This mismatch between the input of reasoning engines and the available feature-modeling dialects limits the applicability of the more expressive constructs. In this work, we shorten this gap between expressive constructs and scalable automated reasoning. Our contribution is twofold: First, we provide a pseudo-Boolean encoding for feature models, which facilitates smaller representations of commonly employed constructs compared to Boolean encoding. Second, we propose a novel method to compile pseudo-Boolean formulas to Boolean d-DNNF. With the compiled d-DNNFs, we can resort to a plethora of efficient analyses already used in feature modeling. Our empirical evaluation shows that our proposal substantially outperforms the state-of-the-art based on CNF inputs for expressive constructs. For every considered dataset representing different feature models and feature-modeling constructs, the feature models can be significantly faster translated to pseudo-Boolean than to CNF. Overall, deriving d-DNNFs from a feature model with the targeted expressive constraints can be substantially accelerated using our pseudo-Boolean approach. Furthermore, our approach is competitive on feature models with only basic constructs.","authors":["Chico Sundermann","Stefan Vill","Elias Kuiter","Sebastian Krieter","Thomas Th\\\"um","Matthias Tichy"],"url":"https://arxiv.org/abs/2505.05976"}
{"created":"2025-05-12","title":"A review of discontinuous Galerkin time-stepping methods for wave propagation problems","abstract":"This chapter reviews and compares discontinuous Galerkin time-stepping methods for the numerical approximation of second-order ordinary differential equations, particularly those stemming from space finite element discretization of wave propagation problems. Two formulations, tailored for second- and first-order systems of ordinary differential equations, are discussed within a generalized framework, assessing their stability, accuracy, and computational efficiency. Theoretical results are supported by various illustrative examples that validate the findings, enhancing the understanding and applicability of these methods in practical scenarios.","authors":["Paola F. Antonietti","Alberto Artoni","Gabriele Ciaramella","Ilario Mazzieri"],"url":"https://arxiv.org/abs/2505.05978"}
{"created":"2025-05-12","title":"On the Potential of Electrified Supply Chains to Provide Long Duration Demand Flexibility","abstract":"Demand flexibility can offset some of the variability introduced on the supply-side by variable renewable generation. However, most efforts (e.g. control of residential vehicle charging) focus on short durations -- typically on the scale of minutes to hours. This paper investigates whether a fully electrified supply chain (transport and manufacturing) could provide demand flexibility over longer durations, exploiting the latency that typically exists between the processing of raw material to the delivery of finished product. Using a case study of the cement industry along the East Coast of the United States, we demonstrate that electrified supply chains could shift gigawatt-hours (GWh) of electricity demand for durations of more than a week, largely following wind power variability. Furthermore, we show that this occurs using low levels of carbon taxing (below $50/tn), at which battery storage is not economically viable. A sensitivity analysis shows potential to provide flexibility in all considered cost scenarios, although where the flexibility comes from can change (e.g. transport vs manufacturing). We show that today's cost of electrified heavy goods vehicles are the most significant parameter -- with substantially lower costs yielding a more demand-flexible supply chain.","authors":["Rina Davila Severiano","Constance Crozier","Mark O Malley"],"url":"https://arxiv.org/abs/2505.05982"}
{"created":"2025-05-12","title":"Architectural Exploration of Hybrid Neural Decoders for Neuromorphic Implantable BMI","abstract":"This work presents an efficient decoding pipeline for neuromorphic implantable brain-machine interfaces (Neu-iBMI), leveraging sparse neural event data from an event-based neural sensing scheme. We introduce a tunable event filter (EvFilter), which also functions as a spike detector (EvFilter-SPD), significantly reducing the number of events processed for decoding by 192X and 554X, respectively. The proposed pipeline achieves high decoding performance, up to R^2=0.73, with ANN- and SNN-based decoders, eliminating the need for signal recovery, spike detection, or sorting, commonly performed in conventional iBMI systems. The SNN-Decoder reduces computations and memory required by 5-23X compared to NN-, and LSTM-Decoders, while the ST-NN-Decoder delivers similar performance to an LSTM-Decoder requiring 2.5X fewer resources. This streamlined approach significantly reduces computational and memory demands, making it ideal for low-power, on-implant, or wearable iBMIs.","authors":["Vivek Mohan","Biyan Zhou","Zhou Wang","Anil Bharath","Emmanuel Drakakis","Arindam Basu"],"url":"https://arxiv.org/abs/2505.05983"}
{"created":"2025-05-12","title":"Discontinuous Galerkin time integration for second-order differential problems: formulations, analysis, and analogies","abstract":"We thoroughly investigate Discontinuous Galerkin (DG) discretizations as time integrators for second-order oscillatory systems, considering both second-order and first-order formulations of the original problem. Key contributions include new convergence analyses for the second-order formulation and equivalence proofs between DG and classical time-stepping schemes (such as Newmark schemes and general linear methods). In addition, the chapter provides a detailed review and convergence analysis for the first-order formulation, alongside comparisons of the proposed schemes in terms of accuracy, consistency, and computational cost.","authors":["Gabriele Ciaramella","Martin J. Gander","Ilario Mazzieri"],"url":"https://arxiv.org/abs/2505.05985"}
{"created":"2025-05-12","title":"GNU Aris: a web application for students","abstract":"We report on recent improvements to the free logic education software tool GNU Aris, including the latest features added during the Google Summer of Code 2023 project. We focused on making GNU Aris a web application to enable almost all users to use it as a standalone offline web application written in a combination of HTML, JavaScript, and WebAssembly. We used the Qt Quick framework with Emscripten to compile the application to WebAssembly. In the report we summarize the user feedback of university students given during a course on logic.","authors":["Saksham Attri (Birla Institute of Technology","Science Pilani","Hyderabad Campus","India)","Zolt\\'an Kov\\'acs (Private University of Education","Diocese Linz","Austria)","Aaron Windischbauer (Private University of Education","Diocese Linz","Austria)"],"url":"https://arxiv.org/abs/2505.05986"}
{"created":"2025-05-12","title":"OnlineProver: Experience with a Visualisation Tool for Teaching Formal Proofs","abstract":"OnlineProver is an interactive proof assistant tailored for the educational setting. Its main features include a user-friendly interface for editing and checking proofs. The user interface provides feedback directly within the derivation, based on error messages from a proof-checking web service. A basic philosophy of the tool is that it should aid the student while still ensuring that the students construct the proofs as if they were working on paper.","authors":["J\\'an Perh\\'a\\v{c} (Technical University of Ko\\v{s}ice","Slovakia)","Samuel Novotn\\'y (Technical University of Ko\\v{s}ice","Slovakia)","Sergej Chodarev (Technical University of Ko\\v{s}ice","Slovakia)","Joachim Tilsted Kristensen (University of Oslo","Norway)","Lars Tveito (University of Oslo","Norway)","Oleks Shturmov (University of Oslo","Norway","University of Copenhagen","Denmark)","Michael Kirkedal Thomsen (University of Oslo","Norway","University of Copenhagen","Denmark)"],"url":"https://arxiv.org/abs/2505.05987"}
{"created":"2025-05-12","title":"Minimal Sequent Calculus for Teaching First-Order Logic: Lessons Learned","abstract":"MiniCalc is a web app for teaching first-order logic based on a minimal sequent calculus. As an option the proofs can be verified in the Isabelle proof assistant. We present the lessons learned using the tool in recent years at our university.","authors":["J{\\o}rgen Villadsen (Technical University of Denmark)"],"url":"https://arxiv.org/abs/2505.05988"}
{"created":"2025-05-12","title":"Modeling Multi-Hop Semantic Paths for Recommendation in Heterogeneous Information Networks","abstract":"This study focuses on the problem of path modeling in heterogeneous information networks and proposes a multi-hop path-aware recommendation framework. The method centers on multi-hop paths composed of various types of entities and relations. It models user preferences through three stages: path selection, semantic representation, and attention-based fusion. In the path selection stage, a path filtering mechanism is introduced to remove redundant and noisy information. In the representation learning stage, a sequential modeling structure is used to jointly encode entities and relations, preserving the semantic dependencies within paths. In the fusion stage, an attention mechanism assigns different weights to each path to generate a global user interest representation. Experiments conducted on real-world datasets such as Amazon-Book show that the proposed method significantly outperforms existing recommendation models across multiple evaluation metrics, including HR@10, Recall@10, and Precision@10. The results confirm the effectiveness of multi-hop paths in capturing high-order interaction semantics and demonstrate the expressive modeling capabilities of the framework in heterogeneous recommendation scenarios. This method provides both theoretical and practical value by integrating structural information modeling in heterogeneous networks with recommendation algorithm design. It offers a more expressive and flexible paradigm for learning user preferences in complex data environments.","authors":["Hongye Zheng","Yue Xing","Lipeng Zhu","Xu Han","Junliang Du","Wanyu Cui"],"url":"https://arxiv.org/abs/2505.05989"}
{"created":"2025-05-12","title":"Maths with Coq in L1, a pedagogical experiment","abstract":"In France, the first year of study at university is usually abbreviated L1 (for premiere annee de Licence). At Sorbonne Paris Nord University, we have been teaching an 18 hour introductory course in formal proofs to L1 students for 3 years.  These students are in a double major mathematics and computer science curriculum. The course is mandatory and consists only of hands-on sessions with the Coq proof assistant.","authors":["Marie Kerjean (CNRS","Universit\\'e Sorbonne Paris Nord","Laboratoire d'informatique de Paris Nord","LIPN","Villetaneuse","France)","Micaela Mayero (Universit\\'e Sorbonne Paris Nord","Laboratoire d'informatique de Paris Nord","LIPN","Villetaneuse","France","Universit\\'e Paris-Saclay","Inria","CNRS","ENS Paris-Saclay","Gif-sur-Yvette","France)","Pierre Rousselin (Universit\\'e Sorbonne Paris Nord","CNRS","Laboratoire Analyse","G\\'eom\\'etrie et Applications","LAGA","Villetaneuse","France","Inria","Paris","CERMICS","\\'Ecole des ponts","Marne-la-Vall\\'ee","France)"],"url":"https://arxiv.org/abs/2505.05990"}
{"created":"2025-05-12","title":"CogniSNN: A First Exploration to Random Graph Architecture based Spiking Neural Networks with Enhanced Expandability and Neuroplasticity","abstract":"Despite advances in spiking neural networks (SNNs) in numerous tasks, their architectures remain highly similar to traditional artificial neural networks (ANNs), restricting their ability to mimic natural connections between biological neurons. This paper develops a new modeling paradigm for SNN with random graph architecture (RGA), termed Cognition-aware SNN (CogniSNN). Furthermore, we improve the expandability and neuroplasticity of CogniSNN by introducing a modified spiking residual neural node (ResNode) to counteract network degradation in deeper graph pathways, as well as a critical path-based algorithm that enables CogniSNN to perform continual learning on new tasks leveraging the features of the data and the RGA learned in the old task. Experiments show that CogniSNN with re-designed ResNode performs outstandingly in neuromorphic datasets with fewer parameters, achieving 95.5% precision in the DVS-Gesture dataset with only 5 timesteps. The critical path-based approach decreases 3% to 5% forgetting while maintaining expected performance in learning new tasks that are similar to or distinct from the old ones. This study showcases the potential of RGA-based SNN and paves a new path for biologically inspired networks based on graph theory.","authors":["Yongsheng Huang","Peibo Duan","Zhipeng Liu","Kai Sun","Changsheng Zhang","Bin Zhang","Mingkun Xu"],"url":"https://arxiv.org/abs/2505.05992"}
{"created":"2025-05-12","title":"P4Kube: In-Network Load Balancer for Kubernetes","abstract":"Kubernetes Services such as LoadBalancer and NodePort expose applications running on pods within a Kubernetes cluster to external users. While the LoadBalancer Service requires an external load-balancing middleware, its alternative, NodePort Service, adds additional hops on the path between clients and the worker nodes. In this paper, we propose P4Kube, a framework consisting of a P4 data plane program and a Kubernetes plugin. Our solution effectively performs load balancing of requests to the worker nodes of a cluster based on the number of running replicas. In P4Kube, the data packets completely bypass the system's control plane. Unlike the previous work, to update its state, the P4Kube data plane works directly with the Kubernetes control plane without any involvement of the network control plane. Our experiments show up to 50% improvement in the average request time to the cluster compared to conventional approaches.","authors":["Garegin Grigoryan","Kevin Penkowski","Minseok Kwon"],"url":"https://arxiv.org/abs/2505.05996"}
{"created":"2025-05-12","title":"A Polynomial-Time Approximation Algorithm for Complete Interval Minors","abstract":"As shown by Robertson and Seymour, deciding whether the complete graph $K_t$ is a minor of an input graph $G$ is a fixed parameter tractable problem when parameterized by $t$. From the approximation viewpoint, the gap to fill is quite large, as there is no PTAS for finding the largest complete minor unless $P = NP$, whereas a polytime $O(\\sqrt n)$-approximation algorithm was given by Alon, Lingas and Wahl\\'en.","authors":["Romain Bourneuf","Julien Cocquet","Chaoliang Tang","St\\'ephan Thomass\\'e"],"url":"https://arxiv.org/abs/2505.05997"}
{"created":"2025-05-12","title":"Differentiable Fuzzy Neural Networks for Recommender Systems","abstract":"As recommender systems become increasingly complex, transparency is essential to increase user trust, accountability, and regulatory compliance. Neuro-symbolic approaches that integrate symbolic reasoning with sub-symbolic learning offer a promising approach toward transparent and user-centric systems. In this work-in-progress, we investigate using fuzzy neural networks (FNNs) as a neuro-symbolic approach for recommendations that learn logic-based rules over predefined, human-readable atoms. Each rule corresponds to a fuzzy logic expression, making the recommender's decision process inherently transparent. In contrast to black-box machine learning methods, our approach reveals the reasoning behind a recommendation while maintaining competitive performance. We evaluate our method on a synthetic and MovieLens 1M datasets and compare it to state-of-the-art recommendation algorithms. Our results demonstrate that our approach accurately captures user behavior while providing a transparent decision-making process. Finally, the differentiable nature of this approach facilitates an integration with other neural models, enabling the development of hybrid, transparent recommender systems.","authors":["Stephan Bartl","Kevin Innerebner","Elisabeth Lex"],"url":"https://arxiv.org/abs/2505.06000"}
{"created":"2025-05-12","title":"Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for Few-shot Action Recognition","abstract":"Large-scale pre-trained models have achieved remarkable success in language and image tasks, leading an increasing number of studies to explore the application of pre-trained image models, such as CLIP, in the domain of few-shot action recognition (FSAR). However, current methods generally suffer from several problems: 1) Direct fine-tuning often undermines the generalization capability of the pre-trained model; 2) The exploration of task-specific information is insufficient in the visual tasks; 3) The semantic order information is typically overlooked during text modeling; 4) Existing cross-modal alignment techniques ignore the temporal coupling of multimodal information. To address these, we propose Task-Adapter++, a parameter-efficient dual adaptation method for both image and text encoders. Specifically, to make full use of the variations across different few-shot learning tasks, we design a task-specific adaptation for the image encoder so that the most discriminative information can be well noticed during feature extraction. Furthermore, we leverage large language models (LLMs) to generate detailed sequential sub-action descriptions for each action class, and introduce semantic order adapters into the text encoder to effectively model the sequential relationships between these sub-actions. Finally, we develop an innovative fine-grained cross-modal alignment strategy that actively maps visual features to reside in the same temporal stage as semantic descriptions. Extensive experiments fully demonstrate the effectiveness and superiority of the proposed method, which achieves state-of-the-art performance on 5 benchmarks consistently. The code is open-sourced at https://github.com/Jaulin-Bage/Task-Adapter-pp.","authors":["Congqi Cao","Peiheng Han","Yueran zhang","Yating Yu","Qinyi Lv","Lingtong Min","Yanning zhang"],"url":"https://arxiv.org/abs/2505.06002"}
{"created":"2025-05-12","title":"From Pixels to Perception: Interpretable Predictions via Instance-wise Grouped Feature Selection","abstract":"Understanding the decision-making process of machine learning models provides valuable insights into the task, the data, and the reasons behind a model's failures. In this work, we propose a method that performs inherently interpretable predictions through the instance-wise sparsification of input images. To align the sparsification with human perception, we learn the masking in the space of semantically meaningful pixel regions rather than on pixel-level. Additionally, we introduce an explicit way to dynamically determine the required level of sparsity for each instance. We show empirically on semi-synthetic and natural image datasets that our inherently interpretable classifier produces more meaningful, human-understandable predictions than state-of-the-art benchmarks.","authors":["Moritz Vandenhirtz","Julia E. Vogt"],"url":"https://arxiv.org/abs/2505.06003"}
{"created":"2025-05-12","title":"Exploring the Feasibility of Multilingual Grammatical Error Correction with a Single LLM up to 9B parameters: A Comparative Study of 17 Models","abstract":"Recent language models can successfully solve various language-related tasks, and many understand inputs stated in different languages. In this paper, we explore the performance of 17 popular models used to correct grammatical issues in texts stated in English, German, Italian, and Swedish when using a single model to correct texts in all those languages. We analyze the outputs generated by these models, focusing on decreasing the number of grammatical errors while keeping the changes small. The conclusions drawn help us understand what problems occur among those models and which models can be recommended for multilingual grammatical error correction tasks. We list six models that improve grammatical correctness in all four languages and show that Gemma 9B is currently the best performing one for the languages considered.","authors":["Dawid Wisniewski","Antoni Solarski","Artur Nowakowski"],"url":"https://arxiv.org/abs/2505.06004"}
{"created":"2025-05-12","title":"Second Price Matching with Complete Allocation and Degree Constraints","abstract":"We study the Second Price Matching problem, introduced by Azar, Birnbaum, Karlin, and Nguyen in 2009. In this problem, a bipartite graph (bidders and goods) is given, and the profit of a matching is the number of matches containing a second unmatched bidder. Maximizing profit is known to be APX-hard and the current best approximation guarantee is $1/2$. APX-hardness even holds when all degrees are bounded by a constant. In this paper, we investigate the approximability of the problem under regular degree constraints. Our main result is an improved approximation guarantee of $9/10$ for Second Price Matching in $(3,2)$-regular graphs and an exact polynomial-time algorithm for $(d,2)$-regular graphs if $d\\geq 4$. Our algorithm and its analysis are based on structural results in non-bipartite matching, in particular the Tutte-Berge formula coupled with novel combinatorial augmentation methods.","authors":["Rom Pinchasi","Neta Singer","Lukas Vogl","Jiaye Wei"],"url":"https://arxiv.org/abs/2505.06005"}
{"created":"2025-05-12","title":"Do Not Change Me: On Transferring Entities Without Modification in Neural Machine Translation -- a Multilingual Perspective","abstract":"Current machine translation models provide us with high-quality outputs in most scenarios. However, they still face some specific problems, such as detecting which entities should not be changed during translation. In this paper, we explore the abilities of popular NMT models, including models from the OPUS project, Google Translate, MADLAD, and EuroLLM, to preserve entities such as URL addresses, IBAN numbers, or emails when producing translations between four languages: English, German, Polish, and Ukrainian. We investigate the quality of popular NMT models in terms of accuracy, discuss errors made by the models, and examine the reasons for errors. Our analysis highlights specific categories, such as emojis, that pose significant challenges for many models considered. In addition to the analysis, we propose a new multilingual synthetic dataset of 36,000 sentences that can help assess the quality of entity transfer across nine categories and four aforementioned languages.","authors":["Dawid Wisniewski","Mikolaj Pokrywka","Zofia Rostek"],"url":"https://arxiv.org/abs/2505.06010"}
{"created":"2025-05-12","title":"Fuzzy-UCS Revisited: Self-Adaptation of Rule Representations in Michigan-Style Learning Fuzzy-Classifier Systems","abstract":"This paper focuses on the impact of rule representation in Michigan-style Learning Fuzzy-Classifier Systems (LFCSs) on its classification performance. A well-representation of the rules in an LFCS is crucial for improving its performance. However, conventional rule representations frequently need help addressing problems with unknown data characteristics. To address this issue, this paper proposes a supervised LFCS (i.e., Fuzzy-UCS) with a self-adaptive rule representation mechanism, entitled Adaptive-UCS. Adaptive-UCS incorporates a fuzzy indicator as a new rule parameter that sets the membership function of a rule as either rectangular (i.e., crisp) or triangular (i.e., fuzzy) shapes. The fuzzy indicator is optimized with evolutionary operators, allowing the system to search for an optimal rule representation. Results from extensive experiments conducted on continuous space problems demonstrate that Adaptive-UCS outperforms other UCSs with conventional crisp-hyperrectangular and fuzzy-hypertrapezoidal rule representations in classification accuracy. Additionally, Adaptive-UCS exhibits robustness in the case of noisy inputs and real-world problems with inherent uncertainty, such as missing values, leading to stable classification performance.","authors":["Hiroki Shiraishi","Yohei Hayamizu","Tomonori Hashiyama"],"url":"https://arxiv.org/abs/2505.06017"}
{"created":"2025-05-12","title":"ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding","abstract":"Understanding visual art requires reasoning across multiple perspectives -- cultural, historical, and stylistic -- beyond mere object recognition. While recent multimodal large language models (MLLMs) perform well on general image captioning, they often fail to capture the nuanced interpretations that fine art demands. We propose ArtRAG, a novel, training-free framework that combines structured knowledge with retrieval-augmented generation (RAG) for multi-perspective artwork explanation. ArtRAG automatically constructs an Art Context Knowledge Graph (ACKG) from domain-specific textual sources, organizing entities such as artists, movements, themes, and historical events into a rich, interpretable graph. At inference time, a multi-granular structured retriever selects semantically and topologically relevant subgraphs to guide generation. This enables MLLMs to produce contextually grounded, culturally informed art descriptions. Experiments on the SemArt and Artpedia datasets show that ArtRAG outperforms several heavily trained baselines. Human evaluations further confirm that ArtRAG generates coherent, insightful, and culturally enriched interpretations.","authors":["Shuai Wang","Ivona Najdenkoska","Hongyi Zhu","Stevan Rudinac","Monika Kackovic","Nachoem Wijnberg","Marcel Worring"],"url":"https://arxiv.org/abs/2505.06020"}
{"created":"2025-05-12","title":"Toward Heterogeneous, Distributed, and Energy-Efficient Computing with SYCL","abstract":"Programming modern high-performance computing systems is challenging due to the need to efficiently program GPUs and accelerators and to handle data movement between nodes. The C++ language has been continuously enhanced in recent years with features that greatly increase productivity. In particular, the C++-based SYCL standard provides a powerful programming model for heterogeneous systems that can target a wide range of devices, including multicore CPUs, GPUs, FPGAs, and accelerators, while providing high-level abstractions. This presentation introduces our research efforts to design a SYCL-based high-level programming interface that provides advanced techniques such as task distribution and energy optimization. The key insight is that SYCL semantics can be easily extended to provide advanced features for easy integration into existing SYCL programs. In particular, we will highlight two SYCL extensions that are designed to deal with workload distribution on accelerator clusters (Celerity) and with energy-efficient computing (SYnergy).","authors":["Biagio Cosenza","Lorenzo Carpentieri","Kaijie Fan","Marco D'Antonio","Peter Thoman","Philip Salzmann"],"url":"https://arxiv.org/abs/2505.06022"}
{"created":"2025-05-12","title":"Universal Approximation Theorem for Deep Q-Learning via FBSDE System","abstract":"The approximation capabilities of Deep Q-Networks (DQNs) are commonly justified by general Universal Approximation Theorems (UATs) that do not leverage the intrinsic structural properties of the optimal Q-function, the solution to a Bellman equation. This paper establishes a UAT for a class of DQNs whose architecture is designed to emulate the iterative refinement process inherent in Bellman updates. A central element of our analysis is the propagation of regularity: while the transformation induced by a single Bellman operator application exhibits regularity, for which Backward Stochastic Differential Equations (BSDEs) theory provides analytical tools, the uniform regularity of the entire sequence of value iteration iterates--specifically, their uniform Lipschitz continuity on compact domains under standard Lipschitz assumptions on the problem data--is derived from finite-horizon dynamic programming principles. We demonstrate that layers of a deep residual network, conceived as neural operators acting on function spaces, can approximate the action of the Bellman operator. The resulting approximation theorem is thus intrinsically linked to the control problem's structure, offering a proof technique wherein network depth directly corresponds to iterations of value function refinement, accompanied by controlled error propagation. This perspective reveals a dynamic systems view of the network's operation on a space of value functions.","authors":["Qian Qi"],"url":"https://arxiv.org/abs/2505.06023"}
{"created":"2025-05-12","title":"Discretization of Dirac systems and port-Hamiltonian systems: the role of the constraint algorithm","abstract":"We study the discretization of (almost-)Dirac structures using the notion of retraction and discretization maps on manifolds. Additionally, we apply the proposed discretization techniques to obtain numerical integrators for port-Hamiltonian systems and we discuss how to merge the discretization procedure and the constraint algorithm associated to systems of implicit differential equations.","authors":["Mar\\'ia Barbero-Li\\~n\\'an","Juan Manuel L\\'opez Medel","David Mart\\'in de Diego"],"url":"https://arxiv.org/abs/2505.06024"}
{"created":"2025-05-12","title":"Efficient Information Updates in Compute-First Networking via Reinforcement Learning with Joint AoI and VoI","abstract":"Timely and efficient dissemination of service information is critical in compute-first networking systems, where user requests arrive dynamically and computing resources are constrained. In such systems, the access point (AP) plays a key role in forwarding user requests to a server based on its latest received service information. This paper considers a single-source, single-destination system and introduces an Age-and-Value-Aware (AVA) metric that jointly captures both the timeliness and the task relevance of service information. Unlike traditional freshness-based metrics, AVA explicitly incorporates variations in server-side service capacity and AP forwarding decisions, allowing more context-aware update evaluation. Building upon AVA, we propose a reinforcement learning-based update policy that learns to selectively transmit service information updates to the AP. It aims to maximize overall task success while minimizing unnecessary communications. Extensive simulations under diverse user request patterns and varying service capacities demonstrate that AVA reduces the update frequency by over 90% on average compared to baselines, with reductions reaching 98% in certain configurations. Crucially, this reduction is achieved without compromising the accuracy of task execution or the quality of decision making.","authors":["Jianpeng Qi","Chao Liu","Chengxiang Xu","Rui Wang","Junyu Dong","Yanwei Yu"],"url":"https://arxiv.org/abs/2505.06025"}
{"created":"2025-05-12","title":"Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation","abstract":"This paper introduces Unilogit, a novel self-distillation method for machine unlearning in Large Language Models. Unilogit addresses the challenge of selectively forgetting specific information while maintaining overall model utility, a critical task in compliance with data privacy regulations like GDPR. Unlike prior methods that rely on static hyperparameters or starting model outputs, Unilogit dynamically adjusts target logits to achieve a uniform probability for the target token, leveraging the current model's outputs for more accurate self-distillation targets. This approach not only eliminates the need for additional hyperparameters but also enhances the model's ability to approximate the golden targets. Extensive experiments on public benchmarks and an in-house e-commerce dataset demonstrate Unilogit's superior performance in balancing forget and retain objectives, outperforming state-of-the-art methods such as NPO and UnDIAL. Our analysis further reveals Unilogit's robustness across various scenarios, highlighting its practical applicability and effectiveness in achieving efficacious machine unlearning.","authors":["Stefan Vasilev","Christian Herold","Baohao Liao","Seyyed Hadi Hashemi","Shahram Khadivi","Christof Monz"],"url":"https://arxiv.org/abs/2505.06027"}
{"created":"2025-05-12","title":"Probability of a Condorcet Winner for Large Electorates: An Analytic Combinatorics Approach","abstract":"We study the probability that a given candidate is an alpha-winner, i.e. a candidate preferred to each other candidate j by a fraction alpha_j of the voters. This extends the classical notion of Condorcet winner, which corresponds to the case alpha = (1/2, ..., 1/2). Our analysis is conducted under the general assumption that voters have independent preferences, illustrated through applications to well-known models such as Impartial Culture and the Mallows model. While previous works use probabilistic arguments to derive the limiting probability as the number of voters tends to infinity, we employ techniques from the field of analytic combinatorics to compute convergence rates and provide a method for obtaining higher-order terms in the asymptotic expansion. In particular, we establish that the probability of a given candidate being the Condorcet winner in Impartial Culture is a_0 + a_{1, n} n^{-1/2} + O(n^{-1}), where we explicitly provide the values of the constant a_0 and the coefficient a_{1, n}, which depends solely on the parity of the number of voters n. Along the way, we derive technical results in multivariate analytic combinatorics that may be of independent interest.","authors":["Emma Caizergues","Fran\\c{c}ois Durand","Marc Noy","\\'Elie de Panafieu","Vlady Ravelomanana"],"url":"https://arxiv.org/abs/2505.06028"}
{"created":"2025-05-12","title":"Why Are You Wrong? Counterfactual Explanations for Language Grounding with 3D Objects","abstract":"Combining natural language and geometric shapes is an emerging research area with multiple applications in robotics and language-assisted design. A crucial task in this domain is object referent identification, which involves selecting a 3D object given a textual description of the target. Variability in language descriptions and spatial relationships of 3D objects makes this a complex task, increasing the need to better understand the behavior of neural network models in this domain. However, limited research has been conducted in this area. Specifically, when a model makes an incorrect prediction despite being provided with a seemingly correct object description, practitioners are left wondering: \"Why is the model wrong?\". In this work, we present a method answering this question by generating counterfactual examples. Our method takes a misclassified sample, which includes two objects and a text description, and generates an alternative yet similar formulation that would have resulted in a correct prediction by the model. We have evaluated our approach with data from the ShapeTalk dataset along with three distinct models. Our counterfactual examples maintain the structure of the original description, are semantically similar and meaningful. They reveal weaknesses in the description, model bias and enhance the understanding of the models behavior. Theses insights help practitioners to better interact with systems as well as engineers to improve models.","authors":["Tobias Preintner","Weixuan Yuan","Qi Huang","Adrian K\\\"onig","Thomas B\\\"ack","Elena Raponi","Niki van Stein"],"url":"https://arxiv.org/abs/2505.06030"}
{"created":"2025-05-12","title":"Short-circuiting Shortcuts: Mechanistic Investigation of Shortcuts in Text Classification","abstract":"Reliance on spurious correlations (shortcuts) has been shown to underlie many of the successes of language models. Previous work focused on identifying the input elements that impact prediction. We investigate how shortcuts are actually processed within the model's decision-making mechanism. We use actor names in movie reviews as controllable shortcuts with known impact on the outcome. We use mechanistic interpretability methods and identify specific attention heads that focus on shortcuts. These heads gear the model towards a label before processing the complete input, effectively making premature decisions that bypass contextual analysis. Based on these findings, we introduce Head-based Token Attribution (HTA), which traces intermediate decisions back to input tokens. We show that HTA is effective in detecting shortcuts in LLMs and enables targeted mitigation by selectively deactivating shortcut-related attention heads.","authors":["Leon Eshuijs","Shihan Wang","Antske Fokkens"],"url":"https://arxiv.org/abs/2505.06032"}
{"created":"2025-05-12","title":"Document Image Rectification Bases on Self-Adaptive Multitask Fusion","abstract":"Deformed document image rectification is essential for real-world document understanding tasks, such as layout analysis and text recognition. However, current multi-task methods -- such as background removal, 3D coordinate prediction, and text line segmentation -- often overlook the complementary features between tasks and their interactions. To address this gap, we propose a self-adaptive learnable multi-task fusion rectification network named SalmRec. This network incorporates an inter-task feature aggregation module that adaptively improves the perception of geometric distortions, enhances feature complementarity, and reduces negative interference. We also introduce a gating mechanism to balance features both within global tasks and between local tasks effectively. Experimental results on two English benchmarks (DIR300 and DocUNet) and one Chinese benchmark (DocReal) demonstrate that our method significantly improves rectification performance. Ablation studies further highlight the positive impact of different tasks on dewarping and the effectiveness of our proposed module.","authors":["Heng Li","Xiangping Wu","Qingcai Chen"],"url":"https://arxiv.org/abs/2505.06038"}
{"created":"2025-05-12","title":"Extending the Control Plane of Container Orchestrators for I/O Virtualization","abstract":"Single Root Input/Output Virtualization (SR-IOV) is a standard technology for forking a single PCI express device and providing it to applications while ensuring performance isolation. It enables container orchestrators to share a limited number of physical network interfaces without incurring significant virtualization overhead. The allocation of virtualized network devices to containers, however, needs to be more configurable based on the bandwidth needs of running applications. Moreover, container orchestrators' network control over the virtualized interfaces is limited by the abilities of SR-IOV. We explore the design considerations for a system with controlled SR-IOV virtualization and present ConRDMA, a novel architecture that enables fine control of RDMA virtualization for containers. Our evaluation shows that ConRDMA enables containers to use RDMA allocated bandwidth more efficiently and to select best-suited nodes to meet their varying communication requirements.","authors":["Garegin Grigoryan","Minseok Kwon","M. Mustafa Rafique"],"url":"https://arxiv.org/abs/2505.06041"}
{"created":"2025-05-12","title":"Learning Music Audio Representations With Limited Data","abstract":"Large deep-learning models for music, including those focused on learning general-purpose music audio representations, are often assumed to require substantial training data to achieve high performance. If true, this would pose challenges in scenarios where audio data or annotations are scarce, such as for underrepresented music traditions, non-popular genres, and personalized music creation and listening. Understanding how these models behave in limited-data scenarios could be crucial for developing techniques to tackle them.","authors":["Christos Plachouras","Emmanouil Benetos","Johan Pauwels"],"url":"https://arxiv.org/abs/2505.06042"}
{"created":"2025-05-12","title":"Triangular preconditioners for double saddle point linear systems arising in the mixed form of poroelasticity equations","abstract":"In this paper, we study a class of inexact block triangular preconditioners for double saddle-point symmetric linear systems arising from the mixed finite element and mixed hybrid finite element discretization of Biot's poroelasticity equations. We develop a spectral analysis of the preconditioned matrix, showing that the complex eigenvalues lie in a circle of center $(1,0)$ and radius smaller than 1. In contrast, the real eigenvalues are described in terms of the roots of a third-degree polynomial with real coefficients. The results of numerical experiments are reported to show the quality of the theoretical bounds and illustrate the efficiency of the proposed preconditioners used with GMRES, especially in comparison with similar block diagonal preconditioning strategies along with the MINRES iteration.","authors":["Luca Bergamaschi","Massimiliano Ferronato","Angeles Martinez"],"url":"https://arxiv.org/abs/2505.06043"}
{"created":"2025-05-12","title":"Designing RoutScape: Geospatial Prototyping with XR for Flood Evacuation Planning","abstract":"Flood response planning in local communities is often hindered by fragmented communication across Disaster Risk Reduction and Management (DRRM) councils. In this work, we explore how extended reality (XR) can support more effective planning through narrative-driven design. We present Routscape, an XR prototype for visualizing flood scenarios and evacuation routes, developed through iterative prototyping and user-centered design with DRRM officers. By grounding the system in real-world experiences and localized narratives, we highlight how XR can aid in fostering shared understanding and spatial sensemaking in disaster preparedness efforts.","authors":["Johndayll Lewis Arizala","Joshua Permito","Steven Errol Escopete","John Kovie Ni\\~no","Jordan Aiko Deja"],"url":"https://arxiv.org/abs/2505.06045"}
{"created":"2025-05-12","title":"Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health Information","abstract":"As Large Language Models (LLMs) become widely accessible, a detailed understanding of their knowledge within specific domains becomes necessary for successful real world use. This is particularly critical in public health, where failure to retrieve relevant, accurate, and current information could significantly impact UK residents. However, currently little is known about LLM knowledge of UK Government public health information. To address this issue, this paper introduces a new benchmark, PubHealthBench, with over 8000 questions for evaluating LLMs' Multiple Choice Question Answering (MCQA) and free form responses to public health queries, created via an automated pipeline. We also release a new dataset of the extracted UK Government public health guidance documents used as source text for PubHealthBench. Assessing 24 LLMs on PubHealthBench we find the latest private LLMs (GPT-4.5, GPT-4.1 and o1) have a high degree of knowledge, achieving >90% in the MCQA setup, and outperform humans with cursory search engine use. However, in the free form setup we see lower performance with no model scoring >75%. Therefore, whilst there are promising signs that state of the art (SOTA) LLMs are an increasingly accurate source of public health information, additional safeguards or tools may still be needed when providing free form responses on public health topics.","authors":["Joshua Harris","Fan Grayson","Felix Feldman","Timothy Laurence","Toby Nonnenmacher","Oliver Higgins","Leo Loman","Selina Patel","Thomas Finnie","Samuel Collins","Michael Borowitz"],"url":"https://arxiv.org/abs/2505.06046"}
{"created":"2025-05-12","title":"PYRREGULAR: A Unified Framework for Irregular Time Series, with Classification Benchmarks","abstract":"Irregular temporal data, characterized by varying recording frequencies, differing observation durations, and missing values, presents significant challenges across fields like mobility, healthcare, and environmental science. Existing research communities often overlook or address these challenges in isolation, leading to fragmented tools and methods. To bridge this gap, we introduce a unified framework, and the first standardized dataset repository for irregular time series classification, built on a common array format to enhance interoperability. This repository comprises 34 datasets on which we benchmark 12 classifier models from diverse domains and communities. This work aims to centralize research efforts and enable a more robust evaluation of irregular temporal data analysis methods.","authors":["Francesco Spinnato","Cristiano Landi"],"url":"https://arxiv.org/abs/2505.06047"}
{"created":"2025-05-12","title":"Seqret: Mining Rule Sets from Event Sequences","abstract":"Summarizing event sequences is a key aspect of data mining. Most existing methods neglect conditional dependencies and focus on discovering sequential patterns only. In this paper, we study the problem of discovering both conditional and unconditional dependencies from event sequence data. We do so by discovering rules of the form $X \\rightarrow Y$ where $X$ and $Y$ are sequential patterns. Rules like these are simple to understand and provide a clear description of the relation between the antecedent and the consequent. To discover succinct and non-redundant sets of rules we formalize the problem in terms of the Minimum Description Length principle. As the search space is enormous and does not exhibit helpful structure, we propose the Seqret method to discover high-quality rule sets in practice. Through extensive empirical evaluation we show that unlike the state of the art, Seqret ably recovers the ground truth on synthetic datasets and finds useful rules from real datasets.","authors":["Aleena Siji","Joscha C\\\"uppers","Osman Ali Mian","Jilles Vreeken"],"url":"https://arxiv.org/abs/2505.06049"}
{"created":"2025-05-12","title":"Safe-EF: Error Feedback for Nonsmooth Constrained Optimization","abstract":"Federated learning faces severe communication bottlenecks due to the high dimensionality of model updates. Communication compression with contractive compressors (e.g., Top-K) is often preferable in practice but can degrade performance without proper handling. Error feedback (EF) mitigates such issues but has been largely restricted for smooth, unconstrained problems, limiting its real-world applicability where non-smooth objectives and safety constraints are critical. We advance our understanding of EF in the canonical non-smooth convex setting by establishing new lower complexity bounds for first-order algorithms with contractive compression. Next, we propose Safe-EF, a novel algorithm that matches our lower bound (up to a constant) while enforcing safety constraints essential for practical applications. Extending our approach to the stochastic setting, we bridge the gap between theory and practical implementation. Extensive experiments in a reinforcement learning setup, simulating distributed humanoid robot training, validate the effectiveness of Safe-EF in ensuring safety and reducing communication complexity.","authors":["Rustem Islamov","Yarden As","Ilyas Fatkhullin"],"url":"https://arxiv.org/abs/2505.06053"}
{"created":"2025-05-12","title":"Towards Better Cephalometric Landmark Detection with Diffusion Data Generation","abstract":"Cephalometric landmark detection is essential for orthodontic diagnostics and treatment planning. Nevertheless, the scarcity of samples in data collection and the extensive effort required for manual annotation have significantly impeded the availability of diverse datasets. This limitation has restricted the effectiveness of deep learning-based detection methods, particularly those based on large-scale vision models. To address these challenges, we have developed an innovative data generation method capable of producing diverse cephalometric X-ray images along with corresponding annotations without human intervention. To achieve this, our approach initiates by constructing new cephalometric landmark annotations using anatomical priors. Then, we employ a diffusion-based generator to create realistic X-ray images that correspond closely with these annotations. To achieve precise control in producing samples with different attributes, we introduce a novel prompt cephalometric X-ray image dataset. This dataset includes real cephalometric X-ray images and detailed medical text prompts describing the images. By leveraging these detailed prompts, our method improves the generation process to control different styles and attributes. Facilitated by the large, diverse generated data, we introduce large-scale vision detection models into the cephalometric landmark detection task to improve accuracy. Experimental results demonstrate that training with the generated data substantially enhances the performance. Compared to methods without using the generated data, our approach improves the Success Detection Rate (SDR) by 6.5%, attaining a notable 82.2%. All code and data are available at: https://um-lab.github.io/cepha-generation","authors":["Dongqian Guo","Wencheng Han","Pang Lyu","Yuxi Zhou","Jianbing Shen"],"url":"https://arxiv.org/abs/2505.06055"}
{"created":"2025-05-12","title":"Scheduled Jacobian Chaining","abstract":"This paper addresses the efficient computation of Jacobian matrices for programs composed of sequential differentiable subprograms. By representing the overall Jacobian as a chain product of the Jacobians of these subprograms, we reduce the problem to optimizing the sequence of matrix multiplications, known as the Jacobian Matrix Chain Product problem. Solutions to this problem yield \"optimal bracketings\", which induce a precedence-constraint scheduling problem. We investigate the inherent parallelism in the solutions and develop a new dynamic programming algorithm as a heuristic that incorporates the scheduling. To assess its performance, we benchmark it against the global optimum, which is computed via a branch-and-bound algorithm.","authors":["Simon M\\\"artens","Uwe Naumann"],"url":"https://arxiv.org/abs/2505.06056"}
{"created":"2025-05-12","title":"Attention on Multiword Expressions: A Multilingual Study of BERT-based Models with Regard to Idiomaticity and Microsyntax","abstract":"This study analyzes the attention patterns of fine-tuned encoder-only models based on the BERT architecture (BERT-based models) towards two distinct types of Multiword Expressions (MWEs): idioms and microsyntactic units (MSUs). Idioms present challenges in semantic non-compositionality, whereas MSUs demonstrate unconventional syntactic behavior that does not conform to standard grammatical categorizations. We aim to understand whether fine-tuning BERT-based models on specific tasks influences their attention to MWEs, and how this attention differs between semantic and syntactic tasks. We examine attention scores to MWEs in both pre-trained and fine-tuned BERT-based models. We utilize monolingual models and datasets in six Indo-European languages - English, German, Dutch, Polish, Russian, and Ukrainian. Our results show that fine-tuning significantly influences how models allocate attention to MWEs. Specifically, models fine-tuned on semantic tasks tend to distribute attention to idiomatic expressions more evenly across layers. Models fine-tuned on syntactic tasks show an increase in attention to MSUs in the lower layers, corresponding with syntactic processing requirements.","authors":["Iuliia Zaitova","Vitalii Hirak","Badr M. Abdullah","Dietrich Klakow","Bernd M\\\"obius","Tania Avgustinova"],"url":"https://arxiv.org/abs/2505.06062"}
{"created":"2025-05-12","title":"Context Informed Incremental Learning Improves Myoelectric Control Performance in Virtual Reality Object Manipulation Tasks","abstract":"Electromyography (EMG)-based gesture recognition is a promising approach for designing intuitive human-computer interfaces. However, while these systems typically perform well in controlled laboratory settings, their usability in real-world applications is compromised by declining performance during real-time control. This decline is largely due to goal-directed behaviors that are not captured in static, offline scenarios. To address this issue, we use \\textit{Context Informed Incremental Learning} (CIIL) - marking its first deployment in an object-manipulation scenario - to continuously adapt the classifier using contextual cues. Nine participants without upper limb differences completed a functional task in a virtual reality (VR) environment involving transporting objects with life-like grips. We compared two scenarios: one where the classifier was adapted in real-time using contextual information, and the other using a traditional open-loop approach without adaptation. The CIIL-based approach not only enhanced task success rates and efficiency, but also reduced the perceived workload by 7.1 %, despite causing a 5.8 % reduction in offline classification accuracy. This study highlights the potential of real-time contextualized adaptation to enhance user experience and usability of EMG-based systems for practical, goal-oriented applications, crucial elements towards their long-term adoption. The source code for this study is available at: https://github.com/BiomedicalITS/ciil-emg-vr.","authors":["Gabriel Gagn\\'e","Anisha Azad","Thomas Labb\\'e","Evan Campbell","Xavier Isabel","Erik Scheme","Ulysse C\\^ot\\'e-Allard","Benoit Gosselin"],"url":"https://arxiv.org/abs/2505.06064"}
{"created":"2025-05-12","title":"Noise-Consistent Siamese-Diffusion for Medical Image Synthesis and Segmentation","abstract":"Deep learning has revolutionized medical image segmentation, yet its full potential remains constrained by the paucity of annotated datasets. While diffusion models have emerged as a promising approach for generating synthetic image-mask pairs to augment these datasets, they paradoxically suffer from the same data scarcity challenges they aim to mitigate. Traditional mask-only models frequently yield low-fidelity images due to their inability to adequately capture morphological intricacies, which can critically compromise the robustness and reliability of segmentation models. To alleviate this limitation, we introduce Siamese-Diffusion, a novel dual-component model comprising Mask-Diffusion and Image-Diffusion. During training, a Noise Consistency Loss is introduced between these components to enhance the morphological fidelity of Mask-Diffusion in the parameter space. During sampling, only Mask-Diffusion is used, ensuring diversity and scalability. Comprehensive experiments demonstrate the superiority of our method. Siamese-Diffusion boosts SANet's mDice and mIoU by 3.6% and 4.4% on the Polyps, while UNet improves by 1.52% and 1.64% on the ISIC2018. Code is available at GitHub.","authors":["Kunpeng Qiu","Zhiqiang Gao","Zhiying Zhou","Mingjie Sun","Yongxin Guo"],"url":"https://arxiv.org/abs/2505.06068"}
{"created":"2025-05-12","title":"Operator Spaces, Linear Logic and the Heisenberg-Schr\\\"odinger Duality of Quantum Theory","abstract":"We show that the category OS of operator spaces, with complete contractions as morphisms, is locally countably presentable and a model of Intuitionistic Linear Logic in the sense of Lafont. We then describe a model of Classical Linear Logic, based on OS, whose duality is compatible with the Heisenberg-Schr\\\"odinger duality of quantum theory. We also show that OS provides a good setting for studying pure state and mixed state quantum information, the interaction between the two, and even higher-order quantum maps such as the quantum switch.","authors":["Bert Lindenhovius","Vladimir Zamdzhiev"],"url":"https://arxiv.org/abs/2505.06069"}
{"created":"2025-05-12","title":"Zero Dynamics Attack Detection and Isolation in Cyber-Physical Systems with Event-triggered Communication","abstract":"This paper investigates the problem of Zero Dynamics (ZD) cyber-attack detection and isolation in Cyber-Physical Systems (CPS). By utilizing the notion of auxiliary systems with event-based communications, we will develop a detection mechanism capable of detecting and isolating the ZD cyber-attack even when the attackers have full knowledge of the dynamics of the auxiliary system and can launch False Data Injection (FDI) attacks on all the communication channels. More specifically, we will utilize a self-triggering rule for the communication channels connecting the auxiliary system with the Command & Control (C&amp;C) center, leveraging its properties to detect the ZD cyber-attack. Finally, the effectiveness and capabilities of our approach are verified and demonstrated through simulation case studies.","authors":["Ali Eslami","Khashayar Khorasani"],"url":"https://arxiv.org/abs/2505.06070"}
{"created":"2025-05-12","title":"Centralized Decision-Making for Platooning By Using SPaT-Driven Reference Speeds","abstract":"This paper introduces a centralized approach for fuel-efficient urban platooning by leveraging real-time Vehicle- to-Everything (V2X) communication and Signal Phase and Timing (SPaT) data. A nonlinear Model Predictive Control (MPC) algorithm optimizes the trajectories of platoon leader vehicles, employing an asymmetric cost function to minimize fuel-intensive acceleration. Following vehicles utilize a gap- and velocity-based control strategy, complemented by dynamic platoon splitting logic communicated through Platoon Control Messages (PCM) and Platoon Awareness Messages (PAM). Simulation results obtained from the CARLA environment demonstrate substantial fuel savings of up to 41.2%, along with smoother traffic flows, fewer vehicle stops, and improved intersection throughput.","authors":["Melih Yazgan","S\\\"uleyman Tatar","J. Marius Z\\\"ollner"],"url":"https://arxiv.org/abs/2505.06071"}
{"created":"2025-05-12","title":"TREND: Tri-teaching for Robust Preference-based Reinforcement Learning with Demonstrations","abstract":"Preference feedback collected by human or VLM annotators is often noisy, presenting a significant challenge for preference-based reinforcement learning that relies on accurate preference labels. To address this challenge, we propose TREND, a novel framework that integrates few-shot expert demonstrations with a tri-teaching strategy for effective noise mitigation. Our method trains three reward models simultaneously, where each model views its small-loss preference pairs as useful knowledge and teaches such useful pairs to its peer network for updating the parameters. Remarkably, our approach requires as few as one to three expert demonstrations to achieve high performance. We evaluate TREND on various robotic manipulation tasks, achieving up to 90% success rates even with noise levels as high as 40%, highlighting its effective robustness in handling noisy preference feedback. Project page: https://shuaiyihuang.github.io/publications/TREND.","authors":["Shuaiyi Huang","Mara Levy","Anubhav Gupta","Daniel Ekpo","Ruijie Zheng","Abhinav Shrivastava"],"url":"https://arxiv.org/abs/2505.06079"}
{"created":"2025-05-12","title":"Fault Diagnosis of 3D-Printed Scaled Wind Turbine Blades","abstract":"This study presents an integrated methodology for fault detection in wind turbine blades using 3D-printed scaled models, finite element simulations, experimental modal analysis, and machine learning techniques. A scaled model of the NREL 5MW blade was fabricated using 3D printing, and crack-type damages were introduced at critical locations. Finite Element Analysis was employed to predict the impact of these damages on the natural frequencies, with the results validated through controlled hammer impact tests. Vibration data was processed to extract both time-domain and frequency-domain features, and key discriminative variables were identified using statistical analyses (ANOVA). Machine learning classifiers, including Support Vector Machine and K-Nearest Neighbors, achieved classification accuracies exceeding 94%. The results revealed that vibration modes 3, 4, and 6 are particularly sensitive to structural anomalies for this blade. This integrated approach confirms the feasibility of combining numerical simulations with experimental validations and paves the way for structural health monitoring systems in wind energy applications.","authors":["Luis Miguel Esquivel-Sancho","Maryam Ghandchi Tehrani","Mauricio Mu\\~noz-Arias","Mahmoud Askari"],"url":"https://arxiv.org/abs/2505.06080"}
{"created":"2025-05-12","title":"HashKitty: Distributed Password Analysis","abstract":"This article documents the HashKitty platform, a distributed solution for password analysis based on the hashcat tool, designed to improve efficiency in both offensive and defensive security operations. The main objectives of this work are to utilise and characterise the hashcat tool, to develop a central platform that connects various computational nodes, to allow the use of nodes with different equipment and manufacturers, to distribute tasks among the nodes through a web platform, and to perform distributed password analysis. The results show that the presented solution achieves the proposed objectives, demonstrating effectiveness in workload distribution and password analysis using different types of nodes based on various operating systems and architectures. The architecture of HashKitty is based on a scalable and modular distributed architecture, composed of several components such as computational nodes, integration and control software, a web platform that implements our API, and database servers. In order to achieve a fast and organised development process for our application we used multiple frameworks, runtimes and libraries. For the communication between the computational nodes and the other software we made use of websockets so that we have real-time updates between them.","authors":["Pedro Antunes","Tom\\'as Santos","Daniel Fuentes","Lu\\'is Fraz\\~ao"],"url":"https://arxiv.org/abs/2505.06084"}
{"created":"2025-05-12","title":"Assessing Tenstorrent's RISC-V MatMul Acceleration Capabilities","abstract":"The increasing demand for generative AI as Large Language Models (LLMs) services has driven the need for specialized hardware architectures that optimize computational efficiency and energy consumption. This paper evaluates the performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic linear algebra kernels at reduced numerical precision, a fundamental operation in LLM computations. We present a detailed characterization of Grayskull's execution model, gridsize, matrix dimensions, data formats, and numerical precision impact computational efficiency. Furthermore, we compare Grayskull's performance against state-of-the-art architectures with tensor acceleration, including Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100). Whilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a competitive trade-off between power consumption and computational throughput, reaching a peak of 1.55 TFLOPs/Watt with BF16.","authors":["Hiari Pizzini Cavagna","Daniele Cesarini","Andrea Bartolini"],"url":"https://arxiv.org/abs/2505.06085"}
{"created":"2025-05-12","title":"Deep Diffusion Maps","abstract":"One of the fundamental problems within the field of machine learning is dimensionality reduction. Dimensionality reduction methods make it possible to combat the so-called curse of dimensionality, visualize high-dimensional data and, in general, improve the efficiency of storing and processing large data sets. One of the best-known nonlinear dimensionality reduction methods is Diffusion Maps. However, despite their virtues, both Diffusion Maps and many other manifold learning methods based on the spectral decomposition of kernel matrices have drawbacks such as the inability to apply them to data outside the initial set, their computational complexity, and high memory costs for large data sets. In this work, we propose to alleviate these problems by resorting to deep learning. Specifically, a new formulation of Diffusion Maps embedding is offered as a solution to a certain unconstrained minimization problem and, based on it, a cost function to train a neural network which computes Diffusion Maps embedding -- both inside and outside the training sample -- without the need to perform any spectral decomposition. The capabilities of this approach are compared on different data sets, both real and synthetic, with those of Diffusion Maps and the Nystrom method.","authors":["Sergio Garc\\'ia-Heredia","\\'Angela Fern\\'andez","Carlos M. Ala\\'iz"],"url":"https://arxiv.org/abs/2505.06087"}
{"created":"2025-05-12","title":"Orthogonal Emptiness Queries for Random Points","abstract":"We present a data-structure for orthogonal range searching for random points in the plane. The new data-structure uses (in expectation) $O\\bigl(n \\log n ( \\log \\log n)^2 \\bigr)$ space, and answers emptiness queries in constant time. As a building block, we construct a data-structure of expected linear size, that can answer predecessor/rank queries, in constant time, for random numbers sampled uniformly from $[0,1]$.","authors":["Jonathan E. Dullerud","Sariel Har-Peled"],"url":"https://arxiv.org/abs/2505.06090"}
{"created":"2025-05-12","title":"UniSymNet: A Unified Symbolic Network Guided by Transformer","abstract":"Symbolic Regression (SR) is a powerful technique for automatically discovering mathematical expressions from input data. Mainstream SR algorithms search for the optimal symbolic tree in a vast function space, but the increasing complexity of the tree structure limits their performance. Inspired by neural networks, symbolic networks have emerged as a promising new paradigm. However, most existing symbolic networks still face certain challenges: binary nonlinear operators $\\{\\times, \\div\\}$ cannot be naturally extended to multivariate operators, and training with fixed architecture often leads to higher complexity and overfitting. In this work, we propose a Unified Symbolic Network that unifies nonlinear binary operators into nested unary operators and define the conditions under which UniSymNet can reduce complexity. Moreover, we pre-train a Transformer model with a novel label encoding method to guide structural selection, and adopt objective-specific optimization strategies to learn the parameters of the symbolic network. UniSymNet shows high fitting accuracy, excellent symbolic solution rate, and relatively low expression complexity, achieving competitive performance on low-dimensional Standard Benchmarks and high-dimensional SRBench.","authors":["Xinxin Li","Juan Zhang","Da Li","Xingyu Liu","Jin Xu","Junping Yin"],"url":"https://arxiv.org/abs/2505.06091"}
{"created":"2025-05-12","title":"Robot Learning Using Multi-Coordinate Elastic Maps","abstract":"To learn manipulation skills, robots need to understand the features of those skills. An easy way for robots to learn is through Learning from Demonstration (LfD), where the robot learns a skill from an expert demonstrator. While the main features of a skill might be captured in one differential coordinate (i.e., Cartesian), they could have meaning in other coordinates. For example, an important feature of a skill may be its shape or velocity profile, which are difficult to discover in Cartesian differential coordinate. In this work, we present a method which enables robots to learn skills from human demonstrations via encoding these skills into various differential coordinates, then determines the importance of each coordinate to reproduce the skill. We also introduce a modified form of Elastic Maps that includes multiple differential coordinates, combining statistical modeling of skills in these differential coordinate spaces. Elastic Maps, which are flexible and fast to compute, allow for the incorporation of several different types of constraints and the use of any number of demonstrations. Additionally, we propose methods for auto-tuning several parameters associated with the modified Elastic Map formulation. We validate our approach in several simulated experiments and a real-world writing task with a UR5e manipulator arm.","authors":["Brendan Hertel","Reza Azadeh"],"url":"https://arxiv.org/abs/2505.06092"}
{"created":"2025-05-12","title":"Free and Fair Hardware: A Pathway to Copyright Infringement-Free Verilog Generation using LLMs","abstract":"Limitations in Large Language Model (LLM) capabilities for hardware design tasks, such as generating functional Verilog codes, have motivated various fine-tuning optimizations utilizing curated hardware datasets from open-source repositories. However, these datasets remain limited in size and contain minimal checks on licensing for reuse, resulting in potential copyright violations by fine-tuned LLMs. Therefore, we propose an evaluation benchmark to estimate the risk of Verilog-trained LLMs to generate copyright-protected codes. To minimize this risk, we present an open-source Verilog dataset, FreeSet, containing over 220k files, along with the automated dataset curation framework utilized to provide additional guarantees of fair-use Verilog data. We then execute an LLM fine-tuning framework consisting of continual pre-training, resulting in a fine-tuned Llama model for Verilog, FreeV. Our results indicate that FreeV demonstrates the smallest risk of copyright-infringement among prior works, with only a 3% violation rate. Furthermore, experimental results demonstrate improvements in Verilog generation functionality over its baseline model, improving VerilogEval pass@10 rates by over 10%.","authors":["Sam Bush","Matthew DeLorenzo","Phat Tieu","Jeyavijayan Rajendran"],"url":"https://arxiv.org/abs/2505.06096"}
{"created":"2025-05-12","title":"Discretized Approximate Ancestral Sampling","abstract":"The Fourier Basis Density Model (FBM) was recently introduced as a flexible probability model for band-limited distributions, i.e. ones which are smooth in the sense of having a characteristic function with limited support around the origin. Its density and cumulative distribution functions can be efficiently evaluated and trained with stochastic optimization methods, which makes the model suitable for deep learning applications. However, the model lacked support for sampling. Here, we introduce a method inspired by discretization--interpolation methods common in Digital Signal Processing, which directly take advantage of the band-limited property. We review mathematical properties of the FBM, and prove quality bounds of the sampled distribution in terms of the total variation (TV) and Wasserstein--1 divergences from the model. These bounds can be used to inform the choice of hyperparameters to reach any desired sample quality. We discuss these results in comparison to a variety of other sampling techniques, highlighting tradeoffs between computational complexity and sampling quality.","authors":["Alfredo De la Fuente","Saurabh Singh","Jona Ball\\'e"],"url":"https://arxiv.org/abs/2505.06098"}
{"created":"2025-05-12","title":"Parameter-Free Segmentation of Robot Movements with Cross-Correlation Using Different Similarity Metrics","abstract":"Often, robots are asked to execute primitive movements, whether as a single action or in a series of actions representing a larger, more complex task. These movements can be learned in many ways, but a common one is from demonstrations presented to the robot by a teacher. However, these demonstrations are not always simple movements themselves, and complex demonstrations must be broken down, or segmented, into primitive movements. In this work, we present a parameter-free approach to segmentation using techniques inspired by autocorrelation and cross-correlation from signal processing. In cross-correlation, a representative signal is found in some larger, more complex signal by correlating the representative signal with the larger signal. This same idea can be applied to segmenting robot motion and demonstrations, provided with a representative motion primitive. This results in a fast and accurate segmentation, which does not take any parameters. One of the main contributions of this paper is the modification of the cross-correlation process by employing similarity metrics that can capture features specific to robot movements. To validate our framework, we conduct several experiments of complex tasks both in simulation and in real-world. We also evaluate the effectiveness of our segmentation framework by comparing various similarity metrics.","authors":["Wendy Carvalho","Meriem Elkoudi","Brendan Hertel","Reza Azadeh"],"url":"https://arxiv.org/abs/2505.06100"}
{"created":"2025-05-12","title":"Unconditionally local bounds preserving numerical scheme based on inverse Lax-Wendroff procedure for advection on networks","abstract":"We derive an implicit numerical scheme for the solution of advection equation where the roles of space and time variables are exchanged using the inverse Lax-Wendroff procedure. The scheme contains a linear weight for which it is always second order accurate in time and space, and the stencil in the implicit part is fully upwinded for any value of the weight, enabling a direct computation of numerical solutions by forward substitution. To fulfill the local bounds for the solution represented by the discrete minimum and maximum principle (DMP), we use a predicted value obtained with the linear weight and check a priori if the DMP is valid. If not, we can use either a nonlinear weight or a limiter function that depends on Courant number and apply such a high-resolution version of the scheme to obtain a corrected value. The advantage of the scheme obtained with the inverse Lax-Wendroff procedure is that only in the case of too small Courant numbers, the limiting is towards the first order accurate scheme, which is not a situation occurring in numerical simulations with implicit schemes very often. In summary, the local bounds are satisfied up to rounding errors unconditionally for any Courant numbers, and the formulas for the predictor and the corrector are explicit. The high-resolution scheme can be extended straightforwardly for advection with nonlinear retardation coefficient with numerical solutions satisfying the DMP, and a scalar nonlinear algebraic equation has to be solved to obtain each predicted and corrected value. In numerical experiments, including transport on a sewer network, we can confirm the advantageous properties of numerical solutions for several representative examples.","authors":["Peter Frolkovi\\v{c}","Svetlana Kri\\v{s}kov\\'a","Katar\\'ina Lackov\\'a"],"url":"https://arxiv.org/abs/2505.06106"}
{"created":"2025-05-12","title":"Differentiating Emigration from Return Migration of Scholars Using Name-Based Nationality Detection Models","abstract":"Most web and digital trace data do not include information about an individual's nationality due to privacy concerns. The lack of data on nationality can create challenges for migration research. It can lead to a left-censoring issue since we are uncertain about the migrant's country of origin. Once we observe an emigration event, if we know the nationality, we can differentiate it from return migration. We propose methods to detect the nationality with the least available data, i.e., full names. We use the detected nationality in comparison with the country of academic origin, which is a common approach in studying the migration of researchers. We gathered 2.6 million unique name-nationality pairs from Wikipedia and categorized them into families of nationalities with three granularity levels to use as our training data. Using a character-based machine learning model, we achieved a weighted F1 score of 84% for the broadest and 67% for the most granular, country-level categorization. In our empirical study, we used the trained and tested model to assign nationality to 8+ million scholars' full names in Scopus data. Our results show that using the country of first publication as a proxy for nationality underestimates the size of return flows, especially for countries with a more diverse academic workforce, such as the USA, Australia, and Canada. We found that around 48% of emigration from the USA was return migration once we used the country of name origin, in contrast to 33% based on academic origin. In the most recent period, 79% of scholars whose affiliation has consistently changed from the USA to China, and are considered emigrants, have Chinese names in contrast to 41% with a Chinese academic origin. Our proposed methods for addressing left-censoring issues are beneficial for other research that uses digital trace data to study migration.","authors":["Faeze Ghorbanpour","Thiago Zordan Malaguth","Aliakbar Akbaritabar"],"url":"https://arxiv.org/abs/2505.06107"}
{"created":"2025-05-12","title":"LLMs Outperform Experts on Challenging Biology Benchmarks","abstract":"This study systematically evaluates 27 frontier Large Language Models on eight diverse biology benchmarks spanning molecular biology, genetics, cloning, virology, and biosecurity. Models from major AI developers released between November 2022 and April 2025 were assessed through ten independent runs per benchmark. The findings reveal dramatic improvements in biological capabilities. Top model performance increased more than 4-fold on the challenging text-only subset of the Virology Capabilities Test over the study period, with the top model now performing twice as well as expert virologists. Several models now match or exceed expert-level performance on other challenging benchmarks, including LAB-Bench CloningScenarios and the biology subsets of GPQA and WMDP. Contrary to expectations, chain-of-thought did not substantially improve performance over zero-shot evaluation, while extended reasoning features in o3-mini and Claude 3.7 Sonnet typically improved performance as predicted by inference scaling. Benchmarks such as PubMedQA and the MMLU and WMDP biology subsets exhibited performance plateaus well below 100%, suggesting benchmark saturation and errors in the underlying benchmark data. The analysis highlights the need for more sophisticated evaluation methodologies as AI systems continue to advance.","authors":["Lennart Justen"],"url":"https://arxiv.org/abs/2505.06108"}
{"created":"2025-05-12","title":"Multimodal Sentiment Analysis on CMU-MOSEI Dataset using Transformer-based Models","abstract":"This project performs multimodal sentiment analysis using the CMU-MOSEI dataset, using transformer-based models with early fusion to integrate text, audio, and visual modalities. We employ BERT-based encoders for each modality, extracting embeddings that are concatenated before classification. The model achieves strong performance, with 97.87\\% 7-class accuracy and a 0.9682 F1-score on the test set, demonstrating the effectiveness of early fusion in capturing cross-modal interactions. The training utilized Adam optimization (lr=1e-4), dropout (0.3), and early stopping to ensure generalization and robustness. Results highlight the superiority of transformer architectures in modeling multimodal sentiment, with a low MAE (0.1060) indicating precise sentiment intensity prediction. Future work may compare fusion strategies or enhance interpretability. This approach utilizes multimodal learning by effectively combining linguistic, acoustic, and visual cues for sentiment analysis.","authors":["Jugal Gajjar","Kaustik Ranaware"],"url":"https://arxiv.org/abs/2505.06110"}
{"created":"2025-05-12","title":"UniVLA: Learning to Act Anywhere with Task-centric Latent Actions","abstract":"A generalist robot should perform effectively across various environments. However, most existing approaches heavily rely on scaling action-annotated data to enhance their capabilities. Consequently, they are often limited to single physical specification and struggle to learn transferable knowledge across different embodiments and environments. To confront these limitations, we propose UniVLA, a new framework for learning cross-embodiment vision-language-action (VLA) policies. Our key innovation is to derive task-centric action representations from videos with a latent action model. This enables us to exploit extensive data across a wide spectrum of embodiments and perspectives. To mitigate the effect of task-irrelevant dynamics, we incorporate language instructions and establish a latent action model within the DINO feature space. Learned from internet-scale videos, the generalist policy can be deployed to various robots through efficient latent action decoding. We obtain state-of-the-art results across multiple manipulation and navigation benchmarks, as well as real-robot deployments. UniVLA achieves superior performance over OpenVLA with less than 1/20 of pretraining compute and 1/10 of downstream data. Continuous performance improvements are observed as heterogeneous data, even including human videos, are incorporated into the training pipeline. The results underscore UniVLA's potential to facilitate scalable and efficient robot policy learning.","authors":["Qingwen Bu","Yanting Yang","Jisong Cai","Shenyuan Gao","Guanghui Ren","Maoqing Yao","Ping Luo","Hongyang Li"],"url":"https://arxiv.org/abs/2505.06111"}
{"created":"2025-05-12","title":"Camera-Only Bird's Eye View Perception: A Neural Approach to LiDAR-Free Environmental Mapping for Autonomous Vehicles","abstract":"Autonomous vehicle perception systems have traditionally relied on costly LiDAR sensors to generate precise environmental representations. In this paper, we propose a camera-only perception framework that produces Bird's Eye View (BEV) maps by extending the Lift-Splat-Shoot architecture. Our method combines YOLOv11-based object detection with DepthAnythingV2 monocular depth estimation across multi-camera inputs to achieve comprehensive 360-degree scene understanding. We evaluate our approach on the OpenLane-V2 and NuScenes datasets, achieving up to 85% road segmentation accuracy and 85-90% vehicle detection rates when compared against LiDAR ground truth, with average positional errors limited to 1.2 meters. These results highlight the potential of deep learning to extract rich spatial information using only camera inputs, enabling cost-efficient autonomous navigation without sacrificing accuracy.","authors":["Anupkumar Bochare"],"url":"https://arxiv.org/abs/2505.06113"}
{"created":"2025-05-12","title":"FIC-TSC: Learning Time Series Classification with Fisher Information Constraint","abstract":"Analyzing time series data is crucial to a wide spectrum of applications, including economics, online marketplaces, and human healthcare. In particular, time series classification plays an indispensable role in segmenting different phases in stock markets, predicting customer behavior, and classifying worker actions and engagement levels. These aspects contribute significantly to the advancement of automated decision-making and system optimization in real-world applications. However, there is a large consensus that time series data often suffers from domain shifts between training and test sets, which dramatically degrades the classification performance. Despite the success of (reversible) instance normalization in handling the domain shifts for time series regression tasks, its performance in classification is unsatisfactory. In this paper, we propose \\textit{FIC-TSC}, a training framework for time series classification that leverages Fisher information as the constraint. We theoretically and empirically show this is an efficient and effective solution to guide the model converge toward flatter minima, which enhances its generalizability to distribution shifts. We rigorously evaluate our method on 30 UEA multivariate and 85 UCR univariate datasets. Our empirical results demonstrate the superiority of the proposed method over 14 recent state-of-the-art methods.","authors":["Xiwen Chen","Wenhui Zhu","Peijie Qiu","Hao Wang","Huayu Li","Zihan Li","Yalin Wang","Aristeidis Sotiras","Abolfazl Razi"],"url":"https://arxiv.org/abs/2505.06114"}
{"created":"2025-05-12","title":"Photovoltaic Defect Image Generator with Boundary Alignment Smoothing Constraint for Domain Shift Mitigation","abstract":"Accurate defect detection of photovoltaic (PV) cells is critical for ensuring quality and efficiency in intelligent PV manufacturing systems. However, the scarcity of rich defect data poses substantial challenges for effective model training. While existing methods have explored generative models to augment datasets, they often suffer from instability, limited diversity, and domain shifts. To address these issues, we propose PDIG, a Photovoltaic Defect Image Generator based on Stable Diffusion (SD). PDIG leverages the strong priors learned from large-scale datasets to enhance generation quality under limited data. Specifically, we introduce a Semantic Concept Embedding (SCE) module that incorporates text-conditioned priors to capture the relational concepts between defect types and their appearances. To further enrich the domain distribution, we design a Lightweight Industrial Style Adaptor (LISA), which injects industrial defect characteristics into the SD model through cross-disentangled attention. At inference, we propose a Text-Image Dual-Space Constraints (TIDSC) module, enforcing the quality of generated images via positional consistency and spatial smoothing alignment. Extensive experiments demonstrate that PDIG achieves superior realism and diversity compared to state-of-the-art methods. Specifically, our approach improves Frechet Inception Distance (FID) by 19.16 points over the second-best method and significantly enhances the performance of downstream defect detection tasks.","authors":["Dongying Li","Binyi Su","Hua Zhang","Yong Li","Haiyong Chen"],"url":"https://arxiv.org/abs/2505.06117"}
{"created":"2025-05-12","title":"Distributed Tensor Network Library for Quantum Computing Emulation","abstract":"Tensor networks offer an adaptable and efficient approach to emulation of quantum computers. Their usage relies on partitioning circuits into small tensors, which are contracted together to form the final result. While this approach intends to minimise the problem size, exceeding the locally available memory is sometimes unavoidable due to the exponential nature of quantum systems. Most HPC tensor network packages tackle this issue with a procedure called circuit slicing, which distributes the entire network onto multiple ranks, recombining it back when necessary. In this study, we present a novel alternative approach, where individual tensors are both broadcast and scattered to harness multiple levels of parallelism. The technique is abstracted behind a fixed distribution pattern, and actualised in a new portable tensor network library, QTNH, built on top of MPI and ScaLAPACK. We showcase its capabilities on ARCHER2, by emulating two well-known algorithms - the Quantum Fourier Transform and Random Circuit Sampling. This is accomplished by leveraging the implemented operations to realise various contraction strategies, including a unique distributed MPS tensor factorisation approach. We thus demonstrate that our library can be used to advance the accuracy of quantum emulation, while offering a simple and flexible interface to tensor distribution.","authors":["Jakub Adamski","Oliver Thomson Brown"],"url":"https://arxiv.org/abs/2505.06119"}
{"created":"2025-05-12","title":"LLMs Get Lost In Multi-Turn Conversation","abstract":"Large Language Models (LLMs) are conversational interfaces. As such, LLMs have the potential to assist their users not only when they can fully specify the task at hand, but also to help them define, explore, and refine what they need through multi-turn conversational exchange. Although analysis of LLM conversation logs has confirmed that underspecification occurs frequently in user instructions, LLM evaluation has predominantly focused on the single-turn, fully-specified instruction setting. In this work, we perform large-scale simulation experiments to compare LLM performance in single- and multi-turn settings. Our experiments confirm that all the top open- and closed-weight LLMs we test exhibit significantly lower performance in multi-turn conversations than single-turn, with an average drop of 39% across six generation tasks. Analysis of 200,000+ simulated conversations decomposes the performance degradation into two components: a minor loss in aptitude and a significant increase in unreliability. We find that LLMs often make assumptions in early turns and prematurely attempt to generate final solutions, on which they overly rely. In simpler terms, we discover that *when LLMs take a wrong turn in a conversation, they get lost and do not recover*.","authors":["Philippe Laban","Hiroaki Hayashi","Yingbo Zhou","Jennifer Neville"],"url":"https://arxiv.org/abs/2505.06120"}
{"created":"2025-05-12","title":"Interaction-Aware Parameter Privacy-Preserving Data Sharing in Coupled Systems via Particle Filter Reinforcement Learning","abstract":"This paper addresses the problem of parameter privacy-preserving data sharing in coupled systems, where a data provider shares data with a data user but wants to protect its sensitive parameters. The shared data affects not only the data user's decision-making but also the data provider's operations through system interactions. To trade off control performance and privacy, we propose an interaction-aware privacy-preserving data sharing approach. Our approach generates distorted data by minimizing a combination of (i) mutual information, quantifying privacy leakage of sensitive parameters, and (ii) the impact of distorted data on the data provider's control performance, considering the interactions between stakeholders. The optimization problem is formulated into a Bellman equation and solved by a particle filter reinforcement learning (RL)-based approach. Compared to existing RL-based methods, our formulation significantly reduces history dependency and efficiently handles scenarios with continuous state space. Validated in a mixed-autonomy platoon scenario, our method effectively protects sensitive driving behavior parameters of human-driven vehicles (HDVs) against inference attacks while maintaining negligible impact on fuel efficiency.","authors":["Haokun Yu","Jingyuan Zhou","Kaidi Yang"],"url":"https://arxiv.org/abs/2505.06122"}
{"created":"2025-05-12","title":"Wasserstein Distances Made Explainable: Insights into Dataset Shifts and Transport Phenomena","abstract":"Wasserstein distances provide a powerful framework for comparing data distributions. They can be used to analyze processes over time or to detect inhomogeneities within data. However, simply calculating the Wasserstein distance or analyzing the corresponding transport map (or coupling) may not be sufficient for understanding what factors contribute to a high or low Wasserstein distance. In this work, we propose a novel solution based on Explainable AI that allows us to efficiently and accurately attribute Wasserstein distances to various data components, including data subgroups, input features, or interpretable subspaces. Our method achieves high accuracy across diverse datasets and Wasserstein distance specifications, and its practical utility is demonstrated in two use cases.","authors":["Philip Naumann","Jacob Kauffmann","Gr\\'egoire Montavon"],"url":"https://arxiv.org/abs/2505.06123"}
{"created":"2025-05-12","title":"KRRF: Kinodynamic Rapidly-exploring Random Forest algorithm for multi-goal motion planning","abstract":"The problem of kinodynamic multi-goal motion planning is to find a trajectory over multiple target locations with an apriori unknown sequence of visits. The objective is to minimize the cost of the trajectory planned in a cluttered environment for a robot with a kinodynamic motion model. This problem has yet to be efficiently solved as it combines two NP-hard problems, the Traveling Salesman Problem~(TSP) and the kinodynamic motion planning problem. We propose a novel approximate method called Kinodynamic Rapidly-exploring Random Forest~(KRRF) to find a collision-free multi-goal trajectory that satisfies the motion constraints of the robot. KRRF simultaneously grows kinodynamic trees from all targets towards all other targets while using the other trees as a heuristic to boost the growth. Once the target-to-target trajectories are planned, their cost is used to solve the TSP to find the sequence of targets. The final multi-goal trajectory satisfying kinodynamic constraints is planned by guiding the RRT-based planner along the target-to-target trajectories in the TSP sequence. Compared with existing approaches, KRRF provides shorter target-to-target trajectories and final multi-goal trajectories with $1.1-2$ times lower costs while being computationally faster in most test cases. The method will be published as an open-source library.","authors":["Petr Je\\v{z}ek","Michal Mina\\v{r}\\'ik","Vojt\\v{e}ch Von\\'asek","Robert P\\v{e}ni\\v{c}ka"],"url":"https://arxiv.org/abs/2505.06126"}
{"created":"2025-05-12","title":"ELA-ZSON: Efficient Layout-Aware Zero-Shot Object Navigation Agent with Hierarchical Planning","abstract":"We introduce ELA-ZSON, an efficient layout-aware zero-shot object navigation (ZSON) approach designed for complex multi-room indoor environments.","authors":["Jiawei Hou","Yuting Xiao","Xiangyang Xue","Taiping Zeng"],"url":"https://arxiv.org/abs/2505.06131"}
{"created":"2025-05-12","title":"BrainSegDMlF: A Dynamic Fusion-enhanced SAM for Brain Lesion Segmentation","abstract":"The segmentation of substantial brain lesions is a significant and challenging task in the field of medical image segmentation. Substantial brain lesions in brain imaging exhibit high heterogeneity, with indistinct boundaries between lesion regions and normal brain tissue. Small lesions in single slices are difficult to identify, making the accurate and reproducible segmentation of abnormal regions, as well as their feature description, highly complex. Existing methods have the following limitations: 1) They rely solely on single-modal information for learning, neglecting the multi-modal information commonly used in diagnosis. This hampers the ability to comprehensively acquire brain lesion information from multiple perspectives and prevents the effective integration and utilization of multi-modal data inputs, thereby limiting a holistic understanding of lesions. 2) They are constrained by the amount of data available, leading to low sensitivity to small lesions and difficulty in detecting subtle pathological changes. 3) Current SAM-based models rely on external prompts, which cannot achieve automatic segmentation and, to some extent, affect diagnostic efficiency.To address these issues, we have developed a large-scale fully automated segmentation model specifically designed for brain lesion segmentation, named BrainSegDMLF. This model has the following features: 1) Dynamic Modal Interactive Fusion (DMIF) module that processes and integrates multi-modal data during the encoding process, providing the SAM encoder with more comprehensive modal information. 2) Layer-by-Layer Upsampling Decoder, enabling the model to extract rich low-level and high-level features even with limited data, thereby detecting the presence of small lesions. 3) Automatic segmentation masks, allowing the model to generate lesion masks automatically without requiring manual prompts.","authors":["Hongming Wang","Yifeng Wu","Huimin Huang","Hongtao Wu","Jia-Xuan Jiang","Xiaodong Zhang","Hao Zheng","Xian Wu","Yefeng Zheng","Jinping Xu","Jing Cheng"],"url":"https://arxiv.org/abs/2505.06133"}
{"created":"2025-05-12","title":"Realistic Adversarial Attacks for Robustness Evaluation of Trajectory Prediction Models via Future State Perturbation","abstract":"Trajectory prediction is a key element of autonomous vehicle systems, enabling them to anticipate and react to the movements of other road users. Evaluating the robustness of prediction models against adversarial attacks is essential to ensure their reliability in real-world traffic. However, current approaches tend to focus on perturbing the past positions of surrounding agents, which can generate unrealistic scenarios and overlook critical vulnerabilities. This limitation may result in overly optimistic assessments of model performance in real-world conditions.","authors":["Julian F. Schumann","Jeroen Hagenus","Frederik Baymler Mathiesen","Arkady Zgonnikov"],"url":"https://arxiv.org/abs/2505.06134"}
{"created":"2025-05-12","title":"Efficient Sensorimotor Learning for Open-world Robot Manipulation","abstract":"This dissertation considers Open-world Robot Manipulation, a manipulation problem where a robot must generalize or quickly adapt to new objects, scenes, or tasks for which it has not been pre-programmed or pre-trained. This dissertation tackles the problem using a methodology of efficient sensorimotor learning. The key to enabling efficient sensorimotor learning lies in leveraging regular patterns that exist in limited amounts of demonstration data. These patterns, referred to as ``regularity,'' enable the data-efficient learning of generalizable manipulation skills. This dissertation offers a new perspective on formulating manipulation problems through the lens of regularity. Building upon this notion, we introduce three major contributions. First, we introduce methods that endow robots with object-centric priors, allowing them to learn generalizable, closed-loop sensorimotor policies from a small number of teleoperation demonstrations. Second, we introduce methods that constitute robots' spatial understanding, unlocking their ability to imitate manipulation skills from in-the-wild video observations. Last but not least, we introduce methods that enable robots to identify reusable skills from their past experiences, resulting in systems that can continually imitate multiple tasks in a sequential manner. Altogether, the contributions of this dissertation help lay the groundwork for building general-purpose personal robots that can quickly adapt to new situations or tasks with low-cost data collection and interact easily with humans. By enabling robots to learn and generalize from limited data, this dissertation takes a step toward realizing the vision of intelligent robotic assistants that can be seamlessly integrated into everyday scenarios.","authors":["Yifeng Zhu"],"url":"https://arxiv.org/abs/2505.06136"}
{"created":"2025-05-12","title":"Towards Robust Few-Shot Text Classification Using Transformer Architectures and Dual Loss Strategies","abstract":"Few-shot text classification has important application value in low-resource environments. This paper proposes a strategy that combines adaptive fine-tuning, contrastive learning, and regularization optimization to improve the classification performance of Transformer-based models. Experiments on the FewRel 2.0 dataset show that T5-small, DeBERTa-v3, and RoBERTa-base perform well in few-shot tasks, especially in the 5-shot setting, which can more effectively capture text features and improve classification accuracy. The experiment also found that there are significant differences in the classification difficulty of different relationship categories. Some categories have fuzzy semantic boundaries or complex feature distributions, making it difficult for the standard cross entropy loss to learn the discriminative information required to distinguish categories. By introducing contrastive loss and regularization loss, the generalization ability of the model is enhanced, effectively alleviating the overfitting problem in few-shot environments. In addition, the research results show that the use of Transformer models or generative architectures with stronger self-attention mechanisms can help improve the stability and accuracy of few-shot classification.","authors":["Xu Han","Yumeng Sun","Weiqiang Huang","Hongye Zheng","Junliang Du"],"url":"https://arxiv.org/abs/2505.06145"}
{"created":"2025-05-12","title":"Learning-Augmented Algorithms for Boolean Satisfiability","abstract":"Learning-augmented algorithms are a prominent recent development in beyond worst-case analysis. In this framework, a problem instance is provided with a prediction (``advice'') from a machine-learning oracle, which provides partial information about an optimal solution, and the goal is to design algorithms that leverage this advice to improve worst-case performance. We study the classic Boolean satisfiability (SAT) decision and optimization problems within this framework using two forms of advice. ``Subset advice\" provides a random $\\epsilon$ fraction of the variables from an optimal assignment, whereas ``label advice\" provides noisy predictions for all variables in an optimal assignment.","authors":["Idan Attias","Xing Gao","Lev Reyzin"],"url":"https://arxiv.org/abs/2505.06146"}
{"created":"2025-05-12","title":"Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study","abstract":"Despite growing interest in automated hate speech detection, most existing approaches overlook the linguistic diversity of online content. Multilingual instruction-tuned large language models such as LLaMA, Aya, Qwen, and BloomZ offer promising capabilities across languages, but their effectiveness in identifying hate speech through zero-shot and few-shot prompting remains underexplored. This work evaluates LLM prompting-based detection across eight non-English languages, utilizing several prompting techniques and comparing them to fine-tuned encoder models. We show that while zero-shot and few-shot prompting lag behind fine-tuned encoder models on most of the real-world evaluation sets, they achieve better generalization on functional tests for hate speech detection. Our study also reveals that prompt design plays a critical role, with each language often requiring customized prompting techniques to maximize performance.","authors":["Faeze Ghorbanpour","Daryna Dementieva","Alexander Fraser"],"url":"https://arxiv.org/abs/2505.06149"}
{"created":"2025-05-12","title":"A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets","abstract":"We introduce a scaling law for fine-tuning large language models (LLMs) under fixed compute budgets that explicitly accounts for data composition. Conventional approaches measure training data solely by total tokens, yet the number of examples and their average token length -- what we term \\emph{dataset volume} -- play a decisive role in model performance. Our formulation is tuned following established procedures. Experiments on the BRICC dataset \\cite{salavati2024reducing} and subsets of the MMLU dataset \\cite{hendrycks2021measuringmassivemultitasklanguage}, evaluated under multiple subsampling strategies, reveal that data composition significantly affects token efficiency. These results motivate refined scaling laws for practical LLM fine-tuning in resource-constrained settings.","authors":["Ryan Lagasse","Aidan Kiernans","Avijit Ghosh","Shiri Dori-Hacohen"],"url":"https://arxiv.org/abs/2505.06150"}
{"created":"2025-05-12","title":"Estimating Quality in Therapeutic Conversations: A Multi-Dimensional Natural Language Processing Framework","abstract":"Engagement between client and therapist is a critical determinant of therapeutic success. We propose a multi-dimensional natural language processing (NLP) framework that objectively classifies engagement quality in counseling sessions based on textual transcripts. Using 253 motivational interviewing transcripts (150 high-quality, 103 low-quality), we extracted 42 features across four domains: conversational dynamics, semantic similarity as topic alignment, sentiment classification, and question detection. Classifiers, including Random Forest (RF), Cat-Boost, and Support Vector Machines (SVM), were hyperparameter tuned and trained using a stratified 5-fold cross-validation and evaluated on a holdout test set. On balanced (non-augmented) data, RF achieved the highest classification accuracy (76.7%), and SVM achieved the highest AUC (85.4%). After SMOTE-Tomek augmentation, performance improved significantly: RF achieved up to 88.9% accuracy, 90.0% F1-score, and 94.6% AUC, while SVM reached 81.1% accuracy, 83.1% F1-score, and 93.6% AUC. The augmented data results reflect the potential of the framework in future larger-scale applications. Feature contribution revealed conversational dynamics and semantic similarity between clients and therapists were among the top contributors, led by words uttered by the client (mean and standard deviation). The framework was robust across the original and augmented datasets and demonstrated consistent improvements in F1 scores and recall. While currently text-based, the framework supports future multimodal extensions (e.g., vocal tone, facial affect) for more holistic assessments. This work introduces a scalable, data-driven method for evaluating engagement quality of the therapy session, offering clinicians real-time feedback to enhance the quality of both virtual and in-person therapeutic interactions.","authors":["Alice Rueda","Argyrios Perivolaris","Niloy Roy","Dylan Weston","Sarmed Shaya","Zachary Cote","Martin Ivanov","Bazen G. Teferra","Yuqi Wu","Sirisha Rambhatla","Divya Sharma","Andrew Greenshaw","Rakesh Jetly","Yanbo Zhang","Bo Cao","Reza Samavi","Sridhar Krishnan","Venkat Bhat"],"url":"https://arxiv.org/abs/2505.06151"}
{"created":"2025-05-12","title":"MM-Skin: Enhancing Dermatology Vision-Language Model with an Image-Text Dataset Derived from Textbooks","abstract":"Medical vision-language models (VLMs) have shown promise as clinical assistants across various medical fields. However, specialized dermatology VLM capable of delivering professional and detailed diagnostic analysis remains underdeveloped, primarily due to less specialized text descriptions in current dermatology multimodal datasets. To address this issue, we propose MM-Skin, the first large-scale multimodal dermatology dataset that encompasses 3 imaging modalities, including clinical, dermoscopic, and pathological and nearly 10k high-quality image-text pairs collected from professional textbooks. In addition, we generate over 27k diverse, instruction-following vision question answering (VQA) samples (9 times the size of current largest dermatology VQA dataset). Leveraging public datasets and MM-Skin, we developed SkinVL, a dermatology-specific VLM designed for precise and nuanced skin disease interpretation. Comprehensive benchmark evaluations of SkinVL on VQA, supervised fine-tuning (SFT) and zero-shot classification tasks across 8 datasets, reveal its exceptional performance for skin diseases in comparison to both general and medical VLM models. The introduction of MM-Skin and SkinVL offers a meaningful contribution to advancing the development of clinical dermatology VLM assistants. MM-Skin is available at https://github.com/ZwQ803/MM-Skin","authors":["Wenqi Zeng","Yuqi Sun","Chenxi Ma","Weimin Tan","Bo Yan"],"url":"https://arxiv.org/abs/2505.06152"}
{"created":"2025-05-12","title":"A Convergent Inexact Abedin-Kitagawa Iteration Method for Monge-Amp\\`ere Eigenvalue Problems","abstract":"In this paper, we propose an inexact Aleksandrov solution based Abedin-Kitagawa iteration (AKI) method for solving (real) Monge-Amp{\\`e}re eigenvalue problems. The proposed approach utilizes the convergent Rayleigh inverse iterative formulation introduced by Abedin and Kitagawa as the prototype. More importantly, it employs an error tolerance criterion of inexact Aleksandrov solutions to approximately solve the subproblems without spoiling the convergence, which becomes the most crucial issue for the efficient implementation of the iterative method. For the two-dimensional case, by properly taking advantage of the flexibility rendered by the proposed inexact approach and a convergent fixed-point-based approach to solve the subproblems, considerable advancements in computational efficiency can be achieved by the inexact AKI method with its convergence under the ${\\cal C}^{2,\\alpha}$ boundary condition being rigorously established. Numerical experiments are conducted to demonstrate the efficiency of the proposed inexact AKI method. The numerical results suggest that the inexact AKI method can be more than eight times faster than the original AKI method, at least for all the tested problems.","authors":["Liang Chen","Youyicun Lin","Junqi Yang","Wenfan Yi"],"url":"https://arxiv.org/abs/2505.06160"}
{"created":"2025-05-12","title":"The Power of Matching for Online Fractional Hedonic Games","abstract":"We study coalition formation in the framework of fractional hedonic games (FHGs). The objective is to maximize social welfare in an online model where agents arrive one by one and must be assigned to coalitions immediately and irrevocably. For general online FHGs, it is known that computing maximal matchings achieves the optimal competitive ratio, which is, however, unbounded for unbounded agent valuations.","authors":["Martin Bullinger","Ren\\'e Romen","Alexander Schlenga"],"url":"https://arxiv.org/abs/2505.06163"}
{"created":"2025-05-12","title":"DiffLocks: Generating 3D Hair from a Single Image using Diffusion Models","abstract":"We address the task of generating 3D hair geometry from a single image, which is challenging due to the diversity of hairstyles and the lack of paired image-to-3D hair data. Previous methods are primarily trained on synthetic data and cope with the limited amount of such data by using low-dimensional intermediate representations, such as guide strands and scalp-level embeddings, that require post-processing to decode, upsample, and add realism. These approaches fail to reconstruct detailed hair, struggle with curly hair, or are limited to handling only a few hairstyles. To overcome these limitations, we propose DiffLocks, a novel framework that enables detailed reconstruction of a wide variety of hairstyles directly from a single image. First, we address the lack of 3D hair data by automating the creation of the largest synthetic hair dataset to date, containing 40K hairstyles. Second, we leverage the synthetic hair dataset to learn an image-conditioned diffusion-transfomer model that generates accurate 3D strands from a single frontal image. By using a pretrained image backbone, our method generalizes to in-the-wild images despite being trained only on synthetic data. Our diffusion model predicts a scalp texture map in which any point in the map contains the latent code for an individual hair strand. These codes are directly decoded to 3D strands without post-processing techniques. Representing individual strands, instead of guide strands, enables the transformer to model the detailed spatial structure of complex hairstyles. With this, DiffLocks can recover highly curled hair, like afro hairstyles, from a single image for the first time. Data and code is available at https://radualexandru.github.io/difflocks/","authors":["Radu Alexandru Rosu","Keyu Wu","Yao Feng","Youyi Zheng","Michael J. Black"],"url":"https://arxiv.org/abs/2505.06166"}
{"created":"2025-05-12","title":"On the Depth of Monotone ReLU Neural Networks and ICNNs","abstract":"We study two models of ReLU neural networks: monotone networks (ReLU$^+$) and input convex neural networks (ICNN). Our focus is on expressivity, mostly in terms of depth, and we prove the following lower bounds. For the maximum function MAX$_n$ computing the maximum of $n$ real numbers, we show that ReLU$^+$ networks cannot compute MAX$_n$, or even approximate it. We prove a sharp $n$ lower bound on the ICNN depth complexity of MAX$_n$. We also prove depth separations between ReLU networks and ICNNs; for every $k$, there is a depth-2 ReLU network of size $O(k^2)$ that cannot be simulated by a depth-$k$ ICNN. The proofs are based on deep connections between neural networks and polyhedral geometry, and also use isoperimetric properties of triangulations.","authors":["Egor Bakaev","Florestan Brunck","Christoph Hertrich","Daniel Reichman","Amir Yehudayoff"],"url":"https://arxiv.org/abs/2505.06169"}
{"created":"2025-05-12","title":"Self-Supervised Federated GNSS Spoofing Detection with Opportunistic Data","abstract":"Global navigation satellite systems (GNSS) are vulnerable to spoofing attacks, with adversarial signals manipulating the location or time information of receivers, potentially causing severe disruptions. The task of discerning the spoofing signals from benign ones is naturally relevant for machine learning, thus recent interest in applying it for detection. While deep learning-based methods are promising, they require extensive labeled datasets, consume significant computational resources, and raise privacy concerns due to the sensitive nature of position data. This is why this paper proposes a self-supervised federated learning framework for GNSS spoofing detection. It consists of a cloud server and local mobile platforms. Each mobile platform employs a self-supervised anomaly detector using long short-term memory (LSTM) networks. Labels for training are generated locally through a spoofing-deviation prediction algorithm, ensuring privacy. Local models are trained independently, and only their parameters are uploaded to the cloud server, which aggregates them into a global model using FedAvg. The updated global model is then distributed back to the mobile platforms and trained iteratively. The evaluation shows that our self-supervised federated learning framework outperforms position-based and deep learning-based methods in detecting spoofing attacks while preserving data privacy.","authors":["Wenjie Liu","Panos Papadimitratos"],"url":"https://arxiv.org/abs/2505.06171"}
{"created":"2025-05-12","title":"Leakage-resilient Algebraic Manipulation Detection Codes with Optimal Parameters","abstract":"Algebraic Manipulation Detection (AMD) codes is a cryptographic primitive that was introduced by Cramer, Dodis, Fehr, Padro and Wichs. They are keyless message authentication codes that protect messages against additive tampering by the adversary assuming that the adversary cannot \"see\" the codeword. For certain applications, it is unreasonable to assume that the adversary computes the added offset without any knowledge of the codeword c. Recently, Ahmadi and Safavi-Naini, and then Lin, Safavi-Naini, and Wang gave a construction of leakage-resilient AMD codes where the adversary has some partial information about the codeword before choosing added offset, and the scheme is secure even conditioned on this partial information. In this paper we establish bounds on the leakage rate r and the code rate k for leakage-resilient AMD codes. In particular we prove that 2r + k < 1 and for the weak case (security is averaged over a uniformly random message) r + k < 1. These bounds hold even if adversary is polynomial-time bounded, as long as we allow leakage function to be arbitrary. We present constructions of AMD codes that (asymptotically) fulfill the above bounds for almost full range of parameters r and k. This shows that the above bounds and constructions are in-fact optimal. In the last section we show that if a leakage function is computationally bounded (we use the Ideal Cipher Model) then it is possible to break these bounds.","authors":["Divesh Aggarwal","Tomasz Kazana","Maciej Obremski"],"url":"https://arxiv.org/abs/2505.06174"}
{"created":"2025-05-12","title":"MonetGPT: Solving Puzzles Enhances MLLMs' Image Retouching Skills","abstract":"Retouching is an essential task in post-manipulation of raw photographs. Generative editing, guided by text or strokes, provides a new tool accessible to users but can easily change the identity of the original objects in unacceptable and unpredictable ways. In contrast, although traditional procedural edits, as commonly supported by photoediting tools (e.g., Gimp, Lightroom), are conservative, they are still preferred by professionals. Unfortunately, professional quality retouching involves many individual procedural editing operations that is challenging to plan for most novices. In this paper, we ask if a multimodal large language model (MLLM) can be taught to critique raw photographs, suggest suitable remedies, and finally realize them with a given set of pre-authored procedural image operations. We demonstrate that MLLMs can be first made aware of the underlying image processing operations, by training them to solve specially designed visual puzzles. Subsequently, such an operation-aware MLLM can both plan and propose edit sequences. To facilitate training, given a set of expert-edited photos, we synthesize a reasoning dataset by procedurally manipulating the expert edits and then grounding a pretrained LLM on the visual adjustments, to synthesize reasoning for finetuning. The proposed retouching operations are, by construction, understandable by the users, preserve object details and resolution, and can be optionally overridden. We evaluate our setup on a variety of test examples and show advantages, in terms of explainability and identity preservation, over existing generative and other procedural alternatives. Code, data, models, and supplementary results can be found via our project website at https://monetgpt.github.io.","authors":["Niladri Shekhar Dutt","Duygu Ceylan","Niloy J. Mitra"],"url":"https://arxiv.org/abs/2505.06176"}
{"created":"2025-05-12","title":"An Empirical Study of Fuzz Harness Degradation","abstract":"The purpose of continuous fuzzing platforms is to enable fuzzing for software projects via \\emph{fuzz harnesses} -- but as the projects continue to evolve, are these harnesses updated in lockstep, or do they run out of date? If these harnesses remain unmaintained, will they \\emph{degrade} over time in terms of coverage achieved or number of bugs found? This is the subject of our study.","authors":["Philipp G\\\"orz","Joschua Schilling","Thorsten Holz","Marcel B\\\"ohme"],"url":"https://arxiv.org/abs/2505.06177"}
{"created":"2025-05-12","title":"A Large Language Model-Enhanced Q-learning for Capacitated Vehicle Routing Problem with Time Windows","abstract":"The Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) is a classic NP-hard combinatorial optimization problem widely applied in logistics distribution and transportation management. Its complexity stems from the constraints of vehicle capacity and time windows, which pose significant challenges to traditional approaches. Advances in Large Language Models (LLMs) provide new possibilities for finding approximate solutions to CVRPTW. This paper proposes a novel LLM-enhanced Q-learning framework to address the CVRPTW with real-time emergency constraints. Our solution introduces an adaptive two-phase training mechanism that transitions from the LLM-guided exploration phase to the autonomous optimization phase of Q-network. To ensure reliability, we design a three-tier self-correction mechanism based on the Chain-of-Thought (CoT) for LLMs: syntactic validation, semantic verification, and physical constraint enforcement. In addition, we also prioritized replay of the experience generated by LLMs to amplify the regulatory role of LLMs in the architecture. Experimental results demonstrate that our framework achieves a 7.3\\% average reduction in cost compared to traditional Q-learning, with fewer training steps required for convergence.","authors":["Linjiang Cao","Maonan Wang","Xi Xiong"],"url":"https://arxiv.org/abs/2505.06178"}
{"created":"2025-05-12","title":"Active Perception for Tactile Sensing: A Task-Agnostic Attention-Based Approach","abstract":"Humans make extensive use of haptic exploration to map and identify the properties of the objects that we touch. In robotics, active tactile perception has emerged as an important research domain that complements vision for tasks such as object classification, shape reconstruction, and manipulation. This work introduces TAP (Task-agnostic Active Perception) -- a novel framework that leverages reinforcement learning (RL) and transformer-based architectures to address the challenges posed by partially observable environments. TAP integrates Soft Actor-Critic (SAC) and CrossQ algorithms within a unified optimization objective, jointly training a perception module and decision-making policy. By design, TAP is completely task-agnostic and can, in principle, generalize to any active perception problem. We evaluate TAP across diverse tasks, including toy examples and realistic applications involving haptic exploration of 3D models from the Tactile MNIST benchmark. Experiments demonstrate the efficacy of TAP, achieving high accuracies on the Tactile MNIST haptic digit recognition task and a tactile pose estimation task. These findings underscore the potential of TAP as a versatile and generalizable framework for advancing active tactile perception in robotics.","authors":["Tim Schneider","Cristiana de Farias","Roberto Calandra","Liming Chen","Jan Peters"],"url":"https://arxiv.org/abs/2505.06182"}
{"created":"2025-05-12","title":"From Millions of Tweets to Actionable Insights: Leveraging LLMs for User Profiling","abstract":"Social media user profiling through content analysis is crucial for tasks like misinformation detection, engagement prediction, hate speech monitoring, and user behavior modeling. However, existing profiling techniques, including tweet summarization, attribute-based profiling, and latent representation learning, face significant limitations: they often lack transferability, produce non-interpretable features, require large labeled datasets, or rely on rigid predefined categories that limit adaptability. We introduce a novel large language model (LLM)-based approach that leverages domain-defining statements, which serve as key characteristics outlining the important pillars of a domain as foundations for profiling. Our two-stage method first employs semi-supervised filtering with a domain-specific knowledge base, then generates both abstractive (synthesized descriptions) and extractive (representative tweet selections) user profiles. By harnessing LLMs' inherent knowledge with minimal human validation, our approach is adaptable across domains while reducing the need for large labeled datasets. Our method generates interpretable natural language user profiles, condensing extensive user data into a scale that unlocks LLMs' reasoning and knowledge capabilities for downstream social network tasks. We contribute a Persian political Twitter (X) dataset and an LLM-based evaluation framework with human validation. Experimental results show our method significantly outperforms state-of-the-art LLM-based and traditional methods by 9.8%, demonstrating its effectiveness in creating flexible, adaptable, and interpretable user profiles.","authors":["Vahid Rahimzadeh","Ali Hamzehpour","Azadeh Shakery","Masoud Asadpour"],"url":"https://arxiv.org/abs/2505.06184"}
{"created":"2025-05-12","title":"Brain Hematoma Marker Recognition Using Multitask Learning: SwinTransformer and Swin-Unet","abstract":"This paper proposes a method MTL-Swin-Unet which is multi-task learning using transformers for classification and semantic segmentation. For spurious-correlation problems, this method allows us to enhance the image representation with two other image representations: representation obtained by semantic segmentation and representation obtained by image reconstruction. In our experiments, the proposed method outperformed in F-value measure than other classifiers when the test data included slices from the same patient (no covariate shift). Similarly, when the test data did not include slices from the same patient (covariate shift setting), the proposed method outperformed in AUC measure.","authors":["Kodai Hirata","Tsuyoshi Okita"],"url":"https://arxiv.org/abs/2505.06185"}
{"created":"2025-05-12","title":"Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies","abstract":"Extracting scientific evidence from biomedical studies for clinical research questions (e.g., Does stem cell transplantation improve quality of life in patients with medically refractory Crohn's disease compared to placebo?) is a crucial step in synthesising biomedical evidence. In this paper, we focus on the task of document-level scientific evidence extraction for clinical questions with conflicting evidence. To support this task, we create a dataset called CochraneForest, leveraging forest plots from Cochrane systematic reviews. It comprises 202 annotated forest plots, associated clinical research questions, full texts of studies, and study-specific conclusions. Building on CochraneForest, we propose URCA (Uniform Retrieval Clustered Augmentation), a retrieval-augmented generation framework designed to tackle the unique challenges of evidence extraction. Our experiments show that URCA outperforms the best existing methods by up to 10.3% in F1 score on this task. However, the results also underscore the complexity of CochraneForest, establishing it as a challenging testbed for advancing automated evidence synthesis systems.","authors":["Massimiliano Pronesti","Joao Bettencourt-Silva","Paul Flanagan","Alessandra Pascale","Oisin Redmond","Anya Belz","Yufang Hou"],"url":"https://arxiv.org/abs/2505.06186"}
{"created":"2025-05-12","title":"Efficient time-domain scattering synthesis via frequency-domain singularity subtraction","abstract":"Fourier-transform-based methods enable accurate, dispersion-free","authors":["Oscar P. Bruno","Manuel A. Santana"],"url":"https://arxiv.org/abs/2505.06189"}
{"created":"2025-05-12","title":"Neuro-Symbolic Concepts","abstract":"This article presents a concept-centric paradigm for building agents that can learn continually and reason flexibly. The concept-centric agent utilizes a vocabulary of neuro-symbolic concepts. These concepts, such as object, relation, and action concepts, are grounded on sensory inputs and actuation outputs. They are also compositional, allowing for the creation of novel concepts through their structural combination. To facilitate learning and reasoning, the concepts are typed and represented using a combination of symbolic programs and neural network representations. Leveraging such neuro-symbolic concepts, the agent can efficiently learn and recombine them to solve various tasks across different domains, ranging from 2D images, videos, 3D scenes, and robotic manipulation tasks. This concept-centric framework offers several advantages, including data efficiency, compositional generalization, continual learning, and zero-shot transfer.","authors":["Jiayuan Mao","Joshua B. Tenenbaum","Jiajun Wu"],"url":"https://arxiv.org/abs/2505.06191"}
{"created":"2025-05-12","title":"Ohana trees and Taylor expansion for the $\\lambda$I-calculus. No variable gets left behind or forgotten!","abstract":"Although the $\\lambda$I-calculus is a natural fragment of the $\\lambda$-calculus, obtained by forbidding the erasure, its equational theories did not receive much attention. The reason is that all proper denotational models studied in the literature equate all non-normalizable $\\lambda$I-terms, whence the associated theory is not very informative. The goal of this paper is to introduce a previously unknown theory of the $\\lambda$I-calculus, induced by a notion of evaluation trees that we call \"Ohana trees\". The Ohana tree of a $\\lambda$I-term is an annotated version of its B\\\"ohm tree, remembering all free variables that are hidden within its meaningless subtrees, or pushed into infinity along its infinite branches.","authors":["R\\'emy Cerda","Giulio Manzonetto","Alexis Saurin"],"url":"https://arxiv.org/abs/2505.06193"}
{"created":"2025-05-12","title":"Stable fully practical finite element methods for axisymmetric Willmore flow","abstract":"We consider fully discrete numerical approximations for axisymmetric Willmore flow that are unconditionally stable and work reliably without remeshing. We restrict our attention to surfaces without boundary, but allow for spontaneous curvature effects. The axisymmetric setting allows us to formulate our schemes in terms of the generating curve of the considered surface. We propose a novel weak formulation, that combines an evolution equation for the surface's mean curvature and the curvature identity of the generating curve. The mean curvature is used to describe the gradient flow structure, which enables an unconditional stability result for the discrete solutions. The generating curve's curvature, on the other hand, describes the surface's in-plane principal curvature and plays the role of a Lagrange multiplier for an equidistribution property on the discrete level. We introduce two fully discrete schemes and prove their unconditional stability. Numerical results are provided to confirm the convergence, stability and equidistribution properties of the introduced schemes.","authors":["Harald Garcke","Robert N\\\"urnberg","Quan Zhao"],"url":"https://arxiv.org/abs/2505.06195"}
{"created":"2025-05-12","title":"On Optimal Batch Size in Coded Computing","abstract":"We consider computing systems that partition jobs into tasks, add redundancy through coding, and assign the encoded tasks to different computing nodes for parallel execution. The expected execution time depends on the level of redundancy. The computing nodes execute large jobs in batches of tasks. We show that the expected execution time depends on the batch size as well. The optimal batch size that minimizes the execution time depends on the level of redundancy under a fixed number of parallel servers and other system parameters. Furthermore, we show how to (jointly) optimize the redundancy level and batch size to reduce the expected job completion time for two service-time distributions. The simulation presented helps us appreciate the claims.","authors":["Swapnil Saha","Emina Soljanin","Philip Whiting"],"url":"https://arxiv.org/abs/2505.06199"}
{"created":"2025-05-12","title":"Robust Multi-Agent Decision-Making in Finite-Population Games","abstract":"We study the robustness of an agent decision-making model in finite-population games, with a particular focus on the Kullback-Leibler Divergence Regularized Learning (KLD-RL) model. Specifically, we examine how the model's parameters influence the effects of various sources of noise and modeling inaccuracies -- factors commonly encountered in engineering applications of population games -- on agents' decision-making. Our analysis provides insights into how these parameters can be effectively tuned to mitigate such effects. Theoretical results are supported by numerical examples and simulation studies that validate the analysis and illustrate practical strategies for parameter selection.","authors":["Shinkyu Park","Lucas C. D. Bezerra"],"url":"https://arxiv.org/abs/2505.06200"}
{"created":"2025-05-12","title":"Decoding Algorithms for Two-dimensional Constacyclic Codes over $\\mathbb{F}_q$","abstract":"We derive the spectral domain properties of two-dimensional (2-D) $(\\lambda_1, \\lambda_2)$-constacyclic codes over $\\mathbb{F}_q$ using the 2-D finite field Fourier transform (FFFT). Based on the spectral nulls of 2-D $(\\lambda_1, \\lambda_2)$-constacyclic codes, we characterize the structure of 2-D constacyclic coded arrays. The proposed 2-D construction has flexible code rates and works for any code areas, be it odd or even area. We present an algorithm to detect the location of 2-D errors. Further, we also propose decoding algorithms for extracting the error values using both time and frequency domain properties by exploiting the sparsity that arises due to duality in the time and frequency domains. Through several illustrative examples, we demonstrate the working of the proposed decoding algorithms.","authors":["Vidya Sagar","Shikha Patel","Shayan Srinivasa Garani"],"url":"https://arxiv.org/abs/2505.06201"}
{"created":"2025-05-12","title":"Auto Tensor Singular Value Thresholding: A Non-Iterative and Rank-Free Framework for Tensor Denoising","abstract":"In modern data-driven tasks such as classification, optimization, and forecasting, mitigating the effects of intrinsic noise is crucial for improving predictive accuracy. While numerous denoising techniques have been developed, the rising dimensionality of real-world datasets limits conventional matrix-based methods in preserving data structure and accuracy. This challenge has led to increasing interest in tensor-based approaches, which naturally capture multi-way data relationships. However, classical tensor decomposition methods (e.g., HOSVD, HOOI) typically require pre-specified ranks and iterative optimization, making them computationally expensive and less practical. In this work, we propose a novel low-rank approximation method for tensor data that avoids these limitations. Our approach applies statistically grounded singular value thresholding to mode-wise matricizations, enabling automatic extraction of significant components without requiring prior rank specification or iterative refinement. Experiments on synthetic and real-world tensors show that our method consistently outperforms existing techniques in terms of estimation accuracy and computational efficiency, especially in noisy high-dimensional settings.","authors":["Hiroki Hasegawa","Yukihiko Okada"],"url":"https://arxiv.org/abs/2505.06203"}
{"created":"2025-05-12","title":"Leveraging Multi-Task Learning for Multi-Label Power System Security Assessment","abstract":"This paper introduces a novel approach to the power system security assessment using Multi-Task Learning (MTL), and reformulating the problem as a multi-label classification task. The proposed MTL framework simultaneously assesses static, voltage, transient, and small-signal stability, improving both accuracy and interpretability with respect to the most state of the art machine learning methods. It consists of a shared encoder and multiple decoders, enabling knowledge transfer between stability tasks. Experiments on the IEEE 68-bus system demonstrate a measurable superior performance of the proposed method compared to the extant state-of-the-art approaches.","authors":["Muhy Eddin Za'ter","Amir Sajad","Bri-Mathias Hodge"],"url":"https://arxiv.org/abs/2505.06207"}
{"created":"2025-05-12","title":"Adapting a Segmentation Foundation Model for Medical Image Classification","abstract":"Recent advancements in foundation models, such as the Segment Anything Model (SAM), have shown strong performance in various vision tasks, particularly image segmentation, due to their impressive zero-shot segmentation capabilities. However, effectively adapting such models for medical image classification is still a less explored topic. In this paper, we introduce a new framework to adapt SAM for medical image classification. First, we utilize the SAM image encoder as a feature extractor to capture segmentation-based features that convey important spatial and contextual details of the image, while freezing its weights to avoid unnecessary overhead during training. Next, we propose a novel Spatially Localized Channel Attention (SLCA) mechanism to compute spatially localized attention weights for the feature maps. The features extracted from SAM's image encoder are processed through SLCA to compute attention weights, which are then integrated into deep learning classification models to enhance their focus on spatially relevant or meaningful regions of the image, thus improving classification performance. Experimental results on three public medical image classification datasets demonstrate the effectiveness and data-efficiency of our approach.","authors":["Pengfei Gu","Haoteng Tang","Islam A. Ebeid","Jose A. Nunez","Fabian Vazquez","Diego Adame","Marcus Zhan","Huimin Li","Bin Fu","Danny Z. Chen"],"url":"https://arxiv.org/abs/2505.06217"}
{"created":"2025-05-12","title":"Let Humanoids Hike! Integrative Skill Development on Complex Trails","abstract":"Hiking on complex trails demands balance, agility, and adaptive decision-making over unpredictable terrain. Current humanoid research remains fragmented and inadequate for hiking: locomotion focuses on motor skills without long-term goals or situational awareness, while semantic navigation overlooks real-world embodiment and local terrain variability. We propose training humanoids to hike on complex trails, driving integrative skill development across visual perception, decision making, and motor execution. We develop a learning framework, LEGO-H, that enables a vision-equipped humanoid robot to hike complex trails autonomously. We introduce two technical innovations: 1) A temporal vision transformer variant - tailored into Hierarchical Reinforcement Learning framework - anticipates future local goals to guide movement, seamlessly integrating locomotion with goal-directed navigation. 2) Latent representations of joint movement patterns, combined with hierarchical metric learning - enhance Privileged Learning scheme - enable smooth policy transfer from privileged training to onboard execution. These components allow LEGO-H to handle diverse physical and environmental challenges without relying on predefined motion patterns. Experiments across varied simulated trails and robot morphologies highlight LEGO-H's versatility and robustness, positioning hiking as a compelling testbed for embodied autonomy and LEGO-H as a baseline for future humanoid development.","authors":["Kwan-Yee Lin","Stella X. Yu"],"url":"https://arxiv.org/abs/2505.06218"}
{"created":"2025-05-12","title":"VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction","abstract":"Next Best View (NBV) algorithms aim to acquire an optimal set of images using minimal resources, time, or number of captures to enable efficient 3D reconstruction of a scene. Existing approaches often rely on prior scene knowledge or additional image captures and often develop policies that maximize coverage. Yet, for many real scenes with complex geometry and self-occlusions, coverage maximization does not lead to better reconstruction quality directly. In this paper, we propose the View Introspection Network (VIN), which is trained to predict the reconstruction quality improvement of views directly, and the VIN-NBV policy. A greedy sequential sampling-based policy, where at each acquisition step, we sample multiple query views and choose the one with the highest VIN predicted improvement score. We design the VIN to perform 3D-aware featurization of the reconstruction built from prior acquisitions, and for each query view create a feature that can be decoded into an improvement score. We then train the VIN using imitation learning to predict the reconstruction improvement score. We show that VIN-NBV improves reconstruction quality by ~30% over a coverage maximization baseline when operating with constraints on the number of acquisitions or the time in motion.","authors":["Noah Frahm","Dongxu Zhao","Andrea Dunn Beltran","Ron Alterovitz","Jan-Michael Frahm","Junier Oliva","Roni Sengupta"],"url":"https://arxiv.org/abs/2505.06219"}
{"created":"2025-05-12","title":"Equalizing Closeness Centralities via Edge Additions","abstract":"Graph modification problems with the goal of optimizing some measure of a given node's network position have a rich history in the algorithms literature. Less commonly explored are modification problems with the goal of equalizing positions, though this class of problems is well-motivated from the perspective of equalizing social capital, i.e., algorithmic fairness. In this work, we study how to add edges to make the closeness centralities of a given pair of nodes more equal. We formalize two versions of this problem: Closeness Ratio Improvement, which aims to maximize the ratio of closeness centralities between two specified nodes, and Closeness Gap Minimization, which aims to minimize the absolute difference of centralities. We show that both problems are $\\textsf{NP}$-hard, and for Closeness Ratio Improvement we present a quasilinear-time $\\frac{6}{11}$-approximation, complemented by a bicriteria inapproximability bound. In contrast, we show that Closeness Gap Minimization admits no multiplicative approximation unless $\\textsf{P} = \\textsf{NP}$. We conclude with a discussion of open directions for this style of problem, including several natural generalizations.","authors":["Alex Crane","Sorelle A. Friedler","Mihir Patel","Blair D. Sullivan"],"url":"https://arxiv.org/abs/2505.06222"}
{"created":"2025-05-12","title":"Towards a Unified Representation Evaluation Framework Beyond Downstream Tasks","abstract":"Downstream probing has been the dominant method for evaluating model representations, an important process given the increasing prominence of self-supervised learning and foundation models. However, downstream probing primarily assesses the availability of task-relevant information in the model's latent space, overlooking attributes such as equivariance, invariance, and disentanglement, which contribute to the interpretability, adaptability, and utility of representations in real-world applications. While some attempts have been made to measure these qualities in representations, no unified evaluation framework with modular, generalizable, and interpretable metrics exists.","authors":["Christos Plachouras","Julien Guinot","George Fazekas","Elio Quinton","Emmanouil Benetos","Johan Pauwels"],"url":"https://arxiv.org/abs/2505.06224"}
{"created":"2025-05-12","title":"Anymate: A Dataset and Baselines for Learning 3D Object Rigging","abstract":"Rigging and skinning are essential steps to create realistic 3D animations, often requiring significant expertise and manual effort. Traditional attempts at automating these processes rely heavily on geometric heuristics and often struggle with objects of complex geometry. Recent data-driven approaches show potential for better generality, but are often constrained by limited training data. We present the Anymate Dataset, a large-scale dataset of 230K 3D assets paired with expert-crafted rigging and skinning information -- 70 times larger than existing datasets. Using this dataset, we propose a learning-based auto-rigging framework with three sequential modules for joint, connectivity, and skinning weight prediction. We systematically design and experiment with various architectures as baselines for each module and conduct comprehensive evaluations on our dataset to compare their performance. Our models significantly outperform existing methods, providing a foundation for comparing future methods in automated rigging and skinning. Code and dataset can be found at https://anymate3d.github.io/.","authors":["Yufan Deng","Yuhao Zhang","Chen Geng","Shangzhe Wu","Jiajun Wu"],"url":"https://arxiv.org/abs/2505.06227"}
{"created":"2025-05-12","title":"Instance-Conditioned Adaptation for Large-scale Generalization of Neural Combinatorial Optimization","abstract":"The neural combinatorial optimization (NCO) approach has shown great potential for solving routing problems without the requirement of expert knowledge. However, existing constructive NCO methods cannot directly solve large-scale instances, which significantly limits their application prospects. To address these crucial shortcomings, this work proposes a novel Instance-Conditioned Adaptation Model (ICAM) for better large-scale generalization of neural combinatorial optimization. In particular, we design a powerful yet lightweight instance-conditioned adaptation module for the NCO model to generate better solutions for instances across different scales. In addition, we develop an efficient three-stage reinforcement learning-based training scheme that enables the model to learn cross-scale features without any labeled optimal solution. Experimental results show that our proposed method is capable of obtaining excellent results with a very fast inference time in solving Traveling Salesman Problems (TSPs) and Capacitated Vehicle Routing Problems (CVRPs) across different scales. To the best of our knowledge, our model achieves state-of-the-art performance among all RL-based constructive methods for TSP and CVRP with up to 1,000 nodes.","authors":["Changliang Zhou","Xi Lin","Zhenkun Wang","Xialiang Tong","Mingxuan Yuan","Qingfu Zhang"],"url":"https://arxiv.org/abs/2405.01906"}
{"created":"2025-05-12","title":"A Context-Driven Approach for Co-Auditing Smart Contracts with The Support of GPT-4 code interpreter","abstract":"The surge in the adoption of smart contracts necessitates rigorous auditing to ensure their security and reliability. Manual auditing, although comprehensive, is time-consuming and heavily reliant on the auditor's expertise. With the rise of Large Language Models (LLMs), there is growing interest in leveraging them to assist auditors in the auditing process (co-auditing). However, the effectiveness of LLMs in smart contract co-auditing is contingent upon the design of the input prompts, especially in terms of context description and code length. This paper introduces a novel context-driven prompting technique for smart contract co-auditing. Our approach employs three techniques for context scoping and augmentation, encompassing code scoping to chunk long code into self-contained code segments based on code inter-dependencies, assessment scoping to enhance context description based on the target assessment goal, thereby limiting the search space, and reporting scoping to force a specific format for the generated response. Through empirical evaluations on publicly available vulnerable contracts, our method demonstrated a detection rate of 96\\% for vulnerable functions, outperforming the native prompting approach, which detected only 53\\%. To assess the reliability of our prompting approach, manual analysis of the results was conducted by expert auditors from our partner, Quantstamp, a world-leading smart contract auditing company. The experts' analysis indicates that, in unlabeled datasets, our proposed approach enhances the proficiency of the GPT-4 code interpreter in detecting vulnerabilities.","authors":["Mohamed Salah Bouafif","Chen Zheng","Ilham Ahmed Qasse","Ed Zulkoski","Mohammad Hamdaqa","Foutse Khomh"],"url":"https://arxiv.org/abs/2406.18075"}
{"created":"2025-05-12","title":"L2R: Learning to Reduce Search Space for Generalizable Neural Routing Solver","abstract":"Constructive neural combinatorial optimization (NCO) has attracted growing research attention due to its ability to solve complex routing problems without relying on handcrafted rules. However, existing NCO methods face significant challenges in generalizing to large-scale problems due to high computational complexity and inefficient capture of structural patterns. To address this issue, we propose a novel learning-based search space reduction method that adaptively selects a small set of promising candidate nodes at each step of the constructive NCO process. Unlike traditional methods that rely on fixed heuristics, our selection model dynamically prioritizes nodes based on learned patterns, significantly reducing the search space while maintaining solution quality. Experimental results demonstrate that our method, trained solely on 100-node instances from uniform distribution, generalizes remarkably well to large-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) instances with up to 1 million nodes from the uniform distribution and over 80K nodes from other distributions.","authors":["Changliang Zhou","Xi Lin","Zhenkun Wang","Qingfu Zhang"],"url":"https://arxiv.org/abs/2503.03137"}
{"created":"2025-05-12","title":"ECGDeDRDNet: A deep learning-based method for Electrocardiogram noise removal using a double recurrent dense network","abstract":"Electrocardiogram (ECG) signals are frequently corrupted by noise, such as baseline wander (BW), muscle artifacts (MA), and electrode motion (EM), which significantly degrade their diagnostic utility. To address this issue, we propose ECGDeDRDNet, a deep learning-based ECG Denoising framework leveraging a Double Recurrent Dense Network architecture. In contrast to traditional approaches, we introduce a double recurrent scheme to enhance information reuse from both ECG waveforms and the estimated clean image. For ECG waveform processing, our basic model employs LSTM layers cascaded with DenseNet blocks. The estimated clean ECG image, obtained by subtracting predicted noise components from the noisy input, is iteratively fed back into the model. This dual recurrent architecture enables comprehensive utilization of both temporal waveform features and spatial image details, leading to more effective noise suppression. Experimental results on the MIT-BIH dataset demonstrate that our method achieves superior performance compared to conventional image denoising methods in terms of PSNR and SSIM while also surpassing classical ECG denoising techniques in both SNR and RMSE.","authors":["Sainan xiao","Wangdong Yang","Buwen Cao","Jintao Wu"],"url":"https://arxiv.org/abs/2505.05477"}
{"created":"2025-05-12","title":"OccuEMBED: Occupancy Extraction Merged with Building Energy Disaggregation for Occupant-Responsive Operation at Scale","abstract":"Buildings account for a significant share of global energy consumption and emissions, making it critical to operate them efficiently. As electricity grids become more volatile with renewable penetration, buildings must provide flexibility to support grid stability. Building automation plays a key role in enhancing efficiency and flexibility via centralized operations, but it must prioritize occupant-centric strategies to balance energy and comfort targets. However, incorporating occupant information into large-scale, centralized building operations remains challenging due to data limitations. We investigate the potential of using whole-building smart meter data to infer both occupancy and system operations. Integrating these insights into data-driven building energy analysis allows more occupant-centric energy-saving and flexibility at scale. Specifically, we propose OccuEMBED, a unified framework for occupancy inference and system-level load analysis. It combines two key components: a probabilistic occupancy profile generator, and a controllable and interpretable load disaggregator supported by Kolmogorov-Arnold Networks (KAN). This design embeds knowledge of occupancy patterns and load-occupancy-weather relationships into deep learning models. We conducted comprehensive evaluations to demonstrate its effectiveness across synthetic and real-world datasets compared to various occupancy inference baselines. OccuEMBED always achieved average F1 scores above 0.8 in discrete occupancy inference and RMSE within 0.1-0.2 for continuous occupancy ratios. We further demonstrate how OccuEMBED integrates with building load monitoring platforms to display occupancy profiles, analyze system-level operations, and inform occupant-responsive strategies. Our model lays a robust foundation in scaling occupant-centric building management systems to meet the challenges of an evolving energy system.","authors":["Yufei Zhang (ETHOS Lab","EPFL-ENAC-IIC)","Andrew Sonta (ETHOS Lab","EPFL-ENAC-IIC)"],"url":"https://arxiv.org/abs/2505.05478"}
{"created":"2025-05-12","title":"Improving Local Air Quality Predictions Using Transfer Learning on Satellite Data and Graph Neural Networks","abstract":"Air pollution is a significant global health risk, contributing to millions of premature deaths annually. Nitrogen dioxide (NO2), a harmful pollutant, disproportionately affects urban areas where monitoring networks are often sparse. We propose a novel method for predicting NO2 concentrations at unmonitored locations using transfer learning with satellite and meteorological data. Leveraging the GraphSAGE framework, our approach integrates autoregression and transfer learning to enhance predictive accuracy in data-scarce regions like Bristol. Pre-trained on data from London, UK, our model achieves a 8.6% reduction in Normalised Root Mean Squared Error (NRMSE) and a 32.6% reduction in Gradient RMSE compared to a baseline model. This work demonstrates the potential of virtual sensors for cost-effective air quality monitoring, contributing to actionable insights for climate and health interventions.","authors":["Finn Gueterbock","Raul Santos-Rodriguez","Jeffrey N. Clark"],"url":"https://arxiv.org/abs/2505.05479"}
{"created":"2025-05-12","title":"Structure & Quality: Conceptual and Formal Foundations for the Mind-Body Problem","abstract":"This paper explores the hard problem of consciousness from a different perspective. Instead of drawing distinctions between the physical and the mental, an exploration of a more foundational relationship is examined: the relationship between structure and quality.","authors":["Ryan Williams"],"url":"https://arxiv.org/abs/2505.05481"}
{"created":"2025-05-12","title":"Constraint Selection in Optimization-Based Controllers","abstract":"Human-machine collaboration often involves constrained optimization problems for decision-making processes. However, when the machine is a dynamical system with a continuously evolving state, infeasibility due to multiple conflicting constraints can lead to dangerous outcomes. In this work, we propose a heuristic-based method that resolves infeasibility at every time step by selectively disregarding a subset of soft constraints based on the past values of the Lagrange multipliers. Compared to existing approaches, our method requires the solution of a smaller optimization problem to determine feasibility, resulting in significantly faster computation. Through a series of simulations, we demonstrate that our algorithm achieves performance comparable to state-of-the-art methods while offering improved computational efficiency.","authors":["Haejoon Lee","Panagiotis Rousseas","Dimitra Panagou"],"url":"https://arxiv.org/abs/2505.05502"}
{"created":"2025-05-12","title":"Image Restoration via Multi-domain Learning","abstract":"Due to adverse atmospheric and imaging conditions, natural images suffer from various degradation phenomena. Consequently, image restoration has emerged as a key solution and garnered substantial attention. Although recent Transformer architectures have demonstrated impressive success across various restoration tasks, their considerable model complexity poses significant challenges for both training and real-time deployment. Furthermore, instead of investigating the commonalities among different degradations, most existing restoration methods focus on modifying Transformer under limited restoration priors. In this work, we first review various degradation phenomena under multi-domain perspective, identifying common priors. Then, we introduce a novel restoration framework, which integrates multi-domain learning into Transformer. Specifically, in Token Mixer, we propose a Spatial-Wavelet-Fourier multi-domain structure that facilitates local-region-global multi-receptive field modeling to replace vanilla self-attention. Additionally, in Feed-Forward Network, we incorporate multi-scale learning to fuse multi-domain features at different resolutions. Comprehensive experimental results across ten restoration tasks, such as dehazing, desnowing, motion deblurring, defocus deblurring, rain streak/raindrop removal, cloud removal, shadow removal, underwater enhancement and low-light enhancement, demonstrate that our proposed model outperforms state-of-the-art methods and achieves a favorable trade-off among restoration performance, parameter size, computational cost and inference latency. The code is available at: https://github.com/deng-ai-lab/SWFormer.","authors":["Xingyu Jiang","Ning Gao","Xiuhui Zhang","Hongkun Dou","Shaowen Fu","Xiaoqing Zhong","Hongjue Li","Yue Deng"],"url":"https://arxiv.org/abs/2505.05504"}
{"created":"2025-05-12","title":"StereoINR: Cross-View Geometry Consistent Stereo Super Resolution with Implicit Neural Representation","abstract":"Stereo image super-resolution (SSR) aims to enhance high-resolution details by leveraging information from stereo image pairs. However, existing stereo super-resolution (SSR) upsampling methods (e.g., pixel shuffle) often overlook cross-view geometric consistency and are limited to fixed-scale upsampling. The key issue is that previous upsampling methods use convolution to independently process deep features of different views, lacking cross-view and non-local information perception, making it difficult to select beneficial information from multi-view scenes adaptively. In this work, we propose Stereo Implicit Neural Representation (StereoINR), which innovatively models stereo image pairs as continuous implicit representations. This continuous representation breaks through the scale limitations, providing a unified solution for arbitrary-scale stereo super-resolution reconstruction of left-right views. Furthermore, by incorporating spatial warping and cross-attention mechanisms, StereoINR enables effective cross-view information fusion and achieves significant improvements in pixel-level geometric consistency. Extensive experiments across multiple datasets show that StereoINR outperforms out-of-training-distribution scale upsampling and matches state-of-the-art SSR methods within training-distribution scales.","authors":["Yi Liu","Xinyi Liu","Panwang Xia","Qiong Wu","Yi Wan","Yongjun Zhang"],"url":"https://arxiv.org/abs/2505.05509"}
{"created":"2025-05-12","title":"Nature's Insight: A Novel Framework and Comprehensive Analysis of Agentic Reasoning Through the Lens of Neuroscience","abstract":"Autonomous AI is no longer a hard-to-reach concept, it enables the agents to move beyond executing tasks to independently addressing complex problems, adapting to change while handling the uncertainty of the environment. However, what makes the agents truly autonomous? It is agentic reasoning, that is crucial for foundation models to develop symbolic logic, statistical correlations, or large-scale pattern recognition to process information, draw inferences, and make decisions. However, it remains unclear why and how existing agentic reasoning approaches work, in comparison to biological reasoning, which instead is deeply rooted in neural mechanisms involving hierarchical cognition, multimodal integration, and dynamic interactions. In this work, we propose a novel neuroscience-inspired framework for agentic reasoning. Grounded in three neuroscience-based definitions and supported by mathematical and biological foundations, we propose a unified framework modeling reasoning from perception to action, encompassing four core types, perceptual, dimensional, logical, and interactive, inspired by distinct functional roles observed in the human brain. We apply this framework to systematically classify and analyze existing AI reasoning methods, evaluating their theoretical foundations, computational designs, and practical limitations. We also explore its implications for building more generalizable, cognitively aligned agents in physical and virtual environments. Finally, building on our framework, we outline future directions and propose new neural-inspired reasoning methods, analogous to chain-of-thought prompting. By bridging cognitive neuroscience and AI, this work offers a theoretical foundation and practical roadmap for advancing agentic reasoning in intelligent systems. The associated project can be found at: https://github.com/BioRAILab/Awesome-Neuroscience-Agent-Reasoning .","authors":["Zinan Liu","Haoran Li","Jingyi Lu","Gaoyuan Ma","Xu Hong","Giovanni Iacca","Arvind Kumar","Shaojun Tang","Lin Wang"],"url":"https://arxiv.org/abs/2505.05515"}
{"created":"2025-05-12","title":"AI-powered virtual eye: perspective, challenges and opportunities","abstract":"We envision the \"virtual eye\" as a next-generation, AI-powered platform that uses interconnected foundation models to simulate the eye's intricate structure and biological function across all scales. Advances in AI, imaging, and multiomics provide a fertile ground for constructing a universal, high-fidelity digital replica of the human eye. This perspective traces the evolution from early mechanistic and rule-based models to contemporary AI-driven approaches, integrating in a unified model with multimodal, multiscale, dynamic predictive capabilities and embedded feedback mechanisms. We propose a development roadmap emphasizing the roles of large-scale multimodal datasets, generative AI, foundation models, agent-based architectures, and interactive interfaces. Despite challenges in interpretability, ethics, data processing and evaluation, the virtual eye holds the potential to revolutionize personalized ophthalmic care and accelerate research into ocular health and disease.","authors":["Yue Wu","Yibo Guo","Yulong Yan","Jiancheng Yang","Xin Zhou","Ching-Yu Cheng","Danli Shi","Mingguang He"],"url":"https://arxiv.org/abs/2505.05516"}
{"created":"2025-05-12","title":"Guidance for Intra-cardiac Echocardiography Manipulation to Maintain Continuous Therapy Device Tip Visibility","abstract":"Intra-cardiac Echocardiography (ICE) plays a critical role in Electrophysiology (EP) and Structural Heart Disease (SHD) interventions by providing real-time visualization of intracardiac structures. However, maintaining continuous visibility of the therapy device tip remains a challenge due to frequent adjustments required during manual ICE catheter manipulation. To address this, we propose an AI-driven tracking model that estimates the device tip incident angle and passing point within the ICE imaging plane, ensuring continuous visibility and facilitating robotic ICE catheter control.","authors":["Jaeyoung Huh","Ankur Kapoor","Young-Ho Kim"],"url":"https://arxiv.org/abs/2505.05518"}
{"created":"2025-05-12","title":"GenAI in Entrepreneurship: a systematic review of generative artificial intelligence in entrepreneurship research: current issues and future directions","abstract":"Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) are recognized to have significant effects on industry and business dynamics, not least because of their impact on the preconditions for entrepreneurship. There is still a lack of knowledge of GenAI as a theme in entrepreneurship research. This paper presents a systematic literature review aimed at identifying and analyzing the evolving landscape of research on the effects of GenAI on entrepreneurship. We analyze 83 peer-reviewed articles obtained from leading academic databases: Web of Science and Scopus. Using natural language processing and unsupervised machine learning techniques with TF-IDF vectorization, Principal Component Analysis (PCA), and hierarchical clustering, five major thematic clusters are identified: (1) Digital Transformation and Behavioral Models, (2) GenAI-Enhanced Education and Learning Systems, (3) Sustainable Innovation and Strategic AI Impact, (4) Business Models and Market Trends, and (5) Data-Driven Technological Trends in Entrepreneurship. Based on the review, we discuss future research directions, gaps in the current literature, as well as ethical concerns raised in the literature. We highlight the need for more macro-level research on GenAI and LLMs as external enablers for entrepreneurship and for research on effective regulatory frameworks that facilitate business experimentation, innovation, and further technology development.","authors":["Anna Kusetogullari","Huseyin Kusetogullari","Martin Andersson","Tony Gorschek"],"url":"https://arxiv.org/abs/2505.05523"}
{"created":"2025-05-12","title":"Machine learning automorphic forms for black holes","abstract":"Modular, Jacobi, and mock-modular forms serve as generating functions for BPS black hole degeneracies. By training feed-forward neural networks on Fourier coefficients of automorphic forms derived from the Dedekind eta function, Eisenstein series, and Jacobi theta functions, we demonstrate that machine learning techniques can accurately predict modular weights from truncated expansions. Our results reveal strong performance for negative weight modular and quasi-modular forms, particularly those arising in exact black hole counting formulae, with lower accuracy for positive weights and more complicated combinations of Jacobi theta functions. This study establishes a proof of concept for using machine learning to identify how data is organized in terms of modular symmetries in gravitational systems and suggests a pathway toward automated detection and verification of symmetries in quantum gravity.","authors":["Vishnu Jejjala","Suresh Nampuri","Dumisani Nxumalo","Pratik Roy","Abinash Swain"],"url":"https://arxiv.org/abs/2505.05549"}
{"created":"2025-05-12","title":"Trading Under Uncertainty: A Distribution-Based Strategy for Futures Markets Using FutureQuant Transformer","abstract":"In the complex landscape of traditional futures trading, where vast data and variables like real-time Limit Order Books (LOB) complicate price predictions, we introduce the FutureQuant Transformer model, leveraging attention mechanisms to navigate these challenges. Unlike conventional models focused on point predictions, the FutureQuant model excels in forecasting the range and volatility of future prices, thus offering richer insights for trading strategies. Its ability to parse and learn from intricate market patterns allows for enhanced decision-making, significantly improving risk management and achieving a notable average gain of 0.1193% per 30-minute trade over state-of-the-art models with a simple algorithm using factors such as RSI, ATR, and Bollinger Bands. This innovation marks a substantial leap forward in predictive analytics within the volatile domain of futures trading.","authors":["Wenhao Guo","Yuda Wang","Zeqiao Huang","Changjiang Zhang","Shumin ma"],"url":"https://arxiv.org/abs/2505.05595"}
{"created":"2025-05-12","title":"Optimal Regret of Bernoulli Bandits under Global Differential Privacy","abstract":"As sequential learning algorithms are increasingly applied to real life, ensuring data privacy while maintaining their utilities emerges as a timely question. In this context, regret minimisation in stochastic bandits under $\\epsilon$-global Differential Privacy (DP) has been widely studied. Unlike bandits without DP, there is a significant gap between the best-known regret lower and upper bound in this setting, though they \"match\" in order. Thus, we revisit the regret lower and upper bounds of $\\epsilon$-global DP algorithms for Bernoulli bandits and improve both. First, we prove a tighter regret lower bound involving a novel information-theoretic quantity characterising the hardness of $\\epsilon$-global DP in stochastic bandits. Our lower bound strictly improves on the existing ones across all $\\epsilon$ values. Then, we choose two asymptotically optimal bandit algorithms, i.e. DP-KLUCB and DP-IMED, and propose their DP versions using a unified blueprint, i.e., (a) running in arm-dependent phases, and (b) adding Laplace noise to achieve privacy. For Bernoulli bandits, we analyse the regrets of these algorithms and show that their regrets asymptotically match our lower bound up to a constant arbitrary close to 1. This refutes the conjecture that forgetting past rewards is necessary to design optimal bandit algorithms under global DP. At the core of our algorithms lies a new concentration inequality for sums of Bernoulli variables under Laplace mechanism, which is a new DP version of the Chernoff bound. This result is universally useful as the DP literature commonly treats the concentrations of Laplace noise and random variables separately, while we couple them to yield a tighter bound.","authors":["Achraf Azize","Yulian Wu","Junya Honda","Francesco Orabona","Shinji Ito","Debabrota Basu"],"url":"https://arxiv.org/abs/2505.05613"}
{"created":"2025-05-12","title":"Score-based Self-supervised MRI Denoising","abstract":"Magnetic resonance imaging (MRI) is a powerful noninvasive diagnostic imaging tool that provides unparalleled soft tissue contrast and anatomical detail. Noise contamination, especially in accelerated and/or low-field acquisitions, can significantly degrade image quality and diagnostic accuracy. Supervised learning based denoising approaches have achieved impressive performance but require high signal-to-noise ratio (SNR) labels, which are often unavailable. Self-supervised learning holds promise to address the label scarcity issue, but existing self-supervised denoising methods tend to oversmooth fine spatial features and often yield inferior performance than supervised methods. We introduce Corruption2Self (C2S), a novel score-based self-supervised framework for MRI denoising. At the core of C2S is a generalized denoising score matching (GDSM) loss, which extends denoising score matching to work directly with noisy observations by modeling the conditional expectation of higher-SNR images given further corrupted observations. This allows the model to effectively learn denoising across multiple noise levels directly from noisy data. Additionally, we incorporate a reparameterization of noise levels to stabilize training and enhance convergence, and introduce a detail refinement extension to balance noise reduction with the preservation of fine spatial features. Moreover, C2S can be extended to multi-contrast denoising by leveraging complementary information across different MRI contrasts. We demonstrate that our method achieves state-of-the-art performance among self-supervised methods and competitive results compared to supervised counterparts across varying noise conditions and MRI contrasts on the M4Raw and fastMRI dataset.","authors":["Jiachen Tu","Yaokun Shi","Fan Lam"],"url":"https://arxiv.org/abs/2505.05631"}
{"created":"2025-05-12","title":"UltraGauss: Ultrafast Gaussian Reconstruction of 3D Ultrasound Volumes","abstract":"Ultrasound imaging is widely used due to its safety, affordability, and real-time capabilities, but its 2D interpretation is highly operator-dependent, leading to variability and increased cognitive demand. 2D-to-3D reconstruction mitigates these challenges by providing standardized volumetric views, yet existing methods are often computationally expensive, memory-intensive, or incompatible with ultrasound physics. We introduce UltraGauss: the first ultrasound-specific Gaussian Splatting framework, extending view synthesis techniques to ultrasound wave propagation. Unlike conventional perspective-based splatting, UltraGauss models probe-plane intersections in 3D, aligning with acoustic image formation. We derive an efficient rasterization boundary formulation for GPU parallelization and introduce a numerically stable covariance parametrization, improving computational efficiency and reconstruction accuracy. On real clinical ultrasound data, UltraGauss achieves state-of-the-art reconstructions in 5 minutes, and reaching 0.99 SSIM within 20 minutes on a single GPU. A survey of expert clinicians confirms UltraGauss' reconstructions are the most realistic among competing methods. Our CUDA implementation will be released upon publication.","authors":["Mark C. Eid","Ana I. L. Namburete","Jo\\~ao F. Henriques"],"url":"https://arxiv.org/abs/2505.05643"}
{"created":"2025-05-12","title":"A New k-Space Model for Non-Cartesian Fourier Imaging","abstract":"For the past several decades, it has been popular to reconstruct Fourier imaging data using model-based approaches that can easily incorporate physical constraints and advanced regularization/machine learning priors. The most common modeling approach is to represent the continuous image as a linear combination of shifted \"voxel\" basis functions. Although well-studied and widely-deployed, this voxel-based model is associated with longstanding limitations, including high computational costs, slow convergence, and a propensity for artifacts. In this work, we reexamine this model from a fresh perspective, identifying new issues that may have been previously overlooked (including undesirable approximation, periodicity, and nullspace characteristics). Our insights motivate us to propose a new model that is more resilient to the limitations (old and new) of the previous approach. Specifically, the new model is based on a Fourier-domain basis expansion rather than the standard image-domain voxel-based approach. Illustrative results, which are presented in the context of non-Cartesian MRI reconstruction, demonstrate that the new model enables improved image quality (reduced artifacts) and/or reduced computational complexity (faster computations and improved convergence).","authors":["Chin-Cheng Chan","Justin P. Haldar"],"url":"https://arxiv.org/abs/2505.05647"}
{"created":"2025-05-12","title":"Unsupervised Blind Speech Separation with a Diffusion Prior","abstract":"Blind Speech Separation (BSS) aims to separate multiple speech sources from audio mixtures recorded by a microphone array. The problem is challenging because it is a blind inverse problem, i.e., the microphone array geometry, the room impulse response (RIR), and the speech sources, are all unknown. We propose ArrayDPS to solve the BSS problem in an unsupervised, array-agnostic, and generative manner. The core idea builds on diffusion posterior sampling (DPS), but unlike DPS where the likelihood is tractable, ArrayDPS must approximate the likelihood by formulating a separate optimization problem. The solution to the optimization approximates room acoustics and the relative transfer functions between microphones. These approximations, along with the diffusion priors, iterate through the ArrayDPS sampling process and ultimately yield separated voice sources. We only need a simple single-speaker speech diffusion model as a prior along with the mixtures recorded at the microphones; no microphone array information is necessary. Evaluation results show that ArrayDPS outperforms all baseline unsupervised methods while being comparable to supervised methods in terms of SDR. Audio demos are provided at: https://arraydps.github.io/ArrayDPSDemo/.","authors":["Zhongweiyang Xu","Xulin Fan","Zhong-Qiu Wang","Xilin Jiang","Romit Roy Choudhury"],"url":"https://arxiv.org/abs/2505.05657"}
{"created":"2025-05-12","title":"V-EfficientNets: Vector-Valued Efficiently Scaled Convolutional Neural Network Models","abstract":"EfficientNet models are convolutional neural networks optimized for parameter allocation by jointly balancing network width, depth, and resolution. Renowned for their exceptional accuracy, these models have become a standard for image classification tasks across diverse computer vision benchmarks. While traditional neural networks learn correlations between feature channels during training, vector-valued neural networks inherently treat multidimensional data as coherent entities, taking for granted the inter-channel relationships. This paper introduces vector-valued EfficientNets (V-EfficientNets), a novel extension of EfficientNet designed to process arbitrary vector-valued data. The proposed models are evaluated on a medical image classification task, achieving an average accuracy of 99.46% on the ALL-IDB2 dataset for detecting acute lymphoblastic leukemia. V-EfficientNets demonstrate remarkable efficiency, significantly reducing parameters while outperforming state-of-the-art models, including the original EfficientNet. The source code is available at https://github.com/mevalle/v-nets.","authors":["Guilherme Vieira Neto","Marcos Eduardo Valle"],"url":"https://arxiv.org/abs/2505.05659"}
{"created":"2025-05-12","title":"Equivariant Imaging Biomarkers for Robust Unsupervised Segmentation of Histopathology","abstract":"Histopathology evaluation of tissue specimens through microscopic examination is essential for accurate disease diagnosis and prognosis. However, traditional manual analysis by specially trained pathologists is time-consuming, labor-intensive, cost-inefficient, and prone to inter-rater variability, potentially affecting diagnostic consistency and accuracy. As digital pathology images continue to proliferate, there is a pressing need for automated analysis to address these challenges. Recent advancements in artificial intelligence-based tools such as machine learning (ML) models, have significantly enhanced the precision and efficiency of analyzing histopathological slides. However, despite their impressive performance, ML models are invariant only to translation, lacking invariance to rotation and reflection. This limitation restricts their ability to generalize effectively, particularly in histopathology, where images intrinsically lack meaningful orientation. In this study, we develop robust, equivariant histopathological biomarkers through a novel symmetric convolutional kernel via unsupervised segmentation. The approach is validated using prostate tissue micro-array (TMA) images from 50 patients in the Gleason 2019 Challenge public dataset. The biomarkers extracted through this approach demonstrate enhanced robustness and generalizability against rotation compared to models using standard convolution kernels, holding promise for enhancing the accuracy, consistency, and robustness of ML models in digital pathology. Ultimately, this work aims to improve diagnostic and prognostic capabilities of histopathology beyond prostate cancer through equivariant imaging.","authors":["Fuyao Chen","Yuexi Du","Tal Zeevi","Nicha C. Dvornek","John A. Onofrey"],"url":"https://arxiv.org/abs/2505.05689"}
{"created":"2025-05-12","title":"Hybrid Learning: A Novel Combination of Self-Supervised and Supervised Learning for MRI Reconstruction without High-Quality Training Reference","abstract":"Purpose: Deep learning has demonstrated strong potential for MRI reconstruction, but conventional supervised learning methods require high-quality reference images, which are often unavailable in practice. Self-supervised learning offers an alternative, yet its performance degrades at high acceleration rates. To overcome these limitations, we propose hybrid learning, a novel two-stage training framework that combines self-supervised and supervised learning for robust image reconstruction.","authors":["Haoyang Pei","Ding Xia","Xiang Xu","William Moore","Yao Wang","Hersh Chandarana","Li Feng"],"url":"https://arxiv.org/abs/2505.05703"}
{"created":"2025-05-12","title":"Multimodal Integrated Knowledge Transfer to Large Language Models through Preference Optimization with Biomedical Applications","abstract":"The scarcity of high-quality multimodal biomedical data limits the ability to effectively fine-tune pretrained Large Language Models (LLMs) for specialized biomedical tasks. To address this challenge, we introduce MINT (Multimodal Integrated kNowledge Transfer), a framework that aligns unimodal large decoder models with domain-specific decision patterns from multimodal biomedical data through preference optimization. While MINT supports different optimization techniques, we primarily implement it with the Odds Ratio Preference Optimization (ORPO) framework as its backbone. This strategy enables the aligned LLMs to perform predictive tasks using text-only or image-only inputs while retaining knowledge learnt from multimodal data. MINT leverages an upstream multimodal machine learning (MML) model trained on high-quality multimodal data to transfer domain-specific insights to downstream text-only or image-only LLMs. We demonstrate its effectiveness through two key applications: (1) Rare genetic disease prediction from texts, where MINT uses a multimodal encoder model, trained on facial photos and clinical notes, to generate a preference dataset for aligning a lightweight Llama 3.2-3B-Instruct. Despite relying on text input only, the MINT-derived model outperforms models trained with SFT, RAG, or DPO, and even outperforms Llama 3.1-405B-Instruct. (2) Tissue type classification using cell nucleus images, where MINT uses a vision-language foundation model as the preference generator, containing knowledge learnt from both text and histopathological images to align downstream image-only models. The resulting MINT-derived model significantly improves the performance of Llama 3.2-Vision-11B-Instruct on tissue type classification. In summary, MINT provides an effective strategy to align unimodal LLMs with high-quality multimodal expertise through preference optimization.","authors":["Da Wu","Zhanliang Wang","Quan Nguyen","Zhuoran Xu","Kai Wang"],"url":"https://arxiv.org/abs/2505.05736"}
{"created":"2025-05-12","title":"Predicting Diabetic Macular Edema Treatment Responses Using OCT: Dataset and Methods of APTOS Competition","abstract":"Diabetic macular edema (DME) significantly contributes to visual impairment in diabetic patients. Treatment responses to intravitreal therapies vary, highlighting the need for patient stratification to predict therapeutic benefits and enable personalized strategies. To our knowledge, this study is the first to explore pre-treatment stratification for predicting DME treatment responses. To advance this research, we organized the 2nd Asia-Pacific Tele-Ophthalmology Society (APTOS) Big Data Competition in 2021. The competition focused on improving predictive accuracy for anti-VEGF therapy responses using ophthalmic OCT images. We provided a dataset containing tens of thousands of OCT images from 2,000 patients with labels across four sub-tasks. This paper details the competition's structure, dataset, leading methods, and evaluation metrics. The competition attracted strong scientific community participation, with 170 teams initially registering and 41 reaching the final round. The top-performing team achieved an AUC of 80.06%, highlighting the potential of AI in personalized DME treatment and clinical decision-making.","authors":["Weiyi Zhang","Peranut Chotcomwongse","Yinwen Li","Pusheng Xu","Ruijie Yao","Lianhao Zhou","Yuxuan Zhou","Hui Feng","Qiping Zhou","Xinyue Wang","Shoujin Huang","Zihao Jin","Florence H. T. Chung","Shujun Wang","Yalin Zheng","Mingguang He","Danli Shi","Paisan Ruamviboonsuk"],"url":"https://arxiv.org/abs/2505.05768"}
{"created":"2025-05-12","title":"FlowHFT: Flow Policy Induced Optimal High-Frequency Trading under Diverse Market Conditions","abstract":"High-frequency trading (HFT) is an investing strategy that continuously monitors market states and places bid and ask orders at millisecond speeds. Traditional HFT approaches fit models with historical data and assume that future market states follow similar patterns. This limits the effectiveness of any single model to the specific conditions it was trained for. Additionally, these models achieve optimal solutions only under specific market conditions, such as assumptions about stock price's stochastic process, stable order flow, and the absence of sudden volatility. Real-world markets, however, are dynamic, diverse, and frequently volatile. To address these challenges, we propose the FlowHFT, a novel imitation learning framework based on flow matching policy. FlowHFT simultaneously learns strategies from numerous expert models, each proficient in particular market scenarios. As a result, our framework can adaptively adjust investment decisions according to the prevailing market state. Furthermore, FlowHFT incorporates a grid-search fine-tuning mechanism. This allows it to refine strategies and achieve superior performance even in complex or extreme market scenarios where expert strategies may be suboptimal. We test FlowHFT in multiple market environments. We first show that flow matching policy is applicable in stochastic market environments, thus enabling FlowHFT to learn trading strategies under different market conditions. Notably, our single framework consistently achieves performance superior to the best expert for each market condition.","authors":["Yang Li","Zhi Chen","Steve Yang"],"url":"https://arxiv.org/abs/2505.05784"}
{"created":"2025-05-12","title":"Anti-concentration inequalities for log-concave variables on the real line","abstract":"We prove sharp anti-concentration results for log-concave random variables on the real line in both the discrete and continuous setting. Our approach is elementary and uses majorization techniques to recover and extend some recent and not so recent results.","authors":["Tulio Gaxiola","James Melbourne","Vincent Pigno","Emma Pollard"],"url":"https://arxiv.org/abs/2505.05793"}
{"created":"2025-05-12","title":"Assessing the Dynamics of the Coffee Value Chain in Davao del Sur: An Agent-Based Modeling Approach","abstract":"The study investigates the coffee value chain dynamics in Davao del Sur using an agent-based model. Three main factors driving interactions among key players were identified: trust, risk, and transaction costs. The model was constructed using NetLogo 6.3.0, and data from a survey questionnaire collected three data points from BACOFA members. Five cases were explored, with each scenario simulated 1000 times. Findings suggest that producers often sell to the market rather than the cooperative due to higher prices. However, producers tend to prioritize trust in buyers and their risk attitude, leading to increased sales to the cooperative. The producer's risk attitude significantly influences their decision-making, affecting performance outcomes such as loans, demand, and price changes. All three factors play a role and exert varying impacts on the value chain. So, the stakeholders' decisions on prioritizing factors in improving relationships depend on their priorities. Nonetheless, simulations show that establishing a harmonious system benefiting all parties is possible. However, achieving this requires adjustments to demand, pricing, trust, and risk attitudes of key players, which may not align with the preferences of some parties in reality.","authors":["Lucia Stephanie B. Sibala","Novy Aila B. Rivas","Giovanna Fae R. Oguis"],"url":"https://arxiv.org/abs/2505.05797"}
{"created":"2025-05-12","title":"Towards order of magnitude X-ray dose reduction in breast cancer imaging using phase contrast and deep denoising","abstract":"Breast cancer is the most frequently diagnosed human cancer in the United States at present. Early detection is crucial for its successful treatment. X-ray mammography and digital breast tomosynthesis are currently the main methods for breast cancer screening. However, both have known limitations in terms of their sensitivity and specificity to breast cancers, while also frequently causing patient discomfort due to the requirement for breast compression. Breast computed tomography is a promising alternative, however, to obtain high-quality images, the X-ray dose needs to be sufficiently high. As the breast is highly radiosensitive, dose reduction is particularly important. Phase-contrast computed tomography (PCT) has been shown to produce higher-quality images at lower doses and has no need for breast compression. It is demonstrated in the present study that, when imaging full fresh mastectomy samples with PCT, deep learning-based image denoising can further reduce the radiation dose by a factor of 16 or more, without any loss of image quality. The image quality has been assessed both in terms of objective metrics, such as spatial resolution and contrast-to-noise ratio, as well as in an observer study by experienced medical imaging specialists and radiologists. This work was carried out in preparation for live patient PCT breast cancer imaging, initially at specialized synchrotron facilities.","authors":["Ashkan Pakzad","Robert Turnbull","Simon J. Mutch","Thomas A. Leatham","Darren Lockie","Jane Fox","Beena Kumar","Daniel H\\\"asermann","Christopher J. Hall","Anton Maksimenko","Benedicta D. Arhatari","Yakov I. Nesterets","Amir Entezam","Seyedamir T. Taba","Patrick C. Brennan","Timur E. Gureyev","Harry M. Quiney"],"url":"https://arxiv.org/abs/2505.05812"}
{"created":"2025-05-12","title":"Representation gaps of rigid planar diagram monoids","abstract":"We define non-pivotal analogs of the Temperley-Lieb, Motzkin, and planar rook monoids, and compute bounds for the sizes of their nontrivial simple representations. From this, we assess the two types of monoids in their relative suitability for use in cryptography by comparing their representation gaps and gap ratios. We conclude that the non-pivotal monoids are generally worse for cryptographic purposes.","authors":["Willow Stewart","Daniel Tubbenhauer"],"url":"https://arxiv.org/abs/2505.05846"}
{"created":"2025-05-12","title":"Evolutionary ecology of words","abstract":"We propose a model for the evolutionary ecology of words as one attempt to extend evolutionary game theory and agent-based models by utilizing the rich linguistic expressions of Large Language Models (LLMs). Our model enables the emergence and evolution of diverse and infinite options for interactions among agents. Within the population, each agent possesses a short word (or phrase) generated by an LLM and moves within a spatial environment. When agents become adjacent, the outcome of their interaction is determined by the LLM based on the relationship between their words, with the loser's word being replaced by the winner's. Word mutations, also based on LLM outputs, may occur. We conducted preliminary experiments assuming that ``strong animal species\" would survive. The results showed that from an initial population consisting of well-known species, many species emerged both gradually and in a punctuated equilibrium manner. Each trial demonstrated the unique evolution of diverse populations, with one type of large species becoming dominant, such as terrestrial animals, marine life, or extinct species, which were ecologically specialized and adapted ones across diverse extreme habitats. We also conducted a long-term experiment with a large population, demonstrating the emergence and coexistence of diverse species.","authors":["Reiji Suzuki","Takaya Arita"],"url":"https://arxiv.org/abs/2505.05863"}
{"created":"2025-05-12","title":"On removing orders from amplitude equations","abstract":"In this paper, we introduce a modified version of the renormalization group (RG) method and test its numerical accuracy. It has been tested on numerous scalar ODEs and systems of ODEs. Our method is primarily motivated by the possibility of simplifying amplitude equations. The key feature of our method is the introduction of a new homogeneous function at each order of the perturbation hierarchy, which is then used to remove terms from the amplitude equations. We have shown that there is a limit to how many terms can be removed, as doing so beyond a certain point would reintroduce linear growth. There is thus a \\textit{core} in the amplitude equation, which consists of the terms that cannot be removed while avoiding linear growth. Using our modified RG method, higher accuracy can also be achieved while maintaining the same level of complexity in the amplitude equation.","authors":["David Juhasz","Per Kristen Jakobsen"],"url":"https://arxiv.org/abs/2505.05915"}
{"created":"2025-05-12","title":"Multi-User Beamforming with Deep Reinforcement Learning in Sensing-Aided Communication","abstract":"Mobile users are prone to experience beam failure due to beam drifting in millimeter wave (mmWave) communications. Sensing can help alleviate beam drifting with timely beam changes and low overhead since it does not need user feedback. This work studies the problem of optimizing sensing-aided communication by dynamically managing beams allocated to mobile users. A multi-beam scheme is introduced, which allocates multiple beams to the users that need an update on the angle of departure (AoD) estimates and a single beam to the users that have satisfied AoD estimation precision. A deep reinforcement learning (DRL) assisted method is developed to optimize the beam allocation policy, relying only upon the sensing echoes. For comparison, a heuristic AoD-based method using approximated Cram\\'er-Rao lower bound (CRLB) for allocation is also presented. Both methods require neither user feedback nor prior state evolution information. Results show that the DRL-assisted method achieves a considerable gain in throughput than the conventional beam sweeping method and the AoD-based method, and it is robust to different user speeds.","authors":["Xiyu Wang","Gilberto Berardinelli","Hei Victor Cheng","Petar Popovski","Ramoni Adeogun"],"url":"https://arxiv.org/abs/2505.05956"}
{"created":"2025-05-12","title":"Efficient Quantum Convolutional Neural Networks for Image Classification: Overcoming Hardware Constraints","abstract":"While classical convolutional neural networks (CNNs) have revolutionized image classification, the emergence of quantum computing presents new opportunities for enhancing neural network architectures. Quantum CNNs (QCNNs) leverage quantum mechanical properties and hold potential to outperform classical approaches. However, their implementation on current noisy intermediate-scale quantum (NISQ) devices remains challenging due to hardware limitations. In our research, we address this challenge by introducing an encoding scheme that significantly reduces the input dimensionality. We demonstrate that a primitive QCNN architecture with 49 qubits is sufficient to directly process $28\\times 28$ pixel MNIST images, eliminating the need for classical dimensionality reduction pre-processing. Additionally, we propose an automated framework based on expressibility, entanglement, and complexity characteristics to identify the building blocks of QCNNs, parameterized quantum circuits (PQCs). Our approach demonstrates advantages in accuracy and convergence speed with a similar parameter count compared to both hybrid QCNNs and classical CNNs. We validated our experiments on IBM's Heron r2 quantum processor, achieving $96.08\\%$ classification accuracy, surpassing the $71.74\\%$ benchmark of traditional approaches under identical training conditions. These results represent one of the first implementations of image classifications on real quantum hardware and validate the potential of quantum computing in this area.","authors":["Peter R\\\"oseler","Oliver Schaudt","Helmut Berg","Christian Bauckhage","Matthias Koch"],"url":"https://arxiv.org/abs/2505.05957"}
{"created":"2025-05-12","title":"Beyond Diagonal RIS Design for Parameter Estimation With and Without Eavesdropping","abstract":"In this letter, we investigate the transmission of a complex-valued parameter vector from a transmitter to an intended receiver, considering both the presence and absence of an eavesdropper. The direct links from the transmitter to both the intended receiver and the eavesdropper are assumed to be blocked, and communications occur solely through cascaded channels facilitated by a beyond-diagonal reconfigurable intelligent surface (BD-RIS). While previous research has considered this system under conventional (diagonal) RIS assistance, we extend the setup to incorporate BD-RIS and quantify the resulting improvement in estimation performance at the intended receiver. This performance is measured by the trace of the Fisher information matrix (FIM), or equivalently, the average Fisher information, while simultaneously limiting the estimation capability of the eavesdropper. We propose solutions and algorithms for optimizing the BD-RIS response matrix and demonstrate their effectiveness. Numerical results reveal that the BD-RIS provides a significant enhancement in estimation quality compared to conventional diagonal RIS architectures.","authors":["\\\"Ozlem Tu\\u{g}fe Demir","Sinan Gezici"],"url":"https://arxiv.org/abs/2505.05971"}
{"created":"2025-05-12","title":"Functoriality of Enriched Data Types","abstract":"In previous work, categories of algebras of endofunctors were shown to be enriched in categories of coalgebras of the same endofunctor, and the extra structure of that enrichment was used to define a generalization of inductive data types. These generalized inductive data types are parametrized by a coalgebra $C$, so we call them $C$-inductive data types; we call the morphisms induced by their universal property $C$-inductive functions. We extend that work by incorporating natural transformations into the theory: given a suitable natural transformation between endofunctors, we show that this induces enriched functors between their categories of algebras which preserve $C$-inductive data types and $C$-inductive functions. Such $C$-inductive data types are often finite versions of the corresponding inductive data type, and we show how our framework can extend classical initial algebra semantics to these types. For instance, we show that our theory naturally produces partially inductive functions on lists, changes in list element types, and tree pruning functions.","authors":["Lukas Mulder","Paige Randall North","Maximilien P\\'eroux"],"url":"https://arxiv.org/abs/2505.06059"}
{"created":"2025-05-12","title":"S2MNet: Speckle-To-Mesh Net for Three-Dimensional Cardiac Morphology Reconstruction via Echocardiogram","abstract":"Echocardiogram is the most commonly used imaging modality in cardiac assessment duo to its non-invasive nature, real-time capability, and cost-effectiveness. Despite its advantages, most clinical echocardiograms provide only two-dimensional views, limiting the ability to fully assess cardiac anatomy and function in three dimensions. While three-dimensional echocardiography exists, it often suffers from reduced resolution, limited availability, and higher acquisition costs. To overcome these challenges, we propose a deep learning framework S2MNet that reconstructs continuous and high-fidelity 3D heart models by integrating six slices of routinely acquired 2D echocardiogram views. Our method has three advantages. First, our method avoid the difficulties on training data acquasition by simulate six of 2D echocardiogram images from corresponding slices of a given 3D heart mesh. Second, we introduce a deformation field-based method, which avoid spatial discontinuities or structural artifacts in 3D echocardiogram reconstructions. We validate our method using clinically collected echocardiogram and demonstrate that our estimated left ventricular volume, a key clinical indicator of cardiac function, is strongly correlated with the doctor measured GLPS, a clinical measurement that should demonstrate a negative correlation with LVE in medical theory. This association confirms the reliability of our proposed 3D construction method.","authors":["Xilin Gong","Yongkai Chen","Shushan Wu","Fang Wang","Ping Ma","Wenxuan Zhong"],"url":"https://arxiv.org/abs/2505.06105"}
{"created":"2025-05-12","title":"The Application of Deep Learning for Lymph Node Segmentation: A Systematic Review","abstract":"Automatic lymph node segmentation is the cornerstone for advances in computer vision tasks for early detection and staging of cancer. Traditional segmentation methods are constrained by manual delineation and variability in operator proficiency, limiting their ability to achieve high accuracy. The introduction of deep learning technologies offers new possibilities for improving the accuracy of lymph node image analysis. This study evaluates the application of deep learning in lymph node segmentation and discusses the methodologies of various deep learning architectures such as convolutional neural networks, encoder-decoder networks, and transformers in analyzing medical imaging data across different modalities. Despite the advancements, it still confronts challenges like the shape diversity of lymph nodes, the scarcity of accurately labeled datasets, and the inadequate development of methods that are robust and generalizable across different imaging modalities. To the best of our knowledge, this is the first study that provides a comprehensive overview of the application of deep learning techniques in lymph node segmentation task. Furthermore, this study also explores potential future research directions, including multimodal fusion techniques, transfer learning, and the use of large-scale pre-trained models to overcome current limitations while enhancing cancer diagnosis and treatment planning strategies.","authors":["Jingguo Qu","Xinyang Han","Man-Lik Chui","Yao Pu","Simon Takadiyi Gunda","Ziman Chen","Jing Qin","Ann Dorothy King","Winnie Chiu-Wing Chu","Jing Cai","Michael Tin-Cheung Ying"],"url":"https://arxiv.org/abs/2505.06118"}
{"created":"2025-05-12","title":"Advancing Finite-Length Quantum Error Correction Using Generalized Bicycle Codes","abstract":"Generalized bicycle (GB) codes have emerged as a promising class of quantum error-correcting codes with practical decoding capabilities. While numerous asymptotically good quantum codes and quantum low-density parity-check code constructions have been proposed, their finite block-length performance often remains unquantified. In this work, we demonstrate that GB codes exhibit comparable or superior error correction performance in finite-length settings, particularly when designed with higher or unrestricted row weights. Leveraging their flexible construction, GB codes can be tailored to achieve high rates while maintaining efficient decoding. We evaluate GB codes against other leading quantum code families, such as quantum Tanner codes and single-parity-check product codes, highlighting their versatility in practical finite-length applications.","authors":["Olai \\AA. Mostad","Hsuan-Yin Lin","Eirik Rosnes","De-Shih Lee","Ching-Yi Lai"],"url":"https://arxiv.org/abs/2505.06157"}
{"created":"2025-05-12","title":"ABAMGuid+: An Enhanced Aerocapture Guidance Framework using Augmented Bank Angle Modulation","abstract":"Aerocapture consists of converting a hyperbolic approach trajectory into a captured target orbit utilizing the aerodynamic forces generated via a single pass through the atmosphere. Aerocapture guidance systems must be robust to significant environmental variations and modeling uncertainty, particularly regarding atmospheric properties and delivery conditions. Recent work has shown that enabling control over both bank angle and angle of attack, a strategy referred to as augmented bank angle modulation (ABAM), can improve robustness to entry state and atmospheric uncertainties. In this work, we derive optimal control solutions for an aerocapture vehicle using ABAM. We first formulate the problem using a linear aerodynamic model and derive closed-form optimal control profiles using Pontryagin's Minimum Principle. To increase modeling fidelity, we also consider a quadratic aerodynamic model and obtain the solution directly using the optimality conditions. Both formulations are solved numerically using Gauss pseudospectral methods (via GPOPS, a software tool for pseudospectral optimal control), to validate the analytic solutions. We then introduce a novel aerocapture guidance algorithm, ABAMGuid+, which indirectly minimizes propellant usage by mimicking the structure of the optimal control solution, enabling efficient guidance by avoiding the complexity of solving the full optimal control problem online. Extensive Monte Carlo simulations of a Uranus aerocapture mission demonstrate that ABAMGuid+ increases capture success rates and reduces post-capture propellant requirements relative to previous methods.","authors":["Kyle A. Sonandres","Thomas R. Palazzo","Jonathan P. How"],"url":"https://arxiv.org/abs/2505.06161"}
{"created":"2025-05-12","title":"Optimization of Quantum Error Correcting Code under Temporal Variation of Qubit Quality","abstract":"Error rates in current noisy quantum hardware are not static; they vary over time and across qubits. This temporal and spatial variation challenges the effectiveness of fixed-distance quantum error correction (QEC) codes. In this paper, we analyze 12 days of calibration data from IBM's 127-qubit device (ibm_kyiv), showing the fluctuation of Pauli-X and CNOT gate error rates. We demonstrate that fixed-distance QEC can either underperform or lead to excessive overhead, depending on the selected qubit and the error rate of the day. We then propose a simple adaptive QEC approach that selects an appropriate code distance per qubit, based on daily error rates. Using logical error rate modeling, we identify qubits that cannot be used and qubits that can be recovered with minimal resources. Our method avoids unnecessary resource overhead by excluding outlier qubits and tailoring code distances. Across 12 calibration days on ibm_kyiv, our adaptive strategy reduces physical qubit overhead by over 50% per logical qubit while maintaining access to 85-100% of usable qubits. To further validate the method, we repeat the experiment on two additional 127-qubit devices, ibm_brisbane and ibm_sherbrooke, where the overhead savings reach up to 71% while still preserving over 80% qubit usability. This approach offers a practical and efficient path forward for Noisy Intermediate-Scale Quantum (NISQ)-era QEC strategies.","authors":["Subrata Das","Swaroop Ghosh"],"url":"https://arxiv.org/abs/2505.06165"}
{"created":"2025-05-12","title":"Turbo-ICL: In-Context Learning-Based Turbo Equalization","abstract":"This paper introduces a novel in-context learning (ICL) framework, inspired by large language models (LLMs), for soft-input soft-output channel equalization in coded multiple-input multiple-output (MIMO) systems. The proposed approach learns to infer posterior symbol distributions directly from a prompt of pilot signals and decoder feedback. A key innovation is the use of prompt augmentation to incorporate extrinsic information from the decoder output as additional context, enabling the ICL model to refine its symbol estimates iteratively across turbo decoding iterations. Two model variants, based on Transformer and state-space architectures, are developed and evaluated. Extensive simulations demonstrate that, when traditional linear assumptions break down, e.g., in the presence of low-resolution quantization, ICL equalizers consistently outperform conventional model-based baselines, even when the latter are provided with perfect channel state information. Results also highlight the advantage of Transformer-based models under limited training diversity, as well as the efficiency of state-space models in resource-constrained scenarios.","authors":["Zihang Song","Matteo Zecchin","Bipin Rajendran","Osvaldo Simeone"],"url":"https://arxiv.org/abs/2505.06175"}
{"created":"2025-05-12","title":"Topo-VM-UNetV2: Encoding Topology into Vision Mamba UNet for Polyp Segmentation","abstract":"Convolutional neural network (CNN) and Transformer-based architectures are two dominant deep learning models for polyp segmentation. However, CNNs have limited capability for modeling long-range dependencies, while Transformers incur quadratic computational complexity. Recently, State Space Models such as Mamba have been recognized as a promising approach for polyp segmentation because they not only model long-range interactions effectively but also maintain linear computational complexity. However, Mamba-based architectures still struggle to capture topological features (e.g., connected components, loops, voids), leading to inaccurate boundary delineation and polyp segmentation. To address these limitations, we propose a new approach called Topo-VM-UNetV2, which encodes topological features into the Mamba-based state-of-the-art polyp segmentation model, VM-UNetV2. Our method consists of two stages: Stage 1: VM-UNetV2 is used to generate probability maps (PMs) for the training and test images, which are then used to compute topology attention maps. Specifically, we first compute persistence diagrams of the PMs, then we generate persistence score maps by assigning persistence values (i.e., the difference between death and birth times) of each topological feature to its birth location, finally we transform persistence scores into attention weights using the sigmoid function. Stage 2: These topology attention maps are integrated into the semantics and detail infusion (SDI) module of VM-UNetV2 to form a topology-guided semantics and detail infusion (Topo-SDI) module for enhancing the segmentation results. Extensive experiments on five public polyp segmentation datasets demonstrate the effectiveness of our proposed method. The code will be made publicly available.","authors":["Diego Adame","Jose A. Nunez","Fabian Vazquez","Nayeli Gurrola","Huimin Li","Haoteng Tang","Bin Fu","Pengfei Gu"],"url":"https://arxiv.org/abs/2505.06210"}
{"created":"2025-05-12","title":"A Machine-Learning Compositional Study of Exoplanetary Material Accreted Onto Five Helium-Atmosphere White Dwarfs with $\\texttt{cecilia}$","abstract":"We present the first application of the Machine Learning (ML) pipeline $\\texttt{cecilia}$ to determine the physical parameters and photospheric composition of five metal-polluted He-atmosphere white dwarfs without well-characterised elemental abundances. To achieve this, we perform a joint and iterative Bayesian fit to their $\\textit{SDSS}$ (R=2,000) and $\\textit{Keck/ESI}$ (R=4,500) optical spectra, covering the wavelength range from about 3,800\\r{A} to 9,000\\r{A}. Our analysis measures the abundances of at least two $-$and up to six$-$ chemical elements in their atmospheres with a predictive accuracy similar to that of conventional WD analysis techniques ($\\approx$0.20 dex). The white dwarfs with the largest number of detected heavy elements are SDSS J0859$+$5732 and SDSS J2311$-$0041, which simultaneously exhibit O, Mg, Si, Ca, and Fe in their $\\textit{Keck/ESI}$ spectra. For all systems, we find that the bulk composition of their pollutants is largely consistent with those of primitive CI chondrites to within 1-2$\\sigma$. We also find evidence of statistically significant ($>2\\sigma$) oxygen excesses for SDSS J0859$+$5732 and SDSS J2311$-$0041, which could point to the accretion of oxygen-rich exoplanetary material. In the future, as wide-field astronomical surveys deliver millions of public WD spectra to the scientific community, $\\texttt{cecilia}$ aspires to unlock population-wide studies of polluted WDs, therefore helping to improve our statistical knowledge of extrasolar compositions.","authors":["Mariona Badenas-Agusti","Siyi Xu","Andrew Vanderburg","Kishalay De","Patrick Dufour","Laura K. Rogers","Susana Hoyos","Simon Blouin","Javier Via\\~na","Amy Bonsor","Ben Zuckerman"],"url":"https://arxiv.org/abs/2505.06228"}
{"created":"2025-05-12","title":"A Gradient-thresholding Algorithm for Sparse Regularization","abstract":"Inverse problems arise in a wide spectrum of applications in fields ranging from engineering to scientific computation. Connected with the rise of interest in inverse problems is the development and analysis of regularization methods, such as Tikhonov-type regularization methods or iterative regularization methods, which are a necessity in most of the inverse problems. In the last few decades, regularization methods motivating sparsity has been the focus of research, due to the high dimensionalty of the real-life data, and $\\mathcal{L}^1$-regularization methods (such as LASSO or FISTA) has been in its center (due to their computational simplicity). In this paper we propose a new (semi-) iterative regularization method which is not only simpler than the mentioned algorithms but also yields better results, in terms of accuracy and sparsity of the recovered solution. Furthermore, we also present a very effective and practical stopping criterion to choose an appropriate regularization parameter (here, it's iteration index) so as to recover a regularized (sparse) solution. To illustrate the computational efficiency of this algorithm we apply it to numerically solve the image deblurring problem and compare our results with certain standard regularization methods, like total variation, FISTA, LSQR etc.","authors":["Abinash Nayak"],"url":"https://arxiv.org/abs/2006.03437"}
{"created":"2025-05-12","title":"Science of science -- Citation models and research evaluation","abstract":"Citations in science are being studied from several perspectives, among which approaches such as scientometrics and science of science. In this chapter I briefly review some of the literature on citations, citation distributions and models of citations. These citations feature prominently in another part of the literature which is dealing with research evaluation and the role of metrics and indicators in that process. Here I briefly review part of the discussion in research evaluation. This also touches on the subject of how citations relate to peer review. Finally, I conclude by trying to integrate the two literatures. The fundamental problem in research evaluation is that research quality is unobservable. This has consequences for conclusions that we can draw from quantitative studies of citations and citation models. The term ``indicators'' is a relevant concept in this context, which I try to clarify. Causality is important for properly understanding indicators, especially when indicators are used in practice: when we act on indicators, we enter causal territory. Even when an indicator might have been valid, through its very use, the consequences of its use may invalidate it. By combining citation models with proper causal reasoning and acknowledging the fundamental problem about unobservable research quality, we may hope to make progress.","authors":["V. A. Traag"],"url":"https://arxiv.org/abs/2207.11116"}
{"created":"2025-05-12","title":"PART: Pre-trained Authorship Representation Transformer","abstract":"Authors writing documents imprint identifying information within their texts: vocabulary, registry, punctuation, misspellings, or even emoji usage. Previous works use hand-crafted features or classification tasks to train their authorship models, leading to poor performance on out-of-domain authors. Using stylometric representations is more suitable, but this by itself is an open research challenge. In this paper, we propose PART, a contrastively trained model fit to learn \\textbf{authorship embeddings} instead of semantics. We train our model on ~1.5M texts belonging to 1162 literature authors, 17287 blog posters and 135 corporate email accounts; a heterogeneous set with identifiable writing styles. We evaluate the model on current challenges, achieving competitive performance. We also evaluate our model on test splits of the datasets achieving zero-shot 72.39\\% accuracy when bounded to 250 authors, a 54\\% and 56\\% higher than RoBERTa embeddings. We qualitatively assess the representations with different data visualizations on the available datasets, observing features such as gender, age, or occupation of the author.","authors":["Javier Huertas-Tato","Alejandro Martin","David Camacho"],"url":"https://arxiv.org/abs/2209.15373"}
{"created":"2025-05-12","title":"Modelling of a DC-DC Buck Converter Using Long-Short-Term-Memory (LSTM)","abstract":"Artificial neural networks make it possible to identify black-box models. Based on a recurrent nonlinear autoregressive exogenous neural network, this research provides a technique for simulating the static and dynamic behavior of a DC-DC power converter. This approach employs an algorithm for training a neural network using the inputs and outputs (currents and voltages) of a Buck converter. The technique is validated using simulated data of a realistic Simulink-programmed nonsynchronous Buck converter model and experimental findings. The correctness of the technique is determined by comparing the predicted outputs of the neural network to the actual outputs of the system, thereby confirming the suggested strategy. Simulation findings demonstrate the practicability and precision of the proposed black-box method.","authors":["Muhy Eddin Za'ter"],"url":"https://arxiv.org/abs/2211.03040"}
{"created":"2025-05-12","title":"Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability","abstract":"Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field concerned with providing intelligible algorithms that are faithful simplifications of the known, but opaque low-level details of black box AI models. Our contributions are (1) generalizing the theory of causal abstraction from mechanism replacement (i.e., hard and soft interventions) to arbitrary mechanism transformation (i.e., functionals from old mechanisms to new mechanisms), (2) providing a flexible, yet precise formalization for the core concepts of polysemantic neurons, the linear representation hypothesis, modular features, and graded faithfulness, and (3) unifying a variety of mechanistic interpretability methods in the common language of causal abstraction, namely, activation and path patching, causal mediation analysis, causal scrubbing, causal tracing, circuit analysis, concept erasure, sparse autoencoders, differential binary masking, distributed alignment search, and steering.","authors":["Atticus Geiger","Duligur Ibeling","Amir Zur","Maheep Chaudhary","Sonakshi Chauhan","Jing Huang","Aryaman Arora","Zhengxuan Wu","Noah Goodman","Christopher Potts","Thomas Icard"],"url":"https://arxiv.org/abs/2301.04709"}
{"created":"2025-05-12","title":"Towards Foundation Models and Few-Shot Parameter-Efficient Fine-Tuning for Volumetric Organ Segmentation","abstract":"The recent popularity of foundation models and the pre-train-and-adapt paradigm, where a large-scale model is transferred to downstream tasks, is gaining attention for volumetric medical image segmentation. However, current transfer learning strategies devoted to full fine-tuning for transfer learning may require significant resources and yield sub-optimal results when the labeled data of the target task is scarce. This makes its applicability in real clinical settings challenging since these institutions are usually constrained on data and computational resources to develop proprietary solutions. To address this challenge, we formalize Few-Shot Efficient Fine-Tuning (FSEFT), a novel and realistic scenario for adapting medical image segmentation foundation models. This setting considers the key role of both data- and parameter-efficiency during adaptation. Building on a foundation model pre-trained on open-access CT organ segmentation sources, we propose leveraging Parameter-Efficient Fine-Tuning and black-box Adapters to address such challenges. Furthermore, novel efficient adaptation methodologies are introduced in this work, which include Spatial black-box Adapters that are more appropriate for dense prediction tasks and constrained transductive inference, leveraging task-specific prior knowledge. Our comprehensive transfer learning experiments confirm the suitability of foundation models in medical image segmentation and unveil the limitations of popular fine-tuning strategies in few-shot scenarios.","authors":["Julio Silva-Rodr\\'iguez","Jose Dolz","Ismail Ben Ayed"],"url":"https://arxiv.org/abs/2303.17051"}
{"created":"2025-05-12","title":"A vector quantized masked autoencoder for audiovisual speech emotion recognition","abstract":"An important challenge in emotion recognition is to develop methods that can leverage unlabeled training data. In this paper, we propose the VQ-MAE-AV model, a self-supervised multimodal model that leverages masked autoencoders to learn representations of audiovisual speech without labels. The model includes vector quantized variational autoencoders that compress raw audio and visual speech data into discrete tokens. The audiovisual speech tokens are used to train a multimodal masked autoencoder that consists of an encoder-decoder architecture with attention mechanisms. The model is designed to extract both local (i.e., at the frame level) and global (i.e., at the sequence level) representations of audiovisual speech. During self-supervised pre-training, the VQ-MAE-AV model is trained on a large-scale unlabeled dataset of audiovisual speech, for the task of reconstructing randomly masked audiovisual speech tokens and with a contrastive learning strategy. During this pre-training, the encoder learns to extract a representation of audiovisual speech that can be subsequently leveraged for emotion recognition. During the supervised fine-tuning stage, a small classification model is trained on top of the VQ-MAE-AV encoder for an emotion recognition task. The proposed approach achieves state-of-the-art emotion recognition results across several datasets in both controlled and in-the-wild conditions.","authors":["Samir Sadok","Simon Leglaive","Renaud S\\'eguier"],"url":"https://arxiv.org/abs/2305.03568"}
{"created":"2025-05-12","title":"New Optimal Results on Codes for Location in Graphs","abstract":"In this paper, we broaden the understanding of the recently introduced concepts of solid-locating-dominating and self-locating-dominating codes in various graphs. In particular, we present the optimal, i.e., smallest possible, codes in the infinite triangular and king grids. Furthermore, we give optimal locating-dominating, self-locating-dominating and solid-locating-dominating codes in the direct product $K_n\\times K_m$ of complete graphs. We also present optimal solid-locating-dominating codes for the Hamming graphs $K_q\\square K_q\\square K_q$ with $q\\geq2$.","authors":["Ville Junnila","Tero Laihonen","Tuomo Lehtil\\\"a"],"url":"https://arxiv.org/abs/2306.07862"}
{"created":"2025-05-12","title":"SuperBench: A Super-Resolution Benchmark Dataset for Scientific Machine Learning","abstract":"Super-resolution (SR) techniques aim to enhance data resolution, enabling the retrieval of finer details, and improving the overall quality and fidelity of the data representation. There is growing interest in applying SR methods to complex spatiotemporal systems within the Scientific Machine Learning (SciML) community, with the hope of accelerating numerical simulations and/or improving forecasts in weather, climate, and related areas. However, the lack of standardized benchmark datasets for comparing and validating SR methods hinders progress and adoption in SciML. To address this, we introduce SuperBench, the first benchmark dataset featuring high-resolution datasets, including data from fluid flows, cosmology, and weather. Here, we focus on validating spatial SR performance from data-centric and physics-preserved perspectives, as well as assessing robustness to data degradation tasks. While deep learning-based SR methods (developed in the computer vision community) excel on certain tasks, despite relatively limited prior physics information, we identify limitations of these methods in accurately capturing intricate fine-scale features and preserving fundamental physical properties and constraints in scientific data. These shortcomings highlight the importance and subtlety of incorporating domain knowledge into ML models. We anticipate that SuperBench will help to advance SR methods for science.","authors":["Pu Ren","N. Benjamin Erichson","Junyi Guo","Shashank Subramanian","Omer San","Zarija Lukic","Michael W. Mahoney"],"url":"https://arxiv.org/abs/2306.14070"}
{"created":"2025-05-12","title":"Descriptive complexity for neural networks via Boolean networks","abstract":"We investigate the expressive power of neural networks from the point of view of descriptive complexity. We study neural networks that use floating-point numbers and piecewise polynomial activation functions from two perspectives: 1) the general scenario where neural networks run for an unlimited number of rounds and have unrestricted topologies, and 2) classical feedforward neural networks that have the topology of layered acyclic graphs and run for only a constant number of rounds. We characterize these neural networks via Boolean networks formalized via a recursive rule-based logic. In particular, we show that the sizes of the neural networks and the corresponding Boolean rule formulae are polynomially related. In fact, in the direction from Boolean rules to neural networks, the blow-up is only linear. Our translations result in a time delay, which is the number of rounds that it takes to simulate a single computation step. In the translation from neural networks to Boolean rules, the time delay of the resulting formula is polylogarithmic in the size of the neural network. In the converse translation, the time delay of the neural network is linear in the formula size. Ultimately, we obtain translations between neural networks, Boolean networks, the diamond-free fragment of modal substitution calculus, and a class of recursive Boolean circuits. Our translations offer a method, for almost any activation function F, of translating any neural network in our setting into an equivalent neural network that uses F at each node. This even includes linear activation functions, which is possible due to using floats rather than actual reals!","authors":["Veeti Ahvonen","Damian Heiman","Antti Kuusisto"],"url":"https://arxiv.org/abs/2308.06277"}
{"created":"2025-05-12","title":"End-to-End Driving via Self-Supervised Imitation Learning Using Camera and LiDAR Data","abstract":"In autonomous driving, the end-to-end (E2E) driving approach that predicts vehicle control signals directly from sensor data is rapidly gaining attention. To learn a safe E2E driving system, one needs an extensive amount of driving data and human intervention. Vehicle control data is constructed by many hours of human driving, and it is challenging to construct large vehicle control datasets. Often, publicly available driving datasets are collected with limited driving scenes, and collecting vehicle control data is only available by vehicle manufacturers. To address these challenges, this letter proposes the first fully self-supervised learning framework, self-supervised imitation learning (SSIL), for E2E driving, based on the self-supervised regression learning (SSRL) framework.The proposed SSIL framework can learn E2E driving networks \\emph{without} using driving command data or a pre-trained model. To construct pseudo steering angle data, proposed SSIL predicts a pseudo target from the vehicle's poses at the current and previous time points that are estimated with light detection and ranging sensors. In addition, we propose two E2E driving networks that predict driving commands depending on high-level instruction. Our numerical experiments with three different benchmark datasets demonstrate that the proposed SSIL framework achieves \\emph{very} comparable E2E driving accuracy with the supervised learning counterpart. The proposed pseudo-label predictor outperformed an existing one using proportional integral derivative controller.","authors":["Jin Bok Park","Jinkyu Lee","Muhyun Back","Hyunmin Han","David T. Ma","Sang Min Won","Sung Soo Hwang","Il Yong Chun"],"url":"https://arxiv.org/abs/2308.14329"}
{"created":"2025-05-12","title":"Uncovering Model Processing Strategies with Non-Negative Per-Example Fisher Factorization","abstract":"We introduce NPEFF (Non-Negative Per-Example Fisher Factorization), an interpretability method that aims to uncover strategies used by a model to generate its predictions. NPEFF decomposes per-example Fisher matrices using a novel decomposition algorithm that learns a set of components represented by learned rank-1 positive semi-definite matrices. Through a combination of human evaluation and automated analysis, we demonstrate that these NPEFF components correspond to model processing strategies for a variety of language models and text processing tasks. We further show how to construct parameter perturbations from NPEFF components to selectively disrupt a given component's role in the model's processing. Along with conducting extensive ablation studies, we include experiments to show how NPEFF can be used to analyze and mitigate collateral effects of unlearning and use NPEFF to study in-context learning. Furthermore, we demonstrate the advantages of NPEFF over baselines such as gradient clustering and using sparse autoencoders for dictionary learning over model activations.","authors":["Michael Matena","Colin Raffel"],"url":"https://arxiv.org/abs/2310.04649"}
{"created":"2025-05-12","title":"Learning-based adaption of robotic friction models","abstract":"In the Fourth Industrial Revolution, wherein artificial intelligence and the automation of machines occupy a central role, the deployment of robots is indispensable. However, the manufacturing process using robots, especially in collaboration with humans, is highly intricate. In particular, modeling the friction torque in robotic joints is a longstanding problem due to the lack of a good mathematical description. This motivates the usage of data-driven methods in recent works. However, model-based and data-driven models often exhibit limitations in their ability to generalize beyond the specific dynamics they were trained on, as we demonstrate in this paper. To address this challenge, we introduce a novel approach based on residual learning, which aims to adapt an existing friction model to new dynamics using as little data as possible. We validate our approach by training a base neural network on a symmetric friction data set to learn an accurate relation between the velocity and the friction torque. Subsequently, to adapt to more complex asymmetric settings, we train a second network on a small dataset, focusing on predicting the residual of the initial network's output. By combining the output of both networks in a suitable manner, our proposed estimator outperforms the conventional model-based approach, an extended LuGre model, and the base neural network significantly. Furthermore, we evaluate our method on trajectories involving external loads and still observe a substantial improvement, approximately 60-70%, over the conventional approach. Our method does not rely on data with external load during training, eliminating the need for external torque sensors. This demonstrates the generalization capability of our approach, even with a small amount of data--less than a minute--enabling adaptation to diverse scenarios based on prior knowledge about friction in different settings.","authors":["Philipp Scholl","Maged Iskandar","Sebastian Wolf","Jinoh Lee","Aras Bacho","Alexander Dietrich","Alin Albu-Sch\\\"affer","Gitta Kutyniok"],"url":"https://arxiv.org/abs/2310.16688"}
{"created":"2025-05-12","title":"Bridging Lottery Ticket and Grokking: Understanding Grokking from Inner Structure of Networks","abstract":"Grokking is an intriguing phenomenon of delayed generalization, where neural networks initially memorize training data with perfect accuracy but exhibit poor generalization, subsequently transitioning to a generalizing solution with continued training. While factors such as weight norms and sparsity have been proposed to explain this delayed generalization, the influence of network structure remains underexplored. In this work, we link the grokking phenomenon to the lottery ticket hypothesis to investigate the impact of internal network structures. We demonstrate that utilizing lottery tickets obtained during the generalizing phase (termed grokked tickets) significantly reduces delayed generalization across various tasks, including multiple modular arithmetic operations, polynomial regression, sparse parity, and MNIST classification. Through controlled experiments, we show that the mitigation of delayed generalization is not due solely to reduced weight norms or increased sparsity, but rather to the discovery of good subnetworks. Furthermore, we find that grokked tickets exhibit periodic weight patterns, beneficial graph properties such as increased average path lengths and reduced clustering coefficients, and undergo rapid structural changes that coincide with improvements in generalization. Additionally, pruning techniques like the edge-popup algorithm can identify these effective structures without modifying the weights, thereby transforming memorizing networks into generalizing ones. These results underscore the novel insight that structural exploration plays a pivotal role in understanding grokking. The implementation code can be accessed via this link: https://github.com/gouki510/Grokking-Tickets.","authors":["Gouki Minegishi","Yusuke Iwasawa","Yutaka Matsuo"],"url":"https://arxiv.org/abs/2310.19470"}
{"created":"2025-05-12","title":"Channel Capacity and Bounds In Mixed Gaussian-Impulsive Noise","abstract":"Communication systems suffer from mixed noise consisting of both non-Gaussian impulsive noise (IN) and white Gaussian noise (WGN) in many practical applications. However, there is little literature about the channel capacity under mixed noise. In this paper, we first investigate statistical properties of the mixed noise model and demonstrate the existence and uniqueness of the capacity-achieving input distribution under the $p$-th moment constraint. Then, we derive lower and upper capacity bounds with closed expressions. It is shown that the lower bounds can degenerate to the well-known Shannon formula under special scenarios. More importantly, we obtain the convergence of the lower and upper bound and therefore, the asymptotic and analytical capacity expression is obtained. In addition, the capacity for specific modulations and the corresponding lower bounds are discussed. Numerical results reveal that the capacity decreases as the impulsiveness of the mixed noise becomes dominant and the proposed capacity bounds are very tight.","authors":["Tianfu Qi","Jun Wang","Xiaoping Li"],"url":"https://arxiv.org/abs/2311.08804"}
{"created":"2025-05-12","title":"Unsupervised Multi-modal Feature Alignment for Time Series Representation Learning","abstract":"In recent times, the field of unsupervised representation learning (URL) for time series data has garnered significant interest due to its remarkable adaptability across diverse downstream applications. Unsupervised learning goals differ from downstream tasks, making it tricky to ensure downstream task utility by focusing only on temporal feature characterization. Researchers have proposed multiple transformations to extract discriminative patterns implied in informative time series, trying to fill the gap. Despite the introduction of a variety of feature engineering techniques, e.g. spectral domain, wavelet transformed features, features in image form and symbolic features etc. the utilization of intricate feature fusion methods and dependence on heterogeneous features during inference hampers the scalability of the solutions. To address this, our study introduces an innovative approach that focuses on aligning and binding time series representations encoded from different modalities, inspired by spectral graph theory, thereby guiding the neural encoder to uncover latent pattern associations among these multi-modal features. In contrast to conventional methods that fuse features from multiple modalities, our proposed approach simplifies the neural architecture by retaining a single time series encoder, consequently leading to preserved scalability. We further demonstrate and prove mechanisms for the encoder to maintain better inductive bias. In our experimental evaluation, we validated the proposed method on a diverse set of time series datasets from various domains. Our approach outperforms existing state-of-the-art URL methods across diverse downstream tasks.","authors":["Chen Liang","Donghua Yang","Zhiyu Liang","Hongzhi Wang","Zheng Liang","Xiyang Zhang","Jianfeng Huang"],"url":"https://arxiv.org/abs/2312.05698"}
{"created":"2025-05-12","title":"An Invitation to Deep Reinforcement Learning","abstract":"Training a deep neural network to maximize a target objective has become the standard recipe for successful machine learning over the last decade. These networks can be optimized with supervised learning, if the target objective is differentiable. For many interesting problems, this is however not the case. Common objectives like intersection over union (IoU), bilingual evaluation understudy (BLEU) score or rewards cannot be optimized with supervised learning. A common workaround is to define differentiable surrogate losses, leading to suboptimal solutions with respect to the actual objective. Reinforcement learning (RL) has emerged as a promising alternative for optimizing deep neural networks to maximize non-differentiable objectives in recent years. Examples include aligning large language models via human feedback, code generation, object detection or control problems. This makes RL techniques relevant to the larger machine learning audience. The subject is, however, time intensive to approach due to the large range of methods, as well as the often very theoretical presentation. In this introduction, we take an alternative approach, different from classic reinforcement learning textbooks. Rather than focusing on tabular problems, we introduce reinforcement learning as a generalization of supervised learning, which we first apply to non-differentiable objectives and later to temporal problems. Assuming only basic knowledge of supervised learning, the reader will be able to understand state-of-the-art deep RL algorithms like proximal policy optimization (PPO) after reading this tutorial.","authors":["Bernhard Jaeger","Andreas Geiger"],"url":"https://arxiv.org/abs/2312.08365"}
{"created":"2025-05-12","title":"MotherNet: Fast Training and Inference via Hyper-Network Transformers","abstract":"Foundation models are transforming machine learning across many modalities, with in-context learning replacing classical model training. Recent work on tabular data hints at a similar opportunity to build foundation models for classification for numerical data. However, existing meta-learning approaches can not compete with tree-based methods in terms of inference time. In this paper, we propose MotherNet, a hypernetwork architecture trained on synthetic classification tasks that, once prompted with a never-seen-before training set generates the weights of a trained ``child'' neural-network by in-context learning using a single forward pass. In contrast to most existing hypernetworks that are usually trained for relatively constrained multi-task settings, MotherNet can create models for multiclass classification on arbitrary tabular datasets without any dataset specific gradient descent. The child network generated by MotherNet outperforms neural networks trained using gradient descent on small datasets, and is comparable to predictions by TabPFN and standard ML methods like Gradient Boosting. Unlike a direct application of TabPFN, MotherNet generated networks are highly efficient at inference time. We also demonstrate that HyperFast is unable to perform effective in-context learning on small datasets, and heavily relies on dataset specific fine-tuning and hyper-parameter tuning, while MotherNet requires no fine-tuning or per-dataset hyper-parameters.","authors":["Andreas M\\\"uller","Carlo Curino","Raghu Ramakrishnan"],"url":"https://arxiv.org/abs/2312.08598"}
{"created":"2025-05-12","title":"Complexity of Local Search for Euclidean Clustering Problems","abstract":"We show that the simplest local search heuristics for two natural Euclidean clustering problems are PLS-complete. First, we show that the Hartigan--Wong method for $k$-Means clustering is PLS-complete, even when $k = 2$. Second, we show the same result for the Flip heuristic for Max Cut, even when the edge weights are given by the (squared) Euclidean distances between the points in some set $\\mathcal{X} \\subseteq \\mathbb{R}^d$; a problem which is equivalent to Min Sum 2-Clustering.","authors":["Bodo Manthey","Nils Morawietz","Jesse van Rhijn","Frank Sommer"],"url":"https://arxiv.org/abs/2312.14916"}
{"created":"2025-05-12","title":"Open-Source, Cost-Aware Kinematically Feasible Planning for Mobile and Surface Robotics","abstract":"We present Smac Planner, an openly available, search-based planning framework that addresses the critical need for kinematically feasible path planning across diverse robot platforms. Smac Planner provides high-performance implementations of Cost-Aware A*, Hybrid-A*, and State Lattice planners that can be deployed for Ackermann, legged, and other large non-circular robots. Our framework introduces novel \"Cost-Aware\" variations that significantly improve performance in complex environments common to mobile robotics while maintaining kinematic feasibility constraints. Integrated as the standard planning system within the popular ROS 2 Navigation stack, Nav2, Smac Planner now powers thousands of robots worldwide across academic research, commercial applications, and field deployments.","authors":["Steve Macenski","Matthew Booker","Joshua Wallace","Tobias Fischer"],"url":"https://arxiv.org/abs/2401.13078"}
{"created":"2025-05-12","title":"The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support","abstract":"People experiencing severe distress increasingly use Large Language Model (LLM) chatbots as mental health support tools. Discussions on social media have described how engagements were lifesaving for some, but evidence suggests that general-purpose LLM chatbots also have notable risks that could endanger the welfare of users if not designed responsibly. In this study, we investigate the lived experiences of people who have used LLM chatbots for mental health support. We build on interviews with 21 individuals from globally diverse backgrounds to analyze how users create unique support roles for their chatbots, fill in gaps in everyday care, and navigate associated cultural limitations when seeking support from chatbots. We ground our analysis in psychotherapy literature around effective support, and introduce the concept of therapeutic alignment, or aligning AI with therapeutic values for mental health contexts. Our study offers recommendations for how designers can approach the ethical and effective use of LLM chatbots and other AI mental health support tools in mental health care.","authors":["Inhwa Song","Sachin R. Pendse","Neha Kumar","Munmun De Choudhury"],"url":"https://arxiv.org/abs/2401.14362"}
{"created":"2025-05-12","title":"Detecting Multimedia Generated by Large AI Models: A Survey","abstract":"The rapid advancement of Large AI Models (LAIMs), particularly diffusion models and large language models, has marked a new era where AI-generated multimedia is increasingly integrated into various aspects of daily life. Although beneficial in numerous fields, this content presents significant risks, including potential misuse, societal disruptions, and ethical concerns. Consequently, detecting multimedia generated by LAIMs has become crucial, with a marked rise in related research. Despite this, there remains a notable gap in systematic surveys that focus specifically on detecting LAIM-generated multimedia. Addressing this, we provide the first survey to comprehensively cover existing research on detecting multimedia (such as text, images, videos, audio, and multimodal content) created by LAIMs. Specifically, we introduce a novel taxonomy for detection methods, categorized by media modality, and aligned with two perspectives: pure detection (aiming to enhance detection performance) and beyond detection (adding attributes like generalizability, robustness, and interpretability to detectors). Additionally, we have presented a brief overview of generation mechanisms, public datasets, online detection tools, and evaluation metrics to provide a valuable resource for researchers and practitioners in this field. Most importantly, we offer a focused analysis from a social media perspective to highlight their broader societal impact. Furthermore, we identify current challenges in detection and propose directions for future research that address unexplored, ongoing, and emerging issues in detecting multimedia generated by LAIMs. Our aim for this survey is to fill an academic gap and contribute to global AI security efforts, helping to ensure the integrity of information in the digital realm. The project link is https://github.com/Purdue-M2/Detect-LAIM-generated-Multimedia-Survey.","authors":["Li Lin","Neeraj Gupta","Yue Zhang","Hainan Ren","Chun-Hao Liu","Feng Ding","Xin Wang","Xin Li","Luisa Verdoliva","Shu Hu"],"url":"https://arxiv.org/abs/2402.00045"}
{"created":"2025-05-12","title":"Generalized Arlery-Tan-Rabaste-Levenshtein Lower Bounds on Ambiguity Function and Their Asymptotic Achievability","abstract":"This paper presents generalized Arlery-Tan-Rabaste-Levenshtein lower bounds on the maximum aperiodic ambiguity function (AF) magnitude of unimodular sequences under certain delay-Doppler low ambiguity zones (LAZ). Our core idea is to explore the upper and lower bounds on the Frobenius norm of the weighted auto- and cross-AF matrices by introducing two weight vectors associated with the delay and Doppler shifts, respectively. As a second major contribution, we demonstrate that our derived lower bounds are asymptotically achievable with selected Chu sequence sets by analyzing their maximum auto- and cross- AF magnitudes within certain LAZ.","authors":["Lingsheng Meng","Yong Liang Guan","Yao Ge","Zilong Liu","Pingzhi Fan"],"url":"https://arxiv.org/abs/2402.00455"}
{"created":"2025-05-12","title":"Deep hybrid models: infer and plan in a dynamic world","abstract":"To determine an optimal plan for complex tasks, one often deals with dynamic and hierarchical relationships between several entities. Traditionally, such problems are tackled with optimal control, which relies on the optimization of cost functions; instead, a recent biologically-motivated proposal casts planning and control as an inference process. Active inference assumes that action and perception are two complementary aspects of life whereby the role of the former is to fulfill the predictions inferred by the latter. Here, we present an active inference approach that exploits discrete and continuous processing, based on three features: the representation of potential body configurations in relation to the objects of interest; the use of hierarchical relationships that enable the agent to easily interpret and flexibly expand its body schema for tool use; the definition of potential trajectories related to the agent's intentions, used to infer and plan with dynamic elements at different temporal scales. We evaluate this deep hybrid model on a habitual task: reaching a moving object after having picked a moving tool. We show that the model can tackle the presented task under different conditions. This study extends past work on planning as inference and advances an alternative direction to optimal control.","authors":["Matteo Priorelli","Ivilin Peev Stoianov"],"url":"https://arxiv.org/abs/2402.10088"}
{"created":"2025-05-12","title":"Image space formalism of convolutional neural networks for k-space interpolation","abstract":"Purpose: Noise resilience in image reconstructions by scan-specific robust artificial neural networks for k-space interpolation (RAKI) is linked to nonlinear activations in k-space. To gain a deeper understanding of this relationship, an image space formalism of RAKI is introduced for analyzing noise propagation analytically, identifying and characterizing image reconstruction features and to describe the role of nonlinear activations in a human readable manner. Methods: The image space formalism for RAKI inference is employed by expressing nonlinear activations in k-space as element-wise multiplications with activation masks, which transform into convolutions in image space. Jacobians of the de-aliased, coil-combined image relative to the aliased coil images can be expressed algebraically, and thus, the noise amplification is quantified analytically (g-factor maps). We analyze the role of nonlinearity for noise resilience by controlling the degree of nonlinearity in the reconstruction model via the negative slope parameter in leaky ReLU. Results: The analytical g-factor maps correspond with those obtained from Monte Carlo simulations and from an auto differentiation approach for in vivo brain images. Apparent blurring and contrast loss artifacts are identified as implications of enhanced noise resilience. These residual artifacts can be traded against noise resilience by adjusting the degree of nonlinearity in the model (Tikhonov-like regularization) in case of limited training data. The inspection of image space activations reveals an autocorrelation pattern leading to a potential center artifact. Conclusion: The image space formalism of RAKI provides the means for analytical quantitative noisepropagation analysis and human-readable visualization of the effects of the nonlinear activation functions in k-space.","authors":["Peter Dawood","Felix Breuer","Istvan Homolya","Maximilian Gram","Peter M. Jakob","Moritz Zaiss","Martin Blaimer"],"url":"https://arxiv.org/abs/2402.17410"}
{"created":"2025-05-12","title":"Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations","abstract":"Several accounts of human cognition posit that our intelligence is rooted in our ability to form abstract composable concepts, ground them in our environment, and reason over these grounded entities. This trifecta of human thought has remained elusive in modern intelligent machines. In this work, we investigate whether slot representations extracted from visual scenes serve as appropriate compositional abstractions for grounding and reasoning. We present the Neural Slot Interpreter (NSI), which learns to ground object semantics in slots. At the core of NSI is a nested schema that uses simple syntax rules to organize the object semantics of a scene into object-centric schema primitives. Then, the NSI metric learns to ground primitives into slots through a structured contrastive learning objective that reasons over the intermodal alignment. Experiments with a bi-modal object-property and scene retrieval task demonstrate the grounding efficacy and interpretability of correspondences learned by NSI. From a scene representation standpoint, we find that emergent NSI slots that move beyond the image grid by binding to spatial objects facilitate improved visual grounding compared to conventional bounding-box-based approaches. From a data efficiency standpoint, we empirically validate that NSI learns more generalizable representations from a fixed amount of annotation data than the traditional approach. We also show that the grounded slots surpass unsupervised slots in real-world object discovery and scale with scene complexity. Finally, we investigate the downstream efficacy of the grounded slots. Vision Transformers trained on grounding-aware NSI tokenizers using as few as ten tokens outperform patch-based tokens on challenging few-shot classification tasks.","authors":["Bhishma Dedhia","Niraj K. Jha"],"url":"https://arxiv.org/abs/2403.07887"}
{"created":"2025-05-12","title":"Diffusion-Reinforcement Learning Hierarchical Motion Planning in Multi-agent Adversarial Games","abstract":"Reinforcement Learning (RL)-based motion planning has recently shown the potential to outperform traditional approaches from autonomous navigation to robot manipulation. In this work, we focus on a motion planning task for an evasive target in a partially observable multi-agent adversarial pursuit-evasion game (PEG). Pursuit-evasion problems are relevant to various applications, such as search and rescue operations and surveillance robots, where robots must effectively plan their actions to gather intelligence or accomplish mission tasks while avoiding detection or capture. We propose a hierarchical architecture that integrates a high-level diffusion model to plan global paths responsive to environment data, while a low-level RL policy reasons about evasive versus global path-following behavior. The benchmark results across different domains and different observability show that our approach outperforms baselines by 77.18% and 47.38% on detection and goal reaching rate, which leads to 51.4% increasing of the performance score on average. Additionally, our method improves interpretability, flexibility and efficiency of the learned policy.","authors":["Zixuan Wu","Sean Ye","Manisha Natarajan","Matthew C. Gombolay"],"url":"https://arxiv.org/abs/2403.10794"}
{"created":"2025-05-12","title":"CoverUp: Effective High Coverage Test Generation for Python","abstract":"Testing is an essential part of software development. Test generation tools attempt to automate the otherwise labor-intensive task of test creation, but generating high-coverage tests remains challenging. This paper proposes CoverUp, a novel approach to driving the generation of high-coverage Python regression tests. CoverUp combines coverage analysis, code context, and feedback in prompts that iteratively guide the LLM to generate tests that improve line and branch coverage. We evaluate our prototype CoverUp implementation across a benchmark of challenging code derived from open-source Python projects and show that CoverUp substantially improves on the state of the art. Compared to CodaMosa, a hybrid search/LLM-based test generator, CoverUp achieves a per-module median line+branch coverage of 80% (vs. 47%). Compared to MuTAP, a mutation- and LLM-based test generator, CoverUp achieves an overall line+branch coverage of 89% (vs. 77%). We also demonstrate that CoverUp's performance stems not only from the LLM used but from the combined effectiveness of its components.","authors":["Juan Altmayer Pizzorno","Emery D. Berger"],"url":"https://arxiv.org/abs/2403.16218"}
{"created":"2025-05-12","title":"Large Language Models Are Struggle to Cope with Unreasonability in Math Problems","abstract":"Recent research have demonstrated LLMs' impressive performance in math and reasoning. However, the capacity of LLMs to address math problems under unconventional conditions, such as internal inconsistencies and flawed assumptions, remains largely unexplored. In this paper, we propose a novel benchmark Unreasonable Math Problem (UMP) designed to assess LLMs' ability to recognize and respond to unreasonability in math problem. The benchmark consists of a carefully curated collection of unreasonable math questions across diverse types. Based on extensive experiments covering 19 LLMs, we observe that even state-of-the-art models such as GPT-4o achieve only limited performance of 0.6 in UMP, while reasoning models such as DeepSeek-R1 are prone to overthinking and unstable. We further explore strategies for improving the recognition of unreasonable inputs, shedding light on both the possibility and limitations of LLMs in this challenging setting.","authors":["Jingyuan Ma","Damai Dai","Zihang Yuan","Rui li","Weilin Luo","Bin Wang","Qun Liu","Lei Sha","Zhifang Sui"],"url":"https://arxiv.org/abs/2403.19346"}
{"created":"2025-05-12","title":"Exact Imposition of Safety Boundary Conditions in Neural Reachable Tubes","abstract":"Hamilton-Jacobi (HJ) reachability analysis is a widely adopted verification tool to provide safety and performance guarantees for autonomous systems. However, it involves solving a partial differential equation (PDE) to compute a safety value function, whose computational and memory complexity scales exponentially with the state dimension, making its direct application to large-scale systems intractable. To overcome these challenges, DeepReach, a recently proposed learning-based approach, approximates high-dimensional reachable tubes using neural networks (NNs). While shown to be effective, the accuracy of the learned solution decreases with system complexity. One of the reasons for this degradation is a soft imposition of safety constraints during the learning process, which corresponds to the boundary conditions of the PDE, resulting in inaccurate value functions. In this work, we propose ExactBC, a variant of DeepReach that imposes safety constraints exactly during the learning process by restructuring the overall value function as a weighted sum of the boundary condition and the NN output. Moreover, the proposed variant no longer needs a boundary loss term during the training process, thus eliminating the need to balance different loss terms. We demonstrate the efficacy of the proposed approach in significantly improving the accuracy of the learned value function for four challenging reachability tasks: a rimless wheel system with state resets, collision avoidance in a cluttered environment, autonomous rocket landing, and multi-aircraft collision avoidance.","authors":["Aditya Singh","Zeyuan Feng","Somil Bansal"],"url":"https://arxiv.org/abs/2404.00814"}
{"created":"2025-05-12","title":"How to build the best medical image segmentation algorithm using foundation models: a comprehensive empirical study with Segment Anything Model","abstract":"Automated segmentation is a fundamental medical image analysis task, which enjoys significant advances due to the advent of deep learning. While foundation models have been useful in natural language processing and some vision tasks for some time, the foundation model developed with image segmentation in mind - Segment Anything Model (SAM) - has been developed only recently and has shown similar promise. However, there are still no systematic analyses or \"best-practice\" guidelines for optimal fine-tuning of SAM for medical image segmentation. This work summarizes existing fine-tuning strategies with various backbone architectures, model components, and fine-tuning algorithms across 18 combinations, and evaluates them on 17 datasets covering all common radiology modalities. Our study reveals that (1) fine-tuning SAM leads to slightly better performance than previous segmentation methods, (2) fine-tuning strategies that use parameter-efficient learning in both the encoder and decoder are superior to other strategies, (3) network architecture has a small impact on final performance, (4) further training SAM with self-supervised learning can improve final model performance. We also demonstrate the ineffectiveness of some methods popular in the literature and further expand our experiments into few-shot and prompt-based settings. Lastly, we released our code and MRI-specific fine-tuned weights, which consistently obtained superior performance over the original SAM, at https://github.com/mazurowski-lab/finetune-SAM.","authors":["Hanxue Gu","Haoyu Dong","Jichen Yang","Maciej A. Mazurowski"],"url":"https://arxiv.org/abs/2404.09957"}
{"created":"2025-05-12","title":"Mixed Text Recognition with Efficient Parameter Fine-Tuning and Transformer","abstract":"With the rapid development of OCR technology, mixed-scene text recognition has become a key technical challenge. Although deep learning models have achieved significant results in specific scenarios, their generality and stability still need improvement, and the high demand for computing resources affects flexibility. To address these issues, this paper proposes DLoRA-TrOCR, a parameter-efficient hybrid text spotting method based on a pre-trained OCR Transformer. By embedding a weight-decomposed DoRA module in the image encoder and a LoRA module in the text decoder, this method can be efficiently fine-tuned on various downstream tasks. Our method requires no more than 0.7\\% trainable parameters, not only accelerating the training efficiency but also significantly improving the recognition accuracy and cross-dataset generalization performance of the OCR system in mixed text scenes. Experiments show that our proposed DLoRA-TrOCR outperforms other parameter-efficient fine-tuning methods in recognizing complex scenes with mixed handwritten, printed, and street text, achieving a CER of 4.02 on the IAM dataset, a F1 score of 94.29 on the SROIE dataset, and a WAR of 86.70 on the STR Benchmark, reaching state-of-the-art performance.","authors":["Da Chang","Yu Li"],"url":"https://arxiv.org/abs/2404.12734"}
{"created":"2025-05-12","title":"\"Set It Up!\": Functional Object Arrangement with Compositional Generative Models","abstract":"This paper studies the challenge of developing robots capable of understanding under-specified instructions for creating functional object arrangements, such as \"set up a dining table for two\"; previous arrangement approaches have focused on much more explicit instructions, such as \"put object A on the table.\" We introduce a framework, SetItUp, for learning to interpret under-specified instructions. SetItUp takes a small number of training examples and a human-crafted program sketch to uncover arrangement rules for specific scene types. By leveraging an intermediate graph-like representation of abstract spatial relationships among objects, SetItUp decomposes the arrangement problem into two subproblems: i) learning the arrangement patterns from limited data and ii) grounding these abstract relationships into object poses. SetItUp leverages large language models (LLMs) to propose the abstract spatial relationships among objects in novel scenes as the constraints to be satisfied; then, it composes a library of diffusion models associated with these abstract relationships to find object poses that satisfy the constraints. We validate our framework on a dataset comprising study desks, dining tables, and coffee tables, with the results showing superior performance in generating physically plausible, functional, and aesthetically pleasing object arrangements compared to existing models.","authors":["Yiqing Xu","Jiayuan Mao","Yilun Du","Tomas Loz\\'ano-P\\'erez","Leslie Pack Kaelbling","David Hsu"],"url":"https://arxiv.org/abs/2405.11928"}
{"created":"2025-05-12","title":"NeurCross: A Neural Approach to Computing Cross Fields for Quad Mesh Generation","abstract":"Quadrilateral mesh generation plays a crucial role in numerical simulations within Computer-Aided Design and Engineering (CAD/E). Producing high-quality quadrangulation typically requires satisfying four key criteria. First, the quadrilateral mesh should closely align with principal curvature directions. Second, singular points should be strategically placed and effectively minimized. Third, the mesh should accurately conform to sharp feature edges. Lastly, quadrangulation results should exhibit robustness against noise and minor geometric variations. Existing methods generally involve first computing a regular cross field to represent quad element orientations across the surface, followed by extracting a quadrilateral mesh aligned closely with this cross field. A primary challenge with this approach is balancing the smoothness of the cross field with its alignment to pre-computed principal curvature directions, which are sensitive to small surface perturbations and often ill-defined in spherical or planar regions.","authors":["Qiujie Dong","Huibiao Wen","Rui Xu","Shuangmin Chen","Jiaran Zhou","Shiqing Xin","Changhe Tu","Taku Komura","Wenping Wang"],"url":"https://arxiv.org/abs/2405.13745"}
{"created":"2025-05-12","title":"Adaptive Gradient Clipping for Robust Federated Learning","abstract":"Robust federated learning aims to maintain reliable performance despite the presence of adversarial or misbehaving workers. While state-of-the-art (SOTA) robust distributed gradient descent (Robust-DGD) methods were proven theoretically optimal, their empirical success has often relied on pre-aggregation gradient clipping. However, existing static clipping strategies yield inconsistent results: enhancing robustness against some attacks while being ineffective or even detrimental against others. To address this limitation, we propose a principled adaptive clipping strategy, Adaptive Robust Clipping (ARC), which dynamically adjusts clipping thresholds based on the input gradients. We prove that ARC not only preserves the theoretical robustness guarantees of SOTA Robust-DGD methods but also provably improves asymptotic convergence when the model is well-initialized. Extensive experiments on benchmark image classification tasks confirm these theoretical insights, demonstrating that ARC significantly enhances robustness, particularly in highly heterogeneous and adversarial settings.","authors":["Youssef Allouah","Rachid Guerraoui","Nirupam Gupta","Ahmed Jellouli","Geovani Rizk","John Stephan"],"url":"https://arxiv.org/abs/2405.14432"}
{"created":"2025-05-12","title":"Credal Wrapper of Model Averaging for Uncertainty Estimation in Classification","abstract":"This paper presents an innovative approach, called credal wrapper, to formulating a credal set representation of model averaging for Bayesian neural networks (BNNs) and deep ensembles (DEs), capable of improving uncertainty estimation in classification tasks. Given a finite collection of single predictive distributions derived from BNNs or DEs, the proposed credal wrapper approach extracts an upper and a lower probability bound per class, acknowledging the epistemic uncertainty due to the availability of a limited amount of distributions. Such probability intervals over classes can be mapped on a convex set of probabilities (a credal set) from which, in turn, a unique prediction can be obtained using a transformation called intersection probability transformation. In this article, we conduct extensive experiments on several out-of-distribution (OOD) detection benchmarks, encompassing various dataset pairs (CIFAR10/100 vs SVHN/Tiny-ImageNet, CIFAR10 vs CIFAR10-C, CIFAR100 vs CIFAR100-C and ImageNet vs ImageNet-O) and using different network architectures (such as VGG16, ResNet-18/50, EfficientNet B2, and ViT Base). Compared to the BNN and DE baselines, the proposed credal wrapper method exhibits superior performance in uncertainty estimation and achieves a lower expected calibration error on corrupted data.","authors":["Kaizheng Wang","Fabio Cuzzolin","Keivan Shariatmadar","David Moens","Hans Hallez"],"url":"https://arxiv.org/abs/2405.15047"}
{"created":"2025-05-12","title":"Pretraining with Random Noise for Fast and Robust Learning without Weight Transport","abstract":"The brain prepares for learning even before interacting with the environment, by refining and optimizing its structures through spontaneous neural activity that resembles random noise. However, the mechanism of such a process has yet to be thoroughly understood, and it is unclear whether this process can benefit the algorithm of machine learning. Here, we study this issue using a neural network with a feedback alignment algorithm, demonstrating that pretraining neural networks with random noise increases the learning efficiency as well as generalization abilities without weight transport. First, we found that random noise training modifies forward weights to match backward synaptic feedback, which is necessary for teaching errors by feedback alignment. As a result, a network with pre-aligned weights learns notably faster than a network without random noise training, even reaching a convergence speed comparable to that of a backpropagation algorithm. Sequential training with both random noise and data brings weights closer to synaptic feedback than training solely with data, enabling more precise credit assignment and faster learning. We also found that each readout probability approaches the chance level and that the effective dimensionality of weights decreases in a network pretrained with random noise. This pre-regularization allows the network to learn simple solutions of a low rank, reducing the generalization loss during subsequent training. This also enables the network robustly to generalize a novel, out-of-distribution dataset. Lastly, we confirmed that random noise pretraining reduces the amount of meta-loss, enhancing the network ability to adapt to various tasks. Overall, our results suggest that random noise training with feedback alignment offers a straightforward yet effective method of pretraining that facilitates quick and reliable learning without weight transport.","authors":["Jeonghwan Cheon","Sang Wan Lee","Se-Bum Paik"],"url":"https://arxiv.org/abs/2405.16731"}
{"created":"2025-05-12","title":"Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles","abstract":"For solving zero-sum games involving non-transitivity, a useful approach is to maintain a policy population to approximate the Nash Equilibrium (NE). Previous studies have shown that the Policy Space Response Oracles (PSRO) algorithm is an effective framework for solving such games. However, current methods initialize a new policy from scratch or inherit a single historical policy in Best Response (BR), missing the opportunity to leverage past policies to generate a better BR. In this paper, we propose Fusion-PSRO, which employs Nash Policy Fusion to initialize a new policy for BR training. Nash Policy Fusion serves as an implicit guiding policy that starts exploration on the current Meta-NE, thus providing a closer approximation to BR. Moreover, it insightfully captures a weighted moving average of past policies, dynamically adjusting these weights based on the Meta-NE in each iteration. This cumulative process further enhances the policy population. Empirical results on classic benchmarks show that Fusion-PSRO achieves lower exploitability, thereby mitigating the shortcomings of previous research on policy initialization in BR.","authors":["Jiesong Lian","Yucong Huang","Chengdong Ma","Mingzhi Wang","Ying Wen","Long Hu","Yixue Hao"],"url":"https://arxiv.org/abs/2405.21027"}
{"created":"2025-05-12","title":"An extension of C++ with memory-centric specifications for HPC to reduce memory footprints and streamline MPI development","abstract":"The C++ programming language and its cousins lean towards a memory-inefficient storage of structs: The compiler inserts helper bits such that individual instance variables fit to byte or cache boundaries, while it is not able to exploit knowledge about the range of integers, enums or bitsets. Furthermore, the language provides neither support for data exchange via MPI nor for arbitrary floating-point precisions. We propose C++ attributes through which developers can guide the compiler what memory arrangements would be beneficial: Can multiple booleans or integers with limited range be squeezed into one bit field, do floating point numbers hold fewer significant bits than in the IEEE standard, or does the code benefit from a MPI datatype for subsets of attributes? The extension offers the opportunity to fall back to normal alignment via plain C++ assignments, no dependencies upon external libraries are introduced, and the resulting code remains standard C++ subject to some weakened guarantees on addresses and pointer arithmetics. Our work implements the language annotations within LLVM and demonstrates their potential impact, both upon the runtime and the memory footprint, through smoothed particle hydrodynamics (SPH) benchmarks. They uncover the potential gains in terms of performance and development productivity.","authors":["Pawel K. Radtke","Cristian G. Barrera-Hinojosa","Mladen Ivkovic","Tobias Weinzierl"],"url":"https://arxiv.org/abs/2406.06095"}
{"created":"2025-05-12","title":"Talking Heads: Understanding Inter-layer Communication in Transformer Language Models","abstract":"Although it is known that transformer language models (LMs) pass features from early layers to later layers, it is not well understood how this information is represented and routed by the model. We analyze a mechanism used in two LMs to selectively inhibit items in a context in one task, and find that it underlies a commonly used abstraction across many context-retrieval behaviors. Specifically, we find that models write into low-rank subspaces of the residual stream to represent features which are then read out by later layers, forming low-rank communication channels (Elhage et al., 2021) between layers. A particular 3D subspace in model activations in GPT-2 can be traversed to positionally index items in lists, and we show that this mechanism can explain an otherwise arbitrary-seeming sensitivity of the model to the order of items in the prompt. That is, the model has trouble copying the correct information from context when many items ``crowd\" this limited space. By decomposing attention heads with the Singular Value Decomposition (SVD), we find that previously described interactions between heads separated by one or more layers can be predicted via analysis of their weight matrices alone. We show that it is possible to manipulate the internal model representations as well as edit model weights based on the mechanism we discover in order to significantly improve performance on our synthetic Laundry List task, which requires recall from a list, often improving task accuracy by over 20%. Our analysis reveals a surprisingly intricate interpretable structure learned from language model pretraining, and helps us understand why sophisticated LMs sometimes fail in simple domains, facilitating future analysis of more complex behaviors.","authors":["Jack Merullo","Carsten Eickhoff","Ellie Pavlick"],"url":"https://arxiv.org/abs/2406.09519"}
{"created":"2025-05-12","title":"Recent Advances in Federated Learning Driven Large Language Models: A Survey on Architecture, Performance, and Security","abstract":"Federated Learning (FL) offers a promising paradigm for training Large Language Models (LLMs) in a decentralized manner while preserving data privacy and minimizing communication overhead. This survey examines recent advancements in FL-driven LLMs, with a particular emphasis on architectural designs, performance optimization, and security concerns, including the emerging area of machine unlearning. In this context, machine unlearning refers to the systematic removal of specific data contributions from trained models to comply with privacy regulations such as the Right to be Forgotten. We review a range of strategies enabling unlearning in federated LLMs, including perturbation-based methods, model decomposition, and incremental retraining, while evaluating their trade-offs in terms of efficiency, privacy guarantees, and model utility. Through selected case studies and empirical evaluations, we analyze how these methods perform in practical FL scenarios. This survey identifies critical research directions toward developing secure, adaptable, and high-performing federated LLM systems for real-world deployment.","authors":["Youyang Qu","Ming Liu","Tianqing Zhu","Longxiang Gao","Shui Yu","Wanlei Zhou"],"url":"https://arxiv.org/abs/2406.09831"}
{"created":"2025-05-12","title":"Embedded Hierarchical MPC for Autonomous Navigation","abstract":"To efficiently deploy robotic systems in society, mobile robots must move autonomously and safely through complex environments. Nonlinear model predictive control (MPC) methods provide a natural way to find a dynamically feasible trajectory through the environment without colliding with nearby obstacles. However, the limited computation power available on typical embedded robotic systems, such as quadrotors, poses a challenge to running MPC in real time, including its most expensive tasks: constraints generation and optimization. To address this problem, we propose a novel hierarchical MPC scheme that consists of a planning and a tracking layer. The planner constructs a trajectory with a long prediction horizon at a slow rate, while the tracker ensures trajectory tracking at a relatively fast rate. We prove that the proposed framework avoids collisions and is recursively feasible. Furthermore, we demonstrate its effectiveness in simulations and lab experiments with a quadrotor that needs to reach a goal position in a complex static environment. The code is efficiently implemented on the quadrotor's embedded computer to ensure real-time feasibility. Compared to a state-of-the-art single-layer MPC formulation, this allows us to increase the planning horizon by a factor of 5, which results in significantly better performance.","authors":["Dennis Benders","Johannes K\\\"ohler","Thijs Niesten","Robert Babu\\v{s}ka","Javier Alonso-Mora","Laura Ferranti"],"url":"https://arxiv.org/abs/2406.11506"}
{"created":"2025-05-12","title":"Tuning a Cascaded Online Feedback Optimization Controller for Provision of Distributed Flexibility","abstract":"Coordinating a high number of flexibility providing units (e.g. to provide ancillary services for the transmission system) across various grid layers requires new control concepts. A flexibility request at a point of common coupling can be met by utilizing a cascaded control structure based on online feedback optimization. In this paper the influence of the parameterization of the individual controllers on the performance of the hierarchical flexibility provision is studied on a three-level test system. The results show a high interdependency between the choice of control parameters of one controller and the behavior of other controllers as well as a significant impact on the accuracy and speed of flexibility provision. With a careful tuning, a cascaded structure based on online feedback optimization can achieve efficient vertical coordination of flexibility providing units.","authors":["Irina Zettl","Florian Klein-Helmkamp","Florian Schmidtke","Lukas Ortmann","Andreas Ulbig"],"url":"https://arxiv.org/abs/2406.16704"}
{"created":"2025-05-12","title":"CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation","abstract":"While recent advances in text-to-motion generation have shown promising results, they typically assume all individuals are grouped as a single unit. Scaling these methods to handle larger crowds and ensuring that individuals respond appropriately to specific events remains a significant challenge. This is primarily due to the complexities of scene planning, which involves organizing groups, planning their activities, and coordinating interactions, and controllable motion generation. In this paper, we present CrowdMoGen, the first zero-shot framework for collective motion generation, which effectively groups individuals and generates event-aligned motion sequences from text prompts. 1) Being limited by the available datasets for training an effective scene planning module in a supervised manner, we instead propose a crowd scene planner that leverages pre-trained large language models (LLMs) to organize individuals into distinct groups. While LLMs offer high-level guidance for group divisions, they lack the low-level understanding of human motion. To address this, we further propose integrating an SMPL-based joint prior to generate context-appropriate activities, which consists of both joint trajectories and textual descriptions. 2) Secondly, to incorporate the assigned activities into the generative network, we introduce a collective motion generator that integrates the activities into a transformer-based network in a joint-wise manner, maintaining the spatial constraints during the multi-step denoising process. Extensive experiments demonstrate that CrowdMoGen significantly outperforms previous approaches, delivering realistic, event-driven motion sequences that are spatially coherent. As the first framework of collective motion generation, CrowdMoGen has the potential to advance applications in urban simulation, crowd planning, and other large-scale interactive environments.","authors":["Yukang Cao","Xinying Guo","Mingyuan Zhang","Haozhe Xie","Chenyang Gu","Ziwei Liu"],"url":"https://arxiv.org/abs/2407.06188"}
{"created":"2025-05-12","title":"Representation Learning and Identity Adversarial Training for Facial Behavior Understanding","abstract":"Facial Action Unit (AU) detection has gained significant attention as it enables the breakdown of complex facial expressions into individual muscle movements. In this paper, we revisit two fundamental factors in AU detection: diverse and large-scale data and subject identity regularization. Motivated by recent advances in foundation models, we highlight the importance of data and introduce Face9M, a diverse dataset comprising 9 million facial images from multiple public sources. Pretraining a masked autoencoder on Face9M yields strong performance in AU detection and facial expression tasks. More importantly, we emphasize that the Identity Adversarial Training (IAT) has not been well explored in AU tasks. To fill this gap, we first show that subject identity in AU datasets creates shortcut learning for the model and leads to sub-optimal solutions to AU predictions. Secondly, we demonstrate that strong IAT regularization is necessary to learn identity-invariant features. Finally, we elucidate the design space of IAT and empirically show that IAT circumvents the identity-based shortcut learning and results in a better solution. Our proposed methods, Facial Masked Autoencoder (FMAE) and IAT, are simple, generic and effective. Remarkably, the proposed FMAE-IAT approach achieves new state-of-the-art F1 scores on BP4D (67.1\\%), BP4D+ (66.8\\%), and DISFA (70.1\\%) databases, significantly outperforming previous work. We release the code and model at https://github.com/forever208/FMAE-IAT.","authors":["Mang Ning","Albert Ali Salah","Itir Onal Ertugrul"],"url":"https://arxiv.org/abs/2407.11243"}
{"created":"2025-05-12","title":"NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context?","abstract":"The capability of large language models to handle long-context information is crucial across various real-world applications. Existing evaluation methods often rely either on real-world long texts, making it difficult to exclude the influence of models' inherent knowledge, or introduce irrelevant filler content to artificially achieve target lengths, reducing assessment effectiveness. To address these limitations, we introduce NeedleBench, a synthetic framework for assessing retrieval and reasoning performance in bilingual long-context tasks with adaptive context lengths. NeedleBench systematically embeds key data points at varying depths to rigorously test model capabilities. Tasks are categorized into two scenarios: information-sparse, featuring minimal relevant details within extensive irrelevant text to simulate simple retrieval tasks; and information-dense (the Ancestral Trace Challenge), where relevant information is continuously distributed throughout the context to simulate complex reasoning tasks. Our experiments reveal that although recent reasoning models like Deepseek-R1 and OpenAI's o3 excel in mathematical reasoning, they struggle with continuous retrieval and reasoning in information-dense scenarios, even at shorter context lengths. We also characterize a phenomenon termed 'under-thinking', where models prematurely conclude reasoning despite available information. NeedleBench thus provides critical insights and targeted tools essential for evaluating and improving LLMs' long-context capabilities. All resources are available at OpenCompass: https://github.com/open-compass/opencompass.","authors":["Mo Li","Songyang Zhang","Taolin Zhang","Haodong Duan","Yunxin Liu","Kai Chen"],"url":"https://arxiv.org/abs/2407.11963"}
{"created":"2025-05-12","title":"TAPTRv2: Attention-based Position Update Improves Tracking Any Point","abstract":"In this paper, we present TAPTRv2, a Transformer-based approach built upon TAPTR for solving the Tracking Any Point (TAP) task. TAPTR borrows designs from DEtection TRansformer (DETR) and formulates each tracking point as a point query, making it possible to leverage well-studied operations in DETR-like algorithms. TAPTRv2 improves TAPTR by addressing a critical issue regarding its reliance on cost-volume,which contaminates the point query\\'s content feature and negatively impacts both visibility prediction and cost-volume computation. In TAPTRv2, we propose a novel attention-based position update (APU) operation and use key-aware deformable attention to realize. For each query, this operation uses key-aware attention weights to combine their corresponding deformable sampling positions to predict a new query position. This design is based on the observation that local attention is essentially the same as cost-volume, both of which are computed by dot-production between a query and its surrounding features. By introducing this new operation, TAPTRv2 not only removes the extra burden of cost-volume computation, but also leads to a substantial performance improvement. TAPTRv2 surpasses TAPTR and achieves state-of-the-art performance on many challenging datasets, demonstrating the superiority","authors":["Hongyang Li","Hao Zhang","Shilong Liu","Zhaoyang Zeng","Feng Li","Tianhe Ren","Bohan Li","Lei Zhang"],"url":"https://arxiv.org/abs/2407.16291"}
{"created":"2025-05-12","title":"ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget","abstract":"Entity Linking (EL) and Relation Extraction (RE) are fundamental tasks in Natural Language Processing, serving as critical components in a wide range of applications. In this paper, we propose ReLiK, a Retriever-Reader architecture for both EL and RE, where, given an input text, the Retriever module undertakes the identification of candidate entities or relations that could potentially appear within the text. Subsequently, the Reader module is tasked to discern the pertinent retrieved entities or relations and establish their alignment with the corresponding textual spans. Notably, we put forward an innovative input representation that incorporates the candidate entities or relations alongside the text, making it possible to link entities or extract relations in a single forward pass and to fully leverage pre-trained language models contextualization capabilities, in contrast with previous Retriever-Reader-based methods, which require a forward pass for each candidate. Our formulation of EL and RE achieves state-of-the-art performance in both in-domain and out-of-domain benchmarks while using academic budget training and with up to 40x inference speed compared to competitors. Finally, we show how our architecture can be used seamlessly for Information Extraction (cIE), i.e. EL + RE, and setting a new state of the art by employing a shared Reader that simultaneously extracts entities and relations.","authors":["Riccardo Orlando","Pere-Lluis Huguet Cabot","Edoardo Barba","Roberto Navigli"],"url":"https://arxiv.org/abs/2408.00103"}
{"created":"2025-05-12","title":"Toward a Better Understanding of Probabilistic Delta Debugging","abstract":"Given a list L of elements and a property that L exhibits, ddmin is a well-known test input minimization algorithm designed to automatically eliminate irrelevant elements from L. This algorithm is extensively adopted in test input minimization and software debloating. Recently, ProbDD, an advanced variant of ddmin, has been proposed and achieved state-of-the-art performance. Employing Bayesian optimization, ProbDD predicts the likelihood of each element in L being essential, and statistically decides which elements and how many should be removed each time. Despite its impressive results, the theoretical probabilistic model of ProbDD is complex, and the specific factors driving its superior performance have not been investigated. In this paper, we conduct the first in-depth theoretical analysis of ProbDD, clarifying trends in probability and subset size changes while simplifying the probability model. Complementing this analysis, we perform empirical experiments, including success rate analysis, ablation studies, and analysis on trade-offs and limitations, to better understand and demystify this state-of-the-art algorithm. Our success rate analysis shows how ProbDD addresses bottlenecks of ddmin by skipping inefficient queries that attempt to delete complements of subsets and previously tried subsets. The ablation study reveals that randomness in ProbDD has no significant impact on efficiency. Based on these findings, we propose CDD, a simplified version of ProbDD, reducing complexity in both theory and implementation. Besides, the performance of CDD validates our key findings. Comprehensive evaluations across 76 benchmarks in test input minimization and software debloating show that CDD can achieve the same performance as ProbDD despite its simplification. These insights provide valuable guidance for future research and applications of test input minimization algorithms.","authors":["Mengxiao Zhang","Zhenyang Xu","Yongqiang Tian","Xinru Cheng","Chengnian Sun"],"url":"https://arxiv.org/abs/2408.04735"}
{"created":"2025-05-12","title":"Galled Perfect Transfer Networks","abstract":"Predicting horizontal gene transfers often requires comparative sequence data, but recent work has shown that character-based approaches could also be useful for this task. Notably, perfect transfer networks (PTN) explain the character diversity of a set of taxa for traits that are gained once, rarely lost, but that can be transferred laterally. Characterizing the structure of such characters is an important step towards understanding more complex characters. Although efficient algorithms can infer such networks from character data, they can sometimes predict overly complicated transfer histories. With the goal of recovering the simplest possible scenarios in this model, we introduce galled perfect transfer networks, which are PTNs that are galled trees. Such networks are useful for characters that are incompatible in terms of tree-like evolution, but that do fit in an almost-tree scenario. We provide polynomial-time algorithms for two problems: deciding whether one can add transfer edges to a tree to transform it into a galled PTN, and deciding whether a set of characters are galled-compatible, that is, they can be explained by some galled PTN. We also analyze a real dataset comprising of a bacterial species trees and KEGG functions as characters, and derive several conclusions on the difficulty of explaining characters in a galled tree, which provide several directions for future research.","authors":["Alitzel L\\'opez S\\'anchez","Manuel Lafond"],"url":"https://arxiv.org/abs/2409.03935"}
{"created":"2025-05-12","title":"Directed-CP: Directed Collaborative Perception for Connected and Autonomous Vehicles via Proactive Attention","abstract":"Collaborative perception (CP) leverages visual data from connected and autonomous vehicles (CAV) to enhance an ego vehicle's field of view (FoV). Despite recent progress, current CP methods expand the ego vehicle's 360-degree perceptual range almost equally, which faces two key challenges. Firstly, in areas with uneven traffic distribution, focusing on directions with little traffic offers limited benefits. Secondly, under limited communication budgets, allocating excessive bandwidth to less critical directions lowers the perception accuracy in more vital areas. To address these issues, we propose Direct-CP, a proactive and direction-aware CP system aiming at improving CP in specific directions. Our key idea is to enable an ego vehicle to proactively signal its interested directions and readjust its attention to enhance local directional CP performance. To achieve this, we first propose an RSU-aided direction masking mechanism that assists an ego vehicle in identifying vital directions. Additionally, we design a direction-aware selective attention module to wisely aggregate pertinent features based on ego vehicle's directional priorities, communication budget, and the positional data of CAVs. Moreover, we introduce a direction-weighted detection loss (DWLoss) to capture the divergence between directional CP outcomes and the ground truth, facilitating effective model training. Extensive experiments on the V2X-Sim 2.0 dataset demonstrate that our approach achieves 19.8\\% higher local perception accuracy in interested directions and 2.5\\% higher overall perception accuracy than the state-of-the-art methods in collaborative 3D object detection tasks.","authors":["Yihang Tao","Senkang Hu","Zhengru Fang","Yuguang Fang"],"url":"https://arxiv.org/abs/2409.08840"}
{"created":"2025-05-12","title":"A Learning Framework for Diverse Legged Robot Locomotion Using Barrier-Based Style Rewards","abstract":"This work introduces a model-free reinforcement learning framework that enables various modes of motion (quadruped, tripod, or biped) and diverse tasks for legged robot locomotion. We employ a motion-style reward based on a relaxed logarithmic barrier function as a soft constraint, to bias the learning process toward the desired motion style, such as gait, foot clearance, joint position, or body height. The predefined gait cycle is encoded in a flexible manner, facilitating gait adjustments throughout the learning process. Extensive experiments demonstrate that KAIST HOUND, a 45 kg robotic system, can achieve biped, tripod, and quadruped locomotion using the proposed framework; quadrupedal capabilities include traversing uneven terrain, galloping at 4.67 m/s, and overcoming obstacles up to 58 cm (67 cm for HOUND2); bipedal capabilities include running at 3.6 m/s, carrying a 7.5 kg object, and ascending stairs-all performed without exteroceptive input.","authors":["Gijeong Kim","Yong-Hoon Lee","Hae-Won Park"],"url":"https://arxiv.org/abs/2409.15780"}
{"created":"2025-05-12","title":"Medha: Efficiently Serving Multi-Million Context Length LLM Inference Requests Without Approximations","abstract":"As large language models (LLMs) handle increasingly longer contexts, serving long inference requests of millions of tokens presents unique challenges. We show that existing work for long context inference is largely based on techniques from long context training, and does not handle the high variability in input lengths during inference. This leads to inefficient resource utilization, server fragmentation, and head-of-line (HOL) blocking.","authors":["Amey Agrawal","Haoran Qiu","Junda Chen","\\'I\\~nigo Goiri","Chaojie Zhang","Rayyan Shahid","Ramachandran Ramjee","Alexey Tumanov","Esha Choukse"],"url":"https://arxiv.org/abs/2409.17264"}
{"created":"2025-05-12","title":"Learning Wheelchair Tennis Navigation from Broadcast Videos with Domain Knowledge Transfer and Diffusion Motion Planning","abstract":"In this paper, we propose a novel and generalizable zero-shot knowledge transfer framework that distills expert sports navigation strategies from web videos into robotic systems with adversarial constraints and out-of-distribution image trajectories. Our pipeline enables diffusion-based imitation learning by reconstructing the full 3D task space from multiple partial views, warping it into 2D image space, closing the planning loop within this 2D space, and transfer constrained motion of interest back to task space. Additionally, we demonstrate that the learned policy can serve as a local planner in conjunction with position control. We apply this framework in the wheelchair tennis navigation problem to guide the wheelchair into the ball-hitting region. Our pipeline achieves a navigation success rate of 97.67% in reaching real-world recorded tennis ball trajectories with a physical robot wheelchair, and achieve a success rate of 68.49% in a real-world, real-time experiment on a full-sized tennis court.","authors":["Zixuan Wu","Zulfiqar Zaidi","Adithya Patil","Qingyu Xiao","Matthew Gombolay"],"url":"https://arxiv.org/abs/2409.19771"}
{"created":"2025-05-12","title":"Enhancing Screen Time Identification in Children with a Multi-View Vision Language Model and Screen Time Tracker","abstract":"Being able to accurately monitor the screen exposure of young children is important for research on phenomena linked to screen use such as childhood obesity, physical activity, and social interaction. Most existing studies rely upon self-report or manual measures from bulky wearable sensors, thus lacking efficiency and accuracy in capturing quantitative screen exposure data. In this work, we developed a novel sensor informatics framework that utilizes egocentric images from a wearable sensor, termed the screen time tracker (STT), and a vision language model (VLM). In particular, we devised a multi-view VLM that takes multiple views from egocentric image sequences and interprets screen exposure dynamically. We validated our approach by using a dataset of children's free-living activities, demonstrating significant improvement over existing methods in plain vision language models and object detection models. Results supported the promise of this monitoring approach, which could optimize behavioral research on screen exposure in children's naturalistic settings.","authors":["Xinlong Hou","Sen Shen","Xueshen Li","Xinran Gao","Ziyi Huang","Steven J. Holiday","Matthew R. Cribbet","Susan W. White","Edward Sazonov","Yu Gan"],"url":"https://arxiv.org/abs/2410.01966"}
{"created":"2025-05-12","title":"GreenLight-Gym: Reinforcement learning benchmark environment for control of greenhouse production systems","abstract":"This study presents GreenLight-Gym, a new, fast, open-source benchmark environment for developing reinforcement learning (RL) methods in greenhouse crop production control. Built on the state-of-the-art GreenLight model, it features a differentiable C++ implementation leveraging the CasADi framework for efficient numerical integration. GreenLight-Gym improves simulation speed by a factor of 17 over the original GreenLight implementation. A modular Python environment wrapper enables flexible configuration of control tasks and RL-based controllers. This flexibility is demonstrated by learning controllers under parametric uncertainty using two well-known RL algorithms. GreenLight-Gym provides a standardized benchmark for advancing RL methodologies and evaluating greenhouse control solutions under diverse conditions. The greenhouse control community is encouraged to use and extend this benchmark to accelerate innovation in greenhouse crop production.","authors":["Bart van Laatum","Eldert J. van Henten","Sjoerd Boersma"],"url":"https://arxiv.org/abs/2410.05336"}
{"created":"2025-05-12","title":"Opacity Enforcement by Edit Functions Under Incomparable Observations","abstract":"As an information-flow privacy property, opacity characterizes whether a malicious external observer (referred to as an intruder) is able to infer the secret behavior of a system. This paper addresses the problem of opacity enforcement using edit functions in discrete event systems modeled by partially observed deterministic finite automata. A defender uses the edit function as an interface at the output of a system to manipulate actual observations through insertion, substitution, and deletion operations so that the intruder will be prevented from inferring the secret behavior of the system. Unlike existing work which usually assumes that the observation capabilities of the intruder and the defender are identical, we consider a more general setting where they may observe incomparable subsets of events generated by the system.To characterize whether the defender has the ability to enforce opacity of the system under this setting, the notion of \\emph{$ic$-enforceability} is introduced. Then, the opacity enforcement problem is transformed to a two-player game, with imperfect information between the system and the defender, which can be used to determine a feasible decision-making strategy for the defender. Within the game scheme, an edit mechanism is constructed to enumerate all feasible edit actions following system behavior. We further show that an $ic$-enforcing edit function (if one exists) can be synthesized from the edit mechanism to enforce opacity.","authors":["Wei Duan","Ruotian Liu","Maria Pia Fanti","Christoforos N. Hadjicostis","Zhiwu Li"],"url":"https://arxiv.org/abs/2410.08471"}
{"created":"2025-05-12","title":"Distillation of Discrete Diffusion through Dimensional Correlations","abstract":"Diffusion models have demonstrated exceptional performances in various fields of generative modeling, but suffer from slow sampling speed due to their iterative nature. While this issue is being addressed in continuous domains, discrete diffusion models face unique challenges, particularly in capturing dependencies between elements (e.g., pixel relationships in image, sequential dependencies in language) mainly due to the computational cost of processing high-dimensional joint distributions. In this paper, (i) we propose \"mixture\" models for discrete diffusion that are capable of treating dimensional correlations while remaining scalable, and (ii) we provide a set of loss functions for distilling the iterations of existing models. Two primary theoretical insights underpin our approach: First, conventional models with element-wise independence can well approximate the data distribution, but essentially require {\\it many sampling steps}. Second, our loss functions enable the mixture models to distill such many-step conventional models into just a few steps by learning the dimensional correlations. Our experimental results show the effectiveness of the proposed method in distilling pretrained discrete diffusion models across image and language domains. The code used in the paper is available at https://github.com/sony/di4c .","authors":["Satoshi Hayakawa","Yuhta Takida","Masaaki Imaizumi","Hiromi Wakaki","Yuki Mitsufuji"],"url":"https://arxiv.org/abs/2410.08709"}
{"created":"2025-05-12","title":"Learning Algorithms Made Simple","abstract":"In this paper, we discuss learning algorithms and their importance in different types of applications which includes training to identify important patterns and features in a straightforward, easy-to-understand manner. We will review the main concepts of artificial intelligence (AI), machine learning (ML), deep learning (DL), and hybrid models. Some important subsets of Machine Learning algorithms such as supervised, unsupervised, and reinforcement learning are also discussed in this paper. These techniques can be used for some important tasks like prediction, classification, and segmentation. Convolutional Neural Networks (CNNs) are used for image and video processing and many more applications. We dive into the architecture of CNNs and how to integrate CNNs with ML algorithms to build hybrid models. This paper explores the vulnerability of learning algorithms to noise, leading to misclassification. We further discuss the integration of learning algorithms with Large Language Models (LLM) to generate coherent responses applicable to many domains such as healthcare, marketing, and finance by learning important patterns from large volumes of data. Furthermore, we discuss the next generation of learning algorithms and how we may have an unified Adaptive and Dynamic Network to perform important tasks. Overall, this article provides brief overview of learning algorithms, exploring their current state, applications and future direction.","authors":["Noorbakhsh Amiri Golilarz","Elias Hossain","Abdoljalil Addeh","Keyan Alexander Rahimi"],"url":"https://arxiv.org/abs/2410.09186"}
{"created":"2025-05-12","title":"Shavette: Low Power Neural Network Acceleration via Algorithm-level Error Detection and Undervolting","abstract":"Reduced voltage operation is an effective technique for substantial energy efficiency improvement in digital circuits. This brief introduces a simple approach for enabling reduced voltage operation of Deep Neural Network (DNN) accelerators by mere software modifications. Conventional approaches for enabling reduced voltage operation e.g., Timing Error Detection (TED) systems, incur significant development costs and overheads, while not being applicable to the off-the-shelf components. Contrary to those, the solution proposed in this paper relies on algorithm-based error detection, and hence, is implemented with low development costs, does not require any circuit modifications, and is even applicable to commodity devices. By showcasing the solution through experimenting on popular DNNs, i.e., LeNet and VGG16, on a GPU platform, we demonstrate 18% to 25% energy saving with no accuracy loss of the models and negligible throughput compromise (< 3.9%), considering the overheads from integration of the error detection schemes into the DNN. The integration of presented algorithmic solution into the design is simpler when compared conventional TED based techniques that require extensive circuit-level modifications, cell library characterizations or special support from the design tools.","authors":["Mikael Rinkinen","Lauri Koskinen","Olli Silven","Mehdi Safarpour"],"url":"https://arxiv.org/abs/2410.13415"}
{"created":"2025-05-12","title":"LEGO-Learn: Label-Efficient Graph Open-Set Learning","abstract":"How can we train graph-based models to recognize unseen classes while keeping labeling costs low? Graph open-set learning (GOL) and out-of-distribution (OOD) detection aim to address this challenge by training models that can accurately classify known, in-distribution (ID) classes while identifying and handling previously unseen classes during inference. It is critical for high-stakes, real-world applications where models frequently encounter unexpected data, including finance, security, and healthcare. However, current GOL methods assume access to many labeled ID samples, which is unrealistic for large-scale graphs due to high annotation costs. In this paper, we propose LEGO-Learn (Label-Efficient Graph Open-set Learning), a novel framework that tackles open-set node classification on graphs within a given label budget by selecting the most informative ID nodes. LEGO-Learn employs a GNN-based filter to identify and exclude potential OOD nodes and then select highly informative ID nodes for labeling using the K-Medoids algorithm. To prevent the filter from discarding valuable ID examples, we introduce a classifier that differentiates between the C known ID classes and an additional class representing OOD nodes (hence, a C+1 classifier). This classifier uses a weighted cross-entropy loss to balance the removal of OOD nodes while retaining informative ID nodes. Experimental results on four real-world datasets demonstrate that LEGO-Learn significantly outperforms leading methods, with up to a 6.62% improvement in ID classification accuracy and a 7.49% increase in AUROC for OOD detection.","authors":["Haoyan Xu","Kay Liu","Zhengtao Yao","Philip S. Yu","Mengyuan Li","Kaize Ding","Yue Zhao"],"url":"https://arxiv.org/abs/2410.16386"}
{"created":"2025-05-12","title":"Prioritized Generative Replay","abstract":"Sample-efficient online reinforcement learning often uses replay buffers to store experience for reuse when updating the value function. However, uniform replay is inefficient, since certain classes of transitions can be more relevant to learning. While prioritization of more useful samples is helpful, this strategy can also lead to overfitting, as useful samples are likely to be more rare. In this work, we instead propose a prioritized, parametric version of an agent's memory, using generative models to capture online experience. This paradigm enables (1) densification of past experience, with new generations that benefit from the generative model's generalization capacity and (2) guidance via a family of \"relevance functions\" that push these generations towards more useful parts of an agent's acquired history. We show this recipe can be instantiated using conditional diffusion models and simple relevance functions such as curiosity- or value-based metrics. Our approach consistently improves performance and sample efficiency in both state- and pixel-based domains. We expose the mechanisms underlying these gains, showing how guidance promotes diversity in our generated transitions and reduces overfitting. We also showcase how our approach can train policies with even higher update-to-data ratios than before, opening up avenues to better scale online RL agents.","authors":["Renhao Wang","Kevin Frans","Pieter Abbeel","Sergey Levine","Alexei A. Efros"],"url":"https://arxiv.org/abs/2410.18082"}
{"created":"2025-05-12","title":"Multi-Draft Speculative Sampling: Canonical Decomposition and Theoretical Limits","abstract":"We consider multi-draft speculative sampling, where the proposal sequences are sampled independently from different draft models. At each step, a token-level draft selection scheme takes a list of valid tokens as input and produces an output token whose distribution matches that of the target model. Previous works have demonstrated that the optimal scheme (which maximizes the probability of accepting one of the input tokens) can be cast as a solution to a linear program. In this work we show that the optimal scheme can be decomposed into a two-step solution: in the first step an importance sampling (IS) type scheme is used to select one intermediate token; in the second step (single-draft) speculative sampling is applied to generate the output token. For the case of two identical draft models we further 1) establish a necessary and sufficient condition on the distributions of the target and draft models for the acceptance probability to equal one and 2) provide an explicit expression for the optimal acceptance probability. Our theoretical analysis also motives a new class of token-level selection schemes based on weighted importance sampling. Our experimental results demonstrate consistent improvements in the achievable block efficiency and token rates over baseline schemes in a number of scenarios.","authors":["Ashish Khisti","M. Reza Ebrahimi","Hassan Dbouk","Arash Behboodi","Roland Memisevic","Christos Louizos"],"url":"https://arxiv.org/abs/2410.18234"}
{"created":"2025-05-12","title":"Egocentric and Exocentric Methods: A Short Survey","abstract":"Egocentric vision captures the scene from the point of view of the camera wearer, while exocentric vision captures the overall scene context. Jointly modeling ego and exo views is crucial to developing next-generation AI agents. The community has regained interest in the field of egocentric vision. While the third-person view and first-person have been thoroughly investigated, very few works aim to study both synchronously. Exocentric videos contain many relevant signals that are transferrable to egocentric videos. This paper provides a timely overview of works combining egocentric and exocentric visions, a very new but promising research topic. We describe in detail the datasets and present a survey of the key applications of ego-exo joint learning, where we identify the most recent advances. With the presentation of the current status of the progress, we believe this short but timely survey will be valuable to the broad video-understanding community, particularly when multi-view modeling is critical.","authors":["Anirudh Thatipelli","Shao-Yuan Lo","Amit K. Roy-Chowdhury"],"url":"https://arxiv.org/abs/2410.20621"}
{"created":"2025-05-12","title":"BM-PAW: A Profitable Mining Attack in the PoW-based Blockchain System","abstract":"Mining attacks enable an adversary to procure a disproportionately large portion of mining rewards by deviating from honest mining practices within the PoW-based blockchain system. In this paper, we demonstrate that the security vulnerabilities of PoW-based blockchain extend beyond what these mining attacks initially reveal. We introduce a novel mining strategy, named BM-PAW, which yields superior rewards for both the attacker and the targeted pool compared to the state-of-the-art mining attack, PAW. BM-PAW attackers are incentivized to offer appropriate bribe money to other targets, as they comply with the attacker's directives upon receiving payment. We further find the BM-PAW attacker can circumvent the miner's dilemma through equilibrium analysis in a two-pool BM-PAW game scenario, wherein the outcome is determined by the attacker's mining power. We finally propose practical countermeasures to mitigate these novel pool attacks.","authors":["Junjie Hu","Na Ruan"],"url":"https://arxiv.org/abs/2411.06187"}
{"created":"2025-05-12","title":"SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree Search for Code Generation","abstract":"Large language models demonstrate exceptional performance in simple code generation tasks but still face challenges in tackling complex problems. These challenges may stem from insufficient reasoning and problem decomposition capabilities. To address this issue, we propose a reasoning-augmented data generation process, SRA-MCTS, which guides the model to autonomously generate high-quality intermediate reasoning paths. This creates a positive feedback loop, enabling continuous improvement. Our method operates entirely through the model itself without requiring additional supervision. By synthesizing natural language reasoning paths and translating them into executable code, the approach ensures analytical accuracy and enhances the success rate in solving complex tasks. Experimental results show that, even without additional supervisory signals, our method achieves performance improvements across different model scales, demonstrating the significant potential of self-improvement in small models. Furthermore, the method remains robust when traditional Chain-of-Thought (CoT) approaches exhibit performance degradation, with notable improvements observed in diversity metrics such as pass@10. We encourage further exploration of reasoning processes within training data to enhance the ability of language models to address complex problems. Our code and data are public at https://github.com/DIRECT-BIT/SRA-MCTS.","authors":["Bin Xu","Yiguan Lin","Yinghao Li","Yang Gao"],"url":"https://arxiv.org/abs/2411.11053"}
{"created":"2025-05-12","title":"Sublinear-Time Sampling of Spanning Trees in the Congested Clique","abstract":"We present the first sublinear-in-$n$ round algorithm for sampling an approximately uniform spanning tree of an $n$-vertex graph in the CongestedClique model of distributed computing. In particular, our algorithm requires $\\Tilde{O}(n^{0.657})$ rounds for sampling a spanning tree within total variation distance $1/n^c$, for arbitrary constant $c > 0$, from the uniform distribution. More precisely, our algorithm requires $\\Tilde{O}(n^{1/2 + \\alpha})$ rounds, where $O(n^\\alpha)$ is the running time of matrix multiplication in the CongestedClique model (currently $\\alpha = 1 - 2/\\omega = 0.157$, where $\\omega$ is the sequential matrix multiplication time exponent). We can adapt our algorithm to give exact rather than approximate samples, but with a larger, though still $o(n)$, runtime of $\\Tilde{O}(n^{2/3+\\alpha}) = O(n^{.824})$.","authors":["Sriram V. Pemmaraju","Sourya Roy","Joshua Z. Sobel"],"url":"https://arxiv.org/abs/2411.13334"}
{"created":"2025-05-12","title":"Garden city: A synthetic dataset and sandbox environment for analysis of pre-processing algorithms for GPS human mobility data","abstract":"Human mobility datasets have seen increasing adoption in the past decade, enabling diverse applications that leverage the high precision of measured trajectories relative to other human mobility datasets. However, there are concerns about whether the high sparsity in some commercial datasets can introduce errors due to lack of robustness in processing algorithms, which could compromise the validity of downstream results. The scarcity of \"ground-truth\" data makes it particularly challenging to evaluate and calibrate these algorithms. To overcome these limitations and allow for an intermediate form of validation of common processing algorithms, we propose a synthetic trajectory simulator and sandbox environment meant to replicate the features of commercial datasets that could cause errors in such algorithms, and which can be used to compare algorithm outputs with \"ground-truth\" synthetic trajectories and mobility diaries. Our code is open-source and is publicly available alongside tutorial notebooks and sample datasets generated with it.","authors":["Thomas H. Li","Francisco Barreras"],"url":"https://arxiv.org/abs/2412.00913"}
{"created":"2025-05-12","title":"Crash Severity Risk Modeling Strategies under Data Imbalance","abstract":"This study investigates crash severity risk modeling strategies for work zones involving large vehicles (i.e., trucks, buses, and vans) under crash data imbalance between low-severity (LS) and high-severity (HS) crashes. We utilized crash data involving large vehicles in South Carolina work zones from 2014 to 2018, which included four times more LS crashes than HS crashes. The objective of this study is to evaluate the crash severity prediction performance of various statistical, machine learning, and deep learning models under different feature selection and data balancing techniques. Findings highlight a disparity in LS and HS predictions, with lower accuracy for HS crashes due to class imbalance and feature overlap. Discriminative Mutual Information (DMI) yields the most effective feature set for predicting HS crashes without requiring data balancing, particularly when paired with gradient boosting models and deep neural networks such as CatBoost, NeuralNetTorch, XGBoost, and LightGBM. Data balancing techniques such as NearMiss-1 maximize HS recall when combined with DMI-selected features and certain models such as LightGBM, making them well-suited for HS crash prediction. Conversely, RandomUnderSampler, HS Class Weighting, and RandomOverSampler achieve more balanced performance, which is defined as an equitable trade-off between LS and HS metrics, especially when applied to NeuralNetTorch, NeuralNetFastAI, CatBoost, LightGBM, and Bayesian Mixed Logit (BML) using merged feature sets or models without feature selection. The insights from this study offer safety analysts guidance on selecting models, feature selection, and data balancing techniques aligned with specific safety goals, providing a robust foundation for enhancing work-zone crash severity prediction.","authors":["Abdullah Al Mamun (Graduate Student","Glenn Department of Civil Engineering","Clemson University)","Abyad Enan (Graduate Student","Glenn Department of Civil Engineering","Clemson University)","Debbie A. Indah (Graduate Student","Department of Engineering","South Carolina State University)","Judith Mwakalonge (Professor","Department of Engineering","South Carolina State University)","Gurcan Comert (Associate Professor","Computational Data Science and Engineering Department","North Carolina A&T State University)","Mashrur Chowdhury (Professor","Glenn Department of Civil Engineering","Clemson University)"],"url":"https://arxiv.org/abs/2412.02094"}
{"created":"2025-05-12","title":"VladVA: Discriminative Fine-tuning of LVLMs","abstract":"Contrastively-trained Vision-Language Models (VLMs) like CLIP have become the de facto approach for discriminative vision-language representation learning. However, these models have limited language understanding, often exhibiting a \"bag of words\" behavior. At the same time, Large Vision-Language Models (LVLMs), which combine vision encoders with LLMs, have been shown to be capable of detailed vision-language reasoning, yet their autoregressive nature renders them less suitable for discriminative tasks.","authors":["Yassine Ouali","Adrian Bulat","Alexandros Xenos","Anestis Zaganidis","Ioannis Maniadis Metaxas","Brais Martinez","Georgios Tzimiropoulos"],"url":"https://arxiv.org/abs/2412.04378"}
{"created":"2025-05-12","title":"Budgeted Spatial Data Acquisition: When Coverage and Connectivity Matter","abstract":"Data is undoubtedly becoming a commodity like oil, land, and labor in the 21st century. Although there have been many successful marketplaces for data trading, the existing data marketplaces lack consideration of the case where buyers want to acquire a collection of datasets (instead of one), and the overall spatial coverage and connectivity matter. In this paper, we take the first attempt to formulate this problem as Budgeted Maximum Coverage with Connectivity Constraint (BMCC), which aims to acquire a dataset collection with the maximum spatial coverage under a limited budget while maintaining spatial connectivity. To solve the problem, we propose two approximate algorithms with detailed theoretical guarantees and time complexity analysis, followed by two acceleration strategies to further improve the efficiency of the algorithm. Experiments are conducted on five real-world spatial dataset collections to verify the efficiency and effectiveness of our algorithms.","authors":["Wenzhe Yang","Shixun Huang","Sheng Wang","Zhiyong Peng"],"url":"https://arxiv.org/abs/2412.04853"}
{"created":"2025-05-12","title":"Tensor-product vertex patch smoothers for biharmonic problems","abstract":"We discuss vertex patch smoothers as overlapping domain decomposition methods for fourth order elliptic partial differential equations. We show that they are numerically very efficient and yield high convergence rates. Furthermore, we discuss low rank tensor approximations for their efficient implementation. Our experiments demonstrate that the inexact local solver yields a method which converges fast and uniformly with respect to mesh refinement. The multiplicative smoother shows superior performance in terms of solution efficiency, requiring fewer iterations. However, in three-dimensional cases, the additive smoother outperforms its multiplicative counterpart due to the latter's lower potential for parallelism. Additionally, the solver infrastructure supports a mixed-precision approach, executing the multigrid preconditioner in single precision while performing the outer iteration in double precision, thereby increasing throughput by up to 70 percent.","authors":["Julius Witte","Cu Cui","Francesca Bonizzoni","Guido Kanschat"],"url":"https://arxiv.org/abs/2412.05082"}
{"created":"2025-05-12","title":"Quasi-Optimal Least Squares: Inhomogeneous boundary conditions, and application with machine learning","abstract":"We construct least squares formulations of PDEs with inhomogeneous essential boundary conditions, where boundary residuals are not measured in unpractical fractional Sobolev norms, but which formulations nevertheless are shown to yield a quasi-best approximations from the employed trial spaces. Dual norms do enter the least-squares functional, so that solving the least squares problem amounts to solving a saddle point or minimax problem. For finite element applications we construct uniformly stable finite element pairs, whereas for Machine Learning applications we employ adversarial networks.","authors":["Harald Monsuur","Robin Smeets","Rob Stevenson"],"url":"https://arxiv.org/abs/2412.05965"}
{"created":"2025-05-12","title":"Conformal variational discretisation of infinite dimensional Hamiltonian systems with gradient flow dissipation","abstract":"Nonconservative evolution problems describe irreversible processes and dissipative effects in a broad variety of phenomena. Such problems are often characterised by a conservative part, which can be modelled as a Hamiltonian term, and a nonconservative part, in the form of gradient flow dissipation. Traditional numerical approximations of this class of problem typically fail to retain the separation into conservative and nonconservative parts hence leading to unphysical solutions. In this work we propose a mixed variational method that gives a semi-discrete problem with the same geometric structure as the infinite-dimensional problem. As a consequence the conservation laws and the dissipative terms are retained. A priori convergence estimates on the solution are established. Numerical tests of the Korteweg-de Vries equation and of the two-dimensional Navier-Stokes equations on the torus and on the sphere are presented to corroborate the theoretical findings.","authors":["Damiano Lombardi","Cecilia Pagliantini"],"url":"https://arxiv.org/abs/2412.06310"}
{"created":"2025-05-12","title":"Counterfactual Explanations for MITL Violations","abstract":"MITL is a temporal logic that facilitates the verification of real-time systems by expressing the critical timing constraints placed on these systems. MITL specifications can be checked against system models expressed as networks of timed automata. A violation of an MITL specification is then witnessed by a timed trace of the network, i.e., an execution consisting of both discrete actions and real-valued delays between these actions. Finding and fixing the root cause of such a violation requires significant manual effort since both discrete actions and real-time delays have to be considered. In this paper, we present an automatic explanation method that eases this process by computing the root causes for the violation of an MITL specification on the execution of a network of timed automata. This method is based on newly developed definitions of counterfactual causality tailored to networks of timed automata in the style of Halpern and Pearl's actual causality. We present and evaluate a prototype implementation that demonstrates the efficacy of our method on several benchmarks from the literature.","authors":["Bernd Finkbeiner","Felix Jahn","Julian Siber"],"url":"https://arxiv.org/abs/2412.10386"}
{"created":"2025-05-12","title":"Round and Communication Efficient Graph Coloring","abstract":"In the context of communication complexity, we explore protocols for graph coloring, focusing on the vertex and edge coloring problems in $n$-vertex graphs $G$ with a maximum degree $\\Delta$. We consider a scenario where the edges of $G$ are partitioned between two players.","authors":["Yi-Jun Chang","Gopinath Mishra","Hung Thuan Nguyen","Farrel D Salim"],"url":"https://arxiv.org/abs/2412.12589"}
{"created":"2025-05-12","title":"AnySat: One Earth Observation Model for Many Resolutions, Scales, and Modalities","abstract":"Geospatial models must adapt to the diversity of Earth observation data in terms of resolutions, scales, and modalities. However, existing approaches expect fixed input configurations, which limits their practical applicability. We propose AnySat, a multimodal model based on joint embedding predictive architecture (JEPA) and scale-adaptive spatial encoders, allowing us to train a single model on highly heterogeneous data in a self-supervised manner. To demonstrate the advantages of this unified approach, we compile GeoPlex, a collection of 5 multimodal datasets with varying characteristics and $11$ distinct sensors. We then train a single powerful model on these diverse datasets simultaneously. Once fine-tuned or probed, we reach state-of-the-art results on the test sets of GeoPlex and for 6 external datasets across various environment monitoring tasks: land cover mapping, tree species identification, crop type classification, change detection, climate type classification, and segmentation of flood, burn scar, and deforestation. The code and models are available at https://github.com/gastruc/AnySat.","authors":["Guillaume Astruc","Nicolas Gonthier","Clement Mallet","Loic Landrieu"],"url":"https://arxiv.org/abs/2412.14123"}
{"created":"2025-05-12","title":"Learning an Adaptive and View-Invariant Vision Transformer for Real-Time UAV Tracking","abstract":"Visual tracking has made significant strides due to the adoption of transformer-based models. Most state-of-the-art trackers struggle to meet real-time processing demands on mobile platforms with constrained computing resources, particularly for real-time unmanned aerial vehicle (UAV) tracking. To achieve a better balance between performance and efficiency, we introduce AVTrack, an adaptive computation framework designed to selectively activate transformer blocks for real-time UAV tracking. The proposed Activation Module (AM) dynamically optimizes the ViT architecture by selectively engaging relevant components, thereby enhancing inference efficiency without significant compromise to tracking performance. Furthermore, to tackle the challenges posed by extreme changes in viewing angles often encountered in UAV tracking, the proposed method enhances ViTs' effectiveness by learning view-invariant representations through mutual information (MI) maximization. Two effective design principles are proposed in the AVTrack. Building on it, we propose an improved tracker, dubbed AVTrack-MD, which introduces the novel MI maximization-based multi-teacher knowledge distillation (MD) framework. It harnesses the benefits of multiple teachers, specifically the off-the-shelf tracking models from the AVTrack, by integrating and refining their outputs, thereby guiding the learning process of the compact student network. Specifically, we maximize the MI between the softened feature representations from the multi-teacher models and the student model, leading to improved generalization and performance of the student model, particularly in noisy conditions. Extensive experiments on multiple UAV tracking benchmarks demonstrate that AVTrack-MD not only achieves performance comparable to the AVTrack baseline but also reduces model complexity, resulting in a significant 17\\% increase in average tracking speed.","authors":["You Wu","Yongxin Li","Mengyuan Liu","Xucheng Wang","Xiangyang Yang","Hengzhou Ye","Dan Zeng","Qijun Zhao","Shuiwang Li"],"url":"https://arxiv.org/abs/2412.20002"}
{"created":"2025-05-12","title":"Persistence of Backdoor-based Watermarks for Neural Networks: A Comprehensive Evaluation","abstract":"Deep Neural Networks (DNNs) have gained considerable traction in recent years due to the unparalleled results they gathered. However, the cost behind training such sophisticated models is resource intensive, resulting in many to consider DNNs to be intellectual property (IP) to model owners. In this era of cloud computing, high-performance DNNs are often deployed all over the internet so that people can access them publicly. As such, DNN watermarking schemes, especially backdoor-based watermarks, have been actively developed in recent years to preserve proprietary rights. Nonetheless, there lies much uncertainty on the robustness of existing backdoor watermark schemes, towards both adversarial attacks and unintended means such as fine-tuning neural network models. One reason for this is that no complete guarantee of robustness can be assured in the context of backdoor-based watermark. In this paper, we extensively evaluate the persistence of recent backdoor-based watermarks within neural networks in the scenario of fine-tuning, we propose/develop a novel data-driven idea to restore watermark after fine-tuning without exposing the trigger set. Our empirical results show that by solely introducing training data after fine-tuning, the watermark can be restored if model parameters do not shift dramatically during fine-tuning. Depending on the types of trigger samples used, trigger accuracy can be reinstated to up to 100%. Our study further explores how the restoration process works using loss landscape visualization, as well as the idea of introducing training data in fine-tuning stage to alleviate watermark vanishing.","authors":["Anh Tu Ngo","Chuan Song Heng","Nandish Chattopadhyay","Anupam Chattopadhyay"],"url":"https://arxiv.org/abs/2501.02704"}
{"created":"2025-05-12","title":"From Models to Network Topologies: A Topology Inference Attack in Decentralized Federated Learning","abstract":"Federated Learning (FL) is widely recognized as a privacy-preserving machine learning paradigm due to its model-sharing mechanism that avoids direct data exchange. Nevertheless, model training leaves exploitable traces that can be used to infer sensitive information. In Decentralized FL (DFL), the topology, defining how participants are connected, plays a crucial role in shaping the model's privacy, robustness, and convergence. However, the topology introduces an unexplored vulnerability: attackers can exploit it to infer participant relationships and launch targeted attacks. This work uncovers the hidden risks of DFL topologies by proposing a novel Topology Inference Attack that infers the topology solely from model behavior. A taxonomy of topology inference attacks is introduced, categorizing them by the attacker's capabilities and knowledge. Practical attack strategies are designed for various scenarios, and experiments are conducted to identify key factors influencing attack success. The results demonstrate that analyzing only the model of each node can accurately infer the DFL topology, highlighting a critical privacy risk in DFL systems. These findings offer valuable insights for improving privacy preservation in DFL environments.","authors":["Chao Feng","Yuanzhe Gao","Alberto Huertas Celdran","Gerome Bovet","Burkhard Stiller"],"url":"https://arxiv.org/abs/2501.03119"}
{"created":"2025-05-12","title":"The Adini finite element on locally refined meshes","abstract":"This work introduces a locally refined version of the Adini finite element for the planar biharmonic equation on rectangular partitions with at most one hanging node per edge. If global continuity of the discrete functions is enforced, for such method there is some freedom in assigning the normal derivative degree of freedom at the hanging nodes. It is proven that the convergence order $h^2$ known for regular solutions and regular partitions is lost for any such choice, and that assigning the average of the normal derivatives at the neighbouring regular vertices is the only choice that achieves a superlinear order, namely $h^{3/2}$ on uniformly refined meshes. On adaptive meshes, the method behaves like a first-order scheme. Furthermore, the reliability and efficiency of an explicit residual-based error estimator are shown up to the best approximation of the Hessian by certain piecewise polynomial functions.","authors":["Dietmar Gallistl"],"url":"https://arxiv.org/abs/2501.11981"}
{"created":"2025-05-12","title":"Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes","abstract":"Tumor documentation in Germany is largely done manually, requiring reading patient records and entering data into structured databases. Large language models (LLMs) could potentially enhance this process by improving efficiency and reliability. This evaluation tests eleven different open source LLMs with sizes ranging from 1-70 billion model parameters on three basic tasks of the tumor documentation process: identifying tumor diagnoses, assigning ICD-10 codes, and extracting the date of first diagnosis. For evaluating the LLMs on these tasks, a dataset of annotated text snippets based on anonymized doctors' notes from urology was prepared. Different prompting strategies were used to investigate the effect of the number of examples in few-shot prompting and to explore the capabilities of the LLMs in general. The models Llama 3.1 8B, Mistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks. Models with less extensive training data or having fewer than 7 billion parameters showed notably lower performance, while larger models did not display performance gains. Examples from a different medical domain than urology could also improve the outcome in few-shot prompting, which demonstrates the ability of LLMs to handle tasks needed for tumor documentation. Open source LLMs show a strong potential for automating tumor documentation. Models from 7-12 billion parameters could offer an optimal balance between performance and resource efficiency. With tailored fine-tuning and well-designed prompting, these models might become important tools for clinical documentation in the future. The code for the evaluation is available from https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset as a new valuable resource that addresses the shortage of authentic and easily accessible benchmarks in German-language medical NLP.","authors":["Stefan Lenz","Arsenij Ustjanzew","Marco Jeray","Meike Ressing","Torsten Panholzer"],"url":"https://arxiv.org/abs/2501.12106"}
{"created":"2025-05-12","title":"An Efficient Sparse Kernel Generator for O(3)-Equivariant Deep Networks","abstract":"Rotation equivariant graph neural networks, i.e. networks designed to guarantee certain geometric relations between their inputs and outputs, yield state of the art performance on spatial deep learning tasks. They exhibit high data efficiency during training and significantly reduced inference time for interatomic potential calculations compared to classical approaches. Key to these models is the Clebsch-Gordon (CG) tensor product, a kernel that contracts two dense feature vectors with a highly-structured sparse tensor to produce a dense output vector. The operation, which may be repeated millions of times for typical equivariant models, is a costly and inefficient bottleneck. We introduce a GPU sparse kernel generator for the CG tensor product that provides significant speedups over the best existing open and closed-source implementations. Our implementation achieves high performance by carefully managing the limited GPU shared memory through static analysis at model compile-time, minimizing reads and writes to global memory. We break the tensor product into a series of smaller kernels with operands that fit entirely into registers, enabling us to emit long arithmetic instruction streams that maximize instruction-level parallelism. By fusing the CG tensor product with a subsequent graph convolution, we reduce both intermediate storage and global memory traffic over naive approaches that duplicate input data. We also provide optimized kernels for the gradient of the CG tensor product and a novel identity for the higher partial derivatives required to predict interatomic forces. Our kernels offer up to 1.3x speedup over NVIDIA's closed-source cuEquivariance package, as well as 10x speedup over the widely-used e3nn package. In FP64 precision, we offer up to 6.2x inference-time speedup for the MACE chemistry foundation model over the original unoptimized version.","authors":["Vivek Bharadwaj","Austin Glover","Aydin Buluc","James Demmel"],"url":"https://arxiv.org/abs/2501.13986"}
{"created":"2025-05-12","title":"Higher-Order Meta Distribution Reliability Analysis of Wireless Networks","abstract":"Communication reliability, as defined by 3GPP, refers to the probability of providing a desired quality of service (QoS). This metric is typically quantified for wireless networks by averaging the QoS success indicator over spatial and temporal random variables. Recently, the meta distribution (MD) has emerged as a two-level performance analysis tool for wireless networks, offering a detailed examination of the outer level (i.e., system-level) reliability versus the inner level (i.e., link-level) reliability thresholds. Most existing studies focus on first-order spatiotemporal MD reliability analyses, and the benefits of leveraging MD reliability for applications beyond this structure remain unexplored, a gap addressed in this paper. We propose a framework for the analysis of higher-order MD reliability of wireless networks considering different levels of temporal dynamicity of random elements in the network where the MD at each layer is leveraged to be used in calculating the MD of the higher layer. We then provide two applications for this framework and provide a detailed analytical and numerical study of the higher-order MD reliability for both examples. The results demonstrate the value of the hierarchical representation of MD reliability across three domains and the impact of the inner-layers target reliabilities on the overall MD reliability measure.","authors":["Mehdi Monemi","Mehdi Rasti","S. Ali Mousavi","Matti Latva-aho","Martin Haenggi"],"url":"https://arxiv.org/abs/2501.14289"}
{"created":"2025-05-12","title":"JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning in Large Language Models","abstract":"Logical reasoning is a critical component of Large Language Models (LLMs), and substantial research efforts in recent years have aimed to enhance their deductive reasoning capabilities. However, existing deductive reasoning benchmarks, which are crucial for evaluating and advancing LLMs, are inadequate due to their lack of task complexity, presence of prior knowledge as a confounder, and superficial error analysis. To address these deficiencies, we introduce JustLogic, a synthetically generated deductive reasoning benchmark designed for rigorous evaluation of LLMs. JustLogic is (i) highly complex, capable of generating a diverse range of linguistic patterns, vocabulary, and argument structures; (ii) prior knowledge independent, eliminating the advantage of models possessing prior knowledge and ensuring that only deductive reasoning is used to answer questions; and (iii) capable of in-depth error analysis on the heterogeneous effects of reasoning depth and argument form on model accuracy. Our experimental results on JustLogic reveal that (i) state-of-the-art (SOTA) reasoning LLMs perform on par or better than the human average but significantly worse than the human ceiling, and (ii) SOTA non-reasoning models still underperform the human average. All code and data are available at https://github.com/michaelchen-lab/JustLogic","authors":["Michael K. Chen","Xikun Zhang","Dacheng Tao"],"url":"https://arxiv.org/abs/2501.14851"}
{"created":"2025-05-12","title":"On the Parallelizability of Approval-Based Committee Rules","abstract":"Approval-Based Committee (ABC) rules are an important tool for choosing a fair set of candidates when given the preferences of a collection of voters. Though finding a winning committee for many ABC rules is NP-hard, natural variations for these rules with polynomial-time algorithms exist. The recently introduced Method of Equal Shares, an important ABC rule with desirable properties, is also computable in polynomial time. However, when working with very large elections, polynomial time is not enough and parallelization may be necessary. We show that computing a winning committee using these ABC rules (including the Method of Equal Shares) is P-hard, thus showing they cannot be parallelized. In contrast, we show that finding a winning committee can be parallelized when the votes are single-peaked or single-crossing for the important ABC rule Chamberlin-Courant.","authors":["Zack Fitzsimmons","Zohair Raza Hassan","Edith Hemaspaandra"],"url":"https://arxiv.org/abs/2501.15006"}
{"created":"2025-05-12","title":"AdaCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Chain-of-Thought","abstract":"Large language models have shown impressive multilingual capabilities through pretraining on diverse corpora. While these models show strong reasoning abilities, their performance varies significantly across languages due to imbalanced training data distribution. Existing approaches using sample-level translation for extensive multilingual pretraining and cross-lingual tuning face scalability challenges and often fail to capture nuanced reasoning processes across languages. In this paper, we introduce AdaCoT (Adaptive Chain-of-Thought), a framework that enhances multilingual factual reasoning by dynamically routing thought processes in intermediary ``thinking languages'' before generating target-language responses. AdaCoT leverages a language-agnostic core and incorporates an adaptive, reward-based mechanism for selecting optimal reasoning pathways without requiring additional pretraining. Our comprehensive evaluation across multiple benchmarks demonstrates substantial improvements in both factual reasoning quality and cross-lingual consistency, with particularly strong performance gains in low-resource language settings. The results suggest that adaptive reasoning paths can effectively bridge the performance gap between high and low-resource languages while maintaining cultural and linguistic nuances.","authors":["Xin Huang","Tarun Kumar Vangani","Zhengyuan Liu","Bowei Zou","Ai Ti Aw"],"url":"https://arxiv.org/abs/2501.16154"}
{"created":"2025-05-12","title":"GDformer: Going Beyond Subsequence Isolation for Multivariate Time Series Anomaly Detection","abstract":"Unsupervised anomaly detection of multivariate time series is a challenging task, given the requirements of deriving a compact detection criterion without accessing the anomaly points. The existing methods are mainly based on reconstruction error or association divergence, which are both confined to isolated subsequences with limited horizons, hardly promising unified series-level criterion. In this paper, we propose the Global Dictionary-enhanced Transformer (GDformer) with a renovated dictionary-based cross attention mechanism to cultivate the global representations shared by all normal points in the entire series. Accordingly, the cross-attention maps reflect the correlation weights between the point and global representations, which naturally leads to the representation-wise similarity-based detection criterion. To foster more compact detection boundary, prototypes are introduced to capture the distribution of normal point-global correlation weights. GDformer consistently achieves state-of-the-art unsupervised anomaly detection performance on five real-world benchmark datasets. Further experiments validate the global dictionary has great transferability among various datasets. The code is available at https://github.com/yuppielqx/GDformer.","authors":["Qingxiang Liu","Chenghao Liu","Sheng Sun","Di Yao","Yuxuan Liang"],"url":"https://arxiv.org/abs/2501.18196"}
{"created":"2025-05-12","title":"Blocked Bloom Filters with Choices","abstract":"Probabilistic filters are approximate set membership data structures that represent a set of keys in small space, and answer set membership queries without false negative answers, but with a certain allowed false positive probability. Such filters are widely used in database systems, networks, storage systems and in biological sequence analysis because of their fast query times and low space requirements. Starting with Bloom filters in the 1970s, many filter data structures have been developed, each with its own advantages and disadvantages, e.g., Blocked Bloom filters, Cuckoo filters, XOR filters, Ribbon filters, and more.","authors":["Johanna Elena Schmitz","Jens Zentgraf","Sven Rahmann"],"url":"https://arxiv.org/abs/2501.18977"}
{"created":"2025-05-12","title":"Estimating LLM Uncertainty with Evidence","abstract":"Over the past few years, Large Language Models (LLMs) have developed rapidly and are widely applied in various domains. However, LLMs face the issue of hallucinations, generating responses that may be unreliable when the models lack relevant knowledge. To be aware of potential hallucinations, uncertainty estimation methods have been introduced, and most of them have confirmed that reliability lies in critical tokens. However, probability-based methods perform poorly in identifying token reliability, limiting their practical utility. In this paper, we reveal that the probability-based method fails to estimate token reliability due to the loss of evidence strength information which is accumulated in the training stage. Therefore, we present Logits-induced token uncertainty (LogTokU), a framework for estimating decoupled token uncertainty in LLMs, enabling real-time uncertainty estimation without requiring multiple sampling processes. We employ evidence modeling to implement LogTokU and use the estimated uncertainty to guide downstream tasks. The experimental results demonstrate that LogTokU has significant effectiveness and promise.","authors":["Huan Ma","Jingdong Chen","Joey Tianyi Zhou","Guangyu Wang","Changqing Zhang"],"url":"https://arxiv.org/abs/2502.00290"}
{"created":"2025-05-12","title":"Phonetic accommodation and inhibition in a dynamic neural field model","abstract":"Short-term phonetic accommodation is a fundamental driver behind accent change, but how does real-time input from another speaker's voice shape the speech planning representations of an interlocutor? We advance a computational model of change in speech planning representations during phonetic accommodation, grounded in dynamic neural field equations for movement planning and memory dynamics. A dual-layer planning/memory field predicts that convergence to a model talker on one trial can trigger divergence on subsequent trials, due to a delayed inhibitory effect in the more slowly evolving memory field. The model's predictions are compared with empirical patterns of accommodation from an experimental pilot study. We show that observed empirical phenomena may correspond to variation in the magnitude of inhibitory memory dynamics, which could reflect resistance to accommodation due to phonological and/or sociolinguistic pressures. We discuss the implications of these results for the relations between short-term phonetic accommodation and sound change.","authors":["Sam Kirkham","Patrycja Strycharczuk","Rob Davies","Danielle Welburn"],"url":"https://arxiv.org/abs/2502.01210"}
{"created":"2025-05-12","title":"GNN-DT: Graph Neural Network Enhanced Decision Transformer for Efficient Optimization in Dynamic Environments","abstract":"Reinforcement Learning (RL) methods used for solving real-world optimization problems often involve dynamic state-action spaces, larger scale, and sparse rewards, leading to significant challenges in convergence, scalability, and efficient exploration of the solution space. This study introduces GNN-DT, a novel Decision Transformer (DT) architecture that integrates Graph Neural Network (GNN) embedders with a novel residual connection between input and output tokens crucial for handling dynamic environments. By learning from previously collected trajectories, GNN-DT tackles the sparse rewards limitations of online RL algorithms and delivers high-quality solutions in real-time. We evaluate GNN-DT on the complex electric vehicle (EV) charging optimization problem and prove that its performance is superior and requires significantly fewer training trajectories, thus improving sample efficiency compared to existing DT and offline RL baselines. Furthermore, GNN-DT exhibits robust generalization to unseen environments and larger action spaces, addressing a critical gap in prior offline and online RL approaches.","authors":["Stavros Orfanoudakis","Nanda Kishor Panda","Peter Palensky","Pedro P. Vergara"],"url":"https://arxiv.org/abs/2502.01778"}
{"created":"2025-05-12","title":"RIE-SenseNet: Riemannian Manifold Embedding of Multi-Source Industrial Sensor Signals for Robust Pattern Recognition","abstract":"Industrial sensor networks produce complex signals with nonlinear structure and shifting distributions. We propose RIE-SenseNet, a novel geometry-aware Transformer model that embeds sensor data in a Riemannian manifold to tackle these challenges. By leveraging hyperbolic geometry for sequence modeling and introducing a manifold-based augmentation technique, RIE-SenseNet preserves sensor signal structure and generates realistic synthetic samples. Experiments show RIE-SenseNet achieves >90% F1-score, far surpassing CNN and Transformer baselines. These results illustrate the benefit of combining non-Euclidean feature representations with geometry-consistent data augmentation for robust pattern recognition in industrial sensing.","authors":["Xu Wang","Puyu Han","Jiaju Kang","Weichao Pan","Luqi Gong"],"url":"https://arxiv.org/abs/2502.02428"}
{"created":"2025-05-12","title":"The Order Effect: Investigating Prompt Sensitivity to Input Order in LLMs","abstract":"As large language models (LLMs) become integral to diverse applications, ensuring their reliability under varying input conditions is crucial. One key issue affecting this reliability is order sensitivity, wherein slight variations in the input arrangement can lead to inconsistent or biased outputs. Although recent advances have reduced this sensitivity, the problem remains unresolved. This paper investigates the extent of order sensitivity in LLMs whose internal components are hidden from users (such as closed-source models or those accessed via API calls). We conduct experiments across multiple tasks, including paraphrasing, relevance judgment, and multiple-choice questions. Our results show that input order significantly affects performance across tasks, with shuffled inputs leading to measurable declines in output accuracy. Few-shot prompting demonstrates mixed effectiveness and offers partial mitigation; however, fails to fully resolve the problem. These findings highlight persistent risks, particularly in high-stakes applications, and point to the need for more robust LLMs or improved input-handling techniques in future development.","authors":["Bryan Guan","Tanya Roosta","Peyman Passban","Mehdi Rezagholizadeh"],"url":"https://arxiv.org/abs/2502.04134"}
{"created":"2025-05-12","title":"Let's Have Both! Optimal List-Recoverability via Alphabet Permutation Codes","abstract":"We introduce alphabet-permutation (AP) codes, a new family of error-correcting codes defined by iteratively applying random coordinate-wise permutations to a fixed initial word. A special case recovers random additive codes and random binary linear codes, where each permutation corresponds to an additive shift over a finite field.","authors":["Sergey Komech","Jonathan Mosheiff"],"url":"https://arxiv.org/abs/2502.05858"}
{"created":"2025-05-12","title":"Structure-preserving contrastive learning for spatial time series","abstract":"The effectiveness of neural network models largely relies on learning meaningful latent patterns from data, where self-supervised learning of informative representations can enhance model performance and generalisability. However, self-supervised representation learning for spatially characterised time series, which are ubiquitous in transportation domain, poses unique challenges due to the necessity of maintaining fine-grained spatio-temporal similarities in the latent space. In this study, we introduce two structure-preserving regularisers for the contrastive learning of spatial time series: one regulariser preserves the topology of similarities between instances, and the other preserves the graph geometry of similarities across spatial and temporal dimensions. To balance the contrastive learning objective and the need for structure preservation, we propose a dynamic weighting mechanism that adaptively manages this trade-off and stabilises training. We validate the proposed method through extensive experiments, including multivariate time series classification to demonstrate its general applicability, as well as macroscopic and microscopic traffic prediction to highlight its particular usefulness in encoding traffic interactions. Across all tasks, our method preserves the similarity structures more effectively and improves state-of-the-art task performances. This method can be integrated with an arbitrary neural network model and is particularly beneficial for time series data with spatial or geographical features. Furthermore, our findings suggest that well-preserved similarity structures in the latent space indicate more informative and useful representations. This provides insights to design more effective neural networks for data-driven transportation research. Our code is made openly accessible with all resulting data at https://github.com/yiru-jiao/spclt","authors":["Yiru Jiao","Sander van Cranenburgh","Simeon Calvert","Hans van Lint"],"url":"https://arxiv.org/abs/2502.06380"}
{"created":"2025-05-12","title":"Generalized Class Discovery in Instance Segmentation","abstract":"This work addresses the task of generalized class discovery (GCD) in instance segmentation. The goal is to discover novel classes and obtain a model capable of segmenting instances of both known and novel categories, given labeled and unlabeled data. Since the real world contains numerous objects with long-tailed distributions, the instance distribution for each class is inherently imbalanced. To address the imbalanced distributions, we propose an instance-wise temperature assignment (ITA) method for contrastive learning and class-wise reliability criteria for pseudo-labels. The ITA method relaxes instance discrimination for samples belonging to head classes to enhance GCD. The reliability criteria are to avoid excluding most pseudo-labels for tail classes when training an instance segmentation network using pseudo-labels from GCD. Additionally, we propose dynamically adjusting the criteria to leverage diverse samples in the early stages while relying only on reliable pseudo-labels in the later stages. We also introduce an efficient soft attention module to encode object-specific representations for GCD. Finally, we evaluate our proposed method by conducting experiments on two settings: COCO$_{half}$ + LVIS and LVIS + Visual Genome. The experimental results demonstrate that the proposed method outperforms previous state-of-the-art methods.","authors":["Cuong Manh Hoang","Yeejin Lee","Byeongkeun Kang"],"url":"https://arxiv.org/abs/2502.08149"}
{"created":"2025-05-12","title":"k-LLMmeans: Scalable, Stable, and Interpretable Text Clustering via LLM-based Centroids","abstract":"We introduce k-LLMmeans, a novel modification of the k-means algorithm for text clustering that leverages LLM-generated summaries as cluster centroids, capturing semantic nuances often missed by purely numerical averages. This design preserves the core optimization properties of k-means while enhancing semantic interpretability and avoiding the scalability and instability issues typical of modern LLM-based clustering. Unlike existing methods, our approach does not increase LLM usage with dataset size and produces transparent intermediate outputs. We further extend it with a mini-batch variant for efficient, real-time clustering of streaming text. Extensive experiments across multiple datasets, embeddings, and LLMs show that k-LLMmeans consistently outperforms k-means and other traditional baselines and achieves results comparable to state-of-the-art LLM-based clustering, with a fraction of the LLM calls. Finally, we present a case study on sequential text streams and introduce a new benchmark dataset constructed from StackExchange to evaluate text-stream clustering methods.","authors":["Jairo Diaz-Rodriguez"],"url":"https://arxiv.org/abs/2502.09667"}
{"created":"2025-05-12","title":"MERGE$^3$: Efficient Evolutionary Merging on Consumer-grade GPUs","abstract":"Evolutionary model merging enables the creation of high-performing multi-task models but remains computationally prohibitive for consumer hardware. We introduce MERGE$^3$, an efficient framework that makes evolutionary merging feasible on a single GPU by reducing fitness computation costs 50$\\times$ while preserving performance. MERGE$^3$ achieves this by Extracting a reduced dataset for evaluation, Estimating model abilities using Item Response Theory (IRT), and Evolving optimal merges via IRT-based performance estimators. Our method enables state-of-the-art multilingual and cross-lingual merging, transferring knowledge across languages with significantly lower computational overhead. We provide theoretical guarantees and an open-source library, democratizing high-quality model merging.","authors":["Tommaso Mencattini","Adrian Robert Minut","Donato Crisostomi","Andrea Santilli","Emanuele Rodol\\`a"],"url":"https://arxiv.org/abs/2502.10436"}
{"created":"2025-05-12","title":"Logic and Computation through the Lens of Semirings","abstract":"We study the expressivity and computational aspects of first-order logic and its extensions in the semiring semantics developed by Gr\\\"adel and Tannen. We characterize the complexity of model checking and data complexity of first-order logic both in terms of a generalization of Blum-Shub-Smale machines and arithmetic circuits defined over a semiring. In particular, we give a logical characterization of constant-depth arithmetic circuits by an extension of first-order logic that holds for any semiring that is both commutative and positive.","authors":["Timon Barlag","Nicolas Fr\\\"ohlich","Teemu Hankala","Miika Hannula","Minna Hirvonen","Vivian Holzapfel","Juha Kontinen","Arne Meier","Laura Strieker"],"url":"https://arxiv.org/abs/2502.12939"}
{"created":"2025-05-12","title":"English Please: Evaluating Machine Translation with Large Language Models for Multilingual Bug Reports","abstract":"Accurate translation of bug reports is critical for efficient collaboration in global software development. In this study, we conduct the first comprehensive evaluation of machine translation (MT) performance on bug reports, analyzing the capabilities of DeepL, AWS Translate, and large language models such as ChatGPT, Claude, Gemini, LLaMA, and Mistral using data from the Visual Studio Code GitHub repository, specifically focusing on reports labeled with the english-please tag. To assess both translation quality and source language identification accuracy, we employ a range of MT evaluation metrics-including BLEU, BERTScore, COMET, METEOR, and ROUGE-alongside classification metrics such as accuracy, precision, recall, and F1-score. Our findings reveal that while ChatGPT (gpt-4o) excels in semantic and lexical translation quality, it does not lead in source language identification. Claude and Mistral achieve the highest F1-scores (0.7182 and 0.7142, respectively), and Gemini records the best precision (0.7414). AWS Translate shows the highest accuracy (0.4717) in identifying source languages. These results highlight that no single system dominates across all tasks, reinforcing the importance of task-specific evaluations. This study underscores the need for domain adaptation when translating technical content and provides actionable insights for integrating MT into bug-triaging workflows. The code and dataset for this paper are available at GitHub-https://github.com/av9ash/English-Please","authors":["Avinash Patil","Siru Tao","Aryan Jadon"],"url":"https://arxiv.org/abs/2502.14338"}
{"created":"2025-05-12","title":"Visual and Auditory Aesthetic Preferences Across Cultures","abstract":"Research on how humans perceive aesthetics in shapes, colours, and music has predominantly focused on Western populations, limiting our understanding of how cultural environments shape aesthetic preferences. We present a large-scale cross-cultural study examining aesthetic preferences across five distinct modalities extensively explored in the literature: shape, curvature, colour, musical harmony and melody. We gather 401,403 preference judgements from 4,835 participants across 10 countries, systematically sampling two-dimensional parameter spaces for each modality. The findings reveal both universal patterns and cultural variations. Preferences for shape and curvature cross-culturally demonstrate a consistent preference for symmetrical forms. While colour preferences are categorically consistent, ratio-like preferences vary across cultures. Musical harmony shows strong agreement in interval relationships despite differing regions of preference within the broad frequency spectrum, while melody shows the highest cross-cultural variation. These results suggest that aesthetic preferences emerge from an interplay between shared perceptual mechanisms and cultural learning.","authors":["Harin Lee","Eline Van Geert","Elif Celen","Raja Marjieh","Pol van Rijn","Minsu Park","Nori Jacoby"],"url":"https://arxiv.org/abs/2502.14439"}
{"created":"2025-05-12","title":"On the $H$-property for Step-graphons: Residual Case","abstract":"We investigate the $H$-property for step-graphons. Specifically, we sample graphs $G_n$ on $n$ nodes from a step-graphon and evaluate the probability that $G_n$ has a Hamiltonian decomposition in the asymptotic regime as $n\\to\\infty$. It has been shown that for almost all step-graphons, this probability converges to either zero or one. We focus in this paper on the residual case where the zero-one law does not apply. We show that the limit of the probability still exists and provide an explicit expression of it. We present a complete proof of the result and validate it through numerical studies.","authors":["Wanting Gao","Xudong Chen"],"url":"https://arxiv.org/abs/2502.14853"}
{"created":"2025-05-12","title":"Gradient-Guided Annealing for Domain Generalization","abstract":"Domain Generalization (DG) research has gained considerable traction as of late, since the ability to generalize to unseen data distributions is a requirement that eludes even state-of-the-art training algorithms. In this paper we observe that the initial iterations of model training play a key role in domain generalization effectiveness, since the loss landscape may be significantly different across the training and test distributions, contrary to the case of i.i.d. data. Conflicts between gradients of the loss components of each domain lead the optimization procedure to undesirable local minima that do not capture the domain-invariant features of the target classes. We propose alleviating domain conflicts in model optimization, by iteratively annealing the parameters of a model in the early stages of training and searching for points where gradients align between domains. By discovering a set of parameter values where gradients are updated towards the same direction for each data distribution present in the training set, the proposed Gradient-Guided Annealing (GGA) algorithm encourages models to seek out minima that exhibit improved robustness against domain shifts. The efficacy of GGA is evaluated on five widely accepted and challenging image classification domain generalization benchmarks, where its use alone is able to establish highly competitive or even state-of-the-art performance. Moreover, when combined with previously proposed domain-generalization algorithms it is able to consistently improve their effectiveness by significant margins.","authors":["Aristotelis Ballas","Christos Diou"],"url":"https://arxiv.org/abs/2502.20162"}
{"created":"2025-05-12","title":"Relation between two Sinc-collocation methods for Volterra integral equations of the second kind and further improvement","abstract":"Two different Sinc-collocation methods for Volterra integral equations of the second kind have been independently proposed by Stenger and Rashidinia--Zarebnia. However, their relation remains unexplored. This study theoretically examines the solutions of these two methods, and reveals that they are not generally equivalent, despite coinciding at the collocation points. Strictly speaking, Stenger's method assumes that the kernel of the integral is a function of a single variable, but this study theoretically justifies the use of his method in general cases, i.e., the kernel is a function of two variables. Then, this study rigorously proves that both methods can attain the same, root-exponential convergence. In addition to the contribution, this study improves Stenger's method to attain significantly higher, almost exponential convergence. Numerical examples supporting the theoretical results are also provided.","authors":["Tomoaki Okayama"],"url":"https://arxiv.org/abs/2502.20221"}
{"created":"2025-05-12","title":"Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization","abstract":"Agentic Generative AI, powered by Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Vector Stores (VSs), represents a transformative technology applicable to specialized domains such as legal systems, research, recommender systems, cybersecurity, and global security, including proliferation research. This technology excels at inferring relationships within vast unstructured or semi-structured datasets. The legal domain here comprises complex data characterized by extensive, interrelated, and semi-structured knowledge systems with complex relations. It comprises constitutions, statutes, regulations, and case law. Extracting insights and navigating the intricate networks of legal documents and their relations is crucial for effective legal research. Here, we introduce a generative AI system that integrates RAG, VS, and KG, constructed via Non-Negative Matrix Factorization (NMF), to enhance legal information retrieval and AI reasoning and minimize hallucinations. In the legal system, these technologies empower AI agents to identify and analyze complex connections among cases, statutes, and legal precedents, uncovering hidden relationships and predicting legal trends-challenging tasks that are essential for ensuring justice and improving operational efficiency. Our system employs web scraping techniques to systematically collect legal texts, such as statutes, constitutional provisions, and case law, from publicly accessible platforms like Justia. It bridges the gap between traditional keyword-based searches and contextual understanding by leveraging advanced semantic representations, hierarchical relationships, and latent topic discovery. This framework supports legal document clustering, summarization, and cross-referencing, for scalable, interpretable, and accurate retrieval for semi-structured data while advancing computational law and AI.","authors":["Ryan C. Barron","Maksim E. Eren","Olga M. Serafimova","Cynthia Matuszek","Boian S. Alexandrov"],"url":"https://arxiv.org/abs/2502.20364"}
{"created":"2025-05-12","title":"KineSoft: Learning Proprioceptive Manipulation Policies with Soft Robot Hands","abstract":"Underactuated soft robot hands offer inherent safety and adaptability advantages over rigid systems, but developing dexterous manipulation skills remains challenging. While imitation learning shows promise for complex manipulation tasks, traditional approaches struggle with soft systems due to demonstration collection challenges and ineffective state representations. We present KineSoft, a framework enabling direct kinesthetic teaching of soft robotic hands by leveraging their natural compliance as a skill teaching advantage rather than only as a control challenge. KineSoft makes two key contributions: (1) an internal strain sensing array providing occlusion-free proprioceptive shape estimation, and (2) a shape-based imitation learning framework that uses proprioceptive feedback with a low-level shape-conditioned controller to ground diffusion-based policies. This enables human demonstrators to physically guide the robot while the system learns to associate proprioceptive patterns with successful manipulation strategies. We validate KineSoft through physical experiments, demonstrating superior shape estimation accuracy compared to baseline methods, precise shape-trajectory tracking, and higher task success rates compared to baseline imitation learning approaches.","authors":["Uksang Yoo","Jonathan Francis","Jean Oh","Jeffrey Ichnowski"],"url":"https://arxiv.org/abs/2503.01078"}
{"created":"2025-05-12","title":"AVA: Attentive VLM Agent for Mastering StarCraft II","abstract":"We introduce Attentive VLM Agent (AVA), a multimodal StarCraft II agent that aligns artificial agent perception with the human gameplay experience. Traditional frameworks such as SMAC rely on abstract state representations that diverge significantly from human perception, limiting the ecological validity of agent behavior. Our agent addresses this limitation by incorporating RGB visual inputs and natural language observations that more closely simulate human cognitive processes during gameplay. The AVA architecture consists of three integrated components: (1) a vision-language model enhanced with specialized self-attention mechanisms for strategic unit targeting and battlefield assessment, (2) a retrieval-augmented generation system that leverages domain-specific StarCraft II knowledge to inform tactical decisions, and (3) a dynamic role-based task distribution system that enables coordinated multi-agent behavior. The experimental evaluation in our proposed AVACraft environment, which contains 21 multimodal StarCraft II scenarios, demonstrates that AVA powered by foundation models (specifically Qwen-VL and GPT-4o) can execute complex tactical maneuvers without explicit training, achieving comparable performance to traditional MARL methods that require substantial training iterations. This work establishes a foundation for developing human-aligned StarCraft II agents and advances the broader research agenda of multimodal game AI. Our implementation is available at https://github.com/camel-ai/VLM-Play-StarCraft2.","authors":["Weiyu Ma","Yuqian Fu","Zecheng Zhang","Bernard Ghanem","Guohao Li"],"url":"https://arxiv.org/abs/2503.05383"}
{"created":"2025-05-12","title":"Inverting Parameterized Burrows-Wheeler Transform","abstract":"The Burrows-Wheeler Transform (BWT) of a string is an invertible permutation of the string, which can be used for data compression and compact indexes for string pattern matching. Ganguly et al. [SODA, 2017] introduced the parameterized BWT (pBWT) to design compact indexes for parameterized matching (p-matching), a variant of string pattern matching with parameter symbols introduced by Baker [STOC, 1993]. Although the pBWT was inspired by the BWT, it is not obvious whether the pBWT itself is invertible or not. In this paper we show that we can retrieve the original string (up to renaming of parameter symbols) from the pBWT of length $n$ in $O(n^2)$ time and $O(n)$ space.","authors":["Shogen Kawanami","Kento Iseri","Tomohiro I"],"url":"https://arxiv.org/abs/2503.06970"}
{"created":"2025-05-12","title":"RS2AD: End-to-End Autonomous Driving Data Generation from Roadside Sensor Observations","abstract":"End-to-end autonomous driving solutions, which process multi-modal sensory data to directly generate refined control commands, have become a dominant paradigm in autonomous driving research. However, these approaches predominantly depend on single-vehicle data collection for model training and optimization, resulting in significant challenges such as high data acquisition and annotation costs, the scarcity of critical driving scenarios, and fragmented datasets that impede model generalization. To mitigate these limitations, we introduce RS2AD, a novel framework for reconstructing and synthesizing vehicle-mounted LiDAR data from roadside sensor observations. Specifically, our method transforms roadside LiDAR point clouds into the vehicle-mounted LiDAR coordinate system by leveraging the target vehicle's relative pose. Subsequently, high-fidelity vehicle-mounted LiDAR data is synthesized through virtual LiDAR modeling, point cloud classification, and resampling techniques. To the best of our knowledge, this is the first approach to reconstruct vehicle-mounted LiDAR data from roadside sensor inputs. Extensive experimental evaluations demonstrate that incorporating the data generated by the RS2AD method (the RS2V-L dataset) into model training as a supplement to the KITTI dataset can significantly enhance the accuracy of 3D object detection and greatly improve the efficiency of end-to-end autonomous driving data generation. These findings strongly validate the effectiveness of the proposed method and underscore its potential in reducing dependence on costly vehicle-mounted data collection while improving the robustness of autonomous driving models.","authors":["Ruidan Xing","Runyi Huang","Qing Xu","Lei He"],"url":"https://arxiv.org/abs/2503.07085"}
{"created":"2025-05-12","title":"A High Efficient and Scalable Obstacle-Avoiding VLSI Global Routing Flow","abstract":"Routing is a crucial step in the VLSI design flow. With the advancement of manufacturing technologies, more constraints have emerged in design rules, particularly regarding obstacles during routing, leading to increased routing complexity. Unfortunately, many global routers struggle to efficiently generate obstacle-free solutions due to the lack of scalable obstacle-avoiding tree generation methods and the capability of handling modern designs with complex obstacles and nets. In this work, we propose an efficient obstacle-aware global routing flow for VLSI designs with obstacles. The flow includes a rule-based obstacle-avoiding rectilinear Steiner minimal tree (OARSMT) algorithm during the tree generation phase. This algorithm is both scalable and fast to provide tree topologies avoiding obstacles in the early stage globally. With its guidance, OARSMT-guided and obstacle-aware sparse maze routing are proposed in the later stages to minimize obstacle violations further and reduce overflow costs. Compared to advanced methods on the benchmark with obstacles, our approach successfully eliminates obstacle violations, and reduces wirelength and overflow cost, while sacrificing only a limited number of via counts and runtime overhead.","authors":["Junhao Guo","Hongxin Kong","Lang Feng"],"url":"https://arxiv.org/abs/2503.07268"}
{"created":"2025-05-12","title":"Self-Supervised Pretraining for Fine-Grained Plankton Recognition","abstract":"Plankton recognition is an important computer vision problem due to plankton's essential role in ocean food webs and carbon capture, highlighting the need for species-level monitoring. However, this task is challenging due to its fine-grained nature and dataset shifts caused by different imaging instruments and varying species distributions. As new plankton image datasets are collected at an increasing pace, there is a need for general plankton recognition models that require minimal expert effort for data labeling. In this work, we study large-scale self-supervised pretraining for fine-grained plankton recognition. We first employ masked autoencoding and a large volume of diverse plankton image data to pretrain a general-purpose plankton image encoder. Then we utilize fine-tuning to obtain accurate plankton recognition models for new datasets with a very limited number of labeled training images. Our experiments show that self-supervised pretraining with diverse plankton data clearly increases plankton recognition accuracy compared to standard ImageNet pretraining when the amount of training data is limited. Moreover, the accuracy can be further improved when unlabeled target data is available and utilized during the pretraining.","authors":["Joona Kareinen","Tuomas Eerola","Kaisa Kraft","Lasse Lensu","Sanna Suikkanen","Heikki K\\\"alvi\\\"ainen"],"url":"https://arxiv.org/abs/2503.11341"}
{"created":"2025-05-12","title":"Privacy-Preserved Automated Scoring using Federated Learning for Educational Research","abstract":"Data privacy remains a critical concern in educational research, requiring strict adherence to ethical standards and regulatory protocols. While traditional approaches rely on anonymization and centralized data collection, they often expose raw student data to security vulnerabilities and impose substantial logistical overhead. In this study, we propose a federated learning (FL) framework for automated scoring of educational assessments that eliminates the need to share sensitive data across institutions. Our approach leverages parameter-efficient fine-tuning of large language models (LLMs) with Low-Rank Adaptation (LoRA), enabling each client (school) to train locally while sharing only optimized model updates. To address data heterogeneity, we implement an adaptive weighted aggregation strategy that considers both client performance and data volume. We benchmark our model against two state-of-the-art FL methods and a centralized learning baseline using NGSS-aligned multi-label science assessment data from nine middle schools. Results show that our model achieves the highest accuracy (94.5%) among FL approaches, and performs within 0.5-1.0 percentage points of the centralized model on these metrics. Additionally, it achieves comparable rubric-level scoring accuracy, with only a 1.3% difference in rubric match and a lower score deviation (MAE), highlighting its effectiveness in preserving both prediction quality and interpretability.","authors":["Ehsan Latif","Xiaoming Zhai"],"url":"https://arxiv.org/abs/2503.11711"}
{"created":"2025-05-12","title":"A Systematic Approach for Multi-objective Double-side Clock Tree Synthesis","abstract":"As the scaling of semiconductor devices nears its limits, utilizing the back-side space of silicon has emerged as a new trend for future integrated circuits. With intense interest, several works have hacked existing backend tools to explore the potential of synthesizing double-side clock trees via nano Through-Silicon-Vias (nTSVs). However, these works lack a systematic perspective on design resource allocation and multi-objective optimization. We propose a systematic approach to design clock trees with double-side metal layers, including hierarchical clock routing, concurrent buffers and nTSVs insertion, and skew refinement. Compared with the state-of-the-art (SOTA) methods, the widely-used open-source tool, our algorithm outperforms them in latency, skew, wirelength, and the number of buffers and nTSVs.","authors":["Xun Jiang","Haoran Lu","Yuxuan Zhao","Jiarui Wang","Zizheng Guo","Heng Wu","Bei Yu","Sung Kyu Lim","Runsheng Wang","Ru Huang","Yibo Lin"],"url":"https://arxiv.org/abs/2503.12512"}
{"created":"2025-05-12","title":"Parameter Invariance Analysis of Moment Equations Using Dulmage-Mendelsohn Decomposition","abstract":"Living organisms maintain stable functioning amid environmental fluctuations through homeostasis, a property that preserves a system's behavior despite changes in environmental conditions. To elucidate homeostasis in stochastic biochemical reactions, theoretical tools for assessing population-level invariance under parameter perturbations are crucial. In this paper, we propose a systematic method for identifying the stationary moments that remain invariant under parameter perturbations by leveraging the structural properties of the stationary moment equations. A key step in this development is addressing the underdetermined nature of moment equations, which has traditionally made it difficult to characterize how stationary moments depend on system parameters. To overcome this, we utilize the Dulmage-Mendelsohn (DM) decomposition of the coefficient matrix to extract welldetermined subequations and reveal their hierarchical structure. Leveraging this structure, we identify stationary moments whose partial derivatives with respect to parameters are structurally zero, facilitating the exploration of fundamental constraints that govern homeostatic behavior in stochastic biochemical systems.","authors":["Akito Igarashi","Yutaka Hori"],"url":"https://arxiv.org/abs/2503.13336"}
{"created":"2025-05-12","title":"The Hidden Bloat in Machine Learning Systems","abstract":"Software bloat refers to code and features that is not used by a software during runtime. For Machine Learning (ML) systems, bloat is a major contributor to their technical debt leading to decreased performance and resource wastage. In this work, we present, Negativa-ML, a novel tool to identify and remove bloat in ML frameworks by analyzing their shared libraries. Our approach includes novel techniques to detect and locate unnecessary code within device code - a key area overlooked by existing research, which focuses primarily on host code. We evaluate Negativa-ML using four popular ML frameworks across ten workloads over 300 shared libraries. The results demonstrate that the ML frameworks are highly bloated on both the device and host code side. On average, Negativa-ML reduces the device code size in these frameworks by up to 75% and the host code by up to 72%, resulting in total file size reductions of up to 55%. The device code is a primary source of bloat within ML frameworks. Through debloating, we achieve reductions in peak host memory usage, peak GPU memory usage, and execution time by up to 74.6%, 69.6%, and 44.6%, respectively.","authors":["Huaifeng Zhang","Ahmed Ali-Eldin"],"url":"https://arxiv.org/abs/2503.14226"}
{"created":"2025-05-12","title":"Higher-Order Graphon Neural Networks: Approximation and Cut Distance","abstract":"Graph limit models, like graphons for limits of dense graphs, have recently been used to study size transferability of graph neural networks (GNNs). While most literature focuses on message passing GNNs (MPNNs), in this work we attend to the more powerful higher-order GNNs. First, we extend the $k$-WL test for graphons (B\\\"oker, 2023) to the graphon-signal space and introduce signal-weighted homomorphism densities as a key tool. As an exemplary focus, we generalize Invariant Graph Networks (IGNs) to graphons, proposing Invariant Graphon Networks (IWNs) defined via a subset of the IGN basis corresponding to bounded linear operators. Even with this restricted basis, we show that IWNs of order $k$ are at least as powerful as the $k$-WL test, and we establish universal approximation results for graphon-signals in $L^p$ distances. This significantly extends the prior work of Cai & Wang (2022), showing that IWNs--a subset of their IGN-small--retain effectively the same expressivity as the full IGN basis in the limit. In contrast to their approach, our blueprint of IWNs also aligns better with the geometry of graphon space, for example facilitating comparability to MPNNs. We highlight that, while typical higher-order GNNs are discontinuous w.r.t. cut distance--which causes their lack of convergence and is inherently tied to the definition of $k$-WL--transferability remains achievable.","authors":["Daniel Herbst","Stefanie Jegelka"],"url":"https://arxiv.org/abs/2503.14338"}
{"created":"2025-05-12","title":"ConvoGen: Enhancing Conversational AI with Synthetic Data: A Multi-Agent Approach","abstract":"In this paper, we present ConvoGen: an innovative framework for generating synthetic conversational data using multi-agent systems. Our method leverages few-shot learning and introduces iterative sampling from a dynamically updated few-shot hub to create diverse and realistic conversational scenarios. The generated data has numerous applications, including training and evaluating conversational AI models, and augmenting existing datasets for tasks like conversational intent classification or conversation summarization. Our experiments demonstrate the effectiveness of this method in producing high-quality diverse synthetic conversational data, highlighting its potential to enhance the development and evaluation of conversational AI systems.","authors":["Reem Gody","Mahmoud Goudy","Ahmed Y. Tawfik"],"url":"https://arxiv.org/abs/2503.17460"}
{"created":"2025-05-12","title":"UB-Mesh: a Hierarchically Localized nD-FullMesh Datacenter Network Architecture","abstract":"As the Large-scale Language Models (LLMs) continue to scale, the requisite computational power and bandwidth escalate. To address this, we introduce UB-Mesh, a novel AI datacenter network architecture designed to enhance scalability, performance, cost-efficiency and availability. Unlike traditional datacenters that provide symmetrical node-to-node bandwidth, UB-Mesh employs a hierarchically localized nD-FullMesh network topology. This design fully leverages the data locality of LLM training, prioritizing short-range, direct interconnects to minimize data movement distance and reduce switch usage.","authors":["Heng Liao","Bingyang Liu","Xianping Chen","Zhigang Guo","Chuanning Cheng","Jianbing Wang","Xiangyu Chen","Peng Dong","Rui Meng","Wenjie Liu","Zhe Zhou","Ziyang Zhang","Yuhang Gai","Cunle Qian","Yi Xiong","Zhongwu Cheng","Jing Xia","Yuli Ma","Xi Chen","Wenhua Du","Shizhong Xiao","Chungang Li","Yong Qin","Liudong Xiong","Zhou Yu","Lv Chen","Lei Chen","Buyun Wang","Pei Wu","Junen Gao","Xiaochu Li","Jian He","Shizhuan Yan","Bill McColl"],"url":"https://arxiv.org/abs/2503.20377"}
{"created":"2025-05-12","title":"MMMORRF: Multimodal Multilingual Modularized Reciprocal Rank Fusion","abstract":"Videos inherently contain multiple modalities, including visual events, text overlays, sounds, and speech, all of which are important for retrieval. However, state-of-the-art multimodal language models like VAST and LanguageBind are built on vision-language models (VLMs), and thus overly prioritize visual signals. Retrieval benchmarks further reinforce this bias by focusing on visual queries and neglecting other modalities. We create a search system MMMORRF that extracts text and features from both visual and audio modalities and integrates them with a novel modality-aware weighted reciprocal rank fusion. MMMORRF is both effective and efficient, demonstrating practicality in searching videos based on users' information needs instead of visual descriptive queries. We evaluate MMMORRF on MultiVENT 2.0 and TVR, two multimodal benchmarks designed for more targeted information needs, and find that it improves nDCG@20 by 81% over leading multimodal encoders and 37% over single-modality retrieval, demonstrating the value of integrating diverse modalities.","authors":["Saron Samuel","Dan DeGenaro","Jimena Guallar-Blasco","Kate Sanders","Oluwaseun Eisape","Tanner Spendlove","Arun Reddy","Alexander Martin","Andrew Yates","Eugene Yang","Cameron Carpenter","David Etter","Efsun Kayi","Matthew Wiesner","Kenton Murray","Reno Kriz"],"url":"https://arxiv.org/abs/2503.20698"}
{"created":"2025-05-12","title":"Rethinking Graph Structure Learning in the Era of LLMs","abstract":"Recently, the emergence of LLMs has prompted researchers to integrate language descriptions into graphs, aiming to enhance model encoding capabilities from a data-centric perspective. This graph representation is called text-attributed graphs (TAGs). A review of prior advancements highlights that graph structure learning (GSL) is a pivotal technique for improving data utility, making it highly relevant to efficient TAG learning. However, most GSL methods are tailored for traditional graphs without textual information, underscoring the necessity of developing a new GSL paradigm. Despite clear motivations, it remains challenging: (1) How can we define a reasonable optimization objective for GSL in the era of LLMs, considering the massive parameters in LLM? (2) How can we design an efficient model architecture that enables seamless integration of LLM for this optimization objective? For Question 1, we reformulate existing GSL optimization objectives as a tree optimization framework, shifting the focus from obtaining a well-trained edge predictor to a language-aware tree sampler. For Question 2, we propose decoupled and training-free model design principles for LLM integration, shifting the focus from computation-intensive fine-tuning to more efficient inference. Based on this, we propose Large Language and Tree Assistant (LLaTA), which leverages tree-based LLM in-context learning to enhance the understanding of topology and text, enabling reliable inference and generating improved graph structure. Extensive experiments on 10 datasets demonstrate that LLaTA enjoys flexibility-incorporated with any backbone; scalability-outperforms other LLM-enhanced graph learning methods; effectiveness-achieves SOTA predictive performance.","authors":["Zhihan Zhang","Xunkai Li","Zhu Lei","Guang Zeng","Ronghua Li","Guoren Wang"],"url":"https://arxiv.org/abs/2503.21223"}
{"created":"2025-05-12","title":"Benchmarking Ultra-Low-Power $\\mu$NPUs","abstract":"Efficient on-device neural network (NN) inference has various advantages over cloud-based processing, including predictable latency, enhanced privacy, greater reliability, and reduced operating costs for vendors. This has sparked the recent rapid development of microcontroller-scale NN accelerators, often referred to as neural processing units ($\\mu$NPUs), designed specifically for ultra-low-power applications.","authors":["Josh Millar","Yushan Huang","Sarab Sethi","Hamed Haddadi","Anil Madhavapeddy"],"url":"https://arxiv.org/abs/2503.22567"}
{"created":"2025-05-12","title":"From Flatland to Space: Teaching Vision-Language Models to Perceive and Reason in 3D","abstract":"Recent advances in LVLMs have improved vision-language understanding, but they still struggle with spatial perception, limiting their ability to reason about complex 3D scenes. Unlike previous approaches that incorporate 3D representations into models to improve spatial understanding, we aim to unlock the potential of VLMs by leveraging spatially relevant image data. To this end, we introduce a novel 2D spatial data generation and annotation pipeline built upon scene data with 3D ground-truth. This pipeline enables the creation of a diverse set of spatial tasks, ranging from basic perception tasks to more complex reasoning tasks. Leveraging this pipeline, we construct SPAR-7M, a large-scale dataset generated from thousands of scenes across multiple public datasets. In addition, we introduce SPAR-Bench, a benchmark designed to offer a more comprehensive evaluation of spatial capabilities compared to existing spatial benchmarks, supporting both single-view and multi-view inputs. Training on both SPAR-7M and large-scale 2D datasets enables our models to achieve state-of-the-art performance on 2D spatial benchmarks. Further fine-tuning on 3D task-specific datasets yields competitive results, underscoring the effectiveness of our dataset in enhancing spatial reasoning.","authors":["Jiahui Zhang","Yurui Chen","Yanpeng Zhou","Yueming Xu","Ze Huang","Jilin Mei","Junhui Chen","Yu-Jie Yuan","Xinyue Cai","Guowei Huang","Xingyue Quan","Hang Xu","Li Zhang"],"url":"https://arxiv.org/abs/2503.22976"}
{"created":"2025-05-12","title":"Foundation Models For Seismic Data Processing: An Extensive Review","abstract":"Seismic processing plays a crucial role in transforming raw data into high-quality subsurface images, pivotal for various geoscience applications. Despite its importance, traditional seismic processing techniques face challenges such as noisy and damaged data and the reliance on manual, time-consuming workflows. The emergence of deep learning approaches has introduced effective and user-friendly alternatives, yet many of these deep learning approaches rely on synthetic datasets and specialized neural networks. Recently, foundation models have gained traction in the seismic domain, due to their success in the natural image domain. Therefore, we investigate the application of natural image foundation models on the three seismic processing tasks: demultiple, interpolation, and denoising. We evaluate the impact of different model characteristics, such as pre-training technique and neural network architecture, on performance and efficiency. Rather than proposing a single seismic foundation model, we critically examine various natural image foundation models and suggest some promising candidates for future exploration.","authors":["Fabian Fuchs","Mario Ruben Fernandez","Norman Ettrich","Janis Keuper"],"url":"https://arxiv.org/abs/2503.24166"}
{"created":"2025-05-12","title":"Rec-R1: Bridging Generative Large Language Models and User-Centric Recommendation Systems via Reinforcement Learning","abstract":"We propose Rec-R1, a general reinforcement learning framework that bridges large language models (LLMs) with recommendation systems through closed-loop optimization. Unlike prompting and supervised fine-tuning (SFT), Rec-R1 directly optimizes LLM generation using feedback from a fixed black-box recommendation model, without relying on synthetic SFT data from proprietary models such as GPT-4o. This avoids the substantial cost and effort required for data distillation. To verify the effectiveness of Rec-R1, we evaluate it on two representative tasks: product search and sequential recommendation. Experimental results demonstrate that Rec-R1 not only consistently outperforms prompting- and SFT-based methods, but also achieves significant gains over strong discriminative baselines, even when used with simple retrievers such as BM25. Moreover, Rec-R1 preserves the general-purpose capabilities of the LLM, unlike SFT, which often impairs instruction-following and reasoning. These findings suggest Rec-R1 as a promising foundation for continual task-specific adaptation without catastrophic forgetting.","authors":["Jiacheng Lin","Tian Wang","Kun Qian"],"url":"https://arxiv.org/abs/2503.24289"}
{"created":"2025-05-12","title":"Repositioning, Ride-matching, and Abandonment in On-demand Ride-hailing Platforms: A Mean Field Game Approach","abstract":"The on-demand ride-hailing industry has experienced rapid growth, transforming transportation norms worldwide. Despite improvements in efficiency over traditional taxi services, significant challenges remain, including drivers' strategic repositioning behavior, customer abandonment, and inefficiencies in dispatch algorithms. To address these issues, we introduce a comprehensive mean field game model that systematically analyzes the dynamics of ride-hailing platforms by incorporating driver repositioning across multiple regions, customer abandonment behavior, and platform dispatch algorithms. Using this framework, we identify all possible mean field equilibria as the Karush-Kuhn-Tucker (KKT) points of an associated optimization problem. Our analysis reveals the emergence of multiple equilibria, including the inefficient \"Wild Goose Chase\" one, characterized by drivers pursuing distant requests, leading to suboptimal system performance. To mitigate these inefficiencies, we propose a novel two-matching-radius nearest-neighbor dispatch algorithm that eliminates undesirable equilibria and ensures a unique mean field equilibrium for multi-region systems. The algorithm dynamically adjusts matching radii based on driver supply rates, optimizing pick-up times and waiting times for drivers while maximizing request completion rates. Numerical experiments and simulation results show that our proposed algorithm reduces customer abandonment, minimizes waiting times for both customers and drivers, and improves overall platform efficiency.","authors":["Yunpeng Li","Antonis Dimakis","Costas A. Courcoubetis"],"url":"https://arxiv.org/abs/2504.02346"}
{"created":"2025-05-12","title":"From Observation to Orientation: an Adaptive Integer Programming Approach to Intervention Design","abstract":"Using both observational and experimental data, a causal discovery process can identify the causal relationships between variables. A unique adaptive intervention design paradigm is presented in this work, where causal directed acyclic graphs (DAGs) are for effectively recovered with practical budgetary considerations. In order to choose treatments that optimize information gain under these considerations, an iterative integer programming (IP) approach is proposed, which drastically reduces the number of experiments required. Simulations over a broad range of graph sizes and edge densities are used to assess the effectiveness of the suggested approach. Results show that the proposed adaptive IP approach achieves full causal graph recovery with fewer intervention iterations and variable manipulations than random intervention baselines, and it is also flexible enough to accommodate a variety of practical constraints.","authors":["Abdelmonem Elrefaey","Rong Pan"],"url":"https://arxiv.org/abs/2504.03122"}
{"created":"2025-05-12","title":"Directional Sign Loss: A Topology-Preserving Loss Function that Approximates the Sign of Finite Differences","abstract":"Preserving critical topological features in learned latent spaces is a fundamental challenge in representation learning, particularly for topology-sensitive data. This paper introduces directional sign loss (DSL), a novel loss function that approximates the number of mismatches in the signs of finite differences between corresponding elements of two arrays. By penalizing discrepancies in critical points between input and reconstructed data, DSL encourages autoencoders and other learnable compressors to retain the topological features of the original data. We present the mathematical formulation, complexity analysis, and practical implementation of DSL, comparing its behavior to its non-differentiable counterpart and to other topological measures. Experiments on one-, two-, and three-dimensional data show that combining DSL with traditional loss functions preserves topological features more effectively than traditional losses alone. Moreover, DSL serves as a differentiable, efficient proxy for common topology-based metrics, enabling its use in gradient-based optimization frameworks.","authors":["Harvey Dam","Tripti Agarwal","Ganesh Gopalakrishnan"],"url":"https://arxiv.org/abs/2504.04202"}
{"created":"2025-05-12","title":"AGITB: A Signal-Level Benchmark for Evaluating Artificial General Intelligence","abstract":"Despite remarkable progress in machine learning, current AI systems continue to fall short of true human-like intelligence. While Large Language Models (LLMs) excel in pattern recognition and response generation, they lack genuine understanding - an essential hallmark of Artificial General Intelligence (AGI). Existing AGI evaluation methods fail to offer a practical, gradual, and informative metric. This paper introduces the Artificial General Intelligence Test Bed (AGITB), comprising twelve rigorous tests that form a signal-processing-level foundation for the potential emergence of cognitive capabilities. AGITB evaluates intelligence through a model's ability to predict binary signals across time without relying on symbolic representations or pretraining. Unlike high-level tests grounded in language or perception, AGITB focuses on core computational invariants reflective of biological intelligence, such as determinism, sensitivity, and generalisation. The test bed assumes no prior bias, operates independently of semantic meaning, and ensures unsolvability through brute force or memorization. While humans pass AGITB by design, no current AI system has met its criteria, making AGITB a compelling benchmark for guiding and recognizing progress toward AGI.","authors":["Matej \\v{S}progar"],"url":"https://arxiv.org/abs/2504.04430"}
{"created":"2025-05-12","title":"Visualization of a multidimensional point cloud as a 3D swarm of avatars","abstract":"The article presents an innovative approach to the visualization of multidimensional data, using icons inspired by Chernoff faces. The approach merges classical projection techniques with the assignment of particular data dimensions to mimic features, capitalizing on the natural ability of the human brain to interpret facial expressions. We introduce a semantic division of data dimensions into intuitive and technical categories, assigning the former to avatar features and projecting the latter into a hyperspace of four, or potentially more dimensions. The technique is implemented as a plugin to the dpVision open-source image handling platform. The plugin allows the data to be interactively explored in the form of a swarm of avatars whose position in hyperspace as well as facial features represent various aspects of the data. Sample visualizations, based on synthetic test data as well as the 12-dimensional database on Portuguese Vinho Verde wines, confirm the usefulness of our approach to the analysis of complex data structures.","authors":["Leszek Luchowski","Dariusz Pojda"],"url":"https://arxiv.org/abs/2504.06751"}
{"created":"2025-05-12","title":"Drive in Corridors: Enhancing the Safety of End-to-end Autonomous Driving via Corridor Learning and Planning","abstract":"Safety remains one of the most critical challenges in autonomous driving systems. In recent years, the end-to-end driving has shown great promise in advancing vehicle autonomy in a scalable manner. However, existing approaches often face safety risks due to the lack of explicit behavior constraints. To address this issue, we uncover a new paradigm by introducing the corridor as the intermediate representation. Widely adopted in robotics planning, the corridors represents spatio-temporal obstacle-free zones for the vehicle to traverse. To ensure accurate corridor prediction in diverse traffic scenarios, we develop a comprehensive learning pipeline including data annotation, architecture refinement and loss formulation. The predicted corridor is further integrated as the constraint in a trajectory optimization process. By extending the differentiability of the optimization, we enable the optimized trajectory to be seamlessly trained within the end-to-end learning framework, improving both safety and interpretability. Experimental results on the nuScenes dataset demonstrate state-of-the-art performance of our approach, showing a 66.7% reduction in collisions with agents and a 46.5% reduction with curbs, significantly enhancing the safety of end-to-end driving. Additionally, incorporating the corridor contributes to higher success rates in closed-loop evaluations. Project page: https://zhiwei-pg.github.io/Drive-in-Corridors.","authors":["Zhiwei Zhang","Ruichen Yang","Ke Wu","Zijun Xu","Jingchu Liu","Lisen Mu","Zhongxue Gan","Wenchao Ding"],"url":"https://arxiv.org/abs/2504.07507"}
{"created":"2025-05-12","title":"Patch distribution modeling framework adaptive cosine estimator (PaDiM-ACE) for anomaly detection and localization in synthetic aperture radar imagery","abstract":"This work presents a new approach to anomaly detection and localization in synthetic aperture radar imagery (SAR), expanding upon the existing patch distribution modeling framework (PaDiM). We introduce the adaptive cosine estimator (ACE) detection statistic. PaDiM uses the Mahalanobis distance at inference, an unbounded metric. ACE instead uses the cosine similarity metric, providing bounded anomaly detection scores. The proposed method is evaluated across multiple SAR datasets, with performance metrics including the area under the receiver operating curve (AUROC) at the image and pixel level, aiming for increased performance in anomaly detection and localization of SAR imagery. The code is publicly available: https://github.com/Advanced-Vision-and-Learning-Lab/PaDiM-ACE.","authors":["Angelina Ibarra","Joshua Peeples"],"url":"https://arxiv.org/abs/2504.08049"}
{"created":"2025-05-12","title":"Quantifying the Spread of Online Incivility in Brazilian Politics","abstract":"Incivility refers to behaviors that violate collective norms and disrupt cooperation within the political process. Although large-scale online data and automated techniques have enabled the quantitative analysis of uncivil discourse, prior research has predominantly focused on impoliteness or toxicity, often overlooking other behaviors that undermine democratic values. To address this gap, we propose a multidimensional conceptual framework encompassing Impoliteness, Physical Harm and Violent Political Rhetoric, Hate Speech and Stereotyping, and Threats to Democratic Institutions and Values. Using this framework, we measure the spread of online political incivility in Brazil using approximately 5 million tweets posted by 2,307 political influencers during the 2022 Brazilian general election. Through statistical modeling and network analysis, we examine the dynamics of uncivil posts at different election stages, identify key disseminators and audiences, and explore the mechanisms driving the spread of uncivil information online. Our findings indicate that impoliteness is more likely to surge during election campaigns. In contrast, the other dimensions of incivility are often triggered by specific violent events. Moreover, we find that left-aligned individual influencers are the primary disseminators of online incivility in the Brazilian Twitter/X sphere and that they disseminate not only direct incivility but also indirect incivility when discussing or opposing incivility expressed by others. They relay those content from politicians, media agents, and individuals to reach broader audiences, revealing a diffusion pattern mixing the direct and two-step flows of communication theory. This study offers new insights into the multidimensional nature of incivility in Brazilian politics and provides a conceptual framework that can be extended to other political contexts.","authors":["Yuan Zhang","Michael Amsler","Laia Castro Herrero","Frank Esser","Alexandre Bovet"],"url":"https://arxiv.org/abs/2504.08960"}
{"created":"2025-05-12","title":"Towards Human-Centered Early Prediction Models for Academic Performance in Real-World Contexts","abstract":"Supporting student success requires collaboration among multiple stakeholders. Researchers have explored machine learning models for academic performance prediction; yet key challenges remain in ensuring these models are interpretable, equitable, and actionable within real-world educational support systems. First, many models prioritize predictive accuracy but overlook human-centered machine learning principles, limiting trust among students and reducing their usefulness for educators and institutional decision-makers. Second, most models require at least a month of data before making reliable predictions, delaying opportunities for early intervention. Third, current models primarily rely on sporadically collected, classroom-derived data, missing broader behavioral patterns that could provide more continuous and actionable insights. To address these gaps, we present three modeling approaches-LR, 1D-CNN, and MTL-1D-CNN-to classify students as low or high academic performers. We evaluate them based on explainability, fairness, and generalizability to assess their alignment with key social values. Using behavioral and self-reported data collected within the first week of two Spring terms, we demonstrate that these models can identify at-risk students as early as week one. However, trade-offs across human-centered machine learning principles highlight the complexity of designing predictive models that effectively support multi-stakeholder decision-making and intervention strategies. We discuss these trade-offs and their implications for different stakeholders, outlining how predictive models can be integrated into student support systems. Finally, we examine broader socio-technical challenges in deploying these models and propose future directions for advancing human-centered, collaborative academic prediction systems.","authors":["Han Zhang","Yiyi Ren","Paula S. Nurius","Jennifer Mankoff","Anind K. Dey"],"url":"https://arxiv.org/abs/2504.12236"}
{"created":"2025-05-12","title":"Reimagining Urban Science: Scaling Causal Inference with Large Language Models","abstract":"Urban causal research is essential for understanding the complex dynamics of cities and informing evidence-based policies. However, it is challenged by the inefficiency and bias of hypothesis generation, barriers to multimodal data complexity, and the methodological fragility of causal experimentation. Recent advances in large language models (LLMs) present an opportunity to rethink how urban causal analysis is conducted. This Perspective examines current urban causal research by analyzing taxonomies that categorize research topics, data sources, and methodological approaches to identify structural gaps. We then introduce an LLM-driven conceptual framework, AutoUrbanCI, composed of four distinct modular agents responsible for hypothesis generation, data engineering, experiment design and execution, and results interpretation with policy recommendations. We propose evaluation criteria for rigor and transparency and reflect on implications for human-AI collaboration, equity, and accountability. We call for a new research agenda that embraces AI-augmented workflows not as replacements for human expertise but as tools to broaden participation, improve reproducibility, and unlock more inclusive forms of urban causal reasoning.","authors":["Yutong Xia","Ao Qu","Yunhan Zheng","Yihong Tang","Dingyi Zhuang","Yuxuan Liang","Shenhao Wang","Cathy Wu","Lijun Sun","Roger Zimmermann","Jinhua Zhao"],"url":"https://arxiv.org/abs/2504.12345"}
{"created":"2025-05-12","title":"Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding","abstract":"High-level 3D scene understanding is essential in many applications. However, the challenges of generating accurate 3D annotations make development of deep learning models difficult. We turn to recent advancements in automatic retrieval of synthetic CAD models, and show that data generated by such methods can be used as high-quality ground truth for training supervised deep learning models. More exactly, we employ a pipeline akin to the one previously used to automatically annotate objects in ScanNet scenes with their 9D poses and CAD models. This time, we apply it to the recent ScanNet++ v1 dataset, which previously lacked such annotations. Our findings demonstrate that it is not only possible to train deep learning models on these automatically-obtained annotations but that the resulting models outperform those trained on manually annotated data. We validate this on two distinct tasks: point cloud completion and single-view CAD model retrieval and alignment. Our results underscore the potential of automatic 3D annotations to enhance model performance while significantly reducing annotation costs. To support future research in 3D scene understanding, we will release our annotations, which we call SCANnotate++, along with our trained models.","authors":["Yuchen Rao","Stefan Ainetter","Sinisa Stekovic","Vincent Lepetit","Friedrich Fraundorfer"],"url":"https://arxiv.org/abs/2504.13580"}
{"created":"2025-05-12","title":"RadioDiff-Inverse: Diffusion Enhanced Bayesian Inverse Estimation for ISAC Radio Map Construction","abstract":"Radio maps (RMs) are essential for environment-aware communication and sensing, providing location-specific wireless channel information. Existing RM construction methods often rely on precise environmental data and base station (BS) locations, which are not always available in dynamic or privacy-sensitive environments. While sparse measurement techniques reduce data collection, the impact of noise in sparse data on RM accuracy is not well understood. This paper addresses these challenges by formulating RM construction as a Bayesian inverse problem under coarse environmental knowledge and noisy sparse measurements. Although maximum a posteriori (MAP) filtering offers an optimal solution, it requires a precise prior distribution of the RM, which is typically unavailable. To solve this, we propose RadioDiff-Inverse, a diffusion-enhanced Bayesian inverse estimation framework that uses an unconditional generative diffusion model to learn the RM prior. This approach not only reconstructs the spatial distribution of wireless channel features but also enables environmental structure perception, such as building outlines, and location of BS just relay on pathloss, through integrated sensing and communication (ISAC). Remarkably, RadioDiff-Inverse is training-free, leveraging a pre-trained model from Imagenet without task-specific fine-tuning, which significantly reduces the training cost of using generative large model in wireless networks. Experimental results demonstrate that RadioDiff-Inverse achieves state-of-the-art performance in accuracy of RM construction and environmental reconstruction, and robustness against noisy sparse sampling.","authors":["Xiucheng Wang (Sherman)","Zhongsheng Fang (Sherman)","Nan Cheng (Sherman)","Ruijin Sun (Sherman)","Zan Li (Sherman)","Xuemin (Sherman)","Shen"],"url":"https://arxiv.org/abs/2504.14298"}
{"created":"2025-05-12","title":"Planet as a Brain: Towards Internet of AgentSites based on AIOS Server","abstract":"The internet is undergoing a historical transformation from the \"Internet of Websites\" to the \"Internet of AgentSites.\" While traditional Websites served as the foundation for information hosting and dissemination, a new frontier is emerging where AgentSites serve as the hubs of the internet, where each AgentSite hosts one or more AI agents that receive tasks, address them, and deliver actionable solutions, marking a significant shift in the digital landscape and representing the next generation of online ecosystems. Under this vision, AIOS, the AI Agent Operating System, serves as the server for the development, deployment and execution of AI agents, which is a fundamental infrastructure for the Internet of Agentsites.","authors":["Xiang Zhang","Yongfeng Zhang"],"url":"https://arxiv.org/abs/2504.14411"}
{"created":"2025-05-12","title":"SCALE-Sim v3: A modular cycle-accurate systolic accelerator simulator for end-to-end system analysis","abstract":"The rapid advancements in AI, scientific computing, and high-performance computing (HPC) have driven the need for versatile and efficient hardware accelerators. Existing tools like SCALE-Sim v2 provide valuable cycle-accurate simulations for systolic-array-based architectures but fall short in supporting key modern features such as sparsity, multi-core scalability, and comprehensive memory analysis. To address these limitations, we present SCALE-Sim v3, a modular, cycle-accurate simulator that extends the capabilities of its predecessor. SCALE-Sim v3 introduces five significant enhancements: multi-core simulation with spatio-temporal partitioning and hierarchical memory structures, support for sparse matrix multiplications (SpMM) with layer-wise and row-wise sparsity, integration with Ramulator for detailed DRAM analysis, precise data layout modeling to minimize memory stalls, and energy and power estimation via Accelergy. These improvements enable deeper end-to-end system analysis for modern AI accelerators, accommodating a wide variety of systems and workloads and providing detailed full-system insights into latency, bandwidth, and power efficiency.","authors":["Ritik Raj","Sarbartha Banerjee","Nikhil Chandra","Zishen Wan","Jianming Tong","Ananda Samajdar","Tushar Krishna"],"url":"https://arxiv.org/abs/2504.15377"}
{"created":"2025-05-12","title":"Utilizing Dynamic Time Warping for Pandemic Surveillance: Understanding the Relationship between Google Trends Network Metrics and COVID-19 Incidences","abstract":"The premise of network statistics derived from Google Trends data to foresee COVID-19 disease progression is gaining momentum in infodemiology. This approach was applied in Metro Manila, National Capital Region, Philippines. Through dynamic time warping (DTW), the temporal alignment was quantified between network metrics and COVID-19 case trajectories, and systematically explored 320 parameter configurations including two network metrics (network density and clustering coefficient), two data preprocessing methods (Rescaling Daily Data and MSV), multiple thresholds, two correlation window sizes, and Sakoe-Chiba band constraints. Results from the Kruskal-Wallis tests revealed that five of the six parameters significantly influenced alignment quality, with the disease comparison type (active cases vs. confirmed cases) demonstrating the strongest effect. The optimal configuration, which is using the network density statistic with a Rescaling Daily Data transformation, a threshold of 0.8, a 15-day window, and a 50-day radius constraint, achieved a DTW score of 36.30. This indicated substantial temporal alignment with the COVID-19 confirmed cases data. The discoveries demonstrate that network metrics rooted from online search behavior can serve as complementary indicators for epidemic surveillance in urban locations like Metro Manila. This strategy leverages the Philippines' extensive online usage during the pandemic to provide potentially valuable early signals of disease spread, and offers a supplementary tool for public health monitoring in resource-limited situations.","authors":["Michael T. Lopez II","Cheska Elise Hung","Maria Regina Justina E. Estuar"],"url":"https://arxiv.org/abs/2504.17146"}
{"created":"2025-05-12","title":"Fr\\'echet Distance in Unweighted Planar Graphs","abstract":"The Fr\\'echet distance is a distance measure between trajectories in the plane or walks in a graph G. Given constant-time shortest path queries in a graph G, the Discrete Fr\\'echet distance $F_G(P, Q)$ between two walks P and Q can be computed in $O(|P| \\cdot |Q|)$ time using a dynamic program. Driemel, van der Hoog, and Rotenberg [SoCG'22] show that for weighted planar graphs this approach is likely tight, as there can be no strongly subquadratic algorithm to compute a $1.01$-approximation of $F_G(P, Q)$ unless the Orthogonal Vector Hypothesis (OVH) fails.","authors":["Ivor van der Hoog","Thijs van der Horst","Eva Rotenberg","Lasse Wulf"],"url":"https://arxiv.org/abs/2504.17342"}
{"created":"2025-05-12","title":"Reliable and Efficient Inverse Analysis using Physics-Informed Neural Networks with Distance Functions and Adaptive Weight Tuning","abstract":"Physics-informed neural networks have attracted significant attention in scientific machine learning for their capability to solve forward and inverse problems governed by partial differential equations. However, the accuracy of PINN solutions is often limited by the treatment of boundary conditions. Conventional penalty-based methods, which incorporate boundary conditions as penalty terms in the loss function, cannot guarantee exact satisfaction of the given boundary conditions and are highly sensitive to the choice of penalty parameters. This paper demonstrates that distance functions, specifically R-functions, can be leveraged to enforce boundary conditions, overcoming these limitations. R-functions provide normalized distance fields, enabling accurate representation of boundary geometries, including non-convex domains, and facilitating various types of boundary conditions. We extend this distance function-based boundary condition imposition method to inverse problems using PINNs and introduce an adaptive weight tuning technique to ensure reliable and efficient inverse analysis. We demonstrate the efficacy of the method through several numerical experiments. Numerical results show that the proposed method solves inverse problems more accurately and efficiently than penalty-based methods, even in the presence of complex non-convex geometries. This approach offers a reliable and efficient framework for inverse analysis using PINNs, with potential applications across a wide range of engineering problems.","authors":["Shota Deguchi","Mitsuteru Asai"],"url":"https://arxiv.org/abs/2504.18091"}
{"created":"2025-05-12","title":"Scaling Laws For Scalable Oversight","abstract":"Scalable oversight, the process by which weaker AI systems supervise stronger ones, has been proposed as a key strategy to control future superintelligent systems. However, it is still unclear how scalable oversight itself scales. To address this gap, we propose a framework that quantifies the probability of successful oversight as a function of the capabilities of the overseer and the system being overseen. Specifically, our framework models oversight as a game between capability-mismatched players; the players have oversight-specific Elo scores that are a piecewise-linear function of their general intelligence, with two plateaus corresponding to task incompetence and task saturation. We validate our framework with a modified version of the game Nim and then apply it to four oversight games: Mafia, Debate, Backdoor Code and Wargames. For each game, we find scaling laws that approximate how domain performance depends on general AI system capability. We then build on our findings in a theoretical study of Nested Scalable Oversight (NSO), a process in which trusted models oversee untrusted stronger models, which then become the trusted models in the next step. We identify conditions under which NSO succeeds and derive numerically (and in some cases analytically) the optimal number of oversight levels to maximize the probability of oversight success. We also apply our theory to our four oversight games, where we find that NSO success rates at a general Elo gap of 400 are 13.5% for Mafia, 51.7% for Debate, 10.0% for Backdoor Code, and 9.4% for Wargames; these rates decline further when overseeing stronger systems.","authors":["Joshua Engels","David D. Baek","Subhash Kantamneni","Max Tegmark"],"url":"https://arxiv.org/abs/2504.18530"}
{"created":"2025-05-12","title":"QuickGrasp: Lightweight Antipodal Grasp Planning with Point Clouds","abstract":"Grasping has been a long-standing challenge in facilitating the final interface between a robot and the environment. As environments and tasks become complicated, the need to embed higher intelligence to infer from the surroundings and act on them has become necessary. Although most methods utilize techniques to estimate grasp pose by treating the problem via pure sampling-based approaches in the six-degree-of-freedom space or as a learning problem, they usually fail in real-life settings owing to poor generalization across domains. In addition, the time taken to generate the grasp plan and the lack of repeatability, owing to sampling inefficiency and the probabilistic nature of existing grasp planning approaches, severely limits their application in real-world tasks. This paper presents a lightweight analytical approach towards robotic grasp planning, particularly antipodal grasps, with little to no sampling in the six-degree-of-freedom space. The proposed grasp planning algorithm is formulated as an optimization problem towards estimating grasp points on the object surface instead of directly estimating the end-effector pose. To this extent, a soft-region-growing algorithm is presented for effective plane segmentation, even in the case of curved surfaces. An optimization-based quality metric is then used for the evaluation of grasp points to ensure indirect force closure. The proposed grasp framework is compared with the existing state-of-the-art grasp planning approach, Grasp pose detection (GPD), as a baseline over multiple simulated objects. The effectiveness of the proposed approach in comparison to GPD is also evaluated in a real-world setting using image and point-cloud data, with the planned grasps being executed using a ROBOTIQ gripper and UR5 manipulator.","authors":["Navin Sriram Ravie","Keerthi Vasan M","Asokan Thondiyath","Bijo Sebastian"],"url":"https://arxiv.org/abs/2504.19716"}
{"created":"2025-05-12","title":"Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage","abstract":"This paper proposes a novel interdisciplinary framework for analyzing police body-worn camera (BWC) footage from the Rochester Police Department (RPD) using advanced artificial intelligence (AI) and statistical machine learning (ML) techniques. Our goal is to detect, classify, and analyze patterns of interaction between police officers and civilians to identify key behavioral dynamics, such as respect, disrespect, escalation, and de-escalation. We apply multimodal data analysis by integrating video, audio, and natural language processing (NLP) techniques to extract meaningful insights from BWC footage. We present our methodology, computational techniques, and findings, outlining a practical approach for law enforcement while advancing the frontiers of knowledge discovery from police BWC data.","authors":["Anita Srbinovska","Angela Srbinovska","Vivek Senthil","Adrian Martin","John McCluskey","Jonathan Bateman","Ernest Fokou\\'e"],"url":"https://arxiv.org/abs/2504.20007"}
{"created":"2025-05-12","title":"Enhanced semi-supervised stamping process monitoring with physically-informed feature extraction","abstract":"In tackling frequent batch anomalies in high-speed stamping processes, this study introduces a novel semi-supervised in-process anomaly monitoring framework, utilizing accelerometer signals and physics information, to capture the process anomaly effectively. The proposed framework facilitates the construction of a monitoring model with imbalanced sample distribution, which enables in-process condition monitoring in real-time to prevent batch anomalies, which helps to reduce batch defects risk and enhance production yield. Firstly, to effectively capture key features from raw data containing redundant information, a hybrid feature extraction algorithm is proposed to utilize data-driven methods and physical mechanisms simultaneously. Secondly, to address the challenge brought by imbalanced sample distribution, a semi-supervised anomaly detection model is established, which merely employs normal samples to build a golden baseline model, and a novel deviation score is proposed to quantify the anomaly level of each online stamping stroke. The effectiveness of the proposed feature extraction method is validated with various classification algorithms. A real-world in-process dataset from stamping manufacturing workshop is employed to illustrate the superiority of proposed semi-supervised framework with enhance performance for process anomaly monitoring.","authors":["Jianyu Zhang"],"url":"https://arxiv.org/abs/2504.21389"}
{"created":"2025-05-12","title":"RWKV-X: A Linear Complexity Hybrid Language Model","abstract":"In this paper, we introduce RWKV-X, a novel hybrid architecture that combines the efficiency of RWKV for short-range modeling with a sparse attention mechanism designed to capture long-range context. Unlike previous hybrid approaches that rely on full attention layers and retain quadratic complexity, RWKV-X achieves linear-time complexity in training and constant-time complexity in inference decoding. We demonstrate that RWKV-X, when continually pretrained on 64K-token sequences, achieves near-perfect accuracy on the 64K passkey retrieval benchmark. It consistently outperforms prior RWKV-7 models on long-context benchmarks, while maintaining strong performance on short-context tasks. These results highlight RWKV-X as a scalable and efficient backbone for general-purpose language modeling, capable of decoding sequences up to 1 million tokens with stable speed and memory usage. To facilitate further research and analysis, we have made the checkpoints and the associated code publicly accessible at: https://github.com/howard-hou/RWKV-X.","authors":["Haowen Hou","Zhiyi Huang","Kaifeng Tan","Rongchang Lu","Fei Richard Yu"],"url":"https://arxiv.org/abs/2504.21463"}
{"created":"2025-05-12","title":"3D Hand-Eye Calibration for Collaborative Robot Arm: Look at Robot Base Once","abstract":"Hand-eye calibration is a common problem in the field of collaborative robotics, involving the determination of the transformation matrix between the visual sensor and the robot flange to enable vision-based robotic tasks. However, this process typically requires multiple movements of the robot arm and an external calibration object, making it both time-consuming and inconvenient, especially in scenarios where frequent recalibration is necessary. In this work, we extend our previous method which eliminates the need for external calibration objects such as a chessboard. We propose a generic dataset generation approach for point cloud registration, focusing on aligning the robot base point cloud with the scanned data. Furthermore, a more detailed simulation study is conducted involving several different collaborative robot arms, followed by real-world experiments in an industrial setting. Our improved method is simulated and evaluated using a total of 14 robotic arms from 9 different brands, including KUKA, Universal Robots, UFACTORY, and Franka Emika, all of which are widely used in the field of collaborative robotics. Physical experiments demonstrate that our extended approach achieves performance comparable to existing commercial hand-eye calibration solutions, while completing the entire calibration procedure in just a few seconds. In addition, we provide a user-friendly hand-eye calibration solution, with the code publicly available at github.com/leihui6/LRBO.","authors":["Leihui Li","Lixuepiao Wan","Volker Krueger","Xuping Zhang"],"url":"https://arxiv.org/abs/2504.21619"}
{"created":"2025-05-12","title":"Gateformer: Advancing Multivariate Time Series Forecasting through Temporal and Variate-Wise Attention with Gated Representations","abstract":"There has been a recent surge of interest in time series modeling using the Transformer architecture. However, forecasting multivariate time series with Transformer presents a unique challenge as it requires modeling both temporal (cross-time) and variate (cross-variate) dependencies. While Transformer-based models have gained popularity for their flexibility in capturing both sequential and cross-variate relationships, it is unclear how to best integrate these two sources of information in the context of the Transformer architecture while optimizing for both performance and efficiency. We re-purpose the Transformer architecture to effectively model both cross-time and cross-variate dependencies. Our approach begins by embedding each variate independently into a variate-wise representation that captures its cross-time dynamics, and then models cross-variate dependencies through attention mechanisms on these learned embeddings. Gating operations in both cross-time and cross-variate modeling phases regulate information flow, allowing the model to focus on the most relevant features for accurate predictions. Our method achieves state-of-the-art performance across 13 real-world datasets and can be seamlessly integrated into other Transformer-based and LLM-based forecasters, delivering performance improvements up to 20.7\\% over original models. Code is available at this repository: https://github.com/nyuolab/Gateformer.","authors":["Yu-Hsiang Lan","Eric K. Oermann"],"url":"https://arxiv.org/abs/2505.00307"}
{"created":"2025-05-12","title":"Active Contact Engagement for Aerial Navigation in Unknown Environments with Glass","abstract":"Autonomous aerial robots are increasingly being deployed in real-world scenarios, where transparent glass obstacles present significant challenges to reliable navigation. Researchers have investigated the use of non-contact sensors and passive contact-resilient aerial vehicle designs to detect glass surfaces, which are often limited in terms of robustness and efficiency. In this work, we propose a novel approach for robust autonomous aerial navigation in unknown environments with transparent glass obstacles, combining the strengths of both sensor-based and contact-based glass detection. The proposed system begins with the incremental detection and information maintenance about potential glass surfaces using visual sensor measurements. The vehicle then actively engages in touch actions with the visually detected potential glass surfaces using a pair of lightweight contact-sensing modules to confirm or invalidate their presence. Following this, the volumetric map is efficiently updated with the glass surface information and safe trajectories are replanned on the fly to circumvent the glass obstacles. We validate the proposed system through real-world experiments in various scenarios, demonstrating its effectiveness in enabling efficient and robust autonomous aerial navigation in complex real-world environments with glass obstacles.","authors":["Xinyi Chen","Yichen Zhang","Hetai Zou","Junzhe Wang","Shaojie Shen"],"url":"https://arxiv.org/abs/2505.00332"}
{"created":"2025-05-12","title":"Vehicular Communication Security: Multi-Channel and Multi-Factor Authentication","abstract":"Secure and reliable communications are crucial for Intelligent Transportation Systems (ITSs), where Vehicle-to-Infrastructure (V2I) communication plays a key role in enabling mobility-enhancing and safety-critical services. Current V2I authentication relies on credential-based methods over wireless Non-Line-of-Sight (NLOS) channels, leaving them exposed to remote impersonation and proximity attacks. To mitigate these risks, we propose a unified Multi-Channel, Multi-Factor Authentication (MFA) scheme that combines NLOS cryptographic credentials with a Line-of-Sight (LOS) visual channel. Our approach leverages a challenge-response security paradigm: the infrastructure issues challenges and the vehicle's headlights respond by flashing a structured sequence containing encoded security data. Deep learning models on the infrastructure side then decode the embedded information to authenticate the vehicle. Real-world experimental evaluations demonstrate high test accuracy, reaching an average of 95% and 96.6%, respectively, under various lighting, weather, speed, and distance conditions. Additionally, we conducted extensive experiments on three state-of-the-art deep learning models, including detailed ablation studies for decoding the flashing sequence. Our results indicate that the optimal architecture employs a dual-channel design, enabling simultaneous decoding of the flashing sequence and extraction of vehicle spatial and locational features for robust authentication.","authors":["Marco De Vincenzi","Shuyang Sun","Chen Bo Calvin Zhang","Manuel Garcia","Shaozu Ding","Chiara Bodei","Ilaria Matteucci","Sanjay E. Sarma","Dajiang Suo"],"url":"https://arxiv.org/abs/2505.00340"}
{"created":"2025-05-12","title":"Improving the scalability of a high-order atmospheric dynamics solver based on the deal.II library","abstract":"We present recent advances on the massively parallel performance of a numerical scheme for atmosphere dynamics applications based on the deal.II library. The implicit-explicit discontinuous finite element scheme is based on a matrix-free approach, meaning that no global sparse matrix is built and only the action of the linear operators on a vector is actually implemented. Following a profiling analysis, we focus on the performance optimization of the numerical method and describe the impact of different preconditioning and solving techniques in this framework. Moreover, we show how the use of the latest version of the deal.II library and of suitable execution flags can improve the parallel performance.","authors":["Giuseppe Orlando","Tommaso Benacchio","Luca Bonaventura"],"url":"https://arxiv.org/abs/2505.00384"}
{"created":"2025-05-12","title":"Machine Learning Meets Transparency in Osteoporosis Risk Assessment: A Comparative Study of ML and Explainability Analysis","abstract":"The present research tackles the difficulty of predicting osteoporosis risk via machine learning (ML) approaches, emphasizing the use of explainable artificial intelligence (XAI) to improve model transparency. Osteoporosis is a significant public health concern, sometimes remaining untreated owing to its asymptomatic characteristics, and early identification is essential to avert fractures. The research assesses six machine learning classifiers: Random Forest, Logistic Regression, XGBoost, AdaBoost, LightGBM, and Gradient Boosting and utilizes a dataset based on clinical, demographic, and lifestyle variables. The models are refined using GridSearchCV to calibrate hyperparameters, with the objective of enhancing predictive efficacy. XGBoost had the greatest accuracy (91%) among the evaluated models, surpassing others in precision (0.92), recall (0.91), and F1-score (0.90). The research further integrates XAI approaches, such as SHAP, LIME, and Permutation Feature Importance, to elucidate the decision-making process of the optimal model. The study indicates that age is the primary determinant in forecasting osteoporosis risk, followed by hormonal alterations and familial history. These results corroborate clinical knowledge and affirm the models' therapeutic significance. The research underscores the significance of explainability in machine learning models for healthcare applications, guaranteeing that physicians can rely on the system's predictions. The report ultimately proposes directions for further research, such as validation across varied populations and the integration of supplementary biomarkers for enhanced predictive accuracy.","authors":["Farhana Elias","Md Shihab Reza","Muhammad Zawad Mahmud","Samiha Islam","Shahran Rahman Alve"],"url":"https://arxiv.org/abs/2505.00410"}
{"created":"2025-05-12","title":"Steering Large Language Models with Register Analysis for Arbitrary Style Transfer","abstract":"Large Language Models (LLMs) have demonstrated strong capabilities in rewriting text across various styles. However, effectively leveraging this ability for example-based arbitrary style transfer, where an input text is rewritten to match the style of a given exemplar, remains an open challenge. A key question is how to describe the style of the exemplar to guide LLMs toward high-quality rewrites. In this work, we propose a prompting method based on register analysis to guide LLMs to perform this task. Empirical evaluations across multiple style transfer tasks show that our prompting approach enhances style transfer strength while preserving meaning more effectively than existing prompting strategies.","authors":["Xinchen Yang","Marine Carpuat"],"url":"https://arxiv.org/abs/2505.00679"}
{"created":"2025-05-12","title":"Carbon Aware Transformers Through Joint Model-Hardware Optimization","abstract":"The rapid growth of machine learning (ML) systems necessitates a more comprehensive evaluation of their environmental impact, particularly their carbon footprint, which comprises operational carbon from training and inference execution and embodied carbon from hardware manufacturing and its entire life-cycle. Despite the increasing importance of embodied emissions, there is a lack of tools and frameworks to holistically quantify and optimize the total carbon footprint of ML systems. To address this, we propose CATransformers, a carbon-aware architecture search framework that enables sustainability-driven co-optimization of ML models and hardware architectures. By incorporating both operational and embodied carbon metrics into early design space exploration of domain-specific hardware accelerators, CATransformers demonstrates that optimizing for carbon yields design choices distinct from those optimized solely for latency or energy efficiency. We apply our framework to multi-modal CLIP-based models, producing CarbonCLIP, a family of CLIP models achieving up to 17% reduction in total carbon emissions while maintaining accuracy and latency compared to state-of-the-art edge small CLIP baselines. This work underscores the need for holistic optimization methods to design high-performance, environmentally sustainable AI systems.","authors":["Irene Wang","Newsha Ardalani","Mostafa Elhoushi","Daniel Jiang","Samuel Hsia","Ekin Sumbul","Divya Mahajan","Carole-Jean Wu","Bilge Acun"],"url":"https://arxiv.org/abs/2505.01386"}
{"created":"2025-05-12","title":"Sparsification Under Siege: Defending Against Poisoning Attacks in Communication-Efficient Federated Learning","abstract":"Federated Learning (FL) enables collaborative model training across distributed clients while preserving data privacy, yet it faces significant challenges in communication efficiency and vulnerability to poisoning attacks. While sparsification techniques mitigate communication overhead by transmitting only critical model parameters, they inadvertently amplify security risks: adversarial clients can exploit sparse updates to evade detection and degrade model performance. Existing defense mechanisms, designed for standard FL communication scenarios, are ineffective in addressing these vulnerabilities within sparsified FL. To bridge this gap, we propose FLARE, a novel federated learning framework that integrates sparse index mask inspection and model update sign similarity analysis to detect and mitigate poisoning attacks in sparsified FL. Extensive experiments across multiple datasets and adversarial scenarios demonstrate that FLARE significantly outperforms existing defense strategies, effectively securing sparsified FL against poisoning attacks while maintaining communication efficiency.","authors":["Zhiyong Jin","Runhua Xu","Chao Li","Yizhong Liu","Jianxin Li"],"url":"https://arxiv.org/abs/2505.01454"}
{"created":"2025-05-12","title":"UK Finfluencers: Exploring Content, Reach, and Responsibility","abstract":"The rise of social media financial influencers (finfluencers) has significantly transformed the personal finance landscape, making financial advice and insights more accessible to a broader and younger audience. By leveraging digital platforms, these influencers have contributed to the democratization of financial literacy. However, the line between education and promotion is often blurred, as many finfluencers lack formal financial qualifications, raising concerns about the accuracy and reliability of the information they share. This study investigates the patterns and behaviours of finfluencers in the UK on TikTok, focusing not on individual actions but on broader trends and the interactions between influencers and their followers. The aim is to identify common engagement patterns and propose guidelines that can help protect the public from potential financial harm. Specifically, the paper contributes a detailed analysis of finfluencer content categorization, sentiment trends, and the prevalence and role of disclaimers, offering empirical insights that inform recommendations for safer and more transparent financial communication on social media.","authors":["Essam Ghadafi","Panagiotis Andriotis"],"url":"https://arxiv.org/abs/2505.01941"}
{"created":"2025-05-12","title":"Subspace Aggregation Query and Index Generation for Multidimensional Resource Space Model","abstract":"Organizing resources in a multidimensional classification space is an approach to efficiently managing and querying large-scale resources. This paper defines an aggregation query on subspace defined by a range on the partial order on coordinate tree at each dimension, where each point contains resources aggregated along the paths of partial order relations on the points so that aggregated resources at each point within the subspace can be measured, ranked and selected. To efficiently locate non-empty points in a large subspace, an approach to generating graph index is proposed to build inclusion links with partial order relations on coordinates of dimensions to enable a subspace query to reach non-empty points by following indexing links and aggregate resources along indexing paths back to their super points. Generating such an index is costly as the number of children of an index node can be very large so that the total number of indexing nodes is unbounded. The proposed approach adopts the following strategies to reduce the cost: (1) adding intersection links between two indexing nodes, which can better reduce query processing costs while controlling the number of nodes of the graph index; (2) intersection links are added between two nodes according to the probabilistic distribution calculated for estimating the costs of adding intersection between two nodes; (3) coordinates at one dimension having more resources are split by coordinates at another dimension to balance the number of resources hold by indexing nodes; and, (4) short-cut links are added between sibling coordinates of coordinate trees to make an efficient query on linear order coordinates. Analysis and experiments verified the effectiveness of the generated index in supporting subspace aggregation query. This work makes significant contributions to the development of data model based on multi-dimensional classification.","authors":["Xiaoping Sun","Hai Zhuge"],"url":"https://arxiv.org/abs/2505.02129"}
{"created":"2025-05-12","title":"Enhancing AI Face Realism: Cost-Efficient Quality Improvement in Distilled Diffusion Models with a Fully Synthetic Dataset","abstract":"This study presents a novel approach to enhance the cost-to-quality ratio of image generation with diffusion models. We hypothesize that differences between distilled (e.g. FLUX.1-schnell) and baseline (e.g. FLUX.1-dev) models are consistent and, therefore, learnable within a specialized domain, like portrait generation. We generate a synthetic paired dataset and train a fast image-to-image translation head. Using two sets of low- and high-quality synthetic images, our model is trained to refine the output of a distilled generator (e.g., FLUX.1-schnell) to a level comparable to a baseline model like FLUX.1-dev, which is more computationally intensive. Our results show that the pipeline, which combines a distilled version of a large generative model with our enhancement layer, delivers similar photorealistic portraits to the baseline version with up to an 82% decrease in computational cost compared to FLUX.1-dev. This study demonstrates the potential for improving the efficiency of AI solutions involving large-scale image generation.","authors":["Jakub Wasala","Bartlomiej Wrzalski","Kornelia Noculak","Yuliia Tarasenko","Oliwer Krupa","Jan Kocon","Grzegorz Chodak"],"url":"https://arxiv.org/abs/2505.02255"}
{"created":"2025-05-12","title":"Moneros Decentralized P2P Exchanges: Functionality, Adoption, and Privacy Risks","abstract":"Privacy-focused cryptocurrencies like Monero remain popular, despite increasing regulatory scrutiny that has led to their delisting from major centralized exchanges. The latter also explains the recent popularity of decentralized exchanges (DEXs) with no centralized ownership structures. These platforms typically leverage peer-to-peer (P2P) networks, promising secure and anonymous asset trading. However, questions of liability remain, and the academic literature lacks comprehensive insights into the functionality, trading activity, and privacy claims of these P2P platforms. In this paper, we provide an early systematization of the current landscape of decentralized peer-to-peer exchanges within the Monero ecosystem. We examine several recently developed DEX platforms, analyzing their popularity, functionality, architectural choices, and potential weaknesses. We further identify and report on a privacy vulnerability in the recently popularized Haveno exchange, demonstrating that certain Haveno trades could be detected, allowing transactions to be linked across the Monero and Bitcoin blockchains. We hope that our findings can nourish the discussion in the research community about more secure designs, and provide insights for regulators.","authors":["Yannik Kopyciok","Friedhelm Victor","Stefan Schmid"],"url":"https://arxiv.org/abs/2505.02392"}
{"created":"2025-05-12","title":"Bielik 11B v2 Technical Report","abstract":"We present Bielik 11B v2, a state-of-the-art language model optimized for Polish text processing. Built on the Mistral 7B v0.2 architecture and scaled to 11B parameters using depth up-scaling, this model demonstrates exceptional performance across Polish language benchmarks while maintaining strong cross-lingual capabilities. We introduce two key technical innovations: Weighted Instruction Cross-Entropy Loss, which optimizes learning across diverse instruction types by assigning quality-based weights to training examples, and Adaptive Learning Rate, which dynamically adjusts based on context length. Comprehensive evaluation across multiple benchmarks demonstrates that Bielik 11B v2 outperforms many larger models, including those with 2-6 times more parameters, and significantly surpasses other specialized Polish language models on tasks ranging from linguistic understanding to complex reasoning. The model's parameter efficiency and extensive quantization options enable deployment across various hardware configurations, advancing Polish language AI capabilities and establishing new benchmarks for resource-efficient language modeling in less-represented languages.","authors":["Krzysztof Ociepa","{\\L}ukasz Flis","Krzysztof Wr\\'obel","Adrian Gwo\\'zdziej","Remigiusz Kinas"],"url":"https://arxiv.org/abs/2505.02410"}
{"created":"2025-05-12","title":"Marker-Based Extrinsic Calibration Method for Accurate Multi-Camera 3D Reconstruction","abstract":"Accurate 3D reconstruction using multi-camera RGB-D systems critically depends on precise extrinsic calibration to achieve proper alignment between captured views. In this paper, we introduce an iterative extrinsic calibration method that leverages the geometric constraints provided by a three-dimensional marker to significantly improve calibration accuracy. Our proposed approach systematically segments and refines marker planes through clustering, regression analysis, and iterative reassignment techniques, ensuring robust geometric correspondence across camera views. We validate our method comprehensively in both controlled environments and practical real-world settings within the Tech4Diet project, aimed at modeling the physical progression of patients undergoing nutritional treatments. Experimental results demonstrate substantial reductions in alignment errors, facilitating accurate and reliable 3D reconstructions.","authors":["Nahuel Garcia-D'Urso","Bernabe Sanchez-Sos","Jorge Azorin-Lopez","Andres Fuster-Guillo","Antonio Macia-Lillo","Higinio Mora-Mora"],"url":"https://arxiv.org/abs/2505.02539"}
{"created":"2025-05-12","title":"Bielik v3 Small: Technical Report","abstract":"We introduce Bielik v3, a series of parameter-efficient generative text models (1.5B and 4.5B) optimized for Polish language processing. These models demonstrate that smaller, well-optimized architectures can achieve performance comparable to much larger counterparts while requiring substantially fewer computational resources. Our approach incorporates several key innovations: a custom Polish tokenizer (APT4) that significantly improves token efficiency, Weighted Instruction Cross-Entropy Loss to balance learning across instruction types, and Adaptive Learning Rate that dynamically adjusts based on training progress. Trained on a meticulously curated corpus of 292 billion tokens spanning 303 million documents, these models excel across multiple benchmarks, including the Open PL LLM Leaderboard, Complex Polish Text Understanding Benchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter model achieves results competitive with models 2-3 times its size, while the 1.5B model delivers strong performance despite its extremely compact profile. These advances establish new benchmarks for parameter-efficient language modeling in less-represented languages, making high-quality Polish language AI more accessible for resource-constrained applications.","authors":["Krzysztof Ociepa","{\\L}ukasz Flis","Remigiusz Kinas","Krzysztof Wr\\'obel","Adrian Gwo\\'zdziej"],"url":"https://arxiv.org/abs/2505.02550"}
{"created":"2025-05-12","title":"ReplaceMe: Network Simplification via Layer Pruning and Linear Transformations","abstract":"We introduce ReplaceMe, a generalized training-free depth pruning method that effectively replaces transformer blocks with a linear operation, while maintaining high performance for low compression ratios. In contrast to conventional pruning approaches that require additional training or fine-tuning, our approach requires only a small calibration dataset that is used to estimate a linear transformation to approximate the pruned blocks. This estimated linear mapping can be seamlessly merged with the remaining transformer blocks, eliminating the need for any additional network parameters. Our experiments show that ReplaceMe consistently outperforms other training-free approaches and remains highly competitive with state-of-the-art pruning methods that involve extensive retraining/fine-tuning and architectural modifications. Applied to several large language models (LLMs), ReplaceMe achieves up to 25% pruning while retaining approximately 90% of the original model's performance on open benchmarks - without any training or healing steps, resulting in minimal computational overhead (see Fig.1). We provide an open-source library implementing ReplaceMe alongside several state-of-the-art depth pruning techniques, available at this repository.","authors":["Dmitriy Shopkhoev","Ammar Ali","Magauiya Zhussip","Valentin Malykh","Stamatios Lefkimmiatis","Nikos Komodakis","Sergey Zagoruyko"],"url":"https://arxiv.org/abs/2505.02819"}
{"created":"2025-05-12","title":"R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning","abstract":"Multimodal Reward Models (MRMs) play a crucial role in enhancing the performance of Multimodal Large Language Models (MLLMs). While recent advancements have primarily focused on improving the model structure and training data of MRMs, there has been limited exploration into the effectiveness of long-term reasoning capabilities for reward modeling and how to activate these capabilities in MRMs. In this paper, we explore how Reinforcement Learning (RL) can be used to improve reward modeling. Specifically, we reformulate the reward modeling problem as a rule-based RL task. However, we observe that directly applying existing RL algorithms, such as Reinforce++, to reward modeling often leads to training instability or even collapse due to the inherent limitations of these algorithms. To address this issue, we propose the StableReinforce algorithm, which refines the training loss, advantage estimation strategy, and reward design of existing RL methods. These refinements result in more stable training dynamics and superior performance. To facilitate MRM training, we collect 200K preference data from diverse datasets. Our reward model, R1-Reward, trained using the StableReinforce algorithm on this dataset, significantly improves performance on multimodal reward modeling benchmarks. Compared to previous SOTA models, R1-Reward achieves a $8.4\\%$ improvement on the VL Reward-Bench and a $14.3\\%$ improvement on the Multimodal Reward Bench. Moreover, with more inference compute, R1-Reward's performance is further enhanced, highlighting the potential of RL algorithms in optimizing MRMs.","authors":["Yi-Fan Zhang","Xingyu Lu","Xiao Hu","Chaoyou Fu","Bin Wen","Tianke Zhang","Changyi Liu","Kaiyu Jiang","Kaibing Chen","Kaiyu Tang","Haojie Ding","Jiankang Chen","Fan Yang","Zhang Zhang","Tingting Gao","Liang Wang"],"url":"https://arxiv.org/abs/2505.02835"}
{"created":"2025-05-12","title":"Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models","abstract":"Assessing how well a large language model (LLM) understands human, rather than merely text, remains an open challenge. To bridge the gap, we introduce Sentient Agent as a Judge (SAGE), an automated evaluation framework that measures an LLM's higher-order social cognition. SAGE instantiates a Sentient Agent that simulates human-like emotional changes and inner thoughts during interaction, providing a more realistic evaluation of the tested model in multi-turn conversations. At every turn, the agent reasons about (i) how its emotion changes, (ii) how it feels, and (iii) how it should reply, yielding a numerical emotion trajectory and interpretable inner thoughts. Experiments on 100 supportive-dialogue scenarios show that the final Sentient emotion score correlates strongly with Barrett-Lennard Relationship Inventory (BLRI) ratings and utterance-level empathy metrics, validating psychological fidelity. We also build a public Sentient Leaderboard covering 18 commercial and open-source models that uncovers substantial gaps (up to 4x) between frontier systems (GPT-4o-Latest, Gemini2.5-Pro) and earlier baselines, gaps not reflected in conventional leaderboards (e.g., Arena). SAGE thus provides a principled, scalable and interpretable tool for tracking progress toward genuinely empathetic and socially adept language agents.","authors":["Bang Zhang","Ruotian Ma","Qingxuan Jiang","Peisong Wang","Jiaqi Chen","Zheng Xie","Xingyu Chen","Yue Wang","Fanghua Ye","Jian Li","Yifan Yang","Zhaopeng Tu","Xiaolong Li"],"url":"https://arxiv.org/abs/2505.02847"}
{"created":"2025-05-12","title":"AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning","abstract":"Critical peer review of scientific manuscripts presents a significant challenge for Large Language Models (LLMs), partly due to data limitations and the complexity of expert reasoning. This report introduces Persistent Workflow Prompting (PWP), a potentially broadly applicable prompt engineering methodology designed to bridge this gap using standard LLM chat interfaces (zero-code, no APIs). We present a proof-of-concept PWP prompt for the critical analysis of experimental chemistry manuscripts, featuring a hierarchical, modular architecture (structured via Markdown) that defines detailed analysis workflows. We develop this PWP prompt through iterative application of meta-prompting techniques and meta-reasoning aimed at systematically codifying expert review workflows, including tacit knowledge. Submitted once at the start of a session, this PWP prompt equips the LLM with persistent workflows triggered by subsequent queries, guiding modern reasoning LLMs through systematic, multimodal evaluations. Demonstrations show the PWP-guided LLM identifying major methodological flaws in a test case while mitigating LLM input bias and performing complex tasks, including distinguishing claims from evidence, integrating text/photo/figure analysis to infer parameters, executing quantitative feasibility checks, comparing estimates against claims, and assessing a priori plausibility. To ensure transparency and facilitate replication, we provide full prompts, detailed demonstration analyses, and logs of interactive chats as supplementary resources. Beyond the specific application, this work offers insights into the meta-development process itself, highlighting the potential of PWP, informed by detailed workflow formalization, to enable sophisticated analysis using readily available LLMs for complex scientific tasks.","authors":["Evgeny Markhasin"],"url":"https://arxiv.org/abs/2505.03332"}
{"created":"2025-05-12","title":"Enhancing Target-unspecific Tasks through a Features Matrix","abstract":"Recent developments in prompt learning of large vision-language models have significantly improved performance in target-specific tasks. However, these prompt optimizing methods often struggle to tackle the target-unspecific or generalizable tasks effectively. It may be attributed to the fact that overfitting training causes the model to forget its general knowledge having strong promotion on target-unspecific tasks. To alleviate this issue, we propose a novel Features Matrix (FM) regularization approach designed to enhance these models on target-unspecific tasks. Our method extracts and leverages general knowledge, shaping a Features Matrix (FM). Specifically, the FM captures the semantics of diverse inputs from a deep and fine perspective, preserving essential general knowledge, which mitigates the risk of overfitting. Representative evaluations demonstrate that: 1) the FM is compatible with existing frameworks as a generic and flexible module, and 2) the FM significantly showcases its effectiveness in enhancing target-unspecific tasks, achieving state-of-the-art performance.","authors":["Fangming Cui","Yonggang Zhang","Xuan Wang","Xinmei Tian","Jun Yu"],"url":"https://arxiv.org/abs/2505.03414"}
{"created":"2025-05-12","title":"Data-efficient inverse design of spinodoid metamaterials","abstract":"We create an data-efficient and accurate surrogate model for structure-property linkages of spinodoid metamaterials with only 75 data points -- far fewer than the several thousands used in prior works -- and demonstrate its use in multi-objective inverse design. The inverse problem of finding a material microstructure that leads to given bulk properties is of great interest in mechanics and materials science. These inverse design tasks often require a large dataset, which can become unaffordable when considering material behavior that requires more expensive simulations or experiments. We generate a data-efficient surrogate for the mapping between the characteristics of the local material structure and the effective elasticity tensor and use it to inversely design structures with multiple objectives simultaneously. The presented neural network-based surrogate model achieves its data efficiency by inherently satisfying certain requirements, such as equivariance with respect to permutations of structure parameters, which avoids having to learn them from data. The resulting surrogate of the forward model is differentiable, allowing its direct use in gradient-based optimization for the inverse design problem. We demonstrate in three inverse design tasks of varying complexity that this approach yields reliable results while requiring significantly less training data than previous approaches based on neural-network surrogates. This paves the way for inverse design involving nonlinear mechanical behavior, where data efficiency is currently the limiting factor.","authors":["Max Rosenkranz","Markus K\\\"astner","Ivo F. Sbalzarini"],"url":"https://arxiv.org/abs/2505.03415"}
{"created":"2025-05-12","title":"Rainbow Delay Compensation: A Multi-Agent Reinforcement Learning Framework for Mitigating Delayed Observation","abstract":"In real-world multi-agent systems (MASs), observation delays are ubiquitous, preventing agents from making decisions based on the environment's true state. An individual agent's local observation often consists of multiple components from other agents or dynamic entities in the environment. These discrete observation components with varying delay characteristics pose significant challenges for multi-agent reinforcement learning (MARL). In this paper, we first formulate the decentralized stochastic individual delay partially observable Markov decision process (DSID-POMDP) by extending the standard Dec-POMDP. We then propose the Rainbow Delay Compensation (RDC), a MARL training framework for addressing stochastic individual delays, along with recommended implementations for its constituent modules. We implement the DSID-POMDP's observation generation pattern using standard MARL benchmarks, including MPE and SMAC. Experiments demonstrate that baseline MARL methods suffer severe performance degradation under fixed and unfixed delays. The RDC-enhanced approach mitigates this issue, remarkably achieving ideal delay-free performance in certain delay scenarios while maintaining generalizability. Our work provides a novel perspective on multi-agent delayed observation problems and offers an effective solution framework. The source code is available at https://anonymous.4open.science/r/RDC-pymarl-4512/.","authors":["Songchen Fu","Siang Chen","Shaojing Zhao","Letian Bai","Ta Li","Yonghong Yan"],"url":"https://arxiv.org/abs/2505.03586"}
{"created":"2025-05-12","title":"Sick of being driven? -- Prevalence and modulating factors of carsickness in the European population in context of automated driving","abstract":"As in automated driving the driver becomes a passenger, carsickness might reduce comfort for susceptible individuals. Insights in the prevalence of carsickness and its modulating factors are considered useful for the development of automated vehicles to mitigate or prevent its occurrence. An online survey was conducted with N = 3999 participants in Spain, Sweden, Poland, and Germany. 30% of participants reported to have already experienced carsickness as adult. The frequency of carsickness was modulated not only by demographic factors (country, gender, age), but also by frequency of being a passenger, type of non-driving related task, road type, and the seating position in car. Furthermore, the efficiency of applied countermeasures, temporal aspects of carsickness development, as well as the relation of carsickness with the acceptability of automated driving and the effect on subjective fitness to drive was investigated. The results are discussed with focus on automated driving.","authors":["Myriam Metzulat","Barbara Metz","Aaron Edelmann","Alexandra Neukum","Wilfried Kunde"],"url":"https://arxiv.org/abs/2505.04210"}
{"created":"2025-05-12","title":"Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration","abstract":"Training data cleaning is a new application for generative model-based speech restoration (SR). This paper introduces Miipher-2, an SR model designed for million-hour scale data, for training data cleaning for large-scale generative models like large language models. Key challenges addressed include generalization to unseen languages, operation without explicit conditioning (e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a frozen, pre-trained Universal Speech Model (USM), supporting over 300 languages, as a robust, conditioning-free feature extractor. To optimize efficiency and minimize memory, Miipher-2 incorporates parallel adapters for predicting clean USM features from noisy inputs and employs the WaveFit neural vocoder for waveform synthesis. These components were trained on 3,000 hours of multi-lingual, studio-quality recordings with augmented degradations, while USM parameters remained fixed. Experimental results demonstrate Miipher-2's superior or comparable performance to conventional SR models in word-error-rate, speaker similarity, and both objective and subjective sound quality scores across all tested languages. Miipher-2 operates efficiently on consumer-grade accelerators, achieving a real-time factor of 0.0078, enabling the processing of a million-hour speech dataset in approximately three days using only 100 such accelerators.","authors":["Shigeki Karita","Yuma Koizumi","Heiga Zen","Haruko Ishikawa","Robin Scheibler","Michiel Bacchiani"],"url":"https://arxiv.org/abs/2505.04457"}
{"created":"2025-05-12","title":"Software Development Life Cycle Perspective: A Survey of Benchmarks for Code Large Language Models and Agents","abstract":"Code large language models (CodeLLMs) and agents have shown great promise in tackling complex software engineering tasks.Compared to traditional software engineering methods, CodeLLMs and agents offer stronger abilities, and can flexibly process inputs and outputs in both natural and code. Benchmarking plays a crucial role in evaluating the capabilities of CodeLLMs and agents, guiding their development and deployment. However, despite their growing significance, there remains a lack of comprehensive reviews of benchmarks for CodeLLMs and agents. To bridge this gap, this paper provides a comprehensive review of existing benchmarks for CodeLLMs and agents, studying and analyzing 181 benchmarks from 461 relevant papers, covering the different phases of the software development life cycle (SDLC). Our findings reveal a notable imbalance in the coverage of current benchmarks, with approximately 60% focused on the software development phase in SDLC, while requirements engineering and software design phases receive minimal attention at only 5% and 3%, respectively. Additionally, Python emerges as the dominant programming language across the reviewed benchmarks. Finally, this paper highlights the challenges of current research and proposes future directions, aiming to narrow the gap between the theoretical capabilities of CodeLLMs and agents and their application in real-world scenarios.","authors":["Kaixin Wang","Tianlin Li","Xiaoyu Zhang","Chong Wang","Weisong Sun","Yang Liu","Bin Shi"],"url":"https://arxiv.org/abs/2505.05283"}
{"created":"2025-05-12","title":"Timestamp Manipulation: Timestamp-based Nakamoto-style Blockchains are Vulnerable","abstract":"We introduce two advanced attack strategies, the Unrestricted Uncle Maker (UUM) Attack and the Staircase-Unrestricted Uncle Maker (SUUM) Attack, which fundamentally threaten the security of timestamp-based Nakamoto-style blockchains by inflicting permanent systemic harm. Unlike prior work that merely enhances adversarial rewards, these attacks exploit vulnerabilities in timestamp manipulation and fork selection rules to irreversibly destabilize blockchain fairness and incentive mechanisms. Specifically, the SUUM attack enables adversaries to persistently launch attacks at zero cost, eliminating constraints on block withholding and risk-free conditions, while systematically maximizing rewards through coordinated timestamp adjustments and strategic block release.","authors":["Junjie Hu","Na Ruan"],"url":"https://arxiv.org/abs/2505.05328"}
{"created":"2025-05-12","title":"LiTransProQA: an LLM-based Literary Translation evaluation metric with Professional Question Answering","abstract":"The impact of Large Language Models (LLMs) has extended into literary domains. However, existing evaluation metrics prioritize mechanical accuracy over artistic expression and tend to overrate machine translation (MT) as being superior to experienced professional human translation. In the long run, this bias could result in a permanent decline in translation quality and cultural authenticity. In response to the urgent need for a specialized literary evaluation metric, we introduce LiTransProQA, a novel, reference-free, LLM-based question-answering framework designed specifically for literary translation evaluation. LiTransProQA uniquely integrates insights from professional literary translators and researchers, focusing on critical elements in literary quality assessment such as literary devices, cultural understanding, and authorial voice. Our extensive evaluation shows that while literary-finetuned XCOMET-XL yields marginal gains, LiTransProQA substantially outperforms current metrics, achieving up to 0.07 gain in correlation (ACC-EQ and Kendall's tau) and surpassing the best state-of-the-art metrics by over 15 points in adequacy assessments. Incorporating professional translator insights as weights further improves performance, highlighting the value of translator inputs. Notably, LiTransProQA approaches human-level evaluation performance comparable to trained linguistic annotators. It demonstrates broad applicability to open-source models such as LLaMA3.3-70b and Qwen2.5-32b, indicating its potential as an accessible and training-free literary evaluation metric and a valuable tool for evaluating texts that require local processing due to copyright or ethical considerations.","authors":["Ran Zhang","Wei Zhao","Lieve Macken","Steffen Eger"],"url":"https://arxiv.org/abs/2505.05423"}
{"created":"2025-05-12","title":"Sparse inverse Cholesky factorization of dense kernel matrices by greedy conditional selection","abstract":"Dense kernel matrices resulting from pairwise evaluations of a kernel function arise naturally in machine learning and statistics. Previous work in constructing sparse approximate inverse Cholesky factors of such matrices by minimizing Kullback-Leibler divergence recovers the Vecchia approximation for Gaussian processes. These methods rely only on the geometry of the evaluation points to construct the sparsity pattern. In this work, we instead construct the sparsity pattern by leveraging a greedy selection algorithm that maximizes mutual information with target points, conditional on all points previously selected. For selecting $k$ points out of $N$, the naive time complexity is $\\mathcal{O}(N k^4)$, but by maintaining a partial Cholesky factor we reduce this to $\\mathcal{O}(N k^2)$. Furthermore, for multiple ($m$) targets we achieve a time complexity of $\\mathcal{O}(N k^2 + N m^2 + m^3)$, which is maintained in the setting of aggregated Cholesky factorization where a selected point need not condition every target. We apply the selection algorithm to image classification and recovery of sparse Cholesky factors. By minimizing Kullback-Leibler divergence, we apply the algorithm to Cholesky factorization, Gaussian process regression, and preconditioning with the conjugate gradient, improving over $k$-nearest neighbors selection.","authors":["Stephen Huan","Joseph Guinness","Matthias Katzfuss","Houman Owhadi","Florian Sch\\\"afer"],"url":"https://arxiv.org/abs/2307.11648"}
{"created":"2025-05-12","title":"Divisible minimal codes","abstract":"Minimal codes are linear codes where all non-zero codewords are minimal, i.e., whose support is not properly contained in the support of another codeword. The minimum possible length of such a $k$-dimensional linear code over $\\mathbb{F}_q$ is denoted by $m(k,q)$. Here we determine $m(7,2)$, $m(8,2)$, and $m(9,2)$, as well as full classifications of all codes attaining $m(k,2)$ for $k\\le 7$ and those attaining $m(9,2)$. We give improved upper bounds for $m(k,2)$ for all $10\\le k\\le 17$. It turns out that in many cases the attaining extremal codes have the property that the weights of all codewords are divisible by some constant $\\Delta>1$. So, here we study the minimum lengths of minimal codes where we additionally assume that the weights of the codewords are divisible by $\\Delta$. As a byproduct we also give a few binary linear codes improving the best known lower bound for the minimum distance.","authors":["Vladimir Chubenko","Sascha Kurz"],"url":"https://arxiv.org/abs/2312.00885"}
{"created":"2025-05-12","title":"Human Perception-Inspired Grain Segmentation Refinement Using Conditional Random Fields","abstract":"Automated detection of grain boundaries in electron microscope images of polycrystalline materials could help accelerate the nanoscale characterization of myriad engineering materials and novel materials under scientific research. Accurate segmentation of interconnected line networks, such as grain boundaries in polycrystalline material microstructures, poses a significant challenge due to the fragmented masks produced by conventional computer vision algorithms, including convolutional neural networks. These algorithms struggle with thin masks, often necessitating post-processing for effective contour closure and continuity. Previous approaches in this domain have typically relied on custom post-processing techniques that are problem-specific and heavily dependent on the quality of the mask obtained from a computer vision algorithm. Addressing this issue, this paper introduces a fast, high-fidelity post-processing technique that is universally applicable to segmentation masks of interconnected line networks. Leveraging domain knowledge about grain boundary connectivity, this method employs conditional random fields and perceptual grouping rules to refine segmentation masks of any image with a discernible grain structure. This approach significantly enhances segmentation mask accuracy, achieving a 79% segment identification accuracy in validation with a U-Net model on electron microscopy images of a polycrystalline oxide. Additionally, a novel grain alignment metric is introduced, showing a 51% improvement in grain alignment. This method not only enables rapid and accurate segmentation but also facilitates an unprecedented level of data analysis, significantly improving the statistical representation of grain boundary networks, making it suitable for a range of disciplines where precise segmentation of interconnected line networks is essential.","authors":["Doruk Aksoy","Huolin L. Xin","Timothy J. Rupert","William J. Bowman"],"url":"https://arxiv.org/abs/2312.09968"}
{"created":"2025-05-12","title":"Digital-analog quantum learning on Rydberg atom arrays","abstract":"We propose hybrid digital-analog learning algorithms on Rydberg atom arrays, combining the potentially practical utility and near-term realizability of quantum learning with the rapidly scaling architectures of neutral atoms. Our construction requires only single-qubit operations in the digital setting and global driving according to the Rydberg Hamiltonian in the analog setting. We perform a comprehensive numerical study of our algorithm on both classical and quantum data, given respectively by handwritten digit classification and unsupervised quantum phase boundary learning. We show in the two representative problems that digital-analog learning is not only feasible in the near term, but also requires shorter circuit depths and is more robust to realistic error models as compared to digital learning schemes. Our results suggest that digital-analog learning opens a promising path towards improved variational quantum learning experiments in the near term.","authors":["Jonathan Z. Lu","Lucy Jiao","Kristina Wolinski","Milan Kornja\\v{c}a","Hong-Ye Hu","Sergio Cantu","Fangli Liu","Susanne F. Yelin","Sheng-Tao Wang"],"url":"https://arxiv.org/abs/2401.02940"}
{"created":"2025-05-12","title":"Generalizable Sleep Staging via Multi-Level Domain Alignment","abstract":"Automatic sleep staging is essential for sleep assessment and disorder diagnosis. Most existing methods depend on one specific dataset and are limited to be generalized to other unseen datasets, for which the training data and testing data are from the same dataset. In this paper, we introduce domain generalization into automatic sleep staging and propose the task of generalizable sleep staging which aims to improve the model generalization ability to unseen datasets. Inspired by existing domain generalization methods, we adopt the feature alignment idea and propose a framework called SleepDG to solve it. Considering both of local salient features and sequential features are important for sleep staging, we propose a Multi-level Feature Alignment combining epoch-level and sequence-level feature alignment to learn domain-invariant feature representations. Specifically, we design an Epoch-level Feature Alignment to align the feature distribution of each single sleep epoch among different domains, and a Sequence-level Feature Alignment to minimize the discrepancy of sequential features among different domains. SleepDG is validated on five public datasets, achieving the state-of-the-art performance.","authors":["Jiquan Wang","Sha Zhao","Haiteng Jiang","Shijian Li","Tao Li","Gang Pan"],"url":"https://arxiv.org/abs/2401.05363"}
{"created":"2025-05-12","title":"Grid Minors and Products","abstract":"Motivated by recent developments regarding the product structure of planar graphs, we study relationships between treewidth, grid minors, and graph products. We show that the Cartesian product of any two connected $n$-vertex graphs contains an $\\Omega(\\sqrt{n})\\times\\Omega(\\sqrt{n})$ grid minor. This result is tight: The lexicographic product (which includes the Cartesian product as a subgraph) of a star and any $n$-vertex tree has no $\\omega(\\sqrt{n})\\times\\omega(\\sqrt{n})$ grid minor.","authors":["Vida Dujmovi\\'c","Pat Morin","David R. Wood","David Worley"],"url":"https://arxiv.org/abs/2402.14181"}
{"created":"2025-05-12","title":"Noise sensitivity on affine Weyl groups","abstract":"We show that on every affine Weyl group natural random walks are noise sensitive in total variation.","authors":["Ryokichi Tanaka"],"url":"https://arxiv.org/abs/2403.01658"}
{"created":"2025-05-12","title":"Convergence of Decentralized Stochastic Subgradient-based Methods for Nonsmooth Nonconvex functions","abstract":"In this paper, we focus on the decentralized stochastic subgradient-based methods in minimizing nonsmooth nonconvex functions without Clarke regularity, especially in the decentralized training of nonsmooth neural networks. We propose a general framework that unifies various decentralized subgradient-based methods, such as decentralized stochastic subgradient descent (DSGD), DSGD with gradient-tracking technique (DSGD-T), and DSGD with momentum (DSGD-M). To establish the convergence properties of our proposed framework, we relate the discrete iterates to the trajectories of a continuous-time differential inclusion, which is assumed to have a coercive Lyapunov function with a stable set $\\mathcal{A}$. We prove the asymptotic convergence of the iterates to the stable set $\\mathcal{A}$ with sufficiently small and diminishing step-sizes. These results provide first convergence guarantees for some well-recognized of decentralized stochastic subgradient-based methods without Clarke regularity of the objective function. Preliminary numerical experiments demonstrate that our proposed framework yields highly efficient decentralized stochastic subgradient-based methods with convergence guarantees in the training of nonsmooth neural networks.","authors":["Siyuan Zhang","Nachuan Xiao","Xin Liu"],"url":"https://arxiv.org/abs/2403.11565"}
{"created":"2025-05-12","title":"A First-Order Gradient Approach for the Connectivity Optimization of Markov Chains","abstract":"Graphs are commonly used to model various complex systems, including social networks, power grids, transportation networks, and biological systems. In many applications, the connectivity of these networks can be expressed through the Mean First Passage Times (MFPTs) of a Markov chain modeling a random walker on the graph. In this paper, we generalize the network metrics based on Markov chains' MFPTs and extend them to networks affected by uncertainty, in which edges may fail and hence not be present according to a pre-determined stochastic model. To find optimally connected Markov chains, we present a parameterization-free method for optimizing the MFPTs of the Markov chain. More specifically, we present an efficient Simultaneous Perturbation Stochastic Approximation (SPSA) algorithm in the context of Markov chain optimization. The proposed algorithm is suitable for both fixed and random networks. Using various numerical experiments, we demonstrate scalability compared to established benchmarks. Importantly, our algorithm finds an optimal solution without requiring prior knowledge of edge failure probabilities, allowing for an online optimization approach.","authors":["Christian P. C. Franssen","Alessandro Zocca","Bernd F. Heidergott"],"url":"https://arxiv.org/abs/2403.11744"}
{"created":"2025-05-12","title":"Using iterated local alignment to aggregate trajectory data into a traffic flow map","abstract":"Vehicle trajectories, with their detailed geolocations, are a promising data source to compute traffic flow maps at scales ranging from the city/regional level to the road level. The main obstacle is that trajectory data are prone to measurement noise. While this is negligible for city level large-scale flow aggregation, it poses substantial difficulties for road level small-scale aggregation. To overcome these difficulties, we introduce innovative local alignment algorithms, where we infer road segments to serve as local reference segments, and proceed to align nearby road segments to them. We deploy these algorithms in an iterative workflow to compute locally aligned flow maps. By applying this workflow to synthetic and empirical trajectories, we verify that our locally aligned flow maps provide high levels of accuracy and spatial resolution of flow aggregation at multiple scales for static and interactive maps.","authors":["Tarn Duong"],"url":"https://arxiv.org/abs/2406.17500"}
{"created":"2025-05-12","title":"Speed-accuracy relations for diffusion models: Wisdom from nonequilibrium thermodynamics and optimal transport","abstract":"We discuss a connection between a generative model, called the diffusion model, and nonequilibrium thermodynamics for the Fokker-Planck equation, called stochastic thermodynamics. Using techniques from stochastic thermodynamics, we derive the speed-accuracy relations for diffusion models, which are inequalities that relate the accuracy of data generation to the entropy production rate. This relation can be interpreted as the speed of the diffusion dynamics in the absence of the non-conservative force. From a stochastic thermodynamic perspective, our results provide quantitative insight into how best to generate data in diffusion models. The optimal learning protocol is introduced by the geodesic of space of the 2-Wasserstein distance in optimal transport theory. We numerically illustrate the validity of the speed-accuracy relations for diffusion models with different noise schedules and different data. We numerically discuss our results for optimal and suboptimal learning protocols. We also demonstrate the applicability of our results to data generation from the real-world image datasets.","authors":["Kotaro Ikeda","Tomoya Uda","Daisuke Okanohara","Sosuke Ito"],"url":"https://arxiv.org/abs/2407.04495"}
{"created":"2025-05-12","title":"TrackFormers: In Search of Transformer-Based Particle Tracking for the High-Luminosity LHC Era","abstract":"High-Energy Physics experiments are facing a multi-fold data increase with every new iteration. This is certainly the case for the upcoming High-Luminosity LHC upgrade. Such increased data processing requirements forces revisions to almost every step of the data processing pipeline. One such step in need of an overhaul is the task of particle track reconstruction, a.k.a., tracking. A Machine Learning-assisted solution is expected to provide significant improvements, since the most time-consuming step in tracking is the assignment of hits to particles or track candidates. This is the topic of this paper.","authors":["Sascha Caron","Nadezhda Dobreva","Antonio Ferrer S\\'anchez","Jos\\'e D. Mart\\'in-Guerrero","Uraz Odyurt","Roberto Ruiz de Austri Bazan","Zef Wolffs","Yue Zhao"],"url":"https://arxiv.org/abs/2407.07179"}
{"created":"2025-05-12","title":"Optimization perspective on raking","abstract":"Raking is widely used in survey inference and global health models to adjust the observations in contingency tables to given marginals, in the latter case reconciling estimates between models with different granularities. We review the convex optimization foundation of raking and focus on a dual perspective that simplifies and streamlines prior raking extensions and provides new functionality, enabling a unified approach to n-dimensional raking, raking with differential weights, ensuring bounds on estimates are respected, raking to margins either as hard constraints or as aggregate observations, handling missing data, and allowing efficient uncertainty propagation. The dual perspective also enables a uniform fast and scalable matrix-free optimization approach for all of these extensions. All of the methods are implemented in an open source Python package with an intuitive user interface, installable from PyPi (https://pypi.org/project/raking/), and we illustrate the capabilities using synthetic data and real mortality estimates.","authors":["Ariane Ducellier (Institute for Health Metrics and Evaluation","University of Washington","Seattle","WA)","Alexander Hsu (Institute for Health Metrics and Evaluation","University of Washington","Seattle","WA","Department of Applied Mathematics","University of Washington","Seattle","WA)","Parkes Kendrick (Institute for Health Metrics and Evaluation","University of Washington","Seattle","WA)","Bill Gustafson (Institute for Health Metrics and Evaluation","University of Washington","Seattle","WA)","Laura Dwyer-Lindgren (Institute for Health Metrics and Evaluation","University of Washington","Seattle","WA)","Christopher Murray (Institute for Health Metrics and Evaluation","University of Washington","Seattle","WA)","Peng Zheng (Institute for Health Metrics and Evaluation","University of Washington","Seattle","WA)","Aleksandr Aravkin (Institute for Health Metrics and Evaluation","University of Washington","Seattle","WA","Department of Applied Mathematics","University of Washington","Seattle","WA)"],"url":"https://arxiv.org/abs/2407.20520"}
{"created":"2025-05-12","title":"Efficient counting of permutation patterns via double posets","abstract":"Corner trees, introduced in \"Even-Zohar and Leng, 2021, Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms\", allow for the efficient counting of certain permutation patterns. Here we identify corner trees as a subset of finite (strict) double posets, which we term twin-tree double posets. They are contained in both twin double posets and tree double posets, giving candidate sets for generalizations of corner tree countings. We provide the generalization of an algorithm proposed by Even-Zohar/Leng to a class of tree double posets, thereby enlarging the space of permutations that can be counted in O(n^{5/3}).","authors":["Joscha Diehl","Emanuele Verri"],"url":"https://arxiv.org/abs/2408.08293"}
{"created":"2025-05-12","title":"Distributional Drift Detection in Medical Imaging with Sketching and Fine-Tuned Transformer","abstract":"Distributional drift detection is important in medical applications as it helps ensure the accuracy and reliability of models by identifying changes in the underlying data distribution that could affect the prediction results of machine learning models. However, current methods have limitations in detecting drift, for example, the inclusion of abnormal datasets can lead to unfair comparisons. This paper presents an accurate and sensitive approach to detect distributional drift in CT-scan medical images by leveraging data-sketching and fine-tuning techniques. We developed a robust baseline library model for real-time anomaly detection, allowing for efficient comparison of incoming images and identification of anomalies. Additionally, we fine-tuned a pre-trained Vision Transformer model to extract relevant features, using mammography as a case study, significantly enhancing model accuracy to 99.11%. Combining with data-sketches and fine-tuning, our feature extraction evaluation demonstrated that cosine similarity scores between similar datasets provide greater improvements, from around 50% increased to 99.1%. Finally, the sensitivity evaluation shows that our solutions are highly sensitive to even 1% salt-and-pepper and speckle noise, and it is not sensitive to lighting noise (e.g., lighting conditions have no impact on data drift). The proposed methods offer a scalable and reliable solution for maintaining the accuracy of diagnostic models in dynamic clinical environments.","authors":["Yusen Wu","Phuong Nguyen","Rose Yesha","Yelena Yesha"],"url":"https://arxiv.org/abs/2408.08456"}
{"created":"2025-05-12","title":"Is speckle noise more challenging to mitigate than additive noise?","abstract":"We study the problem of estimating a function in the presence of both speckle and additive noises, commonly referred to as the de-speckling problem. Although additive noise has been thoroughly explored in nonparametric estimation, speckle noise, prevalent in applications such as synthetic aperture radar, ultrasound imaging, and digital holography, has not received as much attention. Consequently, there is a lack of theoretical investigations into the fundamental limits of mitigating the speckle noise.This paper is the first step in filling this gap.","authors":["Reihaneh Malekian","Hao Xing","Arian Maleki"],"url":"https://arxiv.org/abs/2409.16585"}
{"created":"2025-05-12","title":"Variational Source-Channel Coding for Semantic Communication","abstract":"Semantic communication technology emerges as a pivotal bridge connecting AI with classical communication. The current semantic communication systems are generally modeled as an Auto-Encoder (AE). AE lacks a deep integration of AI principles with communication strategies due to its inability to effectively capture channel dynamics. This gap makes it difficult to justify the need for joint source-channel coding (JSCC) and to explain why performance improves. This paper begins by exploring lossless and lossy communication, highlighting that the inclusion of data distortion distinguishes semantic communication from classical communication. It breaks the conditions for the separation theorem to hold and explains why the amount of data transferred by semantic communication is less. Therefore, employing JSCC becomes imperative for achieving optimal semantic communication. Moreover, a Variational Source-Channel Coding (VSCC) method is proposed for constructing semantic communication systems based on data distortion theory, integrating variational inference and channel characteristics. Using a deep learning network, we develop a semantic communication system employing the VSCC method and demonstrate its capability for semantic transmission. We also establish semantic communication systems of equivalent complexity employing the AE method and the VAE method. Experimental results reveal that the VSCC model offers superior interpretability compared to AE model, as it clearly captures the semantic features of the transmitted data, represented as the variance of latent variables in our experiments. In addition, VSCC model exhibits superior semantic transmission capabilities compared to VAE model. At the same level of data distortion evaluated by PSNR, VSCC model exhibits stronger human interpretability, which can be partially assessed by SSIM.","authors":["Yulong Feng","Jing Xu","Liujun Hu","Guanghui Yu","Xiangyang Duan"],"url":"https://arxiv.org/abs/2410.08222"}
{"created":"2025-05-12","title":"Generalization of semi-regular sequences: Maximal Gr\\\"{o}bner basis degree, variants of genericness, and related conjectures","abstract":"Nowadays, the notion of semi-regular sequences, originally proposed by Fr\\\"oberg, becomes very important not only in Mathematics, but also in Information Science, in particular Cryptology. For example, it is highly expected that randomly generated polynomials form a semi-regular sequence, and based on this observation, secure cryptosystems based on polynomial systems can be devised. In this paper, we deal with a semi-regular sequence and its extension, named a generalized cryptographic semi-regular sequence, and give precise analysis on the complexity of computing a Gr\\\"obner basis of the ideal generated by such a sequence with help of several regularities of the ideal related to Lazard's bound on maximal Gr\\\"{o}bner basis degree and other bounds. We also study the genericness of the property that a sequence is semi-regular, and its variants related to Fr\\\"oberg's conjecture. Moreover, we discuss on the genericness of another important property that the initial ideal is weakly reverse lexicographic, related to Moreno-Soc\\'{i}as' conjecture, and show some criteria to examine whether both Fr\\\"oberg's conjecture and Moreno-Soc\\'{i}as' one hold at the same time.","authors":["Momonari Kudo","Kazuhiro Yokoyama"],"url":"https://arxiv.org/abs/2410.23211"}
{"created":"2025-05-12","title":"Machine Learning Neutrino-Nucleus Cross Sections","abstract":"Neutrino-nucleus scattering cross sections are critical theoretical inputs for long-baseline neutrino oscillation experiments. However, robust modeling of these cross sections remains challenging. For a simple but physically motivated toy model of the DUNE experiment, we demonstrate that an accurate neural-network model of the cross section -- leveraging Standard Model symmetries -- can be learned from near-detector data. We then perform a neutrino oscillation analysis with simulated far-detector events, finding that the modeled cross section achieves results consistent with what could be obtained if the true cross section were known exactly. This proof-of-principle study highlights the potential of future neutrino near-detector datasets and data-driven cross-section models.","authors":["Daniel C. Hackett","Joshua Isaacson","Shirley Weishi Li","Karla Tame-Narvaez","Michael L. Wagman"],"url":"https://arxiv.org/abs/2412.16303"}
{"created":"2025-05-12","title":"Generalizing Egocentric Temporal Neighborhoods to probe for spatial correlations in temporal networks and infer their topology","abstract":"Motifs are thought to be some fundamental components of social face-to-face interaction temporal networks. However, the motifs previously considered are either limited to a handful of nodes and edges, or do not include triangles, which are thought to be of critical relevance to understand the dynamics of social systems. Thus, we introduce a new class of motifs, that include these triangles, are not limited in their number of nodes or edges, and yet can be mined efficiently in any temporal network. Referring to these motifs as the edge-centered motifs, we show analytically how they subsume the Egocentric Temporal Neighborhoods motifs of the literature. We also confirm in empirical data that the edge-centered motifs bring relevant information with respect to the Egocentric motifs by using a principle of maximum entropy. Then, we show how mining for the edge-centered motifs in a network can be used to probe for spatial correlations in the underlying dynamics that have produced that network. We deduce an approximate formula for the distribution of the edge-centered motifs in empirical networks of social face-to-face interactions. In the last section of this paper, we explore how the statistics of the edge-centered motifs can be used to infer the complete topology of the network they were sampled from. This leads to the needs of mathematical development, that we inaugurate here under the name of graph tiling theory.","authors":["Didier Le Bail"],"url":"https://arxiv.org/abs/2501.16070"}
{"created":"2025-05-12","title":"Generative Autoregressive Transformers for Model-Agnostic Federated MRI Reconstruction","abstract":"Although learning-based models hold great promise for MRI reconstruction, single-site models built on limited local datasets often suffer from poor generalization. This challenge has spurred interest in collaborative model training on multi-site datasets via federated learning (FL) -- a privacy-preserving framework that aggregates model updates instead of sharing imaging data. Conventional FL aggregates locally trained model weights into a global model, inherently constraining all sites to use a homogeneous model architecture. This rigidity forces sites to compromise on architectures tailored to their compute resources and application-specific needs, making conventional FL unsuitable for model-heterogeneous settings where each site may prefer a distinct architecture. To overcome this limitation, we introduce FedGAT, a novel model-agnostic FL technique based on generative autoregressive transformers. FedGAT decentralizes the training of a global generative prior that learns the distribution of multi-site MR images. For high-fidelity synthesis, we propose a novel site-prompted GAT prior that controllably synthesizes realistic MR images from desired sites via autoregressive prediction across spatial scales. Each site then trains its own reconstruction model -- using an architecture of its choice -- on a hybrid dataset augmenting its local MRI dataset with GAT-generated synthetic MR images emulating datasets from other sites. This hybrid training strategy enables site-specific reconstruction models to generalize more effectively across diverse data distributions while preserving data privacy. Comprehensive experiments on multi-institutional datasets demonstrate that FedGAT enables flexible, model-heterogeneous collaborations and achieves superior within-site and cross-site reconstruction performance compared to state-of-the-art FL baselines.","authors":["Valiyeh A. Nezhad","Gokberk Elmas","Bilal Kabas","Fuat Arslan","Tolga \\c{C}ukur"],"url":"https://arxiv.org/abs/2502.04521"}
{"created":"2025-05-12","title":"A review of minimum cost box searching games","abstract":"We consider a class of zero-sum search games in which a Hider hides one or more target among a set of $n$ boxes. The boxes may require differing amount of time to search, and detection may be imperfect, so that there is a certain probability that a target may not be found when a box is searched, even when it is there. A Searcher must choose how to search the boxes sequentially, and wishes to minimize the expected time to find the target(s), whereas the Hider wishes to maximize this payoff. We review some known solutions to different cases of this game.","authors":["Thomas Lidbetter"],"url":"https://arxiv.org/abs/2502.10551"}
{"created":"2025-05-12","title":"Multiplicative character sums over two classes of subsets of quadratic extensions of finite fields","abstract":"Let $q$ be a prime power and $r$ a positive even integer. Let $\\mathbb{F}_{q}$ be the finite field with $q$ elements and $\\mathbb{F}_{q^r}$ be its extension field of degree $r$. Let $\\chi$ be a nontrivial multiplicative character of $\\mathbb{F}_{q^r}$ and $f(X)$ a polynomial over $\\mathbb{F}_{q^r}$ with a simple root in $\\mathbb{F}_{q^r}$. In this paper, we improve estimates for character sums $\\sum\\limits_{g \\in\\mathcal{G}}\\chi(f(g))$, where $\\mathcal{G}$ is either a subset of $\\mathbb{F}_{q^r}$ of sparse elements, with respect to some fixed basis of $\\mathbb{F}_{q^r}$ which contains a basis of $\\mathbb{F}_{q^{r/2}}$, or a subset avoiding affine hyperplanes in general position. While such sums have been previously studied, our approach yields sharper bounds by reducing them to sums over the subfield $\\mathbb{F}_{q^{r/2}}$ rather than sums over general linear spaces. These estimates can be used to prove the existence of primitive elements in $\\mathcal{G}$ in the standard way.","authors":["Kaimin Cheng","Arne Winterhof"],"url":"https://arxiv.org/abs/2502.14436"}
{"created":"2025-05-12","title":"Code-Verification Techniques for an Arbitrary-Depth Electromagnetic Slot Model","abstract":"Electromagnetic slot models are employed to efficiently simulate electromagnetic penetration through openings in an otherwise closed electromagnetic scatterer. Such models, which incorporate varying assumptions about the geometry of the openings, are typically coupled with electromagnetic surface integral equations that model electromagnetic scattering. In this paper, we introduce novel code-verification approaches and build upon our previously developed methodologies to assess the correctness of the numerical implementation of an arbitrary-depth slot model. Through these approaches, we measure the convergence rates of the different interacting sources of numerical error and demonstrate the impact of various factors on these rates for several cases.","authors":["Brian A. Freno","Neil R. Matula","Robert A. Pfeiffer","Vinh Q. Dang"],"url":"https://arxiv.org/abs/2503.04004"}
{"created":"2025-05-12","title":"Predicting fermionic densities using a Projected Quantum Kernel method","abstract":"We use a support vector regressor based on a projected quantum kernel method to predict the density structure of 1D fermionic systems of interest in quantum chemistry and quantum matter. The kernel is built on with the observables of a quantum reservoir implementable with interacting Rydberg atoms. Training and test data of the fermionic system are generated using a Density Functional Theory approach. We test the performance of the method for several Hamiltonian parameters, finding a general common behavior of the error as a function of measurement time. At sufficiently large measurement times, we find that the method outperforms the classical linear kernel method and can be competitive with the radial basis function method.","authors":["Francesco Perciavalle","Francesco Plastina","Michele Pisarra","Nicola Lo Gullo"],"url":"https://arxiv.org/abs/2504.14002"}
{"created":"2025-05-12","title":"SeizureFormer: A Transformer Model for IEA-Based Seizure Risk Forecasting","abstract":"We present SeizureFormer, a Transformer-based model for long-term seizure risk forecasting using interictal epileptiform activity (IEA) surrogate biomarkers and long episode (LE) biomarkers from responsive neurostimulation (RNS) systems. Unlike raw scalp EEG-based models, SeizureFormer leverages structured, clinically relevant features and integrates CNN-based patch embedding, multi-head self-attention, and squeeze-and-excitation blocks to model both short-term dynamics and long-term seizure cycles. Tested across five patients and multiple prediction windows (1 to 14 days), SeizureFormer achieved state-of-the-art performance with mean ROC AUC of 79.44 percent and mean PR AUC of 76.29 percent. Compared to statistical, machine learning, and deep learning baselines, it demonstrates enhanced generalizability and seizure risk forecasting performance under class imbalance. This work supports future clinical integration of interpretable and robust seizure forecasting tools for personalized epilepsy management.","authors":["Tianning Feng","Juntong Ni","Ezequiel Gleichgerrcht","Wei Jin"],"url":"https://arxiv.org/abs/2504.16098"}
{"created":"2025-05-12","title":"Exploring exponential time integration for strongly magnetized charged particle motion","abstract":"A fundamental task in particle-in-cell (PIC) simulations of plasma physics is solving for charged particle motion in electromagnetic fields. This problem is especially challenging when the plasma is strongly magnetized due to numerical stiffness arising from the wide separation in time scales between highly oscillatory gyromotion and overall macroscopic behavior of the system. In contrast to conventional finite difference schemes, we investigated exponential integration techniques to numerically simulate strongly magnetized charged particle motion. Numerical experiments with a uniform magnetic field show that exponential integrators yield superior performance for linear problems (i.e. configurations with an electric field given by a quadratic electric scalar potential) and are competitive with conventional methods for nonlinear problems with cubic and quartic electric scalar potentials.","authors":["Tri P. Nguyen","Ilon Joseph","Mayya Tokman"],"url":"https://arxiv.org/abs/2505.01525"}
{"created":"2025-05-12","title":"On multiplicities of interpoint distances","abstract":"Given a set $X\\subseteq\\mathbb{R}^2$ of $n$ points and a distance $d>0$, the multiplicity of $d$ is the number of times the distance $d$ appears between points in $X$. Let $a_1(X) \\geq a_2(X) \\geq \\cdots \\geq a_m(X)$ denote the multiplicities of the $m$ distances determined by $X$ and let $a(X)=\\left(a_1(X),\\dots,a_m(X)\\right)$. In this paper, we study several questions from Erd\\H{o}s's time regarding distance multiplicities. Among other results, we show that:","authors":["Felix Christian Clemen","Adrian Dumitrescu","Dingyuan Liu"],"url":"https://arxiv.org/abs/2505.04283"}
