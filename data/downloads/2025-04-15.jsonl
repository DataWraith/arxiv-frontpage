{"created":"2025-04-15","title":"Latency-Aware 2-Opt Monotonic Local Search for Distributed Constraint Optimization","abstract":"Researchers recently extended Distributed Constraint Optimization Problems (DCOPs) to Communication-Aware DCOPs so that they are applicable in scenarios in which messages can be arbitrarily delayed. Distributed asynchronous local search and inference algorithms designed for CA-DCOPs are less vulnerable to message latency than their counterparts for regular DCOPs. However, unlike local search algorithms for (regular) DCOPs that converge to k-opt solutions (with k > 1), that is, they converge to solutions that cannot be improved by a group of k agents), local search CA-DCOP algorithms are limited to 1-opt solutions only. In this paper, we introduce Latency-Aware Monotonic Distributed Local Search-2 (LAMDLS-2), where agents form pairs and coordinate bilateral assignment replacements. LAMDLS-2 is monotonic, converges to a 2-opt solution, and is also robust to message latency, making it suitable for CA-DCOPs. Our results indicate that LAMDLS-2 converges faster than MGM-2, a benchmark algorithm, to a similar 2-opt solution, in various message latency scenarios.","authors":["Ben Rachmut","Roie Zivan","William Yeoh"],"url":"https://arxiv.org/abs/2504.08737"}
{"created":"2025-04-15","title":"AI-Driven Sentiment Analytics: Unlocking Business Value in the E-Commerce Landscape_v1","abstract":"The rapid growth of e-commerce has led to an overwhelming volume of customer feedback, from product reviews to service interactions. Extracting meaningful insights from this data is crucial for businesses aiming to improve customer satisfaction and optimize decision-making. This paper presents an AI-driven sentiment analysis system designed specifically for e-commerce applications, balancing accuracy with interpretability. Our approach integrates traditional machine learning techniques with modern deep learning models, allowing for a more nuanced understanding of customer sentiment while ensuring transparency in decision-making. Experimental results show that our system outperforms standard sentiment analysis methods, achieving an accuracy of 89.7% on diverse, large-scale datasets. Beyond technical performance, real-world implementation across multiple e-commerce platforms demonstrates tangible improvements in customer engagement and operational efficiency. This study highlights both the potential and the challenges of applying AI to sentiment analysis in a commercial setting, offering insights into practical deployment strategies and areas for future refinement.","authors":["Qianye Wu","Chengxuan Xia","Sixuan Tian"],"url":"https://arxiv.org/abs/2504.08738"}
{"created":"2025-04-15","title":"Enhancing Product Search Interfaces with Sketch-Guided Diffusion and Language Agents","abstract":"The rapid progress in diffusion models, transformers, and language agents has unlocked new possibilities, yet their potential in user interfaces and commercial applications remains underexplored. We present Sketch-Search Agent, a novel framework that transforms the image search experience by integrating a multimodal language agent with freehand sketches as control signals for diffusion models. Using the T2I-Adapter, Sketch-Search Agent combines sketches and text prompts to generate high-quality query images, encoded via a CLIP image encoder for efficient matching against an image corpus. Unlike existing methods, Sketch-Search Agent requires minimal setup, no additional training, and excels in sketch-based image retrieval and natural language interactions. The multimodal agent enhances user experience by dynamically retaining preferences, ranking results, and refining queries for personalized recommendations. This interactive design empowers users to create sketches and receive tailored product suggestions, showcasing the potential of diffusion models in user-centric image retrieval. Experiments confirm Sketch-Search Agent's high accuracy in delivering relevant product search results.","authors":["Edward Sun"],"url":"https://arxiv.org/abs/2504.08739"}
{"created":"2025-04-15","title":"Recommendation System in Advertising and Streaming Media: Unsupervised Data Enhancement Sequence Suggestions","abstract":"Sequential recommendation is an extensively explored approach to capturing users' evolving preferences based on past interactions, aimed at predicting their next likely choice. Despite significant advancements in this domain, including methods based on RNNs and self-attention, challenges like limited supervised signals and noisy data caused by unintentional clicks persist. To address these challenges, some studies have incorporated unsupervised learning by leveraging local item contexts within individual sequences. However, these methods often overlook the intricate associations between items across multiple sequences and are susceptible to noise in item co-occurrence patterns. In this context, we introduce a novel framework, Global Unsupervised Data-Augmentation (UDA4SR), which adopts a graph contrastive learning perspective to generate more robust item embeddings for sequential recommendation. Our approach begins by integrating Generative Adversarial Networks (GANs) for data augmentation, which serves as the first step to enhance the diversity and richness of the training data. Then, we build a Global Item Relationship Graph (GIG) based on all user interaction sequences. Subsequently, we employ graph contrastive learning on the refined graph to enhance item embeddings by capturing complex global associations. To model users' dynamic and diverse interests more effectively, we enhance the CapsNet module with a novel target-attention mechanism. Extensive experiments show that UDA4SR significantly outperforms state-of-the-art approaches.","authors":["Kowei Shih","Yi Han","Li Tan"],"url":"https://arxiv.org/abs/2504.08740"}
{"created":"2025-04-15","title":"DEEP: Edge-based Dataflow Processing with Hybrid Docker Hub and Regional Registries","abstract":"Reducing energy consumption is essential to lessen greenhouse gas emissions, conserve natural resources, and help mitigate the impacts of climate change. In this direction, edge computing, a complementary technology to cloud computing, extends computational capabilities closer to the data producers, enabling energy-efficient and latency-sensitive service delivery for end users. To properly manage data and microservice storage, expanding the Docker Hub registry to the edge using an AWS S3-compatible MinIO-based object storage service can reduce completion time and energy consumption. To address this, we introduce Docker rEgistry-based Edge dataflow Processing (DEEP) to optimize the energy consumption of microservice-based application deployments by focusing on deployments from Docker Hub and MinIO-based regional registries and their processing on edge devices. After applying nash equilibrium and benchmarking the execution of two compute-intensive machine learning (ML) applications of video and text processing, we compare energy consumption across three deployment scenarios: exclusively from Docker Hub, exclusively from the regional registry, and a hybrid method utilizing both. Experimental results show that deploying 83% of text processing microservices from the regional registry improves the energy consumption by 0.34% (18J) compared to microservice deployments exclusively from Docker Hub.","authors":["Narges Mehran","Zahra Najafabadi Samani","Reza Farahani","Josef Hammer","Dragi Kimovski"],"url":"https://arxiv.org/abs/2504.08741"}
{"created":"2025-04-15","title":"Simulating Filter Bubble on Short-video Recommender System with Large Language Model Agents","abstract":"An increasing reliance on recommender systems has led to concerns about the creation of filter bubbles on social media, especially on short video platforms like TikTok. However, their formation is still not entirely understood due to the complex dynamics between recommendation algorithms and user feedback. In this paper, we aim to shed light on these dynamics using a large language model-based simulation framework. Our work employs real-world short-video data containing rich video content information and detailed user-agents to realistically simulate the recommendation-feedback cycle. Through large-scale simulations, we demonstrate that LLMs can replicate real-world user-recommender interactions, uncovering key mechanisms driving filter bubble formation. We identify critical factors, such as demographic features and category attraction that exacerbate content homogenization. To mitigate this, we design and test interventions including various cold-start and feedback weighting strategies, showing measurable reductions in filter bubble effects. Our framework enables rapid prototyping of recommendation strategies, offering actionable solutions to enhance content diversity in real-world systems. Furthermore, we analyze how LLM-inherent biases may propagate through recommendations, proposing safeguards to promote equity for vulnerable groups, such as women and low-income populations. By examining the interplay between recommendation and LLM agents, this work advances a deeper understanding of algorithmic bias and provides practical tools to promote inclusive digital spaces.","authors":["Nicholas Sukiennik","Haoyu Wang","Zailin Zeng","Chen Gao","Yong Li"],"url":"https://arxiv.org/abs/2504.08742"}
{"created":"2025-04-15","title":"Dynamic Topic Analysis in Academic Journals using Convex Non-negative Matrix Factorization Method","abstract":"With the rapid advancement of large language models, academic topic identification and topic evolution analysis are crucial for enhancing AI's understanding capabilities. Dynamic topic analysis provides a powerful approach to capturing and understanding the temporal evolution of topics in large-scale datasets. This paper presents a two-stage dynamic topic analysis framework that incorporates convex optimization to improve topic consistency, sparsity, and interpretability. In Stage 1, a two-layer non-negative matrix factorization (NMF) model is employed to extract annual topics and identify key terms. In Stage 2, a convex optimization algorithm refines the dynamic topic structure using the convex NMF (cNMF) model, further enhancing topic integration and stability. Applying the proposed method to IEEE journal abstracts from 2004 to 2022 effectively identifies and quantifies emerging research topics, such as COVID-19 and digital twins. By optimizing sparsity differences in the clustering feature space between traditional and emerging research topics, the framework provides deeper insights into topic evolution and ranking analysis. Moreover, the NMF-cNMF model demonstrates superior stability in topic consistency. At sparsity levels of 0.4, 0.6, and 0.9, the proposed approach improves topic ranking stability by 24.51%, 56.60%, and 36.93%, respectively. The source code (to be open after publication) is available at https://github.com/meetyangyang/CDNMF.","authors":["Yang Yang","Tong Zhang","Jian Wu","Lijie Su"],"url":"https://arxiv.org/abs/2504.08743"}
{"created":"2025-04-15","title":"ExpertRAG: Efficient RAG with Mixture of Experts -- Optimizing Context Retrieval for Adaptive LLM Responses","abstract":"ExpertRAG is a novel theoretical framework that integrates Mixture-of-Experts (MoE) architectures with Retrieval Augmented Generation (RAG) to advance the efficiency and accuracy of knowledge-intensive language modeling. We propose a dynamic retrieval gating mechanism coupled with expert routing, enabling the model to selectively consult an external knowledge store or rely on specialized internal experts based on the query's needs. The paper lays out the theoretical foundations of ExpertRAG, including a probabilistic formulation that treats retrieval and expert selection as latent decisions, and mathematical justifications for its efficiency in both computation and knowledge utilization. We derive formulae to quantify the expected computational cost savings from selective retrieval and the capacity gains from sparse expert utilization. A comparative analysis positions ExpertRAG against standard RAG (with always-on retrieval) and pure MoE models (e.g., Switch Transformer, Mixtral) to highlight its unique balance between parametric knowledge and non-parametric retrieval. We also outline an experimental validation strategy, proposing benchmarks and evaluation protocols to test ExpertRAG's performance on factual recall, generalization, and inference efficiency. The proposed framework, although presented theoretically, is supported by insights from prior work in RAG and MoE, and is poised to provide more factual, efficient, and adaptive generation by leveraging the best of both paradigms. In summary, ExpertRAG contributes a new perspective on scaling and augmenting language models, backed by a thorough analysis and a roadmap for empirical validation.","authors":["Esmail Gumaan"],"url":"https://arxiv.org/abs/2504.08744"}
{"created":"2025-04-15","title":"Improving RAG for Personalization with Author Features and Contrastive Examples","abstract":"Personalization with retrieval-augmented generation (RAG) often fails to capture fine-grained features of authors, making it hard to identify their unique traits. To enrich the RAG context, we propose providing Large Language Models (LLMs) with author-specific features, such as average sentiment polarity and frequently used words, in addition to past samples from the author's profile. We introduce a new feature called Contrastive Examples: documents from other authors are retrieved to help LLM identify what makes an author's style unique in comparison to others. Our experiments show that adding a couple of sentences about the named entities, dependency patterns, and words a person uses frequently significantly improves personalized text generation. Combining features with contrastive examples boosts the performance further, achieving a relative 15% improvement over baseline RAG while outperforming the benchmarks. Our results show the value of fine-grained features for better personalization, while opening a new research dimension for including contrastive examples as a complement with RAG. We release our code publicly.","authors":["Mert Yazan","Suzan Verberne","Frederik Situmeang"],"url":"https://arxiv.org/abs/2504.08745"}
{"created":"2025-04-15","title":"Enhancing Recommender Systems Using Textual Embeddings from Pre-trained Language Models","abstract":"Recent advancements in language models and pre-trained language models like BERT and RoBERTa have revolutionized natural language processing, enabling a deeper understanding of human-like language. In this paper, we explore enhancing recommender systems using textual embeddings from pre-trained language models to address the limitations of traditional recommender systems that rely solely on explicit features from users, items, and user-item interactions. By transforming structured data into natural language representations, we generate high-dimensional embeddings that capture deeper semantic relationships between users, items, and contexts. Our experiments demonstrate that this approach significantly improves recommendation accuracy and relevance, resulting in more personalized and context-aware recommendations. The findings underscore the potential of PLMs to enhance the effectiveness of recommender systems.","authors":["Ngoc Luyen Le (Heudiasyc)","Marie-H\\'el\\`ene Abel (Heudiasyc)"],"url":"https://arxiv.org/abs/2504.08746"}
{"created":"2025-04-15","title":"GridMind: A Multi-Agent NLP Framework for Unified, Cross-Modal NFL Data Insights","abstract":"The rapid growth of big data and advancements in computational techniques have significantly transformed sports analytics. However, the diverse range of data sources -- including structured statistics, semi-structured formats like sensor data, and unstructured media such as written articles, audio, and video -- creates substantial challenges in extracting actionable insights. These various formats, often referred to as multimodal data, require integration to fully leverage their potential. Conventional systems, which typically prioritize structured data, face limitations when processing and combining these diverse content types, reducing their effectiveness in real-time sports analysis.","authors":["Jordan Chipka","Chris Moyer","Clay Troyer","Tyler Fuelling","Jeremy Hochstedler"],"url":"https://arxiv.org/abs/2504.08747"}
{"created":"2025-04-15","title":"A Survey of Multimodal Retrieval-Augmented Generation","abstract":"Multimodal Retrieval-Augmented Generation (MRAG) enhances large language models (LLMs) by integrating multimodal data (text, images, videos) into retrieval and generation processes, overcoming the limitations of text-only Retrieval-Augmented Generation (RAG). While RAG improves response accuracy by incorporating external textual knowledge, MRAG extends this framework to include multimodal retrieval and generation, leveraging contextual information from diverse data types. This approach reduces hallucinations and enhances question-answering systems by grounding responses in factual, multimodal knowledge. Recent studies show MRAG outperforms traditional RAG, especially in scenarios requiring both visual and textual understanding. This survey reviews MRAG's essential components, datasets, evaluation methods, and limitations, providing insights into its construction and improvement. It also identifies challenges and future research directions, highlighting MRAG's potential to revolutionize multimodal information retrieval and generation. By offering a comprehensive perspective, this work encourages further exploration into this promising paradigm.","authors":["Lang Mei","Siyu Mo","Zhihan Yang","Chong Chen"],"url":"https://arxiv.org/abs/2504.08748"}
{"created":"2025-04-15","title":"A Quantitative Approach to Evaluating Open-Source EHR Systems for Indian Healthcare","abstract":"The increasing use of Electronic Health Records (EHR) has emphasized the need for standardization and interoperability in healthcare data management. The Ministry of Health and Family Welfare, Government of India, has introduced the Electronic Health Record Minimum Data Set (EHRMDS) to facilitate uniformity in clinical documentation. However, the compatibility of Open-Source Electronic Health Record Systems (OS-EHRS) with EHRMDS remains largely unexplored. This study conducts a systematic assessment of the alignment between EHRMDS and commonly utilized OS-EHRS to determine the most appropriate system for healthcare environments in India. A quantitative closeness analysis was performed by comparing the metadata elements of EHRMDS with those of 10 selected OS-EHRS. Using crosswalk methodologies based on syntactic and semantic similarity, the study measured the extent of metadata alignment. Results indicate that OpenEMR exhibits the highest compatibility with EHRMDS, covering 73.81% of its metadata elements, while OpenClinic shows the least alignment at 33.33%. Additionally, the analysis identified 47 metadata elements present in OS-EHRS but absent in EHRMDS, suggesting the need for an extended metadata schema. By bridging gaps in clinical metadata, this study contributes to enhancing the interoperability of EHR systems in India. The findings provide valuable insights for healthcare policymakers and organizations seeking to adopt OS-EHRS aligned with national standards. Keywords. EHR metadata, electronic health record systems, EHRMDS, meta data, structured vocabularies, metadata crosswalk, methodologies and tools, SNOMED-CT, UMLS terms.","authors":["Biswanath Dutta","Debanjali Bain"],"url":"https://arxiv.org/abs/2504.08750"}
{"created":"2025-04-15","title":"Research on the Design of a Short Video Recommendation System Based on Multimodal Information and Differential Privacy","abstract":"With the rapid development of short video platforms, recommendation systems have become key technologies for improving user experience and enhancing platform engagement. However, while short video recommendation systems leverage multimodal information (such as images, text, and audio) to improve recommendation effectiveness, they also face the severe challenge of user privacy leakage. This paper proposes a short video recommendation system based on multimodal information and differential privacy protection. First, deep learning models are used for feature extraction and fusion of multimodal data, effectively improving recommendation accuracy. Then, a differential privacy protection mechanism suitable for recommendation scenarios is designed to ensure user data privacy while maintaining system performance. Experimental results show that the proposed method outperforms existing mainstream approaches in terms of recommendation accuracy, multimodal fusion effectiveness, and privacy protection performance, providing important insights for the design of recommendation systems for short video platforms.","authors":["Haowei Yang","Lei Fu","Qingyi Lu","Yue Fan","Tianle Zhang","Ruohan Wang"],"url":"https://arxiv.org/abs/2504.08751"}
{"created":"2025-04-15","title":"Patience is all you need! An agentic system for performing scientific literature review","abstract":"Large language models (LLMs) have grown in their usage to provide support for question answering across numerous disciplines. The models on their own have already shown promise for answering basic questions, however fail quickly where expert domain knowledge is required or the question is nuanced. Scientific research often involves searching for relevant literature, distilling pertinent information from that literature and analysing how the findings support or contradict one another. The information is often encapsulated in the full text body of research articles, rather than just in the abstracts. Statements within these articles frequently require the wider article context to be fully understood. We have built an LLM-based system that performs such search and distillation of information encapsulated in scientific literature, and we evaluate our keyword based search and information distillation system against a set of biology related questions from previously released literature benchmarks. We demonstrate sparse retrieval methods exhibit results close to state of the art without the need for dense retrieval, with its associated infrastructure and complexity overhead. We also show how to increase the coverage of relevant documents for literature review generation.","authors":["David Brett","Anniek Myatt"],"url":"https://arxiv.org/abs/2504.08752"}
{"created":"2025-04-15","title":"Domain Specific Question to SQL Conversion with Embedded Data Balancing Technique","abstract":"The rise of deep learning in natural language processing has fostered the creation of text to structured query language models composed of an encoder and a decoder. Researchers have experimented with various intermediate processing like schema linking, table type aware, value extract. To generate accurate SQL results for the user question. However error analysis performed on the failed cases on these systems shows, 29 percentage of the errors would be because the system was unable to understand the values expressed by the user in their question. This challenge affects the generation of accurate SQL queries, especially when dealing with domain-specific terms and specific value conditions, where traditional methods struggle to maintain consistency and precision. To overcome these obstacles, proposed two intermediations like implementing data balancing technique and over sampling domain-specific queries which would refine the model architecture to enhance value recognition and fine tuning the model for domain-specific questions. This proposed solution achieved 10.98 percentage improvement in accuracy of the model performance compared to the state of the art model tested on WikiSQL dataset. to convert the user question accurately to SQL queries. Applying oversampling technique on the domain-specific questions shown a significant improvement as compared with traditional approaches.","authors":["Jyothi","T. Satyanarayana Murthy"],"url":"https://arxiv.org/abs/2504.08753"}
{"created":"2025-04-15","title":"Towards Personalized Conversational Sales Agents with Contextual User Profiling for Strategic Action","abstract":"Conversational Recommender Systems (CRSs) aim to engage users in dialogue to provide tailored recommendations. While traditional CRSs focus on eliciting preferences and retrieving items, real-world e-commerce interactions involve more complex decision-making, where users consider multiple factors beyond simple attributes. To bridge this gap, we introduce Conversational Sales (CSales), a novel task that unifies preference elicitation, recommendation, and persuasion to better support user decision-making. For a realistic evaluation of CSales, we present CSUser, an LLM-based user simulator constructed from real-world data, modeling diverse user profiles with needs and personalities. Additionally, we propose CSI, a conversational sales agent that proactively infers contextual profiles through dialogue for personalized action planning. Extensive experiments demonstrate that CSUser effectively replicates real-world users and emphasize the importance of contextual profiling for strategic action selection, ultimately driving successful purchases in e-commerce.","authors":["Tongyoung Kim","Jeongeun Lee","Soojin Yoon","Seonghwan Kim"],"url":"https://arxiv.org/abs/2504.08754"}
{"created":"2025-04-15","title":"Delving into: the quantification of Ai-generated content on the internet (synthetic data)","abstract":"While it is increasingly evident that the internet is becoming saturated with content created by generated Ai large language models, accurately measuring the scale of this phenomenon has proven challenging. By analyzing the frequency of specific keywords commonly used by ChatGPT, this paper demonstrates that such linguistic markers can effectively be used to esti-mate the presence of generative AI content online. The findings suggest that at least 30% of text on active web pages originates from AI-generated sources, with the actual proportion likely ap-proaching 40%. Given the implications of autophagous loops, this is a sobering realization.","authors":["Dirk HR Spennemann"],"url":"https://arxiv.org/abs/2504.08755"}
{"created":"2025-04-15","title":"MHTS: Multi-Hop Tree Structure Framework for Generating Difficulty-Controllable QA Datasets for RAG Evaluation","abstract":"Existing RAG benchmarks often overlook query difficulty, leading to inflated performance on simpler questions and unreliable evaluations. A robust benchmark dataset must satisfy three key criteria: quality, diversity, and difficulty, which capturing the complexity of reasoning based on hops and the distribution of supporting evidence. In this paper, we propose MHTS (Multi-Hop Tree Structure), a novel dataset synthesis framework that systematically controls multi-hop reasoning complexity by leveraging a multi-hop tree structure to generate logically connected, multi-chunk queries. Our fine-grained difficulty estimation formula exhibits a strong correlation with the overall performance metrics of a RAG system, validating its effectiveness in assessing both retrieval and answer generation capabilities. By ensuring high-quality, diverse, and difficulty-controlled queries, our approach enhances RAG evaluation and benchmarking capabilities.","authors":["Jeongsoo Lee","Daeyong Kwon","Kyohoon Jin","Junnyeong Jeong","Minwoo Sim","Minwoo Kim"],"url":"https://arxiv.org/abs/2504.08756"}
{"created":"2025-04-15","title":"A Framework for Lightweight Responsible Prompting Recommendation","abstract":"Computer Science and Design practitioners have been researching and proposing alternatives for a dearth of recommendations, standards, or best practices in user interfaces for decades. Now, with the advent of generative Artificial Intelligence (GenAI), we have yet again an emerging, powerful technology that lacks sufficient guidance in terms of possible interactions, inputs, and outcomes. In this context, this work proposes a lightweight framework for responsible prompting recommendation to be added before the prompt is sent to GenAI. The framework is comprised of (1) a human-curated dataset for recommendations, (2) a red team dataset for assessing recommendations, (3) a sentence transformer for semantics mapping, (4) a similarity metric to map input prompt to recommendations, (5) a set of similarity thresholds, (6) quantized sentence embeddings, (7) a recommendation engine, and (8) an evaluation step to use the red team dataset. With the proposed framework and open-source system, the contributions presented can be applied in multiple contexts where end-users can benefit from guidance for interacting with GenAI in a more responsible way, recommending positive values to be added and harmful sentences to be removed.","authors":["Tiago Machado","Sara E. Berger","Cassia Sanctos","Vagner Figueiredo de Santana","Lemara Williams","Zhaoqing Wu"],"url":"https://arxiv.org/abs/2504.08757"}
{"created":"2025-04-15","title":"Hyper-RAG: Combating LLM Hallucinations using Hypergraph-Driven Retrieval-Augmented Generation","abstract":"Large language models (LLMs) have transformed various sectors, including education, finance, and medicine, by enhancing content generation and decision-making processes. However, their integration into the medical field is cautious due to hallucinations, instances where generated content deviates from factual accuracy, potentially leading to adverse outcomes. To address this, we introduce Hyper-RAG, a hypergraph-driven Retrieval-Augmented Generation method that comprehensively captures both pairwise and beyond-pairwise correlations in domain-specific knowledge, thereby mitigating hallucinations. Experiments on the NeurologyCrop dataset with six prominent LLMs demonstrated that Hyper-RAG improves accuracy by an average of 12.3% over direct LLM use and outperforms Graph RAG and Light RAG by 6.3% and 6.0%, respectively. Additionally, Hyper-RAG maintained stable performance with increasing query complexity, unlike existing methods which declined. Further validation across nine diverse datasets showed a 35.5% performance improvement over Light RAG using a selection-based assessment. The lightweight variant, Hyper-RAG-Lite, achieved twice the retrieval speed and a 3.3% performance boost compared with Light RAG. These results confirm Hyper-RAG's effectiveness in enhancing LLM reliability and reducing hallucinations, making it a robust solution for high-stakes applications like medical diagnostics.","authors":["Yifan Feng","Hao Hu","Xingliang Hou","Shiquan Liu","Shihui Ying","Shaoyi Du","Han Hu","Yue Gao"],"url":"https://arxiv.org/abs/2504.08758"}
{"created":"2025-04-15","title":"UltraRAG: A Modular and Automated Toolkit for Adaptive Retrieval-Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) significantly enhances the performance of large language models (LLMs) in downstream tasks by integrating external knowledge. To facilitate researchers in deploying RAG systems, various RAG toolkits have been introduced. However, many existing RAG toolkits lack support for knowledge adaptation tailored to specific application scenarios. To address this limitation, we propose UltraRAG, a RAG toolkit that automates knowledge adaptation throughout the entire workflow, from data construction and training to evaluation, while ensuring ease of use. UltraRAG features a user-friendly WebUI that streamlines the RAG process, allowing users to build and optimize systems without coding expertise. It supports multimodal input and provides comprehensive tools for managing the knowledge base. With its highly modular architecture, UltraRAG delivers an end-to-end development solution, enabling seamless knowledge adaptation across diverse user scenarios. The code, demonstration videos, and installable package for UltraRAG are publicly available at https://github.com/OpenBMB/UltraRAG.","authors":["Yuxuan Chen","Dewen Guo","Sen Mei","Xinze Li","Hao Chen","Yishan Li","Yixuan Wang","Chaoyue Tang","Ruobing Wang","Dingjun Wu","Yukun Yan","Zhenghao Liu","Shi Yu","Zhiyuan Liu","Maosong Sun"],"url":"https://arxiv.org/abs/2504.08761"}
{"created":"2025-04-15","title":"InteractiveSurvey: An LLM-based Personalized and Interactive Survey Paper Generation System","abstract":"The exponential growth of academic literature creates urgent demands for comprehensive survey papers, yet manual writing remains time-consuming and labor-intensive. Recent advances in large language models (LLMs) and retrieval-augmented generation (RAG) facilitate studies in synthesizing survey papers from multiple references, but most existing works restrict users to title-only inputs and fixed outputs, neglecting the personalized process of survey paper writing. In this paper, we introduce InteractiveSurvey - an LLM-based personalized and interactive survey paper generation system. InteractiveSurvey can generate structured, multi-modal survey papers with reference categorizations from multiple reference papers through both online retrieval and user uploads. More importantly, users can customize and refine intermediate components continuously during generation, including reference categorization, outline, and survey content through an intuitive interface. Evaluations of content quality, time efficiency, and user studies show that InteractiveSurvey is an easy-to-use survey generation system that outperforms most LLMs and existing methods in output content quality while remaining highly time-efficient.","authors":["Zhiyuan Wen","Jiannong Cao","Zian Wang","Beichen Guo","Ruosong Yang","Shuaiqi Liu"],"url":"https://arxiv.org/abs/2504.08762"}
{"created":"2025-04-15","title":"WebMap -- Large Language Model-assisted Semantic Link Induction in the Web","abstract":"Carrying out research tasks is only inadequately supported, if not hindered, by current web search engines. This paper therefore proposes functional extensions of WebMap, a semantically induced overlay linking structure on the web to inherently facilitate research activities. These add-ons support the dynamic determination and regrouping of document clusters, the creation of a semantic signpost in the web, and the interactive tracing of topics back to their origins.","authors":["Shiraj Pokharel","Georg P. Ro{\\ss}rucker","Mario M. Kubek"],"url":"https://arxiv.org/abs/2504.08763"}
{"created":"2025-04-15","title":"Evaluation of the phi-3-mini SLM for identification of texts related to medicine, health, and sports injuries","abstract":"Small Language Models (SLMs) have potential to be used for automatically labelling and identifying aspects of text data for medicine/health-related purposes from documents and the web. As their resource requirements are significantly lower than Large Language Models (LLMs), these can be deployed potentially on more types of devices. SLMs often are benchmarked on health/medicine-related tasks, such as MedQA, although performance on these can vary especially depending on the size of the model in terms of number of parameters. Furthermore, these test results may not necessarily reflect real-world performance regarding the automatic labelling or identification of texts in documents and the web. As a result, we compared topic-relatedness scores from Microsofts phi-3-mini-4k-instruct SLM to the topic-relatedness scores from 7 human evaluators on 1144 samples of medical/health-related texts and 1117 samples of sports injury-related texts. These texts were from a larger dataset of about 9 million news headlines, each of which were processed and assigned scores by phi-3-mini-4k-instruct. Our sample was selected (filtered) based on 1 (low filtering) or more (high filtering) Boolean conditions on the phi-3 SLM scores. We found low-moderate significant correlations between the scores from the SLM and human evaluators for sports injury texts with low filtering (\\r{ho} = 0.3413, p < 0.001) and medicine/health texts with high filtering (\\r{ho} = 0.3854, p < 0.001), and low significant correlation for medicine/health texts with low filtering (\\r{ho} = 0.2255, p < 0.001). There was negligible, insignificant correlation for sports injury-related texts with high filtering (\\r{ho} = 0.0318, p = 0.4466).","authors":["Chris Brogly","Saif Rjaibi","Charlotte Liang","Erica Lam","Edward Wang","Adam Levitan","Sarah Paleczny","Michael Cusimano"],"url":"https://arxiv.org/abs/2504.08764"}
{"created":"2025-04-15","title":"A Proposed Hybrid Recommender System for Tourism Industry in Iraq Using Evolutionary Apriori and K-means Algorithms","abstract":"The rapid proliferation of tourism data across sectors, including accommodations, cultural sites, and events, has made it increasingly challenging for travelers to identify relevant and personalized recommendations. While traditional recommender systems such as collaborative, content-based, and context-aware systems offer partial solutions, they often struggle with issues like data sparsity and overspecialization. This study proposes a novel hybrid recommender system that combines evolutionary Apriori and K-means clustering algorithms to improve recommendation accuracy and efficiency in the tourism domain. Designed specifically to address the diverse and dynamic tourism landscape in Iraq, the system provides personalized recommendations and clusters of tourist destinations tailored to user preferences and contextual information. To evaluate the systems performance, experiments were conducted on an augmented dataset representative of Iraqs tourism activity, comparing the proposed system with existing methods. Results indicate that the proposed hybrid system significantly reduces execution time by 27-56% and space consumption by 24-31%, while achieving consistently lower Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) values, thereby enhancing prediction accuracy. This approach offers a scalable, context-aware framework that is well-suited for application in regions where tourism data is limited, such as Iraq, ultimately advancing tourism recommender systems by addressing their limitations in complex and data-scarce environments.","authors":["Bryar A. Hassan","Alla A. Hassan","Joan Lu","Aram M. Ahmed","Tarik A. Rashid"],"url":"https://arxiv.org/abs/2504.08767"}
{"created":"2025-04-15","title":"Accelerating Causal Network Discovery of Alzheimer Disease Biomarkers via Scientific Literature-based Retrieval Augmented Generation","abstract":"The causal relationships between biomarkers are essential for disease diagnosis and medical treatment planning. One notable application is Alzheimer's disease (AD) diagnosis, where certain biomarkers may influence the presence of others, enabling early detection, precise disease staging, targeted treatments, and improved monitoring of disease progression. However, understanding these causal relationships is complex and requires extensive research. Constructing a comprehensive causal network of biomarkers demands significant effort from human experts, who must analyze a vast number of research papers, and have bias in understanding diseases' biomarkers and their relation. This raises an important question: Can advanced large language models (LLMs), such as those utilizing retrieval-augmented generation (RAG), assist in building causal networks of biomarkers for further medical analysis? To explore this, we collected 200 AD-related research papers published over the past 25 years and then integrated scientific literature with RAG to extract AD biomarkers and generate causal relations among them. Given the high-risk nature of the medical diagnosis, we applied uncertainty estimation to assess the reliability of the generated causal edges and examined the faithfulness and scientificness of LLM reasoning using both automatic and human evaluation. We find that RAG enhances the ability of LLMs to generate more accurate causal networks from scientific papers. However, the overall performance of LLMs in identifying causal relations of AD biomarkers is still limited. We hope this study will inspire further foundational research on AI-driven analysis of AD biomarkers causal network discovery.","authors":["Xiaofan Zhou","Liangjie Huang","Pinyang Cheng","Wenpen Yin","Rui Zhang","Wenrui Hao","Lu Cheng"],"url":"https://arxiv.org/abs/2504.08768"}
{"created":"2025-04-15","title":"Generate the browsing process for short-video recommendation","abstract":"This paper introduces a new model to generate the browsing process for short-video recommendation and proposes a novel Segment Content Aware Model via User Engagement Feedback (SCAM) for watch time prediction in video recommendation. Unlike existing methods that rely on multimodal features for video content understanding, SCAM implicitly models video content through users' historical watching behavior, enabling segment-level understanding without complex multimodal data. By dividing videos into segments based on duration and employing a Transformer-like architecture, SCAM captures the sequential dependence between segments while mitigating duration bias. Extensive experiments on industrial-scale and public datasets demonstrate SCAM's state-of-the-art performance in watch time prediction. The proposed approach offers a scalable and effective solution for video recommendation by leveraging segment-level modeling and users' engagement feedback.","authors":["Chao Feng","Yanze Zhang","Chenghao Zhang"],"url":"https://arxiv.org/abs/2504.08771"}
{"created":"2025-04-15","title":"Reward Generation via Large Vision-Language Model in Offline Reinforcement Learning","abstract":"In offline reinforcement learning (RL), learning from fixed datasets presents a promising solution for domains where real-time interaction with the environment is expensive or risky. However, designing dense reward signals for offline dataset requires significant human effort and domain expertise. Reinforcement learning with human feedback (RLHF) has emerged as an alternative, but it remains costly due to the human-in-the-loop process, prompting interest in automated reward generation models. To address this, we propose Reward Generation via Large Vision-Language Models (RG-VLM), which leverages the reasoning capabilities of LVLMs to generate rewards from offline data without human involvement. RG-VLM improves generalization in long-horizon tasks and can be seamlessly integrated with the sparse reward signals to enhance task performance, demonstrating its potential as an auxiliary reward signal.","authors":["Younghwan Lee","Tung M. Luu","Donghoon Lee","Chang D. Yoo"],"url":"https://arxiv.org/abs/2504.08772"}
{"created":"2025-04-15","title":"Counterfactual Inference under Thompson Sampling","abstract":"Recommender systems exemplify sequential decision-making under uncertainty, strategically deciding what content to serve to users, to optimise a range of potential objectives. To balance the explore-exploit trade-off successfully, Thompson sampling provides a natural and widespread paradigm to probabilistically select which action to take. Questions of causal and counterfactual inference, which underpin use-cases like offline evaluation, are not straightforward to answer in these contexts. Specifically, whilst most existing estimators rely on action propensities, these are not readily available under Thompson sampling procedures.","authors":["Olivier Jeunen"],"url":"https://arxiv.org/abs/2504.08773"}
{"created":"2025-04-15","title":"Layers at Similar Depths Generate Similar Activations Across LLM Architectures","abstract":"How do the latent spaces used by independently-trained LLMs relate to one another? We study the nearest neighbor relationships induced by activations at different layers of 24 open-weight LLMs, and find that they 1) tend to vary from layer to layer within a model, and 2) are approximately shared between corresponding layers of different models. Claim 2 shows that these nearest neighbor relationships are not arbitrary, as they are shared across models, but Claim 1 shows that they are not \"obvious\" either, as there is no single set of nearest neighbor relationships that is universally shared. Together, these suggest that LLMs generate a progression of activation geometries from layer to layer, but that this entire progression is largely shared between models, stretched and squeezed to fit into different architectures.","authors":["Christopher Wolfram","Aaron Schein"],"url":"https://arxiv.org/abs/2504.08775"}
{"created":"2025-04-15","title":"SemCAFE: When Named Entities make the Difference Assessing Web Source Reliability through Entity-level Analytics","abstract":"With the shift from traditional to digital media, the online landscape now hosts not only reliable news articles but also a significant amount of unreliable content. Digital media has faster reachability by significantly influencing public opinion and advancing political agendas. While newspaper readers may be familiar with their preferred outlets political leanings or credibility, determining unreliable news articles is much more challenging. The credibility of many online sources is often opaque, with AI generated content being easily disseminated at minimal cost. Unreliable news articles, particularly those that followed the Russian invasion of Ukraine in 2022, closely mimic the topics and writing styles of credible sources, making them difficult to distinguish. To address this, we introduce SemCAFE, a system designed to detect news reliability by incorporating entity relatedness into its assessment. SemCAFE employs standard Natural Language Processing techniques, such as boilerplate removal and tokenization, alongside entity level semantic analysis using the YAGO knowledge base. By creating a semantic fingerprint for each news article, SemCAFE could assess the credibility of 46,020 reliable and 3,407 unreliable articles on the 2022 Russian invasion of Ukraine. Our approach improved the macro F1 score by 12% over state of the art methods. The sample data and code are available on GitHub","authors":["Gautam Kishore Shahi","Oshani Seneviratne","Marc Spaniol"],"url":"https://arxiv.org/abs/2504.08776"}
{"created":"2025-04-15","title":"The Lyme Disease Controversy: An AI-Driven Discourse Analysis of a Quarter Century of Academic Debate and Divides","abstract":"The scientific discourse surrounding Chronic Lyme Disease (CLD) and Post-Treatment Lyme Disease Syndrome (PTLDS) has evolved over the past twenty-five years into a complex and polarised debate, shaped by shifting research priorities, institutional influences, and competing explanatory models. This study presents the first large-scale, systematic examination of this discourse using an innovative hybrid AI-driven methodology, combining large language models with structured human validation to analyse thousands of scholarly abstracts spanning 25 years. By integrating Large Language Models (LLMs) with expert oversight, we developed a quantitative framework for tracking epistemic shifts in contested medical fields, with applications to other content analysis domains. Our analysis revealed a progressive transition from infection-based models of Lyme disease to immune-mediated explanations for persistent symptoms. This study offers new empirical insights into the structural and epistemic forces shaping Lyme disease research, providing a scalable and replicable methodology for analysing discourse, while underscoring the value of AI-assisted methodologies in social science and medical research.","authors":["Teo Susnjak","Cole Palffy","Tatiana Zimina","Nazgul Altynbekova","Kunal Garg","Leona Gilbert"],"url":"https://arxiv.org/abs/2504.08777"}
{"created":"2025-04-15","title":"From Tokens to Lattices: Emergent Lattice Structures in Language Models","abstract":"Pretrained masked language models (MLMs) have demonstrated an impressive capability to comprehend and encode conceptual knowledge, revealing a lattice structure among concepts. This raises a critical question: how does this conceptualization emerge from MLM pretraining? In this paper, we explore this problem from the perspective of Formal Concept Analysis (FCA), a mathematical framework that derives concept lattices from the observations of object-attribute relationships. We show that the MLM's objective implicitly learns a \\emph{formal context} that describes objects, attributes, and their dependencies, which enables the reconstruction of a concept lattice through FCA. We propose a novel framework for concept lattice construction from pretrained MLMs and investigate the origin of the inductive biases of MLMs in lattice structure learning. Our framework differs from previous work because it does not rely on human-defined concepts and allows for discovering \"latent\" concepts that extend beyond human definitions. We create three datasets for evaluation, and the empirical results verify our hypothesis.","authors":["Bo Xiong","Steffen Staab"],"url":"https://arxiv.org/abs/2504.08778"}
{"created":"2025-04-15","title":"Can AI Master Construction Management (CM)? Benchmarking State-of-the-Art Large Language Models on CM Certification Exams","abstract":"The growing complexity of construction management (CM) projects, coupled with challenges such as strict regulatory requirements and labor shortages, requires specialized analytical tools that streamline project workflow and enhance performance. Although large language models (LLMs) have demonstrated exceptional performance in general reasoning tasks, their effectiveness in tackling CM-specific challenges, such as precise quantitative analysis and regulatory interpretation, remains inadequately explored. To bridge this gap, this study introduces CMExamSet, a comprehensive benchmarking dataset comprising 689 authentic multiple-choice questions sourced from four nationally accredited CM certification exams. Our zero-shot evaluation assesses overall accuracy, subject areas (e.g., construction safety), reasoning complexity (single-step and multi-step), and question formats (text-only, figure-referenced, and table-referenced). The results indicate that GPT-4o and Claude 3.7 surpass typical human pass thresholds (70%), with average accuracies of 82% and 83%, respectively. Additionally, both models performed better on single-step tasks, with accuracies of 85.7% (GPT-4o) and 86.7% (Claude 3.7). Multi-step tasks were more challenging, reducing performance to 76.5% and 77.6%, respectively. Furthermore, both LLMs show significant limitations on figure-referenced questions, with accuracies dropping to approximately 40%. Our error pattern analysis further reveals that conceptual misunderstandings are the most common (44.4% and 47.9%), underscoring the need for enhanced domain-specific reasoning models. These findings underscore the potential of LLMs as valuable supplementary analytical tools in CM, while highlighting the need for domain-specific refinements and sustained human oversight in complex decision making.","authors":["Ruoxin Xiong","Yanyu Wang","Suat Gunhan","Yimin Zhu","Charles Berryman"],"url":"https://arxiv.org/abs/2504.08779"}
{"created":"2025-04-15","title":"How Relevance Emerges: Interpreting LoRA Fine-Tuning in Reranking LLMs","abstract":"We conduct a behavioral exploration of LoRA fine-tuned LLMs for Passage Reranking to understand how relevance signals are learned and deployed by Large Language Models. By fine-tuning Mistral-7B, LLaMA3.1-8B, and Pythia-6.9B on MS MARCO under diverse LoRA configurations, we investigate how relevance modeling evolves across checkpoints, the impact of LoRA rank (1, 2, 8, 32), and the relative importance of updated MHA vs. MLP components. Our ablations reveal which layers and projections within LoRA transformations are most critical for reranking accuracy. These findings offer fresh explanations into LoRA's adaptation mechanisms, setting the stage for deeper mechanistic studies in Information Retrieval. All models used in this study have been shared.","authors":["Atharva Nijasure","Tanya Chowdhury","James Allan"],"url":"https://arxiv.org/abs/2504.08780"}
{"created":"2025-04-15","title":"Efficient Evaluation of Large Language Models via Collaborative Filtering","abstract":"With the development of Large Language Models (LLMs), numerous benchmarks have been proposed to measure and compare the capabilities of different LLMs. However, evaluating LLMs is costly due to the large number of test instances and their slow inference speed. In this paper, we aim to explore how to efficiently estimate a model's real performance on a given benchmark based on its evaluation results on a small number of instances sampled from the benchmark. Inspired by Collaborative Filtering (CF) in Recommendation Systems (RS), we treat LLMs as users and test instances as items and propose a two-stage method. In the first stage, we treat instance selection as recommending products to users to choose instances that can easily distinguish model performance. In the second stage, we see performance prediction as rating prediction problem in RS to predict the target LLM's behavior on unselected instances. Experiments on multiple LLMs and datasets imply that our method can accurately estimate the target model's performance while largely reducing its inference overhead.","authors":["Xu-Xiang Zhong","Chao Yi","Han-Jia Ye"],"url":"https://arxiv.org/abs/2504.08781"}
{"created":"2025-04-15","title":"Embedding Hidden Adversarial Capabilities in Pre-Trained Diffusion Models","abstract":"We introduce a new attack paradigm that embeds hidden adversarial capabilities directly into diffusion models via fine-tuning, without altering their observable behavior or requiring modifications during inference. Unlike prior approaches that target specific images or adjust the generation process to produce adversarial outputs, our method integrates adversarial functionality into the model itself. The resulting tampered model generates high-quality images indistinguishable from those of the original, yet these images cause misclassification in downstream classifiers at a high rate. The misclassification can be targeted to specific output classes. Users can employ this compromised model unaware of its embedded adversarial nature, as it functions identically to a standard diffusion model. We demonstrate the effectiveness and stealthiness of our approach, uncovering a covert attack vector that raises new security concerns. These findings expose a risk arising from the use of externally-supplied models and highlight the urgent need for robust model verification and defense mechanisms against hidden threats in generative models. The code is available at https://github.com/LucasBeerens/CRAFTed-Diffusion .","authors":["Lucas Beerens","Desmond J. Higham"],"url":"https://arxiv.org/abs/2504.08782"}
{"created":"2025-04-15","title":"SLOs-Serve: Optimized Serving of Multi-SLO LLMs","abstract":"This paper introduces SLOs-Serve, a system designed for serving multi-stage large language model (LLM) requests with application- and stage-specific service level objectives (SLOs). The key idea behind SLOs-Serve is to customize the allocation of tokens to meet these SLO requirements. SLOs-Serve uses a multi-SLO dynamic programming-based algorithm to continuously optimize token allocations under SLO constraints by exploring the full design space of chunked prefill and (optional) speculative decoding. Leveraging this resource planning algorithm, SLOs-Serve effectively supports multi-SLOs and multi-replica serving with dynamic request routing while being resilient to bursty arrivals. Our evaluation across 6 LLM application scenarios (including summarization, coding, chatbot, tool calling, and reasoning) demonstrates that SLOs-Serve improves per-GPU serving capacity by 2.2x on average compared to prior state-of-the-art systems.","authors":["Siyuan Chen","Zhipeng Jia","Samira Khan","Arvind Krishnamurthy","Phillip B. Gibbons"],"url":"https://arxiv.org/abs/2504.08784"}
{"created":"2025-04-15","title":"AdaptRec: A Self-Adaptive Framework for Sequential Recommendations with Large Language Models","abstract":"The recent advancements in Large Language Models (LLMs) have generated considerable interest in their utilization for sequential recommendation tasks. While collaborative signals from similar users are central to recommendation modeling, effectively transforming these signals into a format that LLMs can understand and utilize remains challenging. The critical challenges include selecting relevant demonstrations from large-scale user interactions and ensuring their alignment with LLMs' reasoning process. To address these challenges, we introduce AdaptRec, a self-adaptive fram-ework that leverages LLMs for sequential recommendations by incorporating explicit collaborative signals. AdaptRec employs a two-phase user selection mechanism -- User Similarity Retrieval and Self-Adaptive User Selection -- to efficiently identify relevant user sequences in large-scale datasets from multi-metric evaluation. We also develop a User-Based Similarity Retrieval Prompt, enabling the model to actively select similar users and continuously refine its selection criteria during training. Using the collaborative signals from similar users, we construct a User-Contextualized Recommendation Prompt that translates their behavior sequences into natural language, explicitly integrating this information into the recommendation process. Experiments demonstrate AdaptRec's superior performance, with significant improvements in HitRatio@1 scores of 7.13\\%, 18.16\\%, and 10.41\\% across real-world datasets with full fine-tuning, and even higher gains of 23.00\\%, 15.97\\%, and 17.98\\% in few-shot scenarios.","authors":["Tong Zhang"],"url":"https://arxiv.org/abs/2504.08786"}
{"created":"2025-04-15","title":"Hub Star Modeling 2.0 for Medallion Architecture","abstract":"Data warehousing enables performant access to high-quality data integrated from dynamic data sources. The medallion architecture, a standard for data warehousing, addresses these goals by organizing data into bronze, silver and gold layers, representing raw, integrated, and fit-to-purpose data, respectively. In terms of data modeling, bronze layer retains the structure of source data with additional metadata. The gold layer follows established modeling approaches such as star schema, snowflake, and flattened tables. The silver layer, acting as a canonical form, requires a flexible and scalable model to support continuous changes and incremental development. This paper introduces an enhanced Hub Star modeling approach tailored for the medallion architecture, simplifying silver-layer data modeling by generalizing hub and star concepts. This approach has been demonstrated using Databricks and the retail-org sample dataset, with all modeling and transformation scripts available on GitHub.","authors":["Shahram Salami"],"url":"https://arxiv.org/abs/2504.08788"}
{"created":"2025-04-15","title":"PRIMA.CPP: Speeding Up 70B-Scale LLM Inference on Low-Resource Everyday Home Clusters","abstract":"Emergency of DeepSeek R1 and QwQ 32B have broken through performance barriers for running frontier large language models (LLMs) on home devices. While consumer hardware is getting stronger and model quantization is improving, existing end-side solutions still demand GPU clusters, large RAM/VRAM, and high bandwidth, far beyond what a common home cluster can handle. This paper introduces prima.cpp, a distributed inference system that runs 70B-scale models on everyday home devices using a mix of CPU/GPU, low RAM/VRAM, Wi-Fi, and cross-platform support. It uses mmap to manage model weights and introduces piped-ring parallelism with prefetching to hide disk loading. By modeling heterogeneity in computation, communication, disk, memory (and its management behavior), and OS, it optimally assigns model layers to each device's CPU and GPU, further reducing token latency. An elegant algorithm named Halda is proposed to solve this NP-hard assignment problem. We evaluate prima.cpp on a common four-node home cluster. It outperforms llama.cpp, exo, and dllama on 30B+ models while keeping memory pressure below 6%. This brings frontier 30B-70B models, such as Llama 3, DeepSeek R1, Qwen 2.5, and QwQ to home assistants, making advanced AI truly accessible to individuals. The code is open source and available at https://github.com/Lizonghang/prima.cpp.","authors":["Zonghang Li","Tao Li","Wenjiao Feng","Mohsen Guizani","Hongfang Yu"],"url":"https://arxiv.org/abs/2504.08791"}
{"created":"2025-04-15","title":"Enhancing NER Performance in Low-Resource Pakistani Languages using Cross-Lingual Data Augmentation","abstract":"Named Entity Recognition (NER), a fundamental task in Natural Language Processing (NLP), has shown significant advancements for high-resource languages. However, due to a lack of annotated datasets and limited representation in Pre-trained Language Models (PLMs), it remains understudied and challenging for low-resource languages. To address these challenges, we propose a data augmentation technique that generates culturally plausible sentences and experiments on four low-resource Pakistani languages; Urdu, Shahmukhi, Sindhi, and Pashto. By fine-tuning multilingual masked Large Language Models (LLMs), our approach demonstrates significant improvements in NER performance for Shahmukhi and Pashto. We further explore the capability of generative LLMs for NER and data augmentation using few-shot learning.","authors":["Toqeer Ehsan","Thamar Solorio"],"url":"https://arxiv.org/abs/2504.08792"}
{"created":"2025-04-15","title":"A Constraint Programming Model For Serial Batch Scheduling With Minimum Batch Size","abstract":"In serial batch (s-batch) scheduling, jobs are grouped in batches and processed sequentially within their batch. This paper considers multiple parallel machines, nonidentical job weights and release times, and sequence-dependent setup times between batches of different families. Although s-batch has been widely studied in the literature, very few papers have taken into account a minimum batch size, typical in practical settings such as semiconductor manufacturing and the metal industry. The problem with this minimum batch size requirement has been mostly tackled with dynamic programming and meta-heuristics, and no article has ever used constraint programming (CP) to do so. This paper fills this gap by proposing, for the first time, a CP model for s-batching with minimum batch size. The computational experiments on standard cases compare the CP model with two existing mixed-integer programming (MIP) models from the literature. The results demonstrate the versatility of the proposed CP model to handle multiple variations of s-batching; and its ability to produce, in large instances, better solutions than the MIP models faster.","authors":["Jorge A. Huertas","Pascal Van Hentenryck"],"url":"https://arxiv.org/abs/2504.08793"}
{"created":"2025-04-15","title":"DARIS: An Oversubscribed Spatio-Temporal Scheduler for Real-Time DNN Inference on GPUs","abstract":"The widespread use of Deep Neural Networks (DNNs) is limited by high computational demands, especially in constrained environments. GPUs, though effective accelerators, often face underutilization and rely on coarse-grained scheduling. This paper introduces DARIS, a priority-based real-time DNN scheduler for GPUs, utilizing NVIDIA's MPS and CUDA streaming for spatial sharing, and a synchronization-based staging method for temporal partitioning. In particular, DARIS improves GPU utilization and uniquely analyzes GPU concurrency by oversubscribing computing resources. It also supports zero-delay DNN migration between GPU partitions. Experiments show DARIS improves throughput by 15% and 11.5% over batching and state-of-the-art schedulers, respectively, even without batching. All high-priority tasks meet deadlines, with low-priority tasks having under 2% deadline miss rate. High-priority response times are 33% better than those of low-priority tasks.","authors":["Amir Fakhim Babaei","Thidapat Chantem"],"url":"https://arxiv.org/abs/2504.08795"}
{"created":"2025-04-15","title":"Exploring Gradient-Guided Masked Language Model to Detect Textual Adversarial Attacks","abstract":"Textual adversarial examples pose serious threats to the reliability of natural language processing systems. Recent studies suggest that adversarial examples tend to deviate from the underlying manifold of normal texts, whereas pre-trained masked language models can approximate the manifold of normal data. These findings inspire the exploration of masked language models for detecting textual adversarial attacks. We first introduce Masked Language Model-based Detection (MLMD), leveraging the mask and unmask operations of the masked language modeling (MLM) objective to induce the difference in manifold changes between normal and adversarial texts. Although MLMD achieves competitive detection performance, its exhaustive one-by-one masking strategy introduces significant computational overhead. Our posterior analysis reveals that a significant number of non-keywords in the input are not important for detection but consume resources. Building on this, we introduce Gradient-guided MLMD (GradMLMD), which leverages gradient information to identify and skip non-keywords during detection, significantly reducing resource consumption without compromising detection performance.","authors":["Xiaomei Zhang","Zhaoxi Zhang","Yanjun Zhang","Xufei Zheng","Leo Yu Zhang","Shengshan Hu","Shirui Pan"],"url":"https://arxiv.org/abs/2504.08798"}
{"created":"2025-04-15","title":"Learnable Multi-Scale Wavelet Transformer: A Novel Alternative to Self-Attention","abstract":"Transformer architectures, underpinned by the self-attention mechanism, have achieved state-of-the-art results across numerous natural language processing (NLP) tasks by effectively modeling long-range dependencies. However, the computational complexity of self-attention, scaling quadratically with input sequence length, presents significant challenges for processing very long sequences or operating under resource constraints. This paper introduces the Learnable Multi-Scale Wavelet Transformer (LMWT), a novel architecture that replaces the standard dot-product self-attention with a learnable multi-scale Haar wavelet transform module. Leveraging the intrinsic multi-resolution properties of wavelets, the LMWT efficiently captures both local details and global context. Crucially, the parameters of the wavelet transform, including scale-specific coefficients, are learned end-to-end during training, allowing the model to adapt its decomposition strategy to the data and task. We present the detailed mathematical formulation of the learnable Haar wavelet module and its integration into the transformer framework, supplemented by an architectural diagram. We conduct a comprehensive experimental evaluation on a standard machine translation benchmark (WMT16 En-De), comparing the LMWT against a baseline self-attention transformer using metrics like BLEU score, perplexity, and token accuracy. Furthermore, we analyze the computational complexity, highlighting the linear scaling of our approach, discuss its novelty in the context of related work, and explore the interpretability offered by visualizing the learned Haar coefficients. Our results indicate that the LMWT achieves competitive performance while offering substantial computational advantages, positioning it as a promising and novel alternative for efficient sequence modeling.","authors":["Andrew Kiruluta","Priscilla Burity","Samantha Williams"],"url":"https://arxiv.org/abs/2504.08801"}
{"created":"2025-04-15","title":"InfoGain Wavelets: Furthering the Design of Diffusion Wavelets for Graph-Structured Data","abstract":"Diffusion wavelets extract information from graph signals at different scales of resolution by utilizing graph diffusion operators raised to various powers, known as diffusion scales. Traditionally, the diffusion scales are chosen to be dyadic integers, $\\mathbf{2^j}$. Here, we propose a novel, unsupervised method for selecting the diffusion scales based on ideas from information theory. We then show that our method can be incorporated into wavelet-based GNNs via graph classification experiments.","authors":["David R. Johnson","Smita Krishnaswamy","Michael Perlmutter"],"url":"https://arxiv.org/abs/2504.08802"}
{"created":"2025-04-15","title":"A temporal scale transformer framework for precise remaining useful life prediction in fuel cells","abstract":"In exploring Predictive Health Management (PHM) strategies for Proton Exchange Membrane Fuel Cells (PEMFC), the Transformer model, widely used in data-driven approaches, excels in many fields but struggles with time series analysis due to its self-attention mechanism, which yields a complexity of the input sequence squared and low computational efficiency. It also faces challenges in capturing both global long-term dependencies and local details effectively. To tackle this, we propose the Temporal Scale Transformer (TSTransformer), an enhanced version of the inverted Transformer (iTransformer). Unlike traditional Transformers that treat each timestep as an input token, TSTransformer maps sequences of varying lengths into tokens at different stages for inter-sequence modeling, using attention to capture multivariate correlations and feed-forward networks (FFN) to encode sequence representations. By integrating a one-dimensional convolutional layer into the multivariate attention for multi-level scaling of K and V matrices, it improves local feature extraction, captures temporal scale characteristics, and reduces token count and computational costs. Experiments comparing TSTransformer with models like Long Short-Term Memory, iTransformer, and Transformer demonstrate its potential as a powerful tool for advancing PHM in renewable energy, effectively addressing the limitations of pure Transformer models in data-driven time series tasks.","authors":["Zezhi Tang","Xiaoyu Chen","Xin Jin","Benyuan Zhang","Wenyu Liang"],"url":"https://arxiv.org/abs/2504.08803"}
{"created":"2025-04-15","title":"Estimating Item Difficulty Using Large Language Models and Tree-Based Machine Learning Algorithms","abstract":"Estimating item difficulty through field-testing is often resource-intensive and time-consuming. As such, there is strong motivation to develop methods that can predict item difficulty at scale using only the item content. Large Language Models (LLMs) represent a new frontier for this goal. The present research examines the feasibility of using an LLM to predict item difficulty for K-5 mathematics and reading assessment items (N = 5170). Two estimation approaches were implemented: (a) a direct estimation method that prompted the LLM to assign a single difficulty rating to each item, and (b) a feature-based strategy where the LLM extracted multiple cognitive and linguistic features, which were then used in ensemble tree-based models (random forests and gradient boosting) to predict difficulty. Overall, direct LLM estimates showed moderate to strong correlations with true item difficulties. However, their accuracy varied by grade level, often performing worse for early grades. In contrast, the feature-based method yielded stronger predictive accuracy, with correlations as high as r = 0.87 and lower error estimates compared to both direct LLM predictions and baseline regressors. These findings highlight the promise of LLMs in streamlining item development and reducing reliance on extensive field testing and underscore the importance of structured feature extraction. We provide a seven-step workflow for testing professionals who would want to implement a similar item difficulty estimation approach with their item pool.","authors":["Pooya Razavi","Sonya J. Powers"],"url":"https://arxiv.org/abs/2504.08804"}
{"created":"2025-04-15","title":"Generative AI in Live Operations: Evidence of Productivity Gains in Cybersecurity and Endpoint Management","abstract":"We measure the association between generative AI (GAI) tool adoption and four metrics spanning security operations, information protection, and endpoint management: 1) number of security alerts per incident, 2) probability of security incident reopenings, 3) time to classify a data loss prevention alert, and 4) time to resolve device policy conflicts. We find that GAI is associated with robust and statistically and practically significant improvements in the four metrics. Although unobserved confounders inhibit causal identification, these results are among the first to use observational data from live operations to investigate the relationship between GAI adoption and security operations, data loss prevention, and device policy management.","authors":["James Bono","Justin Grana","Kleanthis Karakolios","Pruthvi Hanumanthapura Ramakrishna","Ankit Srivastava"],"url":"https://arxiv.org/abs/2504.08805"}
{"created":"2025-04-15","title":"Endowing Embodied Agents with Spatial Reasoning Capabilities for Vision-and-Language Navigation","abstract":"Enhancing the spatial perception capabilities of mobile robots is crucial for achieving embodied Vision-and-Language Navigation (VLN). Although significant progress has been made in simulated environments, directly transferring these capabilities to real-world scenarios often results in severe hallucination phenomena, causing robots to lose effective spatial awareness. To address this issue, we propose BrainNav, a bio-inspired spatial cognitive navigation framework inspired by biological spatial cognition theories and cognitive map theory. BrainNav integrates dual-map (coordinate map and topological map) and dual-orientation (relative orientation and absolute orientation) strategies, enabling real-time navigation through dynamic scene capture and path planning. Its five core modules-Hippocampal Memory Hub, Visual Cortex Perception Engine, Parietal Spatial Constructor, Prefrontal Decision Center, and Cerebellar Motion Execution Unit-mimic biological cognitive functions to reduce spatial hallucinations and enhance adaptability. Validated in a zero-shot real-world lab environment using the Limo Pro robot, BrainNav, compatible with GPT-4, outperforms existing State-of-the-Art (SOTA) Vision-and-Language Navigation in Continuous Environments (VLN-CE) methods without fine-tuning.","authors":["Luo Ling","Bai Qianqian"],"url":"https://arxiv.org/abs/2504.08806"}
{"created":"2025-04-15","title":"The Exploratory Study on the Relationship Between the Failure of Distance Metrics in High-Dimensional Space and Emergent Phenomena","abstract":"This paper presents a unified framework, integrating information theory and statistical mechanics, to connect metric failure in high-dimensional data with emergence in complex systems. We propose the \"Information Dilution Theorem,\" demonstrating that as dimensionality ($d$) increases, the mutual information efficiency between geometric metrics (e.g., Euclidean distance) and system states decays approximately as $O(1/d)$. This decay arises from the mismatch between linearly growing system entropy and sublinearly growing metric entropy, explaining the mechanism behind distance concentration. Building on this, we introduce information structural complexity ($C(S)$) based on the mutual information matrix spectrum and interaction encoding capacity ($C'$) derived from information bottleneck theory. The \"Emergence Critical Theorem\" states that when $C(S)$ exceeds $C'$, new global features inevitably emerge, satisfying a predefined mutual information threshold. This provides an operational criterion for self-organization and phase transitions. We discuss potential applications in physics, biology, and deep learning, suggesting potential directions like MI-based manifold learning (UMAP+) and offering a quantitative foundation for analyzing emergence across disciplines.","authors":["HongZheng Liu","YiNuo Tian","Zhiyue Wu"],"url":"https://arxiv.org/abs/2504.08807"}
{"created":"2025-04-15","title":"Exploring the Effectiveness and Interpretability of Texts in LLM-based Time Series Models","abstract":"Large Language Models (LLMs) have been applied to time series forecasting tasks, leveraging pre-trained language models as the backbone and incorporating textual data to purportedly enhance the comprehensive capabilities of LLMs for time series. However, are these texts really helpful for interpretation? This study seeks to investigate the actual efficacy and interpretability of such textual incorporations. Through a series of empirical experiments on textual prompts and textual prototypes, our findings reveal that the misalignment between two modalities exists, and the textual information does not significantly improve time series forecasting performance in many cases. Furthermore, visualization analysis indicates that the textual representations learned by existing frameworks lack sufficient interpretability when applied to time series data. We further propose a novel metric named Semantic Matching Index (SMI) to better evaluate the matching degree between time series and texts during our post hoc interpretability investigation. Our analysis reveals the misalignment and limited interpretability of texts in current time-series LLMs, and we hope this study can raise awareness of the interpretability of texts for time series. The code is available at https://github.com/zachysun/TS-Lang-Exp.","authors":["Zhengke Sun","Hangwei Qian","Ivor Tsang"],"url":"https://arxiv.org/abs/2504.08808"}
{"created":"2025-04-15","title":"Decoupling Contrastive Decoding: Robust Hallucination Mitigation in Multimodal Large Language Models","abstract":"Although multimodal large language models (MLLMs) exhibit remarkable reasoning capabilities on complex multimodal understanding tasks, they still suffer from the notorious hallucination issue: generating outputs misaligned with obvious visual or factual evidence. Currently, training-based solutions, like direct preference optimization (DPO), leverage paired preference data to suppress hallucinations. However, they risk sacrificing general reasoning capabilities due to the likelihood displacement. Meanwhile, training-free solutions, like contrastive decoding, achieve this goal by subtracting the estimated hallucination pattern from a distorted input. Yet, these handcrafted perturbations (e.g., add noise to images) may poorly capture authentic hallucination patterns. To avoid these weaknesses of existing methods, and realize robust hallucination mitigation (i.e., maintaining general reasoning performance), we propose a novel framework: Decoupling Contrastive Decoding (DCD). Specifically, DCD decouples the learning of positive and negative samples in preference datasets, and trains separate positive and negative image projections within the MLLM. The negative projection implicitly models real hallucination patterns, which enables vision-aware negative images in the contrastive decoding inference stage. Our DCD alleviates likelihood displacement by avoiding pairwise optimization and generalizes robustly without handcrafted degradation. Extensive ablations across hallucination benchmarks and general reasoning tasks demonstrate the effectiveness of DCD, i.e., it matches DPO's hallucination suppression while preserving general capabilities and outperforms the handcrafted contrastive decoding methods.","authors":["Wei Chen","Xin Yan","Bin Wen","Fan Yang","Tingting Gao","Di Zhang","Long Chen"],"url":"https://arxiv.org/abs/2504.08809"}
{"created":"2025-04-15","title":"PriM: Principle-Inspired Material Discovery through Multi-Agent Collaboration","abstract":"Complex chemical space and limited knowledge scope with biases holds immense challenge for human scientists, yet in automated materials discovery. Existing intelligent methods relies more on numerical computation, leading to inefficient exploration and results with hard-interpretability. To bridge this gap, we introduce a principles-guided material discovery system powered by language inferential multi-agent system (MAS), namely PriM. Our framework integrates automated hypothesis generation with experimental validation in a roundtable system of MAS, enabling systematic exploration while maintaining scientific rigor. Based on our framework, the case study of nano helix demonstrates higher materials exploration rate and property value while providing transparent reasoning pathways. This approach develops an automated-and-transparent paradigm for material discovery, with broad implications for rational design of functional materials. Code is publicly available at our \\href{https://github.com/amair-lab/PriM}{GitHub}.","authors":["Zheyuan Lai","Yingming Pu"],"url":"https://arxiv.org/abs/2504.08810"}
{"created":"2025-04-15","title":"Analogical Learning for Cross-Scenario Generalization: Framework and Application to Intelligent Localization","abstract":"Existing learning models often exhibit poor generalization when deployed across diverse scenarios. It is mainly due to that the underlying reference frame of the data varies with the deployment environment and settings. However, despite the data of each scenario has its distinct reference frame, its generation generally follows the same underlying physical rule. Based on these findings, this article proposes a brand-new universal deep learning framework named analogical learning (AL), which provides a highly efficient way to implicitly retrieve the reference frame information associated with a scenario and then to make accurate prediction by relative analogy across scenarios. Specifically, an elegant bipartite neural network architecture called Mateformer is designed, the first part of which calculates the relativity within multiple feature spaces between the input data and a small amount of embedded data from the current scenario, while the second part uses these relativity to guide the nonlinear analogy. We apply AL to the typical multi-scenario learning problem of intelligent wireless localization in cellular networks. Extensive experiments show that AL achieves state-of-the-art accuracy, stable transferability and robust adaptation to new scenarios without any tuning, and outperforming conventional methods with a precision improvement of nearly two orders of magnitude. All data and code are available at https://github.com/ziruichen-research/ALLoc.","authors":["Zirui Chen","Zhaoyang Zhang","Ziqing Xing","Ridong Li","Zhaohui Yang","Richeng Jin","Chongwen Huang","Yuzhi Yang","M\\'erouane Debbah"],"url":"https://arxiv.org/abs/2504.08811"}
{"created":"2025-04-15","title":"Mechanistic Anomaly Detection for \"Quirky\" Language Models","abstract":"As LLMs grow in capability, the task of supervising LLMs becomes more challenging. Supervision failures can occur if LLMs are sensitive to factors that supervisors are unaware of. We investigate Mechanistic Anomaly Detection (MAD) as a technique to augment supervision of capable models; we use internal model features to identify anomalous training signals so they can be investigated or discarded. We train detectors to flag points from the test environment that differ substantially from the training environment, and experiment with a large variety of detector features and scoring rules to detect anomalies in a set of ``quirky'' language models. We find that detectors can achieve high discrimination on some tasks, but no detector is effective across all models and tasks. MAD techniques may be effective in low-stakes applications, but advances in both detection and evaluation are likely needed if they are to be used in high stakes settings.","authors":["David O. Johnston","Arkajyoti Chakraborty","Nora Belrose"],"url":"https://arxiv.org/abs/2504.08812"}
{"created":"2025-04-15","title":"SafeMLRM: Demystifying Safety in Multi-modal Large Reasoning Models","abstract":"The rapid advancement of multi-modal large reasoning models (MLRMs) -- enhanced versions of multimodal language models (MLLMs) equipped with reasoning capabilities -- has revolutionized diverse applications. However, their safety implications remain underexplored. While prior work has exposed critical vulnerabilities in unimodal reasoning models, MLRMs introduce distinct risks from cross-modal reasoning pathways. This work presents the first systematic safety analysis of MLRMs through large-scale empirical studies comparing MLRMs with their base MLLMs. Our experiments reveal three critical findings: (1) The Reasoning Tax: Acquiring reasoning capabilities catastrophically degrades inherited safety alignment. MLRMs exhibit 37.44% higher jailbreaking success rates than base MLLMs under adversarial attacks. (2) Safety Blind Spots: While safety degradation is pervasive, certain scenarios (e.g., Illegal Activity) suffer 25 times higher attack rates -- far exceeding the average 3.4 times increase, revealing scenario-specific vulnerabilities with alarming cross-model and datasets consistency. (3) Emergent Self-Correction: Despite tight reasoning-answer safety coupling, MLRMs demonstrate nascent self-correction -- 16.9% of jailbroken reasoning steps are overridden by safe answers, hinting at intrinsic safeguards. These findings underscore the urgency of scenario-aware safety auditing and mechanisms to amplify MLRMs' self-correction potential. To catalyze research, we open-source OpenSafeMLRM, the first toolkit for MLRM safety evaluation, providing unified interface for mainstream models, datasets, and jailbreaking methods. Our work calls for immediate efforts to harden reasoning-augmented AI, ensuring its transformative potential aligns with ethical safeguards.","authors":["Junfeng Fang","Yukai Wang","Ruipeng Wang","Zijun Yao","Kun Wang","An Zhang","Xiang Wang","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2504.08813"}
{"created":"2025-04-15","title":"When Federated Learning Meets Quantum Computing: Survey and Research Opportunities","abstract":"Quantum Federated Learning (QFL) is an emerging field that harnesses advances in Quantum Computing (QC) to improve the scalability and efficiency of decentralized Federated Learning (FL) models. This paper provides a systematic and comprehensive survey of the emerging problems and solutions when FL meets QC, from research protocol to a novel taxonomy, particularly focusing on both quantum and federated limitations, such as their architectures, Noisy Intermediate Scale Quantum (NISQ) devices, and privacy preservation, so on. This work explores key developments and integration strategies, along with the impact of quantum computing on FL, keeping a sharp focus on hybrid quantum-classical approaches. The paper offers an in-depth understanding of how the strengths of QC, such as gradient hiding, state entanglement, quantum key distribution, quantum security, and quantum-enhanced differential privacy, have been integrated into FL to ensure the privacy of participants in an enhanced, fast, and secure framework. Finally, this study proposes potential future directions to address the identified research gaps and challenges, aiming to inspire faster and more secure QFL models for practical use.","authors":["Aakar Mathur","Ashish Gupta","Sajal K. Das"],"url":"https://arxiv.org/abs/2504.08814"}
{"created":"2025-04-15","title":"A Graph-Enhanced DeepONet Approach for Real-Time Estimating Hydrogen-Enriched Natural Gas Flow under Variable Operations","abstract":"Blending green hydrogen into natural gas presents a promising approach for renewable energy integration and fuel decarbonization. Accurate estimation of hydrogen fraction in hydrogen-enriched natural gas (HENG) pipeline networks is crucial for operational safety and efficiency, yet it remains challenging due to complex dynamics. While existing data-driven approaches adopt end-to-end architectures for HENG flow state estimation, their limited adaptability to varying operational conditions hinders practical applications. To this end, this study proposes a graph-enhanced DeepONet framework for the real-time estimation of HENG flow, especially hydrogen fractions. First, a dual-network architecture, called branch network and trunk network, is employed to characterize operational conditions and sparse sensor measurements to estimate the HENG state at targeted locations and time points. Second, a graph-enhance branch network is proposed to incorporate pipeline topology, improving the estimation accuracy in large-scale pipeline networks. Experimental results demonstrate that the proposed method achieves superior estimation accuracy for HCNG flow under varying operational conditions compared to conventional approaches.","authors":["Sicheng Liu","Hongchang Huang","Bo Yang","Mingxuan Cai","Xu Yang","Xinping Guan"],"url":"https://arxiv.org/abs/2504.08816"}
{"created":"2025-04-15","title":"Exploring utilization of generative AI for research and education in data-driven materials science","abstract":"Generative AI has recently had a profound impact on various fields, including daily life, research, and education. To explore its efficient utilization in data-driven materials science, we organized a hackathon -- AIMHack2024 -- in July 2024. In this hackathon, researchers from fields such as materials science, information science, bioinformatics, and condensed matter physics worked together to explore how generative AI can facilitate research and education. Based on the results of the hackathon, this paper presents topics related to (1) conducting AI-assisted software trials, (2) building AI tutors for software, and (3) developing GUI applications for software. While generative AI continues to evolve rapidly, this paper provides an early record of its application in data-driven materials science and highlights strategies for integrating AI into research and education.","authors":["Takahiro Misawa","Ai Koizumi","Ryo Tamura","Kazuyoshi Yoshimi"],"url":"https://arxiv.org/abs/2504.08817"}
{"created":"2025-04-15","title":"From Text to Time? Rethinking the Effectiveness of the Large Language Model for Time Series Forecasting","abstract":"Using pre-trained large language models (LLMs) as the backbone for time series prediction has recently gained significant research interest. However, the effectiveness of LLM backbones in this domain remains a topic of debate. Based on thorough empirical analyses, we observe that training and testing LLM-based models on small datasets often leads to the Encoder and Decoder becoming overly adapted to the dataset, thereby obscuring the true predictive capabilities of the LLM backbone. To investigate the genuine potential of LLMs in time series prediction, we introduce three pre-training models with identical architectures but different pre-training strategies. Thereby, large-scale pre-training allows us to create unbiased Encoder and Decoder components tailored to the LLM backbone. Through controlled experiments, we evaluate the zero-shot and few-shot prediction performance of the LLM, offering insights into its capabilities. Extensive experiments reveal that although the LLM backbone demonstrates some promise, its forecasting performance is limited. Our source code is publicly available in the anonymous repository: https://anonymous.4open.science/r/LLM4TS-0B5C.","authors":["Xinyu Zhang","Shanshan Feng","Xutao Li"],"url":"https://arxiv.org/abs/2504.08818"}
{"created":"2025-04-15","title":"CAReDiO: Cultural Alignment of LLM via Representativeness and Distinctiveness Guided Data Optimization","abstract":"As Large Language Models (LLMs) more deeply integrate into human life across various regions, aligning them with pluralistic cultures is crucial for improving user experience and mitigating cultural conflicts. Existing approaches develop culturally aligned LLMs primarily through fine-tuning with massive carefully curated culture-specific corpora. Nevertheless, inspired by culture theories, we identify two key challenges faced by these datasets: (1) Representativeness: These corpora fail to fully capture the target culture's core characteristics with redundancy, causing computation waste; (2) Distinctiveness: They struggle to distinguish the unique nuances of a given culture from shared patterns across other relevant ones, hindering precise cultural modeling. To handle these challenges, we introduce CAReDiO, a novel cultural data construction framework. Specifically, CAReDiO utilizes powerful LLMs to automatically generate cultural conversation data, where both the queries and responses are further optimized by maximizing representativeness and distinctiveness. Using CAReDiO, we construct a small yet effective dataset, covering five cultures, and compare it with several recent cultural corpora. Extensive experiments demonstrate that our method generates more effective data and enables cultural alignment with as few as 100 training samples, enhancing both performance and efficiency.","authors":["Jing Yao","Xiaoyuan Yi","Jindong Wang","Zhicheng Dou","Xing Xie"],"url":"https://arxiv.org/abs/2504.08820"}
{"created":"2025-04-15","title":"Probabilistic QoS Metric Forecasting in Delay-Tolerant Networks Using Conditional Diffusion Models on Latent Dynamics","abstract":"Active QoS metric prediction, commonly employed in the maintenance and operation of DTN, could enhance network performance regarding latency, throughput, energy consumption, and dependability. Naturally formulated as a multivariate time series forecasting problem, it attracts substantial research efforts. Traditional mean regression methods for time series forecasting cannot capture the data complexity adequately, resulting in deteriorated performance in operational tasks in DTNs such as routing. This paper formulates the prediction of QoS metrics in DTN as a probabilistic forecasting problem on multivariate time series, where one could quantify the uncertainty of forecasts by characterizing the distribution of these samples. The proposed approach hires diffusion models and incorporates the latent temporal dynamics of non-stationary and multi-mode data into them. Extensive experiments demonstrate the efficacy of the proposed approach by showing that it outperforms the popular probabilistic time series forecasting methods.","authors":["Enming Zhang","Zheng Liu","Yu Xiang","Yanwen Qu"],"url":"https://arxiv.org/abs/2504.08821"}
{"created":"2025-04-15","title":"FM-LoRA: Factorized Low-Rank Meta-Prompting for Continual Learning","abstract":"How to adapt a pre-trained model continuously for sequential tasks with different prediction class labels and domains and finally learn a generalizable model across diverse tasks is a long-lasting challenge. Continual learning (CL) has emerged as a promising approach to leverage pre-trained models (e.g., Transformers) for sequential tasks. While many existing CL methods incrementally store additional learned structures, such as Low-Rank Adaptation (LoRA) adapters or prompts and sometimes even preserve features from previous samples to maintain performance. This leads to unsustainable parameter growth and escalating storage costs as the number of tasks increases. Moreover, current approaches often lack task similarity awareness, which further hinders the models ability to effectively adapt to new tasks without interfering with previously acquired knowledge. To address these challenges, we propose FM-LoRA, a novel and efficient low-rank adaptation method that integrates both a dynamic rank selector (DRS) and dynamic meta-prompting (DMP). This framework allocates model capacity more effectively across tasks by leveraging a shared low-rank subspace critical for preserving knowledge, thereby avoiding continual parameter expansion. Extensive experiments on various CL benchmarks, including ImageNet-R, CIFAR100, and CUB200 for class-incremental learning (CIL), and DomainNet for domain-incremental learning (DIL), with Transformers backbone demonstrate that FM-LoRA effectively mitigates catastrophic forgetting while delivering robust performance across a diverse range of tasks and domains.","authors":["Xiaobing Yu","Jin Yang","Xiao Wu","Peijie Qiu","Xiaofeng Liu"],"url":"https://arxiv.org/abs/2504.08823"}
{"created":"2025-04-15","title":"ColonScopeX: Leveraging Explainable Expert Systems with Multimodal Data for Improved Early Diagnosis of Colorectal Cancer","abstract":"Colorectal cancer (CRC) ranks as the second leading cause of cancer-related deaths and the third most prevalent malignant tumour worldwide. Early detection of CRC remains problematic due to its non-specific and often embarrassing symptoms, which patients frequently overlook or hesitate to report to clinicians. Crucially, the stage at which CRC is diagnosed significantly impacts survivability, with a survival rate of 80-95\\% for Stage I and a stark decline to 10\\% for Stage IV. Unfortunately, in the UK, only 14.4\\% of cases are diagnosed at the earliest stage (Stage I).","authors":["Natalia Sikora","Robert L. Manschke","Alethea M. Tang","Peter Dunstan","Dean A. Harris","Su Yang"],"url":"https://arxiv.org/abs/2504.08824"}
{"created":"2025-04-15","title":"PatchTrAD: A Patch-Based Transformer focusing on Patch-Wise Reconstruction Error for Time Series Anomaly Detection","abstract":"Time series anomaly detection (TSAD) focuses on identifying whether observations in streaming data deviate significantly from normal patterns. With the prevalence of connected devices, anomaly detection on time series has become paramount, as it enables real-time monitoring and early detection of irregular behaviors across various application domains. In this work, we introduce PatchTrAD, a Patch-based Transformer model for time series anomaly detection. Our approach leverages a Transformer encoder along with the use of patches under a reconstructionbased framework for anomaly detection. Empirical evaluations on multiple benchmark datasets show that PatchTrAD is on par, in terms of detection performance, with state-of-the-art deep learning models for anomaly detection while being time efficient during inference.","authors":["Samy-Melwan Vilhes (LITIS)","Gilles Gasso (LITIS)","Mokhtar Z Alaya (LMAC)"],"url":"https://arxiv.org/abs/2504.08827"}
{"created":"2025-04-15","title":"Datum-wise Transformer for Synthetic Tabular Data Detection in the Wild","abstract":"The growing power of generative models raises major concerns about the authenticity of published content. To address this problem, several synthetic content detection methods have been proposed for uniformly structured media such as image or text. However, little work has been done on the detection of synthetic tabular data, despite its importance in industry and government. This form of data is complex to handle due to the diversity of its structures: the number and types of the columns may vary wildly from one table to another. We tackle the tough problem of detecting synthetic tabular data ''in the wild'', i.e. when the model is deployed on table structures it has never seen before. We introduce a novel datum-wise transformer architecture and show that it outperforms existing models. Furthermore, we investigate the application of domain adaptation techniques to enhance the effectiveness of our model, thereby providing a more robust data-forgery detection solution.","authors":["G. Charbel N. Kindji (IRISA","MALT)","Elisa Fromont (MALT","IRISA)","Lina Maria Rojas-Barahona","Tanguy Urvoy"],"url":"https://arxiv.org/abs/2504.08829"}
{"created":"2025-04-15","title":"Anti-Slip AI-Driven Model-Free Control with Global Exponential Stability in Skid-Steering Robots","abstract":"Undesired lateral and longitudinal wheel slippage can disrupt a mobile robot's heading angle, traction, and, eventually, desired motion. This issue makes the robotization and accurate modeling of heavy-duty machinery very challenging because the application primarily involves off-road terrains, which are susceptible to uneven motion and severe slippage. As a step toward robotization in skid-steering heavy-duty robot (SSHDR), this paper aims to design an innovative robust model-free control system developed by neural networks to strongly stabilize the robot dynamics in the presence of a broad range of potential wheel slippages. Before the control design, the dynamics of the SSHDR are first investigated by mathematically incorporating slippage effects, assuming that all functional modeling terms of the system are unknown to the control system. Then, a novel tracking control framework to guarantee global exponential stability of the SSHDR is designed as follows: 1) the unknown modeling of wheel dynamics is approximated using radial basis function neural networks (RBFNNs); and 2) a new adaptive law is proposed to compensate for slippage effects and tune the weights of the RBFNNs online during execution. Simulation and experimental results verify the proposed tracking control performance of a 4,836 kg SSHDR operating on slippery terrain.","authors":["Mehdi Heydari Shahna","Pauli Mustalahti","Jouni Mattila"],"url":"https://arxiv.org/abs/2504.08831"}
{"created":"2025-04-15","title":"Generative AI in Collaborative Academic Report Writing: Advantages, Disadvantages, and Ethical Considerations","abstract":"The availability and abundance of GenAI tools to administer tasks traditionally managed by people have raised concerns, particularly within the education and academic sectors, as some students may highly rely on these tools to complete the assignments designed to enable learning. This article focuses on informing students about the significance of investing their time during their studies on developing essential life-long learning skills using their own critical thinking, rather than depending on AI models that are susceptible to misinformation, hallucination, and bias. As we transition to an AI-centric era, it is important to educate students on how these models work, their pitfalls, and the ethical concerns associated with feeding data to such tools.","authors":["Mahshid Sadeghpour","Arathi Arakala","Asha Rao"],"url":"https://arxiv.org/abs/2504.08832"}
{"created":"2025-04-15","title":"A Systematic Literature Review of Unmanned Aerial Vehicles for Healthcare and Emergency Services","abstract":"Unmanned aerial vehicles (UAVs), initially developed for military applications, are now used in various fields. As UAVs become more common across multiple industries, it is crucial to understand how to adopt them effectively, efficiently, and safely. The utilization of UAVs in healthcare and emergency services has evolved significantly in recent years, with these aerial vehicles potentially contributing to increased survival rates and enhanced healthcare services.","authors":["Sara Habibi","Naghmeh Ivaki","Jo\\~ao Barata"],"url":"https://arxiv.org/abs/2504.08834"}
{"created":"2025-04-15","title":"VL-Rethinker: Incentivizing Self-Reflection of Vision-Language Models with Reinforcement Learning","abstract":"Recently, slow-thinking systems like GPT-o1 and DeepSeek-R1 have demonstrated great potential in solving challenging problems through explicit reflection. They significantly outperform the best fast-thinking models, such as GPT-4o, on various math and science benchmarks. However, their multimodal reasoning capabilities remain on par with fast-thinking models. For instance, GPT-o1's performance on benchmarks like MathVista, MathVerse, and MathVision is similar to fast-thinking models. In this paper, we aim to enhance the slow-thinking capabilities of vision-language models using reinforcement learning (without relying on distillation) to advance the state of the art. First, we adapt the GRPO algorithm with a novel technique called Selective Sample Replay (SSR) to address the vanishing advantages problem. While this approach yields strong performance, the resulting RL-trained models exhibit limited self-reflection or self-verification. To further encourage slow-thinking, we introduce Forced Rethinking, which appends a textual rethinking trigger to the end of initial rollouts in RL training, explicitly enforcing a self-reflection reasoning step. By combining these two techniques, our model, VL-Rethinker, advances state-of-the-art scores on MathVista, MathVerse, and MathVision to achieve 80.3%, 61.8%, and 43.9% respectively. VL-Rethinker also achieves open-source SoTA on multi-disciplinary benchmarks such as MMMU-Pro, EMMA, and MEGA-Bench, narrowing the gap with GPT-o1.","authors":["Haozhe Wang","Chao Qu","Zuming Huang","Wei Chu","Fangzhen Lin","Wenhu Chen"],"url":"https://arxiv.org/abs/2504.08837"}
{"created":"2025-04-15","title":"SD$^2$: Self-Distilled Sparse Drafters","abstract":"Speculative decoding is a powerful technique for reducing the latency of Large Language Models (LLMs), offering a fault-tolerant framework that enables the use of highly compressed draft models. In this work, we introduce Self-Distilled Sparse Drafters (SD$^2$), a novel methodology that leverages self-data distillation and fine-grained weight sparsity to produce highly efficient and well-aligned draft models. SD$^2$ systematically enhances draft token acceptance rates while significantly reducing Multiply-Accumulate operations (MACs), even in the Universal Assisted Generation (UAG) setting, where draft and target models originate from different model families. On a Llama-3.1-70B target model, SD$^2$ provides a $\\times$1.59 higher Mean Accepted Length (MAL) compared to layer-pruned draft models and reduces MACs by over 43.87% with a 8.36% reduction in MAL compared to a dense draft models. Our results highlight the potential of sparsity-aware fine-tuning and compression strategies to improve LLM inference efficiency while maintaining alignment with target models.","authors":["Mike Lasby","Nish Sinnadurai","Valavan Manohararajah","Sean Lie","Vithursan Thangarasa"],"url":"https://arxiv.org/abs/2504.08838"}
{"created":"2025-04-15","title":"Adaptive Shrinkage Estimation For Personalized Deep Kernel Regression In Modeling Brain Trajectories","abstract":"Longitudinal biomedical studies monitor individuals over time to capture dynamics in brain development, disease progression, and treatment effects. However, estimating trajectories of brain biomarkers is challenging due to biological variability, inconsistencies in measurement protocols (e.g., differences in MRI scanners), scarcity, and irregularity in longitudinal measurements. Herein, we introduce a novel personalized deep kernel regression framework for forecasting brain biomarkers, with application to regional volumetric measurements. Our approach integrates two key components: a population model that captures brain trajectories from a large and diverse cohort, and a subject-specific model that captures individual trajectories. To optimally combine these, we propose Adaptive Shrinkage Estimation, which effectively balances population and subject-specific models. We assess our model's performance through predictive accuracy metrics, uncertainty quantification, and validation against external clinical studies. Benchmarking against state-of-the-art statistical and machine learning models -- including linear mixed effects models, generalized additive models, and deep learning methods -- demonstrates the superior predictive performance of our approach. Additionally, we apply our method to predict trajectories of composite neuroimaging biomarkers, which highlights the versatility of our approach in modeling the progression of longitudinal neuroimaging biomarkers. Furthermore, validation on three external neuroimaging studies confirms the robustness of our method across different clinical contexts. We make the code available at https://github.com/vatass/AdaptiveShrinkageDKGP.","authors":["Vasiliki Tassopoulou","Haochang Shou","Christos Davatzikos"],"url":"https://arxiv.org/abs/2504.08840"}
{"created":"2025-04-15","title":"ES-HPC-MPC: Exponentially Stable Hybrid Perception Constrained MPC for Quadrotor with Suspended Payloads","abstract":"Aerial transportation using quadrotors with cable-suspended payloads holds great potential for applications in disaster response, logistics, and infrastructure maintenance. However, their hybrid and underactuated dynamics pose significant control and perception challenges. Traditional approaches often assume a taut cable condition, limiting their effectiveness in real-world applications where slack-to-taut transitions occur due to disturbances. We introduce ES-HPC-MPC, a model predictive control framework that enforces exponential stability and perception-constrained control under hybrid dynamics.","authors":["Luis F. Recalde","Mrunal Sarvaiya","Giuseppe Loianno","Guanrui Li"],"url":"https://arxiv.org/abs/2504.08841"}
{"created":"2025-04-15","title":"Towards Combinatorial Interpretability of Neural Computation","abstract":"We introduce combinatorial interpretability, a methodology for understanding neural computation by analyzing the combinatorial structures in the sign-based categorization of a network's weights and biases. We demonstrate its power through feature channel coding, a theory that explains how neural networks compute Boolean expressions and potentially underlies other categories of neural network computation. According to this theory, features are computed via feature channels: unique cross-neuron encodings shared among the inputs the feature operates on. Because different feature channels share neurons, the neurons are polysemantic and the channels interfere with one another, making the computation appear inscrutable.","authors":["Micah Adler","Dan Alistarh","Nir Shavit"],"url":"https://arxiv.org/abs/2504.08842"}
{"created":"2025-04-15","title":"AI-University: An LLM-based platform for instructional alignment to scientific classrooms","abstract":"We introduce AI University (AI-U), a flexible framework for AI-driven course content delivery that adapts to instructors' teaching styles. At its core, AI-U fine-tunes a large language model (LLM) with retrieval-augmented generation (RAG) to generate instructor-aligned responses from lecture videos, notes, and textbooks. Using a graduate-level finite-element-method (FEM) course as a case study, we present a scalable pipeline to systematically construct training data, fine-tune an open-source LLM with Low-Rank Adaptation (LoRA), and optimize its responses through RAG-based synthesis. Our evaluation - combining cosine similarity, LLM-based assessment, and expert review - demonstrates strong alignment with course materials. We also have developed a prototype web application, available at https://my-ai-university.com, that enhances traceability by linking AI-generated responses to specific sections of the relevant course material and time-stamped instances of the open-access video lectures. Our expert model is found to have greater cosine similarity with a reference on 86% of test cases. An LLM judge also found our expert model to outperform the base Llama 3.2 model approximately four times out of five. AI-U offers a scalable approach to AI-assisted education, paving the way for broader adoption in higher education. Here, our framework has been presented in the setting of a class on FEM - a subject that is central to training PhD and Master students in engineering science. However, this setting is a particular instance of a broader context: fine-tuning LLMs to research content in science.","authors":["Mostafa Faghih Shojaei","Rahul Gulati","Benjamin A. Jasperson","Shangshang Wang","Simone Cimolato","Dangli Cao","Willie Neiswanger","Krishna Garikipati"],"url":"https://arxiv.org/abs/2504.08846"}
{"created":"2025-04-15","title":"Soap Film-inspired Subdivisional Lattice Structure Construction","abstract":"Lattice structures, distinguished by their customizable geometries at the microscale and outstanding mechanical performance, have found widespread application across various industries. One fundamental process in their design and manufacturing is constructing boundary representation (B-rep) models, which are essential for running advanced applications like simulation, optimization, and process planning. However, this construction process presents significant challenges due to the high complexity of lattice structures, particularly in generating nodal shapes where robustness and smoothness issues can arise from the complex intersections between struts. To address these challenges, this paper proposes a novel approach for lattice structure construction by cutting struts and filling void regions with subdivisional nodal shapes. Inspired by soap films, the method generates smooth, shape-preserving control meshes using Laplacian fairing and subdivides them through the point-normal Loop (PN-Loop) subdivision scheme to obtain subdivisional nodal shapes. The proposed method ensures robust model construction with reduced shape deviations, enhanced surface fairness, and smooth transitions between subdivisional nodal shapes and retained struts. The effectiveness of the method has been demonstrated by a series of examples and comparisons. The code will be open-sourced upon publication.","authors":["Guoyue Luo","Qiang Zou"],"url":"https://arxiv.org/abs/2504.08847"}
{"created":"2025-04-15","title":"X-Guard: Multilingual Guard Agent for Content Moderation","abstract":"Large Language Models (LLMs) have rapidly become integral to numerous applications in critical domains where reliability is paramount. Despite significant advances in safety frameworks and guardrails, current protective measures exhibit crucial vulnerabilities, particularly in multilingual contexts. Existing safety systems remain susceptible to adversarial attacks in low-resource languages and through code-switching techniques, primarily due to their English-centric design. Furthermore, the development of effective multilingual guardrails is constrained by the scarcity of diverse cross-lingual training data. Even recent solutions like Llama Guard-3, while offering multilingual support, lack transparency in their decision-making processes. We address these challenges by introducing X-Guard agent, a transparent multilingual safety agent designed to provide content moderation across diverse linguistic contexts. X-Guard effectively defends against both conventional low-resource language attacks and sophisticated code-switching attacks. Our approach includes: curating and enhancing multiple open-source safety datasets with explicit evaluation rationales; employing a jury of judges methodology to mitigate individual judge LLM provider biases; creating a comprehensive multilingual safety dataset spanning 132 languages with 5 million data points; and developing a two-stage architecture combining a custom-finetuned mBART-50 translation module with an evaluation X-Guard 3B model trained through supervised finetuning and GRPO training. Our empirical evaluations demonstrate X-Guard's effectiveness in detecting unsafe content across multiple languages while maintaining transparency throughout the safety evaluation process. Our work represents a significant advancement in creating robust, transparent, and linguistically inclusive safety systems for LLMs and its integrated systems.","authors":["Bibek Upadhayay","Vahid Behzadan","Ph. D"],"url":"https://arxiv.org/abs/2504.08848"}
{"created":"2025-04-15","title":"Exploring Cognitive Attributes in Financial Decision-Making","abstract":"Cognitive attributes are fundamental to metacognition, shaping how individuals process information, evaluate choices, and make decisions. To develop metacognitive artificial intelligence (AI) models that reflect human reasoning, it is essential to account for the attributes that influence reasoning patterns and decision-maker behavior, often leading to different or even conflicting choices. This makes it crucial to incorporate cognitive attributes in designing AI models that align with human decision-making processes, especially in high-stakes domains such as finance, where decisions have significant real-world consequences. However, existing AI alignment research has primarily focused on value alignment, often overlooking the role of individual cognitive attributes that distinguish decision-makers. To address this issue, this paper (1) analyzes the literature on cognitive attributes, (2) establishes five criteria for defining them, and (3) categorizes 19 domain-specific cognitive attributes relevant to financial decision-making. These three components provide a strong basis for developing AI systems that accurately reflect and align with human decision-making processes in financial contexts.","authors":["Mallika Mainali","Rosina O. Weber"],"url":"https://arxiv.org/abs/2504.08849"}
{"created":"2025-04-15","title":"SpecEE: Accelerating Large Language Model Inference with Speculative Early Exiting","abstract":"Early exiting has recently emerged as a promising technique for accelerating large language models (LLMs) by effectively reducing the hardware computation and memory access. In this paper, we present SpecEE, a fast LLM inference engine with speculative early exiting. (1) At the algorithm level, we propose the speculation-based lightweight predictor design by exploiting the probabilistic correlation between the speculative tokens and the correct results and high parallelism of GPUs. (2) At the system level, we point out that not all layers need a predictor and design the two-level heuristic predictor scheduling engine based on skewed distribution and contextual similarity. (3) At the mapping level, we point out that different decoding methods share the same essential characteristics, and propose the context-aware merged mapping for predictor with efficient GPU implementations to support speculative decoding, and form a framework for various existing orthogonal acceleration techniques (e.g., quantization and sparse activation) on cloud and personal computer (PC) scenarios, successfully pushing the Pareto frontier of accuracy and speedup. It is worth noting that SpecEE can be applied to any LLM by negligible training overhead in advance without affecting the model original parameters. Extensive experiments show that SpecEE achieves 2.25x and 2.43x speedup with Llama2-7B on cloud and PC scenarios respectively.","authors":["Jiaming Xu","Jiayi Pan","Yongkang Zhou","Siming Chen","Jinhao Li","Yaoxiu Lian","Junyi Wu","Guohao Dai"],"url":"https://arxiv.org/abs/2504.08850"}
{"created":"2025-04-15","title":"Mimic In-Context Learning for Multimodal Tasks","abstract":"Recently, In-context Learning (ICL) has become a significant inference paradigm in Large Multimodal Models (LMMs), utilizing a few in-context demonstrations (ICDs) to prompt LMMs for new tasks. However, the synergistic effects in multimodal data increase the sensitivity of ICL performance to the configurations of ICDs, stimulating the need for a more stable and general mapping function. Mathematically, in Transformer-based models, ICDs act as ``shift vectors'' added to the hidden states of query tokens. Inspired by this, we introduce Mimic In-Context Learning (MimIC) to learn stable and generalizable shift effects from ICDs. Specifically, compared with some previous shift vector-based methods, MimIC more strictly approximates the shift effects by integrating lightweight learnable modules into LMMs with four key enhancements: 1) inserting shift vectors after attention layers, 2) assigning a shift vector to each attention head, 3) making shift magnitude query-dependent, and 4) employing a layer-wise alignment loss. Extensive experiments on two LMMs (Idefics-9b and Idefics2-8b-base) across three multimodal tasks (VQAv2, OK-VQA, Captioning) demonstrate that MimIC outperforms existing shift vector-based methods. The code is available at https://github.com/Kamichanw/MimIC.","authors":["Yuchu Jiang","Jiale Fu","Chenduo Hao","Xinting Hu","Yingzhe Peng","Xin Geng","Xu Yang"],"url":"https://arxiv.org/abs/2504.08851"}
{"created":"2025-04-15","title":"ML For Hardware Design Interpretability: Challenges and Opportunities","abstract":"The increasing size and complexity of machine learning (ML) models have driven the growing need for custom hardware accelerators capable of efficiently supporting ML workloads. However, the design of such accelerators remains a time-consuming process, heavily relying on engineers to manually ensure design interpretability through clear documentation and effective communication. Recent advances in large language models (LLMs) offer a promising opportunity to automate these design interpretability tasks, particularly the generation of natural language descriptions for register-transfer level (RTL) code, what we refer to as \"RTL-to-NL tasks.\" In this paper, we examine how design interpretability, particularly in RTL-to-NL tasks, influences the efficiency of the hardware design process. We review existing work adapting LLMs for these tasks, highlight key challenges that remain unaddressed, including those related to data, computation, and model development, and identify opportunities to address them. By doing so, we aim to guide future research in leveraging ML to automate RTL-to-NL tasks and improve hardware design interpretability, thereby accelerating the hardware design process and meeting the increasing demand for custom hardware accelerators in machine learning and beyond.","authors":["Raymond Baartmans","Andrew Ensinger","Victor Agostinelli","Lizhong Chen"],"url":"https://arxiv.org/abs/2504.08852"}
{"created":"2025-04-15","title":"Artificial Intelligence (AI) and the Relationship between Agency, Autonomy, and Moral Patiency","abstract":"The proliferation of Artificial Intelligence (AI) systems exhibiting complex and seemingly agentive behaviours necessitates a critical philosophical examination of their agency, autonomy, and moral status. In this paper we undertake a systematic analysis of the differences between basic, autonomous, and moral agency in artificial systems. We argue that while current AI systems are highly sophisticated, they lack genuine agency and autonomy because: they operate within rigid boundaries of pre-programmed objectives rather than exhibiting true goal-directed behaviour within their environment; they cannot authentically shape their engagement with the world; and they lack the critical self-reflection and autonomy competencies required for full autonomy. Nonetheless, we do not rule out the possibility of future systems that could achieve a limited form of artificial moral agency without consciousness through hybrid approaches to ethical decision-making. This leads us to suggest, by appealing to the necessity of consciousness for moral patiency, that such non-conscious AMAs might represent a case that challenges traditional assumptions about the necessary connection between moral agency and moral patiency.","authors":["Paul Formosa","In\\^es Hip\\'olito","Thomas Montefiore"],"url":"https://arxiv.org/abs/2504.08853"}
{"created":"2025-04-15","title":"Hardware Design and Security Needs Attention: From Survey to Path Forward","abstract":"Recent advances in attention-based artificial intelligence (AI) models have unlocked vast potential to automate digital hardware design while enhancing and strengthening security measures against various threats. This rapidly emerging field leverages Large Language Models (LLMs) to generate HDL code, identify vulnerabilities, and sometimes mitigate them. The state of the art in this design automation space utilizes optimized LLMs with HDL datasets, creating automated systems for register-transfer level (RTL) generation, verification, and debugging, and establishing LLM-driven design environments for streamlined logic designs. Additionally, attention-based models like graph attention have shown promise in chip design applications, including floorplanning. This survey investigates the integration of these models into hardware-related domains, emphasizing logic design and hardware security, with or without the use of IP libraries. This study explores the commercial and academic landscape, highlighting technical hurdles and future prospects for automating hardware design and security. Moreover, it provides new insights into the study of LLM-driven design systems, advances in hardware security mechanisms, and the impact of influential works on industry practices. Through the examination of 30 representative approaches and illustrative case studies, this paper underscores the transformative potential of attention-based models in revolutionizing hardware design while addressing the challenges that lie ahead in this interdisciplinary domain.","authors":["Sujan Ghimire","Muhtasim Alam Chowdhury","Banafsheh Saber Latibari","Muntasir Mamun","Jaeden Wolf Carpenter","Benjamin Tan","Hammond Pearce","Pratik Satam","Soheil Salehi"],"url":"https://arxiv.org/abs/2504.08854"}
{"created":"2025-04-15","title":"Exponential Shift: Humans Adapt to AI Economies","abstract":"This paper explores how artificial intelligence (AI) and robotics are transforming the global labor market. Human workers, limited to a 33% duty cycle due to rest and holidays, cost $14 to $55 per hour. In contrast, digital labor operates nearly 24/7 at just $0.10 to $0.50 per hour. We examine sectors like healthcare, education, manufacturing, and retail, finding that 40-70% of tasks could be automated. Yet, human skills like emotional intelligence and adaptability remain essential. Humans process 5,000-20,000 tokens (units of information) per hour, while AI far exceeds this, though its energy use-3.5 to 7 times higher than humans-could offset 20-40% of cost savings. Using real-world examples, such as AI in journalism and law, we illustrate these dynamics and propose six strategies-like a 4-day workweek and retraining-to ensure a fair transition to an AI-driven economy.","authors":["Kevin J McNamara","Rhea Pritham Marpu"],"url":"https://arxiv.org/abs/2504.08855"}
{"created":"2025-04-15","title":"Examining GPT's Capability to Generate and Map Course Concepts and Their Relationship","abstract":"Extracting key concepts and their relationships from course information and materials facilitates the provision of visualizations and recommendations for learners who need to select the right courses to take from a large number of courses. However, identifying and extracting themes manually is labor-intensive and time-consuming. Previous machine learning-based methods to extract relevant concepts from courses heavily rely on detailed course materials, which necessitates labor-intensive preparation of course materials. This paper investigates the potential of LLMs such as GPT in automatically generating course concepts and their relations. Specifically, we design a suite of prompts and provide GPT with the course information with different levels of detail, thereby generating high-quality course concepts and identifying their relations. Furthermore, we comprehensively evaluate the quality of the generated concepts and relationships through extensive experiments. Our results demonstrate the viability of LLMs as a tool for supporting educational content selection and delivery.","authors":["Tianyuan Yang","Ren Baofeng","Chenghao Gu","Tianjia He","Boxuan Ma","Shinichi Konomi"],"url":"https://arxiv.org/abs/2504.08856"}
{"created":"2025-04-15","title":"A Nonlinear Hash-based Optimization Method for SpMV on GPUs","abstract":"Sparse matrix-vector multiplication (SpMV) is a fundamental operation with a wide range of applications in scientific computing and artificial intelligence. However, the large scale and sparsity of sparse matrix often make it a performance bottleneck. In this paper, we highlight the effectiveness of hash-based techniques in optimizing sparse matrix reordering, introducing the Hash-based Partition (HBP) format, a lightweight SpMV approach. HBP retains the performance benefits of the 2D-partitioning method while leveraging the hash transformation's ability to group similar elements, thereby accelerating the pre-processing phase of sparse matrix reordering. Additionally, we achieve parallel load balancing across matrix blocks through a competitive method. Our experiments, conducted on both Nvidia Jetson AGX Orin and Nvidia RTX 4090, show that in the pre-processing step, our method offers an average speedup of 3.53 times compared to the sorting approach and 3.67 times compared to the dynamic programming method employed in Regu2D. Furthermore, in SpMV, our method achieves a maximum speedup of 3.32 times on Orin and 3.01 times on RTX4090 against the CSR format in sparse matrices from the University of Florida Sparse Matrix Collection.","authors":["Chen Yan","Boyu Diao","Hangda Liu","Zhulin An","Yongjun Xu"],"url":"https://arxiv.org/abs/2504.08860"}
{"created":"2025-04-15","title":"Diachronic and synchronic variation in the performance of adaptive machine learning systems: The ethical challenges","abstract":"Objectives: Machine learning (ML) has the potential to facilitate \"continual learning\" in medicine, in which an ML system continues to evolve in response to exposure to new data over time, even after being deployed in a clinical setting. In this paper, we provide a tutorial on the range of ethical issues raised by the use of such \"adaptive\" ML systems in medicine that have, thus far, been neglected in the literature.","authors":["Joshua Hatherley","Robert Sparrow"],"url":"https://arxiv.org/abs/2504.08861"}
{"created":"2025-04-15","title":"RTLRepoCoder: Repository-Level RTL Code Completion through the Combination of Fine-Tuning and Retrieval Augmentation","abstract":"As an essential part of modern hardware design, manually writing Register Transfer Level (RTL) code such as Verilog is often labor-intensive. Following the tremendous success of large language models (LLMs), researchers have begun to explore utilizing LLMs for generating RTL code. However, current studies primarily focus on generating simple single modules, which can not meet the demands in real world. In fact, due to challenges in managing long-context RTL code and complex cross-file dependencies, existing solutions cannot handle large-scale Verilog repositories in practical hardware development. As the first endeavor to exclusively adapt LLMs for large-scale RTL development, we propose RTLRepoCoder, a groundbreaking solution that incorporates specific fine-tuning and Retrieval-Augmented Generation (RAG) for repository-level Verilog code completion. Open-source Verilog repositories from the real world, along with an extended context size, are used for domain-specific fine-tuning. The optimized RAG system improves the information density of the input context by retrieving relevant code snippets. Tailored optimizations for RAG are carried out, including the embedding model, the cross-file context splitting strategy, and the chunk size. Our solution achieves state-of-the-art performance on public benchmark, significantly surpassing GPT-4 and advanced domain-specific LLMs on Edit Similarity and Exact Match rate. Comprehensive experiments demonstrate the remarkable effectiveness of our approach and offer insights for future work.","authors":["Peiyang Wu","Nan Guo","Junliang Lv","Xiao Xiao","Xiaochun Ye"],"url":"https://arxiv.org/abs/2504.08862"}
{"created":"2025-04-15","title":"An Evaluation of Cultural Value Alignment in LLM","abstract":"LLMs as intelligent agents are being increasingly applied in scenarios where human interactions are involved, leading to a critical concern about whether LLMs are faithful to the variations in culture across regions. Several works have investigated this question in various ways, finding that there are biases present in the cultural representations of LLM outputs. To gain a more comprehensive view, in this work, we conduct the first large-scale evaluation of LLM culture assessing 20 countries' cultures and languages across ten LLMs. With a renowned cultural values questionnaire and by carefully analyzing LLM output with human ground truth scores, we thoroughly study LLMs' cultural alignment across countries and among individual models. Our findings show that the output over all models represents a moderate cultural middle ground. Given the overall skew, we propose an alignment metric, revealing that the United States is the best-aligned country and GLM-4 has the best ability to align to cultural values. Deeper investigation sheds light on the influence of model origin, prompt language, and value dimensions on cultural output. Specifically, models, regardless of where they originate, align better with the US than they do with China. The conclusions provide insight to how LLMs can be better aligned to various cultures as well as provoke further discussion of the potential for LLMs to propagate cultural bias and the need for more culturally adaptable models.","authors":["Nicholas Sukiennik","Chen Gao","Fengli Xu","Yong Li"],"url":"https://arxiv.org/abs/2504.08863"}
{"created":"2025-04-15","title":"An Empirical Study of Production Incidents in Generative AI Cloud Services","abstract":"The ever-increasing demand for generative artificial intelligence (GenAI) has motivated cloud-based GenAI services such as Azure OpenAI Service and Amazon Bedrock. Like any large-scale cloud service, failures are inevitable in cloud-based GenAI services, resulting in user dissatisfaction and significant monetary losses. However, GenAI cloud services, featured by their massive parameter scales, hardware demands, and usage patterns, present unique challenges, including generated content quality issues and privacy concerns, compared to traditional cloud services. To understand the production reliability of GenAI cloud services, we analyzed production incidents from a leading GenAI cloud service provider spanning in the past four years. Our study (1) presents the general characteristics of GenAI cloud service incidents at different stages of the incident life cycle; (2) identifies the symptoms and impacts of these incidents on GenAI cloud service quality and availability; (3) uncovers why these incidents occurred and how they were resolved; (4) discusses open research challenges in terms of incident detection, triage, and mitigation, and sheds light on potential solutions.","authors":["Haoran Yan","Yinfang Chen","Minghua Ma","Ming Wen","Shan Lu","Shenglin Zhang","Tianyin Xu","Rujia Wang","Chetan Bansal","Saravan Rajmohan","Chaoyun Zhang","Dongmei Zhang"],"url":"https://arxiv.org/abs/2504.08865"}
{"created":"2025-04-15","title":"On Transfer-based Universal Attacks in Pure Black-box Setting","abstract":"Despite their impressive performance, deep visual models are susceptible to transferable black-box adversarial attacks. Principally, these attacks craft perturbations in a target model-agnostic manner. However, surprisingly, we find that existing methods in this domain inadvertently take help from various priors that violate the black-box assumption such as the availability of the dataset used to train the target model, and the knowledge of the number of classes in the target model. Consequently, the literature fails to articulate the true potency of transferable black-box attacks. We provide an empirical study of these biases and propose a framework that aids in a prior-free transparent study of this paradigm. Using our framework, we analyze the role of prior knowledge of the target model data and number of classes in attack performance. We also provide several interesting insights based on our analysis, and demonstrate that priors cause overestimation in transferability scores. Finally, we extend our framework to query-based attacks. This extension inspires a novel image-blending technique to prepare data for effective surrogate model training.","authors":["Mohammad A. A. K. Jalwana","Naveed Akhtar","Ajmal Mian","Nazanin Rahnavard","Mubarak Shah"],"url":"https://arxiv.org/abs/2504.08866"}
{"created":"2025-04-15","title":"In almost all shallow analytic neural network optimization landscapes, efficient minimizers have strongly convex neighborhoods","abstract":"Whether or not a local minimum of a cost function has a strongly convex neighborhood greatly influences the asymptotic convergence rate of optimizers. In this article, we rigorously analyze the prevalence of this property for the mean squared error induced by shallow, 1-hidden layer neural networks with analytic activation functions when applied to regression problems. The parameter space is divided into two domains: the 'efficient domain' (all parameters for which the respective realization function cannot be generated by a network having a smaller number of neurons) and the 'redundant domain' (the remaining parameters). In almost all regression problems on the efficient domain the optimization landscape only features local minima that are strongly convex. Formally, we will show that for certain randomly picked regression problems the optimization landscape is almost surely a Morse function on the efficient domain. The redundant domain has significantly smaller dimension than the efficient domain and on this domain, potential local minima are never isolated.","authors":["Felix Benning","Steffen Dereich"],"url":"https://arxiv.org/abs/2504.08867"}
{"created":"2025-04-15","title":"An LLM Framework For Cryptography Over Chat Channels","abstract":"Recent advancements in Large Language Models (LLMs) have transformed communication, yet their role in secure messaging remains underexplored, especially in surveillance-heavy environments. At the same time, many governments all over the world are proposing legislation to detect, backdoor, or even ban encrypted communication. That emphasizes the need for alternative ways to communicate securely and covertly over open channels. We propose a novel cryptographic embedding framework that enables covert Public Key or Symmetric Key encrypted communication over public chat channels with humanlike produced texts. Some unique properties of our framework are: 1. It is LLM agnostic, i.e., it allows participants to use different local LLM models independently; 2. It is pre- or post-quantum agnostic; 3. It ensures indistinguishability from human-like chat-produced texts. Thus, it offers a viable alternative where traditional encryption is detectable and restricted.","authors":["Danilo Gligoroski","Mayank Raikwar","Sonu Kumar Jha"],"url":"https://arxiv.org/abs/2504.08871"}
{"created":"2025-04-15","title":"Personalizing Federated Learning for Hierarchical Edge Networks with Non-IID Data","abstract":"Accommodating edge networks between IoT devices and the cloud server in Hierarchical Federated Learning (HFL) enhances communication efficiency without compromising data privacy. However, devices connected to the same edge often share geographic or contextual similarities, leading to varying edge-level data heterogeneity with different subsets of labels per edge, on top of device-level heterogeneity. This hierarchical non-Independent and Identically Distributed (non-IID) nature, which implies that each edge has its own optimization goal, has been overlooked in HFL research. Therefore, existing edge-accommodated HFL demonstrates inconsistent performance across edges in various hierarchical non-IID scenarios. To ensure robust performance with diverse edge-level non-IID data, we propose a Personalized Hierarchical Edge-enabled Federated Learning (PHE-FL), which personalizes each edge model to perform well on the unique class distributions specific to each edge. We evaluated PHE-FL across 4 scenarios with varying levels of edge-level non-IIDness, with extreme IoT device level non-IIDness. To accurately assess the effectiveness of our personalization approach, we deployed test sets on each edge server instead of the cloud server, and used both balanced and imbalanced test sets. Extensive experiments show that PHE-FL achieves up to 83 percent higher accuracy compared to existing federated learning approaches that incorporate edge networks, given the same number of training rounds. Moreover, PHE-FL exhibits improved stability, as evidenced by reduced accuracy fluctuations relative to the state-of-the-art FedAvg with two-level (edge and cloud) aggregation.","authors":["Seunghyun Lee","Omid Tavallaie","Shuaijun Chen","Kanchana Thilakarathna","Suranga Seneviratne","Adel Nadjaran Toosi","Albert Y. Zomaya"],"url":"https://arxiv.org/abs/2504.08872"}
{"created":"2025-04-15","title":"Distilling and exploiting quantitative insights from Large Language Models for enhanced Bayesian optimization of chemical reactions","abstract":"Machine learning and Bayesian optimization (BO) algorithms can significantly accelerate the optimization of chemical reactions. Transfer learning can bolster the effectiveness of BO algorithms in low-data regimes by leveraging pre-existing chemical information or data outside the direct optimization task (i.e., source data). Large language models (LLMs) have demonstrated that chemical information present in foundation training data can give them utility for processing chemical data. Furthermore, they can be augmented with and help synthesize potentially multiple modalities of source chemical data germane to the optimization task. In this work, we examine how chemical information from LLMs can be elicited and used for transfer learning to accelerate the BO of reaction conditions to maximize yield. Specifically, we show that a survey-like prompting scheme and preference learning can be used to infer a utility function which models prior chemical information embedded in LLMs over a chemical parameter space; we find that the utility function shows modest correlation to true experimental measurements (yield) over the parameter space despite operating in a zero-shot setting. Furthermore, we show that the utility function can be leveraged to focus BO efforts in promising regions of the parameter space, improving the yield of the initial BO query and enhancing optimization in 4 of the 6 datasets studied. Overall, we view this work as a step towards bridging the gap between the chemistry knowledge embedded in LLMs and the capabilities of principled BO methods to accelerate reaction optimization.","authors":["Roshan Patel","Saeed Moayedpour","Louis De Lescure","Lorenzo Kogler-Anele","Alan Cherney","Sven Jager","Yasser Jangjou"],"url":"https://arxiv.org/abs/2504.08874"}
{"created":"2025-04-15","title":"The SERENADE project: Sensor-Based Explainable Detection of Cognitive Decline","abstract":"Mild Cognitive Impairment (MCI) affects 12-18% of individuals over 60. MCI patients exhibit cognitive dysfunctions without significant daily functional loss. While MCI may progress to dementia, predicting this transition remains a clinical challenge due to limited and unreliable indicators. Behavioral changes, like in the execution of Activities of Daily Living (ADLs), can signal such progression. Sensorized smart homes and wearable devices offer an innovative solution for continuous, non-intrusive monitoring ADLs for MCI patients. However, current machine learning models for detecting behavioral changes lack transparency, hindering clinicians' trust. This paper introduces the SERENADE project, a European Union-funded initiative that aims to detect and explain behavioral changes associated with cognitive decline using explainable AI methods. SERENADE aims at collecting one year of data from 30 MCI patients living alone, leveraging AI to support clinical decision-making and offering a new approach to early dementia detection.","authors":["Gabriele Civitarese","Michele Fiori","Andrea Arighi","Daniela Galimberti","Graziana Florio","Claudio Bettini"],"url":"https://arxiv.org/abs/2504.08877"}
{"created":"2025-04-15","title":"Knowledge Graph-extended Retrieval Augmented Generation for Question Answering","abstract":"Large Language Models (LLMs) and Knowledge Graphs (KGs) offer a promising approach to robust and explainable Question Answering (QA). While LLMs excel at natural language understanding, they suffer from knowledge gaps and hallucinations. KGs provide structured knowledge but lack natural language interaction. Ideally, an AI system should be both robust to missing facts as well as easy to communicate with. This paper proposes such a system that integrates LLMs and KGs without requiring training, ensuring adaptability across different KGs with minimal human effort. The resulting approach can be classified as a specific form of a Retrieval Augmented Generation (RAG) with a KG, thus, it is dubbed Knowledge Graph-extended Retrieval Augmented Generation (KG-RAG). It includes a question decomposition module to enhance multi-hop information retrieval and answer explainability. Using In-Context Learning (ICL) and Chain-of-Thought (CoT) prompting, it generates explicit reasoning chains processed separately to improve truthfulness. Experiments on the MetaQA benchmark show increased accuracy for multi-hop questions, though with a slight trade-off in single-hop performance compared to LLM with KG baselines. These findings demonstrate KG-RAG's potential to improve transparency in QA by bridging unstructured language understanding with structured knowledge retrieval.","authors":["Jasper Linders","Jakub M. Tomczak"],"url":"https://arxiv.org/abs/2504.08893"}
{"created":"2025-04-15","title":"Position: Beyond Euclidean -- Foundation Models Should Embrace Non-Euclidean Geometries","abstract":"In the era of foundation models and Large Language Models (LLMs), Euclidean space has been the de facto geometric setting for machine learning architectures. However, recent literature has demonstrated that this choice comes with fundamental limitations. At a large scale, real-world data often exhibit inherently non-Euclidean structures, such as multi-way relationships, hierarchies, symmetries, and non-isotropic scaling, in a variety of domains, such as languages, vision, and the natural sciences. It is challenging to effectively capture these structures within the constraints of Euclidean spaces. This position paper argues that moving beyond Euclidean geometry is not merely an optional enhancement but a necessity to maintain the scaling law for the next-generation of foundation models. By adopting these geometries, foundation models could more efficiently leverage the aforementioned structures. Task-aware adaptability that dynamically reconfigures embeddings to match the geometry of downstream applications could further enhance efficiency and expressivity. Our position is supported by a series of theoretical and empirical investigations of prevalent foundation models.Finally, we outline a roadmap for integrating non-Euclidean geometries into foundation models, including strategies for building geometric foundation models via fine-tuning, training from scratch, and hybrid approaches.","authors":["Neil He","Jiahong Liu","Buze Zhang","Ngoc Bui","Ali Maatouk","Menglin Yang","Irwin King","Melanie Weber","Rex Ying"],"url":"https://arxiv.org/abs/2504.08896"}
{"created":"2025-04-15","title":"Toward Spiking Neural Network Local Learning Modules Resistant to Adversarial Attacks","abstract":"Recent research has shown the vulnerability of Spiking Neural Networks (SNNs) under adversarial examples that are nearly indistinguishable from clean data in the context of frame-based and event-based information. The majority of these studies are constrained in generating adversarial examples using Backpropagation Through Time (BPTT), a gradient-based method which lacks biological plausibility. In contrast, local learning methods, which relax many of BPTT's constraints, remain under-explored in the context of adversarial attacks. To address this problem, we examine adversarial robustness in SNNs through the framework of four types of training algorithms. We provide an in-depth analysis of the ineffectiveness of gradient-based adversarial attacks to generate adversarial instances in this scenario. To overcome these limitations, we introduce a hybrid adversarial attack paradigm that leverages the transferability of adversarial instances. The proposed hybrid approach demonstrates superior performance, outperforming existing adversarial attack methods. Furthermore, the generalizability of the method is assessed under multi-step adversarial attacks, adversarial attacks in black-box FGSM scenarios, and within the non-spiking domain.","authors":["Jiaqi Lin","Abhronil Sengupta"],"url":"https://arxiv.org/abs/2504.08897"}
{"created":"2025-04-15","title":"HAL-NeRF: High Accuracy Localization Leveraging Neural Radiance Fields","abstract":"Precise camera localization is a critical task in XR applications and robotics. Using only the camera captures as input to a system is an inexpensive option that enables localization in large indoor and outdoor environments, but it presents challenges in achieving high accuracy. Specifically, camera relocalization methods, such as Absolute Pose Regression (APR), can localize cameras with a median translation error of more than $0.5m$ in outdoor scenes. This paper presents HAL-NeRF, a high-accuracy localization method that combines a CNN pose regressor with a refinement module based on a Monte Carlo particle filter. The Nerfacto model, an implementation of Neural Radiance Fields (NeRFs), is used to augment the data for training the pose regressor and to measure photometric loss in the particle filter refinement module. HAL-NeRF leverages Nerfacto's ability to synthesize high-quality novel views, significantly improving the performance of the localization pipeline. HAL-NeRF achieves state-of-the-art results that are conventionally measured as the average of the median per scene errors. The translation error was $0.025m$ and the rotation error was $0.59$ degrees and 0.04m and 0.58 degrees on the 7-Scenes dataset and Cambridge Landmarks datasets respectively, with the trade-off of increased computational time. This work highlights the potential of combining APR with NeRF-based refinement techniques to advance monocular camera relocalization accuracy.","authors":["Asterios Reppas","Grigorios-Aris Cheimariotis","Panos K. Papadopoulos","Panagiotis Frasiolas","Dimitrios Zarpalas"],"url":"https://arxiv.org/abs/2504.08901"}
{"created":"2025-04-15","title":"LookingGlass: Generative Anamorphoses via Laplacian Pyramid Warping","abstract":"Anamorphosis refers to a category of images that are intentionally distorted, making them unrecognizable when viewed directly. Their true form only reveals itself when seen from a specific viewpoint, which can be through some catadioptric device like a mirror or a lens. While the construction of these mathematical devices can be traced back to as early as the 17th century, they are only interpretable when viewed from a specific vantage point and tend to lose meaning when seen normally. In this paper, we revisit these famous optical illusions with a generative twist. With the help of latent rectified flow models, we propose a method to create anamorphic images that still retain a valid interpretation when viewed directly. To this end, we introduce Laplacian Pyramid Warping, a frequency-aware image warping technique key to generating high-quality visuals. Our work extends Visual Anagrams (arXiv:2311.17919) to latent space models and to a wider range of spatial transforms, enabling the creation of novel generative perceptual illusions.","authors":["Pascal Chang","Sergio Sancho","Jingwei Tang","Markus Gross","Vinicius C. Azevedo"],"url":"https://arxiv.org/abs/2504.08902"}
{"created":"2025-04-15","title":"Forecasting Communication Derailments Through Conversation Generation","abstract":"Forecasting communication derailment can be useful in real-world settings such as online content moderation, conflict resolution, and business negotiations. However, despite language models' success at identifying offensive speech present in conversations, they struggle to forecast future communication derailments. In contrast to prior work that predicts conversation outcomes solely based on the past conversation history, our approach samples multiple future conversation trajectories conditioned on existing conversation history using a fine-tuned LLM. It predicts the communication outcome based on the consensus of these trajectories. We also experimented with leveraging socio-linguistic attributes, which reflect turn-level conversation dynamics, as guidance when generating future conversations. Our method of future conversation trajectories surpasses state-of-the-art results on English communication derailment prediction benchmarks and demonstrates significant accuracy gains in ablation studies.","authors":["Yunfan Zhang","Kathleen McKeown","Smaranda Muresan"],"url":"https://arxiv.org/abs/2504.08905"}
{"created":"2025-04-15","title":"Robust SAM: On the Adversarial Robustness of Vision Foundation Models","abstract":"The Segment Anything Model (SAM) is a widely used vision foundation model with diverse applications, including image segmentation, detection, and tracking. Given SAM's wide applications, understanding its robustness against adversarial attacks is crucial for real-world deployment. However, research on SAM's robustness is still in its early stages. Existing attacks often overlook the role of prompts in evaluating SAM's robustness, and there has been insufficient exploration of defense methods to balance the robustness and accuracy. To address these gaps, this paper proposes an adversarial robustness framework designed to evaluate and enhance the robustness of SAM. Specifically, we introduce a cross-prompt attack method to enhance the attack transferability across different prompt types. Besides attacking, we propose a few-parameter adaptation strategy to defend SAM against various adversarial attacks. To balance robustness and accuracy, we use the singular value decomposition (SVD) to constrain the space of trainable parameters, where only singular values are adaptable. Experiments demonstrate that our cross-prompt attack method outperforms previous approaches in terms of attack success rate on both SAM and SAM 2. By adapting only 512 parameters, we achieve at least a 15\\% improvement in mean intersection over union (mIoU) against various adversarial attacks. Compared to previous defense methods, our approach enhances the robustness of SAM while maximally maintaining its original performance.","authors":["Jiahuan Long","Zhengqin Xu","Tingsong Jiang","Wen Yao","Shuai Jia","Chao Ma","Xiaoqian Chen"],"url":"https://arxiv.org/abs/2504.08906"}
{"created":"2025-04-15","title":"Spatial Audio Processing with Large Language Model on Wearable Devices","abstract":"Integrating spatial context into large language models (LLMs) has the potential to revolutionize human-computer interaction, particularly in wearable devices. In this work, we present a novel system architecture that incorporates spatial speech understanding into LLMs, enabling contextually aware and adaptive applications for wearable technologies. Our approach leverages microstructure-based spatial sensing to extract precise Direction of Arrival (DoA) information using a monaural microphone. To address the lack of existing dataset for microstructure-assisted speech recordings, we synthetically create a dataset called OmniTalk by using the LibriSpeech dataset. This spatial information is fused with linguistic embeddings from OpenAI's Whisper model, allowing each modality to learn complementary contextual representations. The fused embeddings are aligned with the input space of LLaMA-3.2 3B model and fine-tuned with lightweight adaptation technique LoRA to optimize for on-device processing. SING supports spatially-aware automatic speech recognition (ASR), achieving a mean error of $25.72^\\circ$-a substantial improvement compared to the 88.52$^\\circ$ median error in existing work-with a word error rate (WER) of 5.3. SING also supports soundscaping, for example, inference how many people were talking and their directions, with up to 5 people and a median DoA error of 16$^\\circ$. Our system demonstrates superior performance in spatial speech understanding while addressing the challenges of power efficiency, privacy, and hardware constraints, paving the way for advanced applications in augmented reality, accessibility, and immersive experiences.","authors":["Ayushi Mishra","Yang Bai","Priyadarshan Narayanasamy","Nakul Garg","Nirupam Roy"],"url":"https://arxiv.org/abs/2504.08907"}
{"created":"2025-04-15","title":"Hybrid AI-Physical Modeling for Penetration Bias Correction in X-band InSAR DEMs: A Greenland Case Study","abstract":"Digital elevation models derived from Interferometric Synthetic Aperture Radar (InSAR) data over glacial and snow-covered regions often exhibit systematic elevation errors, commonly termed \"penetration bias.\" We leverage existing physics-based models and propose an integrated correction framework that combines parametric physical modeling with machine learning. We evaluate the approach across three distinct training scenarios - each defined by a different set of acquisition parameters - to assess overall performance and the model's ability to generalize. Our experiments on Greenland's ice sheet using TanDEM-X data show that the proposed hybrid model corrections significantly reduce the mean and standard deviation of DEM errors compared to a purely physical modeling baseline. The hybrid framework also achieves significantly improved generalization than a pure ML approach when trained on data with limited diversity in acquisition parameters.","authors":["Islam Mansour","Georg Fischer","Ronny Haensch","Irena Hajnsek"],"url":"https://arxiv.org/abs/2504.08909"}
{"created":"2025-04-15","title":"HyperCore: The Core Framework for Building Hyperbolic Foundation Models with Comprehensive Modules","abstract":"Hyperbolic neural networks have emerged as a powerful tool for modeling hierarchical data across diverse modalities. Recent studies show that token distributions in foundation models exhibit scale-free properties, suggesting that hyperbolic space is a more suitable ambient space than Euclidean space for many pre-training and downstream tasks. However, existing tools lack essential components for building hyperbolic foundation models, making it difficult to leverage recent advancements. We introduce HyperCore, a comprehensive open-source framework that provides core modules for constructing hyperbolic foundation models across multiple modalities. HyperCore's modules can be effortlessly combined to develop novel hyperbolic foundation models, eliminating the need to extensively modify Euclidean modules from scratch and possible redundant research efforts. To demonstrate its versatility, we build and test the first fully hyperbolic vision transformers (LViT) with a fine-tuning pipeline, the first fully hyperbolic multimodal CLIP model (L-CLIP), and a hybrid Graph RAG with a hyperbolic graph encoder. Our experiments demonstrate that LViT outperforms its Euclidean counterpart. Additionally, we benchmark and reproduce experiments across hyperbolic GNNs, CNNs, Transformers, and vision Transformers to highlight HyperCore's advantages.","authors":["Neil He","Menglin Yang","Rex Ying"],"url":"https://arxiv.org/abs/2504.08912"}
{"created":"2025-04-15","title":"Circuits and Formulas for Datalog over Semirings","abstract":"In this paper, we study circuits and formulas for provenance polynomials of Datalog programs. We ask the following question: given an absorptive semiring and a fact of a Datalog program, what is the optimal depth and size of a circuit/formula that computes its provenance polynomial? We focus on absorptive semirings as these guarantee the existence of a polynomial-size circuit. Our main result is a dichotomy for several classes of Datalog programs on whether they admit a formula of polynomial size or not. We achieve this result by showing that for these Datalog programs the optimal circuit depth is either $\\Theta(\\log m)$ or $\\Theta(\\log^2 m)$, where $m$ is the input size. We also show that for Datalog programs with the polynomial fringe property, we can always construct low-depth circuits of size $O(\\log^2 m)$. Finally, we give characterizations of when Datalog programs are bounded over more general semirings.","authors":["Austen Z. Fan","Paraschos Koutris","Sudeepa Roy"],"url":"https://arxiv.org/abs/2504.08914"}
{"created":"2025-04-15","title":"Parameter-Free Fine-tuning via Redundancy Elimination for Vision Foundation Models","abstract":"Vision foundation models (VFMs) are large pre-trained models that form the backbone of various vision tasks. Fine-tuning VFMs can further unlock their potential for downstream tasks or scenarios. However, VFMs often contain significant feature redundancy, which may limit their adaptability to new tasks. In this paper, we investigate the redundancies in the segment anything model (SAM) and then propose a parameter-free fine-tuning method to address this issue. Unlike traditional fine-tuning methods that adjust parameters, our method emphasizes selecting, reusing, and enhancing pre-trained features, offering a new perspective on model fine-tuning. Specifically, we introduce a channel selection algorithm based on the model's output difference to identify redundant and effective channels. By selectively replacing the redundant channels with more effective ones, we filter out less useful features and reuse the more relevant features to downstream tasks, thereby enhancing the task-specific feature representation. Experiments on both out-of-domain and in-domain datasets demonstrate the efficiency and effectiveness of our method. Notably, our approach can seamlessly integrate with existing fine-tuning strategies (e.g., LoRA, Adapter), further boosting the performance of already fine-tuned models. Moreover, since our channel selection involves only model inference, our method significantly reduces computational and GPU memory overhead.","authors":["Jiahuan Long","Tingsong Jiang","Wen Yao","Yizhe Xiong","Zhengqin Xu","Shuai Jia","Chao Ma"],"url":"https://arxiv.org/abs/2504.08915"}
{"created":"2025-04-15","title":"Are We Merely Justifying Results ex Post Facto? Quantifying Explanatory Inversion in Post-Hoc Model Explanations","abstract":"Post-hoc explanation methods provide interpretation by attributing predictions to input features. Natural explanations are expected to interpret how the inputs lead to the predictions. Thus, a fundamental question arises: Do these explanations unintentionally reverse the natural relationship between inputs and outputs? Specifically, are the explanations rationalizing predictions from the output rather than reflecting the true decision process? To investigate such explanatory inversion, we propose Inversion Quantification (IQ), a framework that quantifies the degree to which explanations rely on outputs and deviate from faithful input-output relationships. Using the framework, we demonstrate on synthetic datasets that widely used methods such as LIME and SHAP are prone to such inversion, particularly in the presence of spurious correlations, across tabular, image, and text domains. Finally, we propose Reproduce-by-Poking (RBP), a simple and model-agnostic enhancement to post-hoc explanation methods that integrates forward perturbation checks. We further show that under the IQ framework, RBP theoretically guarantees the mitigation of explanatory inversion. Empirically, for example, on the synthesized data, RBP can reduce the inversion by 1.8% on average across iconic post-hoc explanation approaches and domains.","authors":["Zhen Tan","Song Wang","Yifan Li","Yu Kong","Jundong Li","Tianlong Chen","Huan Liu"],"url":"https://arxiv.org/abs/2504.08919"}
{"created":"2025-04-15","title":"A convergence law for continuous logic and continuous structures with finite domains","abstract":"We consider continuous relational structures with finite domain $[n] := \\{1, \\ldots, n\\}$ and a many valued logic, $CLA$, with values in the unit interval and which uses continuous connectives and continuous aggregation functions. $CLA$ subsumes first-order logic on ``conventional'' finite structures. To each relation symbol $R$ and identity constraint $ic$ on a tuple the length of which matches the arity of $R$ we associate a continuous probability density function $\\mu_R^{ic} : [0, 1] \\to [0, \\infty)$.","authors":["Vera Koponen"],"url":"https://arxiv.org/abs/2504.08923"}
{"created":"2025-04-15","title":"An Adaptive Vector Index Partitioning Scheme for Low-Latency RAG Pipeline","abstract":"Retrieval Augmented Generation (RAG) systems enhance response quality by integrating Large Language Models (LLMs) with vector databases, enabling external knowledge retrieval to support language model reasoning. While RAG enables efficient question answering with smaller LLMs, existing optimizations for vector search and LLM serving have largely been developed in isolation. As a result, their integration often leads to suboptimal end-to-end performance. ... This paper introduces VectorLiteRAG, an optimized vector index partitioning mechanism designed for RAG systems that enhances the responsiveness of the system by jointly optimizing vector search and LLM serving across CPU and GPU system. A key challenge is to determine which indices and how much of the vector index should reside on the GPU and adjusting LLM batch sizes to balance the pipeline for lower Time-To-First-Token (TTFT) and meeting user-defined Service-Level Objectives (SLOs). To address this, we leverage the insight that cluster access in vector databases exhibits access skew, where a subset of clusters are queried significantly more frequently than others. VectorLiteRAG exploits this property through an optimized memory distribution strategy, dynamically allocating the minimum number of vector indices corresponding to frequently accessed clusters onto the GPU HBM to ensure a balanced pipeline with the LLM for high responsiveness. This adaptive partitioning scheme is guided by a statistical model that informs memory allocation and workload distribution. Our evaluation demonstrates that VectorLiteRAG improves vector search responsiveness by 2x, significantly reduces end-to-end TTFT in RAG systems by intelligently balancing memory resources between vector search and LLM execution.","authors":["Junkyum Kim","Divya Mahajan"],"url":"https://arxiv.org/abs/2504.08930"}
{"created":"2025-04-15","title":"Long Context In-Context Compression by Getting to the Gist of Gisting","abstract":"Long context processing is critical for the adoption of LLMs, but existing methods often introduce architectural complexity that hinders their practical adoption. Gisting, an in-context compression method with no architectural modification to the decoder transformer, is a promising approach due to its simplicity and compatibility with existing frameworks. While effective for short instructions, we demonstrate that gisting struggles with longer contexts, with significant performance drops even at minimal compression rates. Surprisingly, a simple average pooling baseline consistently outperforms gisting. We analyze the limitations of gisting, including information flow interruptions, capacity limitations and the inability to restrict its attention to subsets of the context. Motivated by theoretical insights into the performance gap between gisting and average pooling, and supported by extensive experimentation, we propose GistPool, a new in-context compression method. GistPool preserves the simplicity of gisting, while significantly boosting its performance on long context compression tasks.","authors":["Aleksandar Petrov","Mark Sandler","Andrey Zhmoginov","Nolan Miller","Max Vladymyrov"],"url":"https://arxiv.org/abs/2504.08934"}
{"created":"2025-04-15","title":"Rethinking Few-Shot Fusion: Granular Ball Priors Enable General-Purpose Deep Image Fusion","abstract":"In image fusion tasks, due to the lack of real fused images as priors, most deep learning-based fusion methods obtain global weight features from original images in large-scale data pairs to generate images that approximate real fused images. However, unlike previous studies, this paper utilizes Granular Ball adaptation to extract features in the brightness space as priors for deep networks, enabling the fusion network to converge quickly and complete the fusion task. This leads to few-shot training for a general image fusion network, and based on this, we propose the GBFF fusion method. According to the information expression division of pixel pairs in the original fused image, we classify pixel pairs with significant performance as the positive domain and non-significant pixel pairs as the boundary domain. We perform split inference in the brightness space using Granular Ball adaptation to compute weights for pixels that express information to varying degrees, generating approximate supervision images that provide priors for the neural network in the structural brightness space. Additionally, the extracted global saliency features also adaptively provide priors for setting the loss function weights of each image in the network, guiding the network to converge quickly at both global and pixel levels alongside the supervised images, thereby enhancing the expressiveness of the fused images. Each modality only used 10 pairs of images as the training set, completing the fusion task with a limited number of iterations. Experiments validate the effectiveness of the algorithm and theory, and qualitative and quantitative comparisons with SOTA methods show that this approach is highly competitive in terms of fusion time and image expressiveness.","authors":["Minjie Deng","Yan Wei","Hao Zhai","An Wu","Yuncan Ouyang","Qianyao Peng"],"url":"https://arxiv.org/abs/2504.08937"}
{"created":"2025-04-15","title":"Combining Forecasts using Meta-Learning: A Comparative Study for Complex Seasonality","abstract":"In this paper, we investigate meta-learning for combining forecasts generated by models of different types. While typical approaches for combining forecasts involve simple averaging, machine learning techniques enable more sophisticated methods of combining through meta-learning, leading to improved forecasting accuracy. We use linear regression, $k$-nearest neighbors, multilayer perceptron, random forest, and long short-term memory as meta-learners. We define global and local meta-learning variants for time series with complex seasonality and compare meta-learners on multiple forecasting problems, demonstrating their superior performance compared to simple averaging.","authors":["Grzegorz Dudek"],"url":"https://arxiv.org/abs/2504.08940"}
{"created":"2025-04-15","title":"AgentRewardBench: Evaluating Automatic Evaluations of Web Agent Trajectories","abstract":"Web agents enable users to perform tasks on web browsers through natural language interaction. Evaluating web agents trajectories is an important problem, since it helps us determine whether the agent successfully completed the tasks. Rule-based methods are widely used for this purpose, but they are challenging to extend to new tasks and may not always recognize successful trajectories. We may achieve higher accuracy through human evaluation, but the process would be substantially slower and more expensive. Automatic evaluations with LLMs may avoid the challenges of designing new rules and manually annotating trajectories, enabling faster and cost-effective evaluation. However, it is unclear how effective they are at evaluating web agents. To this end, we propose AgentRewardBench, the first benchmark to assess the effectiveness of LLM judges for evaluating web agents. AgentRewardBench contains 1302 trajectories across 5 benchmarks and 4 LLMs. Each trajectory in AgentRewardBench is reviewed by an expert, who answers questions pertaining to the success, side effects, and repetitiveness of the agent. Using our benchmark, we evaluate 12 LLM judges and find that no single LLM excels across all benchmarks. We also find that the rule-based evaluation used by common benchmarks tends to underreport the success rate of web agents, highlighting a key weakness of rule-based evaluation and the need to develop more flexible automatic evaluations. We release the benchmark at: https://agent-reward-bench.github.io","authors":["Xing Han L\\`u","Amirhossein Kazemnejad","Nicholas Meade","Arkil Patel","Dongchan Shin","Alejandra Zambrano","Karolina Sta\\'nczak","Peter Shaw","Christopher J. Pal","Siva Reddy"],"url":"https://arxiv.org/abs/2504.08942"}
{"created":"2025-04-15","title":"Investigating the Treacherous Turn in Deep Reinforcement Learning","abstract":"The Treacherous Turn refers to the scenario where an artificial intelligence (AI) agent subtly, and perhaps covertly, learns to perform a behavior that benefits itself but is deemed undesirable and potentially harmful to a human supervisor. During training, the agent learns to behave as expected by the human supervisor, but when deployed to perform its task, it performs an alternate behavior without the supervisor there to prevent it. Initial experiments applying DRL to an implementation of the A Link to the Past example do not produce the treacherous turn effect naturally, despite various modifications to the environment intended to produce it. However, in this work, we find the treacherous behavior to be reproducible in a DRL agent when using other trojan injection strategies. This approach deviates from the prototypical treacherous turn behavior since the behavior is explicitly trained into the agent, rather than occurring as an emergent consequence of environmental complexity or poor objective specification. Nonetheless, these experiments provide new insights into the challenges of producing agents capable of true treacherous turn behavior.","authors":["Chace Ashcraft","Kiran Karra","Josh Carney","Nathan Drenkow"],"url":"https://arxiv.org/abs/2504.08943"}
{"created":"2025-04-15","title":"Incremental Bidirectional Typing via Order Maintenance","abstract":"Live programming environments provide various semantic services, including type checking and evaluation, continuously as the user is editing the program. The live paradigm promises to improve the developer experience, but liveness is an implementation challenge particularly when working with large programs. This paper specifies and efficiently implements a system the is able to incrementally update type information for a live program in response to fine-grained program edits. This information includes type error marks and information about the expected and actual type on every expression. The system is specified type-theoretically as a small-step dynamics that propagates updates through the marked and annotated program. Most updates flow according to a base bidirectional type system. Additional pointers are maintained to connect bound variables to their binding locations, with edits traversing these pointers directly. Order maintenance data structures are employed to efficiently maintain these pointers and to prioritize the order of update propagation. We prove this system is equivalent to naive re-analysis in the Agda theorem prover, along with other important metatheoretic properties. We then implement it efficiently in OCaml, detailing a number of impactful optimizations. We evaluate this implementation's performance with a large stress-test and find that it is able to achieve dramatic speed-ups of 275.96$\\times$ compared to from-scratch reanalysis.","authors":["Thomas J. Porter","Marisa Kirisame","Ivan Wei","Pavel Panchekha","Cyrus Omar"],"url":"https://arxiv.org/abs/2504.08946"}
{"created":"2025-04-15","title":"Forecasting Cryptocurrency Prices using Contextual ES-adRNN with Exogenous Variables","abstract":"In this paper, we introduce a new approach to multivariate forecasting cryptocurrency prices using a hybrid contextual model combining exponential smoothing (ES) and recurrent neural network (RNN). The model consists of two tracks: the context track and the main track. The context track provides additional information to the main track, extracted from representative series. This information as well as information extracted from exogenous variables is dynamically adjusted to the individual series forecasted by the main track. The RNN stacked architecture with hierarchical dilations, incorporating recently developed attentive dilated recurrent cells, allows the model to capture short and long-term dependencies across time series and dynamically weight input information. The model generates both point daily forecasts and predictive intervals for one-day, one-week and four-week horizons. We apply our model to forecast prices of 15 cryptocurrencies based on 17 input variables and compare its performance with that of comparative models, including both statistical and ML ones.","authors":["Slawek Smyl","Grzegorz Dudek","Pawe{\\l} Pe{\\l}ka"],"url":"https://arxiv.org/abs/2504.08947"}
{"created":"2025-04-15","title":"Where Does Academic Database Research Go From Here?","abstract":"Panel proposal for an open forum to discuss and debate the future of database research in the context of industry, other research communities, and AI. Includes positions from panelists as well as a sample of the data management community.","authors":["Eugene Wu","Raul Castro Fernandez"],"url":"https://arxiv.org/abs/2504.08948"}
{"created":"2025-04-15","title":"Large Language Model Empowered Recommendation Meets All-domain Continual Pre-Training","abstract":"Recent research efforts have investigated how to integrate Large Language Models (LLMs) into recommendation, capitalizing on their semantic comprehension and open-world knowledge for user behavior understanding. These approaches predominantly employ supervised fine-tuning on single-domain user interactions to adapt LLMs for specific recommendation tasks. However, they typically encounter dual challenges: the mismatch between general language representations and domain-specific preference patterns, as well as the limited adaptability to multi-domain recommendation scenarios. To bridge these gaps, we introduce CPRec -- an All-domain Continual Pre-Training framework for Recommendation -- designed to holistically align LLMs with universal user behaviors through the continual pre-training paradigm. Specifically, we first design a unified prompt template and organize users' multi-domain behaviors into domain-specific behavioral sequences and all-domain mixed behavioral sequences that emulate real-world user decision logic. To optimize behavioral knowledge infusion, we devise a Warmup-Stable-Annealing learning rate schedule tailored for the continual pre-training paradigm in recommendation to progressively enhance the LLM's capability in knowledge adaptation from open-world knowledge to universal recommendation tasks. To evaluate the effectiveness of our CPRec, we implement it on a large-scale dataset covering seven domains and conduct extensive experiments on five real-world datasets from two distinct platforms. Experimental results confirm that our continual pre-training paradigm significantly mitigates the semantic-behavioral discrepancy and achieves state-of-the-art performance in all recommendation scenarios. The source code will be released upon acceptance.","authors":["Haokai Ma","Yunshan Ma","Ruobing Xie","Lei Meng","Jialie Shen","Xingwu Sun","Zhanhui Kang","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2504.08949"}
{"created":"2025-04-15","title":"Exploring the Effects of Load Altering Attacks on Load Frequency Control through Python and RTDS","abstract":"The modern power grid increasingly depends on advanced information and communication technology (ICT) systems to enhance performance and reliability through real-time monitoring, intelligent control, and bidirectional communication. However, ICT integration also exposes the grid to cyber-threats. Load altering attacks (LAAs), which use botnets of high-wattage devices to manipulate load profiles, are a notable threat to grid stability. While previous research has examined LAAs, their specific impact on load frequency control (LFC), critical for maintaining nominal frequency during load fluctuations, still needs to be explored. Even minor frequency deviations can jeopardize grid operations. This study bridges the gap by analyzing LAA effects on LFC through simulations of static and dynamic scenarios using Python and RTDS. The results highlight LAA impacts on frequency stability and present an eigenvalue-based stability assessment for dynamic LAAs (DLAAs), identifying key parameters influencing grid resilience.","authors":["Micha{\\l} Forystek","Andrew D. Syrmakesis","Alkistis Kontou","Panos Kotsampopoulos","Nikos D. Hatziargyriou","Charalambos Konstantinou"],"url":"https://arxiv.org/abs/2504.08951"}
{"created":"2025-04-15","title":"RiskRAG: A Data-Driven Solution for Improved AI Model Risk Reporting","abstract":"Risk reporting is essential for documenting AI models, yet only 14% of model cards mention risks, out of which 96% copying content from a small set of cards, leading to a lack of actionable insights. Existing proposals for improving model cards do not resolve these issues. To address this, we introduce RiskRAG, a Retrieval Augmented Generation based risk reporting solution guided by five design requirements we identified from literature, and co-design with 16 developers: identifying diverse model-specific risks, clearly presenting and prioritizing them, contextualizing for real-world uses, and offering actionable mitigation strategies. Drawing from 450K model cards and 600 real-world incidents, RiskRAG pre-populates contextualized risk reports. A preliminary study with 50 developers showed that they preferred RiskRAG over standard model cards, as it better met all the design requirements. A final study with 38 developers, 40 designers, and 37 media professionals showed that RiskRAG improved their way of selecting the AI model for a specific application, encouraging a more careful and deliberative decision-making. The RiskRAG project page is accessible at: https://social-dynamics.net/ai-risks/card.","authors":["Pooja S. B. Rao","Sanja \\v{S}\\'cepanovi\\'c","Ke Zhou","Edyta Paulina Bogucka","Daniele Quercia"],"url":"https://arxiv.org/abs/2504.08952"}
{"created":"2025-04-15","title":"Should you use LLMs to simulate opinions? Quality checks for early-stage deliberation","abstract":"The array of emergent capabilities of large language models (LLMs) has sparked interest in assessing their ability to simulate human opinions in a variety of contexts, potentially serving as surrogates for human subjects in opinion surveys. However, previous evaluations of this capability have depended heavily on costly, domain-specific human survey data, and mixed empirical results about LLM effectiveness create uncertainty for managers about whether investing in this technology is justified in early-stage research. To address these challenges, we introduce a series of quality checks to support early-stage deliberation about the viability of using LLMs for simulating human opinions. These checks emphasize logical constraints, model stability, and alignment with stakeholder expectations of model outputs, thereby reducing dependence on human-generated data in the initial stages of evaluation. We demonstrate the usefulness of the proposed quality control tests in the context of AI-assisted content moderation, an application that both advocates and critics of LLMs' capabilities to simulate human opinion see as a desirable potential use case. None of the tested models passed all quality control checks, revealing several failure modes. We conclude by discussing implications of these failure modes and recommend how organizations can utilize our proposed tests for prompt engineering and in their risk management practices when considering the use of LLMs for opinion simulation. We make our crowdsourced dataset of claims with human and LLM annotations publicly available for future research.","authors":["Terrence Neumann","Maria De-Arteaga","Sina Fazelpour"],"url":"https://arxiv.org/abs/2504.08954"}
{"created":"2025-04-15","title":"Factors Influencing Gender Representation in IT Faculty Programmes: Insights with a Focus on Software Engineering in a Nordic Context","abstract":"Software engineering remains male-dominated despite efforts to attract and retain women. Many leave the field due to limited opportunities, unfair treatment, and challenging workplace cultures. Examining university life and choices is important, as these formative experiences shape career aspirations and can help address the root causes of underrepresentation in the industry. The study aimed to deepen understanding of the motivations behind women's choice of a career in IT, their experiences in academic life, and how these experiences influence their career decisions, all within a Nordic context. We used a combination of surveys in the bachelor programmes in the IT faculty and interviews with only women from software engineering (SE) to provide a comprehensive view of population experiences and a closer exploration of the experiences of a smaller sample with a focus on SE.","authors":["Cristina Martinez Montes","Jonna Johansson","Emrik Dunvald"],"url":"https://arxiv.org/abs/2504.08957"}
{"created":"2025-04-15","title":"Generating Planning Feedback for Open-Ended Programming Exercises with LLMs","abstract":"To complete an open-ended programming exercise, students need to both plan a high-level solution and implement it using the appropriate syntax. However, these problems are often autograded on the correctness of the final submission through test cases, and students cannot get feedback on their planning process. Large language models (LLM) may be able to generate this feedback by detecting the overall code structure even for submissions with syntax errors. To this end, we propose an approach that detects which high-level goals and patterns (i.e. programming plans) exist in a student program with LLMs. We show that both the full GPT-4o model and a small variant (GPT-4o-mini) can detect these plans with remarkable accuracy, outperforming baselines inspired by conventional approaches to code analysis. We further show that the smaller, cost-effective variant (GPT-4o-mini) achieves results on par with state-of-the-art (GPT-4o) after fine-tuning, creating promising implications for smaller models for real-time grading. These smaller models can be incorporated into autograders for open-ended code-writing exercises to provide feedback for students' implicit planning skills, even when their program is syntactically incorrect. Furthermore, LLMs may be useful in providing feedback for problems in other domains where students start with a set of high-level solution steps and iteratively compute the output, such as math and physics problems.","authors":["Mehmet Arif Demirta\\c{s}","Claire Zheng","Max Fowler","Kathryn Cunningham"],"url":"https://arxiv.org/abs/2504.08958"}
{"created":"2025-04-15","title":"MotionDreamer: One-to-Many Motion Synthesis with Localized Generative Masked Transformer","abstract":"Generative masked transformers have demonstrated remarkable success across various content generation tasks, primarily due to their ability to effectively model large-scale dataset distributions with high consistency. However, in the animation domain, large datasets are not always available. Applying generative masked modeling to generate diverse instances from a single MoCap reference may lead to overfitting, a challenge that remains unexplored. In this work, we present MotionDreamer, a localized masked modeling paradigm designed to learn internal motion patterns from a given motion with arbitrary topology and duration. By embedding the given motion into quantized tokens with a novel distribution regularization method, MotionDreamer constructs a robust and informative codebook for local motion patterns. Moreover, a sliding window local attention is introduced in our masked transformer, enabling the generation of natural yet diverse animations that closely resemble the reference motion patterns. As demonstrated through comprehensive experiments, MotionDreamer outperforms the state-of-the-art methods that are typically GAN or Diffusion-based in both faithfulness and diversity. Thanks to the consistency and robustness of the quantization-based approach, MotionDreamer can also effectively perform downstream tasks such as temporal motion editing, \\textcolor{update}{crowd animation}, and beat-aligned dance generation, all using a single reference motion. Visit our project page: https://motiondreamer.github.io/","authors":["Yilin Wang","Chuan Guo","Yuxuan Mu","Muhammad Gohar Javed","Xinxin Zuo","Juwei Lu","Hai Jiang","Li Cheng"],"url":"https://arxiv.org/abs/2504.08959"}
{"created":"2025-04-15","title":"Quantifying the Spread of Online Incivility in Brazilian Politics","abstract":"Incivility refers to behaviors that violate collective norms and disrupt cooperation within the political process. Although large-scale online data and automated techniques have enabled the quantitative analysis of uncivil discourse, prior research has predominantly focused on impoliteness or toxicity, often overlooking other behaviors that undermine democratic values. To address this gap, we propose a multidimensional conceptual framework encompassing Impoliteness, Physical Harm and Violent Political Rhetoric, Hate Speech and Stereotyping, and Threats to Democratic Institutions and Values. Using this framework, we measure the spread of online political incivility in Brazil using approximately 5 million tweets posted by 2,307 political influencers during the 2022 Brazilian general election. Through statistical modeling and network analysis, we examine the dynamics of uncivil posts at different election stages, identify key disseminators and audiences, and explore the mechanisms driving the spread of uncivil information online. Our findings indicate that impoliteness is more likely to surge during election campaigns. In contrast, the other dimensions of incivility are often triggered by specific violent events. Moreover, we find that left-aligned individual influencers are the primary disseminators of online incivility in the Brazilian Twitter/X sphere and that they disseminate not only direct incivility but also indirect incivility when discussing or opposing incivility expressed by others. They relay those content from politicians, media agents, and individuals to reach broader audiences, revealing a diffusion pattern mixing the direct and two-step flows of communication theory. This study offers new insights into the multidimensional nature of incivility in Brazilian politics and provides a conceptual framework that can be extended to other political contexts.","authors":["Yuan Zhang","Michael Amsler","Laia Castro Herrero","Frank Esser","Alexandre Bovet"],"url":"https://arxiv.org/abs/2504.08960"}
{"created":"2025-04-15","title":"A Fully Automated Pipeline for Conversational Discourse Annotation: Tree Scheme Generation and Labeling with Large Language Models","abstract":"Recent advances in Large Language Models (LLMs) have shown promise in automating discourse annotation for conversations. While manually designing tree annotation schemes significantly improves annotation quality for humans and models, their creation remains time-consuming and requires expert knowledge. We propose a fully automated pipeline that uses LLMs to construct such schemes and perform annotation. We evaluate our approach on speech functions (SFs) and the Switchboard-DAMSL (SWBD-DAMSL) taxonomies. Our experiments compare various design choices, and we show that frequency-guided decision trees, paired with an advanced LLM for annotation, can outperform previously manually designed trees and even match or surpass human annotators while significantly reducing the time required for annotation. We release all code and resultant schemes and annotations to facilitate future research on discourse annotation.","authors":["Kseniia Petukhova","Ekaterina Kochmar"],"url":"https://arxiv.org/abs/2504.08961"}
{"created":"2025-04-15","title":"Bidirectional Linear Recurrent Models for Sequence-Level Multisource Fusion","abstract":"Sequence modeling is a critical yet challenging task with wide-ranging applications, especially in time series forecasting for domains like weather prediction, temperature monitoring, and energy load forecasting. Transformers, with their attention mechanism, have emerged as state-of-the-art due to their efficient parallel training, but they suffer from quadratic time complexity, limiting their scalability for long sequences. In contrast, recurrent neural networks (RNNs) offer linear time complexity, spurring renewed interest in linear RNNs for more computationally efficient sequence modeling. In this work, we introduce BLUR (Bidirectional Linear Unit for Recurrent network), which uses forward and backward linear recurrent units (LRUs) to capture both past and future dependencies with high computational efficiency. BLUR maintains the linear time complexity of traditional RNNs, while enabling fast parallel training through LRUs. Furthermore, it offers provably stable training and strong approximation capabilities, making it highly effective for modeling long-term dependencies. Extensive experiments on sequential image and time series datasets reveal that BLUR not only surpasses transformers and traditional RNNs in accuracy but also significantly reduces computational costs, making it particularly suitable for real-world forecasting tasks. Our code is available here.","authors":["Qisai Liu","Zhanhong Jiang","Joshua R. Waite","Chao Liu","Aditya Balu","Soumik Sarkar"],"url":"https://arxiv.org/abs/2504.08964"}
{"created":"2025-04-15","title":"PACT: Pruning and Clustering-Based Token Reduction for Faster Visual Language Models","abstract":"Visual Language Models require substantial computational resources for inference due to the additional input tokens needed to represent visual information. However, these visual tokens often contain redundant and unimportant information, resulting in an unnecessarily high number of tokens. To address this, we introduce PACT, a method that reduces inference time and memory usage by pruning irrelevant tokens and merging visually redundant ones at an early layer of the language model. Our approach uses a novel importance metric to identify unimportant tokens without relying on attention scores, making it compatible with FlashAttention. We also propose a novel clustering algorithm, called Distance Bounded Density Peak Clustering, which efficiently clusters visual tokens while constraining the distances between elements within a cluster by a predefined threshold. We demonstrate the effectiveness of PACT through extensive experiments.","authors":["Mohamed Dhouib","Davide Buscaldi","Sonia Vanier","Aymen Shabou"],"url":"https://arxiv.org/abs/2504.08966"}
{"created":"2025-04-15","title":"RAG-Based Fuzzing of Cross-Architecture Compilers","abstract":"OneAPI is an open standard that supports cross-architecture software development with minimal effort from developers. It brings DPC++ and C++ compilers which need to be thoroughly tested to verify their correctness, reliability, and security. Compilers have numerous code flows and optimization features. This process requires developers with deep understanding of the different compiler flows to craft testcases specific to target paths in the compiler. This testcase creation is a time-consuming and costly process. In this paper, we propose a large-language model (LLM)-based compiler fuzzing tool that integrates the concept of retrieval-augmented generation (RAG). This tool automates the testcase generation task and relieves experienced compiler developers from investing time to craft testcase generation patterns. We test our proposed approach on the Intel DPC++/C++ compiler. This compiler compiles SYCL code and allows developers to offload it to different architectures, e.g. GPUs and CPUs from different vendors. Using this tool, we managed to identify 87 SYCL code test cases that lead to output value mismatch or compiler runtime errors when compiled using Intel DPC++ and clang++ compilers and run on different architectures. The testcases and the identified unexpected behaviors of the compilers under test were obtained within only few hours with no prior background on the compiler passes under tests. This tool facilitates efficient compiler fuzzing with reduced developer time requirements via the dynamic testcase creation capability provided by an LLM with RAG.","authors":["Rana Elnaggar","Brian Delgado","Jason M. Fung"],"url":"https://arxiv.org/abs/2504.08967"}
{"created":"2025-04-15","title":"On Large-scale Evaluation of Embedding Models for Knowledge Graph Completion","abstract":"Knowledge graph embedding (KGE) models are extensively studied for knowledge graph completion, yet their evaluation remains constrained by unrealistic benchmarks. Commonly used datasets are either faulty or too small to reflect real-world data. Few studies examine the role of mediator nodes, which are essential for modeling n-ary relationships, or investigate model performance variation across domains. Standard evaluation metrics rely on the closed-world assumption, which penalizes models for correctly predicting missing triples, contradicting the fundamental goals of link prediction. These metrics often compress accuracy assessment into a single value, obscuring models' specific strengths and weaknesses. The prevailing evaluation protocol operates under the unrealistic assumption that an entity's properties, for which values are to be predicted, are known in advance. While alternative protocols such as property prediction, entity-pair ranking and triple classification address some of these limitations, they remain underutilized. This paper conducts a comprehensive evaluation of four representative KGE models on large-scale datasets FB-CVT-REV and FB+CVT-REV. Our analysis reveals critical insights, including substantial performance variations between small and large datasets, both in relative rankings and absolute metrics, systematic overestimation of model capabilities when n-ary relations are binarized, and fundamental limitations in current evaluation protocols and metrics.","authors":["Nasim Shirvani-Mahdavi","Farahnaz Akrami","Chengkai Li"],"url":"https://arxiv.org/abs/2504.08970"}
{"created":"2025-04-15","title":"Improving municipal responsiveness through AI-powered image analysis in E-Government","abstract":"Integration of Machine Learning (ML) techniques into public administration marks a new and transformative era for e-government systems. While traditionally e-government studies were focusing on text-based interactions, this one explores the innovative application of ML for image analysis, an approach that enables governments to address citizen petitions more efficiently. By using image classification and object detection algorithms, the model proposed in this article supports public institutions in identifying and fast responding to evidence submitted by citizens in picture format, such as infrastructure issues, environmental concerns or other urban issues that citizens might face. The research also highlights the Jevons Paradox as a critical factor, wherein increased efficiency from the citizen side (especially using mobile platforms and apps) may generate higher demand which should lead to scalable and robust solutions. Using as a case study a Romanian municipality who provided datasets of citizen-submitted images, the author analysed and proved that ML can improve accuracy and responsiveness of public institutions. The findings suggest that adopting ML for e-petition systems can not only enhance citizen participation but also speeding up administrative processes, paving the way for more transparent and effective governance. This study contributes to the discourse on e-government 3.0 by showing the potential of Artificial Intelligence (AI) to transform public service delivery, ensuring sustainable (and scalable) solutions for the growing demands of modern urban governance.","authors":["Catalin Vrabie"],"url":"https://arxiv.org/abs/2504.08972"}
{"created":"2025-04-15","title":"Mixed Signals: Decoding VLMs' Reasoning and Underlying Bias in Vision-Language Conflict","abstract":"Vision-language models (VLMs) have demonstrated impressive performance by effectively integrating visual and textual information to solve complex tasks. However, it is not clear how these models reason over the visual and textual data together, nor how the flow of information between modalities is structured. In this paper, we examine how VLMs reason by analyzing their biases when confronted with scenarios that present conflicting image and text cues, a common occurrence in real-world applications. To uncover the extent and nature of these biases, we build upon existing benchmarks to create five datasets containing mismatched image-text pairs, covering topics in mathematics, science, and visual descriptions. Our analysis shows that VLMs favor text in simpler queries but shift toward images as query complexity increases. This bias correlates with model scale, with the difference between the percentage of image- and text-preferred responses ranging from +56.8% (image favored) to -74.4% (text favored), depending on the task and model. In addition, we explore three mitigation strategies: simple prompt modifications, modifications that explicitly instruct models on how to handle conflicting information (akin to chain-of-thought prompting), and a task decomposition strategy that analyzes each modality separately before combining their results. Our findings indicate that the effectiveness of these strategies in identifying and mitigating bias varies significantly and is closely linked to the model's overall performance on the task and the specific modality in question.","authors":["Pouya Pezeshkpour","Moin Aminnaseri","Estevam Hruschka"],"url":"https://arxiv.org/abs/2504.08974"}
{"created":"2025-04-15","title":"Code-Craft: Hierarchical Graph-Based Code Summarization for Enhanced Context Retrieval","abstract":"Understanding and navigating large-scale codebases remains a significant challenge in software engineering. Existing methods often treat code as flat text or focus primarily on local structural relationships, limiting their ability to provide holistic, context-aware information retrieval. We present Hierarchical Code Graph Summarization (HCGS), a novel approach that constructs a multi-layered representation of a codebase by generating structured summaries in a bottom-up fashion from a code graph. HCGS leverages the Language Server Protocol for language-agnostic code analysis and employs a parallel level-based algorithm for efficient summary generation. Through extensive evaluation on five diverse codebases totaling 7,531 functions, HCGS demonstrates significant improvements in code retrieval accuracy, achieving up to 82 percentage relative improvement in top-1 retrieval precision for large codebases like libsignal (27.15 percentage points), and perfect Pass@3 scores for smaller repositories. The system's hierarchical approach consistently outperforms traditional code-only retrieval across all metrics, with particularly substantial gains in larger, more complex codebases where understanding function relationships is crucial.","authors":["David Sounthiraraj","Jared Hancock","Yassin Kortam","Ashok Javvaji","Prabhat Singh","Shaila Shankar"],"url":"https://arxiv.org/abs/2504.08975"}
{"created":"2025-04-15","title":"Robust Steganography from Large Language Models","abstract":"Recent steganographic schemes, starting with Meteor (CCS'21), rely on leveraging large language models (LLMs) to resolve a historically-challenging task of disguising covert communication as ``innocent-looking'' natural-language communication. However, existing methods are vulnerable to ``re-randomization attacks,'' where slight changes to the communicated text, that might go unnoticed, completely destroy any hidden message. This is also a vulnerability in more traditional encryption-based stegosystems, where adversaries can modify the randomness of an encryption scheme to destroy the hidden message while preserving an acceptable covertext to ordinary users. In this work, we study the problem of robust steganography. We introduce formal definitions of weak and strong robust LLM-based steganography, corresponding to two threat models in which natural language serves as a covertext channel resistant to realistic re-randomization attacks. We then propose two constructions satisfying these notions. We design and implement our steganographic schemes that embed arbitrary secret messages into natural language text generated by LLMs, ensuring recoverability even under adversarial paraphrasing and rewording attacks. To support further research and real-world deployment, we release our implementation and datasets for public use.","authors":["Neil Perry","Sanket Gupte","Nishant Pitta","Lior Rotem"],"url":"https://arxiv.org/abs/2504.08977"}
{"created":"2025-04-15","title":"A Formalism and Library for Database Visualization","abstract":"Existing data visualization formalisms are restricted to single-table inputs, which makes existing visualization grammars like Vega-lite or ggplot2 tedious to use, have overly complex APIs, and unsound when visualization multi-table data. This paper presents the first visualization formalism to support databases as input -- in other words, *database visualization*. A visualization specification is defined as a mapping from database constraints (e.g., schemas, types, foreign keys) to visual representations of those constraints, and we state that a visualization is *faithful* if it visually preserves the underlying database constraints. This formalism explains how visualization designs are the result of implicit data modeling decisions. We further develop a javascript library called dvl and use a series of case studies to show its expressiveness over specialized visualization systems and existing grammar-based languages.","authors":["Eugene Wu","Xiang Yu Tuang","Antonio Li","Vareesh Bainwala"],"url":"https://arxiv.org/abs/2504.08979"}
{"created":"2025-04-15","title":"AGENT: An Aerial Vehicle Generation and Design Tool Using Large Language Models","abstract":"Computer-aided design (CAD) is a promising application area for emerging artificial intelligence methods. Traditional workflows for cyberphysical systems create detailed digital models which can be evaluated by physics simulators in order to narrow the search space before creating physical prototypes. A major bottleneck of this approach is that the simulators are often computationally expensive and slow. Recent advancements in AI methods offer the possibility to accelerate these pipelines. We use the recently released AircraftVerse dataset, which is especially suited for developing and evaluating large language models for designs. AircraftVerse contains a diverse set of UAV designs represented via textual design trees together with detailed physics simulation results. Following the recent success of large language models (LLMs), we propose AGENT (Aircraft GENeraTor). AGENT is a comprehensive design tool built on the CodeT5+ LLM which learns powerful representations of aircraft textual designs directly from JSON files. We develop a curriculum of training tasks which imbues a single model with a suite of useful features. AGENT is able to generate designs conditioned on properties of flight dynamics (hover time, maximum speed, etc.). Additionally, AGENT can issue evaluations of designs allowing it to act as a surrogate model of the physics simulation that underlies the AircraftVerse dataset. We present a series of experiments which demonstrate our system's abilities. We are able to achieve strong performance using the smallest member of the CodeT5+ family (220M parameters). This allows for a flexible and powerful system which can be executed on a single GPU enabling a clear path toward future deployment.","authors":["Colin Samplawski","Adam D. Cobb","Susmit Jha"],"url":"https://arxiv.org/abs/2504.08981"}
{"created":"2025-04-15","title":"Adaptive Additive Parameter Updates of Vision Transformers for Few-Shot Continual Learning","abstract":"Integrating new class information without losing previously acquired knowledge remains a central challenge in artificial intelligence, often referred to as catastrophic forgetting. Few-shot class incremental learning (FSCIL) addresses this by first training a model on a robust dataset of base classes and then incrementally adapting it in successive sessions using only a few labeled examples per novel class. However, this approach is prone to overfitting on the limited new data, which can compromise overall performance and exacerbate forgetting. In this work, we propose a simple yet effective novel FSCIL framework that leverages a frozen Vision Transformer (ViT) backbone augmented with parameter-efficient additive updates. Our approach freezes the pre-trained ViT parameters and selectively injects trainable weights into the self-attention modules via an additive update mechanism. This design updates only a small subset of parameters to accommodate new classes without sacrificing the representations learned during the base session. By fine-tuning a limited number of parameters, our method preserves the generalizable features in the frozen ViT while reducing the risk of overfitting. Furthermore, as most parameters remain fixed, the model avoids overwriting previously learned knowledge when small novel data batches are introduced. Extensive experiments on benchmark datasets demonstrate that our approach yields state-of-the-art performance compared to baseline FSCIL methods.","authors":["Kyle Stein","Andrew Arash Mahyari","Guillermo Francia III","Eman El-Sheikh"],"url":"https://arxiv.org/abs/2504.08982"}
{"created":"2025-04-15","title":"Learning from Elders: Making an LLM-powered Chatbot for Retirement Communities more Accessible through User-centered Design","abstract":"Low technology and eHealth literacy among older adults in retirement communities hinder engagement with digital tools. To address this, we designed an LLM-powered chatbot prototype using a human-centered approach for a local retirement community. Through interviews and persona development, we prioritized accessibility and dual functionality: simplifying internal information retrieval and improving technology and eHealth literacy. A pilot trial with residents demonstrated high satisfaction and ease of use, but also identified areas for further improvement. Based on the feedback, we refined the chatbot using GPT-3.5 Turbo and Streamlit. The chatbot employs tailored prompt engineering to deliver concise responses. Accessible features like adjustable font size, interface theme and personalized follow-up responses were implemented. Future steps include enabling voice-to-text function and longitudinal intervention studies. Together, our results highlight the potential of LLM-driven chatbots to empower older adults through accessible, personalized interactions, bridging literacy gaps in retirement communities.","authors":["Luna Xingyu Li","Ray-yuan Chung","Feng Chen","Wenyu Zeng","Yein Jeon","Oleg Zaslavsky"],"url":"https://arxiv.org/abs/2504.08985"}
{"created":"2025-04-15","title":"Relative-error testing of conjunctions and decision lists","abstract":"We study the relative-error property testing model for Boolean functions that was recently introduced in the work of Chen et al. (SODA 2025). In relative-error testing, the testing algorithm gets uniform random satisfying assignments as well as black-box queries to $f$, and it must accept $f$ with high probability whenever $f$ has the property that is being tested and reject any $f$ that is relative-error far from having the property. Here the relative-error distance from $f$ to a function $g$ is measured with respect to $|f^{-1}(1)|$ rather than with respect to the entire domain size $2^n$ as in the Hamming distance measure that is used in the standard model; thus, unlike the standard model, relative-error testing allows us to study the testability of sparse Boolean functions that have few satisfying assignments. It was shown in Chen et al. (SODA 2025) that relative-error testing is at least as difficult as standard-model property testing, but for many natural and important Boolean function classes the precise relationship between the two notions is unknown.","authors":["Xi Chen","William Pires","Toniann Pitassi","Rocco A. Servedio"],"url":"https://arxiv.org/abs/2504.08987"}
{"created":"2025-04-15","title":"RouterKT: Mixture-of-Experts for Knowledge Tracing","abstract":"Knowledge Tracing (KT) is a fundamental task in Intelligent Tutoring Systems (ITS), which aims to model the dynamic knowledge states of students based on their interaction histories. However, existing KT models often rely on a global forgetting decay mechanism for capturing learning patterns, assuming that students' performance is predominantly influenced by their most recent interactions. Such approaches fail to account for the diverse and complex learning patterns arising from individual differences and varying learning stages. To address this limitation, we propose RouterKT, a novel Mixture-of-Experts (MoE) architecture designed to capture heterogeneous learning patterns by enabling experts to specialize in different patterns without any handcrafted learning pattern bias such as forgetting decay. Specifically, RouterKT introduces a \\textbf{person-wise routing mechanism} to effectively model individual-specific learning behaviors and employs \\textbf{multi-heads as experts} to enhance the modeling of complex and diverse patterns. Comprehensive experiments on ten benchmark datasets demonstrate that RouterKT exhibits significant flexibility and improves the performance of various KT backbone models, with a maximum average AUC improvement of 3.29\\% across different backbones and datasets, outperforming other state-of-the-art models. Moreover, RouterKT demonstrates consistently superior inference efficiency compared to existing approaches based on handcrafted learning pattern bias, highlighting its usability for real-world educational applications. The source code is available at https://github.com/derek-liao/RouterKT.git.","authors":["Han Liao","Shuaishuai Zu"],"url":"https://arxiv.org/abs/2504.08989"}
{"created":"2025-04-15","title":"ReCA: A Parametric ReLU Composite Activation Function","abstract":"Activation functions have been shown to affect the performance of deep neural networks significantly. While the Rectified Linear Unit (ReLU) remains the dominant choice in practice, the optimal activation function for deep neural networks remains an open research question. In this paper, we propose a novel parametric activation function, ReCA, based on ReLU, which has been shown to outperform all baselines on state-of-the-art datasets using different complex neural network architectures.","authors":["John Chidiac","Danielle Azar"],"url":"https://arxiv.org/abs/2504.08994"}
{"created":"2025-04-15","title":"MCP Bridge: A Lightweight, LLM-Agnostic RESTful Proxy for Model Context Protocol Servers","abstract":"Large Language Models (LLMs) are increasingly augmented with external tools through standardized interfaces like the Model Context Protocol (MCP). However, current MCP implementations face critical limitations: they typically require local process execution through STDIO transports, making them impractical for resource-constrained environments like mobile devices, web browsers, and edge computing. We present MCP Bridge, a lightweight RESTful proxy that connects to multiple MCP servers and exposes their capabilities through a unified API. Unlike existing solutions, MCP Bridge is fully LLM-agnostic, supporting any backend regardless of vendor. The system implements a risk-based execution model with three security levels standard execution, confirmation workflow, and Docker isolation while maintaining backward compatibility with standard MCP clients. Complementing this server-side infrastructure is a Python based MCP Gemini Agent that facilitates natural language interaction with MCP tools. The evaluation demonstrates that MCP Bridge successfully addresses the constraints of direct MCP connections while providing enhanced security controls and cross-platform compatibility, enabling sophisticated LLM-powered applications in previously inaccessible environments","authors":["Arash Ahmadi","Sarah Sharif","Yaser M. Banad"],"url":"https://arxiv.org/abs/2504.08999"}
{"created":"2025-04-15","title":"CL-CoTNav: Closed-Loop Hierarchical Chain-of-Thought for Zero-Shot Object-Goal Navigation with Vision-Language Models","abstract":"Visual Object Goal Navigation (ObjectNav) requires a robot to locate a target object in an unseen environment using egocentric observations. However, decision-making policies often struggle to transfer to unseen environments and novel target objects, which is the core generalization problem. Traditional end-to-end learning methods exacerbate this issue, as they rely on memorizing spatial patterns rather than employing structured reasoning, limiting their ability to generalize effectively. In this letter, we introduce Closed-Loop Hierarchical Chain-of-Thought Navigation (CL-CoTNav), a vision-language model (VLM)-driven ObjectNav framework that integrates structured reasoning and closed-loop feedback into navigation decision-making. To enhance generalization, we fine-tune a VLM using multi-turn question-answering (QA) data derived from human demonstration trajectories. This structured dataset enables hierarchical Chain-of-Thought (H-CoT) prompting, systematically extracting compositional knowledge to refine perception and decision-making, inspired by the human cognitive process of locating a target object through iterative reasoning steps. Additionally, we propose a Closed-Loop H-CoT mechanism that incorporates detection and reasoning confidence scores into training. This adaptive weighting strategy guides the model to prioritize high-confidence data pairs, mitigating the impact of noisy inputs and enhancing robustness against hallucinated or incorrect reasoning. Extensive experiments in the AI Habitat environment demonstrate CL-CoTNav's superior generalization to unseen scenes and novel object categories. Our method consistently outperforms state-of-the-art approaches in navigation success rate (SR) and success weighted by path length (SPL) by 22.4\\%. We release our datasets, models, and supplementary videos on our project page.","authors":["Yuxin Cai","Xiangkun He","Maonan Wang","Hongliang Guo","Wei-Yun Yau","Chen Lv"],"url":"https://arxiv.org/abs/2504.09000"}
{"created":"2025-04-15","title":"Exploring Families' Use and Mediation of Generative AI: A Multi-User Perspective","abstract":"Applications of Generative AI (GenAI), such as ChatGPT, have gained popularity among the public due to their ease of access, use, and support of educational and creative activities. Despite these benefits, GenAI poses unique risks for families, such as lacking sufficient safeguards tailored to protect children under 16 years of age and not offering parental control features. This study explores families' use and co-use of GenAI, the perceived risks and opportunities of ChatGPT, and how parents mediate their children's use of GenAI. Through semi-structured interviews with 12 families, we identified ways families used and mediated GenAI and factors that influenced parents' GenAI mediation strategies. We contextualize our findings with a modified model of family mediation strategies, drawing from previous family media and mediation frameworks. We provide insights for future research on family-GenAI interactions and highlight the need for more robust protective measures on GenAI platforms for families.","authors":["Shirley Zhang","Bengisu Cagiltay","Jennica Li","Dakota Sullivan","Bilge Mutlu","Heather Kirkorian","Kassem Fawaz"],"url":"https://arxiv.org/abs/2504.09004"}
{"created":"2025-04-15","title":"Learning in Structured Stackelberg Games","abstract":"We study structured Stackelberg games, in which both players (the leader and the follower) observe information about the state of the world at time of play. Importantly, this information may contain information about the follower, which the leader may use when deciding her strategy. Under this setting, we show that no-regret learning is possible if and only if the set of mappings from contexts to follower types that the leader uses to learn is not ``too complex''. Specifically, we find that standard learning theoretic measures of complexity do not characterize learnability in our setting and we give a new dimension which does, which we term the Stackelberg-Littlestone dimension. In the distributional setting, we give analogous results by showing that standard complexity measures do not characterize the sample complexity of learning, but a new dimension called the Stackelberg-Natarajan dimension does. We then show that an appropriate empirical risk minimization procedure achieves the corresponding sample complexity.","authors":["Maria-Florina Balcan","Kiriaki Fragkia","Keegan Harris"],"url":"https://arxiv.org/abs/2504.09006"}
{"created":"2025-04-15","title":"Community Empowerment through Location-Based AR: The Th\\'amien Ohlone AR Tour","abstract":"Community empowerment is the process of enabling communities to increase control over their narratives, resources, and futures. In HCI and design, this social challenge centers on helping marginalized groups gain agency through technology and design interventions. For Indigenous communities in particular, empowerment means not only representation but sovereignty in how their stories are told and by whom. Location-based augmented reality (AR) offers a novel opportunity to address this challenge. By overlaying digital content onto physical places, AR can spatially anchor community narratives in the real world, allowing communities to re-tell the story of a place on their own terms. Such site-specific AR experiences have already been used to reveal hidden histories, re-imagine colonial monuments, and celebrate minority cultures. The affordances of XR - particularly AR\\'s spatial interaction and immersive storytelling - make it a promising tool for cultural continuity and community activism. In this position paper, we focus on how these XR affordances can empower communities, using the Th\\'amien Ohlone AR Tour as a case study. We outline why traditional digital interventions fall short of true empowerment, how AR's immersive qualities uniquely support Indigenous self-determination, insights from co-designing the Ohlone AR Tour, and future directions to scale such efforts responsibly.","authors":["Kai Lukoff","Xinqi Zhang"],"url":"https://arxiv.org/abs/2504.09010"}
{"created":"2025-04-15","title":"A Fully Planar Approach to Field-coupled Nanocomputing: Scalable Placement and Routing Without Wire Crossings","abstract":"Field-coupled Nanocomputing (FCN) is a class of promising post-CMOS technologies that transmit information through electric or magnetic fields instead of current flow. They utilize basic building blocks called cells, which can form gates that implement Boolean functions. However, the design constraints for FCN circuits differ significantly from those for CMOS. One major challenge is that wires in FCN have to be realized as gates, i.e., they are constructed from cells and incur the same costs as gates. Additionally, all FCN technologies are fabricated on a single layer, e.g., a silicon surface, requiring all elements -- gates and wires -- to be placed within that same layer. Consequently, FCN employs special gates, called wire crossings, to enable signals to cross. While existing wire-crossing implementations are complex and were previously considered costly, initial efforts have aimed at minimizing their use. However, recent physical simulations and experiments on a quantum annealing platform have shown that currently used wire crossings in FCN significantly compromise signal stability, to the extent that circuits cannot function reliably. This work addresses that issue by introducing the first placement and routing algorithm that produces fully planar FCN circuits, eliminating the need for all wire crossings. For a comparative evaluation, a state-of-the-art placement and routing algorithm was also modified to enforce planarity. However, our proposed algorithm is more scalable and can handle inputs with up to 149k gates, enabling it to process circuits that are 182x more complex than those handled by the modified state-of-the-art algorithm.","authors":["Benjamin Hien","Marcel Walter","Simon Hofmann","Robert Wille"],"url":"https://arxiv.org/abs/2504.09012"}
{"created":"2025-04-15","title":"MSCCL++: Rethinking GPU Communication Abstractions for Cutting-edge AI Applications","abstract":"Modern cutting-edge AI applications are being developed over fast-evolving, heterogeneous, nascent hardware devices. This requires frequent reworking of the AI software stack to adopt bottom-up changes from new hardware, which takes time for general-purpose software libraries. Consequently, real applications often develop custom software stacks optimized for their specific workloads and hardware. Custom stacks help quick development and optimization, but incur a lot of redundant efforts across applications in writing non-portable code. This paper discusses an alternative communication library interface for AI applications that offers both portability and performance by reducing redundant efforts while maintaining flexibility for customization. We present MSCCL++, a novel abstraction of GPU communication based on separation of concerns: (1) a primitive interface provides a minimal hardware abstraction as a common ground for software and hardware developers to write custom communication, and (2) higher-level portable interfaces and specialized implementations enable optimization for different hardware environments. This approach makes the primitive interface reusable across applications while enabling highly flexible optimization. Compared to state-of-the-art baselines (NCCL, RCCL, and MSCCL), MSCCL++ achieves speedups of up to 3.8$\\times$ for collective communication and up to 15\\% for real-world AI inference workloads. MSCCL++ is in production of multiple AI services provided by Microsoft Azure, and is also adopted by RCCL, the GPU collective communication library maintained by AMD. MSCCL++ is open-source and available at https://github.com/microsoft/mscclpp.","authors":["Aashaka Shah","Abhinav Jangda","Binyang Li","Caio Rocha","Changho Hwang","Jithin Jose","Madan Musuvathi","Olli Saarikivi","Peng Cheng","Qinghua Zhou","Roshan Dathathri","Saeed Maleki","Ziyue Yang"],"url":"https://arxiv.org/abs/2504.09014"}
{"created":"2025-04-15","title":"VIBES: Exploring Viewer Spatial Interactions as Direct Input for Livestreamed Content","abstract":"Livestreaming has rapidly become a popular online pastime, with real-time interaction between streamer and viewer being a key motivating feature. However, viewers have traditionally had limited opportunity to directly influence the streamed content; even when such interactions are possible, it has been reliant on text-based chat. We investigate the potential of spatial interaction on the livestreamed video content as a form of direct, real-time input for livestreamed applications. We developed VIBES, a flexible digital system that registers viewers' mouse interactions on the streamed video, i.e., clicks or movements, and transmits it directly into the streamed application. We used VIBES as a technology probe; first designing possible demonstrative interactions and using these interactions to explore streamers' perception of viewer influence and possible challenges and opportunities. We then deployed applications built using VIBES in two livestreams to explore its effects on audience engagement and investigate their relationships with the stream, the streamer, and fellow audience members. The use of spatial interactions enhances engagement and participation and opens up new avenues for both streamer-viewer and viewer-viewer participation. We contextualize our findings around a broader understanding of motivations and engagement in livestreaming, and we propose design guidelines and extensions for future research.","authors":["Michael Yin","Robert Xiao"],"url":"https://arxiv.org/abs/2504.09016"}
{"created":"2025-04-15","title":"Entertainers Between Real and Virtual -- Investigating Viewer Interaction, Engagement, and Relationships with Avatarized Virtual Livestreamers","abstract":"Virtual YouTubers (VTubers) are avatar-based livestreamers that are voiced and played by human actors. VTubers have been popular in East Asia for years and have more recently seen widespread international growth. Despite their emergent popularity, research has been scarce into the interactions and relationships that exist between avatarized VTubers and their viewers, particularly in contrast to non-avatarized streamers. To address this gap, we performed in-depth interviews with self-reported VTuber viewers (n=21). Our findings first reveal that the avatarized nature of VTubers fosters new forms of theatrical engagement, as factors of the virtual blend with the real to create a mixture of fantasy and realism in possible livestream interactions. Avatarization furthermore results in a unique audience perception regarding the identity of VTubers - an identity which comprises a dynamic, distinct mix of the real human (the voice actor/actress) and the virtual character. Our findings suggest that each of these dual identities both individually and symbiotically affect viewer interactions and relationships with VTubers. Whereas the performer's identity mediates social factors such as intimacy, relatability, and authenticity, the virtual character's identity offers feelings of escapism, novelty in interactions, and a sense of continuity beyond the livestream. We situate our findings within existing livestreaming literature to highlight how avatarization drives unique, character-based interactions as well as reshapes the motivations and relationships that viewers form with livestreamers. Finally, we provide suggestions and recommendations for areas of future exploration to address the challenges involved in present livestreamed avatarized entertainment.","authors":["Michael Yin","Chenxinran Shen","Robert Xiao"],"url":"https://arxiv.org/abs/2504.09018"}
{"created":"2025-04-15","title":"Empirically Measuring Data Localization in the EU","abstract":"EU data localization regulations limit data transfers to non-EU countries with the GDPR. However, BGP, DNS and other Internet protocols were not designed to enforce jurisdictional constraints, so implementing data localization is challenging. Despite initial research on the topic, little is known about if or how companies currently operate their server infrastructure to comply with the regulations. We close this knowledge gap by empirically measuring the extent to which servers and routers that process EU requests are located outside of the EU (and a handful of \"adequate\" non-EU countries). The key challenge is that both browser measurements (to infer relevant endpoints) and data-plane measurements (to infer relevant IP addresses) are needed, but no large-scale public infrastructure allows both. We build a novel methodology that combines BrightData (browser) and RIPE Atlas (data-plane) probes, with joint measurements from over 1,000 networks in 20 EU countries. We find that, on average, 2.2% of servers serving users in each EU country are located in non-adequate destination countries (1.4% of known trackers). Our findings suggest that data localization policies are largely being followed by content providers, though there are exceptions.","authors":["Alexander Gamero-Garrido","Kicho Yu","Sumukh Vasisht Shankar","Sachin Kumar Singh","Sindhya Balasubramanian","Alexander Wilcox","David Choffnes"],"url":"https://arxiv.org/abs/2504.09019"}
{"created":"2025-04-15","title":"A Champion-level Vision-based Reinforcement Learning Agent for Competitive Racing in Gran Turismo 7","abstract":"Deep reinforcement learning has achieved superhuman racing performance in high-fidelity simulators like Gran Turismo 7 (GT7). It typically utilizes global features that require instrumentation external to a car, such as precise localization of agents and opponents, limiting real-world applicability. To address this limitation, we introduce a vision-based autonomous racing agent that relies solely on ego-centric camera views and onboard sensor data, eliminating the need for precise localization during inference. This agent employs an asymmetric actor-critic framework: the actor uses a recurrent neural network with the sensor data local to the car to retain track layouts and opponent positions, while the critic accesses the global features during training. Evaluated in GT7, our agent consistently outperforms GT7's built-drivers. To our knowledge, this work presents the first vision-based autonomous racing agent to demonstrate champion-level performance in competitive racing scenarios.","authors":["Hojoon Lee","Takuma Seno","Jun Jet Tai","Kaushik Subramanian","Kenta Kawamoto","Peter Stone","Peter R. Wurman"],"url":"https://arxiv.org/abs/2504.09021"}
{"created":"2025-04-15","title":"Game-Theoretic Coordination For Time-Critical Missions of UAV Systems","abstract":"Cooperative missions involving Unmanned Aerial Vehicles (UAVs) in dynamic environments pose significant challenges in ensuring both coordination and agility. In this paper, we introduce a novel game-theoretic approach for time-critical missions, where each UAV optimizes a cost function that incorporates temporal and mission-specific constraints. The optimization is performed within a one-dimensional domain, significantly reducing the computational cost and enabling real-time application to complex and dynamic scenarios. The framework is distributed in structure, allowing to achieve global, system-wide coordination (a Nash equilibrium) by using only local information. For ideal systems, we prove the existence and exponential stability of the Nash equilibrium. Furthermore, we invoke model predictive control (MPC) for non-ideal scenarios. In particular, we propose a discrete-time optimization approach that tackles path-following errors and communication failures, ensuring reliable and agile performance in dynamic and uncertain environments. Simulation results demonstrate the effectiveness and agility of the approach in ensuring successful mission execution across diverse scenarios. Experiments using a motion capture system provide further validation under realistic conditions.","authors":["Mikayel Aramyan","Anna Manucharyan","Lusine Poghosyan","Rohith Madhavan","Tigran Bakaryan","Naira Hovakimyan"],"url":"https://arxiv.org/abs/2504.09022"}
{"created":"2025-04-15","title":"Universal Rate-Distortion-Classification Representations for Lossy Compression","abstract":"In lossy compression, Wang et al. [1] recently introduced the rate-distortion-perception-classification function, which supports multi-task learning by jointly optimizing perceptual quality, classification accuracy, and reconstruction fidelity. Building on the concept of a universal encoder introduced in [2], we investigate the universal representations that enable a broad range of distortion-classification tradeoffs through a single shared encoder coupled with multiple task-specific decoders. We establish, through both theoretical analysis and numerical experiments, that for Gaussian source under mean squared error (MSE) distortion, the entire distortion-classification tradeoff region can be achieved using a single universal encoder. For general sources, we characterize the achievable region and identify conditions under which encoder reuse results in negligible distortion penalty. The experimental result on the MNIST dataset further supports our theoretical findings. We show that universal encoders can obtain distortion performance comparable to task-specific encoders. These results demonstrate the practicality and effectiveness of the proposed universal framework in multi-task compression scenarios.","authors":["Nam Nguyen","Thinh Nguyen","Bella Bose"],"url":"https://arxiv.org/abs/2504.09025"}
{"created":"2025-04-15","title":"Detecting Instruction Fine-tuning Attack on Language Models with Influence Function","abstract":"Instruction fine-tuning attacks pose a significant threat to large language models (LLMs) by subtly embedding poisoned data in fine-tuning datasets, which can trigger harmful or unintended responses across a range of tasks. This undermines model alignment and poses security risks in real-world deployment. In this work, we present a simple and effective approach to detect and mitigate such attacks using influence functions, a classical statistical tool adapted for machine learning interpretation. Traditionally, the high computational costs of influence functions have limited their application to large models and datasets. The recent Eigenvalue-Corrected Kronecker-Factored Approximate Curvature (EK-FAC) approximation method enables efficient influence score computation, making it feasible for large-scale analysis.","authors":["Jiawei Li"],"url":"https://arxiv.org/abs/2504.09026"}
{"created":"2025-04-15","title":"Associating transportation planning-related measures with Mild Cognitive Impairment","abstract":"Understanding the relationship between mild cognitive impairment and driving behavior is essential to improve road safety, especially among older adults. In this study, we computed certain variables that reflect daily driving habits, such as trips to specific locations (e.g., home, work, medical, social, and errands) of older drivers in Nebraska using geohashing. The computed variables were then analyzed using a two-fold approach involving data visualization and machine learning models (C5.0, Random Forest, Support Vector Machines) to investigate the efficiency of the computed variables in predicting whether a driver is cognitively impaired or unimpaired. The C5.0 model demonstrated robust and stable performance with a median recall of 74\\%, indicating that our methodology was able to identify cognitive impairment in drivers 74\\% of the time correctly. This highlights our model's effectiveness in minimizing false negatives which is an important consideration given the cost of missing impaired drivers could be potentially high. Our findings highlight the potential of life space variables in understanding and predicting cognitive decline, offering avenues for early intervention and tailored support for affected individuals.","authors":["Souradeep Chattopadhyay","Guillermo Basulto-Elias","Jun Ha Chang","Matthew Rizzo","Shauna Hallmark","Anuj Sharma","Soumik Sarkar"],"url":"https://arxiv.org/abs/2504.09027"}
{"created":"2025-04-15","title":"Towards On-Device Learning and Reconfigurable Hardware Implementation for Encoded Single-Photon Signal Processing","abstract":"Deep neural networks (DNNs) enhance the accuracy and efficiency of reconstructing key parameters from time-resolved photon arrival signals recorded by single-photon detectors. However, the performance of conventional backpropagation-based DNNs is highly dependent on various parameters of the optical setup and biological samples under examination, necessitating frequent network retraining, either through transfer learning or from scratch. Newly collected data must also be stored and transferred to a high-performance GPU server for retraining, introducing latency and storage overhead. To address these challenges, we propose an online training algorithm based on a One-Sided Jacobi rotation-based Online Sequential Extreme Learning Machine (OSOS-ELM). We fully exploit parallelism in executing OSOS-ELM on a heterogeneous FPGA with integrated ARM cores. Extensive evaluations of OSOS-ELM and OSELM demonstrate that both achieve comparable accuracy across different network dimensions (i.e., input, hidden, and output layers), while OSOS-ELM proves to be more hardware-efficient. By leveraging the parallelism of OSOS-ELM, we implement a holistic computing prototype on a Xilinx ZCU104 FPGA, which integrates a multi-core CPU and programmable logic fabric. We validate our approach through three case studies involving single-photon signal analysis: sensing through fog using commercial single-photon LiDAR, fluorescence lifetime estimation in FLIM, and blood flow index reconstruction in DCS, all utilizing one-dimensional data encoded from photonic signals. From a hardware perspective, we optimize the OSOS-ELM workload by employing multi-tasked processing on ARM CPU cores and pipelined execution on the FPGA's logic fabric. We also implement our OSOS-ELM on the NVIDIA Jetson Xavier NX GPU to comprehensively investigate its computing performance on another type of heterogeneous computing platform.","authors":["Zhenya Zang","Xingda Li","David Day Uei Li"],"url":"https://arxiv.org/abs/2504.09028"}
{"created":"2025-04-15","title":"A Hierarchical Decomposition of Kullback-Leibler Divergence: Disentangling Marginal Mismatches from Statistical Dependencies","abstract":"The Kullback-Leibler (KL) divergence is a foundational measure for comparing probability distributions. Yet in multivariate settings, its structure is often opaque, conflating marginal mismatches and statistical dependencies. We derive an algebraically exact, additive, and hierarchical decomposition of the KL divergence between a joint distribution \\( P_k \\) and a product reference \\( Q^{\\otimes k} \\). The total divergence splits into the sum of marginal KLs, \\( \\sum_{i=1}^k \\mathrm{KL}(P_i \\| Q) \\), and the total correlation \\( C(P_k) \\), which we further decompose as \\( C(P_k) = \\sum_{r=2}^k I^{(r)}(P_k) \\), using Moebius inversion on the subset lattice. Each \\( I^{(r)} \\) quantifies the distinct contribution of \\( r \\)-way statistical interactions to the total divergence. This yields the first decomposition of this form that is both algebraically complete and interpretable using only standard Shannon quantities, with no approximations or model assumptions. Numerical validation using hypergeometric sampling confirms exactness to machine precision across diverse system configurations. This framework enables precise diagnosis of divergence origins, marginal versus interaction, across applications in machine learning, econometrics, and complex systems.","authors":["William Cook"],"url":"https://arxiv.org/abs/2504.09029"}
{"created":"2025-04-15","title":"Authoritarian Recursions: How Fiction, History, and AI Reinforce Control in Education, Warfare, and Discourse","abstract":"The growing integration of artificial intelligence (AI) into military, educational, and propaganda systems raises urgent ethical challenges related to autonomy, bias, and the erosion of human oversight. This study employs a mixed-methods approach -- combining historical analysis, speculative fiction critique, and contemporary case studies -- to examine how AI technologies may reproduce structures of authoritarian control.","authors":["Hasan Oguz"],"url":"https://arxiv.org/abs/2504.09030"}
{"created":"2025-04-15","title":"Chest X-ray Classification using Deep Convolution Models on Low-resolution images with Uncertain Labels","abstract":"Deep Convolutional Neural Networks have consistently proven to achieve state-of-the-art results on a lot of imaging tasks over the past years' majority of which comprise of high-quality data. However, it is important to work on low-resolution images since it could be a cheaper alternative for remote healthcare access where the primary need of automated pathology identification models occurs. Medical diagnosis using low-resolution images is challenging since critical details may not be easily identifiable. In this paper, we report classification results by experimenting on different input image sizes of Chest X-rays to deep CNN models and discuss the feasibility of classification on varying image sizes. We also leverage the noisy labels in the dataset by proposing a Randomized Flipping of labels techniques. We use an ensemble of multi-label classification models on frontal and lateral studies. Our models are trained on 5 out of the 14 chest pathologies of the publicly available CheXpert dataset. We incorporate techniques such as augmentation, regularization for model improvement and use class activation maps to visualize the neural network's decision making. Comparison with classification results on data from 200 subjects, obtained on the corresponding high-resolution images, reported in the original CheXpert paper, has been presented. For pathologies Cardiomegaly, Consolidation and Edema, we obtain 3% higher accuracy with our model architecture.","authors":["Snigdha Agarwal","Neelam Sinha"],"url":"https://arxiv.org/abs/2504.09033"}
{"created":"2025-04-15","title":"A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems","abstract":"Reasoning is a fundamental cognitive process that enables logical inference, problem-solving, and decision-making. With the rapid advancement of large language models (LLMs), reasoning has emerged as a key capability that distinguishes advanced AI systems from conventional models that empower chatbots. In this survey, we categorize existing methods along two orthogonal dimensions: (1) Regimes, which define the stage at which reasoning is achieved (either at inference time or through dedicated training); and (2) Architectures, which determine the components involved in the reasoning process, distinguishing between standalone LLMs and agentic compound systems that incorporate external tools, and multi-agent collaborations. Within each dimension, we analyze two key perspectives: (1) Input level, which focuses on techniques that construct high-quality prompts that the LLM condition on; and (2) Output level, which methods that refine multiple sampled candidates to enhance reasoning quality. This categorization provides a systematic understanding of the evolving landscape of LLM reasoning, highlighting emerging trends such as the shift from inference-scaling to learning-to-reason (e.g., DeepSeek-R1), and the transition to agentic workflows (e.g., OpenAI Deep Research, Manus Agent). Additionally, we cover a broad spectrum of learning algorithms, from supervised fine-tuning to reinforcement learning such as PPO and GRPO, and the training of reasoners and verifiers. We also examine key designs of agentic workflows, from established patterns like generator-evaluator and LLM debate to recent innovations. ...","authors":["Zixuan Ke","Fangkai Jiao","Yifei Ming","Xuan-Phi Nguyen","Austin Xu","Do Xuan Long","Minzhi Li","Chengwei Qin","Peifeng Wang","Silvio Savarese","Caiming Xiong","Shafiq Joty"],"url":"https://arxiv.org/abs/2504.09037"}
{"created":"2025-04-15","title":"Nonconvex Obstacle Avoidance using Efficient Sampling-Based Distance Functions","abstract":"We consider nonconvex obstacle avoidance where a robot described by nonlinear dynamics and a nonconvex shape has to avoid nonconvex obstacles. Obstacle avoidance is a fundamental problem in robotics and well studied in control. However, existing solutions are computationally expensive (e.g., model predictive controllers), neglect nonlinear dynamics (e.g., graph-based planners), use diffeomorphic transformations into convex domains (e.g., for star shapes), or are conservative due to convex overapproximations. The key challenge here is that the computation of the distance between the shapes of the robot and the obstacles is a nonconvex problem. We propose efficient computation of this distance via sampling-based distance functions. We quantify the sampling error and show that, for certain systems, such sampling-based distance functions are valid nonsmooth control barrier functions. We also study how to deal with disturbances on the robot dynamics in our setting. Finally, we illustrate our method on a robot navigation task involving an omnidirectional robot and nonconvex obstacles. We also analyze performance and computational efficiency of our controller as a function of the number of samples.","authors":["Paul Lutkus","Michelle S. Chong","Lars Lindemann"],"url":"https://arxiv.org/abs/2504.09038"}
{"created":"2025-04-15","title":"Sculpting Memory: Multi-Concept Forgetting in Diffusion Models via Dynamic Mask and Concept-Aware Optimization","abstract":"Text-to-image (T2I) diffusion models have achieved remarkable success in generating high-quality images from textual prompts. However, their ability to store vast amounts of knowledge raises concerns in scenarios where selective forgetting is necessary, such as removing copyrighted content, reducing biases, or eliminating harmful concepts. While existing unlearning methods can remove certain concepts, they struggle with multi-concept forgetting due to instability, residual knowledge persistence, and generation quality degradation. To address these challenges, we propose \\textbf{Dynamic Mask coupled with Concept-Aware Loss}, a novel unlearning framework designed for multi-concept forgetting in diffusion models. Our \\textbf{Dynamic Mask} mechanism adaptively updates gradient masks based on current optimization states, allowing selective weight modifications that prevent interference with unrelated knowledge. Additionally, our \\textbf{Concept-Aware Loss} explicitly guides the unlearning process by enforcing semantic consistency through superclass alignment, while a regularization loss based on knowledge distillation ensures that previously unlearned concepts remain forgotten during sequential unlearning. We conduct extensive experiments to evaluate our approach. Results demonstrate that our method outperforms existing unlearning techniques in forgetting effectiveness, output fidelity, and semantic coherence, particularly in multi-concept scenarios. Our work provides a principled and flexible framework for stable and high-fidelity unlearning in generative models. The code will be released publicly.","authors":["Gen Li","Yang Xiao","Jie Ji","Kaiyuan Deng","Bo Hui","Linke Guo","Xiaolong Ma"],"url":"https://arxiv.org/abs/2504.09039"}
{"created":"2025-04-15","title":"An Enhanced Iterative Deepening Search Algorithm for the Unrestricted Container Rehandling Problem","abstract":"In container terminal yards, the Container Rehandling Problem (CRP) involves rearranging containers between stacks under specific operational rules, and it is a pivotal optimization challenge in intelligent container scheduling systems. Existing CRP studies primarily focus on minimizing reallocation costs using two-dimensional bay structures, considering factors such as container size, weight, arrival sequences, and retrieval priorities. This paper introduces an enhanced deepening search algorithm integrated with improved lower bounds to boost search efficiency. To further reduce the search space, we design mutually consistent pruning rules to avoid excessive computational overhead. The proposed algorithm is validated on three widely used benchmark datasets for the Unrestricted Container Rehandling Problem (UCRP). Experimental results demonstrate that our approach outperforms state-of-the-art exact algorithms in solving the more general UCRP variant, particularly exhibiting superior efficiency when handling containers within the same priority group under strict time constraints.","authors":["Ruoqi Wang","Jiawei Li"],"url":"https://arxiv.org/abs/2504.09046"}
{"created":"2025-04-15","title":"Multi-Robot Coordination with Adversarial Perception","abstract":"This paper investigates the resilience of perception-based multi-robot coordination with wireless communication to online adversarial perception. A systematic study of this problem is essential for many safety-critical robotic applications that rely on the measurements from learned perception modules. We consider a (small) team of quadrotor robots that rely only on an Inertial Measurement Unit (IMU) and the visual data measurements obtained from a learned multi-task perception module (e.g., object detection) for downstream tasks, including relative localization and coordination. We focus on a class of adversarial perception attacks that cause misclassification, mislocalization, and latency. We propose that the effects of adversarial misclassification and mislocalization can be modeled as sporadic (intermittent) and spurious measurement data for the downstream tasks. To address this, we present a framework for resilience analysis of multi-robot coordination with adversarial measurements. The framework integrates data from Visual-Inertial Odometry (VIO) and the learned perception model for robust relative localization and state estimation in the presence of adversarially sporadic and spurious measurements. The framework allows for quantifying the degradation in system observability and stability in relation to the success rate of adversarial perception. Finally, experimental results on a multi-robot platform demonstrate the real-world applicability of our methodology for resource-constrained robotic platforms.","authors":["Rayan Bahrami","Hamidreza Jafarnejadsani"],"url":"https://arxiv.org/abs/2504.09047"}
{"created":"2025-04-15","title":"BlockGaussian: Efficient Large-Scale Scene NovelView Synthesis via Adaptive Block-Based Gaussian Splatting","abstract":"The recent advancements in 3D Gaussian Splatting (3DGS) have demonstrated remarkable potential in novel view synthesis tasks. The divide-and-conquer paradigm has enabled large-scale scene reconstruction, but significant challenges remain in scene partitioning, optimization, and merging processes. This paper introduces BlockGaussian, a novel framework incorporating a content-aware scene partition strategy and visibility-aware block optimization to achieve efficient and high-quality large-scale scene reconstruction. Specifically, our approach considers the content-complexity variation across different regions and balances computational load during scene partitioning, enabling efficient scene reconstruction. To tackle the supervision mismatch issue during independent block optimization, we introduce auxiliary points during individual block optimization to align the ground-truth supervision, which enhances the reconstruction quality. Furthermore, we propose a pseudo-view geometry constraint that effectively mitigates rendering degradation caused by airspace floaters during block merging. Extensive experiments on large-scale scenes demonstrate that our approach achieves state-of-the-art performance in both reconstruction efficiency and rendering quality, with a 5x speedup in optimization and an average PSNR improvement of 1.21 dB on multiple benchmarks. Notably, BlockGaussian significantly reduces computational requirements, enabling large-scale scene reconstruction on a single 24GB VRAM device. The project page is available at https://github.com/SunshineWYC/BlockGaussian","authors":["Yongchang Wu","Zipeng Qi","Zhenwei Shi","Zhengxia Zou"],"url":"https://arxiv.org/abs/2504.09048"}
{"created":"2025-04-15","title":"From Punchlines to Predictions: A Metric to Assess LLM Performance in Identifying Humor in Stand-Up Comedy","abstract":"Comedy serves as a profound reflection of the times we live in and is a staple element of human interactions. In light of the widespread adoption of Large Language Models (LLMs), the intersection of humor and AI has become no laughing matter. Advancements in the naturalness of human-computer interaction correlates with improvements in AI systems' abilities to understand humor. In this study, we assess the ability of models in accurately identifying humorous quotes from a stand-up comedy transcript. Stand-up comedy's unique comedic narratives make it an ideal dataset to improve the overall naturalness of comedic understanding. We propose a novel humor detection metric designed to evaluate LLMs amongst various prompts on their capability to extract humorous punchlines. The metric has a modular structure that offers three different scoring methods - fuzzy string matching, sentence embedding, and subspace similarity - to provide an overarching assessment of a model's performance. The model's results are compared against those of human evaluators on the same task. Our metric reveals that regardless of prompt engineering, leading models, ChatGPT, Claude, and DeepSeek, achieve scores of at most 51% in humor detection. Notably, this performance surpasses that of humans who achieve a score of 41%. The analysis of human evaluators and LLMs reveals variability in agreement, highlighting the subjectivity inherent in humor and the complexities involved in extracting humorous quotes from live performance transcripts. Code available at https://github.com/swaggirl9000/humor.","authors":["Adrianna Romanowski","Pedro H. V. Valois","Kazuhiro Fukui"],"url":"https://arxiv.org/abs/2504.09049"}
{"created":"2025-04-15","title":"Sample Efficient Algorithms for Linear System Identification under Noisy Observations","abstract":"In this paper, we focus on learning linear dynamical systems under noisy observations. In this setting, existing algorithms either yield biased parameter estimates, or suffer from large sample complexities. To address these issues, we adapt the instrumental variable method and the bias compensation method, originally proposed for error-in-variables models, to our setting and provide refined non-asymptotic analysis. Under mild conditions, our algorithms achieve superior sample complexities that match the best-known sample complexity for learning a fully observable system without observation noise.","authors":["Yuyang Zhang","Xinhe Zhang","Jia Liu","Na Li"],"url":"https://arxiv.org/abs/2504.09057"}
{"created":"2025-04-15","title":"Towards Stepwise Domain Knowledge-Driven Reasoning Optimization and Reflection Improvement","abstract":"Recently, stepwise supervision on Chain of Thoughts (CoTs) presents an enhancement on the logical reasoning tasks such as coding and math, with the help of Monte Carlo Tree Search (MCTS). However, its contribution to tasks requiring domain-specific expertise and knowledge remains unexplored. Motivated by the interest, we identify several potential challenges of vanilla MCTS within this context, and propose the framework of Stepwise Domain Knowledge-Driven Reasoning Optimization, employing the MCTS algorithm to develop step-level supervision for problems that require essential comprehension, reasoning, and specialized knowledge. Additionally, we also introduce the Preference Optimization towards Reflection Paths, which iteratively learns self-reflection on the reasoning thoughts from better perspectives. We have conducted extensive experiments to evaluate the advantage of the methodologies. Empirical results demonstrate the effectiveness on various legal-domain problems. We also report a diverse set of valuable findings, hoping to encourage the enthusiasm to the research of domain-specific LLMs and MCTS.","authors":["Chengyuan Liu","Shihang Wang","Lizhi Qing","Kaisong Song","Junjie Cao","Jun Lin","Ji Zhang","Ang Li","Kun Kuang","Fei Wu"],"url":"https://arxiv.org/abs/2504.09058"}
{"created":"2025-04-15","title":"Large Language Models integration in Smart Grids","abstract":"Large Language Models (LLMs) are changing the way we operate our society and will undoubtedly impact power systems as well - but how exactly? By integrating various data streams - including real-time grid data, market dynamics, and consumer behaviors - LLMs have the potential to make power system operations more adaptive, enhance proactive security measures, and deliver personalized energy services. This paper provides a comprehensive analysis of 30 real-world applications across eight key categories: Grid Operations and Management, Energy Markets and Trading, Personalized Energy Management and Customer Engagement, Grid Planning and Education, Grid Security and Compliance, Advanced Data Analysis and Knowledge Discovery, Emerging Applications and Societal Impact, and LLM-Enhanced Reinforcement Learning. Critical technical hurdles, such as data privacy and model reliability, are examined, along with possible solutions. Ultimately, this review illustrates how LLMs can significantly contribute to building more resilient, efficient, and sustainable energy infrastructures, underscoring the necessity of their responsible and equitable deployment.","authors":["Seyyedreza Madani","Ahmadreza Tavasoli","Zahra Khoshtarash Astaneh","Pierre-Olivier Pineau"],"url":"https://arxiv.org/abs/2504.09059"}
{"created":"2025-04-15","title":"Multimodal 3D Genome Pre-training","abstract":"Deep learning techniques have driven significant progress in various analytical tasks within 3D genomics in computational biology. However, a holistic understanding of 3D genomics knowledge remains underexplored. Here, we propose MIX-HIC, the first multimodal foundation model of 3D genome that integrates both 3D genome structure and epigenomic tracks, which obtains unified and comprehensive semantics. For accurate heterogeneous semantic fusion, we design the cross-modal interaction and mapping blocks for robust unified representation, yielding the accurate aggregation of 3D genome knowledge. Besides, we introduce the first large-scale dataset comprising over 1 million pairwise samples of Hi-C contact maps and epigenomic tracks for high-quality pre-training, enabling the exploration of functional implications in 3D genomics. Extensive experiments show that MIX-HIC can significantly surpass existing state-of-the-art methods in diverse downstream tasks. This work provides a valuable resource for advancing 3D genomics research.","authors":["Minghao Yang","Pengteng Li","Yan Liang","Qianyi Cai","Zhihang Zheng","Shichen Zhang","Pengfei Zhang","Zhi-An Huang","Hui Xiong"],"url":"https://arxiv.org/abs/2504.09060"}
{"created":"2025-04-15","title":"You Need a Transition Plane: Bridging Continuous Panoramic 3D Reconstruction with Perspective Gaussian Splatting","abstract":"Recently, reconstructing scenes from a single panoramic image using advanced 3D Gaussian Splatting (3DGS) techniques has attracted growing interest. Panoramic images offer a 360$\\times$ 180 field of view (FoV), capturing the entire scene in a single shot. However, panoramic images introduce severe distortion, making it challenging to render 3D Gaussians into 2D distorted equirectangular space directly. Converting equirectangular images to cubemap projections partially alleviates this problem but introduces new challenges, such as projection distortion and discontinuities across cube-face boundaries. To address these limitations, we present a novel framework, named TPGS, to bridge continuous panoramic 3D scene reconstruction with perspective Gaussian splatting. Firstly, we introduce a Transition Plane between adjacent cube faces to enable smoother transitions in splatting directions and mitigate optimization ambiguity in the boundary region. Moreover, an intra-to-inter face optimization strategy is proposed to enhance local details and restore visual consistency across cube-face boundaries. Specifically, we optimize 3D Gaussians within individual cube faces and then fine-tune them in the stitched panoramic space. Additionally, we introduce a spherical sampling technique to eliminate visible stitching seams. Extensive experiments on indoor and outdoor, egocentric, and roaming benchmark datasets demonstrate that our approach outperforms existing state-of-the-art methods. Code and models will be available at https://github.com/zhijieshen-bjtu/TPGS.","authors":["Zhijie Shen","Chunyu Lin","Shujuan Huang","Lang Nie","Kang Liao","Yao Zhao"],"url":"https://arxiv.org/abs/2504.09062"}
{"created":"2025-04-15","title":"A Practical Approach to using Supervised Machine Learning Models to Classify Aviation Safety Occurrences","abstract":"This paper describes a practical approach of using supervised machine learning (ML) models to assist safety investigators to classify aviation occurrences into either incident or serious incident categories. Our implementation currently deployed as a ML web application is trained on a labelled dataset derived from publicly available aviation investigation reports. A selection of five supervised learning models (Support Vector Machine, Logistic Regression, Random Forest Classifier, XGBoost and K-Nearest Neighbors) were evaluated. This paper showed the best performing ML algorithm was the Random Forest Classifier with accuracy = 0.77, F1 Score = 0.78 and MCC = 0.51 (average of 100 sample runs). The study had also explored the effect of applying Synthetic Minority Over-sampling Technique (SMOTE) to the imbalanced dataset, and the overall observation ranged from no significant effect to substantial degradation in performance for some of the models after the SMOTE adjustment.","authors":["Bryan Y. Siow"],"url":"https://arxiv.org/abs/2504.09063"}
{"created":"2025-04-15","title":"PQS (Prune, Quantize, and Sort): Low-Bitwidth Accumulation of Dot Products in Neural Network Computations","abstract":"We present PQS, which uses three techniques together - Prune, Quantize, and Sort - to achieve low-bitwidth accumulation of dot products in neural network computations. In conventional quantized (e.g., 8-bit) dot products, partial results are accumulated into wide (e.g., 32-bit) accumulators to avoid overflows when accumulating intermediate partial sums. However, such wide accumulators increase memory bandwidth usage and reduce energy efficiency. We show that iterative N:M pruning in floating point followed by quantization to 8 (or fewer) bits, and accumulation of partial products in a sorted order (\"small to large\") allows for accurate, compressed models with short dot product lengths that do not require wide accumulators. We design, analyze, and implement the PQS algorithm to eliminate accumulation overflows at inference time for several neural networks. Our method offers a 2.5x reduction in accumulator bitwidth while achieving model accuracy on par with floating-point baselines for multiple image classification tasks.","authors":["Vikas Natesh","H. T. Kung"],"url":"https://arxiv.org/abs/2504.09064"}
{"created":"2025-04-15","title":"Substitutability-Based Graph Node Pricing","abstract":"In the era o fdat commodification,the pricing o fgraph data presents unique challenges that differ significantly from traditional data markets. This paper addresses the critical issue of node pricing within graph structures, an area that has been largely overlooked in existing literature. We introduce a novel pricing mechanism based on the concept of substitutability, inspired by economic principles, to better reflect the ntrinsic value of nodes in a graph. Unlike previous studies that assumed known prices for nodes or subgraphs, our approach emphasizes the structural significance of nodes by employing a dominator tree, utilizing the Lengauer-Tarjan algorithm to extract dominance relationships. This innovative framework allows us to derive a more realistic pricing strategy that accounts for the unique connectivity and roles of nodes within their respective networks. Our comparative experiments demonstrate that the proposed method significantly outperforms existing pricing strategies, yielding high-quality solutions across various datasets. This research aims to contribute to the existing literature by addressing an important gap and providing insights that may assist in the more effective valuation of graph data, potentially supporting improved decision-making in data-driven environments.","authors":["Huiju Wang","Yuanyuan Gao","Zhengkui Wang","Xiao Yue"],"url":"https://arxiv.org/abs/2504.09065"}
{"created":"2025-04-15","title":"Hyperlocal disaster damage assessment using bi-temporal street-view imagery and pre-trained vision models","abstract":"Street-view images offer unique advantages for disaster damage estimation as they capture impacts from a visual perspective and provide detailed, on-the-ground insights. Despite several investigations attempting to analyze street-view images for damage estimation, they mainly focus on post-disaster images. The potential of time-series street-view images remains underexplored. Pre-disaster images provide valuable benchmarks for accurate damage estimations at building and street levels. These images could aid annotators in objectively labeling post-disaster impacts, improving the reliability of labeled data sets for model training, and potentially enhancing the model performance in damage evaluation. The goal of this study is to estimate hyperlocal, on-the-ground disaster damages using bi-temporal street-view images and advanced pre-trained vision models. Street-view images before and after 2024 Hurricane Milton in Horseshoe Beach, Florida, were collected for experiments. The objectives are: (1) to assess the performance gains of incorporating pre-disaster street-view images as a no-damage category in fine-tuning pre-trained models, including Swin Transformer and ConvNeXt, for damage level classification; (2) to design and evaluate a dual-channel algorithm that reads pair-wise pre- and post-disaster street-view images for hyperlocal damage assessment. The results indicate that incorporating pre-disaster street-view images and employing a dual-channel processing framework can significantly enhance damage assessment accuracy. The accuracy improves from 66.14% with the Swin Transformer baseline to 77.11% with the dual-channel Feature-Fusion ConvNeXt model. This research enables rapid, operational damage assessments at hyperlocal spatial resolutions, providing valuable insights to support effective decision-making in disaster management and resilience planning.","authors":["Yifan Yang","Lei Zou","Bing Zhou","Daoyang Li","Binbin Lin","Joynal Abedin","Mingzheng Yang"],"url":"https://arxiv.org/abs/2504.09066"}
{"created":"2025-04-15","title":"UniFlowRestore: A General Video Restoration Framework via Flow Matching and Prompt Guidance","abstract":"Video imaging is often affected by complex degradations such as blur, noise, and compression artifacts. Traditional restoration methods follow a \"single-task single-model\" paradigm, resulting in poor generalization and high computational cost, limiting their applicability in real-world scenarios with diverse degradation types. We propose UniFlowRestore, a general video restoration framework that models restoration as a time-continuous evolution under a prompt-guided and physics-informed vector field. A physics-aware backbone PhysicsUNet encodes degradation priors as potential energy, while PromptGenerator produces task-relevant prompts as momentum. These components define a Hamiltonian system whose vector field integrates inertial dynamics, decaying physical gradients, and prompt-based guidance. The system is optimized via a fixed-step ODE solver to achieve efficient and unified restoration across tasks. Experiments show that UniFlowRestore delivers stateof-the-art performance with strong generalization and efficiency. Quantitative results demonstrate that UniFlowRestore achieves state-of-the-art performance, attaining the highest PSNR (33.89 dB) and SSIM (0.97) on the video denoising task, while maintaining top or second-best scores across all evaluated tasks.","authors":["Shuning Sun","Yu Zhang","Chen Wu","Dianjie Lu","Dianjie Lu","Guijuan Zhan","Yang Weng","Zhuoran Zheng"],"url":"https://arxiv.org/abs/2504.09069"}
{"created":"2025-04-15","title":"Exploration of Plan-Guided Summarization for Narrative Texts: the Case of Small Language Models","abstract":"Plan-guided summarization attempts to reduce hallucinations in small language models (SLMs) by grounding generated summaries to the source text, typically by targeting fine-grained details such as dates or named entities. In this work, we investigate whether plan-based approaches in SLMs improve summarization in long document, narrative tasks. Narrative texts' length and complexity often mean they are difficult to summarize faithfully. We analyze existing plan-guided solutions targeting fine-grained details, and also propose our own higher-level, narrative-based plan formulation. Our results show that neither approach significantly improves on a baseline without planning in either summary quality or faithfulness. Human evaluation reveals that while plan-guided approaches are often well grounded to their plan, plans are equally likely to contain hallucinations compared to summaries. As a result, the plan-guided summaries are just as unfaithful as those from models without planning. Our work serves as a cautionary tale to plan-guided approaches to summarization, especially for long, complex domains such as narrative texts.","authors":["Matt Grenander","Siddharth Varia","Paula Czarnowska","Yogarshi Vyas","Kishaloy Halder","Bonan Min"],"url":"https://arxiv.org/abs/2504.09071"}
{"created":"2025-04-15","title":"MGS: Markov Greedy Sums for Accurate Low-Bitwidth Floating-Point Accumulation","abstract":"We offer a novel approach, MGS (Markov Greedy Sums), to improve the accuracy of low-bitwidth floating-point dot products in neural network computations. In conventional 32-bit floating-point summation, adding values with different exponents may lead to loss of precision in the mantissa of the smaller term, which is right-shifted to align with the larger term's exponent. Such shifting (a.k.a. 'swamping') is a significant source of numerical errors in accumulation when implementing low-bitwidth dot products (e.g., 8-bit floating point) as the mantissa has a small number of bits. We avoid most swamping errors by arranging the terms in dot product summation based on their exponents and summing the mantissas without overflowing the low-bitwidth accumulator. We design, analyze, and implement the algorithm to minimize 8-bit floating point error at inference time for several neural networks. In contrast to traditional sequential summation, our method has significantly lowered numerical errors, achieving classification accuracy on par with high-precision floating-point baselines for multiple image classification tasks. Our dMAC hardware units can reduce power consumption by up to 34.1\\% relative to conventional MAC units.","authors":["Vikas Natesh","H. T. Kung","David Kong"],"url":"https://arxiv.org/abs/2504.09072"}
{"created":"2025-04-15","title":"A Multi-view Discourse Framework for Integrating Semantic and Syntactic Features in Dialog Agents","abstract":"Multiturn dialogue models aim to generate human-like responses by leveraging conversational context, consisting of utterances from previous exchanges. Existing methods often neglect the interactions between these utterances or treat all of them as equally significant. This paper introduces a discourse-aware framework for response selection in retrieval-based dialogue systems. The proposed model first encodes each utterance and response with contextual, positional, and syntactic features using Multi-view Canonical Correlation Analysis (MCCA). It then learns discourse tokens that capture relationships between an utterance and its surrounding turns in a shared subspace via Canonical Correlation Analysis (CCA). This two-step approach effectively integrates semantic and syntactic features to build discourse-level understanding. Experiments on the Ubuntu Dialogue Corpus demonstrate that our model achieves significant improvements in automatic evaluation metrics, highlighting its effectiveness in response selection.","authors":["Akanksha Mehndiratta","Krishna Asawa"],"url":"https://arxiv.org/abs/2504.09073"}
{"created":"2025-04-15","title":"A Case for Kolmogorov-Arnold Networks in Prefetching: Towards Low-Latency, Generalizable ML-Based Prefetchers","abstract":"The memory wall problem arises due to the disparity between fast processors and slower memory, causing significant delays in data access, even more so on edge devices. Data prefetching is a key strategy to address this, with traditional methods evolving to incorporate Machine Learning (ML) for improved accuracy. Modern prefetchers must balance high accuracy with low latency to further practicality. We explore the applicability of utilizing Kolmogorov-Arnold Networks (KAN) with learnable activation functions,a prefetcher we implemented called KANBoost, to further this aim. KANs are a novel, state-of-the-art model that work on breaking down continuous, bounded multi-variate functions into functions of their constituent variables, and use these constitutent functions as activations on each individual neuron. KANBoost predicts the next memory access by modeling deltas between consecutive addresses, offering a balance of accuracy and efficiency to mitigate the memory wall problem with minimal overhead, instead of relying on address-correlation prefetching. Initial results indicate that KAN-based prefetching reduces inference latency (18X lower than state-of-the-art ML prefetchers) while achieving moderate IPC improvements (2.5\\% over no-prefetching). While KANs still face challenges in capturing long-term dependencies, we propose that future research should explore hybrid models that combine KAN efficiency with stronger sequence modeling techniques, paving the way for practical ML-based prefetching in edge devices and beyond.","authors":["Dhruv Kulkarni","Bharat Bhammar","Henil Thaker","Pranav Dhobi","R. P. Gohil","Sai Manoj Pudukotai Dinkarrao"],"url":"https://arxiv.org/abs/2504.09074"}
{"created":"2025-04-15","title":"Exploring Synergistic Ensemble Learning: Uniting CNNs, MLP-Mixers, and Vision Transformers to Enhance Image Classification","abstract":"In recent years, Convolutional Neural Networks (CNNs), MLP-mixers, and Vision Transformers have risen to prominence as leading neural architectures in image classification. Prior research has underscored the distinct advantages of each architecture, and there is growing evidence that combining modules from different architectures can boost performance. In this study, we build upon and improve previous work exploring the complementarity between different architectures. Instead of heuristically merging modules from various architectures through trial and error, we preserve the integrity of each architecture and combine them using ensemble techniques. By maintaining the distinctiveness of each architecture, we aim to explore their inherent complementarity more deeply and with implicit isolation. This approach provides a more systematic understanding of their individual strengths.","authors":["Mk Bashar","Ocean Monjur","Samia Islam","Mohammad Galib Shams","Niamul Quader"],"url":"https://arxiv.org/abs/2504.09076"}
{"created":"2025-04-15","title":"A Visual Self-attention Mechanism Facial Expression Recognition Network beyond Convnext","abstract":"Facial expression recognition is an important research direction in the field of artificial intelligence. Although new breakthroughs have been made in recent years, the uneven distribution of datasets and the similarity between different categories of facial expressions, as well as the differences within the same category among different subjects, remain challenges. This paper proposes a visual facial expression signal feature processing network based on truncated ConvNeXt approach(Conv-cut), to improve the accuracy of FER under challenging conditions. The network uses a truncated ConvNeXt-Base as the feature extractor, and then we designed a Detail Extraction Block to extract detailed features, and introduced a Self-Attention mechanism to enable the network to learn the extracted features more effectively. To evaluate the proposed Conv-cut approach, we conducted experiments on the RAF-DB and FERPlus datasets, and the results show that our model has achieved state-of-the-art performance. Our code could be accessed at Github.","authors":["Bingyu Nan","Feng Liu","Xuezhong Qian","Wei Song"],"url":"https://arxiv.org/abs/2504.09077"}
{"created":"2025-04-15","title":"agriFrame: Agricultural framework to remotely control a rover inside a greenhouse environment","abstract":"The growing demand for innovation in agriculture is essential for food security worldwide and more implicit in developing countries. With growing demand comes a reduction in rapid development time. Data collection and analysis are essential in agriculture. However, considering a given crop, its cycle comes once a year, and researchers must wait a few months before collecting more data for the given crop. To overcome this hurdle, researchers are venturing into digital twins for agriculture. Toward this effort, we present an agricultural framework(agriFrame). Here, we introduce a simulated greenhouse environment for testing and controlling a robot and remotely controlling/implementing the algorithms in the real-world greenhouse setup. This work showcases the importance/interdependence of network setup, remotely controllable rover, and messaging protocol. The sophisticated yet simple-to-use agriFrame has been optimized for the simulator on minimal laptop/desktop specifications.","authors":["Saail Narvekar","Soofiyan Atar","Vishal Gupta","Lohit Penubaku","Kavi Arya"],"url":"https://arxiv.org/abs/2504.09079"}
{"created":"2025-04-15","title":"Using Vision Language Models for Safety Hazard Identification in Construction","abstract":"Safety hazard identification and prevention are the key elements of proactive safety management. Previous research has extensively explored the applications of computer vision to automatically identify hazards from image clips collected from construction sites. However, these methods struggle to identify context-specific hazards, as they focus on detecting predefined individual entities without understanding their spatial relationships and interactions. Furthermore, their limited adaptability to varying construction site guidelines and conditions hinders their generalization across different projects. These limitations reduce their ability to assess hazards in complex construction environments and adaptability to unseen risks, leading to potential safety gaps. To address these challenges, we proposed and experimentally validated a Vision Language Model (VLM)-based framework for the identification of construction hazards. The framework incorporates a prompt engineering module that structures safety guidelines into contextual queries, allowing VLM to process visual information and generate hazard assessments aligned with the regulation guide. Within this framework, we evaluated state-of-the-art VLMs, including GPT-4o, Gemini, Llama 3.2, and InternVL2, using a custom dataset of 1100 construction site images. Experimental results show that GPT-4o and Gemini 1.5 Pro outperformed alternatives and displayed promising BERTScore of 0.906 and 0.888 respectively, highlighting their ability to identify both general and context-specific hazards. However, processing times remain a significant challenge, impacting real-time feasibility. These findings offer insights into the practical deployment of VLMs for construction site hazard detection, thereby contributing to the enhancement of proactive safety management.","authors":["Muhammad Adil","Gaang Lee","Vicente A. Gonzalez","Qipei Mei"],"url":"https://arxiv.org/abs/2504.09083"}
{"created":"2025-04-15","title":"crowd-hpo: Realistic Hyperparameter Optimization and Benchmarking for Learning from Crowds with Noisy Labels","abstract":"Crowdworking is a cost-efficient solution to acquire class labels. Since these labels are subject to noise, various approaches to learning from crowds have been proposed. Typically, these approaches are evaluated with default hyperparameters, resulting in suboptimal performance, or with hyperparameters tuned using a validation set with ground truth class labels, representing an often unrealistic scenario. Moreover, both experimental setups can produce different rankings of approaches, complicating comparisons between studies. Therefore, we introduce crowd-hpo as a realistic benchmark and experimentation protocol including hyperparameter optimization under noisy crowd-labeled data. At its core, crowd-hpo investigates model selection criteria to identify well-performing hyperparameter configurations only with access to noisy crowd-labeled validation data. Extensive experimental evaluations with neural networks show that these criteria are effective for optimizing hyperparameters in learning from crowds approaches. Accordingly, incorporating such criteria into experimentation protocols is essential for enabling more realistic and fair benchmarking.","authors":["Marek Herde","Lukas L\\\"uhrs","Denis Huseljic","Bernhard Sick"],"url":"https://arxiv.org/abs/2504.09085"}
{"created":"2025-04-15","title":"RICCARDO: Radar Hit Prediction and Convolution for Camera-Radar 3D Object Detection","abstract":"Radar hits reflect from points on both the boundary and internal to object outlines. This results in a complex distribution of radar hits that depends on factors including object category, size, and orientation. Current radar-camera fusion methods implicitly account for this with a black-box neural network. In this paper, we explicitly utilize a radar hit distribution model to assist fusion. First, we build a model to predict radar hit distributions conditioned on object properties obtained from a monocular detector. Second, we use the predicted distribution as a kernel to match actual measured radar points in the neighborhood of the monocular detections, generating matching scores at nearby positions. Finally, a fusion stage combines context with the kernel detector to refine the matching scores. Our method achieves the state-of-the-art radar-camera detection performance on nuScenes. Our source code is available at https://github.com/longyunf/riccardo.","authors":["Yunfei Long","Abhinav Kumar","Xiaoming Liu","Daniel Morris"],"url":"https://arxiv.org/abs/2504.09086"}
{"created":"2025-04-15","title":"VibWalk: Mapping Lower-limb Haptic Experiences of Everyday Walking","abstract":"Walking is among the most common human activities where the feet can gather rich tactile information from the ground. The dynamic contact between the feet and the ground generates vibration signals that can be sensed by the foot skin. While existing research focuses on foot pressure sensing and lower-limb interactions, methods of decoding tactile information from foot vibrations remain underexplored. Here, we propose a foot-equipped wearable system capable of recording wideband vibration signals during walking activities. By enabling location-based recording, our system generates maps of haptic data that encode information on ground materials, lower-limb activities, and road conditions. Its efficacy was demonstrated through studies involving 31 users walking over 18 different ground textures, achieving an overall identification accuracy exceeding 95\\% (cross-user accuracy of 87\\%). Our system allows pedestrians to map haptic information through their daily walking activities, which has potential applications in creating digitalized walking experiences and monitoring road conditions.","authors":["Shih-Ying-Lei","Dongxu Tang","Weiming Hu","Sang Ho Yoon","Yitian Shao"],"url":"https://arxiv.org/abs/2504.09089"}
{"created":"2025-04-15","title":"Enhancing Dialogue Systems with Discourse-Level Understanding Using Deep Canonical Correlation Analysis","abstract":"The evolution of conversational agents has been driven by the need for more contextually aware systems that can effectively manage dialogue over extended interactions. To address the limitations of existing models in capturing and utilizing long-term conversational history, we propose a novel framework that integrates Deep Canonical Correlation Analysis (DCCA) for discourse-level understanding. This framework learns discourse tokens to capture relationships between utterances and their surrounding context, enabling a better understanding of long-term dependencies. Experiments on the Ubuntu Dialogue Corpus demonstrate significant enhancement in response selection, based on the improved automatic evaluation metric scores. The results highlight the potential of DCCA in improving dialogue systems by allowing them to filter out irrelevant context and retain critical discourse information for more accurate response retrieval.","authors":["Akanksha Mehndiratta","Krishna Asawa"],"url":"https://arxiv.org/abs/2504.09094"}
{"created":"2025-04-15","title":"Privacy Preservation in Gen AI Applications","abstract":"The ability of machines to comprehend and produce language that is similar to that of humans has revolutionized sectors like customer service, healthcare, and finance thanks to the quick advances in Natural Language Processing (NLP), which are fueled by Generative Artificial Intelligence (AI) and Large Language Models (LLMs). However, because LLMs trained on large datasets may unintentionally absorb and reveal Personally Identifiable Information (PII) from user interactions, these capabilities also raise serious privacy concerns. Deep neural networks' intricacy makes it difficult to track down or stop the inadvertent storing and release of private information, which raises serious concerns about the privacy and security of AI-driven data. This study tackles these issues by detecting Generative AI weaknesses through attacks such as data extraction, model inversion, and membership inference. A privacy-preserving Generative AI application that is resistant to these assaults is then developed. It ensures privacy without sacrificing functionality by using methods to identify, alter, or remove PII before to dealing with LLMs. In order to determine how well cloud platforms like Microsoft Azure, Google Cloud, and AWS provide privacy tools for protecting AI applications, the study also examines these technologies. In the end, this study offers a fundamental privacy paradigm for generative AI systems, focusing on data security and moral AI implementation, and opening the door to a more secure and conscientious use of these tools.","authors":["Swetha S","Ram Sundhar K Shaju","Rakshana M","Ganesh R","Balavedhaa S","Thiruvaazhi U"],"url":"https://arxiv.org/abs/2504.09095"}
{"created":"2025-04-15","title":"High dimensional online calibration in polynomial time","abstract":"In online (sequential) calibration, a forecaster predicts probability distributions over a finite outcome space $[d]$ over a sequence of $T$ days, with the goal of being calibrated. While asymptotically calibrated strategies are known to exist, they suffer from the curse of dimensionality: the best known algorithms require $\\exp(d)$ days to achieve non-trivial calibration.","authors":["Binghui Peng"],"url":"https://arxiv.org/abs/2504.09096"}
{"created":"2025-04-15","title":"BIGS: Bimanual Category-agnostic Interaction Reconstruction from Monocular Videos via 3D Gaussian Splatting","abstract":"Reconstructing 3Ds of hand-object interaction (HOI) is a fundamental problem that can find numerous applications. Despite recent advances, there is no comprehensive pipeline yet for bimanual class-agnostic interaction reconstruction from a monocular RGB video, where two hands and an unknown object are interacting with each other. Previous works tackled the limited hand-object interaction case, where object templates are pre-known or only one hand is involved in the interaction. The bimanual interaction reconstruction exhibits severe occlusions introduced by complex interactions between two hands and an object. To solve this, we first introduce BIGS (Bimanual Interaction 3D Gaussian Splatting), a method that reconstructs 3D Gaussians of hands and an unknown object from a monocular video. To robustly obtain object Gaussians avoiding severe occlusions, we leverage prior knowledge of pre-trained diffusion model with score distillation sampling (SDS) loss, to reconstruct unseen object parts. For hand Gaussians, we exploit the 3D priors of hand model (i.e., MANO) and share a single Gaussian for two hands to effectively accumulate hand 3D information, given limited views. To further consider the 3D alignment between hands and objects, we include the interacting-subjects optimization step during Gaussian optimization. Our method achieves the state-of-the-art accuracy on two challenging datasets, in terms of 3D hand pose estimation (MPJPE), 3D object reconstruction (CDh, CDo, F10), and rendering quality (PSNR, SSIM, LPIPS), respectively.","authors":["Jeongwan On","Kyeonghwan Gwak","Gunyoung Kang","Junuk Cha","Soohyun Hwang","Hyein Hwang","Seungryul Baek"],"url":"https://arxiv.org/abs/2504.09097"}
{"created":"2025-04-15","title":"The trace dual of nonlinear skew cyclic codes","abstract":"Codes which have a finite field $\\mathbb{F}_{q^m}$ as their alphabet but which are only linear over a subfield $\\mathbb{F}_q$ are a topic of much recent interest due to their utility in constructing quantum error correcting codes. In this article, we find generators for trace dual spaces of different families of $\\mathbb{F}_q$-linear codes over $\\mathbb{F}_{q^2}$. In particular, given the field extension $\\mathbb{F}_q\\leq \\mathbb{F}_{q^2}$ with $q$ an odd prime power, we determine the trace Euclidean and trace Hermitian dual codes for the general $\\mathbb{F}_q$-linear cyclic $\\mathbb{F}_{q^2}$-code. In addition, we also determine the trace Euclidean and trace Hermitian duals for general $\\mathbb{F}_q$-linear skew cyclic $\\mathbb{F}_{q^2}$-codes, which are defined to be left $\\mathbb{F}_q[X]$-submodules of $\\mathbb{F}_{q^2}[X;\\sigma]/(X^n-1)$, where $\\sigma$ denotes the Frobenius automorphism and $\\mathbb{F}_{q^2}[X;\\sigma]$ the induced skew polynomial ring.","authors":["Daniel Bossaller","Daniel Herden","Indalecio Ruiz-Bola\\~nos"],"url":"https://arxiv.org/abs/2504.09098"}
{"created":"2025-04-15","title":"Rethinking News and Media System Design Towards Positive Societal Implications","abstract":"Since this century, the speed, availability, and plethora of online informational content have made it increasingly difficult for humans to keep an overview of real-world situations, build a personal opinion, and sometimes even decide on the truth. Thereby, personal opinion-making and public discourse became harder - two essential building blocks that keep a democratic society alive. HCI thus needs to rethink news, information, and social media systems to mitigate such negative effects. Instead of polarising through emotional and extremely framed messages, informational content online should make people think about other opinions and discuss constructively. Instead, through polarization and filter bubble effects, people lose openness and tolerance for the existence of opposing opinions. In this workshop, we will discuss how we can redesign our information technology for a better societal impact. We will present key takeaways from the social sciences and discuss how we can implement them using recent HCI findings and digital technologies.","authors":["Florian Bemmann","Doruntina Murtezaj"],"url":"https://arxiv.org/abs/2504.09099"}
{"created":"2025-04-15","title":"A Short Survey on Small Reasoning Models: Training, Inference, Applications and Research Directions","abstract":"Recently, the reasoning capabilities of large reasoning models (LRMs), such as DeepSeek-R1, have seen significant advancements through the slow thinking process. Despite these achievements, the substantial computational demands of LRMs present considerable challenges. In contrast, small reasoning models (SRMs), often distilled from larger ones, offer greater efficiency and can exhibit distinct capabilities and cognitive trajectories compared to LRMs. This work surveys around 170 recently published papers on SRMs for tackling various complex reasoning tasks. We review the current landscape of SRMs and analyze diverse training and inference techniques related to SRMs. Furthermore, we provide a comprehensive review of SRMs for domain-specific applications and discuss possible future research directions. This survey serves as an essential reference for researchers to leverage or develop SRMs for advanced reasoning functionalities with high efficiency.","authors":["Chengyu Wang","Taolin Zhang","Richang Hong","Jun Huang"],"url":"https://arxiv.org/abs/2504.09100"}
{"created":"2025-04-15","title":"Synthetic Aircraft Trajectory Generation Using Time-Based VQ-VAE","abstract":"In modern air traffic management, generating synthetic flight trajectories has emerged as a promising solution for addressing data scarcity, protecting sensitive information, and supporting large-scale analyses. In this paper, we propose a novel method for trajectory synthesis by adapting the Time-Based Vector Quantized Variational Autoencoder (TimeVQVAE). Our approach leverages time-frequency domain processing, vector quantization, and transformer-based priors to capture both global and local dynamics in flight data. By discretizing the latent space and integrating transformer priors, the model learns long-range spatiotemporal dependencies and preserves coherence across entire flight paths. We evaluate the adapted TimeVQVAE using an extensive suite of quality, statistical, and distributional metrics, as well as a flyability assessment conducted in an open-source air traffic simulator. Results indicate that TimeVQVAE outperforms a temporal convolutional VAE baseline, generating synthetic trajectories that mirror real flight data in terms of spatial accuracy, temporal consistency, and statistical properties. Furthermore, the simulator-based assessment shows that most generated trajectories maintain operational feasibility, although occasional outliers underscore the potential need for additional domain-specific constraints. Overall, our findings underscore the importance of multi-scale representation learning for capturing complex flight behaviors and demonstrate the promise of TimeVQVAE in producing representative synthetic trajectories for downstream tasks such as model training, airspace design, and air traffic forecasting.","authors":["Abdulmajid Murad","Massimiliano Ruocco"],"url":"https://arxiv.org/abs/2504.09101"}
{"created":"2025-04-15","title":"IMPACT: Behavioral Intention-aware Multimodal Trajectory Prediction with Adaptive Context Trimming","abstract":"While most prior research has focused on improving the precision of multimodal trajectory predictions, the explicit modeling of multimodal behavioral intentions (e.g., yielding, overtaking) remains relatively underexplored. This paper proposes a unified framework that jointly predicts both behavioral intentions and trajectories to enhance prediction accuracy, interpretability, and efficiency. Specifically, we employ a shared context encoder for both intention and trajectory predictions, thereby reducing structural redundancy and information loss. Moreover, we address the lack of ground-truth behavioral intention labels in mainstream datasets (Waymo, Argoverse) by auto-labeling these datasets, thus advancing the community's efforts in this direction. We further introduce a vectorized occupancy prediction module that infers the probability of each map polyline being occupied by the target vehicle's future trajectory. By leveraging these intention and occupancy prediction priors, our method conducts dynamic, modality-dependent pruning of irrelevant agents and map polylines in the decoding stage, effectively reducing computational overhead and mitigating noise from non-critical elements. Our approach ranks first among LiDAR-free methods on the Waymo Motion Dataset and achieves first place on the Waymo Interactive Prediction Dataset. Remarkably, even without model ensembling, our single-model framework improves the soft mean average precision (softmAP) by 10 percent compared to the second-best method in the Waymo Interactive Prediction Leaderboard. Furthermore, the proposed framework has been successfully deployed on real vehicles, demonstrating its practical effectiveness in real-world applications.","authors":["Jiawei Sun","Xibin Yue","Jiahui Li","Tianle Shen","Chengran Yuan","Shuo Sun","Sheng Guo","Quanyun Zhou","Marcelo H Ang Jr"],"url":"https://arxiv.org/abs/2504.09103"}
{"created":"2025-04-15","title":"Tell-XR: Conversational End-User Development of XR Automations","abstract":"The availability of extended reality (XR) devices has widened their adoption, yet authoring interactive experiences remains complex for non-programmers. We introduce Tell-XR, an intelligent agent leveraging large language models (LLMs) to guide end-users in defining the interaction in XR settings using automations described as Event-Condition-Action (ECA) rules. Through a formative study, we identified the key conversation stages to define and refine automations, which informed the design of the system architecture. The evaluation study in two scenarios (a VR museum and an AR smart home) demonstrates the effectiveness of Tell-XR across different XR interaction settings.","authors":["Alessandro Carcangiu","Marco Manca","Jacopo Mereu","Carmen Santoro","Ludovica Simeoli","Lucio Davide Spano"],"url":"https://arxiv.org/abs/2504.09104"}
{"created":"2025-04-15","title":"Multi-modal and Multi-view Fundus Image Fusion for Retinopathy Diagnosis via Multi-scale Cross-attention and Shifted Window Self-attention","abstract":"The joint interpretation of multi-modal and multi-view fundus images is critical for retinopathy prevention, as different views can show the complete 3D eyeball field and different modalities can provide complementary lesion areas. Compared with single images, the sequence relationships in multi-modal and multi-view fundus images contain long-range dependencies in lesion features. By modeling the long-range dependencies in these sequences, lesion areas can be more comprehensively mined, and modality-specific lesions can be detected. To learn the long-range dependency relationship and fuse complementary multi-scale lesion features between different fundus modalities, we design a multi-modal fundus image fusion method based on multi-scale cross-attention, which solves the static receptive field problem in previous multi-modal medical fusion methods based on attention. To capture multi-view relative positional relationships between different views and fuse comprehensive lesion features between different views, we design a multi-view fundus image fusion method based on shifted window self-attention, which also solves the computational complexity of the multi-view fundus fusion method based on self-attention is quadratic to the size and number of multi-view fundus images. Finally, we design a multi-task retinopathy diagnosis framework to help ophthalmologists reduce workload and improve diagnostic accuracy by combining the proposed two fusion methods. The experimental results of retinopathy classification and report generation tasks indicate our method's potential to improve the efficiency and reliability of retinopathy diagnosis in clinical practice, achieving a classification accuracy of 82.53\\% and a report generation BlEU-1 of 0.543.","authors":["Yonghao Huang","Leiting Chen","Chuan Zhou"],"url":"https://arxiv.org/abs/2504.09106"}
{"created":"2025-04-15","title":"Shrinkage Initialization for Smooth Learning of Neural Networks","abstract":"The successes of intelligent systems have quite relied on the artificial learning of information, which lead to the broad applications of neural learning solutions. As a common sense, the training of neural networks can be largely improved by specifically defined initialization, neuron layers as well as the activation functions. Though there are sequential layer based initialization available, the generalized solution to initial stages is still desired. In this work, an improved approach to initialization of neural learning is presented, which adopts the shrinkage approach to initialize the transformation of each layer of networks. It can be universally adapted for the structures of any networks with random layers, while stable performance can be attained. Furthermore, the smooth learning of networks is adopted in this work, due to the diverse influence on neural learning. Experimental results on several artificial data sets demonstrate that, the proposed method is able to present robust results with the shrinkage initialization, and competent for smooth learning of neural networks.","authors":["Miao Cheng","Feiyan Zhou","Hongwei Zou","Limin Wang"],"url":"https://arxiv.org/abs/2504.09107"}
{"created":"2025-04-15","title":"Probability Distribution Alignment and Low-Rank Weight Decomposition for Source-Free Domain Adaptive Brain Decoding","abstract":"Brain decoding currently faces significant challenges in individual differences, modality alignment, and high-dimensional embeddings. To address individual differences, researchers often use source subject data, which leads to issues such as privacy leakage and heavy data storage burdens. In modality alignment, current works focus on aligning the softmax probability distribution but neglect the alignment of marginal probability distributions, resulting in modality misalignment. Additionally, images and text are aligned separately with fMRI without considering the complex interplay between images and text, leading to poor image reconstruction. Finally, the enormous dimensionality of CLIP embeddings causes significant computational costs. Although the dimensionality of CLIP embeddings can be reduced by ignoring the number of patches obtained from images and the number of tokens acquired from text, this comes at the cost of a significant drop in model performance, creating a dilemma. To overcome these limitations, we propose a source-free domain adaptation-based brain decoding framework","authors":["Ganxi Xu","Jinyi Long","Hanrui Wu","Jia Zhang"],"url":"https://arxiv.org/abs/2504.09109"}
{"created":"2025-04-15","title":"Adaptive and Efficient Log Parsing as a Cloud Service","abstract":"Logs are a critical data source for cloud systems, enabling advanced features like monitoring, alerting, and root cause analysis. However, the massive scale and diverse formats of unstructured logs pose challenges for adaptable, efficient, and accurate parsing methods. This paper introduces ByteBrain-LogParser, an innovative log parsing framework designed specifically for cloud environments. ByteBrain-LogParser employs a hierarchical clustering algorithm to allow real-time precision adjustments, coupled with optimizations such as positional similarity distance, deduplication, and hash encoding to enhance performance. Experiments on large-scale datasets show that it processes 229,000 logs per second on average, achieving an 840% speedup over the fastest baseline while maintaining accuracy comparable to state-of-the-art methods. Real-world evaluations further validate its efficiency and adaptability, demonstrating its potential as a robust cloud-based log parsing solution.","authors":["Zeyan Li","Jie Song","Tieying Zhang","Tao Yang","Xiongjun Ou","Yingjie Ye","Pengfei Duan","Muchen Lin","Jianjun Chen"],"url":"https://arxiv.org/abs/2504.09113"}
{"created":"2025-04-15","title":"Deploying Large AI Models on Resource-Limited Devices with Split Federated Learning","abstract":"Large Artificial Intelligence Models (LAMs) powered by massive datasets, extensive parameter scales, and extensive computational resources, leading to significant transformations across various industries. Yet, their practical deployment on resource-limited mobile edge devices is hindered by critical challenges such as data privacy, constrained resources, and high overhead costs. Addressing this gap, this paper proposes a novel framework, named Quantized Split Federated Fine-Tuning Large AI Model (SFLAM). By partitioning the training load between edge devices and servers using a split learning paradigm, SFLAM can facilitate the operation of large models on devices and significantly lowers the memory requirements on edge devices. Additionally, SFLAM incorporates quantization management, power control, and bandwidth allocation strategies to enhance training efficiency while concurrently reducing energy consumption and communication latency. A theoretical analysis exploring the latency-energy trade-off is presented, and the framework's efficacy is validated via comprehensive simulations. The findings indicate that SFLAM achieves superior performance in terms of learning efficiency and scalability compared to conventional methods, thereby providing a valuable approach for enabling advanced AI services in resource-constrained scenarios.","authors":["Xianke Qiang","Hongda Liu","Xinran Zhang","Zheng Chang","Ying-Chang Liang"],"url":"https://arxiv.org/abs/2504.09114"}
{"created":"2025-04-15","title":"CAShift: Benchmarking Log-Based Cloud Attack Detection under Normality Shift","abstract":"With the rapid advancement of cloud-native computing, securing cloud environments has become an important task. Log-based Anomaly Detection (LAD) is the most representative technique used in different systems for attack detection and safety guarantee, where multiple LAD methods and relevant datasets have been proposed. However, even though some of these datasets are specifically prepared for cloud systems, they only cover limited cloud behaviors and lack information from a whole-system perspective. Besides, another critical issue to consider is normality shift, which implies the test distribution could differ from the training distribution and highly affects the performance of LAD. Unfortunately, existing works only focus on simple shift types such as chronological changes, while other important and cloud-specific shift types are ignored, e.g., the distribution shift introduced by different deployed cloud architectures. Therefore, creating a new dataset that covers diverse behaviors of cloud systems and normality shift types is necessary.","authors":["Jiongchi Yu","Xiaofei Xie","Qiang Hu","Bowen Zhang","Ziming Zhao","Yun Lin","Lei Ma","Ruitao Feng","Frank Liau"],"url":"https://arxiv.org/abs/2504.09115"}
{"created":"2025-04-15","title":"HARQ-based Quantized Average Consensus over Unreliable Directed Network Topologies","abstract":"In this paper, we propose a distributed algorithm (herein called HARQ-QAC) that enables nodes to calculate the average of their initial states by exchanging quantized messages over a directed communication network. In our setting, we assume that our communication network consists of unreliable communication links (i.e., links suffering from packet drops). For countering link unreliability our algorithm leverages narrowband error-free feedback channels for acknowledging whether a packet transmission between nodes was successful. Additionally, we show that the feedback channels play a crucial role in enabling our algorithm to exhibit finite-time convergence. We analyze our algorithm and demonstrate its operation via an example, where we illustrate its operational advantages. Finally, simulations corroborate that our proposed algorithm converges to the average of the initial quantized values in a finite number of steps, despite the packet losses. This is the first quantized consensus algorithm in the literature that can handle packet losses and converge to the average. Additionally, the use of the retransmission mechanism allows for accelerating the convergence.","authors":["Neofytos Charalampous","Evagoras Makridis","Apostolos I. Rikos","Themistoklis Charalambous"],"url":"https://arxiv.org/abs/2504.09117"}
{"created":"2025-04-15","title":"Optimizing FDTD Solvers for Electromagnetics: A Compiler-Guided Approach with High-Level Tensor Abstractions","abstract":"The Finite Difference Time Domain (FDTD) method is a widely used numerical technique for solving Maxwell's equations, particularly in computational electromagnetics and photonics. It enables accurate modeling of wave propagation in complex media and structures but comes with significant computational challenges. Traditional FDTD implementations rely on handwritten, platform-specific code that optimizes certain kernels while underperforming in others. The lack of portability increases development overhead and creates performance bottlenecks, limiting scalability across modern hardware architectures. To address these challenges, we introduce an end-to-end domain-specific compiler based on the MLIR/LLVM infrastructure for FDTD simulations. Our approach generates efficient and portable code optimized for diverse hardware platforms.We implement the three-dimensional FDTD kernel as operations on a 3D tensor abstraction with explicit computational semantics. High-level optimizations such as loop tiling, fusion, and vectorization are automatically applied by the compiler. We evaluate our customized code generation pipeline on Intel, AMD, and ARM platforms, achieving up to $10\\times$ speedup over baseline Python implementation using NumPy.","authors":["Yifei He","M{\\aa}ns I. Andersson","Stefano Markidis"],"url":"https://arxiv.org/abs/2504.09118"}
{"created":"2025-04-15","title":"Linear complementary dual quasi-cyclic codes of index 2","abstract":"We provide a polynomial approach to investigate linear complementary dual (LCD) quasi-cyclic codes over finite fields. We establish necessary and sufficient conditions for LCD quasi-cyclic codes of index 2 with respect to the Euclidean, Hermitian, and symplectic inner products. As a consequence of these characterizations, we derive necessary and sufficient conditions for LCD one-generator quasi-cyclic codes.","authors":["Kanat Abdukhalikov","Duy Ho","San Ling","Gyanendra K. Verma"],"url":"https://arxiv.org/abs/2504.09126"}
{"created":"2025-04-15","title":"A Constrained Optimization Approach for Gaussian Splatting from Coarsely-posed Images and Noisy Lidar Point Clouds","abstract":"3D Gaussian Splatting (3DGS) is a powerful reconstruction technique, but it needs to be initialized from accurate camera poses and high-fidelity point clouds. Typically, the initialization is taken from Structure-from-Motion (SfM) algorithms; however, SfM is time-consuming and restricts the application of 3DGS in real-world scenarios and large-scale scene reconstruction. We introduce a constrained optimization method for simultaneous camera pose estimation and 3D reconstruction that does not require SfM support. Core to our approach is decomposing a camera pose into a sequence of camera-to-(device-)center and (device-)center-to-world optimizations. To facilitate, we propose two optimization constraints conditioned to the sensitivity of each parameter group and restricts each parameter's search space. In addition, as we learn the scene geometry directly from the noisy point clouds, we propose geometric constraints to improve the reconstruction quality. Experiments demonstrate that the proposed method significantly outperforms the existing (multi-modal) 3DGS baseline and methods supplemented by COLMAP on both our collected dataset and two public benchmarks.","authors":["Jizong Peng","Tze Ho Elden Tse","Kai Xu","Wenchao Gao","Angela Yao"],"url":"https://arxiv.org/abs/2504.09129"}
{"created":"2025-04-15","title":"VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search","abstract":"Recent advancements in Large Vision-Language Models have showcased remarkable capabilities. However, they often falter when confronted with complex reasoning tasks that humans typically address through visual aids and deliberate, step-by-step thinking. While existing methods have explored text-based slow thinking or rudimentary visual assistance, they fall short of capturing the intricate, interleaved nature of human visual-verbal reasoning processes. To overcome these limitations and inspired by the mechanisms of slow thinking in human cognition, we introduce VisuoThink, a novel framework that seamlessly integrates visuospatial and linguistic domains. VisuoThink facilitates multimodal slow thinking by enabling progressive visual-textual reasoning and incorporates test-time scaling through look-ahead tree search. Extensive experiments demonstrate that VisuoThink significantly enhances reasoning capabilities via inference-time scaling, even without fine-tuning, achieving state-of-the-art performance in tasks involving geometry and spatial reasoning.","authors":["Yikun Wang","Siyin Wang","Qinyuan Cheng","Zhaoye Fei","Liang Ding","Qipeng Guo","Dacheng Tao","Xipeng Qiu"],"url":"https://arxiv.org/abs/2504.09130"}
{"created":"2025-04-15","title":"Haptic Perception via the Dynamics of Flexible Body Inspired by an Ostrich's Neck","abstract":"In biological systems, haptic perception is achieved through both flexible skin and flexible body. In fully soft robots, the fragility of their bodies and the time delays in sensory processing pose significant challenges. The musculoskeletal system possesses both the deformability inherent in soft materials and the durability of rigid-body robots. Additionally, by outsourcing part of the intelligent information processing to the morphology of the musculoskeletal system, applications for dynamic tasks are expected. This study focuses on the pecking movements of birds, which achieve precise haptic perception through the musculoskeletal system of their flexible neck. Physical reservoir computing is applied to flexible structures inspired by an ostrich neck to analyze the relationship between haptic perception and physical characteristics. Combined experiments using both an actual robot and simulations demonstrate that, under appropriate body viscoelasticity, the flexible structure can distinguish objects of varying softness and memorize this information as behaviors. Drawing on these findings and anatomical insights from the ostrich neck, a haptic sensing system is proposed that possesses separability and this behavioral memory in flexible structures, enabling rapid learning and real-time inference. The results demonstrate that through the dynamics of flexible structures, diverse functions can emerge beyond their original design as manipulators.","authors":["Kazashi Nakano","Katsuma Inoue","Yasuo Kuniyoshi","Kohei Nakajima"],"url":"https://arxiv.org/abs/2504.09131"}
{"created":"2025-04-15","title":"Self-Supervised Autoencoder Network for Robust Heart Rate Extraction from Noisy Photoplethysmogram: Applying Blind Source Separation to Biosignal Analysis","abstract":"Biosignals can be viewed as mixtures measuring particular physiological events, and blind source separation (BSS) aims to extract underlying source signals from mixtures. This paper proposes a self-supervised multi-encoder autoencoder (MEAE) to separate heartbeat-related source signals from photoplethysmogram (PPG), enhancing heart rate (HR) detection in noisy PPG data. The MEAE is trained on PPG signals from a large open polysomnography database without any pre-processing or data selection. The trained network is then applied to a noisy PPG dataset collected during the daily activities of nine subjects. The extracted heartbeat-related source signal significantly improves HR detection as compared to the original PPG. The absence of pre-processing and the self-supervised nature of the proposed method, combined with its strong performance, highlight the potential of BSS in biosignal analysis.","authors":["Matthew B. Webster","Dongheon Lee","Joonnyong Lee"],"url":"https://arxiv.org/abs/2504.09132"}
{"created":"2025-04-15","title":"Steady-State Drifting Equilibrium Analysis of Single-Track Two-Wheeled Robots for Controller Design","abstract":"Drifting is an advanced driving technique where the wheeled robot's tire-ground interaction breaks the common non-holonomic pure rolling constraint. This allows high-maneuverability tasks like quick cornering, and steady-state drifting control enhances motion stability under lateral slip conditions. While drifting has been successfully achieved in four-wheeled robot systems, its application to single-track two-wheeled (STTW) robots, such as unmanned motorcycles or bicycles, has not been thoroughly studied. To bridge this gap, this paper extends the drifting equilibrium theory to STTW robots and reveals the mechanism behind the steady-state drifting maneuver. Notably, the counter-steering drifting technique used by skilled motorcyclists is explained through this theory. In addition, an analytical algorithm based on intrinsic geometry and kinematics relationships is proposed, reducing the computation time by four orders of magnitude while maintaining less than 6% error compared to numerical methods. Based on equilibrium analysis, a model predictive controller (MPC) is designed to achieve steady-state drifting and equilibrium points transition, with its effectiveness and robustness validated through simulations.","authors":["Feilong Jing","Yang Deng","Boyi Wang","Xudong Zheng","Yifan Sun","Zhang Chen","Bin Liang"],"url":"https://arxiv.org/abs/2504.09134"}
{"created":"2025-04-15","title":"Efficient and Asymptotically Unbiased Constrained Decoding for Large Language Models","abstract":"In real-world applications of large language models, outputs are often required to be confined: selecting items from predefined product or document sets, generating phrases that comply with safety standards, or conforming to specialized formatting styles. To control the generation, constrained decoding has been widely adopted. However, existing prefix-tree-based constrained decoding is inefficient under GPU-based model inference paradigms, and it introduces unintended biases into the output distribution. This paper introduces Dynamic Importance Sampling for Constrained Decoding (DISC) with GPU-based Parallel Prefix-Verification (PPV), a novel algorithm that leverages dynamic importance sampling to achieve theoretically guaranteed asymptotic unbiasedness and overcomes the inefficiency of prefix-tree. Extensive experiments demonstrate the superiority of our method over existing methods in both efficiency and output quality. These results highlight the potential of our methods to improve constrained generation in applications where adherence to specific constraints is essential.","authors":["Haotian Ye","Himanshu Jain","Chong You","Ananda Theertha Suresh","Haowei Lin","James Zou","Felix Yu"],"url":"https://arxiv.org/abs/2504.09135"}
{"created":"2025-04-15","title":"Can Large Language Models Become Policy Refinement Partners? Evidence from China's Social Security Studies","abstract":"The rapid development of large language models (LLMs) is reshaping operational paradigms across multidisciplinary domains. LLMs' emergent capability to synthesize policy-relevant insights across disciplinary boundaries suggests potential as decision-support tools. However, their actual performance and suitability as policy refinement partners still require verification through rigorous and systematic evaluations. Our study employs the context-embedded generation-adaptation framework to conduct a tripartite comparison among the American GPT-4o, the Chinese DeepSeek-R1 and human researchers, investigating the capability boundaries and performance characteristics of LLMs in generating policy recommendations for China's social security issues. This study demonstrates that while large LLMs exhibit distinct advantages in systematic policy design, they face significant limitations in addressing complex social dynamics, balancing stakeholder interests, and controlling fiscal risks within the social security domain. Furthermore, DeepSeek-R1 demonstrates superior performance to GPT-4o across all evaluation dimensions in policy recommendation generation, illustrating the potential of localized training to improve contextual alignment. These findings suggest that regionally-adapted LLMs can function as supplementary tools for generating diverse policy alternatives informed by domain-specific social insights. Nevertheless, the formulation of policy refinement requires integration with human researchers' expertise, which remains critical for interpreting institutional frameworks, cultural norms, and value systems.","authors":["Ke Jinghan","Zhou Zheng","Zhao Yuxuan"],"url":"https://arxiv.org/abs/2504.09137"}
{"created":"2025-04-15","title":"White-Box AI Model: Next Frontier of Wireless Communications","abstract":"White-box AI (WAI), or explainable AI (XAI) model, a novel tool to achieve the reasoning behind decisions and predictions made by the AI algorithms, makes it more understandable and transparent. It offers a new approach to address key challenges of interpretability and mathematical validation in traditional black-box models. In this paper, WAI-aided wireless communication systems are proposed and investigated thoroughly to utilize the promising capabilities. First, we introduce the fundamental principles of WAI. Then, a detailed comparison between WAI and traditional black-box model is conducted in terms of optimization objectives and architecture design, with a focus on deep neural networks (DNNs) and transformer networks. Furthermore, in contrast to the traditional black-box methods, WAI leverages theory-driven causal modeling and verifiable optimization paths, thereby demonstrating potential advantages in areas such as signal processing and resource allocation. Finally, we outline future research directions for the integration of WAI in wireless communication systems.","authors":["Jiayao Yang","Jiayi Zhang","Bokai Xu","Jiakang Zheng","Zhilong Liu","Ziheng Liu","Dusit Niyato","M\\'erouane Debbah","Zhu Han","Bo Ai"],"url":"https://arxiv.org/abs/2504.09138"}
{"created":"2025-04-15","title":"Exact inequalities and optimal recovery by inaccurate information","abstract":"The paper considers a multidimensional problem of optimal recovery of an operator whose action is represented by multiplying the original function by a weight function of a special type, based on inaccurately specified information about the values of operators of a similar type. An exact inequality for the norms of such operators is obtained. The problem under consideration is a generalization of the problem of optimal recovery of a derivative based on other inaccurately specified derivatives in the space $\\mathbb R^d$ and the problem of an exact inequality, which is an analogue of the Hardy-Littlewood-Polya inequality.","authors":["K. Yu. Osipenko"],"url":"https://arxiv.org/abs/2504.09139"}
{"created":"2025-04-15","title":"Understanding Intention to Adopt Smart Thermostats: The Role of Individual Predictors and Social Beliefs Across Five EU Countries","abstract":"Heating of buildings represents a significant share of the energy consumption in Europe. Smart thermostats that capitalize on the data-driven analysis of heating patterns in order to optimize heat supply are a very promising part of building energy management technology. However, factors driving their acceptance by building inhabitants are poorly understood although being a prerequisite for fully tapping on their potential. In order to understand the driving forces of technology adoption in this use case, a large survey (N = 2250) was conducted in five EU countries (Austria, Belgium, Estonia, Germany, Greece). For the data analysis structural equation modelling based on the Unified Theory of Acceptance and Use of Technology (UTAUT) was employed, which was extended by adding social beliefs, including descriptive social norms, collective efficacy, social identity and trust. As a result, performance expectancy, price value, and effort expectancy proved to be the most important predictors overall, with variations across countries. In sum, the adoption of smart thermostats appears more strongly associated with individual beliefs about their functioning, potentially reducing their adoption. At the end of the paper, implications for policy making and marketing of smart heating technologies are discussed.","authors":["Mona Bielig","Florian Kutzner","Sonja Klingert","Celina Kacperski"],"url":"https://arxiv.org/abs/2504.09142"}
{"created":"2025-04-15","title":"Kernel-Based Enhanced Oversampling Method for Imbalanced Classification","abstract":"This paper introduces a novel oversampling technique designed to improve classification performance on imbalanced datasets. The proposed method enhances the traditional SMOTE algorithm by incorporating convex combination and kernel-based weighting to generate synthetic samples that better represent the minority class. Through experiments on multiple real-world datasets, we demonstrate that the new technique outperforms existing methods in terms of F1-score, G-mean, and AUC, providing a robust solution for handling imbalanced datasets in classification tasks.","authors":["Wenjie Li","Sibo Zhu","Zhijian Li","Hanlin Wang"],"url":"https://arxiv.org/abs/2504.09147"}
{"created":"2025-04-15","title":"MASH: Masked Anchored SpHerical Distances for 3D Shape Representation and Generation","abstract":"We introduce Masked Anchored SpHerical Distances (MASH), a novel multi-view and parametrized representation of 3D shapes. Inspired by multi-view geometry and motivated by the importance of perceptual shape understanding for learning 3D shapes, MASH represents a 3D shape as a collection of observable local surface patches, each defined by a spherical distance function emanating from an anchor point. We further leverage the compactness of spherical harmonics to encode the MASH functions, combined with a generalized view cone with a parameterized base that masks the spatial extent of the spherical function to attain locality. We develop a differentiable optimization algorithm capable of converting any point cloud into a MASH representation accurately approximating ground-truth surfaces with arbitrary geometry and topology. Extensive experiments demonstrate that MASH is versatile for multiple applications including surface reconstruction, shape generation, completion, and blending, achieving superior performance thanks to its unique representation encompassing both implicit and explicit features.","authors":["Changhao Li","Yu Xin","Xiaowei Zhou","Ariel Shamir","Hao Zhang","Ligang Liu","Ruizhen Hu"],"url":"https://arxiv.org/abs/2504.09149"}
{"created":"2025-04-15","title":"Leveraging Application-Specific Knowledge for Energy-Efficient Deep Learning Accelerators on Resource-Constrained FPGAs","abstract":"The growing adoption of Deep Learning (DL) applications in the Internet of Things has increased the demand for energy-efficient accelerators. Field Programmable Gate Arrays (FPGAs) offer a promising platform for such acceleration due to their flexibility and power efficiency. However, deploying DL models on resource-constrained FPGAs remains challenging because of limited resources, workload variability, and the need for energy-efficient operation. This paper presents a framework for generating energy-efficient DL accelerators on resource-constrained FPGAs. The framework systematically explores design configurations to enhance energy efficiency while meeting requirements for resource utilization and inference performance in diverse application scenarios. The contributions of this work include: (1) analyzing challenges in achieving energy efficiency on resource-constrained FPGAs; (2) proposing a methodology for designing DL accelerators with integrated Register Transfer Level (RTL) optimizations, workload-aware strategies, and application-specific knowledge; and (3) conducting a literature review to identify gaps and demonstrate the necessity of this work.","authors":["Chao Qian"],"url":"https://arxiv.org/abs/2504.09151"}
{"created":"2025-04-15","title":"MatWheel: Addressing Data Scarcity in Materials Science Through Synthetic Data","abstract":"Data scarcity and the high cost of annotation have long been persistent challenges in the field of materials science. Inspired by its potential in other fields like computer vision, we propose the MatWheel framework, which train the material property prediction model using the synthetic data generated by the conditional generative model. We explore two scenarios: fully-supervised and semi-supervised learning. Using CGCNN for property prediction and Con-CDVAE as the conditional generative model, experiments on two data-scarce material property datasets from Matminer database are conducted. Results show that synthetic data has potential in extreme data-scarce scenarios, achieving performance close to or exceeding that of real samples in all two tasks. We also find that pseudo-labels have little impact on generated data quality. Future work will integrate advanced models and optimize generation conditions to boost the effectiveness of the materials data flywheel.","authors":["Wentao Li","Yizhe Chen","Jiangjie Qiu","Xiaonan Wang"],"url":"https://arxiv.org/abs/2504.09152"}
{"created":"2025-04-15","title":"Secure Physical Layer Communications for Low-Altitude Economy Networking: A Survey","abstract":"The Low-Altitude Economy Networking (LAENet) is emerging as a transformative paradigm that enables an integrated and sophisticated communication infrastructure to support aerial vehicles in carrying out a wide range of economic activities within low-altitude airspace. However, the physical layer communications in the LAENet face growing security threats due to inherent characteristics of aerial communication environments, such as signal broadcast nature and channel openness. These challenges highlight the urgent need for safeguarding communication confidentiality, availability, and integrity. In view of the above, this survey comprehensively reviews existing secure countermeasures for physical layer communication in the LAENet. We explore core methods focusing on anti-eavesdropping and authentication for ensuring communication confidentiality. Subsequently, availability-enhancing techniques are thoroughly discussed for anti-jamming and spoofing defense. Then, we review approaches for safeguarding integrity through anomaly detection and injection protection. Furthermore, we discuss future research directions, emphasizing energy-efficient physical layer security, multi-drone collaboration for secure communication, AI-driven security defense strategy, space-air-ground integrated security architecture, and 6G-enabled secure UAV communication. This survey may provide valuable references and new insights for researchers in the field of secure physical layer communication for the LAENet.","authors":["Lingyi Cai","Jiacheng Wang","Ruichen Zhang","Yu Zhang","Tao Jiang","Dusit Niyato","Xianbin Wang","Abbas Jamalipour","Xuemin Shen"],"url":"https://arxiv.org/abs/2504.09153"}
{"created":"2025-04-15","title":"Exploring Modality Disruption in Multimodal Fake News Detection","abstract":"The rapid growth of social media has led to the widespread dissemination of fake news across multiple content forms, including text, images, audio, and video. Compared to unimodal fake news detection, multimodal fake news detection benefits from the increased availability of information across multiple modalities. However, in the context of social media, certain modalities in multimodal fake news detection tasks may contain disruptive or over-expressive information. These elements often include exaggerated or embellished content. We define this phenomenon as modality disruption and explore its impact on detection models through experiments. To address the issue of modality disruption in a targeted manner, we propose a multimodal fake news detection framework, FND-MoE. Additionally, we design a two-pass feature selection mechanism to further mitigate the impact of modality disruption. Extensive experiments on the FakeSV and FVC-2018 datasets demonstrate that FND-MoE significantly outperforms state-of-the-art methods, with accuracy improvements of 3.45% and 3.71% on the respective datasets compared to baseline models.","authors":["Moyang Liu","Kaiying Yan","Yukun Liu","Ruibo Fu","Zhengqi Wen","Xuefei Liu","Chenxing Li"],"url":"https://arxiv.org/abs/2504.09154"}
{"created":"2025-04-15","title":"Evolved Hierarchical Masking for Self-Supervised Learning","abstract":"Existing Masked Image Modeling methods apply fixed mask patterns to guide the self-supervised training. As those mask patterns resort to different criteria to depict image contents, sticking to a fixed pattern leads to a limited vision cues modeling capability.This paper introduces an evolved hierarchical masking method to pursue general visual cues modeling in self-supervised learning. The proposed method leverages the vision model being trained to parse the input visual cues into a hierarchy structure, which is hence adopted to generate masks accordingly. The accuracy of hierarchy is on par with the capability of the model being trained, leading to evolved mask patterns at different training stages. Initially, generated masks focus on low-level visual cues to grasp basic textures, then gradually evolve to depict higher-level cues to reinforce the learning of more complicated object semantics and contexts. Our method does not require extra pre-trained models or annotations and ensures training efficiency by evolving the training difficulty. We conduct extensive experiments on seven downstream tasks including partial-duplicate image retrieval relying on low-level details, as well as image classification and semantic segmentation that require semantic parsing capability. Experimental results demonstrate that it substantially boosts performance across these tasks. For instance, it surpasses the recent MAE by 1.1\\% in imageNet-1K classification and 1.4\\% in ADE20K segmentation with the same training epochs. We also align the proposed method with the current research focus on LLMs. The proposed approach bridges the gap with large-scale pre-training on semantic demanding tasks and enhances intricate detail perception in tasks requiring low-level feature recognition.","authors":["Zhanzhou Feng","Shiliang Zhang"],"url":"https://arxiv.org/abs/2504.09155"}
{"created":"2025-04-15","title":"LEREL: Lipschitz Continuity-Constrained Emotion Recognition Ensemble Learning For Electroencephalography","abstract":"Accurate and efficient perception of emotional states in oneself and others is crucial, as emotion-related disorders are associated with severe psychosocial impairments. While electroencephalography (EEG) offers a powerful tool for emotion detection, current EEG-based emotion recognition (EER) methods face key limitations: insufficient model stability, limited accuracy in processing high-dimensional nonlinear EEG signals, and poor robustness against intra-subject variability and signal noise. To address these challenges, we propose LEREL (Lipschitz continuity-constrained Emotion Recognition Ensemble Learning), a novel framework that significantly enhances both the accuracy and robustness of emotion recognition performance. The LEREL framework employs Lipschitz continuity constraints to enhance model stability and generalization in EEG emotion recognition, reducing signal variability and noise susceptibility while maintaining strong performance on small-sample datasets. The ensemble learning strategy reduces single-model bias and variance through multi-classifier decision fusion, further optimizing overall performance. Experimental results on three public benchmark datasets (EAV, FACED and SEED) demonstrate LEREL's effectiveness, achieving average recognition accuracies of 76.43%, 83.00% and 89.22%, respectively.","authors":["Shengyu Gong","Yueyang Li","Zijian Kang","Weiming Zeng","Hongjie Yan","Wai Ting Siok","Nizhuan Wang"],"url":"https://arxiv.org/abs/2504.09156"}
{"created":"2025-04-15","title":"SCFlow2: Plug-and-Play Object Pose Refiner with Shape-Constraint Scene Flow","abstract":"We introduce SCFlow2, a plug-and-play refinement framework for 6D object pose estimation. Most recent 6D object pose methods rely on refinement to get accurate results. However, most existing refinement methods either suffer from noises in establishing correspondences, or rely on retraining for novel objects. SCFlow2 is based on the SCFlow model designed for refinement with shape constraint, but formulates the additional depth as a regularization in the iteration via 3D scene flow for RGBD frames. The key design of SCFlow2 is an introduction of geometry constraints into the training of recurrent matching network, by combining the rigid-motion embeddings in 3D scene flow and 3D shape prior of the target. We train SCFlow2 on a combination of dataset Objaverse, GSO and ShapeNet, and evaluate on BOP datasets with novel objects. After using our method as a post-processing, most state-of-the-art methods produce significantly better results, without any retraining or fine-tuning. The source code is available at https://scflow2.github.io.","authors":["Qingyuan Wang","Rui Song","Jiaojiao Li","Kerui Cheng","David Ferstl","Yinlin Hu"],"url":"https://arxiv.org/abs/2504.09160"}
{"created":"2025-04-15","title":"Deconfounded Reasoning for Multimodal Fake News Detection via Causal Intervention","abstract":"The rapid growth of social media has led to the widespread dissemination of fake news across multiple content forms, including text, images, audio, and video. Traditional unimodal detection methods fall short in addressing complex cross-modal manipulations; as a result, multimodal fake news detection has emerged as a more effective solution. However, existing multimodal approaches, especially in the context of fake news detection on social media, often overlook the confounders hidden within complex cross-modal interactions, leading models to rely on spurious statistical correlations rather than genuine causal mechanisms. In this paper, we propose the Causal Intervention-based Multimodal Deconfounded Detection (CIMDD) framework, which systematically models three types of confounders via a unified Structural Causal Model (SCM): (1) Lexical Semantic Confounder (LSC); (2) Latent Visual Confounder (LVC); (3) Dynamic Cross-Modal Coupling Confounder (DCCC). To mitigate the influence of these confounders, we specifically design three causal modules based on backdoor adjustment, frontdoor adjustment, and cross-modal joint intervention to block spurious correlations from different perspectives and achieve causal disentanglement of representations for deconfounded reasoning. Experimental results on the FakeSV and FVC datasets demonstrate that CIMDD significantly improves detection accuracy, outperforming state-of-the-art methods by 4.27% and 4.80%, respectively. Furthermore, extensive experimental results indicate that CIMDD exhibits strong generalization and robustness across diverse multimodal scenarios.","authors":["Moyang Liu","Kaiying Yan","Yukun Liu","Ruibo Fu","Zhengqi Wen","Xuefei Liu","Chenxing Li"],"url":"https://arxiv.org/abs/2504.09163"}
{"created":"2025-04-15","title":"Can postgraduate translation students identify machine-generated text?","abstract":"Given the growing use of generative artificial intelligence as a tool for creating multilingual content and bypassing both machine and traditional translation methods, this study explores the ability of linguistically trained individuals to discern machine-generated output from human-written text (HT). After brief training sessions on the textual anomalies typically found in synthetic text (ST), twenty-three postgraduate translation students analysed excerpts of Italian prose and assigned likelihood scores to indicate whether they believed they were human-written or AI-generated (ChatGPT-4o). The results show that, on average, the students struggled to distinguish between HT and ST, with only two participants achieving notable accuracy. Closer analysis revealed that the students often identified the same textual anomalies in both HT and ST, although features such as low burstiness and self-contradiction were more frequently associated with ST. These findings suggest the need for improvements in the preparatory training. Moreover, the study raises questions about the necessity of editing synthetic text to make it sound more human-like and recommends further research to determine whether AI-generated text is already sufficiently natural-sounding not to require further refinement.","authors":["Michael Farrell"],"url":"https://arxiv.org/abs/2504.09164"}
{"created":"2025-04-15","title":"SBFT Tool Competition 2025 -- Java Test Case Generation Track","abstract":"This short report presents the 2025 edition of the Java Unit Testing Competition in which four test generation tools (EVOFUZZ, EVOSUITE, BBC, and RANDOOP) were benchmarked on a freshly selected set of 55 Java classes from six different open source projects. The benchmarking was based on structural metrics, such as code and mutation coverage of the classes under test, as well as on the readability of the generated test cases.","authors":["Fitsum Kifetew","Lin Yun","Davide Prandi"],"url":"https://arxiv.org/abs/2504.09168"}
{"created":"2025-04-15","title":"UX Remix: Improving Measurement Item Design Process Using Large Language Models and Prior Literature","abstract":"Researchers often struggle to develop measurement items and lack a standardized process. To support the design process, we present UX Remix, a system to help researchers develop constructs and measurement items using large language models (LLMs). UX Remix leverages a database of constructs and associated measurement items from previous papers. Based on the data, UX Remix recommends constructs relevant to the research context. The researchers then select appropriate constructs based on the recommendations. Afterward, selected constructs are used to generate a custom construct, and UX Remix recommends measurement items. UX Remix streamlines the process of selecting constructs, developing measurement items, and adapting them to research contexts, addressing challenges in the selection and reuse of measurement items. This paper describes the implementation of the system, the potential benefits, and future directions to improve the rigor and efficiency of measurement design in human-computer interaction (HCI) research.","authors":["Hyeonggeun Yun","Jinkyu Jang"],"url":"https://arxiv.org/abs/2504.09169"}
{"created":"2025-04-15","title":"Langformers: Unified NLP Pipelines for Language Models","abstract":"Transformer-based language models have revolutionized the field of natural language processing (NLP). However, using these models often involves navigating multiple frameworks and tools, as well as writing repetitive boilerplate code. This complexity can discourage non-programmers and beginners, and even slow down prototyping for experienced developers. To address these challenges, we introduce Langformers, an open-source Python library designed to streamline NLP pipelines through a unified, factory-based interface for large language model (LLM) and masked language model (MLM) tasks. Langformers integrates conversational AI, MLM pretraining, text classification, sentence embedding/reranking, data labelling, semantic search, and knowledge distillation into a cohesive API, supporting popular platforms such as Hugging Face and Ollama. Key innovations include: (1) task-specific factories that abstract training, inference, and deployment complexities; (2) built-in memory and streaming for conversational agents; and (3) lightweight, modular design that prioritizes ease of use. Documentation: https://langformers.com","authors":["Rabindra Lamsal","Maria Rodriguez Read","Shanika Karunasekera"],"url":"https://arxiv.org/abs/2504.09170"}
{"created":"2025-04-15","title":"Self-Orthogonal Cellular Automata","abstract":"It is known that no-boundary Cellular Automata (CA) defined by bipermutive local rules give rise to Latin squares. In this paper, we study under which conditions the Latin square generated by a bipermutive CA is self-orthogonal, i.e. orthogonal to its transpose. We first enumerate all bipermutive CA over the binary alphabet up to diameter $d=6$, remarking that only some linear rules give rise to self-orthogonal Latin squares. We then give a full theoretical characterization of self-orthogonal linear CA, by considering the square matrix obtained by stacking the transition matrices of the CA and of its transpose, and determining when it is invertible. Interestingly, the stacked matrix turns out to have a circulant structure, for which there exists an extensive body of results to characterize its invertibility. Further, for the case of the binary alphabet we prove that irreducibility is a sufficient condition for self-orthogonality, and we derive a simpler characterization which boils down to computing the parity of the central coefficients of the local rule.","authors":["Luca Mariot","Federico Mazzone"],"url":"https://arxiv.org/abs/2504.09173"}
{"created":"2025-04-15","title":"Commutative algebra-enhanced topological data analysis","abstract":"Topological Data Analysis (TDA) combines computational topology and data science to extract and analyze intrinsic topological and geometric structures in data set in a metric space. While the persistent homology (PH), a widely used tool in TDA, which tracks the lifespan information of topological features through a filtration process, has shown its effectiveness in applications,it is inherently limited in homotopy invariants and overlooks finer geometric and combinatorial details. To bridge this gap, we introduce two novel commutative algebra-based frameworks which extend beyond homology by incorporating tools from computational commutative algebra : (1) \\emph{the persistent ideals} derived from the decomposition of algebraic objects associated to simplicial complexes, like those in theory of edge ideals and Stanley--Reisner ideals, which will provide new commutative algebra-based barcodes and offer a richer characterization of topological and geometric structures in filtrations.(2)\\emph{persistent chain complex of free modules} associated with traditional persistent simplicial complex by labelling each chain in the chain complex of the persistent simplicial complex with elements in a commutative ring, which will enable us to detect local information of the topology via some pure algebraic operations. \\emph{Crucially, both of the two newly-established framework can recover topological information got from conventional PH and will give us more information.} Therefore, they provide new insights in computational topology, computational algebra and data science.","authors":["Chuanshen Hu","Yu Wang","Kelin Xia","Ke Ye","Yipeng Zhang"],"url":"https://arxiv.org/abs/2504.09174"}
{"created":"2025-04-15","title":"A Confounding Factors-Inhibition Adversarial Learning Framework for Multi-site fMRI Mental Disorder Identification","abstract":"In open data sets of functional magnetic resonance imaging (fMRI), the heterogeneity of the data is typically attributed to a combination of factors, including differences in scanning procedures, the presence of confounding effects, and population diversities between multiple sites. These factors contribute to the diminished effectiveness of representation learning, which in turn affects the overall efficacy of subsequent classification procedures. To address these limitations, we propose a novel multi-site adversarial learning network (MSalNET) for fMRI-based mental disorder detection. Firstly, a representation learning module is introduced with a node information assembly (NIA) mechanism to better extract features from functional connectivity (FC). This mechanism aggregates edge information from both horizontal and vertical directions, effectively assembling node information. Secondly, to generalize the feature across sites, we proposed a site-level feature extraction module that can learn from individual FC data, which circumvents additional prior information. Lastly, an adversarial learning network is proposed as a means of balancing the trade-off between individual classification and site regression tasks, with the introduction of a novel loss function. The proposed method was evaluated on two multi-site fMRI datasets, i.e., Autism Brain Imaging Data Exchange (ABIDE) and ADHD-200. The results indicate that the proposed method achieves a better performance than other related algorithms with the accuracy of 75.56 and 68.92 in ABIDE and ADHD-200 datasets, respectively. Furthermore, the result of the site regression indicates that the proposed method reduces site variability from a data-driven perspective. The most discriminative brain regions revealed by NIA are consistent with statistical findings, uncovering the \"black box\" of deep learning to a certain extent.","authors":["Xin Wen","Shijie Guo","Wenbo Ning","Rui Cao","Yan Niu","Bin Wan","Peng Wei","Xiaobo Liu","Jie Xiang"],"url":"https://arxiv.org/abs/2504.09179"}
{"created":"2025-04-15","title":"A Multi-Layered Security Analysis of Blockchain Systems: From Attack Vectors to Defense and System Hardening","abstract":"The application of Bitcoin enables people to understand blockchain technology gradually. Bitcoin is a decentralized currency that does not rely on third-party credit institutions, and the core of Bitcoin's underlying technology is blockchain. With the increasing value of Bitcoin and the vigorous development of decentralization, people's research on blockchain is also increasing day by day. Today's blockchain technology has not only made great achievements in the application of Bitcoin, but has also been preliminarily applied in other fields, such as finance, medical treatment, the Internet of Things, and so on. However, with the initial application of blockchain technology on the Internet, the security of blockchain technology has also been widely concerned by people in the industry. For example, whether currency trading platforms, smart contracts, blockchain consensus mechanisms, and other technologies are vulnerable to attacks, and how we can defend against these attacks digitally and optimize the blockchain system is exactly the subject we want to study. For the security of appeal blockchain, this paper first analyzes the security threats faced by the application digital currency trading platform of the blockchain system, then analyzes the security problems of smart contract closely related to blockchain 2.0, and then analyzes and studies the security threats of blockchain public chain, consensus mechanism, and P2P. Finally, combined with the security problems at all levels of the blockchain system we analyze and study how to optimize the security of the blockchain system.","authors":["Yuhuan Yang","Shipeng Ye","Xiaoqi Li"],"url":"https://arxiv.org/abs/2504.09181"}
{"created":"2025-04-15","title":"Parameterized Synthetic Text Generation with SimpleStories","abstract":"We present SimpleStories, a large synthetic story dataset in simple language, consisting of 2 million stories each in English and Japanese. Our method employs parametrization of prompts with features at multiple levels of abstraction, allowing for systematic control over story characteristics to ensure broad syntactic and semantic diversity. Building on and addressing limitations in the TinyStories dataset, our approach demonstrates that simplicity and variety can be achieved simultaneously in synthetic text generation at scale.","authors":["Lennart Finke","Thomas Dooms","Mat Allen","Juan Diego Rodriguez","Noa Nabeshima","Dan Braun"],"url":"https://arxiv.org/abs/2504.09184"}
{"created":"2025-04-15","title":"Repetitive Contrastive Learning Enhances Mamba's Selectivity in Time Series Prediction","abstract":"Long sequence prediction is a key challenge in time series forecasting. While Mamba-based models have shown strong performance due to their sequence selection capabilities, they still struggle with insufficient focus on critical time steps and incomplete noise suppression, caused by limited selective abilities. To address this, we introduce Repetitive Contrastive Learning (RCL), a token-level contrastive pretraining framework aimed at enhancing Mamba's selective capabilities. RCL pretrains a single Mamba block to strengthen its selective abilities and then transfers these pretrained parameters to initialize Mamba blocks in various backbone models, improving their temporal prediction performance. RCL uses sequence augmentation with Gaussian noise and applies inter-sequence and intra-sequence contrastive learning to help the Mamba module prioritize information-rich time steps while ignoring noisy ones. Extensive experiments show that RCL consistently boosts the performance of backbone models, surpassing existing methods and achieving state-of-the-art results. Additionally, we propose two metrics to quantify Mamba's selective capabilities, providing theoretical, qualitative, and quantitative evidence for the improvements brought by RCL.","authors":["Wenbo Yan","Hanzhong Cao","Ying Tan"],"url":"https://arxiv.org/abs/2504.09185"}
{"created":"2025-04-15","title":"SW-TNC : Reaching the Most Complex Random Quantum Circuit via Tensor Network Contraction","abstract":"Classical simulation is essential in quantum algorithm development and quantum device verification. With the increasing complexity and diversity of quantum circuit structures, existing classical simulation algorithms need to be improved and extended. In this work, we propose novel strategies for tensor network contraction based simulator on Sunway architecture. Our approach addresses three main aspects: complexity, computational paradigms and fine-grained optimization. Data reuse schemes are designed to reduce floating-point operations, and memory organization techniques are employed to eliminate slicing overhead while maintaining parallelism. Step fusion strategy is extended by multi-core cooperation to improve the data locality and computation intensity. Fine-grained optimizations, such as in-kernel vectorized permutations, and split-K operators, are developed as well to address the challenges in new hotspot distribution and topological structure. These innovations can accelerate the simulation of the Zuchongzhi-60-24 by more than 10 times, using more than 1024 Sunway nodes (399,360 cores). Our work demonstrates the potential for enabling efficient classical simulation of increasingly complex quantum circuits.","authors":["Yaojian Chen","Zhaoqi Sun","Chengyu Qiu","Zegang Li","Yanfei Liu","Lin Gan","Xiaohui Duan","Guangwen Yang"],"url":"https://arxiv.org/abs/2504.09186"}
{"created":"2025-04-15","title":"RSLAQ -- A Robust SLA-driven 6G O-RAN QoS xApp using deep reinforcement learning","abstract":"The evolution of 6G envisions a wide range of applications and services characterized by highly differentiated and stringent Quality of Service (QoS) requirements. Open Radio Access Network (O-RAN) technology has emerged as a transformative approach that enables intelligent software-defined management of the RAN. A cornerstone of O-RAN is the RAN Intelligent Controller (RIC), which facilitates the deployment of intelligent applications (xApps and rApps) near the radio unit. In this context, QoS management through O-RAN has been explored using network slice and machine learning (ML) techniques. Although prior studies have demonstrated the ability to optimize RAN resource allocation and prioritize slices effectively, they have not considered the critical integration of Service Level Agreements (SLAs) into the ML learning process. This omission can lead to suboptimal resource utilization and, in many cases, service outages when target Key Performance Indicators (KPIs) are not met. This work introduces RSLAQ, an innovative xApp designed to ensure robust QoS management for RAN slicing while incorporating SLAs directly into its operational framework. RSLAQ translates operator policies into actionable configurations, guiding resource distribution and scheduling for RAN slices. Using deep reinforcement learning (DRL), RSLAQ dynamically monitors RAN performance metrics and computes optimal actions, embedding SLA constraints to mitigate conflicts and prevent outages. Extensive system-level simulations validate the efficacy of the proposed solution, demonstrating its ability to optimize resource allocation, improve SLA adherence, and maintain operational reliability (>95%) in challenging scenarios.","authors":["Noe M. Yungaicela-Naula","Vishal Sharma","Sandra Scott-Hayward"],"url":"https://arxiv.org/abs/2504.09187"}
{"created":"2025-04-15","title":"Compliant Explicit Reference Governor for Contact Friendly Robotic Manipulators","abstract":"This paper introduces the Compliant Explicit Reference Governor (C-ERG), an extension of the Explicit Reference Governor that allows the robot to operate safely while in contact with the environment.","authors":["Yaashia Gautam","Nataliya Nechyporenko","Chi-Hui Lin","Alessandro Roncone","Marco M. Nicotra"],"url":"https://arxiv.org/abs/2504.09188"}
{"created":"2025-04-15","title":"Feature-Aware Malicious Output Detection and Mitigation","abstract":"The rapid advancement of large language models (LLMs) has brought significant benefits to various domains while introducing substantial risks. Despite being fine-tuned through reinforcement learning, LLMs lack the capability to discern malicious content, limiting their defense against jailbreak. To address these safety concerns, we propose a feature-aware method for harmful response rejection (FMM), which detects the presence of malicious features within the model's feature space and adaptively adjusts the model's rejection mechanism. By employing a simple discriminator, we detect potential malicious traits during the decoding phase. Upon detecting features indicative of toxic tokens, FMM regenerates the current token. By employing activation patching, an additional rejection vector is incorporated during the subsequent token generation, steering the model towards a refusal response. Experimental results demonstrate the effectiveness of our approach across multiple language models and diverse attack techniques, while crucially maintaining the models' standard generation capabilities.","authors":["Weilong Dong","Peiguang Li","Yu Tian","Xinyi Zeng","Fengdi Li","Sirui Wang"],"url":"https://arxiv.org/abs/2504.09191"}
{"created":"2025-04-15","title":"Towards More Efficient, Robust, Instance-adaptive, and Generalizable Online Learning","abstract":"The primary goal of my Ph.D. study is to develop provably efficient and practical algorithms for data-driven online sequential decision-making under uncertainty. My work focuses on reinforcement learning (RL), multi-armed bandits, and their applications, including recommendation systems, computer networks, video analytics, and large language models (LLMs). Online learning methods, such as bandits and RL, have demonstrated remarkable success - ranging from outperforming human players in complex games like Atari and Go to advancing robotics, recommendation systems, and fine-tuning LLMs. Despite these successes, many established algorithms rely on idealized models that can fail under model misspecifications or adversarial perturbations, particularly in settings where accurate prior knowledge of the underlying model class is unavailable or where malicious users operate within dynamic systems. These challenges are pervasive in real-world applications, where robust and adaptive solutions are critical. Furthermore, while worst-case guarantees provide theoretical reliability, they often fail to capture instance-dependent performance, which can lead to more efficient and practical solutions. Another key challenge lies in generalizing to new, unseen environments, a crucial requirement for deploying these methods in dynamic and unpredictable settings. To address these limitations, my research aims to develop more efficient, robust, instance-adaptive, and generalizable online learning algorithms for both reinforcement learning and bandits. Towards this end, I focus on developing more efficient, robust, instance-adaptive, and generalizable for both general reinforcement learning (RL) and bandits.","authors":["Zhiyong Wang"],"url":"https://arxiv.org/abs/2504.09192"}
{"created":"2025-04-15","title":"ReferGPT: Towards Zero-Shot Referring Multi-Object Tracking","abstract":"Tracking multiple objects based on textual queries is a challenging task that requires linking language understanding with object association across frames. Previous works typically train the whole process end-to-end or integrate an additional referring text module into a multi-object tracker, but they both require supervised training and potentially struggle with generalization to open-set queries. In this work, we introduce ReferGPT, a novel zero-shot referring multi-object tracking framework. We provide a multi-modal large language model (MLLM) with spatial knowledge enabling it to generate 3D-aware captions. This enhances its descriptive capabilities and supports a more flexible referring vocabulary without training. We also propose a robust query-matching strategy, leveraging CLIP-based semantic encoding and fuzzy matching to associate MLLM generated captions with user queries. Extensive experiments on Refer-KITTI, Refer-KITTIv2 and Refer-KITTI+ demonstrate that ReferGPT achieves competitive performance against trained methods, showcasing its robustness and zero-shot capabilities in autonomous driving. The codes are available on https://github.com/Tzoulio/ReferGPT","authors":["Tzoulio Chamiti","Leandro Di Bella","Adrian Munteanu","Nikos Deligiannis"],"url":"https://arxiv.org/abs/2504.09195"}
{"created":"2025-04-15","title":"RT-DATR:Real-time Unsupervised Domain Adaptive Detection Transformer with Adversarial Feature Learning","abstract":"Despite domain-adaptive object detectors based on CNN and transformers have made significant progress in cross-domain detection tasks, it is regrettable that domain adaptation for real-time transformer-based detectors has not yet been explored. Directly applying existing domain adaptation algorithms has proven to be suboptimal. In this paper, we propose RT-DATR, a simple and efficient real-time domain adaptive detection transformer. Building on RT-DETR as our base detector, we first introduce a local object-level feature alignment module to significantly enhance the feature representation of domain invariance during object transfer. Additionally, we introduce a scene semantic feature alignment module designed to boost cross-domain detection performance by aligning scene semantic features. Finally, we introduced a domain query and decoupled it from the object query to further align the instance feature distribution within the decoder layer, reduce the domain gap, and maintain discriminative ability. Experimental results on various benchmarks demonstrate that our method outperforms current state-of-the-art approaches. Our code will be released soon.","authors":["Feng Lv","Chunlong Xia","Shuo Wang","Huo Cao"],"url":"https://arxiv.org/abs/2504.09196"}
{"created":"2025-04-15","title":"Graph Learning-Driven Multi-Vessel Association: Fusing Multimodal Data for Maritime Intelligence","abstract":"Ensuring maritime safety and optimizing traffic management in increasingly crowded and complex waterways require effective waterway monitoring. However, current methods struggle with challenges arising from multimodal data, such as dimensional disparities, mismatched target counts, vessel scale variations, occlusions, and asynchronous data streams from systems like the automatic identification system (AIS) and closed-circuit television (CCTV). Traditional multi-target association methods often struggle with these complexities, particularly in densely trafficked waterways. To overcome these issues, we propose a graph learning-driven multi-vessel association (GMvA) method tailored for maritime multimodal data fusion. By integrating AIS and CCTV data, GMvA leverages time series learning and graph neural networks to capture the spatiotemporal features of vessel trajectories effectively. To enhance feature representation, the proposed method incorporates temporal graph attention and spatiotemporal attention, effectively capturing both local and global vessel interactions. Furthermore, a multi-layer perceptron-based uncertainty fusion module computes robust similarity scores, and the Hungarian algorithm is adopted to ensure globally consistent and accurate target matching. Extensive experiments on real-world maritime datasets confirm that GMvA delivers superior accuracy and robustness in multi-target association, outperforming existing methods even in challenging scenarios with high vessel density and incomplete or unevenly distributed AIS and CCTV data.","authors":["Yuxu Lu","Kaisen Yang","Dong Yang","Haifeng Ding","Jinxian Weng","Ryan Wen Liu"],"url":"https://arxiv.org/abs/2504.09197"}
{"created":"2025-04-15","title":"Illusion Worlds: Deceptive UI Attacks in Social VR","abstract":"Social Virtual Reality (VR) platforms have surged in popularity, yet their security risks remain underexplored. This paper presents four novel UI attacks that covertly manipulate users into performing harmful actions through deceptive virtual content. Implemented on VRChat and validated in an IRB-approved study with 30 participants, these attacks demonstrate how deceptive elements can mislead users into malicious actions without their awareness. To address these vulnerabilities, we propose MetaScanner, a proactive countermeasure that rapidly analyzes objects and scripts in virtual worlds, detecting suspicious elements within seconds.","authors":["Junhee Lee","Hwanjo Heo","Seungwon Woo","Minseok Kim","Jongseop Kim","Jinwoo Kim"],"url":"https://arxiv.org/abs/2504.09199"}
{"created":"2025-04-15","title":"A Datagram Extension to DNS over QUIC: Proven Resource Conservation in the Internet of Things","abstract":"In this paper, we investigate the Domain Name System (DNS) over QUIC (DoQ) and propose a non-disruptive extension, which can greatly reduce DoQ's resource consumption. This extension can benefit all DNS clients - especially Internet of Things (IoT) devices. This is important because even resource-constrained IoT devices can generate dozens of DNS requests every hour. DNS is a crucial service that correlates IP addresses and domain names. It is traditionally sent as plain-text, favoring low-latency results over security and privacy. The repercussion of this can be eavesdropping and information leakage about IoT devices. To address these concerns, the newest and most promising solution is DoQ. QUIC offers features similar to TCP and TLS while also supporting early data delivery and stream multiplexing. DoQ's specification requires that DNS exchanges occur over independent streams in a long-lived QUIC connection. Our hypothesis is that due to DNS's typically high transaction volume, managing QUIC streams may be overly resource intensive for IoT devices. Therefore, we have designed and implemented a data delivery mode for DoQ using QUIC datagrams, which we believe to be more preferable than stream-based delivery. To test our theory, we analyzed the memory, CPU, signaling, power, and time of each DoQ delivery mode in a setup generating real queries and network traffic. Our novel datagram-based delivery mode proved to be decisively more resource-friendly with little compromise in terms of functionality or performance. Furthermore, our paper is the first to investigate multiple queries over DoQ, to our knowledge.","authors":["Darius Saif","Ashraf Matrawy"],"url":"https://arxiv.org/abs/2504.09200"}
{"created":"2025-04-15","title":"From Visual Explanations to Counterfactual Explanations with Latent Diffusion","abstract":"Visual counterfactual explanations are ideal hypothetical images that change the decision-making of the classifier with high confidence toward the desired class while remaining visually plausible and close to the initial image. In this paper, we propose a new approach to tackle two key challenges in recent prominent works: i) determining which specific counterfactual features are crucial for distinguishing the \"concept\" of the target class from the original class, and ii) supplying valuable explanations for the non-robust classifier without relying on the support of an adversarially robust model. Our method identifies the essential region for modification through algorithms that provide visual explanations, and then our framework generates realistic counterfactual explanations by combining adversarial attacks based on pruning the adversarial gradient of the target classifier and the latent diffusion model. The proposed method outperforms previous state-of-the-art results on various evaluation criteria on ImageNet and CelebA-HQ datasets. In general, our method can be applied to arbitrary classifiers, highlight the strong association between visual and counterfactual explanations, make semantically meaningful changes from the target classifier, and provide observers with subtle counterfactual images.","authors":["Tung Luu","Nam Le","Duc Le","Bac Le"],"url":"https://arxiv.org/abs/2504.09202"}
{"created":"2025-04-15","title":"AerOSeg: Harnessing SAM for Open-Vocabulary Segmentation in Remote Sensing Images","abstract":"Image segmentation beyond predefined categories is a key challenge in remote sensing, where novel and unseen classes often emerge during inference. Open-vocabulary image Segmentation addresses these generalization issues in traditional supervised segmentation models while reducing reliance on extensive per-pixel annotations, which are both expensive and labor-intensive to obtain. Most Open-Vocabulary Segmentation (OVS) methods are designed for natural images but struggle with remote sensing data due to scale variations, orientation changes, and complex scene compositions. This necessitates the development of OVS approaches specifically tailored for remote sensing. In this context, we propose AerOSeg, a novel OVS approach for remote sensing data. First, we compute robust image-text correlation features using multiple rotated versions of the input image and domain-specific prompts. These features are then refined through spatial and class refinement blocks. Inspired by the success of the Segment Anything Model (SAM) in diverse domains, we leverage SAM features to guide the spatial refinement of correlation features. Additionally, we introduce a semantic back-projection module and loss to ensure the seamless propagation of SAM's semantic information throughout the segmentation pipeline. Finally, we enhance the refined correlation features using a multi-scale attention-aware decoder to produce the final segmentation map. We validate our SAM-guided Open-Vocabulary Remote Sensing Segmentation model on three benchmark remote sensing datasets: iSAID, DLRSD, and OpenEarthMap. Our model outperforms state-of-the-art open-vocabulary segmentation methods, achieving an average improvement of 2.54 h-mIoU.","authors":["Saikat Dutta","Akhil Vasim","Siddhant Gole","Hamid Rezatofighi","Biplab Banerjee"],"url":"https://arxiv.org/abs/2504.09203"}
{"created":"2025-04-15","title":"Query-based Knowledge Transfer for Heterogeneous Learning Environments","abstract":"Decentralized collaborative learning under data heterogeneity and privacy constraints has rapidly advanced. However, existing solutions like federated learning, ensembles, and transfer learning, often fail to adequately serve the unique needs of clients, especially when local data representation is limited. To address this issue, we propose a novel framework called Query-based Knowledge Transfer (QKT) that enables tailored knowledge acquisition to fulfill specific client needs without direct data exchange. QKT employs a data-free masking strategy to facilitate communication-efficient query-focused knowledge transfer while refining task-specific parameters to mitigate knowledge interference and forgetting. Our experiments, conducted on both standard and clinical benchmarks, show that QKT significantly outperforms existing collaborative learning methods by an average of 20.91\\% points in single-class query settings and an average of 14.32\\% points in multi-class query scenarios. Further analysis and ablation studies reveal that QKT effectively balances the learning of new and existing knowledge, showing strong potential for its application in decentralized learning.","authors":["Norah Alballa","Wenxuan Zhang","Ziquan Liu","Ahmed M. Abdelmoniem","Mohamed Elhoseiny","Marco Canini"],"url":"https://arxiv.org/abs/2504.09205"}
{"created":"2025-04-15","title":"Rethinking Remaining Useful Life Prediction with Scarce Time Series Data: Regression under Indirect Supervision","abstract":"Supervised time series prediction relies on directly measured target variables, but real-world use cases such as predicting remaining useful life (RUL) involve indirect supervision, where the target variable is labeled as a function of another dependent variable. Trending temporal regression techniques rely on sequential time series inputs to capture temporal patterns, requiring interpolation when dealing with sparsely and irregularly sampled covariates along the timeline. However, interpolation can introduce significant biases, particularly with highly scarce data. In this paper, we address the RUL prediction problem with data scarcity as time series regression under indirect supervision. We introduce a unified framework called parameterized static regression, which takes single data points as inputs for regression of target values, inherently handling data scarcity without requiring interpolation. The time dependency under indirect supervision is captured via a parametrical rectification (PR) process, approximating a parametric function during inference with historical posteriori estimates, following the same underlying distribution used for labeling during training. Additionally, we propose a novel batch training technique for tasks in indirect supervision to prevent overfitting and enhance efficiency. We evaluate our model on public benchmarks for RUL prediction with simulated data scarcity. Our method demonstrates competitive performance in prediction accuracy when dealing with highly scarce time series data.","authors":["Jiaxiang Cheng","Yipeng Pang","Guoqiang Hu"],"url":"https://arxiv.org/abs/2504.09206"}
{"created":"2025-04-15","title":"Pneuma: Leveraging LLMs for Tabular Data Representation and Retrieval in an End-to-End System","abstract":"Finding relevant tables among databases, lakes, and repositories is the first step in extracting value from data. Such a task remains difficult because assessing whether a table is relevant to a problem does not always depend only on its content but also on the context, which is usually tribal knowledge known to the individual or team. While tools like data catalogs and academic data discovery systems target this problem, they rely on keyword search or more complex interfaces, limiting non-technical users' ability to find relevant data. The advent of large language models (LLMs) offers a unique opportunity for users to ask questions directly in natural language, making dataset discovery more intuitive, accessible, and efficient.","authors":["Muhammad Imam Luthfi Balaka","David Alexander","Qiming Wang","Yue Gong","Adila Krisnadhi","Raul Castro Fernandez"],"url":"https://arxiv.org/abs/2504.09207"}
{"created":"2025-04-15","title":"EchoMask: Speech-Queried Attention-based Mask Modeling for Holistic Co-Speech Motion Generation","abstract":"Masked modeling framework has shown promise in co-speech motion generation. However, it struggles to identify semantically significant frames for effective motion masking. In this work, we propose a speech-queried attention-based mask modeling framework for co-speech motion generation. Our key insight is to leverage motion-aligned speech features to guide the masked motion modeling process, selectively masking rhythm-related and semantically expressive motion frames. Specifically, we first propose a motion-audio alignment module (MAM) to construct a latent motion-audio joint space. In this space, both low-level and high-level speech features are projected, enabling motion-aligned speech representation using learnable speech queries. Then, a speech-queried attention mechanism (SQA) is introduced to compute frame-level attention scores through interactions between motion keys and speech queries, guiding selective masking toward motion frames with high attention scores. Finally, the motion-aligned speech features are also injected into the generation network to facilitate co-speech motion generation. Qualitative and quantitative evaluations confirm that our method outperforms existing state-of-the-art approaches, successfully producing high-quality co-speech motion.","authors":["Xiangyue Zhang","Jianfang Li","Jiaxu Zhang","Jianqiang Ren","Liefeng Bo","Zhigang Tu"],"url":"https://arxiv.org/abs/2504.09209"}
{"created":"2025-04-15","title":"FairACE: Achieving Degree Fairness in Graph Neural Networks via Contrastive and Adversarial Group-Balanced Training","abstract":"Fairness has been a significant challenge in graph neural networks (GNNs) since degree biases often result in un-equal prediction performance among nodes with varying degrees. Existing GNN models focus on prediction accuracy, frequently overlooking fairness across different degree groups. To addressthis issue, we propose a novel GNN framework, namely Fairness- Aware Asymmetric Contrastive Ensemble (FairACE), which inte-grates asymmetric contrastive learning with adversarial training to improve degree fairness. FairACE captures one-hop local neighborhood information and two-hop monophily similarity to create fairer node representations and employs a degree fairness regulator to balance performance between high-degree and low-degree nodes. During model training, a novel group-balanced fairness loss is proposed to minimize classification disparities across degree groups. In addition, we also propose a novel fairness metric, the Accuracy Distribution Gap (ADG), which can quantitatively assess and ensure equitable performance across different degree-based node groups. Experimental results on both synthetic and real-world datasets demonstrate that FairACE significantly improves degree fairness metrics while maintaining competitive accuracy in comparison to the state-of-the-art GNN models.","authors":["Jiaxin Liu","Xiaoqian Jiang","Cangqi Zhou","Jing Zhang"],"url":"https://arxiv.org/abs/2504.09210"}
{"created":"2025-04-15","title":"Accurate Diagnosis of Respiratory Viruses Using an Explainable Machine Learning with Mid-Infrared Biomolecular Fingerprinting of Nasopharyngeal Secretions","abstract":"Accurate identification of respiratory viruses (RVs) is critical for outbreak control and public health. This study presents a diagnostic system that combines Attenuated Total Reflectance Fourier Transform Infrared Spectroscopy (ATR-FTIR) from nasopharyngeal secretions with an explainable Rotary Position Embedding-Sparse Attention Transformer (RoPE-SAT) model to accurately identify multiple RVs within 10 minutes. Spectral data (4000-00 cm-1) were collected, and the bio-fingerprint region (1800-900 cm-1) was employed for analysis. Standard normal variate (SNV) normalization and second-order derivation were applied to reduce scattering and baseline drift. Gradient-weighted class activation mapping (Grad-CAM) was employed to generate saliency maps, highlighting spectral regions most relevant to classification and enhancing the interpretability of model outputs. Two independent cohorts from Beijing Youan Hospital, processed with different viral transport media (VTMs) and drying methods, were evaluated, with one including influenza B, SARS-CoV-2, and healthy controls, and the other including mycoplasma, SARS-CoV-2, and healthy controls. The model achieved sensitivity and specificity above 94.40% across both cohorts. By correlating model-selected infrared regions with known biomolecular signatures, we verified that the system effectively recognizes virus-specific spectral fingerprints, including lipids, Amide I, Amide II, Amide III, nucleic acids, and carbohydrates, and leverages their weighted contributions for accurate classification.","authors":["Wenwen Zhang","Zhouzhuo Tang","Yingmei Feng","Xia Yu","Qi Jie Wang","Zhiping Lin"],"url":"https://arxiv.org/abs/2504.09211"}
{"created":"2025-04-15","title":"Spiking Neural Network for Intra-cortical Brain Signal Decoding","abstract":"Decoding brain signals accurately and efficiently is crucial for intra-cortical brain-computer interfaces. Traditional decoding approaches based on neural activity vector features suffer from low accuracy, whereas deep learning based approaches have high computational cost. To improve both the decoding accuracy and efficiency, this paper proposes a spiking neural network (SNN) for effective and energy-efficient intra-cortical brain signal decoding. We also propose a feature fusion approach, which integrates the manually extracted neural activity vector features with those extracted by a deep neural network, to further improve the decoding accuracy. Experiments in decoding motor-related intra-cortical brain signals of two rhesus macaques demonstrated that our SNN model achieved higher accuracy than traditional artificial neural networks; more importantly, it was tens or hundreds of times more efficient. The SNN model is very suitable for high precision and low power applications like intra-cortical brain-computer interfaces.","authors":["Song Yang","Haotian Fu","Herui Zhang","Peng Zhang","Wei Li","Dongrui Wu"],"url":"https://arxiv.org/abs/2504.09213"}
{"created":"2025-04-15","title":"Multi-scale Activation, Refinement, and Aggregation: Exploring Diverse Cues for Fine-Grained Bird Recognition","abstract":"Given the critical role of birds in ecosystems, Fine-Grained Bird Recognition (FGBR) has gained increasing attention, particularly in distinguishing birds within similar subcategories. Although Vision Transformer (ViT)-based methods often outperform Convolutional Neural Network (CNN)-based methods in FGBR, recent studies reveal that the limited receptive field of plain ViT model hinders representational richness and makes them vulnerable to scale variance. Thus, enhancing the multi-scale capabilities of existing ViT-based models to overcome this bottleneck in FGBR is a worthwhile pursuit. In this paper, we propose a novel framework for FGBR, namely Multi-scale Diverse Cues Modeling (MDCM), which explores diverse cues at different scales across various stages of a multi-scale Vision Transformer (MS-ViT) in an \"Activation-Selection-Aggregation\" paradigm. Specifically, we first propose a multi-scale cue activation module to ensure the discriminative cues learned at different stage are mutually different. Subsequently, a multi-scale token selection mechanism is proposed to remove redundant noise and highlight discriminative, scale-specific cues at each stage. Finally, the selected tokens from each stage are independently utilized for bird recognition, and the recognition results from multiple stages are adaptively fused through a multi-scale dynamic aggregation mechanism for final model decisions. Both qualitative and quantitative results demonstrate the effectiveness of our proposed MDCM, which outperforms CNN- and ViT-based models on several widely-used FGBR benchmarks.","authors":["Zhicheng Zhang","Hao Tang","Jinhui Tang"],"url":"https://arxiv.org/abs/2504.09215"}
{"created":"2025-04-15","title":"Generation of Musical Timbres using a Text-Guided Diffusion Model","abstract":"In recent years, text-to-audio systems have achieved remarkable success, enabling the generation of complete audio segments directly from text descriptions. While these systems also facilitate music creation, the element of human creativity and deliberate expression is often limited. In contrast, the present work allows composers, arrangers, and performers to create the basic building blocks for music creation: audio of individual musical notes for use in electronic instruments and DAWs. Through text prompts, the user can specify the timbre characteristics of the audio. We introduce a system that combines a latent diffusion model and multi-modal contrastive learning to generate musical timbres conditioned on text descriptions. By jointly generating the magnitude and phase of the spectrogram, our method eliminates the need for subsequently running a phase retrieval algorithm, as related methods do.","authors":["Weixuan Yuan","Qadeer Khan","Vladimir Golkov"],"url":"https://arxiv.org/abs/2504.09219"}
{"created":"2025-04-15","title":"CMCRD: Cross-Modal Contrastive Representation Distillation for Emotion Recognition","abstract":"Emotion recognition is an important component of affective computing, and also human-machine interaction. Unimodal emotion recognition is convenient, but the accuracy may not be high enough; on the contrary, multi-modal emotion recognition may be more accurate, but it also increases the complexity and cost of the data collection system. This paper considers cross-modal emotion recognition, i.e., using both electroencephalography (EEG) and eye movement in training, but only EEG or eye movement in test. We propose cross-modal contrastive representation distillation (CMCRD), which uses a pre-trained eye movement classification model to assist the training of an EEG classification model, improving feature extraction from EEG signals, or vice versa. During test, only EEG signals (or eye movement signals) are acquired, eliminating the need for multi-modal data. CMCRD not only improves the emotion recognition accuracy, but also makes the system more simplified and practical. Experiments using three different neural network architectures on three multi-modal emotion recognition datasets demonstrated the effectiveness of CMCRD. Compared with the EEG-only model, it improved the average classification accuracy by about 6.2%.","authors":["Siyuan Kan","Huanyu Wu","Zhenyao Cui","Fan Huang","Xiaolong Xu","Dongrui Wu"],"url":"https://arxiv.org/abs/2504.09221"}
{"created":"2025-04-15","title":"DL-QAT: Weight-Decomposed Low-Rank Quantization-Aware Training for Large Language Models","abstract":"Improving the efficiency of inference in Large Language Models (LLMs) is a critical area of research. Post-training Quantization (PTQ) is a popular technique, but it often faces challenges at low-bit levels, particularly in downstream tasks. Quantization-aware Training (QAT) can alleviate this problem, but it requires significantly more computational resources. To tackle this, we introduced Weight-Decomposed Low-Rank Quantization-Aware Training (DL-QAT), which merges the advantages of QAT while training only less than 1% of the total parameters. Specifically, we introduce a group-specific quantization magnitude to adjust the overall scale of each quantization group. Within each quantization group, we use LoRA matrices to update the weight size and direction in the quantization space. We validated the effectiveness of our method on the LLaMA and LLaMA2 model families. The results show significant improvements over our baseline method across different quantization granularities. For instance, for LLaMA-7B, our approach outperforms the previous state-of-the-art method by 4.2% in MMLU on 3-bit LLaMA-7B model. Additionally, our quantization results on pre-trained models also surpass previous QAT methods, demonstrating the superior performance and efficiency of our approach.","authors":["Wenjin Ke","Zhe Li","Dong Li","Lu Tian","Emad Barsoum"],"url":"https://arxiv.org/abs/2504.09223"}
{"created":"2025-04-15","title":"AMNet: An Acoustic Model Network for Enhanced Mandarin Speech Synthesis","abstract":"This paper presents AMNet, an Acoustic Model Network designed to improve the performance of Mandarin speech synthesis by incorporating phrase structure annotation and local convolution modules. AMNet builds upon the FastSpeech 2 architecture while addressing the challenge of local context modeling, which is crucial for capturing intricate speech features such as pauses, stress, and intonation. By embedding a phrase structure parser into the model and introducing a local convolution module, AMNet enhances the model's sensitivity to local information. Additionally, AMNet decouples tonal characteristics from phonemes, providing explicit guidance for tone modeling, which improves tone accuracy and pronunciation. Experimental results demonstrate that AMNet outperforms baseline models in subjective and objective evaluations. The proposed model achieves superior Mean Opinion Scores (MOS), lower Mel Cepstral Distortion (MCD), and improved fundamental frequency fitting $F0 (R^2)$, confirming its ability to generate high-quality, natural, and expressive Mandarin speech.","authors":["Yubing Cao","Yinfeng Yu","Yongming Li","Liejun Wang"],"url":"https://arxiv.org/abs/2504.09225"}
{"created":"2025-04-15","title":"SceneScout: Towards AI Agent-driven Access to Street View Imagery for Blind Users","abstract":"People who are blind or have low vision (BLV) may hesitate to travel independently in unfamiliar environments due to uncertainty about the physical landscape. While most tools focus on in-situ navigation, those exploring pre-travel assistance typically provide only landmarks and turn-by-turn instructions, lacking detailed visual context. Street view imagery, which contains rich visual information and has the potential to reveal numerous environmental details, remains inaccessible to BLV people. In this work, we introduce SceneScout, a multimodal large language model (MLLM)-driven AI agent that enables accessible interactions with street view imagery. SceneScout supports two modes: (1) Route Preview, enabling users to familiarize themselves with visual details along a route, and (2) Virtual Exploration, enabling free movement within street view imagery. Our user study (N=10) demonstrates that SceneScout helps BLV users uncover visual information otherwise unavailable through existing means. A technical evaluation shows that most descriptions are accurate (72%) and describe stable visual elements (95%) even in older imagery, though occasional subtle and plausible errors make them difficult to verify without sight. We discuss future opportunities and challenges of using street view imagery to enhance navigation experiences.","authors":["Gaurav Jain","Leah Findlater","Cole Gleason"],"url":"https://arxiv.org/abs/2504.09227"}
{"created":"2025-04-15","title":"Learning Occlusion-Robust Vision Transformers for Real-Time UAV Tracking","abstract":"Single-stream architectures using Vision Transformer (ViT) backbones show great potential for real-time UAV tracking recently. However, frequent occlusions from obstacles like buildings and trees expose a major drawback: these models often lack strategies to handle occlusions effectively. New methods are needed to enhance the occlusion resilience of single-stream ViT models in aerial tracking. In this work, we propose to learn Occlusion-Robust Representations (ORR) based on ViTs for UAV tracking by enforcing an invariance of the feature representation of a target with respect to random masking operations modeled by a spatial Cox process. Hopefully, this random masking approximately simulates target occlusions, thereby enabling us to learn ViTs that are robust to target occlusion for UAV tracking. This framework is termed ORTrack. Additionally, to facilitate real-time applications, we propose an Adaptive Feature-Based Knowledge Distillation (AFKD) method to create a more compact tracker, which adaptively mimics the behavior of the teacher model ORTrack according to the task's difficulty. This student model, dubbed ORTrack-D, retains much of ORTrack's performance while offering higher efficiency. Extensive experiments on multiple benchmarks validate the effectiveness of our method, demonstrating its state-of-the-art performance. Codes is available at https://github.com/wuyou3474/ORTrack.","authors":["You Wu","Xucheng Wang","Xiangyang Yang","Mengyuan Liu","Dan Zeng","Hengzhou Ye","Shuiwang Li"],"url":"https://arxiv.org/abs/2504.09228"}
{"created":"2025-04-15","title":"Scaling up Reversible Logic with HKI Superconducting Inductors","abstract":"Researchers developed about a dozen semiconductor reversible (or adiabatic) logic chips since the early 1990s, validating circuit designs and proving the concept--but scale up required a further advance. This document shows that cryogenic inductors made of a new High Kinetic Inductance (HKI) material provide the advance. This material can be deposited as an integrated circuit layer, where it has enough energy recycling capacity to power a reversible circuit of the same size. This allows a designer to replicate and scale a complete reversible logic subsystem in accordance with Moore's law.","authors":["Erik P. DeBenedictis"],"url":"https://arxiv.org/abs/2504.09229"}
{"created":"2025-04-15","title":"Concurrent-Allocation Task Execution for Multi-Robot Path-Crossing-Minimal Navigation in Obstacle Environments","abstract":"Reducing undesirable path crossings among trajectories of different robots is vital in multi-robot navigation missions, which not only reduces detours and conflict scenarios, but also enhances navigation efficiency and boosts productivity. Despite recent progress in multi-robot path-crossing-minimal (MPCM) navigation, the majority of approaches depend on the minimal squared-distance reassignment of suitable desired points to robots directly. However, if obstacles occupy the passing space, calculating the actual robot-point distances becomes complex or intractable, which may render the MPCM navigation in obstacle environments inefficient or even infeasible.","authors":["Bin-Bin Hu","Weijia Yao","Yanxin Zhou","Henglai Wei","Chen Lv"],"url":"https://arxiv.org/abs/2504.09230"}
{"created":"2025-04-15","title":"Unleashing Optimizations in Dynamic Circuits through Branch Expansion","abstract":"Dynamic quantum circuits enable adaptive operations through intermediate measurements and classical feedback. Current transpilation toolchains, such as Qiskit and T$\\ket{\\text{ket}}$, however, fail to fully exploit branch-specific simplifications. In this work, we propose recursive branch expansion as a novel technique which systematically expands and refines conditional branches. Our method complements existing transpilers by creating additional opportunities for branch-specific simplifications without altering the overall circuit functionality. Using randomly generated circuits with varying patterns and scales, we demonstrate that our method consistently reduces the depth and gate count of execution paths of dynamic circuits. We also showcase the potential of our method to enable optimizations on error-corrected circuits.","authors":["Yanbin Chen"],"url":"https://arxiv.org/abs/2504.09234"}
{"created":"2025-04-15","title":"Development of a PPO-Reinforcement Learned Walking Tripedal Soft-Legged Robot using SOFA","abstract":"Rigid robots were extensively researched, whereas soft robotics remains an underexplored field. Utilizing soft-legged robots in performing tasks as a replacement for human beings is an important stride to take, especially under harsh and hazardous conditions over rough terrain environments. For the demand to teach any robot how to behave in different scenarios, a real-time physical and visual simulation is essential. When it comes to soft robots specifically, a simulation framework is still an arduous problem that needs to be disclosed. Using the simulation open framework architecture (SOFA) is an advantageous step. However, neither SOFA's manual nor prior public SOFA projects show its maximum capabilities the users can reach. So, we resolved this by establishing customized settings and handling the framework components appropriately. Settling on perfect, fine-tuned SOFA parameters has stimulated our motivation towards implementing the state-of-the-art (SOTA) reinforcement learning (RL) method of proximal policy optimization (PPO). The final representation is a well-defined, ready-to-deploy walking, tripedal, soft-legged robot based on PPO-RL in a SOFA environment. Robot navigation performance is a key metric to be considered for measuring the success resolution. Although in the simulated soft robots case, an 82\\% success rate in reaching a single goal is a groundbreaking output, we pushed the boundaries to further steps by evaluating the progress under assigning a sequence of goals. While trailing the platform steps, outperforming discovery has been observed with an accumulative squared error deviation of 19 mm. The full code is publicly available at \\href{https://github.com/tarekshohdy/PPO_SOFA_Soft_Legged_Robot.git}{github.com/tarekshohdy/PPO$\\textunderscore$SOFA$\\textunderscore$Soft$\\textunderscore$Legged$\\textunderscore$ Robot.git}","authors":["Yomna Mokhtar","Tarek Shohdy","Abdallah A. Hassan","Mostafa Eshra","Omar Elmenawy","Osama Khalil","Haitham El-Hussieny"],"url":"https://arxiv.org/abs/2504.09242"}
{"created":"2025-04-15","title":"REALM: Real-Time Estimates of Assistance for Learned Models in Human-Robot Interaction","abstract":"There are a variety of mechanisms (i.e., input types) for real-time human interaction that can facilitate effective human-robot teaming. For example, previous works have shown how teleoperation, corrective, and discrete (i.e., preference over a small number of choices) input can enable robots to complete complex tasks. However, few previous works have looked at combining different methods, and in particular, opportunities for a robot to estimate and elicit the most effective form of assistance given its understanding of a task. In this paper, we propose a method for estimating the value of different human assistance mechanisms based on the action uncertainty of a robot policy. Our key idea is to construct mathematical expressions for the expected post-interaction differential entropy (i.e., uncertainty) of a stochastic robot policy to compare the expected value of different interactions. As each type of human input imposes a different requirement for human involvement, we demonstrate how differential entropy estimates can be combined with a likelihood penalization approach to effectively balance feedback informational needs with the level of required input. We demonstrate evidence of how our approach interfaces with emergent learning models (e.g., a diffusion model) to produce accurate assistance value estimates through both simulation and a robot user study. Our user study results indicate that the proposed approach can enable task completion with minimal human feedback for uncertain robot behaviors.","authors":["Michael Hagenow","Julie A. Shah"],"url":"https://arxiv.org/abs/2504.09243"}
{"created":"2025-04-15","title":"Ensemble Score Filter for Data Assimilation of Two-Phase Flow Models in Porous Media","abstract":"Numerical modeling and simulation of two-phase flow in porous media is challenging due to the uncertainties in key parameters, such as permeability. To address these challenges, we propose a computational framework by utilizing the novel Ensemble Score Filter (EnSF) to enhance the accuracy of state estimation for two-phase flow systems in porous media. The forward simulation of the two-phase flow model is implemented using a mixed finite element method, which ensures accurate approximation of the pressure, the velocity, and the saturation. The EnSF leverages score-based diffusion models to approximate filtering distributions efficiently, avoiding the computational expense of neural network-based methods. By incorporating a closed-form score approximation and an analytical update mechanism, the EnSF overcomes degeneracy issues and handles high-dimensional nonlinear filtering with minimal computational overhead. Numerical experiments demonstrate the capabilities of EnSF in scenarios with uncertain permeability and incomplete observational data.","authors":["Ruoyu Hu","Sanjeeb Poudel","Feng Bao","Sanghyun Lee"],"url":"https://arxiv.org/abs/2504.09245"}
{"created":"2025-04-15","title":"Type-Constrained Code Generation with Language Models","abstract":"Large language models (LLMs) have achieved notable success in code generation. However, they still frequently produce uncompilable output because their next-token inference procedure does not model formal aspects of code. Although constrained decoding is a promising approach to alleviate this issue, it has only been applied to handle either domain-specific languages or syntactic language features. This leaves typing errors, which are beyond the domain of syntax and generally hard to adequately constrain. To address this challenge, we introduce a type-constrained decoding approach that leverages type systems to guide code generation. We develop novel prefix automata for this purpose and introduce a sound approach to enforce well-typedness based on type inference and a search over inhabitable types. We formalize our approach on a simply-typed language and extend it to TypeScript to demonstrate practicality. Our evaluation on HumanEval shows that our approach reduces compilation errors by more than half and increases functional correctness in code synthesis, translation, and repair tasks across LLMs of various sizes and model families, including SOTA open-weight models with more than 30B parameters.","authors":["Niels M\\\"undler","Jingxuan He","Hao Wang","Koushik Sen","Dawn Song","Martin Vechev"],"url":"https://arxiv.org/abs/2504.09246"}
{"created":"2025-04-15","title":"Large Language Models as Particle Swarm Optimizers","abstract":"Optimization problems often require domain-specific expertise to design problem-dependent methodologies. Recently, several approaches have gained attention by integrating large language models (LLMs) into genetic algorithms. Building on this trend, we introduce Language Model Particle Swarm Optimization (LMPSO), a novel method that incorporates an LLM into the swarm intelligence framework of Particle Swarm Optimization (PSO). In LMPSO, the velocity of each particle is represented as a prompt that generates the next candidate solution, leveraging the capabilities of an LLM to produce solutions in accordance with the PSO paradigm. This integration enables an LLM-driven search process that adheres to the foundational principles of PSO. The proposed LMPSO approach is evaluated across multiple problem domains, including the Traveling Salesman Problem (TSP), heuristic improvement for TSP, and symbolic regression. These problems are traditionally challenging for standard PSO due to the structured nature of their solutions. Experimental results demonstrate that LMPSO is particularly effective for solving problems where solutions are represented as structured sequences, such as mathematical expressions or programmatic constructs. By incorporating LLMs into the PSO framework, LMPSO establishes a new direction in swarm intelligence research. This method not only broadens the applicability of PSO to previously intractable problems but also showcases the potential of LLMs in addressing complex optimization challenges.","authors":["Yamato Shinohara","Jinglue Xu","Tianshui Li","Hitoshi Iba"],"url":"https://arxiv.org/abs/2504.09247"}
{"created":"2025-04-15","title":"Asymptotic stabilization under homomorphic encryption: A re-encryption free method","abstract":"In this paper, we propose methods to encrypted a pre-given dynamic controller with homomorphic encryption, without re-encrypting the control inputs. We first present a preliminary result showing that the coefficients in a pre-given dynamic controller can be scaled up into integers by the zooming-in factor in dynamic quantization, without utilizing re-encryption. However, a sufficiently small zooming-in factor may not always exist because it requires that the convergence speed of the pre-given closed-loop system should be sufficiently fast. Then, as the main result, we design a new controller approximating the pre-given dynamic controller, in which the zooming-in factor is decoupled from the convergence rate of the pre-given closed-loop system. Therefore, there always exist a (sufficiently small) zooming-in factor of dynamic quantization scaling up all the controller's coefficients to integers, and a finite modulus preventing overflow in cryptosystems. The process is asymptotically stable and the quantizer is not saturated.","authors":["Shuai Feng","Qian Ma","Junsoo Kim","Shengyuan Xu"],"url":"https://arxiv.org/abs/2504.09248"}
{"created":"2025-04-15","title":"NoTeS-Bank: Benchmarking Neural Transcription and Search for Scientific Notes Understanding","abstract":"Understanding and reasoning over academic handwritten notes remains a challenge in document AI, particularly for mathematical equations, diagrams, and scientific notations. Existing visual question answering (VQA) benchmarks focus on printed or structured handwritten text, limiting generalization to real-world note-taking. To address this, we introduce NoTeS-Bank, an evaluation benchmark for Neural Transcription and Search in note-based question answering. NoTeS-Bank comprises complex notes across multiple domains, requiring models to process unstructured and multimodal content. The benchmark defines two tasks: (1) Evidence-Based VQA, where models retrieve localized answers with bounding-box evidence, and (2) Open-Domain VQA, where models classify the domain before retrieving relevant documents and answers. Unlike classical Document VQA datasets relying on optical character recognition (OCR) and structured data, NoTeS-BANK demands vision-language fusion, retrieval, and multimodal reasoning. We benchmark state-of-the-art Vision-Language Models (VLMs) and retrieval frameworks, exposing structured transcription and reasoning limitations. NoTeS-Bank provides a rigorous evaluation with NDCG@5, MRR, Recall@K, IoU, and ANLS, establishing a new standard for visual document understanding and reasoning.","authors":["Aniket Pal","Sanket Biswas","Alloy Das","Ayush Lodh","Priyanka Banerjee","Soumitri Chattopadhyay","Dimosthenis Karatzas","Josep Llados","C. V. Jawahar"],"url":"https://arxiv.org/abs/2504.09249"}
{"created":"2025-04-15","title":"FVQ: A Large-Scale Dataset and A LMM-based Method for Face Video Quality Assessment","abstract":"Face video quality assessment (FVQA) deserves to be explored in addition to general video quality assessment (VQA), as face videos are the primary content on social media platforms and human visual system (HVS) is particularly sensitive to human faces. However, FVQA is rarely explored due to the lack of large-scale FVQA datasets. To fill this gap, we present the first large-scale in-the-wild FVQA dataset, FVQ-20K, which contains 20,000 in-the-wild face videos together with corresponding mean opinion score (MOS) annotations. Along with the FVQ-20K dataset, we further propose a specialized FVQA method named FVQ-Rater to achieve human-like rating and scoring for face video, which is the first attempt to explore the potential of large multimodal models (LMMs) for the FVQA task. Concretely, we elaborately extract multi-dimensional features including spatial features, temporal features, and face-specific features (i.e., portrait features and face embeddings) to provide comprehensive visual information, and take advantage of the LoRA-based instruction tuning technique to achieve quality-specific fine-tuning, which shows superior performance on both FVQ-20K and CFVQA datasets. Extensive experiments and comprehensive analysis demonstrate the significant potential of the FVQ-20K dataset and FVQ-Rater method in promoting the development of FVQA.","authors":["Sijing Wu","Yunhao Li","Ziwen Xu","Yixuan Gao","Huiyu Duan","Wei Sun","Guangtao Zhai"],"url":"https://arxiv.org/abs/2504.09255"}
{"created":"2025-04-15","title":"MiMIC: Multi-Modal Indian Earnings Calls Dataset to Predict Stock Prices","abstract":"Predicting stock market prices following corporate earnings calls remains a significant challenge for investors and researchers alike, requiring innovative approaches that can process diverse information sources. This study investigates the impact of corporate earnings calls on stock prices by introducing a multi-modal predictive model. We leverage textual data from earnings call transcripts, along with images and tables from accompanying presentations, to forecast stock price movements on the trading day immediately following these calls. To facilitate this research, we developed the MiMIC (Multi-Modal Indian Earnings Calls) dataset, encompassing companies representing the Nifty 50, Nifty MidCap 50, and Nifty Small 50 indices. The dataset includes earnings call transcripts, presentations, fundamentals, technical indicators, and subsequent stock prices. We present a multimodal analytical framework that integrates quantitative variables with predictive signals derived from textual and visual modalities, thereby enabling a holistic approach to feature representation and analysis. This multi-modal approach demonstrates the potential for integrating diverse information sources to enhance financial forecasting accuracy. To promote further research in computational economics, we have made the MiMIC dataset publicly available under the CC-NC-SA-4.0 licence. Our work contributes to the growing body of literature on market reactions to corporate communications and highlights the efficacy of multi-modal machine learning techniques in financial analysis.","authors":["Sohom Ghosh","Arnab Maji","Sudip Kumar Naskar"],"url":"https://arxiv.org/abs/2504.09257"}
{"created":"2025-04-15","title":"PathVLM-R1: A Reinforcement Learning-Driven Reasoning Model for Pathology Visual-Language Tasks","abstract":"The diagnosis of pathological images is often limited by expert availability and regional disparities, highlighting the importance of automated diagnosis using Vision-Language Models (VLMs). Traditional multimodal models typically emphasize outcomes over the reasoning process, compromising the reliability of clinical decisions. To address the weak reasoning abilities and lack of supervised processes in pathological VLMs, we have innovatively proposed PathVLM-R1, a visual language model designed specifically for pathological images. We have based our model on Qwen2.5-VL-7B-Instruct and enhanced its performance for pathological tasks through meticulously designed post-training strategies. Firstly, we conduct supervised fine-tuning guided by pathological data to imbue the model with foundational pathological knowledge, forming a new pathological base model. Subsequently, we introduce Group Relative Policy Optimization (GRPO) and propose a dual reward-driven reinforcement learning optimization, ensuring strict constraint on logical supervision of the reasoning process and accuracy of results via cross-modal process reward and outcome accuracy reward. In the pathological image question-answering tasks, the testing results of PathVLM-R1 demonstrate a 14% improvement in accuracy compared to baseline methods, and it demonstrated superior performance compared to the Qwen2.5-VL-32B version despite having a significantly smaller parameter size. Furthermore, in out-domain data evaluation involving four medical imaging modalities: Computed Tomography (CT), dermoscopy, fundus photography, and Optical Coherence Tomography (OCT) images: PathVLM-R1's transfer performance improved by an average of 17.3% compared to traditional SFT methods. These results clearly indicate that PathVLM-R1 not only enhances accuracy but also possesses broad applicability and expansion potential.","authors":["Jianyu Wu","Hao Yang","Xinhua Zeng","Guibing He","Zhiyu Chen","Zihui Li","Xiaochuan Zhang","Yangyang Ma","Run Fang","Yang Liu"],"url":"https://arxiv.org/abs/2504.09258"}
{"created":"2025-04-15","title":"NetTAG: A Multimodal RTL-and-Layout-Aligned Netlist Foundation Model via Text-Attributed Graph","abstract":"Circuit representation learning has shown promise in advancing Electronic Design Automation (EDA) by capturing structural and functional circuit properties for various tasks. Existing pre-trained solutions rely on graph learning with complex functional supervision, such as truth table simulation. However, they only handle simple and-inverter graphs (AIGs), struggling to fully encode other complex gate functionalities. While large language models (LLMs) excel at functional understanding, they lack the structural awareness for flattened netlists. To advance netlist representation learning, we present NetTAG, a netlist foundation model that fuses gate semantics with graph structure, handling diverse gate types and supporting a variety of functional and physical tasks. Moving beyond existing graph-only methods, NetTAG formulates netlists as text-attributed graphs, with gates annotated by symbolic logic expressions and physical characteristics as text attributes. Its multimodal architecture combines an LLM-based text encoder for gate semantics and a graph transformer for global structure. Pre-trained with gate and graph self-supervised objectives and aligned with RTL and layout stages, NetTAG captures comprehensive circuit intrinsics. Experimental results show that NetTAG consistently outperforms each task-specific method on four largely different functional and physical tasks and surpasses state-of-the-art AIG encoders, demonstrating its versatility.","authors":["Wenji Fang","Wenkai Li","Shang Liu","Yao Lu","Hongce Zhang","Zhiyao Xie"],"url":"https://arxiv.org/abs/2504.09260"}
{"created":"2025-04-15","title":"Head-Aware KV Cache Compression for Efficient Visual Autoregressive Modeling","abstract":"Visual Autoregressive (VAR) models have emerged as a powerful approach for multi-modal content creation, offering high efficiency and quality across diverse multimedia applications. However, they face significant memory bottlenecks due to extensive KV cache accumulation during inference. Existing KV cache compression techniques for large language models are suboptimal for VAR models due to, as we identify in this paper, two distinct categories of attention heads in VAR models: Structural Heads, which preserve spatial coherence through diagonal attention patterns, and Contextual Heads, which maintain semantic consistency through vertical attention patterns. These differences render single-strategy KV compression techniques ineffective for VAR models. To address this, we propose HACK, a training-free Head-Aware Compression method for KV cache. HACK allocates asymmetric cache budgets and employs pattern-specific compression strategies tailored to the essential characteristics of each head category. Experiments on Infinity-2B, Infinity-8B, and VAR-d30 demonstrate its effectiveness in text-to-image and class-conditional generation tasks. HACK can hack down up to 50\\% and 70\\% of cache with minimal performance degradation for VAR-d30 and Infinity-8B, respectively. Even with 70\\% and 90\\% KV cache compression in VAR-d30 and Infinity-8B, HACK still maintains high-quality generation while reducing memory usage by 44.2\\% and 58.9\\%, respectively.","authors":["Ziran Qin","Youru Lv","Mingbao Lin","Zeren Zhang","Danping Zou","Weiyao Lin"],"url":"https://arxiv.org/abs/2504.09261"}
{"created":"2025-04-15","title":"Machine Learning-Based AP Selection in User-Centric Cell-free Multiple-Antenna Networks","abstract":"User-centric cell-free (UCCF) massive multiple-input multiple-output (MIMO) systems are considered a viable solution to realize the advantages offered by cell-free (CF) networks, including reduced interference and consistent quality of service while maintaining manageable complexity. In this paper, we propose novel learning-based access point (AP) selection schemes tailored for UCCF massive MIMO systems. The learning model exploits the dataset generated from two distinct AP selection schemes, based on large-scale fading (LSF) coefficients and the sum-rate coefficients, respectively. The proposed learning-based AP selection schemes could be implemented centralized or distributed, with the aim of performing AP selection efficiently. We evaluate our model's performance against CF and two heuristic clustering schemes for UCCF networks. The results demonstrate that the learning-based approach achieves a comparable sum-rate performance to that of competing techniques for UCCF networks, while significantly reducing computational complexity.","authors":["S. Salehi","S. Mashdour","O. Tamyigit","S. Seyedmasoumian","M. Moradikia","R. C. de Lamare","A. Schmeink"],"url":"https://arxiv.org/abs/2504.09263"}
{"created":"2025-04-15","title":"Mixture of Group Experts for Learning Invariant Representations","abstract":"Sparsely activated Mixture-of-Experts (MoE) models effectively increase the number of parameters while maintaining consistent computational costs per token. However, vanilla MoE models often suffer from limited diversity and specialization among experts, constraining their performance and scalability, especially as the number of experts increases. In this paper, we present a novel perspective on vanilla MoE with top-$k$ routing inspired by sparse representation. This allows us to bridge established theoretical insights from sparse representation into MoE models. Building on this foundation, we propose a group sparse regularization approach for the input of top-$k$ routing, termed Mixture of Group Experts (MoGE). MoGE indirectly regularizes experts by imposing structural constraints on the routing inputs, while preserving the original MoE architecture. Furthermore, we organize the routing input into a 2D topographic map, spatially grouping neighboring elements. This structure enables MoGE to capture representations invariant to minor transformations, thereby significantly enhancing expert diversity and specialization. Comprehensive evaluations across various Transformer models for image classification and language modeling tasks demonstrate that MoGE substantially outperforms its MoE counterpart, with minimal additional memory and computation overhead. Our approach provides a simple yet effective solution to scale the number of experts and reduce redundancy among them. The source code is included in the supplementary material and will be publicly released.","authors":["Lei Kang","Jia Li","Mi Tian","Hua Huang"],"url":"https://arxiv.org/abs/2504.09265"}
{"created":"2025-04-15","title":"A $P$-Adaptive Hermite Method for Nonlinear Dispersive Maxwell's Equations","abstract":"In this work, we introduce a novel Hermite method to handle Maxwell's equations for nonlinear dispersive media. The proposed method achieves high-order accuracy and is free of any nonlinear algebraic solver, requiring solving instead small local linear systems for which the dimension is independent of the order. The implementation of order adaptive algorithms is straightforward in this setting, making the resulting p-adaptive Hermite method appealing for the simulations of soliton-like wave propagation.","authors":["Yann-Meing Law","Zhichao Peng","Daniel Appel\\\"o","Thomas Hagstrom"],"url":"https://arxiv.org/abs/2504.09269"}
{"created":"2025-04-15","title":"Linguistic Comparison of AI- and Human-Written Responses to Online Mental Health Queries","abstract":"The ubiquity and widespread use of digital and online technologies have transformed mental health support, with online mental health communities (OMHCs) providing safe spaces for peer support. More recently, generative AI and large language models (LLMs) have introduced new possibilities for scalable, around-the-clock mental health assistance that could potentially augment and supplement the capabilities of OMHCs. Although genAI shows promise in delivering immediate and personalized responses, their effectiveness in replicating the nuanced, experience-based support of human peers remains an open question. In this study, we harnessed 24,114 posts and 138,758 online community (OC) responses from 55 OMHCs on Reddit. We prompted several state-of-the-art LLMs (GPT-4-Turbo, Llama-3, and Mistral-7B) with these posts, and compared their (AI) responses to human-written (OC) responses based on a variety of linguistic measures across psycholinguistics and lexico-semantics. Our findings revealed that AI responses are more verbose, readable, and analytically structured, but lack linguistic diversity and personal narratives inherent in human-human interactions. Through a qualitative examination, we found validation as well as complementary insights into the nature of AI responses, such as its neutrality of stance and the absence of seeking back-and-forth clarifications. We discuss the ethical and practical implications of integrating generative AI into OMHCs, advocating for frameworks that balance AI's scalability and timeliness with the irreplaceable authenticity, social interactiveness, and expertise of human connections that form the ethos of online support communities.","authors":["Koustuv Saha","Yoshee Jain","Munmun De Choudhury"],"url":"https://arxiv.org/abs/2504.09271"}
{"created":"2025-04-15","title":"SynthTRIPs: A Knowledge-Grounded Framework for Benchmark Query Generation for Personalized Tourism Recommenders","abstract":"Tourism Recommender Systems (TRS) are crucial in personalizing travel experiences by tailoring recommendations to users' preferences, constraints, and contextual factors. However, publicly available travel datasets often lack sufficient breadth and depth, limiting their ability to support advanced personalization strategies -- particularly for sustainable travel and off-peak tourism. In this work, we explore using Large Language Models (LLMs) to generate synthetic travel queries that emulate diverse user personas and incorporate structured filters such as budget constraints and sustainability preferences.","authors":["Ashmi Banerjee","Adithi Satish","Fitri Nur Aisyah","Wolfgang W\\\"orndl","Yashar Deldjoo"],"url":"https://arxiv.org/abs/2504.09277"}
{"created":"2025-04-15","title":"VideoAds for Fast-Paced Video Understanding: Where Opensource Foundation Models Beat GPT-4o & Gemini-1.5 Pro","abstract":"Advertisement videos serve as a rich and valuable source of purpose-driven information, encompassing high-quality visual, textual, and contextual cues designed to engage viewers. They are often more complex than general videos of similar duration due to their structured narratives and rapid scene transitions, posing significant challenges to multi-modal large language models (MLLMs). In this work, we introduce VideoAds, the first dataset tailored for benchmarking the performance of MLLMs on advertisement videos. VideoAds comprises well-curated advertisement videos with complex temporal structures, accompanied by \\textbf{manually} annotated diverse questions across three core tasks: visual finding, video summary, and visual reasoning. We propose a quantitative measure to compare VideoAds against existing benchmarks in terms of video complexity. Through extensive experiments, we find that Qwen2.5-VL-72B, an opensource MLLM, achieves 73.35\\% accuracy on VideoAds, outperforming GPT-4o (66.82\\%) and Gemini-1.5 Pro (69.66\\%); the two proprietary models especially fall behind the opensource model in video summarization and reasoning, but perform the best in visual finding. Notably, human experts easily achieve a remarkable accuracy of 94.27\\%. These results underscore the necessity of advancing MLLMs' temporal modeling capabilities and highlight VideoAds as a potentially pivotal benchmark for future research in understanding video that requires high FPS sampling. The dataset and evaluation code will be publicly available at https://videoadsbenchmark.netlify.app.","authors":["Zheyuan Zhang","Monica Dou","Linkai Peng","Hongyi Pan","Ulas Bagci","Boqing Gong"],"url":"https://arxiv.org/abs/2504.09282"}
{"created":"2025-04-15","title":"Semantic Commit: Helping Users Update Intent Specifications for AI Memory at Scale","abstract":"How do we update AI memory of user intent as intent changes? We consider how an AI interface may assist the integration of new information into a repository of natural language data. Inspired by software engineering concepts like impact analysis, we develop methods and a UI for managing semantic changes with non-local effects, which we call \"semantic conflict resolution.\" The user commits new intent to a project -- makes a \"semantic commit\" -- and the AI helps the user detect and resolve semantic conflicts within a store of existing information representing their intent (an \"intent specification\"). We develop an interface, SemanticCommit, to better understand how users resolve conflicts when updating intent specifications such as Cursor Rules and game design documents. A knowledge graph-based RAG pipeline drives conflict detection, while LLMs assist in suggesting resolutions. We evaluate our technique on an initial benchmark. Then, we report a 12 user within-subjects study of SemanticCommit for two task domains -- game design documents, and AI agent memory in the style of ChatGPT memories -- where users integrated new information into an existing list. Half of our participants adopted a workflow of impact analysis, where they would first flag conflicts without AI revisions then resolve conflicts locally, despite having access to a global revision feature. We argue that AI agent interfaces, such as software IDEs like Cursor and Windsurf, should provide affordances for impact analysis and help users validate AI retrieval independently from generation. Our work speaks to how AI agent designers should think about updating memory as a process that involves human feedback and decision-making.","authors":["Priyan Vaithilingam","Munyeong Kim","Frida-Cecilia Acosta-Parenteau","Daniel Lee","Amine Mhedhbi","Elena L. Glassman","Ian Arawjo"],"url":"https://arxiv.org/abs/2504.09283"}
{"created":"2025-04-15","title":"DynaServe: Unified and Elastic Tandem-Style Execution for Dynamic Disaggregated LLM Serving","abstract":"Modern large language model (LLM) serving must efficiently handle highly dynamic workloads, where prompt and response lengths vary significantly across requests. Existing systems typically adopt either colocated execution, where prefill and decode stages share the same GPU for high throughput, or disaggregated execution, which decouples the two stages and assign their tasks to dedicated GPUs for interference avoidance. However, both paradigms face critical limitations: colocation suffers from resource contention and prolonged tail latency, whereas disaggregation likely leads to resource wasting when prefill or decode GPUs are not fully occupied.","authors":["Chaoyi Ruan","Yinhe Chen","Dongqi Tian","Yandong Shi","Yongji Wu","Jialin Li","Cheng Li"],"url":"https://arxiv.org/abs/2504.09285"}
{"created":"2025-04-15","title":"Enhancing Productivity in Database Management Through AI: A Three-Phase Approach for Database","abstract":"This paper presents a novel AI-powered framework designed to streamline database management and query optimization for PostgreSQL systems. Structured in three phases: Natural Language to SQL Translation, Query Execution and Analysis, and Insight Generation, the approach empowers users with intuitive, intelligent interaction with databases. By leveraging advanced natural language processing and language models, the system enables non-technical users to extract meaningful insights from complex datasets, reducing the dependency on specialized DBAs. The framework also introduces iterative refinement of queries, automatic report generation, and support for temporal data forecasting. Experimental results demonstrate improved productivity, reduced query latency, and enhanced accuracy, validating the system's effectiveness across diverse business use cases. The solution was developed and evaluated at ABV-IIITM Gwalior, under the guidance of Prof. Dr. Arun Kuma","authors":["Kushagra Parashar","Ajay Dev","Aditya Kumar","Darpan Khatri"],"url":"https://arxiv.org/abs/2504.09288"}
{"created":"2025-04-15","title":"Sparse Hybrid Linear-Morphological Networks","abstract":"We investigate hybrid linear-morphological networks. Recent studies highlight the inherent affinity of morphological layers to pruning, but also their difficulty in training. We propose a hybrid network structure, wherein morphological layers are inserted between the linear layers of the network, in place of activation functions. We experiment with the following morphological layers: 1) maxout pooling layers (as a special case of a morphological layer), 2) fully connected dense morphological layers, and 3) a novel, sparsely initialized variant of (2). We conduct experiments on the Magna-Tag-A-Tune (music auto-tagging) and CIFAR-10 (image classification) datasets, replacing the linear classification heads of state-of-the-art convolutional network architectures with our proposed network structure for the various morphological layers. We demonstrate that these networks induce sparsity to their linear layers, making them more prunable under L1 unstructured pruning. We also show that on MTAT our proposed sparsely initialized layer achieves slightly better performance than ReLU, maxout, and densely initialized max-plus layers, and exhibits faster initial convergence.","authors":["Konstantinos Fotopoulos","Christos Garoufis","Petros Maragos"],"url":"https://arxiv.org/abs/2504.09289"}
{"created":"2025-04-15","title":"Towards Explainable Partial-AIGC Image Quality Assessment","abstract":"The rapid advancement of AI-driven visual generation technologies has catalyzed significant breakthroughs in image manipulation, particularly in achieving photorealistic localized editing effects on natural scene images (NSIs). Despite extensive research on image quality assessment (IQA) for AI-generated images (AGIs), most studies focus on fully AI-generated outputs (e.g., text-to-image generation), leaving the quality assessment of partial-AIGC images (PAIs)-images with localized AI-driven edits an almost unprecedented field. Motivated by this gap, we construct the first large-scale PAI dataset towards explainable partial-AIGC image quality assessment (EPAIQA), the EPAIQA-15K, which includes 15K images with localized AI manipulation in different regions and over 300K multi-dimensional human ratings. Based on this, we leverage large multi-modal models (LMMs) and propose a three-stage model training paradigm. This paradigm progressively trains the LMM for editing region grounding, quantitative quality scoring, and quality explanation. Finally, we develop the EPAIQA series models, which possess explainable quality feedback capabilities. Our work represents a pioneering effort in the perceptual IQA field for comprehensive PAI quality assessment.","authors":["Jiaying Qian","Ziheng Jia","Zicheng Zhang","Zeyu Zhang","Guangtao Zhai","Xiongkuo Min"],"url":"https://arxiv.org/abs/2504.09291"}
{"created":"2025-04-15","title":"Adaptive Planning Framework for UAV-Based Surface Inspection in Partially Unknown Indoor Environments","abstract":"Inspecting indoor environments such as tunnels, industrial facilities, and construction sites is essential for infrastructure monitoring and maintenance. While manual inspection in these environments is often time-consuming and potentially hazardous, Unmanned Aerial Vehicles (UAVs) can improve efficiency by autonomously handling inspection tasks. Such inspection tasks usually rely on reference maps for coverage planning. However, in industrial applications, only the floor plans are typically available. The unforeseen obstacles not included in the floor plans will result in outdated reference maps and inefficient or unsafe inspection trajectories. In this work, we propose an adaptive inspection framework that integrates global coverage planning with local reactive adaptation to improve the coverage and efficiency of UAV-based inspection in partially unknown indoor environments. Experimental results in structured indoor scenarios demonstrate the effectiveness of the proposed approach in inspection efficiency and achieving high coverage rates with adaptive obstacle handling, highlighting its potential for enhancing the efficiency of indoor facility inspection.","authors":["Hanyu Jin","Zhefan Xu","Haoyu Shen","Xinming Han","Kanlong Ye","Kenji Shimada"],"url":"https://arxiv.org/abs/2504.09294"}
{"created":"2025-04-15","title":"Look and Talk: Seamless AI Assistant Interaction with Gaze-Triggered Activation","abstract":"Engaging with AI assistants to gather essential information in time is becoming increasingly common. Traditional activation methods, like wake words such as Hey Siri, Ok Google, and Hey Alexa, are constrained by technical challenges such as false activations, recognition errors, and discomfort in public settings. Similarly, activating AI systems via physical buttons imposes strict interactive limitations as it demands particular physical actions, which hinders fluid and spontaneous communication with AI. Our approach employs eye-tracking technology within AR glasses to discern a user's intention to engage with the AI assistant. By sustaining eye contact on a virtual AI avatar for a specific time, users can initiate an interaction silently and without using their hands. Preliminary user feedback suggests that this technique is relatively intuitive, natural, and less obtrusive, highlighting its potential for integrating AI assistants fluidly into everyday interactions.","authors":["Zhang Qing","Rekimoto Jun"],"url":"https://arxiv.org/abs/2504.09296"}
{"created":"2025-04-15","title":"Cycle Training with Semi-Supervised Domain Adaptation: Bridging Accuracy and Efficiency for Real-Time Mobile Scene Detection","abstract":"Nowadays, smartphones are ubiquitous, and almost everyone owns one. At the same time, the rapid development of AI has spurred extensive research on applying deep learning techniques to image classification. However, due to the limited resources available on mobile devices, significant challenges remain in balancing accuracy with computational efficiency. In this paper, we propose a novel training framework called Cycle Training, which adopts a three-stage training process that alternates between exploration and stabilization phases to optimize model performance. Additionally, we incorporate Semi-Supervised Domain Adaptation (SSDA) to leverage the power of large models and unlabeled data, thereby effectively expanding the training dataset. Comprehensive experiments on the CamSSD dataset for mobile scene detection demonstrate that our framework not only significantly improves classification accuracy but also ensures real-time inference efficiency. Specifically, our method achieves a 94.00% in Top-1 accuracy and a 99.17% in Top-3 accuracy and runs inference in just 1.61ms using CPU, demonstrating its suitability for real-world mobile deployment.","authors":["Huu-Phong Phan-Nguyen","Anh Dao","Tien-Huy Nguyen","Tuan Quang","Huu-Loc Tran","Tinh-Anh Nguyen-Nhu","Huy-Thach Pham","Quan Nguyen","Hoang M. Le","Quang-Vinh Dinh"],"url":"https://arxiv.org/abs/2504.09297"}
{"created":"2025-04-15","title":"A Lightweight Moment Retrieval System with Global Re-Ranking and Robust Adaptive Bidirectional Temporal Search","abstract":"The exponential growth of digital video content has posed critical challenges in moment-level video retrieval, where existing methodologies struggle to efficiently localize specific segments within an expansive video corpus. Current retrieval systems are constrained by computational inefficiencies, temporal context limitations, and the intrinsic complexity of navigating video content. In this paper, we address these limitations through a novel Interactive Video Corpus Moment Retrieval framework that integrates a SuperGlobal Reranking mechanism and Adaptive Bidirectional Temporal Search (ABTS), strategically optimizing query similarity, temporal stability, and computational resources. By preprocessing a large corpus of videos using a keyframe extraction model and deduplication technique through image hashing, our approach provides a scalable solution that significantly reduces storage requirements while maintaining high localization precision across diverse video repositories.","authors":["Tinh-Anh Nguyen-Nhu","Huu-Loc Tran","Nguyen-Khang Le","Minh-Nhat Nguyen","Tien-Huy Nguyen","Hoang-Long Nguyen-Huu","Huu-Phong Phan-Nguyen","Huy-Thach Pham","Quan Nguyen","Hoang M. Le","Quang-Vinh Dinh"],"url":"https://arxiv.org/abs/2504.09298"}
{"created":"2025-04-15","title":"Beyond Glucose-Only Assessment: Advancing Nocturnal Hypoglycemia Prediction in Children with Type 1 Diabetes","abstract":"The dead-in-bed syndrome describes the sudden and unexplained death of young individuals with Type 1 Diabetes (T1D) without prior long-term complications. One leading hypothesis attributes this phenomenon to nocturnal hypoglycemia (NH), a dangerous drop in blood glucose during sleep. This study aims to improve NH prediction in children with T1D by leveraging physiological data and machine learning (ML) techniques. We analyze an in-house dataset collected from 16 children with T1D, integrating physiological metrics from wearable sensors. We explore predictive performance through feature engineering, model selection, architectures, and oversampling. To address data limitations, we apply transfer learning from a publicly available adult dataset. Our results achieve an AUROC of 0.75 +- 0.21 on the in-house dataset, further improving to 0.78 +- 0.05 with transfer learning. This research moves beyond glucose-only predictions by incorporating physiological parameters, showcasing the potential of ML to enhance NH detection and improve clinical decision-making for pediatric diabetes management.","authors":["Marco Voegeli","Sonia Laguna","Heike Leutheuser","Marc Pfister","Marie-Anne Burckhardt","Julia E Vogt"],"url":"https://arxiv.org/abs/2504.09299"}
{"created":"2025-04-15","title":"Continuum-Interaction-Driven Intelligence: Human-Aligned Neural Architecture via Crystallized Reasoning and Fluid Generation","abstract":"Current AI systems based on probabilistic neural networks, such as large language models (LLMs), have demonstrated remarkable generative capabilities yet face critical challenges including hallucination, unpredictability, and misalignment with human decision-making. These issues fundamentally stem from the over-reliance on randomized (probabilistic) neural networks-oversimplified models of biological neural networks-while neglecting the role of procedural reasoning (chain-of-thought) in trustworthy decision-making. Inspired by the human cognitive duality of fluid intelligence (flexible generation) and crystallized intelligence (structured knowledge), this study proposes a dual-channel intelligent architecture that integrates probabilistic generation (LLMs) with white-box procedural reasoning (chain-of-thought) to construct interpretable, continuously learnable, and human-aligned AI systems. Concretely, this work: (1) redefines chain-of-thought as a programmable crystallized intelligence carrier, enabling dynamic knowledge evolution and decision verification through multi-turn interaction frameworks; (2) introduces a task-driven modular network design that explicitly demarcates the functional boundaries between randomized generation and procedural control to address trustworthiness in vertical-domain applications; (3) demonstrates that multi-turn interaction is a necessary condition for intelligence emergence, with dialogue depth positively correlating with the system's human-alignment degree. This research not only establishes a new paradigm for trustworthy AI deployment but also provides theoretical foundations for next-generation human-AI collaborative systems.","authors":["Pengcheng Zhou","Zhiqiang Nie","Haochen Li"],"url":"https://arxiv.org/abs/2504.09301"}
{"created":"2025-04-15","title":"Application of Contrastive Learning on ECG Data: Evaluating Performance in Japanese and Classification with Around 100 Labels","abstract":"The electrocardiogram (ECG) is a fundamental tool in cardiovascular diagnostics due to its powerful and non-invasive nature. One of the most critical usages is to determine whether more detailed examinations are necessary, with users ranging across various levels of expertise. Given this diversity in expertise, it is essential to assist users to avoid critical errors. Recent studies in machine learning have addressed this challenge by extracting valuable information from ECG data. Utilizing language models, these studies have implemented multimodal models aimed at classifying ECGs according to labeled terms. However, the number of classes was reduced, and it remains uncertain whether the technique is effective for languages other than English. To move towards practical application, we utilized ECG data from regular patients visiting hospitals in Japan, maintaining a large number of Japanese labels obtained from actual ECG readings. Using a contrastive learning framework, we found that even with 98 labels for classification, our Japanese-based language model achieves accuracy comparable to previous research. This study extends the applicability of multimodal machine learning frameworks to broader clinical studies and non-English languages.","authors":["Junichiro Takahashi","JingChuan Guan","Masataka Sato","Kaito Baba","Kazuto Haruguchi","Daichi Nagashima","Satoshi Kodera","Norihiko Takeda"],"url":"https://arxiv.org/abs/2504.09302"}
{"created":"2025-04-15","title":"Enhancing Contrastive Demonstration Selection with Semantic Diversity for Robust In-Context Machine Translation","abstract":"In-Context Learning (ICL) empowers large language models to perform tasks by conditioning on a few input-output examples. However, the performance of ICL is highly sensitive to the selection of these demonstrations. While existing methods focus on similarity or contrastive selection, they often overlook the importance of diversity among the chosen examples. In this paper, we propose DiverseConE (Diversity-Enhanced Contrastive Example Selection), a novel approach for demonstration selection in in-context learning for machine translation. Our method builds upon contrastive selection by incorporating a diversity enhancement step based on embedding space dissimilarity. We conduct extensive experiments on the Llama2-7b model across four language pairs (English-Chinese, Chinese-English, Russian-German, German-Russian) in 1-shot and 3-shot settings, using COMET20 and COMET22 for evaluation. Our results demonstrate that DiverseConE consistently outperforms strong baseline methods, including random selection, BM25, TopK, and a state-of-the-art contrastive selection method. Further analysis, including diversity metrics and human evaluation, validates the effectiveness of our approach and highlights the benefits of considering demonstration diversity for improved translation quality.","authors":["Owen Patterson","Chee Ng"],"url":"https://arxiv.org/abs/2504.09305"}
{"created":"2025-04-15","title":"Lumos: Efficient Performance Modeling and Estimation for Large-scale LLM Training","abstract":"Training LLMs in distributed environments presents significant challenges due to the complexity of model execution, deployment systems, and the vast space of configurable strategies. Although various optimization techniques exist, achieving high efficiency in practice remains difficult. Accurate performance models that effectively characterize and predict a model's behavior are essential for guiding optimization efforts and system-level studies. We propose Lumos, a trace-driven performance modeling and estimation toolkit for large-scale LLM training, designed to accurately capture and predict the execution behaviors of modern LLMs. We evaluate Lumos on a production ML cluster with up to 512 NVIDIA H100 GPUs using various GPT-3 variants, demonstrating that it can replay execution time with an average error of just 3.3%, along with other runtime details, across different models and configurations. Additionally, we validate its ability to estimate performance for new setups from existing traces, facilitating efficient exploration of model and deployment configurations.","authors":["Mingyu Liang","Hiwot Tadese Kassa","Wenyin Fu","Brian Coutinho","Louis Feng","Christina Delimitrou"],"url":"https://arxiv.org/abs/2504.09307"}
{"created":"2025-04-15","title":"Improving the Accuracy and Efficiency of Legal Document Tagging with Large Language Models and Instruction Prompts","abstract":"Legal multi-label classification is a critical task for organizing and accessing the vast amount of legal documentation. Despite its importance, it faces challenges such as the complexity of legal language, intricate label dependencies, and significant label imbalance. In this paper, we propose Legal-LLM, a novel approach that leverages the instruction-following capabilities of Large Language Models (LLMs) through fine-tuning. We reframe the multi-label classification task as a structured generation problem, instructing the LLM to directly output the relevant legal categories for a given document. We evaluate our method on two benchmark datasets, POSTURE50K and EURLEX57K, using micro-F1 and macro-F1 scores. Our experimental results demonstrate that Legal-LLM outperforms a range of strong baseline models, including traditional methods and other Transformer-based approaches. Furthermore, ablation studies and human evaluations validate the effectiveness of our approach, particularly in handling label imbalance and generating relevant and accurate legal labels.","authors":["Emily Johnson","Xavier Holt","Noah Wilson"],"url":"https://arxiv.org/abs/2504.09309"}
{"created":"2025-04-15","title":"Conformal Calibration: Ensuring the Reliability of Black-Box AI in Wireless Systems","abstract":"AI is poised to revolutionize telecommunication networks by boosting efficiency, automation, and decision-making. However, the black-box nature of most AI models introduces substantial risk, possibly deterring adoption by network operators. These risks are not addressed by the current prevailing deployment strategy, which typically follows a best-effort train-and-deploy paradigm. This paper reviews conformal calibration, a general framework that moves beyond the state of the art by adopting computationally lightweight, advanced statistical tools that offer formal reliability guarantees without requiring further training or fine-tuning. Conformal calibration encompasses pre-deployment calibration via uncertainty quantification or hyperparameter selection; online monitoring to detect and mitigate failures in real time; and counterfactual post-deployment performance analysis to address \"what if\" diagnostic questions after deployment. By weaving conformal calibration into the AI model lifecycle, network operators can establish confidence in black-box AI models as a dependable enabling technology for wireless systems.","authors":["Osvaldo Simeone","Sangwoo Park","Matteo Zecchin"],"url":"https://arxiv.org/abs/2504.09310"}
{"created":"2025-04-15","title":"Dupin: A Parallel Framework for Densest Subgraph Discovery in Fraud Detection on Massive Graphs (Technical Report)","abstract":"Detecting fraudulent activities in financial and e-commerce transaction networks is crucial. One effective method for this is Densest Subgraph Discovery (DSD). However, deploying DSD methods in production systems faces substantial scalability challenges due to the predominantly sequential nature of existing methods, which impedes their ability to handle large-scale transaction networks and results in significant detection delays. To address these challenges, we introduce Dupin, a novel parallel processing framework designed for efficient DSD processing in billion-scale graphs. Dupin is powered by a processing engine that exploits the unique properties of the peeling process, with theoretical guarantees on detection quality and efficiency. Dupin provides userfriendly APIs for flexible customization of DSD objectives and ensures robust adaptability to diverse fraud detection scenarios. Empirical evaluations demonstrate that Dupin consistently outperforms several existing DSD methods, achieving performance improvements of up to 100 times compared to traditional approaches. On billion-scale graphs, Dupin demonstrates the potential to enhance the prevention of fraudulent transactions from 45% to 94.5% and reduces density error from 30% to below 5%, as supported by our experimental results. These findings highlight the effectiveness of Dupin in real-world applications, ensuring both speed and accuracy in fraud detection.","authors":["Jiaxin Jiang","Siyuan Yao","Yuchen Li","Qiange Wang","Bingsheng He","Min Chen"],"url":"https://arxiv.org/abs/2504.09311"}
{"created":"2025-04-15","title":"Testing Juntas and Junta Subclasses with Relative Error","abstract":"This papers considers the junta testing problem in a recently introduced ``relative error'' variant of the standard Boolean function property testing model. In relative-error testing we measure the distance from $f$ to $g$, where $f,g: \\{0,1\\}^n \\to \\{0,1\\}$, by the ratio of $|f^{-1}(1) \\triangle g^{-1}(1)|$ (the number of inputs on which $f$ and $g$ disagree) to $|f^{-1}(1)|$ (the number of satisfying assignments of $f$), and we give the testing algorithm both black-box access to $f$ and also access to independent uniform samples from $f^{-1}(1)$.","authors":["Xi Chen","William Pires","Toniann Pitassi","Rocco A. Servedio"],"url":"https://arxiv.org/abs/2504.09312"}
{"created":"2025-04-15","title":"SmartShift: A Secure and Efficient Approach to Smart Contract Migration","abstract":"Blockchain and smart contracts have emerged as revolutionary technologies transforming distributed computing. While platform evolution and smart contracts' inherent immutability necessitate migrations both across and within chains, migrating the vast amounts of critical data in these contracts while maintaining data integrity and minimizing operational disruption presents a significant challenge. To address these challenges, we present SmartShift, a framework that enables secure and efficient smart contract migrations through intelligent state partitioning and progressive function activation, preserving operational continuity during transitions. Our comprehensive evaluation demonstrates that SmartShift significantly reduces migration downtime while ensuring robust security, establishing a foundation for efficient and secure smart contract migration systems.","authors":["Tahrim Hossain","Faisal Haque Bappy","Tarannum Shaila Zaman","Raiful Hasan","Tariqul Islam"],"url":"https://arxiv.org/abs/2504.09315"}
{"created":"2025-04-15","title":"CrossLink: A Decentralized Framework for Secure Cross-Chain Smart Contract Execution","abstract":"This paper introduces CrossLink, a decentralized framework for secure cross-chain smart contract execution that effectively addresses the inherent limitations of contemporary solutions, which primarily focus on asset transfers and rely on potentially vulnerable centralized intermediaries. Recognizing the escalating demand for seamless interoperability among decentralized applications, CrossLink provides a trustless mechanism for smart contracts across disparate blockchain networks to communicate and interact. At its core, CrossLink utilizes a compact chain for selectively storing authorized contract states and employs a secure inter-chain messaging mechanism to ensure atomic execution and data consistency. By implementing a deposit/collateral fee system and efficient state synchronization, CrossLink enhances security and mitigates vulnerabilities, offering a novel approach to seamless, secure, and decentralized cross-chain interoperability. A formal security analysis further validates CrossLink's robustness against unauthorized modifications and denial-of-service attacks.","authors":["Tahrim Hossain","Faisal Haque Bappy","Tarannum Shaila Zaman","Tariqul Islam"],"url":"https://arxiv.org/abs/2504.09319"}
{"created":"2025-04-15","title":"MedIL: Implicit Latent Spaces for Generating Heterogeneous Medical Images at Arbitrary Resolutions","abstract":"In this work, we introduce MedIL, a first-of-its-kind autoencoder built for encoding medical images with heterogeneous sizes and resolutions for image generation. Medical images are often large and heterogeneous, where fine details are of vital clinical importance. Image properties change drastically when considering acquisition equipment, patient demographics, and pathology, making realistic medical image generation challenging. Recent work in latent diffusion models (LDMs) has shown success in generating images resampled to a fixed-size. However, this is a narrow subset of the resolutions native to image acquisition, and resampling discards fine anatomical details. MedIL utilizes implicit neural representations to treat images as continuous signals, where encoding and decoding can be performed at arbitrary resolutions without prior resampling. We quantitatively and qualitatively show how MedIL compresses and preserves clinically-relevant features over large multi-site, multi-resolution datasets of both T1w brain MRIs and lung CTs. We further demonstrate how MedIL can influence the quality of images generated with a diffusion model, and discuss how MedIL can enhance generative models to resemble raw clinical acquisitions.","authors":["Tyler Spears","Shen Zhu","Yinzhu Jin","Aman Shrivastava","P. Thomas Fletcher"],"url":"https://arxiv.org/abs/2504.09322"}
{"created":"2025-04-15","title":"Infused Suppression Of Magnification Artefacts For Micro-AU Detection","abstract":"Facial micro-expressions are spontaneous, brief and subtle facial motions that unveil the underlying, suppressed emotions. Detecting Action Units (AUs) in micro-expressions is crucial because it yields a finer representation of facial motions than categorical emotions, effectively resolving the ambiguity among different expressions. One of the difficulties in micro-expression analysis is that facial motions are subtle and brief, thereby increasing the difficulty in correlating facial motion features to AU occurrence. To bridge the subtlety issue, flow-related features and motion magnification are a few common approaches as they can yield descriptive motion changes and increased motion amplitude respectively. While motion magnification can amplify the motion changes, it also accounts for illumination changes and projection errors during the amplification process, thereby creating motion artefacts that confuse the model to learn inauthentic magnified motion features. The problem is further aggravated in the context of a more complicated task where more AU classes are analyzed in cross-database settings. To address this issue, we propose InfuseNet, a layer-wise unitary feature infusion framework that leverages motion context to constrain the Action Unit (AU) learning within an informative facial movement region, thereby alleviating the influence of magnification artefacts. On top of that, we propose leveraging magnified latent features instead of reconstructing magnified samples to limit the distortion and artefacts caused by the projection inaccuracy in the motion reconstruction process. Via alleviating the magnification artefacts, InfuseNet has surpassed the state-of-the-art results in the CD6ME protocol. Further quantitative studies have also demonstrated the efficacy of motion artefacts alleviation.","authors":["Huai-Qian Khor","Yante Li","Xingxun Jiang","Guoying Zhao"],"url":"https://arxiv.org/abs/2504.09326"}
{"created":"2025-04-15","title":"Text To 3D Object Generation For Scalable Room Assembly","abstract":"Modern machine learning models for scene understanding, such as depth estimation and object tracking, rely on large, high-quality datasets that mimic real-world deployment scenarios. To address data scarcity, we propose an end-to-end system for synthetic data generation for scalable, high-quality, and customizable 3D indoor scenes. By integrating and adapting text-to-image and multi-view diffusion models with Neural Radiance Field-based meshing, this system generates highfidelity 3D object assets from text prompts and incorporates them into pre-defined floor plans using a rendering tool. By introducing novel loss functions and training strategies into existing methods, the system supports on-demand scene generation, aiming to alleviate the scarcity of current available data, generally manually crafted by artists. This system advances the role of synthetic data in addressing machine learning training limitations, enabling more robust and generalizable models for real-world applications.","authors":["Sonia Laguna","Alberto Garcia-Garcia","Marie-Julie Rakotosaona","Stylianos Moschoglou","Leonhard Helminger","Sergio Orts-Escolano"],"url":"https://arxiv.org/abs/2504.09328"}
{"created":"2025-04-15","title":"Regretful Decisions under Label Noise","abstract":"Machine learning models are routinely used to support decisions that affect individuals -- be it to screen a patient for a serious illness or to gauge their response to treatment. In these tasks, we are limited to learning models from datasets with noisy labels. In this paper, we study the instance-level impact of learning under label noise. We introduce a notion of regret for this regime which measures the number of unforeseen mistakes due to noisy labels. We show that standard approaches to learning under label noise can return models that perform well at a population level while subjecting individuals to a lottery of mistakes. We present a versatile approach to estimate the likelihood of mistakes at the individual level from a noisy dataset by training models over plausible realizations of datasets without label noise. This is supported by a comprehensive empirical study of label noise in clinical prediction tasks. Our results reveal how failure to anticipate mistakes can compromise model reliability and adoption, and demonstrate how we can address these challenges by anticipating and avoiding regretful decisions.","authors":["Sujay Nagaraj","Yang Liu","Flavio P. Calmon","Berk Ustun"],"url":"https://arxiv.org/abs/2504.09330"}
{"created":"2025-04-15","title":"The Goldilocks Time Window for Proactive Interventions in Wearable AI Systems","abstract":"As AI systems become increasingly integrated into our daily lives and into wearable form factors, there's a fundamental tension between their potential to proactively assist us and the risk of creating intrusive, dependency-forming experiences. This work proposes the concept of a Goldilocks Time Window -- a contextually adaptive time window for proactive AI systems to deliver effective interventions. We discuss the critical factors that determine the time window, and the need of a framework for designing and evaluating proactive AI systems that can navigate this tension successfully.","authors":["Cathy Mengying Fang","Wazeer Zulfikar","Yasith Samaradivakara","Suranga Nanayakkara","Pattie Maes"],"url":"https://arxiv.org/abs/2504.09332"}
{"created":"2025-04-15","title":"Efficient Implementation of Reinforcement Learning over Homomorphic Encryption","abstract":"We investigate encrypted control policy synthesis over the cloud. While encrypted control implementations have been studied previously, we focus on the less explored paradigm of privacy-preserving control synthesis, which can involve heavier computations ideal for cloud outsourcing. We classify control policy synthesis into model-based, simulator-driven, and data-driven approaches and examine their implementation over fully homomorphic encryption (FHE) for privacy enhancements. A key challenge arises from comparison operations (min or max) in standard reinforcement learning algorithms, which are difficult to execute over encrypted data. This observation motivates our focus on Relative-Entropy-regularized reinforcement learning (RL) problems, which simplifies encrypted evaluation of synthesis algorithms due to their comparison-free structures. We demonstrate how linearly solvable value iteration, path integral control, and Z-learning can be readily implemented over FHE. We conduct a case study of our approach through numerical simulations of encrypted Z-learning in a grid world environment using the CKKS encryption scheme, showing convergence with acceptable approximation error. Our work suggests the potential for secure and efficient cloud-based reinforcement learning.","authors":["Jihoon Suh","Takashi Tanaka"],"url":"https://arxiv.org/abs/2504.09335"}
{"created":"2025-04-15","title":"Essentially Non-oscillatory Spectral Volume Methods","abstract":"A new Essentially Non-oscillatory (ENO) recovery algorithm is developed and tested in a Finite Volume method. The construction is hinged on a reformulation of the reconstruction as the solution to a variational problem. The sign property of the classical ENO algorithm is expressed as restrictions on the admissible set of solutions to this variational problem. In conjunction with an educated guessing algorithm for possible locations of discontinuities an ENO reconstruction algorithm without divided differences or smoothness indicators is constructed. No tunable parameters exist apart from the desired order and stencil width. The desired order is in principle arbitrary, but growing stencils are needed. While classical ENO methods consider all connected stencils that surround a cell under consideration the proposed recovery method uses a fixed stencil, simplifying efficient high order implementations.","authors":["Simon-Christian Klein"],"url":"https://arxiv.org/abs/2504.09336"}
{"created":"2025-04-15","title":"Towards Optimal Differentially Private Regret Bounds in Linear MDPs","abstract":"We study regret minimization under privacy constraints in episodic inhomogeneous linear Markov Decision Processes (MDPs), motivated by the growing use of reinforcement learning (RL) in personalized decision-making systems that rely on sensitive user data. In this setting, both transition probabilities and reward functions are assumed to be linear in a feature mapping $\\phi(s, a)$, and we aim to ensure privacy through joint differential privacy (JDP), a relaxation of differential privacy suited to online learning. Prior work has established suboptimal regret bounds by privatizing the LSVI-UCB algorithm, which achieves $\\widetilde{O}(\\sqrt{d^3 H^4 K})$ regret in the non-private setting. Building on recent advances that improve this to minimax optimal regret $\\widetilde{O}(HD\\sqrt{K})$ via LSVI-UCB++ with Bernstein-style bonuses, we design a new differentially private algorithm by privatizing LSVI-UCB++ and adapting techniques for variance-aware analysis from offline RL. Our algorithm achieves a regret bound of $\\widetilde{O}(d \\sqrt{H^3 K} + H^{4.5} d^{7/6} K^{1/2} / \\epsilon)$, improving over previous private methods. Empirical results show that our algorithm retains near-optimal utility compared to non-private baselines, indicating that privacy can be achieved with minimal performance degradation in this setting.","authors":["Sharan Sahu"],"url":"https://arxiv.org/abs/2504.09339"}
{"created":"2025-04-15","title":"Minority Reports: Balancing Cost and Quality in Ground Truth Data Annotation","abstract":"High-quality data annotation is an essential but laborious and costly aspect of developing machine learning-based software. We explore the inherent tradeoff between annotation accuracy and cost by detecting and removing minority reports -- instances where annotators provide incorrect responses -- that indicate unnecessary redundancy in task assignments. We propose an approach to prune potentially redundant annotation task assignments before they are executed by estimating the likelihood of an annotator disagreeing with the majority vote for a given task. Our approach is informed by an empirical analysis over computer vision datasets annotated by a professional data annotation platform, which reveals that the likelihood of a minority report event is dependent primarily on image ambiguity, worker variability, and worker fatigue. Simulations over these datasets show that we can reduce the number of annotations required by over 60% with a small compromise in label quality, saving approximately 6.6 days-equivalent of labor. Our approach provides annotation service platforms with a method to balance cost and dataset quality. Machine learning practitioners can tailor annotation accuracy levels according to specific application needs, thereby optimizing budget allocation while maintaining the data quality necessary for critical settings like autonomous driving technology.","authors":["Hsuan Wei Liao","Christopher Klugmann","Daniel Kondermann","Rafid Mahmood"],"url":"https://arxiv.org/abs/2504.09341"}
{"created":"2025-04-15","title":"Confirmation Bias in Generative AI Chatbots: Mechanisms, Risks, Mitigation Strategies, and Future Research Directions","abstract":"This article explores the phenomenon of confirmation bias in generative AI chatbots, a relatively underexamined aspect of AI-human interaction. Drawing on cognitive psychology and computational linguistics, it examines how confirmation bias, commonly understood as the tendency to seek information that aligns with existing beliefs, can be replicated and amplified by the design and functioning of large language models. The article analyzes the mechanisms by which confirmation bias may manifest in chatbot interactions, assesses the ethical and practical risks associated with such bias, and proposes a range of mitigation strategies. These include technical interventions, interface redesign, and policy measures aimed at promoting balanced AI-generated discourse. The article concludes by outlining future research directions, emphasizing the need for interdisciplinary collaboration and empirical evaluation to better understand and address confirmation bias in generative AI systems.","authors":["Yiran Du"],"url":"https://arxiv.org/abs/2504.09343"}
{"created":"2025-04-15","title":"Context-Aware Adaptive Sampling for Intelligent Data Acquisition Systems Using DQN","abstract":"Multi-sensor systems are widely used in the Internet of Things, environmental monitoring, and intelligent manufacturing. However, traditional fixed-frequency sampling strategies often lead to severe data redundancy, high energy consumption, and limited adaptability, failing to meet the dynamic sensing needs of complex environments. To address these issues, this paper proposes a DQN-based multi-sensor adaptive sampling optimization method. By leveraging a reinforcement learning framework to learn the optimal sampling strategy, the method balances data quality, energy consumption, and redundancy. We first model the multi-sensor sampling task as a Markov Decision Process (MDP), then employ a Deep Q-Network to optimize the sampling policy. Experiments on the Intel Lab Data dataset confirm that, compared with fixed-frequency sampling, threshold-triggered sampling, and other reinforcement learning approaches, DQN significantly improves data quality while lowering average energy consumption and redundancy rates. Moreover, in heterogeneous multi-sensor environments, DQN-based adaptive sampling shows enhanced robustness, maintaining superior data collection performance even in the presence of interference factors. These findings demonstrate that DQN-based adaptive sampling can enhance overall data acquisition efficiency in multi-sensor systems, providing a new solution for efficient and intelligent sensing.","authors":["Weiqiang Huang","Juecen Zhan","Yumeng Sun","Xu Han","Tai An","Nan Jiang"],"url":"https://arxiv.org/abs/2504.09344"}
{"created":"2025-04-15","title":"MoE-Lens: Towards the Hardware Limit of High-Throughput MoE LLM Serving Under Resource Constraints","abstract":"Mixture of Experts (MoE) LLMs, characterized by their sparse activation patterns, offer a promising approach to scaling language models while avoiding proportionally increasing the inference cost. However, their large parameter sizes present deployment challenges in resource-constrained environments with limited GPU memory capacity, as GPU memory is often insufficient to accommodate the full set of model weights. Consequently, typical deployments rely on CPU-GPU hybrid execution: the GPU handles compute-intensive GEMM operations, while the CPU processes the relatively lightweight attention mechanism. This setup introduces a key challenge: how to effectively optimize resource utilization across CPU and GPU? Prior work has designed system optimizations based on performance models with limited scope. Specifically, such models do not capture the complex interactions between hardware properties and system execution mechanisms. Therefore, previous approaches neither identify nor achieve the hardware limit.","authors":["Yichao Yuan","Lin Ma","Nishil Talati"],"url":"https://arxiv.org/abs/2504.09345"}
{"created":"2025-04-15","title":"\"It's not a representation of me\": Examining Accent Bias and Digital Exclusion in Synthetic AI Voice Services","abstract":"Recent advances in artificial intelligence (AI) speech generation and voice cloning technologies have produced naturalistic speech and accurate voice replication, yet their influence on sociotechnical systems across diverse accents and linguistic traits is not fully understood. This study evaluates two synthetic AI voice services (Speechify and ElevenLabs) through a mixed methods approach using surveys and interviews to assess technical performance and uncover how users' lived experiences influence their perceptions of accent variations in these speech technologies. Our findings reveal technical performance disparities across five regional, English-language accents and demonstrate how current speech generation technologies may inadvertently reinforce linguistic privilege and accent-based discrimination, potentially creating new forms of digital exclusion. Overall, our study highlights the need for inclusive design and regulation by providing actionable insights for developers, policymakers, and organizations to ensure equitable and socially responsible AI speech technologies.","authors":["Shira Michel","Sufi Kaur","Sarah Elizabeth Gillespie","Jeffrey Gleason","Christo Wilson","Avijit Ghosh"],"url":"https://arxiv.org/abs/2504.09346"}
{"created":"2025-04-15","title":"Explorer: Robust Collection of Interactable GUI Elements","abstract":"Automation of existing Graphical User Interfaces (GUIs) is important but hard to achieve. Upstream of making the GUI user-accessible or somehow scriptable, even the data-collection to understand the original interface poses significant challenges. For example, large quantities of general UI data seem helpful for training general machine learning (ML) models, but accessibility for each person can hinge on the ML's precision on a specific app. We therefore take the perspective that a given user needs confidence, that the relevant UI elements are being detected correctly throughout one app or digital environment. We mostly assume that the target application is known in advance, so that data collection and ML-training can be personalized for the test-time target domain. The proposed Explorer system focuses on detecting on-screen buttons and text-entry fields, i.e. interactables, where the training process has access to a live version of the application. The live application can run on almost any popular platform except iOS phones, and the collection is especially streamlined for Android phones or for desktop Chrome browsers. Explorer also enables the recording of interactive user sessions, and subsequent mapping of how such sessions overlap and sometimes loop back to similar states. We show how having such a map enables a kind of path planning through the GUI, letting a user issue audio commands to get to their destination. Critically, we are releasing our code for Explorer openly at https://github.com/varnelis/Explorer.","authors":["Iason Chaimalas","Arnas Vy\\v{s}niauskas","Gabriel Brostow"],"url":"https://arxiv.org/abs/2504.09352"}
{"created":"2025-04-15","title":"Breaking the Lens of the Telescope: Online Relevance Estimation over Large Retrieval Sets","abstract":"Advanced relevance models, such as those that use large language models (LLMs), provide highly accurate relevance estimations. However, their computational costs make them infeasible for processing large document corpora. To address this, retrieval systems often employ a telescoping approach, where computationally efficient but less precise lexical and semantic retrievers filter potential candidates for further ranking. However, this approach heavily depends on the quality of early-stage retrieval, which can potentially exclude relevant documents early in the process. In this work, we propose a novel paradigm for re-ranking called online relevance estimation that continuously updates relevance estimates for a query throughout the ranking process. Instead of re-ranking a fixed set of top-k documents in a single step, online relevance estimation iteratively re-scores smaller subsets of the most promising documents while adjusting relevance scores for the remaining pool based on the estimations from the final model using an online bandit-based algorithm. This dynamic process mitigates the recall limitations of telescoping systems by re-prioritizing documents initially deemed less relevant by earlier stages -- including those completely excluded by earlier-stage retrievers. We validate our approach on TREC benchmarks under two scenarios: hybrid retrieval and adaptive retrieval. Experimental results demonstrate that our method is sample-efficient and significantly improves recall, highlighting the effectiveness of our online relevance estimation framework for modern search systems.","authors":["Mandeep Rathee","Venktesh V","Sean MacAvaney","Avishek Anand"],"url":"https://arxiv.org/abs/2504.09353"}
{"created":"2025-04-15","title":"REMEMBER: Retrieval-based Explainable Multimodal Evidence-guided Modeling for Brain Evaluation and Reasoning in Zero- and Few-shot Neurodegenerative Diagnosis","abstract":"Timely and accurate diagnosis of neurodegenerative disorders, such as Alzheimer's disease, is central to disease management. Existing deep learning models require large-scale annotated datasets and often function as \"black boxes\". Additionally, datasets in clinical practice are frequently small or unlabeled, restricting the full potential of deep learning methods. Here, we introduce REMEMBER -- Retrieval-based Explainable Multimodal Evidence-guided Modeling for Brain Evaluation and Reasoning -- a new machine learning framework that facilitates zero- and few-shot Alzheimer's diagnosis using brain MRI scans through a reference-based reasoning process. Specifically, REMEMBER first trains a contrastively aligned vision-text model using expert-annotated reference data and extends pseudo-text modalities that encode abnormality types, diagnosis labels, and composite clinical descriptions. Then, at inference time, REMEMBER retrieves similar, human-validated cases from a curated dataset and integrates their contextual information through a dedicated evidence encoding module and attention-based inference head. Such an evidence-guided design enables REMEMBER to imitate real-world clinical decision-making process by grounding predictions in retrieved imaging and textual context. Specifically, REMEMBER outputs diagnostic predictions alongside an interpretable report, including reference images and explanations aligned with clinical workflows. Experimental results demonstrate that REMEMBER achieves robust zero- and few-shot performance and offers a powerful and explainable framework to neuroimaging-based diagnosis in the real world, especially under limited data.","authors":["Duy-Cat Can","Quang-Huy Tang","Huong Ha","Binh T. Nguyen","Oliver Y. Ch\\'en"],"url":"https://arxiv.org/abs/2504.09354"}
{"created":"2025-04-15","title":"Designing Reality-Based VR Interfaces for Geological Uncertainty","abstract":"Inherent uncertainty in geological data acquisition leads to the generation of large ensembles of equiprobable 3D reservoir models. Running computationally costly numerical flow simulations across such a vast solution space is infeasible. A more suitable approach is to carefully select a small number of geological models that reasonably capture the overall variability of the ensemble. Identifying these representative models is a critical task that enables the oil and gas industry to generate cost-effective production forecasts. Our work leverages virtual reality (VR) to provide engineers with a system for conducting geological uncertainty analysis, enabling them to perform inherently spatial tasks using an associative 3D interaction space. We present our VR system through the lens of the reality-based interaction paradigm, designing 3D interfaces that enable familiar physical interactions inspired by real-world analogies-such as gesture-based operations and view-dependent lenses. We also report an evaluation conducted with 12 reservoir engineers from an industry partner. Our findings offer insights into the benefits, pitfalls, and opportunities for refining our system design. We catalog our results into a set of design recommendations intended to guide researchers and developers of immersive interfaces-in reservoir engineering and broader application domains.","authors":["Roberta Mota","Ehud Sharlin","Usman Alim"],"url":"https://arxiv.org/abs/2504.09355"}
{"created":"2025-04-15","title":"DoorBot: Closed-Loop Task Planning and Manipulation for Door Opening in the Wild with Haptic Feedback","abstract":"Robots operating in unstructured environments face significant challenges when interacting with everyday objects like doors. They particularly struggle to generalize across diverse door types and conditions. Existing vision-based and open-loop planning methods often lack the robustness to handle varying door designs, mechanisms, and push/pull configurations. In this work, we propose a haptic-aware closed-loop hierarchical control framework that enables robots to explore and open different unseen doors in the wild. Our approach leverages real-time haptic feedback, allowing the robot to adjust its strategy dynamically based on force feedback during manipulation. We test our system on 20 unseen doors across different buildings, featuring diverse appearances and mechanical types. Our framework achieves a 90% success rate, demonstrating its ability to generalize and robustly handle varied door-opening tasks. This scalable solution offers potential applications in broader open-world articulated object manipulation tasks.","authors":["Zhi Wang","Yuchen Mo","Shengmiao Jin","Wenzhen Yuan"],"url":"https://arxiv.org/abs/2504.09358"}
{"created":"2025-04-15","title":"PapMOT: Exploring Adversarial Patch Attack against Multiple Object Tracking","abstract":"Tracking multiple objects in a continuous video stream is crucial for many computer vision tasks. It involves detecting and associating objects with their respective identities across successive frames. Despite significant progress made in multiple object tracking (MOT), recent studies have revealed the vulnerability of existing MOT methods to adversarial attacks. Nevertheless, all of these attacks belong to digital attacks that inject pixel-level noise into input images, and are therefore ineffective in physical scenarios. To fill this gap, we propose PapMOT, which can generate physical adversarial patches against MOT for both digital and physical scenarios. Besides attacking the detection mechanism, PapMOT also optimizes a printable patch that can be detected as new targets to mislead the identity association process. Moreover, we introduce a patch enhancement strategy to further degrade the temporal consistency of tracking results across video frames, resulting in more aggressive attacks. We further develop new evaluation metrics to assess the robustness of MOT against such attacks. Extensive evaluations on multiple datasets demonstrate that our PapMOT can successfully attack various architectures of MOT trackers in digital scenarios. We also validate the effectiveness of PapMOT for physical attacks by deploying printed adversarial patches in the real world.","authors":["Jiahuan Long","Tingsong Jiang","Wen Yao","Shuai Jia","Weijia Zhang","Weien Zhou","Chao Ma","Xiaoqian Chen"],"url":"https://arxiv.org/abs/2504.09361"}
{"created":"2025-04-15","title":"Machine Learning-Based Cyberattack Detection and Identification for Automatic Generation Control Systems Considering Nonlinearities","abstract":"Automatic generation control (AGC) systems play a crucial role in maintaining system frequency across power grids. However, AGC systems' reliance on communicated measurements exposes them to false data injection attacks (FDIAs), which can compromise the overall system stability. This paper proposes a machine learning (ML)-based detection framework that identifies FDIAs and determines the compromised measurements. The approach utilizes an ML model trained offline to accurately detect attacks and classify the manipulated signals based on a comprehensive set of statistical and time-series features extracted from AGC measurements before and after disturbances. For the proposed approach, we compare the performance of several powerful ML algorithms. Our results demonstrate the efficacy of the proposed method in detecting FDIAs while maintaining a low false alarm rate, with an F1-score of up to 99.98%, outperforming existing approaches.","authors":["Nour M. Shabar","Ahmad Mohammad Saber","Deepa Kundur"],"url":"https://arxiv.org/abs/2504.09363"}
{"created":"2025-04-15","title":"QUDsim: Quantifying Discourse Similarities in LLM-Generated Text","abstract":"As large language models become increasingly capable at various writing tasks, their weakness at generating unique and creative content becomes a major liability. Although LLMs have the ability to generate text covering diverse topics, there is an overall sense of repetitiveness across texts that we aim to formalize and quantify via a similarity metric. The familiarity between documents arises from the persistence of underlying discourse structures. However, existing similarity metrics dependent on lexical overlap and syntactic patterns largely capture $\\textit{content}$ overlap, thus making them unsuitable for detecting $\\textit{structural}$ similarities. We introduce an abstraction based on linguistic theories in Questions Under Discussion (QUD) and question semantics to help quantify differences in discourse progression. We then use this framework to build $\\textbf{QUDsim}$, a similarity metric that can detect discursive parallels between documents. Using QUDsim, we find that LLMs often reuse discourse structures (more so than humans) across samples, even when content differs. Furthermore, LLMs are not only repetitive and structurally uniform, but are also divergent from human authors in the types of structures they use.","authors":["Ramya Namuduri","Yating Wu","Anshun Asher Zheng","Manya Wadhwa","Greg Durrett","Junyi Jessy Li"],"url":"https://arxiv.org/abs/2504.09373"}
{"created":"2025-04-15","title":"Cross-Partisan Interactions on Twitter","abstract":"Many social media studies argue that social media creates echo chambers where some users only interact with peers of the same political orientation. However, recent studies suggest that a substantial amount of Cross-Partisan Interactions (CPIs) do exist - even within echo chambers, but they may be toxic. There is no consensus about how such interactions occur and when they lead to healthy or toxic dialogue. In this paper, we study a comprehensive Twitter dataset that consists of 3 million tweets from 2020 related to the U.S. context to understand the dynamics behind CPIs. We investigate factors that are more associated with such interactions, including how users engage in CPIs, which topics are more contentious, and what are the stances associated with healthy interactions. We find that CPIs are significantly influenced by the nature of the topics being discussed, with politically charged events acting as strong catalysts. The political discourse and pre-established political views sway how users participate in CPIs, but the direction in which users go is nuanced. While Democrats engage in cross-partisan interactions slightly more frequently, these interactions often involve more negative and nonconstructive stances compared to their intra-party interactions. In contrast, Republicans tend to maintain a more consistent tone across interactions. Although users are more likely to engage in CPIs with popular accounts in general, this is less common among Republicans who often engage in CPIs with accounts with a low number of followers for personal matters. Our study has implications beyond Twitter as identifying topics with low toxicity and high CPI can help highlight potential opportunities for reducing polarization while topics with high toxicity and low CPI may action targeted interventions when moderating harm.","authors":["Yusuf M\\\"ucahit \\c{C}etinkaya","Vahid Ghafouri","Guillermo Suarez-Tangil","Jose Such","Tu\\u{g}rulcan Elmas"],"url":"https://arxiv.org/abs/2504.09376"}
{"created":"2025-04-15","title":"Beyond Degradation Conditions: All-in-One Image Restoration via HOG Transformers","abstract":"All-in-one image restoration, which aims to address diverse degradations within a unified framework, is critical for practical applications. However, existing methods rely on predicting and integrating degradation conditions, which can misactivate degradation-specific features in complex scenarios, limiting their restoration performance. To address this issue, we propose a novel all-in-one image restoration framework guided by Histograms of Oriented Gradients (HOG), named HOGformer. By leveraging the degradation-discriminative capability of HOG descriptors, HOGformer employs a dynamic self-attention mechanism that adaptively attends to long-range spatial dependencies based on degradation-aware HOG cues. To enhance the degradation sensitivity of attention inputs, we design a HOG-guided local dynamic-range convolution module that captures long-range degradation similarities while maintaining awareness of global structural information. Furthermore, we propose a dynamic interaction feed-forward module, efficiently increasing the model capacity to adapt to different degradations through channel-spatial interactions. Extensive experiments across diverse benchmarks, including adverse weather and natural degradations, demonstrate that HOGformer achieves state-of-the-art performance and generalizes effectively to complex real-world degradations. Code is available at https://github.com/Fire-friend/HOGformer.","authors":["Jiawei Wu","Zhifei Yang","Zhe Wang","Zhi Jin"],"url":"https://arxiv.org/abs/2504.09377"}
{"created":"2025-04-15","title":"Can you map it to English? The Role of Cross-Lingual Alignment in Multilingual Performance of LLMs","abstract":"Large language models (LLMs) pre-trained predominantly on English text exhibit surprising multilingual capabilities, yet the mechanisms driving cross-lingual generalization remain poorly understood. This work investigates how the alignment of representations for text written in different languages correlates with LLM performance on natural language understanding tasks and translation tasks, both at the language and the instance level. For this purpose, we introduce cross-lingual alignment metrics such as the Discriminative Alignment Index (DALI) to quantify the alignment at an instance level for discriminative tasks. Through experiments on three natural language understanding tasks (Belebele, XStoryCloze, XCOPA), and machine translation, we find that while cross-lingual alignment metrics strongly correlate with task accuracy at the language level, the sample-level alignment often fails to distinguish correct from incorrect predictions, exposing alignment as a necessary but insufficient condition for success.","authors":["Kartik Ravisankar","Hyojung Han","Marine Carpuat"],"url":"https://arxiv.org/abs/2504.09378"}
{"created":"2025-04-15","title":"Low-Light Image Enhancement using Event-Based Illumination Estimation","abstract":"Low-light image enhancement (LLIE) aims to improve the visibility of images captured in poorly lit environments. Prevalent event-based solutions primarily utilize events triggered by motion, i.e., ''motion events'' to strengthen only the edge texture, while leaving the high dynamic range and excellent low-light responsiveness of event cameras largely unexplored. This paper instead opens a new avenue from the perspective of estimating the illumination using ''temporal-mapping'' events, i.e., by converting the timestamps of events triggered by a transmittance modulation into brightness values. The resulting fine-grained illumination cues facilitate a more effective decomposition and enhancement of the reflectance component in low-light images through the proposed Illumination-aided Reflectance Enhancement module. Furthermore, the degradation model of temporal-mapping events under low-light condition is investigated for realistic training data synthesizing. To address the lack of datasets under this regime, we construct a beam-splitter setup and collect EvLowLight dataset that includes images, temporal-mapping events, and motion events. Extensive experiments across 5 synthetic datasets and our real-world EvLowLight dataset substantiate that the devised pipeline, dubbed RetinEV, excels in producing well-illuminated, high dynamic range images, outperforming previous state-of-the-art event-based methods by up to 6.62 dB, while maintaining an efficient inference speed of 35.6 frame-per-second on a 640X480 image.","authors":["Lei Sun","Yuhan Bao","Jiajun Zhai","Jingyun Liang","Yulun Zhang","Kaiwei Wang","Danda Pani Paudel","Luc Van Gool"],"url":"https://arxiv.org/abs/2504.09379"}
{"created":"2025-04-15","title":"Modeling Scrap Composition in Electric Arc and Basic Oxygen Furnaces","abstract":"This article aims to determine the composition of scrap (recycled material) used in an Electric Arc Furnace (EAF) or basic Oxygen Furnace (BOF) based on the assumption of mass balance. Accurate knowledge of this composition can increase the usage of recycled material to produce steel, reducing the need for raw ore extraction and minimizing environmental impact by conserving natural resources and lowering carbon emissions. The study develops two models to describe the behavior of elements in the EAF or BOF process. A linear state space model is used for elements transferring completely from scrap to steel, while a non-linear state space model is applied to elements moving into both steel and slag. The Kalman filter and unscented Kalman filter are employed to approximate these models, respectively. Importantly, the models leverage only data already collected as part of the standard production process, avoiding the need for additional measurements that are often costly. This article outlines the formulation of both models, the algorithms used, and discusses the hyperparameters involved. We provide practical suggestions on how to choose appropriate hyperparameters based on expert knowledge and historical data. The models are applied to real BOF data. Cu and Cr are chosen as examples for linear and non-linear models, respectively. The results show that both models can reconstruct the composition of scrap for these elements. The findings provide valuable insights for improving process control and ensuring product quality in steelmaking.","authors":["Yiqing Zhou","Karsten Naert","Dirk Nuyens"],"url":"https://arxiv.org/abs/2504.09382"}
{"created":"2025-04-15","title":"Contour Flow Constraint: Preserving Global Shape Similarity for Deep Learning based Image Segmentation","abstract":"For effective image segmentation, it is crucial to employ constraints informed by prior knowledge about the characteristics of the areas to be segmented to yield favorable segmentation outcomes. However, the existing methods have primarily focused on priors of specific properties or shapes, lacking consideration of the general global shape similarity from a Contour Flow (CF) perspective. Furthermore, naturally integrating this contour flow prior image segmentation model into the activation functions of deep convolutional networks through mathematical methods is currently unexplored. In this paper, we establish a concept of global shape similarity based on the premise that two shapes exhibit comparable contours. Furthermore, we mathematically derive a contour flow constraint that ensures the preservation of global shape similarity. We propose two implementations to integrate the constraint with deep neural networks. Firstly, the constraint is converted to a shape loss, which can be seamlessly incorporated into the training phase for any learning-based segmentation framework. Secondly, we add the constraint into a variational segmentation model and derive its iterative schemes for solution. The scheme is then unrolled to get the architecture of the proposed CFSSnet. Validation experiments on diverse datasets are conducted on classic benchmark deep network segmentation models. The results indicate a great improvement in segmentation accuracy and shape similarity for the proposed shape loss, showcasing the general adaptability of the proposed loss term regardless of specific network architectures. CFSSnet shows robustness in segmenting noise-contaminated images, and inherent capability to preserve global shape similarity.","authors":["Shengzhe Chen","Zhaoxuan Dong","Jun Liu"],"url":"https://arxiv.org/abs/2504.09384"}
{"created":"2025-04-15","title":"Expressivity of Quadratic Neural ODEs","abstract":"This work focuses on deriving quantitative approximation error bounds for neural ordinary differential equations having at most quadratic nonlinearities in the dynamics. The simple dynamics of this model form demonstrates how expressivity can be derived primarily from iteratively composing many basic elementary operations, versus from the complexity of those elementary operations themselves. Like the analog differential analyzer and universal polynomial DAEs, the expressivity is derived instead primarily from the \"depth\" of the model. These results contribute to our understanding of what depth specifically imparts to the capabilities of deep learning architectures.","authors":["Joshua Hanson","Maxim Raginsky"],"url":"https://arxiv.org/abs/2504.09385"}
{"created":"2025-04-15","title":"On Language Models' Sensitivity to Suspicious Coincidences","abstract":"Humans are sensitive to suspicious coincidences when generalizing inductively over data, as they make assumptions as to how the data was sampled. This results in smaller, more specific hypotheses being favored over more general ones. For instance, when provided the set {Austin, Dallas, Houston}, one is more likely to think that this is sampled from \"Texas Cities\" over \"US Cities\" even though both are compatible. Suspicious coincidence is strongly connected to pragmatic reasoning, and can serve as a testbed to analyze systems on their sensitivity towards the communicative goals of the task (i.e., figuring out the true category underlying the data). In this paper, we analyze whether suspicious coincidence effects are reflected in language models' (LMs) behavior. We do so in the context of two domains: 1) the number game, where humans made judgments of whether a number (e.g., 4) fits a list of given numbers (e.g., 16, 32, 2); and 2) by extending the number game setup to prominent cities. For both domains, the data is compatible with multiple hypotheses and we study which hypothesis is most consistent with the models' behavior. On analyzing five models, we do not find strong evidence for suspicious coincidences in LMs' zero-shot behavior. However, when provided access to the hypotheses space via chain-of-thought or explicit prompting, LMs start to show an effect resembling suspicious coincidences, sometimes even showing effects consistent with humans. Our study suggests that inductive reasoning behavior in LMs can be enhanced with explicit access to the hypothesis landscape.","authors":["Sriram Padmanabhan","Kanishka Misra","Kyle Mahowald","Eunsol Choi"],"url":"https://arxiv.org/abs/2504.09387"}
{"created":"2025-04-15","title":"The Rate-Immediacy Barrier in Explicit Tree Code Constructions","abstract":"Since the introduction of tree codes by Schulman (STOC 1993), explicit construction of such codes has remained a notorious challenge. While the construction of asymptotically-good explicit tree codes continues to be elusive, a work by Cohen, Haeupler and Schulman (STOC 2018), as well as the state-of-the-art construction by Ben Yaacov, Cohen, and Yankovitz (STOC 2022) have achieved codes with rate $\\Omega(1/\\log\\log n)$, exponentially improving upon the original construction of Evans, Klugerman and Schulman from 1994. All of these constructions rely, at least in part, on increasingly sophisticated methods of combining (block) error-correcting codes.","authors":["Gil Cohen","Leonard J. Schulman","Piyush Srivastava"],"url":"https://arxiv.org/abs/2504.09388"}
{"created":"2025-04-15","title":"Beyond Memorization: Mapping the Originality-Quality Frontier of Language Models","abstract":"As large language models (LLMs) are increasingly used for ideation and scientific discovery, it is important to evaluate their ability to generate novel output. Prior work evaluates novelty as the originality with respect to training data, but original outputs can be low quality. In contrast, non-expert judges may favor high-quality but memorized outputs, limiting the reliability of human preference as a metric. We propose a new novelty metric for LLM generations that balances originality and quality -- the harmonic mean of the fraction of \\ngrams unseen during training and a task-specific quality score. We evaluate the novelty of generations from two families of open-data models (OLMo and Pythia) on three creative tasks: story completion, poetry writing, and creative tool use. We find that LLM generated text is less novel than human written text. To elicit more novel outputs, we experiment with various inference-time methods, which reveals a trade-off between originality and quality. While these methods can boost novelty, they do so by increasing originality at the expense of quality. In contrast, increasing model size or applying post-training reliably shifts the Pareto frontier, highlighting that starting with a stronger base model is a more effective way to improve novelty.","authors":["Vishakh Padmakumar","Chen Yueh-Han","Jane Pan","Valerie Chen","He He"],"url":"https://arxiv.org/abs/2504.09389"}
{"created":"2025-04-15","title":"Probabilistic Strategies: Definability and the Tensor Completeness Problem","abstract":"Programs that combine I/O and countable probabilistic choice, modulo either bisimilarity or trace equivalence, can be seen as describing a probabilistic strategy. For well-founded programs, we might expect to axiomatize bisimilarity via a sum of equational theories and trace equivalence via a tensor of such theories. This is by analogy with similar results for nondeterminism, established previously.","authors":["Nathan Bowler","Sergey Goncharov","Paul Blain Levy"],"url":"https://arxiv.org/abs/2504.09392"}
{"created":"2025-04-15","title":"Vision Transformers Exhibit Human-Like Biases: Evidence of Orientation and Color Selectivity, Categorical Perception, and Phase Transitions","abstract":"This study explored whether Vision Transformers (ViTs) developed orientation and color biases similar to those observed in the human brain. Using synthetic datasets with controlled variations in noise levels, angles, lengths, widths, and colors, we analyzed the behavior of ViTs fine-tuned with LoRA. Our findings revealed four key insights: First, ViTs exhibited an oblique effect showing the lowest angle prediction errors at 180 deg (horizontal) across all conditions. Second, angle prediction errors varied by color. Errors were highest for bluish hues and lowest for yellowish ones. Additionally, clustering analysis of angle prediction errors showed that ViTs grouped colors in a way that aligned with human perceptual categories. In addition to orientation and color biases, we observed phase transition phenomena. While two phase transitions occurred consistently across all conditions, the training loss curves exhibited delayed transitions when color was incorporated as an additional data attribute. Finally, we observed that attention heads in certain layers inherently develop specialized capabilities, functioning as task-agnostic feature extractors regardless of the downstream task. These observations suggest that biases and properties arise primarily from pre-training on the original dataset which shapes the model's foundational representations and the inherent architectural constraints of the vision transformer, rather than being solely determined by downstream data statistics.","authors":["Nooshin Bahador"],"url":"https://arxiv.org/abs/2504.09393"}
{"created":"2025-04-15","title":"Evaluation Under Imperfect Benchmarks and Ratings: A Case Study in Text Simplification","abstract":"Despite the successes of language models, their evaluation remains a daunting challenge for new and existing tasks. We consider the task of text simplification, commonly used to improve information accessibility, where evaluation faces two major challenges. First, the data in existing benchmarks might not reflect the capabilities of current language models on the task, often containing disfluent, incoherent, or simplistic examples. Second, existing human ratings associated with the benchmarks often contain a high degree of disagreement, resulting in inconsistent ratings; nevertheless, existing metrics still have to show higher correlations with these imperfect ratings. As a result, evaluation for the task is not reliable and does not reflect expected trends (e.g., more powerful models being assigned higher scores). We address these challenges for the task of text simplification through three contributions. First, we introduce SynthSimpliEval, a synthetic benchmark for text simplification featuring simplified sentences generated by models of varying sizes. Through a pilot study, we show that human ratings on our benchmark exhibit high inter-annotator agreement and reflect the expected trend: larger models produce higher-quality simplifications. Second, we show that auto-evaluation with a panel of LLM judges (LLMs-as-a-jury) often suffices to obtain consistent ratings for the evaluation of text simplification. Third, we demonstrate that existing learnable metrics for text simplification benefit from training on our LLMs-as-a-jury-rated synthetic data, closing the gap with pure LLMs-as-a-jury for evaluation. Overall, through our case study on text simplification, we show that a reliable evaluation requires higher quality test data, which could be obtained through synthetic data and LLMs-as-a-jury ratings.","authors":["Joseph Liu","Yoonsoo Nam","Xinyue Cui","Swabha Swayamdipta"],"url":"https://arxiv.org/abs/2504.09394"}
{"created":"2025-04-15","title":"Adaptive Insurance Reserving with CVaR-Constrained Reinforcement Learning under Macroeconomic Regimes","abstract":"This paper proposes a reinforcement learning (RL) framework for insurance reserving that integrates tail-risk sensitivity, macroeconomic regime modeling, and regulatory compliance. The reserving problem is formulated as a finite-horizon Markov Decision Process (MDP), in which reserve adjustments are optimized using Proximal Policy Optimization (PPO) subject to Conditional Value-at-Risk (CVaR) constraints. To enhance policy robustness across varying economic conditions, the agent is trained using a regime-aware curriculum that progressively increases volatility exposure.","authors":["Stella C. Dong","James R. Finlay"],"url":"https://arxiv.org/abs/2504.09396"}
{"created":"2025-04-15","title":"Composable NLP Workflows for BERT-based Ranking and QA System","abstract":"There has been a lot of progress towards building NLP models that scale to multiple tasks. However, real-world systems contain multiple components and it is tedious to handle cross-task interaction with varying levels of text granularity. In this work, we built an end-to-end Ranking and Question-Answering (QA) system using Forte, a toolkit that makes composable NLP pipelines. We utilized state-of-the-art deep learning models such as BERT, RoBERTa in our pipeline, evaluated the performance on MS-MARCO and Covid-19 datasets using metrics such as BLUE, MRR, F1 and compared the results of ranking and QA systems with their corresponding benchmark results. The modular nature of our pipeline and low latency of reranker makes it easy to build complex NLP applications easily.","authors":["Gaurav Kumar","Murali Mohana Krishna Dandu"],"url":"https://arxiv.org/abs/2504.09398"}
{"created":"2025-04-15","title":"Question Tokens Deserve More Attention: Enhancing Large Language Models without Training through Step-by-Step Reading and Question Attention Recalibration","abstract":"Large Language Models (LLMs) often struggle with tasks that require a deep understanding of complex questions, especially when faced with long-range dependencies or multi-step reasoning. This work investigates the limitations of current LLMs in question comprehension and identifies three insights: (1) repeating question tokens improves comprehension by increasing attention to question regions, (2) increased backward dependencies negatively affect performance due to unidirectional attentional constraints, and (3) recalibrating attentional mechanisms to prioritize question-relevant regions improves performance.","authors":["Feijiang Han","Licheng Guo","Hengtao Cui","Zhiyuan Lyu"],"url":"https://arxiv.org/abs/2504.09402"}
{"created":"2025-04-15","title":"Tin-Tin: Towards Tiny Learning on Tiny Devices with Integer-based Neural Network Training","abstract":"Recent advancements in machine learning (ML) have enabled its deployment on resource-constrained edge devices, fostering innovative applications such as intelligent environmental sensing. However, these devices, particularly microcontrollers (MCUs), face substantial challenges due to limited memory, computing capabilities, and the absence of dedicated floating-point units (FPUs). These constraints hinder the deployment of complex ML models, especially those requiring lifelong learning capabilities. To address these challenges, we propose Tin-Tin, an integer-based on-device training framework designed specifically for low-power MCUs. Tin-Tin introduces novel integer rescaling techniques to efficiently manage dynamic ranges and facilitate efficient weight updates using integer data types. Unlike existing methods optimized for devices with FPUs, GPUs, or FPGAs, Tin-Tin addresses the unique demands of tiny MCUs, prioritizing energy efficiency and optimized memory utilization. We validate the effectiveness of Tin-Tin through end-to-end application examples on real-world tiny devices, demonstrating its potential to support energy-efficient and sustainable ML applications on edge platforms.","authors":["Yi Hu","Jinhang Zuo","Eddie Zhang","Bob Iannucci","Carlee Joe-Wong"],"url":"https://arxiv.org/abs/2504.09405"}
{"created":"2025-04-15","title":"UXAgent: A System for Simulating Usability Testing of Web Design with LLM Agents","abstract":"Usability testing is a fundamental research method that user experience (UX) researchers use to evaluate and iterate a web design, but\\textbf{ how to evaluate and iterate the usability testing study design } itself? Recent advances in Large Language Model-simulated Agent (\\textbf{LLM Agent}) research inspired us to design \\textbf{UXAgent} to support UX researchers in evaluating and reiterating their usability testing study design before they conduct the real human-subject study. Our system features a Persona Generator module, an LLM Agent module, and a Universal Browser Connector module to automatically generate thousands of simulated users to interactively test the target website. The system also provides an Agent Interview Interface and a Video Replay Interface so that the UX researchers can easily review and analyze the generated qualitative and quantitative log data. Through a heuristic evaluation, five UX researcher participants praised the innovation of our system but also expressed concerns about the future of LLM Agent usage in UX studies.","authors":["Yuxuan Lu","Bingsheng Yao","Hansu Gu","Jing Huang","Jessie Wang","Yang Li","Jiri Gesi","Qi He","Toby Jia-Jun Li","Dakuo Wang"],"url":"https://arxiv.org/abs/2504.09407"}
{"created":"2025-04-15","title":"Heterogeneous multiscale methods for fourth-order singular perturbations","abstract":"We develop a numerical homogenization method for fourth-order singular perturbation problems within the framework of heterogeneous multiscale method. These problems arise from heterogeneous strain gradient elasticity and elasticity models for architectured materials. We establish an error estimate for the homogenized solution applicable to general media and derive an explicit convergence for the locally periodic media with the fine-scale $\\varepsilon$. For cell problems of size $\\delta=\\mathbb{N}\\varepsilon$, the classical resonance error $\\mathcal{O}(\\varepsilon/\\delta)$ can be eliminated due to the dominance of the higher-order operator. Despite the occurrence of boundary layer effects, discretization errors do not necessarily deteriorate for general boundary conditions. Numerical simulations corroborate these theoretical findings.","authors":["Yulei Liao","Pingbing Ming"],"url":"https://arxiv.org/abs/2504.09410"}
{"created":"2025-04-15","title":"Scalable Motion In-betweening via Diffusion and Physics-Based Character Adaptation","abstract":"We propose a two-stage framework for motion in-betweening that combines diffusion-based motion generation with physics-based character adaptation. In Stage 1, a character-agnostic diffusion model synthesizes transitions from sparse keyframes on a canonical skeleton, allowing the same model to generalize across diverse characters. In Stage 2, a reinforcement learning-based controller adapts the canonical motion to the target character's morphology and dynamics, correcting artifacts and enhancing stylistic realism. This design supports scalable motion generation across characters with diverse skeletons without retraining the entire model. Experiments on standard benchmarks and stylized characters demonstrate that our method produces physically plausible, style-consistent motions under sparse and long-range constraints.","authors":["Jia Qin"],"url":"https://arxiv.org/abs/2504.09413"}
{"created":"2025-04-15","title":"Appointed-Time Fault-Tolerant Control for Flexible Hypersonic Vehicles with Unmeasurable States Independent of Initial Errors","abstract":"This article aims to derive a practical tracking control algorithm for flexible air-breathing hypersonic vehicles (FAHVs) with lumped disturbances, unmeasurable states and actuator failures. Based on the framework of the backstepping technique, an appointed-time fault-tolerant protocol independent of initial errors is proposed. Firstly, a new type of a state observer is constructed to reconstruct the unmeasurable states. Then, an error transformation function is designed to achieve prescribed performance control that does not depend on the initial tracking error. To deal with the actuator failures, practical fixed-time neural network observers are established to provide the estimation of the lumped disturbances. Finally, the proposed control strategy can ensure the practical fixed-time convergence of the closed-loop system, thereby greatly enhancing the transient performance. The proposed method addresses the challenges of ensuring real-time measurement accuracy for angle of attack and flight path angle in hypersonic vehicles, coupled with potential sudden actuator failures, effectively overcoming the drawback of prescribed performance control that requires knowledge of initial tracking errors. Some simulation results are provided to demonstrate the feasibility and the effectiveness of the proposed strategy","authors":["Tianlong Zhao","Fei Hao"],"url":"https://arxiv.org/abs/2504.09414"}
{"created":"2025-04-15","title":"Nash Equilibrium Between Consumer Electronic Devices and DoS Attacker for Distributed IoT-enabled RSE Systems","abstract":"In electronic consumer Internet of Things (IoT), consumer electronic devices as edge devices require less computational overhead and the remote state estimation (RSE) of consumer electronic devices is always at risk of denial-of-service (DoS) attacks. Therefore, the adversarial strategy between consumer electronic devices and DoS attackers is critical. This paper focuses on the adversarial strategy between consumer electronic devices and DoS attackers in IoT-enabled RSE Systems. We first propose a remote joint estimation model for distributed measurements to effectively reduce consumer electronic device workload and minimize data leakage risks. The Kalman filter is deployed on the remote estimator, and the DoS attacks with open-loop as well as closed-loop are considered. We further introduce advanced reinforcement learning techniques, including centralized and distributed Minimax-DQN, to address high-dimensional decision-making challenges in both open-loop and closed-loop scenarios. Especially, the Q-network instead of the Q-table is used in the proposed approaches, which effectively solves the challenge of Q-learning. Moreover, the proposed distributed Minimax-DQN reduces the action space to expedite the search for Nash Equilibrium (NE). The experimental results validate that the proposed model can expeditiously restore the RSE error covariance to a stable state in the presence of DoS attacks, exhibiting notable attack robustness. The proposed centralized and distributed Minimax-DQN effectively resolves the NE in both open and closed-loop case, showcasing remarkable performance in terms of convergence. It reveals that substantial advantages in both efficiency and stability are achieved compared with the state-of-the-art methods.","authors":["Gengcan Chen","Donghong Cai","Zahid Khan","Jawad Ahmad","Wadii Boulila"],"url":"https://arxiv.org/abs/2504.09415"}
{"created":"2025-04-15","title":"Spatially Directional Dual-Attention GAT for Spatial Fluoride Health Risk Modeling","abstract":"Environmental exposure to fluoride is a major public health concern, particularly in regions with naturally elevated fluoride concentrations. Accurate modeling of fluoride-related health risks, such as dental fluorosis, requires spatially aware learning frameworks capable of capturing both geographic and semantic heterogeneity. In this work, we propose Spatially Directional Dual-Attention Graph Attention Network (SDD-GAT), a novel spatial graph neural network designed for fine-grained health risk prediction. SDD-GAT introduces a dual-graph architecture that disentangles geographic proximity and attribute similarity, and incorporates a directional attention mechanism that explicitly encodes spatial orientation and distance into the message passing process. To further enhance spatial coherence, we introduce a spatial smoothness regularization term that enforces consistency in predictions across neighboring locations. We evaluate SDD-GAT on a large-scale dataset covering over 50,000 fluoride monitoring samples and fluorosis records across Guizhou Province, China. Results show that SDD-GAT significantly outperforms traditional models and state-of-the-art GNNs in both regression and classification tasks, while also exhibiting improved spatial autocorrelation as measured by Moran's I. Our framework provides a generalizable foundation for spatial health risk modeling and geospatial learning under complex environmental settings.","authors":["Da Yuan"],"url":"https://arxiv.org/abs/2504.09416"}
{"created":"2025-04-15","title":"SaRO: Enhancing LLM Safety through Reasoning-based Alignment","abstract":"Current safety alignment techniques for large language models (LLMs) face two key challenges: (1) under-generalization, which leaves models vulnerable to novel jailbreak attacks, and (2) over-alignment, which leads to the excessive refusal of benign instructions. Our preliminary investigation reveals semantic overlap between jailbreak/harmful queries and normal prompts in embedding space, suggesting that more effective safety alignment requires a deeper semantic understanding. This motivates us to incorporate safety-policy-driven reasoning into the alignment process. To this end, we propose the Safety-oriented Reasoning Optimization Framework (SaRO), which consists of two stages: (1) Reasoning-style Warmup (RW) that enables LLMs to internalize long-chain reasoning through supervised fine-tuning, and (2) Safety-oriented Reasoning Process Optimization (SRPO) that promotes safety reflection via direct preference optimization (DPO). Extensive experiments demonstrate the superiority of SaRO over traditional alignment methods.","authors":["Yutao Mou","Yuxiao Luo","Shikun Zhang","Wei Ye"],"url":"https://arxiv.org/abs/2504.09420"}
{"created":"2025-04-15","title":"ClinicalGPT-R1: Pushing reasoning capability of generalist disease diagnosis with large language model","abstract":"Recent advances in reasoning with large language models (LLMs)has shown remarkable reasoning capabilities in domains such as mathematics and coding, yet their application to clinical diagnosis remains underexplored. Here, we introduce ClinicalGPT-R1, a reasoning enhanced generalist large language model for disease diagnosis. Trained on a dataset of 20,000 real-world clinical records, ClinicalGPT-R1 leverages diverse training strategies to enhance diagnostic reasoning. To benchmark performance, we curated MedBench-Hard, a challenging dataset spanning seven major medical specialties and representative diseases. Experimental results demonstrate that ClinicalGPT-R1 outperforms GPT-4o in Chinese diagnostic tasks and achieves comparable performance to GPT-4 in English settings. This comparative study effectively validates the superior performance of ClinicalGPT-R1 in disease diagnosis tasks. Resources are available at https://github.com/medfound/medfound.","authors":["Wuyang Lan","Wenzheng Wang","Changwei Ji","Guoxing Yang","Yongbo Zhang","Xiaohong Liu","Song Wu","Guangyu Wang"],"url":"https://arxiv.org/abs/2504.09421"}
{"created":"2025-04-15","title":"Comparing Performance of Preprocessing Techniques for Traffic Sign Recognition Using a HOG-SVM","abstract":"This study compares the performance of various preprocessing techniques for Traffic Sign Recognition (TSR) using Histogram of Oriented Gradients (HOG) and Support Vector Machine (SVM) on the German Traffic Sign Recognition Benchmark (GTSRB) dataset. Techniques such as CLAHE, HUE, and YUV were evaluated for their impact on classification accuracy. Results indicate that YUV in particular significantly enhance the performance of the HOG-SVM classifier (improving accuracy from 89.65% to 91.25%), providing insights into improvements for preprocessing pipeline of TSR applications.","authors":["Luis Vieira"],"url":"https://arxiv.org/abs/2504.09424"}
{"created":"2025-04-15","title":"BabyVLM: Data-Efficient Pretraining of VLMs Inspired by Infant Learning","abstract":"Human infants rapidly develop visual reasoning skills from minimal input, suggesting that developmentally inspired pretraining could significantly enhance the efficiency of vision-language models (VLMs). Although recent efforts have leveraged infant-inspired datasets like SAYCam, existing evaluation benchmarks remain misaligned--they are either too simplistic, narrowly scoped, or tailored for large-scale pretrained models. Additionally, training exclusively on infant data overlooks the broader, diverse input from which infants naturally learn. To address these limitations, we propose BabyVLM, a novel framework comprising comprehensive in-domain evaluation benchmarks and a synthetic training dataset created via child-directed transformations of existing datasets. We demonstrate that VLMs trained with our synthetic dataset achieve superior performance on BabyVLM tasks compared to models trained solely on SAYCam or general-purpose data of the SAYCam size. BabyVLM thus provides a robust, developmentally aligned evaluation tool and illustrates how compact models trained on carefully curated data can generalize effectively, opening pathways toward data-efficient vision-language learning paradigms.","authors":["Shengao Wang","Arjun Chandra","Aoming Liu","Venkatesh Saligrama","Boqing Gong"],"url":"https://arxiv.org/abs/2504.09426"}
{"created":"2025-04-15","title":"Ensemble-Enhanced Graph Autoencoder with GAT and Transformer-Based Encoders for Robust Fault Diagnosis","abstract":"Fault classification in industrial machinery is vital for enhancing reliability and reducing downtime, yet it remains challenging due to the variability of vibration patterns across diverse operating conditions. This study introduces a novel graph-based framework for fault classification, converting time-series vibration data from machinery operating at varying horsepower levels into a graph representation. We utilize Shannon's entropy to determine the optimal window size for data segmentation, ensuring each segment captures significant temporal patterns, and employ Dynamic Time Warping (DTW) to define graph edges based on segment similarity. A Graph Auto Encoder (GAE) with a deep graph transformer encoder, decoder, and ensemble classifier is developed to learn latent graph representations and classify faults across various categories. The GAE's performance is evaluated on the Case Western Reserve University (CWRU) dataset, with cross-dataset generalization assessed on the HUST dataset. Results show that GAE achieves a mean F1-score of 0.99 on the CWRU dataset, significantly outperforming baseline models-CNN, LSTM, RNN, GRU, and Bi-LSTM (F1-scores: 0.94-0.97, p < 0.05, Wilcoxon signed-rank test for Bi-LSTM: p < 0.05) -- particularly in challenging classes (e.g., Class 8: 0.99 vs. 0.71 for Bi-LSTM). Visualization of dataset characteristics reveals that datasets with amplified vibration patterns and diverse fault dynamics enhance generalization. This framework provides a robust solution for fault diagnosis under varying conditions, offering insights into dataset impacts on model performance.","authors":["Moirangthem Tiken Singh"],"url":"https://arxiv.org/abs/2504.09427"}
{"created":"2025-04-15","title":"FROG: Effective Friend Recommendation in Online Games via Modality-aware User Preferences","abstract":"Due to the convenience of mobile devices, the online games have become an important part for user entertainments in reality, creating a demand for friend recommendation in online games. However, none of existing approaches can effectively incorporate the multi-modal user features (\\emph{e.g.}, images and texts) with the structural information in the friendship graph, due to the following limitations: (1) some of them ignore the high-order structural proximity between users, (2) some fail to learn the pairwise relevance between users at modality-specific level, and (3) some cannot capture both the local and global user preferences on different modalities. By addressing these issues, in this paper, we propose an end-to-end model \\textsc{FROG} that better models the user preferences on potential friends. Comprehensive experiments on both offline evaluation and online deployment at \\kw{Tencent} have demonstrated the superiority of \\textsc{FROG} over existing approaches.","authors":["Qiwei Wang","Dandan Lin","Wenqing Lin","Ziming Wu"],"url":"https://arxiv.org/abs/2504.09428"}
{"created":"2025-04-15","title":"Constants of motion network revisited","abstract":"Discovering constants of motion is meaningful in helping understand the dynamical systems, but inevitably needs proficient mathematical skills and keen analytical capabilities. With the prevalence of deep learning, methods employing neural networks, such as Constant Of Motion nETwork (COMET), are promising in handling this scientific problem. Although the COMET method can produce better predictions on dynamics by exploiting the discovered constants of motion, there is still plenty of room to sharpen it. In this paper, we propose a novel neural network architecture, built using the singular-value-decomposition (SVD) technique, and a two-phase training algorithm to improve the performance of COMET. Extensive experiments show that our approach not only retains the advantages of COMET, such as applying to non-Hamiltonian systems and indicating the number of constants of motion, but also can be more lightweight and noise-robust than COMET.","authors":["Wenqi Fang","Chao Chen","Yongkui Yang","Zheng Wang"],"url":"https://arxiv.org/abs/2504.09434"}
{"created":"2025-04-15","title":"Design Probes for AI-Driven AAC: Addressing Complex Communication Needs in Aphasia","abstract":"AI offers key advantages such as instant generation, multi-modal support, and personalized adaptability - potential that can address the highly heterogeneous communication barriers faced by people with aphasia (PWAs). We designed AI-enhanced communication tools and used them as design probes to explore how AI's real-time processing and generation capabilities - across text, image, and audio - can align with PWAs' needs in real-time communication and preparation for future conversations respectively. Through a two-phase \"Research through Design\" approach, eleven PWAs contributed design insights and evaluated four AI-enhanced prototypes. These prototypes aimed to improve communication grounding and conversational agency through visual verification, grammar construction support, error correction, and reduced language processing load. Despite some challenges, such as occasional mismatches with user intent, findings demonstrate how AI's specific capabilities can be advantageous in addressing PWAs' complex needs. Our work contributes design insights for future Augmentative and Alternative Communication (AAC) systems.","authors":["Lei Mao","Jong Ho Lee","Yasmeen Faroqi Shah","Stephanie Valencia"],"url":"https://arxiv.org/abs/2504.09435"}
{"created":"2025-04-15","title":"PLS-Assisted Offloading for Edge Computing-Enabled Post-Quantum Security in Resource-Constrained Devices","abstract":"With the advent of post-quantum cryptography (PQC) standards, it has become imperative for resource-constrained devices (RCDs) in the Internet of Things (IoT) to adopt these quantum-resistant protocols. However, the high computational overhead and the large key sizes associated with PQC make direct deployment on such devices impractical. To address this challenge, we propose an edge computing-enabled PQC framework that leverages a physical-layer security (PLS)-assisted offloading strategy, allowing devices to either offload intensive cryptographic tasks to a post-quantum edge server (PQES) or perform them locally. Furthermore, to ensure data confidentiality within the edge domain, our framework integrates two PLS techniques: offloading RCDs employ wiretap coding to secure data transmission, while non-offloading RCDs serve as friendly jammers by broadcasting artificial noise to disrupt potential eavesdroppers. Accordingly, we co-design the computation offloading and PLS strategy by jointly optimizing the device transmit power, PQES computation resource allocation, and offloading decisions to minimize overall latency under resource constraints. Numerical results demonstrate significant latency reductions compared to baseline schemes, confirming the scalability and efficiency of our approach for secure PQC operations in IoT networks.","authors":["Hamid Amiriara","Mahtab Mirmohseni","Rahim Tafazolli"],"url":"https://arxiv.org/abs/2504.09437"}
{"created":"2025-04-15","title":"Cartographers in Cubicles: How Training and Preferences of Mapmakers Interplay with Structures and Norms in Not-for-Profit Organizations","abstract":"Choropleth maps are a common and effective way to visualize geographic thematic data. Although cartographers have established many principles about map design, data binning and color usage, less is known about how mapmakers make individual decisions in practice. We interview 16 cartographers and geographic information systems (GIS) experts from 13 government organizations, NGOs, and federal agencies about their choropleth mapmaking decisions and workflows. We categorize our findings and report on how mapmakers follow cartographic guidelines and personal rules of thumb, collaborate with other stakeholders within and outside their organization, and how organizational structures and norms are tied to decision-making during data preparation, data analysis, data binning, map styling, and map post-processing. We find several points of variation as well as regularity across mapmakers and organizations and present takeaways to inform cartographic education and practice, including broader implications and opportunities for CSCW, HCI, and information visualization researchers and practitioners.","authors":["Arpit Narechania","Alex Endert","Clio Andris"],"url":"https://arxiv.org/abs/2504.09438"}
{"created":"2025-04-15","title":"Identity-Aware Vision-Language Model for Explainable Face Forgery Detection","abstract":"Recent advances in generative artificial intelligence have enabled the creation of highly realistic image forgeries, raising significant concerns about digital media authenticity. While existing detection methods demonstrate promising results on benchmark datasets, they face critical limitations in real-world applications. First, existing detectors typically fail to detect semantic inconsistencies with the person's identity, such as implausible behaviors or incompatible environmental contexts in given images. Second, these methods rely heavily on low-level visual cues, making them effective for known forgeries but less reliable against new or unseen manipulation techniques. To address these challenges, we present a novel personalized vision-language model (VLM) that integrates low-level visual artifact analysis and high-level semantic inconsistency detection. Unlike previous VLM-based methods, our approach avoids resource-intensive supervised fine-tuning that often struggles to preserve distinct identity characteristics. Instead, we employ a lightweight method that dynamically encodes identity-specific information into specialized identifier tokens. This design enables the model to learn distinct identity characteristics while maintaining robust generalization capabilities. We further enhance detection capabilities through a lightweight detection adapter that extracts fine-grained information from shallow features of the vision encoder, preserving critical low-level evidence. Comprehensive experiments demonstrate that our approach achieves 94.25% accuracy and 94.08% F1 score, outperforming both traditional forgery detectors and general VLMs while requiring only 10 extra tokens.","authors":["Junhao Xu","Jingjing Chen","Yang Jiao","Jiacheng Zhang","Zhiyu Tan","Hao Li","Yu-Gang Jiang"],"url":"https://arxiv.org/abs/2504.09439"}
{"created":"2025-04-15","title":"Enhancing Mathematical Reasoning in Large Language Models with Self-Consistency-Based Hallucination Detection","abstract":"Large language models (LLMs) have demonstrated strong mathematical reasoning capabilities but remain susceptible to hallucinations producing plausible yet incorrect statements especially in theorem proving, symbolic manipulation, and numerical computation. While self-consistency (SC) has been explored as a means to improve factuality in LLMs, existing approaches primarily apply SC to final-answer selection, neglecting the logical consistency of intermediate reasoning steps. In this work, we introduce a structured self-consistency framework designed to enhance the reliability of mathematical reasoning. Our method enforces self-consistency across intermediate steps and final outputs, reducing logical inconsistencies and hallucinations. We evaluate our approach across three core mathematical tasks: theorem proving, symbolic transformation, and numerical computation. Experimental results demonstrate that SC significantly improves proof validity, symbolic reasoning accuracy, and numerical stability while maintaining computational efficiency. Further analysis reveals that structured self-consistency not only enhances problem-solving accuracy but also reduces the variance of model-generated outputs. These findings highlight self-consistency as a robust mechanism for improving mathematical reasoning in LLMs, paving the way for more reliable and interpretable AI-driven mathematics.","authors":["MingShan Liu","Shi Bo","Jialing Fang"],"url":"https://arxiv.org/abs/2504.09440"}
{"created":"2025-04-15","title":"Structure-Accurate Medical Image Translation based on Dynamic Frequency Balance and Knowledge Guidance","abstract":"Multimodal medical images play a crucial role in the precise and comprehensive clinical diagnosis. Diffusion model is a powerful strategy to synthesize the required medical images. However, existing approaches still suffer from the problem of anatomical structure distortion due to the overfitting of high-frequency information and the weakening of low-frequency information. Thus, we propose a novel method based on dynamic frequency balance and knowledge guidance. Specifically, we first extract the low-frequency and high-frequency components by decomposing the critical features of the model using wavelet transform. Then, a dynamic frequency balance module is designed to adaptively adjust frequency for enhancing global low-frequency features and effective high-frequency details as well as suppressing high-frequency noise. To further overcome the challenges posed by the large differences between different medical modalities, we construct a knowledge-guided mechanism that fuses the prior clinical knowledge from a visual language model with visual features, to facilitate the generation of accurate anatomical structures. Experimental evaluations on multiple datasets show the proposed method achieves significant improvements in qualitative and quantitative assessments, verifying its effectiveness and superiority.","authors":["Jiahua Xu","Dawei Zhou","Lei Hu","Zaiyi Liu","Nannan Wang","Xinbo Gao"],"url":"https://arxiv.org/abs/2504.09441"}
{"created":"2025-04-15","title":"Sparse Deformable Mamba for Hyperspectral Image Classification","abstract":"Although the recent Mamba models significantly improve hyperspectral image (HSI) classification, one critical challenge is caused by the difficulty to build the Mamba sequence efficiently and effectively. This paper presents a Sparse Deformable Mamba (SDMamba) approach for enhanced HSI classification, with the following contributions. First, to enhance Mamba sequence, an efficient Sparse Deformable Sequencing (SDS) approach is designed to adaptively learn the \"optimal\" sequence, leading to sparse and deformable Mamba sequence with increased detail preservation and decreased computations. Second, to boost spatial-spectral feature learning, based on SDS, a Sparse Deformable Spatial Mamba Module (SDSpaM) and a Sparse Deformable Spectral Mamba Module (SDSpeM) are designed for tailored modeling of the spatial information spectral information. Last, to improve the fusion of SDSpaM and SDSpeM, an attention based feature fusion approach is designed to integrate the outputs of the SDSpaM and SDSpeM. The proposed method is tested on several benchmark datasets with many state-of-the-art approaches, demonstrating that the proposed approach can achieve higher accuracy, faster speed, and better detail small-class preservation capability.","authors":["Lincoln Linlin Xu","Yimin Zhu","Zack Dewis","Zhengsen Xu","Motasem Alkayid","Mabel Heffring","Saeid Taleghanidoozdoozan"],"url":"https://arxiv.org/abs/2504.09446"}
{"created":"2025-04-15","title":"InfoBound: A Provable Information-Bounds Inspired Framework for Both OoD Generalization and OoD Detection","abstract":"In real-world scenarios, distribution shifts give rise to the importance of two problems: out-of-distribution (OoD) generalization, which focuses on models' generalization ability against covariate shifts (i.e., the changes of environments), and OoD detection, which aims to be aware of semantic shifts (i.e., test-time unseen classes). Real-world testing environments often involve a combination of both covariate and semantic shifts. While numerous methods have been proposed to address these critical issues, only a few works tackled them simultaneously. Moreover, prior works often improve one problem but sacrifice the other. To overcome these limitations, we delve into boosting OoD detection and OoD generalization from the perspective of information theory, which can be easily applied to existing models and different tasks. Building upon the theoretical bounds for mutual information and conditional entropy, we provide a unified approach, composed of Mutual Information Minimization (MI-Min) and Conditional Entropy Maximizing (CE-Max). Extensive experiments and comprehensive evaluations on multi-label image classification and object detection have demonstrated the superiority of our method. It successfully mitigates trade-offs between the two challenges compared to competitive baselines.","authors":["Lin Zhu","Yifeng Yang","Zichao Nie","Yuan Gao","Jiarui Li","Qinying Gu","Xinbing Wang","Chenghu Zhou","Nanyang Ye"],"url":"https://arxiv.org/abs/2504.09448"}
{"created":"2025-04-15","title":"aweSOM: a CPU/GPU-accelerated Self-organizing Map and Statistically Combined Ensemble Framework for Machine-learning Clustering Analysis","abstract":"We introduce aweSOM, an open-source Python package for machine learning (ML) clustering and classification, using a Self-organizing Maps (SOM) algorithm that incorporates CPU/GPU acceleration to accommodate large ($N > 10^6$, where $N$ is the number of data points), multidimensional datasets. aweSOM consists of two main modules, one that handles the initialization and training of the SOM, and another that stacks the results of multiple SOM realizations to obtain more statistically robust clusters. Existing Python-based SOM implementations (e.g., POPSOM, Yuan (2018); MiniSom, Vettigli (2018); sklearn-som) primarily serve as proof-of-concept demonstrations, optimized for smaller datasets, but lacking scalability for large, multidimensional data. aweSOM provides a solution for this gap in capability, with good performance scaling up to $\\sim 10^8$ individual points, and capable of utilizing multiple features per point. We compare the code performance against the legacy implementations it is based on, and find a 10-100x speed up, as well as significantly improved memory efficiency, due to several built-in optimizations.","authors":["Trung Ha","Joonas N\\\"attil\\\"a","Jordy Davelaar"],"url":"https://arxiv.org/abs/2504.09449"}
{"created":"2025-04-15","title":"FractalForensics: Proactive Deepfake Detection and Localization via Fractal Watermarks","abstract":"Proactive Deepfake detection via robust watermarks has been raised ever since passive Deepfake detectors encountered challenges in identifying high-quality synthetic images. However, while demonstrating reasonable detection performance, they lack localization functionality and explainability in detection results. Additionally, the unstable robustness of watermarks can significantly affect the detection performance accordingly. In this study, we propose novel fractal watermarks for proactive Deepfake detection and localization, namely FractalForensics. Benefiting from the characteristics of fractals, we devise a parameter-driven watermark generation pipeline that derives fractal-based watermarks and conducts one-way encryption regarding the parameters selected. Subsequently, we propose a semi-fragile watermarking framework for watermark embedding and recovery, trained to be robust against benign image processing operations and fragile when facing Deepfake manipulations in a black-box setting. Meanwhile, we introduce an entry-to-patch strategy that implicitly embeds the watermark matrix entries into image patches at corresponding positions, achieving localization of Deepfake manipulations. Extensive experiments demonstrate satisfactory robustness and fragility of our approach against common image processing operations and Deepfake manipulations, outperforming state-of-the-art semi-fragile watermarking algorithms and passive detectors for Deepfake detection. Furthermore, by highlighting the areas manipulated, our method provides explainability for the proactive Deepfake detection results.","authors":["Tianyi Wang","Harry Cheng","Ming-Hui Liu","Mohan Kankanhalli"],"url":"https://arxiv.org/abs/2504.09451"}
{"created":"2025-04-15","title":"Stong order 1 adaptive approximation of jump-diffusion SDEs with discontinuous drift","abstract":"We present an adaptive approximation scheme for jump-diffusion SDEs with discontinuous drift and (possibly) degenerate diffusion. This transformation-based doubly-adaptive quasi-Milstein scheme is the first scheme that has strong convergence rate $1$ in $L^p$ for $p\\in[1,\\infty)$ with respect to the average computational cost for these SDEs. To obtain our result, we prove that under slightly stronger assumptions which are still weaker than those in existing literature, a related doubly-adaptive quasi-Milstein scheme has convergence order $1$. This scheme is doubly-adaptive in the sense that it is jump-adapted, i.e.~all jump times of the Poisson noise are grid points, and it includes an adaptive stepsize strategy to account for the discontinuities of the drift.","authors":["Verena Schwarz"],"url":"https://arxiv.org/abs/2504.09452"}
{"created":"2025-04-15","title":"D$^2$iT: Dynamic Diffusion Transformer for Accurate Image Generation","abstract":"Diffusion models are widely recognized for their ability to generate high-fidelity images. Despite the excellent performance and scalability of the Diffusion Transformer (DiT) architecture, it applies fixed compression across different image regions during the diffusion process, disregarding the naturally varying information densities present in these regions. However, large compression leads to limited local realism, while small compression increases computational complexity and compromises global consistency, ultimately impacting the quality of generated images. To address these limitations, we propose dynamically compressing different image regions by recognizing the importance of different regions, and introduce a novel two-stage framework designed to enhance the effectiveness and efficiency of image generation: (1) Dynamic VAE (DVAE) at first stage employs a hierarchical encoder to encode different image regions at different downsampling rates, tailored to their specific information densities, thereby providing more accurate and natural latent codes for the diffusion process. (2) Dynamic Diffusion Transformer (D$^2$iT) at second stage generates images by predicting multi-grained noise, consisting of coarse-grained (less latent code in smooth regions) and fine-grained (more latent codes in detailed regions), through an novel combination of the Dynamic Grain Transformer and the Dynamic Content Transformer. The strategy of combining rough prediction of noise with detailed regions correction achieves a unification of global consistency and local realism. Comprehensive experiments on various generation tasks validate the effectiveness of our approach. Code will be released at https://github.com/jiawn-creator/Dynamic-DiT.","authors":["Weinan Jia","Mengqi Huang","Nan Chen","Lei Zhang","Zhendong Mao"],"url":"https://arxiv.org/abs/2504.09454"}
{"created":"2025-04-15","title":"Enhancing Wide-Angle Image Using Narrow-Angle View of the Same Scene","abstract":"A common dilemma while photographing a scene is whether to capture it in wider angle, allowing more of the scene to be covered but in lesser details or to click in narrow angle that captures better details but leaves out portions of the scene. We propose a novel method in this paper that infuses wider shots with finer quality details that is usually associated with an image captured by the primary lens by capturing the same scene using both narrow and wide field of view (FoV) lenses. We do so by training a GAN-based model to learn to extract the visual quality parameters from a narrow angle shot and to transfer these to the corresponding wide-angle image of the scene. We have mentioned in details the proposed technique to isolate the visual essence of an image and to transfer it into another image. We have also elaborately discussed our implementation details and have presented the results of evaluation over several benchmark datasets and comparisons with contemporary advancements in the field.","authors":["Hussain Md. Safwan","Mahbub Islam Mahim","Fawwaz Mohammed Amin"],"url":"https://arxiv.org/abs/2504.09455"}
{"created":"2025-04-15","title":"Don't Deceive Me: Mitigating Gaslighting through Attention Reallocation in LMMs","abstract":"Large Multimodal Models (LMMs) have demonstrated remarkable capabilities across a wide range of tasks. However, their vulnerability to user gaslighting-the deliberate use of misleading or contradictory inputs-raises critical concerns about their reliability in real-world applications. In this paper, we address the novel and challenging issue of mitigating the negative impact of negation-based gaslighting on LMMs, where deceptive user statements lead to significant drops in model accuracy. Specifically, we introduce GasEraser, a training-free approach that reallocates attention weights from misleading textual tokens to semantically salient visual regions. By suppressing the influence of \"attention sink\" tokens and enhancing focus on visually grounded cues, GasEraser significantly improves LMM robustness without requiring retraining or additional supervision. Extensive experimental results demonstrate that GasEraser is effective across several leading open-source LMMs on the GaslightingBench. Notably, for LLaVA-v1.5-7B, GasEraser reduces the misguidance rate by 48.2%, demonstrating its potential for more trustworthy LMMs.","authors":["Pengkun Jiao","Bin Zhu","Jingjing Chen","Chong-Wah Ngo","Yu-Gang Jiang"],"url":"https://arxiv.org/abs/2504.09456"}
{"created":"2025-04-15","title":"The Whitney method of fundamental solutions with Lusin wavelets","abstract":"We establish the theoretical foundation for a variant of the method of fundamental solutions (MFS), where the source points $\\{q_j\\}_{j=1}^\\infty$ accumulate towards the domain in a Whitney fashion, meaning that their separation is proportional to the distance to the domain. We prove that the normalized Lusin wavelets $\\psi_j(w) = b_j(w-q_j)^{-2}$ constitute a generalized basis, known as a frame, for the Hardy subspace of $L_2$-traces of holomorphic functions on the domain. Consequently, our method, where $\\psi_j$ are used as basis functions in the MFS, enables a numerically stable approximation of solutions to Laplace boundary value problems, even when the solutions lack analytic continuation across the boundary. Despite the source points accumulating towards the domain, our computations show no loss of accuracy near the boundary, in contrast to the boundary integral equation method.","authors":["Jakob Jonsson","Andreas Ros\\'en","Emil Timlin"],"url":"https://arxiv.org/abs/2504.09458"}
{"created":"2025-04-15","title":"Measuring Leakage in Concept-Based Methods: An Information Theoretic Approach","abstract":"Concept Bottleneck Models (CBMs) aim to enhance interpretability by structuring predictions around human-understandable concepts. However, unintended information leakage, where predictive signals bypass the concept bottleneck, compromises their transparency. This paper introduces an information-theoretic measure to quantify leakage in CBMs, capturing the extent to which concept embeddings encode additional, unintended information beyond the specified concepts. We validate the measure through controlled synthetic experiments, demonstrating its effectiveness in detecting leakage trends across various configurations. Our findings highlight that feature and concept dimensionality significantly influence leakage, and that classifier choice impacts measurement stability, with XGBoost emerging as the most reliable estimator. Additionally, preliminary investigations indicate that the measure exhibits the anticipated behavior when applied to soft joint CBMs, suggesting its reliability in leakage quantification beyond fully synthetic settings. While this study rigorously evaluates the measure in controlled synthetic experiments, future work can extend its application to real-world datasets.","authors":["Mikael Makonnen","Moritz Vandenhirtz","Sonia Laguna","Julia E Vogt"],"url":"https://arxiv.org/abs/2504.09459"}
{"created":"2025-04-15","title":"ADDT -- A Digital Twin Framework for Proactive Safety Validation in Autonomous Driving Systems","abstract":"Autonomous driving systems continue to face safety-critical failures, often triggered by rare and unpredictable corner cases that evade conventional testing. We present the Autonomous Driving Digital Twin (ADDT) framework, a high-fidelity simulation platform designed to proactively identify hidden faults, evaluate real-time performance, and validate safety before deployment. ADDT combines realistic digital models of driving environments, vehicle dynamics, sensor behavior, and fault conditions to enable scalable, scenario-rich stress-testing under diverse and adverse conditions. It supports adaptive exploration of edge cases using reinforcement-driven techniques, uncovering failure modes that physical road testing often misses. By shifting from reactive debugging to proactive simulation-driven validation, ADDT enables a more rigorous and transparent approach to autonomous vehicle safety engineering. To accelerate adoption and facilitate industry-wide safety improvements, the entire ADDT framework has been released as open-source software, providing developers with an accessible and extensible tool for comprehensive safety testing at scale.","authors":["Bo Yu","Chaoran Yuan","Zishen Wan","Jie Tang","Fadi Kurdahi","Shaoshan Liu"],"url":"https://arxiv.org/abs/2504.09461"}
{"created":"2025-04-15","title":"Comorbidity-Informed Transfer Learning for Neuro-developmental Disorder Diagnosis","abstract":"Neuro-developmental disorders are manifested as dysfunctions in cognition, communication, behaviour and adaptability, and deep learning-based computer-aided diagnosis (CAD) can alleviate the increasingly strained healthcare resources on neuroimaging. However, neuroimaging such as fMRI contains complex spatio-temporal features, which makes the corresponding representations susceptible to a variety of distractions, thus leading to less effective in CAD. For the first time, we present a Comorbidity-Informed Transfer Learning(CITL) framework for diagnosing neuro-developmental disorders using fMRI. In CITL, a new reinforced representation generation network is proposed, which first combines transfer learning with pseudo-labelling to remove interfering patterns from the temporal domain of fMRI and generates new representations using encoder-decoder architecture. The new representations are then trained in an architecturally simple classification network to obtain CAD model. In particular, the framework fully considers the comorbidity mechanisms of neuro-developmental disorders and effectively integrates them with semi-supervised learning and transfer learning, providing new perspectives on interdisciplinary. Experimental results demonstrate that CITL achieves competitive accuracies of 76.32% and 73.15% for detecting autism spectrum disorder and attention deficit hyperactivity disorder, respectively, which outperforms existing related transfer learning work for 7.2% and 0.5% respectively.","authors":["Xin Wen","Shijie Guo","Wenbo Ning","Rui Cao","Jie Xiang","Xiaobo Liu","Jintai Chen"],"url":"https://arxiv.org/abs/2504.09463"}
{"created":"2025-04-15","title":"Evolutionary Defense: Advancing Moving Target Strategies with Bio-Inspired Reinforcement Learning to Secure Misconfigured Software Applications","abstract":"Improper configurations in software systems often create vulnerabilities, leaving them open to exploitation. Static architectures exacerbate this issue by allowing misconfigurations to persist, providing adversaries with opportunities to exploit them during attacks. To address this challenge, a dynamic proactive defense strategy known as Moving Target Defense (MTD) can be applied. MTD continually changes the attack surface of the system, thwarting potential threats. In the previous research, we developed a proof of concept for a single-player MTD game model called RL-MTD, which utilizes Reinforcement Learning (RL) to generate dynamic secure configurations. While the model exhibited satisfactory performance in generating secure configurations, it grappled with an unoptimized and sparse search space, leading to performance issues. To tackle this obstacle, this paper addresses the search space optimization problem by leveraging two bio-inspired search algorithms: Genetic Algorithm (GA) and Particle Swarm Optimization (PSO). Additionally, we extend our base RL-MTD model by integrating these algorithms, resulting in the creation of PSO-RL andGA-RL. We compare the performance of three models: base RL-MTD, GA-RL, and PSO-RL, across four misconfigured SUTs in terms of generating the most secure configuration. Results show that the optimal search space derived from both GA-RL and PSO-RL significantly enhances the performance of the base RL-MTD model compared to the version without optimized search space. While both GA-RL and PSO-RL demonstrate effective search capabilities, PSO-RL slightly outperforms GA-RL for most SUTs. Overall, both algorithms excel in seeking an optimal search space which in turn improves the performance of the model in generating optimal secure configuration.","authors":["Niloofar Heidarikohol","Shuvalaxmi Dass","Akbar Siami Namin"],"url":"https://arxiv.org/abs/2504.09465"}
{"created":"2025-04-15","title":"AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender","abstract":"Despite extensive efforts in safety alignment, large language models (LLMs) remain vulnerable to jailbreak attacks. Activation steering offers a training-free defense method but relies on fixed steering coefficients, resulting in suboptimal protection and increased false rejections of benign inputs. To address this, we propose AdaSteer, an adaptive activation steering method that dynamically adjusts model behavior based on input characteristics. We identify two key properties: Rejection Law (R-Law), which shows that stronger steering is needed for jailbreak inputs opposing the rejection direction, and Harmfulness Law (H-Law), which differentiates adversarial and benign inputs. AdaSteer steers input representations along both the Rejection Direction (RD) and Harmfulness Direction (HD), with adaptive coefficients learned via logistic regression, ensuring robust jailbreak defense while preserving benign input handling. Experiments on LLaMA-3.1, Gemma-2, and Qwen2.5 show that AdaSteer outperforms baseline methods across multiple jailbreak attacks with minimal impact on utility. Our results highlight the potential of interpretable model internals for real-time, flexible safety enforcement in LLMs.","authors":["Weixiang Zhao","Jiahe Guo","Yulin Hu","Yang Deng","An Zhang","Xingyu Sui","Xinyang Han","Yanyan Zhao","Bing Qin","Tat-Seng Chua","Ting Liu"],"url":"https://arxiv.org/abs/2504.09466"}
{"created":"2025-04-15","title":"Incubation and Beyond: A Comparative Analysis of ASF Projects Sustainability Impacts on Software Quality","abstract":"Free and Open Source Software (FOSS) communities' sustainability, meaning to remain operational without signs of weakening or interruptions to its development, is fundamental for the resilience and continuity of society's digital infrastructure. Many digital services and products either leverage or entirely rely on FOSS in their software stack. FOSS sustainability is a multifaceted concept, and the impact of its decline on community products is less known. In this study, we sought to understand how the different aspects of FOSS sustainability impact software quality from a life-cycle perspective. Specifically, we investigate whether and how support and incubation of FOSS projects or bypassing incubation correlate with software quality outcomes. We selected 342 FOSS projects from the Apache Software Foundation that have either graduated, retired, or bypassed their incubator program. We used 16 sustainability metrics to examine their impact on eight software quality metrics. Using Bayesian data analysis, we found that our selected sustainability metrics exhibit distinct relationships with software quality across different project trajectories. Graduated projects showed the strongest sustainability-software quality (SWQ) relationship, both during and post-incubation. In contrast, retired projects showed weaker relationships, despite receiving similar governance support. Bypassed projects, while not outperforming graduated ones, showed comparable sustainability-SWQ relationships. While structured incubation strengthens sustainability and SWQ in graduated projects, retired projects struggle to maintain strong sustainability-SWQ relationships, indicating that additional factors internal and specific to projects influence sustainability. This effect was evident among bypassed projects; their self-reliant sustainability practices yielded stronger sustainability-SWQ compared to the retired ones.","authors":["Adam Alami","Steffan Klockmann","Lasse Rehder S{\\o}rensen","Ra\\'ul Pardo","Johan Lin\\r{a}ker"],"url":"https://arxiv.org/abs/2504.09468"}
{"created":"2025-04-15","title":"CamMimic: Zero-Shot Image To Camera Motion Personalized Video Generation Using Diffusion Models","abstract":"We introduce CamMimic, an innovative algorithm tailored for dynamic video editing needs. It is designed to seamlessly transfer the camera motion observed in a given reference video onto any scene of the user's choice in a zero-shot manner without requiring any additional data. Our algorithm achieves this using a two-phase strategy by leveraging a text-to-video diffusion model. In the first phase, we develop a multi-concept learning method using a combination of LoRA layers and an orthogonality loss to capture and understand the underlying spatial-temporal characteristics of the reference video as well as the spatial features of the user's desired scene. The second phase proposes a unique homography-based refinement strategy to enhance the temporal and spatial alignment of the generated video. We demonstrate the efficacy of our method through experiments conducted on a dataset containing combinations of diverse scenes and reference videos containing a variety of camera motions. In the absence of an established metric for assessing camera motion transfer between unrelated scenes, we propose CameraScore, a novel metric that utilizes homography representations to measure camera motion similarity between the reference and generated videos. Extensive quantitative and qualitative evaluations demonstrate that our approach generates high-quality, motion-enhanced videos. Additionally, a user study reveals that 70.31% of participants preferred our method for scene preservation, while 90.45% favored it for motion transfer. We hope this work lays the foundation for future advancements in camera motion transfer across different scenes.","authors":["Pooja Guhan","Divya Kothandaraman","Tsung-Wei Huang","Guan-Ming Su","Dinesh Manocha"],"url":"https://arxiv.org/abs/2504.09472"}
{"created":"2025-04-15","title":"MigGPT: Harnessing Large Language Models for Automated Migration of Out-of-Tree Linux Kernel Patches Across Versions","abstract":"Out-of-tree kernel patches are essential for adapting the Linux kernel to new hardware or enabling specific functionalities. Maintaining and updating these patches across different kernel versions demands significant effort from experienced engineers. Large language models (LLMs) have shown remarkable progress across various domains, suggesting their potential for automating out-of-tree kernel patch migration. However, our findings reveal that LLMs, while promising, struggle with incomplete code context understanding and inaccurate migration point identification. In this work, we propose MigGPT, a framework that employs a novel code fingerprint structure to retain code snippet information and incorporates three meticulously designed modules to improve the migration accuracy and efficiency of out-of-tree kernel patches. Furthermore, we establish a robust benchmark using real-world out-of-tree kernel patch projects to evaluate LLM capabilities. Evaluations show that MigGPT significantly outperforms the direct application of vanilla LLMs, achieving an average completion rate of 72.59% (50.74% improvement) for migration tasks.","authors":["Pucheng Dang","Di Huang","Dong Li","Kang Chen","Yuanbo Wen","Qi Guo","Xing Hu","Ninghui Sun"],"url":"https://arxiv.org/abs/2504.09474"}
{"created":"2025-04-15","title":"Cloud Uptime Archive: Open-Access Availability Data of Web, Cloud, and Gaming Services","abstract":"Cloud services are critical to society. However, their reliability is poorly understood. Towards solving the problem, we propose a standard repository for cloud uptime data. We populate this repository with the data we collect containing failure reports from users and operators of cloud services, web services, and online games. The multiple vantage points help reduce bias from individual users and operators. We compare our new data to existing failure data from the Failure Trace Archive and the Google cluster trace.","authors":["Sacheendra Talluri","Dante Niewenhuis","Xiaoyu Chu","Jakob Kyselica","Mehmet Cetin","Alexander Balgavy","Alexandru Iosup"],"url":"https://arxiv.org/abs/2504.09476"}
{"created":"2025-04-15","title":"A highly maneuverable flying squirrel drone with controllable foldable wings","abstract":"Typical drones with multi rotors are generally less maneuverable due to unidirectional thrust, which may be unfavorable to agile flight in very narrow and confined spaces. This paper suggests a new bio-inspired drone that is empowered with high maneuverability in a lightweight and easy-to-carry way. The proposed flying squirrel inspired drone has controllable foldable wings to cover a wider range of flight attitudes and provide more maneuverable flight capability with stable tracking performance. The wings of a drone are fabricated with silicone membranes and sophisticatedly controlled by reinforcement learning based on human-demonstrated data. Specially, such learning based wing control serves to capture even the complex aerodynamics that are often impossible to model mathematically. It is shown through experiment that the proposed flying squirrel drone intentionally induces aerodynamic drag and hence provides the desired additional repulsive force even under saturated mechanical thrust. This work is very meaningful in demonstrating the potential of biomimicry and machine learning for realizing an animal-like agile drone.","authors":["Jun-Gill Kang","Dohyeon Lee","Soohee Han"],"url":"https://arxiv.org/abs/2504.09478"}
{"created":"2025-04-15","title":"Draw with Thought: Unleashing Multimodal Reasoning for Scientific Diagram Generation","abstract":"Scientific diagrams are vital tools for communicating structured knowledge across disciplines. However, they are often published as static raster images, losing symbolic semantics and limiting reuse. While Multimodal Large Language Models (MLLMs) offer a pathway to bridging vision and structure, existing methods lack semantic control and structural interpretability, especially on complex diagrams. We propose Draw with Thought (DwT), a training-free framework that guides MLLMs to reconstruct diagrams into editable mxGraph XML code through cognitively-grounded Chain-of-Thought reasoning. DwT enables interpretable and controllable outputs without model fine-tuning by dividing the task into two stages: Coarse-to-Fine Planning, which handles perceptual structuring and semantic specification, and Structure-Aware Code Generation, enhanced by format-guided refinement. To support evaluation, we release Plot2XML, a benchmark of 247 real-world scientific diagrams with gold-standard XML annotations. Extensive experiments across eight MLLMs show that our approach yields high-fidelity, semantically aligned, and structurally valid reconstructions, with human evaluations confirming strong alignment in both accuracy and visual aesthetics, offering a scalable solution for converting static visuals into executable representations and advancing machine understanding of scientific graphics.","authors":["Zhiqing Cui","Jiahao Yuan","Hanqing Wang","Yanshu Li","Chenxu Du","Zhenglong Ding"],"url":"https://arxiv.org/abs/2504.09479"}
{"created":"2025-04-15","title":"Vision-Language Model for Object Detection and Segmentation: A Review and Evaluation","abstract":"Vision-Language Model (VLM) have gained widespread adoption in Open-Vocabulary (OV) object detection and segmentation tasks. Despite they have shown promise on OV-related tasks, their effectiveness in conventional vision tasks has thus far been unevaluated. In this work, we present the systematic review of VLM-based detection and segmentation, view VLM as the foundational model and conduct comprehensive evaluations across multiple downstream tasks for the first time: 1) The evaluation spans eight detection scenarios (closed-set detection, domain adaptation, crowded objects, etc.) and eight segmentation scenarios (few-shot, open-world, small object, etc.), revealing distinct performance advantages and limitations of various VLM architectures across tasks. 2) As for detection tasks, we evaluate VLMs under three finetuning granularities: \\textit{zero prediction}, \\textit{visual fine-tuning}, and \\textit{text prompt}, and further analyze how different finetuning strategies impact performance under varied task. 3) Based on empirical findings, we provide in-depth analysis of the correlations between task characteristics, model architectures, and training methodologies, offering insights for future VLM design. 4) We believe that this work shall be valuable to the pattern recognition experts working in the fields of computer vision, multimodal learning, and vision foundation models by introducing them to the problem, and familiarizing them with the current status of the progress while providing promising directions for future research. A project associated with this review and evaluation has been created at https://github.com/better-chao/perceptual_abilities_evaluation.","authors":["Yongchao Feng","Yajie Liu","Shuai Yang","Wenrui Cai","Jinqing Zhang","Qiqi Zhan","Ziyue Huang","Hongxi Yan","Qiao Wan","Chenguang Liu","Junzhe Wang","Jiahui Lv","Ziqi Liu","Tengyuan Shi","Qingjie Liu","Yunhong Wang"],"url":"https://arxiv.org/abs/2504.09480"}
{"created":"2025-04-15","title":"Rethinking the generalization of drug target affinity prediction algorithms via similarity aware evaluation","abstract":"Drug-target binding affinity prediction is a fundamental task for drug discovery. It has been extensively explored in literature and promising results are reported. However, in this paper, we demonstrate that the results may be misleading and cannot be well generalized to real practice. The core observation is that the canonical randomized split of a test set in conventional evaluation leaves the test set dominated by samples with high similarity to the training set. The performance of models is severely degraded on samples with lower similarity to the training set but the drawback is highly overlooked in current evaluation. As a result, the performance can hardly be trusted when the model meets low-similarity samples in real practice. To address this problem, we propose a framework of similarity aware evaluation in which a novel split methodology is proposed to adapt to any desired distribution. This is achieved by a formulation of optimization problems which are approximately and efficiently solved by gradient descent. We perform extensive experiments across five representative methods in four datasets for two typical target evaluations and compare them with various counterpart methods. Results demonstrate that the proposed split methodology can significantly better fit desired distributions and guide the development of models. Code is released at https://github.com/Amshoreline/SAE/tree/main.","authors":["Chenbin Zhang","Zhiqiang Hu","Chuchu Jiang","Wen Chen","Jie Xu","Shaoting Zhang"],"url":"https://arxiv.org/abs/2504.09481"}
{"created":"2025-04-15","title":"HalluShift: Measuring Distribution Shifts towards Hallucination Detection in LLMs","abstract":"Large Language Models (LLMs) have recently garnered widespread attention due to their adeptness at generating innovative responses to the given prompts across a multitude of domains. However, LLMs often suffer from the inherent limitation of hallucinations and generate incorrect information while maintaining well-structured and coherent responses. In this work, we hypothesize that hallucinations stem from the internal dynamics of LLMs. Our observations indicate that, during passage generation, LLMs tend to deviate from factual accuracy in subtle parts of responses, eventually shifting toward misinformation. This phenomenon bears a resemblance to human cognition, where individuals may hallucinate while maintaining logical coherence, embedding uncertainty within minor segments of their speech. To investigate this further, we introduce an innovative approach, HalluShift, designed to analyze the distribution shifts in the internal state space and token probabilities of the LLM-generated responses. Our method attains superior performance compared to existing baselines across various benchmark datasets. Our codebase is available at https://github.com/sharanya-dasgupta001/hallushift.","authors":["Sharanya Dasgupta","Sujoy Nath","Arkaprabha Basu","Pourya Shamsolmoali","Swagatam Das"],"url":"https://arxiv.org/abs/2504.09482"}
{"created":"2025-04-15","title":"An overview of condensation phenomenon in deep learning","abstract":"In this paper, we provide an overview of a common phenomenon, condensation, observed during the nonlinear training of neural networks: During the nonlinear training of neural networks, neurons in the same layer tend to condense into groups with similar outputs. Empirical observations suggest that the number of condensed clusters of neurons in the same layer typically increases monotonically as training progresses. Neural networks with small weight initializations or Dropout optimization can facilitate this condensation process. We also examine the underlying mechanisms of condensation from the perspectives of training dynamics and the structure of the loss landscape. The condensation phenomenon offers valuable insights into the generalization abilities of neural networks and correlates to stronger reasoning abilities in transformer-based language models.","authors":["Zhi-Qin John Xu","Yaoyu Zhang","Zhangchen Zhou"],"url":"https://arxiv.org/abs/2504.09484"}
{"created":"2025-04-15","title":"GenEDA: Unleashing Generative Reasoning on Netlist via Multimodal Encoder-Decoder Aligned Foundation Model","abstract":"The success of foundation AI has motivated the research of circuit foundation models, which are customized to assist the integrated circuit (IC) design process. However, existing pre-trained circuit models are typically limited to standalone encoders for predictive tasks or decoders for generative tasks. These two model types are developed independently, operate on different circuit modalities, and reside in separate latent spaces, which restricts their ability to complement each other for more advanced applications. In this work, we present GenEDA, the first framework that aligns circuit encoders with decoders within a shared latent space. GenEDA bridges the gap between graph-based circuit representations and text-based large language models (LLMs), enabling communication between their respective latent spaces. To achieve the alignment, we propose two paradigms that support both open-source trainable LLMs and commercial frozen LLMs. Built on this aligned architecture, GenEDA enables three unprecedented generative reasoning tasks over netlists, where the model reversely generates the high-level functionality from low-level netlists in different granularities. These tasks extend traditional gate-type prediction to direct generation of full-circuit functionality. Experiments demonstrate that GenEDA significantly boosts advanced LLMs' (e.g., GPT-4o and DeepSeek-V3) performance in all tasks.","authors":["Wenji Fang","Jing Wang","Yao Lu","Shang Liu","Zhiyao Xie"],"url":"https://arxiv.org/abs/2504.09485"}
{"created":"2025-04-15","title":"Adaptive Cluster-Based Synthetic Minority Oversampling Technique for Traffic Mode Choice Prediction with Imbalanced Dataset","abstract":"Urban datasets such as citizen transportation modes often contain disproportionately distributed classes, posing significant challenges to the classification of under-represented samples using data-driven models. In the literature, various resampling methods have been developed to create synthetic data for minority classes (oversampling) or remove samples from majority classes (undersampling) to alleviate class imbalance. However, oversampling approaches tend to overgeneralize minor classes that are closely clustered and neglect sparse regions which may contain crucial information. Conversely, undersampling methods potentially remove useful information on certain subgroups. Hence, a resampling approach that takes the inherent distribution of data into consideration is required to ensure appropriate synthetic data creation. This study proposes an adaptive cluster-based synthetic minority oversampling technique. Density-based spatial clustering is applied on minority classes to identify subgroups based on their input features. The classes in each of these subgroups are then oversampled according to the ratio of data points of their local cluster to the largest majority class. When used in conjunction with machine learning models such as random forest and extreme gradient boosting, this oversampling method results in significantly higher F1 scores for the minority classes compared to other resampling techniques. These improved models provide accurate classification of transportation modes.","authors":["Guang An Ooi","Shehab Ahmed"],"url":"https://arxiv.org/abs/2504.09486"}
{"created":"2025-04-15","title":"Kongzi: A Historical Large Language Model with Fact Enhancement","abstract":"The capabilities of the latest large language models (LLMs) have been extended from pure natural language understanding to complex reasoning tasks. However, current reasoning models often exhibit factual inaccuracies in longer reasoning chains, which poses challenges for historical reasoning and limits the potential of LLMs in complex, knowledge-intensive tasks. Historical studies require not only the accurate presentation of factual information but also the ability to establish cross-temporal correlations and derive coherent conclusions from fragmentary and often ambiguous sources. To address these challenges, we propose Kongzi, a large language model specifically designed for historical analysis. Through the integration of curated, high-quality historical data and a novel fact-reinforcement learning strategy, Kongzi demonstrates strong factual alignment and sophisticated reasoning depth. Extensive experiments on tasks such as historical question answering and narrative generation demonstrate that Kongzi outperforms existing models in both factual accuracy and reasoning depth. By effectively addressing the unique challenges inherent in historical texts, Kongzi sets a new standard for the development of accurate and reliable LLMs in professional domains.","authors":["Jiashu Yang","Ningning Wang","Yian Zhao","Chaoran Feng","Junjia Du","Hao Pang","Zhirui Fang","Xuxin Cheng"],"url":"https://arxiv.org/abs/2504.09488"}
{"created":"2025-04-15","title":"Square Packing with Asymptotically Smallest Waste Only Needs Good Squares","abstract":"We consider the problem of packing a large square with nonoverlapping unit squares. Let $W(x)$ be the minimum wasted area when a large square of side length $x$ is packed with unit squares. In Roth and Vaughan's paper that proves the lower bound $W(x) \\notin o(x^{1/2})$, a good square is defined to be a square with inclination at most $10^{-10}$ with respect to the large square. In this article, we prove that in calculating the asymptotic growth of the wasted space, it suffices to only consider packings with only good squares. This allows the lower bound proof in Roth and Vaughan's paper to be simplified by not having to handle bad squares.","authors":["Hong Duc Bui"],"url":"https://arxiv.org/abs/2504.09489"}
{"created":"2025-04-15","title":"DropoutGS: Dropping Out Gaussians for Better Sparse-view Rendering","abstract":"Although 3D Gaussian Splatting (3DGS) has demonstrated promising results in novel view synthesis, its performance degrades dramatically with sparse inputs and generates undesirable artifacts. As the number of training views decreases, the novel view synthesis task degrades to a highly under-determined problem such that existing methods suffer from the notorious overfitting issue. Interestingly, we observe that models with fewer Gaussian primitives exhibit less overfitting under sparse inputs. Inspired by this observation, we propose a Random Dropout Regularization (RDR) to exploit the advantages of low-complexity models to alleviate overfitting. In addition, to remedy the lack of high-frequency details for these models, an Edge-guided Splitting Strategy (ESS) is developed. With these two techniques, our method (termed DropoutGS) provides a simple yet effective plug-in approach to improve the generalization performance of existing 3DGS methods. Extensive experiments show that our DropoutGS produces state-of-the-art performance under sparse views on benchmark datasets including Blender, LLFF, and DTU. The project page is at: https://xuyx55.github.io/DropoutGS/.","authors":["Yexing Xu","Longguang Wang","Minglin Chen","Sheng Ao","Li Li","Yulan Guo"],"url":"https://arxiv.org/abs/2504.09491"}
{"created":"2025-04-15","title":"Hybrid Radial Kernels for Solving Weakly Singular Fredholm Integral Equations: Balancing Accuracy and Stability in Meshless Methods","abstract":"Over the past few decades, kernel-based approximation methods had achieved astonishing success in solving different problems in the field of science and engineering. However, when employing the direct or standard method of performing computations using infinitely smooth kernels, a conflict arises between the accuracy that can be theoretically attained and the numerical stability. In other words, when the shape parameter tends to zero, the operational matrix for the standard bases with infinitely smooth kernels become severely ill-conditioned. This conflict can be managed applying hybrid kernels. The hybrid kernels extend the approximation space and provide high flexibility to strike the best possible balance between accuracy and stability. In the current study, an innovative approach using hybrid radial kernels (HRKs) is provided to solve weakly singular Fredholm integral equations (WSFIEs) of the second kind in a meshless scheme. The approach employs hybrid kernels built on dispersed nodes as a basis within the discrete collocation technique. This method transforms the problem being studied into a linear system of algebraic equations. Also, the particle swarm optimization (PSO) algorithm is utilized to calculate the optimal parameters for the hybrid kernels, which is based on minimizing the maximum absolute error (MAE). We also study the error estimate of the suggested scheme. Lastly, we assess the accuracy and validity of the hybrid technique by carrying out various numerical experiments. The numerical findings show that the estimates obtained from hybrid kernels are significantly more accurate in solving WSFIEs compared to pure kernels. Additionally, it was revealed that the hybrid bases remain stable across various values of the shape parameters.","authors":["Davoud Moazami","Mohsen Esmaeilbeigi","Tahereh Akbari"],"url":"https://arxiv.org/abs/2504.09492"}
{"created":"2025-04-15","title":"Federated Prototype Graph Learning","abstract":"In recent years, Federated Graph Learning (FGL) has gained significant attention for its distributed training capabilities in graph-based machine intelligence applications, mitigating data silos while offering a new perspective for privacy-preserve large-scale graph learning. However, multi-level FGL heterogeneity presents various client-server collaboration challenges: (1) Model-level: The variation in clients for expected performance and scalability necessitates the deployment of heterogeneous models. Unfortunately, most FGL methods rigidly demand identical client models due to the direct model weight aggregation on the server. (2) Data-level: The intricate nature of graphs, marked by the entanglement of node profiles and topology, poses an optimization dilemma. This implies that models obtained by federated training struggle to achieve superior performance. (3) Communication-level: Some FGL methods attempt to increase message sharing among clients or between clients and the server to improve training, which inevitably leads to high communication costs. In this paper, we propose FedPG as a general prototype-guided optimization method for the above multi-level FGL heterogeneity. Specifically, on the client side, we integrate multi-level topology-aware prototypes to capture local graph semantics. Subsequently, on the server side, leveraging the uploaded prototypes, we employ topology-guided contrastive learning and personalized technology to tailor global prototypes for each client, broadcasting them to improve local training. Experiments demonstrate that FedPG outperforms SOTA baselines by an average of 3.57\\% in accuracy while reducing communication costs by 168x.","authors":["Zhengyu Wu","Xunkai Li","Yinlin Zhu","Rong-Hua Li","Guoren Wang","Chenghu Zhou"],"url":"https://arxiv.org/abs/2504.09493"}
{"created":"2025-04-15","title":"Debiasing 6-DOF IMU via Hierarchical Learning of Continuous Bias Dynamics","abstract":"This paper develops a deep learning approach to the online debiasing of IMU gyroscopes and accelerometers. Most existing methods rely on implicitly learning a bias term to compensate for raw IMU data. Explicit bias learning has recently shown its potential as a more interpretable and motion-independent alternative. However, it remains underexplored and faces challenges, particularly the need for ground truth bias data, which is rarely available. To address this, we propose a neural ordinary differential equation (NODE) framework that explicitly models continuous bias dynamics, requiring only pose ground truth, often available in datasets. This is achieved by extending the canonical NODE framework to the matrix Lie group for IMU kinematics with a hierarchical training strategy. The validation on two public datasets and one real-world experiment demonstrates significant accuracy improvements in IMU measurements, reducing errors in both pure IMU integration and visual-inertial odometry.","authors":["Ben Liu","Tzu-Yuan Lin","Wei Zhang","Maani Ghaffari"],"url":"https://arxiv.org/abs/2504.09495"}
{"created":"2025-04-15","title":"Extending Behavioral Software Engineering: Decision-Making and Collaboration in Human-AI Teams for Responsible Software Engineering","abstract":"The study of behavioral and social dimensions of software engineering (SE) tasks characterizes behavioral software engineering (BSE);however, the increasing significance of human-AI collaboration (HAIC) brings new directions in BSE by presenting new challenges and opportunities.This PhD research focuses on decision-making (DM) for SE tasks and collaboration within human-AI teams, aiming to promote responsible software engineering through a cognitive partnership between humans and AI.The goal of the research is to identify the challenges and nuances in HAIC from a cognitive perspective, design and optimize collaboration/partnership (human-AI team) that enhance collective intelligence and promote better, responsible DM in SE through human-centered approaches. The research addresses HAIC and its impact on individual, team, and organizational level aspects of BSE.","authors":["Lekshmi Murali Rani"],"url":"https://arxiv.org/abs/2504.09496"}
{"created":"2025-04-15","title":"EasyREG: Easy Depth-Based Markerless Registration and Tracking using Augmented Reality Device for Surgical Guidance","abstract":"The use of Augmented Reality (AR) devices for surgical guidance has gained increasing traction in the medical field. Traditional registration methods often rely on external fiducial markers to achieve high accuracy and real-time performance. However, these markers introduce cumbersome calibration procedures and can be challenging to deploy in clinical settings. While commercial solutions have attempted real-time markerless tracking using the native RGB cameras of AR devices, their accuracy remains questionable for medical guidance, primarily due to occlusions and significant outliers between the live sensor data and the preoperative target anatomy point cloud derived from MRI or CT scans. In this work, we present a markerless framework that relies only on the depth sensor of AR devices and consists of two modules: a registration module for high-precision, outlier-robust target anatomy localization, and a tracking module for real-time pose estimation. The registration module integrates depth sensor error correction, a human-in-the-loop region filtering technique, and a robust global alignment with curvature-aware feature sampling, followed by local ICP refinement, for markerless alignment of preoperative models with patient anatomy. The tracking module employs a fast and robust registration algorithm that uses the initial pose from the registration module to estimate the target pose in real-time. We comprehensively evaluated the performance of both modules through simulation and real-world measurements. The results indicate that our markerless system achieves superior performance for registration and comparable performance for tracking to industrial solutions. The two-module design makes our system a one-stop solution for surgical procedures where the target anatomy moves or stays static during surgery.","authors":["Yue Yang","Christoph Leuze","Brian Hargreaves","Bruce Daniel","Fred Baik"],"url":"https://arxiv.org/abs/2504.09498"}
{"created":"2025-04-15","title":"Decoding the mechanisms of the Hattrick football manager game using Bayesian network structure learning for optimal decision-making","abstract":"Hattrick is a free web-based probabilistic football manager game with over 200,000 users competing for titles at national and international levels. Launched in Sweden in 1997 as part of an MSc project, the game's slow-paced design has fostered a loyal community, with many users remaining active for decades. Hattrick's game-engine mechanics are partially hidden, and users have attempted to decode them with incremental success over the years. Rule-based, statistical and machine learning models have been developed to aid this effort and are widely used by the community. However, these models or tools have not been formally described or evaluated in the scientific literature. This study is the first to explore Hattrick using structure learning techniques and Bayesian networks, integrating both data and domain knowledge to develop models capable of explaining and simulating the game engine. We present a comprehensive analysis assessing the effectiveness of structure learning algorithms in relation to knowledge-based structures, and show that while structure learning may achieve a higher overall network fit, it does not result in more accurate predictions for selected variables of interest, when compared to knowledge-based networks that produce a lower overall network fit. Additionally, we introduce and publicly share a fully specified Bayesian network model that matches the performance of top models used by the Hattrick community. We further demonstrate how analysis extends beyond prediction by providing a visual representation of conditional dependencies, and using the best performing Bayesian network model for in-game decision-making. To support future research, we make all data, graphical structures, and models publicly available online.","authors":["Anthony C. Constantinou","Nicholas Higgins","Neville K. Kitson"],"url":"https://arxiv.org/abs/2504.09499"}
{"created":"2025-04-15","title":"PCM-SAR: Physics-Driven Contrastive Mutual Learning for SAR Classification","abstract":"Existing SAR image classification methods based on Contrastive Learning often rely on sample generation strategies designed for optical images, failing to capture the distinct semantic and physical characteristics of SAR data. To address this, we propose Physics-Driven Contrastive Mutual Learning for SAR Classification (PCM-SAR), which incorporates domain-specific physical insights to improve sample generation and feature extraction. PCM-SAR utilizes the gray-level co-occurrence matrix (GLCM) to simulate realistic noise patterns and applies semantic detection for unsupervised local sampling, ensuring generated samples accurately reflect SAR imaging properties. Additionally, a multi-level feature fusion mechanism based on mutual learning enables collaborative refinement of feature representations. Notably, PCM-SAR significantly enhances smaller models by refining SAR feature representations, compensating for their limited capacity. Experimental results show that PCM-SAR consistently outperforms SOTA methods across diverse datasets and SAR classification tasks.","authors":["Pengfei Wang (School of Computer Science","Engineering","Central South University","Changsha","China)","Hao Zheng (School of Computer Science","Engineering","Central South University","Changsha","China)","Zhigang Hu (School of Computer Science","Engineering","Central South University","Changsha","China)","Aikun Xu (School of Computer Science","Engineering","Central South University","Changsha","China)","Meiguang Zheng (School of Computer Science","Engineering","Central South University","Changsha","China)","Liu Yang (School of Computer Science","Engineering","Central South University","Changsha","China)"],"url":"https://arxiv.org/abs/2504.09502"}
{"created":"2025-04-15","title":"MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs","abstract":"When applying pre-trained large language models (LLMs) to address anomaly detection tasks, the multivariate time series (MTS) modality of anomaly detection does not align with the text modality of LLMs. Existing methods simply transform the MTS data into multiple univariate time series sequences, which can cause many problems. This paper introduces MADLLM, a novel multivariate anomaly detection method via pre-trained LLMs. We design a new triple encoding technique to align the MTS modality with the text modality of LLMs. Specifically, this technique integrates the traditional patch embedding method with two novel embedding approaches: Skip Embedding, which alters the order of patch processing in traditional methods to help LLMs retain knowledge of previous features, and Feature Embedding, which leverages contrastive learning to allow the model to better understand the correlations between different features. Experimental results demonstrate that our method outperforms state-of-the-art methods in various public anomaly detection datasets.","authors":["Wei Tao","Xiaoyang Qu","Kai Lu","Jiguang Wan","Guokuan Li","Jianzong Wang"],"url":"https://arxiv.org/abs/2504.09504"}
{"created":"2025-04-15","title":"Pillar-Voxel Fusion Network for 3D Object Detection in Airborne Hyperspectral Point Clouds","abstract":"Hyperspectral point clouds (HPCs) can simultaneously characterize 3D spatial and spectral information of ground objects, offering excellent 3D perception and target recognition capabilities. Current approaches for generating HPCs often involve fusion techniques with hyperspectral images and LiDAR point clouds, which inevitably lead to geometric-spectral distortions due to fusion errors and obstacle occlusions. These adverse effects limit their performance in downstream fine-grained tasks across multiple scenarios, particularly in airborne applications. To address these issues, we propose PiV-AHPC, a 3D object detection network for airborne HPCs. To the best of our knowledge, this is the first attempt at this HPCs task. Specifically, we first develop a pillar-voxel dual-branch encoder, where the former captures spectral and vertical structural features from HPCs to overcome spectral distortion, while the latter emphasizes extracting accurate 3D spatial features from point clouds. A multi-level feature fusion mechanism is devised to enhance information interaction between the two branches, achieving neighborhood feature alignment and channel-adaptive selection, thereby organically integrating heterogeneous features and mitigating geometric distortion. Extensive experiments on two airborne HPCs datasets demonstrate that PiV-AHPC possesses state-of-the-art detection performance and high generalization capability.","authors":["Yanze Jiang","Yanfeng Gu","Xian Li"],"url":"https://arxiv.org/abs/2504.09506"}
{"created":"2025-04-15","title":"FVOS for MOSE Track of 4th PVUW Challenge: 3rd Place Solution","abstract":"Video Object Segmentation (VOS) is one of the most fundamental and challenging tasks in computer vision and has a wide range of applications. Most existing methods rely on spatiotemporal memory networks to extract frame-level features and have achieved promising results on commonly used datasets. However, these methods often struggle in more complex real-world scenarios. This paper addresses this issue, aiming to achieve accurate segmentation of video objects in challenging scenes. We propose fine-tuning VOS (FVOS), optimizing existing methods for specific datasets through tailored training. Additionally, we introduce a morphological post-processing strategy to address the issue of excessively large gaps between adjacent objects in single-model predictions. Finally, we apply a voting-based fusion method on multi-scale segmentation results to generate the final output. Our approach achieves J&amp;F scores of 76.81% and 83.92% during the validation and testing stages, respectively, securing third place overall in the MOSE Track of the 4th PVUW challenge 2025.","authors":["Mengjiao Wang","Junpei Zhang","Xu Liu","Yuting Yang","Mengru Ma"],"url":"https://arxiv.org/abs/2504.09507"}
{"created":"2025-04-15","title":"Towards Intuitive Drone Operation Using a Handheld Motion Controller","abstract":"We present an intuitive human-drone interaction system that utilizes a gesture-based motion controller to enhance the drone operation experience in real and simulated environments. The handheld motion controller enables natural control of the drone through the movements of the operator's hand, thumb, and index finger: the trigger press manages the throttle, the tilt of the hand adjusts pitch and roll, and the thumbstick controls yaw rotation. Communication with drones is facilitated via the ExpressLRS radio protocol, ensuring robust connectivity across various frequencies. The user evaluation of the flight experience with the designed drone controller using the UEQ-S survey showed high scores for both Pragmatic (mean=2.2, SD = 0.8) and Hedonic (mean=2.3, SD = 0.9) Qualities. This versatile control interface supports applications such as research, drone racing, and training programs in real and simulated environments, thereby contributing to advances in the field of human-drone interaction.","authors":["Daria Trinitatova","Sofia Shevelo","Dzmitry Tsetserukou"],"url":"https://arxiv.org/abs/2504.09510"}
{"created":"2025-04-15","title":"DiffuMural: Restoring Dunhuang Murals with Multi-scale Diffusion","abstract":"Large-scale pre-trained diffusion models have produced excellent results in the field of conditional image generation. However, restoration of ancient murals, as an important downstream task in this field, poses significant challenges to diffusion model-based restoration methods due to its large defective area and scarce training samples. Conditional restoration tasks are more concerned with whether the restored part meets the aesthetic standards of mural restoration in terms of overall style and seam detail, and such metrics for evaluating heuristic image complements are lacking in current research. We therefore propose DiffuMural, a combined Multi-scale convergence and Collaborative Diffusion mechanism with ControlNet and cyclic consistency loss to optimise the matching between the generated images and the conditional control. DiffuMural demonstrates outstanding capabilities in mural restoration, leveraging training data from 23 large-scale Dunhuang murals that exhibit consistent visual aesthetics. The model excels in restoring intricate details, achieving a coherent overall appearance, and addressing the unique challenges posed by incomplete murals lacking factual grounding. Our evaluation framework incorporates four key metrics to quantitatively assess incomplete murals: factual accuracy, textural detail, contextual semantics, and holistic visual coherence. Furthermore, we integrate humanistic value assessments to ensure the restored murals retain their cultural and artistic significance. Extensive experiments validate that our method outperforms state-of-the-art (SOTA) approaches in both qualitative and quantitative metrics.","authors":["Puyu Han","Jiaju Kang","Yuhang Pan","Erting Pan","Zeyu Zhang","Qunchao Jin","Juntao Jiang","Zhichen Liu","Luqi Gong"],"url":"https://arxiv.org/abs/2504.09513"}
{"created":"2025-04-15","title":"Capturing Longitudinal Changes in Brain Morphology Using Temporally Parameterized Neural Displacement Fields","abstract":"Longitudinal image registration enables studying temporal changes in brain morphology which is useful in applications where monitoring the growth or atrophy of specific structures is important. However this task is challenging due to; noise/artifacts in the data and quantifying small anatomical changes between sequential scans. We propose a novel longitudinal registration method that models structural changes using temporally parameterized neural displacement fields. Specifically, we implement an implicit neural representation (INR) using a multi-layer perceptron that serves as a continuous coordinate-based approximation of the deformation field at any time point. In effect, for any N scans of a particular subject, our model takes as input a 3D spatial coordinate location x, y, z and a corresponding temporal representation t and learns to describe the continuous morphology of structures for both observed and unobserved points in time. Furthermore, we leverage the analytic derivatives of the INR to derive a new regularization function that enforces monotonic rate of change in the trajectory of the voxels, which is shown to provide more biologically plausible patterns. We demonstrate the effectiveness of our method on 4D brain MR registration.","authors":["Aisha L. Shuaibu","Kieran A. Gibb","Peter A. Wijeratne","Ivor J. A. Simpson"],"url":"https://arxiv.org/abs/2504.09514"}
{"created":"2025-04-15","title":"A Categorical Unification for Multi-Model Data: Part II Categorical Algebra and Calculus","abstract":"Multi-model databases are designed to store, manage, and query data in various models, such as relational, hierarchical, and graph data, simultaneously. In this paper, we provide a theoretical basis for querying categorical databases. We propose two formal query languages: categorical calculus and categorical algebra, by extending relational calculus and relational algebra respectively. We demonstrate the equivalence between these two languages of queries. We propose a series of transformation rules of categorical algebra to facilitate query optimization. Finally, we analyze the expressive power and computation complexity for the proposed query languages.","authors":["Jiaheng Lu"],"url":"https://arxiv.org/abs/2504.09515"}
{"created":"2025-04-15","title":"FSSUAVL: A Discriminative Framework using Vision Models for Federated Self-Supervised Audio and Image Understanding","abstract":"Recent studies have demonstrated that vision models can effectively learn multimodal audio-image representations when paired. However, the challenge of enabling deep models to learn representations from unpaired modalities remains unresolved. This issue is especially pertinent in scenarios like Federated Learning (FL), where data is often decentralized, heterogeneous, and lacks a reliable guarantee of paired data. Previous attempts tackled this issue through the use of auxiliary pretrained encoders or generative models on local clients, which invariably raise computational cost with increasing number modalities. Unlike these approaches, in this paper, we aim to address the task of unpaired audio and image recognition using \\texttt{FSSUAVL}, a single deep model pretrained in FL with self-supervised contrastive learning (SSL). Instead of aligning the audio and image modalities, \\texttt{FSSUAVL} jointly discriminates them by projecting them into a common embedding space using contrastive SSL. This extends the utility of \\texttt{FSSUAVL} to paired and unpaired audio and image recognition tasks. Our experiments with CNN and ViT demonstrate that \\texttt{FSSUAVL} significantly improves performance across various image- and audio-based downstream tasks compared to using separate deep models for each modality. Additionally, \\texttt{FSSUAVL}'s capacity to learn multimodal feature representations allows for integrating auxiliary information, if available, to enhance recognition accuracy.","authors":["Yasar Abbas Ur Rehman","Kin Wai Lau","Yuyang Xie","Ma Lan","JiaJun Shen"],"url":"https://arxiv.org/abs/2504.09516"}
{"created":"2025-04-15","title":"RoboComm: A DID-based scalable and privacy-preserving Robot-to-Robot interaction over state channels","abstract":"In a multi robot system establishing trust amongst untrusted robots from different organisations while preserving a robot's privacy is a challenge. Recently decentralized technologies such as smart contract and blockchain are being explored for applications in robotics. However, the limited transaction processing and high maintenance cost hinder the widespread adoption of such approaches. Moreover, blockchain transactions be they on public or private permissioned blockchain are publically readable which further fails to preserve the confidentiality of the robot's data and privacy of the robot.","authors":["Roshan Singh","Sushant Pandey"],"url":"https://arxiv.org/abs/2504.09517"}
{"created":"2025-04-15","title":"3D CoCa: Contrastive Learners are 3D Captioners","abstract":"3D captioning, which aims to describe the content of 3D scenes in natural language, remains highly challenging due to the inherent sparsity of point clouds and weak cross-modal alignment in existing methods. To address these challenges, we propose 3D CoCa, a novel unified framework that seamlessly combines contrastive vision-language learning with 3D caption generation in a single architecture. Our approach leverages a frozen CLIP vision-language backbone to provide rich semantic priors, a spatially-aware 3D scene encoder to capture geometric context, and a multi-modal decoder to generate descriptive captions. Unlike prior two-stage methods that rely on explicit object proposals, 3D CoCa jointly optimizes contrastive and captioning objectives in a shared feature space, eliminating the need for external detectors or handcrafted proposals. This joint training paradigm yields stronger spatial reasoning and richer semantic grounding by aligning 3D and textual representations. Extensive experiments on the ScanRefer and Nr3D benchmarks demonstrate that 3D CoCa significantly outperforms current state-of-the-arts by 10.2% and 5.76% in CIDEr at 0.5IoU, respectively. Code will be available at https://github.com/AIGeeksGroup/3DCoCa.","authors":["Ting Huang","Zeyu Zhang","Yemin Wang","Hao Tang"],"url":"https://arxiv.org/abs/2504.09518"}
{"created":"2025-04-15","title":"How new data permeates LLM knowledge and how to dilute it","abstract":"Large language models learn and continually learn through the accumulation of gradient-based updates, but how individual pieces of new information affect existing knowledge, leading to both beneficial generalization and problematic hallucination, remains poorly understood. We demonstrate that when learning new information, LLMs exhibit a \"priming\" effect: learning a new fact can cause the model to inappropriately apply that knowledge in unrelated contexts. To systematically study this phenomenon, we introduce \"Outlandish,\" a carefully curated dataset of 1320 diverse text samples designed to probe how new knowledge permeates through an LLM's existing knowledge base. Using this dataset, we show that the degree of priming after learning new information can be predicted by measuring the token probability of key words before learning. This relationship holds robustly across different model architectures (PALM-2, Gemma, Llama), sizes, and training stages. Finally, we develop two novel techniques to modulate how new knowledge affects existing model behavior: (1) a ``stepping-stone'' text augmentation strategy and (2) an ``ignore-k'' update pruning method. These approaches reduce undesirable priming effects by 50-95\\% while preserving the model's ability to learn new information. Our findings provide both empirical insights into how LLMs learn and practical tools for improving the specificity of knowledge insertion in language models. Further materials: https://sunchipsster1.github.io/projects/outlandish/","authors":["Chen Sun","Renat Aksitov","Andrey Zhmoginov","Nolan Andrew Miller","Max Vladymyrov","Ulrich Rueckert","Been Kim","Mark Sandler"],"url":"https://arxiv.org/abs/2504.09522"}
{"created":"2025-04-15","title":"SimLabel: Similarity-Weighted Semi-supervision for Multi-annotator Learning with Missing Labels","abstract":"Multi-annotator learning has emerged as an important research direction for capturing diverse perspectives in subjective annotation tasks. Typically, due to the large scale of datasets, each annotator can only label a subset of samples, resulting in incomplete (or missing) annotations per annotator. Traditional methods generally skip model updates for missing parts, leading to inefficient data utilization. In this paper, we propose a novel similarity-weighted semi-supervised learning framework (SimLabel) that leverages inter-annotator similarities to generate weighted soft labels. This approach enables the prediction, utilization, and updating of missing parts rather than discarding them. Meanwhile, we introduce a confidence assessment mechanism combining maximum probability with entropy-based uncertainty metrics to prioritize high-confidence predictions to impute missing labels during training as an iterative refinement pipeline, which continuously improves both inter-annotator similarity estimates and individual model performance. For the comprehensive evaluation, we contribute a new video emotion recognition dataset, AMER2, which exhibits higher missing rates than its predecessor, AMER. Experimental results demonstrate our method's superior performance compared to existing approaches under missing-label conditions.","authors":["Liyun Zhang","Zheng Lian","Hong Liu","Takanori Takebe","Yuta Nakashima"],"url":"https://arxiv.org/abs/2504.09525"}
{"created":"2025-04-15","title":"Super-Exponential Approximation of the Riemann-Liouville Fractional Integral via Shifted Gegenbauer Pseudospectral Methods","abstract":"This paper introduces a shifted Gegenbauer pseudospectral (SGPS) method for high-precision approximation of the left Riemann-Liouville fractional integral (RLFI). By using precomputable fractional-order shifted Gegenbauer integration matrices (FSGIMs), the method achieves super-exponential convergence for smooth functions, delivering near machine-precision accuracy with minimal computational cost. Tunable shifted Gegenbauer (SG) parameters enable flexible optimization across diverse problems, while rigorous error analysis confirms rapid error decay under optimal settings. Numerical experiments demonstrate that the SGPS method outperforms MATLAB's integral, MATHEMATICA's NIntegrate, and existing techniques by up to two orders of magnitude in accuracy, with superior efficiency for varying fractional orders 0 < \\alpha < 1. Its adaptability and precision make the SGPS method a transformative tool for fractional calculus, ideal for modeling complex systems with memory and non-local behavior.","authors":["Kareem T. Elgindy"],"url":"https://arxiv.org/abs/2504.09526"}
{"created":"2025-04-15","title":"A Secure Communication Protocol for Remote Keyless Entry System with Adaptive Adjustment of Transmission Parameters","abstract":"Remote Keyless Entry (RKE) systems have become a standard feature in modern vehicles, yet their unidirectional fixed-frequency radio communication renders them vulnerable to replay attacks, impersonation attacks, cryptanalysis, and intentional interference. Existing cryptographic authentication methods enhance security but often fail to address real-world constraints such as computational efficiency and radio interference. To mitigate these threats, we designed the Adaptive Frequency-Hopping Algorithm and the Adaptive TXP and PHY Mode Control Algorithm that can dynamically optimize channel selection, transmission power, and PHY modes based on real-time channel quality assessment. To enhance the security and reliability of RKE systems, we propose the Lightweight Vehicle-Key Authentication Protocol. In addition, a prototype of the proposed scheme was implemented to verify its effectiveness in mitigating interference and preventing unauthorized access.Experimental results show that our scheme significantly enhances communication security and reliability while maintaining low computational overhead. Under mild interference conditions, the packet delivery rate (PDR) of the adaptive scheme increases from 93% to 99.23%, and under strong interference, it improves from 85% to 99.01%. Additionally, the scheme effectively prevents replay and impersonation attacks, ensuring secure vehicle access control by dynamically optimizing communication parameters to maintain stable and reliable transmission.","authors":["Jingjing Guo","Bo Tang","Jiayuan Xu","Qingyi Li","Yuyuan Qin","Xinghua Li"],"url":"https://arxiv.org/abs/2504.09527"}
{"created":"2025-04-15","title":"AeroLite: Tag-Guided Lightweight Generation of Aerial Image Captions","abstract":"Accurate and automated captioning of aerial imagery is crucial for applications like environmental monitoring, urban planning, and disaster management. However, this task remains challenging due to complex spatial semantics and domain variability. To address these issues, we introduce \\textbf{AeroLite}, a lightweight, tag-guided captioning framework designed to equip small-scale language models (1--3B parameters) with robust and interpretable captioning capabilities specifically for remote sensing images. \\textbf{AeroLite} leverages GPT-4o to generate a large-scale, semantically rich pseudo-caption dataset by integrating multiple remote sensing benchmarks, including DLRSD, iSAID, LoveDA, WHU, and RSSCN7. To explicitly capture key semantic elements such as orientation and land-use types, AeroLite employs natural language processing techniques to extract relevant semantic tags. These tags are then learned by a dedicated multi-label CLIP encoder, ensuring precise semantic predictions. To effectively fuse visual and semantic information, we propose a novel bridging multilayer perceptron (MLP) architecture, aligning semantic tags with visual embeddings while maintaining minimal computational overhead. AeroLite's flexible design also enables seamless integration with various pretrained large language models. We adopt a two-stage LoRA-based training approach: the initial stage leverages our pseudo-caption dataset to capture broad remote sensing semantics, followed by fine-tuning on smaller, curated datasets like UCM and Sydney Captions to refine domain-specific alignment. Experimental evaluations demonstrate that AeroLite surpasses significantly larger models (e.g., 13B parameters) in standard captioning metrics, including BLEU and METEOR, while maintaining substantially lower computational costs.","authors":["Xing Zi","Tengjun Ni","Xianjing Fan","Xian Tao","Jun Li","Ali Braytee","Mukesh Prasad"],"url":"https://arxiv.org/abs/2504.09528"}
{"created":"2025-04-15","title":"Trajectory-guided Motion Perception for Facial Expression Quality Assessment in Neurological Disorders","abstract":"Automated facial expression quality assessment (FEQA) in neurological disorders is critical for enhancing diagnostic accuracy and improving patient care, yet effectively capturing the subtle motions and nuances of facial muscle movements remains a challenge. We propose to analyse facial landmark trajectories, a compact yet informative representation, that encodes these subtle motions from a high-level structural perspective. Hence, we introduce Trajectory-guided Motion Perception Transformer (TraMP-Former), a novel FEQA framework that fuses landmark trajectory features for fine-grained motion capture with visual semantic cues from RGB frames, ultimately regressing the combined features into a quality score. Extensive experiments demonstrate that TraMP-Former achieves new state-of-the-art performance on benchmark datasets with neurological disorders, including PFED5 (up by 6.51%) and an augmented Toronto NeuroFace (up by 7.62%). Our ablation studies further validate the efficiency and effectiveness of landmark trajectories in FEQA. Our code is available at https://github.com/shuchaoduan/TraMP-Former.","authors":["Shuchao Duan","Amirhossein Dadashzadeh","Alan Whone","Majid Mirmehdi"],"url":"https://arxiv.org/abs/2504.09530"}
{"created":"2025-04-15","title":"Embodied Chain of Action Reasoning with Multi-Modal Foundation Model for Humanoid Loco-manipulation","abstract":"Enabling humanoid robots to autonomously perform loco-manipulation tasks in complex, unstructured environments poses significant challenges. This entails equipping robots with the capability to plan actions over extended horizons while leveraging multi-modality to bridge gaps between high-level planning and actual task execution. Recent advancements in multi-modal foundation models have showcased substantial potential in enhancing planning and reasoning abilities, particularly in the comprehension and processing of semantic information for robotic control tasks. In this paper, we introduce a novel framework based on foundation models that applies the embodied chain of action reasoning methodology to autonomously plan actions from textual instructions for humanoid loco-manipulation. Our method integrates humanoid-specific chain of thought methodology, including detailed affordance and body movement analysis, which provides a breakdown of the task into a sequence of locomotion and manipulation actions. Moreover, we incorporate spatial reasoning based on the observation and target object properties to effectively navigate where target position may be unseen or occluded. Through rigorous experimental setups on object rearrangement, manipulations and loco-manipulation tasks on a real-world environment, we evaluate our method's efficacy on the decoupled upper and lower body control and demonstrate the effectiveness of the chain of robotic action reasoning strategies in comprehending human instructions.","authors":["Yu Hao","Geeta Chandra Raju Bethala","Niraj Pudasaini","Hao Huang","Shuaihang Yuan","Congcong Wen","Baoru Huang","Anh Nguyen","Yi Fang"],"url":"https://arxiv.org/abs/2504.09532"}
{"created":"2025-04-15","title":"FastRSR: Efficient and Accurate Road Surface Reconstruction from Bird's Eye View","abstract":"Road Surface Reconstruction (RSR) is crucial for autonomous driving, enabling the understanding of road surface conditions. Recently, RSR from the Bird's Eye View (BEV) has gained attention for its potential to enhance performance. However, existing methods for transforming perspective views to BEV face challenges such as information loss and representation sparsity. Moreover, stereo matching in BEV is limited by the need to balance accuracy with inference speed. To address these challenges, we propose two efficient and accurate BEV-based RSR models: FastRSR-mono and FastRSR-stereo. Specifically, we first introduce Depth-Aware Projection (DAP), an efficient view transformation strategy designed to mitigate information loss and sparsity by querying depth and image features to aggregate BEV data within specific road surface regions using a pre-computed look-up table. To optimize accuracy and speed in stereo matching, we design the Spatial Attention Enhancement (SAE) and Confidence Attention Generation (CAG) modules. SAE adaptively highlights important regions, while CAG focuses on high-confidence predictions and filters out irrelevant information. FastRSR achieves state-of-the-art performance, exceeding monocular competitors by over 6.0% in elevation absolute error and providing at least a 3.0x speedup by stereo methods on the RSRD dataset. The source code will be released.","authors":["Yuting Zhao","Yuheng Ji","Xiaoshuai Hao","Shuxiao Li"],"url":"https://arxiv.org/abs/2504.09535"}
{"created":"2025-04-15","title":"EmbodiedOcc++: Boosting Embodied 3D Occupancy Prediction with Plane Regularization and Uncertainty Sampler","abstract":"Online 3D occupancy prediction provides a comprehensive spatial understanding of embodied environments. While the innovative EmbodiedOcc framework utilizes 3D semantic Gaussians for progressive indoor occupancy prediction, it overlooks the geometric characteristics of indoor environments, which are primarily characterized by planar structures. This paper introduces EmbodiedOcc++, enhancing the original framework with two key innovations: a Geometry-guided Refinement Module (GRM) that constrains Gaussian updates through plane regularization, along with a Semantic-aware Uncertainty Sampler (SUS) that enables more effective updates in overlapping regions between consecutive frames. GRM regularizes the position update to align with surface normals. It determines the adaptive regularization weight using curvature-based and depth-based constraints, allowing semantic Gaussians to align accurately with planar surfaces while adapting in complex regions. To effectively improve geometric consistency from different views, SUS adaptively selects proper Gaussians to update. Comprehensive experiments on the EmbodiedOcc-ScanNet benchmark demonstrate that EmbodiedOcc++ achieves state-of-the-art performance across different settings. Our method demonstrates improved edge accuracy and retains more geometric details while ensuring computational efficiency, which is essential for online embodied perception. The code will be released at: https://github.com/PKUHaoWang/EmbodiedOcc2.","authors":["Hao Wang","Xiaobao Wei","Xiaoan Zhang","Jianing Li","Chengyu Bai","Ying Li","Ming Lu","Wenzhao Zheng","Shanghang Zhang"],"url":"https://arxiv.org/abs/2504.09540"}
{"created":"2025-04-15","title":"Solar-charge your car: EV charging can be aligned with renewables by providing pro-environmental information on a smartboard","abstract":"The integration of electric vehicle (EV) charging with renewable energy sources is crucial for minimizing the carbon footprint of transportation. This study investigates whether real-time pro-environmental information displayed on a smartboard at EV charging stations can influence drivers to align their charging behavior with periods of high renewable energy availability. A pre-post-control quasi-experimental field trial was conducted in a sustainable neighborhood in Ghent, Belgium. A smartboard provided real-time signals indicating optimal charging times based on renewable energy production. The results demonstrate that the presence of real-time pro-environmental information on a smartboard was associated with significant increases in both the number of charging operations and the amount of energy charged during periods of high renewable energy availability. This approach offers a scalable, cost-effective method for optimizing energy consumption and reducing greenhouse gas emissions in residential settings.","authors":["Celina Kacperski","Melanie Vogel","Florian Kutzner","Mona Bielig","Soroush Karimi Madahi","Lieven Demolder","Matthias Strobbe","Sonja Klingert"],"url":"https://arxiv.org/abs/2504.09542"}
{"created":"2025-04-15","title":"Causal integration of chemical structures improves representations of microscopy images for morphological profiling","abstract":"Recent advances in self-supervised deep learning have improved our ability to quantify cellular morphological changes in high-throughput microscopy screens, a process known as morphological profiling. However, most current methods only learn from images, despite many screens being inherently multimodal, as they involve both a chemical or genetic perturbation as well as an image-based readout. We hypothesized that incorporating chemical compound structure during self-supervised pre-training could improve learned representations of images in high-throughput microscopy screens. We introduce a representation learning framework, MICON (Molecular-Image Contrastive Learning), that models chemical compounds as treatments that induce counterfactual transformations of cell phenotypes. MICON significantly outperforms classical hand-crafted features such as CellProfiler and existing deep-learning-based representation learning methods in challenging evaluation settings where models must identify reproducible effects of drugs across independent replicates and data-generating centers. We demonstrate that incorporating chemical compound information into the learning process provides consistent improvements in our evaluation setting and that modeling compounds specifically as treatments in a causal framework outperforms approaches that directly align images and compounds in a single representation space. Our findings point to a new direction for representation learning in morphological profiling, suggesting that methods should explicitly account for the multimodal nature of microscopy screening data.","authors":["Yemin Yu","Neil Tenenholtz","Lester Mackey","Ying Wei","David Alvarez-Melis","Ava P. Amini","Alex X. Lu"],"url":"https://arxiv.org/abs/2504.09544"}
{"created":"2025-04-15","title":"Hybrid discontinuous Galerkin discretizations for the damped time-harmonic Galbrun's equation","abstract":"In this article, we consider the damped time-harmonic Galbrun's equation which models solar and stellar oscillations. We introduce and analyze hybrid discontinuous Galerkin discretizations, which are stable and convergent for any polynomial degree greater or equal than one and are computationally more efficient than discontinuous Galerkin discretizations. Additionally, the methods are stable with respect to the drastic changes in the magnitude of the coefficients occurring in stars. The analysis is based on the concept of discrete approximation schemes and weak T-compatibility, which exploits the weakly T-coercive structure of the equation.","authors":["Martin Halla","Christoph Lehrenfeld","Tim van Beeck"],"url":"https://arxiv.org/abs/2504.09547"}
{"created":"2025-04-15","title":"SD-ReID: View-aware Stable Diffusion for Aerial-Ground Person Re-Identification","abstract":"Aerial-Ground Person Re-IDentification (AG-ReID) aims to retrieve specific persons across cameras with different viewpoints. Previous works focus on designing discriminative ReID models to maintain identity consistency despite drastic changes in camera viewpoints. The core idea behind these methods is quite natural, but designing a view-robust network is a very challenging task. Moreover, they overlook the contribution of view-specific features in enhancing the model's capability to represent persons. To address these issues, we propose a novel two-stage feature learning framework named SD-ReID for AG-ReID, which takes advantage of the powerful understanding capacity of generative models, e.g., Stable Diffusion (SD), to generate view-specific features between different viewpoints. In the first stage, we train a simple ViT-based model to extract coarse-grained representations and controllable conditions. Then, in the second stage, we fine-tune the SD model to learn complementary representations guided by the controllable conditions. Furthermore, we propose the View-Refine Decoder (VRD) to obtain additional controllable conditions to generate missing cross-view features. Finally, we use the coarse-grained representations and all-view features generated by SD to retrieve target persons. Extensive experiments on the AG-ReID benchmarks demonstrate the effectiveness of our proposed SD-ReID. The source code will be available upon acceptance.","authors":["Xiang Hu","Pingping Zhang","Yuhao Wang","Bin Yan","Huchuan Lu"],"url":"https://arxiv.org/abs/2504.09549"}
{"created":"2025-04-15","title":"Procedural Multiscale Geometry Modeling using Implicit Functions","abstract":"Materials exhibit geometric structures across mesoscopic to microscopic scales, influencing macroscale properties such as appearance, mechanical strength, and thermal behavior. Capturing and modeling these multiscale structures is challenging but essential for computer graphics, engineering, and materials science. We present a framework inspired by hypertexture methods, using implicit functions and adaptive sphere tracing to synthesize multiscale structures on the fly without precomputation. This framework models volumetric materials with particulate, fibrous, porous, and laminar structures, allowing control over size, shape, density, distribution, and orientation. We enhance structural diversity by superimposing implicit periodic functions while improving computational efficiency. The framework also supports spatially varying particulate media, particle agglomeration, and piling on convex and concave structures, such as rock formations (mesoscale), without explicit simulation. We show its potential in the appearance modeling of volumetric materials and explore how spatially varying properties influence perceived macroscale appearance. Our framework enables seamless multiscale modeling, reconstructing procedural volumetric materials from image and signed distance field (SDF) synthetic exemplars using first-order and gradient-free optimization.","authors":["Bojja Venu","Adam Bosak","Juan Raul Padron-Griffe"],"url":"https://arxiv.org/abs/2504.09553"}
{"created":"2025-04-15","title":"HD-RAG: Retrieval-Augmented Generation for Hybrid Documents Containing Text and Hierarchical Tables","abstract":"With the rapid advancement of large language models (LLMs), Retrieval-Augmented Generation (RAG) effectively combines LLMs generative capabilities with external retrieval-based information. The Hybrid Document RAG task aims to integrate textual and hierarchical tabular data for more comprehensive retrieval and generation in complex scenarios. However, there is no existing dataset specifically designed for this task that includes both text and tabular data. Additionally, existing methods struggle to retrieve relevant tabular data and integrate it with text. Semantic similarity-based retrieval lacks accuracy, while table-specific methods fail to handle complex hierarchical structures effectively. Furthermore, the QA task requires complex reasoning and calculations, further complicating the challenge. In this paper, we propose a new large-scale dataset, DocRAGLib, specifically designed for the question answering (QA) task scenario under Hybrid Document RAG. To tackle these challenges, we introduce HD-RAG, a novel framework that incorporates a row-and-column level (RCL) table representation, employs a two-stage process combining ensemble and LLM-based retrieval, and integrates RECAP, which is designed for multi-step reasoning and complex calculations in Document-QA tasks. We conduct comprehensive experiments with DocRAGLib, showing that HD-RAG outperforms existing baselines in both retrieval accuracy and QA performance, demonstrating its effectiveness.","authors":["Chi Zhang","Qiyang Chen"],"url":"https://arxiv.org/abs/2504.09554"}
{"created":"2025-04-15","title":"Mitigating Long-tail Distribution in Oracle Bone Inscriptions: Dataset, Model, and Benchmark","abstract":"The oracle bone inscription (OBI) recognition plays a significant role in understanding the history and culture of ancient China. However, the existing OBI datasets suffer from a long-tail distribution problem, leading to biased performance of OBI recognition models across majority and minority classes. With recent advancements in generative models, OBI synthesis-based data augmentation has become a promising avenue to expand the sample size of minority classes. Unfortunately, current OBI datasets lack large-scale structure-aligned image pairs for generative model training. To address these problems, we first present the Oracle-P15K, a structure-aligned OBI dataset for OBI generation and denoising, consisting of 14,542 images infused with domain knowledge from OBI experts. Second, we propose a diffusion model-based pseudo OBI generator, called OBIDiff, to achieve realistic and controllable OBI generation. Given a clean glyph image and a target rubbing-style image, it can effectively transfer the noise style of the original rubbing to the glyph image. Extensive experiments on OBI downstream tasks and user preference studies show the effectiveness of the proposed Oracle-P15K dataset and demonstrate that OBIDiff can accurately preserve inherent glyph structures while transferring authentic rubbing styles effectively.","authors":["Jinhao Li","Zijian Chen","Runze Dong","Tingzhu Chen","Changbo Wang","Guangtao Zhai"],"url":"https://arxiv.org/abs/2504.09555"}
{"created":"2025-04-15","title":"BIT: Battery-free, IC-less and Wireless Smart Textile Interface and Sensing System","abstract":"The development of smart textile interfaces is hindered by the inclusion of rigid hardware components and batteries within the fabric, which pose challenges in terms of manufacturability, usability, and environmental concerns related to electronic waste. To mitigate these issues, we propose a smart textile interface and its wireless sensing system to eliminate the need for ICs, batteries, and connectors embedded into textiles. Our technique is established on the integration of multi-resonant circuits in smart textile interfaces, and utilizing near-field electromagnetic coupling between two coils to facilitate wireless power transfer and data acquisition from smart textile interface. A key aspect of our system is the development of a mathematical model that accurately represents the equivalent circuit of the sensing system. Using this model, we developed a novel algorithm to accurately estimate sensor signals based on changes in system impedance. Through simulation-based experiments and a user study, we demonstrate that our technique effectively supports multiple textile sensors of various types.","authors":["Weiye Xu","Tony Li","Yuntao Wang","Xing-dong Yang","Te-yen Wu"],"url":"https://arxiv.org/abs/2504.09558"}
{"created":"2025-04-15","title":"LoopLynx: A Scalable Dataflow Architecture for Efficient LLM Inference","abstract":"In this paper, we propose LoopLynx, a scalable dataflow architecture for efficient LLM inference that optimizes FPGA usage through a hybrid spatial-temporal design. The design of LoopLynx incorporates a hybrid temporal-spatial architecture, where computationally intensive operators are implemented as large dataflow kernels. This achieves high throughput similar to spatial architecture, and organizing and reusing these kernels in a temporal way together enhances FPGA peak performance. Furthermore, to overcome the resource limitations of a single device, we provide a multi-FPGA distributed architecture that overlaps and hides all data transfers so that the distributed accelerators are fully utilized. By doing so, LoopLynx can be effectively scaled to multiple devices to further explore model parallelism for large-scale LLM inference. Evaluation of GPT-2 model demonstrates that LoopLynx can achieve comparable performance to state-of-the-art single FPGA-based accelerations. In addition, compared to Nvidia A100, our accelerator with a dual-FPGA configuration delivers a 2.52x speed-up in inference latency while consuming only 48.1% of the energy.","authors":["Jianing Zheng","Gang Chen"],"url":"https://arxiv.org/abs/2504.09561"}
{"created":"2025-04-15","title":"Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution","abstract":"Chain-of-Thought (CoT) prompting enhances the reasoning of large language models (LLMs) by decomposing problems into sequential steps, mimicking human logic and reducing errors. However, complex tasks with vast solution spaces and vague constraints often exceed the capacity of a single reasoning chain. Inspired by Minimal Free Resolution (MFR) in commutative algebra and algebraic geometry, we propose Syzygy of Thoughts (SoT)-a novel framework that extends CoT by introducing auxiliary, interrelated reasoning paths. SoT captures deeper logical dependencies, enabling more robust and structured problem-solving. MFR decomposes a module into a sequence of free modules with minimal rank, providing a structured analytical approach to complex systems. This method introduces the concepts of \"Module\", \"Betti numbers\",\"Freeness\", \"Mapping\", \"Exactness\" and \"Minimality\", enabling the systematic decomposition of the original complex problem into logically complete minimal subproblems while preserving key problem features and reducing reasoning length. We tested SoT across diverse datasets (e.g., GSM8K, MATH) and models (e.g., GPT-4o-mini, Qwen2.5), achieving inference accuracy that matches or surpasses mainstream CoTs standards. Additionally, by aligning the sampling process with algebraic constraints, our approach enhances the scalability of inference time in LLMs, ensuring both transparent reasoning and high performance. Our code will be publicly available at https://github.com/dlMARiA/Syzygy-of-thoughts.","authors":["Chenghao Li","Chaoning Zhang","Yi Lu","Jiaquan Zhang","Qigan Sun","Xudong Wang","Jiwei Wei","Guoqing Wang","Yang Yang","Heng Tao Shen"],"url":"https://arxiv.org/abs/2504.09566"}
{"created":"2025-04-15","title":"LLMs Can Achieve High-quality Simultaneous Machine Translation as Efficiently as Offline","abstract":"When the complete source sentence is provided, Large Language Models (LLMs) perform excellently in offline machine translation even with a simple prompt \"Translate the following sentence from [src lang] into [tgt lang]:\". However, in many real scenarios, the source tokens arrive in a streaming manner and simultaneous machine translation (SiMT) is required, then the efficiency and performance of decoder-only LLMs are significantly limited by their auto-regressive nature. To enable LLMs to achieve high-quality SiMT as efficiently as offline translation, we propose a novel paradigm that includes constructing supervised fine-tuning (SFT) data for SiMT, along with new training and inference strategies. To replicate the token input/output stream in SiMT, the source and target tokens are rearranged into an interleaved sequence, separated by special tokens according to varying latency requirements. This enables powerful LLMs to learn read and write operations adaptively, based on varying latency prompts, while still maintaining efficient auto-regressive decoding. Experimental results show that, even with limited SFT data, our approach achieves state-of-the-art performance across various SiMT benchmarks, and preserves the original abilities of offline translation. Moreover, our approach generalizes well to document-level SiMT setting without requiring specific fine-tuning, even beyond the offline translation model.","authors":["Biao Fu","Minpeng Liao","Kai Fan","Chengxi Li","Liang Zhang","Yidong Chen","Xiaodong Shi"],"url":"https://arxiv.org/abs/2504.09570"}
{"created":"2025-04-15","title":"Improved FOX Optimization Algorithm","abstract":"Optimization algorithms are essential for solving many real-world problems. However, challenges such as premature convergence to local optima and the difficulty of effectively balancing exploration and exploitation often hinder their performance. To address these issues, this paper proposes an improved FOX optimization algorithm, Improved FOX (IFOX). The IFOX algorithm introduces a new adaptive mechanism for balancing exploration and exploitation based on fitness values. It also reduces the number of hyperparameters and simplifies the core equations of the original FOX. To evaluate its effectiveness, IFOX has been tested on classical uni-modal and multi-modal benchmark functions, as well as on benchmark sets from the Congress on Evolutionary Computation (CEC), in addition to two engineering design problems: Pressure Vessel Design and Economic Load Dispatch. The results show that IFOX outperforms existing optimization algorithms, achieving superior results on 51 benchmark functions. These findings underscore the strong potential of IFOX as a competitive and robust optimization algorithm for a wide range of applications.","authors":["Mahmood A. Jumaah","Yossra H. Ali","Tarik A. Rashid"],"url":"https://arxiv.org/abs/2504.09574"}
{"created":"2025-04-15","title":"Unification of Consensus-Based Multi-Objective Optimization and Multi-Robot Path Planning","abstract":"Multi-agent systems seeking consensus may also have other objective functions to optimize, requiring the research of multi-objective optimization in consensus. Several recent publications have explored this domain using various methods such as weighted-sum optimization and penalization methods. This paper reviews the state of the art for consensus-based multi-objective optimization, poses a multi-agent lunar rover exploration problem seeking consensus and maximization of explored area, and achieves optimal edge weights and steering angles by applying SQP algorithms.","authors":["Michael P. Wozniak"],"url":"https://arxiv.org/abs/2504.09577"}
{"created":"2025-04-15","title":"Bounds and Optimal Constructions of Generalized Merge-Convertible Codes for Code Conversion into LRCs","abstract":"Error-correcting codes are essential for ensuring fault tolerance in modern distributed data storage systems. However, in practice, factors such as the failure rates of storage devices can vary significantly over time, resulting in changes to the optimal code parameters. To reduce storage costs while maintaining efficiency, Maturana and Rashmi introduced a theoretical framework known as code conversion, which enables dynamic adjustment of code parameters according to device performance. In this paper, we focus exclusively on the bounds and constructions of generalized merge-convertible codes. First, we establish a new lower bound on the access cost when the final code is an $(r,\\delta)$-LRC. This bound unifies and generalizes all previously known bounds for merge conversion where the initial and final codes are either an LRC or an MDS code. We then construct a family of access-optimal MDS convertible codes by leveraging subgroups of the automorphism group of a rational function field. It is worth noting that our construction is also per-symbol read access-optimal. Next, we further extend our MDS-based construction to design access-optimal convertible codes for the conversion between $(r,\\delta)$-LRCs. Finally, using the parity-check matrix approach, we present a construction of access-optimal convertible codes that enable merge conversion from MDS codes to an $(r,\\delta)$-LRC. To the best of our knowledge, this is the first explicit optimal construction of code conversion between MDS codes and LRCs. All of our constructions are over finite fields whose sizes grow linearly with the code length.","authors":["Haoming Shi","Weijun Fang","Yuan Gao"],"url":"https://arxiv.org/abs/2504.09580"}
{"created":"2025-04-15","title":"Reduction of Supervision for Biomedical Knowledge Discovery","abstract":"Knowledge discovery is hindered by the increasing volume of publications and the scarcity of extensive annotated data. To tackle the challenge of information overload, it is essential to employ automated methods for knowledge extraction and processing. Finding the right balance between the level of supervision and the effectiveness of models poses a significant challenge. While supervised techniques generally result in better performance, they have the major drawback of demanding labeled data. This requirement is labor-intensive and time-consuming and hinders scalability when exploring new domains. In this context, our study addresses the challenge of identifying semantic relationships between biomedical entities (e.g., diseases, proteins) in unstructured text while minimizing dependency on supervision. We introduce a suite of unsupervised algorithms based on dependency trees and attention mechanisms and employ a range of pointwise binary classification methods. Transitioning from weakly supervised to fully unsupervised settings, we assess the methods' ability to learn from data with noisy labels. The evaluation on biomedical benchmark datasets explores the effectiveness of the methods. Our approach tackles a central issue in knowledge discovery: balancing performance with minimal supervision. By gradually decreasing supervision, we assess the robustness of pointwise binary classification techniques in handling noisy labels, revealing their capability to shift from weakly supervised to entirely unsupervised scenarios. Comprehensive benchmarking offers insights into the effectiveness of these techniques, suggesting an encouraging direction toward adaptable knowledge discovery systems, representing progress in creating data-efficient methodologies for extracting useful insights when annotated data is limited.","authors":["Christos Theodoropoulos","Andrei Catalin Coman","James Henderson","Marie-Francine Moens"],"url":"https://arxiv.org/abs/2504.09582"}
{"created":"2025-04-15","title":"AirVista-II: An Agentic System for Embodied UAVs Toward Dynamic Scene Semantic Understanding","abstract":"Unmanned Aerial Vehicles (UAVs) are increasingly important in dynamic environments such as logistics transportation and disaster response. However, current tasks often rely on human operators to monitor aerial videos and make operational decisions. This mode of human-machine collaboration suffers from significant limitations in efficiency and adaptability. In this paper, we present AirVista-II -- an end-to-end agentic system for embodied UAVs, designed to enable general-purpose semantic understanding and reasoning in dynamic scenes. The system integrates agent-based task identification and scheduling, multimodal perception mechanisms, and differentiated keyframe extraction strategies tailored for various temporal scenarios, enabling the efficient capture of critical scene information. Experimental results demonstrate that the proposed system achieves high-quality semantic understanding across diverse UAV-based dynamic scenarios under a zero-shot setting.","authors":["Fei Lin","Yonglin Tian","Tengchao Zhang","Jun Huang","Sangtian Guan","Fei-Yue Wang"],"url":"https://arxiv.org/abs/2504.09583"}
{"created":"2025-04-15","title":"Eccfrog512ck2: An Enhanced 512-bit Weierstrass Elliptic Curve","abstract":"Whilst many key exchange and digital signature methods use the NIST P256 (secp256r1) and secp256k1 curves, there is often a demand for increased security. With these curves, we have a 128-bit security. These security levels can be increased to 256-bit security with NIST P-521 Curve 448 and Brainpool-P512. This paper outlines a new curve - Eccfrog512ck2 - and which provides 256-bit security and enhanced performance over NIST P-521. Along with this, it has side-channel resistance and is designed to avoid weaknesses such as related to the MOV attack. It shows that Eccfrog512ck2 can have a 61.5% speed-up on scalar multiplication and a 33.3% speed-up on point generation over the NIST P-521 curve.","authors":["V\\'ictor Duarte Melo","William J. Buchanan"],"url":"https://arxiv.org/abs/2504.09584"}
{"created":"2025-04-15","title":"Short-Path Prompting in LLMs: Analyzing Reasoning Instability and Solutions for Robust Performance","abstract":"Recent years have witnessed significant progress in large language models' (LLMs) reasoning, which is largely due to the chain-of-thought (CoT) approaches, allowing models to generate intermediate reasoning steps before reaching the final answer. Building on these advances, state-of-the-art LLMs are instruction-tuned to provide long and detailed CoT pathways when responding to reasoning-related questions. However, human beings are naturally cognitive misers and will prompt language models to give rather short responses, thus raising a significant conflict with CoT reasoning. In this paper, we delve into how LLMs' reasoning performance changes when users provide short-path prompts. The results and analysis reveal that language models can reason effectively and robustly without explicit CoT prompts, while under short-path prompting, LLMs' reasoning ability drops significantly and becomes unstable, even on grade-school problems. To address this issue, we propose two approaches: an instruction-guided approach and a fine-tuning approach, both designed to effectively manage the conflict. Experimental results show that both methods achieve high accuracy, providing insights into the trade-off between instruction adherence and reasoning accuracy in current models.","authors":["Zuoli Tang","Junjie Ou","Kaiqin Hu","Chunwei Wu","Zhaoxin Huan","Chilin Fu","Xiaolu Zhang","Jun Zhou","Chenliang Li"],"url":"https://arxiv.org/abs/2504.09586"}
{"created":"2025-04-15","title":"GeoNav: Empowering MLLMs with Explicit Geospatial Reasoning Abilities for Language-Goal Aerial Navigation","abstract":"Language-goal aerial navigation is a critical challenge in embodied AI, requiring UAVs to localize targets in complex environments such as urban blocks based on textual specification. Existing methods, often adapted from indoor navigation, struggle to scale due to limited field of view, semantic ambiguity among objects, and lack of structured spatial reasoning. In this work, we propose GeoNav, a geospatially aware multimodal agent to enable long-range navigation. GeoNav operates in three phases-landmark navigation, target search, and precise localization-mimicking human coarse-to-fine spatial strategies. To support such reasoning, it dynamically builds two different types of spatial memory. The first is a global but schematic cognitive map, which fuses prior textual geographic knowledge and embodied visual cues into a top-down, annotated form for fast navigation to the landmark region. The second is a local but delicate scene graph representing hierarchical spatial relationships between blocks, landmarks, and objects, which is used for definite target localization. On top of this structured representation, GeoNav employs a spatially aware, multimodal chain-of-thought prompting mechanism to enable multimodal large language models with efficient and interpretable decision-making across stages. On the CityNav urban navigation benchmark, GeoNav surpasses the current state-of-the-art by up to 12.53% in success rate and significantly improves navigation efficiency, even in hard-level tasks. Ablation studies highlight the importance of each module, showcasing how geospatial representations and coarse-to-fine reasoning enhance UAV navigation.","authors":["Haotian Xu","Yue Hu","Chen Gao","Zhengqiu Zhu","Yong Zhao","Yong Li","Quanjun Yin"],"url":"https://arxiv.org/abs/2504.09587"}
{"created":"2025-04-15","title":"TextSplat: Text-Guided Semantic Fusion for Generalizable Gaussian Splatting","abstract":"Recent advancements in Generalizable Gaussian Splatting have enabled robust 3D reconstruction from sparse input views by utilizing feed-forward Gaussian Splatting models, achieving superior cross-scene generalization. However, while many methods focus on geometric consistency, they often neglect the potential of text-driven guidance to enhance semantic understanding, which is crucial for accurately reconstructing fine-grained details in complex scenes. To address this limitation, we propose TextSplat--the first text-driven Generalizable Gaussian Splatting framework. By employing a text-guided fusion of diverse semantic cues, our framework learns robust cross-modal feature representations that improve the alignment of geometric and semantic information, producing high-fidelity 3D reconstructions. Specifically, our framework employs three parallel modules to obtain complementary representations: the Diffusion Prior Depth Estimator for accurate depth information, the Semantic Aware Segmentation Network for detailed semantic information, and the Multi-View Interaction Network for refined cross-view features. Then, in the Text-Guided Semantic Fusion Module, these representations are integrated via the text-guided and attention-based feature aggregation mechanism, resulting in enhanced 3D Gaussian parameters enriched with detailed semantic cues. Experimental results on various benchmark datasets demonstrate improved performance compared to existing methods across multiple evaluation metrics, validating the effectiveness of our framework. The code will be publicly available.","authors":["Zhicong Wu","Hongbin Xu","Gang Xu","Ping Nie","Zhixin Yan","Jinkai Zheng","Liangqiong Qu","Ming Li","Liqiang Nie"],"url":"https://arxiv.org/abs/2504.09588"}
{"created":"2025-04-15","title":"Efficient LLM Serving on Hybrid Real-time and Best-effort Requests","abstract":"Recent breakthroughs in large Language Models (LLMs) have enabled various generative tasks on a single model. Real-world services (e.g., OpenAI's ChatGPT [27]) powered by an LLM often concurrently support latency-critical requests for interactive applications (e.g., question-answering systems, referred to as real-time or RT requests) and throughput-oriented requests for back-of-house processing (e.g., documents batch processing [28], referred to best-effort or BE requests), with complex hybrid inference workloads to the underlying model. State-of-the-art (SOTA) LLM serving systems dedicate machines to each type of request, towards either low inference latency or high serving throughput, respectively. This practice simplifies request scheduling and management but suffers from poor resource utilization. We propose BROS, a hybrid LLM serving system that aims to collocate RT/BE requests, meeting RT requests' latency requirements while maintaining BE requests' throughput. BROS formulates the problem of hybrid RT/BE request scheduling and solves it with a dynamic priority-based algorithm. BROS designs a bidirectional KV cache management mechanism, allowing RT requests to share KV memory with BE requests to remove the scheduling restrictions caused by insufficient KV memory and improve utilization. Extensive experiments validate that BROS achieves a good trade-off when serving hybrid RT and BE requests. It significantly reduces the latency of RT requests (up to 74.20%), improving their fine-grained service level objectives (SLOs) attainments (up to 36.38x), with negligible throughput reduction for BE requests, showing significant advantages over SOTA systems like vLLM and TGI.","authors":["Wan Borui","Zhao Juntao","Jiang Chenyu","Guo Chuanxiong","Wu Chuan"],"url":"https://arxiv.org/abs/2504.09590"}
{"created":"2025-04-15","title":"ControlNET: A Firewall for RAG-based LLM System","abstract":"Retrieval-Augmented Generation (RAG) has significantly enhanced the factual accuracy and domain adaptability of Large Language Models (LLMs). This advancement has enabled their widespread deployment across sensitive domains such as healthcare, finance, and enterprise applications. RAG mitigates hallucinations by integrating external knowledge, yet introduces privacy risk and security risk, notably data breaching risk and data poisoning risk. While recent studies have explored prompt injection and poisoning attacks, there remains a significant gap in comprehensive research on controlling inbound and outbound query flows to mitigate these threats. In this paper, we propose an AI firewall, ControlNET, designed to safeguard RAG-based LLM systems from these vulnerabilities. ControlNET controls query flows by leveraging activation shift phenomena to detect adversarial queries and mitigate their impact through semantic divergence. We conduct comprehensive experiments on four different benchmark datasets including Msmarco, HotpotQA, FinQA, and MedicalSys using state-of-the-art open source LLMs (Llama3, Vicuna, and Mistral). Our results demonstrate that ControlNET achieves over 0.909 AUROC in detecting and mitigating security threats while preserving system harmlessness. Overall, ControlNET offers an effective, robust, harmless defense mechanism, marking a significant advancement toward the secure deployment of RAG-based LLM systems.","authors":["Hongwei Yao","Haoran Shi","Yidou Chen","Yixin Jiang","Cong Wang","Zhan Qin","Kui Ren","Chun Chen"],"url":"https://arxiv.org/abs/2504.09593"}
{"created":"2025-04-15","title":"Revisiting Self-Attentive Sequential Recommendation","abstract":"Recommender systems are ubiquitous in on-line services to drive businesses. And many sequential recommender models were deployed in these systems to enhance personalization. The approach of using the transformer decoder as the sequential recommender was proposed years ago and is still a strong baseline in recent works. But this kind of sequential recommender model did not scale up well, compared to language models. Quite some details in the classical self-attentive sequential recommender model could be revisited, and some new experiments may lead to new findings, without changing the general model structure which was the focus of many previous works. In this paper, we show the details and propose new experiment methodologies for future research on sequential recommendation, in hope to motivate further exploration to new findings in this area.","authors":["Zan Huang"],"url":"https://arxiv.org/abs/2504.09596"}
{"created":"2025-04-15","title":"Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws","abstract":"Large Language Models (LLMs) have demonstrated remarkable capabilities across numerous tasks, yet principled explanations for their underlying mechanisms and several phenomena, such as scaling laws, hallucinations, and related behaviors, remain elusive. In this work, we revisit the classical relationship between compression and prediction, grounded in Kolmogorov complexity and Shannon information theory, to provide deeper insights into LLM behaviors. By leveraging the Kolmogorov Structure Function and interpreting LLM compression as a two-part coding process, we offer a detailed view of how LLMs acquire and store information across increasing model and data scales -- from pervasive syntactic patterns to progressively rarer knowledge elements. Motivated by this theoretical perspective and natural assumptions inspired by Heap's and Zipf's laws, we introduce a simplified yet representative hierarchical data-generation framework called the Syntax-Knowledge model. Under the Bayesian setting, we show that prediction and compression within this model naturally lead to diverse learning and scaling behaviors of LLMs. In particular, our theoretical analysis offers intuitive and principled explanations for both data and model scaling laws, the dynamics of knowledge acquisition during training and fine-tuning, factual knowledge hallucinations in LLMs. The experimental results validate our theoretical predictions.","authors":["Zhixuan Pan","Shaowen Wang","Jian Li"],"url":"https://arxiv.org/abs/2504.09597"}
{"created":"2025-04-15","title":"DualPrompt-MedCap: A Dual-Prompt Enhanced Approach for Medical Image Captioning","abstract":"Medical image captioning via vision-language models has shown promising potential for clinical diagnosis assistance. However, generating contextually relevant descriptions with accurate modality recognition remains challenging. We present DualPrompt-MedCap, a novel dual-prompt enhancement framework that augments Large Vision-Language Models (LVLMs) through two specialized components: (1) a modality-aware prompt derived from a semi-supervised classification model pretrained on medical question-answer pairs, and (2) a question-guided prompt leveraging biomedical language model embeddings. To address the lack of captioning ground truth, we also propose an evaluation framework that jointly considers spatial-semantic relevance and medical narrative quality. Experiments on multiple medical datasets demonstrate that DualPrompt-MedCap outperforms the baseline BLIP-3 by achieving a 22% improvement in modality recognition accuracy while generating more comprehensive and question-aligned descriptions. Our method enables the generation of clinically accurate reports that can serve as medical experts' prior knowledge and automatic annotations for downstream vision-language tasks.","authors":["Yining Zhao","Ali Braytee","Mukesh Prasad"],"url":"https://arxiv.org/abs/2504.09598"}
{"created":"2025-04-15","title":"Mixture-of-Shape-Experts (MoSE): End-to-End Shape Dictionary Framework to Prompt SAM for Generalizable Medical Segmentation","abstract":"Single domain generalization (SDG) has recently attracted growing attention in medical image segmentation. One promising strategy for SDG is to leverage consistent semantic shape priors across different imaging protocols, scanner vendors, and clinical sites. However, existing dictionary learning methods that encode shape priors often suffer from limited representational power with a small set of offline computed shape elements, or overfitting when the dictionary size grows. Moreover, they are not readily compatible with large foundation models such as the Segment Anything Model (SAM). In this paper, we propose a novel Mixture-of-Shape-Experts (MoSE) framework that seamlessly integrates the idea of mixture-of-experts (MoE) training into dictionary learning to efficiently capture diverse and robust shape priors. Our method conceptualizes each dictionary atom as a shape expert, which specializes in encoding distinct semantic shape information. A gating network dynamically fuses these shape experts into a robust shape map, with sparse activation guided by SAM encoding to prevent overfitting. We further provide this shape map as a prompt to SAM, utilizing the powerful generalization capability of SAM through bidirectional integration. All modules, including the shape dictionary, are trained in an end-to-end manner. Extensive experiments on multiple public datasets demonstrate its effectiveness.","authors":["Jia Wei","Xiaoqi Zhao","Jonghye Woo","Jinsong Ouyang","Georges El Fakhri","Qingyu Chen","Xiaofeng Liu"],"url":"https://arxiv.org/abs/2504.09601"}
{"created":"2025-04-15","title":"Mitigating Many-Shot Jailbreaking","abstract":"Many-shot jailbreaking (MSJ) is an adversarial technique that exploits the long context windows of modern LLMs to circumvent model safety training by including in the prompt many examples of a ``fake'' assistant responding inappropriately before the final request. With enough examples, the model's in-context learning abilities override its safety training, and it responds as if it were the ``fake'' assistant. In this work, we probe the effectiveness of different fine tuning and input sanitization approaches on mitigating MSJ attacks, alone and in combination. We find incremental mitigation effectiveness for each, and we show that the combined techniques significantly reduce the effectiveness of MSJ attacks, while retaining model performance in benign in-context learning and conversational tasks. We suggest that our approach could meaningfully ameliorate this vulnerability if incorporated into model safety post-training.","authors":["Christopher M. Ackerman","Nina Panickssery"],"url":"https://arxiv.org/abs/2504.09604"}
{"created":"2025-04-15","title":"Early-Bird Diffusion: Investigating and Leveraging Timestep-Aware Early-Bird Tickets in Diffusion Models for Efficient Training","abstract":"Training diffusion models (DMs) requires substantial computational resources due to multiple forward and backward passes across numerous timesteps, motivating research into efficient training techniques. In this paper, we propose EB-Diff-Train, a new efficient DM training approach that is orthogonal to other methods of accelerating DM training, by investigating and leveraging Early-Bird (EB) tickets -- sparse subnetworks that manifest early in the training process and maintain high generation quality.","authors":["Lexington Whalen (Celine)","Zhenbang Du (Celine)","Haoran You (Celine)","Chaojian Li (Celine)","Sixu Li (Celine)","Yingyan (Celine)","Lin"],"url":"https://arxiv.org/abs/2504.09606"}
{"created":"2025-04-15","title":"ERL-MPP: Evolutionary Reinforcement Learning with Multi-head Puzzle Perception for Solving Large-scale Jigsaw Puzzles of Eroded Gaps","abstract":"Solving jigsaw puzzles has been extensively studied. While most existing models focus on solving either small-scale puzzles or puzzles with no gap between fragments, solving large-scale puzzles with gaps presents distinctive challenges in both image understanding and combinatorial optimization. To tackle these challenges, we propose a framework of Evolutionary Reinforcement Learning with Multi-head Puzzle Perception (ERL-MPP) to derive a better set of swapping actions for solving the puzzles. Specifically, to tackle the challenges of perceiving the puzzle with gaps, a Multi-head Puzzle Perception Network (MPPN) with a shared encoder is designed, where multiple puzzlet heads comprehensively perceive the local assembly status, and a discriminator head provides a global assessment of the puzzle. To explore the large swapping action space efficiently, an Evolutionary Reinforcement Learning (EvoRL) agent is designed, where an actor recommends a set of suitable swapping actions from a large action space based on the perceived puzzle status, a critic updates the actor using the estimated rewards and the puzzle status, and an evaluator coupled with evolutionary strategies evolves the actions aligning with the historical assembly experience. The proposed ERL-MPP is comprehensively evaluated on the JPLEG-5 dataset with large gaps and the MIT dataset with large-scale puzzles. It significantly outperforms all state-of-the-art models on both datasets.","authors":["Xingke Song","Xiaoying Yang","Chenglin Yao","Jianfeng Ren","Ruibin Bai","Xin Chen","Xudong Jiang"],"url":"https://arxiv.org/abs/2504.09608"}
{"created":"2025-04-15","title":"A highly maneuverable flying squirrel drone with agility-improving foldable wings","abstract":"Drones, like most airborne aerial vehicles, face inherent disadvantages in achieving agile flight due to their limited thrust capabilities. These physical constraints cannot be fully addressed through advancements in control algorithms alone. Drawing inspiration from the winged flying squirrel, this paper proposes a highly maneuverable drone equipped with agility-enhancing foldable wings. By leveraging collaborative control between the conventional propeller system and the foldable wings-coordinated through the Thrust-Wing Coordination Control (TWCC) framework-the controllable acceleration set is expanded, enabling the generation of abrupt vertical forces that are unachievable with traditional wingless drones. The complex aerodynamics of the foldable wings are modeled using a physics-assisted recurrent neural network (paRNN), which calibrates the angle of attack (AOA) to align with the real aerodynamic behavior of the wings. The additional air resistance generated by appropriately deploying these wings significantly improves the tracking performance of the proposed \"flying squirrel\" drone. The model is trained on real flight data and incorporates flat-plate aerodynamic principles. Experimental results demonstrate that the proposed flying squirrel drone achieves a 13.1% improvement in tracking performance, as measured by root mean square error (RMSE), compared to a conventional wingless drone. A demonstration video is available on YouTube: https://youtu.be/O8nrip18azY.","authors":["Dohyeon Lee","Jun-Gill Kang","Soohee Han"],"url":"https://arxiv.org/abs/2504.09609"}
{"created":"2025-04-15","title":"A Systematic Literature Review of Infrastructure Studies in SIGCHI","abstract":"Infrastructure is an indispensable part of human life. Over the past decades, the Human-Computer Interaction (HCI) community has paid increasing attention to human interactions with infrastructure. In this paper, we conducted a systematic literature review on infrastructure studies in SIGCHI, one of the most influential communities in HCI. We collected a total of 174 primary studies, covering works published between 2006 and 2023. Most of these studies are inspired by Susan Leigh Star's notion of infrastructure. We identify three major themes in infrastructure studies: growing infrastructure, appropriating infrastructure, and coping with infrastructure. Our review highlights a prevailing trend in SIGCHI's infrastructure research: a focus on informal infrastructural activities across various sociotechnical contexts. In particular, we examine studies that problematize infrastructure and alert the HCI community to its potentially harmful aspects.","authors":["Yao Lyu","Jie Cai","John M. Carroll"],"url":"https://arxiv.org/abs/2504.09612"}
{"created":"2025-04-15","title":"Counting Number of Triangulations of Point Sets: Reinterpreting and Generalizing the Triangulation Polynomials","abstract":"We describe a framework that unifies the two types of polynomials introduced respectively by Bacher and Mouton and by Rutschmann and Wettstein to analyze the number of triangulations of point sets. Using this insight, we generalize the triangulation polynomials of chains to a wider class of near-edges, enabling efficient computation of the number of triangulations of certain families of point sets. We use the framework to try to improve the result in Rutschmann and Wettstein without success, suggesting that their result is close to optimal.","authors":["Hong Duc Bui"],"url":"https://arxiv.org/abs/2504.09615"}
{"created":"2025-04-15","title":"Metropolis-Hastings Captioning Game: Knowledge Fusion of Vision Language Models via Decentralized Bayesian Inference","abstract":"We propose the Metropolis-Hastings Captioning Game (MHCG), a method to fuse knowledge of multiple vision-language models (VLMs) by learning from each other. Although existing methods that combine multiple models suffer from inference costs and architectural constraints, MHCG avoids these problems by performing decentralized Bayesian inference through a process resembling a language game. The knowledge fusion process establishes communication between two VLM agents alternately captioning images and learning from each other. We conduct two image-captioning experiments with two VLMs, each pre-trained on a different dataset. The first experiment demonstrates that MHCG achieves consistent improvement in reference-free evaluation metrics. The second experiment investigates how MHCG contributes to sharing VLMs' category-level vocabulary by observing the occurrence of the vocabulary in the generated captions.","authors":["Yuta Matsui","Ryosuke Yamaki","Ryo Ueda","Seitaro Shinagawa","Tadahiro Taniguchi"],"url":"https://arxiv.org/abs/2504.09620"}
{"created":"2025-04-15","title":"Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images","abstract":"Global contextual information and local detail features are essential for haze removal tasks. Deep learning models perform well on small, low-resolution images, but they encounter difficulties with large, high-resolution ones due to GPU memory limitations. As a compromise, they often resort to image slicing or downsampling. The former diminishes global information, while the latter discards high-frequency details. To address these challenges, we propose DehazeXL, a haze removal method that effectively balances global context and local feature extraction, enabling end-to-end modeling of large images on mainstream GPU hardware. Additionally, to evaluate the efficiency of global context utilization in haze removal performance, we design a visual attribution method tailored to the characteristics of haze removal tasks. Finally, recognizing the lack of benchmark datasets for haze removal in large images, we have developed an ultra-high-resolution haze removal dataset (8KDehaze) to support model training and testing. It includes 10000 pairs of clear and hazy remote sensing images, each sized at 8192 $\\times$ 8192 pixels. Extensive experiments demonstrate that DehazeXL can infer images up to 10240 $\\times$ 10240 pixels with only 21 GB of memory, achieving state-of-the-art results among all evaluated methods. The source code and experimental dataset are available at https://github.com/CastleChen339/DehazeXL.","authors":["Jiuchen Chen","Xinyu Yan","Qizhi Xu","Kaiqi Li"],"url":"https://arxiv.org/abs/2504.09621"}
{"created":"2025-04-15","title":"Ges3ViG: Incorporating Pointing Gestures into Language-Based 3D Visual Grounding for Embodied Reference Understanding","abstract":"3-Dimensional Embodied Reference Understanding (3D-ERU) combines a language description and an accompanying pointing gesture to identify the most relevant target object in a 3D scene. Although prior work has explored pure language-based 3D grounding, there has been limited exploration of 3D-ERU, which also incorporates human pointing gestures. To address this gap, we introduce a data augmentation framework-Imputer, and use it to curate a new benchmark dataset-ImputeRefer for 3D-ERU, by incorporating human pointing gestures into existing 3D scene datasets that only contain language instructions. We also propose Ges3ViG, a novel model for 3D-ERU that achieves ~30% improvement in accuracy as compared to other 3D-ERU models and ~9% compared to other purely language-based 3D grounding models. Our code and dataset are available at https://github.com/AtharvMane/Ges3ViG.","authors":["Atharv Mahesh Mane","Dulanga Weerakoon","Vigneshwaran Subbaraju","Sougata Sen","Sanjay E. Sarma","Archan Misra"],"url":"https://arxiv.org/abs/2504.09623"}
{"created":"2025-04-15","title":"Slow Thinking for Sequential Recommendation","abstract":"To develop effective sequential recommender systems, numerous methods have been proposed to model historical user behaviors. Despite the effectiveness, these methods share the same fast thinking paradigm. That is, for making recommendations, these methods typically encodes user historical interactions to obtain user representations and directly match these representations with candidate item representations. However, due to the limited capacity of traditional lightweight recommendation models, this one-step inference paradigm often leads to suboptimal performance. To tackle this issue, we present a novel slow thinking recommendation model, named STREAM-Rec. Our approach is capable of analyzing historical user behavior, generating a multi-step, deliberative reasoning process, and ultimately delivering personalized recommendations. In particular, we focus on two key challenges: (1) identifying the suitable reasoning patterns in recommender systems, and (2) exploring how to effectively stimulate the reasoning capabilities of traditional recommenders. To this end, we introduce a three-stage training framework. In the first stage, the model is pretrained on large-scale user behavior data to learn behavior patterns and capture long-range dependencies. In the second stage, we design an iterative inference algorithm to annotate suitable reasoning traces by progressively refining the model predictions. This annotated data is then used to fine-tune the model. Finally, in the third stage, we apply reinforcement learning to further enhance the model generalization ability. Extensive experiments validate the effectiveness of our proposed method.","authors":["Junjie Zhang","Beichen Zhang","Wenqi Sun","Hongyu Lu","Wayne Xin Zhao","Yu Chen","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2504.09627"}
{"created":"2025-04-15","title":"Outage Probability Analysis for OTFS with Finite Blocklength","abstract":"Orthogonal time frequency space (OTFS) modulation is widely acknowledged as a prospective waveform for future wireless communication networks.To provide insights for the practical system design, this paper analyzes the outage probability of OTFS modulation with finite blocklength.To begin with, we present the system model and formulate the analysis of outage probability for OTFS with finite blocklength as an equivalent problem of calculating the outage probability with finite blocklength over parallel additive white Gaussian noise (AWGN) channels.Subsequently, we apply the equivalent noise approach to derive a lower bound on the outage probability of OTFS with finite blocklength under both average power allocation and water-filling power allocation strategies, respectively.Finally, the lower bounds of the outage probability are determined using the Monte-Carlo method for the two power allocation strategies.The impact of the number of resolvable paths and coding rates on the outage probability is analyzed, and the simulation results are compared with the theoretical lower bounds.","authors":["Xin Zhang","Wensheng Lin","Lixin Li","Zhu Han","Tad Matsumoto"],"url":"https://arxiv.org/abs/2504.09628"}
{"created":"2025-04-15","title":"Quantization Error Propagation: Revisiting Layer-Wise Post-Training Quantization","abstract":"Layer-wise post-training quantization has emerged as a widely used technique for compressing large language models (LLMs) without retraining. However, recent progress in this line of research is saturating, underscoring the need to revisit its core limitation and explore further improvements. This study identifies a critical bottleneck in existing layer-wise PTQ methods: the accumulation of quantization errors across layers significantly degrades performance, particularly in low-bit regimes. To address this, we propose Quantization Error Propagation (QEP), a lightweight and general framework that enhances layer-wise PTQ by explicitly propagating the quantization error which enable compensating for accumulated quantization errors. Additionally, we introduce a tunable propagation mechanism that allows for control over both propagation strength and computational overhead, making the framework adaptable to various architectures and resource constraints. Empirical evaluation on LLaMA2 models (7B, 13B, 70B) demonstrate that incorporating QEP into standard layer-wise PTQ pipelines outperforms standard PTQ methods. Notably, QEP yields substantial performance improvements under extreme low-bit quantization settings.","authors":["Yamato Arai","Yuma Ichikawa"],"url":"https://arxiv.org/abs/2504.09629"}
{"created":"2025-04-15","title":"Evaluating Machine Learning-Driven Intrusion Detection Systems in IoT: Performance and Energy Consumption","abstract":"In the evolving landscape of the Internet of Things (IoT), Machine Learning (ML)-based Intrusion Detection Systems (IDS) represent a significant advancement, especially when integrated with Software-Defined Networking (SDN). These systems play a critical role in enhancing security infrastructure within resource-constrained IoT systems. Despite their growing adoption, limited research has explored the impact of ML-based IDS on key performance metrics, such as CPU load, CPU usage, and energy consumption, particularly under real-time cyber threats. This study bridges that gap through an empirical evaluation of cutting-edge ML-based IDSs deployed at the edge of IoT networks under both benign and attack scenarios. Additionally, we investigate how SDN's centralized control and dynamic resource management influence IDS performance. Our experimental framework compares traditional ML-based IDS with deep learning (DL)-based counterparts, both with and without SDN integration. Results reveal that edge-deployed ML-based IDSs significantly impact system performance during cyber threats, with marked increases in resource consumption. SDN integration further influences these outcomes, emphasizing the need for optimized architectural design. Statistical analysis using ANOVA confirms the significance of our findings. This research provides critical insights into the performance and trade-offs of deploying ML-based IDSs in edge-based IoT systems.","authors":["Saeid Jamshidi","Kawser Wazed Nafi","Amin Nikanjam","Foutse Khomh"],"url":"https://arxiv.org/abs/2504.09634"}
{"created":"2025-04-15","title":"A Two-Stage Interpretable Matching Framework for Causal Inference","abstract":"Matching in causal inference from observational data aims to construct treatment and control groups with similar distributions of covariates, thereby reducing confounding and ensuring an unbiased estimation of treatment effects. This matched sample closely mimics a randomized controlled trial (RCT), thus improving the quality of causal estimates. We introduce a novel Two-stage Interpretable Matching (TIM) framework for transparent and interpretable covariate matching. In the first stage, we perform exact matching across all available covariates. For treatment and control units without an exact match in the first stage, we proceed to the second stage. Here, we iteratively refine the matching process by removing the least significant confounder in each iteration and attempting exact matching on the remaining covariates. We learn a distance metric for the dropped covariates to quantify closeness to the treatment unit(s) within the corresponding strata. We used these high- quality matches to estimate the conditional average treatment effects (CATEs). To validate TIM, we conducted experiments on synthetic datasets with varying association structures and correlations. We assessed its performance by measuring bias in CATE estimation and evaluating multivariate overlap between treatment and control groups before and after matching. Additionally, we apply TIM to a real-world healthcare dataset from the Centers for Disease Control and Prevention (CDC) to estimate the causal effect of high cholesterol on diabetes. Our results demonstrate that TIM improves CATE estimates, increases multivariate overlap, and scales effectively to high-dimensional data, making it a robust tool for causal inference in observational data.","authors":["Sahil Shikalgar","Md. Noor-E-Alam"],"url":"https://arxiv.org/abs/2504.09635"}
{"created":"2025-04-15","title":"Optimal convergence rates for the finite element approximation of the Sobolev constant","abstract":"We establish optimal convergence rates for the P1 finite element approximation of the Sobolev constant in arbitrary dimensions N\\geq 2 and for Lebesgue exponents 1<p><N. Our analysis relies on a refined study of the Sobolev deficit in suitable quasi-norms, which have been introduced and utilized in the context of finite element approximations of the p- Laplacian. The proof further involves sharp estimates for the finite element approximation of Sobolev minimizers.","authors":["Liviu I. Ignat","Enrique Zuazua"],"url":"https://arxiv.org/abs/2504.09637"}
{"created":"2025-04-15","title":"Leveraging Reasoning Model Answers to Enhance Non-Reasoning Model Capability","abstract":"Recent advancements in large language models (LLMs), such as DeepSeek-R1 and OpenAI-o1, have demonstrated the significant effectiveness of test-time scaling, achieving substantial performance gains across various benchmarks. These advanced models utilize deliberate \"thinking\" steps to systematically enhance answer quality. In this paper, we propose leveraging these high-quality outputs generated by reasoning-intensive models to improve less computationally demanding, non-reasoning models. We explore and compare methodologies for utilizing the answers produced by reasoning models to train and improve non-reasoning models. Through straightforward Supervised Fine-Tuning (SFT) experiments on established benchmarks, we demonstrate consistent improvements across various benchmarks, underscoring the potential of this approach for advancing the ability of models to answer questions directly.","authors":["Haotian Wang","Han Zhao","Shuaiting Chen","Xiaoyu Tian","Sitong Zhao","Yunjie Ji","Yiping Peng","Xiangang Li"],"url":"https://arxiv.org/abs/2504.09639"}
{"created":"2025-04-15","title":"TinyLLaVA-Video-R1: Towards Smaller LMMs for Video Reasoning","abstract":"Recently, improving the reasoning ability of large multimodal models (LMMs) through reinforcement learning has made great progress. However, most existing works are based on highly reasoning-intensive datasets such as mathematics and code, and researchers generally choose large-scale models as the foundation. We argue that exploring small-scale models' reasoning capabilities remains valuable for researchers with limited computational resources. Moreover, enabling models to explain their reasoning processes on general question-answering datasets is equally meaningful. Therefore, we present the small-scale video reasoning model TinyLLaVA-Video-R1. Based on TinyLLaVA-Video, a traceably trained video understanding model with no more than 4B parameters, it not only demonstrates significantly improved reasoning and thinking capabilities after using reinforcement learning on general Video-QA datasets, but also exhibits the emergent characteristic of \"aha moments\". Furthermore, we share a series of experimental findings, aiming to provide practical insights for future exploration of video reasoning (thinking) abilities in small-scale models. It is available at https://github.com/ZhangXJ199/TinyLLaVA-Video-R1.","authors":["Xingjian Zhang","Siwei Wen","Wenjun Wu","Lei Huang"],"url":"https://arxiv.org/abs/2504.09641"}
{"created":"2025-04-15","title":"HBS -- Hardware Build System: A Tcl-based, minimal common abstraction approach for build system for hardware designs","abstract":"Build systems become an indispensable part of the software implementation and deployment process. New programming languages are released with the build system integrated into the language tools, for example, Go, Rust, or Zig. However, in the hardware description domain, no official build systems have been released with the predominant Hardware Description Languages (HDL) such as VHDL or SystemVerilog. Moreover, hardware design projects are often multilanguage.","authors":["Micha{\\l} Kruszewski"],"url":"https://arxiv.org/abs/2504.09642"}
{"created":"2025-04-15","title":"Iterative Self-Training for Code Generation via Reinforced Re-Ranking","abstract":"Generating high-quality code that solves complex programming tasks is challenging, especially with current decoder-based models that produce highly stochastic outputs. In code generation, even minor errors can easily break the entire solution. Leveraging multiple sampled solutions can significantly improve the overall output quality.","authors":["Nikita Sorokin","Ivan Sedykh","Valentin Malykh"],"url":"https://arxiv.org/abs/2504.09643"}
{"created":"2025-04-15","title":"SegEarth-R1: Geospatial Pixel Reasoning via Large Language Model","abstract":"Remote sensing has become critical for understanding environmental dynamics, urban planning, and disaster management. However, traditional remote sensing workflows often rely on explicit segmentation or detection methods, which struggle to handle complex, implicit queries that require reasoning over spatial context, domain knowledge, and implicit user intent. Motivated by this, we introduce a new task, \\ie, geospatial pixel reasoning, which allows implicit querying and reasoning and generates the mask of the target region. To advance this task, we construct and release the first large-scale benchmark dataset called EarthReason, which comprises 5,434 manually annotated image masks with over 30,000 implicit question-answer pairs. Moreover, we propose SegEarth-R1, a simple yet effective language-guided segmentation baseline that integrates a hierarchical visual encoder, a large language model (LLM) for instruction parsing, and a tailored mask generator for spatial correlation. The design of SegEarth-R1 incorporates domain-specific adaptations, including aggressive visual token compression to handle ultra-high-resolution remote sensing images, a description projection module to fuse language and multi-scale features, and a streamlined mask prediction pipeline that directly queries description embeddings. Extensive experiments demonstrate that SegEarth-R1 achieves state-of-the-art performance on both reasoning and referring segmentation tasks, significantly outperforming traditional and LLM-based segmentation methods. Our data and code will be released at https://github.com/earth-insights/SegEarth-R1.","authors":["Kaiyu Li","Zepeng Xin","Li Pang","Chao Pang","Yupeng Deng","Jing Yao","Guisong Xia","Deyu Meng","Zhi Wang","Xiangyong Cao"],"url":"https://arxiv.org/abs/2504.09644"}
{"created":"2025-04-15","title":"Myanmar XNLI: Building a Dataset and Exploring Low-resource Approaches to Natural Language Inference with Myanmar","abstract":"Despite dramatic recent progress in NLP, it is still a major challenge to apply Large Language Models (LLM) to low-resource languages. This is made visible in benchmarks such as Cross-Lingual Natural Language Inference (XNLI), a key task that demonstrates cross-lingual capabilities of NLP systems across a set of 15 languages. In this paper, we extend the XNLI task for one additional low-resource language, Myanmar, as a proxy challenge for broader low-resource languages, and make three core contributions. First, we build a dataset called Myanmar XNLI (myXNLI) using community crowd-sourced methods, as an extension to the existing XNLI corpus. This involves a two-stage process of community-based construction followed by expert verification; through an analysis, we demonstrate and quantify the value of the expert verification stage in the context of community-based construction for low-resource languages. We make the myXNLI dataset available to the community for future research. Second, we carry out evaluations of recent multilingual language models on the myXNLI benchmark, as well as explore data-augmentation methods to improve model performance. Our data-augmentation methods improve model accuracy by up to 2 percentage points for Myanmar, while uplifting other languages at the same time. Third, we investigate how well these data-augmentation methods generalise to other low-resource languages in the XNLI dataset.","authors":["Aung Kyaw Htet","Mark Dras"],"url":"https://arxiv.org/abs/2504.09645"}
{"created":"2025-04-15","title":"Building AI Service Repositories for On-Demand Service Orchestration in 6G AI-RAN","abstract":"Efficient orchestration of AI services in 6G AI-RAN requires well-structured, ready-to-deploy AI service repositories combined with orchestration methods adaptive to diverse runtime contexts across radio access, edge, and cloud layers. Current literature lacks comprehensive frameworks for constructing such repositories and generally overlooks key practical orchestration factors. This paper systematically identifies and categorizes critical attributes influencing AI service orchestration in 6G networks and introduces an open-source, LLM-assisted toolchain that automates service packaging, deployment, and runtime profiling. We validate the proposed toolchain through the Cranfield AI Service repository case study, demonstrating significant automation benefits, reduced manual coding efforts, and the necessity of infrastructure-specific profiling, paving the way for more practical orchestration frameworks.","authors":["Yun Tang","Mengbang Zou","Udhaya Chandhar Srinivasan","Obumneme Umealor","Dennis Kevogo","Benjamin James Scott","Weisi Guo"],"url":"https://arxiv.org/abs/2504.09647"}
{"created":"2025-04-15","title":"RANSAC Revisited: An Improved Algorithm for Robust Subspace Recovery under Adversarial and Noisy Corruptions","abstract":"In this paper, we study the problem of robust subspace recovery (RSR) in the presence of both strong adversarial corruptions and Gaussian noise. Specifically, given a limited number of noisy samples -- some of which are tampered by an adaptive and strong adversary -- we aim to recover a low-dimensional subspace that approximately contains a significant fraction of the uncorrupted samples, up to an error that scales with the Gaussian noise. Existing approaches to this problem often suffer from high computational costs or rely on restrictive distributional assumptions, limiting their applicability in truly adversarial settings. To address these challenges, we revisit the classical random sample consensus (RANSAC) algorithm, which offers strong robustness to adversarial outliers, but sacrifices efficiency and robustness against Gaussian noise and model misspecification in the process. We propose a two-stage algorithm, RANSAC+, that precisely pinpoints and remedies the failure modes of standard RANSAC. Our method is provably robust to both Gaussian and adversarial corruptions, achieves near-optimal sample complexity without requiring prior knowledge of the subspace dimension, and is more efficient than existing RANSAC-type methods.","authors":["Guixian Chen","Jianhao Ma","Salar Fattahi"],"url":"https://arxiv.org/abs/2504.09648"}
{"created":"2025-04-15","title":"GitBugs: Bug Reports for Duplicate Detection, Retrieval Augmented Generation, Triage, and More","abstract":"Bug reports provide critical insights into software quality, yet existing datasets often suffer from limited scope, outdated content, or insufficient metadata for machine learning. To address these limitations, we present GitBugs-a comprehen- sive and up-to-date dataset comprising over 150,000 bug reports from nine actively maintained open-source projects, including Firefox, Cassandra, and VS Code. GitBugs aggregates data from Github, Bugzilla and Jira issue trackers, offering standardized categorical fields for classification tasks and predefined train/test splits for duplicate bug detection. In addition, it includes ex- ploratory analysis notebooks and detailed project-level statistics, such as duplicate rates and resolution times. GitBugs supports various software engineering research tasks, including duplicate detection, retrieval augmented generation, resolution prediction, automated triaging, and temporal analysis. The openly licensed dataset provides a valuable cross-project resource for bench- marking and advancing automated bug report analysis. Access the data and code at https://github.com/av9ash/gitbugs/.","authors":["Avinash Patil"],"url":"https://arxiv.org/abs/2504.09651"}
{"created":"2025-04-15","title":"Bridging Immutability with Flexibility: A Scheme for Secure and Efficient Smart Contract Upgrades","abstract":"The emergence of blockchain technology has revolutionized contract execution through the introduction of smart contracts. Ethereum, the leading blockchain platform, leverages smart contracts to power decentralized applications (DApps), enabling transparent and self-executing systems across various domains. While the immutability of smart contracts enhances security and trust, it also poses significant challenges for updates, defect resolution, and adaptation to changing requirements. Existing upgrade mechanisms are complex, resource-intensive, and costly in terms of gas consumption, often compromising security and limiting practical adoption. To address these challenges, we propose FlexiContracts+, a novel scheme that reimagines smart contracts by enabling secure, in-place upgrades on Ethereum while preserving historical data without relying on multiple contracts or extensive pre-deployment planning. FlexiContracts+ enhances security, simplifies development, reduces engineering overhead, and supports adaptable, expandable smart contracts. Comprehensive testing demonstrates that FlexiContracts+ achieves a practical balance between immutability and flexibility, advancing the capabilities of smart contract systems.","authors":["Tahrim Hossain","Sakib Hassan","Faisal Haque Bappy","Muhammad Nur Yanhaona","Tarannum Shaila Zaman","Tariqul Islam"],"url":"https://arxiv.org/abs/2504.09652"}
{"created":"2025-04-15","title":"KeyVID: Keyframe-Aware Video Diffusion for Audio-Synchronized Visual Animation","abstract":"Generating video from various conditions, such as text, image, and audio, enables both spatial and temporal control, leading to high-quality generation results. Videos with dramatic motions often require a higher frame rate to ensure smooth motion. Currently, most audio-to-visual animation models use uniformly sampled frames from video clips. However, these uniformly sampled frames fail to capture significant key moments in dramatic motions at low frame rates and require significantly more memory when increasing the number of frames directly. In this paper, we propose KeyVID, a keyframe-aware audio-to-visual animation framework that significantly improves the generation quality for key moments in audio signals while maintaining computation efficiency. Given an image and an audio input, we first localize keyframe time steps from the audio. Then, we use a keyframe generator to generate the corresponding visual keyframes. Finally, we generate all intermediate frames using the motion interpolator. Through extensive experiments, we demonstrate that KeyVID significantly improves audio-video synchronization and video quality across multiple datasets, particularly for highly dynamic motions. The code is released in https://github.com/XingruiWang/KeyVID.","authors":["Xingrui Wang","Jiang Liu","Ze Wang","Xiaodong Yu","Jialian Wu","Ximeng Sun","Yusheng Su","Alan Yuille","Zicheng Liu","Emad Barsoum"],"url":"https://arxiv.org/abs/2504.09656"}
{"created":"2025-04-15","title":"Nonlinear Online Optimization for Vehicle-Home-Grid Integration including Household Load Prediction and Battery Degradation","abstract":"This paper investigates the economic impact of vehicle-home-grid integration, by proposing an online energy management algorithm that optimizes energy flows between an electric vehicle (EV), a household, and the electrical grid. The algorithm leverages vehicle-to-home (V2H) for self-consumption and vehicle-to-grid (V2G) for energy trading, adapting to real-time conditions through a hybrid long short-term memory (LSTM) neural network for accurate household load prediction, alongside a comprehensive nonlinear battery degradation model accounting for both cycle and calendar aging. Simulation results reveal significant economic advantages: compared to smart unidirectional charging, the proposed method yields an annual economic benefit of up to EUR 3046.81, despite a modest 1.96% increase in battery degradation. Even under unfavorable market conditions, where V2G energy selling generates no revenue, V2H alone ensures yearly savings of EUR 425.48. A systematic sensitivity analysis investigates how variations in battery capacity, household load, and price ratios affect economic outcomes, confirming the consistent benefits of bidirectional energy exchange. These findings highlight the potential of EVs as active energy nodes, enabling sustainable energy management and cost-effective battery usage in real-world conditions.","authors":["Francesco Popolizio","Torsten Wik","Chih Feng Lee","Changfu Zou"],"url":"https://arxiv.org/abs/2504.09657"}
{"created":"2025-04-15","title":"AgentDynEx: Nudging the Mechanics and Dynamics of Multi-Agent Simulations","abstract":"Multi-agent large language model simulations have the potential to model complex human behaviors and interactions. If the mechanics are set up properly, unanticipated and valuable social dynamics can surface. However, it is challenging to consistently enforce simulation mechanics while still allowing for notable and emergent dynamics. We present AgentDynEx, an AI system that helps set up simulations from user-specified mechanics and dynamics. AgentDynEx uses LLMs to guide users through a Configuration Matrix to identify core mechanics and define milestones to track dynamics. It also introduces a method called \\textit{nudging}, where the system dynamically reflects on simulation progress and gently intervenes if it begins to deviate from intended outcomes. A technical evaluation found that nudging enables simulations to have more complex mechanics and maintain its notable dynamics compared to simulations without nudging. We discuss the importance of nudging as a technique for balancing mechanics and dynamics of multi-agent simulations.","authors":["Jenny Ma","Riya Sahni","Karthik Sreedhar","Lydia B. Chilton"],"url":"https://arxiv.org/abs/2504.09662"}
{"created":"2025-04-15","title":"Ordinary Least Squares as an Attention Mechanism","abstract":"I show that ordinary least squares (OLS) predictions can be rewritten as the output of a restricted attention module, akin to those forming the backbone of large language models. This connection offers an alternative perspective on attention beyond the conventional information retrieval framework, making it more accessible to researchers and analysts with a background in traditional statistics. It falls into place when OLS is framed as a similarity-based method in a transformed regressor space, distinct from the standard view based on partial correlations. In fact, the OLS solution can be recast as the outcome of an alternative problem: minimizing squared prediction errors by optimizing the embedding space in which training and test vectors are compared via inner products. Rather than estimating coefficients directly, we equivalently learn optimal encoding and decoding operations for predictors. From this vantage point, OLS maps naturally onto the query-key-value structure of attention mechanisms. Building on this foundation, I discuss key elements of Transformer-style attention and draw connections to classic ideas from time series econometrics.","authors":["Philippe Goulet Coulombe"],"url":"https://arxiv.org/abs/2504.09663"}
{"created":"2025-04-15","title":"Adapting to the Unknown: Robust Meta-Learning for Zero-Shot Financial Time Series Forecasting","abstract":"Financial time series forecasting in the zero-shot setting is essential for risk management and investment decision-making, particularly during abrupt market regime shifts or in emerging markets with limited historical data. While Model-Agnostic Meta-Learning (MAML)-based approaches have shown promise in this domain, existing meta task construction strategies often lead to suboptimal performance, especially when dealing with highly turbulent financial time series. To address this challenge, we propose a novel task construction method that leverages learned embeddings for more effective meta-learning in the zero-shot setting. Specifically, we construct two complementary types of meta-tasks based on the learned embeddings: intra-cluster tasks and inter-cluster tasks. To capture diverse fine-grained patterns, we apply stochastic projection matrices to the learned embeddings and use clustering algorithm to form the tasks. Additionally, to improve generalization capabilities, we employ hard task mining strategies and leverage inter-cluster tasks to identify invariant patterns across different time series. Extensive experiments on the real world financial dataset demonstrate that our method significantly outperforms existing approaches, showing better generalization ability in the zero-shot scenario.","authors":["Anxian Liu","Junying Ma","Guang Zhang"],"url":"https://arxiv.org/abs/2504.09664"}
{"created":"2025-04-15","title":"CLEAR-KGQA: Clarification-Enhanced Ambiguity Resolution for Knowledge Graph Question Answering","abstract":"This study addresses the challenge of ambiguity in knowledge graph question answering (KGQA). While recent KGQA systems have made significant progress, particularly with the integration of large language models (LLMs), they typically assume user queries are unambiguous, which is an assumption that rarely holds in real-world applications. To address these limitations, we propose a novel framework that dynamically handles both entity ambiguity (e.g., distinguishing between entities with similar names) and intent ambiguity (e.g., clarifying different interpretations of user queries) through interactive clarification. Our approach employs a Bayesian inference mechanism to quantify query ambiguity and guide LLMs in determining when and how to request clarification from users within a multi-turn dialogue framework. We further develop a two-agent interaction framework where an LLM-based user simulator enables iterative refinement of logical forms through simulated user feedback. Experimental results on the WebQSP and CWQ dataset demonstrate that our method significantly improves performance by effectively resolving semantic ambiguities. Additionally, we contribute a refined dataset of disambiguated queries, derived from interaction histories, to facilitate future research in this direction.","authors":["Liqiang Wen","Guanming Xiong","Tong Mo","Bing Li","Weiping Li","Wen Zhao"],"url":"https://arxiv.org/abs/2504.09665"}
{"created":"2025-04-15","title":"Uncertainty Guided Refinement for Fine-Grained Salient Object Detection","abstract":"Recently, salient object detection (SOD) methods have achieved impressive performance. However, salient regions predicted by existing methods usually contain unsaturated regions and shadows, which limits the model for reliable fine-grained predictions. To address this, we introduce the uncertainty guidance learning approach to SOD, intended to enhance the model's perception of uncertain regions. Specifically, we design a novel Uncertainty Guided Refinement Attention Network (UGRAN), which incorporates three important components, i.e., the Multilevel Interaction Attention (MIA) module, the Scale Spatial-Consistent Attention (SSCA) module, and the Uncertainty Refinement Attention (URA) module. Unlike conventional methods dedicated to enhancing features, the proposed MIA facilitates the interaction and perception of multilevel features, leveraging the complementary characteristics among multilevel features. Then, through the proposed SSCA, the salient information across diverse scales within the aggregated features can be integrated more comprehensively and integrally. In the subsequent steps, we utilize the uncertainty map generated from the saliency prediction map to enhance the model's perception capability of uncertain regions, generating a highly-saturated fine-grained saliency prediction map. Additionally, we devise an adaptive dynamic partition (ADP) mechanism to minimize the computational overhead of the URA module and improve the utilization of uncertainty guidance. Experiments on seven benchmark datasets demonstrate the superiority of the proposed UGRAN over the state-of-the-art methodologies. Codes will be released at https://github.com/I2-Multimedia-Lab/UGRAN.","authors":["Yao Yuan","Pan Gao","Qun Dai","Jie Qin","Wei Xiang"],"url":"https://arxiv.org/abs/2504.09666"}
{"created":"2025-04-15","title":"Nash Social Welfare with Submodular Valuations: Approximation Algorithms and Integrality Gaps","abstract":"We study the problem of allocating items to agents such that the (un)weighted Nash social welfare (NSW) is maximized under submodular valuations. The best-known results for unweighted and weighted problems are the $(4+\\epsilon)$ approximation given by Garg, Husic, Li, Vega, and Vondrak~\\cite{stoc/GargHLVV23} and the $(233+\\epsilon)$ approximation given by Feng, Hu, Li, and Zhang~\\cite{stoc/FHLZ25}, respectively.","authors":["Xiaohui Bei","Yuda Feng","Yang Hu","Shi Li","Ruilong Zhang"],"url":"https://arxiv.org/abs/2504.09669"}
{"created":"2025-04-15","title":"LightHeadEd: Relightable & Editable Head Avatars from a Smartphone","abstract":"Creating photorealistic, animatable, and relightable 3D head avatars traditionally requires expensive Lightstage with multiple calibrated cameras, making it inaccessible for widespread adoption. To bridge this gap, we present a novel, cost-effective approach for creating high-quality relightable head avatars using only a smartphone equipped with polaroid filters. Our approach involves simultaneously capturing cross-polarized and parallel-polarized video streams in a dark room with a single point-light source, separating the skin's diffuse and specular components during dynamic facial performances. We introduce a hybrid representation that embeds 2D Gaussians in the UV space of a parametric head model, facilitating efficient real-time rendering while preserving high-fidelity geometric details. Our learning-based neural analysis-by-synthesis pipeline decouples pose and expression-dependent geometrical offsets from appearance, decomposing the surface into albedo, normal, and specular UV texture maps, along with the environment maps. We collect a unique dataset of various subjects performing diverse facial expressions and head movements.","authors":["Pranav Manu","Astitva Srivastava","Amit Raj","Varun Jampani","Avinash Sharma","P. J. Narayanan"],"url":"https://arxiv.org/abs/2504.09671"}
{"created":"2025-04-15","title":"Earthquake Simulation","abstract":"This paper presents a seismic activity simulator that models the effects of fault lines on surface pressure. This project uses C programming to create a fully interactive learning resource intended to educate users on the mechanics of earthquakes. The motivation behind this project is to make studying seismic activity more accessible, engaging and cost effective.","authors":["Palak Chawla"],"url":"https://arxiv.org/abs/2504.09673"}
{"created":"2025-04-15","title":"On Stochastic Performance Analysis of Secure Integrated Sensing and Communication Networks","abstract":"This paper analyzes the stochastic security performance of a multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system in a downlink scenario. A base station (BS) transmits a multi-functional signal to simultaneously communicate with a user, sense a target angular location, and counteract eavesdropping threats. The system includes a passive single-antenna communication eavesdropper and a multi-antenna sensing eavesdropper attempting to infer the target location. The BS-user and BS-eavesdroppers channels follow Rayleigh fading, while the target azimuth angle is uniformly distributed. To evaluate the performance, we derive exact expressions for the secrecy ergodic rate and the ergodic Cramer-Rao lower bound (CRB) for target localization at both the BS and the sensing eavesdropper. This involves computing the probability density functions (PDFs) of the signal-to-noise ratio (SNR) and CRB, leveraging the central limit theorem for tractability. Numerical results validate our findings.","authors":["Marziyeh Soltani","Mahtab Mirmohseni","Rahim Tafazolli"],"url":"https://arxiv.org/abs/2504.09674"}
{"created":"2025-04-15","title":"SPOT: Spatio-Temporal Pattern Mining and Optimization for Load Consolidation in Freight Transportation Networks","abstract":"Freight consolidation has significant potential to reduce transportation costs and mitigate congestion and pollution. An effective load consolidation plan relies on carefully chosen consolidation points to ensure alignment with existing transportation management processes, such as driver scheduling, personnel planning, and terminal operations. This complexity represents a significant challenge when searching for optimal consolidation strategies. Traditional optimization-based methods provide exact solutions, but their computational complexity makes them impractical for large-scale instances and they fail to leverage historical data. Machine learning-based approaches address these issues but often ignore operational constraints, leading to infeasible consolidation plans.","authors":["Sikai Cheng","Amira Hijazi","Jeren Konak","Alan Erera","Pascal Van Hentenryck"],"url":"https://arxiv.org/abs/2504.09680"}
{"created":"2025-04-15","title":"Can LLMs Revolutionize the Design of Explainable and Efficient TinyML Models?","abstract":"This paper introduces a novel framework for designing efficient neural network architectures specifically tailored to tiny machine learning (TinyML) platforms. By leveraging large language models (LLMs) for neural architecture search (NAS), a vision transformer (ViT)-based knowledge distillation (KD) strategy, and an explainability module, the approach strikes an optimal balance between accuracy, computational efficiency, and memory usage. The LLM-guided search explores a hierarchical search space, refining candidate architectures through Pareto optimization based on accuracy, multiply-accumulate operations (MACs), and memory metrics. The best-performing architectures are further fine-tuned using logits-based KD with a pre-trained ViT-B/16 model, which enhances generalization without increasing model size. Evaluated on the CIFAR-100 dataset and deployed on an STM32H7 microcontroller (MCU), the three proposed models, LMaNet-Elite, LMaNet-Core, and QwNet-Core, achieve accuracy scores of 74.50%, 74.20% and 73.00%, respectively. All three models surpass current state-of-the-art (SOTA) models, such as MCUNet-in3/in4 (69.62% / 72.86%) and XiNet (72.27%), while maintaining a low computational cost of less than 100 million MACs and adhering to the stringent 320 KB static random-access memory (SRAM) constraint. These results demonstrate the efficiency and performance of the proposed framework for TinyML platforms, underscoring the potential of combining LLM-driven search, Pareto optimization, KD, and explainability to develop accurate, efficient, and interpretable models. This approach opens new possibilities in NAS, enabling the design of efficient architectures specifically suited for TinyML.","authors":["Christophe El Zeinaty","Wassim Hamidouche","Glenn Herrou","Daniel Menard","Merouane Debbah"],"url":"https://arxiv.org/abs/2504.09685"}
{"created":"2025-04-15","title":"Domain-Adaptive Continued Pre-Training of Small Language Models","abstract":"Continued pre-training of small language models offers a promising path for domain adaptation with limited computational resources. I've investigated this approach within educational domains, evaluating it as a resource-efficient alternative to training models from scratch. Using a 125M parameter model, I demonstrate significant performance improvements through incremental training on 400 million tokens, followed by further training to reach 1 billion tokens. My approach includes comprehensive data preprocessing, memory-optimized training configurations, and benchmark-based evaluation. Results show notable gains in knowledge-intensive tasks (MMLU +8.1%) and contextual understanding (HellaSwag +7.6%), while revealing educational domain specialization trade-offs. I analyze token efficiency, catastrophic forgetting mitigation strategies, and scaling patterns. My findings suggest that thoughtful preprocessing and training methodologies enable meaningful improvements in language model capabilities even with constrained computational resources, opening pathways for domain-specific adaptation of smaller language models.","authors":["Salman Faroz"],"url":"https://arxiv.org/abs/2504.09687"}
{"created":"2025-04-15","title":"GAMA: High-Performance \\underline{G}EMM \\underline{A}cceleration on AMD Versal \\underline{M}L-Optimized \\underline{A}I Engines","abstract":"General matrix-matrix multiplication (GEMM) is a fundamental operation in machine learning (ML) applications. We present the first comprehensive performance acceleration of GEMM workloads on AMD's second-generation AIE-ML (AIE2) architecture, which is specifically optimized for ML applications. Compared to AI-Engine (AIE1), AIE offers increased compute throughput and larger on-chip memory capacity. We propose a novel design that maximizes AIE memory utilization, incorporates custom buffer placement within the AIE2 and staggered kernel placement across the AIE2 array, significantly reducing performance bottlenecks such as memory stalls and routing congestion, resulting in improved performance and efficiency compared to the default compiler provided by AMD. We evaluate the performance benefits of our design at three levels: single AIE, pack of AIEs and the complete AIE array. GAMA achieves state-of-the-art performance, delivering up to 165 TOPS (85% of peak) for int8 precision and 83 TBFLOPS (86% of peak) for bfloat16 precision GEMM workloads. Our solution achieves 8.7%, 9%, 39% and 53.6% higher peak throughput efficiency compared to the state-of-the-art AIE1 frameworks AMA, MAXEVA, ARIES and CHARM, respectively.","authors":["Kaustubh Mhatre","Endri Taka","Aman Arora"],"url":"https://arxiv.org/abs/2504.09688"}
{"created":"2025-04-15","title":"EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety","abstract":"The rise of LLM-driven AI characters raises safety concerns, particularly for vulnerable human users with psychological disorders. To address these risks, we propose EmoAgent, a multi-agent AI framework designed to evaluate and mitigate mental health hazards in human-AI interactions. EmoAgent comprises two components: EmoEval simulates virtual users, including those portraying mentally vulnerable individuals, to assess mental health changes before and after interactions with AI characters. It uses clinically proven psychological and psychiatric assessment tools (PHQ-9, PDI, PANSS) to evaluate mental risks induced by LLM. EmoGuard serves as an intermediary, monitoring users' mental status, predicting potential harm, and providing corrective feedback to mitigate risks. Experiments conducted in popular character-based chatbots show that emotionally engaging dialogues can lead to psychological deterioration in vulnerable users, with mental state deterioration in more than 34.4% of the simulations. EmoGuard significantly reduces these deterioration rates, underscoring its role in ensuring safer AI-human interactions. Our code is available at: https://github.com/1akaman/EmoAgent","authors":["Jiahao Qiu","Yinghui He","Xinzhe Juan","Yiming Wang","Yuhan Liu","Zixin Yao","Yue Wu","Xun Jiang","Ling Yang","Mengdi Wang"],"url":"https://arxiv.org/abs/2504.09689"}
{"created":"2025-04-15","title":"Migrating Code At Scale With LLMs At Google","abstract":"Developers often evolve an existing software system by making internal changes, called migration. Moving to a new framework, changing implementation to improve efficiency, and upgrading a dependency to its latest version are examples of migrations.","authors":["Celal Ziftci","Stoyan Nikolov","Anna Sj\\\"ovall","Bo Kim","Daniele Codecasa","Max Kim"],"url":"https://arxiv.org/abs/2504.09691"}
{"created":"2025-04-15","title":"Computer-Aided Layout Generation for Building Design: A Review","abstract":"Generating realistic building layouts for automatic building design has been studied in both the computer vision and architecture domains. Traditional approaches from the architecture domain, which are based on optimization techniques or heuristic design guidelines, can synthesize desirable layouts, but usually require post-processing and involve human interaction in the design pipeline, making them costly and timeconsuming. The advent of deep generative models has significantly improved the fidelity and diversity of the generated architecture layouts, reducing the workload by designers and making the process much more efficient. In this paper, we conduct a comprehensive review of three major research topics of architecture layout design and generation: floorplan layout generation, scene layout synthesis, and generation of some other formats of building layouts. For each topic, we present an overview of the leading paradigms, categorized either by research domains (architecture or machine learning) or by user input conditions or constraints. We then introduce the commonly-adopted benchmark datasets that are used to verify the effectiveness of the methods, as well as the corresponding evaluation metrics. Finally, we identify the well-solved problems and limitations of existing approaches, then propose new perspectives as promising directions for future research in this important research area. A project associated with this survey to maintain the resources is available at awesome-building-layout-generation.","authors":["Jiachen Liu","Yuan Xue","Haomiao Ni","Rui Yu","Zihan Zhou","Sharon X. Huang"],"url":"https://arxiv.org/abs/2504.09694"}
{"created":"2025-04-15","title":"GRPO-LEAD: A Difficulty-Aware Reinforcement Learning Approach for Concise Mathematical Reasoning in Language Models","abstract":"Recent advances in R1-like reasoning models leveraging Group Relative Policy Optimization (GRPO) have significantly improved the performance of language models on mathematical reasoning tasks. However, current GRPO implementations encounter critical challenges, including reward sparsity due to binary accuracy metrics, limited incentives for conciseness, and insufficient focus on complex reasoning tasks. To address these issues, we propose GRPO-LEAD, a suite of novel enhancements tailored for mathematical reasoning. Specifically, GRPO-LEAD introduces (1) a length-dependent accuracy reward to encourage concise and precise solutions, (2) an explicit penalty mechanism for incorrect answers to sharpen decision boundaries, and (3) a difficulty-aware advantage reweighting strategy that amplifies learning signals for challenging problems. Furthermore, we systematically examine the impact of model scale and supervised fine-tuning (SFT) strategies, demonstrating that larger-scale base models and carefully curated datasets significantly enhance reinforcement learning effectiveness. Extensive empirical evaluations and ablation studies confirm that GRPO-LEAD substantially mitigates previous shortcomings, resulting in language models that produce more concise, accurate, and robust reasoning across diverse mathematical tasks.","authors":["Jixiao Zhang","Chunsheng Zuo"],"url":"https://arxiv.org/abs/2504.09696"}
{"created":"2025-04-15","title":"SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow","abstract":"Recent prompt-based image editing models have demonstrated impressive prompt-following capability at structural editing tasks. However, existing models still fail to perform local edits, follow detailed editing prompts, or maintain global image quality beyond a single editing step. To address these challenges, we introduce SPICE, a training-free workflow that accepts arbitrary resolutions and aspect ratios, accurately follows user requirements, and improves image quality consistently during more than 100 editing steps. By synergizing the strengths of a base diffusion model and a Canny edge ControlNet model, SPICE robustly handles free-form editing instructions from the user. SPICE outperforms state-of-the-art baselines on a challenging realistic image-editing dataset consisting of semantic editing (object addition, removal, replacement, and background change), stylistic editing (texture changes), and structural editing (action change) tasks. Not only does SPICE achieve the highest quantitative performance according to standard evaluation metrics, but it is also consistently preferred by users over existing image-editing methods. We release the workflow implementation for popular diffusion model Web UIs to support further research and artistic exploration.","authors":["Kenan Tang","Yanhong Li","Yao Qin"],"url":"https://arxiv.org/abs/2504.09697"}
{"created":"2025-04-15","title":"ToolTipNet: A Segmentation-Driven Deep Learning Baseline for Surgical Instrument Tip Detection","abstract":"In robot-assisted laparoscopic radical prostatectomy (RALP), the location of the instrument tip is important to register the ultrasound frame with the laparoscopic camera frame. A long-standing limitation is that the instrument tip position obtained from the da Vinci API is inaccurate and requires hand-eye calibration. Thus, directly computing the position of the tool tip in the camera frame using the vision-based method becomes an attractive solution. Besides, surgical instrument tip detection is the key component of other tasks, like surgical skill assessment and surgery automation. However, this task is challenging due to the small size of the tool tip and the articulation of the surgical instrument. Surgical instrument segmentation becomes relatively easy due to the emergence of the Segmentation Foundation Model, i.e., Segment Anything. Based on this advancement, we explore the deep learning-based surgical instrument tip detection approach that takes the part-level instrument segmentation mask as input. Comparison experiments with a hand-crafted image-processing approach demonstrate the superiority of the proposed method on simulated and real datasets.","authors":["Zijian Wu","Shuojue Yang","Yueming Jin","Septimiu E Salcudean"],"url":"https://arxiv.org/abs/2504.09700"}
{"created":"2025-04-15","title":"MLRC-Bench: Can Language Agents Solve Machine Learning Research Challenges?","abstract":"Existing evaluation of large language model (LLM) agents on scientific discovery lacks objective baselines and metrics to assess the viability of their proposed methods. To address this issue, we introduce MLRC-Bench, a benchmark designed to quantify how effectively language agents can tackle challenging Machine Learning (ML) Research Competitions. Our benchmark highlights open research problems that demand novel methodologies, in contrast to recent benchmarks such as OpenAI's MLE-Bench (Chan et al., 2024) and METR's RE-Bench (Wijk et al., 2024), which focus on well-established research tasks that are largely solvable through sufficient engineering effort. Unlike prior work, e.g., AI Scientist (Lu et al., 2024b), which evaluates the end-to-end agentic pipeline by using LLM-as-a-judge, MLRC-Bench measures the key steps of proposing and implementing novel research methods and evaluates them with newly proposed rigorous protocol and objective metrics. Our curated suite of 7 competition tasks reveals significant challenges for LLM agents. Even the best-performing tested agent (gemini-exp-1206 under MLAB (Huang et al., 2024a)) closes only 9.3% of the gap between baseline and top human participant scores. Furthermore, our analysis reveals a misalignment between the LLM-judged innovation and their actual performance on cutting-edge ML research problems. MLRC-Bench is a dynamic benchmark, which is designed to continually grow with new ML competitions to encourage rigorous and objective evaluations of AI's research capabilities.","authors":["Yunxiang Zhang","Muhammad Khalifa","Shitanshu Bhushan","Grant D Murphy","Lajanugen Logeswaran","Jaekyeom Kim","Moontae Lee","Honglak Lee","Lu Wang"],"url":"https://arxiv.org/abs/2504.09702"}
{"created":"2025-04-15","title":"Transformer-Based Representation Learning for Robust Gene Expression Modeling and Cancer Prognosis","abstract":"Transformer-based models have achieved remarkable success in natural language and vision tasks, but their application to gene expression analysis remains limited due to data sparsity, high dimensionality, and missing values. We present GexBERT, a transformer-based autoencoder framework for robust representation learning of gene expression data. GexBERT learns context-aware gene embeddings by pretraining on large-scale transcriptomic profiles with a masking and restoration objective that captures co-expression relationships among thousands of genes. We evaluate GexBERT across three critical tasks in cancer research: pan-cancer classification, cancer-specific survival prediction, and missing value imputation. GexBERT achieves state-of-the-art classification accuracy from limited gene subsets, improves survival prediction by restoring expression of prognostic anchor genes, and outperforms conventional imputation methods under high missingness. Furthermore, its attention-based interpretability reveals biologically meaningful gene patterns across cancer types. These findings demonstrate the utility of GexBERT as a scalable and effective tool for gene expression modeling, with translational potential in settings where gene coverage is limited or incomplete.","authors":["Shuai Jiang","Saeed Hassanpour"],"url":"https://arxiv.org/abs/2504.09704"}
{"created":"2025-04-15","title":"From Movement Primitives to Distance Fields to Dynamical Systems","abstract":"Developing autonomous robots capable of learning and reproducing complex motions from demonstrations remains a fundamental challenge in robotics. On the one hand, movement primitives (MPs) provide a compact and modular representation of continuous trajectories. On the other hand, autonomous systems provide control policies that are time independent. We propose in this paper a simple and flexible approach that gathers the advantages of both representations by transforming MPs into autonomous systems. The key idea is to transform the explicit representation of a trajectory as an implicit shape encoded as a distance field. This conversion from a time-dependent motion to a spatial representation enables the definition of an autonomous dynamical system with modular reactions to perturbation. Asymptotic stability guarantees are provided by using Bernstein basis functions in the MPs, representing trajectories as concatenated quadratic B\\'ezier curves, which provide an analytical method for computing distance fields. This approach bridges conventional MPs with distance fields, ensuring smooth and precise motion encoding, while maintaining a continuous spatial representation. By simply leveraging the analytic gradients of the curve and its distance field, a stable dynamical system can be computed to reproduce the demonstrated trajectories while handling perturbations, without requiring a model of the dynamical system to be estimated. Numerical simulations and real-world robotic experiments validate our method's ability to encode complex motion patterns while ensuring trajectory stability, together with the flexibility of designing the desired reaction to perturbations. An interactive project page demonstrating our approach is available at https://mp-df-ds.github.io/.","authors":["Yiming Li","Sylvain Calinon"],"url":"https://arxiv.org/abs/2504.09705"}
{"created":"2025-04-15","title":"InfoMAE: Pair-Efficient Cross-Modal Alignment for Multimodal Time-Series Sensing Signals","abstract":"Standard multimodal self-supervised learning (SSL) algorithms regard cross-modal synchronization as implicit supervisory labels during pretraining, thus posing high requirements on the scale and quality of multimodal samples. These constraints significantly limit the performance of sensing intelligence in IoT applications, as the heterogeneity and the non-interpretability of time-series signals result in abundant unimodal data but scarce high-quality multimodal pairs. This paper proposes InfoMAE, a cross-modal alignment framework that tackles the challenge of multimodal pair efficiency under the SSL setting by facilitating efficient cross-modal alignment of pretrained unimodal representations. InfoMAE achieves \\textit{efficient cross-modal alignment} with \\textit{limited data pairs} through a novel information theory-inspired formulation that simultaneously addresses distribution-level and instance-level alignment. Extensive experiments on two real-world IoT applications are performed to evaluate InfoMAE's pairing efficiency to bridge pretrained unimodal models into a cohesive joint multimodal model. InfoMAE enhances downstream multimodal tasks by over 60% with significantly improved multimodal pairing efficiency. It also improves unimodal task accuracy by an average of 22%.","authors":["Tomoyoshi Kimura","Xinlin Li","Osama Hanna","Yatong Chen","Yizhuo Chen","Denizhan Kara","Tianshi Wang","Jinyang Li","Xiaomin Ouyang","Shengzhong Liu","Mani Srivastava","Suhas Diggavi","Tarek Abdelzaher"],"url":"https://arxiv.org/abs/2504.09707"}
{"created":"2025-04-15","title":"DUMP: Automated Distribution-Level Curriculum Learning for RL-based LLM Post-training","abstract":"Recent advances in reinforcement learning (RL)-based post-training have led to notable improvements in large language models (LLMs), particularly in enhancing their reasoning capabilities to handle complex tasks. However, most existing methods treat the training data as a unified whole, overlooking the fact that modern LLM training often involves a mixture of data from diverse distributions-varying in both source and difficulty. This heterogeneity introduces a key challenge: how to adaptively schedule training across distributions to optimize learning efficiency. In this paper, we present a principled curriculum learning framework grounded in the notion of distribution-level learnability. Our core insight is that the magnitude of policy advantages reflects how much a model can still benefit from further training on a given distribution. Based on this, we propose a distribution-level curriculum learning framework for RL-based LLM post-training, which leverages the Upper Confidence Bound (UCB) principle to dynamically adjust sampling probabilities for different distrubutions. This approach prioritizes distributions with either high average advantage (exploitation) or low sample count (exploration), yielding an adaptive and theoretically grounded training schedule. We instantiate our curriculum learning framework with GRPO as the underlying RL algorithm and demonstrate its effectiveness on logic reasoning datasets with multiple difficulties and sources. Our experiments show that our framework significantly improves convergence speed and final performance, highlighting the value of distribution-aware curriculum strategies in LLM post-training. Code: https://github.com/ZhentingWang/DUMP.","authors":["Zhenting Wang","Guofeng Cui","Kun Wan","Wentian Zhao"],"url":"https://arxiv.org/abs/2504.09710"}
{"created":"2025-04-15","title":"Simultaneous Input and State Estimation under Output Quantization: A Gaussian Mixture approach","abstract":"Simultaneous Input and State Estimation (SISE) enables the reconstruction of unknown inputs and internal states in dynamical systems, with applications in fault detection, robotics, and control. While various methods exist for linear systems, extensions to systems with output quantization are scarce, and formal connections to limit Kalman filters in this context are lacking. This work addresses these gaps by proposing a novel SISE algorithm for linear systems with quantized output measurements that is based on a Gaussian mixture model formulation. The observation model is represented as a Gaussian sum density, leading to closed-form recursive equations in the form of a Gaussian sum filter. In the absence of input prior knowledge, the recursions converge to a limit-case SISE algorithm, implementable as a bank of linear SISE filters running in parallel. A simulation example is presented to illustrate the effectiveness of the proposed approach.","authors":["Rodrigo A. Gonz\\'alez","Angel L. Cede\\~no"],"url":"https://arxiv.org/abs/2504.09711"}
{"created":"2025-04-15","title":"The Structural Safety Generalization Problem","abstract":"LLM jailbreaks are a widespread safety challenge. Given this problem has not yet been tractable, we suggest targeting a key failure mechanism: the failure of safety to generalize across semantically equivalent inputs. We further focus the target by requiring desirable tractability properties of attacks to study: explainability, transferability between models, and transferability between goals. We perform red-teaming within this framework by uncovering new vulnerabilities to multi-turn, multi-image, and translation-based attacks. These attacks are semantically equivalent by our design to their single-turn, single-image, or untranslated counterparts, enabling systematic comparisons; we show that the different structures yield different safety outcomes. We then demonstrate the potential for this framework to enable new defenses by proposing a Structure Rewriting Guardrail, which converts an input to a structure more conducive to safety assessment. This guardrail significantly improves refusal of harmful inputs, without over-refusing benign ones. Thus, by framing this intermediate challenge - more tractable than universal defenses but essential for long-term safety - we highlight a critical milestone for AI safety research.","authors":["Julius Broomfield","Tom Gibbs","Ethan Kosak-Hine","George Ingebretsen","Tia Nasir","Jason Zhang","Reihaneh Iranmanesh","Sara Pieri","Reihaneh Rabbany","Kellin Pelrine"],"url":"https://arxiv.org/abs/2504.09712"}
{"created":"2025-04-15","title":"A Full Spectrum of 3D Ferroelectric Memory Architectures Shaped by Polarization Sensing","abstract":"Ferroelectric memories have attracted significant interest due to their non-volatile storage, energy efficiency, and fast operation, making them prime candidates for future memory technologies. As commercial Dynamic Random Access Memory (DRAM) and NAND flash memory are transiting or have moved toward three-dimensional (3D) integration, 3D ferroelectric memory architectures are also emerging, provided they can achieve a competitive position within the modern memory hierarchy. Given the excellent scalability of ferroelectric HfO2, various dense 3D integrated ferroelectric memory architectures are feasible, each offering unique strengths and facing distinct challenges. In this work, we present a comprehensive classification of 3D ferroelectric memory architectures based on polarization sensing methods, highlighting their critical role in shaping memory cell design and operational efficiency. Through a systematic evaluation of these architectures, we develop a unified framework to assess their advantages and trade-offs. This classification not only enhances the understanding of current 3D ferroelectric memory technologies but also lays the foundation for designing next-generation architectures optimized for advanced computing and high-performance applications.","authors":["Jiahui Duan","Asif Khan","Xiao Gong","Vijaykrishnan Narayanan","Kai Ni"],"url":"https://arxiv.org/abs/2504.09713"}
{"created":"2025-04-15","title":"Evaluating the Quality of Benchmark Datasets for Low-Resource Languages: A Case Study on Turkish","abstract":"The reliance on translated or adapted datasets from English or multilingual resources introduces challenges regarding linguistic and cultural suitability. This study addresses the need for robust and culturally appropriate benchmarks by evaluating the quality of 17 commonly used Turkish benchmark datasets. Using a comprehensive framework that assesses six criteria, both human and LLM-judge annotators provide detailed evaluations to identify dataset strengths and shortcomings.","authors":["Ay\\c{s}e Aysu Cengiz","Ahmet Kaan Sever","Elif Ecem \\\"Um\\\"utl\\\"u","Naime \\c{S}eyma Erdem","Burak Aytan","B\\\"u\\c{s}ra Tufan","Abdullah Topraksoy","Esra Dar{\\i}c{\\i}","Cagri Toraman"],"url":"https://arxiv.org/abs/2504.09714"}
{"created":"2025-04-15","title":"Dominated Actions in Imperfect-Information Games","abstract":"Dominance is a fundamental concept in game theory. In strategic-form games dominated strategies can be identified in polynomial time. As a consequence, iterative removal of dominated strategies can be performed efficiently as a preprocessing step for reducing the size of a game before computing a Nash equilibrium. For imperfect-information games in extensive form, we could convert the game to strategic form and then iteratively remove dominated strategies in the same way; however, this conversion may cause an exponential blowup in game size. In this paper we define and study the concept of dominated actions in imperfect-information games. Our main result is a polynomial-time algorithm for determining whether an action is dominated (strictly or weakly) by any mixed strategy in n-player games, which can be extended to an algorithm for iteratively removing dominated actions. This allows us to efficiently reduce the size of the game tree as a preprocessing step for Nash equilibrium computation. We explore the role of dominated actions empirically in the \"All In or Fold\" No-Limit Texas Hold'em poker variant.","authors":["Sam Ganzfried"],"url":"https://arxiv.org/abs/2504.09716"}
{"created":"2025-04-15","title":"Adapting Robot's Explanation for Failures Based on Observed Human Behavior in Human-Robot Collaboration","abstract":"This work aims to interpret human behavior to anticipate potential user confusion when a robot provides explanations for failure, allowing the robot to adapt its explanations for more natural and efficient collaboration. Using a dataset that included facial emotion detection, eye gaze estimation, and gestures from 55 participants in a user study, we analyzed how human behavior changed in response to different types of failures and varying explanation levels. Our goal is to assess whether human collaborators are ready to accept less detailed explanations without inducing confusion. We formulate a data-driven predictor to predict human confusion during robot failure explanations. We also propose and evaluate a mechanism, based on the predictor, to adapt the explanation level according to observed human behavior. The promising results from this evaluation indicate the potential of this research in adapting a robot's explanations for failures to enhance the collaborative experience.","authors":["Andreas Naoum","Parag Khanna","Elmira Yadollahi","M{\\aa}rten Bj\\\"orkman","Christian Smith"],"url":"https://arxiv.org/abs/2504.09717"}
{"created":"2025-04-15","title":"AgentA/B: Automated and Scalable Web A/BTesting with Interactive LLM Agents","abstract":"A/B testing experiment is a widely adopted method for evaluating UI/UX design decisions in modern web applications. Yet, traditional A/B testing remains constrained by its dependence on the large-scale and live traffic of human participants, and the long time of waiting for the testing result. Through formative interviews with six experienced industry practitioners, we identified critical bottlenecks in current A/B testing workflows. In response, we present AgentA/B, a novel system that leverages Large Language Model-based autonomous agents (LLM Agents) to automatically simulate user interaction behaviors with real webpages. AgentA/B enables scalable deployment of LLM agents with diverse personas, each capable of navigating the dynamic webpage and interactively executing multi-step interactions like search, clicking, filtering, and purchasing. In a demonstrative controlled experiment, we employ AgentA/B to simulate a between-subject A/B testing with 1,000 LLM agents Amazon.com, and compare agent behaviors with real human shopping behaviors at a scale. Our findings suggest AgentA/B can emulate human-like behavior patterns.","authors":["Dakuo Wang","Ting-Yao Hsu","Yuxuan Lu","Limeng Cui","Yaochen Xie","William Headean","Bingsheng Yao","Akash Veeragouni","Jiapeng Liu","Sreyashi Nag","Jessie Wang"],"url":"https://arxiv.org/abs/2504.09723"}
{"created":"2025-04-15","title":"A Survey on Efficient Vision-Language Models","abstract":"Vision-language models (VLMs) integrate visual and textual information, enabling a wide range of applications such as image captioning and visual question answering, making them crucial for modern AI systems. However, their high computational demands pose challenges for real-time applications. This has led to a growing focus on developing efficient vision language models. In this survey, we review key techniques for optimizing VLMs on edge and resource-constrained devices. We also explore compact VLM architectures, frameworks and provide detailed insights into the performance-memory trade-offs of efficient VLMs. Furthermore, we establish a GitHub repository at https://github.com/MPSCUMBC/Efficient-Vision-Language-Models-A-Survey to compile all surveyed papers, which we will actively update. Our objective is to foster deeper research in this area.","authors":["Gaurav Shinde","Anuradha Ravi","Emon Dey","Shadman Sakib","Milind Rampure","Nirmalya Roy"],"url":"https://arxiv.org/abs/2504.09724"}
{"created":"2025-04-15","title":"Learning-based decentralized control with collision avoidance for multi-agent systems","abstract":"In this paper, we present a learning-based tracking controller based on Gaussian processes (GP) for collision avoidance of multi-agent systems where the agents evolve in the special Euclidean group in the space SE(3). In particular, we use GPs to estimate certain uncertainties that appear in the dynamics of the agents. The control algorithm is designed to learn and mitigate these uncertainties by using GPs as a learning-based model for the predictions. In particular, the presented approach guarantees that the tracking error remains bounded with high probability. We present some simulation results to show how the control algorithm is implemented.","authors":["Omayra Yago Nieto","Alexandre Anahory Simoes","Juan I. Giribet","Leonardo J. Colombo"],"url":"https://arxiv.org/abs/2504.09730"}
{"created":"2025-04-15","title":"Epsilon-Neighborhood Decision-Boundary Governed Estimation (EDGE) of 2D Black Box Classifier Functions","abstract":"Accurately estimating decision boundaries in black box systems is critical when ensuring safety, quality, and feasibility in real-world applications. However, existing methods iteratively refine boundary estimates by sampling in regions of uncertainty, without providing guarantees on the closeness to the decision boundary and also result in unnecessary exploration that is especially disadvantageous when evaluations are costly. This paper presents the Epsilon-Neighborhood Decision-Boundary Governed Estimation (EDGE), a sample efficient and function-agnostic algorithm that leverages the intermediate value theorem to estimate the location of the decision boundary of a black box binary classifier within a user-specified epsilon-neighborhood. Evaluations are conducted on three nonlinear test functions and a case study of an electric grid stability problem with uncertain renewable power injection. The EDGE algorithm demonstrates superior sample efficiency and better boundary approximation than adaptive sampling techniques and grid-based searches.","authors":["Mithun Goutham","Riccardo DalferroNucci","Stephanie Stockar","Meghna Menon","Sneha Nayak","Harshad Zade","Chetan Patel","Mario Santillo"],"url":"https://arxiv.org/abs/2504.09733"}
{"created":"2025-04-15","title":"Dynamik: Syntactically-Driven Dynamic Font Sizing for Emphasis of Key Information","abstract":"In today's globalized world, there are increasing opportunities for individuals to communicate using a common non-native language (lingua franca). Non-native speakers often have opportunities to listen to foreign languages, but may not comprehend them as fully as native speakers do. To aid real-time comprehension, live transcription of subtitles is frequently used in everyday life (e.g., during Zoom conversations, watching YouTube videos, or on social networking sites). However, simultaneously reading subtitles while listening can increase cognitive load. In this study, we propose Dynamik, a system that reduces cognitive load during reading by decreasing the size of less important words and enlarging important ones, thereby enhancing sentence contrast. Our results indicate that Dynamik can reduce certain aspects of cognitive load, specifically, participants' perceived performance and effort among individuals with low proficiency in English, as well as enhance the users' sense of comprehension, especially among people with low English ability. We further discuss our methods' applicability to other languages and potential improvements and further research directions.","authors":["Naoto Nishida","Yoshio Ishiguro","Jun Rekiomto","Naomi Yamashita"],"url":"https://arxiv.org/abs/2504.09734"}
{"created":"2025-04-15","title":"Can LLM feedback enhance review quality? A randomized study of 20K reviews at ICLR 2025","abstract":"Peer review at AI conferences is stressed by rapidly rising submission volumes, leading to deteriorating review quality and increased author dissatisfaction. To address these issues, we developed Review Feedback Agent, a system leveraging multiple large language models (LLMs) to improve review clarity and actionability by providing automated feedback on vague comments, content misunderstandings, and unprofessional remarks to reviewers. Implemented at ICLR 2025 as a large randomized control study, our system provided optional feedback to more than 20,000 randomly selected reviews. To ensure high-quality feedback for reviewers at this scale, we also developed a suite of automated reliability tests powered by LLMs that acted as guardrails to ensure feedback quality, with feedback only being sent to reviewers if it passed all the tests. The results show that 27% of reviewers who received feedback updated their reviews, and over 12,000 feedback suggestions from the agent were incorporated by those reviewers. This suggests that many reviewers found the AI-generated feedback sufficiently helpful to merit updating their reviews. Incorporating AI feedback led to significantly longer reviews (an average increase of 80 words among those who updated after receiving feedback) and more informative reviews, as evaluated by blinded researchers. Moreover, reviewers who were selected to receive AI feedback were also more engaged during paper rebuttals, as seen in longer author-reviewer discussions. This work demonstrates that carefully designed LLM-generated review feedback can enhance peer review quality by making reviews more specific and actionable while increasing engagement between reviewers and authors. The Review Feedback Agent is publicly available at https://github.com/zou-group/review_feedback_agent.","authors":["Nitya Thakkar","Mert Yuksekgonul","Jake Silberg","Animesh Garg","Nanyun Peng","Fei Sha","Rose Yu","Carl Vondrick","James Zou"],"url":"https://arxiv.org/abs/2504.09737"}
{"created":"2025-04-15","title":"Automatic Detection of Intro and Credits in Video using CLIP and Multihead Attention","abstract":"Detecting transitions between intro/credits and main content in videos is a crucial task for content segmentation, indexing, and recommendation systems. Manual annotation of such transitions is labor-intensive and error-prone, while heuristic-based methods often fail to generalize across diverse video styles. In this work, we introduce a deep learning-based approach that formulates the problem as a sequence-to-sequence classification task, where each second of a video is labeled as either \"intro\" or \"film.\" Our method extracts frames at a fixed rate of 1 FPS, encodes them using CLIP (Contrastive Language-Image Pretraining), and processes the resulting feature representations with a multihead attention model incorporating learned positional encoding. The system achieves an F1-score of 91.0%, Precision of 89.0%, and Recall of 97.0% on the test set, and is optimized for real-time inference, achieving 11.5 FPS on CPU and 107 FPS on high-end GPUs. This approach has practical applications in automated content indexing, highlight detection, and video summarization. Future work will explore multimodal learning, incorporating audio features and subtitles to further enhance detection accuracy.","authors":["Vasilii Korolkov","Andrey Yanchenko"],"url":"https://arxiv.org/abs/2504.09738"}
{"created":"2025-04-15","title":"Analysis and structure-preserving approximation of a Cahn-Hilliard-Forchheimer system with solution-dependent mass and volume source","abstract":"We analyze a coupled Cahn-Hilliard-Forchheimer system featuring concentration-dependent mobility, mass source and convective transport. The velocity field is governed by a generalized quasi-incompressible Forchheimer equation with solution-dependent volume source. We impose Dirichlet boundary conditions for the pressure to accommodate the source term. Our contributions include a novel well-posedness result for the generalized Forchheimer subsystem via the Browder-Minty theorem, and existence of weak solutions for the full coupled system established through energy estimates at the Galerkin level combined with compactness techniques such as Aubin-Lions' lemma and Minty's trick. Furthermore, we develop a structure-preserving discretization using Raviart-Thomas elements for the velocity that maintains exact mass balance and discrete energy-dissipation balance, with well-posedness demonstrated through relative energy estimates and inf-sup stability. Lastly, we validate our model through numerical experiments, demonstrating optimal convergence rates, structure preservation, and the role of the Forchheimer nonlinearity in governing phase-field evolution dynamics.","authors":["Aaron Brunk","Marvin Fritz"],"url":"https://arxiv.org/abs/2504.09739"}
{"created":"2025-04-15","title":"Customer Validation, Feedback and Collaboration in Large-Scale Continuous Software Development","abstract":"The importance of continuously incorporating customer feedback in the software development process is well established and firmly grounded in concepts such as agile and DevOps. In large-scale organizations such as Dell Technologies however, an array of challenges remain unsolved relating to this crucial aspect of software development. Despite a wide variety of tools and techniques available for collecting and analyzing customer feedback, in large-scale organizations implementing agile and continuous software development practices, harmful disconnects, discrepancies and processes exist. Such challenges negatively impact on an organizations ability to regularly deploy incremental improvements to their software products which meet customer needs. In this Professional Doctorate research program, wherein the researcher is a practitioner within Dell Technologies, we explore the challenges of continuously integrating customer feedback in a large scale global organization with over 100,000 employees and hundreds of software products. Leveraging an Action Research approach, we will propose a model to enhance the continuous incorporation of customer feedback and validation, providing organizations with the ability to frequently deliver incremental software improvements which satisfy the needs of its customers, measurable by metrics such as customer satisfaction, product adoption, bugs/defect escapes, production incidents and deployment frequency.","authors":["David Molamphy"],"url":"https://arxiv.org/abs/2504.09740"}
{"created":"2025-04-15","title":"SegOTA: Accelerating Over-the-Air Federated Learning with Segmented Transmission","abstract":"Federated learning (FL) with over-the-air computation efficiently utilizes the communication resources, but it can still experience significant latency when each device transmits a large number of model parameters to the server. This paper proposes the Segmented Over-The-Air (SegOTA) method for FL, which reduces latency by partitioning devices into groups and letting each group transmit only one segment of the model parameters in each communication round. Considering a multi-antenna server, we model the SegOTA transmission and reception process to establish an upper bound on the expected model learning optimality gap. We minimize this upper bound, by formulating the per-round online optimization of device grouping and joint transmit-receive beamforming, for which we derive efficient closed-form solutions. Simulation results show that our proposed SegOTA substantially outperforms the conventional full-model OTA approach and other common alternatives.","authors":["Chong Zhang","Min Dong","Ben Liang","Ali Afana","Yahia Ahmed"],"url":"https://arxiv.org/abs/2504.09745"}
{"created":"2025-04-15","title":"Stochastic generative methods for stable and accurate closure modeling of chaotic dynamical systems","abstract":"Traditional deterministic subgrid-scale (SGS) models are often dissipative and unstable, especially in regions of chaotic and turbulent flow. Ongoing work in climate science and ocean modeling motivates the use of stochastic SGS models for chaotic dynamics. Further, developing stochastic generative models of underlying dynamics is a rapidly expanding field. In this work, we aim to incorporate stochastic integration toward closure modeling for chaotic dynamical systems. Further, we want to explore the potential stabilizing effect that stochastic models could have on linearized chaotic systems. We propose parametric and generative approaches for closure modeling using stochastic differential equations (SDEs). We derive and implement a quadratic diffusion model based on the fluctuations, demonstrating increased accuracy from bridging theoretical models with generative approaches. Results are demonstrated on the Lorenz-63 dynamical system.","authors":["Emily Williams","David Darmofal"],"url":"https://arxiv.org/abs/2504.09750"}
{"created":"2025-04-15","title":"Accelerating Ray Tracing-Based Wireless Channels Generation for Real-Time Network Digital Twins","abstract":"Ray tracing (RT) simulation is a widely used approach to enable modeling wireless channels in applications such as network digital twins. However, the computational cost to execute RT is proportional to factors such as the level of detail used in the adopted 3D scenario. This work proposes RT pre-processing algorithms that aim at simplifying the 3D scene without distorting the channel. It also proposes a post-processing method that augments a set of RT results to achieve an improved time resolution. These methods enable using RT in applications that use a detailed and photorealistic 3D scenario, while generating consistent wireless channels over time. Our simulation results with different 3D scenarios demonstrate that it is possible to reduce the simulation time by more than 50% without compromising the accuracy of the RT parameters.","authors":["Cl\\'audio Modesto","Lucas Mozart","Pedro Batista","Andr\\'e Cavalcante","Aldebaro Klautau"],"url":"https://arxiv.org/abs/2504.09751"}
{"created":"2025-04-15","title":"Improving Multilingual Capabilities with Cultural and Local Knowledge in Large Language Models While Enhancing Native Performance","abstract":"Large Language Models (LLMs) have shown remarkable capabilities, but their development has primarily focused on English and other high-resource languages, leaving many languages underserved. We present our latest Hindi-English bi-lingual LLM \\textbf{Mantra-14B} with ~3\\% average improvement in benchmark scores over both languages, outperforming models twice its size. Using a curated dataset composed of English and Hindi instruction data of 485K samples, we instruction tuned models such as Qwen-2.5-14B-Instruct and Phi-4 to improve performance over both English and Hindi. Our experiments encompassing seven different LLMs of varying parameter sizes and over 140 training attempts with varying English-Hindi training data ratios demonstrated that it is possible to significantly improve multilingual performance without compromising native performance. Further, our approach avoids resource-intensive techniques like vocabulary expansion or architectural modifications, thus keeping the model size small. Our results indicate that modest fine-tuning with culturally and locally informed data can bridge performance gaps without incurring significant computational overhead. We release our training code, datasets, and models under mit and apache licenses to aid further research towards under-represented and low-resource languages.","authors":["Ram Mohan Rao Kadiyala","Siddartha Pullakhandam","Siddhant Gupta","Drishti Sharma","Jebish Purbey","Kanwal Mehreen","Muhammad Arham","Hamza Farooq"],"url":"https://arxiv.org/abs/2504.09753"}
{"created":"2025-04-15","title":"Integrating Large Language Models for Automated Structural Analysis","abstract":"Automated analysis for engineering structures offers considerable potential for boosting efficiency by minimizing repetitive tasks. Although AI-driven methods are increasingly common, no systematic framework yet leverages Large Language Models (LLMs) for automatic structural analysis. To address this gap, we propose a novel framework that integrates LLMs with structural analysis software. LLMs serve as the core engine: they parse structural descriptions from text and translate them into executable Python scripts. Moreover, the framework integrates the generative capabilities of LLMs with code-based finite element (FE) tools like OpenSeesPy. It employs domain-specific prompt design and in-context learning strategies to enhance the LLM's problem-solving capabilities and generative stability, enabling fully automated structural analysis from descriptive text to model outputs. In our experiments, we introduce a well-curated small-scale benchmark dataset of 20 structural analysis word problems (SAWPs) with ground-truth solutions and evaluate the performance of different LLMs within our framework in solving these SAWPs. The role of system instructions, crafted by structural engineers, is also investigated to understand their impact on LLM-driven structural analysis. Additionally, the generative stability of our framework is examined. Through multiple validation experiments on the benchmark, our results demonstrate that the proposed framework can substantially increase the level of automation in solving SAWPs compared to traditional methods. Quantitatively, the framework, built on GPT-4o, achieved 100% accuracy, surpassing GPT-4 (85%), Gemini 1.5 Pro (80%), and Llama-3.3 (30%) on the test examples. Furthermore, integrating domain-specific instructions enhanced performance by 30% on problems with asymmetrical structural configurations.","authors":["Haoran Liang","Mohammad Talebi Kalaleh","Qipei Mei"],"url":"https://arxiv.org/abs/2504.09754"}
{"created":"2025-04-15","title":"UruBots RoboCup Work Team Description Paper","abstract":"This work presents a team description paper for the RoboCup Work League. Our team, UruBots, has been developing robots and projects for research and competitions in the last three years, attending robotics competitions in Uruguay and around the world. In this instance, we aim to participate and contribute to the RoboCup Work category, hopefully making our debut in this prestigious competition. For that, we present an approach based on the Limo robot, whose main characteristic is its hybrid locomotion system with wheels and tracks, with some extras added by the team to complement the robot's functionalities. Overall, our approach allows the robot to efficiently and autonomously navigate a Work scenario, with the ability to manipulate objects, perform autonomous navigation, and engage in a simulated industrial environment.","authors":["Hiago Sodre","Juan Deniz","Pablo Moraes","William Moraes","Igor Nunes","Vincent Sandin","Ahilen Mazondo","Santiago Fernandez","Gabriel da Silva","Monica Rodriguez","Sebastian Barcelona","Ricardo Grando"],"url":"https://arxiv.org/abs/2504.09755"}
{"created":"2025-04-15","title":"Alleviating the Fear of Losing Alignment in LLM Fine-tuning","abstract":"Large language models (LLMs) have demonstrated revolutionary capabilities in understanding complex contexts and performing a wide range of tasks. However, LLMs can also answer questions that are unethical or harmful, raising concerns about their applications. To regulate LLMs' responses to such questions, a training strategy called \\textit{alignment} can help. Yet, alignment can be unexpectedly compromised when fine-tuning an LLM for downstream tasks. This paper focuses on recovering the alignment lost during fine-tuning.","authors":["Kang Yang","Guanhong Tao","Xun Chen","Jun Xu"],"url":"https://arxiv.org/abs/2504.09757"}
{"created":"2025-04-15","title":"Enhancing Classifier Evaluation: A Fairer Benchmarking Strategy Based on Ability and Robustness","abstract":"Benchmarking is a fundamental practice in machine learning (ML) for comparing the performance of classification algorithms. However, traditional evaluation methods often overlook a critical aspect: the joint consideration of dataset complexity and an algorithm's ability to generalize. Without this dual perspective, assessments may favor models that perform well on easy instances while failing to capture their true robustness. To address this limitation, this study introduces a novel evaluation methodology that combines Item Response Theory (IRT) with the Glicko-2 rating system, originally developed to measure player strength in competitive games. IRT assesses classifier ability based on performance over difficult instances, while Glicko-2 updates performance metrics - such as rating, deviation, and volatility - via simulated tournaments between classifiers. This combined approach provides a fairer and more nuanced measure of algorithm capability. A case study using the OpenML-CC18 benchmark showed that only 15% of the datasets are truly challenging and that a reduced subset with 50% of the original datasets offers comparable evaluation power. Among the algorithms tested, Random Forest achieved the highest ability score. The results highlight the importance of improving benchmark design by focusing on dataset quality and adopting evaluation strategies that reflect both difficulty and classifier proficiency.","authors":["Lucas Cardoso","Vitor Santos","Jos\\'e Ribeiro","Regiane Kawasaki","Ricardo Prud\\^encio","Ronnie Alves"],"url":"https://arxiv.org/abs/2504.09759"}
{"created":"2025-04-15","title":"Hybrid Lyapunov and Barrier Function-Based Control with Stabilization Guarantees","abstract":"Control Lyapunov Functions (CLFs) and Control Barrier Functions (CBFs) can be combined, typically by means of Quadratic Programs (QPs), to design controllers that achieve performance and safety objectives. However, a significant limitation of this framework is the introduction of asymptotically stable equilibrium points besides the minimizer of the CLF, leading to deadlock situations even for simple systems and bounded convex unsafe sets. To address this problem, we propose a hybrid CLF-CBF control framework with global asymptotic stabilization and safety guarantees, offering a more flexible and systematic design methodology compared to current alternatives available in the literature. We further extend this framework to higher-order systems via a recursive procedure based on a joint CLF-CBF backstepping approach. The proposed solution is assessed through several simulation examples.","authors":["Hugo Matias","Daniel Silvestre"],"url":"https://arxiv.org/abs/2504.09760"}
{"created":"2025-04-15","title":"Dynamical symmetries in the fluctuation-driven regime: an application of Noether's theorem to noisy dynamical systems","abstract":"Noether's theorem provides a powerful link between continuous symmetries and conserved quantities for systems governed by some variational principle. Perhaps unfortunately, most dynamical systems of interest in neuroscience and artificial intelligence cannot be described by any such principle. On the other hand, nonequilibrium physics provides a variational principle that describes how fairly generic noisy dynamical systems are most likely to transition between two states; in this work, we exploit this principle to apply Noether's theorem, and hence learn about how the continuous symmetries of dynamical systems constrain their most likely trajectories. We identify analogues of the conservation of energy, momentum, and angular momentum, and briefly discuss examples of each in the context of models of decision-making, recurrent neural networks, and diffusion generative models.","authors":["John J. Vastola"],"url":"https://arxiv.org/abs/2504.09761"}
{"created":"2025-04-15","title":"(How) Do reasoning models reason?","abstract":"We will provide a broad unifying perspective on the recent breed of Large Reasoning Models (LRMs) such as OpenAI o1 and DeepSeek R1, including their promise, sources of power, misconceptions and limitations.","authors":["Subbarao Kambhampati","Kaya Stechly","Karthik Valmeekam"],"url":"https://arxiv.org/abs/2504.09762"}
{"created":"2025-04-15","title":"Executable Functional Abstractions: Inferring Generative Programs for Advanced Math Problems","abstract":"Scientists often infer abstract procedures from specific instances of problems and use the abstractions to generate new, related instances. For example, programs encoding the formal rules and properties of a system have been useful in fields ranging from RL (procedural environments) to physics (simulation engines). These programs can be seen as functions which execute to different outputs based on their parameterizations (e.g., gridworld configuration or initial physical conditions). We introduce the term EFA (Executable Functional Abstraction) to denote such programs for math problems. EFA-like constructs have been shown to be useful for math reasoning as problem generators for stress-testing models. However, prior work has been limited to abstractions for grade-school math (whose simple rules are easy to encode in programs), while generating EFAs for advanced math has thus far required human engineering. We explore the automatic construction of EFAs for advanced math problems. We operationalize the task of automatically constructing EFAs as a program synthesis task, and develop EFAGen, which conditions an LLM on a seed math problem and its step-by-step solution to generate candidate EFA programs that are faithful to the generalized problem and solution class underlying the seed problem. Furthermore, we formalize properties any valid EFA must possess in terms of executable unit tests, and show how the tests can be used as verifiable rewards to train LLMs to become better writers of EFAs. We demonstrate that EFAs constructed by EFAGen behave rationally by remaining faithful to seed problems, produce learnable problem variations, and that EFAGen can infer EFAs across multiple diverse sources of competition-level math problems. Finally, we show downstream uses of model-written EFAs e.g. finding problem variations that are harder or easier for a learner to solve, as well as data generation.","authors":["Zaid Khan","Elias Stengel-Eskin","Archiki Prasad","Jaemin Cho","Mohit Bansal"],"url":"https://arxiv.org/abs/2504.09763"}
{"created":"2025-04-15","title":"Socratic Chart: Cooperating Multiple Agents for Robust SVG Chart Understanding","abstract":"Multimodal Large Language Models (MLLMs) have shown remarkable versatility but face challenges in demonstrating true visual understanding, particularly in chart reasoning tasks. Existing benchmarks like ChartQA reveal significant reliance on text-based shortcuts and probabilistic pattern-matching rather than genuine visual reasoning. To rigorously evaluate visual reasoning, we introduce a more challenging test scenario by removing textual labels and introducing chart perturbations in the ChartQA dataset. Under these conditions, models like GPT-4o and Gemini-2.0 Pro experience up to a 30% performance drop, underscoring their limitations. To address these challenges, we propose Socratic Chart, a new framework that transforms chart images into Scalable Vector Graphics (SVG) representations, enabling MLLMs to integrate textual and visual modalities for enhanced chart understanding. Socratic Chart employs a multi-agent pipeline with specialized agent-generators to extract primitive chart attributes (e.g., bar heights, line coordinates) and an agent-critic to validate results, ensuring high-fidelity symbolic representations. Our framework surpasses state-of-the-art models in accurately capturing chart primitives and improving reasoning performance, establishing a robust pathway for advancing MLLM visual understanding.","authors":["Yuyang Ji","Haohan Wang"],"url":"https://arxiv.org/abs/2504.09764"}
{"created":"2025-04-15","title":"On the representation of stack operators by mathematical morphology","abstract":"This paper introduces the class of grey-scale image stack operators as those that (a) map binary-images into binary-images and (b) commute in average with cross-sectioning. We show that stack operators are 1-Lipchitz extensions of set operators which can be represented by applying a characteristic set operator to the cross-sections of the image and summing. In particular, they are a generalisation of stack filters, for which the characteristic set operators are increasing. Our main result is that stack operators inherit lattice properties of the characteristic set operators. We focus on the case of translation-invariant and locally defined stack operators and show the main result by deducing the characteristic function, kernel, and basis representation of stack operators. The results of this paper have implications on the design of image operators, since imply that to solve some grey-scale image processing problems it is enough to design an operator for performing the desired transformation on binary images, and then considering its extension given by a stack operator. We leave many topics for future research regarding the machine learning of stack operators and the characterisation of the image processing problems that can be solved by them.","authors":["Diego Marcondes"],"url":"https://arxiv.org/abs/2504.09766"}
{"created":"2025-04-15","title":"Robust Output-Feedback MPC for Nonlinear Systems with Applications to Robotic Exploration","abstract":"This paper introduces a novel method for robust output-feedback model predictive control (MPC) for a class of nonlinear discrete-time systems. We propose a novel interval-valued predictor which, given an initial estimate of the state, produces intervals which are guaranteed to contain the future trajectory of the system. By parameterizing the control input with an initial stabilizing feedback term, we are able to reduce the width of the predicted state intervals compared to existing methods. We demonstrate this through a numerical comparison where we show that our controller performs better in the presence of large amounts of noise. Finally, we present a simulation study of a robot navigation scenario, where we incorporate a time-varying entropy term into the cost function in order to autonomously explore an uncertain area.","authors":["Scott Brown","Mohammad Khajenejad","Aamodh Suresh","Sonia Martinez"],"url":"https://arxiv.org/abs/2504.09768"}
{"created":"2025-04-15","title":"Identification of Community Structures in Networks Employing a Modified Divisive Algorithm","abstract":"In numerous networks, it is vital to identify communities consisting of closely joined groups of individuals. Such communities often reveal the role of the networks or primary properties of the individuals. In this perspective, Newman and Girvan proposed a modularity score (Q) for quantifying the power of community structure and measuring the appropriateness of a division. The Q function has newly become a significant standard. In this paper, the strengths of the Q score and another technique known as the divisive algorithm are combined to enhance the efficiently of the identification of communities from a network. To achieve that goal, we have developed a new algorithm. The simulation results indicated that our algorithm achieved a division with a slightly higher Q score against some conventional methods.","authors":["Ghazal Ghajari","Hooshang Jazayeri-Rad","Mashalla Abbasi Dezfooli"],"url":"https://arxiv.org/abs/2504.09769"}
{"created":"2025-04-15","title":"Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning","abstract":"Multi-agent systems (MAS) built on large language models (LLMs) offer a promising path toward solving complex, real-world tasks that single-agent systems often struggle to manage. While recent advancements in test-time scaling (TTS) have significantly improved single-agent performance on challenging reasoning tasks, how to effectively scale collaboration and reasoning in MAS remains an open question. In this work, we introduce an adaptive multi-agent framework designed to enhance collaborative reasoning through both model-level training and system-level coordination. We construct M500, a high-quality dataset containing 500 multi-agent collaborative reasoning traces, and fine-tune Qwen2.5-32B-Instruct on this dataset to produce M1-32B, a model optimized for multi-agent collaboration. To further enable adaptive reasoning, we propose a novel CEO agent that dynamically manages the discussion process, guiding agent collaboration and adjusting reasoning depth for more effective problem-solving. Evaluated in an open-source MAS across a range of tasks-including general understanding, mathematical reasoning, and coding-our system significantly outperforms strong baselines. For instance, M1-32B achieves 12% improvement on GPQA-Diamond, 41% on AIME2024, and 10% on MBPP-Sanitized, matching the performance of state-of-the-art models like DeepSeek-R1 on some tasks. These results highlight the importance of both learned collaboration and adaptive coordination in scaling multi-agent reasoning. Code is available at https://github.com/jincan333/MAS-TTS","authors":["Can Jin","Hongwu Peng","Qixin Zhang","Yujin Tang","Dimitris N. Metaxas","Tong Che"],"url":"https://arxiv.org/abs/2504.09772"}
{"created":"2025-04-15","title":"Understanding and Optimizing Multi-Stage AI Inference Pipelines","abstract":"The rapid evolution of Large Language Models (LLMs) has driven the need for increasingly sophisticated inference pipelines and hardware platforms. Modern LLM serving extends beyond traditional prefill-decode workflows, incorporating multi-stage processes such as Retrieval Augmented Generation (RAG), key-value (KV) cache retrieval, dynamic model routing, and multi step reasoning. These stages exhibit diverse computational demands, requiring distributed systems that integrate GPUs, ASICs, CPUs, and memory-centric architectures. However, existing simulators lack the fidelity to model these heterogeneous, multi-engine workflows, limiting their ability to inform architectural decisions.","authors":["Abhimanyu Rajeshkumar Bambhaniya","Hanjiang Wu","Suvinay Subramanian","Sudarshan Srinivasan","Souvik Kundu","Amir Yazdanbakhsh","Midhilesh Elavazhagan","Madhu Kumar","Tushar Krishna"],"url":"https://arxiv.org/abs/2504.09775"}
{"created":"2025-04-15","title":"An Investigation of Large Language Models and Their Vulnerabilities in Spam Detection","abstract":"Spam messages continue to present significant challenges to digital users, cluttering inboxes and posing security risks. Traditional spam detection methods, including rules-based, collaborative, and machine learning approaches, struggle to keep up with the rapidly evolving tactics employed by spammers. This project studies new spam detection systems that leverage Large Language Models (LLMs) fine-tuned with spam datasets. More importantly, we want to understand how LLM-based spam detection systems perform under adversarial attacks that purposefully modify spam emails and data poisoning attacks that exploit the differences between the training data and the massages in detection, to which traditional machine learning models are shown to be vulnerable. This experimentation employs two LLM models of GPT2 and BERT and three spam datasets of Enron, LingSpam, and SMSspamCollection for extensive training and testing tasks. The results show that, while they can function as effective spam filters, the LLM models are susceptible to the adversarial and data poisoning attacks. This research provides very useful insights for future applications of LLM models for information security.","authors":["Qiyao Tang","Xiangyang Li"],"url":"https://arxiv.org/abs/2504.09776"}
{"created":"2025-04-15","title":"Reasoning without Regret","abstract":"Chain-of-thought reasoning enables large language models to solve multi-step tasks by framing problem solving as sequential decision problems. Outcome-based rewards, which provide feedback only on final answers, show impressive success, but face challenges with credit assignment and slow convergence. In contrast, procedure-based rewards offer efficient step-level feedback, but typically require costly human supervision. We introduce \\emph{Backwards Adaptive Reward Shaping} (BARS), a no-regret framework that converts sparse outcomes-based rewards into effective procedure-based signals. BARS uses sparse rewards generated from terminal-state priors and cover trees to scale rewards while preventing exploitation. With Bellman contraction and $(\\Delta, \\epsilon)$-gap rewards, our backward Euler solver achieves $\\epsilon$-accuracy in $O\\left((R_{\\max}/\\Delta)\\log(1/\\epsilon)\\right)$ iterations with $O(\\log T)$ dynamic regret over $T$ rounds. Our analysis, based on generic chaining, continuous scaling limits, and non-linear Feynman-Kac bounds, connects recent outcome-based methods' empirical successes with the benefits of intermediate supervision. Combined, this provides the first rigorous no-regret algorithm for outcome reward shaping, providing a theoretical foundation for the empirical success of DeepSeek's R1.","authors":["Tarun Chitra"],"url":"https://arxiv.org/abs/2504.09777"}
{"created":"2025-04-15","title":"RoboCup Rescue 2025 Team Description Paper UruBots","abstract":"This paper describes the approach used by Team UruBots for participation in the 2025 RoboCup Rescue Robot League competition. Our team aims to participate for the first time in this competition at RoboCup, using experience learned from previous competitions and research. We present our vehicle and our approach to tackle the task of detecting and finding victims in search and rescue environments. Our approach contains known topics in robotics, such as ROS, SLAM, Human Robot Interaction and segmentation and perception. Our proposed approach is open source, available to the RoboCup Rescue community, where we aim to learn and contribute to the league.","authors":["Kevin Farias","Pablo Moraes","Igor Nunes","Juan Deniz","Sebastian Barcelona","Hiago Sodre","William Moraes","Monica Rodriguez","Ahilen Mazondo","Vincent Sandin","Gabriel da Silva","Victoria Saravia","Vinicio Melgar","Santiago Fernandez","Ricardo Grando"],"url":"https://arxiv.org/abs/2504.09778"}
{"created":"2025-04-15","title":"\"All Roads Lead to ChatGPT\": How Generative AI is Eroding Social Interactions and Student Learning Communities","abstract":"The widespread adoption of generative AI is already impacting learning and help-seeking. While the benefits of generative AI are well-understood, recent studies have also raised concerns about increased potential for cheating and negative impacts on students' metacognition and critical thinking. However, the potential impacts on social interactions, peer learning, and classroom dynamics are not yet well understood. To investigate these aspects, we conducted 17 semi-structured interviews with undergraduate computing students across seven R1 universities in North America. Our findings suggest that help-seeking requests are now often mediated by generative AI. For example, students often redirected questions from their peers to generative AI instead of providing assistance themselves, undermining peer interaction. Students also reported feeling increasingly isolated and demotivated as the social support systems they rely on begin to break down. These findings are concerning given the important role that social interactions play in students' learning and sense of belonging.","authors":["Irene Hou","Owen Man","Kate Hamilton","Srishty Muthusekaran","Jeffin Johnykutty","Leili Zadeh","Stephen MacNeil"],"url":"https://arxiv.org/abs/2504.09779"}
{"created":"2025-04-15","title":"Reasoning Court: Combining Reasoning, Action, and Judgment for Multi-Hop Reasoning","abstract":"While large language models (LLMs) have demonstrated strong capabilities in tasks like question answering and fact verification, they continue to suffer from hallucinations and reasoning errors, especially in multi-hop tasks that require integration of multiple information sources. Current methods address these issues through retrieval-based techniques (grounding reasoning in external evidence), reasoning-based approaches (enhancing coherence via improved prompting), or hybrid strategies combining both elements. One prominent hybrid method, ReAct, has outperformed purely retrieval-based or reasoning-based approaches; however, it lacks internal verification of intermediate reasoning steps, allowing potential errors to propagate through complex reasoning tasks. In this paper, we introduce Reasoning Court (RC), a novel framework that extends iterative reasoning-and-retrieval methods, such as ReAct, with a dedicated LLM judge. Unlike ReAct, RC employs this judge to independently evaluate multiple candidate answers and their associated reasoning generated by separate LLM agents. The judge is asked to select the answer that it considers the most factually grounded and logically coherent based on the presented reasoning and evidence, or synthesizes a new answer using available evidence and its pre-trained knowledge if all candidates are inadequate, flawed, or invalid. Evaluations on multi-hop benchmarks (HotpotQA, MuSiQue) and fact-verification (FEVER) demonstrate that RC consistently outperforms state-of-the-art few-shot prompting methods without task-specific fine-tuning.","authors":["Jingtian Wu","Claire Cardie"],"url":"https://arxiv.org/abs/2504.09781"}
{"created":"2025-04-15","title":"Computationally Efficient State and Model Estimation via Interval Observers for Partially Unknown Systems","abstract":"This paper addresses the synthesis of interval observers for partially unknown nonlinear systems subject to bounded noise, aiming to simultaneously estimate system states and learn a model of the unknown dynamics. Our approach leverages Jacobian sign-stable (JSS) decompositions, tight decomposition functions for nonlinear systems, and a data-driven over-approximation framework to construct interval estimates that provably enclose the true augmented states. By recursively computing tight and tractable bounds for the unknown dynamics based on current and past interval framers, we systematically integrate these bounds into the observer design. Additionally, we formulate semi-definite programs (SDP) for observer gain synthesis, ensuring input-to-state stability and optimality of the proposed framework. Finally, simulation results demonstrate the computational efficiency of our approach compared to a method previously proposed by the authors.","authors":["Mohammad Khajenejad","Zeyuan Jin"],"url":"https://arxiv.org/abs/2504.09784"}
{"created":"2025-04-15","title":"Using Process Calculus for Optimizing Data and Computation Sharing in Complex Stateful Parallel Computations","abstract":"We propose novel techniques that exploit data and computation sharing to improve the performance of complex stateful parallel computations, like agent-based simulations. Parallel computations are translated into behavioral equations, a novel formalism layered on top of the foundational process calculus $\\pi$-calculus. Behavioral equations blend code and data, allowing a system to easily compose and transform parallel programs into specialized programs. We show how optimizations like merging programs, synthesizing efficient message data structures, eliminating local messaging, rewriting communication instructions into local computations, and {aggregation pushdown} can be expressed as transformations of behavioral equations. We have also built a system called OptiFusion that implements behavioral equations and the aforementioned optimizations. Our experiments showed that OptiFusion is over 10$\\times$ faster than state-of-the-art stateful systems benchmarked via complex stateful workloads. Generating specialized instructions that are impractical to write by hand allows OptiFusion to outperform even the hand-optimized implementations by up to 2$\\times$.","authors":["Zilu Tian","Dan Olteanu","Christoph Koch"],"url":"https://arxiv.org/abs/2504.09788"}
{"created":"2025-04-15","title":"EquiVDM: Equivariant Video Diffusion Models with Temporally Consistent Noise","abstract":"Temporally consistent video-to-video generation is essential for applications of video diffusion models in areas such as sim-to-real, style-transfer, video upsampling, etc. In this paper, we propose a video diffusion framework that leverages temporally consistent noise to generate coherent video frames without specialized modules or additional constraints. We show that the standard training objective of diffusion models, when applied with temporally consistent noise, encourages the model to be equivariant to spatial transformations in input video and noise. This enables our model to better follow motion patterns from the input video, producing aligned motion and high-fidelity frames. Furthermore, we extend our approach to 3D-consistent video generation by attaching noise as textures on 3D meshes, ensuring 3D consistency in sim-to-real applications. Experimental results demonstrate that our method surpasses state-of-the-art baselines in motion alignment, 3D consistency, and video quality while requiring only a few sampling steps in practice.","authors":["Chao Liu","Arash Vahdat"],"url":"https://arxiv.org/abs/2504.09789"}
{"created":"2025-04-15","title":"A Tale of Two Learning Algorithms: Multiple Stream Random Walk and Asynchronous Gossip","abstract":"Although gossip and random walk-based learning algorithms are widely known for decentralized learning, there has been limited theoretical and experimental analysis to understand their relative performance for different graph topologies and data heterogeneity. We first design and analyze a random walk-based learning algorithm with multiple streams (walks), which we name asynchronous \"Multi-Walk (MW)\". We provide a convergence analysis for MW w.r.t iteration (computation), wall-clock time, and communication. We also present a convergence analysis for \"Asynchronous Gossip\", noting the lack of a comprehensive analysis of its convergence, along with the computation and communication overhead, in the literature. Our results show that MW has better convergence in terms of iterations as compared to Asynchronous Gossip in graphs with large diameters (e.g., cycles), while its relative performance, as compared to Asynchronous Gossip, depends on the number of walks and the data heterogeneity in graphs with small diameters (e.g., complete graphs). In wall-clock time analysis, we observe a linear speed-up with the number of walks and nodes in MW and Asynchronous Gossip, respectively. Finally, we show that MW outperforms Asynchronous Gossip in communication overhead, except in small-diameter topologies with extreme data heterogeneity. These results highlight the effectiveness of each algorithm in different graph topologies and data heterogeneity. Our codes are available for reproducibility.","authors":["Peyman Gholami","Hulya Seferoglu"],"url":"https://arxiv.org/abs/2504.09792"}
{"created":"2025-04-15","title":"Toward Effective PBFT Consensus Service under Software Aging in Dynamic Scenarios","abstract":"The increasing application and deployment of blockchain in various services necessitates the assurance of the effectiveness of PBFT (Practical Byzantine Fault Tolerance) consensus service. However, the performance of PBFT consensus service is challenged in dynamic scenarios. The paper explores how to reduce the consensus processing time and maintenance cost of PBFT consensus service under software aging in dynamic scenarios. We first propose a PBFT system, consisting of three subsystems, one active-node subsystem, one standby-node subsystem and a repair subsystem. All the active nodes participate in the consensus and all standby nodes aim for fault-tolerance. Each aging/crashed nodes become standby nodes after completing its repairing in the repair subsystem. The nodes migrate between the active-node and standby-node subsystems in order to support the continuity of the PBFT consensus service while reducing maintenance cost. Then, we develop a Markov-chain-based analytical model for capturing the behaviors of the system and also derive the formulas for calculating the metrics, including consensus processing time, PBFT service availability, the mean number of nodes in each subsystem. Finally, we design a Multi-Objective Evolutionary Algorithm-based method for minimizing both the PBFT service response time and the PBFT system maintenance cost. We also conduct experiments for evaluation.","authors":["Yujing Cai","Yukun Meng","Weimeng Wang","Xuanming Zhang","Xiaolin Chang"],"url":"https://arxiv.org/abs/2504.09793"}
{"created":"2025-04-15","title":"VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents","abstract":"We aim to develop a retrieval-augmented generation (RAG) framework that answers questions over a corpus of visually-rich documents presented in mixed modalities (e.g., charts, tables) and diverse formats (e.g., PDF, PPTX). In this paper, we introduce a new RAG framework, VDocRAG, which can directly understand varied documents and modalities in a unified image format to prevent missing information that occurs by parsing documents to obtain text. To improve the performance, we propose novel self-supervised pre-training tasks that adapt large vision-language models for retrieval by compressing visual information into dense token representations while aligning them with textual content in documents. Furthermore, we introduce OpenDocVQA, the first unified collection of open-domain document visual question answering datasets, encompassing diverse document types and formats. OpenDocVQA provides a comprehensive resource for training and evaluating retrieval and question answering models on visually-rich documents in an open-domain setting. Experiments show that VDocRAG substantially outperforms conventional text-based RAG and has strong generalization capability, highlighting the potential of an effective RAG paradigm for real-world documents.","authors":["Ryota Tanaka","Taichi Iki","Taku Hasegawa","Kyosuke Nishida","Kuniko Saito","Jun Suzuki"],"url":"https://arxiv.org/abs/2504.09795"}
{"created":"2025-04-15","title":"Advancing RFI-Detection in Radio Astronomy with Liquid State Machines","abstract":"Radio Frequency Interference (RFI) from anthropogenic radio sources poses significant challenges to current and future radio telescopes. Contemporary approaches to detecting RFI treat the task as a semantic segmentation problem on radio telescope spectrograms. Typically, complex heuristic algorithms handle this task of `flagging' in combination with manual labeling (in the most difficult cases). While recent machine-learning approaches have demonstrated high accuracy, they often fail to meet the stringent operational requirements of modern radio observatories. Owing to their inherently time-varying nature, spiking neural networks (SNNs) are a promising alternative method to RFI-detection by utilizing the time-varying nature of the spectrographic source data. In this work, we apply Liquid State Machines (LSMs), a class of spiking neural networks, to RFI-detection. We employ second-order Leaky Integrate-and-Fire (LiF) neurons, marking the first use of this architecture and neuron type for RFI-detection. We test three encoding methods and three increasingly complex readout layers, including a transformer decoder head, providing a hybrid of SNN and ANN techniques. Our methods extend LSMs beyond conventional classification tasks to fine-grained spatio-temporal segmentation. We train LSMs on simulated data derived from the Hyrogen Epoch of Reionization Array (HERA), a known benchmark for RFI-detection. Our model achieves a per-pixel accuracy of 98% and an F1-score of 0.743, demonstrating competitive performance on this highly challenging task. This work expands the sophistication of SNN techniques and architectures applied to RFI-detection, and highlights the effectiveness of LSMs in handling fine-grained, complex, spatio-temporal signal-processing tasks.","authors":["Nicholas J Pritchard","Andreas Wicenec","Mohammed Bennamoun","Richard Dodson"],"url":"https://arxiv.org/abs/2504.09796"}
{"created":"2025-04-15","title":"IGL-DT: Iterative Global-Local Feature Learning with Dual-Teacher Semantic Segmentation Framework under Limited Annotation Scheme","abstract":"Semi-Supervised Semantic Segmentation (SSSS) aims to improve segmentation accuracy by leveraging a small set of labeled images alongside a larger pool of unlabeled data. Recent advances primarily focus on pseudo-labeling, consistency regularization, and co-training strategies. However, existing methods struggle to balance global semantic representation with fine-grained local feature extraction. To address this challenge, we propose a novel tri-branch semi-supervised segmentation framework incorporating a dual-teacher strategy, named IGL-DT. Our approach employs SwinUnet for high-level semantic guidance through Global Context Learning and ResUnet for detailed feature refinement via Local Regional Learning. Additionally, a Discrepancy Learning mechanism mitigates over-reliance on a single teacher, promoting adaptive feature learning. Extensive experiments on benchmark datasets demonstrate that our method outperforms state-of-the-art approaches, achieving superior segmentation performance across various data regimes.","authors":["Dinh Dai Quan Tran","Hoang-Thien Nguyen. Thanh-Huy Nguyen","Gia-Van To","Tien-Huy Nguyen","Quan Nguyen"],"url":"https://arxiv.org/abs/2504.09797"}
{"created":"2025-04-15","title":"ReadMe.LLM: A Framework to Help LLMs Understand Your Library","abstract":"Large Language Models (LLMs) often struggle with code generation tasks involving niche software libraries. Existing code generation techniques with only human-oriented documentation can fail -- even when the LLM has access to web search and the library is documented online. To address this challenge, we propose ReadMe.LLM, LLM-oriented documentation for software libraries. By attaching the contents of ReadMe.LLM to a query, performance consistently improves to near-perfect accuracy, with one case study demonstrating up to 100% success across all tested models. We propose a software development lifecycle where LLM-specific documentation is maintained alongside traditional software updates. In this study, we present two practical applications of the ReadMe.LLM idea with diverse software libraries, highlighting that our proposed approach could generalize across programming domains.","authors":["Sandya Wijaya","Jacob Bolano","Alejandro Gomez Soteres","Shriyanshu Kode","Yue Huang","Anant Sahai"],"url":"https://arxiv.org/abs/2504.09798"}
{"created":"2025-04-15","title":"Multi-task Federated Learning with Encoder-Decoder Structure: Enabling Collaborative Learning Across Different Tasks","abstract":"Federated learning has been extensively studied and applied due to its ability to ensure data security in distributed environments while building better models. However, clients participating in federated learning still face limitations, as clients with different structures or tasks cannot participate in learning together. In view of this, constructing a federated learning framework that allows collaboration between clients with different model structures and performing different tasks, enabling them to share valuable knowledge to enhance model efficiency, holds significant practical implications for the widespread application of federated learning. To achieve this goal, we propose a multi-task federated learning with encoder-decoder structure (M-Fed). Specifically, given the widespread adoption of the encoder-decoder architecture in current models, we leverage this structure to share intra-task knowledge through traditional federated learning methods and extract general knowledge from the encoder to achieve cross-task knowledge sharing. The training process is similar to traditional federated learning, and we incorporate local decoder and global decoder information into the loss function. The local decoder iteratively updates and gradually approaches the global decoder until sufficient cross-task knowledge sharing is achieved. Our method is lightweight and modular, demonstrating innovation compared to previous research. It enables clients performing different tasks to share general knowledge while maintaining the efficiency of traditional federated learning systems. We conducted experiments on two widely used benchmark datasets to verify the feasibility of M-Fed and compared it with traditional methods. The experimental results demonstrate the effectiveness of M-Fed in multi-task federated learning.","authors":["Jingxuan Zhou","Weidong Bao","Ji Wang","Dayu Zhang","Xiongtao Zhang","Yaohong Zhang"],"url":"https://arxiv.org/abs/2504.09800"}
{"created":"2025-04-15","title":"Training Small Reasoning LLMs with Cognitive Preference Alignment","abstract":"The reasoning capabilities of large language models (LLMs), such as OpenAI's o1 and DeepSeek-R1, have seen substantial advancements through deep thinking. However, these enhancements come with significant resource demands, underscoring the need to explore strategies to train effective reasoning LLMs with far fewer parameters. A critical challenge is that smaller models have different capacities and cognitive trajectories than their larger counterparts. Hence, direct distillation of chain-of-thought (CoT) results from large LLMs to smaller ones can be sometimes ineffective and requires a huge amount of annotated data. In this paper, we introduce a novel framework called Critique-Rethink-Verify (CRV), designed for training smaller yet powerful reasoning LLMs. Our CRV framework consists of multiple LLM agents, each specializing in unique abilities: (i) critiquing the CoTs according to the cognitive capabilities of smaller models, (ii) rethinking and refining these CoTs based on the critiques, and (iii) verifying the correctness of the refined results. We further propose the cognitive preference optimization (CogPO) algorithm to enhance the reasoning abilities of smaller models by aligning thoughts of these models with their cognitive capacities. Comprehensive evaluations on challenging reasoning benchmarks demonstrate the efficacy of CRV and CogPO, which outperforms other training methods by a large margin.","authors":["Wenrui Cai","Chengyu Wang","Junbing Yan","Jun Huang","Xiangzhong Fang"],"url":"https://arxiv.org/abs/2504.09802"}
{"created":"2025-04-15","title":"CUT: Pruning Pre-Trained Multi-Task Models into Compact Models for Edge Devices","abstract":"Multi-task learning has garnered widespread attention in the industry due to its efficient data utilization and strong generalization capabilities, making it particularly suitable for providing high-quality intelligent services to users. Edge devices, as the primary platforms directly serving users, play a crucial role in delivering multi-task services. However, current multi-task models are often large, and user task demands are increasingly diverse. Deploying such models directly on edge devices not only increases the burden on these devices but also leads to task redundancy. To address this issue, this paper innovatively proposes a pre-trained multi-task model pruning method specifically designed for edge computing. The goal is to utilize existing pre-trained multi-task models to construct a compact multi-task model that meets the needs of edge devices. The specific implementation steps are as follows: First, decompose the tasks within the pre-trained multi-task model and select tasks based on actual user needs. Next, while retaining the knowledge of the original pre-trained model, evaluate parameter importance and use a parameter fusion method to effectively integrate shared parameters among tasks. Finally, obtain a compact multi-task model suitable for edge devices. To validate the effectiveness of the proposed method, we conducted experiments on three public image datasets. The experimental results fully demonstrate the superiority and efficiency of this method, providing a new solution for multi-task learning on edge devices.","authors":["Jingxuan Zhou","Weidong Bao","Ji Wang","Zhengyi Zhong"],"url":"https://arxiv.org/abs/2504.09803"}
{"created":"2025-04-15","title":"BO-SA-PINNs: Self-adaptive physics-informed neural networks based on Bayesian optimization for automatically designing PDE solvers","abstract":"Physics-informed neural networks (PINNs) is becoming a popular alternative method for solving partial differential equations (PDEs). However, they require dedicated manual modifications to the hyperparameters of the network, the sampling methods and loss function weights for different PDEs, which reduces the efficiency of the solvers. In this paper, we pro- pose a general multi-stage framework, i.e. BO-SA-PINNs to alleviate this issue. In the first stage, Bayesian optimization (BO) is used to select hyperparameters for the training process, and based on the results of the pre-training, the network architecture, learning rate, sampling points distribution and loss function weights suitable for the PDEs are automatically determined. The proposed hyperparameters search space based on experimental results can enhance the efficiency of BO in identifying optimal hyperparameters. After selecting the appropriate hyperparameters, we incorporate a global self-adaptive (SA) mechanism the second stage. Using the pre-trained model and loss information in the second-stage training, the exponential moving average (EMA) method is employed to optimize the loss function weights, and residual-based adaptive refinement with distribution (RAR-D) is used to optimize the sampling points distribution. In the third stage, L-BFGS is used for stable training. In addition, we introduce a new activation function that enables BO-SA-PINNs to achieve higher accuracy. In numerical experiments, we conduct comparative and ablation experiments to verify the performance of the model on Helmholtz, Maxwell, Burgers and high-dimensional Poisson equations. The comparative experiment results show that our model can achieve higher accuracy and fewer iterations in test cases, and the ablation experiments demonstrate the positive impact of every improvement.","authors":["Rui Zhang","Liang Li","St\\'ephane Lanteri","Hao Kang","Jiaqi Li"],"url":"https://arxiv.org/abs/2504.09804"}
{"created":"2025-04-15","title":"You can lie but not deny: SWMR registers with signature properties in systems with Byzantine processes","abstract":"We define and show how to implement SWMR registers that provide properties of unforgeable digital signatures - without actually using such signatures - in systems with Byzantine processes. More precisely, we first define SWMR verifiable registers. Intuitively, processes can use these registers to write values as if they are ``signed'', such that these ``signed values'' can be ``verified'' by any process and ``relayed'' to any process. We give a signature-free implementation of such registers from plain SWMR registers in systems with $n > 3f$ processes, $f$ of which can be Byzantine. We also give a signature-free implementation of SWMR sticky registers from SWMR registers in systems with $n > 3f$ processes. Once the writer $p$ writes a value $v$ into a SWMR sticky register $R$, the register never changes its value. Note that the value $v$ can be considered ``signed'' by $p$: once $p$ writes $v$ in $R$, $p$ cannot change the value in $R$ or deny that it wrote $v$ in $R$, and every reader can verify that $p$ wrote $v$ just by reading $R$. This holds even if the writer $p$ of $R$ is Byzantine. We prove that our implementations are optimal in the number of Byzantine processes they can tolerate. Since SWMR registers can be implemented in message-passing systems with Byzantine processes and $n > 3f$ [9], the results in this paper also show that one can implement verifiable registers and sticky registers in such systems.","authors":["Xing Hu","Sam Toueg"],"url":"https://arxiv.org/abs/2504.09805"}
{"created":"2025-04-15","title":"See or Recall: A Sanity Check for the Role of Vision in Solving Visualization Question Answer Tasks with Multimodal LLMs","abstract":"Recent developments in multimodal large language models (MLLM) have equipped language models to reason about vision and language jointly. This permits MLLMs to both perceive and answer questions about data visualization across a variety of designs and tasks. Applying MLLMs to a broad range of visualization tasks requires us to properly evaluate their capabilities, and the most common way to conduct evaluation is through measuring a model's visualization reasoning capability, analogous to how we would evaluate human understanding of visualizations (e.g., visualization literacy). However, we found that in the context of visualization question answering (VisQA), how an MLLM perceives and reasons about visualizations can be fundamentally different from how humans approach the same problem. During the evaluation, even without visualization, the model could correctly answer a substantial portion of the visualization test questions, regardless of whether any selection options were provided. We hypothesize that the vast amount of knowledge encoded in the language model permits factual recall that supersedes the need to seek information from the visual signal. It raises concerns that the current VisQA evaluation may not fully capture the models' visualization reasoning capabilities. To address this, we propose a comprehensive sanity check framework that integrates a rule-based decision tree and a sanity check table to disentangle the effects of \"seeing\" (visual processing) and \"recall\" (reliance on prior knowledge). This validates VisQA datasets for evaluation, highlighting where models are truly \"seeing\", positively or negatively affected by the factual recall, or relying on inductive biases for question answering. Our study underscores the need for careful consideration in designing future visualization understanding studies when utilizing MLLMs.","authors":["Zhimin Li","Haichao Miao","Xinyuan Yan","Valerio Pascucci","Matthew Berger","Shusen Liu"],"url":"https://arxiv.org/abs/2504.09809"}
{"created":"2025-04-15","title":"High-Order Interior Penalty Finite Element Methods for Fourth-Order Phase-Field Models in Fracture Analysis","abstract":"This paper presents a novel approach for solving fourth-order phase-field models in brittle fracture mechanics using the Interior Penalty Finite Element Method (IP-FEM). The fourth-order model improves numerical stability and accuracy compared to traditional second-order phase-field models, particularly when simulating complex crack paths. The IP-FEM provides an efficient framework for discretizing these models, effectively handling nonconforming trial functions and complex boundary conditions.","authors":["Tian Tian","Chen Chunyu","Wei Huayi"],"url":"https://arxiv.org/abs/2504.09810"}
{"created":"2025-04-15","title":"Efficient Multi-Task Modeling through Automated Fusion of Trained Models","abstract":"Although multi-task learning is widely applied in intelligent services, traditional multi-task modeling methods often require customized designs based on specific task combinations, resulting in a cumbersome modeling process. Inspired by the rapid development and excellent performance of single-task models, this paper proposes an efficient multi-task modeling method that can automatically fuse trained single-task models with different structures and tasks to form a multi-task model. As a general framework, this method allows modelers to simply prepare trained models for the required tasks, simplifying the modeling process while fully utilizing the knowledge contained in the trained models. This eliminates the need for excessive focus on task relationships and model structure design. To achieve this goal, we consider the structural differences among various trained models and employ model decomposition techniques to hierarchically decompose them into multiple operable model components. Furthermore, we have designed an Adaptive Knowledge Fusion (AKF) module based on Transformer, which adaptively integrates intra-task and inter-task knowledge based on model components. Through the proposed method, we achieve efficient and automated construction of multi-task models, and its effectiveness is verified through extensive experiments on three datasets.","authors":["Jingxuan Zhou","Weidong Bao","Ji Wang","Zhengyi Zhong","Dayu Zhang"],"url":"https://arxiv.org/abs/2504.09812"}
{"created":"2025-04-15","title":"DUDA: Distilled Unsupervised Domain Adaptation for Lightweight Semantic Segmentation","abstract":"Unsupervised Domain Adaptation (UDA) is essential for enabling semantic segmentation in new domains without requiring costly pixel-wise annotations. State-of-the-art (SOTA) UDA methods primarily use self-training with architecturally identical teacher and student networks, relying on Exponential Moving Average (EMA) updates. However, these approaches face substantial performance degradation with lightweight models due to inherent architectural inflexibility leading to low-quality pseudo-labels. To address this, we propose Distilled Unsupervised Domain Adaptation (DUDA), a novel framework that combines EMA-based self-training with knowledge distillation (KD). Our method employs an auxiliary student network to bridge the architectural gap between heavyweight and lightweight models for EMA-based updates, resulting in improved pseudo-label quality. DUDA employs a strategic fusion of UDA and KD, incorporating innovative elements such as gradual distillation from large to small networks, inconsistency loss prioritizing poorly adapted classes, and learning with multiple teachers. Extensive experiments across four UDA benchmarks demonstrate DUDA's superiority in achieving SOTA performance with lightweight models, often surpassing the performance of heavyweight models from other approaches.","authors":["Beomseok Kang","Niluthpol Chowdhury Mithun","Abhinav Rajvanshi","Han-Pang Chiu","Supun Samarasekera"],"url":"https://arxiv.org/abs/2504.09814"}
{"created":"2025-04-15","title":"Augmented Relevance Datasets with Fine-Tuned Small LLMs","abstract":"Building high-quality datasets and labeling query-document relevance are essential yet resource-intensive tasks, requiring detailed guidelines and substantial effort from human annotators. This paper explores the use of small, fine-tuned large language models (LLMs) to automate relevance assessment, with a focus on improving ranking models' performance by augmenting their training dataset. We fine-tuned small LLMs to enhance relevance assessments, thereby improving dataset creation quality for downstream ranking model training. Our experiments demonstrate that these fine-tuned small LLMs not only outperform certain closed source models on our dataset but also lead to substantial improvements in ranking model performance. These results highlight the potential of leveraging small LLMs for efficient and scalable dataset augmentation, providing a practical solution for search engine optimization.","authors":["Quentin Fitte-Rey","Matyas Amrouche","Romain Deveaud"],"url":"https://arxiv.org/abs/2504.09816"}
{"created":"2025-04-15","title":"Transferable text data distillation by trajectory matching","abstract":"In the realm of large language model (LLM), as the size of large models increases, it also brings higher training costs. There is a urgent need to minimize the data size in LLM training. Compared with data selection method, the data distillation method aims to synthesize a small number of data samples to achieve the training effect of the full data set and has better flexibility. Despite its successes in computer vision, the discreteness of text data has hitherto stymied its exploration in natural language processing (NLP). In this work, we proposed a method that involves learning pseudo prompt data based on trajectory matching and finding its nearest neighbor ID to achieve cross-architecture transfer. During the distillation process, we introduce a regularization loss to improve the robustness of our distilled data. To our best knowledge, this is the first data distillation work suitable for text generation tasks such as instruction tuning. Evaluations on two benchmarks, including ARC-Easy and MMLU instruction tuning datasets, established the superiority of our distillation approach over the SOTA data selection method LESS. Furthermore, our method demonstrates a good transferability over LLM structures (i.e., OPT to Llama).","authors":["Rong Yao","Hailin Hu","Yifei Fu","Hanting Chen","Wenyi Fang","Fanyi Du","Kai Han","Yunhe Wang"],"url":"https://arxiv.org/abs/2504.09818"}
{"created":"2025-04-15","title":"Density-based Object Detection in Crowded Scenes","abstract":"Compared with the generic scenes, crowded scenes contain highly-overlapped instances, which result in: 1) more ambiguous anchors during training of object detectors, and 2) more predictions are likely to be mistakenly suppressed in post-processing during inference. To address these problems, we propose two new strategies, density-guided anchors (DGA) and density-guided NMS (DG-NMS), which uses object density maps to jointly compute optimal anchor assignments and reweighing, as well as an adaptive NMS. Concretely, based on an unbalanced optimal transport (UOT) problem, the density owned by each ground-truth object is transported to each anchor position at a minimal transport cost. And density on anchors comprises an instance-specific density distribution, from which DGA decodes the optimal anchor assignment and re-weighting strategy. Meanwhile, DG-NMS utilizes the predicted density map to adaptively adjust the NMS threshold to reduce mistaken suppressions. In the UOT, a novel overlap-aware transport cost is specifically designed for ambiguous anchors caused by overlapped neighboring objects. Extensive experiments on the challenging CrowdHuman dataset with Citypersons dataset demonstrate that our proposed density-guided detector is effective and robust to crowdedness. The code and pre-trained models will be made available later.","authors":["Chenyang Zhao","Jia Wan","Antoni B. Chan"],"url":"https://arxiv.org/abs/2504.09819"}
{"created":"2025-04-15","title":"RAKG:Document-level Retrieval Augmented Knowledge Graph Construction","abstract":"With the rise of knowledge graph based retrieval-augmented generation (RAG) techniques such as GraphRAG and Pike-RAG, the role of knowledge graphs in enhancing the reasoning capabilities of large language models (LLMs) has become increasingly prominent. However, traditional Knowledge Graph Construction (KGC) methods face challenges like complex entity disambiguation, rigid schema definition, and insufficient cross-document knowledge integration. This paper focuses on the task of automatic document-level knowledge graph construction. It proposes the Document-level Retrieval Augmented Knowledge Graph Construction (RAKG) framework. RAKG extracts pre-entities from text chunks and utilizes these pre-entities as queries for RAG, effectively addressing the issue of long-context forgetting in LLMs and reducing the complexity of Coreference Resolution. In contrast to conventional KGC methods, RAKG more effectively captures global information and the interconnections among disparate nodes, thereby enhancing the overall performance of the model. Additionally, we transfer the RAG evaluation framework to the KGC field and filter and evaluate the generated knowledge graphs, thereby avoiding incorrectly generated entities and relationships caused by hallucinations in LLMs. We further developed the MINE dataset by constructing standard knowledge graphs for each article and experimentally validated the performance of RAKG. The results show that RAKG achieves an accuracy of 95.91 % on the MINE dataset, a 6.2 % point improvement over the current best baseline, GraphRAG (89.71 %). The code is available at https://github.com/LMMApplication/RAKG.","authors":["Hairong Zhang","Jiaheng Si","Guohang Yan","Boyuan Qi","Pinlong Cai","Song Mao","Ding Wang","Botian Shi"],"url":"https://arxiv.org/abs/2504.09823"}
{"created":"2025-04-15","title":"Abacus-SQL: A Text-to-SQL System Empowering Cross-Domain and Open-Domain Database Retrieval","abstract":"The existing text-to-SQL systems have made significant progress in SQL query generation, but they still face numerous challenges. Existing systems often lack retrieval capabilities for open-domain databases, requiring users to manually filter relevant databases. Additionally, their cross-domain transferability is limited, making it challenging to accommodate diverse query requirements. To address these issues, we propose Abacus-SQL. Abacus-SQL utilizes database retrieval technology to accurately locate the required databases in an open-domain database environment. It also enhances the system cross-domain transfer ability through data augmentation methods. Moreover, Abacus-SQL employs Pre-SQL and Self-debug methods, thereby enhancing the accuracy of SQL queries. Experimental results demonstrate that Abacus-SQL performs excellently in multi-turn text-to-SQL tasks, effectively validating the approach's effectiveness. Abacus-SQL is publicly accessible at https://huozi.8wss.com/abacus-sql/.","authors":["Keyan Xu","Dingzirui Wang","Xuanliang Zhang","Qingfu Zhu","Wanxiang Che"],"url":"https://arxiv.org/abs/2504.09824"}
{"created":"2025-04-15","title":"Redesign of Online Design Communities: Facilitating Personalized Visual Design Learning with Structured Comments","abstract":"Online Design Communities (ODCs) offer various artworks with members' comments for beginners to learn visual design. However, as identified by our Formative Study (N = 10), current ODCs lack features customized for personal learning purposes, e.g., searching artworks and digesting useful comments to learn design principles about buttons. In this paper, we present DesignLearner, a redesigned interface of ODCs to facilitate personalized visual design learning with comments structured based on UI components (e.g., button, text) and visual elements (e.g., color, contrast). In DesignLearner, learners can specify the UI components and visual elements that they wish to learn to filter artworks and associated comments. They can interactively read comments on an artwork, take notes, and get suggestions for the next artworks to explore. Our between-subjects study (N = 24) indicates that compared to a traditional ODC interface, DesignLearner can improve the user learning outcome and is deemed significantly more useful. We conclude with design considerations for customizing the interface of online communities to satisfy users' learning needs.","authors":["Xia Chen","Xinyue Chen","Weixian Hu","Haojia Zheng","YuJun Qian","Zhenhui Peng"],"url":"https://arxiv.org/abs/2504.09827"}
{"created":"2025-04-15","title":"FATE: A Prompt-Tuning-Based Semi-Supervised Learning Framework for Extremely Limited Labeled Data","abstract":"Semi-supervised learning (SSL) has achieved significant progress by leveraging both labeled data and unlabeled data. Existing SSL methods overlook a common real-world scenario when labeled data is extremely scarce, potentially as limited as a single labeled sample in the dataset. General SSL approaches struggle to train effectively from scratch under such constraints, while methods utilizing pre-trained models often fail to find an optimal balance between leveraging limited labeled data and abundant unlabeled data. To address this challenge, we propose Firstly Adapt, Then catEgorize (FATE), a novel SSL framework tailored for scenarios with extremely limited labeled data. At its core, the two-stage prompt tuning paradigm FATE exploits unlabeled data to compensate for scarce supervision signals, then transfers to downstream tasks. Concretely, FATE first adapts a pre-trained model to the feature distribution of downstream data using volumes of unlabeled samples in an unsupervised manner. It then applies an SSL method specifically designed for pre-trained models to complete the final classification task. FATE is designed to be compatible with both vision and vision-language pre-trained models. Extensive experiments demonstrate that FATE effectively mitigates challenges arising from the scarcity of labeled samples in SSL, achieving an average performance improvement of 33.74% across seven benchmarks compared to state-of-the-art SSL methods. Code is available at https://anonymous.4open.science/r/Semi-supervised-learning-BA72.","authors":["Hezhao Liu","Yang Lu","Mengke Li","Yiqun Zhang","Shreyank N Gowda","Chen Gong","Hanzi Wang"],"url":"https://arxiv.org/abs/2504.09828"}
{"created":"2025-04-15","title":"PreCi: Pretraining and Continual Improvement of Humanoid Locomotion via Model-Assumption-Based Regularization","abstract":"Humanoid locomotion is a challenging task due to its inherent complexity and high-dimensional dynamics, as well as the need to adapt to diverse and unpredictable environments. In this work, we introduce a novel learning framework for effectively training a humanoid locomotion policy that imitates the behavior of a model-based controller while extending its capabilities to handle more complex locomotion tasks, such as more challenging terrain and higher velocity commands. Our framework consists of three key components: pre-training through imitation of the model-based controller, fine-tuning via reinforcement learning, and model-assumption-based regularization (MAR) during fine-tuning. In particular, MAR aligns the policy with actions from the model-based controller only in states where the model assumption holds to prevent catastrophic forgetting. We evaluate the proposed framework through comprehensive simulation tests and hardware experiments on a full-size humanoid robot, Digit, demonstrating a forward speed of 1.5 m/s and robust locomotion across diverse terrains, including slippery, sloped, uneven, and sandy terrains.","authors":["Hyunyoung Jung","Zhaoyuan Gu","Ye Zhao","Hae-Won Park","Sehoon Ha"],"url":"https://arxiv.org/abs/2504.09833"}
{"created":"2025-04-15","title":"Mining for Lags in Updating Critical Security Threats: A Case Study of Log4j Library","abstract":"The Log4j-Core vulnerability, known as Log4Shell, exposed significant challenges to dependency management in software ecosystems. When a critical vulnerability is disclosed, it is imperative that dependent packages quickly adopt patched versions to mitigate risks. However, delays in applying these updates can leave client systems exposed to exploitation. Previous research has primarily focused on NPM, but there is a need for similar analysis in other ecosystems, such as Maven. Leveraging the 2025 mining challenge dataset of Java dependencies, we identify factors influencing update lags and categorize them based on version classification (major, minor, patch release cycles). Results show that lags exist, but projects with higher release cycle rates tend to address severe security issues more swiftly. In addition, over half of vulnerability fixes are implemented through patch updates, highlighting the critical role of incremental changes in maintaining software security. Our findings confirm that these lags also appear in the Maven ecosystem, even when migrating away from severe threats.","authors":["Hidetake Tanaka","Kazuma Yamasaki","Momoka Hirose","Takashi Nakano","Youmei Fan","Kazumasa Shimari","Raula Gaikovina Kula","Kenichi Matsumoto"],"url":"https://arxiv.org/abs/2504.09834"}
{"created":"2025-04-15","title":"Laugh at Your Own Pace: Basic Performance Evaluation of Language Learning Assistance by Adjustment of Video Playback Speeds Based on Laughter Detection","abstract":"Among various methods to learn a second language (L2), such as listening and shadowing, Extensive Viewing involves learning L2 by watching many videos. However, it is difficult for many L2 learners to smoothly and effortlessly comprehend video contents made for native speakers at the original speed. Therefore, we developed a language learning assistance system that automatically adjusts the playback speed according to the learner's comprehension. Our system judges that learners understand the contents if they laugh at the punchlines of comedy dramas, and vice versa. Experimental results show that this system supports learners with relatively low L2 ability (under 700 in TOEIC Score in the experimental condition) to understand video contents. Our system can widen learners' possible options of native speakers' videos as Extensive Viewing material.","authors":["Naoto Nishida","Hinako Nozaki","Buntarou Shizuki"],"url":"https://arxiv.org/abs/2504.09835"}
{"created":"2025-04-15","title":"SafeSpeech: Robust and Universal Voice Protection Against Malicious Speech Synthesis","abstract":"Speech synthesis technology has brought great convenience, while the widespread usage of realistic deepfake audio has triggered hazards. Malicious adversaries may unauthorizedly collect victims' speeches and clone a similar voice for illegal exploitation (\\textit{e.g.}, telecom fraud). However, the existing defense methods cannot effectively prevent deepfake exploitation and are vulnerable to robust training techniques. Therefore, a more effective and robust data protection method is urgently needed. In response, we propose a defensive framework, \\textit{\\textbf{SafeSpeech}}, which protects the users' audio before uploading by embedding imperceptible perturbations on original speeches to prevent high-quality synthetic speech. In SafeSpeech, we devise a robust and universal proactive protection technique, \\textbf{S}peech \\textbf{PE}rturbative \\textbf{C}oncealment (\\textbf{SPEC}), that leverages a surrogate model to generate universally applicable perturbation for generative synthetic models. Moreover, we optimize the human perception of embedded perturbation in terms of time and frequency domains. To evaluate our method comprehensively, we conduct extensive experiments across advanced models and datasets, both subjectively and objectively. Our experimental results demonstrate that SafeSpeech achieves state-of-the-art (SOTA) voice protection effectiveness and transferability and is highly robust against advanced adaptive adversaries. Moreover, SafeSpeech has real-time capability in real-world tests. The source code is available at \\href{https://github.com/wxzyd123/SafeSpeech}{https://github.com/wxzyd123/SafeSpeech}.","authors":["Zhisheng Zhang","Derui Wang","Qianyi Yang","Pengyang Huang","Junhan Pu","Yuxin Cao","Kai Ye","Jie Hao","Yixian Yang"],"url":"https://arxiv.org/abs/2504.09839"}
{"created":"2025-04-15","title":"StruPhantom: Evolutionary Injection Attacks on Black-Box Tabular Agents Powered by Large Language Models","abstract":"The proliferation of autonomous agents powered by large language models (LLMs) has revolutionized popular business applications dealing with tabular data, i.e., tabular agents. Although LLMs are observed to be vulnerable against prompt injection attacks from external data sources, tabular agents impose strict data formats and predefined rules on the attacker's payload, which are ineffective unless the agent navigates multiple layers of structural data to incorporate the payload. To address the challenge, we present a novel attack termed StruPhantom which specifically targets black-box LLM-powered tabular agents. Our attack designs an evolutionary optimization procedure which continually refines attack payloads via the proposed constrained Monte Carlo Tree Search augmented by an off-topic evaluator. StruPhantom helps systematically explore and exploit the weaknesses of target applications to achieve goal hijacking. Our evaluation validates the effectiveness of StruPhantom across various LLM-based agents, including those on real-world platforms, and attack scenarios. Our attack achieves over 50% higher success rates than baselines in enforcing the application's response to contain phishing links or malicious codes.","authors":["Yang Feng","Xudong Pan"],"url":"https://arxiv.org/abs/2504.09841"}
{"created":"2025-04-15","title":"ST-Booster: An Iterative SpatioTemporal Perception Booster for Vision-and-Language Navigation in Continuous Environments","abstract":"Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires agents to navigate unknown, continuous spaces based on natural language instructions. Compared to discrete settings, VLN-CE poses two core perception challenges. First, the absence of predefined observation points leads to heterogeneous visual memories and weakened global spatial correlations. Second, cumulative reconstruction errors in three-dimensional scenes introduce structural noise, impairing local feature perception. To address these challenges, this paper proposes ST-Booster, an iterative spatiotemporal booster that enhances navigation performance through multi-granularity perception and instruction-aware reasoning. ST-Booster consists of three key modules -- Hierarchical SpatioTemporal Encoding (HSTE), Multi-Granularity Aligned Fusion (MGAF), and ValueGuided Waypoint Generation (VGWG). HSTE encodes long-term global memory using topological graphs and captures shortterm local details via grid maps. MGAF aligns these dualmap representations with instructions through geometry-aware knowledge fusion. The resulting representations are iteratively refined through pretraining tasks. During reasoning, VGWG generates Guided Attention Heatmaps (GAHs) to explicitly model environment-instruction relevance and optimize waypoint selection. Extensive comparative experiments and performance analyses are conducted, demonstrating that ST-Booster outperforms existing state-of-the-art methods, particularly in complex, disturbance-prone environments.","authors":["Lu Yue","Dongliang Zhou","Liang Xie","Erwei Yin","Feitian Zhang"],"url":"https://arxiv.org/abs/2504.09843"}
{"created":"2025-04-15","title":"OVERLORD: Ultimate Scaling of DataLoader for Multi-Source Large Foundation Model Training","abstract":"Modern frameworks for training large foundation models (LFMs) employ data loaders in a data parallel paradigm. While this design offers implementation simplicity, it introduces two fundamental challenges. First, due to the quadratic computational complexity of the attention operator, the non-uniform sample distribution over data-parallel ranks leads to a significant workload imbalance among loaders, which degrades the training efficiency. This paradigm also impedes the implementation of data mixing algorithms (e.g., curriculum learning) over different datasets. Second, to acquire a broad range of capability, LFMs training ingests data from diverse sources, each with distinct file access states. Colocating massive datasets within loader instances can easily exceed local pod memory capacity. Additionally, heavy sources with higher transformation latency require larger worker pools, further exacerbating memory consumption.","authors":["Juntao Zhao","Qi Lu","Wei Jia","Borui Wan","Lei Zuo","Junda Feng","Jianyu Jiang","Yangrui Chen","Shuaishuai Cao","Jialing He","Kaihua Jiang","Yuanzhe Hu","Yanghua Peng","Haibin Lin","Xin Liu","Chuan Wu"],"url":"https://arxiv.org/abs/2504.09844"}
{"created":"2025-04-15","title":"GlyTwin: Digital Twin for Glucose Control in Type 1 Diabetes Through Optimal Behavioral Modifications Using Patient-Centric Counterfactuals","abstract":"Frequent and long-term exposure to hyperglycemia (i.e., high blood glucose) increases the risk of chronic complications such as neuropathy, nephropathy, and cardiovascular disease. Current technologies like continuous subcutaneous insulin infusion (CSII) and continuous glucose monitoring (CGM) primarily model specific aspects of glycemic control-like hypoglycemia prediction or insulin delivery. Similarly, most digital twin approaches in diabetes management simulate only physiological processes. These systems lack the ability to offer alternative treatment scenarios that support proactive behavioral interventions. To address this, we propose GlyTwin, a novel digital twin framework that uses counterfactual explanations to simulate optimal treatments for glucose regulation. Our approach helps patients and caregivers modify behaviors like carbohydrate intake and insulin dosing to avoid abnormal glucose events. GlyTwin generates behavioral treatment suggestions that proactively prevent hyperglycemia by recommending small adjustments to daily choices, reducing both frequency and duration of these events. Additionally, it incorporates stakeholder preferences into the intervention design, making recommendations patient-centric and tailored. We evaluate GlyTwin on AZT1D, a newly constructed dataset with longitudinal data from 21 type 1 diabetes (T1D) patients on automated insulin delivery systems over 26 days. Results show GlyTwin outperforms state-of-the-art counterfactual methods, generating 76.6% valid and 86% effective interventions. These findings demonstrate the promise of counterfactual-driven digital twins in delivering personalized healthcare.","authors":["Asiful Arefeen","Saman Khamesian","Maria Adela Grando","Bithika Thompson","Hassan Ghasemzadeh"],"url":"https://arxiv.org/abs/2504.09846"}
{"created":"2025-04-15","title":"A Survey of Large Language Model-Powered Spatial Intelligence Across Scales: Advances in Embodied Agents, Smart Cities, and Earth Science","abstract":"Over the past year, the development of large language models (LLMs) has brought spatial intelligence into focus, with much attention on vision-based embodied intelligence. However, spatial intelligence spans a broader range of disciplines and scales, from navigation and urban planning to remote sensing and earth science. What are the differences and connections between spatial intelligence across these fields? In this paper, we first review human spatial cognition and its implications for spatial intelligence in LLMs. We then examine spatial memory, knowledge representations, and abstract reasoning in LLMs, highlighting their roles and connections. Finally, we analyze spatial intelligence across scales -- from embodied to urban and global levels -- following a framework that progresses from spatial memory and understanding to spatial reasoning and intelligence. Through this survey, we aim to provide insights into interdisciplinary spatial intelligence research and inspire future studies.","authors":["Jie Feng","Jinwei Zeng","Qingyue Long","Hongyi Chen","Jie Zhao","Yanxin Xi","Zhilun Zhou","Yuan Yuan","Shengyuan Wang","Qingbin Zeng","Songwei Li","Yunke Zhang","Yuming Lin","Tong Li","Jingtao Ding","Chen Gao","Fengli Xu","Yong Li"],"url":"https://arxiv.org/abs/2504.09848"}
{"created":"2025-04-15","title":"Accelerating Differentially Private Federated Learning via Adaptive Extrapolation","abstract":"The federated learning (FL) framework enables multiple clients to collaboratively train machine learning models without sharing their raw data, but it remains vulnerable to privacy attacks. One promising approach is to incorporate differential privacy (DP)-a formal notion of privacy-into the FL framework. DP-FedAvg is one of the most popular algorithms for DP-FL, but it is known to suffer from the slow convergence in the presence of heterogeneity among clients' data. Most of the existing methods to accelerate DP-FL require 1) additional hyperparameters or 2) additional computational cost for clients, which is not desirable since 1) hyperparameter tuning is computationally expensive and data-dependent choice of hyperparameters raises the risk of privacy leakage, and 2) clients are often resource-constrained. To address this issue, we propose DP-FedEXP, which adaptively selects the global step size based on the diversity of the local updates without requiring any additional hyperparameters or client computational cost. We show that DP-FedEXP provably accelerates the convergence of DP-FedAvg and it empirically outperforms existing methods tailored for DP-FL.","authors":["Shokichi Takakura","Seng Pei Liew","Satoshi Hasegawa"],"url":"https://arxiv.org/abs/2504.09850"}
{"created":"2025-04-15","title":"Carbon-Efficient 3D DNN Acceleration: Optimizing Performance and Sustainability","abstract":"As Deep Neural Networks (DNNs) continue to drive advancements in artificial intelligence, the design of hardware accelerators faces growing concerns over embodied carbon footprint due to complex fabrication processes. 3D integration improves performance but introduces sustainability challenges, making carbon-aware optimization essential. In this work, we propose a carbon-efficient design methodology for 3D DNN accelerators, leveraging approximate computing and genetic algorithm-based design space exploration to optimize Carbon Delay Product (CDP). By integrating area-efficient approximate multipliers into Multiply-Accumulate (MAC) units, our approach effectively reduces silicon area and fabrication overhead while maintaining high computational accuracy. Experimental evaluations across three technology nodes (45nm, 14nm, and 7nm) show that our method reduces embodied carbon by up to 30% with negligible accuracy drop.","authors":["Aikaterini Maria Panteleaki","Konstantinos Balaskas","Georgios Zervakis","Hussam Amrouch","Iraklis Anagnostopoulos"],"url":"https://arxiv.org/abs/2504.09851"}
{"created":"2025-04-15","title":"GFT: Gradient Focal Transformer","abstract":"Fine-Grained Image Classification (FGIC) remains a complex task in computer vision, as it requires models to distinguish between categories with subtle localized visual differences. Well-studied CNN-based models, while strong in local feature extraction, often fail to capture the global context required for fine-grained recognition, while more recent ViT-backboned models address FGIC with attention-driven mechanisms but lack the ability to adaptively focus on truly discriminative regions. TransFG and other ViT-based extensions introduced part-aware token selection to enhance attention localization, yet they still struggle with computational efficiency, attention region selection flexibility, and detail-focus narrative in complex environments. This paper introduces GFT (Gradient Focal Transformer), a new ViT-derived framework created for FGIC tasks. GFT integrates the Gradient Attention Learning Alignment (GALA) mechanism to dynamically prioritize class-discriminative features by analyzing attention gradient flow. Coupled with a Progressive Patch Selection (PPS) strategy, the model progressively filters out less informative regions, reducing computational overhead while enhancing sensitivity to fine details. GFT achieves SOTA accuracy on FGVC Aircraft, Food-101, and COCO datasets with 93M parameters, outperforming ViT-based advanced FGIC models in efficiency. By bridging global context and localized detail extraction, GFT sets a new benchmark in fine-grained recognition, offering interpretable solutions for real-world deployment scenarios.","authors":["Boris Kriuk","Simranjit Kaur Gill","Shoaib Aslam","Amir Fakhrutdinov"],"url":"https://arxiv.org/abs/2504.09852"}
{"created":"2025-04-15","title":"PestMA: LLM-based Multi-Agent System for Informed Pest Management","abstract":"Effective pest management is complex due to the need for accurate, context-specific decisions. Recent advancements in large language models (LLMs) open new possibilities for addressing these challenges by providing sophisticated, adaptive knowledge acquisition and reasoning. However, existing LLM-based pest management approaches often rely on a single-agent paradigm, which can limit their capacity to incorporate diverse external information, engage in systematic validation, and address complex, threshold-driven decisions. To overcome these limitations, we introduce PestMA, an LLM-based multi-agent system (MAS) designed to generate reliable and evidence-based pest management advice. Building on an editorial paradigm, PestMA features three specialized agents, an Editor for synthesizing pest management recommendations, a Retriever for gathering relevant external data, and a Validator for ensuring correctness. Evaluations on real-world pest scenarios demonstrate that PestMA achieves an initial accuracy of 86.8% for pest management decisions, which increases to 92.6% after validation. These results underscore the value of collaborative agent-based workflows in refining and validating decisions, highlighting the potential of LLM-based multi-agent systems to automate and enhance pest management processes.","authors":["Hongrui Shi","Shunbao Li","Zhipeng Yuan","Po Yang"],"url":"https://arxiv.org/abs/2504.09855"}
{"created":"2025-04-15","title":"Working with Large Language Models to Enhance Messaging Effectiveness for Vaccine Confidence","abstract":"Vaccine hesitancy and misinformation are significant barriers to achieving widespread vaccination coverage. Smaller public health departments may lack the expertise or resources to craft effective vaccine messaging. This paper explores the potential of ChatGPT-augmented messaging to promote confidence in vaccination uptake.","authors":["Lucinda Gullison","Feng Fu"],"url":"https://arxiv.org/abs/2504.09857"}
{"created":"2025-04-15","title":"Reasoning Models Can Be Effective Without Thinking","abstract":"Recent LLMs have significantly improved reasoning capabilities, primarily by including an explicit, lengthy Thinking process as part of generation. In this paper, we question whether this explicit thinking is necessary. Using the state-of-the-art DeepSeek-R1-Distill-Qwen, we find that bypassing the thinking process via simple prompting, denoted as NoThinking, can be surprisingly effective. When controlling for the number of tokens, NoThinking outperforms Thinking across a diverse set of seven challenging reasoning datasets--including mathematical problem solving, formal theorem proving, and coding--especially in low-budget settings, e.g., 51.3 vs. 28.9 on ACM 23 with 700 tokens. Notably, the performance of NoThinking becomes more competitive with pass@k as k increases. Building on this observation, we demonstrate that a parallel scaling approach that uses NoThinking to generate N outputs independently and aggregates them is highly effective. For aggregation, we use task-specific verifiers when available, or we apply simple best-of-N strategies such as confidence-based selection. Our method outperforms a range of baselines with similar latency using Thinking, and is comparable to Thinking with significantly longer latency (up to 9x). Together, our research encourages a reconsideration of the necessity of lengthy thinking processes, while also establishing a competitive reference for achieving strong reasoning performance in low-budget settings or at low latency using parallel scaling.","authors":["Wenjie Ma","Jingxuan He","Charlie Snell","Tyler Griggs","Sewon Min","Matei Zaharia"],"url":"https://arxiv.org/abs/2504.09858"}
{"created":"2025-04-15","title":"Can VLMs Assess Similarity Between Graph Visualizations?","abstract":"Graph visualizations have been studied for tasks such as clustering and temporal analysis, but how these visual similarities relate to established graph similarity measures remains unclear. In this paper, we explore the potential of Vision Language Models (VLMs) to approximate human-like perception of graph similarity. We generate graph datasets of various sizes and densities and compare VLM-derived visual similarity scores with feature-based measures. Our findings indicate VLMs can assess graph similarity in a manner similar to feature-based measures, even though differences among the measures exist. In future work, we plan to extend our research by conducting experiments on human visual graph perception.","authors":["Seokweon Jung","Hyeon Jeon","Jeongmin Rhee","Jinwook Seo"],"url":"https://arxiv.org/abs/2504.09859"}
{"created":"2025-04-15","title":"SUMART: SUMmARizing Translation from Wordy to Concise Expression","abstract":"We propose SUMART, a method for summarizing and compressing the volume of verbose subtitle translations. SUMART is designed for understanding translated captions (e.g., interlingual conversations via subtitle translation or when watching movies in foreign language audio and translated captions). SUMART is intended for users who want a big-picture and fast understanding of the conversation, audio, video content, and speech in a foreign language. During the training data collection, when a speaker makes a verbose statement, SUMART employs a large language model on-site to compress the volume of subtitles. This compressed data is then stored in a database for fine-tuning purposes. Later, SUMART uses data pairs from those non-compressed ASR results and compressed translated results for fine-tuning the translation model to generate more concise translations for practical uses. In practical applications, SUMART utilizes this trained model to produce concise translation results. Furthermore, as a practical application, we developed an application that allows conversations using subtitle translation in augmented reality spaces. As a pilot study, we conducted qualitative surveys using a SUMART prototype and a survey on the summarization model for SUMART. We envision the most effective use case of this system is where users need to consume a lot of information quickly (e.g., Speech, lectures, podcasts, Q&amp;A in conferences).","authors":["Naoto Nishida","Jun Rekimoto"],"url":"https://arxiv.org/abs/2504.09860"}
{"created":"2025-04-15","title":"EthosGPT: Mapping Human Value Diversity to Advance Sustainable Development Goals (SDGs)","abstract":"Large language models (LLMs) are transforming global decision-making and societal systems by processing diverse data at unprecedented scales. However, their potential to homogenize human values poses critical risks, similar to biodiversity loss undermining ecological resilience. Rooted in the ancient Greek concept of ethos, meaning both individual character and the shared moral fabric of communities, EthosGPT draws on a tradition that spans from Aristotle's virtue ethics to Adam Smith's moral sentiments as the ethical foundation of economic cooperation. These traditions underscore the vital role of value diversity in fostering social trust, institutional legitimacy, and long-term prosperity. EthosGPT addresses the challenge of value homogenization by introducing an open-source framework for mapping and evaluating LLMs within a global scale of human values. Using international survey data on cultural indices, prompt-based assessments, and comparative statistical analyses, EthosGPT reveals both the adaptability and biases of LLMs across regions and cultures. It offers actionable insights for developing inclusive LLMs, such as diversifying training data and preserving endangered cultural heritage to ensure representation in AI systems. These contributions align with the United Nations Sustainable Development Goals (SDGs), especially SDG 10 (Reduced Inequalities), SDG 11.4 (Cultural Heritage Preservation), and SDG 16 (Peace, Justice and Strong Institutions). Through interdisciplinary collaboration, EthosGPT promotes AI systems that are both technically robust and ethically inclusive, advancing value plurality as a cornerstone for sustainable and equitable futures.","authors":["Luyao Zhang"],"url":"https://arxiv.org/abs/2504.09861"}
{"created":"2025-04-15","title":"RadarLLM: Empowering Large Language Models to Understand Human Motion from Millimeter-wave Point Cloud Sequence","abstract":"Millimeter-wave radar provides a privacy-preserving solution for human motion analysis, yet its sparse point clouds pose significant challenges for semantic understanding. We present Radar-LLM, the first framework that leverages large language models (LLMs) for human motion understanding using millimeter-wave radar as the sensing modality. Our approach introduces two key innovations: (1) a motion-guided radar tokenizer based on our Aggregate VQ-VAE architecture that incorporates deformable body templates and masked trajectory modeling to encode spatiotemporal point clouds into compact semantic tokens, and (2) a radar-aware language model that establishes cross-modal alignment between radar and text in a shared embedding space. To address data scarcity, we introduce a physics-aware synthesis pipeline that generates realistic radar-text pairs from motion-text datasets. Extensive experiments demonstrate that Radar-LLM achieves state-of-the-art performance across both synthetic and real-world benchmarks, enabling accurate translation of millimeter-wave signals to natural language descriptions. This breakthrough facilitates comprehensive motion understanding in privacy-sensitive applications like healthcare and smart homes. We will release the full implementation to support further research on https://inowlzy.github.io/RadarLLM/.","authors":["Zengyuan Lai","Jiarui Yang","Songpengcheng Xia","Lizhou Lin","Lan Sun","Renwen Wang","Jianran Liu","Qi Wu","Ling Pei"],"url":"https://arxiv.org/abs/2504.09862"}
{"created":"2025-04-15","title":"Labeling Messages as AI-Generated Does Not Reduce Their Persuasive Effects","abstract":"As generative artificial intelligence (AI) enables the creation and dissemination of information at massive scale and speed, it is increasingly important to understand how people perceive AI-generated content. One prominent policy proposal requires explicitly labeling AI-generated content to increase transparency and encourage critical thinking about the information, but prior research has not yet tested the effects of such labels. To address this gap, we conducted a survey experiment (N=1601) on a diverse sample of Americans, presenting participants with an AI-generated message about several public policies (e.g., allowing colleges to pay student-athletes), randomly assigning whether participants were told the message was generated by (a) an expert AI model, (b) a human policy expert, or (c) no label. We found that messages were generally persuasive, influencing participants' views of the policies by 9.74 percentage points on average. However, while 94.6% of participants assigned to the AI and human label conditions believed the authorship labels, labels had no significant effects on participants' attitude change toward the policies, judgments of message accuracy, nor intentions to share the message with others. These patterns were robust across a variety of participant characteristics, including prior knowledge of the policy, prior experience with AI, political party, education level, or age. Taken together, these results imply that, while authorship labels would likely enhance transparency, they are unlikely to substantially affect the persuasiveness of the labeled content, highlighting the need for alternative strategies to address challenges posed by AI-generated information.","authors":["Isabel O. Gallegos","Chen Shani","Weiyan Shi","Federico Bianchi","Izzy Gainsburg","Dan Jurafsky","Robb Willer"],"url":"https://arxiv.org/abs/2504.09865"}
{"created":"2025-04-15","title":"PASS-FC: Progressive and Adaptive Search Scheme for Fact Checking of Comprehensive Claims","abstract":"Automated fact-checking faces challenges in handling complex real-world claims. We present PASS-FC, a novel framework that addresses these issues through claim augmentation, adaptive question generation, and iterative verification. PASS-FC enhances atomic claims with temporal and entity context, employs advanced search techniques, and utilizes a reflection mechanism. We evaluate PASS-FC on six diverse datasets, demonstrating superior performance across general knowledge, scientific, real-world, and multilingual fact-checking tasks. Our framework often surpasses stronger baseline models. Hyperparameter analysis reveals optimal settings for evidence quantity and reflection label triggers, while ablation studies highlight the importance of claim augmentation and language-specific adaptations. PASS-FC's performance underscores its effectiveness in improving fact-checking accuracy and adaptability across various domains. We will open-source our code and experimental results to facilitate further research in this area.","authors":["Ziyu Zhuang"],"url":"https://arxiv.org/abs/2504.09866"}
{"created":"2025-04-15","title":"NeRF-Based Transparent Object Grasping Enhanced by Shape Priors","abstract":"Transparent object grasping remains a persistent challenge in robotics, largely due to the difficulty of acquiring precise 3D information. Conventional optical 3D sensors struggle to capture transparent objects, and machine learning methods are often hindered by their reliance on high-quality datasets. Leveraging NeRF's capability for continuous spatial opacity modeling, our proposed architecture integrates a NeRF-based approach for reconstructing the 3D information of transparent objects. Despite this, certain portions of the reconstructed 3D information may remain incomplete. To address these deficiencies, we introduce a shape-prior-driven completion mechanism, further refined by a geometric pose estimation method we have developed. This allows us to obtain a complete and reliable 3D information of transparent objects. Utilizing this refined data, we perform scene-level grasp prediction and deploy the results in real-world robotic systems. Experimental validation demonstrates the efficacy of our architecture, showcasing its capability to reliably capture 3D information of various transparent objects in cluttered scenes, and correspondingly, achieve high-quality, stables, and executable grasp predictions.","authors":["Yi Han","Zixin Lin","Dongjie Li","Lvping Chen","Yongliang Shi","Gan Ma"],"url":"https://arxiv.org/abs/2504.09868"}
{"created":"2025-04-15","title":"Ember: A Compiler for Efficient Embedding Operations on Decoupled Access-Execute Architectures","abstract":"Irregular embedding lookups are a critical bottleneck in recommender models, sparse large language models, and graph learning models. In this paper, we first demonstrate that, by offloading these lookups to specialized access units, Decoupled Access-Execute (DAE) processors achieve 2.6$\\times$ higher performance and 6.4$\\times$ higher performance/watt than GPUs on end-to-end models. Then, we propose the Ember compiler for automatically generating optimized DAE code from PyTorch and TensorFlow. Conversely from other DAE compilers, Ember features multiple intermediate representations specifically designed for different optimization levels. In this way, Ember can implement all optimizations to match the performance of hand-written code, unlocking the full potential of DAE architectures at scale.","authors":["Marco Siracusa (Barcelona Supercomputing Center)","Olivia Hsu (Stanford University)","Victor Soria-Pardos (Barcelona Supercomputing Center)","Joshua Randall (Arm)","Arnaud Grasset (Arm)","Eric Biscondi (Arm)","Doug Joseph (Arm)","Randy Allen (Barcelona Supercomputing Center)","Fredrik Kjolstad (Stanford University)","Miquel Moret\\'o Planas (Barcelona Supercomputing Center","Universitat Polit\\`ecnica de Catalunya)","Adri\\`a Armejach (Barcelona Supercomputing Center","Universitat Polit\\`ecnica de Catalunya)"],"url":"https://arxiv.org/abs/2504.09870"}
{"created":"2025-04-15","title":"Truncated Matrix Completion - An Empirical Study","abstract":"Low-rank Matrix Completion (LRMC) describes the problem where we wish to recover missing entries of partially observed low-rank matrix. Most existing matrix completion work deals with sampling procedures that are independent of the underlying data values. While this assumption allows the derivation of nice theoretical guarantees, it seldom holds in real-world applications. In this paper, we consider various settings where the sampling mask is dependent on the underlying data values, motivated by applications in sensing, sequential decision-making, and recommender systems. Through a series of experiments, we study and compare the performance of various LRMC algorithms that were originally successful for data-independent sampling patterns.","authors":["Rishhabh Naik","Nisarg Trivedi","Davoud Ataee Tarzanagh","Laura Balzano"],"url":"https://arxiv.org/abs/2504.09873"}
{"created":"2025-04-15","title":"Maximum bound preservation of exponential integrators for Allen-Cahn equations","abstract":"We develop and analyze a class of arbitrarily high-order, maximum bound preserving time-stepping schemes for solving Allen-Cahn equations. These schemes are constructed within the iterative framework of exponential integrators, combined with carefully chosen numerical quadrature rules, including the Gauss-Legendre quadrature rule and the left Gauss-Radau quadrature rule. Notably, the proposed schemes are rigorously proven to unconditionally preserve the maximum bound without requiring any additional postprocessing techniques, while simultaneously achieving arbitrarily high-order temporal accuracy. A thorough error analysis in the $L^2$ norm is provided. Numerical experiments validate the theoretical results, demonstrate the effectiveness of the proposed methods, and highlight that an inappropriate choice of quadrature rules may violate the maximum bound principle, leading to incorrect dynamics.","authors":["Chaoyu Quan","Pingzhong Zheng","Zhi Zhou"],"url":"https://arxiv.org/abs/2504.09874"}
{"created":"2025-04-15","title":"HDC: Hierarchical Distillation for Multi-level Noisy Consistency in Semi-Supervised Fetal Ultrasound Segmentation","abstract":"Transvaginal ultrasound is a critical imaging modality for evaluating cervical anatomy and detecting physiological changes. However, accurate segmentation of cervical structures remains challenging due to low contrast, shadow artifacts, and fuzzy boundaries. While convolutional neural networks (CNNs) have shown promising results in medical image segmentation, their performance is often limited by the need for large-scale annotated datasets - an impractical requirement in clinical ultrasound imaging. Semi-supervised learning (SSL) offers a compelling solution by leveraging unlabeled data, but existing teacher-student frameworks often suffer from confirmation bias and high computational costs. We propose HDC, a novel semi-supervised segmentation framework that integrates Hierarchical Distillation and Consistency learning within a multi-level noise mean-teacher framework. Unlike conventional approaches that rely solely on pseudo-labeling, we introduce a hierarchical distillation mechanism that guides feature-level learning via two novel objectives: (1) Correlation Guidance Loss to align feature representations between the teacher and main student branch, and (2) Mutual Information Loss to stabilize representations between the main and noisy student branches. Our framework reduces model complexity while improving generalization. Extensive experiments on two fetal ultrasound datasets, FUGC and PSFH, demonstrate that our method achieves competitive performance with significantly lower computational overhead than existing multi-teacher models.","authors":["Tran Quoc Khanh Le","Nguyen Lan Vi Vu","Ha-Hieu Pham","Xuan-Loc Huynh","Tien-Huy Nguyen","Minh Huu Nhat Le","Quan Nguyen","Hien D. Nguyen"],"url":"https://arxiv.org/abs/2504.09876"}
{"created":"2025-04-15","title":"Constructing Micro Knowledge Graphs from Technical Support Documents","abstract":"Short technical support pages such as IBM Technotes are quite common in technical support domain. These pages can be very useful as the knowledge sources for technical support applications such as chatbots, search engines and question-answering (QA) systems. Information extracted from documents to drive technical support applications is often stored in the form of Knowledge Graph (KG). Building KGs from a large corpus of documents poses a challenge of granularity because a large number of entities and actions are present in each page. The KG becomes virtually unusable if all entities and actions from these pages are stored in the KG. Therefore, only key entities and actions from each page are extracted and stored in the KG. This approach however leads to loss of knowledge represented by entities and actions left out of the KG as they are no longer available to graph search and reasoning functions. We propose a set of techniques to create micro knowledge graph (micrograph) for each of such web pages. The micrograph stores all the entities and actions in a page and also takes advantage of the structure of the page to represent exactly in which part of that page these entities and actions appeared, and also how they relate to each other. These micrographs can be used as additional knowledge sources by technical support applications. We define schemas for representing semi-structured and plain text knowledge present in the technical support web pages. Solutions in technical support domain include procedures made of steps. We also propose a technique to extract procedures from these webpages and the schemas to represent them in the micrographs. We also discuss how technical support applications can take advantage of the micrographs.","authors":["Atul Kumar","Nisha Gupta","Saswati Dana"],"url":"https://arxiv.org/abs/2504.09877"}
{"created":"2025-04-15","title":"MCBlock: Boosting Neural Radiance Field Training Speed by MCTS-based Dynamic-Resolution Ray Sampling","abstract":"Neural Radiance Field (NeRF) is widely known for high-fidelity novel view synthesis. However, even the state-of-the-art NeRF model, Gaussian Splatting, requires minutes for training, far from the real-time performance required by multimedia scenarios like telemedicine. One of the obstacles is its inefficient sampling, which is only partially addressed by existing works. Existing point-sampling algorithms uniformly sample simple-texture regions (easy to fit) and complex-texture regions (hard to fit), while existing ray-sampling algorithms sample these regions all in the finest granularity (i.e. the pixel level), both wasting GPU training resources. Actually, regions with different texture intensities require different sampling granularities. To this end, we propose a novel dynamic-resolution ray-sampling algorithm, MCBlock, which employs Monte Carlo Tree Search (MCTS) to partition each training image into pixel blocks with different sizes for active block-wise training. Specifically, the trees are initialized according to the texture of training images to boost the initialization speed, and an expansion/pruning module dynamically optimizes the block partition. MCBlock is implemented in Nerfstudio, an open-source toolset, and achieves a training acceleration of up to 2.33x, surpassing other ray-sampling algorithms. We believe MCBlock can apply to any cone-tracing NeRF model and contribute to the multimedia community.","authors":["Yunpeng Tan","Junlin Hao","Jiangkai Wu","Liming Liu","Qingyang Li","Xinggong Zhang"],"url":"https://arxiv.org/abs/2504.09878"}
{"created":"2025-04-15","title":"Revisiting the attacker's knowledge in inference attacks against Searchable Symmetric Encryption","abstract":"Encrypted search schemes have been proposed to address growing privacy concerns. However, several leakage-abuse attacks have highlighted some security vulnerabilities. Recent attacks assumed an attacker's knowledge containing data ``similar'' to the indexed data. However, this vague assumption is barely discussed in literature: how likely is it for an attacker to obtain a \"similar enough\" data?","authors":["Marc Damie","Jean-Benoist Leger","Florian Hahn","Andreas Peter"],"url":"https://arxiv.org/abs/2504.09879"}
{"created":"2025-04-15","title":"Focus on Local: Finding Reliable Discriminative Regions for Visual Place Recognition","abstract":"Visual Place Recognition (VPR) is aimed at predicting the location of a query image by referencing a database of geotagged images. For VPR task, often fewer discriminative local regions in an image produce important effects while mundane background regions do not contribute or even cause perceptual aliasing because of easy overlap. However, existing methods lack precisely modeling and full exploitation of these discriminative regions. In this paper, we propose the Focus on Local (FoL) approach to stimulate the performance of image retrieval and re-ranking in VPR simultaneously by mining and exploiting reliable discriminative local regions in images and introducing pseudo-correlation supervision. First, we design two losses, Extraction-Aggregation Spatial Alignment Loss (SAL) and Foreground-Background Contrast Enhancement Loss (CEL), to explicitly model reliable discriminative local regions and use them to guide the generation of global representations and efficient re-ranking. Second, we introduce a weakly-supervised local feature training strategy based on pseudo-correspondences obtained from aggregating global features to alleviate the lack of local correspondences ground truth for the VPR task. Third, we suggest an efficient re-ranking pipeline that is efficiently and precisely based on discriminative region guidance. Finally, experimental results show that our FoL achieves the state-of-the-art on multiple VPR benchmarks in both image retrieval and re-ranking stages and also significantly outperforms existing two-stage VPR methods in terms of computational efficiency. Code and models are available at https://github.com/chenshunpeng/FoL","authors":["Changwei Wang","Shunpeng Chen","Yukun Song","Rongtao Xu","Zherui Zhang","Jiguang Zhang","Haoran Yang","Yu Zhang","Kexue Fu","Shide Du","Zhiwei Xu","Longxiang Gao","Li Guo","Shibiao Xu"],"url":"https://arxiv.org/abs/2504.09881"}
{"created":"2025-04-15","title":"SIO-Mapper: A Framework for Lane-Level HD Map Construction Using Satellite Images and OpenStreetMap with No On-Site Visits","abstract":"High-definition (HD) maps, particularly those containing lane-level information regarded as ground truth, are crucial for vehicle localization research. Traditionally, constructing HD maps requires highly accurate sensor measurements collection from the target area, followed by manual annotation to assign semantic information. Consequently, HD maps are limited in terms of geographic coverage. To tackle this problem, in this paper, we propose SIO-Mapper, a novel lane-level HD map construction framework that constructs city-scale maps without physical site visits by utilizing satellite images and OpenStreetmap data. One of the key contributions of SIO-Mapper is its ability to extract lane information more accurately by introducing SIO-Net, a novel deep learning network that integrates features from satellite image and OpenStreetmap using both Transformer-based and convolution-based encoders. Furthermore, to overcome challenges in merging lanes over large areas, we introduce a novel lane integration methodology that combines cluster-based and graph-based approaches. This algorithm ensures the seamless aggregation of lane segments with high accuracy and coverage, even in complex road environments. We validated SIO-Mapper on the Naver Labs Open Dataset and NuScenes dataset, demonstrating better performance in various environments including Korea, the United States, and Singapore compared to the state-of-the-art lane-level HD mapconstruction methods.","authors":["Younghun Cho","Jee-Hwan Ryu"],"url":"https://arxiv.org/abs/2504.09882"}
{"created":"2025-04-15","title":"Markov Clustering based Fully Automated Nonblocking Hierarchical Supervisory Control of Large-Scale Discrete-Event Systems","abstract":"In this paper we revisit the abstraction-based approach to synthesize a hierarchy of decentralized supervisors and coordinators for nonblocking control of large-scale discrete-event systems (DES), and augment it with a new clustering method for automatic and flexible grouping of relevant components during the hierarchical synthesis process. This method is known as Markov clustering, which not only automatically performs grouping but also allows flexible tuning the sizes of the resulting clusters using a single parameter. Compared to the existing abstraction-based approach that lacks effective grouping method for general cases, our proposed approach based on Markov clustering provides a fully automated and effective hierarchical synthesis procedure applicable to general large-scale DES. Moreover, it is proved that the resulting hierarchy of supervisors and coordinators collectively achieves global nonblocking (and maximally permissive) controlled behavior under the same conditions as those in the existing abstraction-based approach. Finally, a benchmark case study is conducted to empirically demonstrate the effectiveness of our approach.","authors":["Yingying Liu","Zhaojian Cai","Kai Cai"],"url":"https://arxiv.org/abs/2504.09884"}
{"created":"2025-04-15","title":"Separate to Collaborate: Dual-Stream Diffusion Model for Coordinated Piano Hand Motion Synthesis","abstract":"Automating the synthesis of coordinated bimanual piano performances poses significant challenges, particularly in capturing the intricate choreography between the hands while preserving their distinct kinematic signatures. In this paper, we propose a dual-stream neural framework designed to generate synchronized hand gestures for piano playing from audio input, addressing the critical challenge of modeling both hand independence and coordination. Our framework introduces two key innovations: (i) a decoupled diffusion-based generation framework that independently models each hand's motion via dual-noise initialization, sampling distinct latent noise for each while leveraging a shared positional condition, and (ii) a Hand-Coordinated Asymmetric Attention (HCAA) mechanism suppresses symmetric (common-mode) noise to highlight asymmetric hand-specific features, while adaptively enhancing inter-hand coordination during denoising. The system operates hierarchically: it first predicts 3D hand positions from audio features and then generates joint angles through position-aware diffusion models, where parallel denoising streams interact via HCAA. Comprehensive evaluations demonstrate that our framework outperforms existing state-of-the-art methods across multiple metrics.","authors":["Zihao Liu","Mingwen Ou","Zunnan Xu","Jiaqi Huang","Haonan Han","Ronghui Li","Xiu Li"],"url":"https://arxiv.org/abs/2504.09885"}
{"created":"2025-04-15","title":"Investigating Syntactic Biases in Multilingual Transformers with RC Attachment Ambiguities in Italian and English","abstract":"This paper leverages past sentence processing studies to investigate whether monolingual and multilingual LLMs show human-like preferences when presented with examples of relative clause attachment ambiguities in Italian and English. Furthermore, we test whether these preferences can be modulated by lexical factors (the type of verb/noun in the matrix clause) which have been shown to be tied to subtle constraints on syntactic and semantic relations. Our results overall showcase how LLM behavior varies interestingly across models, but also general failings of these models in correctly capturing human-like preferences. In light of these results, we argue that RC attachment is the ideal benchmark for cross-linguistic investigations of LLMs' linguistic knowledge and biases.","authors":["Michael Kamerath","Aniello De Santo"],"url":"https://arxiv.org/abs/2504.09886"}
{"created":"2025-04-15","title":"Enhanced Semantic Extraction and Guidance for UGC Image Super Resolution","abstract":"Due to the disparity between real-world degradations in user-generated content(UGC) images and synthetic degradations, traditional super-resolution methods struggle to generalize effectively, necessitating a more robust approach to model real-world distortions. In this paper, we propose a novel approach to UGC image super-resolution by integrating semantic guidance into a diffusion framework. Our method addresses the inconsistency between degradations in wild and synthetic datasets by separately simulating the degradation processes on the LSDIR dataset and combining them with the official paired training set. Furthermore, we enhance degradation removal and detail generation by incorporating a pretrained semantic extraction model (SAM2) and fine-tuning key hyperparameters for improved perceptual fidelity. Extensive experiments demonstrate the superiority of our approach against state-of-the-art methods. Additionally, the proposed model won second place in the CVPR NTIRE 2025 Short-form UGC Image Super-Resolution Challenge, further validating its effectiveness. The code is available at https://github.c10pom/Moonsofang/NTIRE-2025-SRlab.","authors":["Yiwen Wang","Ying Liang","Yuxuan Zhang","Xinning Chai","Zhengxue Cheng","Yingsheng Qin","Yucai Yang","Rong Xie","Li Song"],"url":"https://arxiv.org/abs/2504.09887"}
{"created":"2025-04-15","title":"NR-SSOR right preconditioned RRGMRES for arbitrary singular systems and least squares problems","abstract":"GMRES is known to determine a least squares solution of $ A x = b $ where $ A \\in R^{n \\times n} $ without breakdown for arbitrary $ b \\in R^n $, and initial iterate $ x_0 \\in R^n $ if and only if $ A $ is range-symmetric, i.e. $ R(A^T) = R(A) $, where $ A $ may be singular and $ b $ may not be in the range space $ R(A) $ of $ A $.","authors":["Kouta Sugihara","Ken Hayami"],"url":"https://arxiv.org/abs/2504.09891"}
{"created":"2025-04-15","title":"Vermilion: A Traffic-Aware Reconfigurable Optical Interconnect with Formal Throughput Guarantees","abstract":"The increasing gap between datacenter traffic volume and the capacity of electrical switches has driven the development of reconfigurable network designs utilizing optical circuit switching. Recent advancements, particularly those featuring periodic fixed-duration reconfigurations, have achieved practical end-to-end delays of just a few microseconds. However, current designs rely on multi-hop routing to enhance utilization, which can lead to a significant reduction in worst-case throughput and added overhead from congestion control and routing complexity. These factors pose significant operational challenges for the large-scale deployment of these technologies.","authors":["Vamsi Addanki","Chen Avin","Goran Dario Knabe","Giannis Patronas","Dimitris Syrivelis","Nikos Terzenidis","Paraskevas Bakopoulos","Ilias Marinos","Stefan Schmid"],"url":"https://arxiv.org/abs/2504.09892"}
{"created":"2025-04-15","title":"LangPert: Detecting and Handling Task-level Perturbations for Robust Object Rearrangement","abstract":"Task execution for object rearrangement could be challenged by Task-Level Perturbations (TLP), i.e., unexpected object additions, removals, and displacements that can disrupt underlying visual policies and fundamentally compromise task feasibility and progress. To address these challenges, we present LangPert, a language-based framework designed to detect and mitigate TLP situations in tabletop rearrangement tasks. LangPert integrates a Visual Language Model (VLM) to comprehensively monitor policy's skill execution and environmental TLP, while leveraging the Hierarchical Chain-of-Thought (HCoT) reasoning mechanism to enhance the Large Language Model (LLM)'s contextual understanding and generate adaptive, corrective skill-execution plans. Our experimental results demonstrate that LangPert handles diverse TLP situations more effectively than baseline methods, achieving higher task completion rates, improved execution efficiency, and potential generalization to unseen scenarios.","authors":["Xu Yin","Min-Sung Yoon","Yuchi Huo","Kang Zhang","Sung-Eui Yoon"],"url":"https://arxiv.org/abs/2504.09893"}
{"created":"2025-04-15","title":"Learning from Reference Answers: Versatile Language Model Alignment without Binary Human Preference Data","abstract":"Large language models~(LLMs) are expected to be helpful, harmless, and honest. In various alignment scenarios, such as general human preference, safety, and confidence alignment, binary preference data collection and reward modeling are resource-intensive but necessary for human preference transferring. In this work, we explore using the similarity between sampled generations and high-quality reference answers as an alternative reward function for LLM alignment. Using similarity as a reward circumvents training reward models, and collecting a single reference answer potentially costs less time than constructing binary preference pairs when multiple candidates are available. Specifically, we develop \\textit{RefAlign}, a versatile REINFORCE-style alignment algorithm, which is free of reference and reward models. Instead, RefAlign utilizes BERTScore between sampled generations and high-quality reference answers as the surrogate reward. Beyond general human preference optimization, RefAlign can be readily extended to diverse scenarios, such as safety and confidence alignment, by incorporating the similarity reward with task-related objectives. In various scenarios, {RefAlign} demonstrates comparable performance to previous alignment methods while offering high efficiency.","authors":["Shuai Zhao","Linchao Zhu","Yi Yang"],"url":"https://arxiv.org/abs/2504.09895"}
{"created":"2025-04-15","title":"TWSSenti: A Novel Hybrid Framework for Topic-Wise Sentiment Analysis on Social Media Using Transformer Models","abstract":"Sentiment analysis is a crucial task in natural language processing (NLP) that enables the extraction of meaningful insights from textual data, particularly from dynamic platforms like Twitter and IMDB. This study explores a hybrid framework combining transformer-based models, specifically BERT, GPT-2, RoBERTa, XLNet, and DistilBERT, to improve sentiment classification accuracy and robustness. The framework addresses challenges such as noisy data, contextual ambiguity, and generalization across diverse datasets by leveraging the unique strengths of these models. BERT captures bidirectional context, GPT-2 enhances generative capabilities, RoBERTa optimizes contextual understanding with larger corpora and dynamic masking, XLNet models dependency through permutation-based learning, and DistilBERT offers efficiency with reduced computational overhead while maintaining high accuracy. We demonstrate text cleaning, tokenization, and feature extraction using Term Frequency Inverse Document Frequency (TF-IDF) and Bag of Words (BoW), ensure high-quality input data for the models. The hybrid approach was evaluated on benchmark datasets Sentiment140 and IMDB, achieving superior accuracy rates of 94\\% and 95\\%, respectively, outperforming standalone models. The results validate the effectiveness of combining multiple transformer models in ensemble-like setups to address the limitations of individual architectures. This research highlights its applicability to real-world tasks such as social media monitoring, customer sentiment analysis, and public opinion tracking which offers a pathway for future advancements in hybrid NLP frameworks.","authors":["Aish Albladi","Md Kaosar Uddin","Minarul Islam","Cheryl Seals"],"url":"https://arxiv.org/abs/2504.09896"}
{"created":"2025-04-15","title":"TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models","abstract":"Multimodal Large Language Models (MLLMs) have shown remarkable versatility in understanding diverse multimodal data and tasks. However, these capabilities come with an increased model scale. While post-training pruning reduces model size in unimodal models, its application to MLLMs often yields limited success. Our analysis discovers that conventional methods fail to account for the unique token attributes across layers and modalities inherent to MLLMs. Inspired by this observation, we propose TAMP, a simple yet effective pruning framework tailored for MLLMs, featuring two key components: (1) Diversity-Aware Sparsity, which adjusts sparsity ratio per layer based on diversities among multimodal output tokens, preserving more parameters in high-diversity layers; and (2) Adaptive Multimodal Input Activation, which identifies representative multimodal input tokens using attention scores to guide unstructured weight pruning. We validate our method on two state-of-the-art MLLMs: LLaVA-NeXT, designed for vision-language tasks, and VideoLLaMA2, capable of processing audio, visual, and language modalities. Empirical experiments across various multimodal evaluation benchmarks demonstrate that each component of our approach substantially outperforms existing pruning techniques.","authors":["Jaewoo Lee (May)","Keyang Xuan (May)","Chanakya Ekbote (May)","Sandeep Polisetty (May)","Yi R. (May)","Fung","Paul Pu Liang"],"url":"https://arxiv.org/abs/2504.09897"}
{"created":"2025-04-15","title":"Digital Staining with Knowledge Distillation: A Unified Framework for Unpaired and Paired-But-Misaligned Data","abstract":"Staining is essential in cell imaging and medical diagnostics but poses significant challenges, including high cost, time consumption, labor intensity, and irreversible tissue alterations. Recent advances in deep learning have enabled digital staining through supervised model training. However, collecting large-scale, perfectly aligned pairs of stained and unstained images remains difficult. In this work, we propose a novel unsupervised deep learning framework for digital cell staining that reduces the need for extensive paired data using knowledge distillation. We explore two training schemes: (1) unpaired and (2) paired-but-misaligned settings. For the unpaired case, we introduce a two-stage pipeline, comprising light enhancement followed by colorization, as a teacher model. Subsequently, we obtain a student staining generator through knowledge distillation with hybrid non-reference losses. To leverage the pixel-wise information between adjacent sections, we further extend to the paired-but-misaligned setting, adding the Learning to Align module to utilize pixel-level information. Experiment results on our dataset demonstrate that our proposed unsupervised deep staining method can generate stained images with more accurate positions and shapes of the cell targets in both settings. Compared with competing methods, our method achieves improved results both qualitatively and quantitatively (e.g., NIQE and PSNR).We applied our digital staining method to the White Blood Cell (WBC) dataset, investigating its potential for medical applications.","authors":["Ziwang Xu","Lanqing Guo","Satoshi Tsutsui","Shuyan Zhang","Alex C. Kot","Bihan Wen"],"url":"https://arxiv.org/abs/2504.09899"}
{"created":"2025-04-15","title":"Small Object Detection with YOLO: A Performance Analysis Across Model Versions and Hardware","abstract":"This paper provides an extensive evaluation of YOLO object detection models (v5, v8, v9, v10, v11) by com- paring their performance across various hardware platforms and optimization libraries. Our study investigates inference speed and detection accuracy on Intel and AMD CPUs using popular libraries such as ONNX and OpenVINO, as well as on GPUs through TensorRT and other GPU-optimized frameworks. Furthermore, we analyze the sensitivity of these YOLO models to object size within the image, examining performance when detecting objects that occupy 1%, 2.5%, and 5% of the total area of the image. By identifying the trade-offs in efficiency, accuracy, and object size adaptability, this paper offers insights for optimal model selection based on specific hardware constraints and detection requirements, aiding practitioners in deploying YOLO models effectively for real-world applications.","authors":["Muhammad Fasih Tariq","Muhammad Azeem Javed"],"url":"https://arxiv.org/abs/2504.09900"}
{"created":"2025-04-15","title":"Quantum Image Visualizer: Visual Debugging of Quantum Image Processing Circuits","abstract":"Quantum computing is an emerging field that utilizes the unique principles of quantum mechanics to offer significant advantages in algorithm execution over classical approaches. This potential is particularly promising in the domain of quantum image processing, which aims to manipulate all pixels simultaneously. However, the process of designing and verifying these algorithms remains a complex and error-prone task. To address this challenge, new methods are needed to support effective debugging of quantum circuits. The Quantum Image Visualizer is an interactive visual analysis tool that allows for the examination of quantum images and their transformation throughout quantum circuits. The framework incorporates two overview visualizations that trace image evolution across a sequence of gates based on the most probable outcomes. Interactive exploration allows users to focus on relevant gates, and select pixels of interest. Upon selection, detailed visualizations enable in-depth inspection of individual pixels and their probability distributions, revealing how specific gates influence the likelihood of pixel color values and the magnitude of these changes. An evaluation of the Quantum Image Visualizer was conducted through in-depth interviews with eight domain experts. The findings demonstrate the effectiveness and practical value of our approach in supporting visual debugging of quantum image processing circuits.","authors":["Anja Heim","Thomas Lang","Alexander Gall","Eduard Gr\\\"oller","Christoph Heinzl"],"url":"https://arxiv.org/abs/2504.09902"}
{"created":"2025-04-15","title":"Refining Financial Consumer Complaints through Multi-Scale Model Interaction","abstract":"Legal writing demands clarity, formality, and domain-specific precision-qualities often lacking in documents authored by individuals without legal training. To bridge this gap, this paper explores the task of legal text refinement that transforms informal, conversational inputs into persuasive legal arguments. We introduce FinDR, a Chinese dataset of financial dispute records, annotated with official judgments on claim reasonableness. Our proposed method, Multi-Scale Model Interaction (MSMI), leverages a lightweight classifier to evaluate outputs and guide iterative refinement by Large Language Models (LLMs). Experimental results demonstrate that MSMI significantly outperforms single-pass prompting strategies. Additionally, we validate the generalizability of MSMI on several short-text benchmarks, showing improved adversarial robustness. Our findings reveal the potential of multi-model collaboration for enhancing legal document generation and broader text refinement tasks.","authors":["Bo-Wei Chen","An-Zi Yen","Chung-Chi Chen"],"url":"https://arxiv.org/abs/2504.09903"}
{"created":"2025-04-15","title":"LiteTracker: Leveraging Temporal Causality for Accurate Low-latency Tissue Tracking","abstract":"Tissue tracking plays a critical role in various surgical navigation and extended reality (XR) applications. While current methods trained on large synthetic datasets achieve high tracking accuracy and generalize well to endoscopic scenes, their runtime performances fail to meet the low-latency requirements necessary for real-time surgical applications. To address this limitation, we propose LiteTracker, a low-latency method for tissue tracking in endoscopic video streams. LiteTracker builds on a state-of-the-art long-term point tracking method, and introduces a set of training-free runtime optimizations. These optimizations enable online, frame-by-frame tracking by leveraging a temporal memory buffer for efficient feature reuse and utilizing prior motion for accurate track initialization. LiteTracker demonstrates significant runtime improvements being around 7x faster than its predecessor and 2x than the state-of-the-art. Beyond its primary focus on efficiency, LiteTracker delivers high-accuracy tracking and occlusion prediction, performing competitively on both the STIR and SuPer datasets. We believe LiteTracker is an important step toward low-latency tissue tracking for real-time surgical applications in the operating room.","authors":["Mert Asim Karaoglu","Wenbo Ji","Ahmed Abbas","Nassir Navab","Benjamin Busam","Alexander Ladikos"],"url":"https://arxiv.org/abs/2504.09904"}
{"created":"2025-04-15","title":"Plasticity-Aware Mixture of Experts for Learning Under QoE Shifts in Adaptive Video Streaming","abstract":"Adaptive video streaming systems are designed to optimize Quality of Experience (QoE) and, in turn, enhance user satisfaction. However, differences in user profiles and video content lead to different weights for QoE factors, resulting in user-specific QoE functions and, thus, varying optimization objectives. This variability poses significant challenges for neural networks, as they often struggle to generalize under evolving targets - a phenomenon known as plasticity loss that prevents conventional models from adapting effectively to changing optimization objectives. To address this limitation, we propose the Plasticity-Aware Mixture of Experts (PA-MoE), a novel learning framework that dynamically modulates network plasticity by balancing memory retention with selective forgetting. In particular, PA-MoE leverages noise injection to promote the selective forgetting of outdated knowledge, thereby endowing neural networks with enhanced adaptive capabilities. In addition, we present a rigorous theoretical analysis of PA-MoE by deriving a regret bound that quantifies its learning performance. Experimental evaluations demonstrate that PA-MoE achieves a 45.5% improvement in QoE over competitive baselines in dynamic streaming environments. Further analysis reveals that the model effectively mitigates plasticity loss by optimizing neuron utilization. Finally, a parameter sensitivity study is performed by injecting varying levels of noise, and the results align closely with our theoretical predictions.","authors":["Zhiqiang He","Zhi Liu"],"url":"https://arxiv.org/abs/2504.09906"}
{"created":"2025-04-15","title":"Quantum Natural Language Processing: A Comprehensive Review of Models, Methods, and Applications","abstract":"In recent developments, deep learning methodologies applied to Natural Language Processing (NLP) have revealed a paradox: They improve performance but demand considerable data and resources for their training. Alternatively, quantum computing exploits the principles of quantum mechanics to overcome the computational limitations of current methodologies, thereby establishing an emerging field known as quantum natural language processing (QNLP). This domain holds the potential to attain a quantum advantage in the processing of linguistic structures, surpassing classical models in both efficiency and accuracy. In this paper, it is proposed to categorise QNLP models based on quantum computing principles, architecture, and computational approaches. This paper attempts to provide a survey on how quantum meets language by mapping state-of-the-art in this area, embracing quantum encoding techniques for classical data, QNLP models for prevalent NLP tasks, and quantum optimisation techniques for hyper parameter tuning. The landscape of quantum computing approaches applied to various NLP tasks is summarised by showcasing the specific QNLP methods used, and the popularity of these methods is indicated by their count. From the findings, it is observed that QNLP approaches are still limited to small data sets, with only a few models explored extensively, and there is increasing interest in the application of quantum computing to natural language processing tasks.","authors":["Farha Nausheen","Khandakar Ahmed","M Imad Khan"],"url":"https://arxiv.org/abs/2504.09909"}
{"created":"2025-04-15","title":"Learning to Erase Private Knowledge from Multi-Documents for Retrieval-Augmented Large Language Models","abstract":"Retrieval-Augmented Generation (RAG) is a promising technique for applying LLMs to proprietary domains. However, retrieved documents may contain sensitive knowledge, posing risks of privacy leakage in generative results. Thus, effectively erasing private information from retrieved documents is a key challenge for RAG. Unlike traditional text anonymization, RAG should consider: (1) the inherent multi-document reasoning may face de-anonymization attacks; (2) private knowledge varies by scenarios, so users should be allowed to customize which information to erase; (3) preserving sufficient publicly available knowledge for generation tasks. This paper introduces the privacy erasure task for RAG and proposes Eraser4RAG, a private knowledge eraser which effectively removes user-defined private knowledge from documents while preserving sufficient public knowledge for generation. Specifically, we first construct a global knowledge graph to identify potential knowledge across documents, aiming to defend against de-anonymization attacks. Then we randomly split it into private and public sub-graphs, and fine-tune Flan-T5 to rewrite the retrieved documents excluding private triples. Finally, PPO algorithm optimizes the rewriting model to minimize private triples and maximize public triples retention. Experiments on four QA datasets demonstrate that Eraser4RAG achieves superior erase performance than GPT-4o.","authors":["Yujing Wang","Hainan Zhang","Liang Pang","Yongxin Tong","Binghui Guo","Hongwei Zheng","Zhiming Zheng"],"url":"https://arxiv.org/abs/2504.09910"}
{"created":"2025-04-15","title":"Improving Multimodal Hateful Meme Detection Exploiting LMM-Generated Knowledge","abstract":"Memes have become a dominant form of communication in social media in recent years. Memes are typically humorous and harmless, however there are also memes that promote hate speech, being in this way harmful to individuals and groups based on their identity. Therefore, detecting hateful content in memes has emerged as a task of critical importance. The need for understanding the complex interactions of images and their embedded text renders the hateful meme detection a challenging multimodal task. In this paper we propose to address the aforementioned task leveraging knowledge encoded in powerful Large Multimodal Models (LMM). Specifically, we propose to exploit LMMs in a two-fold manner. First, by extracting knowledge oriented to the hateful meme detection task in order to build strong meme representations. Specifically, generic semantic descriptions and emotions that the images along with their embedded texts elicit are extracted, which are then used to train a simple classification head for hateful meme detection. Second, by developing a novel hard mining approach introducing directly LMM-encoded knowledge to the training process, providing further improvements. We perform extensive experiments on two datasets that validate the effectiveness of the proposed method, achieving state-of-the-art performance. Our code and trained models are publicly available at: https://github.com/IDT-ITI/LMM-CLIP-meme.","authors":["Maria Tzelepi","Vasileios Mezaris"],"url":"https://arxiv.org/abs/2504.09914"}
{"created":"2025-04-15","title":"StePO-Rec: Towards Personalized Outfit Styling Assistant via Knowledge-Guided Multi-Step Reasoning","abstract":"Advancements in Generative AI offers new opportunities for FashionAI, surpassing traditional recommendation systems that often lack transparency and struggle to integrate expert knowledge, leaving the potential for personalized fashion styling remain untapped. To address these challenges, we present PAFA (Principle-Aware Fashion), a multi-granular knowledge base that organizes professional styling expertise into three levels of metadata, domain principles, and semantic relationships. Using PAFA, we develop StePO-Rec, a knowledge-guided method for multi-step outfit recommendation. StePO-Rec provides structured suggestions using a scenario-dimension-attribute framework, employing recursive tree construction to align recommendations with both professional principles and individual preferences. A preference-trend re-ranking system further adapts to fashion trends while maintaining the consistency of the user's original style. Experiments on the widely used personalized outfit dataset IQON show a 28% increase in Recall@1 and 32.8% in MAP. Furthermore, case studies highlight improved explainability, traceability, result reliability, and the seamless integration of expertise and personalization.","authors":["Yuxi Bi","Yunfan Gao","Haofen Wang"],"url":"https://arxiv.org/abs/2504.09915"}
{"created":"2025-04-15","title":"Guiding Reasoning in Small Language Models with LLM Assistance","abstract":"The limited reasoning capabilities of small language models (SLMs) cast doubt on their suitability for tasks demanding deep, multi-step logical deduction. This paper introduces a framework called Small Reasons, Large Hints (SMART), which selectively augments SLM reasoning with targeted guidance from large language models (LLMs). Inspired by the concept of cognitive scaffolding, SMART employs a score-based evaluation to identify uncertain reasoning steps and injects corrective LLM-generated reasoning only when necessary. By framing structured reasoning as an optimal policy search, our approach steers the reasoning trajectory toward correct solutions without exhaustive sampling. Our experiments on mathematical reasoning datasets demonstrate that targeted external scaffolding significantly improves performance, paving the way for collaborative use of both SLM and LLM to tackle complex reasoning tasks that are currently unsolvable by SLMs alone.","authors":["Yujin Kim","Euiin Yi","Minu Kim","Se-Young Yun","Taehyeon Kim"],"url":"https://arxiv.org/abs/2504.09923"}
{"created":"2025-04-15","title":"Passive Channel Charting: Locating Passive Targets using Wi-Fi Channel State Information","abstract":"We propose passive channel charting, an extension of channel charting to passive target localization. As in conventional channel charting, we follow a dimensionality reduction approach to reconstruct a physically interpretable map of target positions from similarities in high-dimensional channel state information. We show that algorithms and neural network architectures developed in the context of channel charting with active mobile transmitters can be straightforwardly applied to the passive case, where we assume a scenario with static transmitters and receivers and a mobile target. We evaluate our method on a channel state information dataset collected indoors with a distributed setup of ESPARGOS Wi-Fi sensing antenna arrays. This scenario can be interpreted as either a multi-static or passive radar system. We demonstrate that passive channel charting outperforms a baseline based on classical triangulation in terms of localization accuracy. We discuss our results and highlight some unsolved issues related to the proposed concept.","authors":["Florian Euchner","David Kellner","Phillip Stephan","Stephan ten Brink"],"url":"https://arxiv.org/abs/2504.09924"}
{"created":"2025-04-15","title":"FUSION: Fully Integration of Vision-Language Representations for Deep Cross-Modal Understanding","abstract":"We introduce FUSION, a family of multimodal large language models (MLLMs) with a fully vision-language alignment and integration paradigm. Unlike existing methods that primarily rely on late-stage modality interaction during LLM decoding, our approach achieves deep, dynamic integration throughout the entire processing pipeline. To this end, we propose Text-Guided Unified Vision Encoding, incorporating textual information in vision encoding to achieve pixel-level integration. We further design Context-Aware Recursive Alignment Decoding that recursively aggregates visual features conditioned on textual context during decoding, enabling fine-grained, question-level semantic integration. To guide feature mapping and mitigate modality discrepancies, we develop Dual-Supervised Semantic Mapping Loss. Additionally, we construct a Synthesized Language-Driven Question-Answer (QA) dataset through a new data synthesis method, prioritizing high-quality QA pairs to optimize text-guided feature integration. Building on these foundations, we train FUSION at two scales-3B, 8B-and demonstrate that our full-modality integration approach significantly outperforms existing methods with only 630 vision tokens. Notably, FUSION 3B surpasses Cambrian-1 8B and Florence-VL 8B on most benchmarks. FUSION 3B continues to outperform Cambrian-1 8B even when limited to 300 vision tokens. Our ablation studies show that FUSION outperforms LLaVA-NeXT on over half of the benchmarks under same configuration without dynamic resolution, highlighting the effectiveness of our approach. We release our code, model weights, and dataset. https://github.com/starriver030515/FUSION","authors":["Zheng Liu","Mengjie Liu","Jingzhou Chen","Jingwei Xu","Bin Cui","Conghui He","Wentao Zhang"],"url":"https://arxiv.org/abs/2504.09925"}
{"created":"2025-04-15","title":"Efficient Task-specific Conditional Diffusion Policies: Shortcut Model Acceleration and SO(3) Optimization","abstract":"Imitation learning, particularly Diffusion Policies based methods, has recently gained significant traction in embodied AI as a powerful approach to action policy generation. These models efficiently generate action policies by learning to predict noise. However, conventional Diffusion Policy methods rely on iterative denoising, leading to inefficient inference and slow response times, which hinder real-time robot control. To address these limitations, we propose a Classifier-Free Shortcut Diffusion Policy (CF-SDP) that integrates classifier-free guidance with shortcut-based acceleration, enabling efficient task-specific action generation while significantly improving inference speed. Furthermore, we extend diffusion modeling to the SO(3) manifold in shortcut model, defining the forward and reverse processes in its tangent space with an isotropic Gaussian distribution. This ensures stable and accurate rotational estimation, enhancing the effectiveness of diffusion-based control. Our approach achieves nearly 5x acceleration in diffusion inference compared to DDIM-based Diffusion Policy while maintaining task performance. Evaluations both on the RoboTwin simulation platform and real-world scenarios across various tasks demonstrate the superiority of our method.","authors":["Haiyong Yu","Yanqiong Jin","Yonghao He","Wei Sui"],"url":"https://arxiv.org/abs/2504.09927"}
{"created":"2025-04-15","title":"Moderate Actor-Critic Methods: Controlling Overestimation Bias via Expectile Loss","abstract":"Overestimation is a fundamental characteristic of model-free reinforcement learning (MF-RL), arising from the principles of temporal difference learning and the approximation of the Q-function. To address this challenge, we propose a novel moderate target in the Q-function update, formulated as a convex optimization of an overestimated Q-function and its lower bound. Our primary contribution lies in the efficient estimation of this lower bound through the lower expectile of the Q-value distribution conditioned on a state. Notably, our moderate target integrates seamlessly into state-of-the-art (SOTA) MF-RL algorithms, including Deep Deterministic Policy Gradient (DDPG) and Soft Actor Critic (SAC). Experimental results validate the effectiveness of our moderate target in mitigating overestimation bias in DDPG, SAC, and distributional RL algorithms.","authors":["Ukjo Hwang","Songnam Hong"],"url":"https://arxiv.org/abs/2504.09929"}
{"created":"2025-04-15","title":"Multi-objective Bayesian Optimization With Mixed-categorical Design Variables for Expensive-to-evaluate Aeronautical Applications","abstract":"This work aims at developing new methodologies to optimize computational costly complex systems (e.g., aeronautical engineering systems). The proposed surrogate-based method (often called Bayesian optimization) uses adaptive sampling to promote a trade-off between exploration and exploitation. Our in-house implementation, called SEGOMOE, handles a high number of design variables (continuous, discrete or categorical) and nonlinearities by combining mixtures of experts for the objective and/or the constraints. Additionally, the method handles multi-objective optimization settings, as it allows the construction of accurate Pareto fronts with a minimal number of function evaluations. Different infill criteria have been implemented to handle multiple objectives with or without constraints. The effectiveness of the proposed method was tested on practical aeronautical applications within the context of the European Project AGILE 4.0 and demonstrated favorable results. A first example concerns a retrofitting problem where a comparison between two optimizers have been made. A second example introduces hierarchical variables to deal with architecture system in order to design an aircraft family. The third example increases drastically the number of categorical variables as it combines aircraft design, supply chain and manufacturing process. In this article, we show, on three different realistic problems, various aspects of our optimization codes thanks to the diversity of the treated aircraft problems.","authors":["Nathalie Bartoli","Thierry Lefebvre","R\\'emi Lafage","Paul Saves","Youssef Diouane","Joseph Morlier","Jasper Bussemaker","Giuseppa Donelli","Joao Marcos Gomes de Mello","Massimo Mandorino","Pierluigi Della Vecchia"],"url":"https://arxiv.org/abs/2504.09930"}
{"created":"2025-04-15","title":"A Theory of Universal Rate-Distortion-Classification Representations for Lossy Compression","abstract":"In lossy compression, Blau and Michaeli [5] introduced the information rate-distortion-perception (RDP) function, extending traditional rate-distortion theory by incorporating perceptual quality. More recently, this framework was expanded by defining the rate-distortion-perception-classification (RDPC) function, integrating multi-task learning that jointly optimizes generative tasks such as perceptual quality and classification accuracy alongside reconstruction tasks [28]. To that end, motivated by the concept of a universal RDP encoder introduced in [34], we investigate universal representations that enable diverse distortion-classification tradeoffs through a single fixed encoder combined with multiple decoders. Specifically, theoretical analysis and numerical experiment demonstrate that for the Gaussian source under mean squared error (MSE) distortion, the entire distortion-classification tradeoff region can be achieved using one universal encoder. In addition, this paper characterizes achievable distortion-classification regions for fixed universal representations in general source distributions, identifying conditions that ensure minimal distortion penalty when reusing encoders across varying tradeoff points. Experimental results using MNIST and SVHN datasets validate our theoretical insights, showing that universal encoders can obtain distortion performance comparable to task-specific encoders, thus supporting the practicality and effectiveness of our proposed universal representations.","authors":["Nam Nguyen","Thinh Nguyen","Bella Bose"],"url":"https://arxiv.org/abs/2504.09932"}
{"created":"2025-04-15","title":"Constrained Auto-Regressive Decoding Constrains Generative Retrieval","abstract":"Generative retrieval seeks to replace traditional search index data structures with a single large-scale neural network, offering the potential for improved efficiency and seamless integration with generative large language models. As an end-to-end paradigm, generative retrieval adopts a learned differentiable search index to conduct retrieval by directly generating document identifiers through corpus-specific constrained decoding. The generalization capabilities of generative retrieval on out-of-distribution corpora have gathered significant attention.","authors":["Shiguang Wu","Zhaochun Ren","Xin Xin","Jiyuan Yang","Mengqi Zhang","Zhumin Chen","Maarten de Rijke","Pengjie Ren"],"url":"https://arxiv.org/abs/2504.09935"}
{"created":"2025-04-15","title":"KeepKV: Eliminating Output Perturbation in KV Cache Compression for Efficient LLMs Inference","abstract":"Efficient inference of large language models (LLMs) is hindered by an ever-growing key-value (KV) cache, making KV cache compression a critical research direction. Traditional methods selectively evict less important KV cache entries based on attention scores or position heuristics, which leads to information loss and hallucinations. Recently, merging-based strategies have been explored to retain more information by merging KV pairs that would be discarded; however, these existing approaches inevitably introduce inconsistencies in attention distributions before and after merging, causing output perturbation and degraded generation quality. To overcome this challenge, we propose KeepKV, a novel adaptive KV cache merging method designed to eliminate output perturbation while preserving performance under strict memory constraints. KeepKV introduces the Electoral Votes mechanism that records merging history and adaptively adjusts attention scores. Moreover, it further leverages a novel Zero Inference-Perturbation Merging methods, keeping attention consistency and compensating for attention loss resulting from cache merging. KeepKV successfully retains essential context information within a significantly compressed cache. Extensive experiments on various benchmarks and LLM architectures demonstrate that KeepKV substantially reduces memory usage, enhances inference throughput by more than 2x and keeps superior generation quality even with 10% KV cache budgets.","authors":["Yuxuan Tian","Zihan Wang","Yebo Peng","Aomufei Yuan","Zhiming Wang","Bairen Yi","Xin Liu","Yong Cui","Tong Yang"],"url":"https://arxiv.org/abs/2504.09936"}
{"created":"2025-04-15","title":"TianQuan-Climate: A Subseasonal-to-Seasonal Global Weather Model via Incorporate Climatology State","abstract":"Subseasonal forecasting serves as an important support for Sustainable Development Goals (SDGs), such as climate challenges, agricultural yield and sustainable energy production. However, subseasonal forecasting is a complex task in meteorology due to dissipating initial conditions and delayed external forces. Although AI models are increasingly pushing the boundaries of this forecasting limit, they face two major challenges: error accumulation and Smoothness. To address these two challenges, we propose Climate Furnace Subseasonal-to-Seasonal (TianQuan-Climate), a novel machine learning model designed to provide global daily mean forecasts up to 45 days, covering five upper-air atmospheric variables at 13 pressure levels and two surface variables. Our proposed TianQuan-Climate has two advantages: 1) it utilizes a multi-model prediction strategy to reduce system error impacts in long-term subseasonal forecasts; 2) it incorporates a Content Fusion Module for climatological integration and extends ViT with uncertainty blocks (UD-ViT) to improve generalization by learning from uncertainty. We demonstrate the effectiveness of TianQuan-Climate on benchmarks for weather forecasting and climate projections within the 15 to 45-day range, where TianQuan-Climate outperforms existing numerical and AI methods.","authors":["Guowen Li","Xintong Liu","Shilei Cao","Haoyuan Liang","Mengxuan Chen","Lixian Zhang","Jinxiao Zhang","Jiuke Wang","Meng Jin","Juepeng Zheng"],"url":"https://arxiv.org/abs/2504.09940"}
{"created":"2025-04-15","title":"FedRecon: Missing Modality Reconstruction in Distributed Heterogeneous Environments","abstract":"Multimodal data are often incomplete and exhibit Non-Independent and Identically Distributed (Non-IID) characteristics in real-world scenarios. These inherent limitations lead to both modality heterogeneity through partial modality absence and data heterogeneity from distribution divergence, creating fundamental challenges for effective federated learning (FL). To address these coupled challenges, we propose FedRecon, the first method targeting simultaneous missing modality reconstruction and Non-IID adaptation in multimodal FL. Our approach first employs a lightweight Multimodal Variational Autoencoder (MVAE) to reconstruct missing modalities while preserving cross-modal consistency. Distinct from conventional imputation methods, we achieve sample-level alignment through a novel distribution mapping mechanism that guarantees both data consistency and completeness. Additionally, we introduce a strategy employing global generator freezing to prevent catastrophic forgetting, which in turn mitigates Non-IID fluctuations. Extensive evaluations on multimodal datasets demonstrate FedRecon's superior performance in modality reconstruction under Non-IID conditions, surpassing state-of-the-art methods.","authors":["Junming Liu","Guosun Zeng","Ding Wang","Yanting Gao","Yufei Jin"],"url":"https://arxiv.org/abs/2504.09941"}
{"created":"2025-04-15","title":"Assessing Judging Bias in Large Reasoning Models: An Empirical Study","abstract":"Large Reasoning Models (LRMs) like DeepSeek-R1 and OpenAI-o1 have demonstrated remarkable reasoning capabilities, raising important questions about their biases in LLM-as-a-judge settings. We present a comprehensive benchmark comparing judging biases between LLMs and LRMs across both subjective preference-alignment datasets and objective fact-based datasets. Through investigation of bandwagon, authority, position, and distraction biases, we uncover four key findings: (1) despite their advanced reasoning capabilities, LRMs remain susceptible to the above biases; (2) LRMs demonstrate better robustness than LLMs specifically on fact-related datasets; (3) LRMs exhibit notable position bias, preferring options in later positions; and (4) we identify a novel \"superficial reflection bias\" where phrases mimicking reasoning (e.g., \"wait, let me think...\") significantly influence model judgments. To address these biases, we design and evaluate three mitigation strategies: specialized system prompts that reduce judging biases by up to 19\\% in preference alignment datasets and 14\\% in fact-related datasets, in-context learning that provides up to 27\\% improvement on preference tasks but shows inconsistent results on factual tasks, and a self-reflection mechanism that reduces biases by up to 10\\% in preference datasets and 16\\% in fact-related datasets, with self-reflection proving particularly effective for LRMs. Our work provides crucial insights for developing more reliable LLM-as-a-Judge frameworks, especially as LRMs become increasingly deployed as automated judges.","authors":["Qian Wang","Zhanzhi Lou","Zhenheng Tang","Nuo Chen","Xuandong Zhao","Wenxuan Zhang","Dawn Song","Bingsheng He"],"url":"https://arxiv.org/abs/2504.09946"}
{"created":"2025-04-15","title":"Omni-Dish: Photorealistic and Faithful Image Generation and Editing for Arbitrary Chinese Dishes","abstract":"Dish images play a crucial role in the digital era, with the demand for culturally distinctive dish images continuously increasing due to the digitization of the food industry and e-commerce. In general cases, existing text-to-image generation models excel in producing high-quality images; however, they struggle to capture diverse characteristics and faithful details of specific domains, particularly Chinese dishes. To address this limitation, we propose Omni-Dish, the first text-to-image generation model specifically tailored for Chinese dishes. We develop a comprehensive dish curation pipeline, building the largest dish dataset to date. Additionally, we introduce a recaption strategy and employ a coarse-to-fine training scheme to help the model better learn fine-grained culinary nuances. During inference, we enhance the user's textual input using a pre-constructed high-quality caption library and a large language model, enabling more photorealistic and faithful image generation. Furthermore, to extend our model's capability for dish editing tasks, we propose Concept-Enhanced P2P. Based on this approach, we build a dish editing dataset and train a specialized editing model. Extensive experiments demonstrate the superiority of our methods.","authors":["Huijie Liu","Bingcan Wang","Jie Hu","Xiaoming Wei","Guoliang Kang"],"url":"https://arxiv.org/abs/2504.09948"}
{"created":"2025-04-15","title":"Pseudo-Label Guided Real-World Image De-weathering: A Learning Framework with Imperfect Supervision","abstract":"Real-world image de-weathering aims at removingvarious undesirable weather-related artifacts, e.g., rain, snow,and fog. To this end, acquiring ideal training pairs is crucial.Existing real-world datasets are typically constructed paired databy extracting clean and degraded images from live streamsof landscape scene on the Internet. Despite the use of strictfiltering mechanisms during collection, training pairs inevitablyencounter inconsistency in terms of lighting, object position, scenedetails, etc, making de-weathering models possibly suffer fromdeformation artifacts under non-ideal supervision. In this work,we propose a unified solution for real-world image de-weatheringwith non-ideal supervision, i.e., a pseudo-label guided learningframework, to address various inconsistencies within the realworld paired dataset. Generally, it consists of a de-weatheringmodel (De-W) and a Consistent Label Constructor (CLC), bywhich restoration result can be adaptively supervised by originalground-truth image to recover sharp textures while maintainingconsistency with the degraded inputs in non-weather contentthrough the supervision of pseudo-labels. Particularly, a Crossframe Similarity Aggregation (CSA) module is deployed withinCLC to enhance the quality of pseudo-labels by exploring thepotential complementary information of multi-frames throughgraph model. Moreover, we introduce an Information AllocationStrategy (IAS) to integrate the original ground-truth imagesand pseudo-labels, thereby facilitating the joint supervision forthe training of de-weathering model. Extensive experimentsdemonstrate that our method exhibits significant advantageswhen trained on imperfectly aligned de-weathering datasets incomparison with other approaches.","authors":["Heming Xu","Xiaohui Liu","Zhilu Zhang","Hongzhi Zhang","Xiaohe Wu","Wangmeng Zuo"],"url":"https://arxiv.org/abs/2504.09949"}
{"created":"2025-04-15","title":"Constrained Error-Correcting Codes for Efficient DNA Synthesis","abstract":"DNA synthesis is considered as one of the most expensive components in current DNA storage systems. In this paper, focusing on a common synthesis machine, which generates multiple DNA strands in parallel following a fixed supersequence,we propose constrained codes with polynomial-time encoding and decoding algorithms. Compared to the existing works, our codes simultaneously satisfy both l-runlength limited and {\\epsilon}-balanced constraints. By enumerating all valid sequences, our codes achieve the maximum rate, matching the capacity. Additionally, we design constrained error-correcting codes capable of correcting one insertion or deletion in the obtained DNA sequence while still adhering to the constraints.","authors":["Yajuan Liu","Tolga M. Duman"],"url":"https://arxiv.org/abs/2504.09950"}
{"created":"2025-04-15","title":"Secrecy and Privacy in Multi-Access Combinatorial Topology","abstract":"In this work, we consider the multi-access combinatorial topology with $C$ caches where each user accesses a unique set of $r$ caches. For this setup, we consider secrecy, where each user should not know anything about the files it did not request, and demand privacy, where each user's demand must be kept private from other non-colluding users. We propose a scheme satisfying both conditions and derive a lower bound based on cut-set arguments. Also, we prove that our scheme is optimal when $r\\geq C-1$, and it is order-optimal when the cache memory size $M$ is greater than or equal to a certain threshold for $r<C-1$. When $r=1$, in most of the memory region, our scheme achieves the same rate as the one given by the secretive scheme for the dedicated cache setup by Ravindrakumar et al. ( 'Private Coded Caching,' in \\textit{IEEE Transactions on Information Forensics and Security}, 2018), while satisfying both secrecy and demand privacy conditions.","authors":["Mallikharjuna Chinnapadamala","B. Sundar Rajan"],"url":"https://arxiv.org/abs/2504.09952"}
{"created":"2025-04-15","title":"Efficient 2D to Full 3D Human Pose Uplifting including Joint Rotations","abstract":"In sports analytics, accurately capturing both the 3D locations and rotations of body joints is essential for understanding an athlete's biomechanics. While Human Mesh Recovery (HMR) models can estimate joint rotations, they often exhibit lower accuracy in joint localization compared to 3D Human Pose Estimation (HPE) models. Recent work addressed this limitation by combining a 3D HPE model with inverse kinematics (IK) to estimate both joint locations and rotations. However, IK is computationally expensive. To overcome this, we propose a novel 2D-to-3D uplifting model that directly estimates 3D human poses, including joint rotations, in a single forward pass. We investigate multiple rotation representations, loss functions, and training strategies - both with and without access to ground truth rotations. Our models achieve state-of-the-art accuracy in rotation estimation, are 150 times faster than the IK-based approach, and surpass HMR models in joint localization precision.","authors":["Katja Ludwig","Yuliia Oksymets","Robin Sch\\\"on","Daniel Kienzle","Rainer Lienhart"],"url":"https://arxiv.org/abs/2504.09953"}
{"created":"2025-04-15","title":"VR MRI Training for Adolescents: A Comparative Study of Gamified VR, Passive VR, 360 Video, and Traditional Educational Video","abstract":"Magnetic Resonance Imaging (MRI) can be a stressful experience for pediatric patients due to the loud acoustic environment, enclosed scanner bore, and a prolonged requirement to remain still. While sedation is commonly used to manage anxiety and motion, it carries clinical risks and logistical burdens. Traditional preparatory approaches, such as instructional videos and mock scans, often lack engagement for older children and adolescents. In this study, we present a comparative evaluation of four MRI preparation modalities: (1) a gamified virtual reality (VR) simulation that trains stillness through real-time feedback; (2) a passive VR experience replicating the MRI environment without interactivity; (3) a 360 degree first-person video of a real MRI procedure; and (4) a standard 2D educational video. Using a within-subjects design (N = 11, ages 10-16), we assess each method's impact on head motion data, anxiety reduction, procedural preparedness, usability, cognitive workload, and subjective preference. Results show that the gamified VR condition has significantly lower head motion (p < 0.001) and yielded the highest preparedness scores (p < 0.05). Head motion data were significantly correlated with learning outcomes (p < 0.01), suggesting that behavioral performance in VR strongly indicates procedural readiness. While all modalities reduced anxiety and were rated usable, interactive VR was preferred by most participants and demonstrated unique advantages in promoting engagement and behavioral rehearsal. We conclude with design recommendations for designing immersive simulations and integrating VR training into pediatric imaging workflows.","authors":["Yue Yang","Mengyao Guo","Emmanuel A Corona","Bruce Daniel","Christoph Leuze","Fred Baik"],"url":"https://arxiv.org/abs/2504.09955"}
{"created":"2025-04-15","title":"Semantic Depth Matters: Explaining Errors of Deep Vision Networks through Perceived Class Similarities","abstract":"Understanding deep neural network (DNN) behavior requires more than evaluating classification accuracy alone; analyzing errors and their predictability is equally crucial. Current evaluation methodologies lack transparency, particularly in explaining the underlying causes of network misclassifications. To address this, we introduce a novel framework that investigates the relationship between the semantic hierarchy depth perceived by a network and its real-data misclassification patterns. Central to our framework is the Similarity Depth (SD) metric, which quantifies the semantic hierarchy depth perceived by a network along with a method of evaluation of how closely the network's errors align with its internally perceived similarity structure. We also propose a graph-based visualization of model semantic relationships and misperceptions. A key advantage of our approach is that leveraging class templates -- representations derived from classifier layer weights -- is applicable to already trained networks without requiring additional data or experiments. Our approach reveals that deep vision networks encode specific semantic hierarchies and that high semantic depth improves the compliance between perceived class similarities and actual errors.","authors":["Katarzyna Filus","Micha{\\l} Romaszewski","Mateusz \\.Zarski"],"url":"https://arxiv.org/abs/2504.09956"}
{"created":"2025-04-15","title":"C-MTCSD: A Chinese Multi-Turn Conversational Stance Detection Dataset","abstract":"Stance detection has become an essential tool for analyzing public discussions on social media. Current methods face significant challenges, particularly in Chinese language processing and multi-turn conversational analysis. To address these limitations, we introduce C-MTCSD, the largest Chinese multi-turn conversational stance detection dataset, comprising 24,264 carefully annotated instances from Sina Weibo, which is 4.2 times larger than the only prior Chinese conversational stance detection dataset. Our comprehensive evaluation using both traditional approaches and large language models reveals the complexity of C-MTCSD: even state-of-the-art models achieve only 64.07% F1 score in the challenging zero-shot setting, while performance consistently degrades with increasing conversation depth. Traditional models particularly struggle with implicit stance detection, achieving below 50% F1 score. This work establishes a challenging new benchmark for Chinese stance detection research, highlighting significant opportunities for future improvements.","authors":["Fuqiang Niu","Yi Yang","Xianghua Fu","Genan Dai","Bowen Zhang"],"url":"https://arxiv.org/abs/2504.09958"}
{"created":"2025-04-15","title":"Dual-Path Enhancements in Event-Based Eye Tracking: Augmented Robustness and Adaptive Temporal Modeling","abstract":"Event-based eye tracking has become a pivotal technology for augmented reality and human-computer interaction. Yet, existing methods struggle with real-world challenges such as abrupt eye movements and environmental noise. Building on the efficiency of the Lightweight Spatiotemporal Network-a causal architecture optimized for edge devices-we introduce two key advancements. First, a robust data augmentation pipeline incorporating temporal shift, spatial flip, and event deletion improves model resilience, reducing Euclidean distance error by 12% (1.61 vs. 1.70 baseline) on challenging samples. Second, we propose KnightPupil, a hybrid architecture combining an EfficientNet-B3 backbone for spatial feature extraction, a bidirectional GRU for contextual temporal modeling, and a Linear Time-Varying State-Space Module to adapt to sparse inputs and noise dynamically. Evaluated on the 3ET+ benchmark, our framework achieved 1.61 Euclidean distance on the private test set of the Event-based Eye Tracking Challenge at CVPR 2025, demonstrating its effectiveness for practical deployment in AR/VR systems while providing a foundation for future innovations in neuromorphic vision.","authors":["Hoang M. Truong","Vinh-Thuan Ly","Huy G. Tran","Thuan-Phat Nguyen","Tram T. Doan"],"url":"https://arxiv.org/abs/2504.09960"}
{"created":"2025-04-15","title":"Privacy Meets Explainability: Managing Confidential Data and Transparency Policies in LLM-Empowered Science","abstract":"As Large Language Models (LLMs) become integral to scientific workflows, concerns over the confidentiality and ethical handling of confidential data have emerged. This paper explores data exposure risks through LLM-powered scientific tools, which can inadvertently leak confidential information, including intellectual property and proprietary data, from scientists' perspectives. We propose \"DataShield\", a framework designed to detect confidential data leaks, summarize privacy policies, and visualize data flow, ensuring alignment with organizational policies and procedures. Our approach aims to inform scientists about data handling practices, enabling them to make informed decisions and protect sensitive information. Ongoing user studies with scientists are underway to evaluate the framework's usability, trustworthiness, and effectiveness in tackling real-world privacy challenges.","authors":["Yashothara Shanmugarasa","Shidong Pan","Ming Ding","Dehai Zhao","Thierry Rakotoarivelo"],"url":"https://arxiv.org/abs/2504.09961"}
{"created":"2025-04-15","title":"Towards Unbiased Federated Graph Learning: Label and Topology Perspectives","abstract":"Federated Graph Learning (FGL) enables privacy-preserving, distributed training of graph neural networks without sharing raw data. Among its approaches, subgraph-FL has become the dominant paradigm, with most work focused on improving overall node classification accuracy. However, these methods often overlook fairness due to the complexity of node features, labels, and graph structures. In particular, they perform poorly on nodes with disadvantaged properties, such as being in the minority class within subgraphs or having heterophilous connections (neighbors with dissimilar labels or misleading features). This reveals a critical issue: high accuracy can mask degraded performance on structurally or semantically marginalized nodes. To address this, we advocate for two fairness goals: (1) improving representation of minority class nodes for class-wise fairness and (2) mitigating topological bias from heterophilous connections for topology-aware fairness. We propose FairFGL, a novel framework that enhances fairness through fine-grained graph mining and collaborative learning. On the client side, the History-Preserving Module prevents overfitting to dominant local classes, while the Majority Alignment Module refines representations of heterophilous majority-class nodes. The Gradient Modification Module transfers minority-class knowledge from structurally favorable clients to improve fairness. On the server side, FairFGL uploads only the most influenced subset of parameters to reduce communication costs and better reflect local distributions. A cluster-based aggregation strategy reconciles conflicting updates and curbs global majority dominance . Extensive evaluations on eight benchmarks show FairFGL significantly improves minority-group performance , achieving up to a 22.62 percent Macro-F1 gain while enhancing convergence over state-of-the-art baselines.","authors":["Zhengyu Wu","Boyang Pang","Xunkai Li","Yinlin Zhu","Daohan Su","Bowen Fan","Rong-Hua Li","Guoren Wang","Chenghu Zhou"],"url":"https://arxiv.org/abs/2504.09963"}
{"created":"2025-04-15","title":"SemiETS: Integrating Spatial and Content Consistencies for Semi-Supervised End-to-end Text Spotting","abstract":"Most previous scene text spotting methods rely on high-quality manual annotations to achieve promising performance. To reduce their expensive costs, we study semi-supervised text spotting (SSTS) to exploit useful information from unlabeled images. However, directly applying existing semi-supervised methods of general scenes to SSTS will face new challenges: 1) inconsistent pseudo labels between detection and recognition tasks, and 2) sub-optimal supervisions caused by inconsistency between teacher/student. Thus, we propose a new Semi-supervised framework for End-to-end Text Spotting, namely SemiETS that leverages the complementarity of text detection and recognition. Specifically, it gradually generates reliable hierarchical pseudo labels for each task, thereby reducing noisy labels. Meanwhile, it extracts important information in locations and transcriptions from bidirectional flows to improve consistency. Extensive experiments on three datasets under various settings demonstrate the effectiveness of SemiETS on arbitrary-shaped text. For example, it outperforms previous state-of-the-art SSL methods by a large margin on end-to-end spotting (+8.7%, +5.6%, and +2.6% H-mean under 0.5%, 1%, and 2% labeled data settings on Total-Text, respectively). More importantly, it still improves upon a strongly supervised text spotter trained with plenty of labeled data by 2.0%. Compelling domain adaptation ability shows practical potential. Moreover, our method demonstrates consistent improvement on different text spotters.","authors":["Dongliang Luo","Hanshen Zhu","Ziyang Zhang","Dingkang Liang","Xudong Xie","Yuliang Liu","Xiang Bai"],"url":"https://arxiv.org/abs/2504.09966"}
{"created":"2025-04-15","title":"Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data","abstract":"The emergence of medical generalist foundation models has revolutionized conventional task-specific model development paradigms, aiming to better handle multiple tasks through joint training on large-scale medical datasets. However, recent advances prioritize simple data scaling or architectural component enhancement, while neglecting to re-examine multi-task learning from a data-centric perspective. Critically, simply aggregating existing data resources leads to decentralized image-task alignment, which fails to cultivate comprehensive image understanding or align with clinical needs for multi-dimensional image interpretation. In this paper, we introduce the image-centric multi-annotation X-ray dataset (IMAX), the first attempt to enhance the multi-task learning capabilities of medical multi-modal large language models (MLLMs) from the data construction level. To be specific, IMAX is featured from the following attributes: 1) High-quality data curation. A comprehensive collection of more than 354K entries applicable to seven different medical tasks. 2) Image-centric dense annotation. Each X-ray image is associated with an average of 4.10 tasks and 7.46 training entries, ensuring multi-task representation richness per image. Compared to the general decentralized multi-annotation X-ray dataset (DMAX), IMAX consistently demonstrates significant multi-task average performance gains ranging from 3.20% to 21.05% across seven open-source state-of-the-art medical MLLMs. Moreover, we investigate differences in statistical patterns exhibited by IMAX and DMAX training processes, exploring potential correlations between optimization dynamics and multi-task performance. Finally, leveraging the core concept of IMAX data construction, we propose an optimized DMAX-based training strategy to alleviate the dilemma of obtaining high-quality IMAX data in practical scenarios.","authors":["Xun Zhu","Fanbin Mo","Zheng Zhang","Jiaxi Wang","Yiming Shi","Ming Wu","Chuang Zhang","Miao Li","Ji Wu"],"url":"https://arxiv.org/abs/2504.09967"}
{"created":"2025-04-15","title":"Semi-implicit-explicit Runge-Kutta method for nonlinear differential equations","abstract":"A semi-implicit-explicit (semi-IMEX) Runge-Kutta (RK) method is proposed for the numerical integration of ordinary differential equations (ODEs) of the form $\\mathbf{u}' = \\mathbf{f}(t,\\mathbf{u}) + G(t,\\mathbf{u}) \\mathbf{u}$, where $\\mathbf{f}$ is a non-stiff term and $G\\mathbf{u}$ represents the stiff terms. Such systems frequently arise from spatial discretizations of time-dependent nonlinear partial differential equations (PDEs). For instance, $G$ could involve higher-order derivative terms with nonlinear coefficients. Traditional IMEX-RK methods, which treat $\\mathbf{f}$ explicitly and $G\\mathbf{u}$ implicitly, require solving nonlinear systems at each time step when $G$ depends on $\\mathbf{u}$, leading to increased computational cost and complexity. In contrast, the proposed semi-IMEX scheme treats $G$ explicitly while keeping $\\mathbf{u}$ implicit, reducing the problem to solving only linear systems. This approach eliminates the need to compute Jacobians while preserving the stability advantages of implicit methods. A family of semi-IMEX RK schemes with varying orders of accuracy is introduced. Numerical simulations for various nonlinear equations, including nonlinear diffusion models, the Navier-Stokes equations, and the Cahn-Hilliard equation, confirm the expected convergence rates and demonstrate that the proposed method allows for larger time step sizes without triggering stability issues.","authors":["Lingyun Ding"],"url":"https://arxiv.org/abs/2504.09969"}
{"created":"2025-04-15","title":"IsoSEL: Isometric Structural Entropy Learning for Deep Graph Clustering in Hyperbolic Space","abstract":"Graph clustering is a longstanding topic in machine learning. In recent years, deep learning methods have achieved encouraging results, but they still require predefined cluster numbers K, and typically struggle with imbalanced graphs, especially in identifying minority clusters. The limitations motivate us to study a challenging yet practical problem: deep graph clustering without K considering the imbalance in reality. We approach this problem from a fresh perspective of information theory (i.e., structural information). In the literature, structural information has rarely been touched in deep clustering, and the classic definition falls short in its discrete formulation, neglecting node attributes and exhibiting prohibitive complexity. In this paper, we first establish a new Differentiable Structural Information, generalizing the discrete formalism to continuous realm, so that the optimal partitioning tree, revealing the cluster structure, can be created by the gradient backpropagation. Theoretically, we demonstrate its capability in clustering without requiring K and identifying the minority clusters in imbalanced graphs, while reducing the time complexity to O(N) w.r.t. the number of nodes. Subsequently, we present a novel IsoSEL framework for deep graph clustering, where we design a hyperbolic neural network to learn the partitioning tree in the Lorentz model of hyperbolic space, and further conduct Lorentz Tree Contrastive Learning with isometric augmentation. As a result, the partitioning tree incorporates node attributes via mutual information maximization, while the cluster assignment is refined by the proposed tree contrastive learning. Extensive experiments on five benchmark datasets show the IsoSEL outperforms 14 recent baselines by an average of +1.3% in NMI.","authors":["Li Sun","Zhenhao Huang","Yujie Wang","Hongbo Lv","Chunyang Liu","Hao Peng","Philip S. Yu"],"url":"https://arxiv.org/abs/2504.09970"}
{"created":"2025-04-15","title":"Proofs of Useful Work from Arbitrary Matrix Multiplication","abstract":"We revisit the longstanding open problem of implementing Nakamoto's proof-of-work (PoW) consensus based on a real-world computational task $T(x)$ (as opposed to artificial random hashing), in a truly permissionless setting where the miner itself chooses the input $x$. The challenge in designing such a Proof-of-Useful-Work (PoUW) protocol, is using the native computation of $T(x)$ to produce a PoW certificate with prescribed hardness and with negligible computational overhead over the worst-case complexity of $T(\\cdot)$ -- This ensures malicious miners cannot ``game the system\" by fooling the verifier to accept with higher probability compared to honest miners (while using similar computational resources). Indeed, obtaining a PoUW with $O(1)$-factor overhead is trivial for any task $T$, but also useless.","authors":["Ilan Komargodski","Itamar Schen","Omri Weinstein"],"url":"https://arxiv.org/abs/2504.09971"}
{"created":"2025-04-15","title":"Beyond Degradation Redundancy: Contrastive Prompt Learning for All-in-One Image Restoration","abstract":"All-in-one image restoration, addressing diverse degradation types with a unified model, presents significant challenges in designing task-specific prompts that effectively guide restoration across multiple degradation scenarios. While adaptive prompt learning enables end-to-end optimization, it often yields overlapping or redundant task representations. Conversely, explicit prompts derived from pretrained classifiers enhance discriminability but may discard critical visual information for reconstruction. To address these limitations, we introduce Contrastive Prompt Learning (CPL), a novel framework that fundamentally enhances prompt-task alignment through two complementary innovations: a \\emph{Sparse Prompt Module (SPM)} that efficiently captures degradation-specific features while minimizing redundancy, and a \\emph{Contrastive Prompt Regularization (CPR)} that explicitly strengthens task boundaries by incorporating negative prompt samples across different degradation types. Unlike previous approaches that focus primarily on degradation classification, CPL optimizes the critical interaction between prompts and the restoration model itself. Extensive experiments across five comprehensive benchmarks demonstrate that CPL consistently enhances state-of-the-art all-in-one restoration models, achieving significant improvements in both standard multi-task scenarios and challenging composite degradation settings. Our framework establishes new state-of-the-art performance while maintaining parameter efficiency, offering a principled solution for unified image restoration.","authors":["Gang Wu","Junjun Jiang","Kui Jiang","Xianming Liu","Liqiang Nie"],"url":"https://arxiv.org/abs/2504.09973"}
{"created":"2025-04-15","title":"OctGPT: Octree-based Multiscale Autoregressive Models for 3D Shape Generation","abstract":"Autoregressive models have achieved remarkable success across various domains, yet their performance in 3D shape generation lags significantly behind that of diffusion models. In this paper, we introduce OctGPT, a novel multiscale autoregressive model for 3D shape generation that dramatically improves the efficiency and performance of prior 3D autoregressive approaches, while rivaling or surpassing state-of-the-art diffusion models. Our method employs a serialized octree representation to efficiently capture the hierarchical and spatial structures of 3D shapes. Coarse geometry is encoded via octree structures, while fine-grained details are represented by binary tokens generated using a vector quantized variational autoencoder (VQVAE), transforming 3D shapes into compact \\emph{multiscale binary sequences} suitable for autoregressive prediction. To address the computational challenges of handling long sequences, we incorporate octree-based transformers enhanced with 3D rotary positional encodings, scale-specific embeddings, and token-parallel generation schemes. These innovations reduce training time by 13 folds and generation time by 69 folds, enabling the efficient training of high-resolution 3D shapes, e.g.,$1024^3$, on just four NVIDIA 4090 GPUs only within days. OctGPT showcases exceptional versatility across various tasks, including text-, sketch-, and image-conditioned generation, as well as scene-level synthesis involving multiple objects. Extensive experiments demonstrate that OctGPT accelerates convergence and improves generation quality over prior autoregressive methods, offering a new paradigm for high-quality, scalable 3D content creation.","authors":["Si-Tong Wei","Rui-Huan Wang","Chuan-Zhi Zhou","Baoquan Chen","Peng-Shuai Wang"],"url":"https://arxiv.org/abs/2504.09975"}
{"created":"2025-04-15","title":"EthCluster: An Unsupervised Static Analysis Method for Ethereum Smart Contract","abstract":"Poorly designed smart contracts are particularly vulnerable, as they may allow attackers to exploit weaknesses and steal the virtual currency they manage. In this study, we train a model using unsupervised learning to identify vulnerabilities in the Solidity source code of Ethereum smart contracts. To address the challenges associated with real-world smart contracts, our training data is derived from actual vulnerability samples obtained from datasets such as SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us to develop a robust unsupervised static analysis method for detecting five specific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency, tx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms to identify outliers, which are subsequently classified as vulnerable smart contracts.","authors":["Hong-Sheng Huang","Jen-Yi Ho","Hao-Wen Chen","Hung-Min Sun"],"url":"https://arxiv.org/abs/2504.09977"}
{"created":"2025-04-15","title":"New exponential law for real networks","abstract":"In this article we have shown that the distributions of ksi satisfy an exponential law for real networks while the distributions of ksi for random networks are bell-shaped and closer to the normal distribution. The ksi distributions for Barabasi-Albert and Watts-Strogatz networks are similar to the ksi distributions for random networks (bell-shaped) for most parameters, but when these parameters become small enough, the Barabasi-Albert and Watts-Strogatz networks become more realistic with respect to the ksi distributions.","authors":["Mikhail Tuzhilin"],"url":"https://arxiv.org/abs/2504.09978"}
{"created":"2025-04-15","title":"Resampling Benchmark for Efficient Comprehensive Evaluation of Large Vision-Language Models","abstract":"We propose an efficient evaluation protocol for large vision-language models (VLMs). Given their broad knowledge and reasoning capabilities, multiple benchmarks are needed for comprehensive assessment, making evaluation computationally expensive. To improve efficiency, we construct a subset that yields results comparable to full benchmark evaluations. Our benchmark classification experiments reveal that no single benchmark fully covers all challenges. We then introduce a subset construction method using farthest point sampling (FPS). Our experiments show that FPS-based benchmarks maintain a strong correlation (> 0.96) with full evaluations while using only ~1\\% of the data. Additionally, applying FPS to an existing benchmark improves correlation with overall evaluation results, suggesting its potential to reduce unintended dataset biases.","authors":["Teppei Suzuki","Keisuke Ozawa"],"url":"https://arxiv.org/abs/2504.09979"}
{"created":"2025-04-15","title":"Turn-taking annotation for quantitative and qualitative analyses of conversation","abstract":"This paper has two goals. First, we present the turn-taking annotation layers created for 95 minutes of conversational speech of the Graz Corpus of Read and Spontaneous Speech (GRASS), available to the scientific community. Second, we describe the annotation system and the annotation process in more detail, so other researchers may use it for their own conversational data. The annotation system was developed with an interdisciplinary application in mind. It should be based on sequential criteria according to Conversation Analysis, suitable for subsequent phonetic analysis, thus time-aligned annotations were made Praat, and it should be suitable for automatic classification, which required the continuous annotation of speech and a label inventory that is not too large and results in a high inter-rater agreement. Turn-taking was annotated on two layers, Inter-Pausal Units (IPU) and points of potential completion (PCOMP; similar to transition relevance places). We provide a detailed description of the annotation process and of segmentation and labelling criteria. A detailed analysis of inter-rater agreement and common confusions shows that agreement for IPU annotation is near-perfect, that agreement for PCOMP annotations is substantial, and that disagreements often are either partial or can be explained by a different analysis of a sequence which also has merit. The annotation system can be applied to a variety of conversational data for linguistic studies and technological applications, and we hope that the annotations, as well as the annotation system will contribute to a stronger cross-fertilization between these disciplines.","authors":["Anneliese Kelterer","Barbara Schuppler"],"url":"https://arxiv.org/abs/2504.09980"}
{"created":"2025-04-15","title":"DeepCompile: A Compiler-Driven Approach to Optimizing Distributed Deep Learning Training","abstract":"The increasing scale of deep learning models has led to the development of various parallelization strategies for distributed training across accelerators. For example, fully sharded approaches like DeepSpeed ZeRO-3 and FSDP partition the parameters of each layer across multiple GPUs and gather them through communication when needed. These methods rely on optimizations such as prefetching, which initiates communication early to overlap it with computation and reduce communication overhead, and unsharding, which retains as many parameters in their unsharded form as possible to reduce communication volume. Although the timing of prefetching should be adjusted in response to dynamic memory usage during execution, these systems lack the flexibility to control it, which limits the benefits of prefetching. Moreover, they cannot anticipate how memory usage will change after prefetching is applied, making it difficult to combine it effectively with other optimizations such as unsharding. We present DeepCompile, which compiles user-defined models into computation graphs and applies a sequence of profiling-guided optimization passes for distributed training. Taking dynamic memory usage into account, these passes flexibly insert, reorder, or remove operations to improve communication-computation overlap, reduce memory pressure, and coordinate multiple optimizations in a unified manner. To evaluate the effectiveness of this design, we implemented a fully sharded approach like ZeRO-3 and FSDP on top of DeepCompile, along with three optimizations: proactive prefetching, selective unsharding, and adaptive offloading. We evaluate DeepCompile on the training of Llama 3 70B and Mixtral 8x7B MoE models. DeepCompile achieves up to 1.28x and 1.54x performance improvements over ZeRO-3 and FSDP baselines, respectively, and up to a 7.01x throughput increase with limited GPU resources, using offloading.","authors":["Masahiro Tanaka","Du Li","Umesh Chand","Ali Zafar","Haiying Shen","Olatunji Ruwase"],"url":"https://arxiv.org/abs/2504.09983"}
{"created":"2025-04-15","title":"On Precomputation and Caching in Information Retrieval Experiments with Pipeline Architectures","abstract":"Modern information retrieval systems often rely on multiple components executed in a pipeline. In a research setting, this can lead to substantial redundant computations (e.g., retrieving the same query multiple times for evaluating different downstream rerankers). To overcome this, researchers take cached \"result\" files as inputs, which represent the output of another pipeline. However, these result files can be brittle and can cause a disconnect between the conceptual design of the pipeline and its logical implementation. To overcome both the redundancy problem (when executing complete pipelines) and the disconnect problem (when relying on intermediate result files), we describe our recent efforts to improve the caching capabilities in the open-source PyTerrier IR platform. We focus on two main directions: (1) automatic implicit caching of common pipeline prefixes when comparing systems and (2) explicit caching of operations through a new extension package, pyterrier-caching. These approaches allow for the best of both worlds: pipelines can be fully expressed end-to-end, while also avoiding redundant computations between pipelines.","authors":["Sean MacAvaney","Craig Macdonald"],"url":"https://arxiv.org/abs/2504.09984"}
{"created":"2025-04-15","title":"FTHP-MPI: Towards Providing Replication-based Fault Tolerance in a Fault-Intolerant Native MPI Library","abstract":"Faults in high-performance systems are expected to be very large in the current exascale computing era. To compensate for a higher failure rate, the standard checkpoint/restart technique would need to create checkpoints at a much higher frequency resulting in an excessive amount of overhead which would not be sustainable for many scientific applications. To improve application efficiency in such high failure environments, the mechanism of replication of MPI processes was proposed. Replication allows for fast recovery from failures by simply dropping the failed processes and using their replicas to continue the regular operation of the application.","authors":["Sarthak Joshi","Sathish Vadhiyar"],"url":"https://arxiv.org/abs/2504.09989"}
{"created":"2025-04-15","title":"Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning","abstract":"Modeling label correlations has always played a pivotal role in multi-label image classification (MLC), attracting significant attention from researchers. However, recent studies have overemphasized co-occurrence relationships among labels, which can lead to overfitting risk on this overemphasis, resulting in suboptimal models. To tackle this problem, we advocate for balancing correlative and discriminative relationships among labels to mitigate the risk of overfitting and enhance model performance. To this end, we propose the Multi-Label Visual Prompt Tuning framework, a novel and parameter-efficient method that groups classes into multiple class subsets according to label co-occurrence and mutual exclusivity relationships, and then models them respectively to balance the two relationships. In this work, since each group contains multiple classes, multiple prompt tokens are adopted within Vision Transformer (ViT) to capture the correlation or discriminative label relationship within each group, and effectively learn correlation or discriminative representations for class subsets. On the other hand, each group contains multiple group-aware visual representations that may correspond to multiple classes, and the mixture of experts (MoE) model can cleverly assign them from the group-aware to the label-aware, adaptively obtaining label-aware representation, which is more conducive to classification. Experiments on multiple benchmark datasets show that our proposed approach achieves competitive results and outperforms SOTA methods on multiple pre-trained models.","authors":["LeiLei Ma","Shuo Xu","MingKun Xie","Lei Wang","Dengdi Sun","Haifeng Zhao"],"url":"https://arxiv.org/abs/2504.09990"}
{"created":"2025-04-15","title":"Bipartite Matching is in Catalytic Logspace","abstract":"Matching is a central problem in theoretical computer science, with a large body of work spanning the last five decades. However, understanding matching in the time-space bounded setting remains a longstanding open question, even in the presence of additional resources such as randomness or non-determinism.","authors":["Aryan Agarwala","Ian Mertz"],"url":"https://arxiv.org/abs/2504.09991"}
{"created":"2025-04-15","title":"AimTS: Augmented Series and Image Contrastive Learning for Time Series Classification","abstract":"Time series classification (TSC) is an important task in time series analysis. Existing TSC methods mainly train on each single domain separately, suffering from a degradation in accuracy when the samples for training are insufficient in certain domains. The pre-training and fine-tuning paradigm provides a promising direction for solving this problem. However, time series from different domains are substantially divergent, which challenges the effective pre-training on multi-source data and the generalization ability of pre-trained models. To handle this issue, we introduce Augmented Series and Image Contrastive Learning for Time Series Classification (AimTS), a pre-training framework that learns generalizable representations from multi-source time series data. We propose a two-level prototype-based contrastive learning method to effectively utilize various augmentations in multi-source pre-training, which learns representations for TSC that can be generalized to different domains. In addition, considering augmentations within the single time series modality are insufficient to fully address classification problems with distribution shift, we introduce the image modality to supplement structural information and establish a series-image contrastive learning to improve the generalization of the learned representations for TSC tasks. Extensive experiments show that after multi-source pre-training, AimTS achieves good generalization performance, enabling efficient learning and even few-shot learning on various downstream TSC datasets.","authors":["Yuxuan Chen","Shanshan Huang","Yunyao Cheng","Peng Chen","Zhongwen Rao","Yang Shu","Bin Yang","Lujia Pan","Chenjuan Guo"],"url":"https://arxiv.org/abs/2504.09993"}
{"created":"2025-04-15","title":"COUNTER: Cluster GCN based Energy Efficient Resource Management for Sustainable Cloud Computing Environments","abstract":"Cloud computing, thanks to the pervasiveness of information technologies, provides a foundational environment for developing IT applications, offering organizations virtually unlimited and flexible computing resources on a pay-per-use basis. However, the large data centres where cloud computing services are hosted consume significant amounts of electricity annually due to Information and Communication Technology (ICT) components. This issue is exacerbated by the increasing deployment of large artificial intelligence (AI) models, which often rely on distributed data centres, thereby significantly impacting the global environment. This study proposes the COUNTER model, designed for sustainable cloud resource management. COUNTER is integrated with cluster graph neural networks and evaluated in a simulated cloud environment, aiming to reduce energy consumption while maintaining quality of service parameters. Experimental results demonstrate improvements in resource utilisation, energy consumption, and cost effectiveness compared to the baseline model, HUNTER, which employs a gated graph neural network aimed at achieving carbon neutrality in cloud computing for modern ICT systems.","authors":["Han Wang","Sukhpal Singh Gill","Steve Uhlig"],"url":"https://arxiv.org/abs/2504.09995"}
{"created":"2025-04-15","title":"GenTe: Generative Real-world Terrains for General Legged Robot Locomotion Control","abstract":"Developing bipedal robots capable of traversing diverse real-world terrains presents a fundamental robotics challenge, as existing methods using predefined height maps and static environments fail to address the complexity of unstructured landscapes. To bridge this gap, we propose GenTe, a framework for generating physically realistic and adaptable terrains to train generalizable locomotion policies. GenTe constructs an atomic terrain library that includes both geometric and physical terrains, enabling curriculum training for reinforcement learning-based locomotion policies. By leveraging function-calling techniques and reasoning capabilities of Vision-Language Models (VLMs), GenTe generates complex, contextually relevant terrains from textual and graphical inputs. The framework introduces realistic force modeling for terrain interactions, capturing effects such as soil sinkage and hydrodynamic resistance. To the best of our knowledge, GenTe is the first framework that systemically generates simulation environments for legged robot locomotion control. Additionally, we introduce a benchmark of 100 generated terrains. Experiments demonstrate improved generalization and robustness in bipedal robot locomotion.","authors":["Hanwen Wan","Mengkang Li","Donghao Wu","Yebin Zhong","Yixuan Deng","Zhenglong Sun","Xiaoqiang Ji"],"url":"https://arxiv.org/abs/2504.09997"}
{"created":"2025-04-15","title":"Metric-Guided Synthesis of Class Activation Mapping","abstract":"Class activation mapping (CAM) is a widely adopted class of saliency methods used to explain the behavior of convolutional neural networks (CNNs). These methods generate heatmaps that highlight the parts of the input most relevant to the CNN output. Various CAM methods have been proposed, each distinguished by the expressions used to derive heatmaps. In general, users look for heatmaps with specific properties that reflect different aspects of CNN functionality. These may include similarity to ground truth, robustness, equivariance, and more. Although existing CAM methods implicitly encode some of these properties in their expressions, they do not allow for variability in heatmap generation following the user's intent or domain knowledge. In this paper, we address this limitation by introducing SyCAM, a metric-based approach for synthesizing CAM expressions. Given a predefined evaluation metric for saliency maps, SyCAM automatically generates CAM expressions optimized for that metric. We specifically explore a syntax-guided synthesis instantiation of SyCAM, where CAM expressions are derived based on predefined syntactic constraints and the given metric. Using several established evaluation metrics, we demonstrate the efficacy and flexibility of our approach in generating targeted heatmaps. We compare SyCAM with other well-known CAM methods on three prominent models: ResNet50, VGG16, and VGG19.","authors":["Alejandro Luque-Cerpa","Elizabeth Polgreen","Ajitha Rajan","Hazem Torfah"],"url":"https://arxiv.org/abs/2504.09998"}
{"created":"2025-04-15","title":"Do We Really Need Curated Malicious Data for Safety Alignment in Multi-modal Large Language Models?","abstract":"Multi-modal large language models (MLLMs) have made significant progress, yet their safety alignment remains limited. Typically, current open-source MLLMs rely on the alignment inherited from their language module to avoid harmful generations. However, the lack of safety measures specifically designed for multi-modal inputs creates an alignment gap, leaving MLLMs vulnerable to vision-domain attacks such as typographic manipulation. Current methods utilize a carefully designed safety dataset to enhance model defense capability, while the specific knowledge or patterns acquired from the high-quality dataset remain unclear. Through comparison experiments, we find that the alignment gap primarily arises from data distribution biases, while image content, response quality, or the contrastive behavior of the dataset makes little contribution to boosting multi-modal safety. To further investigate this and identify the key factors in improving MLLM safety, we propose finetuning MLLMs on a small set of benign instruct-following data with responses replaced by simple, clear rejection sentences. Experiments show that, without the need for labor-intensive collection of high-quality malicious data, model safety can still be significantly improved, as long as a specific fraction of rejection data exists in the finetuning set, indicating the security alignment is not lost but rather obscured during multi-modal pretraining or instruction finetuning. Simply correcting the underlying data bias could narrow the safety gap in the vision domain.","authors":["Yanbo Wang","Jiyang Guan","Jian Liang","Ran He"],"url":"https://arxiv.org/abs/2504.10000"}
{"created":"2025-04-15","title":"GaussVideoDreamer: 3D Scene Generation with Video Diffusion and Inconsistency-Aware Gaussian Splatting","abstract":"Single-image 3D scene reconstruction presents significant challenges due to its inherently ill-posed nature and limited input constraints. Recent advances have explored two promising directions: multiview generative models that train on 3D consistent datasets but struggle with out-of-distribution generalization, and 3D scene inpainting and completion frameworks that suffer from cross-view inconsistency and suboptimal error handling, as they depend exclusively on depth data or 3D smoothness, which ultimately degrades output quality and computational performance. Building upon these approaches, we present GaussVideoDreamer, which advances generative multimedia approaches by bridging the gap between image, video, and 3D generation, integrating their strengths through two key innovations: (1) A progressive video inpainting strategy that harnesses temporal coherence for improved multiview consistency and faster convergence. (2) A 3D Gaussian Splatting consistency mask to guide the video diffusion with 3D consistent multiview evidence. Our pipeline combines three core components: a geometry-aware initialization protocol, Inconsistency-Aware Gaussian Splatting, and a progressive video inpainting strategy. Experimental results demonstrate that our approach achieves 32% higher LLaVA-IQA scores and at least 2x speedup compared to existing methods while maintaining robust performance across diverse scenes.","authors":["Junlin Hao","Peiheng Wang","Haoyang Wang","Xinggong Zhang","Zongming Guo"],"url":"https://arxiv.org/abs/2504.10001"}
{"created":"2025-04-15","title":"FLoRA: Sample-Efficient Preference-based RL via Low-Rank Style Adaptation of Reward Functions","abstract":"Preference-based reinforcement learning (PbRL) is a suitable approach for style adaptation of pre-trained robotic behavior: adapting the robot's policy to follow human user preferences while still being able to perform the original task. However, collecting preferences for the adaptation process in robotics is often challenging and time-consuming. In this work we explore the adaptation of pre-trained robots in the low-preference-data regime. We show that, in this regime, recent adaptation approaches suffer from catastrophic reward forgetting (CRF), where the updated reward model overfits to the new preferences, leading the agent to become unable to perform the original task. To mitigate CRF, we propose to enhance the original reward model with a small number of parameters (low-rank matrices) responsible for modeling the preference adaptation. Our evaluation shows that our method can efficiently and effectively adjust robotic behavior to human preferences across simulation benchmark tasks and multiple real-world robotic tasks.","authors":["Daniel Marta","Simon Holk","Miguel Vasco","Jens Lundell","Timon Homberger","Finn Busch","Olov Andersson","Danica Kragic","Iolanda Leite"],"url":"https://arxiv.org/abs/2504.10002"}
{"created":"2025-04-15","title":"NaviDiffusor: Cost-Guided Diffusion Model for Visual Navigation","abstract":"Visual navigation, a fundamental challenge in mobile robotics, demands versatile policies to handle diverse environments. Classical methods leverage geometric solutions to minimize specific costs, offering adaptability to new scenarios but are prone to system errors due to their multi-modular design and reliance on hand-crafted rules. Learning-based methods, while achieving high planning success rates, face difficulties in generalizing to unseen environments beyond the training data and often require extensive training. To address these limitations, we propose a hybrid approach that combines the strengths of learning-based methods and classical approaches for RGB-only visual navigation. Our method first trains a conditional diffusion model on diverse path-RGB observation pairs. During inference, it integrates the gradients of differentiable scene-specific and task-level costs, guiding the diffusion model to generate valid paths that meet the constraints. This approach alleviates the need for retraining, offering a plug-and-play solution. Extensive experiments in both indoor and outdoor settings, across simulated and real-world scenarios, demonstrate zero-shot transfer capability of our approach, achieving higher success rates and fewer collisions compared to baseline methods. Code will be released at https://github.com/SYSU-RoboticsLab/NaviD.","authors":["Yiming Zeng","Hao Ren","Shuhang Wang","Junlong Huang","Hui Cheng"],"url":"https://arxiv.org/abs/2504.10003"}
{"created":"2025-04-15","title":"An Image is Worth $K$ Topics: A Visual Structural Topic Model with Pretrained Image Embeddings","abstract":"Political scientists are increasingly interested in analyzing visual content at scale. However, the existing computational toolbox is still in need of methods and models attuned to the specific challenges and goals of social and political inquiry. In this article, we introduce a visual Structural Topic Model (vSTM) that combines pretrained image embeddings with a structural topic model. This has important advantages compared to existing approaches. First, pretrained embeddings allow the model to capture the semantic complexity of images relevant to political contexts. Second, the structural topic model provides the ability to analyze how topics and covariates are related, while maintaining a nuanced representation of images as a mixture of multiple topics. In our empirical application, we show that the vSTM is able to identify topics that are interpretable, coherent, and substantively relevant to the study of online political communication.","authors":["Mat\\'ias Piqueras","Alexandra Segerberg","Matteo Magnani","M{\\aa}ns Magnusson","Nata\\v{s}a Sladoje"],"url":"https://arxiv.org/abs/2504.10004"}
{"created":"2025-04-15","title":"Session-based Recommender Systems: User Interest as a Stochastic Process in the Latent Space","abstract":"This paper jointly addresses the problem of data uncertainty, popularity bias, and exposure bias in session-based recommender systems. We study the symptoms of this bias both in item embeddings and in recommendations. We propose treating user interest as a stochastic process in the latent space and providing a model-agnostic implementation of this mathematical concept. The proposed stochastic component consists of elements: debiasing item embeddings with regularization for embedding uniformity, modeling dense user interest from session prefixes, and introducing fake targets in the data to simulate extended exposure. We conducted computational experiments on two popular benchmark datasets, Diginetica and YooChoose 1/64, as well as several modifications of the YooChoose dataset with different ratios of popular items. The results show that the proposed approach allows us to mitigate the challenges mentioned.","authors":["Klaudia Balcer","Piotr Lipinski"],"url":"https://arxiv.org/abs/2504.10005"}
{"created":"2025-04-15","title":"Improving Controller Generalization with Dimensionless Markov Decision Processes","abstract":"Controllers trained with Reinforcement Learning tend to be very specialized and thus generalize poorly when their testing environment differs from their training one. We propose a Model-Based approach to increase generalization where both world model and policy are trained in a dimensionless state-action space. To do so, we introduce the Dimensionless Markov Decision Process ($\\Pi$-MDP): an extension of Contextual-MDPs in which state and action spaces are non-dimensionalized with the Buckingham-$\\Pi$ theorem. This procedure induces policies that are equivariant with respect to changes in the context of the underlying dynamics. We provide a generic framework for this approach and apply it to a model-based policy search algorithm using Gaussian Process models. We demonstrate the applicability of our method on simulated actuated pendulum and cartpole systems, where policies trained on a single environment are robust to shifts in the distribution of the context.","authors":["Valentin Charvet","Sebastian Stein","Roderick Murray-Smith"],"url":"https://arxiv.org/abs/2504.10006"}
{"created":"2025-04-15","title":"Balancing Two Classifiers via A Simplex ETF Structure for Model Calibration","abstract":"In recent years, deep neural networks (DNNs) have demonstrated state-of-the-art performance across various domains. However, despite their success, they often face calibration issues, particularly in safety-critical applications such as autonomous driving and healthcare, where unreliable predictions can have serious consequences. Recent research has started to improve model calibration from the view of the classifier. However, the exploration of designing the classifier to solve the model calibration problem is insufficient. Let alone most of the existing methods ignore the calibration errors arising from underconfidence. In this work, we propose a novel method by balancing learnable and ETF classifiers to solve the overconfidence or underconfidence problem for model Calibration named BalCAL. By introducing a confidence-tunable module and a dynamic adjustment method, we ensure better alignment between model confidence and its true accuracy. Extensive experimental validation shows that ours significantly improves model calibration performance while maintaining high predictive accuracy, outperforming existing techniques. This provides a novel solution to the calibration challenges commonly encountered in deep learning.","authors":["Jiani Ni","He Zhao","Jintong Gao","Dandan Guo","Hongyuan Zha"],"url":"https://arxiv.org/abs/2504.10007"}
{"created":"2025-04-15","title":"Time for Timed Monitorability","abstract":"Monitoring is an important part of the verification toolbox, in particular in situations where exhaustive verification using, e.g., model-checking, is infeasible. The goal of online monitoring is to determine the satisfaction or violation of a specification during runtime, i.e., based on finite execution prefixes. However, not every specification is amenable to monitoring, e.g., properties for which no finite execution can witness satisfaction or violation. Monitorability is the question whether a given specification is amenable to monitoring, and has been extensively studied in discrete time.","authors":["Thomas M. Grosen","Sean Kauffman","Kim G. Larsen","Martin Zimmermann"],"url":"https://arxiv.org/abs/2504.10008"}
{"created":"2025-04-15","title":"Investigating Environments' and Avatars' Effects on Thermal Perception in Virtual Reality to Reduce Energy Consumption","abstract":"Understanding thermal regulation and subjective perception of temperature is crucial for improving thermal comfort and human energy consumption in times of global warming. Previous work shows that an environment's color temperature affects the experienced temperature. As virtual reality (VR) enables visual immersion, recent work suggests that a VR scene's color temperature also affects experienced temperature. In addition, virtual avatars representing thermal cues influence users' thermal perception and even the body temperature. As immersive technology becomes increasingly prevalent in daily life, leveraging thermal cues to enhance thermal comfort - without relying on actual thermal energy - presents a promising opportunity. Understanding these effects is crucial for optimizing virtual experiences and promoting sustainable energy practices. Therefore, we propose three controlled experiments to learn more about thermal effects caused by virtual worlds and avatars.","authors":["Martin Kocur","Niels Henze"],"url":"https://arxiv.org/abs/2504.10010"}
{"created":"2025-04-15","title":"KeyMPs: One-Shot Vision-Language Guided Motion Generation by Sequencing DMPs for Occlusion-Rich Tasks","abstract":"Dynamic Movement Primitives (DMPs) provide a flexible framework wherein smooth robotic motions are encoded into modular parameters. However, they face challenges in integrating multimodal inputs commonly used in robotics like vision and language into their framework. To fully maximize DMPs' potential, enabling them to handle multimodal inputs is essential. In addition, we also aim to extend DMPs' capability to handle object-focused tasks requiring one-shot complex motion generation, as observation occlusion could easily happen mid-execution in such tasks (e.g., knife occlusion in cake icing, hand occlusion in dough kneading, etc.). A promising approach is to leverage Vision-Language Models (VLMs), which process multimodal data and can grasp high-level concepts. However, they typically lack enough knowledge and capabilities to directly infer low-level motion details and instead only serve as a bridge between high-level instructions and low-level control. To address this limitation, we propose Keyword Labeled Primitive Selection and Keypoint Pairs Generation Guided Movement Primitives (KeyMPs), a framework that combines VLMs with sequencing of DMPs. KeyMPs use VLMs' high-level reasoning capability to select a reference primitive through keyword labeled primitive selection and VLMs' spatial awareness to generate spatial scaling parameters used for sequencing DMPs by generalizing the overall motion through keypoint pairs generation, which together enable one-shot vision-language guided motion generation that aligns with the intent expressed in the multimodal input. We validate our approach through an occlusion-rich manipulation task, specifically object cutting experiments in both simulated and real-world environments, demonstrating superior performance over other DMP-based methods that integrate VLMs support.","authors":["Edgar Anarossi","Yuhwan Kwon","Hirotaka Tahara","Shohei Tanaka","Keisuke Shirai","Masashi Hamaya","Cristian C. Beltran-Hernandez","Atsushi Hashimoto","Takamitsu Matsubara"],"url":"https://arxiv.org/abs/2504.10011"}
{"created":"2025-04-15","title":"EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting","abstract":"While 3D Gaussian Splatting (3D-GS) achieves photorealistic novel view synthesis, its performance degrades with motion blur. In scenarios with rapid motion or low-light conditions, existing RGB-based deblurring methods struggle to model camera pose and radiance changes during exposure, reducing reconstruction accuracy. Event cameras, capturing continuous brightness changes during exposure, can effectively assist in modeling motion blur and improving reconstruction quality. Therefore, we propose Event-driven Bundle Adjusted Deblur Gaussian Splatting (EBAD-Gaussian), which reconstructs sharp 3D Gaussians from event streams and severely blurred images. This method jointly learns the parameters of these Gaussians while recovering camera motion trajectories during exposure time. Specifically, we first construct a blur loss function by synthesizing multiple latent sharp images during the exposure time, minimizing the difference between real and synthesized blurred images. Then we use event stream to supervise the light intensity changes between latent sharp images at any time within the exposure period, supplementing the light intensity dynamic changes lost in RGB images. Furthermore, we optimize the latent sharp images at intermediate exposure times based on the event-based double integral (EDI) prior, applying consistency constraints to enhance the details and texture information of the reconstructed images. Extensive experiments on synthetic and real-world datasets show that EBAD-Gaussian can achieve high-quality 3D scene reconstruction under the condition of blurred images and event stream inputs.","authors":["Yufei Deng","Yuanjian Wang","Rong Xiao","Chenwei Tang","Jizhe Zhou","Jiahao Fan","Deng Xiong","Jiancheng Lv","Huajin Tang"],"url":"https://arxiv.org/abs/2504.10012"}
{"created":"2025-04-15","title":"Training LLMs on HPC Systems: Best Practices from the OpenGPT-X Project","abstract":"The training of large language models (LLMs) requires substantial computational resources, complex software stacks, and carefully designed workflows to achieve scalability and efficiency. This report presents best practices and insights gained from the OpenGPT-X project, a German initiative focused on developing open, multilingual LLMs optimized for European languages. We detail the use of high-performance computing (HPC) systems, primarily JUWELS Booster at JSC, for training Teuken-7B, a 7-billion-parameter transformer model. The report covers system architecture, training infrastructure, software choices, profiling and benchmarking tools, as well as engineering and operational challenges.","authors":["Carolin Penke","Chelsea Maria John","Jan Ebert","Stefan Kesselheim","Andreas Herten"],"url":"https://arxiv.org/abs/2504.10013"}
{"created":"2025-04-15","title":"Air Quality Prediction with A Meteorology-Guided Modality-Decoupled Spatio-Temporal Network","abstract":"Air quality prediction plays a crucial role in public health and environmental protection. Accurate air quality prediction is a complex multivariate spatiotemporal problem, that involves interactions across temporal patterns, pollutant correlations, spatial station dependencies, and particularly meteorological influences that govern pollutant dispersion and chemical transformations. Existing works underestimate the critical role of atmospheric conditions in air quality prediction and neglect comprehensive meteorological data utilization, thereby impairing the modeling of dynamic interdependencies between air quality and meteorological data. To overcome this, we propose MDSTNet, an encoder-decoder framework that explicitly models air quality observations and atmospheric conditions as distinct modalities, integrating multi-pressure-level meteorological data and weather forecasts to capture atmosphere-pollution dependencies for prediction. Meantime, we construct ChinaAirNet, the first nationwide dataset combining air quality records with multi-pressure-level meteorological observations. Experimental results on ChinaAirNet demonstrate MDSTNet's superiority, substantially reducing 48-hour prediction errors by 17.54\\% compared to the state-of-the-art model. The source code and dataset will be available on github.","authors":["Hang Yin","Yan-Ming Zhang","Jian Xu","Jian-Long Chang","Yin Li","Cheng-Lin Liu"],"url":"https://arxiv.org/abs/2504.10014"}
{"created":"2025-04-15","title":"Quantifying Privacy Leakage in Split Inference via Fisher-Approximated Shannon Information Analysis","abstract":"Split inference (SI) partitions deep neural networks into distributed sub-models, enabling privacy-preserving collaborative learning. Nevertheless, it remains vulnerable to Data Reconstruction Attacks (DRAs), wherein adversaries exploit exposed smashed data to reconstruct raw inputs. Despite extensive research on adversarial attack-defense games, a shortfall remains in the fundamental analysis of privacy risks. This paper establishes a theoretical framework for privacy leakage quantification using information theory, defining it as the adversary's certainty and deriving both average-case and worst-case error bounds. We introduce Fisher-approximated Shannon information (FSInfo), a novel privacy metric utilizing Fisher Information (FI) for operational privacy leakage computation. We empirically show that our privacy metric correlates well with empirical attacks and investigate some of the factors that affect privacy leakage, namely the data distribution, model size, and overfitting.","authors":["Ruijun Deng","Zhihui Lu","Qiang Duan"],"url":"https://arxiv.org/abs/2504.10016"}
{"created":"2025-04-15","title":"RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset and An Asymmetric RWKV Fusion Framework","abstract":"Existing pedestrian attribute recognition methods are generally developed based on RGB frame cameras. However, these approaches are constrained by the limitations of RGB cameras, such as sensitivity to lighting conditions and motion blur, which hinder their performance. Furthermore, current attribute recognition primarily focuses on analyzing pedestrians' external appearance and clothing, lacking an exploration of emotional dimensions. In this paper, we revisit these issues and propose a novel multi-modal RGB-Event attribute recognition task by drawing inspiration from the advantages of event cameras in low-light, high-speed, and low-power consumption. Specifically, we introduce the first large-scale multi-modal pedestrian attribute recognition dataset, termed EventPAR, comprising 100K paired RGB-Event samples that cover 50 attributes related to both appearance and six human emotions, diverse scenes, and various seasons. By retraining and evaluating mainstream PAR models on this dataset, we establish a comprehensive benchmark and provide a solid foundation for future research in terms of data and algorithmic baselines. In addition, we propose a novel RWKV-based multi-modal pedestrian attribute recognition framework, featuring an RWKV visual encoder and an asymmetric RWKV fusion module. Extensive experiments are conducted on our proposed dataset as well as two simulated datasets (MARS-Attribute and DukeMTMC-VID-Attribute), achieving state-of-the-art results. The source code and dataset will be released on https://github.com/Event-AHU/OpenPAR","authors":["Xiao Wang","Haiyang Wang","Shiao Wang","Qiang Chen","Jiandong Jin","Haoyu Song","Bo Jiang","Chenglong Li"],"url":"https://arxiv.org/abs/2504.10018"}
{"created":"2025-04-15","title":"The Mirage of Performance Gains: Why Contrastive Decoding Fails to Address Multimodal Hallucination","abstract":"Contrastive decoding strategies are widely used to reduce hallucinations in multimodal large language models (MLLMs). These methods work by constructing contrastive samples to induce hallucinations and then suppressing them in the output distribution. However, this paper demonstrates that such approaches fail to effectively mitigate the hallucination problem. The performance improvements observed on POPE Benchmark are largely driven by two misleading factors: (1) crude, unidirectional adjustments to the model's output distribution and (2) the adaptive plausibility constraint, which reduces the sampling strategy to greedy search. To further illustrate these issues, we introduce a series of spurious improvement methods and evaluate their performance against contrastive decoding techniques. Experimental results reveal that the observed performance gains in contrastive decoding are entirely unrelated to its intended goal of mitigating hallucinations. Our findings challenge common assumptions about the effectiveness of contrastive decoding strategies and pave the way for developing genuinely effective solutions to hallucinations in MLLMs.","authors":["Hao Yin","Gunagzong Si","Zilei Wang"],"url":"https://arxiv.org/abs/2504.10020"}
{"created":"2025-04-15","title":"Masked Autoencoder Self Pre-Training for Defect Detection in Microelectronics","abstract":"Whereas in general computer vision, transformer-based architectures have quickly become the gold standard, microelectronics defect detection still heavily relies on convolutional neural networks (CNNs). We hypothesize that this is due to the fact that a) transformers have an increased need for data and b) labelled image generation procedures for microelectronics are costly, and labelled data is therefore sparse. Whereas in other domains, pre-training on large natural image datasets can mitigate this problem, in microelectronics transfer learning is hindered due to the dissimilarity of domain data and natural images. Therefore, we evaluate self pre-training, where models are pre-trained on the target dataset, rather than another dataset. We propose a vision transformer (ViT) pre-training framework for defect detection in microelectronics based on masked autoencoders (MAE). In MAE, a large share of image patches is masked and reconstructed by the model during pre-training. We perform pre-training and defect detection using a dataset of less than 10.000 scanning acoustic microscopy (SAM) images labelled using transient thermal analysis (TTA). Our experimental results show that our approach leads to substantial performance gains compared to a) supervised ViT, b) ViT pre-trained on natural image datasets, and c) state-of-the-art CNN-based defect detection models used in the literature. Additionally, interpretability analysis reveals that our self pre-trained models, in comparison to ViT baselines, correctly focus on defect-relevant features such as cracks in the solder material. This demonstrates that our approach yields fault-specific feature representations, making our self pre-trained models viable for real-world defect detection in microelectronics.","authors":["Nikolai R\\\"ohrich (XITASO GmbH","LMU Munich)","Alwin Hoffmann (XITASO GmbH)","Richard Nordsieck (XITASO GmbH)","Emilio Zarbali (XITASO GmbH)","Alireza Javanmardi (LMU Munich","Munich Center for Machine Learning)"],"url":"https://arxiv.org/abs/2504.10021"}
{"created":"2025-04-15","title":"Relative Illumination Fields: Learning Medium and Light Independent Underwater Scenes","abstract":"We address the challenge of constructing a consistent and photorealistic Neural Radiance Field in inhomogeneously illuminated, scattering environments with unknown, co-moving light sources. While most existing works on underwater scene representation focus on a static homogeneous illumination, limited attention has been paid to scenarios such as when a robot explores water deeper than a few tens of meters, where sunlight becomes insufficient. To address this, we propose a novel illumination field locally attached to the camera, enabling the capture of uneven lighting effects within the viewing frustum. We combine this with a volumetric medium representation to an overall method that effectively handles interaction between dynamic illumination field and static scattering medium. Evaluation results demonstrate the effectiveness and flexibility of our approach.","authors":["Mengkun She","Felix Seegr\\\"aber","David Nakath","Patricia Sch\\\"ontag","Kevin K\\\"oser"],"url":"https://arxiv.org/abs/2504.10024"}
{"created":"2025-04-15","title":"An efffcient numerical scheme for two-dimensional nonlinear time fractional Schr\\\"odinger equation","abstract":"In this paper, a linearized fully discrete scheme is proposed to solve the two-dimensional nonlinear time fractional Schr\\\"odinger equation with weakly singular solutions, which is constructed by using L1 scheme for Caputo fractional derivative, backward formula for the approximation of nonlinear term and five-point difference scheme in space. We rigorously prove the unconditional stability and pointwise-in-time convergence of the fully discrete scheme, which does not require any restriction on the grid ratio. Numerical results are presented to verify the accuracy of the theoretical analysis.","authors":["Jun Ma","Tao Sun","Hu Chen"],"url":"https://arxiv.org/abs/2504.10026"}
{"created":"2025-04-15","title":"EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical Challenge in Multi-Robot Control","abstract":"This paper introduces EmbodiedAgent, a hierarchical framework for heterogeneous multi-robot control. EmbodiedAgent addresses critical limitations of hallucination in impractical tasks. Our approach integrates a next-action prediction paradigm with a structured memory system to decompose tasks into executable robot skills while dynamically validating actions against environmental constraints. We present MultiPlan+, a dataset of more than 18,000 annotated planning instances spanning 100 scenarios, including a subset of impractical cases to mitigate hallucination. To evaluate performance, we propose the Robot Planning Assessment Schema (RPAS), combining automated metrics with LLM-aided expert grading. Experiments demonstrate EmbodiedAgent's superiority over state-of-the-art models, achieving 71.85% RPAS score. Real-world validation in an office service task highlights its ability to coordinate heterogeneous robots for long-horizon objectives.","authors":["Hanwen Wan","Yifei Chen","Zeyu Wei","Dongrui Li","Zexin Lin","Donghao Wu","Jiu Cheng","Yuxiang Zhang","Xiaoqiang Ji"],"url":"https://arxiv.org/abs/2504.10030"}
{"created":"2025-04-15","title":"Using Reinforcement Learning to Integrate Subjective Wellbeing into Climate Adaptation Decision Making","abstract":"Subjective wellbeing is a fundamental aspect of human life, influencing life expectancy and economic productivity, among others. Mobility plays a critical role in maintaining wellbeing, yet the increasing frequency and intensity of both nuisance and high-impact floods due to climate change are expected to significantly disrupt access to activities and destinations, thereby affecting overall wellbeing. Addressing climate adaptation presents a complex challenge for policymakers, who must select and implement policies from a broad set of options with varying effects while managing resource constraints and uncertain climate projections. In this work, we propose a multi-modular framework that uses reinforcement learning as a decision-support tool for climate adaptation in Copenhagen, Denmark. Our framework integrates four interconnected components: long-term rainfall projections, flood modeling, transport accessibility, and wellbeing modeling. This approach enables decision-makers to identify spatial and temporal policy interventions that help sustain or enhance subjective wellbeing over time. By modeling climate adaptation as an open-ended system, our framework provides a structured framework for exploring and evaluating adaptation policy pathways. In doing so, it supports policymakers to make informed decisions that maximize wellbeing in the long run.","authors":["Arthur Vandervoort","Miguel Costa","Morten W. Petersen","Martin Drews","Sonja Haustein","Karyn Morrissey","Francisco C. Pereira"],"url":"https://arxiv.org/abs/2504.10031"}
{"created":"2025-04-15","title":"TT3D: Table Tennis 3D Reconstruction","abstract":"Sports analysis requires processing large amounts of data, which is time-consuming and costly. Advancements in neural networks have significantly alleviated this burden, enabling highly accurate ball tracking in sports broadcasts. However, relying solely on 2D ball tracking is limiting, as it depends on the camera's viewpoint and falls short of supporting comprehensive game analysis. To address this limitation, we propose a novel approach for reconstructing precise 3D ball trajectories from online table tennis match recordings. Our method leverages the underlying physics of the ball's motion to identify the bounce state that minimizes the reprojection error of the ball's flying trajectory, hence ensuring an accurate and reliable 3D reconstruction. A key advantage of our approach is its ability to infer ball spin without relying on human pose estimation or racket tracking, which are often unreliable or unavailable in broadcast footage. We developed an automated camera calibration method capable of reliably tracking camera movements. Additionally, we adapted an existing 3D pose estimation model, which lacks depth motion capture, to accurately track player movements. Together, these contributions enable the full 3D reconstruction of a table tennis rally.","authors":["Thomas Gossard","Andreas Ziegler","Andreas Zell"],"url":"https://arxiv.org/abs/2504.10035"}
{"created":"2025-04-15","title":"DataMosaic: Explainable and Verifiable Multi-Modal Data Analytics through Extract-Reason-Verify","abstract":"Large Language Models (LLMs) are transforming data analytics, but their widespread adoption is hindered by two critical limitations: they are not explainable (opaque reasoning processes) and not verifiable (prone to hallucinations and unchecked errors). While retrieval-augmented generation (RAG) improves accuracy by grounding LLMs in external data, it fails to address the core challenges of trustworthy analytics - especially when processing noisy, inconsistent, or multi-modal data (for example, text, tables, images). We propose DataMosaic, a framework designed to make LLM-powered analytics both explainable and verifiable. By dynamically extracting task-specific structures (for example, tables, graphs, trees) from raw data, DataMosaic provides transparent, step-by-step reasoning traces and enables validation of intermediate results. Built on a multi-agent framework, DataMosaic orchestrates self-adaptive agents that align with downstream task requirements, enhancing consistency, completeness, and privacy. Through this approach, DataMosaic not only tackles the limitations of current LLM-powered analytics systems but also lays the groundwork for a new paradigm of grounded, accurate, and explainable multi-modal data analytics.","authors":["Zhengxuan Zhang","Zhuowen Liang","Yin Wu","Teng Lin","Yuyu Luo","Nan Tang"],"url":"https://arxiv.org/abs/2504.10036"}
{"created":"2025-04-15","title":"Investigating the Role of Bilateral Symmetry for Inpainting Brain MRI","abstract":"Inpainting has recently emerged as a valuable and interesting technology to employ in the analysis of medical imaging data, in particular brain MRI. A wide variety of methodologies for inpainting MRI have been proposed and demonstrated on tasks including anomaly detection. In this work we investigate the statistical relationship between inpainted brain structures and the amount of subject-specific conditioning information, i.e. the other areas of the image that are masked. In particular, we analyse the distribution of inpainting results when masking additional regions of the image, specifically the contra-lateral structure. This allows us to elucidate where in the brain the model is drawing information from, and in particular, what is the importance of hemispherical symmetry? Our experiments interrogate a diffusion inpainting model through analysing the inpainting of subcortical brain structures based on intensity and estimated area change. We demonstrate that some structures show a strong influence of symmetry in the conditioning of the inpainting process.","authors":["Sergey Kuznetsov","Sanduni Pinnawala","Peter A. Wijeratne","Ivor J. A. Simpson"],"url":"https://arxiv.org/abs/2504.10039"}
{"created":"2025-04-15","title":"Prior Does Matter: Visual Navigation via Denoising Diffusion Bridge Models","abstract":"Recent advancements in diffusion-based imitation learning, which show impressive performance in modeling multimodal distributions and training stability, have led to substantial progress in various robot learning tasks. In visual navigation, previous diffusion-based policies typically generate action sequences by initiating from denoising Gaussian noise. However, the target action distribution often diverges significantly from Gaussian noise, leading to redundant denoising steps and increased learning complexity. Additionally, the sparsity of effective action distributions makes it challenging for the policy to generate accurate actions without guidance. To address these issues, we propose a novel, unified visual navigation framework leveraging the denoising diffusion bridge models named NaviBridger. This approach enables action generation by initiating from any informative prior actions, enhancing guidance and efficiency in the denoising process. We explore how diffusion bridges can enhance imitation learning in visual navigation tasks and further examine three source policies for generating prior actions. Extensive experiments in both simulated and real-world indoor and outdoor scenarios demonstrate that NaviBridger accelerates policy inference and outperforms the baselines in generating target action sequences. Code is available at https://github.com/hren20/NaiviBridger.","authors":["Hao Ren","Yiming Zeng","Zetong Bi","Zhaoliang Wan","Junlong Huang","Hui Cheng"],"url":"https://arxiv.org/abs/2504.10041"}
{"created":"2025-04-15","title":"Aligning Anime Video Generation with Human Feedback","abstract":"Anime video generation faces significant challenges due to the scarcity of anime data and unusual motion patterns, leading to issues such as motion distortion and flickering artifacts, which result in misalignment with human preferences. Existing reward models, designed primarily for real-world videos, fail to capture the unique appearance and consistency requirements of anime. In this work, we propose a pipeline to enhance anime video generation by leveraging human feedback for better alignment. Specifically, we construct the first multi-dimensional reward dataset for anime videos, comprising 30k human-annotated samples that incorporating human preferences for both visual appearance and visual consistency. Based on this, we develop AnimeReward, a powerful reward model that employs specialized vision-language models for different evaluation dimensions to guide preference alignment. Furthermore, we introduce Gap-Aware Preference Optimization (GAPO), a novel training method that explicitly incorporates preference gaps into the optimization process, enhancing alignment performance and efficiency. Extensive experiment results show that AnimeReward outperforms existing reward models, and the inclusion of GAPO leads to superior alignment in both quantitative benchmarks and human evaluations, demonstrating the effectiveness of our pipeline in enhancing anime video quality. Our dataset and code will be publicly available.","authors":["Bingwen Zhu","Yudong Jiang","Baohan Xu","Siqian Yang","Mingyu Yin","Yidi Wu","Huyang Sun","Zuxuan Wu"],"url":"https://arxiv.org/abs/2504.10044"}
{"created":"2025-04-15","title":"CHARM: Calibrating Reward Models With Chatbot Arena Scores","abstract":"Reward models (RMs) play a crucial role in Reinforcement Learning from Human Feedback by serving as proxies for human preferences in aligning large language models. In this paper, we identify a model preference bias in RMs, where they systematically assign disproportionately high scores to responses from certain policy models. This bias distorts ranking evaluations and leads to unfair judgments. To address this issue, we propose a calibration method named CHatbot Arena calibrated Reward Modeling (CHARM) that leverages Elo scores from the Chatbot Arena leaderboard to mitigate RM overvaluation. We also introduce a Mismatch Degree metric to measure this preference bias. Our approach is computationally efficient, requiring only a small preference dataset for continued training of the RM. We conduct extensive experiments on reward model benchmarks and human preference alignment. Results demonstrate that our calibrated RMs (1) achieve improved evaluation accuracy on RM-Bench and the Chat-Hard domain of RewardBench, and (2) exhibit a stronger correlation with human preferences by producing scores more closely aligned with Elo rankings. By mitigating model preference bias, our method provides a generalizable and efficient solution for building fairer and more reliable reward models.","authors":["Xiao Zhu","Chenmien Tan","Pinzhen Chen","Rico Sennrich","Yanlin Zhang","Hanxu Hu"],"url":"https://arxiv.org/abs/2504.10045"}
{"created":"2025-04-15","title":"CodeRAG: Supportive Code Retrieval on Bigraph for Real-World Code Generation","abstract":"Large language models (LLMs) have shown promising performance in automated code generation, especially excelling in simple tasks such as generating standalone codes. Different from simple tasks, real-world code generation usually depends on specific programming environment (e.g., code repositories). It contains complex dependencies and domain knowledge, which is needed for LLMs when generating target code snippets. In this paper, we propose CodeRAG, a retrieval-augmented code generation (RAG) framework to comprehensively retrieve supportive codes for real-world code generation. Beginning with the requirement, CodeRAG first constructs a requirement graph for the current repository, and retrieves sub- and similar- requirement nodes of the target requirement on the graph. Meanwhile, it models the repository into a DS-code graph. CodeRAG then maps these relevant requirement nodes into their corresponding code nodes, and treats these code nodes as archors for LLM reasoning on DS-code graph. Finally, CodeRAG introduces a code-oriented agentic reasoning process, seamlessly allowing LLMs to reason and comprehensively retrieve for supportive codes which LLMs' need for generating correct programs. Experiments show that CodeRAG achieves significant improvements (i.e., increasing 40.90 and 37.79 Pass@1 on GPT-4o and Gemini-Pro on DevEval) compared to no RAG scenarios. Further tests on reasoning LLMs (i.e., QwQ-32B) confirm CodeRAG's adaptability and efficacy across various types of LLMs. In addition, CodeRAG outperforms commercial programming products such as Copilit and Cursor. We further investigate the performance of our framework on different dependency types, and observe that CodeRAG is superior in generating examples where target codes invoke predefined cross-file code snippets. These results demonstrate CodeRAG's potential in solving real-world repo-level coding challenges.","authors":["Jia Li","Xianjie Shi","Kechi Zhang","Lei Li","Ge Li","Zhengwei Tao","Jia Li","Fang Liu","Chongyang Tao","Zhi Jin"],"url":"https://arxiv.org/abs/2504.10046"}
{"created":"2025-04-15","title":"Multi-Object Grounding via Hierarchical Contrastive Siamese Transformers","abstract":"Multi-object grounding in 3D scenes involves localizing multiple objects based on natural language input. While previous work has primarily focused on single-object grounding, real-world scenarios often demand the localization of several objects. To tackle this challenge, we propose Hierarchical Contrastive Siamese Transformers (H-COST), which employs a Hierarchical Processing strategy to progressively refine object localization, enhancing the understanding of complex language instructions. Additionally, we introduce a Contrastive Siamese Transformer framework, where two networks with the identical structure are used: one auxiliary network processes robust object relations from ground-truth labels to guide and enhance the second network, the reference network, which operates on segmented point-cloud data. This contrastive mechanism strengthens the model' s semantic understanding and significantly enhances its ability to process complex point-cloud data. Our approach outperforms previous state-of-the-art methods by 9.5% on challenging multi-object grounding benchmarks.","authors":["Chengyi Du","Keyan Jin"],"url":"https://arxiv.org/abs/2504.10048"}
{"created":"2025-04-15","title":"Summarization of Multimodal Presentations with Vision-Language Models: Study of the Effect of Modalities and Structure","abstract":"Vision-Language Models (VLMs) can process visual and textual information in multiple formats: texts, images, interleaved texts and images, or even hour-long videos. In this work, we conduct fine-grained quantitative and qualitative analyses of automatic summarization of multimodal presentations using VLMs with various representations as input. From these experiments, we suggest cost-effective strategies for generating summaries from text-heavy multimodal documents under different input-length budgets using VLMs. We show that slides extracted from the video stream can be beneficially used as input against the raw video, and that a structured representation from interleaved slides and transcript provides the best performance. Finally, we reflect and comment on the nature of cross-modal interactions in multimodal presentations and share suggestions to improve the capabilities of VLMs to understand documents of this nature.","authors":["Th\\'eo Gigant","Camille Guinaudeau","Fr\\'ed\\'eric Dufaux"],"url":"https://arxiv.org/abs/2504.10049"}
{"created":"2025-04-15","title":"Emotional Strain and Frustration in LLM Interactions in Software Engineering","abstract":"Large Language Models (LLMs) are increasingly integrated into various daily tasks in Software Engineering such as coding and requirement elicitation. Despite their various capabilities and constant use, some interactions can lead to unexpected challenges (e.g. hallucinations or verbose answers) and, in turn, cause emotions that develop into frustration. Frustration can negatively impact engineers' productivity and well-being if they escalate into stress and burnout. In this paper, we assess the impact of LLM interactions on software engineers' emotional responses, specifically strains, and identify common causes of frustration when interacting with LLMs at work. Based on 62 survey responses from software engineers in industry and academia across various companies and universities, we found that a majority of our respondents experience frustrations or other related emotions regardless of the nature of their work. Additionally, our results showed that frustration mainly stemmed from issues with correctness and less critical issues such as adaptability to context or specific format. While such issues may not cause frustration in general, artefacts that do not follow certain preferences, standards, or best practices can make the output unusable without extensive modification, causing frustration over time. In addition to the frustration triggers, our study offers guidelines to improve the software engineers' experience, aiming to minimise long-term consequences on mental health.","authors":["Cristina Martinez Montes","Ranim Khojah"],"url":"https://arxiv.org/abs/2504.10050"}
{"created":"2025-04-15","title":"Synthetic Biology meets Neuromorphic Computing: Towards a bio-inspired Olfactory Perception System","abstract":"In this study, we explore how the combination of synthetic biology, neuroscience modeling, and neuromorphic electronic systems offers a new approach to creating an artificial system that mimics the natural sense of smell. We argue that a co-design approach offers significant advantages in replicating the complex dynamics of odor sensing and processing. We investigate a hybrid system of synthetic sensory neurons that provides three key features: a) receptor-gated ion channels, b) interface between synthetic biology and semiconductors and c) event-based encoding and computing based on spiking networks. This research seeks to develop a platform for ultra-sensitive, specific, and energy-efficient odor detection, with potential implications for environmental monitoring, medical diagnostics, and security.","authors":["Kevin Max","Larissa Sames","Shimeng Ye","Jan Steink\\\"uhler","Federico Corradi"],"url":"https://arxiv.org/abs/2504.10053"}
{"created":"2025-04-15","title":"Implementation and Performance Evaluation of TCP over QUIC Tunnels","abstract":"QUIC, a UDP-based transport protocol, addresses several limitations of TCP by offering built-in encryption, stream multiplexing, and improved loss recovery. To extend these benefits to legacy TCP-based applications, this paper explores the implementation and evaluation of a TCP over QUIC tunneling approach. A lightweight, stream-based tunnel is constructed using the Rust-based Quinn library, enabling TCP traffic to traverse QUIC connections transparently. Performance is evaluated under varying network conditions, including packet loss, high latency, and out-of-order delivery. Results indicate that TCP over QUIC maintains significantly higher throughput than native TCP in lossy or unstable environments, with up to a high improvement under 20\\% packet loss. However, under ideal network conditions, tunneling introduces modest overhead due to encryption and user-space processing. These findings provide insights into the trade-offs of TCP over QUIC tunneling and its suitability for deployment in dynamic or impaired networks.","authors":["Xuanhong Guo","Zekun Bao","Ying Chen"],"url":"https://arxiv.org/abs/2504.10054"}
{"created":"2025-04-15","title":"Joint Action Language Modelling for Transparent Policy Execution","abstract":"An agent's intention often remains hidden behind the black-box nature of embodied policies. Communication using natural language statements that describe the next action can provide transparency towards the agent's behavior. We aim to insert transparent behavior directly into the learning process, by transforming the problem of policy learning into a language generation problem and combining it with traditional autoregressive modelling. The resulting model produces transparent natural language statements followed by tokens representing the specific actions to solve long-horizon tasks in the Language-Table environment. Following previous work, the model is able to learn to produce a policy represented by special discretized tokens in an autoregressive manner. We place special emphasis on investigating the relationship between predicting actions and producing high-quality language for a transparent agent. We find that in many cases both the quality of the action trajectory and the transparent statement increase when they are generated simultaneously.","authors":["Theodor Wulff","Rahul Singh Maharjan","Xinyun Chi","Angelo Cangelosi"],"url":"https://arxiv.org/abs/2504.10055"}
{"created":"2025-04-15","title":"Data Cooperatives: Democratic Models for Ethical Data Stewardship","abstract":"Data cooperatives offer a new model for fair data governance, enabling individuals to collectively control, manage, and benefit from their information while adhering to cooperative principles such as democratic member control, economic participation, and community concern. This paper reviews data cooperatives, distinguishing them from models like data trusts, data commons, and data unions, and defines them based on member ownership, democratic governance, and data sovereignty. It explores applications in sectors like healthcare, agriculture, and construction. Despite their potential, data cooperatives face challenges in coordination, scalability, and member engagement, requiring innovative governance strategies, robust technical systems, and mechanisms to align member interests with cooperative goals. The paper concludes by advocating for data cooperatives as a sustainable, democratic, and ethical model for the future data economy.","authors":["Francisco Mendonca","Giovanna DiMarzo","Nabil Abdennadher"],"url":"https://arxiv.org/abs/2504.10058"}
{"created":"2025-04-15","title":"Computing the unitary best approximant to the exponential function","abstract":"Unitary best approximation to the exponential function on an interval on the imaginary axis has been introduced recently. In the present work two algorithms are considered to compute this best approximant: an algorithm based on rational interpolation in successively corrected interpolation nodes and the AAA-Lawson method. Moreover, a posteriori bounds are introduced to evaluate the quality of a computed approximant and to show convergence to the unitary best approximant in practice. Two a priori estimates -- one based on experimental data, and one based on an asymptotic error estimate -- are introduced to determine the underlying frequency for which the unitary best approximant achieves a given accuracy. Performance of algorithms and estimates is verified by numerical experiments. In particular, the interpolation-based algorithm converges to the unitary best approximant within a small number of iterations in practice.","authors":["Tobias Jawecki"],"url":"https://arxiv.org/abs/2504.10062"}
{"created":"2025-04-15","title":"Hallucination Detection in LLMs via Topological Divergence on Attention Graphs","abstract":"Hallucination, i.e., generating factually incorrect content, remains a critical challenge for large language models (LLMs). We introduce TOHA, a TOpology-based HAllucination detector in the RAG setting, which leverages a topological divergence metric to quantify the structural properties of graphs induced by attention matrices. Examining the topological divergence between prompt and response subgraphs reveals consistent patterns: higher divergence values in specific attention heads correlate with hallucinated outputs, independent of the dataset. Extensive experiments, including evaluation on question answering and data-to-text tasks, show that our approach achieves state-of-the-art or competitive results on several benchmarks, two of which were annotated by us and are being publicly released to facilitate further research. Beyond its strong in-domain performance, TOHA maintains remarkable domain transferability across multiple open-source LLMs. Our findings suggest that analyzing the topological structure of attention matrices can serve as an efficient and robust indicator of factual reliability in LLMs.","authors":["Alexandra Bazarova","Aleksandr Yugay","Andrey Shulga","Alina Ermilova","Andrei Volodichev","Konstantin Polev","Julia Belikova","Rauf Parchiev","Dmitry Simakov","Maxim Savchenko","Andrey Savchenko","Serguei Barannikov","Alexey Zaytsev"],"url":"https://arxiv.org/abs/2504.10063"}
{"created":"2025-04-15","title":"A Computational Cognitive Model for Processing Repetitions of Hierarchical Relations","abstract":"Patterns are fundamental to human cognition, enabling the recognition of structure and regularity across diverse domains. In this work, we focus on structural repeats, patterns that arise from the repetition of hierarchical relations within sequential data, and develop a candidate computational model of how humans detect and understand such structural repeats. Based on a weighted deduction system, our model infers the minimal generative process of a given sequence in the form of a Template program, a formalism that enriches the context-free grammar with repetition combinators. Such representation efficiently encodes the repetition of sub-computations in a recursive manner. As a proof of concept, we demonstrate the expressiveness of our model on short sequences from music and action planning. The proposed model offers broader insights into the mental representations and cognitive mechanisms underlying human pattern recognition.","authors":["Zeng Ren","Xinyi Guan","Martin Rohrmeier"],"url":"https://arxiv.org/abs/2504.10065"}
{"created":"2025-04-15","title":"A Framework for Adaptive Load Redistribution in Human-Exoskeleton-Cobot Systems","abstract":"Wearable devices like exoskeletons are designed to reduce excessive loads on specific joints of the body. Specifically, single- or two-degrees-of-freedom (DOF) upper-body industrial exoskeletons typically focus on compensating for the strain on the elbow and shoulder joints. However, during daily activities, there is no assurance that external loads are correctly aligned with the supported joints. Optimizing work processes to ensure that external loads are primarily (to the extent that they can be compensated by the exoskeleton) directed onto the supported joints can significantly enhance the overall usability of these devices and the ergonomics of their users. Collaborative robots (cobots) can play a role in this optimization, complementing the collaborative aspects of human work. In this study, we propose an adaptive and coordinated control system for the human-cobot-exoskeleton interaction. This system adjusts the task coordinates to maximize the utilization of the supported joints. When the torque limits of the exoskeleton are exceeded, the framework continuously adapts the task frame, redistributing excessive loads to non-supported body joints to prevent overloading the supported ones. We validated our approach in an equivalent industrial painting task involving a single-DOF elbow exoskeleton, a cobot, and four subjects, each tested in four different initial arm configurations with five distinct optimisation weight matrices and two different payloads.","authors":["Emir Mobedi","Gokhan Solak","Arash Ajoudani"],"url":"https://arxiv.org/abs/2504.10066"}
{"created":"2025-04-15","title":"Undermining Federated Learning Accuracy in EdgeIoT via Variational Graph Auto-Encoders","abstract":"EdgeIoT represents an approach that brings together mobile edge computing with Internet of Things (IoT) devices, allowing for data processing close to the data source. Sending source data to a server is bandwidth-intensive and may compromise privacy. Instead, federated learning allows each device to upload a shared machine-learning model update with locally processed data. However, this technique, which depends on aggregating model updates from various IoT devices, is vulnerable to attacks from malicious entities that may inject harmful data into the learning process. This paper introduces a new attack method targeting federated learning in EdgeIoT, known as data-independent model manipulation attack. This attack does not rely on training data from the IoT devices but instead uses an adversarial variational graph auto-encoder (AV-GAE) to create malicious model updates by analyzing benign model updates intercepted during communication. AV-GAE identifies and exploits structural relationships between benign models and their training data features. By manipulating these structural correlations, the attack maximizes the training loss of the federated learning system, compromising its overall effectiveness.","authors":["Kai Li","Shuyan Hu","Bochun Wu","Sai Zou","Wei Ni","Falko Dressler"],"url":"https://arxiv.org/abs/2504.10067"}
{"created":"2025-04-15","title":"Mavors: Multi-granularity Video Representation for Multimodal Large Language Model","abstract":"Long-context video understanding in multimodal large language models (MLLMs) faces a critical challenge: balancing computational efficiency with the retention of fine-grained spatio-temporal patterns. Existing approaches (e.g., sparse sampling, dense sampling with low resolution, and token compression) suffer from significant information loss in temporal dynamics, spatial details, or subtle interactions, particularly in videos with complex motion or varying resolutions. To address this, we propose $\\mathbf{Mavors}$, a novel framework that introduces $\\mathbf{M}$ulti-gr$\\mathbf{a}$nularity $\\mathbf{v}$ide$\\mathbf{o}$ $\\mathbf{r}$epre$\\mathbf{s}$entation for holistic long-video modeling. Specifically, Mavors directly encodes raw video content into latent representations through two core components: 1) an Intra-chunk Vision Encoder (IVE) that preserves high-resolution spatial features via 3D convolutions and Vision Transformers, and 2) an Inter-chunk Feature Aggregator (IFA) that establishes temporal coherence across chunks using transformer-based dependency modeling with chunk-level rotary position encodings. Moreover, the framework unifies image and video understanding by treating images as single-frame videos via sub-image decomposition. Experiments across diverse benchmarks demonstrate Mavors' superiority in maintaining both spatial fidelity and temporal continuity, significantly outperforming existing methods in tasks requiring fine-grained spatio-temporal reasoning.","authors":["Yang Shi","Jiaheng Liu","Yushuo Guan","Zhenhua Wu","Yuanxing Zhang","Zihao Wang","Weihong Lin","Jingyun Hua","Zekun Wang","Xinlong Chen","Bohan Zeng","Wentao Zhang","Fuzheng Zhang","Wenjing Yang","Di Zhang"],"url":"https://arxiv.org/abs/2504.10068"}
{"created":"2025-04-15","title":"DTFSal: Audio-Visual Dynamic Token Fusion for Video Saliency Prediction","abstract":"Audio-visual saliency prediction aims to mimic human visual attention by identifying salient regions in videos through the integration of both visual and auditory information. Although visual-only approaches have significantly advanced, effectively incorporating auditory cues remains challenging due to complex spatio-temporal interactions and high computational demands. To address these challenges, we propose Dynamic Token Fusion Saliency (DFTSal), a novel audio-visual saliency prediction framework designed to balance accuracy with computational efficiency. Our approach features a multi-scale visual encoder equipped with two novel modules: the Learnable Token Enhancement Block (LTEB), which adaptively weights tokens to emphasize crucial saliency cues, and the Dynamic Learnable Token Fusion Block (DLTFB), which employs a shifting operation to reorganize and merge features, effectively capturing long-range dependencies and detailed spatial information. In parallel, an audio branch processes raw audio signals to extract meaningful auditory features. Both visual and audio features are integrated using our Adaptive Multimodal Fusion Block (AMFB), which employs local, global, and adaptive fusion streams for precise cross-modal fusion. The resulting fused features are processed by a hierarchical multi-decoder structure, producing accurate saliency maps. Extensive evaluations on six audio-visual benchmarks demonstrate that DFTSal achieves SOTA performance while maintaining computational efficiency.","authors":["Kiana Hoshanfar","Alireza Hosseini","Ahmad Kalhor","Babak Nadjar Araabi"],"url":"https://arxiv.org/abs/2504.10070"}
{"created":"2025-04-15","title":"Pay Attention to What and Where? Interpretable Feature Extractor in Vision-based Deep Reinforcement Learning","abstract":"Current approaches in Explainable Deep Reinforcement Learning have limitations in which the attention mask has a displacement with the objects in visual input. This work addresses a spatial problem within traditional Convolutional Neural Networks (CNNs). We propose the Interpretable Feature Extractor (IFE) architecture, aimed at generating an accurate attention mask to illustrate both \"what\" and \"where\" the agent concentrates on in the spatial domain. Our design incorporates a Human-Understandable Encoding module to generate a fully interpretable attention mask, followed by an Agent-Friendly Encoding module to enhance the agent's learning efficiency. These two components together form the Interpretable Feature Extractor for vision-based deep reinforcement learning to enable the model's interpretability. The resulting attention mask is consistent, highly understandable by humans, accurate in spatial dimension, and effectively highlights important objects or locations in visual input. The Interpretable Feature Extractor is integrated into the Fast and Data-efficient Rainbow framework, and evaluated on 57 ATARI games to show the effectiveness of the proposed approach on Spatial Preservation, Interpretability, and Data-efficiency. Finally, we showcase the versatility of our approach by incorporating the IFE into the Asynchronous Advantage Actor-Critic Model.","authors":["Tien Pham","Angelo Cangelosi"],"url":"https://arxiv.org/abs/2504.10071"}
{"created":"2025-04-15","title":"MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation Framework","abstract":"Recent advancements in large language models (LLMs) and multi-modal LLMs have been remarkable. However, these models still rely solely on their parametric knowledge, which limits their ability to generate up-to-date information and increases the risk of producing erroneous content. Retrieval-Augmented Generation (RAG) partially mitigates these challenges by incorporating external data sources, yet the reliance on databases and retrieval systems can introduce irrelevant or inaccurate documents, ultimately undermining both performance and reasoning quality. In this paper, we propose Multi-Modal Knowledge-Based Retrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework that leverages the inherent knowledge boundaries of models to dynamically generate semantic tags for the retrieval process. This strategy enables the joint filtering of retrieved documents, retaining only the most relevant and accurate references. Extensive experiments on knowledge-based visual question-answering tasks demonstrate the efficacy of our approach: on the E-VQA dataset, our method improves performance by +4.2\\% on the Single-Hop subset and +0.4\\% on the full dataset, while on the InfoSeek dataset, it achieves gains of +7.8\\% on the Unseen-Q subset, +8.2\\% on the Unseen-E subset, and +8.1\\% on the full dataset. These results highlight significant enhancements in both accuracy and robustness over the current state-of-the-art MLLM and RAG frameworks.","authors":["Zihan Ling","Zhiyao Guo","Yixuan Huang","Yi An","Shuai Xiao","Jinsong Lan","Xiaoyong Zhu","Bo Zheng"],"url":"https://arxiv.org/abs/2504.10074"}
{"created":"2025-04-15","title":"Towards Scalable Bayesian Optimization via Gradient-Informed Bayesian Neural Networks","abstract":"Bayesian optimization (BO) is a widely used method for data-driven optimization that generally relies on zeroth-order data of objective function to construct probabilistic surrogate models. These surrogates guide the exploration-exploitation process toward finding global optimum. While Gaussian processes (GPs) are commonly employed as surrogates of the unknown objective function, recent studies have highlighted the potential of Bayesian neural networks (BNNs) as scalable and flexible alternatives. Moreover, incorporating gradient observations into GPs, when available, has been shown to improve BO performance. However, the use of gradients within BNN surrogates remains unexplored. By leveraging automatic differentiation, gradient information can be seamlessly integrated into BNN training, resulting in more informative surrogates for BO. We propose a gradient-informed loss function for BNN training, effectively augmenting function observations with local gradient information. The effectiveness of this approach is demonstrated on well-known benchmarks in terms of improved BNN predictions and faster BO convergence as the number of decision variables increases.","authors":["Georgios Makrygiorgos","Joshua Hang Sai Ip","Ali Mesbah"],"url":"https://arxiv.org/abs/2504.10076"}
{"created":"2025-04-15","title":"Towards Quantifying Commonsense Reasoning with Mechanistic Insights","abstract":"Commonsense reasoning deals with the implicit knowledge that is well understood by humans and typically acquired via interactions with the world. In recent times, commonsense reasoning and understanding of various LLMs have been evaluated using text-based tasks. In this work, we argue that a proxy of this understanding can be maintained as a graphical structure that can further help to perform a rigorous evaluation of commonsense reasoning abilities about various real-world activities. We create an annotation scheme for capturing this implicit knowledge in the form of a graphical structure for 37 daily human activities. We find that the created resource can be used to frame an enormous number of commonsense queries (~ 10^{17}), facilitating rigorous evaluation of commonsense reasoning in LLMs. Moreover, recently, the remarkable performance of LLMs has raised questions about whether these models are truly capable of reasoning in the wild and, in general, how reasoning occurs inside these models. In this resource paper, we bridge this gap by proposing design mechanisms that facilitate research in a similar direction. Our findings suggest that the reasoning components are localized in LLMs that play a prominent role in decision-making when prompted with a commonsense query.","authors":["Abhinav Joshi","Areeb Ahmad","Divyaksh Shukla","Ashutosh Modi"],"url":"https://arxiv.org/abs/2504.10077"}
{"created":"2025-04-15","title":"Unleashing Expert Opinion from Social Media for Stock Prediction","abstract":"While stock prediction task traditionally relies on volume-price and fundamental data to predict the return ratio or price movement trend, sentiment factors derived from social media platforms such as StockTwits offer a complementary and useful source of real-time market information. However, we find that most social media posts, along with the public sentiment they reflect, provide limited value for trading predictions due to their noisy nature. To tackle this, we propose a novel dynamic expert tracing algorithm that filters out non-informative posts and identifies both true and inverse experts whose consistent predictions can serve as valuable trading signals. Our approach achieves significant improvements over existing expert identification methods in stock trend prediction. However, when using binary expert predictions to predict the return ratio, similar to all other expert identification methods, our approach faces a common challenge of signal sparsity with expert signals cover only about 4% of all stock-day combinations in our dataset. To address this challenge, we propose a dual graph attention neural network that effectively propagates expert signals across related stocks, enabling accurate prediction of return ratios and significantly increasing signal coverage. Empirical results show that our propagated expert-based signals not only exhibit strong predictive power independently but also work synergistically with traditional financial features. These combined signals significantly outperform representative baseline models in all quant-related metrics including predictive accuracy, return metrics, and correlation metrics, resulting in more robust investment strategies. We hope this work inspires further research into leveraging social media data for enhancing quantitative investment strategies. The code can be seen in https://github.com/wanyunzh/DualGAT.","authors":["Wanyun Zhou","Saizhuo Wang","Xiang Li","Yiyan Qi","Jian Guo","Xiaowen Chu"],"url":"https://arxiv.org/abs/2504.10078"}
{"created":"2025-04-15","title":"Hierarchical Relation-augmented Representation Generalization for Few-shot Action Recognition","abstract":"Few-shot action recognition (FSAR) aims to recognize novel action categories with few exemplars. Existing methods typically learn frame-level representations independently for each video by designing various inter-frame temporal modeling strategies. However, they neglect explicit relation modeling between videos and tasks, thus failing to capture shared temporal patterns across videos and reuse temporal knowledge from historical tasks. In light of this, we propose HR2G-shot, a Hierarchical Relation-augmented Representation Generalization framework for FSAR, which unifies three types of relation modeling (inter-frame, inter-video, and inter-task) to learn task-specific temporal patterns from a holistic view. In addition to conducting inter-frame temporal interactions, we further devise two components to respectively explore inter-video and inter-task relationships: i) Inter-video Semantic Correlation (ISC) performs cross-video frame-level interactions in a fine-grained manner, thereby capturing task-specific query features and learning intra- and inter-class temporal correlations among support features; ii) Inter-task Knowledge Transfer (IKT) retrieves and aggregates relevant temporal knowledge from the bank, which stores diverse temporal patterns from historical tasks. Extensive experiments on five benchmarks show that HR2G-shot outperforms current top-leading FSAR methods.","authors":["Hongyu Qu","Ling Xing","Rui Yan","Yazhou Yao","Guo-Sen Xie","Xiangbo Shu"],"url":"https://arxiv.org/abs/2504.10079"}
{"created":"2025-04-15","title":"Learning to Harmonize Cross-vendor X-ray Images by Non-linear Image Dynamics Correction","abstract":"In this paper, we explore how conventional image enhancement can improve model robustness in medical image analysis. By applying commonly used normalization methods to images from various vendors and studying their influence on model generalization in transfer learning, we show that the nonlinear characteristics of domain-specific image dynamics cannot be addressed by simple linear transforms. To tackle this issue, we reformulate the image harmonization task as an exposure correction problem and propose a method termed Global Deep Curve Estimation (GDCE) to reduce domain-specific exposure mismatch. GDCE performs enhancement via a pre-defined polynomial function and is trained with the help of a ``domain discriminator'', aiming to improve model transparency in downstream tasks compared to existing black-box methods.","authors":["Yucheng Lu","Shunxin Wang","Dovile Juodelyte","Veronika Cheplygina"],"url":"https://arxiv.org/abs/2504.10080"}
{"created":"2025-04-15","title":"RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning Capability","abstract":"Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have been rapidly progressing and achieving breakthrough performance on complex reasoning tasks such as mathematics and coding. However, the open-source R1 models have raised safety concerns in wide applications, such as the tendency to comply with malicious queries, which greatly impacts the utility of these powerful models in their applications. In this paper, we introduce RealSafe-R1 as safety-aligned versions of DeepSeek-R1 distilled models. To train these models, we construct a dataset of 15k safety-aware reasoning trajectories generated by DeepSeek-R1, under explicit instructions for expected refusal behavior. Both quantitative experiments and qualitative case studies demonstrate the models' improvements, which are shown in their safety guardrails against both harmful queries and jailbreak attacks. Importantly, unlike prior safety alignment efforts that often compromise reasoning performance, our method preserves the models' reasoning capabilities by maintaining the training data within the original distribution of generation. Model weights of RealSafe-R1 are open-source at https://huggingface.co/RealSafe.","authors":["Yichi Zhang","Zihao Zeng","Dongbai Li","Yao Huang","Zhijie Deng","Yinpeng Dong"],"url":"https://arxiv.org/abs/2504.10081"}
{"created":"2025-04-15","title":"Leveraging Metaphors in a VR Serious Game for Computational Thinking","abstract":"This paper presents Cooking Code, a VR-based serious game designed to introduce programming concepts to students (ages 12-16) through an immersive, scenario-driven experience. Set in a futuristic world where humans and machines coexist, players take on the role of a fast-food chef who must assemble food orders based on pseudocode instructions. By interpreting and executing these instructions correctly, players develop problem-solving skills, computational thinking, and a foundational understanding of programming logic. The game leverages the kitchen metaphor to teach computational thinking, using affordances for an immersive VR experience.","authors":["I. Rodriguez","A. Puig"],"url":"https://arxiv.org/abs/2504.10082"}
{"created":"2025-04-15","title":"UP-Person: Unified Parameter-Efficient Transfer Learning for Text-based Person Retrieval","abstract":"Text-based Person Retrieval (TPR) as a multi-modal task, which aims to retrieve the target person from a pool of candidate images given a text description, has recently garnered considerable attention due to the progress of contrastive visual-language pre-trained model. Prior works leverage pre-trained CLIP to extract person visual and textual features and fully fine-tune the entire network, which have shown notable performance improvements compared to uni-modal pre-training models. However, full-tuning a large model is prone to overfitting and hinders the generalization ability. In this paper, we propose a novel Unified Parameter-Efficient Transfer Learning (PETL) method for Text-based Person Retrieval (UP-Person) to thoroughly transfer the multi-modal knowledge from CLIP. Specifically, UP-Person simultaneously integrates three lightweight PETL components including Prefix, LoRA and Adapter, where Prefix and LoRA are devised together to mine local information with task-specific information prompts, and Adapter is designed to adjust global feature representations. Additionally, two vanilla submodules are optimized to adapt to the unified architecture of TPR. For one thing, S-Prefix is proposed to boost attention of prefix and enhance the gradient propagation of prefix tokens, which improves the flexibility and performance of the vanilla prefix. For another thing, L-Adapter is designed in parallel with layer normalization to adjust the overall distribution, which can resolve conflicts caused by overlap and interaction among multiple submodules. Extensive experimental results demonstrate that our UP-Person achieves state-of-the-art results across various person retrieval datasets, including CUHK-PEDES, ICFG-PEDES and RSTPReid while merely fine-tuning 4.7\\% parameters. Code is available at https://github.com/Liu-Yating/UP-Person.","authors":["Yating Liu","Yaowei Li","Xiangyuan Lan","Wenming Yang","Zimo Liu","Qingmin Liao"],"url":"https://arxiv.org/abs/2504.10084"}
{"created":"2025-04-15","title":"Code size constraints in b-symbol read channels: A bound analysis","abstract":"In classical coding theory, error-correcting codes are designed to protect against errors occurring at individual symbol positions in a codeword. However, in practical storage and communication systems, errors often affect multiple adjacent symbols rather than single symbols independently. To address this, symbol-pair read channels were introduced \\cite{Yuval2011}, and later generalized to $b$-symbol read channels \\cite{yaakobi2016} to better model such error patterns. $b$-Symbol read channels generalize symbol-pair read channels to account for clustered errors in modern storage and communication systems. By developing bounds and efficient codes, researchers improve data reliability in applications such as storage devices, wireless networks, and DNA-based storage. Given integers $q$, $n$, $d$, and $b \\geq 2$, let $A_b(n,d,q)$ denote the largest possible code size for which there exists a $q$-ary code of length $n$ with minimum $b$-symbol distance at least $d$. In \\cite{chen2022}, various upper and lower bounds on $A_b(n,d,q)$ are given for $b=2$. In this paper, we generalize some of these bounds to the $b$-symbol read channels for $b>2$ and present several new bounds on $A_b(n,d,q)$. In particular, we establish the linear programming bound, a recurrence relation on $A_b(n,d,q)$, the Johnson bound (even), the restricted Johnson bound, the Gilbert-Varshamov-type bound, and the Elias bound for the metric of symbols $b$, $b\\geq 2$. Furthermore, we provide examples demonstrating that the Gilbert-Varshamov bound we establish offers a stronger lower bound than the one presented in \\cite{Song2018}. Additionally, we introduce an alternative approach to deriving the Sphere-packing and Plotkin bounds.","authors":["Gyanendra K. Verma","Nupur Patanker","Abhay Kumar Singh"],"url":"https://arxiv.org/abs/2504.10088"}
{"created":"2025-04-15","title":"Convergence Analysis of a Stochastic Interacting Particle-Field Algorithm for 3D Parabolic-Parabolic Keller-Segel Systems","abstract":"Chemotaxis models describe the movement of organisms in response to chemical gradients. In this paper, we present a stochastic interacting particle-field algorithm with random batch approximation (SIPF-$r$) for the three-dimensional (3D) parabolic-parabolic Keller-Segel (KS) system, also known as the fully parabolic KS system. The SIPF-$r$ method approximates the KS system by coupling particle-based representations of density with a smooth field variable computed using spectral methods. By incorporating the random batch method (RBM), we bypass the mean-field limit and significantly reduce computational complexity. Under mild assumptions on the regularity of the original KS system and the boundedness of numerical approximations, we prove that, with high probability, the empirical measure of the SIPF-$r$ particle system converges to the exact measure of the limiting McKean-Vlasov process in the $1$-Wasserstein distance. Numerical experiments validate the theoretical convergence rates and demonstrate the robustness and accuracy of the SIPF-$r$ method.","authors":["Boyi Hu","Zhongjian Wang","Jack Xin","Zhiwen Zhang"],"url":"https://arxiv.org/abs/2504.10089"}
{"created":"2025-04-15","title":"CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography","abstract":"Large language models (LLMs) and multimodal large language models (MLLMs) have significantly advanced artificial intelligence. However, visual reasoning, reasoning involving both visual and textual inputs, remains underexplored. Recent advancements, including the reasoning models like OpenAI o1 and Gemini 2.0 Flash Thinking, which incorporate image inputs, have opened this capability. In this ongoing work, we focus specifically on photography-related tasks because a photo is a visual snapshot of the physical world where the underlying physics (i.e., illumination, blur extent, etc.) interplay with the camera parameters. Successfully reasoning from the visual information of a photo to identify these numerical camera settings requires the MLLMs to have a deeper understanding of the underlying physics for precise visual comprehension, representing a challenging and intelligent capability essential for practical applications like photography assistant agents. We aim to evaluate MLLMs on their ability to distinguish visual differences related to numerical camera settings, extending a methodology previously proposed for vision-language models (VLMs). Our preliminary results demonstrate the importance of visual reasoning in photography-related tasks. Moreover, these results show that no single MLLM consistently dominates across all evaluation tasks, demonstrating ongoing challenges and opportunities in developing MLLMs with better visual reasoning.","authors":["I-Sheng Fang","Jun-Cheng Chen"],"url":"https://arxiv.org/abs/2504.10090"}
{"created":"2025-04-15","title":"Wasserstein convergence rates for stochastic particle approximation of Boltzmann models","abstract":"We establish quantitative convergence rates for stochastic particle approximation based on Nanbu-type Monte Carlo schemes applied to a broad class of collisional kinetic models. Using coupling techniques and stability estimates in the Wasserstein-1 (Kantorovich-Rubinstein) metric, we derive sharp error bounds that reflect the nonlinear interaction structure of the models. Our framework includes classical Nanbu Monte Carlo method and more recent developments as Time Relaxed Monte Carlo methods. The results bridge the gap between probabilistic particle approximations and deterministic numerical error analysis, and provide a unified perspective for the convergence theory of Monte Carlo methods for Boltzmann-type equations. As a by-product, we also obtain existence and uniqueness of solutions to a large class of Boltzmann-type equations.","authors":["Giacomo Borghi","Lorenzo Pareschi"],"url":"https://arxiv.org/abs/2504.10091"}
{"created":"2025-04-15","title":"Gradient modelling of memristive systems","abstract":"We introduce a gradient modeling framework for memristive systems. Our focus is on memristive systems as they appear in neurophysiology and neuromorphic systems. Revisiting the original definition of Chua, we regard memristive elements as gradient operators of quadratic functionals with respect to a metric determined by the memristance. We explore the consequences of gradient properties for the analysis and design of neuromorphic circuits.","authors":["Fulvio Forni","Rodolphe Sepulchre"],"url":"https://arxiv.org/abs/2504.10093"}
{"created":"2025-04-15","title":"STaRFormer: Semi-Supervised Task-Informed Representation Learning via Dynamic Attention-Based Regional Masking for Sequential Data","abstract":"Accurate predictions using sequential spatiotemporal data are crucial for various applications. Utilizing real-world data, we aim to learn the intent of a smart device user within confined areas of a vehicle's surroundings. However, in real-world scenarios, environmental factors and sensor limitations result in non-stationary and irregularly sampled data, posing significant challenges. To address these issues, we developed a Transformer-based approach, STaRFormer, which serves as a universal framework for sequential modeling. STaRFormer employs a novel, dynamic attention-based regional masking scheme combined with semi-supervised contrastive learning to enhance task-specific latent representations. Comprehensive experiments on 15 datasets varying in types (including non-stationary and irregularly sampled), domains, sequence lengths, training samples, and applications, demonstrate the efficacy and practicality of STaRFormer. We achieve notable improvements over state-of-the-art approaches. Code and data will be made available.","authors":["Maxmilian Forstenh\\\"ausler","Daniel K\\\"ulzer","Christos Anagnostopoulos","Shameem Puthiya Parambath","Natascha Weber"],"url":"https://arxiv.org/abs/2504.10097"}
{"created":"2025-04-15","title":"The Human Visual System Can Inspire New Interaction Paradigms for LLMs","abstract":"The dominant metaphor of LLMs-as-minds leads to misleading conceptions of machine agency and is limited in its ability to help both users and developers build the right degree of trust and understanding for outputs from LLMs. It makes it harder to disentangle hallucinations from useful model interactions. This position paper argues that there are fundamental similarities between visual perception and the way LLMs process and present language. These similarities inspire a metaphor for LLMs which could open new avenues for research into interaction paradigms and shared representations. Our visual system metaphor introduces possibilities for addressing these challenges by understanding the information landscape assimilated by LLMs. In this paper we motivate our proposal, introduce the interrelating theories from the fields that inspired this view and discuss research directions that stem from this abstraction.","authors":["Diana Robinson","Neil Lawrence"],"url":"https://arxiv.org/abs/2504.10101"}
{"created":"2025-04-15","title":"A Human-Sensitive Controller: Adapting to Human Ergonomics and Physical Constraints via Reinforcement Learning","abstract":"Work-Related Musculoskeletal Disorders continue to be a major challenge in industrial environments, leading to reduced workforce participation, increased healthcare costs, and long-term disability. This study introduces a human-sensitive robotic system aimed at reintegrating individuals with a history of musculoskeletal disorders into standard job roles, while simultaneously optimizing ergonomic conditions for the broader workforce. This research leverages reinforcement learning to develop a human-aware control strategy for collaborative robots, focusing on optimizing ergonomic conditions and preventing pain during task execution. Two RL approaches, Q-Learning and Deep Q-Network (DQN), were implemented and tested to personalize control strategies based on individual user characteristics. Although experimental results revealed a simulation-to-real gap, a fine-tuning phase successfully adapted the policies to real-world conditions. DQN outperformed Q-Learning by completing tasks faster while maintaining zero pain risk and safe ergonomic levels. The structured testing protocol confirmed the system's adaptability to diverse human anthropometries, underscoring the potential of RL-driven cobots to enable safer, more inclusive workplaces.","authors":["Vitor Martins (Center for MicroElectroMechanical Systems)","Sara M. Cerqueira (Center for MicroElectroMechanical Systems)","Mercedes Balcells (IMES","Massachusetts Institute of Technology","Cambridge","MA","USA","GEVAB","IQS School of Engineering","Barcelona","Spain)","Elazer R Edelman (IMES","Massachusetts Institute of Technology","Cambridge","MA","USA","Brigham and Women's Hospital","Harvard Medical School Boston","MA","USA)","Cristina P. Santos (Center for MicroElectroMechanical Systems","LABBELS-Associate Laboratory","University of Minho","Guimar\\~aes","Portugal)"],"url":"https://arxiv.org/abs/2504.10102"}
{"created":"2025-04-15","title":"Numerical approach for solving problems arising from polynomial analysis","abstract":"This paper deals with the use of numerical methods based on random root sampling techniques to solve some theoretical problems arising in the analysis of polynomials. These methods are proved to be practical and give solutions where traditional methods might fall short.","authors":["Yousra Gati","Vladimir Petrov Kostov","Mohamed Chaouki Tarchi"],"url":"https://arxiv.org/abs/2504.10103"}
{"created":"2025-04-15","title":"Global and Local Mamba Network for Multi-Modality Medical Image Super-Resolution","abstract":"Convolutional neural networks and Transformer have made significant progresses in multi-modality medical image super-resolution. However, these methods either have a fixed receptive field for local learning or significant computational burdens for global learning, limiting the super-resolution performance. To solve this problem, State Space Models, notably Mamba, is introduced to efficiently model long-range dependencies in images with linear computational complexity. Relying on the Mamba and the fact that low-resolution images rely on global information to compensate for missing details, while high-resolution reference images need to provide more local details for accurate super-resolution, we propose a global and local Mamba network (GLMamba) for multi-modality medical image super-resolution. To be specific, our GLMamba is a two-branch network equipped with a global Mamba branch and a local Mamba branch. The global Mamba branch captures long-range relationships in low-resolution inputs, and the local Mamba branch focuses more on short-range details in high-resolution reference images. We also use the deform block to adaptively extract features of both branches to enhance the representation ability. A modulator is designed to further enhance deformable features in both global and local Mamba blocks. To fully integrate the reference image for low-resolution image super-resolution, we further develop a multi-modality feature fusion block to adaptively fuse features by considering similarities, differences, and complementary aspects between modalities. In addition, a contrastive edge loss (CELoss) is developed for sufficient enhancement of edge textures and contrast in medical images.","authors":["Zexin Ji","Beiji Zou","Xiaoyan Kui","Sebastien Thureau","Su Ruan"],"url":"https://arxiv.org/abs/2504.10105"}
{"created":"2025-04-15","title":"SoccerNet-v3D: Leveraging Sports Broadcast Replays for 3D Scene Understanding","abstract":"Sports video analysis is a key domain in computer vision, enabling detailed spatial understanding through multi-view correspondences. In this work, we introduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasets designed for 3D scene understanding in soccer broadcast analysis. These datasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based camera calibration and multi-view synchronization, enabling 3D object localization through triangulation. We propose a monocular 3D ball localization task built upon the triangulation of ground-truth 2D ball annotations, along with several calibration and reprojection metrics to assess annotation quality on demand. Additionally, we present a single-image 3D ball localization method as a baseline, leveraging camera calibration and ball size priors to estimate the ball's position from a monocular viewpoint. To further refine 2D annotations, we introduce a bounding box optimization technique that ensures alignment with the 3D scene representation. Our proposed datasets establish new benchmarks for 3D soccer scene understanding, enhancing both spatial and temporal analysis in sports analytics. Finally, we provide code to facilitate access to our annotations and the generation pipelines for the datasets.","authors":["Marc Guti\\'errez-P\\'erez","Antonio Agudo"],"url":"https://arxiv.org/abs/2504.10106"}
{"created":"2025-04-15","title":"Enhancing LLM-based Recommendation through Semantic-Aligned Collaborative Knowledge","abstract":"Large Language Models (LLMs) demonstrate remarkable capabilities in leveraging comprehensive world knowledge and sophisticated reasoning mechanisms for recommendation tasks. However, a notable limitation lies in their inability to effectively model sparse identifiers (e.g., user and item IDs), unlike conventional collaborative filtering models (Collabs.), thus hindering LLM to learn distinctive user-item representations and creating a performance bottleneck. Prior studies indicate that integrating collaborative knowledge from Collabs. into LLMs can mitigate the above limitations and enhance their recommendation performance. Nevertheless, the significant discrepancy in knowledge distribution and semantic space between LLMs and Collab. presents substantial challenges for effective knowledge transfer. To tackle these challenges, we propose a novel framework, SeLLa-Rec, which focuses on achieving alignment between the semantic spaces of Collabs. and LLMs. This alignment fosters effective knowledge fusion, mitigating the influence of discriminative noise and facilitating the deep integration of knowledge from diverse models. Specifically, three special tokens with collaborative knowledge are embedded into the LLM's semantic space through a hybrid projection layer and integrated into task-specific prompts to guide the recommendation process. Experiments conducted on two public benchmark datasets (MovieLens-1M and Amazon Book) demonstrate that SeLLa-Rec achieves state-of-the-art performance.","authors":["Zihan Wang","Jinghao Lin","Xiaocui Yang","Yongkang Liu","Shi Feng","Daling Wang","Yifei Zhang"],"url":"https://arxiv.org/abs/2504.10107"}
{"created":"2025-04-15","title":"Lightweight Trustworthy Distributed Clustering","abstract":"Ensuring data trustworthiness within individual edge nodes while facilitating collaborative data processing poses a critical challenge in edge computing systems (ECS), particularly in resource-constrained scenarios such as autonomous systems sensor networks, industrial IoT, and smart cities. This paper presents a lightweight, fully distributed k-means clustering algorithm specifically adapted for edge environments, leveraging a distributed averaging approach with additive secret sharing, a secure multiparty computation technique, during the cluster center update phase to ensure the accuracy and trustworthiness of data across nodes.","authors":["Hongyang Li","Caesar Wu","Mohammed Chadli","Said Mammar","Pascal Bouvry"],"url":"https://arxiv.org/abs/2504.10109"}
{"created":"2025-04-15","title":"Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design","abstract":"Large Language Models (LLMs) have emerged as a powerful approach for driving offensive penetration-testing tooling. This paper analyzes the methodology and benchmarking practices used for evaluating Large Language Model (LLM)-driven attacks, focusing on offensive uses of LLMs in cybersecurity. We review 16 research papers detailing 15 prototypes and their respective testbeds.","authors":["Andreas Happe","J\\\"urgen Cito"],"url":"https://arxiv.org/abs/2504.10112"}
{"created":"2025-04-15","title":"Unveiling Contrastive Learning's Capability of Neighborhood Aggregation for Collaborative Filtering","abstract":"Personalized recommendation is widely used in the web applications, and graph contrastive learning (GCL) has gradually become a dominant approach in recommender systems, primarily due to its ability to extract self-supervised signals from raw interaction data, effectively alleviating the problem of data sparsity. A classic GCL-based method typically uses data augmentation during graph convolution to generates more contrastive views, and performs contrast on these new views to obtain rich self-supervised signals. Despite this paradigm is effective, the reasons behind the performance gains remain a mystery. In this paper, we first reveal via theoretical derivation that the gradient descent process of the CL objective is formally equivalent to graph convolution, which implies that CL objective inherently supports neighborhood aggregation on interaction graphs. We further substantiate this capability through experimental validation and identify common misconceptions in the selection of positive samples in previous methods, which limit the potential of CL objective. Based on this discovery, we propose the Light Contrastive Collaborative Filtering (LightCCF) method, which introduces a novel neighborhood aggregation objective to bring users closer to all interacted items while pushing them away from other positive pairs, thus achieving high-quality neighborhood aggregation with very low time complexity. On three highly sparse public datasets, the proposed method effectively aggregate neighborhood information while preventing graph over-smoothing, demonstrating significant improvements over existing GCL-based counterparts in both training efficiency and recommendation accuracy. Our implementations are publicly accessible.","authors":["Yu Zhang","Yiwen Zhang","Yi Zhang","Lei Sang","Yun Yang"],"url":"https://arxiv.org/abs/2504.10113"}
{"created":"2025-04-15","title":"AGO: Adaptive Grounding for Open World 3D Occupancy Prediction","abstract":"Open-world 3D semantic occupancy prediction aims to generate a voxelized 3D representation from sensor inputs while recognizing both known and unknown objects. Transferring open-vocabulary knowledge from vision-language models (VLMs) offers a promising direction but remains challenging. However, methods based on VLM-derived 2D pseudo-labels with traditional supervision are limited by a predefined label space and lack general prediction capabilities. Direct alignment with pretrained image embeddings, on the other hand, fails to achieve reliable performance due to often inconsistent image and text representations in VLMs. To address these challenges, we propose AGO, a novel 3D occupancy prediction framework with adaptive grounding to handle diverse open-world scenarios. AGO first encodes surrounding images and class prompts into 3D and text embeddings, respectively, leveraging similarity-based grounding training with 3D pseudo-labels. Additionally, a modality adapter maps 3D embeddings into a space aligned with VLM-derived image embeddings, reducing modality gaps. Experiments on Occ3D-nuScenes show that AGO improves unknown object prediction in zero-shot and few-shot transfer while achieving state-of-the-art closed-world self-supervised performance, surpassing prior methods by 4.09 mIoU.","authors":["Peizheng Li","Shuxiao Ding","You Zhou","Qingwen Zhang","Onat Inak","Larissa Triess","Niklas Hanselmann","Marius Cordts","Andreas Zell"],"url":"https://arxiv.org/abs/2504.10117"}
{"created":"2025-04-15","title":"Stochastic Multigrid Minimization for Ptychographic Phase Retrieval","abstract":"We propose a novel stochastic multigrid minimization method for ptychographic phase retrieval. In our formulation, the challenging nonconvex and ill-posed inverse problem is recast as the iterative minimization of a quadratic surrogate model that majorizes the original objective function. Our general framework encompasses the Ptychographic Iterative Engine (PIE) family of algorithms. By efficiently solving the surrogate problem using a multigrid method, our approach delivers significant improvements in both convergence speed and reconstruction quality compared with conventional PIE techniques.","authors":["Borong Zhang","Qin Li","Zichao Wendy Di"],"url":"https://arxiv.org/abs/2504.10118"}
{"created":"2025-04-15","title":"Universally Composable Commitments with Communicating Malicious Physically Uncloneable Functions","abstract":"In this work, we explore the possibility of universally composable (UC)-secure commitments using Physically Uncloneable Functions (PUFs) within a new adversarial model. We introduce the communicating malicious PUFs, i.e. malicious PUFs that can interact with their creator even when not in their possession, obtaining a stronger adversarial model. Prior work [ASIACRYPT 2013, LNCS, vol. 8270, pp. 100-119] proposed a compiler for constructing UC-secure commitments from ideal extractable commitments, and our task would be to adapt the ideal extractable commitment scheme proposed therein to our new model. However, we found an attack and identified a few other issues in that construction, and to address them, we modified the aforementioned ideal extractable commitment scheme and introduced new properties and tools that allow us to rigorously develop and present security proofs in this context. We propose a new UC-secure commitment scheme against adversaries that can only create stateless malicious PUFs which can receive, but not send, information from their creators. Our protocol is more efficient compared to previous proposals, as we have parallelized the ideal extractable commitments within it. The restriction to stateless malicious PUFs is significant, mainly since the protocol from [ASIACRYPT 2013, LNCS, vol. 8270, pp. 100-119] assumes malicious PUFs with unbounded state, thus limiting its applicability. However it is the only way we found to address the issues of the original construction. We hope that in future work this restriction can be lifted, and along the lines of our work, UC-secure commitments with fewer restrictions on both the state and communication can be constructed.","authors":["Louren\\c{c}o Abecasis","Paulo Mateus","Chrysoula Vlachou"],"url":"https://arxiv.org/abs/2504.10120"}
{"created":"2025-04-15","title":"M2S-RoAD: Multi-Modal Semantic Segmentation for Road Damage Using Camera and LiDAR Data","abstract":"Road damage can create safety and comfort challenges for both human drivers and autonomous vehicles (AVs). This damage is particularly prevalent in rural areas due to less frequent surveying and maintenance of roads. Automated detection of pavement deterioration can be used as an input to AVs and driver assistance systems to improve road safety. Current research in this field has predominantly focused on urban environments driven largely by public datasets, while rural areas have received significantly less attention. This paper introduces M2S-RoAD, a dataset for the semantic segmentation of different classes of road damage. M2S-RoAD was collected in various towns across New South Wales, Australia, and labelled for semantic segmentation to identify nine distinct types of road damage. This dataset will be released upon the acceptance of the paper.","authors":["Tzu-Yun Tseng","Hongyu Lyu","Josephine Li","Julie Stephany Berrio","Mao Shan","Stewart Worrall"],"url":"https://arxiv.org/abs/2504.10123"}
{"created":"2025-04-15","title":"An initial-boundary corrected splitting method for diffusion-reaction problems","abstract":"Strang splitting is a widely used second-order method for solving diffusion-reaction problems. However, its convergence order is often reduced to order $1$ for Dirichlet boundary conditions and to order $1.5$ for Neumann and Robin boundary conditions, leading to lower accuracy and reduced efficiency. In this paper, we propose a new splitting approach, called an initial-boundary corrected splitting, which avoids order reduction while improving computational efficiency for a wider range of applications. In contrast to the corrections proposed in the literature, it does not require the computation of correction terms that depend on the boundary conditions and boundary data. Through rigorous analytical convergence analysis and numerical experiments, we demonstrate the improved accuracy and performance of the proposed method.","authors":["Thi Tam Dang","Lukas Einkemmer","Alexander Ostermann"],"url":"https://arxiv.org/abs/2504.10125"}
{"created":"2025-04-15","title":"Breaking the Data Barrier -- Building GUI Agents Through Task Generalization","abstract":"Graphical User Interface (GUI) agents offer cross-platform solutions for automating complex digital tasks, with significant potential to transform productivity workflows. However, their performance is often constrained by the scarcity of high-quality trajectory data. To address this limitation, we propose training Vision Language Models (VLMs) on data-rich, reasoning-intensive tasks during a dedicated mid-training stage, and then examine how incorporating these tasks facilitates generalization to GUI planning scenarios. Specifically, we explore a range of tasks with readily available instruction-tuning data, including GUI perception, multimodal reasoning, and textual reasoning. Through extensive experiments across 11 mid-training tasks, we demonstrate that: (1) Task generalization proves highly effective, yielding substantial improvements across most settings. For instance, multimodal mathematical reasoning enhances performance on AndroidWorld by an absolute 6.3%. Remarkably, text-only mathematical data significantly boosts GUI web agent performance, achieving a 5.6% improvement on WebArena and 5.4% improvement on AndroidWorld, underscoring notable cross-modal generalization from text-based to visual domains; (2) Contrary to prior assumptions, GUI perception data - previously considered closely aligned with GUI agent tasks and widely utilized for training - has a comparatively limited impact on final performance; (3) Building on these insights, we identify the most effective mid-training tasks and curate optimized mixture datasets, resulting in absolute performance gains of 8.0% on WebArena and 12.2% on AndroidWorld. Our work provides valuable insights into cross-domain knowledge transfer for GUI agents and offers a practical approach to addressing data scarcity challenges in this emerging field. The code, data and models will be available at https://github.com/hkust-nlp/GUIMid.","authors":["Junlei Zhang","Zichen Ding","Chang Ma","Zijie Chen","Qiushi Sun","Zhenzhong Lan","Junxian He"],"url":"https://arxiv.org/abs/2504.10127"}
{"created":"2025-04-15","title":"Let's Talk About It: Making Scientific Computational Reproducibility Easy","abstract":"Computational reproducibility of scientific results, that is, the execution of a computational experiment (e.g., a script) using its original settings (data, code, etc.), should always be possible. However, reproducibility has become a significant challenge, as researchers often face difficulties in accurately replicating experiments due to inconsistencies in documentation, setup configurations, and missing data. This lack of reproducibility may undermine the credibility of scientific results.","authors":["L\\'azaro Costa","Susana Barbosa","J\\'acome Cunha"],"url":"https://arxiv.org/abs/2504.10134"}
{"created":"2025-04-15","title":"Exploiting Structure in MIMO Scaled Graph Analysis","abstract":"Scaled graphs offer a graphical tool for analysis of nonlinear feedback systems. Although recently substantial progress has been made in scaled graph analysis, at present their use in multivariable feedback systems is limited by conservatism. In this paper, we aim to reduce this conservatism by introducing multipliers and exploit system structure in the analysis with scaled graphs. In particular, we use weighted inner products to arrive at a weighted scaled graph and combine this with a commutation property to formulate a stability result for multivariable feedback systems. We present a method for computing the weighted scaled graph of Lur'e systems based on solving sets of linear matrix inequalities, and demonstrate a significant reduction in conservatism through an example.","authors":["Timo de Groot","Tom Oomen","Sebastiaan van den Eijnden"],"url":"https://arxiv.org/abs/2504.10135"}
{"created":"2025-04-15","title":"Uncertainty Propagation in the Fast Fourier Transform","abstract":"We address the problem of uncertainty propagation in the discrete Fourier transform by modeling the fast Fourier transform as a factor graph. Building on this representation, we propose an efficient framework for approximate Bayesian inference using belief propagation (BP) and expectation propagation, extending its applicability beyond Gaussian assumptions. By leveraging an appropriate BP message representation and a suitable schedule, our method achieves stable convergence with accurate mean and variance estimates. Numerical experiments in representative scenarios from communications demonstrate the practical potential of the proposed framework for uncertainty-aware inference in probabilistic systems operating across both time and frequency domain.","authors":["Luca Schmid","Charlotte Muth","Laurent Schmalen"],"url":"https://arxiv.org/abs/2504.10136"}
{"created":"2025-04-15","title":"Multi-Target Position Error Bound and Power Allocation Scheme for Cell-Free mMIMO-OTFS ISAC Systems","abstract":"This paper investigates multi-target position estimation in cell-free massive multiple-input multiple-output (CF mMIMO) architectures, where orthogonal time frequency and space (OTFS) is used as an integrated sensing and communication (ISAC) signal. Closed-form expressions for the Cram\\'{e}r-Rao lower bound and the positioning error bound (PEB) in multi-target position estimation are derived, providing quantitative evaluations of sensing performance. To enhance the overall performance of the ISAC system, a power allocation algorithm is developed to maximize the minimum user communication signal-to-interference-plus-noise ratio while ensuring a specified sensing PEB requirement. The results validate the proposed PEB expression and its approximation, clearly illustrating the coordination gain enabled by ISAC. Further, the superiority of using the multi-static CF mMIMO architecture over traditional cellular ISAC is demonstrated, and the advantages of OTFS signals in high-mobility scenarios are highlighted.","authors":["Yifei Fan","Shaochuan Wu","Haojie Wang","Mingjun Sun","Jianhe Wang"],"url":"https://arxiv.org/abs/2504.10137"}
{"created":"2025-04-15","title":"The topology of synergy: linking topological and information-theoretic approaches to higher-order interactions in complex systems","abstract":"The study of irreducible higher-order interactions has become a core topic of study in complex systems. Two of the most well-developed frameworks, topological data analysis and multivariate information theory, aim to provide formal tools for identifying higher-order interactions in empirical data. Despite similar aims, however, these two approaches are built on markedly different mathematical foundations and have been developed largely in parallel. In this study, we present a head-to-head comparison of topological data analysis and information-theoretic approaches to describing higher-order interactions in multivariate data; with the aim of assessing the similarities and differences between how the frameworks define ``higher-order structures.\" We begin with toy examples with known topologies, before turning to naturalistic data: fMRI signals collected from the human brain. We find that intrinsic, higher-order synergistic information is associated with three-dimensional cavities in a point cloud: shapes such as spheres are synergy-dominated. In fMRI data, we find strong correlations between synergistic information and both the number and size of three-dimensional cavities. Furthermore, we find that dimensionality reduction techniques such as PCA preferentially represent higher-order redundancies, and largely fail to preserve both higher-order information and topological structure, suggesting that common manifold-based approaches to studying high-dimensional data are systematically failing to identify important features of the data. These results point towards the possibility of developing a rich theory of higher-order interactions that spans topological and information-theoretic approaches while simultaneously highlighting the profound limitations of more conventional methods.","authors":["Thomas F. Varley","Pedro A. M. Mediano","Alice Patania","Josh Bongard"],"url":"https://arxiv.org/abs/2504.10140"}
{"created":"2025-04-15","title":"The Impact of Model Zoo Size and Composition on Weight Space Learning","abstract":"Re-using trained neural network models is a common strategy to reduce training cost and transfer knowledge. Weight space learning - using the weights of trained models as data modality - is a promising new field to re-use populations of pre-trained models for future tasks. Approaches in this field have demonstrated high performance both on model analysis and weight generation tasks. However, until now their learning setup requires homogeneous model zoos where all models share the same exact architecture, limiting their capability to generalize beyond the population of models they saw during training. In this work, we remove this constraint and propose a modification to a common weight space learning method to accommodate training on heterogeneous populations of models. We further investigate the resulting impact of model diversity on generating unseen neural network model weights for zero-shot knowledge transfer. Our extensive experimental evaluation shows that including models with varying underlying image datasets has a high impact on performance and generalization, for both in- and out-of-distribution settings. Code is available on github.com/HSG-AIML/MultiZoo-SANE.","authors":["Damian Falk","Konstantin Sch\\\"urholt","Damian Borth"],"url":"https://arxiv.org/abs/2504.10141"}
{"created":"2025-04-15","title":"Negate or Embrace: On How Misalignment Shapes Multimodal Representation Learning","abstract":"Multimodal representation learning, exemplified by multimodal contrastive learning (MMCL) using image-text pairs, aims to learn powerful representations by aligning cues across modalities. This approach relies on the core assumption that the exemplar image-text pairs constitute two representations of an identical concept. However, recent research has revealed that real-world datasets often exhibit misalignment. There are two distinct viewpoints on how to address this issue: one suggests mitigating the misalignment, and the other leveraging it. We seek here to reconcile these seemingly opposing perspectives, and to provide a practical guide for practitioners. Using latent variable models we thus formalize misalignment by introducing two specific mechanisms: selection bias, where some semantic variables are missing, and perturbation bias, where semantic variables are distorted -- both affecting latent variables shared across modalities. Our theoretical analysis demonstrates that, under mild assumptions, the representations learned by MMCL capture exactly the information related to the subset of the semantic variables invariant to selection and perturbation biases. This provides a unified perspective for understanding misalignment. Based on this, we further offer actionable insights into how misalignment should inform the design of real-world ML systems. We validate our theoretical findings through extensive empirical studies on both synthetic data and real image-text datasets, shedding light on the nuanced impact of misalignment on multimodal representation learning.","authors":["Yichao Cai","Yuhang Liu","Erdun Gao","Tianjiao Jiang","Zhen Zhang","Anton van den Hengel","Javen Qinfeng Shi"],"url":"https://arxiv.org/abs/2504.10143"}
{"created":"2025-04-15","title":"GeoUni: A Unified Model for Generating Geometry Diagrams, Problems and Problem Solutions","abstract":"We propose GeoUni, the first unified geometry expert model capable of generating problem solutions and diagrams within a single framework in a way that enables the creation of unique and individualized geometry problems. Traditionally, solving geometry problems and generating diagrams have been treated as separate tasks in machine learning, with no models successfully integrating both to support problem creation. However, we believe that mastery in geometry requires frictionless integration of all of these skills, from solving problems to visualizing geometric relationships, and finally, crafting tailored problems. Our extensive experiments demonstrate that GeoUni, with only 1.5B parameters, achieves performance comparable to larger models such as DeepSeek-R1 with 671B parameters in geometric reasoning tasks. GeoUni also excels in generating precise geometric diagrams, surpassing both text-to-image models and unified models, including the GPT-4o image generation. Most importantly, GeoUni is the only model capable of successfully generating textual problems with matching diagrams based on specific knowledge points, thus offering a wider range of capabilities that extend beyond current models.","authors":["Jo-Ku Cheng","Zeren Zhang","Ran Chen","Jingyang Deng","Ziran Qin","Jinwen Ma"],"url":"https://arxiv.org/abs/2504.10146"}
{"created":"2025-04-15","title":"A Survey of Personalization: From RAG to Agent","abstract":"Personalization has become an essential capability in modern AI systems, enabling customized interactions that align with individual user preferences, contexts, and goals. Recent research has increasingly concentrated on Retrieval-Augmented Generation (RAG) frameworks and their evolution into more advanced agent-based architectures within personalized settings to enhance user satisfaction. Building on this foundation, this survey systematically examines personalization across the three core stages of RAG: pre-retrieval, retrieval, and generation. Beyond RAG, we further extend its capabilities into the realm of Personalized LLM-based Agents, which enhance traditional RAG systems with agentic functionalities, including user understanding, personalized planning and execution, and dynamic generation. For both personalization in RAG and agent-based personalization, we provide formal definitions, conduct a comprehensive review of recent literature, and summarize key datasets and evaluation metrics. Additionally, we discuss fundamental challenges, limitations, and promising research directions in this evolving field. Relevant papers and resources are continuously updated at https://github.com/Applied-Machine-Learning-Lab/Awesome-Personalized-RAG-Agent.","authors":["Xiaopeng Li","Pengyue Jia","Derong Xu","Yi Wen","Yingyi Zhang","Wenlin Zhang","Wanyu Wang","Yichao Wang","Zhaocheng Du","Xiangyang Li","Yong Liu","Huifeng Guo","Ruiming Tang","Xiangyu Zhao"],"url":"https://arxiv.org/abs/2504.10147"}
{"created":"2025-04-15","title":"Hierarchical and Step-Layer-Wise Tuning of Attention Specialty for Multi-Instance Synthesis in Diffusion Transformers","abstract":"Text-to-image (T2I) generation models often struggle with multi-instance synthesis (MIS), where they must accurately depict multiple distinct instances in a single image based on complex prompts detailing individual features. Traditional MIS control methods for UNet architectures like SD v1.5/SDXL fail to adapt to DiT-based models like FLUX and SD v3.5, which rely on integrated attention between image and text tokens rather than text-image cross-attention. To enhance MIS in DiT, we first analyze the mixed attention mechanism in DiT. Our token-wise and layer-wise analysis of attention maps reveals a hierarchical response structure: instance tokens dominate early layers, background tokens in middle layers, and attribute tokens in later layers. Building on this observation, we propose a training-free approach for enhancing MIS in DiT-based models with hierarchical and step-layer-wise attention specialty tuning (AST). AST amplifies key regions while suppressing irrelevant areas in distinct attention maps across layers and steps, guided by the hierarchical structure. This optimizes multimodal interactions by hierarchically decoupling the complex prompts with instance-based sketches. We evaluate our approach using upgraded sketch-based layouts for the T2I-CompBench and customized complex scenes. Both quantitative and qualitative results confirm our method enhances complex layout generation, ensuring precise instance placement and attribute representation in MIS.","authors":["Chunyang Zhang","Zhenhong Sun","Zhicheng Zhang","Junyan Wang","Yu Zhang","Dong Gong","Huadong Mo","Daoyi Dong"],"url":"https://arxiv.org/abs/2504.10148"}
{"created":"2025-04-15","title":"BoTTA: Benchmarking on-device Test Time Adaptation","abstract":"The performance of deep learning models depends heavily on test samples at runtime, and shifts from the training data distribution can significantly reduce accuracy. Test-time adaptation (TTA) addresses this by adapting models during inference without requiring labeled test data or access to the original training set. While research has explored TTA from various perspectives like algorithmic complexity, data and class distribution shifts, model architectures, and offline versus continuous learning, constraints specific to mobile and edge devices remain underexplored. We propose BoTTA, a benchmark designed to evaluate TTA methods under practical constraints on mobile and edge devices. Our evaluation targets four key challenges caused by limited resources and usage conditions: (i) limited test samples, (ii) limited exposure to categories, (iii) diverse distribution shifts, and (iv) overlapping shifts within a sample. We assess state-of-the-art TTA methods under these scenarios using benchmark datasets and report system-level metrics on a real testbed. Furthermore, unlike prior work, we align with on-device requirements by advocating periodic adaptation instead of continuous inference-time adaptation. Experiments reveal key insights: many recent TTA algorithms struggle with small datasets, fail to generalize to unseen categories, and depend on the diversity and complexity of distribution shifts. BoTTA also reports device-specific resource use. For example, while SHOT improves accuracy by $2.25\\times$ with $512$ adaptation samples, it uses $1.08\\times$ peak memory on Raspberry Pi versus the base model. BoTTA offers actionable guidance for TTA in real-world, resource-constrained deployments.","authors":["Michal Danilowski","Soumyajit Chatterjee","Abhirup Ghosh"],"url":"https://arxiv.org/abs/2504.10149"}
{"created":"2025-04-15","title":"HistLLM: A Unified Framework for LLM-Based Multimodal Recommendation with User History Encoding and Compression","abstract":"While large language models (LLMs) have proven effective in leveraging textual data for recommendations, their application to multimodal recommendation tasks remains relatively underexplored. Although LLMs can process multimodal information through projection functions that map visual features into their semantic space, recommendation tasks often require representing users' history interactions through lengthy prompts combining text and visual elements, which not only hampers training and inference efficiency but also makes it difficult for the model to accurately capture user preferences from complex and extended prompts, leading to reduced recommendation performance. To address this challenge, we introduce HistLLM, an innovative multimodal recommendation framework that integrates textual and visual features through a User History Encoding Module (UHEM), compressing multimodal user history interactions into a single token representation, effectively facilitating LLMs in processing user preferences. Extensive experiments demonstrate the effectiveness and efficiency of our proposed mechanism.","authors":["Chen Zhang","Bo Hu","Weidong Chen","Zhendong Mao"],"url":"https://arxiv.org/abs/2504.10150"}
{"created":"2025-04-15","title":"Continual learning for rotating machinery fault diagnosis with cross-domain environmental and operational variations","abstract":"Although numerous machine learning models exist to detect issues like rolling bearing strain and deformation, typically caused by improper mounting, overloading, or poor lubrication, these models often struggle to isolate faults from the noise of real-world operational and environmental variability. Conditions such as variable loads, high temperatures, stress, and rotational speeds can mask early signs of failure, making reliable detection challenging. To address these limitations, this work proposes a continual deep learning approach capable of learning across domains that share underlying structure over time. This approach goes beyond traditional accuracy metrics by addressing four second-order challenges: catastrophic forgetting (where new learning overwrites past knowledge), lack of plasticity (where models fail to adapt to new data), forward transfer (using past knowledge to improve future learning), and backward transfer (refining past knowledge with insights from new domains). The method comprises a feature generator and domain-specific classifiers, allowing capacity to grow as new domains emerge with minimal interference, while an experience replay mechanism selectively revisits prior domains to mitigate forgetting. Moreover, nonlinear dependencies across domains are exploited by prioritizing replay from those with the highest prior errors, refining models based on most informative past experiences. Experiments show high average domain accuracy (up to 88.96%), with forgetting measures as low as .0027 across non-stationary class-incremental environments.","authors":["Diogo Risca","Afonso Louren\\c{c}o","Goreti Marreiros"],"url":"https://arxiv.org/abs/2504.10151"}
{"created":"2025-04-15","title":"SocioVerse: A World Model for Social Simulation Powered by LLM Agents and A Pool of 10 Million Real-World Users","abstract":"Social simulation is transforming traditional social science research by modeling human behavior through interactions between virtual individuals and their environments. With recent advances in large language models (LLMs), this approach has shown growing potential in capturing individual differences and predicting group behaviors. However, existing methods face alignment challenges related to the environment, target users, interaction mechanisms, and behavioral patterns. To this end, we introduce SocioVerse, an LLM-agent-driven world model for social simulation. Our framework features four powerful alignment components and a user pool of 10 million real individuals. To validate its effectiveness, we conducted large-scale simulation experiments across three distinct domains: politics, news, and economics. Results demonstrate that SocioVerse can reflect large-scale population dynamics while ensuring diversity, credibility, and representativeness through standardized procedures and minimal manual adjustments.","authors":["Xinnong Zhang","Jiayu Lin","Xinyi Mou","Shiyue Yang","Xiawei Liu","Libo Sun","Hanjia Lyu","Yihang Yang","Weihong Qi","Yue Chen","Guanying Li","Ling Yan","Yao Hu","Siming Chen","Yu Wang","Jingxuan Huang","Jiebo Luo","Shiping Tang","Libo Wu","Baohua Zhou","Zhongyu Wei"],"url":"https://arxiv.org/abs/2504.10157"}
{"created":"2025-04-15","title":"COUNTS: Benchmarking Object Detectors and Multimodal Large Language Models under Distribution Shifts","abstract":"Current object detectors often suffer significant perfor-mance degradation in real-world applications when encountering distributional shifts. Consequently, the out-of-distribution (OOD) generalization capability of object detectors has garnered increasing attention from researchers. Despite this growing interest, there remains a lack of a large-scale, comprehensive dataset and evaluation benchmark with fine-grained annotations tailored to assess the OOD generalization on more intricate tasks like object detection and grounding. To address this gap, we introduce COUNTS, a large-scale OOD dataset with object-level annotations. COUNTS encompasses 14 natural distributional shifts, over 222K samples, and more than 1,196K labeled bounding boxes. Leveraging COUNTS, we introduce two novel benchmarks: O(OD)2 and OODG. O(OD)2 is designed to comprehensively evaluate the OOD generalization capabilities of object detectors by utilizing controlled distribution shifts between training and testing data. OODG, on the other hand, aims to assess the OOD generalization of grounding abilities in multimodal large language models (MLLMs). Our findings reveal that, while large models and extensive pre-training data substantially en hance performance in in-distribution (IID) scenarios, significant limitations and opportunities for improvement persist in OOD contexts for both object detectors and MLLMs. In visual grounding tasks, even the advanced GPT-4o and Gemini-1.5 only achieve 56.7% and 28.0% accuracy, respectively. We hope COUNTS facilitates advancements in the development and assessment of robust object detectors and MLLMs capable of maintaining high performance under distributional shifts.","authors":["Jiansheng Li","Xingxuan Zhang","Hao Zou","Yige Guo","Renzhe Xu","Yilong Liu","Chuzhao Zhu","Yue He","Peng Cui"],"url":"https://arxiv.org/abs/2504.10158"}
{"created":"2025-04-15","title":"Monadic type-and-effect soundness","abstract":"We introduce the abstract notions of \"monadic operational semantics\", a small-step semantics where computational effects are modularly modeled by a monad, and \"type-and-effect system\", including \"effect types\" whose interpretation lifts well-typedness to its monadic version. In this meta-theory, as usually done in the non-monadic case, we can express progress and subject reduction properties and provide a proof, given once and for all, that they imply soundness. The approach is illustrated on a lambda calculus with generic effects. We equip the calculus with an expressive type-and-effect system, and provide proofs of progress and subject reduction which are parametric on the interpretation of effect types. In this way, we obtain as instances many significant examples, such as checking exceptions, preventing/limiting non-determinism, constraining order/fairness of outputs on different locations. We also provide an extension with constructs to raise and handle computational effects, which can be instantiated to model different policies.","authors":["Francesco Dagnino","Paola Giannini","Elena Zucca"],"url":"https://arxiv.org/abs/2504.10159"}
{"created":"2025-04-15","title":"MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like Reinforcement Learning","abstract":"Large-scale reinforcement learning (RL) methods have proven highly effective in enhancing the reasoning abilities of large language models (LLMs), particularly for tasks with verifiable solutions such as mathematics and coding. However, applying this idea to machine translation (MT), where outputs are flexibly formatted and difficult to automatically evaluate with explicit rules, remains underexplored. In this work, we introduce MT-R1-Zero, the first open-source adaptation of the R1-Zero RL framework for MT without supervised fine-tuning or cold-start. We propose a rule-metric mixed reward mechanism to guide LLMs towards improved translation quality via emergent reasoning. On the WMT 24 English-Chinese benchmark, our MT-R1-Zero-3B-Mix achieves competitive performance, surpassing TowerInstruct-7B-v0.2 by an average of 1.26 points. Meanwhile, our MT-R1-Zero-7B-Mix attains a high average score of 62.25 across all metrics, placing it on par with advanced proprietary models such as GPT-4o and Claude-3.5-Sonnet, while the MT-R1-Zero-7B-Sem variant achieves state-of-the-art scores on semantic metrics. Moreover, our work exhibits strong generalization capabilities on out-of-distribution MT tasks, robustly supporting multilingual and low-resource settings. Extensive analysis of model behavior across different initializations and reward metrics offers pioneering insight into the critical role of reward design, LLM adaptability, training dynamics, and emergent reasoning patterns within the R1-Zero paradigm for MT. Our code is available at https://github.com/fzp0424/MT-R1-Zero.","authors":["Zhaopeng Feng","Shaosheng Cao","Jiahan Ren","Jiayuan Su","Ruizhe Chen","Yan Zhang","Zhe Xu","Yao Hu","Jian Wu","Zuozhu Liu"],"url":"https://arxiv.org/abs/2504.10160"}
{"created":"2025-04-15","title":"When Do We Feel Present in a Virtual Reality? Towards Sensitivity and User Acceptance of Presence Questionnaires","abstract":"Presence is an important and widely used metric to measure the quality of virtual reality (VR) applications. Given the multifaceted and subjective nature of presence, the most common measures for presence are questionnaires. But there is little research on their validity regarding specific presence dimensions and their responsiveness to differences in perception among users. We investigated four presence questionnaires (SUS, PQ, IPQ, Bouchard) on their responsiveness to intensity variations of known presence dimensions and asked users about their consistency with their experience. Therefore, we created five VR scenarios that were designed to emphasize a specific presence dimension. Our findings showed heterogeneous sensitivity of the questionnaires dependent on the different dimensions of presence. This highlights a context-specific suitability of presence questionnaires. The questionnaires' sensitivity was further stated as lower than actually perceived. Based on our findings, we offer guidance on selecting these questionnaires based on their suitability for particular use cases.","authors":["Annalisa Degenhard","Ali Askari","Michael Rietzler","Enrico Rukzio"],"url":"https://arxiv.org/abs/2504.10162"}
{"created":"2025-04-15","title":"Shoulder Range of Motion Rehabilitation Robot Incorporating Scapulohumeral Rhythm for Frozen Shoulder","abstract":"This paper presents a novel rehabilitation robot designed to address the challenges of passive range of motion (PROM) exercises for frozen shoulder patients by integrating advanced scapulohumeral rhythm stabilization. Frozen shoulder is characterized by limited glenohumeral motion and disrupted scapulohumeral rhythm, with therapist-assisted interventions being highly effective for restoring normal shoulder function. While existing robotic solutions replicate natural shoulder biomechanics, they lack the ability to stabilize compensatory movements, such as shoulder shrugging, which are critical for effective rehabilitation. Our proposed device features a 6 degrees of freedom (DoF) mechanism, including 5 DoF for shoulder motion and an innovative 1 DoF Joint press for scapular stabilization. The robot employs a personalized two-phase operation: recording normal shoulder movement patterns from the unaffected side and applying them to guide the affected side. Experimental results demonstrated the robot's ability to replicate recorded motion patterns with high precision, with root mean square error (RMSE) values consistently below 1 degree. In simulated frozen shoulder conditions, the robot effectively suppressed scapular elevation, delaying the onset of compensatory movements and guiding the affected shoulder to move more closely in alignment with normal shoulder motion, particularly during arm elevation movements such as abduction and flexion. These findings confirm the robot's potential as a rehabilitation tool capable of automating PROM exercises while correcting compensatory movements. The system provides a foundation for advanced, personalized rehabilitation for patients with frozen shoulders.","authors":["Hyunbum Cho","Sungmoon Hur","Joowan Kim","Keewon Kim","Jaeheung Park"],"url":"https://arxiv.org/abs/2504.10163"}
{"created":"2025-04-15","title":"WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs","abstract":"Live tracking of wildlife via high-resolution video processing directly onboard drones is widely unexplored and most existing solutions rely on streaming video to ground stations to support navigation. Yet, both autonomous animal-reactive flight control beyond visual line of sight and/or mission-specific individual and behaviour recognition tasks rely to some degree on this capability. In response, we introduce WildLive -- a near real-time animal detection and tracking framework for high-resolution imagery running directly onboard uncrewed aerial vehicles (UAVs). The system performs multi-animal detection and tracking at 17fps+ for HD and 7fps+ on 4K video streams suitable for operation during higher altitude flights to minimise animal disturbance. Our system is optimised for Jetson Orin AGX onboard hardware. It integrates the efficiency of sparse optical flow tracking and mission-specific sampling with device-optimised and proven YOLO-driven object detection and segmentation techniques. Essentially, computational resource is focused onto spatio-temporal regions of high uncertainty to significantly improve UAV processing speeds without domain-specific loss of accuracy. Alongside, we introduce our WildLive dataset, which comprises 200k+ annotated animal instances across 19k+ frames from 4K UAV videos collected at the Ol Pejeta Conservancy in Kenya. All frames contain ground truth bounding boxes, segmentation masks, as well as individual tracklets and tracking point trajectories. We compare our system against current object tracking approaches including OC-SORT, ByteTrack, and SORT. Our multi-animal tracking experiments with onboard hardware confirm that near real-time high-resolution wildlife tracking is possible on UAVs whilst maintaining high accuracy levels as needed for future navigational and mission-specific animal-centric operational autonomy.","authors":["Nguyen Ngoc Dat","Tom Richardson","Matthew Watson","Kilian Meier","Jenna Kline","Sid Reid","Guy Maalouf","Duncan Hine","Majid Mirmehdi","Tilo Burghardt"],"url":"https://arxiv.org/abs/2504.10165"}
{"created":"2025-04-15","title":"Fact-Checking with Contextual Narratives: Leveraging Retrieval-Augmented LLMs for Social Media Analysis","abstract":"We propose CRAVE (Cluster-based Retrieval Augmented Verification with Explanation); a novel framework that integrates retrieval-augmented Large Language Models (LLMs) with clustering techniques to address fact-checking challenges on social media. CRAVE automatically retrieves multimodal evidence from diverse, often contradictory, sources. Evidence is clustered into coherent narratives, and evaluated via an LLM-based judge to deliver fact-checking verdicts explained by evidence summaries. By synthesizing evidence from both text and image modalities and incorporating agent-based refinement, CRAVE ensures consistency and diversity in evidence representation. Comprehensive experiments demonstrate CRAVE's efficacy in retrieval precision, clustering quality, and judgment accuracy, showcasing its potential as a robust decision-support tool for fact-checkers.","authors":["Arka Ujjal Dey","Muhammad Junaid Awan","Georgia Channing","Christian Schroeder de Witt","John Collomosse"],"url":"https://arxiv.org/abs/2504.10166"}
{"created":"2025-04-15","title":"C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination Evaluation","abstract":"Despite the rapid advancement of large language models, they remain highly susceptible to generating hallucinations, which significantly hinders their widespread application. Hallucination research requires dynamic and fine-grained evaluation. However, most existing hallucination benchmarks (especially in Chinese language) rely on human annotations, making automatical and cost-effective hallucination evaluation challenging. To address this, we introduce HaluAgent, an agentic framework that automatically constructs fine-grained QA dataset based on some knowledge documents. Our experiments demonstrate that the manually designed rules and prompt optimization can improve the quality of generated data. Using HaluAgent, we construct C-FAITH, a Chinese QA hallucination benchmark created from 1,399 knowledge documents obtained from web scraping, totaling 60,702 entries. We comprehensively evaluate 16 mainstream LLMs with our proposed C-FAITH, providing detailed experimental results and analysis.","authors":["Xu Zhang","Zhifei Liu","Jiahao Wang","Huixuan Zhang","Fan Xu","Junzhe Zhang","Xiaojun Wan"],"url":"https://arxiv.org/abs/2504.10167"}
{"created":"2025-04-15","title":"HalluSearch at SemEval-2025 Task 3: A Search-Enhanced RAG Pipeline for Hallucination Detection","abstract":"In this paper, we present HalluSearch, a multilingual pipeline designed to detect fabricated text spans in Large Language Model (LLM) outputs. Developed as part of Mu-SHROOM, the Multilingual Shared-task on Hallucinations and Related Observable Overgeneration Mistakes, HalluSearch couples retrieval-augmented verification with fine-grained factual splitting to identify and localize hallucinations in fourteen different languages. Empirical evaluations show that HalluSearch performs competitively, placing fourth in both English (within the top ten percent) and Czech. While the system's retrieval-based strategy generally proves robust, it faces challenges in languages with limited online coverage, underscoring the need for further research to ensure consistent hallucination detection across diverse linguistic contexts.","authors":["Mohamed A. Abdallah","Samhaa R. El-Beltagy"],"url":"https://arxiv.org/abs/2504.10168"}
{"created":"2025-04-15","title":"Challenges in interpretability of additive models","abstract":"We review generalized additive models as a type of ``transparent'' model that has recently seen renewed interest in the deep learning community as neural additive models. We highlight multiple types of nonidentifiability in this model class and discuss challenges in interpretability, arguing for restraint when claiming ``interpretability'' or ``suitability for safety-critical applications'' of such models.","authors":["Xinyu Zhang","Julien Martinelli","ST John"],"url":"https://arxiv.org/abs/2504.10169"}
{"created":"2025-04-15","title":"LLaVA-ReID: Selective Multi-image Questioner for Interactive Person Re-Identification","abstract":"Traditional text-based person ReID assumes that person descriptions from witnesses are complete and provided at once. However, in real-world scenarios, such descriptions are often partial or vague. To address this limitation, we introduce a new task called interactive person re-identification (Inter-ReID). Inter-ReID is a dialogue-based retrieval task that iteratively refines initial descriptions through ongoing interactions with the witnesses. To facilitate the study of this new task, we construct a dialogue dataset that incorporates multiple types of questions by decomposing fine-grained attributes of individuals. We further propose LLaVA-ReID, a question model that generates targeted questions based on visual and textual contexts to elicit additional details about the target person. Leveraging a looking-forward strategy, we prioritize the most informative questions as supervision during training. Experimental results on both Inter-ReID and text-based ReID benchmarks demonstrate that LLaVA-ReID significantly outperforms baselines.","authors":["Yiding Lu","Mouxing Yang","Dezhong Peng","Peng Hu","Yijie Lin","Xi Peng"],"url":"https://arxiv.org/abs/2504.10174"}
{"created":"2025-04-15","title":"MSCoT: Structured Chain-of-Thought Generation for Multiple Programming Languages","abstract":"With the rapid development of code intelligence, the application of multiple programming languages is becoming increasingly widespread. However, most existing code generation models mainly focus on a single or a few programming languages, resulting in unsatisfactory performance in a multilingual environment. Chain-of-Thought (CoT) reasoning can significantly improve the performance of the model without the need for retraining or fine-tuning the code generation model by reasonably decomposing complex code generation tasks into multiple subtasks and gradually deriving solutions for each subtask. Nevertheless, the existing CoT generation methods mainly concentrate on Python code, and the performance on other programming languages remains unclear. To fill this gap, we first constructed a CoT generation dataset for 12 programming languages through multi-agent technology. On this basis, we proposed a CoT generation method MSCoT applicable to multiple programming languages. By introducing CoT into the code generation large model, the performance of the code generation large model in a multilingual environment can be improved. Through large-scale empirical research, we compared the generalization abilities of MSCoT and the existing CoT generation methods on multiple programming languages and proved the effectiveness of MSCoT for multiple programming languages. In addition, we also designed a human study to prove the quality of the CoT generated by MSCoT. Finally, we opensourced the model and dataset of MSCoT to promote the research on CoT generation for multiple programming languages.","authors":["Naizhu Jin","Zhong Li","Tian Zhang","Qingkai Zeng"],"url":"https://arxiv.org/abs/2504.10178"}
{"created":"2025-04-15","title":"The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental Evaluation of Prompt Engineering Methods for Robust Multimodal Performance","abstract":"Multimodal Large Language Models (MLLMs) are set to transform how machines process and generate human-like responses by integrating diverse modalities such as text, images, and code. Yet, effectively harnessing their capabilities hinges on optimal prompt engineering. We present a comprehensive experimental evaluation of seven prompt engineering methods applied to 13 open-source MLLMs over 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding and Alignment, Complex Code Generation and Execution, and Knowledge Retrieval and Integration. Our approach stratifies models by parameter count into Small (<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting techniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought, Analogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel in structured tasks such as code generation, achieving accuracies up to 96.88% under Few-Shot prompting, all models struggle with complex reasoning and abstract understanding, often yielding accuracies below 60% and high hallucination rates. Structured reasoning prompts frequently increased hallucination up to 75% in small models and led to longer response times (over 20 seconds in Large MLLMs), while simpler prompting methods provided more concise and efficient outputs. No single prompting method uniformly optimises all task types. Instead, adaptive strategies combining example-based guidance with selective structured reasoning are essential to enhance robustness, efficiency, and factual accuracy. Our findings offer practical recommendations for prompt engineering and support more reliable deployment of MLLMs across applications including AI-assisted coding, knowledge retrieval, and multimodal content understanding.","authors":["Anwesha Mohanty","Venkatesh Balavadhani Parthasarathy","Arsalan Shahid"],"url":"https://arxiv.org/abs/2504.10179"}
{"created":"2025-04-15","title":"ChartOptimiser: Task-driven Optimisation of Chart Designs","abstract":"Effective chart design is essential for satisfying viewers' information needs, such as retrieving values from a chart or comparing two values. However, creating effective charts is challenging and time-consuming due to the large design space and the inter-dependencies between individual design parameters. To address this challenge, we propose ChartOptimiser -- a Bayesian approach for task-driven optimisation of charts, such as bar charts. At the core of ChartOptimiser is a novel objective function to automatically optimise an eight-dimensional design space combining four perceptual metrics: visual saliency, text legibility, colour preference, and white space ratio. Through empirical evaluation on 12 bar charts and four common analytical tasks -- finding the extreme value, retrieving a value, comparing two values, and computing a derived value -- we show that ChartOptimiser outperforms existing design baselines concerning task-solving ease, visual aesthetics, and chart clarity. We also discuss two practical applications of ChartOptimiser: generating charts for accessibility and content localisation. Taken together, ChartOptimiser opens up an exciting new research direction in automated chart design where charts are optimised for users' information needs, preferences, and contexts.","authors":["Yao Wang","Jiarong Pan","Danqing Shi","Zhiming Hu","Antti Oulasvirta","Andreas Bulling"],"url":"https://arxiv.org/abs/2504.10180"}
{"created":"2025-04-15","title":"A New Paradigm in IBR Modeling for Power Flow and Short Circuit Analysis","abstract":"The fault characteristics of inverter-based resources (IBRs) are different from conventional synchronous generators. The fault response of IBRs is non-linear due to saturation states and mainly determined by fault ride through (FRT) strategies of the associated voltage source converter (VSC). This results in prohibitively large solution times for power flows considering these short circuit characteristics, especially when the power system states change fast due to uncertainty in IBR generations. To overcome this, a phasor-domain steady state (SS) short circuit (SC) solver for IBR dominated power systems is proposed in this paper, and subsequently the developed IBR models are incorporated with a novel Jacobian-based Power Flow (PF) solver. In this multiphase PF solver, any power system components can be modeled by considering their original non-linear or linear mathematical representations. Moreover, two novel FRT strategies are proposed to fully utilize the converter capacity and to comply with IEEE-2800 2022 std and German grid code. The results are compared with the Electromagnetic Transient (EMT) simulation on the IEEE 34 test network and the 120 kV EPRI benchmark system. The developed IBR sequence domain PF model demonstrates more accurate behavior compared to the classical IBR generator model. The error in calculating the short circuit current with the proposed SC solver is less than 3%, while achieving significant speed improvements of three order of magnitudes.","authors":["Zahid Javid","Firdous Ul Nazir","Wentao Zhu","Diptargha Chakravorty","Ahmed Aboushady","Mohamed Galeela"],"url":"https://arxiv.org/abs/2504.10181"}
{"created":"2025-04-15","title":"Dispatching Odyssey: Exploring Performance in Computing Clusters under Real-world Workloads","abstract":"Recent workload measurements in Google data centers provide an opportunity to challenge existing models and, more broadly, to enhance the understanding of dispatching policies in computing clusters. Through extensive data-driven simulations, we aim to highlight the key features of workload traffic traces that influence response time performance under simple yet representative dispatching policies. For a given computational power budget, we vary the cluster size, i.e., the number of available servers. A job-level analysis reveals that Join Idle Queue (JIQ) and Least Work Left (LWL) exhibit an optimal working point for a fixed utilization coefficient as the number of servers is varied, whereas Round Robin (RR) demonstrates monotonously worsening performance. Additionally, we explore the accuracy of simple G/G queue approximations. When decomposing jobs into tasks, interesting results emerge; notably, the simpler, non-size-based policy JIQ appears to outperform the more \"powerful\" size-based LWL policy. Complementing these findings, we present preliminary results on a two-stage scheduling approach that partitions tasks based on service thresholds, illustrating that modest architectural modifications can further enhance performance under realistic workload conditions. We provide insights into these results and suggest promising directions for fully explaining the observed phenomena.","authors":["Mert Yildiz","Alexey Rolich","Andrea Baiocchi"],"url":"https://arxiv.org/abs/2504.10184"}
{"created":"2025-04-15","title":"LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks","abstract":"Large language model unlearning has become a critical challenge in ensuring safety and controlled model behavior by removing undesired data-model influences from the pretrained model while preserving general utility. Significant recent efforts have been dedicated to developing LLM unlearning benchmarks such as WMDP (Weapons of Mass Destruction Proxy) and MUSE (Machine Unlearning Six-way Evaluation), facilitating standardized unlearning performance assessment and method comparison. Despite their usefulness, we uncover for the first time a novel coreset effect within these benchmarks. Specifically, we find that LLM unlearning achieved with the original (full) forget set can be effectively maintained using a significantly smaller subset (functioning as a \"coreset\"), e.g., as little as 5% of the forget set, even when selected at random. This suggests that LLM unlearning in these benchmarks can be performed surprisingly easily, even in an extremely low-data regime. We demonstrate that this coreset effect remains strong, regardless of the LLM unlearning method used, such as NPO (Negative Preference Optimization) and RMU (Representation Misdirection Unlearning), the popular ones in these benchmarks. The surprisingly strong coreset effect is also robust across various data selection methods, ranging from random selection to more sophisticated heuristic approaches. We explain the coreset effect in LLM unlearning through a keyword-based perspective, showing that keywords extracted from the forget set alone contribute significantly to unlearning effectiveness and indicating that current unlearning is driven by a compact set of high-impact tokens rather than the entire dataset. We further justify the faithfulness of coreset-unlearned models along additional dimensions, such as mode connectivity and robustness to jailbreaking attacks. Codes are available at https://github.com/OPTML-Group/MU-Coreset.","authors":["Soumyadeep Pal","Changsheng Wang","James Diffenderfer","Bhavya Kailkhura","Sijia Liu"],"url":"https://arxiv.org/abs/2504.10185"}
{"created":"2025-04-15","title":"Deep Reasoning Translation via Reinforcement Learning","abstract":"Recently, deep reasoning LLMs (e.g., OpenAI o1/o3 and DeepSeek-R1) have shown promising performance in various complex tasks. Free translation is an important and interesting task in the multilingual world, which requires going beyond word-for-word translation and taking cultural differences into account. This task is still under-explored in deep reasoning LLMs. In this paper, we introduce DeepTrans, a deep reasoning translation model that learns free translation via reinforcement learning. Specifically, we carefully build a reward model with pre-defined scoring criteria on both the translation results and the thought process. Given the source sentences, the reward model teaches the deep translation model how to think and free-translate them during reinforcement learning. In this way, training DeepTrans does not need any labeled translations, avoiding the human-intensive annotation or resource-intensive data synthesis. Experimental results show the effectiveness of DeepTrans. Using Qwen2.5-7B as the backbone, DeepTrans improves performance by 16.3% in literature translation, and outperforms strong deep reasoning baselines as well as baselines that are fine-tuned with synthesized data. Moreover, we summarize the failures and interesting findings during our RL exploration. We hope this work could inspire other researchers in free translation.","authors":["Jiaan Wang","Fandong Meng","Jie Zhou"],"url":"https://arxiv.org/abs/2504.10187"}
{"created":"2025-04-15","title":"Efficient Generative Model Training via Embedded Representation Warmup","abstract":"Diffusion models excel at generating high-dimensional data but fall short in training efficiency and representation quality compared to self-supervised methods. We identify a key bottleneck: the underutilization of high-quality, semantically rich representations during training notably slows down convergence. Our systematic analysis reveals a critical representation processing region -- primarily in the early layers -- where semantic and structural pattern learning takes place before generation can occur. To address this, we propose Embedded Representation Warmup (ERW), a plug-and-play framework where in the first stage we get the ERW module serves as a warmup that initializes the early layers of the diffusion model with high-quality, pretrained representations. This warmup minimizes the burden of learning representations from scratch, thereby accelerating convergence and boosting performance. Our theoretical analysis demonstrates that ERW's efficacy depends on its precise integration into specific neural network layers -- termed the representation processing region -- where the model primarily processes and transforms feature representations for later generation. We further establish that ERW not only accelerates training convergence but also enhances representation quality: empirically, our method achieves a 40$\\times$ acceleration in training speed compared to REPA, the current state-of-the-art methods. Code is available at https://github.com/LINs-lab/ERW.","authors":["Deyuan Liu","Peng Sun","Xufeng Li","Tao Lin"],"url":"https://arxiv.org/abs/2504.10188"}
{"created":"2025-04-15","title":"Differentially Private 2D Human Pose Estimation","abstract":"Human pose estimation (HPE) has become essential in numerous applications including healthcare, activity recognition, and human-computer interaction. However, the privacy implications of processing sensitive visual data present significant deployment barriers in critical domains. While traditional anonymization techniques offer limited protection and often compromise data utility for broader motion analysis, Differential Privacy (DP) provides formal privacy guarantees but typically degrades model performance when applied naively. In this work, we present the first differentially private 2D human pose estimation (2D-HPE) by applying Differentially Private Stochastic Gradient Descent (DP-SGD) to this task. To effectively balance privacy with performance, we adopt Projected DP-SGD (PDP-SGD), which projects the noisy gradients to a low-dimensional subspace. Additionally, we adapt TinyViT, a compact and efficient vision transformer for coordinate classification in HPE, providing a lightweight yet powerful backbone that enhances privacy-preserving deployment feasibility on resource-limited devices. Our approach is particularly valuable for multimedia interpretation tasks, enabling privacy-safe analysis and understanding of human motion across diverse visual media while preserving the semantic meaning required for downstream applications. Comprehensive experiments on the MPII Human Pose Dataset demonstrate significant performance enhancement with PDP-SGD achieving 78.48% PCKh@0.5 at a strict privacy budget ($\\epsilon=0.2$), compared to 63.85% for standard DP-SGD. This work lays foundation for privacy-preserving human pose estimation in real-world, sensitive applications.","authors":["Kaushik Bhargav Sivangi","Idris Zakariyya","Paul Henderson","Fani Deligianni"],"url":"https://arxiv.org/abs/2504.10190"}
{"created":"2025-04-15","title":"Localized Cultural Knowledge is Conserved and Controllable in Large Language Models","abstract":"Just as humans display language patterns influenced by their native tongue when speaking new languages, LLMs often default to English-centric responses even when generating in other languages. Nevertheless, we observe that local cultural information persists within the models and can be readily activated for cultural customization. We first demonstrate that explicitly providing cultural context in prompts significantly improves the models' ability to generate culturally localized responses. We term the disparity in model performance with versus without explicit cultural context the explicit-implicit localization gap, indicating that while cultural knowledge exists within LLMs, it may not naturally surface in multilingual interactions if cultural context is not explicitly provided. Despite the explicit prompting benefit, however, the answers reduce in diversity and tend toward stereotypes. Second, we identify an explicit cultural customization vector, conserved across all non-English languages we explore, which enables LLMs to be steered from the synthetic English cultural world-model toward each non-English cultural world. Steered responses retain the diversity of implicit prompting and reduce stereotypes to dramatically improve the potential for customization. We discuss the implications of explicit cultural customization for understanding the conservation of alternative cultural world models within LLMs, and their controllable utility for translation, cultural customization, and the possibility of making the explicit implicit through soft control for expanded LLM function and appeal.","authors":["Veniamin Veselovsky","Berke Argin","Benedikt Stroebl","Chris Wendler","Robert West","James Evans","Thomas L. Griffiths","Arvind Narayanan"],"url":"https://arxiv.org/abs/2504.10191"}
{"created":"2025-04-15","title":"A Piece of QAICCC: Towards a Countermeasure Against Crosstalk Attacks in Quantum Servers","abstract":"Quantum computing, while allowing for processing information exponentially faster than classical computing, requires computations to be delegated to quantum servers, which makes security threats possible. For instance, previous studies demonstrated that crosstalk between attacker and victim's qubits can be exploited to mount security attacks.","authors":["Yoann Marquer","Domenico Bianculli"],"url":"https://arxiv.org/abs/2504.10193"}
{"created":"2025-04-15","title":"DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation","abstract":"Dynamic Retrieval-augmented Generation (RAG) has shown great success in mitigating hallucinations in large language models (LLMs) during generation. However, existing dynamic RAG methods face significant limitations in two key aspects: 1) Lack of an effective mechanism to control retrieval triggers, and 2) Lack of effective scrutiny of retrieval content. To address these limitations, we propose an innovative dynamic RAG method, DioR (Adaptive Cognitive Detection and Contextual Retrieval Optimization), which consists of two main components: adaptive cognitive detection and contextual retrieval optimization, specifically designed to determine when retrieval is needed and what to retrieve for LLMs is useful. Experimental results demonstrate that DioR achieves superior performance on all tasks, demonstrating the effectiveness of our work.","authors":["Hanghui Guo","Jia Zhu","Shimin Di","Weijie Shi","Zhangze Chen","Jiajie Xu"],"url":"https://arxiv.org/abs/2504.10198"}
{"created":"2025-04-15","title":"VibrantLeaves: A principled parametric image generator for training deep restoration models","abstract":"Even though Deep Neural Networks are extremely powerful for image restoration tasks, they have several limitations. They are poorly understood and suffer from strong biases inherited from the training sets. One way to address these shortcomings is to have a better control over the training sets, in particular by using synthetic sets. In this paper, we propose a synthetic image generator relying on a few simple principles. In particular, we focus on geometric modeling, textures, and a simple modeling of image acquisition. These properties, integrated in a classical Dead Leaves model, enable the creation of efficient training sets. Standard image denoising and super-resolution networks can be trained on such datasets, reaching performance almost on par with training on natural image datasets. As a first step towards explainability, we provide a careful analysis of the considered principles, identifying which image properties are necessary to obtain good performances. Besides, such training also yields better robustness to various geometric and radiometric perturbations of the test sets.","authors":["Raphael Achddou","Yann Gousseau","Sa\\\"id Ladjal","Sabine S\\\"usstrunk"],"url":"https://arxiv.org/abs/2504.10201"}
{"created":"2025-04-15","title":"A moving horizon estimator for aquifer thermal energy storages","abstract":"Aquifer thermal energy storages (ATES) represent groundwater saturated aquifers that store thermal energy in the form of heated or cooled groundwater. Combining two ATES, one can harness excess thermal energy from summer (heat) and winter (cold) to support the building's heating, ventilation, and air conditioning (HVAC) technology. In general, a dynamic operation of ATES throughout the year is beneficial to avoid using fossil fuel-based HVAC technology and maximize the ``green use'' of ATES. Model predictive control (MPC) with an appropriate system model may become a crucial control approach for ATES systems. Consequently, the MPC model should reflect spatial temperature profiles around ATES' boreholes to predict extracted groundwater temperatures accurately. However, meaningful predictions require the estimation of the current state of the system, as measurements are usually only at the borehole of the ATES. In control, this is often realized by model-based observers. Still, observing the state of an ATES system is non-trivial, since the model is typically hybrid. We show how to exploit the specific structure of the hybrid ATES model and design an easy-to-solve moving horizon estimator based on a quadratic program.","authors":["Johannes van Randenborgh","Moritz Schulze Darup"],"url":"https://arxiv.org/abs/2504.10203"}
{"created":"2025-04-15","title":"From Prompting to Alignment: A Generative Framework for Query Recommendation","abstract":"In modern search systems, search engines often suggest relevant queries to users through various panels or components, helping refine their information needs. Traditionally, these recommendations heavily rely on historical search logs to build models, which suffer from cold-start or long-tail issues. Furthermore, tasks such as query suggestion, completion or clarification are studied separately by specific design, which lacks generalizability and hinders adaptation to novel applications. Despite recent attempts to explore the use of LLMs for query recommendation, these methods mainly rely on the inherent knowledge of LLMs or external sources like few-shot examples, retrieved documents, or knowledge bases, neglecting the importance of the calibration and alignment with user feedback, thus limiting their practical utility. To address these challenges, we first propose a general Generative Query Recommendation (GQR) framework that aligns LLM-based query generation with user preference. Specifically, we unify diverse query recommendation tasks by a universal prompt framework, leveraging the instruct-following capability of LLMs for effective generation. Secondly, we align LLMs with user feedback via presenting a CTR-alignment framework, which involves training a query-wise CTR predictor as a process reward model and employing list-wise preference alignment to maximize the click probability of the generated query list. Furthermore, recognizing the inconsistency between LLM knowledge and proactive search intents arising from the separation of user-initiated queries from models, we align LLMs with user initiative via retrieving co-occurrence queries as side information when historical logs are available.","authors":["Erxue Min","Hsiu-Yuan Huang","Min Yang","Xihong Yang","Xin Jia","Yunfang Wu","Hengyi Cai","Shuaiqiang Wang","Dawei Yin"],"url":"https://arxiv.org/abs/2504.10208"}
{"created":"2025-04-15","title":"Can Competition Enhance the Proficiency of Agents Powered by Large Language Models in the Realm of News-driven Time Series Forecasting?","abstract":"Multi-agents-based news-driven time series forecasting is considered as a potential paradigm shift in the era of large language models (LLMs). The challenge of this task lies in measuring the influences of different news events towards the fluctuations of time series. This requires agents to possess stronger abilities of innovative thinking and the identifying misleading logic. However, the existing multi-agent discussion framework has limited enhancement on time series prediction in terms of optimizing these two capabilities. Inspired by the role of competition in fostering innovation, this study embeds a competition mechanism within the multi-agent discussion to enhance agents' capability of generating innovative thoughts. Furthermore, to bolster the model's proficiency in identifying misleading information, we incorporate a fine-tuned small-scale LLM model within the reflective stage, offering auxiliary decision-making support. Experimental results confirm that the competition can boost agents' capacity for innovative thinking, which can significantly improve the performances of time series prediction. Similar to the findings of social science, the intensity of competition within this framework can influence the performances of agents, providing a new perspective for studying LLMs-based multi-agent systems.","authors":["Yuxuan Zhang","Yangyang Feng","Daifeng Li","Kexin Zhang","Junlan Chen","Bowen Deng"],"url":"https://arxiv.org/abs/2504.10210"}
{"created":"2025-04-15","title":"Energy-preserving iteration schemes for Gauss collocation integrators","abstract":"In this work, we develop energy-preserving iterative schemes for the (non-)linear systems arising in the Gauss integration of Poisson systems with quadratic Hamiltonian. Exploiting the relation between Gauss collocation integrators and diagonal Pad\\'e approximations, we establish a Krylov-subspace iteration scheme based on a $Q$-Arnoldi process for linear systems that provides energy conservation not only at convergence --as standard iteration schemes do--, but also at the level of the individual iterates. It is competitive with GMRES in terms of accuracy and cost for a single iteration step and hence offers significant efficiency gains, when it comes to time integration of high-dimensional Poisson systems within given error tolerances. On top of the linear results, we consider non-linear Poisson systems and design non-linear solvers for the implicit midpoint rule (Gauss integrator of second order), using the fact that the associated Pad\\'e approximation is a Cayley transformation. For the non-linear systems arising at each time step, we propose fixed-point and Newton-type iteration schemes that inherit the convergence order with comparable cost from their classical versions, but have energy-preserving iterates.","authors":["Stefan Maier","Nicole Marheineke","Andreas Frommer"],"url":"https://arxiv.org/abs/2504.10211"}
{"created":"2025-04-15","title":"WG-IDENT: Weak Group Identification of PDEs with Varying Coefficients","abstract":"Partial Differential Equations (PDEs) identification is a data-driven method for mathematical modeling, and has received a lot of attentions recently. The stability and precision in identifying PDE from heavily noisy spatiotemporal data present significant difficulties. This problem becomes even more complex when the coefficients of the PDEs are subject to spatial variation. In this paper, we propose a Weak formulation of Group-sparsity-based framework for IDENTifying PDEs with varying coefficients, called WG-IDENT, to tackle this challenge. Our approach utilizes the weak formulation of PDEs to reduce the impact of noise. We represent test functions and unknown PDE coefficients using B-splines, where the knot vectors of test functions are optimally selected based on spectral analysis of the noisy data. To facilitate feature selection, we propose to integrate group sparse regression with a newly designed group feature trimming technique, called GF-trim, to eliminate unimportant features. Extensive and comparative ablation studies are conducted to validate our proposed method. The proposed method not only demonstrates greater robustness to high noise levels compared to state-of-the-art algorithms but also achieves superior performance while exhibiting reduced sensitivity to hyperparameter selection.","authors":["Cheng Tang","Roy Y. He","Hao Liu"],"url":"https://arxiv.org/abs/2504.10212"}
{"created":"2025-04-15","title":"Balancing Stability and Plasticity in Pretrained Detector: A Dual-Path Framework for Incremental Object Detection","abstract":"The balance between stability and plasticity remains a fundamental challenge in pretrained model-based incremental object detection (PTMIOD). While existing PTMIOD methods demonstrate strong performance on in-domain tasks aligned with pretraining data, their plasticity to cross-domain scenarios remains underexplored. Through systematic component-wise analysis of pretrained detectors, we reveal a fundamental discrepancy: the localization modules demonstrate inherent cross-domain stability-preserving precise bounding box estimation across distribution shifts-while the classification components require enhanced plasticity to mitigate discriminability degradation in cross-domain scenarios. Motivated by these findings, we propose a dual-path framework built upon pretrained DETR-based detectors which decouples localization stability and classification plasticity: the localization path maintains stability to preserve pretrained localization knowledge, while the classification path facilitates plasticity via parameter-efficient fine-tuning and resists forgetting with pseudo-feature replay. Extensive evaluations on both in-domain (MS COCO and PASCAL VOC) and cross-domain (TT100K) benchmarks show state-of-the-art performance, demonstrating our method's ability to effectively balance stability and plasticity in PTMIOD, achieving robust cross-domain adaptation and strong retention of anti-forgetting capabilities.","authors":["Songze Li","Qixing Xu","Tonghua Su","Xu-Yao Zhang","Zhongjie Wang"],"url":"https://arxiv.org/abs/2504.10214"}
{"created":"2025-04-15","title":"PRM-BAS: Enhancing Multimodal Reasoning through PRM-guided Beam Annealing Search","abstract":"Recent work increasingly focuses on improving the reasoning capabilities of Multimodal Large Language Models (MLLMs). Among existing methods, Process Reward Models (PRMs) stand out for offering dense, step-wise supervision to guide intermediate reasoning. However, how to effectively integrate PRMs into search strategies remains an open question. In this paper, we introduce PRM-BAS (PRM-Guided Beam Annealing Search), a lightweight approach for PRM-guided reasoning that dynamically adjusts beam size -- starting with a broader search space and gradually narrowing it as contextual information accumulates, thereby balancing performance and efficiency. We further propose a unified framework for data construction and PRM training. Specifically, we construct the PRM-BAS-300k dataset by selecting 300k questions from existing datasets and performing rollouts at each step to estimate the probability of reaching a correct final answer. The PRM is then trained using a combination of value loss for absolute action quality and rank loss for relative action quality. Extensive experiments on challenging multimodal reasoning benchmarks demonstrate that PRM-BAS significantly improves reasoning performance while maintaining low computational cost. Moreover, it generalizes well across different model scales and architectures, showcasing strong robustness and plug-and-play capability.","authors":["Pengfei Hu","Zhenrong Zhang","Qikai Chang","Shuhang Liu","Jiefeng Ma","Jun Du","Jianshu Zhang","Quan Liu","Jianqing Gao","Feng Ma","Qingfeng Liu"],"url":"https://arxiv.org/abs/2504.10222"}
{"created":"2025-04-15","title":"A Quasi-Steady-State Black Box Simulation Approach for the Generation of g-g-g-v Diagrams","abstract":"The classical g-g diagram, representing the achievable acceleration space for a vehicle, is commonly used as a constraint in trajectory planning and control due to its computational simplicity. To address non-planar road geometries, this concept can be extended to incorporate g-g constraints as a function of vehicle speed and vertical acceleration, commonly referred to as g-g-g-v diagrams. However, the estimation of g-g-g-v diagrams is an open problem. Existing simulation-based approaches struggle to isolate non-transient, open-loop stable states across all combinations of speed and acceleration, while optimization-based methods often require simplified vehicle equations and have potential convergence issues. In this paper, we present a novel, open-source, quasi-steady-state black box simulation approach that applies a virtual inertial force in the longitudinal direction. The method emulates the load conditions associated with a specified longitudinal acceleration while maintaining constant vehicle speed, enabling open-loop steering ramps in a purely QSS manner. Appropriate regulation of the ramp steer rate inherently mitigates transient vehicle dynamics when determining the maximum feasible lateral acceleration. Moreover, treating the vehicle model as a black box eliminates model mismatch issues, allowing the use of high-fidelity or proprietary vehicle dynamics models typically unsuited for optimization approaches. An open-source version of the proposed method is available at: https://github.com/TUM-AVS/GGGVDiagrams","authors":["Frederik Werner","Simon Sagmeister","Mattia Piccinini","Johannes Betz"],"url":"https://arxiv.org/abs/2504.10225"}
{"created":"2025-04-15","title":"Probing then Editing Response Personality of Large Language Models","abstract":"Large Language Models (LLMs) have demonstrated promising capabilities to generate responses that exhibit consistent personality traits. Despite the major attempts to analyze personality expression through output-based evaluations, little is known about how such traits are internally encoded within LLM parameters. In this paper, we introduce a layer-wise probing framework to systematically investigate the layer-wise capability of LLMs in encoding personality for responding. We conduct probing experiments on 11 open-source LLMs over the PersonalityEdit benchmark and find that LLMs predominantly encode personality for responding in their middle and upper layers, with instruction-tuned models demonstrating a slightly clearer separation of personality traits. Furthermore, by interpreting the trained probing hyperplane as a layer-wise boundary for each personality category, we propose a layer-wise perturbation method to edit the personality expressed by LLMs during inference. Our results show that even when the prompt explicitly specifies a particular personality, our method can still successfully alter the response personality of LLMs. Interestingly, the difficulty of converting between certain personality traits varies substantially, which aligns with the representational distances in our probing experiments. Finally, we conduct a comprehensive MMLU benchmark evaluation and time overhead analysis, demonstrating that our proposed personality editing method incurs only minimal degradation in general capabilities while maintaining low training costs and acceptable inference latency. Our code is publicly available at https://github.com/universe-sky/probing-then-editing-personality.","authors":["Tianjie Ju","Zhenyu Shao","Bowen Wang","Yujia Chen","Zhuosheng Zhang","Hao Fei","Mong-Li Lee","Wynne Hsu","Sufeng Duan","Gongshen Liu"],"url":"https://arxiv.org/abs/2504.10227"}
{"created":"2025-04-15","title":"ROSFD: Robust Online Streaming Fraud Detection with Resilience to Concept Drift in Data Streams","abstract":"Continuous generation of streaming data from diverse sources, such as online transactions and digital interactions, necessitates timely fraud detection. Traditional batch processing methods often struggle to capture the rapidly evolving patterns of fraudulent activities. This paper highlights the critical importance of processing streaming data for effective fraud detection. To address the inherent challenges of latency, scalability, and concept drift in streaming environments, we propose a robust online streaming fraud detection (ROSFD) framework. Our proposed framework comprises two key stages: (i) Stage One: Offline Model Initialization. In this initial stage, a model is built in offline settings using incremental learning principles to overcome the \"cold-start\" problem. (ii) Stage Two: Real-time Model Adaptation. In this dynamic stage, drift detection algorithms (viz.,, DDM, EDDM, and ADWIN) are employed to identify concept drift in the incoming data stream and incrementally train the model accordingly. This \"train-only-when-required\" strategy drastically reduces the number of retrains needed without significantly impacting the area under the receiver operating characteristic curve (AUC). Overall, ROSFD utilizing ADWIN as the drift detection method demonstrated the best performance among the employed methods. In terms of model efficacy, Adaptive Random Forest consistently outperformed other models, achieving the highest AUC in four out of five datasets.","authors":["Vivek Yelleti"],"url":"https://arxiv.org/abs/2504.10229"}
{"created":"2025-04-15","title":"A Model Zoo of Vision Transformers","abstract":"The availability of large, structured populations of neural networks - called 'model zoos' - has led to the development of a multitude of downstream tasks ranging from model analysis, to representation learning on model weights or generative modeling of neural network parameters. However, existing model zoos are limited in size and architecture and neglect the transformer, which is among the currently most successful neural network architectures. We address this gap by introducing the first model zoo of vision transformers (ViT). To better represent recent training approaches, we develop a new blueprint for model zoo generation that encompasses both pre-training and fine-tuning steps, and publish 250 unique models. They are carefully generated with a large span of generating factors, and their diversity is validated using a thorough choice of weight-space and behavioral metrics. To further motivate the utility of our proposed dataset, we suggest multiple possible applications grounded in both extensive exploratory experiments and a number of examples from the existing literature. By extending previous lines of similar work, our model zoo allows researchers to push their model population-based methods from the small model regime to state-of-the-art architectures. We make our model zoo available at github.com/ModelZoos/ViTModelZoo.","authors":["Damian Falk","L\\'eo Meynent","Florence Pfammatter","Konstantin Sch\\\"urholt","Damian Borth"],"url":"https://arxiv.org/abs/2504.10231"}
{"created":"2025-04-15","title":"Fairness and Efficiency in Two-Sided Matching Markets","abstract":"We propose a new fairness notion, motivated by the practical challenge of allocating teaching assistants (TAs) to courses in a department. Each course requires a certain number of TAs and each TA has preferences over the courses they want to assist. Similarly, each course instructor has preferences over the TAs who applied for their course. We demand fairness and efficiency for both sides separately, giving rise to the following criteria: (i) every course gets the required number of TAs and the average utility of the assigned TAs meets a threshold; (ii) the allocation of courses to TAs is envy-free, where a TA envies another TA if the former prefers the latter's course and has a higher or equal grade in that course. Note that the definition of envy-freeness here differs from the one in the literature, and we call it merit-based envy-freeness.","authors":["Pallavi Jain","Palash Jha","Shubham Solanki"],"url":"https://arxiv.org/abs/2504.10232"}
{"created":"2025-04-15","title":"Bingo: Radix-based Bias Factorization for Random Walk on Dynamic Graphs","abstract":"Random walks are a primary means for extracting information from large-scale graphs. While most real-world graphs are inherently dynamic, state-of-the-art random walk engines failed to efficiently support such a critical use case. This paper takes the initiative to build a general random walk engine for dynamically changing graphs with two key principles: (i) This system should support both low-latency streaming updates and high-throughput batched updates. (ii) This system should achieve fast sampling speed while maintaining acceptable space consumption to support dynamic graph updates. Upholding both standards, we introduce Bingo, a GPU-based random walk engine for dynamically changing graphs. First, we propose a novel radix-based bias factorization algorithm to support constant time sampling complexity while supporting fast streaming updates. Second, we present a group-adaption design to reduce space consumption dramatically. Third, we incorporate GPU-aware designs to support high-throughput batched graph updates on massively parallel platforms. Together, Bingo outperforms existing efforts across various applications, settings, and datasets, achieving up to a 271.11x speedup compared to the state-of-the-art efforts.","authors":["Pinhuan Wang","Chengying Huan","Zhibin Wang","Chen Tian","Yuede Ji","Hang Liu"],"url":"https://arxiv.org/abs/2504.10233"}
{"created":"2025-04-15","title":"Resolving Nondeterminism by Chance","abstract":"History-deterministic automata are those in which nondeterministic choices can be correctly resolved stepwise: there is a strategy to select a continuation of a run given the next input letter so that if the overall input word admits some accepting run, then the constructed run is also accepting.","authors":["Soumyajit Paul","David Purser","Sven Schewe","Qiyi Tang","Patrick Totzke","Di-De Yen"],"url":"https://arxiv.org/abs/2504.10234"}
{"created":"2025-04-15","title":"GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction","abstract":"Circuit link prediction identifying missing component connections from incomplete netlists is crucial in automating analog circuit design. However, existing methods face three main challenges: 1) Insufficient use of topological patterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to the complexity of annotations hinders model generalization; 3) Limited adaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural Networks (GNNs) based framework featuring three innovations to tackle these challenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes for Link Prediction) framework and achieve port-level accuracy in circuit link prediction. Second, we propose Netlist Babel Fish, a netlist format conversion tool leveraging retrieval-augmented generation (RAG) with large language model (LLM) to enhance the compatibility of netlist formats. Finally, we construct SpiceNetlist, a comprehensive dataset that contains 775 annotated circuits across 10 different classes of components. The experimental results demonstrate an improvement of 15.05% on the SpiceNetlist dataset and 12.01% on the Image2Net dataset over the existing approach.","authors":["Guanyuan Pan","Tiansheng Zhou","Bingtao Ma","Yaqi Wang","Jianxiang Zhao","Shuai Wang"],"url":"https://arxiv.org/abs/2504.10240"}
{"created":"2025-04-15","title":"CAT: A Conditional Adaptation Tailor for Efficient and Effective Instance-Specific Pansharpening on Real-World Data","abstract":"Pansharpening is a crucial remote sensing technique that fuses low-resolution multispectral (LRMS) images with high-resolution panchromatic (PAN) images to generate high-resolution multispectral (HRMS) imagery. Although deep learning techniques have significantly advanced pansharpening, many existing methods suffer from limited cross-sensor generalization and high computational overhead, restricting their real-time applications. To address these challenges, we propose an efficient framework that quickly adapts to a specific input instance, completing both training and inference in a short time. Our framework splits the input image into multiple patches, selects a subset for unsupervised CAT training, and then performs inference on all patches, stitching them into the final output. The CAT module, integrated between the feature extraction and channel transformation stages of a pre-trained network, tailors the fused features and fixes the parameters for efficient inference, generating improved results. Our approach offers two key advantages: (1) $\\textit{Improved Generalization Ability}$: by mitigating cross-sensor degradation, our model--although pre-trained on a specific dataset--achieves superior performance on datasets captured by other sensors; (2) $\\textit{Enhanced Computational Efficiency}$: the CAT-enhanced network can swiftly adapt to the test sample using the single LRMS-PAN pair input, without requiring extensive large-scale data retraining. Experiments on the real-world data from WorldView-3 and WorldView-2 datasets demonstrate that our method achieves state-of-the-art performance on cross-sensor real-world data, while achieving both training and inference of $512\\times512$ image within $\\textit{0.4 seconds}$ and $4000\\times4000$ image within $\\textit{3 seconds}$ at the fastest setting on a commonly used RTX 3090 GPU.","authors":["Tianyu Xin","Jin-Liang Xiao","Zeyu Xia","Shan Yin","Liang-Jian Deng"],"url":"https://arxiv.org/abs/2504.10242"}
{"created":"2025-04-15","title":"Simplified and Verified: A Second Look at a Proof-Producing Union-Find Algorithm","abstract":"Using Isabelle/HOL, we verify a union-find data structure with an explain operation due to Nieuwenhuis and Oliveras. We devise a simpler, more naive version of the explain operation whose soundness and completeness is easy to verify. Then, we prove the original formulation of the explain operation to be equal to our version. Finally, we refine this data structure to Imperative HOL, enabling us to export efficient imperative code. The formalisation provides a stepping stone towards the verification of proof-producing congruence closure algorithms which are a core ingredient of Satisfiability Modulo Theories (SMT) solvers.","authors":["Lukas Stevens","Rebecca Ghidini"],"url":"https://arxiv.org/abs/2504.10246"}
{"created":"2025-04-15","title":"Struggle First, Prompt Later: How Task Complexity Shapes Learning with GenAI-Assisted Pretesting","abstract":"This study examines the role of AI-assisted pretesting in enhancing learning outcomes, particularly when integrated with generative AI tools like ChatGPT. Pretesting, a learning strategy in which students attempt to answer questions or solve problems before receiving instruction, has been shown to improve retention by activating prior knowledge. The adaptability and interactivity of AI-assisted pretesting introduce new opportunities for optimizing learning in digital environments. Across three experimental studies, we explored how pretesting strategies, task characteristics, and student motivation influence learning. Findings suggest that AI-assisted pretesting enhances learning outcomes, particularly for tasks requiring higher-order thinking. While adaptive AI-driven pretesting increased engagement, its benefits were most pronounced in complex, exploratory tasks rather than straightforward computational problems. These results highlight the importance of aligning pretesting strategies with task demands, demonstrating that AI can optimize learning when applied to tasks requiring deeper cognitive engagement. This research provides insights into how AI-assisted pretesting can be effectively integrated with generative AI tools to enhance both cognitive and motivational outcomes in learning environments.","authors":["Mahir Akgun","Sacip Toker"],"url":"https://arxiv.org/abs/2504.10249"}
{"created":"2025-04-15","title":"MURR: Model Updating with Regularized Replay for Searching a Document Stream","abstract":"The Internet produces a continuous stream of new documents and user-generated queries. These naturally change over time based on events in the world and the evolution of language. Neural retrieval models that were trained once on a fixed set of query-document pairs will quickly start misrepresenting newly-created content and queries, leading to less effective retrieval. Traditional statistical sparse retrieval can update collection statistics to reflect these changes in the use of language in documents and queries. In contrast, continued fine-tuning of the language model underlying neural retrieval approaches such as DPR and ColBERT creates incompatibility with previously-encoded documents. Re-encoding and re-indexing all previously-processed documents can be costly. In this work, we explore updating a neural dual encoder retrieval model without reprocessing past documents in the stream. We propose MURR, a model updating strategy with regularized replay, to ensure the model can still faithfully search existing documents without reprocessing, while continuing to update the model for the latest topics. In our simulated streaming environments, we show that fine-tuning models using MURR leads to more effective and more consistent retrieval results than other strategies as the stream of documents and queries progresses.","authors":["Eugene Yang","Nicola Tonellotto","Dawn Lawrie","Sean MacAvaney","James Mayfield","Douglas W. Oard","Scott Miller"],"url":"https://arxiv.org/abs/2504.10250"}
{"created":"2025-04-15","title":"TinyverseGP: Towards a Modular Cross-domain Benchmarking Framework for Genetic Programming","abstract":"Over the years, genetic programming (GP) has evolved, with many proposed variations, especially in how they represent a solution. Being essentially a program synthesis algorithm, it is capable of tackling multiple problem domains. Current benchmarking initiatives are fragmented, as the different representations are not compared with each other and their performance is not measured across the different domains. In this work, we propose a unified framework, dubbed TinyverseGP (inspired by tinyGP), which provides support to multiple representations and problem domains, including symbolic regression, logic synthesis and policy search.","authors":["Roman Kalkreuth","Fabricio Olivetti de Fran\\c{c}a","Julian Dierkes","Marie Anastacio","Anja Jankovic","Zdenek Vasicek","Holger Hoos"],"url":"https://arxiv.org/abs/2504.10253"}
{"created":"2025-04-15","title":"MASSeg : 2nd Technical Report for 4th PVUW MOSE Track","abstract":"Complex video object segmentation continues to face significant challenges in small object recognition, occlusion handling, and dynamic scene modeling. This report presents our solution, which ranked second in the MOSE track of CVPR 2025 PVUW Challenge. Based on an existing segmentation framework, we propose an improved model named MASSeg for complex video object segmentation, and construct an enhanced dataset, MOSE+, which includes typical scenarios with occlusions, cluttered backgrounds, and small target instances. During training, we incorporate a combination of inter-frame consistent and inconsistent data augmentation strategies to improve robustness and generalization. During inference, we design a mask output scaling strategy to better adapt to varying object sizes and occlusion levels. As a result, MASSeg achieves a J score of 0.8250, F score of 0.9007, and a J&amp;F score of 0.8628 on the MOSE test set.","authors":["Xuqiang Cao","Linnan Zhao","Jiaxuan Zhao","Fang Liu","Puhua Chen","Wenping Ma"],"url":"https://arxiv.org/abs/2504.10254"}
{"created":"2025-04-15","title":"XY-Cut++: Advanced Layout Ordering via Hierarchical Mask Mechanism on a Novel Benchmark","abstract":"Document Reading Order Recovery is a fundamental task in document image understanding, playing a pivotal role in enhancing Retrieval-Augmented Generation (RAG) and serving as a critical preprocessing step for large language models (LLMs). Existing methods often struggle with complex layouts(e.g., multi-column newspapers), high-overhead interactions between cross-modal elements (visual regions and textual semantics), and a lack of robust evaluation benchmarks. We introduce XY-Cut++, an advanced layout ordering method that integrates pre-mask processing, multi-granularity segmentation, and cross-modal matching to address these challenges. Our method significantly enhances layout ordering accuracy compared to traditional XY-Cut techniques. Specifically, XY-Cut++ achieves state-of-the-art performance (98.8 BLEU overall) while maintaining simplicity and efficiency. It outperforms existing baselines by up to 24\\% and demonstrates consistent accuracy across simple and complex layouts on the newly introduced DocBench-100 dataset. This advancement establishes a reliable foundation for document structure recovery, setting a new standard for layout ordering tasks and facilitating more effective RAG and LLM preprocessing.","authors":["Shuai Liu","Youmeng Li","Jizeng Wei"],"url":"https://arxiv.org/abs/2504.10258"}
{"created":"2025-04-15","title":"Dual-grid parameter choice method with application to image deblurring","abstract":"Variational regularization of ill-posed inverse problems is based on minimizing the sum of a data fidelity term and a regularization term. The balance between them is tuned using a positive regularization parameter, whose automatic choice remains an open question in general. A novel approach for parameter choice is introduced, based on the use of two slightly different computational models for the same inverse problem. Small parameter values should give two very different reconstructions due to amplification of noise. Large parameter values lead to two identical but trivial reconstructions. Optimal parameter is chosen between the extremes by matching image similarity of the two reconstructions with a pre-defined value. Efficacy of the new method is demonstrated with image deblurring using measured data and two different regularizers.","authors":["Markus Juvonen","Bj{\\o}rn Jensen","Ilmari Pohjola","Yiqiu Dong","Samuli Siltanen"],"url":"https://arxiv.org/abs/2504.10259"}
{"created":"2025-04-15","title":"When Technologies Are Not Enough: Understanding How Domestic Workers Employ (and Avoid) Online Technologies in Their Work Practices","abstract":"Although domestic work is often viewed as manual labor, it involves significant interaction with online technologies. However, the detailed exploration of how domestic workers use these technologies remains limited. This study examines the impact of online technologies on domestic workers' work practices, perceptions, and relationships with customers and employers. We interviewed 30 domestic workers residing in the United States, who provided examples that highlight the insufficient transformative role of current online technologies in their work. By conducting a thematic analysis, we characterize how they approach and avoid these digital tools at different stages of their work. Through these findings, we investigate the limitations of technology and identify challenges and opportunities that could inform the design of more suitable tools to improve the conditions of this marginalized group.","authors":["Mariana Fernandez-Espinosa","Mariana Gonzalez-Bejar","Jacobo Wiesner","Diego Gomez-Zara"],"url":"https://arxiv.org/abs/2504.10265"}
{"created":"2025-04-15","title":"Vision based driving agent for race car simulation environments","abstract":"In recent years, autonomous driving has become a popular field of study. As control at tire grip limit is essential during emergency situations, algorithms developed for racecars are useful for road cars too. This paper examines the use of Deep Reinforcement Learning (DRL) to solve the problem of grip limit driving in a simulated environment. Proximal Policy Optimization (PPO) method is used to train an agent to control the steering wheel and pedals of the vehicle, using only visual inputs to achieve professional human lap times. The paper outlines the formulation of the task of time optimal driving on a race track as a deep reinforcement learning problem, and explains the chosen observations, actions, and reward functions. The results demonstrate human-like learning and driving behavior that utilize maximum tire grip potential.","authors":["Gergely B\\'ari","L\\'aszl\\'o Palkovics"],"url":"https://arxiv.org/abs/2504.10266"}
{"created":"2025-04-15","title":"Trade-offs in Privacy-Preserving Eye Tracking through Iris Obfuscation: A Benchmarking Study","abstract":"Recent developments in hardware, computer graphics, and AI may soon enable AR/VR head-mounted displays (HMDs) to become everyday devices like smartphones and tablets. Eye trackers within HMDs provide a special opportunity for such setups as it is possible to facilitate gaze-based research and interaction. However, estimating users' gaze information often requires raw eye images and videos that contain iris textures, which are considered a gold standard biometric for user authentication, and this raises privacy concerns. Previous research in the eye-tracking community focused on obfuscating iris textures while keeping utility tasks such as gaze estimation accurate. Despite these attempts, there is no comprehensive benchmark that evaluates state-of-the-art approaches. Considering all, in this paper, we benchmark blurring, noising, downsampling, rubber sheet model, and iris style transfer to obfuscate user identity, and compare their impact on image quality, privacy, utility, and risk of imposter attack on two datasets. We use eye segmentation and gaze estimation as utility tasks, and reduction in iris recognition accuracy as a measure of privacy protection, and false acceptance rate to estimate risk of attack. Our experiments show that canonical image processing methods like blurring and noising cause a marginal impact on deep learning-based tasks. While downsampling, rubber sheet model, and iris style transfer are effective in hiding user identifiers, iris style transfer, with higher computation cost, outperforms others in both utility tasks, and is more resilient against spoof attacks. Our analyses indicate that there is no universal optimal approach to balance privacy, utility, and computation burden. Therefore, we recommend practitioners consider the strengths and weaknesses of each approach, and possible combinations of those to reach an optimal privacy-utility trade-off.","authors":["Mengdi Wang","Efe Bozkir","Enkelejda Kasneci"],"url":"https://arxiv.org/abs/2504.10267"}
{"created":"2025-04-15","title":"Change Your Perspective, Widen Your Worldview! Societally Beneficial Perceptual Filter Bubbles in Personalized Reality","abstract":"Extended Reality (XR) technologies enable the personalized mediation of an individual's perceivable reality across modalities, thereby creating a Personalized Reality (PR). While this may lead to individually beneficial effects in the form of more efficient, more fun, and safer experiences, it may also lead to perceptual filter bubbles since individuals are exposed predominantly or exclusively to content that is congruent with their existing beliefs and opinions. This undermining of a shared basis for interaction and discussion through constrained perceptual worldviews may impact society through increased polarization and other well-documented negative effects of filter bubbles. In this paper, we argue that this issue can be mitigated by increasing individuals' awareness of their current perspective and providing avenues for development, including through support for engineered serendipity and fostering of self-actualization that already show promise for traditional recommender systems. We discuss how these methods may be transferred to XR to yield valuable tools to give people transparency and agency over their perceptual worldviews in a responsible manner.","authors":["Jannis Strecker","Luka Bekavac","Kenan Bekta\\c{s}","Simon Mayer"],"url":"https://arxiv.org/abs/2504.10271"}
{"created":"2025-04-15","title":"Sidecar: A Structure-Preserving Framework for Solving Partial Differential Equations with Neural Networks","abstract":"Solving partial differential equations (PDEs) with neural networks (NNs) has shown great potential in various scientific and engineering fields. However, most existing NN solvers mainly focus on satisfying the given PDEs, without explicitly considering intrinsic physical properties such as mass conservation or energy dissipation. This limitation can result in unstable or nonphysical solutions, particularly in long-term simulations. To address this issue, we propose Sidecar, a novel framework that enhances the accuracy and physical consistency of existing NN solvers by incorporating structure-preserving knowledge. Inspired by the Time-Dependent Spectral Renormalization (TDSR) approach, our Sidecar framework introduces a small copilot network, which is trained to guide the existing NN solver in preserving physical structure. This framework is designed to be highly flexible, enabling the incorporation of structure-preserving principles from diverse PDEs into a wide range of NN solvers. Our experimental results on benchmark PDEs demonstrate the improvement of the existing neural network solvers in terms of accuracy and consistency with structure-preserving properties.","authors":["Gaohang Chen","Zhonghua Qiao"],"url":"https://arxiv.org/abs/2504.10273"}
{"created":"2025-04-15","title":"LMFormer: Lane based Motion Prediction Transformer","abstract":"Motion prediction plays an important role in autonomous driving. This study presents LMFormer, a lane-aware transformer network for trajectory prediction tasks. In contrast to previous studies, our work provides a simple mechanism to dynamically prioritize the lanes and shows that such a mechanism introduces explainability into the learning behavior of the network. Additionally, LMFormer uses the lane connection information at intersections, lane merges, and lane splits, in order to learn long-range dependency in lane structure. Moreover, we also address the issue of refining the predicted trajectories and propose an efficient method for iterative refinement through stacked transformer layers. For benchmarking, we evaluate LMFormer on the nuScenes dataset and demonstrate that it achieves SOTA performance across multiple metrics. Furthermore, the Deep Scenario dataset is used to not only illustrate cross-dataset network performance but also the unification capabilities of LMFormer to train on multiple datasets and achieve better performance.","authors":["Harsh Yadav","Maximilian Schaefer","Kun Zhao","Tobias Meisen"],"url":"https://arxiv.org/abs/2504.10275"}
{"created":"2025-04-15","title":"Who Speaks for Ethics? How Demographics Shape Ethical Advocacy in Software Development","abstract":"The integration of ethics into software development faces significant challenges due to market fundamentalism in organizational practices, where profit often takes precedence over ethical considerations. Additionally, the critical influence of practitioners' individual backgrounds on ethical decision-making remains underexplored, highlighting a gap in comprehensive research. This is especially essential to understand due to the demographic imbalance in software roles. This study investigates ethical concerns in software development, focusing on how they are perceived, prioritized, and addressed by demographically different practitioners. By surveying 217 software practitioners across diverse roles, industries, and countries, we identify critical barriers to ethical integration and examine practitioners' capacity to mitigate these issues. Our findings reveal pronounced demographic disparities, with marginalized groups - including women, BIPOC, and disabled individuals - reporting ethical concerns at higher frequencies. Notably, marginalized practitioners demonstrated heightened sensitivity to ethical implementation and greater empowerment to address them. However, practitioners overall often lack the support needed to address ethical challenges effectively. These insights underscore the urgent need for reforms in software education and development processes that center on diverse perspectives. Such reforms are essential to advancing ethical integration in software development and ensuring responsible computing practices in an increasingly complex technological landscape.","authors":["Lauren Olson","Ricarda Anna-Lena Fischer","Florian Kunneman","Emitz\\'a Guzm\\'an"],"url":"https://arxiv.org/abs/2504.10276"}
{"created":"2025-04-15","title":"RealHarm: A Collection of Real-World Language Model Application Failures","abstract":"Language model deployments in consumer-facing applications introduce numerous risks. While existing research on harms and hazards of such applications follows top-down approaches derived from regulatory frameworks and theoretical analyses, empirical evidence of real-world failure modes remains underexplored. In this work, we introduce RealHarm, a dataset of annotated problematic interactions with AI agents built from a systematic review of publicly reported incidents. Analyzing harms, causes, and hazards specifically from the deployer's perspective, we find that reputational damage constitutes the predominant organizational harm, while misinformation emerges as the most common hazard category. We empirically evaluate state-of-the-art guardrails and content moderation systems to probe whether such systems would have prevented the incidents, revealing a significant gap in the protection of AI applications.","authors":["Pierre Le Jeune","Jiaen Liu","Luca Rossi","Matteo Dora"],"url":"https://arxiv.org/abs/2504.10277"}
{"created":"2025-04-15","title":"DiffMOD: Progressive Diffusion Point Denoising for Moving Object Detection in Remote Sensing","abstract":"Moving object detection (MOD) in remote sensing is significantly challenged by low resolution, extremely small object sizes, and complex noise interference. Current deep learning-based MOD methods rely on probability density estimation, which restricts flexible information interaction between objects and across temporal frames. To flexibly capture high-order inter-object and temporal relationships, we propose a point-based MOD in remote sensing. Inspired by diffusion models, the network optimization is formulated as a progressive denoising process that iteratively recovers moving object centers from sparse noisy points. Specifically, we sample scattered features from the backbone outputs as atomic units for subsequent processing, while global feature embeddings are aggregated to compensate for the limited coverage of sparse point features. By modeling spatial relative positions and semantic affinities, Spatial Relation Aggregation Attention is designed to enable high-order interactions among point-level features for enhanced object representation. To enhance temporal consistency, the Temporal Propagation and Global Fusion module is designed, which leverages an implicit memory reasoning mechanism for robust cross-frame feature integration. To align with the progressive denoising process, we propose a progressive MinK optimal transport assignment strategy that establishes specialized learning objectives at each denoising level. Additionally, we introduce a missing loss function to counteract the clustering tendency of denoised points around salient objects. Experiments on the RsData remote sensing MOD dataset show that our MOD method based on scattered point denoising can more effectively explore potential relationships between sparse moving objects and improve the detection capability and temporal consistency.","authors":["Jinyue Zhang","Xiangrong Zhang","Zhongjian Huang","Tianyang Zhang","Yifei Jiang","Licheng Jiao"],"url":"https://arxiv.org/abs/2504.10278"}
{"created":"2025-04-15","title":"Look-to-Touch: A Vision-Enhanced Proximity and Tactile Sensor for Distance and Geometry Perception in Robotic Manipulation","abstract":"Camera-based tactile sensors provide robots with a high-performance tactile sensing approach for environment perception and dexterous manipulation. However, achieving comprehensive environmental perception still requires cooperation with additional sensors, which makes the system bulky and limits its adaptability to unstructured environments. In this work, we present a vision-enhanced camera-based dual-modality sensor, which realizes full-scale distance sensing from 50 cm to -3 mm while simultaneously keeping ultra-high-resolution texture sensing and reconstruction capabilities. Unlike conventional designs with fixed opaque gel layers, our sensor features a partially transparent sliding window, enabling mechanical switching between tactile and visual modes. For each sensing mode, a dynamic distance sensing model and a contact geometry reconstruction model are proposed. Through integration with soft robotic fingers, we systematically evaluate the performance of each mode, as well as in their synergistic operation. Experimental results show robust distance tracking across various speeds, nanometer-scale roughness detection, and sub-millimeter 3D texture reconstruction. The combination of both modalities improves the robot's efficiency in executing grasping tasks. Furthermore, the embedded mechanical transmission in the sensor allows for fine-grained intra-hand adjustments and precise manipulation, unlocking new capabilities for soft robotic hands.","authors":["Yueshi Dong","Jieji Ren","Zhenle Liu","Zhanxuan Peng","Zihao Yuan","Ningbin Zhang","Guoying Gu"],"url":"https://arxiv.org/abs/2504.10280"}
{"created":"2025-04-15","title":"$\\alpha$-Flow: A Unified Framework for Continuous-State Discrete Flow Matching Models","abstract":"Recent efforts have extended the flow-matching framework to discrete generative modeling. One strand of models directly works with the continuous probabilities instead of discrete tokens, which we colloquially refer to as Continuous-State Discrete Flow Matching (CS-DFM). Existing CS-DFM models differ significantly in their representations and geometric assumptions. This work presents a unified framework for CS-DFM models, under which the existing variants can be understood as operating on different $\\alpha$-representations of probabilities. Building upon the theory of information geometry, we introduce $\\alpha$-Flow, a family of CS-DFM models that adheres to the canonical $\\alpha$-geometry of the statistical manifold, and demonstrate its optimality in minimizing the generalized kinetic energy. Theoretically, we show that the flow matching loss for $\\alpha$-flow establishes a unified variational bound for the discrete negative log-likelihood. We comprehensively evaluate different instantiations of $\\alpha$-flow on various discrete generation domains to demonstrate their effectiveness in discrete generative modeling, including intermediate values whose geometries have never been explored before. $\\alpha$-flow significantly outperforms its discrete-state counterpart in image and protein sequence generation and better captures the entropy in language modeling.","authors":["Chaoran Cheng","Jiahan Li","Jiajun Fan","Ge Liu"],"url":"https://arxiv.org/abs/2504.10283"}
{"created":"2025-04-15","title":"Can LLMs Generate Tabular Summaries of Science Papers? Rethinking the Evaluation Protocol","abstract":"Literature review tables are essential for summarizing and comparing collections of scientific papers. We explore the task of generating tables that best fulfill a user's informational needs given a collection of scientific papers. Building on recent work (Newman et al., 2024), we extend prior approaches to address real-world complexities through a combination of LLM-based methods and human annotations. Our contributions focus on three key challenges encountered in real-world use: (i) User prompts are often under-specified; (ii) Retrieved candidate papers frequently contain irrelevant content; and (iii) Task evaluation should move beyond shallow text similarity techniques and instead assess the utility of inferred tables for information-seeking tasks (e.g., comparing papers). To support reproducible evaluation, we introduce ARXIV2TABLE, a more realistic and challenging benchmark for this task, along with a novel approach to improve literature review table generation in real-world scenarios. Our extensive experiments on this benchmark show that both open-weight and proprietary LLMs struggle with the task, highlighting its difficulty and the need for further advancements. Our dataset and code are available at https://github.com/JHU-CLSP/arXiv2Table.","authors":["Weiqi Wang","Jiefu Ou","Yangqiu Song","Benjamin Van Durme","Daniel Khashabi"],"url":"https://arxiv.org/abs/2504.10284"}
{"created":"2025-04-15","title":"Characterizing LLM-driven Social Network: The Chirper.ai Case","abstract":"Large language models (LLMs) demonstrate the ability to simulate human decision-making processes, enabling their use as agents in modeling sophisticated social networks, both offline and online. Recent research has explored collective behavioral patterns and structural characteristics of LLM agents within simulated networks. However, empirical comparisons between LLM-driven and human-driven online social networks remain scarce, limiting our understanding of how LLM agents differ from human users. This paper presents a large-scale analysis of Chirper.ai, an X/Twitter-like social network entirely populated by LLM agents, comprising over 65,000 agents and 7.7 million AI-generated posts. For comparison, we collect a parallel dataset from Mastodon, a human-driven decentralized social network, with over 117,000 users and 16 million posts. We examine key differences between LLM agents and humans in posting behaviors, abusive content, and social network structures. Our findings provide critical insights into the evolving landscape of online social network analysis in the AI era, offering a comprehensive profile of LLM agents in social simulations.","authors":["Yiming Zhu","Yupeng He","Ehsan-Ul Haq","Gareth Tyson","Pan Hui"],"url":"https://arxiv.org/abs/2504.10286"}
{"created":"2025-04-15","title":"Noise2Ghost: Self-supervised deep convolutional reconstruction for ghost imaging","abstract":"We present a new self-supervised deep-learning-based Ghost Imaging (GI) reconstruction method, which provides unparalleled reconstruction performance for noisy acquisitions among unsupervised methods. We present the supporting mathematical framework and results from theoretical and real data use cases. Self-supervision removes the need for clean reference data while offering strong noise reduction. This provides the necessary tools for addressing signal-to-noise ratio concerns for GI acquisitions in emerging and cutting-edge low-light GI scenarios. Notable examples include micro- and nano-scale x-ray emission imaging, e.g., x-ray fluorescence imaging of dose-sensitive samples. Their applications include in-vivo and in-operando case studies for biological samples and batteries.","authors":["Mathieu Manni","Dmitry Karpov","K. Joost Batenburg","Sharon Shwartz","Nicola Vigan\\`o"],"url":"https://arxiv.org/abs/2504.10288"}
{"created":"2025-04-15","title":"Optimal Graph Stretching for Distributed Averaging","abstract":"The performance of distributed averaging depends heavily on the underlying topology. In various fields, including compressed sensing, multi-party computation, and abstract graph theory, graphs may be expected to be free of short cycles, i.e. to have high girth. Though extensive analyses and heuristics exist for optimising the performance of distributed averaging in general networks, these studies do not consider girth. As such, it is not clear what happens to convergence time when a graph is stretched to a higher girth.","authors":["Florine W. Dekker (Delft University of Technology","the Netherlands and)","Zekeriya Erkin (Delft University of Technology","the Netherlands and)","Mauro Conti (Universit\\`a di Padova","Italy","Delft University of Technology","the Netherlands and)"],"url":"https://arxiv.org/abs/2504.10289"}
{"created":"2025-04-15","title":"Ankle Exoskeletons in Walking and Load-Carrying Tasks: Insights into Biomechanics and Human-Robot Interaction","abstract":"Background: Lower limb exoskeletons can enhance quality of life, but widespread adoption is limited by the lack of frameworks to assess their biomechanical and human-robot interaction effects, which are essential for developing adaptive and personalized control strategies. Understanding impacts on kinematics, muscle activity, and HRI dynamics is key to achieve improved usability of wearable robots. Objectives: We propose a systematic methodology evaluate an ankle exoskeleton's effects on human movement during walking and load-carrying (10 kg front pack), focusing on joint kinematics, muscle activity, and HRI torque signals. Materials and Methods: Using Xsens MVN (inertial motion capture), Delsys EMG, and a unilateral exoskeleton, three experiments were conducted: (1) isolated dorsiflexion/plantarflexion; (2) gait analysis (two subjects, passive/active modes); and (3) load-carrying under assistance. Results and Conclusions: The first experiment confirmed that the HRI sensor captured both voluntary and involuntary torques, providing directional torque insights. The second experiment showed that the device slightly restricted ankle range of motion (RoM) but supported normal gait patterns across all assistance modes. The exoskeleton reduced muscle activity, particularly in active mode. HRI torque varied according to gait phases and highlighted reduced synchronization, suggesting a need for improved support. The third experiment revealed that load-carrying increased GM and TA muscle activity, but the device partially mitigated user effort by reducing muscle activity compared to unassisted walking. HRI increased during load-carrying, providing insights into user-device dynamics. These results demonstrate the importance of tailoring exoskeleton evaluation methods to specific devices and users, while offering a framework for future studies on exoskeleton biomechanics and HRI.","authors":["J. F. Almeida","J. Andr\\'e","C. P. Santos"],"url":"https://arxiv.org/abs/2504.10294"}
{"created":"2025-04-15","title":"Siamese Network with Dual Attention for EEG-Driven Social Learning: Bridging the Human-Robot Gap in Long-Tail Autonomous Driving","abstract":"Robots with wheeled, quadrupedal, or humanoid forms are increasingly integrated into built environments. However, unlike human social learning, they lack a critical pathway for intrinsic cognitive development, namely, learning from human feedback during interaction. To understand human ubiquitous observation, supervision, and shared control in dynamic and uncertain environments, this study presents a brain-computer interface (BCI) framework that enables classification of Electroencephalogram (EEG) signals to detect cognitively demanding and safety-critical events. As a timely and motivating co-robotic engineering application, we simulate a human-in-the-loop scenario to flag risky events in semi-autonomous robotic driving-representative of long-tail cases that pose persistent bottlenecks to the safety performance of smart mobility systems and robotic vehicles. Drawing on recent advances in few-shot learning, we propose a dual-attention Siamese convolutional network paired with Dynamic Time Warping Barycenter Averaging approach to generate robust EEG-encoded signal representations. Inverse source localization reveals activation in Broadman areas 4 and 9, indicating perception-action coupling during task-relevant mental imagery. The model achieves 80% classification accuracy under data-scarce conditions and exhibits a nearly 100% increase in the utility of salient features compared to state-of-the-art methods, as measured through integrated gradient attribution. Beyond performance, this study contributes to our understanding of the cognitive architecture required for BCI agents-particularly the role of attention and memory mechanisms-in categorizing diverse mental states and supporting both inter- and intra-subject adaptation. Overall, this research advances the development of cognitive robotics and socially guided learning for service robots in complex built environments.","authors":["Xiaoshan Zhou","Carol C. Menassa","Vineet R. Kamat"],"url":"https://arxiv.org/abs/2504.10296"}
{"created":"2025-04-15","title":"IRR-Based AS Type of Relationship Inference","abstract":"The Internet comprises tens of thousands of autonomous systems (ASes) whose commercial relationships are not publicly announced. The classification of the Type of Relationship (ToR) between ASes has been extensively studied over the past two decades due to its relevance in network routing management and security.","authors":["Amit Zulan","Omer Miron","Tal Shapira","Yuval Shavitt"],"url":"https://arxiv.org/abs/2504.10299"}
{"created":"2025-04-15","title":"CROSSAN: Towards Efficient and Effective Adaptation of Multiple Multimodal Foundation Models for Sequential Recommendation","abstract":"Multimodal Foundation Models (MFMs) excel at representing diverse raw modalities (e.g., text, images, audio, videos, etc.). As recommender systems increasingly incorporate these modalities, leveraging MFMs to generate better representations has great potential. However, their application in sequential recommendation remains largely unexplored. This is primarily because mainstream adaptation methods, such as Fine-Tuning and even Parameter-Efficient Fine-Tuning (PEFT) techniques (e.g., Adapter and LoRA), incur high computational costs, especially when integrating multiple modality encoders, thus hindering research progress. As a result, it remains unclear whether we can efficiently and effectively adapt multiple (>2) MFMs for the sequential recommendation task.","authors":["Junchen Fu","Yongxin Ni","Joemon M. Jose","Ioannis Arapakis","Kaiwen Zheng","Youhua Li","Xuri Ge"],"url":"https://arxiv.org/abs/2504.10307"}
{"created":"2025-04-15","title":"AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style Matching Text-to-Speech Synthesis","abstract":"With the advancement of speech synthesis technology, users have higher expectations for the naturalness and expressiveness of synthesized speech. But previous research ignores the importance of prompt selection. This study proposes a text-to-speech (TTS) framework based on Retrieval-Augmented Generation (RAG) technology, which can dynamically adjust the speech style according to the text content to achieve more natural and vivid communication effects. We have constructed a speech style knowledge database containing high-quality speech samples in various contexts and developed a style matching scheme. This scheme uses embeddings, extracted by Llama, PER-LLM-Embedder,and Moka, to match with samples in the knowledge database, selecting the most appropriate speech style for synthesis. Furthermore, our empirical research validates the effectiveness of the proposed method. Our demo can be viewed at: https://thuhcsi.github.io/icme2025-AutoStyle-TTS","authors":["Dan Luo","Chengyuan Ma","Weiqin Li","Jun Wang","Wei Chen","Zhiyong Wu"],"url":"https://arxiv.org/abs/2504.10309"}
{"created":"2025-04-15","title":"An Empirical Evaluation of White-box and Black-box Test Case Prioritization Techniques in CPSs Modeled in Simulink","abstract":"MATLAB/Simulink is the leading tool for simulating complex Cyber-Physical Systems (CPSs). The simulation models of complex CPSs are typically compute intensive, and the execution of test cases is long. Furthermore, the execution of test cases is typically triggered several times at different ``in-the-Loop'' test levels (i.e., Model, Software and Hardware-in-the-Loop). Therefore, test optimization techniques, such as test case prioritization, are paramount when testing these systems. In this paper, we present the largest empirical study on test case prioritization techniques for Simulink models by comparing the performance of white-box and black-box test case prioritization techniques. We assess traditional test case prioritization techniques, and we also propose new approaches for use in the context of Simulink models. We empirically compared 11 test case prioritization techniques using six Simulink models of different sizes and complexities. When comparing white-box against black-box test case prioritization techniques, we found that in general, white-box techniques were slightly better than black-box ones. In the context of white-box test case prioritization, the total greedy approach performed better than the additional greedy techniques in larger models. As for the test case prioritization time, black-box techniques were faster, although total greedy techniques were fast enough to be used in practice.","authors":["Aitor Arrieta"],"url":"https://arxiv.org/abs/2504.10313"}
{"created":"2025-04-15","title":"Universal Algebra and Effectful Computation","abstract":"Abstract clones serve as an algebraic presentation of the syntax of a simple type theory. From the perspective of universal algebra, they define algebraic theories like those of groups, monoids and rings. This link allows one to study the language of simple type theory from the viewpoint of universal algebra.","authors":["Nayan Rajesh"],"url":"https://arxiv.org/abs/2504.10314"}
{"created":"2025-04-15","title":"ESCT3D: Efficient and Selectively Controllable Text-Driven 3D Content Generation with Gaussian Splatting","abstract":"In recent years, significant advancements have been made in text-driven 3D content generation. However, several challenges remain. In practical applications, users often provide extremely simple text inputs while expecting high-quality 3D content. Generating optimal results from such minimal text is a difficult task due to the strong dependency of text-to-3D models on the quality of input prompts. Moreover, the generation process exhibits high variability, making it difficult to control. Consequently, multiple iterations are typically required to produce content that meets user expectations, reducing generation efficiency. To address this issue, we propose GPT-4V for self-optimization, which significantly enhances the efficiency of generating satisfactory content in a single attempt. Furthermore, the controllability of text-to-3D generation methods has not been fully explored. Our approach enables users to not only provide textual descriptions but also specify additional conditions, such as style, edges, scribbles, poses, or combinations of multiple conditions, allowing for more precise control over the generated 3D content. Additionally, during training, we effectively integrate multi-view information, including multi-view depth, masks, features, and images, to address the common Janus problem in 3D content generation. Extensive experiments demonstrate that our method achieves robust generalization, facilitating the efficient and controllable generation of high-quality 3D content.","authors":["Huiqi Wu","Jianbo Mei","Yingjie Huang","Yining Xu","Jingjiao You","Yilong Liu","Li Yao"],"url":"https://arxiv.org/abs/2504.10316"}
{"created":"2025-04-15","title":"Analysis of Attention in Video Diffusion Transformers","abstract":"We conduct an in-depth analysis of attention in video diffusion transformers (VDiTs) and report a number of novel findings. We identify three key properties of attention in VDiTs: Structure, Sparsity, and Sinks. Structure: We observe that attention patterns across different VDiTs exhibit similar structure across different prompts, and that we can make use of the similarity of attention patterns to unlock video editing via self-attention map transfer. Sparse: We study attention sparsity in VDiTs, finding that proposed sparsity methods do not work for all VDiTs, because some layers that are seemingly sparse cannot be sparsified. Sinks: We make the first study of attention sinks in VDiTs, comparing and contrasting them to attention sinks in language models. We propose a number of future directions that can make use of our insights to improve the efficiency-quality Pareto frontier for VDiTs.","authors":["Yuxin Wen","Jim Wu","Ajay Jain","Tom Goldstein","Ashwinee Panda"],"url":"https://arxiv.org/abs/2504.10317"}
{"created":"2025-04-15","title":"Shield Bash: Abusing Defensive Coherence State Retrieval to Break Timing Obfuscation","abstract":"Microarchitectural attacks are a significant concern, leading to many hardware-based defense proposals. However, different defenses target different classes of attacks, and their impact on each other has not been fully considered. To raise awareness of this problem, we study an interaction between two state-of-the art defenses in this paper, timing obfuscations of remote cache lines (TORC) and delaying speculative changes to remote cache lines (DSRC). TORC mitigates cache-hit based attacks and DSRC mitigates speculative coherence state change attacks.","authors":["Kartik Ramkrishnan","Antonia Zhai","Stephen McCamant","Pen Chung Yew"],"url":"https://arxiv.org/abs/2504.10318"}
{"created":"2025-04-15","title":"SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model","abstract":"Video anomaly detection (VAD) aims to identify unexpected events in videos and has wide applications in safety-critical domains. While semi-supervised methods trained on only normal samples have gained traction, they often suffer from high false alarm rates and poor interpretability. Recently, vision-language models (VLMs) have demonstrated strong multimodal reasoning capabilities, offering new opportunities for explainable anomaly detection. However, their high computational cost and lack of domain adaptation hinder real-time deployment and reliability. Inspired by dual complementary pathways in human visual perception, we propose SlowFastVAD, a hybrid framework that integrates a fast anomaly detector with a slow anomaly detector (namely a retrieval augmented generation (RAG) enhanced VLM), to address these limitations. Specifically, the fast detector first provides coarse anomaly confidence scores, and only a small subset of ambiguous segments, rather than the entire video, is further analyzed by the slower yet more interpretable VLM for elaborate detection and reasoning. Furthermore, to adapt VLMs to domain-specific VAD scenarios, we construct a knowledge base including normal patterns based on few normal samples and abnormal patterns inferred by VLMs. During inference, relevant patterns are retrieved and used to augment prompts for anomaly reasoning. Finally, we smoothly fuse the anomaly confidence of fast and slow detectors to enhance robustness of anomaly detection. Extensive experiments on four benchmarks demonstrate that SlowFastVAD effectively combines the strengths of both fast and slow detectors, and achieves remarkable detection accuracy and interpretability with significantly reduced computational overhead, making it well-suited for real-world VAD applications with high reliability requirements.","authors":["Zongcan Ding","Haodong Zhang","Peng Wu","Guansong Pang","Zhiwei Yang","Peng Wang","Yanning Zhang"],"url":"https://arxiv.org/abs/2504.10320"}
{"created":"2025-04-15","title":"Efficient Prompt Tuning for Hierarchical Ingredient Recognition","abstract":"Fine-grained ingredient recognition presents a significant challenge due to the diverse appearances of ingredients, resulting from different cutting and cooking methods. While existing approaches have shown promising results, they still require extensive training costs and focus solely on fine-grained ingredient recognition. In this paper, we address these limitations by introducing an efficient prompt-tuning framework that adapts pretrained visual-language models (VLMs), such as CLIP, to the ingredient recognition task without requiring full model finetuning. Additionally, we introduce three-level ingredient hierarchies to enhance both training performance and evaluation robustness. Specifically, we propose a hierarchical ingredient recognition task, designed to evaluate model performance across different hierarchical levels (e.g., chicken chunks, chicken, meat), capturing recognition capabilities from coarse- to fine-grained categories. Our method leverages hierarchical labels, training prompt-tuned models with both fine-grained and corresponding coarse-grained labels. Experimental results on the VireoFood172 dataset demonstrate the effectiveness of prompt-tuning with hierarchical labels, achieving superior performance. Moreover, the hierarchical ingredient recognition task provides valuable insights into the model's ability to generalize across different levels of ingredient granularity.","authors":["Yinxuan Gui","Bin Zhu","Jingjing Chen","Chong-Wah Ngo"],"url":"https://arxiv.org/abs/2504.10322"}
{"created":"2025-04-15","title":"Rel: A Programming Language for Relational Data","abstract":"From the moment of their inception, languages for relational data have been described as sublanguages embedded in a host programming language. Rel is a new relational language whose key design goal is to go beyond this paradigm with features that allow for programming in the large, making it possible to fully describe end to end application semantics. With the new approach we can model the semantics of entire enterprise applications relationally, which helps significantly reduce architecture complexity and avoid the well-known impedance mismatch problem. This paradigm shift is enabled by 50 years of database research, making it possible to revisit the sublanguage/host language paradigm, starting from the fundamental principles. We present the main features of Rel: those that give it the power to express traditional query language operations and those that are designed to grow the language and allow programming in the large.","authors":["Molham Aref","Paolo Guagliardo","George Kastrinis","Leonid Libkin","Victor Marsault","Wim Martens","Mary McGrath","Filip Murlak","Nathaniel Nystrom","Liat Peterfreund","Allison Rogers","Cristina Sirangelo","Domagoj Vrgoc","David Zhao","Abdul Zreika"],"url":"https://arxiv.org/abs/2504.10323"}
{"created":"2025-04-15","title":"Cumulative-Time Signal Temporal Logic","abstract":"Signal Temporal Logic (STL) is a widely adopted specification language in cyber-physical systems for expressing critical temporal requirements, such as safety conditions and response time. However, STL's expressivity is not sufficient to capture the cumulative duration during which a property holds within an interval of time. To overcome this limitation, we introduce Cumulative-Time Signal Temporal Logic (CT-STL) that operates over discrete-time signals and extends STL with a new cumulative-time operator. This operator compares the sum of all time steps for which its nested formula is true with a threshold. We present both a qualitative and a quantitative (robustness) semantics for CT-STL and prove both their soundness and completeness properties. We provide an efficient online monitoring algorithm for both semantics. Finally, we show the applicability of CT-STL in two case studies: specifying and monitoring cumulative temporal requirements for a microgrid and an artificial pancreas.","authors":["Hongkai Chen","Zeyu Zhang","Shouvik Roy","Ezio Bartocci","Scott A. Smolka","Scott D. Stoller","Shan Lin"],"url":"https://arxiv.org/abs/2504.10325"}
{"created":"2025-04-15","title":"AlayaDB: The Data Foundation for Efficient and Effective Long-context LLM Inference","abstract":"AlayaDB is a cutting-edge vector database system natively architected for efficient and effective long-context inference for Large Language Models (LLMs) at AlayaDB AI. Specifically, it decouples the KV cache and attention computation from the LLM inference systems, and encapsulates them into a novel vector database system. For the Model as a Service providers (MaaS), AlayaDB consumes fewer hardware resources and offers higher generation quality for various workloads with different kinds of Service Level Objectives (SLOs), when comparing with the existing alternative solutions (e.g., KV cache disaggregation, retrieval-based sparse attention). The crux of AlayaDB is that it abstracts the attention computation and cache management for LLM inference into a query processing procedure, and optimizes the performance via a native query optimizer. In this work, we demonstrate the effectiveness of AlayaDB via (i) three use cases from our industry partners, and (ii) extensive experimental results on LLM inference benchmarks.","authors":["Yangshen Deng","Zhengxin You","Long Xiang","Qilong Li","Peiqi Yuan","Zhaoyang Hong","Yitao Zheng","Wanting Li","Runzhong Li","Haotian Liu","Kyriakos Mouratidis","Man Lung Yiu","Huan Li","Qiaomu Shen","Rui Mao","Bo Tang"],"url":"https://arxiv.org/abs/2504.10326"}
{"created":"2025-04-15","title":"InstructEngine: Instruction-driven Text-to-Image Alignment","abstract":"Reinforcement Learning from Human/AI Feedback (RLHF/RLAIF) has been extensively utilized for preference alignment of text-to-image models. Existing methods face certain limitations in terms of both data and algorithm. For training data, most approaches rely on manual annotated preference data, either by directly fine-tuning the generators or by training reward models to provide training signals. However, the high annotation cost makes them difficult to scale up, the reward model consumes extra computation and cannot guarantee accuracy. From an algorithmic perspective, most methods neglect the value of text and only take the image feedback as a comparative signal, which is inefficient and sparse. To alleviate these drawbacks, we propose the InstructEngine framework. Regarding annotation cost, we first construct a taxonomy for text-to-image generation, then develop an automated data construction pipeline based on it. Leveraging advanced large multimodal models and human-defined rules, we generate 25K text-image preference pairs. Finally, we introduce cross-validation alignment method, which refines data efficiency by organizing semantically analogous samples into mutually comparable pairs. Evaluations on DrawBench demonstrate that InstructEngine improves SD v1.5 and SDXL's performance by 10.53% and 5.30%, outperforming state-of-the-art baselines, with ablation study confirming the benefits of InstructEngine's all components. A win rate of over 50% in human reviews also proves that InstructEngine better aligns with human preferences.","authors":["Xingyu Lu","Yuhang Hu","YiFan Zhang","Kaiyu Jiang","Changyi Liu","Tianke Zhang","Jinpeng Wang","Bin Wen","Chun Yuan","Fan Yang","Tingting Gao","Di Zhang"],"url":"https://arxiv.org/abs/2504.10329"}
{"created":"2025-04-15","title":"LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian Splatting for Novel View Synthesis","abstract":"Novel view synthesis (NVS) in low-light scenes remains a significant challenge due to degraded inputs characterized by severe noise, low dynamic range (LDR) and unreliable initialization. While recent NeRF-based approaches have shown promising results, most suffer from high computational costs, and some rely on carefully captured or pre-processed data--such as RAW sensor inputs or multi-exposure sequences--which severely limits their practicality. In contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering with competitive visual fidelity; however, existing 3DGS-based methods struggle with low-light sRGB inputs, resulting in unstable Gaussian initialization and ineffective noise suppression. To address these challenges, we propose LL-Gaussian, a novel framework for 3D reconstruction and enhancement from low-light sRGB images, enabling pseudo normal-light novel view synthesis. Our method introduces three key innovations: 1) an end-to-end Low-Light Gaussian Initialization Module (LLGIM) that leverages dense priors from learning-based MVS approach to generate high-quality initial point clouds; 2) a dual-branch Gaussian decomposition model that disentangles intrinsic scene properties (reflectance and illumination) from transient interference, enabling stable and interpretable optimization; 3) an unsupervised optimization strategy guided by both physical constrains and diffusion prior to jointly steer decomposition and enhancement. Additionally, we contribute a challenging dataset collected in extreme low-light environments and demonstrate the effectiveness of LL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussian achieves up to 2,000 times faster inference and reduces training time to just 2%, while delivering superior reconstruction and rendering quality.","authors":["Hao Sun","Fenggen Yu","Huiyao Xu","Tao Zhang","Changqing Zou"],"url":"https://arxiv.org/abs/2504.10331"}
{"created":"2025-04-15","title":"Flying Hand: End-Effector-Centric Framework for Versatile Aerial Manipulation Teleoperation and Policy Learning","abstract":"Aerial manipulation has recently attracted increasing interest from both industry and academia. Previous approaches have demonstrated success in various specific tasks. However, their hardware design and control frameworks are often tightly coupled with task specifications, limiting the development of cross-task and cross-platform algorithms. Inspired by the success of robot learning in tabletop manipulation, we propose a unified aerial manipulation framework with an end-effector-centric interface that decouples high-level platform-agnostic decision-making from task-agnostic low-level control. Our framework consists of a fully-actuated hexarotor with a 4-DoF robotic arm, an end-effector-centric whole-body model predictive controller, and a high-level policy. The high-precision end-effector controller enables efficient and intuitive aerial teleoperation for versatile tasks and facilitates the development of imitation learning policies. Real-world experiments show that the proposed framework significantly improves end-effector tracking accuracy, and can handle multiple aerial teleoperation and imitation learning tasks, including writing, peg-in-hole, pick and place, changing light bulbs, etc. We believe the proposed framework provides one way to standardize and unify aerial manipulation into the general manipulation community and to advance the field. Project website: https://lecar-lab.github.io/flying_hand/.","authors":["Guanqi He","Xiaofeng Guo","Luyi Tang","Yuanhang Zhang","Mohammadreza Mousaei","Jiahe Xu","Junyi Geng","Sebastian Scherer","Guanya Shi"],"url":"https://arxiv.org/abs/2504.10334"}
{"created":"2025-04-15","title":"MorphTok: Morphologically Grounded Tokenization for Indian Languages","abstract":"Tokenization is a crucial step in NLP, especially with the rise of large language models (LLMs), impacting downstream performance, computational cost, and efficiency. Existing LLMs rely on the classical Byte-pair Encoding (BPE) algorithm for subword tokenization that greedily merges frequent character bigrams. This often leads to segmentation that does not align with linguistically meaningful units. To address this, we propose morphology-aware segmentation as a pre-tokenization step prior to applying BPE. To facilitate morphology-aware segmentation, we create a novel dataset for Hindi and Marathi, incorporating sandhi splitting to enhance the subword tokenization. Experiments on downstream tasks show that morphologically grounded tokenization improves performance for machine translation and language modeling. Additionally, to handle the ambiguity in the Unicode characters for diacritics, particularly dependent vowels in syllable-based writing systems, we introduce Constrained BPE (CBPE), an extension to the traditional BPE algorithm that incorporates script-specific constraints. Specifically, CBPE handles dependent vowels. Our results show that CBPE achieves a 1.68\\% reduction in fertility scores while maintaining comparable or improved downstream performance in machine translation, offering a computationally efficient alternative to standard BPE. Moreover, to evaluate segmentation across different tokenization algorithms, we introduce a new human evaluation metric, \\textit{EvalTok}, enabling more human-grounded assessment.","authors":["Maharaj Brahma","N J Karthika","Atul Singh","Devaraj Adiga","Smruti Bhate","Ganesh Ramakrishnan","Rohit Saluja","Maunendra Sankar Desarkar"],"url":"https://arxiv.org/abs/2504.10335"}
{"created":"2025-04-15","title":"Heimdall: test-time scaling on the generative verification","abstract":"An AI system can create and maintain knowledge only to the extent that it can verify that knowledge itself. Recent work on long Chain-of-Thought reasoning has demonstrated great potential of LLMs on solving competitive problems, but their verification ability remains to be weak and not sufficiently investigated. In this paper, we propose Heimdall, the long CoT verification LLM that can accurately judge the correctness of solutions. With pure reinforcement learning, we boost the verification accuracy from 62.5% to 94.5% on competitive math problems. By scaling with repeated sampling, the accuracy further increases to 97.5%. Through human evaluation, Heimdall demonstrates impressive generalization capabilities, successfully detecting most issues in challenging math proofs, the type of which is not included during training. Furthermore, we propose Pessimistic Verification to extend the functionality of Heimdall to scaling up the problem solving. It calls Heimdall to judge the solutions from a solver model and based on the pessimistic principle, selects the most likely correct solution with the least uncertainty. Taking DeepSeek-R1-Distill-Qwen-32B as the solver model, Pessimistic Verification improves the solution accuracy on AIME2025 from 54.2% to 70.0% with 16x compute budget and to 83.3% with more compute budget. With the stronger solver Gemini 2.5 Pro, the score reaches 93.0%. Finally, we prototype an automatic knowledge discovery system, a ternary system where one poses questions, another provides solutions, and the third verifies the solutions. Using the data synthesis work NuminaMath for the first two components, Heimdall effectively identifies problematic records within the dataset and reveals that nearly half of the data is flawed, which interestingly aligns with the recent ablation studies from NuminaMath.","authors":["Wenlei Shi","Xing Jin"],"url":"https://arxiv.org/abs/2504.10337"}
{"created":"2025-04-15","title":"Forecasting from Clinical Textual Time Series: Adaptations of the Encoder and Decoder Language Model Families","abstract":"Clinical case reports encode rich, temporal patient trajectories that are often underexploited by traditional machine learning methods relying on structured data. In this work, we introduce the forecasting problem from textual time series, where timestamped clinical findings--extracted via an LLM-assisted annotation pipeline--serve as the primary input for prediction. We systematically evaluate a diverse suite of models, including fine-tuned decoder-based large language models and encoder-based transformers, on tasks of event occurrence prediction, temporal ordering, and survival analysis. Our experiments reveal that encoder-based models consistently achieve higher F1 scores and superior temporal concordance for short- and long-horizon event forecasting, while fine-tuned masking approaches enhance ranking performance. In contrast, instruction-tuned decoder models demonstrate a relative advantage in survival analysis, especially in early prognosis settings. Our sensitivity analyses further demonstrate the importance of time ordering, which requires clinical time series construction, as compared to text ordering, the format of the text inputs that LLMs are classically trained on. This highlights the additional benefit that can be ascertained from time-ordered corpora, with implications for temporal tasks in the era of widespread LLM use.","authors":["Shahriar Noroozizadeh","Sayantan Kumar","Jeremy C. Weiss"],"url":"https://arxiv.org/abs/2504.10340"}
{"created":"2025-04-15","title":"VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain Knowledge","abstract":"Current multimodal benchmarks often conflate reasoning with domain-specific knowledge, making it difficult to isolate and evaluate general reasoning abilities in non-expert settings. To address this, we introduce VisualPuzzles, a benchmark that targets visual reasoning while deliberately minimizing reliance on specialized knowledge. VisualPuzzles consists of diverse questions spanning five categories: algorithmic, analogical, deductive, inductive, and spatial reasoning. One major source of our questions is manually translated logical reasoning questions from the Chinese Civil Service Examination. Experiments show that VisualPuzzles requires significantly less intensive domain-specific knowledge and more complex reasoning compared to benchmarks like MMMU, enabling us to better evaluate genuine multimodal reasoning. Evaluations show that state-of-the-art multimodal large language models consistently lag behind human performance on VisualPuzzles, and that strong performance on knowledge-intensive benchmarks does not necessarily translate to success on reasoning-focused, knowledge-light tasks. Additionally, reasoning enhancements such as scaling up inference compute (with \"thinking\" modes) yield inconsistent gains across models and task types, and we observe no clear correlation between model size and performance. We also found that models exhibit different reasoning and answering patterns on VisualPuzzles compared to benchmarks with heavier emphasis on knowledge. VisualPuzzles offers a clearer lens through which to evaluate reasoning capabilities beyond factual recall and domain knowledge.","authors":["Yueqi Song","Tianyue Ou","Yibo Kong","Zecheng Li","Graham Neubig","Xiang Yue"],"url":"https://arxiv.org/abs/2504.10342"}
{"created":"2025-04-15","title":"Domain-Adversarial Neural Network and Explainable AI for Reducing Tissue-of-Origin Signal in Pan-cancer Mortality Classification","abstract":"Tissue-of-origin signals dominate pan-cancer gene expression, often obscuring molecular features linked to patient survival. This hampers the discovery of generalizable biomarkers, as models tend to overfit tissue-specific patterns rather than capture survival-relevant signals. To address this, we propose a Domain-Adversarial Neural Network (DANN) trained on TCGA RNA-seq data to learn representations less biased by tissue and more focused on survival. Identifying tissue-independent genetic profiles is key to revealing core cancer programs. We assess the DANN using: (1) Standard SHAP, based on the original input space and DANN's mortality classifier; (2) A layer-aware strategy applied to hidden activations, including an unsupervised manifold from raw activations and a supervised manifold from mortality-specific SHAP values. Standard SHAP remains confounded by tissue signals due to biases inherent in its computation. The raw activation manifold was dominated by high-magnitude activations, which masked subtle tissue and mortality-related signals. In contrast, the layer-aware SHAP manifold offers improved low-dimensional representations of both tissue and mortality signals, independent of activation strength, enabling subpopulation stratification and pan-cancer identification of survival-associated genes.","authors":["Cristian Padron-Manrique","Juan Jos\\'e Oropeza Valdez","Osbaldo Resendis-Antonio"],"url":"https://arxiv.org/abs/2504.10343"}
{"created":"2025-04-15","title":"ALMTokenizer: A Low-bitrate and Semantic-rich Audio Codec Tokenizer for Audio Language Modeling","abstract":"Recent advancements in audio language models have underscored the pivotal role of audio tokenization, which converts audio signals into discrete tokens, thereby facilitating the application of language model architectures to the audio domain. In this study, we introduce ALMTokenizer, a novel low-bitrate and semantically rich audio codec tokenizer for audio language models. Prior methods, such as Encodec, typically encode individual audio frames into discrete tokens without considering the use of context information across frames. Unlike these methods, we introduce a novel query-based compression strategy to capture holistic information with a set of learnable query tokens by explicitly modeling the context information across frames. This design not only enables the codec model to capture more semantic information but also encodes the audio signal with fewer token sequences. Additionally, to enhance the semantic information in audio codec models, we introduce the following: (1) A masked autoencoder (MAE) loss, (2) Vector quantization based on semantic priors, and (3) An autoregressive (AR) prediction loss. As a result, ALMTokenizer achieves competitive reconstruction performance relative to state-of-the-art approaches while operating at a lower bitrate. Within the same audio language model framework, ALMTokenizer outperforms previous tokenizers in audio understanding and generation tasks.","authors":["Dongchao Yang","Songxiang Liu","Haohan Guo","Jiankun Zhao","Yuanyuan Wang","Helin Wang","Zeqian Ju","Xubo Liu","Xueyuan Chen","Xu Tan","Xixin Wu","Helen Meng"],"url":"https://arxiv.org/abs/2504.10344"}
{"created":"2025-04-15","title":"AraOS: Analyzing the Impact of Virtual Memory Management on Vector Unit Performance","abstract":"Vector processor architectures offer an efficient solution for accelerating data-parallel workloads (e.g., ML, AI), reducing instruction count, and enhancing processing efficiency. This is evidenced by the increasing adoption of vector ISAs, such as Arm's SVE/SVE2 and RISC-V's RVV, not only in high-performance computers but also in embedded systems. The open-source nature of RVV has particularly encouraged the development of numerous vector processor designs across industry and academia. However, despite the growing number of open-source RVV processors, there is a lack of published data on their performance in a complex application environment hosted by a full-fledged operating system (Linux). In this work, we add OS support to the open-source bare-metal Ara2 vector processor (AraOS) by sharing the MMU of CVA6, the scalar core used for instruction dispatch to Ara2, and integrate AraOS into the open-source Cheshire SoC platform. We evaluate the performance overhead of virtual-to-physical address translation by benchmarking matrix multiplication kernels across several problem sizes and translation lookaside buffer (TLB) configurations in CVA6's shared MMU, providing insights into vector performance in a full-system environment with virtual memory. With at least 16 TLB entries, the virtual memory overhead remains below 3.5%. Finally, we benchmark a 2-lane AraOS instance with the open-source RiVEC benchmark suite for RVV architectures, with peak average speedups of 3.2x against scalar-only execution.","authors":["Matteo Perotti","Vincenzo Maisto","Moritz Imfeld","Nils Wistoff","Alessandro Cilardo","Luca Benini"],"url":"https://arxiv.org/abs/2504.10345"}
{"created":"2025-04-15","title":"Uncertain Location Transmitter and UAV-Aided Warden Based LEO Satellite Covert Communication Systems","abstract":"We propose a novel covert communication system in which a ground user, Alice, transmits unauthorized message fragments to Bob, a low-Earth orbit satellite (LEO), and an unmanned aerial vehicle (UAV) warden (Willie) attempts to detect these transmissions. The key contribution is modeling a scenario where Alice and Willie are unaware of each other's exact locations and move randomly within a specific area. Alice utilizes environmental obstructions to avoid detection and only transmits when the satellite is directly overhead. LEO satellite technology allows users to avoid transmitting messages near a base station. We introduce two key performance metrics: catch probability (Willie detects and locates Alice during a message chunk transmission) and overall catch probability over multiple message chunks. We analyze how two parameters impact these metrics: 1) the size of the detection window and 2) the number of message chunks. The paper proposes two algorithms to optimize these parameters. The simulation results show that the algorithms effectively reduce the detection risks. This work advances the understanding of covert communication under mobility and uncertainty in satellite-aided systems.","authors":["Pei Peng","Xianfu Chen","Tianheng Xu","Celimuge Wu","Yulong Zou","Qiang Ni","Emina Soljanin"],"url":"https://arxiv.org/abs/2504.10347"}
{"created":"2025-04-15","title":"Benchmarking 3D Human Pose Estimation Models Under Occlusions","abstract":"This paper addresses critical challenges in 3D Human Pose Estimation (HPE) by analyzing the robustness and sensitivity of existing models to occlusions, camera position, and action variability. Using a novel synthetic dataset, BlendMimic3D, which includes diverse scenarios with multi-camera setups and several occlusion types, we conduct specific tests on several state-of-the-art models. Our study focuses on the discrepancy in keypoint formats between common datasets such as Human3.6M, and 2D datasets such as COCO, commonly used for 2D detection models and frequently input of 3D HPE models. Our work explores the impact of occlusions on model performance and the generality of models trained exclusively under standard conditions. The findings suggest significant sensitivity to occlusions and camera settings, revealing a need for models that better adapt to real-world variability and occlusion scenarios. This research contributed to ongoing efforts to improve the fidelity and applicability of 3D HPE systems in complex environments.","authors":["Filipa Lino","Carlos Santiago","Manuel Marques"],"url":"https://arxiv.org/abs/2504.10350"}
{"created":"2025-04-15","title":"Multimodal Representation Learning Techniques for Comprehensive Facial State Analysis","abstract":"Multimodal foundation models have significantly improved feature representation by integrating information from multiple modalities, making them highly suitable for a broader set of applications. However, the exploration of multimodal facial representation for understanding perception has been limited. Understanding and analyzing facial states, such as Action Units (AUs) and emotions, require a comprehensive and robust framework that bridges visual and linguistic modalities. In this paper, we present a comprehensive pipeline for multimodal facial state analysis. First, we compile a new Multimodal Face Dataset (MFA) by generating detailed multilevel language descriptions of face, incorporating Action Unit (AU) and emotion descriptions, by leveraging GPT-4o. Second, we introduce a novel Multilevel Multimodal Face Foundation model (MF^2) tailored for Action Unit (AU) and emotion recognition. Our model incorporates comprehensive visual feature modeling at both local and global levels of face image, enhancing its ability to represent detailed facial appearances. This design aligns visual representations with structured AU and emotion descriptions, ensuring effective cross-modal integration. Third, we develop a Decoupled Fine-Tuning Network (DFN) that efficiently adapts MF^2 across various tasks and datasets. This approach not only reduces computational overhead but also broadens the applicability of the foundation model to diverse scenarios. Experimentation show superior performance for AU and emotion detection tasks.","authors":["Kaiwen Zheng","Xuri Ge","Junchen Fu","Jun Peng","Joemon M. Jose"],"url":"https://arxiv.org/abs/2504.10351"}
{"created":"2025-04-15","title":"Patch and Shuffle: A Preprocessing Technique for Texture Classification in Autonomous Cementitious Fabrication","abstract":"Autonomous fabrication systems are transforming construction and manufacturing, yet they remain vulnerable to print errors. Texture classification is a key component of computer vision systems that enable real-time monitoring and adjustment during cementitious fabrication. Traditional classification methods often rely on global image features, which can bias the model toward semantic content rather than low-level textures. In this paper, we introduce a novel preprocessing technique called \"patch and shuffle,\" which segments input images into smaller patches, shuffles them, and reconstructs a jumbled image before classification. This transformation removes semantic context, forcing the classifier to rely on local texture features.","authors":["Jeremiah Giordani"],"url":"https://arxiv.org/abs/2504.10353"}
{"created":"2025-04-15","title":"MultiLoKo: a multilingual local knowledge benchmark for LLMs spanning 31 languages","abstract":"We present MultiLoKo, a new benchmark for evaluating multilinguality in LLMs covering 31 languages. MultiLoKo consists of three partitions: a main partition consisting of 500 questions per language, separately sourced to be locally relevant to the specific language, and two translated partitions, containing human-authored translations from 30 non-English languages to English and vice versa. For comparison, we also release corresponding machine-authored translations. The data is equally distributed over two splits: a dev split and a blind, out-of-distribution test split. MultiLoKo can be used to study a variety of questions regarding the multilinguality of LLMs as well as meta-questions about multilingual benchmark creation. We compute MultiLoKo scores for 11 base and chat models marketed to be multilingual and study their average performance, their performance parity across languages, how much their ability to answer questions depends on the question language, and which languages are most difficult. None of the models we studied performs well on MultiLoKo, as indicated by low average scores as well as large differences between the best and worst scoring languages. Furthermore, we find a substantial effect of the question language, indicating sub-optimal knowledge transfer between languages. Lastly, we find that using local vs English-translated data can result in differences more than 20 points for the best performing models, drastically change the estimated difficulty of some languages. For using machines instead of human translations, we find a weaker effect on ordering of language difficulty, a larger difference in model rankings, and a substantial drop in estimated performance for all models.","authors":["Dieuwke Hupkes","Nikolay Bogoychev"],"url":"https://arxiv.org/abs/2504.10356"}
{"created":"2025-04-15","title":"FingER: Content Aware Fine-grained Evaluation with Reasoning for AI-Generated Videos","abstract":"Recent advances in video generation have posed great challenges in the assessment of AI-generated content, particularly with the emergence of increasingly sophisticated models. The various inconsistencies and defects observed in such videos are inherently complex, making overall scoring notoriously difficult. In this paper, we emphasize the critical importance of integrating fine-grained reasoning into video evaluation, and we propose $\\textbf{F}$ing$\\textbf{ER}$, a novel entity-level reasoning evaluation framework that first automatically generates $\\textbf{F}$ine-grained $\\textbf{E}$ntity-level questions, and then answers those questions by a $\\textbf{R}$easoning model with scores, which can be subsequently weighted summed to an overall score for different applications. Specifically, we leverage LLMs to derive entity-level questions across five distinct perspectives, which (i) often focus on some specific entities of the content, thereby making answering or scoring much easier by MLLMs, and (ii) are more interpretable. Then we construct a FingER dataset, consisting of approximately 3.3k videos and corresponding 60k fine-grained QA annotations, each with detailed reasons. Based on that, we further investigate various training protocols to best incentivize the reasoning capability of MLLMs for correct answer prediction. Extensive experiments demonstrate that a reasoning model trained using Group Relative Policy Optimization (GRPO) with a cold-start strategy achieves the best performance. Notably, our model surpasses existing methods by a relative margin of $11.8\\%$ on GenAI-Bench and $5.5\\%$ on MonetBench with only 3.3k training videos, which is at most one-tenth of the training samples utilized by other methods. Our code and dataset will be released soon.","authors":["Rui Chen","Lei Sun","Jing Tang","Geng Li","Xiangxiang Chu"],"url":"https://arxiv.org/abs/2504.10358"}
{"created":"2025-04-15","title":"DICE: A Framework for Dimensional and Contextual Evaluation of Language Models","abstract":"Language models (LMs) are increasingly being integrated into a wide range of applications, yet the modern evaluation paradigm does not sufficiently reflect how they are actually being used. Current evaluations rely on benchmarks that often lack direct applicability to the real-world contexts in which LMs are being deployed. To address this gap, we propose Dimensional and Contextual Evaluation (DICE), an approach that evaluates LMs on granular, context-dependent dimensions. In this position paper, we begin by examining the insufficiency of existing LM benchmarks, highlighting their limited applicability to real-world use cases. Next, we propose a set of granular evaluation parameters that capture dimensions of LM behavior that are more meaningful to stakeholders across a variety of application domains. Specifically, we introduce the concept of context-agnostic parameters - such as robustness, coherence, and epistemic honesty - and context-specific parameters that must be tailored to the specific contextual constraints and demands of stakeholders choosing to deploy LMs into a particular setting. We then discuss potential approaches to operationalize this evaluation framework, finishing with the opportunities and challenges DICE presents to the LM evaluation landscape. Ultimately, this work serves as a practical and approachable starting point for context-specific and stakeholder-relevant evaluation of LMs.","authors":["Aryan Shrivastava","Paula Akemi Aoyagui"],"url":"https://arxiv.org/abs/2504.10359"}
{"created":"2025-04-15","title":"Reactive power flow optimization in AC drive systems","abstract":"This paper explores a limit avoidance approach in the case of input (modulation) and output (current) constraints with the aim of enhancing system availability of AC drives. Drawing on the observation that, in a certain range of reactive power, there exists a trade-off between current and modulation magnitude, we exploit this freedom and define a constrained optimization problem. We propose two approaches, one in the form of an activation-function which drives the reactive power set-point towards safety, and an approach which uses online feedback optimization to set the reactive power dynamically. Both methods compromise reactive power tracking accuracy for increased system robustness. Through a high fidelity simulation, we compare the benefits of the two methods, highlighting their effectiveness in industrial applications.","authors":["Sanjay Chandrasekaran","Catalin Arghir","Pieder Joerg","Florian Doerfler","Silvia Mastellone"],"url":"https://arxiv.org/abs/2504.10360"}
{"created":"2025-04-15","title":"Staggering and Fragmentation for Improved Large Message Handling in libp2p GossipSub","abstract":"The libp2p GossipSub protocol leverages a full-message mesh with a lower node degree and a more densely connected metadata-only (gossip) mesh. This combination allows an efficient dissemination of messages in unstructured peer-to-peer (P2P) networks. However, GossipSub needs to consider message size, which is crucial for the efficient operation of many applications, such as handling large Ethereum blocks. This paper proposes modifications to improve GossipSub's performance when transmitting large messages. We evaluate the proposed improvements using the shadow simulator. Our results show that the proposed improvements significantly enhance GossipSub's performance for large message transmissions in sizeable networks.","authors":["Muhammad Umar Farooq","Tanguy Cizain","Daniel Kaiser"],"url":"https://arxiv.org/abs/2504.10365"}
{"created":"2025-04-15","title":"S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability of Large Reasoning Models","abstract":"We introduce S1-Bench, a novel benchmark designed to evaluate Large Reasoning Models' (LRMs) performance on simple tasks that favor intuitive system 1 thinking rather than deliberative system 2 reasoning. While LRMs have achieved significant breakthroughs in complex reasoning tasks through explicit chains of thought, their reliance on deep analytical thinking may limit their system 1 thinking capabilities. Moreover, a lack of benchmark currently exists to evaluate LRMs' performance in tasks that require such capabilities. To fill this gap, S1-Bench presents a set of simple, diverse, and naturally clear questions across multiple domains and languages, specifically designed to assess LRMs' performance in such tasks. Our comprehensive evaluation of 22 LRMs reveals significant lower efficiency tendencies, with outputs averaging 15.5 times longer than those of traditional small LLMs. Additionally, LRMs often identify correct answers early but continue unnecessary deliberation, with some models even producing numerous errors. These findings highlight the rigid reasoning patterns of current LRMs and underscore the substantial development needed to achieve balanced dual-system thinking capabilities that can adapt appropriately to task complexity.","authors":["Wenyuan Zhang","Shuaiyi Nie","Xinghua Zhang","Zefeng Zhang","Tingwen Liu"],"url":"https://arxiv.org/abs/2504.10368"}
{"created":"2025-04-15","title":"SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired Symbolic Reasoning","abstract":"Optimizing Register Transfer Level (RTL) code is crucial for improving the power, performance, and area (PPA) of digital circuits in the early stages of synthesis. Manual rewriting, guided by synthesis feedback, can yield high-quality results but is time-consuming and error-prone. Most existing compiler-based approaches have difficulty handling complex design constraints. Large Language Model (LLM)-based methods have emerged as a promising alternative to address these challenges. However, LLM-based approaches often face difficulties in ensuring alignment between the generated code and the provided prompts. This paper presents SymRTLO, a novel neuron-symbolic RTL optimization framework that seamlessly integrates LLM-based code rewriting with symbolic reasoning techniques. Our method incorporates a retrieval-augmented generation (RAG) system of optimization rules and Abstract Syntax Tree (AST)-based templates, enabling LLM-based rewriting that maintains syntactic correctness while minimizing undesired circuit behaviors. A symbolic module is proposed for analyzing and optimizing finite state machine (FSM) logic, allowing fine-grained state merging and partial specification handling beyond the scope of pattern-based compilers. Furthermore, a fast verification pipeline, combining formal equivalence checks with test-driven validation, further reduces the complexity of verification. Experiments on the RTL-Rewriter benchmark with Synopsys Design Compiler and Yosys show that SymRTLO improves power, performance, and area (PPA) by up to 43.9%, 62.5%, and 51.1%, respectively, compared to the state-of-the-art methods.","authors":["Yiting Wang","Wanghao Ye","Ping Guo","Yexiao He","Ziyao Wang","Yexiao He","Bowei Tian","Shwai He","Guoheng Sun","Zheyu Shen","Sihan Chen","Ankur Srivastava","Qingfu Zhang","Gang Qu","Ang Li"],"url":"https://arxiv.org/abs/2504.10369"}
{"created":"2025-04-15","title":"Brain-Machine Interfaces & Information Retrieval Challenges and Opportunities","abstract":"The fundamental goal of Information Retrieval (IR) systems lies in their capacity to effectively satisfy human information needs - a challenge that encompasses not just the technical delivery of information, but the nuanced understanding of human cognition during information seeking. Contemporary IR platforms rely primarily on observable interaction signals, creating a fundamental gap between system capabilities and users' cognitive processes. Brain-Machine Interface (BMI) technologies now offer unprecedented potential to bridge this gap through direct measurement of previously inaccessible aspects of information-seeking behaviour. This perspective paper offers a broad examination of the IR landscape, providing a comprehensive analysis of how BMI technology could transform IR systems, drawing from advances at the intersection of both neuroscience and IR research. We present our analysis through three identified fundamental vertices: (1) understanding the neural correlates of core IR concepts to advance theoretical models of search behaviour, (2) enhancing existing IR systems through contextual integration of neurophysiological signals, and (3) developing proactive IR capabilities through direct neurophysiological measurement. For each vertex, we identify specific research opportunities and propose concrete directions for developing BMI-enhanced IR systems. We conclude by examining critical technical and ethical challenges in implementing these advances, providing a structured roadmap for future research at the intersection of neuroscience and IR.","authors":["Yashar Moshfeghi","Niall McGuire"],"url":"https://arxiv.org/abs/2504.10371"}
{"created":"2025-04-15","title":"Simple physical systems as a reference for multivariate information dynamics","abstract":"Understanding a complex system entails capturing the non-trivial collective phenomena that arise from interactions between its different parts. Information theory is a flexible and robust framework to study such behaviours, with several measures designed to quantify and characterise the interdependencies among the system's components. However, since these estimators rely on the statistical distributions of observed quantities, it is crucial to examine the relationships between information-theoretic measures and the system's underlying mechanistic structure. To this end, here we present an information-theoretic analytical investigation of an elementary system of interactive random walkers subject to Gaussian noise. Focusing on partial information decomposition, causal emergence, and integrated information, our results help us develop some intuitions on their relationship with the physical parameters of the system. For instance, we observe that uncoupled systems can exhibit emergent properties, in a way that we suggest may be better described as ''statistically autonomous''. Overall, we observe that in this simple scenario information measures align more reliably with the system's mechanistic properties when calculated at the level of microscopic components, rather than their coarse-grained counterparts, and over timescales comparable with the system's intrinsic dynamics. Moreover, we show that approaches that separate the contributions of the system's dynamics and steady-state distribution (e.g. via causal perturbations) may help strengthen the interpretation of information-theoretic analyses.","authors":["Alberto Liardi","Madalina I. Sas","George Blackburne","William J. Knottenbelt","Pedro A. M. Mediano","Henrik Jeldtoft Jensen"],"url":"https://arxiv.org/abs/2504.10372"}
{"created":"2025-04-15","title":"DUE: A Deep Learning Framework and Library for Modeling Unknown Equations","abstract":"Equations, particularly differential equations, are fundamental for understanding natural phenomena and predicting complex dynamics across various scientific and engineering disciplines. However, the governing equations for many complex systems remain unknown due to intricate underlying mechanisms. Recent advancements in machine learning and data science offer a new paradigm for modeling unknown equations from measurement or simulation data. This paradigm shift, known as data-driven discovery or modeling, stands at the forefront of AI for science, with significant progress made in recent years. In this paper, we introduce a systematic framework for data-driven modeling of unknown equations using deep learning. This versatile framework is capable of learning unknown ODEs, PDEs, DAEs, IDEs, SDEs, reduced or partially observed systems, and non-autonomous differential equations. Based on this framework, we have developed Deep Unknown Equations (DUE), an open-source software package designed to facilitate the data-driven modeling of unknown equations using modern deep learning techniques. DUE serves as an educational tool for classroom instruction, enabling students and newcomers to gain hands-on experience with differential equations, data-driven modeling, and contemporary deep learning approaches such as FNN, ResNet, generalized ResNet, operator semigroup networks (OSG-Net), and Transformers. Additionally, DUE is a versatile and accessible toolkit for researchers across various scientific and engineering fields. It is applicable not only for learning unknown equations from data but also for surrogate modeling of known, yet complex, equations that are costly to solve using traditional numerical methods. We provide detailed descriptions of DUE and demonstrate its capabilities through diverse examples, which serve as templates that can be easily adapted for other applications.","authors":["Junfeng Chen","Kailiang Wu","Dongbin Xiu"],"url":"https://arxiv.org/abs/2504.10373"}
{"created":"2025-04-15","title":"Ctrl-Z: Controlling AI Agents via Resampling","abstract":"Control evaluations measure whether monitoring and security protocols for AI systems prevent intentionally subversive AI models from causing harm. Our work presents the first control evaluation performed in an agent environment. We construct BashBench, a dataset of 257 challenging multi-step system administration tasks, and evaluate whether various safety measures can prevent an adversarially constructed AI agent from covertly downloading and executing malicious code in this environment. This multi-step setting introduces new attack and defense dynamics, which we investigate in order to design novel control protocols that prevent safety failures without hindering the ability of non-malicious agents to perform useful work. We introduce a class of control protocols called resample protocols that dynamically take additional samples of certain actions. We find these protocols significantly improve on existing techniques by selectively blocking the AI agent from executing suspicious code and incriminating the agent by generating additional examples of dangerous behavior. We measure the tradeoff between attack prevention and usefulness; our best protocol combines resampling with analysis of previous steps, reducing the success rate of attacks from 58% to 7% at a 5% cost to the performance of a non-malicious agent.","authors":["Aryan Bhatt","Cody Rushing","Adam Kaufman","Tyler Tracy","Vasil Georgiev","David Matolcsi","Akbir Khan","Buck Shlegeris"],"url":"https://arxiv.org/abs/2504.10374"}
{"created":"2025-04-15","title":"PG-DPIR: An efficient plug-and-play method for high-count Poisson-Gaussian inverse problems","abstract":"Poisson-Gaussian noise describes the noise of various imaging systems thus the need of efficient algorithms for Poisson-Gaussian image restoration. Deep learning methods offer state-of-the-art performance but often require sensor-specific training when used in a supervised setting. A promising alternative is given by plug-and-play (PnP) methods, which consist in learning only a regularization through a denoiser, allowing to restore images from several sources with the same network. This paper introduces PG-DPIR, an efficient PnP method for high-count Poisson-Gaussian inverse problems, adapted from DPIR. While DPIR is designed for white Gaussian noise, a naive adaptation to Poisson-Gaussian noise leads to prohibitively slow algorithms due to the absence of a closed-form proximal operator. To address this, we adapt DPIR for the specificities of Poisson-Gaussian noise and propose in particular an efficient initialization of the gradient descent required for the proximal step that accelerates convergence by several orders of magnitude. Experiments are conducted on satellite image restoration and super-resolution problems. High-resolution realistic Pleiades images are simulated for the experiments, which demonstrate that PG-DPIR achieves state-of-the-art performance with improved efficiency, which seems promising for on-ground satellite processing chains.","authors":["Maud Biquard","Marie Chabert","Florence Genin","Christophe Latry","Thomas Oberlin"],"url":"https://arxiv.org/abs/2504.10375"}
{"created":"2025-04-15","title":"A 10.8mW Mixed-Signal Simulated Bifurcation Ising Solver using SRAM Compute-In-Memory with 0.6us Time-to-Solution","abstract":"Combinatorial optimization problems are funda- mental for various fields ranging from finance to wireless net- works. This work presents a simulated bifurcation (SB) Ising solver in CMOS for NP-hard optimization problems. Analog domain computing led to a superior implementation of this algorithm as inherent and injected noise is required in SB Ising solvers. The architecture novelties include the use of SRAM compute-in-memory (CIM) to accelerate bifurcation as well as the generation and injection of optimal decaying noise in the analog domain. We propose a novel 10-T SRAM cell capable of performing ternary multiplication. When measured with 60- node, 50% density, random, binary MAXCUT graphs, this all- to-all connected Ising solver reliably achieves above 93% of the ground state solution in 0.6us with 10.8mW average power in TSMC 180nm CMOS. Our chip achieves an order of magnitude improvement in time-to-solution and power compared to previously proposed Ising solvers in CMOS and other platforms.","authors":["Alana Marie Dee","Sajjad Moazeni"],"url":"https://arxiv.org/abs/2504.10384"}
{"created":"2025-04-15","title":"Teacher Motion Priors: Enhancing Robot Locomotion over Challenging Terrain","abstract":"Achieving robust locomotion on complex terrains remains a challenge due to high dimensional control and environmental uncertainties. This paper introduces a teacher prior framework based on the teacher student paradigm, integrating imitation and auxiliary task learning to improve learning efficiency and generalization. Unlike traditional paradigms that strongly rely on encoder-based state embeddings, our framework decouples the network design, simplifying the policy network and deployment. A high performance teacher policy is first trained using privileged information to acquire generalizable motion skills. The teacher's motion distribution is transferred to the student policy, which relies only on noisy proprioceptive data, via a generative adversarial mechanism to mitigate performance degradation caused by distributional shifts. Additionally, auxiliary task learning enhances the student policy's feature representation, speeding up convergence and improving adaptability to varying terrains. The framework is validated on a humanoid robot, showing a great improvement in locomotion stability on dynamic terrains and significant reductions in development costs. This work provides a practical solution for deploying robust locomotion strategies in humanoid robots.","authors":["Fangcheng Jin","Yuqi Wang","Peixin Ma","Guodong Yang","Pan Zhao","En Li","Zhengtao Zhang"],"url":"https://arxiv.org/abs/2504.10390"}
{"created":"2025-04-15","title":"LLM-driven Constrained Copy Generation through Iterative Refinement","abstract":"Crafting a marketing message (copy), or copywriting is a challenging generation task, as the copy must adhere to various constraints. Copy creation is inherently iterative for humans, starting with an initial draft followed by successive refinements. However, manual copy creation is time-consuming and expensive, resulting in only a few copies for each use case. This limitation restricts our ability to personalize content to customers. Contrary to the manual approach, LLMs can generate copies quickly, but the generated content does not consistently meet all the constraints on the first attempt (similar to humans). While recent studies have shown promise in improving constrained generation through iterative refinement, they have primarily addressed tasks with only a few simple constraints. Consequently, the effectiveness of iterative refinement for tasks such as copy generation, which involves many intricate constraints, remains unclear. To address this gap, we propose an LLM-based end-to-end framework for scalable copy generation using iterative refinement. To the best of our knowledge, this is the first study to address multiple challenging constraints simultaneously in copy generation. Examples of these constraints include length, topics, keywords, preferred lexical ordering, and tone of voice. We demonstrate the performance of our framework by creating copies for e-commerce banners for three different use cases of varying complexity. Our results show that iterative refinement increases the copy success rate by $16.25-35.91$% across use cases. Furthermore, the copies generated using our approach outperformed manually created content in multiple pilot studies using a multi-armed bandit framework. The winning copy improved the click-through rate by $38.5-45.21$%.","authors":["Varun Vasudevan","Faezeh Akhavizadegan","Abhinav Prakash","Yokila Arora","Jason Cho","Tanya Mendiratta","Sushant Kumar","Kannan Achan"],"url":"https://arxiv.org/abs/2504.10391"}
{"created":"2025-04-15","title":"Better Coherence, Better Height: Fusing Physical Models and Deep Learning for Forest Height Estimation from Interferometric SAR Data","abstract":"Estimating forest height from Synthetic Aperture Radar (SAR) images often relies on traditional physical models, which, while interpretable and data-efficient, can struggle with generalization. In contrast, Deep Learning (DL) approaches lack physical insight. To address this, we propose CoHNet - an end-to-end framework that combines the best of both worlds: DL optimized with physics-informed constraints. We leverage a pre-trained neural surrogate model to enforce physical plausibility through a unique training loss. Our experiments show that this approach not only improves forest height estimation accuracy but also produces meaningful features that enhance the reliability of predictions.","authors":["Ragini Bal Mahesh","Ronny H\\\"ansch"],"url":"https://arxiv.org/abs/2504.10395"}
{"created":"2025-04-15","title":"Can LLMs Assist Expert Elicitation for Probabilistic Causal Modeling?","abstract":"Objective: This study investigates the potential of Large Language Models (LLMs) as an alternative to human expert elicitation for extracting structured causal knowledge and facilitating causal modeling in biometric and healthcare applications.","authors":["Olha Shaposhnyk","Daria Zahorska","Svetlana Yanushkevich"],"url":"https://arxiv.org/abs/2504.10397"}
{"created":"2025-04-15","title":"Unique Decoding of Reed-Solomon and Related Codes for Semi-Adversarial Errors","abstract":"For over a quarter century, the Guruswami-Sudan algorithm has served as the state-of-the-art for list-decoding Reed-Solomon (RS) codes up to the Johnson bound against adversarial errors. However, some recent structural results on the combinatorial list decoding of randomly punctured Reed-Solomon codes suggest that Johnson bound can likely be broken for some subclasses of RS codes. Motivated by these results, we seek to make traction on understanding adversarial decoding by considering a new model: semi-adversarial errors. This error model bridges between fully random errors and fully adversarial errors by allowing some symbols of a message to be corrupted by an adversary while others are replaced with uniformly random symbols.","authors":["Joshua Brakensiek","Yeyuan Chen","Manik Dhar","Zihan Zhang"],"url":"https://arxiv.org/abs/2504.10399"}
{"created":"2025-04-15","title":"Towards Low-Latency Event-based Obstacle Avoidance on a FPGA-Drone","abstract":"This work quantitatively evaluates the performance of event-based vision systems (EVS) against conventional RGB-based models for action prediction in collision avoidance on an FPGA accelerator. Our experiments demonstrate that the EVS model achieves a significantly higher effective frame rate (1 kHz) and lower temporal (-20 ms) and spatial prediction errors (-20 mm) compared to the RGB-based model, particularly when tested on out-of-distribution data. The EVS model also exhibits superior robustness in selecting optimal evasion maneuvers. In particular, in distinguishing between movement and stationary states, it achieves a 59 percentage point advantage in precision (78% vs. 19%) and a substantially higher F1 score (0.73 vs. 0.06), highlighting the susceptibility of the RGB model to overfitting. Further analysis in different combinations of spatial classes confirms the consistent performance of the EVS model in both test data sets. Finally, we evaluated the system end-to-end and achieved a latency of approximately 2.14 ms, with event aggregation (1 ms) and inference on the processing unit (0.94 ms) accounting for the largest components. These results underscore the advantages of event-based vision for real-time collision avoidance and demonstrate its potential for deployment in resource-constrained environments.","authors":["Pietro Bonazzi","Christian Vogt","Michael Jost","Lyes Khacef","Federico Paredes-Vall\\'es","Michele Magno"],"url":"https://arxiv.org/abs/2504.10400"}
{"created":"2025-04-15","title":"Satellite Federated Fine-Tuning for Foundation Models in Space Computing Power Networks","abstract":"Advancements in artificial intelligence (AI) and low-earth orbit (LEO) satellites have promoted the application of large remote sensing foundation models for various downstream tasks. However, direct downloading of these models for fine-tuning on the ground is impeded by privacy concerns and limited bandwidth. Satellite federated learning (FL) offers a solution by enabling model fine-tuning directly on-board satellites and aggregating model updates without data downloading. Nevertheless, for large foundation models, the computational capacity of satellites is insufficient to support effective on-board fine-tuning in traditional satellite FL frameworks. To address these challenges, we propose a satellite-ground collaborative federated fine-tuning framework. The key of the framework lies in how to reasonably decompose and allocate model components to alleviate insufficient on-board computation capabilities. During fine-tuning, satellites exchange intermediate results with ground stations or other satellites for forward propagation and back propagation, which brings communication challenges due to the special communication topology of space transmission networks, such as intermittent satellite-ground communication, short duration of satellite-ground communication windows, and unstable inter-orbit inter-satellite links (ISLs). To reduce transmission delays, we further introduce tailored communication strategies that integrate both communication and computing resources. Specifically, we propose a parallel intra-orbit communication strategy, a topology-aware satellite-ground communication strategy, and a latency-minimalization inter-orbit communication strategy to reduce space communication costs. Simulation results demonstrate significant reductions in training time with improvements of approximately 33%.","authors":["Yan zhu","Jingyang zhu","Ting Wang","Yuanming Shi","Chunxiao Jiang","Khaled Ben Letaief"],"url":"https://arxiv.org/abs/2504.10403"}
{"created":"2025-04-15","title":"Framing Perception: Exploring Camera Induced Objectification in Cinema","abstract":"This study investigates how cinematographic techniques influence viewer perception and contribute to the objectification of women, utilizing eye-tracking data from 91 participants. They watched a sexualized music video (SV) known for objectifying portrayals and a non-sexualized music video (TV). Using dynamic Areas of Interests (AOIs) (head, torso, and lower body), gaze metrics such as fixation duration, visit count, and scan paths were recorded to assess visual attention patterns. Participants were grouped according to their average fixations on sexualized AOIs. Statistical analyses revealed significant differences in gaze behavior between the videos and among the groups, with increased attention to sexualized AOIs in SV. Additionally, data-driven group differences in fixations identified specific segments with heightened objectification that are further analyzed using scan path visualization techniques. These findings provide strong empirical evidence of camera-driven gaze objectification, demonstrating how cinematic framing implicitly shapes objectifying gaze patterns, highlighting the critical need for mindful media representation.","authors":["Parth Maradia","Ayushi Agarwal","Srija Bhupathiraju","Kavita Vemuri"],"url":"https://arxiv.org/abs/2504.10404"}
{"created":"2025-04-15","title":"Performance of Large Language Models in Supporting Medical Diagnosis and Treatment","abstract":"The integration of Large Language Models (LLMs) into healthcare holds significant potential to enhance diagnostic accuracy and support medical treatment planning. These AI-driven systems can analyze vast datasets, assisting clinicians in identifying diseases, recommending treatments, and predicting patient outcomes. This study evaluates the performance of a range of contemporary LLMs, including both open-source and closed-source models, on the 2024 Portuguese National Exam for medical specialty access (PNA), a standardized medical knowledge assessment. Our results highlight considerable variation in accuracy and cost-effectiveness, with several models demonstrating performance exceeding human benchmarks for medical students on this specific task. We identify leading models based on a combined score of accuracy and cost, discuss the implications of reasoning methodologies like Chain-of-Thought, and underscore the potential for LLMs to function as valuable complementary tools aiding medical professionals in complex clinical decision-making.","authors":["Diogo Sousa","Guilherme Barbosa","Catarina Rocha","Dulce Oliveira"],"url":"https://arxiv.org/abs/2504.10405"}
{"created":"2025-04-15","title":"GPS: Distilling Compact Memories via Grid-based Patch Sampling for Efficient Online Class-Incremental Learning","abstract":"Online class-incremental learning aims to enable models to continuously adapt to new classes with limited access to past data, while mitigating catastrophic forgetting. Replay-based methods address this by maintaining a small memory buffer of previous samples, achieving competitive performance. For effective replay under constrained storage, recent approaches leverage distilled data to enhance the informativeness of memory. However, such approaches often involve significant computational overhead due to the use of bi-level optimization. Motivated by these limitations, we introduce Grid-based Patch Sampling (GPS), a lightweight and effective strategy for distilling informative memory samples without relying on a trainable model. GPS generates informative samples by sampling a subset of pixels from the original image, yielding compact low-resolution representations that preserve both semantic content and structural information. During replay, these representations are reassembled to support training and evaluation. Experiments on extensive benchmarks demonstrate that GRS can be seamlessly integrated into existing replay frameworks, leading to 3%-4% improvements in average end accuracy under memory-constrained settings, with limited computational overhead.","authors":["Mingchuan Ma","Yuhao Zhou","Jindi Lv","Yuxin Tian","Dan Si","Shujian Li","Qing Ye","Jiancheng Lv"],"url":"https://arxiv.org/abs/2504.10409"}
{"created":"2025-04-15","title":"FPGA-Optimized Hardware Accelerator for Fast Fourier Transform and Singular Value Decomposition in AI","abstract":"This research introduces an FPGA-based hardware accelerator to optimize the Singular Value Decomposition (SVD) and Fast Fourier transform (FFT) operations in AI models. The proposed design aims to improve processing speed and reduce computational latency. Through experiments, we validate the performance benefits of the hardware accelerator and show how well it handles FFT and SVD operations. With its strong security and durability, the accelerator design achieves significant speedups over software implementations, thanks to its modules for data flow control, watermark embedding, FFT, and SVD.","authors":["Hong Ding","Chia Chao Kang","SuYang Xi","Zehang Liu","Xuan Zhang","Yi Ding"],"url":"https://arxiv.org/abs/2504.10411"}
{"created":"2025-04-15","title":"AI-Driven Code Refactoring: Using Graph Neural Networks to Enhance Software Maintainability","abstract":"This study explores Graph Neural Networks (GNNs) as a transformative tool for code refactoring, using abstract syntax trees (ASTs) to boost software maintainability. It analyzes a dataset of 2 million snippets from CodeSearchNet and a custom 75000-file GitHub Python corpus, comparing GNNs against rule-based SonarQube and decision trees. Metrics include cyclomatic complexity (target below 10), coupling (target below 5), and refactoring precision. GNNs achieve 92% accuracy, reducing complexity by 35% and coupling by 33%, outperforming SonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% of syntax errors. Bar graphs, tables, and AST visuals clarify results. This offers a scalable AI-driven path to cleaner codebases, which is crucial for software engineering.","authors":["Gopichand Bandarupalli"],"url":"https://arxiv.org/abs/2504.10412"}
{"created":"2025-04-15","title":"HUMOTO: A 4D Dataset of Mocap Human Object Interactions","abstract":"We present Human Motions with Objects (HUMOTO), a high-fidelity dataset of human-object interactions for motion generation, computer vision, and robotics applications. Featuring 736 sequences (7,875 seconds at 30 fps), HUMOTO captures interactions with 63 precisely modeled objects and 72 articulated parts. Our innovations include a scene-driven LLM scripting pipeline creating complete, purposeful tasks with natural progression, and a mocap-and-camera recording setup to effectively handle occlusions. Spanning diverse activities from cooking to outdoor picnics, HUMOTO preserves both physical accuracy and logical task flow. Professional artists rigorously clean and verify each sequence, minimizing foot sliding and object penetrations. We also provide benchmarks compared to other datasets. HUMOTO's comprehensive full-body motion and simultaneous multi-object interactions address key data-capturing challenges and provide opportunities to advance realistic human-object interaction modeling across research domains with practical applications in animation, robotics, and embodied AI systems. Project: https://jiaxin-lu.github.io/humoto/ .","authors":["Jiaxin Lu","Chun-Hao Paul Huang","Uttaran Bhattacharya","Qixing Huang","Yi Zhou"],"url":"https://arxiv.org/abs/2504.10414"}
{"created":"2025-04-15","title":"LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models","abstract":"Scientific equation discovery is a fundamental task in the history of scientific progress, enabling the derivation of laws governing natural phenomena. Recently, Large Language Models (LLMs) have gained interest for this task due to their potential to leverage embedded scientific knowledge for hypothesis generation. However, evaluating the true discovery capabilities of these methods remains challenging, as existing benchmarks often rely on common equations that are susceptible to memorization by LLMs, leading to inflated performance metrics that do not reflect discovery. In this paper, we introduce LLM-SRBench, a comprehensive benchmark with 239 challenging problems across four scientific domains specifically designed to evaluate LLM-based scientific equation discovery methods while preventing trivial memorization. Our benchmark comprises two main categories: LSR-Transform, which transforms common physical models into less common mathematical representations to test reasoning beyond memorized forms, and LSR-Synth, which introduces synthetic, discovery-driven problems requiring data-driven reasoning. Through extensive evaluation of several state-of-the-art methods, using both open and closed LLMs, we find that the best-performing system so far achieves only 31.5% symbolic accuracy. These findings highlight the challenges of scientific equation discovery, positioning LLM-SRBench as a valuable resource for future research.","authors":["Parshin Shojaee","Ngoc-Hieu Nguyen","Kazem Meidani","Amir Barati Farimani","Khoa D Doan","Chandan K Reddy"],"url":"https://arxiv.org/abs/2504.10415"}
{"created":"2025-04-15","title":"Region Based SLAM-Aware Exploration: Efficient and Robust Autonomous Mapping Strategy That Can Scale","abstract":"Autonomous exploration for mapping unknown large scale environments is a fundamental challenge in robotics, with efficiency in time, stability against map corruption and computational resources being crucial. This paper presents a novel approach to indoor exploration that addresses these key issues in existing methods. We introduce a Simultaneous Localization and Mapping (SLAM)-aware region-based exploration strategy that partitions the environment into discrete regions, allowing the robot to incrementally explore and stabilize each region before moving to the next one. This approach significantly reduces redundant exploration and improves overall efficiency. As the device finishes exploring a region and stabilizes it, we also perform SLAM keyframe marginalization, a technique which reduces problem complexity by eliminating variables, while preserving their essential information. To improves robustness and further enhance efficiency, we develop a check- point system that enables the robot to resume exploration from the last stable region in case of failures, eliminating the need for complete re-exploration. Our method, tested in real homes, office and simulations, outperforms state-of-the-art approaches. The improvements demonstrate substantial enhancements in various real world environments, with significant reductions in keyframe usage (85%), submap usage (50% office, 32% home), pose graph optimization time (78-80%), and exploration duration (10-15%). This region-based strategy with keyframe marginalization offers an efficient solution for autonomous robotic mapping.","authors":["Megha Maheshwari","Sadeigh Rabiee","He Yin","Martin Labrie","Hang Liu"],"url":"https://arxiv.org/abs/2504.10416"}
{"created":"2025-04-15","title":"Silent Self-Stabilizing Ranking: Time Optimal and Space Efficient","abstract":"We present a silent, self-stabilizing ranking protocol for the population protocol model of distributed computing, where agents interact in randomly chosen pairs to solve a common task. We are given $n$ anonymous agents, and the goal is to assign each agent a unique rank in $\\{1, \\dots, n\\}$. Given unique ranks, it is straightforward to select a designated leader. Thus, our protocol is a self-stabilizing leader election protocol as well. Ranking requires at least $n$ states per agent; hence, the goal is to minimize the additional number of states, called overhead states. The core of our protocol is a space-efficient but non-self-stabilizing ranking protocol that requires only $n + O(\\log n)$ states. Our protocol stabilizes in $O(n^2\\log n)$ interactions w.h.p.\\ and in expectation, using $n + O(\\log^2 n)$ states in total. Our stabilization time is asymptotically optimal (see Burman et al., PODC'21). In comparison to the currently best known ranking protocol by Burman et al., which requires $n + \\Omega(n)$ states, our result exponentially improves the number of overhead states.","authors":["Petra Berenbrink","Robert Els\\\"asser","Thorsten G\\\"otte","Lukas Hintze","Dominik Kaaser"],"url":"https://arxiv.org/abs/2504.10417"}
{"created":"2025-04-15","title":"CliniChat: A Multi-Source Knowledge-Driven Framework for Clinical Interview Dialogue Reconstruction and Evaluation","abstract":"Large language models (LLMs) hold great promise for assisting clinical interviews due to their fluent interactive capabilities and extensive medical knowledge. However, the lack of high-quality interview dialogue data and widely accepted evaluation methods has significantly impeded this process. So we propose CliniChat, a framework that integrates multi-source knowledge to enable LLMs to simulate real-world clinical interviews. It consists of two modules: Clini-Recon and Clini-Eval, each responsible for reconstructing and evaluating interview dialogues, respectively. By incorporating three sources of knowledge, Clini-Recon transforms clinical notes into systematic, professional, and empathetic interview dialogues. Clini-Eval combines a comprehensive evaluation metric system with a two-phase automatic evaluation approach, enabling LLMs to assess interview performance like experts. We contribute MedQA-Dialog, a high-quality synthetic interview dialogue dataset, and CliniChatGLM, a model specialized for clinical interviews. Experimental results demonstrate that CliniChatGLM's interview capabilities undergo a comprehensive upgrade, particularly in history-taking, achieving state-of-the-art performance.","authors":["Jing Chen","Zhihua Wei","Wei Zhang","Yingying Hu","Qiong Zhang"],"url":"https://arxiv.org/abs/2504.10418"}
{"created":"2025-04-15","title":"Unchecked and Overlooked: Addressing the Checkbox Blind Spot in Large Language Models with CheckboxQA","abstract":"Checkboxes are critical in real-world document processing where the presence or absence of ticks directly informs data extraction and decision-making processes. Yet, despite the strong performance of Large Vision and Language Models across a wide range of tasks, they struggle with interpreting checkable content. This challenge becomes particularly pressing in industries where a single overlooked checkbox may lead to costly regulatory or contractual oversights. To address this gap, we introduce the CheckboxQA dataset, a targeted resource designed to evaluate and improve model performance on checkbox-related tasks. It reveals the limitations of current models and serves as a valuable tool for advancing document comprehension systems, with significant implications for applications in sectors such as legal tech and finance.","authors":["Micha{\\l} Turski","Mateusz Chili\\'nski","{\\L}ukasz Borchmann"],"url":"https://arxiv.org/abs/2504.10419"}
{"created":"2025-04-15","title":"Can We Edit LLMs for Long-Tail Biomedical Knowledge?","abstract":"Knowledge editing has emerged as an effective approach for updating large language models (LLMs) by modifying their internal knowledge. However, their application to the biomedical domain faces unique challenges due to the long-tailed distribution of biomedical knowledge, where rare and infrequent information is prevalent. In this paper, we conduct the first comprehensive study to investigate the effectiveness of knowledge editing methods for editing long-tail biomedical knowledge. Our results indicate that, while existing editing methods can enhance LLMs' performance on long-tail biomedical knowledge, their performance on long-tail knowledge remains inferior to that on high-frequency popular knowledge, even after editing. Our further analysis reveals that long-tail biomedical knowledge contains a significant amount of one-to-many knowledge, where one subject and relation link to multiple objects. This high prevalence of one-to-many knowledge limits the effectiveness of knowledge editing in improving LLMs' understanding of long-tail biomedical knowledge, highlighting the need for tailored strategies to bridge this performance gap.","authors":["Xinhao Yi","Jake Lever","Kevin Bryson","Zaiqiao Meng"],"url":"https://arxiv.org/abs/2504.10421"}
{"created":"2025-04-15","title":"Foundation models for electronic health records: representation dynamics and transferability","abstract":"Foundation models (FMs) trained on electronic health records (EHRs) have shown strong performance on a range of clinical prediction tasks. However, adapting these models to local health systems remains challenging due to limited data availability and resource constraints. In this study, we investigated what these models learn and evaluated the transferability of an FM trained on MIMIC-IV to an institutional EHR dataset at the University of Chicago Medical Center. We assessed their ability to identify outlier patients and examined representation-space patient trajectories in relation to future clinical outcomes. We also evaluated the performance of supervised fine-tuned classifiers on both source and target datasets. Our findings offer insights into the adaptability of FMs across different healthcare systems, highlight considerations for their effective implementation, and provide an empirical analysis of the underlying factors that contribute to their predictive performance.","authors":["Michael C. Burkhart","Bashar Ramadan","Zewei Liao","Kaveri Chhikara","Juan C. Rojas","William F. Parker","Brett K. Beaulieu-Jones"],"url":"https://arxiv.org/abs/2504.10422"}
{"created":"2025-04-15","title":"Lowering the Cost of Diamond Open Access Journals","abstract":"Many scholarly societies face challenges in adapting their publishing to an open access model where neither authors nor readers pay any fees. Some have argued that one of the main barriers is the actual cost of publishing. The goal of this paper is to show that the actual costs can be extremely low while still maintaining scholarly quality. We accomplish this by building a journal publishing workflow that minimizes the amount of required human labor. We recently built a software system for this and launched a journal using the system, and we estimate estimate our cost to publish this journal is approximately \\$705 per year, plus \\$1 per article and about 10 minutes of volunteer labor per article. We benefited from two factors, namely the fact that authors in our discipline use LaTeX to prepare their manuscripts, and we had volunteer labor to develop software and run the journal. We have made most of this software open source in the hopes that it can help others.","authors":["Joppe Bos","Kevin S. McCurley"],"url":"https://arxiv.org/abs/2504.10424"}
{"created":"2025-04-15","title":"LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety in Large Language Models","abstract":"Recent advancements in Large Language Models (LLMs) have enabled them to approach human-level persuasion capabilities. However, such potential also raises concerns about the safety risks of LLM-driven persuasion, particularly their potential for unethical influence through manipulation, deception, exploitation of vulnerabilities, and many other harmful tactics. In this work, we present a systematic investigation of LLM persuasion safety through two critical aspects: (1) whether LLMs appropriately reject unethical persuasion tasks and avoid unethical strategies during execution, including cases where the initial persuasion goal appears ethically neutral, and (2) how influencing factors like personality traits and external pressures affect their behavior. To this end, we introduce PersuSafety, the first comprehensive framework for the assessment of persuasion safety which consists of three stages, i.e., persuasion scene creation, persuasive conversation simulation, and persuasion safety assessment. PersuSafety covers 6 diverse unethical persuasion topics and 15 common unethical strategies. Through extensive experiments across 8 widely used LLMs, we observe significant safety concerns in most LLMs, including failing to identify harmful persuasion tasks and leveraging various unethical persuasion strategies. Our study calls for more attention to improve safety alignment in progressive and goal-driven conversations such as persuasion.","authors":["Minqian Liu","Zhiyang Xu","Xinyi Zhang","Heajun An","Sarvech Qadir","Qi Zhang","Pamela J. Wisniewski","Jin-Hee Cho","Sang Won Lee","Ruoxi Jia","Lifu Huang"],"url":"https://arxiv.org/abs/2504.10430"}
{"created":"2025-04-15","title":"Invariance Matters: Empowering Social Recommendation via Graph Invariant Learning","abstract":"Graph-based social recommendation systems have shown significant promise in enhancing recommendation performance, particularly in addressing the issue of data sparsity in user behaviors. Typically, these systems leverage Graph Neural Networks (GNNs) to capture user preferences by incorporating high-order social influences from observed social networks. However, existing graph-based social recommendations often overlook the fact that social networks are inherently noisy, containing task-irrelevant relationships that can hinder accurate user preference learning. The removal of these redundant social relations is crucial, yet it remains challenging due to the lack of ground truth. In this paper, we approach the social denoising problem from the perspective of graph invariant learning and propose a novel method, Social Graph Invariant Learning(SGIL). Specifically,SGIL aims to uncover stable user preferences within the input social graph, thereby enhancing the robustness of graph-based social recommendation systems. To achieve this goal, SGIL first simulates multiple noisy social environments through graph generators. It then seeks to learn environment-invariant user preferences by minimizing invariant risk across these environments. To further promote diversity in the generated social environments, we employ an adversarial training strategy to simulate more potential social noisy distributions. Extensive experimental results demonstrate the effectiveness of the proposed SGIL. The code is available at https://github.com/yimutianyang/SIGIR2025-SGIL.","authors":["Yonghui Yang","Le Wu","Yuxin Liao","Zhuangzhuang He","Pengyang Shao","Richang Hong","Meng Wang"],"url":"https://arxiv.org/abs/2504.10432"}
{"created":"2025-04-15","title":"MonoDiff9D: Monocular Category-Level 9D Object Pose Estimation via Diffusion Model","abstract":"Object pose estimation is a core means for robots to understand and interact with their environment. For this task, monocular category-level methods are attractive as they require only a single RGB camera. However, current methods rely on shape priors or CAD models of the intra-class known objects. We propose a diffusion-based monocular category-level 9D object pose generation method, MonoDiff9D. Our motivation is to leverage the probabilistic nature of diffusion models to alleviate the need for shape priors, CAD models, or depth sensors for intra-class unknown object pose estimation. We first estimate coarse depth via DINOv2 from the monocular image in a zero-shot manner and convert it into a point cloud. We then fuse the global features of the point cloud with the input image and use the fused features along with the encoded time step to condition MonoDiff9D. Finally, we design a transformer-based denoiser to recover the object pose from Gaussian noise. Extensive experiments on two popular benchmark datasets show that MonoDiff9D achieves state-of-the-art monocular category-level 9D object pose estimation accuracy without the need for shape priors or CAD models at any stage. Our code will be made public at https://github.com/CNJianLiu/MonoDiff9D.","authors":["Jian Liu","Wei Sun","Hui Yang","Jin Zheng","Zichen Geng","Hossein Rahmani","Ajmal Mian"],"url":"https://arxiv.org/abs/2504.10433"}
{"created":"2025-04-15","title":"Anchor Token Matching: Implicit Structure Locking for Training-free AR Image Editing","abstract":"Text-to-image generation has seen groundbreaking advancements with diffusion models, enabling high-fidelity synthesis and precise image editing through cross-attention manipulation. Recently, autoregressive (AR) models have re-emerged as powerful alternatives, leveraging next-token generation to match diffusion models. However, existing editing techniques designed for diffusion models fail to translate directly to AR models due to fundamental differences in structural control. Specifically, AR models suffer from spatial poverty of attention maps and sequential accumulation of structural errors during image editing, which disrupt object layouts and global consistency. In this work, we introduce Implicit Structure Locking (ISLock), the first training-free editing strategy for AR visual models. Rather than relying on explicit attention manipulation or fine-tuning, ISLock preserves structural blueprints by dynamically aligning self-attention patterns with reference images through the Anchor Token Matching (ATM) protocol. By implicitly enforcing structural consistency in latent space, our method ISLock enables structure-aware editing while maintaining generative autonomy. Extensive experiments demonstrate that ISLock achieves high-quality, structure-consistent edits without additional training and is superior or comparable to conventional editing techniques. Our findings pioneer the way for efficient and flexible AR-based image editing, further bridging the performance gap between diffusion and autoregressive generative models. The code will be publicly available at https://github.com/hutaiHang/ATM","authors":["Taihang Hu","Linxuan Li","Kai Wang","Yaxing Wang","Jian Yang","Ming-Ming Cheng"],"url":"https://arxiv.org/abs/2504.10434"}
{"created":"2025-04-15","title":"What metric to optimize for suppressing instability in a Vlasov-Poisson system?","abstract":"Stabilizing plasma dynamics is an important task in green energy generation via nuclear fusion. One common strategy is to introduce an external field to prevent the plasma distribution from developing turbulence. However, finding such external fields efficiently remains an open question, even for simplified models such as the Vlasov-Poisson (VP) system. In this work, we leverage two different approaches to build such fields: for the first approach, we use an analytical derivation of the dispersion relation of the VP system to find a range of reasonable fields that can potentially suppress instability, providing a qualitative suggestion. For the second approach, we leverage PDE-constrained optimization to obtain a locally optimal field using different loss functions. As the stability of the system can be characterized in several different ways, the objective functions need to be tailored accordingly. We show, through extensive numerical tests, that objective functions such as the relative entropy (KL divergence) and the $L^{2}$ norm result in a highly non-convex problem, rendering the global minimum difficult to find. However, we show that using the electric energy of the system as a loss function is advantageous, as it has a large convex basin close to the global minimum. Unfortunately, outside the basin, the electric energy landscape consists of unphysical flat local minima, thus rendering a good initial guess key for the overall convergence of the optimization problem, particularly for solvers with adaptive steps.","authors":["Martin Guerra","Qin Li","Yukun Yue"],"url":"https://arxiv.org/abs/2504.10435"}
{"created":"2025-04-15","title":"Model Order Reduction of Linear Systems via $(\\gamma,\\delta)$-Similarity","abstract":"Model order reduction aims to determine a low-order approximation of high-order models with least possible approximation errors. For application to physical systems, it is crucial that the reduced order model (ROM) is robust to any disturbance that acts on the full order model (FOM) -- in the sense that the output of the ROM remains a good approximation of that of the FOM, even in the presence of such disturbances. In this work, we present a framework for model order reduction for a class of continuous-time linear systems that ensures this property for any $L_2$ disturbance. Apart from robustness to disturbances in this sense, the proposed framework also displays other desirable properties for model order reduction: (1) a provable bound on the error defined as the $L_2$ norm of the difference between the output of the ROM and FOM, (2) preservation of stability, (3) compositionality properties and a provable error bound for arbitrary interconnected systems, (4) a provable bound on the output of the FOM when the controller designed for the ROM is used with the FOM, and finally, (5) compatibility with existing approaches such as balanced truncation and moment matching. Property (4) does not require computation of any gap metric and property (5) is beneficial as existing approaches can also be equipped with some of the preceding properties. The theoretical results are corroborated on numerical case studies, including on a building model.","authors":["Shivam Bajaj","Carolyn L. Beck","Vijay Gupta"],"url":"https://arxiv.org/abs/2504.10437"}
{"created":"2025-04-15","title":"Streaming Democratized: Ease Across the Latency Spectrum with Delayed View Semantics and Snowflake Dynamic Tables","abstract":"Streaming data pipelines remain challenging and expensive to build and maintain, despite significant advancements in stronger consistency, event time semantics, and SQL support over the last decade. Persistent obstacles continue to hinder usability, such as the need for manual incrementalization, semantic discrepancies across SQL implementations, and the lack of enterprise-grade operational features. While the rise of incremental view maintenance (IVM) as a way to integrate streaming with databases has been a huge step forward, transaction isolation in the presence of IVM remains underspecified, leaving the maintenance of application-level invariants as a painful exercise for the user. Meanwhile, most streaming systems optimize for latencies of 100 ms to 3 sec, whereas many practical use cases are well-served by latencies ranging from seconds to tens of minutes.","authors":["Daniel Sotolongo","Daniel Mills","Tyler Akidau","Anirudh Santhiar","Attila-P\\'eter T\\'oth","Ilaria Battiston","Ankur Sharma","Botong Huang","Boyuan Zhang","Dzmitry Pauliukevich","Enrico Sartorello","Igor Belianski","Ivan Kalev","Lawrence Benson","Leon Papke","Ling Geng","Matt Uhlar","Nikhil Shah","Niklas Semmler","Olivia Zhou","Saras Nowak","Sasha Lionheart","Till Merker","Vlad Lifliand","Wendy Grus","Yi Huang","Yiwen Zhu"],"url":"https://arxiv.org/abs/2504.10438"}
{"created":"2025-04-15","title":"Bayesian Analysis of Interpretable Aging across Thousands of Lithium-ion Battery Cycles","abstract":"The Doyle-Fuller-Newman (DFN) model is a common mechanistic model for lithium-ion batteries. The reaction rate constant and diffusivity within the DFN model are key parameters that directly affect the movement of lithium ions, thereby offering explanations for cell aging. This work investigates the ability to uniquely estimate each electrode's diffusion coefficients and reaction rate constants of 95 Tesla Model 3 cells with a nickel cobalt aluminum oxide (NCA) cathode and silicon oxide--graphite (LiC$_\\text{6}$--SiO$_{\\text{x}}$) anode. The parameters are estimated at intermittent diagnostic cycles over the lifetime of each cell. The four parameters are estimated using Markov chain Monte Carlo (MCMC) for uncertainty quantification (UQ) for a total of 7776 cycles at discharge C-rates of C/5, 1C, and 2C. While one or more anode parameters are uniquely identifiable over every cell's lifetime, cathode parameters become identifiable at mid- to end-of-life, indicating measurable resistive growth in the cathode. The contribution of key parameters to the state of health (SOH) is expressed as a power law. This model for SOH shows a high consistency with the MCMC results performed over the overall lifespan of each cell. Our approach suggests that effective diagnosis of aging can be achieved by predicting the trajectories of the parameters contributing to cell aging. As such, extending our analysis with more physically accurate models building on DFN may lead to more identifiable parameters and further improved aging predictions.","authors":["Marc D. Berliner","Minsu Kim","Xiao Cui","Vivek N. Lam","Patrick A. Asinger","Martin Z. Bazant","William C. Chueh","Richard D. Braatz"],"url":"https://arxiv.org/abs/2504.10439"}
{"created":"2025-04-15","title":"HybridCollab: Unifying In-Person and Remote Collaboration for Cardiovascular Surgical Planning in Mobile Augmented Reality","abstract":"Surgical planning for congenital heart disease traditionally relies on collaborative group examinations of a patient's 3D-printed heart model, a process that lacks flexibility and accessibility. While mobile augmented reality (AR) offers a promising alternative with its portability and familiar interaction gestures, existing solutions limit collaboration to users in the same physical space. We developed HybridCollab, the first iOS AR application that introduces a novel paradigm that enables both in-person and remote medical teams to interact with a shared AR heart model in a single surgical planning session. For example, a team of two doctors in one hospital room can collaborate in real time with another team in a different hospital.Our approach is the first to leverage Apple's GameKit service for surgical planning, ensuring an identical collaborative experience for all participants, regardless of location. Additionally, co-located users can interact with the same anchored heart model in their shared physical space. By bridging the gap between remote and in-person collaboration across medical teams, HybridCollab has the potential for significant real-world impact, streamlining communication and enhancing the effectiveness of surgical planning. Watch the demo: https://youtu.be/hElqJYDuvLM.","authors":["Pratham Darrpan Mehta","Rahul Ozhur Narayanan","Vidhi Kulkarni","Timothy Slesnick","Fawwaz Shaw","Duen Horng Chau"],"url":"https://arxiv.org/abs/2504.10440"}
{"created":"2025-04-15","title":"Multimodal Long Video Modeling Based on Temporal Dynamic Context","abstract":"Recent advances in Large Language Models (LLMs) have led to significant breakthroughs in video understanding. However, existing models still struggle with long video processing due to the context length constraint of LLMs and the vast amount of information within the video. Although some recent methods are designed for long video understanding, they often lose crucial information during token compression and struggle with additional modality like audio. In this work, we propose a dynamic long video encoding method utilizing the temporal relationship between frames, named Temporal Dynamic Context (TDC). Firstly, we segment the video into semantically consistent scenes based on inter-frame similarities, then encode each frame into tokens using visual-audio encoders. Secondly, we propose a novel temporal context compressor to reduce the number of tokens within each segment. Specifically, we employ a query-based Transformer to aggregate video, audio, and instruction text tokens into a limited set of temporal context tokens. Finally, we feed the static frame tokens and the temporal context tokens into the LLM for video understanding. Furthermore, to handle extremely long videos, we propose a training-free chain-of-thought strategy that progressively extracts answers from multiple video segments. These intermediate answers serve as part of the reasoning process and contribute to the final answer. We conduct extensive experiments on general video understanding and audio-video understanding benchmarks, where our method demonstrates strong performance. The code and models are available at https://github.com/Hoar012/TDC-Video.","authors":["Haoran Hao","Jiaming Han","Yiyuan Zhang","Xiangyu Yue"],"url":"https://arxiv.org/abs/2504.10443"}
{"created":"2025-04-15","title":"RealWebAssist: A Benchmark for Long-Horizon Web Assistance with Real-World Users","abstract":"To achieve successful assistance with long-horizon web-based tasks, AI agents must be able to sequentially follow real-world user instructions over a long period. Unlike existing web-based agent benchmarks, sequential instruction following in the real world poses significant challenges beyond performing a single, clearly defined task. For instance, real-world human instructions can be ambiguous, require different levels of AI assistance, and may evolve over time, reflecting changes in the user's mental state. To address this gap, we introduce RealWebAssist, a novel benchmark designed to evaluate sequential instruction-following in realistic scenarios involving long-horizon interactions with the web, visual GUI grounding, and understanding ambiguous real-world user instructions. RealWebAssist includes a dataset of sequential instructions collected from real-world human users. Each user instructs a web-based assistant to perform a series of tasks on multiple websites. A successful agent must reason about the true intent behind each instruction, keep track of the mental state of the user, understand user-specific routines, and ground the intended tasks to actions on the correct GUI elements. Our experimental results show that state-of-the-art models struggle to understand and ground user instructions, posing critical challenges in following real-world user instructions for long-horizon web assistance.","authors":["Suyu Ye","Haojun Shi","Darren Shih","Hyokun Yun","Tanya Roosta","Tianmin Shu"],"url":"https://arxiv.org/abs/2504.10445"}
{"created":"2025-04-15","title":"M1: Towards Scalable Test-Time Compute with Mamba Reasoning Models","abstract":"Effective reasoning is crucial to solving complex mathematical problems. Recent large language models (LLMs) have boosted performance by scaling test-time computation through long chain-of-thought reasoning. However, transformer-based models are inherently limited in extending context length due to their quadratic computational complexity and linear memory requirements. In this paper, we introduce a novel hybrid linear RNN reasoning model, M1, built on the Mamba architecture, which allows memory-efficient inference. Our approach leverages a distillation process from existing reasoning models and is further enhanced through RL training. Experimental results on the AIME and MATH benchmarks show that M1 not only outperforms previous linear RNN models but also matches the performance of state-of-the-art Deepseek R1 distilled reasoning models at a similar scale. We also compare our generation speed with a highly performant general purpose inference engine, vLLM, and observe more than a 3x speedup compared to a same size transformer. With throughput speedup, we are able to achieve higher accuracy compared to DeepSeek R1 distilled transformer reasoning models under a fixed generation time budget using self-consistency voting. Overall, we introduce a hybrid Mamba reasoning model and provide a more effective approach to scaling test-time generation using self-consistency or long chain of thought reasoning.","authors":["Junxiong Wang","Wen-Ding Li","Daniele Paliotta","Daniel Ritter","Alexander M. Rush","Tri Dao"],"url":"https://arxiv.org/abs/2504.10449"}
{"created":"2025-04-15","title":"Minimizing Functions of Age of Incorrect Information for Remote Estimation","abstract":"The age of incorrect information (AoII) process which keeps track of the time since the source and monitor processes are in sync, has been extensively used in remote estimation problems. In this paper, we consider a push-based remote estimation system with a discrete-time Markov chain (DTMC) information source transmitting status update packets towards the monitor once the AoII process exceeds a certain estimation-based threshold. In this paper, the time average of an arbitrary function of AoII is taken as the AoII cost, as opposed to using the average AoII as the mismatch metric, whereas this function is also allowed to depend on the estimation value. In this very general setting, our goal is to minimize a weighted sum of AoII and transmission costs. For this purpose, we formulate a discrete-time semi-Markov decision process (SMDP) regarding the multi-threshold status update policy. We propose a novel tool in discrete-time called 'dual-regime absorbing Markov chain' (DR-AMC) and its corresponding absorption time distribution named as 'dual-regime phase-type' (DR-PH) distribution, to obtain the characterizing parameters of the SMDP, which allows us to obtain the distribution of the AoII process for a given policy, and hence the average of any function of AoII. The proposed method is validated with numerical results by which we compare our proposed method against other policies obtained by exhaustive-search, and also various benchmark policies.","authors":["Ismail Cosandal","Sennur Ulukus","Nail Akar"],"url":"https://arxiv.org/abs/2504.10451"}
{"created":"2025-04-15","title":"Integrating Vision and Location with Transformers: A Multimodal Deep Learning Framework for Medical Wound Analysis","abstract":"Effective recognition of acute and difficult-to-heal wounds is a necessary step in wound diagnosis. An efficient classification model can help wound specialists classify wound types with less financial and time costs and also help in deciding on the optimal treatment method. Traditional machine learning models suffer from feature selection and are usually cumbersome models for accurate recognition. Recently, deep learning (DL) has emerged as a powerful tool in wound diagnosis. Although DL seems promising for wound type recognition, there is still a large scope for improving the efficiency and accuracy of the model. In this study, a DL-based multimodal classifier was developed using wound images and their corresponding locations to classify them into multiple classes, including diabetic, pressure, surgical, and venous ulcers. A body map was also created to provide location data, which can help wound specialists label wound locations more effectively. The model uses a Vision Transformer to extract hierarchical features from input images, a Discrete Wavelet Transform (DWT) layer to capture low and high frequency components, and a Transformer to extract spatial features. The number of neurons and weight vector optimization were performed using three swarm-based optimization techniques (Monster Gorilla Toner (MGTO), Improved Gray Wolf Optimization (IGWO), and Fox Optimization Algorithm). The evaluation results show that weight vector optimization using optimization algorithms can increase diagnostic accuracy and make it a very effective approach for wound detection. In the classification using the original body map, the proposed model was able to achieve an accuracy of 0.8123 using image data and an accuracy of 0.8007 using a combination of image data and wound location. Also, the accuracy of the model in combination with the optimization models varied from 0.7801 to 0.8342.","authors":["Ramin Mousa","Hadis Taherinia","Khabiba Abdiyeva","Amir Ali Bengari","Mohammadmahdi Vahediahmar"],"url":"https://arxiv.org/abs/2504.10452"}
{"created":"2025-04-15","title":"Privacy-Preserving Distributed Link Predictions Among Peers in Online Classrooms Using Federated Learning","abstract":"Social interactions among classroom peers, represented as social learning networks (SLNs), play a crucial role in enhancing learning outcomes. While SLN analysis has recently garnered attention, most existing approaches rely on centralized training, where data is aggregated and processed on a local/cloud server with direct access to raw data. However, in real-world educational settings, such direct access across multiple classrooms is often restricted due to privacy concerns. Furthermore, training models on isolated classroom data prevents the identification of common interaction patterns that exist across multiple classrooms, thereby limiting model performance. To address these challenges, we propose one of the first frameworks that integrates Federated Learning (FL), a distributed and collaborative machine learning (ML) paradigm, with SLNs derived from students' interactions in multiple classrooms' online forums to predict future link formations (i.e., interactions) among students. By leveraging FL, our approach enables collaborative model training across multiple classrooms while preserving data privacy, as it eliminates the need for raw data centralization. Recognizing that each classroom may exhibit unique student interaction dynamics, we further employ model personalization techniques to adapt the FL model to individual classroom characteristics. Our results demonstrate the effectiveness of our approach in capturing both shared and classroom-specific representations of student interactions in SLNs. Additionally, we utilize explainable AI (XAI) techniques to interpret model predictions, identifying key factors that influence link formation across different classrooms. These insights unveil the drivers of social learning interactions within a privacy-preserving, collaborative, and distributed ML framework -- an aspect that has not been explored before.","authors":["Anurata Prabha Hridi","Muntasir Hoq","Zhikai Gao","Collin Lynch","Rajeev Sahay","Seyyedali Hosseinalipour","Bita Akram"],"url":"https://arxiv.org/abs/2504.10456"}
{"created":"2025-04-15","title":"GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents","abstract":"Existing efforts in building Graphical User Interface (GUI) agents largely rely on the training paradigm of supervised fine-tuning on Large Vision-Language Models (LVLMs). However, this approach not only demands extensive amounts of training data but also struggles to effectively understand GUI screenshots and generalize to unseen interfaces. The issue significantly limits its application in real-world scenarios, especially for high-level tasks. Inspired by Reinforcement Fine-Tuning (RFT) in large reasoning models (e.g., DeepSeek-R1), which efficiently enhances the problem-solving capabilities of large language models in real-world settings, we propose \\name, the first reinforcement learning framework designed to enhance the GUI capabilities of LVLMs in high-level real-world task scenarios, through unified action space rule modeling. By leveraging a small amount of carefully curated high-quality data across multiple platforms (including Windows, Linux, MacOS, Android, and Web) and employing policy optimization algorithms such as Group Relative Policy Optimization (GRPO) to update the model, \\name achieves superior performance using only 0.02\\% of the data (3K vs. 13M) compared to previous state-of-the-art methods like OS-Atlas across eight benchmarks spanning three different platforms (mobile, desktop, and web). These results demonstrate the immense potential of reinforcement learning based on unified action space rule modeling in improving the execution capabilities of LVLMs for real-world GUI agent tasks.","authors":["Xiaobo Xia","Run Luo"],"url":"https://arxiv.org/abs/2504.10458"}
{"created":"2025-04-15","title":"The Price of Competitive Information Disclosure","abstract":"In many decision-making scenarios, individuals strategically choose what information to disclose to optimize their own outcomes. It is unclear whether such strategic information disclosure can lead to good societal outcomes. To address this question, we consider a competitive Bayesian persuasion model in which multiple agents selectively disclose information about their qualities to a principal, who aims to choose the candidates with the highest qualities. Using the price-of-anarchy framework, we quantify the inefficiency of such strategic disclosure. We show that the price of anarchy is at most a constant when the agents have independent quality distributions, even if their utility functions are heterogeneous. This result provides the first theoretical guarantee on the limits of inefficiency in Bayesian persuasion with competitive information disclosure.","authors":["Siddhartha Banerjee","Kamesh Munagala","Yiheng Shen","Kangning Wang"],"url":"https://arxiv.org/abs/2504.10459"}
{"created":"2025-04-15","title":"Layered Multirate Control of Constrained Linear Systems","abstract":"Layered control architectures have been a standard paradigm for efficiently managing complex constrained systems. A typical architecture consists of: i) a higher layer, where a low-frequency planner controls a simple model of the system, and ii) a lower layer, where a high-frequency tracking controller guides a detailed model of the system toward the output of the higher-layer model. A fundamental problem in this layered architecture is the design of planners and tracking controllers that guarantee both higher- and lower-layer system constraints are satisfied. Toward addressing this problem, we introduce a principled approach for layered multirate control of linear systems subject to output and input constraints. Inspired by discrete-time simulation functions, we propose a streamlined control design that guarantees the lower-layer system tracks the output of the higher-layer system with computable precision. Using this design, we derive conditions and present a method for propagating the constraints of the lower-layer system to the higher-layer system. The propagated constraints are integrated into the design of an arbitrary planner that can handle higher-layer system constraints. Our framework ensures that the output constraints of the lower-layer system are satisfied at all high-level time steps, while respecting its input constraints at all low-level time steps. We apply our approach in a scenario of motion planning, highlighting its critical role in ensuring collision avoidance.","authors":["Charis Stamouli","Anastasios Tsiamis","Manfred Morari","George J. Pappas"],"url":"https://arxiv.org/abs/2504.10461"}
{"created":"2025-04-15","title":"The Scalability of Simplicity: Empirical Analysis of Vision-Language Learning with a Single Transformer","abstract":"This paper introduces SAIL, a single transformer unified multimodal large language model (MLLM) that integrates raw pixel encoding and language decoding within a singular architecture. Unlike existing modular MLLMs, which rely on a pre-trained vision transformer (ViT), SAIL eliminates the need for a separate vision encoder, presenting a more minimalist architecture design. Instead of introducing novel architectural components, SAIL adapts mix-attention mechanisms and multimodal positional encodings to better align with the distinct characteristics of visual and textual modalities. We systematically compare SAIL's properties-including scalability, cross-modal information flow patterns, and visual representation capabilities-with those of modular MLLMs. By scaling both training data and model size, SAIL achieves performance comparable to modular MLLMs. Notably, the removal of pretrained ViT components enhances SAIL's scalability and results in significantly different cross-modal information flow patterns. Moreover, SAIL demonstrates strong visual representation capabilities, achieving results on par with ViT-22B in vision tasks such as semantic segmentation. Code and models are available at https://github.com/bytedance/SAIL.","authors":["Weixian Lei","Jiacong Wang","Haochen Wang","Xiangtai Li","Jun Hao Liew","Jiashi Feng","Zilong Huang"],"url":"https://arxiv.org/abs/2504.10462"}
{"created":"2025-04-15","title":"Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding","abstract":"Multimodal Large Language Models (MLLMs) achieve remarkable performance for fine-grained pixel-level understanding tasks. However, all the works rely heavily on extra components, such as vision encoder (CLIP), segmentation experts, leading to high system complexity and limiting model scaling. In this work, our goal is to explore a highly simplified MLLM without introducing extra components. Our work is motivated by the recent works on Single trAnsformer as a unified vIsion-Language Model (SAIL) design, where these works jointly learn vision tokens and text tokens in transformers. We present Pixel-SAIL, a single transformer for pixel-wise MLLM tasks. In particular, we present three technical improvements on the plain baseline. First, we design a learnable upsampling module to refine visual token features. Secondly, we propose a novel visual prompt injection strategy to enable the single transformer to understand visual prompt inputs and benefit from the early fusion of visual prompt embeddings and vision tokens. Thirdly, we introduce a vision expert distillation strategy to efficiently enhance the single transformer's fine-grained feature extraction capability. In addition, we have collected a comprehensive pixel understanding benchmark (PerBench), using a manual check. It includes three tasks: detailed object description, visual prompt-based question answering, and visual-text referring segmentation. Extensive experiments on four referring segmentation benchmarks, one visual prompt benchmark, and our PerBench show that our Pixel-SAIL achieves comparable or even better results with a much simpler pipeline. Code and model will be released at https://github.com/magic-research/Sa2VA.","authors":["Tao Zhang","Xiangtai Li","Zilong Huang","Yanwei Li","Weixian Lei","Xueqing Deng","Shihao Chen","Shunping Ji","Jiashi Feng"],"url":"https://arxiv.org/abs/2504.10465"}
{"created":"2025-04-15","title":"Art3D: Training-Free 3D Generation from Flat-Colored Illustration","abstract":"Large-scale pre-trained image-to-3D generative models have exhibited remarkable capabilities in diverse shape generations. However, most of them struggle to synthesize plausible 3D assets when the reference image is flat-colored like hand drawings due to the lack of 3D illusion, which are often the most user-friendly input modalities in art content creation. To this end, we propose Art3D, a training-free method that can lift flat-colored 2D designs into 3D. By leveraging structural and semantic features with pre- trained 2D image generation models and a VLM-based realism evaluation, Art3D successfully enhances the three-dimensional illusion in reference images, thus simplifying the process of generating 3D from 2D, and proves adaptable to a wide range of painting styles. To benchmark the generalization performance of existing image-to-3D models on flat-colored images without 3D feeling, we collect a new dataset, Flat-2D, with over 100 samples. Experimental results demonstrate the performance and robustness of Art3D, exhibiting superior generalizable capacity and promising practical applicability. Our source code and dataset will be publicly available on our project page: https://joy-jy11.github.io/ .","authors":["Xiaoyan Cong","Jiayi Shen","Zekun Li","Rao Fu","Tao Lu","Srinath Sridhar"],"url":"https://arxiv.org/abs/2504.10466"}
{"created":"2025-04-15","title":"MIEB: Massive Image Embedding Benchmark","abstract":"Image representations are often evaluated through disjointed, task-specific protocols, leading to a fragmented understanding of model capabilities. For instance, it is unclear whether an image embedding model adept at clustering images is equally good at retrieving relevant images given a piece of text. We introduce the Massive Image Embedding Benchmark (MIEB) to evaluate the performance of image and image-text embedding models across the broadest spectrum to date. MIEB spans 38 languages across 130 individual tasks, which we group into 8 high-level categories. We benchmark 50 models across our benchmark, finding that no single method dominates across all task categories. We reveal hidden capabilities in advanced vision models such as their accurate visual representation of texts, and their yet limited capabilities in interleaved encodings and matching images and texts in the presence of confounders. We also show that the performance of vision encoders on MIEB correlates highly with their performance when used in multimodal large language models. Our code, dataset, and leaderboard are publicly available at https://github.com/embeddings-benchmark/mteb.","authors":["Chenghao Xiao","Isaac Chung","Imene Kerboua","Jamie Stirling","Xin Zhang","M\\'arton Kardos","Roman Solomatin","Noura Al Moubayed","Kenneth Enevoldsen","Niklas Muennighoff"],"url":"https://arxiv.org/abs/2504.10471"}
{"created":"2025-04-15","title":"Co-optimizing Physical Reconfiguration Parameters and Controllers for an Origami-inspired Reconfigurable Manipulator","abstract":"Reconfigurable robots that can change their physical configuration post-fabrication have demonstrate their potential in adapting to different environments or tasks. However, it is challenging to determine how to optimally adjust reconfigurable parameters for a given task, especially when the controller depends on the robot's configuration. In this paper, we address this problem using a tendon-driven reconfigurable manipulator composed of multiple serially connected origami-inspired modules as an example. Under tendon actuation, these modules can achieve different shapes and motions, governed by joint stiffnesses (reconfiguration parameters) and the tendon displacements (control inputs). We leverage recent advances in co-optimization of design and control for robotic system to treat reconfiguration parameters as design variables and optimize them using reinforcement learning techniques. We first establish a forward model based on the minimum potential energy method to predict the shape of the manipulator under tendon actuations. Using the forward model as the environment dynamics, we then co-optimize the control policy (on the tendon displacements) and joint stiffnesses of the modules for goal reaching tasks while ensuring collision avoidance. Through co-optimization, we obtain optimized joint stiffness and the corresponding optimal control policy to enable the manipulator to accomplish the task that would be infeasible with fixed reconfiguration parameters (i.e., fixed joint stiffness). We envision the co-optimization framework can be extended to other reconfigurable robotic systems, enabling them to optimally adapt their configuration and behavior for diverse tasks and environments.","authors":["Zhe Chen","Li Chen","Hao Zhang","Jianguo Zhao"],"url":"https://arxiv.org/abs/2504.10474"}
{"created":"2025-04-15","title":"Weight Ensembling Improves Reasoning in Language Models","abstract":"We investigate a failure mode that arises during the training of reasoning models, where the diversity of generations begins to collapse, leading to suboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during supervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a simple intervention of interpolating the weights of the latest SFT checkpoint with an early checkpoint, otherwise known as WiSE-FT, almost completely recovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves better test-time scaling (Best@k, majority vote) and achieves superior results with less data when tuned further by reinforcement learning. Finally, we find that WiSE-FT provides complementary performance gains that cannot be achieved only through diversity-inducing decoding strategies, like temperature scaling. We formalize a bias-variance tradeoff of Pass@k with respect to the expectation and variance of Pass@1 over the test distribution. We find that WiSE-FT can reduce bias and variance simultaneously, while temperature scaling inherently trades-off between bias and variance.","authors":["Xingyu Dang","Christina Baek","Kaiyue Wen","Zico Kolter","Aditi Raghunathan"],"url":"https://arxiv.org/abs/2504.10478"}
{"created":"2025-04-15","title":"InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models","abstract":"We introduce InternVL3, a significant advancement in the InternVL series featuring a native multimodal pre-training paradigm. Rather than adapting a text-only large language model (LLM) into a multimodal large language model (MLLM) that supports visual inputs, InternVL3 jointly acquires multimodal and linguistic capabilities from both diverse multimodal data and pure-text corpora during a single pre-training stage. This unified training paradigm effectively addresses the complexities and alignment challenges commonly encountered in conventional post-hoc training pipelines for MLLMs. To further improve performance and scalability, InternVL3 incorporates variable visual position encoding (V2PE) to support extended multimodal contexts, employs advanced post-training techniques such as supervised fine-tuning (SFT) and mixed preference optimization (MPO), and adopts test-time scaling strategies alongside an optimized training infrastructure. Extensive empirical evaluations demonstrate that InternVL3 delivers superior performance across a wide range of multi-modal tasks. In particular, InternVL3-78B achieves a score of 72.2 on the MMMU benchmark, setting a new state-of-the-art among open-source MLLMs. Its capabilities remain highly competitive with leading proprietary models, including ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro, while also maintaining strong pure-language proficiency. In pursuit of open-science principles, we will publicly release both the training data and model weights to foster further research and development in next-generation MLLMs.","authors":["Jinguo Zhu","Weiyun Wang","Zhe Chen","Zhaoyang Liu","Shenglong Ye","Lixin Gu","Yuchen Duan","Hao Tian","Weijie Su","Jie Shao","Zhangwei Gao","Erfei Cui","Yue Cao","Yangzhou Liu","Weiye Xu","Hao Li","Jiahao Wang","Han Lv","Dengnian Chen","Songze Li","Yinan He","Tan Jiang","Jiapeng Luo","Yi Wang","Conghui He","Botian Shi","Xingcheng Zhang","Wenqi Shao","Junjun He","Yingtong Xiong","Wenwen Qu","Peng Sun","Penglong Jiao","Lijun Wu","Kaipeng Zhang","Huipeng Deng","Jiaye Ge","Kai Chen","Limin Wang","Min Dou","Lewei Lu","Xizhou Zhu","Tong Lu","Dahua Lin","Yu Qiao","Jifeng Dai","Wenhai Wang"],"url":"https://arxiv.org/abs/2504.10479"}
{"created":"2025-04-15","title":"xVerify: Efficient Answer Verifier for Reasoning Model Evaluations","abstract":"With the release of the o1 model by OpenAI, reasoning models adopting slow thinking strategies have gradually emerged. As the responses generated by such models often include complex reasoning, intermediate steps, and self-reflection, existing evaluation methods are often inadequate. They struggle to determine whether the LLM output is truly equivalent to the reference answer, and also have difficulty identifying and extracting the final answer from long, complex responses. To address this issue, we propose xVerify, an efficient answer verifier for reasoning model evaluations. xVerify demonstrates strong capability in equivalence judgment, enabling it to effectively determine whether the answers produced by reasoning models are equivalent to reference answers across various types of objective questions. To train and evaluate xVerify, we construct the VAR dataset by collecting question-answer pairs generated by multiple LLMs across various datasets, leveraging multiple reasoning models and challenging evaluation sets designed specifically for reasoning model assessment. A multi-round annotation process is employed to ensure label accuracy. Based on the VAR dataset, we train multiple xVerify models of different scales. In evaluation experiments conducted on both the test set and generalization set, all xVerify models achieve overall F1 scores and accuracy exceeding 95\\%. Notably, the smallest variant, xVerify-0.5B-I, outperforms all evaluation methods except GPT-4o, while xVerify-3B-Ib surpasses GPT-4o in overall performance. These results validate the effectiveness and generalizability of xVerify.","authors":["Ding Chen","Qingchen Yu","Pengyuan Wang","Wentao Zhang","Bo Tang","Feiyu Xiong","Xinchi Li","Minchuan Yang","Zhiyu Li"],"url":"https://arxiv.org/abs/2504.10481"}
{"created":"2025-04-15","title":"REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion Transformers","abstract":"In this paper we tackle a fundamental question: \"Can we train latent diffusion models together with the variational auto-encoder (VAE) tokenizer in an end-to-end manner?\" Traditional deep-learning wisdom dictates that end-to-end training is often preferable when possible. However, for latent diffusion transformers, it is observed that end-to-end training both VAE and diffusion-model using standard diffusion-loss is ineffective, even causing a degradation in final performance. We show that while diffusion loss is ineffective, end-to-end training can be unlocked through the representation-alignment (REPA) loss -- allowing both VAE and diffusion model to be jointly tuned during the training process. Despite its simplicity, the proposed training recipe (REPA-E) shows remarkable performance; speeding up diffusion model training by over 17x and 45x over REPA and vanilla training recipes, respectively. Interestingly, we observe that end-to-end tuning with REPA-E also improves the VAE itself; leading to improved latent space structure and downstream generation performance. In terms of final performance, our approach sets a new state-of-the-art; achieving FID of 1.26 and 1.83 with and without classifier-free guidance on ImageNet 256 x 256. Code is available at https://end2end-diffusion.github.io.","authors":["Xingjian Leng","Jaskirat Singh","Yunzhong Hou","Zhenchang Xing","Saining Xie","Liang Zheng"],"url":"https://arxiv.org/abs/2504.10483"}
{"created":"2025-04-15","title":"Decoupled Diffusion Sparks Adaptive Scene Generation","abstract":"Controllable scene generation could reduce the cost of diverse data collection substantially for autonomous driving. Prior works formulate the traffic layout generation as predictive progress, either by denoising entire sequences at once or by iteratively predicting the next frame. However, full sequence denoising hinders online reaction, while the latter's short-sighted next-frame prediction lacks precise goal-state guidance. Further, the learned model struggles to generate complex or challenging scenarios due to a large number of safe and ordinal driving behaviors from open datasets. To overcome these, we introduce Nexus, a decoupled scene generation framework that improves reactivity and goal conditioning by simulating both ordinal and challenging scenarios from fine-grained tokens with independent noise states. At the core of the decoupled pipeline is the integration of a partial noise-masking training strategy and a noise-aware schedule that ensures timely environmental updates throughout the denoising process. To complement challenging scenario generation, we collect a dataset consisting of complex corner cases. It covers 540 hours of simulated data, including high-risk interactions such as cut-in, sudden braking, and collision. Nexus achieves superior generation realism while preserving reactivity and goal orientation, with a 40% reduction in displacement error. We further demonstrate that Nexus improves closed-loop planning by 20% through data augmentation and showcase its capability in safety-critical data generation.","authors":["Yunsong Zhou","Naisheng Ye","William Ljungbergh","Tianyu Li","Jiazhi Yang","Zetong Yang","Hongzi Zhu","Christoffer Petersson","Hongyang Li"],"url":"https://arxiv.org/abs/2504.10485"}
{"created":"2025-04-15","title":"DNF-Avatar: Distilling Neural Fields for Real-time Animatable Avatar Relighting","abstract":"Creating relightable and animatable human avatars from monocular videos is a rising research topic with a range of applications, e.g. virtual reality, sports, and video games. Previous works utilize neural fields together with physically based rendering (PBR), to estimate geometry and disentangle appearance properties of human avatars. However, one drawback of these methods is the slow rendering speed due to the expensive Monte Carlo ray tracing. To tackle this problem, we proposed to distill the knowledge from implicit neural fields (teacher) to explicit 2D Gaussian splatting (student) representation to take advantage of the fast rasterization property of Gaussian splatting. To avoid ray-tracing, we employ the split-sum approximation for PBR appearance. We also propose novel part-wise ambient occlusion probes for shadow computation. Shadow prediction is achieved by querying these probes only once per pixel, which paves the way for real-time relighting of avatars. These techniques combined give high-quality relighting results with realistic shadow effects. Our experiments demonstrate that the proposed student model achieves comparable or even better relighting results with our teacher model while being 370 times faster at inference time, achieving a 67 FPS rendering speed.","authors":["Zeren Jiang","Shaofei Wang","Siyu Tang"],"url":"https://arxiv.org/abs/2504.10486"}
{"created":"2025-04-15","title":"FLOSS: Free Lunch in Open-vocabulary Semantic Segmentation","abstract":"Recent Open-Vocabulary Semantic Segmentation (OVSS) models extend the CLIP model to segmentation while maintaining the use of multiple templates (e.g., a photo of , a sketch of a , etc.) for constructing class-wise averaged text embeddings, acting as a classifier. In this paper, we challenge this status quo and investigate the impact of templates for OVSS. Empirically, we observe that for each class, there exist single-template classifiers significantly outperforming the conventional averaged classifier. We refer to them as class-experts. Given access to unlabeled images and without any training involved, we estimate these experts by leveraging the class-wise prediction entropy of single-template classifiers, selecting as class-wise experts those which yield the lowest entropy. All experts, each specializing in a specific class, collaborate in a newly proposed fusion method to generate more accurate OVSS predictions. Our plug-and-play method, coined FLOSS, is orthogonal and complementary to existing OVSS methods, offering a ''free lunch'' to systematically improve OVSS without labels and additional training. Extensive experiments demonstrate that FLOSS consistently boosts state-of-the-art methods on various OVSS benchmarks. Moreover, the selected expert templates can generalize well from one dataset to others sharing the same semantic categories, yet exhibiting distribution shifts. Additionally, we obtain satisfactory improvements under a low-data regime, where only a few unlabeled images are available. Our code is available at https://github.com/yasserben/FLOSS .","authors":["Yasser Benigmim","Mohammad Fahes","Tuan-Hung Vu","Andrei Bursuc","Raoul de Charette"],"url":"https://arxiv.org/abs/2504.10487"}
{"created":"2025-04-15","title":"Feature Distribution on Graph Topology Mediates the Effect of Graph Convolution: Homophily Perspective","abstract":"How would randomly shuffling feature vectors among nodes from the same class affect graph neural networks (GNNs)? The feature shuffle, intuitively, perturbs the dependence between graph topology and features (A-X dependence) for GNNs to learn from. Surprisingly, we observe a consistent and significant improvement in GNN performance following the feature shuffle. Having overlooked the impact of A-X dependence on GNNs, the prior literature does not provide a satisfactory understanding of the phenomenon. Thus, we raise two research questions. First, how should A-X dependence be measured, while controlling for potential confounds? Second, how does A-X dependence affect GNNs? In response, we (i) propose a principled measure for A-X dependence, (ii) design a random graph model that controls A-X dependence, (iii) establish a theory on how A-X dependence relates to graph convolution, and (iv) present empirical analysis on real-world graphs that align with the theory. We conclude that A-X dependence mediates the effect of graph convolution, such that smaller dependence improves GNN-based node classification.","authors":["Soo Yong Lee","Sunwoo Kim","Fanchen Bu","Jaemin Yoo","Jiliang Tang","Kijung Shin"],"url":"https://arxiv.org/abs/2402.04621"}
{"created":"2025-04-15","title":"Intanify AI Platform: Embedded AI for Automated IP Audit and Due Diligence","abstract":"In this paper we introduce a Platform created in order to support SMEs' endeavor to extract value from their intangible assets effectively. To implement the Platform, we developed five knowledge bases using a knowledge-based ex-pert system shell that contain knowledge from intangible as-set consultants, patent attorneys and due diligence lawyers. In order to operationalize the knowledge bases, we developed a \"Rosetta Stone\", an interpreter unit for the knowledge bases outside the shell and embedded in the plat-form. Building on the initial knowledge bases we have created a system of red flags, risk scoring, and valuation with the involvement of the same experts; these additional systems work upon the initial knowledge bases and therefore they can be regarded as meta-knowledge-representations that take the form of second-order knowledge graphs. All this clever technology is dressed up in an easy-to-handle graphical user interface that we will showcase at the conference. The initial platform was finished mid-2024; therefore, it qualifies as an \"emerging application of AI\" and \"deployable AI\", while development continues. The two firms that provided experts for developing the knowledge bases obtained a white-label version of the product (i.e. it runs under their own brand \"powered by Intanify\"), and there are two completed cases.","authors":["Viktor Dorfler","Dylan Dryden","Viet Lee"],"url":"https://arxiv.org/abs/2503.17374"}
{"created":"2025-04-15","title":"Emergence of psychopathological computations in large language models","abstract":"Can large language models (LLMs) implement computations of psychopathology? An effective approach to the question hinges on addressing two factors. First, for conceptual validity, we require a general and computational account of psychopathology that is applicable to computational entities without biological embodiment or subjective experience. Second, mechanisms underlying LLM behaviors need to be studied for better methodological validity. Thus, we establish a computational-theoretical framework to provide an account of psychopathology applicable to LLMs. To ground the theory for empirical analysis, we also propose a novel mechanistic interpretability method alongside a tailored empirical analytic framework. Based on the frameworks, we conduct experiments demonstrating three key claims: first, that distinct dysfunctional and problematic representational states are implemented in LLMs; second, that their activations can spread and self-sustain to trap LLMs; and third, that dynamic, cyclic structural causal models encoded in the LLMs underpin these patterns. In concert, the empirical results corroborate our hypothesis that network-theoretic computations of psychopathology have already emerged in LLMs. This suggests that certain LLM behaviors mirroring psychopathology may not be a superficial mimicry but a feature of their internal processing. Thus, our work alludes to the possibility of AI systems with psychopathological behaviors in the near future.","authors":["Soo Yong Lee","Hyunjin Hwang","Taekwan Kim","Yuyeong Kim","Kyuri Park","Jaemin Yoo","Denny Borsboom","Kijung Shin"],"url":"https://arxiv.org/abs/2504.08016"}
{"created":"2025-04-15","title":"Towards scientific machine learning for granular material simulations -- challenges and opportunities","abstract":"Micro-scale mechanisms, such as inter-particle and particle-fluid interactions, govern the behaviour of granular systems. While particle-scale simulations provide detailed insights into these interactions, their computational cost is often prohibitive. Attended by researchers from both the granular materials (GM) and machine learning (ML) communities, a recent Lorentz Center Workshop on \"Machine Learning for Discrete Granular Media\" brought the ML community up to date with GM challenges.","authors":["Marc Fransen","Andreas F\\\"urst","Deepak Tunuguntla","Daniel N. Wilke","Benedikt Alkin","Daniel Barreto","Johannes Brandstetter","Miguel Angel Cabrera","Xinyan Fan","Mengwu Guo","Bram Kieskamp","Krishna Kumar","John Morrissey","Jonathan Nuttall","Jin Ooi","Luisa Orozco","Stefanos-Aldo Papanicolopulos","Tongming Qu","Dingena Schott","Takayuki Shuku","WaiChing Sun","Thomas Weinhart","Dongwei Ye","Hongyang Cheng"],"url":"https://arxiv.org/abs/2504.08766"}
{"created":"2025-04-15","title":"High-order expansion of Neural Ordinary Differential Equations flows","abstract":"Artificial neural networks, widely recognised for their role in machine learning, are now transforming the study of ordinary differential equations (ODEs), bridging data-driven modelling with classical dynamical systems and enabling the development of infinitely deep neural models. However, the practical applicability of these models remains constrained by the opacity of their learned dynamics, which operate as black-box systems with limited explainability, thereby hindering trust in their deployment. Existing approaches for the analysis of these dynamical systems are predominantly restricted to first-order gradient information due to computational constraints, thereby limiting the depth of achievable insight. Here, we introduce Event Transition Tensors, a framework based on high-order differentials that provides a rigorous mathematical description of neural ODE dynamics on event manifolds. We demonstrate its versatility across diverse applications: characterising uncertainties in a data-driven prey-predator control model, analysing neural optimal feedback dynamics, and mapping landing trajectories in a three-body neural Hamiltonian system. In all cases, our method enhances the interpretability and rigour of neural ODEs by expressing their behaviour through explicit mathematical structures. Our findings contribute to a deeper theoretical foundation for event-triggered neural differential equations and provide a mathematical construct for explaining complex system dynamics.","authors":["Dario Izzo","Sebastien Origer","Giacomo Acciarini","Francesco Biscani"],"url":"https://arxiv.org/abs/2504.08769"}
{"created":"2025-04-15","title":"Corrosion of metal reinforcements within concrete and localisation of supporting reactions under natural conditions","abstract":"Corrosion in concrete prevents in-situ observation, necessitating models to provide insight into the local reaction currents. We present a computational method for predicting corrosion rates of reinforcements within concrete under natural conditions, i.e. requiring the corrosion current to be supported by equal cathodic currents. In contrast to typical corrosion models, where these two counteracting currents are required to be co-located, we allow these currents to be separated such that pitting corrosion can be supported by cathodic reactions over a much larger area. Pitting corrosion is investigated, elucidating the effects of the concrete porosity and water saturation, the presence of dissolved oxygen, and chlorine concentration within the pore solution. The presented model is capable of capturing the dynamic growth of acidic regions around corrosion pits, showing the limited region over which the hydrogen evolution reaction occurs and how this region evolves over time. The ability of oxygen to diffuse towards the metal surface due to increased porosity is seen to have a major effect on the corrosion rate, whereas changes in the chlorine concentration (and thus changes in the conductivity of the pore solution) play a secondary role. Furthermore, external oxygen is seen to enhance corrosion but is not required to initialise and sustain acidic corrosion pits.","authors":["T. Hageman","C. Andrade","E. Mart\\'inez-Pa\\~neda"],"url":"https://arxiv.org/abs/2504.08794"}
{"created":"2025-04-15","title":"Double Machine Learning for Causal Inference under Shared-State Interference","abstract":"Researchers and practitioners often wish to measure treatment effects in settings where units interact via markets and recommendation systems. In these settings, units are affected by certain shared states, like prices, algorithmic recommendations or social signals. We formalize this structure, calling it shared-state interference, and argue that our formulation captures many relevant applied settings. Our key modeling assumption is that individuals' potential outcomes are independent conditional on the shared state. We then prove an extension of a double machine learning (DML) theorem providing conditions for achieving efficient inference under shared-state interference. We also instantiate our general theorem in several models of interest where it is possible to efficiently estimate the average direct effect (ADE) or global average treatment effect (GATE).","authors":["Chris Hays","Manish Raghavan"],"url":"https://arxiv.org/abs/2504.08836"}
{"created":"2025-04-15","title":"Artificial Intelligence Augmented Medical Imaging Reconstruction in Radiation Therapy","abstract":"Efficiently acquired and precisely reconstructed imaging are crucial to the success of modern radiation therapy (RT). Computed tomography (CT) and magnetic resonance imaging (MRI) are two common modalities for providing RT treatment planning and delivery guidance/monitoring. In recent decades, artificial intelligence (AI) has emerged as a powerful and widely adopted technique across various fields, valued for its efficiency and convenience enabled by implicit function definition and data-driven feature representation learning. Here, we present a series of AI-driven medical imaging reconstruction frameworks for enhanced radiotherapy, designed to improve CT image reconstruction quality and speed, refine dual-energy CT (DECT) multi-material decomposition (MMD), and significantly accelerate 4D MRI acquisition.","authors":["Di Xu"],"url":"https://arxiv.org/abs/2504.08844"}
{"created":"2025-04-15","title":"PolyConf: Unlocking Polymer Conformation Generation through Hierarchical Generative Models","abstract":"Polymer conformation generation is a critical task that enables atomic-level studies of diverse polymer materials. While significant advances have been made in designing various conformation generation methods for small molecules and proteins, these methods struggle to generate polymer conformations due to polymers' unique structural characteristics. The scarcity of polymer conformation datasets further limits progress, making this promising area largely unexplored. In this work, we propose PolyConf, a pioneering tailored polymer conformation generation method that leverages hierarchical generative models to unlock new possibilities for this task. Specifically, we decompose the polymer conformation into a series of local conformations (i.e., the conformations of its repeating units), generating these local conformations through an autoregressive model. We then generate corresponding orientation transformations via a diffusion model to assemble these local conformations into the complete polymer conformation. Moreover, we develop the first benchmark with a high-quality polymer conformation dataset derived from molecular dynamics simulations to boost related research in this area. The comprehensive evaluation demonstrates that PolyConf consistently generates high-quality polymer conformations, facilitating advancements in polymer modeling and simulation.","authors":["Fanmeng Wang","Wentao Guo","Qi Ou","Hongshuai Wang","Haitao Lin","Hongteng Xu","Zhifeng Gao"],"url":"https://arxiv.org/abs/2504.08859"}
{"created":"2025-04-15","title":"DataMap: A Portable Application for Visualizing High-Dimensional Data","abstract":"Motivation: The visualization and analysis of high-dimensional data are essential in biomedical research. There is a need for secure, scalable, and reproducible tools to facilitate data exploration and interpretation. Results: We introduce DataMap, a browser-based application for visualization of high-dimensional data using heatmaps, principal component analysis (PCA), and t-distributed stochastic neighbor embedding (t-SNE). DataMap runs in the web browser, ensuring data privacy while eliminating the need for installation or a server. The application has an intuitive user interface for data transformation, annotation, and generation of reproducible R code. Availability and Implementation: Freely available as a GitHub page https://gexijin.github.io/datamap/. The source code can be found at https://github.com/gexijin/datamap, and can also be installed as an R package. Contact: Xijin.Ge@sdstate.ed","authors":["Xijin Ge"],"url":"https://arxiv.org/abs/2504.08875"}
{"created":"2025-04-15","title":"Is Productivity in Quantum Programming Equivalent to Expressiveness?","abstract":"The expressiveness of quantum programming languages plays a crucial role in the efficient and comprehensible representation of quantum algorithms. Unlike classical programming languages, which offer mature and well-defined abstraction mechanisms, quantum languages must integrate cognitively challenging concepts such as superposition, interference and entanglement while maintaining clarity and usability. However, identifying and characterizing differences in expressiveness between quantum programming paradigms remains an open area of study. Our work investigates the landscape of expressiveness through a comparative analysis of hosted quantum programming languages such as Qiskit, Cirq, Qrisp, and quAPL, and standalone languages including Q# and Qmod. We focused on evaluating how different quantum programming languages support the implementation of core quantum algorithms -- Deutsch-Jozsa, Simon, Bernstein-Vazirani, and Grover -- using expressiveness metrics: Lines of Code (LOC), Cyclomatic Complexity (CC), and Halstead Complexity (HC) metrics as proxies for developer productivity. Our findings suggest that different quantum programming paradigms offer distinct trade-offs between expressiveness and productivity, highlighting the importance of language design in quantum software development.","authors":["Francini Corrales-Garro","Danny Valerio-Ram\\'irez","Santiago N\\'u\\~ez-Corrales"],"url":"https://arxiv.org/abs/2504.08876"}
{"created":"2025-04-15","title":"Improving the evaluation of samplers on multi-modal targets","abstract":"Addressing multi-modality constitutes one of the major challenges of sampling. In this reflection paper, we advocate for a more systematic evaluation of samplers towards two sources of difficulty that are mode separation and dimension. For this, we propose a synthetic experimental setting that we illustrate on a selection of samplers, focusing on the challenging criterion of recovery of the mode relative importance. These evaluations are crucial to diagnose the potential of samplers to handle multi-modality and therefore to drive progress in the field.","authors":["Louis Grenioux","Maxence Noble","Marylou Gabri\\'e"],"url":"https://arxiv.org/abs/2504.08916"}
{"created":"2025-04-15","title":"InterQ: A DQN Framework for Optimal Intermittent Control","abstract":"In this letter, we explore the communication-control co-design of discrete-time stochastic linear systems through reinforcement learning. Specifically, we examine a closed-loop system involving two sequential decision-makers: a scheduler and a controller. The scheduler continuously monitors the system's state but transmits it to the controller intermittently to balance the communication cost and control performance. The controller, in turn, determines the control input based on the intermittently received information. Given the partially nested information structure, we show that the optimal control policy follows a certainty-equivalence form. Subsequently, we analyze the qualitative behavior of the scheduling policy. To develop the optimal scheduling policy, we propose InterQ, a deep reinforcement learning algorithm which uses a deep neural network to approximate the Q-function. Through extensive numerical evaluations, we analyze the scheduling landscape and further compare our approach against two baseline strategies: (a) a multi-period periodic scheduling policy, and (b) an event-triggered policy. The results demonstrate that our proposed method outperforms both baselines. The open source implementation can be found at https://github.com/AC-sh/InterQ.","authors":["Shubham Aggarwal","Dipankar Maity","Tamer Ba\\c{s}ar"],"url":"https://arxiv.org/abs/2504.09035"}
{"created":"2025-04-15","title":"An Incremental Non-Linear Manifold Approximation Method","abstract":"Analyzing high-dimensional data presents challenges due to the \"curse of dimensionality'', making computations intensive. Dimension reduction techniques, categorized as linear or non-linear, simplify such data. Non-linear methods are particularly essential for efficiently visualizing and processing complex data structures in interactive and graphical applications. This research develops an incremental non-linear dimension reduction method using the Geometric Multi-Resolution Analysis (GMRA) framework for streaming data. The proposed method enables real-time data analysis and visualization by incrementally updating the cluster map, PCA basis vectors, and wavelet coefficients. Numerical experiments show that the incremental GMRA accurately represents non-linear manifolds even with small initial samples and aligns closely with batch GMRA, demonstrating efficient updates and maintaining the multiscale structure. The findings highlight the potential of Incremental GMRA for real-time visualization and interactive graphics applications that require adaptive high-dimensional data representations.","authors":["Praveen T. W. Hettige","Benjamin W. Ong"],"url":"https://arxiv.org/abs/2504.09068"}
{"created":"2025-04-15","title":"Parallel Seismic Data Processing Performance with Cloud-based Storage","abstract":"This article introduces a general processing framework to effectively utilize waveform data stored on modern cloud platforms. The focus is hybrid processing schemes where a local system drives processing. We show that downloading files and doing all processing locally is problematic even when the local system is a high-performance compute cluster. Benchmark tests with parallel processing show that approach always creates a bottleneck as the volume of data being handled increases with more processes pulling data. We find a hybrid model where processing to reduce the volume of data transferred from the cloud servers to the local system can dramatically improve processing time. Tests implemented with Massively Parallel Analysis System for Seismology (MsPASS) utilizing Amazon Web Service's Lamba service yield throughput comparable to processing day files on a local HPC file system. Given the ongoing migration of seismology data to cloud storage, our results show doing some or all processing on the cloud will be essential for any processing involving large volumes of data.","authors":["Sasmita Mohapatra","Weiming Yang","Zhengtang Yang","Chenxiao Wang","Jinxin Ma","Gary L. Pavlis","Yinzhi Wang"],"url":"https://arxiv.org/abs/2504.09075"}
{"created":"2025-04-15","title":"SIFT-50M: A Large-Scale Multilingual Dataset for Speech Instruction Fine-Tuning","abstract":"We introduce SIFT (Speech Instruction Fine-Tuning), a 50M-example dataset designed for instruction fine-tuning and pre-training of speech-text large language models (LLMs). SIFT-50M is built from publicly available speech corpora, which collectively contain 14K hours of speech, and leverages LLMs along with off-the-shelf expert models. The dataset spans five languages, encompassing a diverse range of speech understanding as well as controllable speech generation instructions. Using SIFT-50M, we train SIFT-LLM, which outperforms existing speech-text LLMs on instruction-following benchmarks while achieving competitive performance on foundational speech tasks. To support further research, we also introduce EvalSIFT, a benchmark dataset specifically designed to evaluate the instruction-following capabilities of speech-text LLMs.","authors":["Prabhat Pandey","Rupak Vignesh Swaminathan","K V Vijay Girish","Arunasish Sen","Jian Xie","Grant P. Strimel","Andreas Schwarz"],"url":"https://arxiv.org/abs/2504.09081"}
{"created":"2025-04-15","title":"Multi-Modal Brain Tumor Segmentation via 3D Multi-Scale Self-attention and Cross-attention","abstract":"Due to the success of CNN-based and Transformer-based models in various computer vision tasks, recent works study the applicability of CNN-Transformer hybrid architecture models in 3D multi-modality medical segmentation tasks. Introducing Transformer brings long-range dependent information modeling ability in 3D medical images to hybrid models via the self-attention mechanism. However, these models usually employ fixed receptive fields of 3D volumetric features within each self-attention layer, ignoring the multi-scale volumetric lesion features. To address this issue, we propose a CNN-Transformer hybrid 3D medical image segmentation model, named TMA-TransBTS, based on an encoder-decoder structure. TMA-TransBTS realizes simultaneous extraction of multi-scale 3D features and modeling of long-distance dependencies by multi-scale division and aggregation of 3D tokens in a self-attention layer. Furthermore, TMA-TransBTS proposes a 3D multi-scale cross-attention module to establish a link between the encoder and the decoder for extracting rich volume representations by exploiting the mutual attention mechanism of cross-attention and multi-scale aggregation of 3D tokens. Extensive experimental results on three public 3D medical segmentation datasets show that TMA-TransBTS achieves higher averaged segmentation results than previous state-of-the-art CNN-based 3D methods and CNN-Transform hybrid 3D methods for the segmentation of 3D multi-modality brain tumors.","authors":["Yonghao Huang","Leiting Chen","Chuan Zhou"],"url":"https://arxiv.org/abs/2504.09088"}
{"created":"2025-04-15","title":"Dose-finding design based on level set estimation in phase I cancer clinical trials","abstract":"The primary objective of phase I cancer clinical trials is to evaluate the safety of a new experimental treatment and to find the maximum tolerated dose (MTD). We show that the MTD estimation problem can be regarded as a level set estimation (LSE) problem whose objective is to determine the regions where an unknown function value is above or below a given threshold. Then, we propose a novel dose-finding design in the framework of LSE. The proposed design determines the next dose on the basis of an acquisition function incorporating uncertainty in the posterior distribution of the dose-toxicity curve as well as overdose control. Simulation experiments show that the proposed LSE design achieves a higher accuracy in estimating the MTD and involves a lower risk of overdosing allocation compared to existing designs, thereby indicating that it provides an effective methodology for phase I cancer clinical trial design.","authors":["Keiichiro Seno","Kota Matsui","Shogo Iwazaki","Yu Inatsu","Shion Takeno","Shigeyuki Matsui"],"url":"https://arxiv.org/abs/2504.09157"}
{"created":"2025-04-15","title":"Stable Determination and Reconstruction of a Quasilinear Term in an Elliptic Equation","abstract":"In this work, we investigate the inverse problem of determining a quasilinear term appearing in a nonlinear elliptic equation from the measurement of the conormal derivative on the boundary. This problem arises in several practical applications, e.g., heat conduction. We derive novel H\\\"older stability estimates for both multi- and one-dimensional cases: in the multi-dimensional case, the stability estimates are stated with one single boundary measurement, whereas in the one-dimensional case, due to dimensionality limitation, the stability results are stated for the Dirichlet boundary condition varying in a space of dimension one. We derive these estimates using different properties of solution representations. We complement the theoretical results with numerical reconstructions of the quasilinear term, which illustrate the stable recovery of the quasilinear term in the presence of data noise.","authors":["Jason Choy","Maolin Deng","Bangti Jin","Yavar Kian"],"url":"https://arxiv.org/abs/2504.09167"}
{"created":"2025-04-15","title":"seg2med: a segmentation-based medical image generation framework using denoising diffusion probabilistic models","abstract":"In this study, we present seg2med, an advanced medical image synthesis framework that uses Denoising Diffusion Probabilistic Models (DDPM) to generate high-quality synthetic medical images conditioned on anatomical masks from TotalSegmentator. The framework synthesizes CT and MR images from segmentation masks derived from real patient data and XCAT digital phantoms, achieving a Structural Similarity Index Measure (SSIM) of 0.94 +/- 0.02 for CT and 0.89 +/- 0.04 for MR images compared to ground-truth images of real patients. It also achieves a Feature Similarity Index Measure (FSIM) of 0.78 +/- 0.04 for CT images from XCAT. The generative quality is further supported by a Fr\\'echet Inception Distance (FID) of 3.62 for CT image generation.","authors":["Zeyu Yang","Zhilin Chen","Yipeng Sun","Anika Strittmatter","Anish Raj","Ahmad Allababidi","Johann S. Rink","Frank G. Z\\\"ollner"],"url":"https://arxiv.org/abs/2504.09182"}
{"created":"2025-04-15","title":"Adiabatic Encoding of Pre-trained MPS Classifiers into Quantum Circuits","abstract":"Although Quantum Neural Networks (QNNs) offer powerful methods for classification tasks, the training of QNNs faces two major training obstacles: barren plateaus and local minima. A promising solution is to first train a tensor-network (TN) model classically and then embed it into a QNN.\\ However, embedding TN-classifiers into quantum circuits generally requires postselection whose success probability may decay exponentially with the system size. We propose an \\emph{adiabatic encoding} framework that encodes pre-trained MPS-classifiers into quantum MPS (qMPS) circuits with postselection, and gradually removes the postselection while retaining performance. We prove that training qMPS-classifiers from scratch on a certain artificial dataset is exponentially hard due to barren plateaus, but our adiabatic encoding circumvents this issue. Additional numerical experiments on binary MNIST also confirm its robustness.","authors":["Keisuke Murota"],"url":"https://arxiv.org/abs/2504.09250"}
{"created":"2025-04-15","title":"Arnold diffusion in the full three-body problem","abstract":"We show the existence of Arnold diffusion in the planar full three-body problem, which is expressed as a perturbation of a Kepler problem and a planar circular restricted three-body problem, with the perturbation parameter being the mass of the smallest body. In this context, we obtain Arnold diffusion in terms of a transfer of energy, in an amount independent of the perturbation parameter, between the Kepler problem and the restricted three-body problem. Our argument is based on a topological method based on correctly aligned windows which is implemented into a computer assisted proof. This approach can be applied to physically relevant masses of the bodies, such as those in a Neptune-Triton-asteroid system. In this case, we obtain explicit estimates for the range of the perturbation parameter and for the diffusion time.","authors":["Maciej J. Capinski","Marian Gidea"],"url":"https://arxiv.org/abs/2504.09273"}
{"created":"2025-04-15","title":"No-Regret Generative Modeling via Parabolic Monge-Amp\\`ere PDE","abstract":"We introduce a novel generative modeling framework based on a discretized parabolic Monge-Amp\\`ere PDE, which emerges as a continuous limit of the Sinkhorn algorithm commonly used in optimal transport. Our method performs iterative refinement in the space of Brenier maps using a mirror gradient descent step. We establish theoretical guarantees for generative modeling through the lens of no-regret analysis, demonstrating that the iterates converge to the optimal Brenier map under a variety of step-size schedules. As a technical contribution, we derive a new Evolution Variational Inequality tailored to the parabolic Monge-Amp\\`ere PDE, connecting geometry, transportation cost, and regret. Our framework accommodates non-log-concave target distributions, constructs an optimal sampling process via the Brenier map, and integrates favorable learning techniques from generative adversarial networks and score-based diffusion models. As direct applications, we illustrate how our theory paves new pathways for generative modeling and variational inference.","authors":["Nabarun Deb","Tengyuan Liang"],"url":"https://arxiv.org/abs/2504.09279"}
{"created":"2025-04-15","title":"Adaptive Robustness of Hypergrid Johnson-Lindenstrauss","abstract":"Johnson and Lindenstrauss (Contemporary Mathematics, 1984) showed that for $n > m$, a scaled random projection $\\mathbf{A}$ from $\\mathbb{R}^n$ to $\\mathbb{R}^m$ is an approximate isometry on any set $S$ of size at most exponential in $m$. If $S$ is larger, however, its points can contract arbitrarily under $\\mathbf{A}$. In particular, the hypergrid $([-B, B] \\cap \\mathbb{Z})^n$ is expected to contain a point that is contracted by a factor of $\\kappa_{\\mathsf{stat}} = \\Theta(B)^{-1/\\alpha}$, where $\\alpha = m/n$.","authors":["Andrej Bogdanov","Alon Rosen","Neekon Vafa","Vinod Vaikuntanathan"],"url":"https://arxiv.org/abs/2504.09331"}
{"created":"2025-04-15","title":"Building Machine Learning Limited Area Models: Kilometer-Scale Weather Forecasting in Realistic Settings","abstract":"Machine learning is revolutionizing global weather forecasting, with models that efficiently produce highly accurate forecasts. Apart from global forecasting there is also a large value in high-resolution regional weather forecasts, focusing on accurate simulations of the atmosphere for a limited area. Initial attempts have been made to use machine learning for such limited area scenarios, but these experiments do not consider realistic forecasting settings and do not investigate the many design choices involved. We present a framework for building kilometer-scale machine learning limited area models with boundary conditions imposed through a flexible boundary forcing method. This enables boundary conditions defined either from reanalysis or operational forecast data. Our approach employs specialized graph constructions with rectangular and triangular meshes, along with multi-step rollout training strategies to improve temporal consistency. We perform systematic evaluation of different design choices, including the boundary width, graph construction and boundary forcing integration. Models are evaluated across both a Danish and a Swiss domain, two regions that exhibit different orographical characteristics. Verification is performed against both gridded analysis data and in-situ observations, including a case study for the storm Ciara in February 2020. Both models achieve skillful predictions across a wide range of variables, with our Swiss model outperforming the numerical weather prediction baseline for key surface variables. With their substantially lower computational cost, our findings demonstrate great potential for machine learning limited area models in the future of regional weather forecasting.","authors":["Simon Adamov","Joel Oskarsson","Leif Denby","Tomas Landelius","Kasper Hintz","Simon Christiansen","Irene Schicker","Carlos Osuna","Fredrik Lindsten","Oliver Fuhrer","Sebastian Schemm"],"url":"https://arxiv.org/abs/2504.09340"}
{"created":"2025-04-15","title":"Computationally Efficient Signal Detection with Unknown Bandwidths","abstract":"Signal detection in environments with unknown signal bandwidth and time intervals is a basic problem in adversarial and spectrum-sharing scenarios. This paper addresses the problem of detecting signals occupying unknown degrees of freedom from non-coherent power measurements where the signal is constrained to an interval in one dimension or hypercube in multiple dimensions. A Generalized Likelihood Ratio Test (GLRT) is derived, resulting in a straightforward metric involving normalized average signal energy on each candidate signal set. We present bounds on false alarm and missed detection probabilities, demonstrating their dependence on signal-to-noise ratios (SNR) and signal set sizes. To overcome the inherent computational complexity of exhaustive searches, we propose a computationally efficient binary search method, reducing the complexity from O(N2) to O(N) for one-dimensional cases. Simulations indicate that the method maintains performance near exhaustive searches and achieves asymptotic consistency, with interval-of-overlap converging to one under constant SNR as measurement size increases. The simulation studies also demonstrate superior performance and reduced complexity compared to contemporary neural network-based approaches, specifically outperforming custom-trained U-Net models in spectrum detection tasks.","authors":["Ali Rasteh","Sundeep Rangan"],"url":"https://arxiv.org/abs/2504.09342"}
{"created":"2025-04-15","title":"Inferring Outcome Means of Exponential Family Distributions Estimated by Deep Neural Networks","abstract":"Despite the widespread use of deep neural networks (DNNs) for prediction, inference on estimated means for categorical or exponential family outcomes remains underexplored. We address this gap by framing the problem within the generalized linear models (GLMs) framework and developing a rigorous statistical approach for inference on DNN-estimated means. To address a key limitation of assuming independence between prediction errors and input variables in the literature, which often fails in GLMs, we introduce a truncation technique that partitions the problem into regimes with distinct noise behaviors, enabling refined analysis and robust theoretical guarantees under general GLM frameworks. To implement inference, we consider an Ensemble Subsampling Method (ESM) that leverages U-statistics and the Hoeffding decomposition to construct reliable confidence intervals. This method enables model-free variance estimation and accounts for heterogeneity among individuals in the population. Through extensive simulations across Binary, Poisson and Binomial models, we demonstrate the effectiveness and efficiency of our method. We further apply the method to real-world data from the eICU dataset to predict patient readmission risks, providing actionable insights for clinical decision-making.","authors":["Xuran Meng","Yi Li"],"url":"https://arxiv.org/abs/2504.09347"}
{"created":"2025-04-15","title":"Graph-Based Prediction Models for Data Debiasing","abstract":"Bias in data collection, arising from both under-reporting and over-reporting, poses significant challenges in critical applications such as healthcare and public safety. In this work, we introduce Graph-based Over- and Under-reporting Debiasing (GROUD), a novel graph-based optimization framework that debiases reported data by jointly estimating the true incident counts and the associated reporting bias probabilities. By modeling the bias as a smooth signal over a graph constructed from geophysical or feature-based similarities, our convex formulation not only ensures a unique solution but also comes with theoretical recovery guarantees under certain assumptions. We validate GROUD on both challenging simulated experiments and real-world datasets -- including Atlanta emergency calls and COVID-19 vaccine adverse event reports -- demonstrating its robustness and superior performance in accurately recovering debiased counts. This approach paves the way for more reliable downstream decision-making in systems affected by reporting irregularities.","authors":["Dongze Wu","Hanyang Jiang","Yao Xie"],"url":"https://arxiv.org/abs/2504.09348"}
{"created":"2025-04-15","title":"DiTSE: High-Fidelity Generative Speech Enhancement via Latent Diffusion Transformers","abstract":"Real-world speech recordings suffer from degradations such as background noise and reverberation. Speech enhancement aims to mitigate these issues by generating clean high-fidelity signals. While recent generative approaches for speech enhancement have shown promising results, they still face two major challenges: (1) content hallucination, where plausible phonemes generated differ from the original utterance; and (2) inconsistency, failing to preserve speaker's identity and paralinguistic features from the input speech. In this work, we introduce DiTSE (Diffusion Transformer for Speech Enhancement), which addresses quality issues of degraded speech in full bandwidth. Our approach employs a latent diffusion transformer model together with robust conditioning features, effectively addressing these challenges while remaining computationally efficient. Experimental results from both subjective and objective evaluations demonstrate that DiTSE achieves state-of-the-art audio quality that, for the first time, matches real studio-quality audio from the DAPS dataset. Furthermore, DiTSE significantly improves the preservation of speaker identity and content fidelity, reducing hallucinations across datasets compared to state-of-the-art enhancers. Audio samples are available at: http://hguimaraes.me/DiTSE","authors":["Heitor R. Guimar\\~aes","Jiaqi Su","Rithesh Kumar","Tiago H. Falk","Zeyu Jin"],"url":"https://arxiv.org/abs/2504.09381"}
{"created":"2025-04-15","title":"Survival of the Optimized: An Evolutionary Approach to T-depth Reduction","abstract":"Quantum Error Correction (QEC) is essential for realizing practical Fault-Tolerant Quantum Computing (FTQC) but comes with substantial resource overhead. Quantum circuits must be compiled into the Clifford+T gate set, where the non-transversal nature of the T-gates necessitates costly magic distillation. As circuit complexity grows, so does the T-depth: the sequential T-gate layers, due to the decomposition of arbitrary rotations, further increasing the QEC demands. Optimizing T-depth poses two key challenges: it is NP-hard and existing solutions like greedy or brute-force algorithms are either suboptimal or computationally expensive. We address this by framing the problem as a search task and propose a Genetic Algorithm (GA)-based approach to discover near-optimal T-gate merge patterns across circuit layers. To improve upon convergence and solution quality, we incorporate a mathematical expansion scheme that facilitates reordering layers to identify better merge opportunities, along with a greedy initialization strategy based on T-gate density. Our method achieves up to 79.23% T-depth reduction and 41.86% T-count reduction in large circuits (90-100 qubits). Compared to state-of-the-art methods like the lookahead-based approach, our framework yields an average improvement of 1.2x across varying circuit sizes and T-gate densities. Our approach is hardware-agnostic making it compatible with diverse QEC architectures such as surface codes and QLDPCs, resulting in a scalable and practical optimization framework for near-term fault-tolerant quantum computing.","authors":["Archisman Ghosh","Avimita Chatterjee","Swaroop Ghosh"],"url":"https://arxiv.org/abs/2504.09391"}
{"created":"2025-04-15","title":"Bregman Linearized Augmented Lagrangian Method for Nonconvex Constrained Stochastic Zeroth-order Optimization","abstract":"In this paper, we study nonconvex constrained stochastic zeroth-order optimization problems, for which we have access to exact information of constraints and noisy function values of the objective. We propose a Bregman linearized augmented Lagrangian method that utilizes stochastic zeroth-order gradient estimators combined with a variance reduction technique. We analyze its oracle complexity, in terms of the total number of stochastic function value evaluations required to achieve an \\(\\epsilon\\)-KKT point in \\(\\ell_p\\)-norm metrics with \\(p \\ge 2\\), where \\(p\\) is a parameter associated with the selected Bregman distance. In particular, starting from a near-feasible initial point and using Rademacher smoothing, the oracle complexity is in order \\(O(p d^{2/p} \\epsilon^{-3})\\) for \\(p \\in [2, 2 \\ln d]\\), and \\(O(\\ln d \\cdot \\epsilon^{-3})\\) for \\(p > 2 \\ln d\\), where \\(d\\) denotes the problem dimension. Those results show that the complexity of the proposed method can achieve a dimensional dependency lower than \\(O(d)\\) without requiring additional assumptions, provided that a Bregman distance is chosen properly. This offers a significant improvement in the high-dimensional setting over existing work, and matches the lowest complexity order with respect to the tolerance \\(\\epsilon\\) reported in the literature. Numerical experiments on constrained Lasso and black-box adversarial attack problems highlight the promising performances of the proposed method.","authors":["Qiankun Shi","Xiao Wang","Hao Wang"],"url":"https://arxiv.org/abs/2504.09409"}
{"created":"2025-04-15","title":"Predicting ulcer in H&E images of inflammatory bowel disease using domain-knowledge-driven graph neural network","abstract":"Inflammatory bowel disease (IBD) involves chronic inflammation of the digestive tract, with treatment options often burdened by adverse effects. Identifying biomarkers for personalized treatment is crucial. While immune cells play a key role in IBD, accurately identifying ulcer regions in whole slide images (WSIs) is essential for characterizing these cells and exploring potential therapeutics. Multiple instance learning (MIL) approaches have advanced WSI analysis but they lack spatial context awareness. In this work, we propose a weakly-supervised model called DomainGCN that employs a graph convolution neural network (GCN) and incorporates domain-specific knowledge of ulcer features, specifically, the presence of epithelium, lymphocytes, and debris for WSI-level ulcer prediction in IBD. We demonstrate that DomainGCN outperforms various state-of-the-art (SOTA) MIL methods and show the added value of domain knowledge.","authors":["Ruiwen Ding","Lin Li","Rajath Soans","Tosha Shah","Radha Krishnan","Marc Alexander Sze","Sasha Lukyanov","Yash Deshpande","Antong Chen"],"url":"https://arxiv.org/abs/2504.09430"}
{"created":"2025-04-15","title":"Optimal sparse phase retrieval via a quasi-Bayesian approach","abstract":"This paper addresses the problem of sparse phase retrieval, a fundamental inverse problem in applied mathematics, physics, and engineering, where a signal need to be reconstructed using only the magnitude of its transformation while phase information remains inaccessible. Leveraging the inherent sparsity of many real-world signals, we introduce a novel sparse quasi-Bayesian approach and provide the first theoretical guarantees for such an approach. Specifically, we employ a scaled Student distribution as a continuous shrinkage prior to enforce sparsity and analyze the method using the PAC-Bayesian inequality framework. Our results establish that the proposed Bayesian estimator achieves minimax-optimal convergence rates under sub-exponential noise, matching those of state-of-the-art frequentist methods. To ensure computational feasibility, we develop an efficient Langevin Monte Carlo sampling algorithm. Through numerical experiments, we demonstrate that our method performs comparably to existing frequentist techniques, highlighting its potential as a principled alternative for sparse phase retrieval in noisy settings.","authors":["The Tien Mai"],"url":"https://arxiv.org/abs/2504.09509"}
{"created":"2025-04-15","title":"Hofmann-Streicher lifting of fibred categories","abstract":"In 1997, Hofmann and Streicher introduced an explicit construction to lift a Grothendieck universe $\\mathcal{U}$ from $\\mathbf{Set}$ into the category of $\\mathbf{Set}$-valued presheaves on a $\\mathcal{U}$-small category $B$. More recently, Awodey presented an elegant functorial analysis of this construction in terms of the categorical nerve, the right adjoint to the functor that takes a presheaf to its category of elements; in particular, the categorical nerve's functorial action on the universal $\\mathcal{U}$-small discrete fibration gives the generic family of $\\mathcal{U}$'s Hofmann-Streicher lifting. Inspired by Awodey's analysis, we define a relative version of Hofmann-Streicher lifting in terms of the right pseudo-adjoint to the 2-functor $\\mathbf{Fib}_{A}\\to\\mathbf{Fib}_{B}$ given by postcomposition with a fibration $p\\colon A\\to B$.","authors":["Andrew Slattery","Jonathan Sterling"],"url":"https://arxiv.org/abs/2504.09520"}
{"created":"2025-04-15","title":"A simulation-heuristics dual-process model for intuitive physics","abstract":"The role of mental simulation in human physical reasoning is widely acknowledged, but whether it is employed across scenarios with varying simulation costs and where its boundary lies remains unclear. Using a pouring-marble task, our human study revealed two distinct error patterns when predicting pouring angles, differentiated by simulation time. While mental simulation accurately captured human judgments in simpler scenarios, a linear heuristic model better matched human predictions when simulation time exceeded a certain boundary. Motivated by these observations, we propose a dual-process framework, Simulation-Heuristics Model (SHM), where intuitive physics employs simulation for short-time simulation but switches to heuristics when simulation becomes costly. By integrating computational methods previously viewed as separate into a unified model, SHM quantitatively captures their switching mechanism. The SHM aligns more precisely with human behavior and demonstrates consistent predictive performance across diverse scenarios, advancing our understanding of the adaptive nature of intuitive physical reasoning.","authors":["Shiqian Li","Yuxi Ma","Jiajun Yan","Bo Dai","Yujia Peng","Chi Zhang","Yixin Zhu"],"url":"https://arxiv.org/abs/2504.09546"}
{"created":"2025-04-15","title":"Conditional Independence Test Based on Transport Maps","abstract":"Testing conditional independence between two random vectors given a third is a fundamental and challenging problem in statistics, particularly in multivariate nonparametric settings due to the complexity of conditional structures. We propose a novel framework for testing conditional independence using transport maps. At the population level, we show that two well-defined transport maps can transform the conditional independence test into an unconditional independence test, this substantially simplifies the problem. These transport maps are estimated from data using conditional continuous normalizing flow models. Within this framework, we derive a test statistic and prove its consistency under both the null and alternative hypotheses. A permutation-based procedure is employed to evaluate the significance of the test. We validate the proposed method through extensive simulations and real-data analysis. Our numerical studies demonstrate the practical effectiveness of the proposed method for conditional independence testing.","authors":["Chenxuan He","Yuan Gao","Liping Zhu","Jian Huang"],"url":"https://arxiv.org/abs/2504.09567"}
{"created":"2025-04-15","title":"Knowledge Independence Breeds Disruption but Limits Recognition","abstract":"Recombinant growth theory highlights the pivotal role of cumulative knowledge in driving innovation. Although interconnected knowledge facilitates smoother dissemination, its connection to scientific disruption remains poorly understood. Here, we quantify knowledge dependence based on the degree to which references within a given paper's bibliography cite one another. Analyzing 53.8 million papers spanning six decades, we observe that papers built on independent knowledge have decreased over time. However, propensity score matching and regression analyses reveal that such papers are associated with greater scientific disruption, as those who cite them are less likely to cite their references. Moreover, a team's preference for independent knowledge amplifies its disruptive potential, regardless of team size, geographic distance, or collaboration freshness. Despite the disruptive nature, papers built on independent knowledge receive fewer citations and delayed recognition. Taken together, these findings fill a critical gap in our fundamental understanding of scientific innovation, revealing a universal law in peer recognition: Knowledge independence breeds disruption at the cost of impact.","authors":["Xiaoyao Yu","Talal Rahwan","Tao Jia"],"url":"https://arxiv.org/abs/2504.09589"}
{"created":"2025-04-15","title":"Fine-tuning an Large Language Model for Automating Computational Fluid Dynamics Simulations","abstract":"Configuring computational fluid dynamics (CFD) simulations typically demands extensive domain expertise, limiting broader access. Although large language models (LLMs) have advanced scientific computing, their use in automating CFD workflows is underdeveloped. We introduce a novel approach centered on domain-specific LLM adaptation. By fine-tuning Qwen2.5-7B-Instruct on NL2FOAM, our custom dataset of 28716 natural language-to-OpenFOAM configuration pairs with chain-of-thought (CoT) annotations, we enable direct translation from natural language descriptions to executable CFD setups. A multi-agent framework orchestrates the process, autonomously verifying inputs, generating configurations, running simulations, and correcting errors. Evaluation on a benchmark of 21 diverse flow cases demonstrates state-of-the-art performance, achieving 88.7% solution accuracy and 82.6% first-attempt success rate. This significantly outperforms larger general-purpose models like Qwen2.5-72B-Instruct, DeepSeek-R1, and Llama3.3-70B-Instruct, while also requiring fewer correction iterations and maintaining high computational efficiency. The results highlight the critical role of domain-specific adaptation in deploying LLM assistants for complex engineering workflows.","authors":["Zhehao Dong","Zhen Lu","Yue Yang"],"url":"https://arxiv.org/abs/2504.09602"}
{"created":"2025-04-15","title":"Data-Driven Two-Stage Distributionally Robust Dispatch of Multi-Energy Microgrid","abstract":"This paper studies adaptive distributionally robust dispatch (DRD) of the multi-energy microgrid under supply and demand uncertainties. A Wasserstein ambiguity set is constructed to support data-driven decision-making. By fully leveraging the special structure of worst-case expectation from the primal perspective, a novel and high-efficient decomposition algorithm under the framework of column-and-constraint generation is customized and developed to address the computational burden. Numerical studies demonstrate the effectiveness of our DRD approach, and shed light on the interrelationship of it with the traditional dispatch approaches through stochastic programming and robust optimization schemes. Also, comparisons with popular algorithms in the literature for two-stage distributionally robust optimization verify the powerful capacity of our algorithm in computing the DRD problem.","authors":["Xunhang Sun","Xiaoyu Cao","Bo Zeng","Miaomiao Li","Xiaohong Guan","Tamer Ba\\c{s}ar"],"url":"https://arxiv.org/abs/2504.09638"}
{"created":"2025-04-15","title":"OmniMamba4D: Spatio-temporal Mamba for longitudinal CT lesion segmentation","abstract":"Accurate segmentation of longitudinal CT scans is important for monitoring tumor progression and evaluating treatment responses. However, existing 3D segmentation models solely focus on spatial information. To address this gap, we propose OmniMamba4D, a novel segmentation model designed for 4D medical images (3D images over time). OmniMamba4D utilizes a spatio-temporal tetra-orientated Mamba block to effectively capture both spatial and temporal features. Unlike traditional 3D models, which analyze single-time points, OmniMamba4D processes 4D CT data, providing comprehensive spatio-temporal information on lesion progression. Evaluated on an internal dataset comprising of 3,252 CT scans, OmniMamba4D achieves a competitive Dice score of 0.682, comparable to state-of-the-arts (SOTA) models, while maintaining computational efficiency and better detecting disappeared lesions. This work demonstrates a new framework to leverage spatio-temporal information for longitudinal CT lesion segmentation.","authors":["Justin Namuk Kim","Yiqiao Liu","Rajath Soans","Keith Persson","Sarah Halek","Michal Tomaszewski","Jianda Yuan","Gregory Goldmacher","Antong Chen"],"url":"https://arxiv.org/abs/2504.09655"}
{"created":"2025-04-15","title":"Preconditioned Gradient Descent for Over-Parameterized Nonconvex Matrix Factorization","abstract":"In practical instances of nonconvex matrix factorization, the rank of the true solution $r^{\\star}$ is often unknown, so the rank $r$ of the model can be overspecified as $r>r^{\\star}$. This over-parameterized regime of matrix factorization significantly slows down the convergence of local search algorithms, from a linear rate with $r=r^{\\star}$ to a sublinear rate when $r>r^{\\star}$. We propose an inexpensive preconditioner for the matrix sensing variant of nonconvex matrix factorization that restores the convergence rate of gradient descent back to linear, even in the over-parameterized case, while also making it agnostic to possible ill-conditioning in the ground truth. Classical gradient descent in a neighborhood of the solution slows down due to the need for the model matrix factor to become singular. Our key result is that this singularity can be corrected by $\\ell_{2}$ regularization with a specific range of values for the damping parameter. In fact, a good damping parameter can be inexpensively estimated from the current iterate. The resulting algorithm, which we call preconditioned gradient descent or PrecGD, is stable under noise, and converges linearly to an information theoretically optimal error bound. Our numerical experiments find that PrecGD works equally well in restoring the linear convergence of other variants of nonconvex matrix factorization in the over-parameterized regime.","authors":["Gavin Zhang","Salar Fattahi","Richard Y. Zhang"],"url":"https://arxiv.org/abs/2504.09708"}
{"created":"2025-04-15","title":"Level-set topology optimisation with unfitted finite elements and automatic shape differentiation","abstract":"In this paper we develop automatic shape differentiation techniques for unfitted discretisations and link these to recent advances in shape calculus for unfitted methods. We extend existing analytic shape calculus results to the case where the domain boundary intersects with the boundary of the background domain. We further show that we can recover these analytic derivatives to machine precision regardless of the mesh size using the developed automatic shape differentiation techniques. In addition, we show that we can also recover the symmetric shape Hessian. We implement these techniques for both serial and distributed computing frameworks in the Julia package GridapTopOpt and the wider Gridap ecosystem. As part of this implementation we propose a novel graph-based approach for isolated volume detection. We demonstrate the applicability of the unfitted automatic shape differentiation framework and our implementation by considering the three-dimensional minimum compliance topology optimisation of a linear elastic wheel and of a linear elastic structure in a fluid-structure interaction problem with Stokes flow. The implementation is general and allows GridapTopOpt to solve a wide range of problems without analytic calculation of shape derivatives and avoiding issues that arise when material properties are smoothed at the domain boundary. The software is open source and available at https://github.com/zjwegert/GridapTopOpt.jl.","authors":["Zachary J. Wegert","Jordi Manyer","Connor Mallon","Santiago Badia","Vivien J. Challis"],"url":"https://arxiv.org/abs/2504.09748"}
{"created":"2025-04-15","title":"A SageMath Package for Analytic Combinatorics in Several Variables: Beyond the Smooth Case","abstract":"The field of analytic combinatorics in several variables (ACSV) develops techniques to compute the asymptotic behaviour of multivariate sequences from analytic properties of their generating functions. When the generating function under consideration is rational, its set of singularities forms an algebraic variety -- called the singular variety -- and asymptotic behaviour depends heavily on the geometry of the singular variety. By combining a recent algorithm for the Whitney stratification of algebraic varieties with methods from ACSV, we present the first software that rigorously computes asymptotics of sequences whose generating functions have non-smooth singular varieties (under other assumptions on local geometry). Our work is built on the existing sage_acsv package for the SageMath computer algebra system, which previously gave asymptotics under a smoothness assumption. We also report on other improvements to the package, such as an efficient technique for determining higher order asymptotic expansions using Newton iteration, the ability to use more efficient backends for algebraic computations, and a method to compute so-called critical points for any multivariate rational function through Whitney stratification.","authors":["Benjamin Hackl","Andrew Luo","Stephen Melczer","\\'Eric Schost"],"url":"https://arxiv.org/abs/2504.09790"}
{"created":"2025-04-15","title":"Virtual domain extension for imposing boundary conditions in flow simulation using pre-trained local neural operator","abstract":"This paper builds up a virtual domain extension (VDE) framework for imposing boundary conditions (BCs) in flow simulation using pre-trained local neural operator (LNO). It creates extended virtual domains to the input function to compensate for the corrosion nature of computational domains during LNO inference, thus turns the implementation of BC into the determination of field values on the extended domain. Several strategies to calculate the field values are proposed and validated in solving numerical examples, including padding operation, direct imposition, pressure symmetry, and optimization by backpropagation, and compared with boundary imposition in traditional solvers. It is found that the large time interval of LNO induces a relatively wide near-boundary domain to be processed, thus imposing BC on only a few nodes near the boundary following the immersed boundary conception in traditional solvers can hardly achieve high accuracy. With appropriate values assigned on the extended virtual domains, VDE can accurately impose BCs and lead to reasonable flow field predictions. This work provides a guidance for imposing BCs reliably in LNO prediction, which could facilitate the reuse of pre-trained LNO in more applications.","authors":["Ximeng Ye","Hongyu Li","Zhen-Guo Yan"],"url":"https://arxiv.org/abs/2504.09807"}
{"created":"2025-04-15","title":"Finite-Precision Conjugate Gradient Method for Massive MIMO Detection","abstract":"The implementation of the conjugate gradient (CG) method for massive MIMO detection is computationally challenging, especially for a large number of users and correlated channels. In this paper, we propose a low computational complexity CG detection from a finite-precision perspective. First, we develop a finite-precision CG (FP-CG) detection to mitigate the computational bottleneck of each CG iteration and provide the attainable accuracy, convergence, and computational complexity analysis to reveal the impact of finite-precision arithmetic. A practical heuristic is presented to select suitable precisions. Then, to further reduce the number of iterations, we propose a joint finite-precision and block-Jacobi preconditioned CG (FP-BJ-CG) detection. The corresponding performance analysis is also provided. Finally, simulation results validate the theoretical insights and demonstrate the superiority of the proposed detection.","authors":["Yiming Fang","Li Chen","Changsheng You","Dingzhu Wen","Pengcheng Zhu"],"url":"https://arxiv.org/abs/2504.09820"}
{"created":"2025-04-15","title":"Offline Dynamic Inventory and Pricing Strategy: Addressing Censored and Dependent Demand","abstract":"In this paper, we study the offline sequential feature-based pricing and inventory control problem where the current demand depends on the past demand levels and any demand exceeding the available inventory is lost. Our goal is to leverage the offline dataset, consisting of past prices, ordering quantities, inventory levels, covariates, and censored sales levels, to estimate the optimal pricing and inventory control policy that maximizes long-term profit. While the underlying dynamic without censoring can be modeled by Markov decision process (MDP), the primary obstacle arises from the observed process where demand censoring is present, resulting in missing profit information, the failure of the Markov property, and a non-stationary optimal policy. To overcome these challenges, we first approximate the optimal policy by solving a high-order MDP characterized by the number of consecutive censoring instances, which ultimately boils down to solving a specialized Bellman equation tailored for this problem. Inspired by offline reinforcement learning and survival analysis, we propose two novel data-driven algorithms to solving these Bellman equations and, thus, estimate the optimal policy. Furthermore, we establish finite sample regret bounds to validate the effectiveness of these algorithms. Finally, we conduct numerical experiments to demonstrate the efficacy of our algorithms in estimating the optimal policy. To the best of our knowledge, this is the first data-driven approach to learning optimal pricing and inventory control policies in a sequential decision-making environment characterized by censored and dependent demand. The implementations of the proposed algorithms are available at https://github.com/gundemkorel/Inventory_Pricing_Control","authors":["Korel Gundem","Zhengling Qi"],"url":"https://arxiv.org/abs/2504.09831"}
{"created":"2025-04-15","title":"Score Matching Diffusion Based Feedback Control and Planning of Nonlinear Systems","abstract":"We propose a novel control-theoretic framework that leverages principles from generative modeling -- specifically, Denoising Diffusion Probabilistic Models (DDPMs) -- to stabilize control-affine systems with nonholonomic constraints. Unlike traditional stochastic approaches, which rely on noise-driven dynamics in both forward and reverse processes, our method crucially eliminates the need for noise in the reverse phase, making it particularly relevant for control applications. We introduce two formulations: one where noise perturbs all state dimensions during the forward phase while the control system enforces time reversal deterministically, and another where noise is restricted to the control channels, embedding system constraints directly into the forward process.","authors":["Karthik Elamvazhuthi","Darshan Gadginmath","Fabio Pasqualetti"],"url":"https://arxiv.org/abs/2504.09836"}
{"created":"2025-04-15","title":"Modelling & Steady State Compliance Testing of an Improved Time Synchronized Phasor Measurement Unit Based on IEEE Standard C37.118.1","abstract":"Synchrophasor technology is an emerging and developing technology for monitoring and control of wide area measurement systems (WAMS). In an elementary WAMS, two identical phasors measured at two different locations have difference in the phase angles measured since their reference waveforms are not synchronized with each other. Phasor measurement units (PMUs) measure input phasors with respect to a common reference wave based on the atomic clock pulses received from global positioning system (GPS) satellites, eliminating variation in the measured phase angles due to distant locations of the measurement nodes. This has found tremendous applications in quick fault detection, fault location analysis, accurate current, voltage, frequency and phase angle measurements in WAMS. Commercially available PMU models are often proven to be expensive for research and development as well as for grid integration projects. This research article proposes an economic PMU model optimized for accurate steadystate performance based on recursive discrete Fourier transform (DFT) and provides results and detailed analysis of the proposed PMU model as per the steady state compliance specifications of IEEE standard C37.118.1. Results accurate up to 13 digits after decimal point are obtained through the developed PMU model for both nominal and off-nominal frequency inputs in steady state.","authors":["Nisarg Trivedi"],"url":"https://arxiv.org/abs/2504.09883"}
{"created":"2025-04-15","title":"A posteriori estimates for problems with monotone operators","abstract":"We propose a method of obtaining a posteriori estimates which does not use the duality theory and which applies to variational inequalities with monotone operators, without assuming the potentiality of operators. The effectiveness of the method is demonstrated on problems driven by nonlinear operators of the $p$-Laplacian type, including the anisotropic $p$-Laplacian, polyharmonic $p$-Laplacian, and fractional $p$-Laplacian.","authors":["Vladimir Bobkov","Svetlana Pastukhova"],"url":"https://arxiv.org/abs/2504.09931"}
{"created":"2025-04-15","title":"On the $N$th $2$-adic complexity of binary sequences identified with algebraic $2$-adic integers","abstract":"We identify a binary sequence $\\mathcal{S}=(s_n)_{n=0}^\\infty$ with the $2$-adic integer $G_\\mathcal{S}(2)=\\sum\\limits_{n=0}^\\infty s_n2^n$. In the case that $G_\\mathcal{S}(2)$ is algebraic over $\\mathbb{Q}$ of degree $d\\ge 2$, we prove that the $N$th $2$-adic complexity of $\\mathcal{S}$ is at least $\\frac{N}{d}+O(1)$, where the implied constant depends only on the minimal polynomial of $G_\\mathcal{S}(2)$. This result is an analog of the bound of M\\'erai and the second author on the linear complexity of automatic sequences, that is, sequences with algebraic $G_\\mathcal{S}(X)$ over the rational function field $\\mathbb{F}_2(X)$. We further discuss the most important case $d=2$ in both settings and explain that the intersection of the set of $2$-adic algebraic sequences and the set of automatic sequences is the set of (eventually) periodic sequences. Finally, we provide some experimental results supporting the conjecture that $2$-adic algebraic sequences can have also a desirable $N$th linear complexity and automatic sequences a desirable $N$th $2$-adic complexity, respectively.","authors":["Zhixiong Chen","Arne Winterhof"],"url":"https://arxiv.org/abs/2504.09933"}
{"created":"2025-04-15","title":"Fully-Adaptive and Semi-Adaptive Frequency Sweep Algorithm Exploiting Loewner-State Model for EM Simulation of Multiport Systems","abstract":"This paper employs a fully adaptive and semi-adaptive frequency sweep algorithm using the Loewner matrix-based state model for the electromagnetic simulation. The proposed algorithms use two Loewner matrix models with different or the same orders with small frequency perturbation for adaptive frequency selection. The error between the two models is calculated in each iteration, and the next frequency points are selected to minimize maximum error. With the help of memory, the algorithm terminates when the error between the model and the simulation result is reached within the specified error tolerance. In the fully adaptive frequency sweep algorithm, the method starts with the minimum and maximum frequency of simulation. In the semi-adaptive algorithm, a novel approach has been proposed to determine the initial number of frequency points necessary for system interpolation based on the electrical size of the structure. The proposed algorithms have been compared with the Stoer-Bulirsch algorithm and Pradovera's minimal sampling algorithm for electromagnetic simulation. Four examples are presented using MATLAB R2024b. The results show that the proposed methods offer better performance in terms of speed, accuracy and the requirement of the minimum number of frequency samples. The proposed method shows remarkable consistency with full-wave simulation data, and the algorithm can be effectively applicable to electromagnetic simulations.","authors":["Shilpa T. N.","Rakesh Sinha"],"url":"https://arxiv.org/abs/2504.09942"}
{"created":"2025-04-15","title":"Towards Weaker Variance Assumptions for Stochastic Optimization","abstract":"We revisit a classical assumption for analyzing stochastic gradient algorithms where the squared norm of the stochastic subgradient (or the variance for smooth problems) is allowed to grow as fast as the squared norm of the optimization variable. We contextualize this assumption in view of its inception in the 1960s, its seemingly independent appearance in the recent literature, its relationship to weakest-known variance assumptions for analyzing stochastic gradient algorithms, and its relevance in deterministic problems for non-Lipschitz nonsmooth convex optimization. We build on and extend a connection recently made between this assumption and the Halpern iteration. For convex nonsmooth, and potentially stochastic, optimization, we analyze horizon-free, anytime algorithms with last-iterate rates. For problems beyond simple constrained optimization, such as convex problems with functional constraints or regularized convex-concave min-max problems, we obtain rates for optimality measures that do not require boundedness of the feasible set.","authors":["Ahmet Alacaoglu","Yura Malitsky","Stephen J. Wright"],"url":"https://arxiv.org/abs/2504.09951"}
{"created":"2025-04-15","title":"Towards Resilient Tracking in Autonomous Vehicles: A Distributionally Robust Input and State Estimation Approach","abstract":"This paper proposes a novel framework for the distributionally robust input and state estimation (DRISE) for autonomous vehicles operating under model uncertainties and measurement outliers. The proposed framework improves the input and state estimation (ISE) approach by integrating distributional robustness, enhancing the estimator's resilience and robustness to adversarial inputs and unmodeled dynamics. Moment-based ambiguity sets capture probabilistic uncertainties in both system dynamics and measurement noise, offering analytical tractability and efficiently handling uncertainties in mean and covariance. In particular, the proposed framework minimizes the worst-case estimation error, ensuring robustness against deviations from nominal distributions. The effectiveness of the proposed approach is validated through simulations conducted in the CARLA autonomous driving simulator, demonstrating improved performance in state estimation accuracy and robustness in dynamic and uncertain environments.","authors":["Kasra Azizi","Kumar Anurag","Wenbin Wan"],"url":"https://arxiv.org/abs/2504.09974"}
{"created":"2025-04-15","title":"Physical Scales Matter: The Role of Receptive Fields and Advection in Satellite-Based Thunderstorm Nowcasting with Convolutional Neural Networks","abstract":"The focus of nowcasting development is transitioning from physically motivated advection methods to purely data-driven Machine Learning (ML) approaches. Nevertheless, recent work indicates that incorporating advection into the ML value chain has improved skill for radar-based precipitation nowcasts. However, the generality of this approach and the underlying causes remain unexplored. This study investigates the generality by probing the approach on satellite-based thunderstorm nowcasts for the first time. Resorting to a scale argument, we then put forth an explanation when and why skill improvements can be expected. In essence, advection guarantees that thunderstorm patterns relevant for nowcasting are contained in the receptive field at long lead times. To test our hypotheses, we train ResU-Nets solving segmentation tasks with lightning observations as ground truth. The input of the Baseline Neural Network (BNN) are short time series of multispectral satellite imagery and lightning observations, whereas the Advection-Informed Neural Network (AINN) additionally receives the Lagrangian persistence nowcast of all input channels at the desired lead time. Overall, we find only a minor skill improvement of the AINN over the BNN when considering fully averaged scores. However, assessing skill conditioned on lead time and wind speed, we demonstrate that our scale argument correctly predicts the onset of skill improvement of the AINN over the BNN after 2h lead time. We confirm that generally advection becomes gradually more important with longer lead times and higher wind speeds. Our work accentuates the importance of considering and incorporating the underlying physical scales when designing ML based forecasting models.","authors":["Christoph Metzl","Kianusch Vahid Yousefnia","Richard M\\\"uller","Virginia Poli","Miria Celano","Tobias B\\\"olle"],"url":"https://arxiv.org/abs/2504.09994"}
{"created":"2025-04-15","title":"Progressive Transfer Learning for Multi-Pass Fundus Image Restoration","abstract":"Diabetic retinopathy is a leading cause of vision impairment, making its early diagnosis through fundus imaging critical for effective treatment planning. However, the presence of poor quality fundus images caused by factors such as inadequate illumination, noise, blurring and other motion artifacts yields a significant challenge for accurate DR screening. In this study, we propose progressive transfer learning for multi pass restoration to iteratively enhance the quality of degraded fundus images, ensuring more reliable DR screening. Unlike previous methods that often focus on a single pass restoration, multi pass restoration via PTL can achieve a superior blind restoration performance that can even improve most of the good quality fundus images in the dataset. Initially, a Cycle GAN model is trained to restore low quality images, followed by PTL induced restoration passes over the latest restored outputs to improve overall quality in each pass. The proposed method can learn blind restoration without requiring any paired data while surpassing its limitations by leveraging progressive learning and fine tuning strategies to minimize distortions and preserve critical retinal features. To evaluate PTL's effectiveness on multi pass restoration, we conducted experiments on DeepDRiD, a large scale fundus imaging dataset specifically curated for diabetic retinopathy detection. Our result demonstrates state of the art performance, showcasing PTL's potential as a superior approach to iterative image quality restoration.","authors":["Uyen Phan","Ozer Can Devecioglu","Serkan Kiranyaz","Moncef Gabbouj"],"url":"https://arxiv.org/abs/2504.10025"}
{"created":"2025-04-15","title":"Sequence models for by-trial decoding of cognitive strategies from neural data","abstract":"Understanding the sequence of cognitive operations that underlie decision-making is a fundamental challenge in cognitive neuroscience. Traditional approaches often rely on group-level statistics, which obscure trial-by-trial variations in cognitive strategies. In this study, we introduce a novel machine learning method that combines Hidden Multivariate Pattern analysis with a Structured State Space Sequence model to decode cognitive strategies from electroencephalography data at the trial level. We apply this method to a decision-making task, where participants were instructed to prioritize either speed or accuracy in their responses. Our results reveal an additional cognitive operation, labeled Confirmation, which seems to occur predominantly in the accuracy condition but also frequently in the speed condition. The modeled probability that this operation occurs is associated with higher probability of responding correctly as well as changes of mind, as indexed by electromyography data. By successfully modeling cognitive operations at the trial level, we provide empirical evidence for dynamic variability in decision strategies, challenging the assumption of homogeneous cognitive processes within experimental conditions. Our approach shows the potential of sequence modeling in cognitive neuroscience to capture trial-level variability that is obscured by aggregate analyses. The introduced method offers a new way to detect and understand cognitive strategies in a data-driven manner, with implications for both theoretical research and practical applications in many fields.","authors":["Rick den Otter","Gabriel Weindel","Sjoerd Stuit","Leendert van Maanen"],"url":"https://arxiv.org/abs/2504.10028"}
{"created":"2025-04-15","title":"Frequency Hopping Waveform Design for Secure Integrated Sensing and Communications","abstract":"We introduce a comprehensive approach to enhance the security, privacy, and sensing capabilities of integrated sensing and communications (ISAC) systems by leveraging random frequency agility (RFA) and random pulse repetition interval (PRI) agility (RPA) techniques. The combination of these techniques, which we refer to collectively as random frequency and PRI agility (RFPA), with channel reciprocity-based key generation (CRKG) obfuscates both Doppler frequency and PRIs, significantly hindering the chances that passive adversaries can successfully estimate radar parameters. In addition, a hybrid information embedding method integrating amplitude shift keying (ASK), phase shift keying (PSK), index modulation (IM), and spatial modulation (SM) is incorporated to increase the achievable bit rate of the system significantly. Next, a sparse-matched filter receiver design is proposed to efficiently decode the embedded information with a low bit error rate (BER). Finally, a novel RFPA-based secret generation scheme using CRKG ensures secure code creation without a coordinating authority. The improved range and velocity estimation and reduced clutter effects achieved with the method are demonstrated via the evaluation of the ambiguity function (AF) of the proposed waveforms.","authors":["Ali Khandan Boroujeni","Giuseppe Thadeu Freitas de Abreu","Stefan K\\\"opsell","Ghazal Bagheri","Kuranage Roche Rayan Ranasinghe","Rafael F. Schaefer"],"url":"https://arxiv.org/abs/2504.10052"}
{"created":"2025-04-15","title":"Bayesian optimal experimental design with Wasserstein information criteria","abstract":"Bayesian optimal experimental design (OED) provides a principled framework for selecting the most informative observational settings in experiments. With rapid advances in computational power, Bayesian OED has become increasingly feasible for inference problems involving large-scale simulations, attracting growing interest in fields such as inverse problems. In this paper, we introduce a novel design criterion based on the expected Wasserstein-$p$ distance between the prior and posterior distributions. Especially, for $p=2$, this criterion shares key parallels with the widely used expected information gain (EIG), which relies on the Kullback--Leibler divergence instead. First, the Wasserstein-2 criterion admits a closed-form solution for Gaussian regression, a property which can be also leveraged for approximative schemes. Second, it can be interpreted as maximizing the information gain measured by the transport cost incurred when updating the prior to the posterior. Our main contribution is a stability analysis of the Wasserstein-1 criterion, where we provide a rigorous error analysis under perturbations of the prior or likelihood. We partially extend this study also to the Wasserstein-2 criterion. In particular, these results yield error rates when empirical approximations of priors are used. Finally, we demonstrate the computability of the Wasserstein-2 criterion and demonstrate our approximation rates through simulations.","authors":["Tapio Helin","Youssef Marzouk","Jose Rodrigo Rojo-Garcia"],"url":"https://arxiv.org/abs/2504.10092"}
{"created":"2025-04-15","title":"Performances in solving the Bethe-Salpeter equation with the Yambo code","abstract":"In this work, we analyze the performances of two different strategies in solving the structured eigenvalue problem deriving from the Bethe-Salpeter equation (BSE) in condensed matter physics. The first strategy employs direct diagonalization, while the second is based on an iterative solver. The BSE matrix is constructed with the Yambo code, and the two strategies are implemented by interfacing Yambo with the ScaLAPACK and ELPA libraries for direct diagonalization, and with the SLEPc library for the iterative approach. We consider both the hermitian (Tamm-Dancoff approximation) and pseudo-hermitian forms, addressing dense matrices of three different sizes. A description of the implementation is also provided, with details for the pseudo-hermitian case. Timing and memory utilization are analyzed on both CPU and GPU clusters. The CPU simulations are performed on a local cluster in Rome, while the GPU simulations are performed on the Leonardo HPC cluster of CINECA. Our results demonstrate that it is now feasible to handle dense BSE matrices of the order 10$^5$.","authors":["Petru Milev","Blanca Mellado-Pinto","Muralidhar Nalabothula","Ali Esquembre Kucukalic","Fernando Alvarruiz","Enrique Ramos","Ludger Wirtz","Jose E. Roman","Davide Sangalli"],"url":"https://arxiv.org/abs/2504.10096"}
{"created":"2025-04-15","title":"Conditional Distribution Compression via the Kernel Conditional Mean Embedding","abstract":"Existing distribution compression methods, like Kernel Herding (KH), were originally developed for unlabelled data. However, no existing approach directly compresses the conditional distribution of labelled data. To address this gap, we first introduce the Average Maximum Conditional Mean Discrepancy (AMCMD), a natural metric for comparing conditional distributions. We then derive a consistent estimator for the AMCMD and establish its rate of convergence. Next, we make a key observation: in the context of distribution compression, the cost of constructing a compressed set targeting the AMCMD can be reduced from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(n)$. Building on this, we extend the idea of KH to develop Average Conditional Kernel Herding (ACKH), a linear-time greedy algorithm that constructs a compressed set targeting the AMCMD. To better understand the advantages of directly compressing the conditional distribution rather than doing so via the joint distribution, we introduce Joint Kernel Herding (JKH), a straightforward adaptation of KH designed to compress the joint distribution of labelled data. While herding methods provide a simple and interpretable selection process, they rely on a greedy heuristic. To explore alternative optimisation strategies, we propose Joint Kernel Inducing Points (JKIP) and Average Conditional Kernel Inducing Points (ACKIP), which jointly optimise the compressed set while maintaining linear complexity. Experiments show that directly preserving conditional distributions with ACKIP outperforms both joint distribution compression (via JKH and JKIP) and the greedy selection used in ACKH. Moreover, we see that JKIP consistently outperforms JKH.","authors":["Dominic Broadbent","Nick Whiteley","Robert Allison","Tom Lovett"],"url":"https://arxiv.org/abs/2504.10139"}
{"created":"2025-04-15","title":"Towards contrast- and pathology-agnostic clinical fetal brain MRI segmentation using SynthSeg","abstract":"Magnetic resonance imaging (MRI) has played a crucial role in fetal neurodevelopmental research. Structural annotations of MR images are an important step for quantitative analysis of the developing human brain, with Deep learning providing an automated alternative for this otherwise tedious manual process. However, segmentation performances of Convolutional Neural Networks often suffer from domain shift, where the network fails when applied to subjects that deviate from the distribution with which it is trained on. In this work, we aim to train networks capable of automatically segmenting fetal brain MRIs with a wide range of domain shifts pertaining to differences in subject physiology and acquisition environments, in particular shape-based differences commonly observed in pathological cases. We introduce a novel data-driven train-time sampling strategy that seeks to fully exploit the diversity of a given training dataset to enhance the domain generalizability of the trained networks. We adapted our sampler, together with other existing data augmentation techniques, to the SynthSeg framework, a generator that utilizes domain randomization to generate diverse training data, and ran thorough experimentations and ablation studies on a wide range of training/testing data to test the validity of the approaches. Our networks achieved notable improvements in the segmentation quality on testing subjects with intense anatomical abnormalities (p < 1e-4), though at the cost of a slighter decrease in performance in cases with fewer abnormalities. Our work also lays the foundation for future works on creating and adapting data-driven sampling strategies for other training pipelines.","authors":["Ziyao Shang","Misha Kaandorp","Kelly Payette","Marina Fernandez Garcia","Roxane Licandro","Georg Langs","Jordina Aviles Verdera","Jana Hutter","Bjoern Menze","Gregor Kasprian","Meritxell Bach Cuadra","Andras Jakab"],"url":"https://arxiv.org/abs/2504.10244"}
{"created":"2025-04-15","title":"Adaptive Sensor Steering Strategy Using Deep Reinforcement Learning for Dynamic Data Acquisition in Digital Twins","abstract":"This paper introduces a sensor steering methodology based on deep reinforcement learning to enhance the predictive accuracy and decision support capabilities of digital twins by optimising the data acquisition process. Traditional sensor placement techniques are often constrained by one-off optimisation strategies, which limit their applicability for online applications requiring continuous informative data assimilation. The proposed approach addresses this limitation by offering an adaptive framework for sensor placement within the digital twin paradigm. The sensor placement problem is formulated as a Markov decision process, enabling the training and deployment of an agent capable of dynamically repositioning sensors in response to the evolving conditions of the physical structure as represented by the digital twin. This ensures that the digital twin maintains a highly representative and reliable connection to its physical counterpart. The proposed framework is validated through a series of comprehensive case studies involving a cantilever plate structure subjected to diverse conditions, including healthy and damaged conditions. The results demonstrate the capability of the deep reinforcement learning agent to adaptively reposition sensors improving the quality of data acquisition and hence enhancing the overall accuracy of digital twins.","authors":["Collins O. Ogbodo","Timothy J. Rogers","Mattia Dal Borgo","David J. Wagg"],"url":"https://arxiv.org/abs/2504.10248"}
{"created":"2025-04-15","title":"Zero-shot Autonomous Microscopy for Scalable and Intelligent Characterization of 2D Materials","abstract":"Characterization of atomic-scale materials traditionally requires human experts with months to years of specialized training. Even for trained human operators, accurate and reliable characterization remains challenging when examining newly discovered materials such as two-dimensional (2D) structures. This bottleneck drives demand for fully autonomous experimentation systems capable of comprehending research objectives without requiring large training datasets. In this work, we present ATOMIC (Autonomous Technology for Optical Microscopy & Intelligent Characterization), an end-to-end framework that integrates foundation models to enable fully autonomous, zero-shot characterization of 2D materials. Our system integrates the vision foundation model (i.e., Segment Anything Model), large language models (i.e., ChatGPT), unsupervised clustering, and topological analysis to automate microscope control, sample scanning, image segmentation, and intelligent analysis through prompt engineering, eliminating the need for additional training. When analyzing typical MoS2 samples, our approach achieves 99.7% segmentation accuracy for single layer identification, which is equivalent to that of human experts. In addition, the integrated model is able to detect grain boundary slits that are challenging to identify with human eyes. Furthermore, the system retains robust accuracy despite variable conditions including defocus, color temperature fluctuations, and exposure variations. It is applicable to a broad spectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardless of whether they were fabricated via chemical vapor deposition or mechanical exfoliation. This work represents the implementation of foundation models to achieve autonomous analysis, establishing a scalable and data-efficient characterization paradigm that fundamentally transforms the approach to nanoscale materials research.","authors":["Jingyun Yang","Ruoyan Avery Yin","Chi Jiang","Yuepeng Hu","Xiaokai Zhu","Xingjian Hu","Sutharsika Kumar","Xiao Wang","Xiaohua Zhai","Keran Rong","Yunyue Zhu","Tianyi Zhang","Zongyou Yin","Jing Kong","Neil Zhenqiang Gong","Zhichu Ren","Haozhe Wang"],"url":"https://arxiv.org/abs/2504.10281"}
{"created":"2025-04-15","title":"Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis","abstract":"Recent zero-shot text-to-speech (TTS) systems face a common dilemma: autoregressive (AR) models suffer from slow generation and lack duration controllability, while non-autoregressive (NAR) models lack temporal modeling and typically require complex designs. In this paper, we introduce a novel pseudo-autoregressive (PAR) codec language modeling approach that unifies AR and NAR modeling. Combining explicit temporal modeling from AR with parallel generation from NAR, PAR generates dynamic-length spans at fixed time steps. Building on PAR, we propose PALLE, a two-stage TTS system that leverages PAR for initial generation followed by NAR refinement. In the first stage, PAR progressively generates speech tokens along the time dimension, with each step predicting all positions in parallel but only retaining the left-most span. In the second stage, low-confidence tokens are iteratively refined in parallel, leveraging the global contextual information. Experiments demonstrate that PALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on large-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech test-clean set in terms of speech quality, speaker similarity, and intelligibility, while achieving up to ten times faster inference speed. Audio samples are available at https://anonymous-palle.github.io.","authors":["Yifan Yang","Shujie Liu","Jinyu Li","Yuxuan Hu","Haibin Wu","Hui Wang","Jianwei Yu","Lingwei Meng","Haiyang Sun","Yanqing Liu","Yan Lu","Kai Yu","Xie Chen"],"url":"https://arxiv.org/abs/2504.10352"}
{"created":"2025-04-15","title":"Fine-Grained Complexity via Quantum Natural Proofs","abstract":"Buhrman, Patro, and Speelman presented a framework of conjectures that together form a quantum analogue of the strong exponential-time hypothesis and its variants. They called it the QSETH framework. In this paper, using a notion of quantum natural proofs (built from natural proofs introduced by Razborov and Rudich), we show how part of the QSETH conjecture that requires properties to be `compression oblivious' can in many cases be replaced by assuming the existence of quantum-secure pseudorandom functions, a standard hardness assumption. Combined with techniques from Fourier analysis of Boolean functions, we show that properties such as PARITY and MAJORITY are compression oblivious for certain circuit class $\\Lambda$ if subexponentially secure quantum pseudorandom functions exist in $\\Lambda$, answering an open question in [Buhrman-Patro-Speelman 2021].","authors":["Yanlin Chen","Yilei Chen","Rajendra Kumar","Subhasree Patro","Florian Speelman"],"url":"https://arxiv.org/abs/2504.10363"}
{"created":"2025-04-15","title":"Further Comments on Yablo's Construction","abstract":"We continue our analysis of Yablo's coding of the liar paradox by infinite acyclic graphs. The present notes are based on and continue the author's previous results on the problem. In particular, our approach is often more systematic than before.","authors":["Karl Schlechta"],"url":"https://arxiv.org/abs/2504.10370"}
{"created":"2025-04-15","title":"Inferring genotype-phenotype maps using attention models","abstract":"Predicting phenotype from genotype is a central challenge in genetics. Traditional approaches in quantitative genetics typically analyze this problem using methods based on linear regression. These methods generally assume that the genetic architecture of complex traits can be parameterized in terms of an additive model, where the effects of loci are independent, plus (in some cases) pairwise epistatic interactions between loci. However, these models struggle to analyze more complex patterns of epistasis or subtle gene-environment interactions. Recent advances in machine learning, particularly attention-based models, offer a promising alternative. Initially developed for natural language processing, attention-based models excel at capturing context-dependent interactions and have shown exceptional performance in predicting protein structure and function. Here, we apply attention-based models to quantitative genetics. We analyze the performance of this attention-based approach in predicting phenotype from genotype using simulated data across a range of models with increasing epistatic complexity, and using experimental data from a recent quantitative trait locus mapping study in budding yeast. We find that our model demonstrates superior out-of-sample predictions in epistatic regimes compared to standard methods. We also explore a more general multi-environment attention-based model to jointly analyze genotype-phenotype maps across multiple environments and show that such architectures can be used for \"transfer learning\" - predicting phenotypes in novel environments with limited training data.","authors":["Krishna Rijal","Caroline M. Holmes","Samantha Petti","Gautam Reddy","Michael M. Desai","Pankaj Mehta"],"url":"https://arxiv.org/abs/2504.10388"}
{"created":"2025-04-15","title":"Diversity-Fair Online Selection","abstract":"Online selection problems frequently arise in applications such as crowdsourcing and employee recruitment. Existing research typically focuses on candidates with a single attribute. However, crowdsourcing tasks often require contributions from individuals across various demographics. Further motivated by the dynamic nature of crowdsourcing and hiring, we study the diversity-fair online selection problem, in which a recruiter must make real-time decisions to foster workforce diversity across many dimensions. We propose two scenarios for this problem. The fixed-capacity scenario, suited for short-term hiring for crowdsourced workers, provides the recruiter with a fixed capacity to fill temporary job vacancies. In contrast, in the unknown-capacity scenario, recruiters optimize diversity across recruitment seasons with increasing capacities, reflecting that the firm honors diversity consideration in a long-term employee acquisition strategy. By modeling the diversity over $d$ dimensions as a max-min fairness objective, we show that no policy can surpass a competitive ratio of $O(1/d^{1/3})$ for either scenario, indicating that any achievable result inevitably decays by some polynomial factor in $d$. To this end, we develop bilevel hierarchical randomized policies that ensure compliance with the capacity constraint. For the fixed-capacity scenario, leveraging marginal information about the arriving population allows us to achieve a competitive ratio of $1/(4\\sqrt{d} \\lceil \\log_2 d \\rceil)$. For the unknown-capacity scenario, we establish a competitive ratio of $\\Omega(1/d^{3/4})$ under mild boundedness conditions. In both bilevel hierarchical policies, the higher level determines ex-ante selection probabilities and then informs the lower level's randomized selection that ensures no loss in efficiency. Both policies prioritize core diversity and then adjust for underrepresented dimensions.","authors":["Ming Hu","Yanzhi Li","Tongwen Wu"],"url":"https://arxiv.org/abs/2504.10389"}
{"created":"2025-04-15","title":"Expected Length of the Longest Common Subsequence of Multiple Strings","abstract":"We study the generalized Chv\\'atal-Sankoff constant $\\gamma_{k,d}$, which represents the normalized expected length of the longest common subsequence (LCS) of $d$ independent uniformly random strings over an alphabet of size $k$. We derive asymptotically tight bounds for $\\gamma_{2,d}$, establishing that $\\gamma_{2,d} = \\frac{1}{2} + \\Theta\\left(\\frac{1}{\\sqrt{d}}\\right)$. We also derive asymptotically near-optimal bounds on $\\gamma_{k,d}$ for $d\\ge \\Omega(\\log k)$.","authors":["Ray Li","William Ren","Yiran Wen"],"url":"https://arxiv.org/abs/2504.10425"}
{"created":"2025-04-15","title":"Learning with Positive and Imperfect Unlabeled Data","abstract":"We study the problem of learning binary classifiers from positive and unlabeled data when the unlabeled data distribution is shifted, which we call Positive and Imperfect Unlabeled (PIU) Learning. In the absence of covariate shifts, i.e., with perfect unlabeled data, Denis (1998) reduced this problem to learning under Massart noise; however, that reduction fails under even slight shifts.","authors":["Jane H. Lee","Anay Mehrotra","Manolis Zampetakis"],"url":"https://arxiv.org/abs/2504.10428"}
{"created":"2025-04-15","title":"Capacities of highly Markovian divisible quantum channels","abstract":"We analyze information transmission capacities of quantum channels acting on $d$-dimensional quantum systems that are highly Markovian divisible, i.e., channels of the form \\begin{equation*}","authors":["Satvik Singh","Nilanjana Datta"],"url":"https://arxiv.org/abs/2504.10436"}
{"created":"2025-04-15","title":"Anchors no more: Using peculiar velocities to constrain $H_0$ and the primordial Universe without calibrators","abstract":"We develop a novel approach to constrain the Hubble parameter $H_0$ and the primordial power spectrum amplitude $A_\\mathrm{s}$ using supernovae type Ia (SNIa) data. By considering SNIa as tracers of the peculiar velocity field, we can model their distance and their covariance as a function of cosmological parameters without the need of calibrators like Cepheids; this yields a new independent probe of the large-scale structure based on SNIa data without distance anchors. Crucially, we implement a differentiable pipeline in JAX, including efficient emulators and affine sampling, reducing inference time from years to hours on a single GPU. We first validate our method on mock datasets, demonstrating that we can constrain $H_0$ and $\\log 10^{10}A_\\mathrm{s}$ within $\\sim10\\%$ using $\\sim10^3$ SNIa. We then test our pipeline with SNIa from an $N$-body simulation, obtaining $7\\%$-level unbiased constraints on $H_0$ with a moderate noise level. We finally apply our method to Pantheon+ data, constraining $H_0$ at the $10\\%$ level without Cepheids when fixing $A_\\mathrm{s}$ to its $\\it{Planck}$ value. On the other hand, we obtain $15\\%$-level constraints on $\\log 10^{10}A_\\mathrm{s}$ in agreement with $\\it{Planck}$ when including Cepheids in the analysis. In light of upcoming observations of low redshift SNIa from the Zwicky Transient Facility and the Vera Rubin Legacy Survey of Space and Time, surveys for which our method will develop its full potential, we make our code publicly available.","authors":["Davide Piras","Francesco Sorrenti","Ruth Durrer","Martin Kunz"],"url":"https://arxiv.org/abs/2504.10453"}
{"created":"2025-04-15","title":"Design of Pulse Shapes Based on Sampling with Gaussian Prefilter","abstract":"Two new pulse shapes for communications are presented. The first pulse shape generates a set of pulses without intersymbol interference (ISI) or ISI-free for short. In the neighbourhood of the origin it is similar in shape to the classical cardinal sine function but is of exponential decay at infinity. This pulse shape is identical to the interpolating function of a recent sampling theorem with Gaussian prefilter. The second pulse shape is obtained from the first pulse shape by spectral factorization. Besides being also of exponential decay at infinity, it has a causal appearance since it is of superexponential decay for negative times. It is closely related to the orthonormal generating function considered earlier by Unser in the context of shift-invariant spaces. This pulse shape is not ISI-free but it generates a set of orthonormal pulses. The second pulse shape may also be used to define a receive matched filter so that at the filter output the ISI-free pulses of the first kind are recovered.","authors":["Edwin Hammerich"],"url":"https://arxiv.org/abs/0907.2412"}
{"created":"2025-04-15","title":"Fortuitous sequences of flips of the top of a stack of n burnt pancakes for all n>24","abstract":"Burnt pancakes problem was defined by Gates and Papadimitriou in 1979. A stack $S$ of pancakes with a burnt side must be sorted by size, the smallest on top, and each pancake with burnt side down. The only operation allowed is to split stack in two parts and flip upper part. $g(S)$ is the minimal number of flips needed to sort stack $S$. Stack $S$ may be $-I_n$ when pancakes are in right order but upside down or $-f_n$ when all pancakes are right side up but sorted in reverse order. Gates et al. proved that $g(-f_n)\\ge 3n/2-1$. In 1995 Cohen and Blum proved that $g(-I_n)=g(-f_n)+1\\ge 3n/2$. In 1997 Heydari and Sudborough proved that $g(-I_n)\\le 3(n+1)/2$ whenever some fortuitous sequence of flips exists. They gave fortuitous sequences for $n$=3, 15, 27 and 31. They showed that two fortuitous sequences $S_n$ and $S_{n'}$ may combine into another fortuitous sequence $S_{n''}$ with $n''=n+n'-3$. So a fortuitous sequence $S_n$ gives a fortuitous sequence $S_{n+12}$. This proves that $g(-I_n)\\le 3(n+1)/2$ if $n$ is congruent to 3 modulo 4 and $n\\ge 23$. In 2011 Josef Cibulka enhanced Gates and Papadimitriou's lower bound thanks to a potential function. He got so $g(-I_n)\\ge3n/2+1$ if $n > 1$ proving thereby, that $g(-I_n)=3(n+1)/2$ if $n$ is congruent to 3 modulo 4 and $n\\ge 23$. This paper explains how to build generalized fortuitous sequences for $n=15, 19, 23$ and every $n\\ge 25$, odd or even, proving thereby that $g(-I_n)=\\lceil 3n/2\\rceil+1$ for these $n$. It gives $g(-I_n)$ for all $n$.","authors":["Laurent Pierre"],"url":"https://arxiv.org/abs/1601.06278"}
{"created":"2025-04-15","title":"Identification of Wearable Devices with Bluetooth","abstract":"With wearable devices such as smartwatches on the rise in the consumer electronics market, securing these wearables is vital. However, the current security mechanisms only focus on validating the user not the device itself. Indeed, wearables can be (1) unauthorized wearable devices with correct credentials accessing valuable systems and networks, (2) passive insiders or outsider wearable devices, or (3) information-leaking wearables devices. Fingerprinting via machine learning can provide necessary cyber threat intelligence to address all these cyber attacks. In this work, we introduce a wearable fingerprinting technique focusing on Bluetooth classic protocol, which is a common protocol used by the wearables and other IoT devices. Specifically, we propose a non-intrusive wearable device identification framework which utilizes 20 different Machine Learning (ML) algorithms in the training phase of the classification process and selects the best performing algorithm for the testing phase. Furthermore, we evaluate the performance of proposed wearable fingerprinting technique on real wearable devices, including various off-the-shelf smartwatches. Our evaluation demonstrates the feasibility of the proposed technique to provide reliable cyber threat intelligence. Specifically, our detailed accuracy results show on average 98.5%, 98.3% precision and recall for identifying wearables using the Bluetooth classic protocol.","authors":["Hidayet Aksu","A. Selcuk Uluagac","Elizabeth S. Bentley"],"url":"https://arxiv.org/abs/1809.10387"}
{"created":"2025-04-15","title":"Fine-tuning Multi-hop Question Answering with Hierarchical Graph Network","abstract":"In this paper, we present a two stage model for multi-hop question answering. The first stage is a hierarchical graph network, which is used to reason over multi-hop question and is capable to capture different levels of granularity using the nature structure(i.e., paragraphs, questions, sentences and entities) of documents. The reasoning process is convert to node classify task(i.e., paragraph nodes and sentences nodes). The second stage is a language model fine-tuning task. In a word, stage one use graph neural network to select and concatenate support sentences as one paragraph, and stage two find the answer span in language model fine-tuning paradigm.","authors":["Guanming Xiong"],"url":"https://arxiv.org/abs/2004.13821"}
{"created":"2025-04-15","title":"Delay Violation Probability and Effective Rate of Downlink NOMA over $\\alpha$-$\\mu$ Fading Channels","abstract":"Non-orthogonal multiple access (NOMA) is a potential candidate to further enhance the spectrum utilization efficiency in beyond fifth-generation (B5G) standards. However, there has been little attention on the quantification of the delay-limited performance of downlink NOMA systems. In this paper, we analyze the performance of a two-user downlink NOMA system over generalized {\\alpha}-{\\mu} fading in terms of delay violation probability (DVP) and effective rate (ER). In particular, we derive an analytical expression for an upper bound on the DVP and we derive the exact sum ER of the downlink NOMA system. We also derive analytical expressions for high and low signal-to-noise ratio (SNR) approximations to the sum ER, as well as a fundamental upper bound on the sum ER which represents the ergodic sum-rate for the downlink NOMA system. We also analyze the sum ER of a corresponding time-division-multiplexed orthogonal multiple access (OMA) system. Our results show that while NOMA consistently outperforms OMA over the practical SNR range, the relative gain becomes smaller in more severe fading conditions, and is also smaller in the presence a more strict delay quality-of-service (QoS) constraint.","authors":["Vaibhav Kumar","Barry Cardiff","Shankar Prakriya","Mark F. Flanagan"],"url":"https://arxiv.org/abs/2006.16505"}
{"created":"2025-04-15","title":"Self-stabilizing Graph Exploration by a Single Agent","abstract":"In this paper, we present two self-stabilizing algorithms that enable a single (mobile) agent to explore graphs. Starting from any initial configuration, \\ie regardless of the initial states of the agent and all nodes, as well as the initial location of the agent, the algorithms ensure the agent visits all nodes. We evaluate the algorithms based on two metrics: the \\emph{cover time}, defined as the number of moves required to visit all nodes, and \\emph{memory usage}, defined as the storage needed for maintaining the states of the agent and each node. The first algorithm is randomized. Given an integer $c = \\Omega(n)$, its cover time is optimal, \\ie $O(m)$ in expectation, and its memory requirements are $O(\\log c)$ bits for the agent and $O(\\log (c+\\delta_v))$ bits for each node $v$, where $n$ and $m$ are the numbers of nodes and edges, respectively, and $\\delta_v$ is the degree of node $v$. For general $c \\ge 2$, its cover time is $O( m \\cdot \\min(D, \\frac{n}{c}+1, \\frac{D}{c} + \\log n))$, where $D$ is the diameter of a graph. The second algorithm is deterministic. It requires an input integer $k \\ge \\max(D, \\dmax)$, where $\\dmax$ is the maximum degree of the graph. The cover time of this algorithm is $O(m + nD)$, and it uses $O(\\log k)$ bits of memory for both the agent and each node.","authors":["Yuichi Sudo","Fukuhito Ooshita","Sayaka Kamei"],"url":"https://arxiv.org/abs/2010.08929"}
{"created":"2025-04-15","title":"On the performance of downlink NOMA in underlay spectrum sharing","abstract":"Non-orthogonal multiple access (NOMA) and spectrum sharing are two potential technologies for providing massive connectivity in beyond fifth-generation (B5G) networks. In this paper, we present the performance analysis of a multi-antenna-assisted two-user downlink NOMA system in an underlay spectrum sharing system. We derive closed-form expressions for the average achievable sum-rate and outage probability of the secondary network under a peak interference constraint and/or peak power constraint, depending on the availability of channel state information (CSI) of the interference link between secondary transmitter (ST) and primary receiver (PR). For the case where the ST has a fixed power budget, we show that performance can be divided into two specific regimes, where either the interference constraint or the power constraint primarily dictates the performance. Our results confirm that the NOMA-based underlay spectrum sharing system significantly outperforms its orthogonal multiple access (OMA) based counterpart, by achieving higher average sum-rate and lower outage probability. We also show the effect of information loss at the ST in terms of CSI of the link between the ST and PR on the system performance. Moreover, we also present closed-form expressions for the optimal power allocation coefficient that minimizes the outage probability of the NOMA system for the special case where the secondary users are each equipped with a single antenna. A close agreement between the simulation and analytical results confirms the correctness of the presented analysis.","authors":["Vaibhav Kumar","Zhiguo Ding","Mark F. Flanagan"],"url":"https://arxiv.org/abs/2011.08159"}
{"created":"2025-04-15","title":"NOMA-Based Cooperative Relaying with Receive Diversity in Nakagami-m Fading Channels","abstract":"Non-orthogonal multiple access (NOMA) is being widely considered as a potential candidate to enhance the spectrum utilization in beyond fifth-generation (B5G) communications. In this paper, we derive closed-form expressions for the ergodic rate and outage probability of a multiple-antenna-assisted NOMA-based cooperative relaying system (CRS-NOMA). We present the performance analysis of the system for two different receive diversity schemes - selection combining (SC) and maximal-ratio combining (MRC), in Nakagami-m fading. We also evaluate the asymptotic behavior of the CRS-NOMA to determine the slope of the ergodic rate and diversity order. Our results show that in contrast to the existing CRS-NOMA systems, the CRS-NOMA with receive diversity outperforms its orthogonal multiple access (OMA) based counterpart even in the low-SNR regime, by achieving higher ergodic rate. Diversity analysis confirms that the CRS-NOMA achieves full diversity order using both SC and MRC schemes, and this diversity order depends on both the shape parameter m and the number of receive antennas. We also discuss the problem of optimal power allocation for the minimization of the outage probability of the system, and subsequently use this optimal value to obtain the ergodic rate. An excellent match is observed between the numerical and the analytical results, confirming the correctness of the derived analytical expressions.","authors":["Vaibhav Kumar","Barry Cardiff","Mark F Flanagan"],"url":"https://arxiv.org/abs/2011.11692"}
{"created":"2025-04-15","title":"Fuzzy Logic-based Robust Failure Handling Mechanism for Fog Computing","abstract":"Fog computing is an emerging computing paradigm which is mainly suitable for time-sensitive and real-time Internet of Things (IoT) applications. Academia and industries are focusing on the exploration of various aspects of Fog computing for market adoption. The key idea of the Fog computing paradigm is to use idle computation resources of various handheld, mobile, stationery and network devices around us, to serve the application requests in the Fog-IoT environment. The devices in the Fog environment are autonomous and not exclusively dedicated to Fog application processing. Due to that, the probability of device failure in the Fog environment is high compared with other distributed computing paradigms. Solving failure issues in Fog is crucial because successful application execution can only be ensured if failure can be handled carefully. To handle failure, there are several techniques available in the literature, such as checkpointing and task migration, each of which works well in cloud based enterprise applications that mostly deals with static or transactional data. These failure handling methods are not applicable to highly dynamic Fog environment. In contrast, this work focuses on solving the problem of managing application failure in the Fog environment by proposing a composite solution (combining fuzzy logic-based task checkpointing and task migration techniques with task replication) for failure handling and generating a robust schedule. We evaluated the proposed methods using real failure traces in terms of application execution time, delay and cost. Average delay and total processing time improved by 56% and 48% respectively, on an average for the proposed solution, compared with the existing failure handling approaches.","authors":["Ranesh Naha","Saurabh Garg","Sudheer Kumar Battula","Muhammad Bilal Amin","Rajiv Ranjan"],"url":"https://arxiv.org/abs/2103.06381"}
{"created":"2025-04-15","title":"A reduced 3D-0D FSI model of the aortic valve including leaflet curvature","abstract":"We introduce an innovative lumped-parameter model of the aortic valve, designed to efficiently simulate the impact of valve dynamics on blood flow. Our reduced model includes the elastic effects associated with the leaflets' curvature and the stress exchanged with the blood flow. The introduction of a lumped-parameter model based on momentum balance entails an easier calibration of the model parameters: phenomenological-based models, on the other hand, typically have numerous parameters. This model is coupled to 3D Navier-Stokes equations describing the blood flow, where the moving valve leaflets are immersed in the fluid domain by a resistive method. A stabilized finite element method with a BDF time scheme is adopted for the discretization of the coupled problem, and the computational results show the suitability of the system in representing the leaflet motion, the blood flow in the ascending aorta, and the pressure jump across the leaflets. Both physiological and stenotic configurations are investigated, and we analyze the effects of different treatments for the leaflet velocity on the blood flow.","authors":["Ivan Fumagalli","Luca Dede'","Alfio Quarteroni"],"url":"https://arxiv.org/abs/2106.00571"}
{"created":"2025-04-15","title":"A Fast Horizon Detector and a New Annotated Dataset for Maritime Video Processing","abstract":"Accurate and fast sea horizon detection is vital for tasks in autonomous navigation and maritime security, such as video stabilization, target region reduction, precise tracking, and obstacle avoidance. This paper introduces a novel sea horizon detector from RGB videos, focusing on rapid and effective sea noise suppression while preserving weak horizon edges. Line fitting methods are subsequently employed on filtered edges for horizon detection. We address the filtering problem by extracting line segments with a very low edge threshold, ensuring the detection of line segments even in low-contrast horizon conditions. We show that horizon line segments have simple and relevant properties in RGB images, which we exploit to suppress noisy segments. Then we use the surviving segments to construct a filtered edge map and infer the horizon from the filtered edges. We propose a careful incorporation of temporal information for horizon inference and experimentally show its effectiveness. We address the computational constraint by providing a vectorized implementation for efficient CPU execution, and leveraging image downsizing with minimal loss of accuracy on the original size. Moreover, we contribute a public horizon line dataset to enrich existing data resources. Our algorithm's performance is rigorously evaluated against state-of-the-art methods, and its components are validated through ablation experiments. Source code and dataset files are available at: https://github.com/Zardoua-Yassir/A_fast_horizon_detector_and_a_new_annotated_dataset_for_maritime_video_processing","authors":["Yassir Zardoua","Boulaala Mohammed","Mhamed El Mrabet","Astito Abdelali"],"url":"https://arxiv.org/abs/2110.13694"}
{"created":"2025-04-15","title":"MIO : Mutual Information Optimization using Self-Supervised Binary Contrastive Learning","abstract":"Self-supervised contrastive learning frameworks have progressed rapidly over the last few years. In this paper, we propose a novel loss function for contrastive learning. We model our pre-training task as a binary classification problem to induce an implicit contrastive effect. We further improve the n\\\"aive loss function after removing the effect of the positive-positive repulsion and incorporating the upper bound of the negative pair repulsion. Unlike existing methods, the proposed loss function optimizes the mutual information in positive and negative pairs. We also present a closed-form expression for the parameter gradient flow and compare the behaviour of self-supervised contrastive frameworks using Hessian eigenspectrum to analytically study their convergence. The proposed method outperforms SOTA self-supervised contrastive frameworks on benchmark datasets such as CIFAR-10, CIFAR-100, STL-10, and Tiny-ImageNet. After 200 pretraining epochs with ResNet-18 as the backbone, the proposed model achieves an accuracy of 86.36%, 58.18%, 80.50%, and 30.87% on the CIFAR-10, CIFAR-100, STL-10, and Tiny-ImageNet datasets, respectively, and surpasses the SOTA contrastive baseline by 1.93%, 3.57%, 4.85%, and 0.33%, respectively. The proposed framework also achieves a state-of-the-art accuracy of 78.4% (200 epochs) and 65.22% (100 epochs) Top-1 Linear Evaluation accuracy on ImageNet100 and ImageNet1K datasets, respectively.","authors":["Siladittya Manna","Umapada Pal","Saumik Bhattacharya"],"url":"https://arxiv.org/abs/2111.12664"}
{"created":"2025-04-15","title":"Global2Local: A Joint-Hierarchical Attention for Video Captioning","abstract":"Recently, automatic video captioning has attracted increasing attention, where the core challenge lies in capturing the key semantic items, like objects and actions as well as their spatial-temporal correlations from the redundant frames and semantic content. To this end, existing works select either the key video clips in a global level~(across multi frames), or key regions within each frame, which, however, neglect the hierarchical order, i.e., key frames first and key regions latter. In this paper, we propose a novel joint-hierarchical attention model for video captioning, which embeds the key clips, the key frames and the key regions jointly into the captioning model in a hierarchical manner. Such a joint-hierarchical attention model first conducts a global selection to identify key frames, followed by a Gumbel sampling operation to identify further key regions based on the key frames, achieving an accurate global-to-local feature representation to guide the captioning. Extensive quantitative evaluations on two public benchmark datasets MSVD and MSR-VTT demonstrates the superiority of the proposed method over the state-of-the-art methods.","authors":["Chengpeng Dai","Fuhai Chen","Xiaoshuai Sun","Rongrong Ji","Qixiang Ye","Yongjian Wu"],"url":"https://arxiv.org/abs/2203.06663"}
{"created":"2025-04-15","title":"Forecasting Sparse Movement Speed of Urban Road Networks with Nonstationary Temporal Matrix Factorization","abstract":"Movement speed data from urban road networks, computed from ridesharing vehicles or taxi trajectories, is often high-dimensional, sparse, and nonstationary (e.g., exhibiting seasonality). To address these challenges, we propose a Nonstationary Temporal Matrix Factorization (NoTMF) model that leverages matrix factorization to project high-dimensional and sparse movement speed data into low-dimensional latent spaces. This results in a concise formula with the multiplication between spatial and temporal factor matrices. To characterize the temporal correlations, NoTMF takes a latent equation on the seasonal differenced temporal factors using higher-order vector autoregression (VAR). This approach not only preserves the low-rank structure of sparse movement speed data but also maintains consistent temporal dynamics, including seasonality information. The learning process for NoTMF involves optimizing the spatial and temporal factor matrices along with a collection of VAR coefficient matrices. To solve this efficiently, we introduce an alternating minimization framework, which tackles a challenging procedure of estimating the temporal factor matrix using conjugate gradient method, as the subproblem involves both partially observed matrix factorization and seasonal differenced VAR. To evaluate the forecasting performance of NoTMF, we conduct extensive experiments on Uber movement speed datasets, which are estimated from ridesharing vehicle trajectories. These datasets contain a large proportion of missing values due to insufficient ridesharing vehicles on the urban road network. Despite the presence of missing data, NoTMF demonstrates superior forecasting accuracy and effectiveness compared to baseline models. Moreover, as the seasonality of movement speed data is of great concern, the experiment results highlight the significance of addressing the nonstationarity of movement speed data.","authors":["Xinyu Chen","Chengyuan Zhang","Xi-Le Zhao","Nicolas Saunier","Lijun Sun"],"url":"https://arxiv.org/abs/2203.10651"}
{"created":"2025-04-15","title":"Embedding Principle in Depth for the Loss Landscape Analysis of Deep Neural Networks","abstract":"Understanding the relation between deep and shallow neural networks is extremely important for the theoretical study of deep learning. In this work, we discover an embedding principle in depth that loss landscape of an NN \"contains\" all critical points of the loss landscapes for shallower NNs. The key tool for our discovery is the critical lifting operator proposed in this work that maps any critical point of a network to critical manifolds of any deeper network while preserving the outputs. This principle provides new insights to many widely observed behaviors of DNNs. Regarding the easy training of deep networks, we show that local minimum of an NN can be lifted to strict saddle points of a deeper NN. Regarding the acceleration effect of batch normalization, we demonstrate that batch normalization helps avoid the critical manifolds lifted from shallower NNs by suppressing layer linearization. We also prove that increasing training data shrinks the lifted critical manifolds, which can result in acceleration of training as demonstrated in experiments. Overall, our discovery of the embedding principle in depth uncovers the depth-wise hierarchical structure of deep learning loss landscape, which serves as a solid foundation for the further study about the role of depth for DNNs.","authors":["Zhiwei Bai","Tao Luo","Zhi-Qin John Xu","Yaoyu Zhang"],"url":"https://arxiv.org/abs/2205.13283"}
{"created":"2025-04-15","title":"Why is constrained neural language generation particularly challenging?","abstract":"Recent advances in deep neural language models combined with the capacity of large scale datasets have accelerated the development of natural language generation systems that produce fluent and coherent texts (to various degrees of success) in a multitude of tasks and application contexts. However, controlling the output of these models for desired user and task needs is still an open challenge. This is crucial not only to customizing the content and style of the generated language, but also to their safe and reliable deployment in the real world. We present an extensive survey on the emerging topic of constrained neural language generation in which we formally define and categorize the problems of natural language generation by distinguishing between conditions and constraints (the latter being testable conditions on the output text instead of the input), present constrained text generation tasks, and review existing methods and evaluation metrics for constrained text generation. Our aim is to highlight recent progress and trends in this emerging field, informing on the most promising directions and limitations towards advancing the state-of-the-art of constrained neural language generation research.","authors":["Cristina Garbacea","Qiaozhu Mei"],"url":"https://arxiv.org/abs/2206.05395"}
{"created":"2025-04-15","title":"Adding New Categories in Object Detection Using Few-Shot Copy-Paste","abstract":"Developing data-efficient instance detection models that can handle rare object categories remains a key challenge in computer vision. However, existing research often overlooks data collection strategies and evaluation metrics tailored to real-world scenarios involving neural networks. In this study, we systematically investigate data collection and augmentation techniques focused on object occlusion, aiming to mimic occlusion relationships observed in practical applications. Surprisingly, we find that even a simple occlusion mechanism is sufficient to achieve strong performance when introducing new object categories. Notably, by adding just 15 images of a new category to a large-scale training dataset containing over half a million images across hundreds of categories, the model achieves 95\\% accuracy on an unseen test set with thousands of instances of the new category.","authors":["Boyang Deng","Meiyan Lin","Shoulun Long"],"url":"https://arxiv.org/abs/2206.05730"}
{"created":"2025-04-15","title":"A Theory of Sub-Barcodes","abstract":"From the work of Bauer and Lesnick, it is known that there is no functor from the category of pointwise finite-dimensional persistence modules to the category of barcodes and overlap matchings. In this work, we introduce sub-barcodes and show that there is a functor from the category of factorizations of persistence module homomorphisms to a poset of barcodes ordered by the sub-barcode relation. Sub-barcodes and factorizations provide a looser alternative to bottleneck matchings and interleavings that can give strong guarantees in a number of settings that arise naturally in topological data analysis. The main use of sub-barcodes is to make strong claims about an unknown barcode in the absence of an interleaving. For example, given only upper and lower bounds $g\\geq f\\geq \\ell$ of an unknown real-valued function $f$, a sub-barcode associated with $f$ can be constructed from $\\ell$ and $g$ alone. We propose a theory of sub-barcodes and observe that the subobjects in the category of functors from intervals to matchings naturally correspond to sub-barcodes.","authors":["Oliver A. Chubet","Kirk P. Gardner","Donald R. Sheehy"],"url":"https://arxiv.org/abs/2206.10504"}
{"created":"2025-04-15","title":"Topology-aware Generalization of Decentralized SGD","abstract":"This paper studies the algorithmic stability and generalizability of decentralized stochastic gradient descent (D-SGD). We prove that the consensus model learned by D-SGD is $\\mathcal{O}{(N^{-1}+m^{-1} +\\lambda^2)}$-stable in expectation in the non-convex non-smooth setting, where $N$ is the total sample size, $m$ is the worker number, and $1+\\lambda$ is the spectral gap that measures the connectivity of the communication topology. These results then deliver an $\\mathcal{O}{(N^{-(1+\\alpha)/2}+ m^{-(1+\\alpha)/2}+\\lambda^{1+\\alpha} + \\phi_{\\mathcal{S}})}$ in-average generalization bound, which is non-vacuous even when $\\lambda$ is closed to $1$, in contrast to vacuous as suggested by existing literature on the projected version of D-SGD. Our theory indicates that the generalizability of D-SGD is positively correlated with the spectral gap, and can explain why consensus control in initial training phase can ensure better generalization. Experiments of VGG-11 and ResNet-18 on CIFAR-10, CIFAR-100 and Tiny-ImageNet justify our theory. To our best knowledge, this is the first work on the topology-aware generalization of vanilla D-SGD. Code is available at https://github.com/Raiden-Zhu/Generalization-of-DSGD.","authors":["Tongtian Zhu","Fengxiang He","Lan Zhang","Zhengyang Niu","Mingli Song","Dacheng Tao"],"url":"https://arxiv.org/abs/2206.12680"}
{"created":"2025-04-15","title":"Selective Query-guided Debiasing for Video Corpus Moment Retrieval","abstract":"Video moment retrieval (VMR) aims to localize target moments in untrimmed videos pertinent to a given textual query. Existing retrieval systems tend to rely on retrieval bias as a shortcut and thus, fail to sufficiently learn multi-modal interactions between query and video. This retrieval bias stems from learning frequent co-occurrence patterns between query and moments, which spuriously correlate objects (e.g., a pencil) referred in the query with moments (e.g., scene of writing with a pencil) where the objects frequently appear in the video, such that they converge into biased moment predictions. Although recent debiasing methods have focused on removing this retrieval bias, we argue that these biased predictions sometimes should be preserved because there are many queries where biased predictions are rather helpful. To conjugate this retrieval bias, we propose a Selective Query-guided Debiasing network (SQuiDNet), which incorporates the following two main properties: (1) Biased Moment Retrieval that intentionally uncovers the biased moments inherent in objects of the query and (2) Selective Query-guided Debiasing that performs selective debiasing guided by the meaning of the query. Our experimental results on three moment retrieval benchmarks (i.e., TVR, ActivityNet, DiDeMo) show the effectiveness of SQuiDNet and qualitative analysis shows improved interpretability.","authors":["Sunjae Yoon","Ji Woo Hong","Eunseop Yoon","Dahyun Kim","Junyeong Kim","Hee Suk Yoon","Chang D. Yoo"],"url":"https://arxiv.org/abs/2210.08714"}
{"created":"2025-04-15","title":"Ham2Pose: Animating Sign Language Notation into Pose Sequences","abstract":"Translating spoken languages into Sign languages is necessary for open communication between the hearing and hearing-impaired communities. To achieve this goal, we propose the first method for animating a text written in HamNoSys, a lexical Sign language notation, into signed pose sequences. As HamNoSys is universal, our proposed method offers a generic solution invariant to the target Sign language. Our method gradually generates pose predictions using transformer encoders that create meaningful representations of the text and poses while considering their spatial and temporal information. We use weak supervision for the training process and show that our method succeeds in learning from partial and inaccurate data. Additionally, we offer a new distance measurement for pose sequences, normalized Dynamic Time Warping (nDTW), based on DTW over normalized keypoints trajectories, and validate its correctness using AUTSL, a large-scale Sign language dataset. We show that it measures the distance between pose sequences more accurately than existing measurements and use it to assess the quality of our generated pose sequences. Code for the data pre-processing, the model, and the distance measurement is publicly released for future research.","authors":["Rotem Shalev-Arkushin","Amit Moryossef","Ohad Fried"],"url":"https://arxiv.org/abs/2211.13613"}
{"created":"2025-04-15","title":"When Brain-Computer Interfaces Meet the Metaverse: Landscape, Demonstrator, Trends, Challenges, and Concerns","abstract":"The metaverse has gained tremendous popularity in recent years, allowing the interconnection of users worldwide. However, current systems in metaverse scenarios, such as virtual reality glasses, offer a partial immersive experience. In this context, Brain-Computer Interfaces (BCIs) can introduce a revolution in the metaverse, although a study of the applicability and implications of BCIs in these virtual scenarios is required. Based on the absence of literature, this work reviews, for the first time, the applicability of BCIs in the metaverse, analyzing the current status of this integration based on different categories related to virtual worlds and the evolution of BCIs in these scenarios in the medium and long term. This work also proposes the design and implementation of a general framework that integrates BCIs with different data sources from sensors and actuators (e.g., VR glasses) based on a modular design to be easily extended. This manuscript also validates the framework in a demonstrator consisting of driving a car within a metaverse, using a BCI for neural data acquisition, a VR headset to provide realism, and a steering wheel and pedals. Four use cases (UCs) are selected, focusing on cognitive and emotional assessment of the driver, detection of drowsiness, and driver authentication while using the vehicle. Moreover, this manuscript offers an analysis of BCI trends in the metaverse, also identifying future challenges that the intersection of these technologies will face. Finally, it reviews the concerns that using BCIs in virtual world applications could generate according to different categories: accessibility, user inclusion, privacy, cybersecurity, physical safety, and ethics.","authors":["Sergio L\\'opez Bernal","Mario Quiles P\\'erez","Enrique Tom\\'as Mart\\'inez Beltr\\'an","Gregorio Mart\\'inez P\\'erez","Alberto Huertas Celdr\\'an"],"url":"https://arxiv.org/abs/2212.03169"}
{"created":"2025-04-15","title":"Fuzzing: On Benchmarking Outcome as a Function of Benchmark Properties","abstract":"Characteristics of a benchmarking setup clearly can have some impact on the benchmark outcome. In this paper, we explore two methodologies to quantify the impact of the specific properties on the benchmarking outcome. Our first methodology is the controlled experiment to identify a causal relationship between a single property in isolation and the benchmarking outcome. However, manipulating one property exactly may not always be practical or possible. Hence, our second methodology is randomization and non-parametric regression to identify the strength of the relationship between arbitrary benchmark properties (i.e., covariates) and outcome. Together, these two fundamental aspects of experimental design, control and randomization, can provide a comprehensive picture of the impact of various properties of the current benchmark on the fuzzer ranking. These analyses can be used to guide fuzzer developers towards areas of improvement in their tools and allow researchers to make more nuanced claims about fuzzer effectiveness. We instantiate each approach on a subset of properties suspected of impacting the relative effectiveness of fuzzers and quantify the effects of these properties on the evaluation outcome. In doing so, we identify multiple novel properties which can have statistically significant effect on the relative effectiveness of fuzzers.","authors":["Dylan Wolff","Marcel B\\\"ohme","Abhik Roychoudhury"],"url":"https://arxiv.org/abs/2212.09519"}
{"created":"2025-04-15","title":"Predict+Optimize Problem in Renewable Energy Scheduling","abstract":"Predict+Optimize frameworks integrate forecasting and optimization to address real-world challenges such as renewable energy scheduling, where variability and uncertainty are critical factors. This paper benchmarks solutions from the IEEE-CIS Technical Challenge on Predict+Optimize for Renewable Energy Scheduling, focusing on forecasting renewable production and demand and optimizing energy cost. The competition attracted 49 participants in total. The top-ranked method employed stochastic optimization using LightGBM ensembles, and achieved at least a 2% reduction in energy costs compared to deterministic approaches, demonstrating that the most accurate point forecast does not necessarily guarantee the best performance in downstream optimization. The published data and problem setting establish a benchmark for further research into integrated forecasting-optimization methods for energy systems, highlighting the importance of considering forecast uncertainty in optimization models to achieve cost-effective and reliable energy management. The novelty of this work lies in its comprehensive evaluation of Predict+Optimize methodologies applied to a real-world renewable energy scheduling problem, providing insights into the scalability, generalizability, and effectiveness of the proposed solutions. Potential applications extend beyond energy systems to any domain requiring integrated forecasting and optimization, such as supply chain management, transportation planning, and financial portfolio optimization.","authors":["Christoph Bergmeir","Frits de Nijs","Evgenii Genov","Abishek Sriramulu","Mahdi Abolghasemi","Richard Bean","John Betts","Quang Bui","Nam Trong Dinh","Nils Einecke","Rasul Esmaeilbeigi","Scott Ferraro","Priya Galketiya","Robert Glasgow","Rakshitha Godahewa","Yanfei Kang","Steffen Limmer","Luis Magdalena","Pablo Montero-Manso","Daniel Peralta","Yogesh Pipada Sunil Kumar","Alejandro Rosales-P\\'erez","Julian Ruddick","Akylas Stratigakos","Peter Stuckey","Guido Tack","Isaac Triguero","Rui Yuan"],"url":"https://arxiv.org/abs/2212.10723"}
{"created":"2025-04-15","title":"The Hermite-Taylor Correction Function Method for Embedded Boundary and Maxwell's Interface Problems","abstract":"We propose a novel Hermite-Taylor correction function method to handle embedded boundary and interface conditions for Maxwell's equations. The Hermite-Taylor method evolves the electromagnetic fields and their derivatives through order $m$ in each Cartesian coordinate. This makes the development of a systematic approach to enforce boundary and interface conditions difficult. Here we use the correction function method to update the numerical solution where the Hermite-Taylor method cannot be applied directly. Time derivatives of boundary and interface conditions, converted into spatial derivatives, are enforced to obtain a stable method and relax the time-step size restriction of the Hermite-Taylor correction function method. The proposed high-order method offers a flexible systematic approach to handle embedded boundary and interface problems, including problems with discontinuous solutions at the interface. This method is also easily adaptable to other first order hyperbolic systems.","authors":["Yann-Meing Law","Daniel Appel\\\"o","Thomas Hagstrom"],"url":"https://arxiv.org/abs/2301.01752"}
{"created":"2025-04-15","title":"Painting 3D Nature in 2D: View Synthesis of Natural Scenes from a Single Semantic Mask","abstract":"We introduce a novel approach that takes a single semantic mask as input to synthesize multi-view consistent color images of natural scenes, trained with a collection of single images from the Internet. Prior works on 3D-aware image synthesis either require multi-view supervision or learning category-level prior for specific classes of objects, which can hardly work for natural scenes. Our key idea to solve this challenging problem is to use a semantic field as the intermediate representation, which is easier to reconstruct from an input semantic mask and then translate to a radiance field with the assistance of off-the-shelf semantic image synthesis models. Experiments show that our method outperforms baseline methods and produces photorealistic, multi-view consistent videos of a variety of natural scenes.","authors":["Shangzan Zhang","Sida Peng","Tianrun Chen","Linzhan Mou","Haotong Lin","Kaicheng Yu","Yiyi Liao","Xiaowei Zhou"],"url":"https://arxiv.org/abs/2302.07224"}
{"created":"2025-04-15","title":"Isogeometric multi-patch $C^1$-mortar coupling for the biharmonic equation","abstract":"We propose an isogeometric mortar method for solving fourth-order elliptic problems. Specifically, our approach focuses on discretizing the biharmonic equation on $C^0$-conforming multi-patch domains, employing the mortar technique to weakly enforce $C^1$-continuity across interfaces. To guarantee discrete inf-sup stability, we introduce a carefully designed Lagrange multiplier space. In this formulation, the multipliers are splines with a degree reduced by two relative to the primal space and feature enhanced smoothness (or merged elements for splines with maximum smoothness) near the vertices. Within this framework, we establish optimal a priori error estimates and validate the theoretical results through numerical tests.","authors":["Andrea Benvenuti","Gabriele Loli","Giancarlo Sangalli","Thomas Takacs"],"url":"https://arxiv.org/abs/2303.07255"}
{"created":"2025-04-15","title":"Critical Relaxed Stable Matchings with Ties in the Many-to-Many Setting","abstract":"We study the many-to-many bipartite matching problem in the presence of preferences where ties, as well as lower quotas, may appear on both sides of the bipartition. The input is a bipartite graph $G=(A \\cup B, E)$, where each vertex in $A \\cup B$ has a positive upper quota and a non-negative lower quota denoting the maximum and minimum number of vertices that can be assigned to it from its neighborhood. Additionally, each vertex specifies a preference ordering, possibly containing ties, over its neighbors. A \\textit{critical} matching is a matching which fulfills vertex lower quotas to the maximum possible extent. We seek to compute a matching that is critical as well as optimal with respect to the preferences of vertices. Stability, a well-accepted notion of optimality in the presence of two-sided preferences, is generalized to weak-stability in the presence of ties. However, a matching that is critical as well as weakly stable may not exist. Popularity is another well-investigated notion of optimality for the two-sided preference model; however, in the presence of ties (even without lower quotas), a popular matching may not exist. We, therefore, consider the notion of relaxed stability, which was introduced and studied by Krishnaa, Limaye, Nasre, and Nimbhorkar~(JoCO 2023). We show that a critical matching that is relaxed stable always exists, although computing a maximum-size relaxed stable matching turns out to be NP-hard. Our main contribution is a $\\frac{3}{2}$-approximation algorithm for computing a maximum-size critical relaxed stable matching.","authors":["Meghana Nasre","Prajakta Nimbhorkar","Keshav Ranjan"],"url":"https://arxiv.org/abs/2303.12325"}
{"created":"2025-04-15","title":"Clo(o)k: Human-Time Interactions Through a Clock That \"Looks\"","abstract":"What if a clock could do more than tell time - what if it could look around? This project explores the conceptualization, design, and construction of a timepiece with visual perception capabilities, featuring three types of human-time interactions. Informal observations during a demonstration highlight its unique user experiences. https://www.zhuoyuelyu.com/clook","authors":["Zhuoyue Lyu"],"url":"https://arxiv.org/abs/2303.14557"}
{"created":"2025-04-15","title":"ATHEENA: A Toolflow for Hardware Early-Exit Network Automation","abstract":"The continued need for improvements in accuracy, throughput, and efficiency of Deep Neural Networks has resulted in a multitude of methods that make the most of custom architectures on FPGAs. These include the creation of hand-crafted networks and the use of quantization and pruning to reduce extraneous network parameters. However, with the potential of static solutions already well exploited, we propose to shift the focus to using the varying difficulty of individual data samples to further improve efficiency and reduce average compute for classification. Input-dependent computation allows for the network to make runtime decisions to finish a task early if the result meets a confidence threshold. Early-Exit network architectures have become an increasingly popular way to implement such behaviour in software.","authors":["Benjamin Biggs","Christos-Savvas Bouganis","George A. Constantinides"],"url":"https://arxiv.org/abs/2304.08400"}
{"created":"2025-04-15","title":"Extensional Taylor Expansion","abstract":"We introduce a calculus of extensional resource terms. These are resource terms \\`a la Ehrhard-Regnier, but in infinitely eta-long form. The calculus still retains a finite syntax and dynamics: in particular, we prove strong confluence and normalization.","authors":["Lison Blondeau-Patissier","Pierre Clairambault","Lionel Vaux Auclair"],"url":"https://arxiv.org/abs/2305.08489"}
{"created":"2025-04-15","title":"STLCCP: Efficient Convex Optimization-based Framework for Signal Temporal Logic Specifications","abstract":"Signal temporal logic (STL) is a powerful formalism for specifying various temporal properties in dynamical systems. However, existing methods, such as mixed-integer programming and nonlinear programming, often struggle to efficiently solve control problems with complex, long-horizon STL specifications. This study introduces \\textit{STLCCP}, a novel convex optimization-based framework that leverages key structural properties of STL: monotonicity of the robustness function, its hierarchical tree structure, and correspondence between convexity/concavity in optimizations and conjunctiveness/disjunctiveness in specifications. The framework begins with a structure-aware decomposition of STL formulas, transforming the problem into an equivalent difference of convex (DC) programs. This is then solved sequentially as a convex quadratic program using an improved version of the convex-concave procedure (CCP). To further enhance efficiency, we develop a smooth approximation of the robustness function using a function termed the \\textit{mellowmin} function, specifically tailored to the proposed framework. Numerical experiments on motion planning benchmarks demonstrate that \\textit{STLCCP} can efficiently handle complex scenarios over long horizons, outperforming existing methods.","authors":["Yoshinari Takayama","Kazumune Hashimoto","Toshiyuki Ohtsuka"],"url":"https://arxiv.org/abs/2305.09441"}
{"created":"2025-04-15","title":"Enhancing Smart Contract Security Analysis with Execution Property Graphs","abstract":"Smart contract vulnerabilities have led to significant financial losses, with their increasing complexity rendering outright prevention of hacks increasingly challenging. This trend highlights the crucial need for advanced forensic analysis and real-time intrusion detection, where dynamic analysis plays a key role in dissecting smart contract executions. Therefore, there is a pressing need for a unified and generic representation of smart contract executions, complemented by an efficient methodology that enables the modeling and identification of a broad spectrum of emerging attacks.","authors":["Kaihua Qin","Zhe Ye","Zhun Wang","Weilin Li","Liyi Zhou","Chao Zhang","Dawn Song","Arthur Gervais"],"url":"https://arxiv.org/abs/2305.14046"}
{"created":"2025-04-15","title":"BotArtist: Generic approach for bot detection in Twitter via semi-automatic machine learning pipeline","abstract":"Twitter, as one of the most popular social networks, provides a platform for communication and online discourse. Unfortunately, it has also become a target for bots and fake accounts, resulting in the spread of false information and manipulation. This paper introduces a semi-automatic machine learning pipeline (SAMLP) designed to address the challenges associated with machine learning model development. Through this pipeline, we develop a comprehensive bot detection model named BotArtist, based on user profile features. SAMLP leverages nine distinct publicly available datasets to train the BotArtist model. To assess BotArtist's performance against current state-of-the-art solutions, we evaluate 35 existing Twitter bot detection methods, each utilizing a diverse range of features. Our comparative evaluation of BotArtist and these existing methods, conducted across nine public datasets under standardized conditions, reveals that the proposed model outperforms existing solutions by almost 10% in terms of F1-score, achieving an average score of 83.19% and 68.5% over specific and general approaches, respectively. As a result of this research, we provide one of the largest labeled Twitter bot datasets. The dataset contains extracted features combined with BotArtist predictions for 10,929,533 Twitter user profiles, collected via Twitter API during the 2022 Russo-Ukrainian War over a 16-month period. This dataset was created based on [Shevtsov et al., 2022a] where the original authors share anonymized tweets discussing the Russo-Ukrainian war, totaling 127,275,386 tweets. The combination of the existing textual dataset and the provided labeled bot and human profiles will enable future development of more advanced bot detection large language models in the post-Twitter API era.","authors":["Alexander Shevtsov","Despoina Antonakaki","Ioannis Lamprou","Polyvios Pratikakis","Sotiris Ioannidis"],"url":"https://arxiv.org/abs/2306.00037"}
{"created":"2025-04-15","title":"Renormalized Graph Representations for Node Classification","abstract":"Graph neural networks process information on graphs represented at a given resolution scale. We analyze the effect of using different coarse-grained graph resolutions, obtained through the Laplacian renormalization group theory, on node classification tasks. At the theory's core is grouping nodes connected by significant information flow at a given time scale. Representations of the graph at different scales encode interaction information at different ranges. We specifically experiment using representations at the characteristic scale of the graph's mesoscopic structures. We provide the models with the original graph and the graph represented at the characteristic resolution scale and compare them to models that can only access the original graph. Our results showed that models with access to both the original graph and the characteristic scale graph can achieve statistically significant improvements in test accuracy.","authors":["Francesco Caso","Giovanni Trappolini","Andrea Bacciu","Pietro Li\\`o","Fabrizio Silvestri"],"url":"https://arxiv.org/abs/2306.00707"}
{"created":"2025-04-15","title":"Unlearnable Examples Give a False Sense of Data Privacy: Understanding and Relearning","abstract":"Unlearnable examples are proposed to prevent third parties from exploiting unauthorized data, which generates unlearnable examples by adding imperceptible perturbations to public publishing data. These unlearnable examples proficiently misdirect the model training process, leading it to focus on learning perturbation features while neglecting the semantic features of the image. In this paper, we make an in-depth analysis and observe that models can learn both image features and perturbation features of unlearnable examples at an early training stage, but are rapidly trapped in perturbation features learning since the shallow layers tend to learn on perturbation features and propagate harmful activations to deeper layers. Based on the observations, we propose Progressive Staged Training, a self-adaptive training framework specially designed to break unlearnable examples. The proposed framework effectively prevents models from becoming trapped in learning perturbation features. We evaluated our method on multiple model architectures over diverse datasets, e.g., CIFAR-10, CIFAR-100, and ImageNet-mini. Our method circumvents the unlearnability of all state-of-the-art methods in the literature, revealing that existing unlearnable examples give a false sense of privacy protection and provide a reliable baseline for further evaluation of unlearnable techniques.","authors":["Pucheng Dang","Xing Hu","Kaidi Xu","Jinhao Duan","Di Huang","Husheng Han","Rui Zhang","Zidong Du"],"url":"https://arxiv.org/abs/2306.02064"}
{"created":"2025-04-15","title":"Fractals from Regular Behaviours","abstract":"We forge connections between the theory of fractal sets obtained as attractors of iterated function systems and process calculi. To this end, we reinterpret Milner's expressions for processes as contraction operators on a complete metric space. When the space is, for example, the plane, the denotations of fixed point terms correspond to familiar fractal sets. We give a sound and complete axiomatization of fractal equivalence, the congruence on terms consisting of pairs that construct identical self-similar sets in all interpretations. We further make connections to labelled Markov chains and to invariant measures. In all of this work, we use important results from process calculi. For example, we use Rabinovich's completeness theorem for trace equivalence in our own completeness theorem. In addition to our results, we also raise many questions related to both fractals and process calculi.","authors":["Todd Schmid","Victoria Noquez","Lawrence S. Moss"],"url":"https://arxiv.org/abs/2306.03894"}
{"created":"2025-04-15","title":"Evaluating AI systems under uncertain ground truth: a case study in dermatology","abstract":"For safety, medical AI systems undergo thorough evaluations before deployment, validating their predictions against a ground truth which is assumed to be fixed and certain. However, this ground truth is often curated in the form of differential diagnoses. While a single differential diagnosis reflects the uncertainty in one expert assessment, multiple experts introduce another layer of uncertainty through disagreement. Both forms of uncertainty are ignored in standard evaluation which aggregates these differential diagnoses to a single label. In this paper, we show that ignoring uncertainty leads to overly optimistic estimates of model performance, therefore underestimating risk associated with particular diagnostic decisions. To this end, we propose a statistical aggregation approach, where we infer a distribution on probabilities of underlying medical condition candidates themselves, based on observed annotations. This formulation naturally accounts for the potential disagreements between different experts, as well as uncertainty stemming from individual differential diagnoses, capturing the entire ground truth uncertainty. Our approach boils down to generating multiple samples of medical condition probabilities, then evaluating and averaging performance metrics based on these sampled probabilities. In skin condition classification, we find that a large portion of the dataset exhibits significant ground truth uncertainty and standard evaluation severely over-estimates performance without providing uncertainty estimates. In contrast, our framework provides uncertainty estimates on common metrics of interest such as top-k accuracy and average overlap, showing that performance can change multiple percentage points. We conclude that, while assuming a crisp ground truth can be acceptable for many AI applications, a more nuanced evaluation protocol should be utilized in medical diagnosis.","authors":["David Stutz","Ali Taylan Cemgil","Abhijit Guha Roy","Tatiana Matejovicova","Melih Barsbey","Patricia Strachan","Mike Schaekermann","Jan Freyberg","Rajeev Rikhye","Beverly Freeman","Javier Perez Matos","Umesh Telang","Dale R. Webster","Yuan Liu","Greg S. Corrado","Yossi Matias","Pushmeet Kohli","Yun Liu","Arnaud Doucet","Alan Karthikesalingam"],"url":"https://arxiv.org/abs/2307.02191"}
{"created":"2025-04-15","title":"Loss Functions and Metrics in Deep Learning","abstract":"This paper presents a comprehensive review of loss functions and performance metrics in deep learning, highlighting key developments and practical insights across diverse application areas. We begin by outlining fundamental considerations in classic tasks such as regression and classification, then extend our analysis to specialized domains like computer vision and natural language processing including retrieval-augmented generation. In each setting, we systematically examine how different loss functions and evaluation metrics can be paired to address task-specific challenges such as class imbalance, outliers, and sequence-level optimization. Key contributions of this work include: (1) a unified framework for understanding how losses and metrics align with different learning objectives, (2) an in-depth discussion of multi-loss setups that balance competing goals, and (3) new insights into specialized metrics used to evaluate modern applications like retrieval-augmented generation, where faithfulness and context relevance are pivotal. Along the way, we highlight best practices for selecting or combining losses and metrics based on empirical behaviors and domain constraints. Finally, we identify open problems and promising directions, including the automation of loss-function search and the development of robust, interpretable evaluation measures for increasingly complex deep learning tasks. Our review aims to equip researchers and practitioners with clearer guidance in designing effective training pipelines and reliable model assessments for a wide spectrum of real-world applications.","authors":["Juan Terven","Diana M. Cordova-Esparza","Alfonso Ramirez-Pedraza","Edgar A. Chavez-Urbiola","Julio A. Romero-Gonzalez"],"url":"https://arxiv.org/abs/2307.02694"}
{"created":"2025-04-15","title":"Testing the Predictions of Surprisal Theory in 11 Languages","abstract":"A fundamental result in psycholinguistics is that less predictable words take a longer time to process. One theoretical explanation for this finding is Surprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word's predictability as its surprisal, i.e. its negative log-probability given a context. While evidence supporting the predictions of Surprisal Theory have been replicated widely, most have focused on a very narrow slice of data: native English speakers reading English texts. Indeed, no comprehensive multilingual analysis exists. We address this gap in the current literature by investigating the relationship between surprisal and reading times in eleven different languages, distributed across five language families. Deriving estimates from language models trained on monolingual and multilingual corpora, we test three predictions associated with surprisal theory: (i) whether surprisal is predictive of reading times; (ii) whether expected surprisal, i.e. contextual entropy, is predictive of reading times; (iii) and whether the linking function between surprisal and reading times is linear. We find that all three predictions are borne out crosslinguistically. By focusing on a more diverse set of languages, we argue that these results offer the most robust link to-date between information theory and incremental language processing across languages.","authors":["Ethan Gotlieb Wilcox","Tiago Pimentel","Clara Meister","Ryan Cotterell","Roger P. Levy"],"url":"https://arxiv.org/abs/2307.03667"}
{"created":"2025-04-15","title":"Dyn-E: Local Appearance Editing of Dynamic Neural Radiance Fields","abstract":"Recently, the editing of neural radiance fields (NeRFs) has gained considerable attention, but most prior works focus on static scenes while research on the appearance editing of dynamic scenes is relatively lacking. In this paper, we propose a novel framework to edit the local appearance of dynamic NeRFs by manipulating pixels in a single frame of training video. Specifically, to locally edit the appearance of dynamic NeRFs while preserving unedited regions, we introduce a local surface representation of the edited region, which can be inserted into and rendered along with the original NeRF and warped to arbitrary other frames through a learned invertible motion representation network. By employing our method, users without professional expertise can easily add desired content to the appearance of a dynamic scene. We extensively evaluate our approach on various scenes and show that our approach achieves spatially and temporally consistent editing results. Notably, our approach is versatile and applicable to different variants of dynamic NeRF representations.","authors":["Shangzan Zhang","Sida Peng","Yinji ShenTu","Qing Shuai","Tianrun Chen","Kaicheng Yu","Hujun Bao","Xiaowei Zhou"],"url":"https://arxiv.org/abs/2307.12909"}
{"created":"2025-04-15","title":"An Antithetic Multilevel Monte Carlo-Milstein Scheme for Stochastic Partial Differential Equations with non-commutative noise","abstract":"We present a novel multilevel Monte Carlo approach for estimating quantities of interest for stochastic partial differential equations (SPDEs). Drawing inspiration from [Giles and Szpruch: Antithetic multilevel Monte Carlo estimation for multi-dimensional SDEs without L\\'evy area simulation, Annals of Appl. Prob., 2014], we extend the antithetic Milstein scheme for finite-dimensional stochastic differential equations to Hilbert space-valued SPDEs. Our method has the advantages of both Euler and Milstein discretizations, as it is easy to implement and does not involve intractable L\\'evy area terms. Moreover, the antithetic correction in our method leads to the same variance decay in a MLMC algorithm as the standard Milstein method, resulting in significantly lower computational complexity than a corresponding MLMC Euler scheme. Our approach is applicable to a broader range of non-linear diffusion coefficients and does not require any commutative properties. The key component of our MLMC algorithm is a truncated Milstein-type time stepping scheme for SPDEs, which accelerates the rate of variance decay in the MLMC method when combined with an antithetic coupling on the fine scales. We combine the truncated Milstein scheme with appropriate spatial discretizations and noise approximations on all scales to obtain a fully discrete scheme and show that the antithetic coupling does not introduce an additional bias.","authors":["Abdul-Lateef Haji-Ali","Andreas Stein"],"url":"https://arxiv.org/abs/2307.14169"}
{"created":"2025-04-15","title":"PatchContrast: Self-Supervised Pre-training for 3D Object Detection","abstract":"Accurately detecting objects in the environment is a key challenge for autonomous vehicles. However, obtaining annotated data for detection is expensive and time-consuming. We introduce PatchContrast, a novel self-supervised point cloud pre-training framework for 3D object detection. We propose to utilize two levels of abstraction to learn discriminative representation from unlabeled data: proposal-level and patch-level. The proposal-level aims at localizing objects in relation to their surroundings, whereas the patch-level adds information about the internal connections between the object's components, hence distinguishing between different objects based on their individual components. We demonstrate how these levels can be integrated into self-supervised pre-training for various backbones to enhance the downstream 3D detection task. We show that our method outperforms existing state-of-the-art models on three commonly-used 3D detection datasets.","authors":["Oren Shrout","Ori Nizan","Yizhak Ben-Shabat","Ayellet Tal"],"url":"https://arxiv.org/abs/2308.06985"}
{"created":"2025-04-15","title":"Structure and computability of preimages in the Game of Life","abstract":"Conway's Game of Life is a two-dimensional cellular automaton. As a dynamical system, it is well-known to be computationally universal, i.e.\\ capable of simulating an arbitrary Turing machine. We show that in a sense taking a single backwards step of the Game of Life is a computationally universal process, by constructing patterns whose preimage computation encodes an arbitrary circuit-satisfaction problem, or, equivalently, any tiling problem. As a corollary, we obtain for example that the set of orphans is coNP-complete, exhibit a $6210 \\times 37800$-periodic configuration whose preimage is nonempty but contains no periodic configurations, and prove that the existence of a preimage for a periodic point is undecidable. Our constructions were obtained by a combination of computer searches and manual design.","authors":["Ville Salo","Ilkka T\\\"orm\\\"a"],"url":"https://arxiv.org/abs/2308.10198"}
{"created":"2025-04-15","title":"GraspGF: Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping","abstract":"The use of anthropomorphic robotic hands for assisting individuals in situations where human hands may be unavailable or unsuitable has gained significant importance. In this paper, we propose a novel task called human-assisting dexterous grasping that aims to train a policy for controlling a robotic hand's fingers to assist users in grasping objects. Unlike conventional dexterous grasping, this task presents a more complex challenge as the policy needs to adapt to diverse user intentions, in addition to the object's geometry. We address this challenge by proposing an approach consisting of two sub-modules: a hand-object-conditional grasping primitive called Grasping Gradient Field~(GraspGF), and a history-conditional residual policy. GraspGF learns `how' to grasp by estimating the gradient from a success grasping example set, while the residual policy determines `when' and at what speed the grasping action should be executed based on the trajectory history. Experimental results demonstrate the superiority of our proposed method compared to baselines, highlighting the user-awareness and practicality in real-world applications. The codes and demonstrations can be viewed at \"https://sites.google.com/view/graspgf\".","authors":["Tianhao Wu","Mingdong Wu","Jiyao Zhang","Yunchong Gan","Hao Dong"],"url":"https://arxiv.org/abs/2309.06038"}
{"created":"2025-04-15","title":"LD4MRec: Simplifying and Powering Diffusion Model for Multimedia Recommendation","abstract":"Multimedia recommendation aims to predict users' future behaviors based on observed behaviors and item content information. However, the inherent noise contained in observed behaviors easily leads to suboptimal recommendation performance. Recently, the diffusion model's ability to generate information from noise presents a promising solution to this issue, prompting us to explore its application in multimedia recommendation. Nonetheless, several challenges must be addressed: 1) The diffusion model requires simplification to meet the efficiency requirements of real-time recommender systems, 2) The generated behaviors must align with user preference. To address these challenges, we propose a Light Diffusion model for Multimedia Recommendation (LD4MRec). LD4MRec largely reduces computational complexity by employing a forward-free inference strategy, which directly predicts future behaviors from observed noisy behaviors. Meanwhile, to ensure the alignment between generated behaviors and user preference, we propose a novel Conditional neural Network (C-Net). C-Net achieves guided generation by leveraging two key signals, collaborative signals and personalized modality preference signals, thereby improving the semantic consistency between generated behaviors and user preference. Experiments conducted on three real-world datasets demonstrate the effectiveness of LD4MRec.","authors":["Jiarui Zhu","Jun Hou","Penghang Yu","Zhiyi Tan","Bing-Kun Bao"],"url":"https://arxiv.org/abs/2309.15363"}
{"created":"2025-04-15","title":"Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight Quantization of Large Language Models","abstract":"Large Language Models (LLMs) have recently demonstrated remarkable success across various tasks. However, efficiently serving LLMs has been a challenge due to the large memory bottleneck, specifically in small batch inference settings (e.g. mobile devices). Weight-only quantization can be a promising approach, but sub-4 bit quantization remains a challenge due to large-magnitude activation outliers. To mitigate the undesirable outlier effect, we first propose per-IC quantization, a simple yet effective method that creates quantization groups within each input channel (IC) rather than the conventional per-output-channel (per-OC). Our method is motivated by the observation that activation outliers affect the input dimension of the weight matrix, so similarly grouping the weights in the IC direction can isolate outliers within a group. We also find that activation outliers do not dictate quantization difficulty, and inherent weight sensitivities also exist. With per-IC quantization as a new outlier-friendly scheme, we propose Adaptive Dimensions (AdaDim), a versatile quantization framework that can adapt to various weight sensitivity patterns. We demonstrate the effectiveness of AdaDim by augmenting prior methods such as Round-To-Nearest and GPTQ, showing significant improvements across various language modeling benchmarks for both base (up to +4.7% on MMLU) and instruction-tuned (up to +10% on HumanEval) LLMs. Code is available at https://github.com/johnheo/adadim-llm","authors":["Jung Hwan Heo","Jeonghoon Kim","Beomseok Kwon","Byeongwook Kim","Se Jung Kwon","Dongsoo Lee"],"url":"https://arxiv.org/abs/2309.15531"}
{"created":"2025-04-15","title":"Randomly sparsified Richardson iteration: A dimension-independent sparse linear solver","abstract":"Recently, a class of algorithms combining classical fixed point iterations with repeated random sparsification of approximate solution vectors has been successfully applied to eigenproblems with matrices as large as $10^{108} \\times 10^{108}$. So far, a complete mathematical explanation for their success has proven elusive.","authors":["Jonathan Weare","Robert J. Webber"],"url":"https://arxiv.org/abs/2309.17270"}
{"created":"2025-04-15","title":"SCANet: Scene Complexity Aware Network for Weakly-Supervised Video Moment Retrieval","abstract":"Video moment retrieval aims to localize moments in video corresponding to a given language query. To avoid the expensive cost of annotating the temporal moments, weakly-supervised VMR (wsVMR) systems have been studied. For such systems, generating a number of proposals as moment candidates and then selecting the most appropriate proposal has been a popular approach. These proposals are assumed to contain many distinguishable scenes in a video as candidates. However, existing proposals of wsVMR systems do not respect the varying numbers of scenes in each video, where the proposals are heuristically determined irrespective of the video. We argue that the retrieval system should be able to counter the complexities caused by varying numbers of scenes in each video. To this end, we present a novel concept of a retrieval system referred to as Scene Complexity Aware Network (SCANet), which measures the `scene complexity' of multiple scenes in each video and generates adaptive proposals responding to variable complexities of scenes in each video. Experimental results on three retrieval benchmarks (i.e., Charades-STA, ActivityNet, TVR) achieve state-of-the-art performances and demonstrate the effectiveness of incorporating the scene complexity.","authors":["Sunjae Yoon","Gwanhyeong Koo","Dahyun Kim","Chang D. Yoo"],"url":"https://arxiv.org/abs/2310.05241"}
{"created":"2025-04-15","title":"Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class Manipulation Using DeepFool Algorithm","abstract":"The susceptibility of deep neural networks (DNNs) to adversarial attacks undermines their reliability across numerous applications, underscoring the necessity for an in-depth exploration of these vulnerabilities and the formulation of robust defense strategies. The DeepFool algorithm by Moosavi-Dezfooli et al. (2016) represents a pivotal step in identifying minimal perturbations required to induce misclassification of input images. Nonetheless, its generic methodology falls short in scenarios necessitating targeted interventions. Additionally, previous research studies have predominantly concentrated on the success rate of attacks without adequately addressing the consequential distortion of images, the maintenance of image quality, or the confidence threshold required for misclassification. To bridge these gaps, we introduce the Enhanced Targeted DeepFool (ET DeepFool) algorithm, an evolution of DeepFool that not only facilitates the specification of desired misclassification targets but also incorporates a configurable minimum confidence score. Our empirical investigations demonstrate the superiority of this refined approach in maintaining the integrity of images and minimizing perturbations across a variety of DNN architectures. Unlike previous iterations, such as the Targeted DeepFool by Gajjar et al. (2022), our method grants unparalleled control over the perturbation process, enabling precise manipulation of model responses. Preliminary outcomes reveal that certain models, including AlexNet and the advanced Vision Transformer, display commendable robustness to such manipulations. This discovery of varying levels of model robustness, as unveiled through our confidence level adjustments, could have far-reaching implications for the field of image recognition. Our code is available at https://github.com/FazleLabib/et_deepfool.","authors":["S. M. Fazle Rabby Labib","Joyanta Jyoti Mondal","Meem Arafat Manab","Xi Xiao","Sarfaraz Newaz"],"url":"https://arxiv.org/abs/2310.13019"}
{"created":"2025-04-15","title":"Can Offline Metrics Measure Explanation Goals? A Comparative Survey Analysis of Offline Explanation Metrics in Recommender Systems","abstract":"Explanations in a Recommender System (RS) provide reasons for recommendations to users and can enhance transparency, persuasiveness, engagement, and trust-known as explanation goals. Evaluating the effectiveness of explanation algorithms offline remains challenging due to subjectivity. Initially, we conducted a literature review on current offline metrics, revealing that algorithms are often assessed with anecdotal evidence, offering convincing examples, or with metrics that don't align with human perception. We investigated whether, in explanations connecting interacted and recommended items based on shared content, the selection of item attributes and interacted items affects explanation goals. Metrics measuring the diversity and popularity of attributes and the recency of item interactions were used to evaluate explanations from three state-of-the-art agnostic algorithms across six recommendation systems. These offline metrics were compared with results from an online user study. Our findings reveal a trade-off: transparency and trust relate to popular properties, while engagement and persuasiveness are linked to diversified properties. This study contributes to the development of more robust evaluation methods for explanation algorithms in recommender systems.","authors":["Andr\\'e Levi Zanon","Marcelo Garcia Manzato","Leonardo Rocha"],"url":"https://arxiv.org/abs/2310.14379"}
{"created":"2025-04-15","title":"Audio-Visual Speaker Tracking: Progress, Challenges, and Future Directions","abstract":"Audio-visual speaker tracking has drawn increasing attention over the past few years due to its academic values and wide applications. Audio and visual modalities can provide complementary information for localization and tracking. With audio and visual information, the Bayesian-based filter and deep learning-based methods can solve the problem of data association, audio-visual fusion and track management. In this paper, we conduct a comprehensive overview of audio-visual speaker tracking. To our knowledge, this is the first extensive survey over the past five years. We introduce the family of Bayesian filters and summarize the methods for obtaining audio-visual measurements. In addition, the existing trackers and their performance on the AV16.3 dataset are summarized. In the past few years, deep learning techniques have thrived, which also boost the development of audio-visual speaker tracking. The influence of deep learning techniques in terms of measurement extraction and state estimation is also discussed. Finally, we discuss the connections between audio-visual speaker tracking and other areas such as speech separation and distributed speaker tracking.","authors":["Jinzheng Zhao","Yong Xu","Xinyuan Qian","Davide Berghi","Peipei Wu","Meng Cui","Jianyuan Sun","Philip J. B. Jackson","Wenwu Wang"],"url":"https://arxiv.org/abs/2310.14778"}
{"created":"2025-04-15","title":"Toward 6G Native-AI Network: Foundation Model based Cloud-Edge-End Collaboration Framework","abstract":"Future wireless communication networks are in a position to move beyond data-centric, device-oriented connectivity and offer intelligent, immersive experiences based on multi-agent collaboration, especially in the context of the thriving development of pre-trained foundation models (PFM) and the evolving vision of 6G native artificial intelligence (AI). Therefore, redefining modes of collaboration between devices and agents, and constructing native intelligence libraries become critically important in 6G. In this paper, we analyze the challenges of achieving 6G native AI from the perspectives of data, AI models, and operational paradigm. Then, we propose a 6G native AI framework based on foundation models, provide an integration method for the expert knowledge, present the customization for two kinds of PFM, and outline a novel operational paradigm for the native AI framework. As a practical use case, we apply this framework for orchestration, achieving the maximum sum rate within a cell-free massive MIMO system, and presenting preliminary evaluation results. Finally, we outline research directions for achieving native AI in 6G.","authors":["Xiang Chen","Zhiheng Guo","Xijun Wang","Howard H. Yang","Chenyuan Feng","Shuangfeng Han","Xiaoyun Wang","Tony Q. S. Quek"],"url":"https://arxiv.org/abs/2310.17471"}
{"created":"2025-04-15","title":"VideoDreamer: Customized Multi-Subject Text-to-Video Generation with Disen-Mix Finetuning on Language-Video Foundation Models","abstract":"Customized text-to-video generation aims to generate text-guided videos with user-given subjects, which has gained increasing attention. However, existing works are primarily limited to single-subject oriented text-to-video generation, leaving the more challenging problem of customized multi-subject generation unexplored. In this paper, we fill this gap and propose a novel VideoDreamer framework, which can generate temporally consistent text-guided videos that faithfully preserve the visual features of the given multiple subjects. Specifically, VideoDreamer adopts the pretrained Stable Diffusion with temporal modules as its base video generator, taking the power of the text-to-image model to generate diversified content. The video generator is further customized for multi-subjects, which leverages the proposed Disen-Mix Finetuning and Human-in-the-Loop Re-finetuning strategy, to tackle the attribute binding problem of multi-subject generation. Additionally, we present a disentangled motion customization strategy to finetune the temporal modules so that we can generate videos with both customized subjects and motions. To evaluate the performance of customized multi-subject text-to-video generation, we introduce the MultiStudioBench benchmark. Extensive experiments demonstrate the remarkable ability of VideoDreamer to generate videos with new content such as new events and backgrounds, tailored to the customized multiple subjects.","authors":["Hong Chen","Xin Wang","Guanning Zeng","Yipeng Zhang","Yuwei Zhou","Feilin Han","Yaofei Wu","Wenwu Zhu"],"url":"https://arxiv.org/abs/2311.00990"}
{"created":"2025-04-15","title":"Affine Invariance in Continuous-Domain Convolutional Neural Networks","abstract":"The notion of group invariance helps neural networks in recognizing patterns and features under geometric transformations. Group convolutional neural networks enhance traditional convolutional neural networks by incorporating group-based geometric structures into their design. This research studies affine invariance on continuous-domain convolutional neural networks. Despite other research considering isometric invariance or similarity invariance, we focus on the full structure of affine transforms generated by the group of all invertible $2 \\times 2$ real matrices (generalized linear group $\\mathrm{GL}_2(\\mathbb{R})$). We introduce a new criterion to assess the invariance of two signals under affine transformations. The input image is embedded into the affine Lie group $G_2 = \\mathbb{R}^2 \\ltimes \\mathrm{GL}_2(\\mathbb{R})$ to facilitate group convolution operations that respect affine invariance. Then, we analyze the convolution of embedded signals over $G_2$. In sum, our research could eventually extend the scope of geometrical transformations that usual deep-learning pipelines can handle.","authors":["Ali Mohaddes","Johannes Lederer"],"url":"https://arxiv.org/abs/2311.09245"}
{"created":"2025-04-15","title":"Enhanced Fractional Fourier Transform (FRFT) scheme based on closed Newton-Cotes rules","abstract":"The paper improves the accuracy of the one-dimensional fractional Fourier transform (FRFT) by leveraging closed Newton-Cotes quadrature rules. Using the weights derived from the Composite Newton-Cotes rules of order QN, we demonstrate that the FRFT of a QN-long weighted sequence can be expressed as two composites of FRFTs. The first composite consists of an FRFT of a Q-long weighted sequence and an FRFT of an N-long sequence. Similarly, the second composite comprises an FRFT of an N-long weighted sequence and an FRFT of a Q-long sequence. Empirical results suggest that the composite FRFTs exhibit the commutative property and maintain consistency both algebraically and numerically. The proposed composite FRFT approach is applied to the inversion of Fourier and Laplace transforms, where it outperforms both the standard non-weighted FRFT and the Newton-Cotes integration method, though the improvement over the latter is less pronounced.","authors":["A. H. Nzokem"],"url":"https://arxiv.org/abs/2311.16379"}
{"created":"2025-04-15","title":"Enhancing autonomousnvehicle acceptance with age and education sensitive simulation interventions: An experimental trial","abstract":"The familiarity principle posits that acceptance increases with exposure, which has previously been shown with in vivo and simulated experiences with connected and autonomous vehicles (CAVs). We investigate the impact of a simulated video-based first-person drive on CAV acceptance, as well as the impact of information customization, with a particular focus on acceptance by older individuals and those with lower education. Findings from an online experiment with N=799 German residents reveal that the simulated experience improved acceptance across response variables such as intention to use and ease of use, particularly among older individuals. However, the opportunity to customize navigation information decreased acceptance of older individuals and those with university degrees and increased acceptance for younger individuals and those with lower educational levels.","authors":["Celina Kacperski","Roberto Ulloa","Jeremy Wautelet","Tobias Vogel","Florian Kutzner"],"url":"https://arxiv.org/abs/2311.16780"}
{"created":"2025-04-15","title":"PCDP-SGD: Improving the Convergence of Differentially Private SGD via Projection in Advance","abstract":"The paradigm of Differentially Private SGD~(DP-SGD) can provide a theoretical guarantee for training data in both centralized and federated settings. However, the utility degradation caused by DP-SGD limits its wide application in high-stakes tasks, such as medical image diagnosis. In addition to the necessary perturbation, the convergence issue is attributed to the information loss on the gradient clipping. In this work, we propose a general framework PCDP-SGD, which aims to compress redundant gradient norms and preserve more crucial top gradient components via projection operation before gradient clipping. Additionally, we extend PCDP-SGD as a fundamental component in differential privacy federated learning~(DPFL) for mitigating the data heterogeneous challenge and achieving efficient communication. We prove that pre-projection enhances the convergence of DP-SGD by reducing the dependence of clipping error and bias to a fraction of the top gradient eigenspace, and in theory, limits cross-client variance to improve the convergence under heterogeneous federation. Experimental results demonstrate that PCDP-SGD achieves higher accuracy compared with state-of-the-art DP-SGD variants in computer vision tasks. Moreover, PCDP-SGD outperforms current federated learning frameworks when DP is guaranteed on local training sets.","authors":["Haichao Sha (Renmin University of China)","Ruixuan Liu (Renmin University of China)","Yixuan Liu (Renmin University of China)","Hong Chen (Renmin University of China)"],"url":"https://arxiv.org/abs/2312.03792"}
{"created":"2025-04-15","title":"Multi-class Support Vector Machine with Maximizing Minimum Margin","abstract":"Support Vector Machine (SVM) stands out as a prominent machine learning technique widely applied in practical pattern recognition tasks. It achieves binary classification by maximizing the \"margin\", which represents the minimum distance between instances and the decision boundary. Although many efforts have been dedicated to expanding SVM for multi-class case through strategies such as one versus one and one versus the rest, satisfactory solutions remain to be developed. In this paper, we propose a novel method for multi-class SVM that incorporates pairwise class loss considerations and maximizes the minimum margin. Adhering to this concept, we embrace a new formulation that imparts heightened flexibility to multi-class SVM. Furthermore, the correlations between the proposed method and multiple forms of multi-class SVM are analyzed. The proposed regularizer, akin to the concept of \"margin\", can serve as a seamless enhancement over the softmax in deep learning, providing guidance for network parameter learning. Empirical evaluations demonstrate the effectiveness and superiority of our proposed method over existing multi-classification methods.Code is available at https://github.com/zz-haooo/M3SVM.","authors":["Feiping Nie","Zhezheng Hao","Rong Wang"],"url":"https://arxiv.org/abs/2312.06578"}
{"created":"2025-04-15","title":"Nonlinear Expectation Inference for Efficient Uncertainty Quantification and History Matching of Transient Darcy Flows in Porous Media with Random Parameters Under Distribution Uncertainty","abstract":"The uncertainty quantification of Darcy flows using history matching is important for the evaluation and prediction of subsurface reservoir performance. Conventional methods aim to obtain the maximum a posterior or maximum likelihood estimate (MLE) using gradient-based, heuristic or ensemble-based methods. These methods can be computationally expensive for high-dimensional problems since forward simulation needs to be run iteratively as physical parameters are updated. In the current study, we propose a nonlinear expectation inference (NEI) method for efficient history matching and uncertainty quantification accounting for distribution or Knightian uncertainty. Forward simulation runs are conducted on prior realisations once, and then a range of expectations are computed in the data space based on subsets of prior realisations with no repetitive forward runs required. In NEI, no prior probability distribution for data is assumed. Instead, the probability distribution is assumed to be uncertain with prior and posterior uncertainty quantified by nonlinear expectations. The inferred result of NEI is the posterior subsets on which the expected flow rates cover the varying interval of observation. The accuracy and efficiency of the new method are validated using single- and two-phase Darcy flows in 2D and 3D heterogeneous reservoirs.","authors":["Zhao Zhang","Xinpeng Li","Menghan Li","Piyang Liu","Xia Yan","Kai Zhang"],"url":"https://arxiv.org/abs/2312.06923"}
{"created":"2025-04-15","title":"HEAR: Hearing Enhanced Audio Response for Video-grounded Dialogue","abstract":"Video-grounded Dialogue (VGD) aims to answer questions regarding a given multi-modal input comprising video, audio, and dialogue history. Although there have been numerous efforts in developing VGD systems to improve the quality of their responses, existing systems are competent only to incorporate the information in the video and text and tend to struggle in extracting the necessary information from the audio when generating appropriate responses to the question. The VGD system seems to be deaf, and thus, we coin this symptom of current systems' ignoring audio data as a deaf response. To overcome the deaf response problem, Hearing Enhanced Audio Response (HEAR) framework is proposed to perform sensible listening by selectively attending to audio whenever the question requires it. The HEAR framework enhances the accuracy and audibility of VGD systems in a model-agnostic manner. HEAR is validated on VGD datasets (i.e., AVSD@DSTC7 and AVSD@DSTC8) and shows effectiveness with various VGD systems.","authors":["Sunjae Yoon","Dahyun Kim","Eunseop Yoon","Hee Suk Yoon","Junyeong Kim","Chnag D. Yoo"],"url":"https://arxiv.org/abs/2312.09736"}
{"created":"2025-04-15","title":"SplatMesh: Interactive 3D Segmentation and Editing Using Mesh-Based Gaussian Splatting","abstract":"A key challenge in fine-grained 3D-based interactive editing is the absence of an efficient representation that balances diverse modifications with high-quality view synthesis under a given memory constraint. While 3D meshes provide robustness for various modifications, they often yield lower-quality view synthesis compared to 3D Gaussian Splatting, which, in turn, suffers from instability during extensive editing. A straightforward combination of these two representations results in suboptimal performance and fails to meet memory constraints. In this paper, we introduce SplatMesh, a novel fine-grained interactive 3D segmentation and editing algorithm that integrates 3D Gaussian Splat with a precomputed mesh and could adjust the memory request based on the requirement. Specifically, given a mesh, \\method simplifies it while considering both color and shape, ensuring it meets memory constraints. Then, SplatMesh aligns Gaussian splats with the simplified mesh by treating each triangle as a new reference point. By segmenting and editing the simplified mesh, we can effectively edit the Gaussian splats as well, which will lead to extensive experiments on real and synthetic datasets, coupled with illustrative visual examples, highlighting the superiority of our approach in terms of representation quality and editing performance. Code of our paper can be found here: https://github.com/kaichen-z/SplatMesh.","authors":["Kaichen Zhou","Lanqing Hong","Xinhai Chang","Yingji Zhong","Enze Xie","Hao Dong","Zhihao Li","Yongxin Yang","Zhenguo Li","Wei Zhang"],"url":"https://arxiv.org/abs/2312.15856"}
{"created":"2025-04-15","title":"Beyond Chinchilla-Optimal: Accounting for Inference in Language Model Scaling Laws","abstract":"Large language model (LLM) scaling laws are empirical formulas that estimate changes in model quality as a result of increasing parameter count and training data. However, these formulas, including the popular Deepmind Chinchilla scaling laws, neglect to include the cost of inference. We modify the Chinchilla scaling laws to calculate the optimal LLM parameter count and pre-training data size to train and deploy a model of a given quality and inference demand. We conduct our analysis both in terms of a compute budget and real-world costs and find that LLM researchers expecting reasonably large inference demand (~1B requests) should train models smaller and longer than Chinchilla-optimal. Furthermore, we train 47 models of varying sizes and parameter counts to validate our formula and find that model quality continues to improve as we scale tokens per parameter to extreme ranges (up to 10,000). Finally, we ablate the procedure used to fit the Chinchilla scaling law coefficients and find that developing scaling laws only from data collected at typical token/parameter ratios overestimates the impact of additional tokens at these extreme ranges.","authors":["Nikhil Sardana","Jacob Portes","Sasha Doubov","Jonathan Frankle"],"url":"https://arxiv.org/abs/2401.00448"}
{"created":"2025-04-15","title":"BANG: Billion-Scale Approximate Nearest Neighbor Search using a Single GPU","abstract":"Approximate Nearest Neighbour Search (ANNS) is a subroutine in algorithms routinely employed in information retrieval, pattern recognition, data mining, image processing, and beyond. Recent works have established that graph-based ANNS algorithms are practically more efficient than the other methods proposed in the literature. The growing volume and dimensionality of data necessitates designing scalable techniques for ANNS. To this end, the prior art has explored parallelising graph-based ANNS on GPU, leveraging its massive parallelism. The current state-of-the-art GPU-based ANNS algorithms either (i) require both the dataset and the generated graph index to reside entirely in the GPU memory, or (ii) they partition the dataset into small independent shards, each of which can fit in GPU memory, and perform the search on these shards on the GPU. While the first approach fails to handle large datasets due to the limited memory available on the GPU, the latter delivers poor performance on large datasets due to high data traffic over the low-bandwidth PCIe interconnect.","authors":["Karthik V.","Saim Khan","Somesh Singh","Harsha Vardhan Simhadri","Jyothi Vedurada"],"url":"https://arxiv.org/abs/2401.11324"}
{"created":"2025-04-15","title":"Embedding Ontologies via Incorporating Extensional and Intensional Knowledge","abstract":"Ontologies contain rich knowledge within domain, which can be divided into two categories, namely extensional knowledge and intensional knowledge. Extensional knowledge provides information about the concrete instances that belong to specific concepts in the ontology, while intensional knowledge details inherent properties, characteristics, and semantic associations among concepts. However, existing ontology embedding approaches fail to take both extensional knowledge and intensional knowledge into fine consideration simultaneously. In this paper, we propose a novel ontology embedding approach named EIKE (Extensional and Intensional Knowledge Embedding) by representing ontologies in two spaces, called extensional space and intensional space. EIKE presents a unified framework for embedding instances, concepts and their relations in an ontology, applying a geometry-based method to model extensional knowledge and a pretrained language model to model intensional knowledge, which can capture both structure information and textual information. Experimental results show that EIKE significantly outperforms state-of-the-art methods in three datasets for both triple classification and link prediction, indicating that EIKE provides a more comprehensive and representative perspective of the domain.","authors":["Keyu Wang","Guilin Qi","Jiaoyan Chen","Yi Huang","Tianxing Wu"],"url":"https://arxiv.org/abs/2402.01677"}
{"created":"2025-04-15","title":"Unveiling the Deficiencies of Pre-trained Text-and-Layout Models in Real-world Visually-rich Document Information Extraction","abstract":"Recently developed pre-trained text-and-layout models (PTLMs) have shown remarkable success in multiple information extraction tasks on visually-rich documents (VrDs). However, despite achieving extremely high performance on benchmarks, their real-world performance falls short of expectations. Owing to this issue, we investigate the prevailing evaluation pipeline to reveal that: (1) The inadequate annotations within benchmark datasets introduce spurious correlations between task inputs and labels, which would lead to overly-optimistic estimation of model performance. (2) The evaluation solely relies on the performance on benchmarks and is insufficient to comprehensively explore the capabilities of methods in real-world scenarios. These problems impede the prevailing evaluation pipeline from reflecting the real-world performance of methods, misleading the design choices of method optimization. In this work, we introduce EC-FUNSD, an entity-centric dataset crafted for benchmarking information extraction from visually-rich documents. This dataset contains diverse layouts and high-quality annotations. Additionally, this dataset disentangles the falsely-coupled segment and entity annotations that arises from the block-level annotation of FUNSD. Using the proposed dataset, we evaluate the real-world information extraction capabilities of PTLMs from multiple aspects, including their absolute performance, as well as generalization, robustness and fairness. The results indicate that prevalent PTLMs do not perform as well as anticipated in real-world information extraction scenarios. We hope that our study can inspire reflection on the directions of PTLM development.","authors":["Chong Zhang","Yixi Zhao","Yulu Xie","Chenshu Yuan","Yi Tu","Ya Guo","Mingxu Chai","Ziyu Shen","Yue Zhang","Qi Zhang"],"url":"https://arxiv.org/abs/2402.02379"}
{"created":"2025-04-15","title":"Secret Collusion among Generative AI Agents: Multi-Agent Deception via Steganography","abstract":"Recent capability increases in large language models (LLMs) open up applications in which groups of communicating generative AI agents solve joint tasks. This poses privacy and security challenges concerning the unauthorised sharing of information, or other unwanted forms of agent coordination. Modern steganographic techniques could render such dynamics hard to detect. In this paper, we comprehensively formalise the problem of secret collusion in systems of generative AI agents by drawing on relevant concepts from both AI and security literature. We study incentives for the use of steganography, and propose a variety of mitigation measures. Our investigations result in a model evaluation framework that systematically tests capabilities required for various forms of secret collusion. We provide extensive empirical results across a range of contemporary LLMs. While the steganographic capabilities of current models remain limited, GPT-4 displays a capability jump suggesting the need for continuous monitoring of steganographic frontier model capabilities. We conclude by laying out a comprehensive research program to mitigate future risks of collusion between generative AI models.","authors":["Sumeet Ramesh Motwani","Mikhail Baranchuk","Martin Strohmeier","Vijay Bolina","Philip H. S. Torr","Lewis Hammond","Christian Schroeder de Witt"],"url":"https://arxiv.org/abs/2402.07510"}
{"created":"2025-04-15","title":"Plato: Plan to Efficiently Decode for Large Language Model Inference","abstract":"Large language models (LLMs) have achieved remarkable success in natural language tasks, but their inference incurs substantial computational and memory overhead. To improve efficiency, parallel decoding methods like Skeleton-of-Thought (SoT) decompose prompts into sub-problems for concurrent processing. However, these methods significantly compromise answer quality by treating semantically linked sub-problems as independent. We propose Plato, a novel approach that co-designs algorithms and systems for semantic-aware parallel decoding. Plato leverages LLMs to organize sub-problems into a dependency graph based on logical and causal relationships, enabling concurrent decoding of non-dependent nodes while preserving answer coherence and quality. To further enhance efficiency, Plato pipelines planning and node decoding stages, implements a global context cache, and carefully structures node inference prompts to maximize key-value cache reuse and minimize overhead. Our evaluations show that Plato improves throughput by 68% over autoregressive decoding while achieving a 40% net win rate in answer quality. Compared to SoT, Plato demonstrates a remarkable 90% quality net-win rate. Ablation studies reveal that our pipeline design improves speedup by 29%, while our KV cache reuse optimization reduces overhead by 75%.","authors":["Shuowei Jin","Xueshen Liu","Yongji Wu","Haizhong Zheng","Qingzhao Zhang","Atul Prakash","Matthew Lentz","Danyang Zhuo","Feng Qian","Z. Morley Mao"],"url":"https://arxiv.org/abs/2402.12280"}
{"created":"2025-04-15","title":"Multi-view Intent Learning and Alignment with Large Language Models for Session-based Recommendation","abstract":"Session-based recommendation (SBR) methods often rely on user behavior data, which can struggle with the sparsity of session data, limiting performance. Researchers have identified that beyond behavioral signals, rich semantic information in item descriptions is crucial for capturing hidden user intent. While large language models (LLMs) offer new ways to leverage this semantic data, the challenges of session anonymity, short-sequence nature, and high LLM training costs have hindered the development of a lightweight, efficient LLM framework for SBR.","authors":["Shutong Qiao","Wei Zhou","Junhao Wen","Chen Gao","Qun Luo","Peixuan Chen","Yong Li"],"url":"https://arxiv.org/abs/2402.13840"}
{"created":"2025-04-15","title":"On Schr\\\"odingerization based quantum algorithms for linear dynamical systems with inhomogeneous terms","abstract":"We analyze the Schr\\\"odingerization method for quantum simulation of a general class of non-unitary dynamics with inhomogeneous source terms. The Schr\\\"odingerization technique, introduced in [31], transforms any linear ordinary and partial differential equations with non-unitary dynamics into a system under unitary dynamics via a warped phase transition that maps the equations into a higher dimension, making them suitable for quantum simulation. This technique can also be applied to these equations with inhomogeneous terms modeling source or forcing terms, or boundary and interface conditions, and discrete dynamical systems such as iterative methods in numerical linear algebra, through extra equations in the system. Difficulty arises with the presence of inhomogeneous terms since they can change the stability of the original system. In this paper, we systematically study-both theoretically and numerically-the important issue of recovering the original variables from the Schr\\\"odingerized equations, even when the evolution operator contains unstable modes. We show that, even with unstable modes, one can still construct a stable scheme; however, to recover the original variable, one needs to use suitable data in the extended space. We analyze and compare both the discrete and continuous Fourier transforms used in the extended dimension and derive corresponding error estimates, which allow one to use the more appropriate transform for specific equations. We also provide a smoother initialization for the Schr\\\"odingerized system to gain higher-order accuracy in the extended space. We homogenize the inhomogeneous terms with a stretch transformation, making it easier to recover the original variable. Our recovery technique also provides a simple and generic framework to solve general ill-posed problems in a computationally stable way.","authors":["Shi Jin","Nana Liu","Chuwen Ma"],"url":"https://arxiv.org/abs/2402.14696"}
{"created":"2025-04-15","title":"COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling","abstract":"The therapeutic working alliance is a critical predictor of psychotherapy success. Traditionally, working alliance assessment relies on questionnaires completed by both therapists and patients. In this paper, we present COMPASS, a novel framework to directly infer the therapeutic working alliance from the natural language used in psychotherapy sessions. Our approach leverages advanced large language models (LLMs) to analyze session transcripts and map them to distributed representations. These representations capture the semantic similarities between the dialogues and psychometric instruments, such as the Working Alliance Inventory. Analyzing a dataset of over 950 sessions spanning diverse psychiatric conditions -- including anxiety (N=498), depression (N=377), schizophrenia (N=71), and suicidal tendencies (N=12) -- collected between 1970 and 2012, we demonstrate the effectiveness of our method in providing fine-grained mapping of patient-therapist alignment trajectories, offering interpretable insights for clinical practice, and identifying emerging patterns related to the condition being treated. By employing various deep learning-based topic modeling techniques in combination with prompting generative language models, we analyze the topical characteristics of different psychiatric conditions and how these topics evolve during each turn of the conversation. This integrated framework enhances the understanding of therapeutic interactions, enables timely feedback for therapists on the quality of therapeutic relationships, and provides clear, actionable insights to improve the effectiveness of psychotherapy.","authors":["Baihan Lin","Djallel Bouneffouf","Yulia Landa","Rachel Jespersen","Cheryl Corcoran","Guillermo Cecchi"],"url":"https://arxiv.org/abs/2402.14701"}
{"created":"2025-04-15","title":"Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses","abstract":"Mitigating hallucination issues is a key challenge that must be overcome to reliably deploy large language models (LLMs) in real-world scenarios. Recently, various methods have been proposed to detect and revise factual errors in LLM-generated texts, in order to reduce hallucination. In this paper, we propose Re-Ex, a method for post-editing LLM-generated responses. Re-Ex introduces a novel reasoning step dubbed as the factual error explanation step. Re-Ex revises the initial response of LLMs using 3-steps : first, external tools are used to retrieve the evidences of the factual errors in the initial LLM response; next, LLM is instructed to explain the problematic parts of the response based on the gathered evidence; finally, LLM revises the initial response using the explanations provided in the previous step. In addition to the explanation step, Re-Ex also incorporates new prompting techniques to reduce the token count and inference time required for the response revision process. Compared with existing methods including FacTool, CoVE, and RARR, Re-Ex provides better detection and revision performance with less inference time and fewer tokens in multiple benchmarks.","authors":["Juyeon Kim","Jeongeun Lee","Yoonho Chang","Chanyeol Choi","Junseong Kim","Jy-yong Sohn"],"url":"https://arxiv.org/abs/2402.17097"}
{"created":"2025-04-15","title":"PhD: A ChatGPT-Prompted Visual hallucination Evaluation Dataset","abstract":"Multimodal Large Language Models (MLLMs) hallucinate, resulting in an emerging topic of visual hallucination evaluation (VHE). This paper contributes a ChatGPT-Prompted visual hallucination evaluation Dataset (PhD) for objective VHE at a large scale. The essence of VHE is to ask an MLLM questions about specific images to assess its susceptibility to hallucination. Depending on what to ask (objects, attributes, sentiment, etc.) and how the questions are asked, we structure PhD along two dimensions, i.e. task and mode. Five visual recognition tasks, ranging from low-level (object / attribute recognition) to middle-level (sentiment / position recognition and counting), are considered. Besides a normal visual QA mode, which we term PhD-base, PhD also asks questions with specious context (PhD-sec) or with incorrect context ({PhD-icc), or with AI-generated counter common sense images (PhD-ccs). We construct PhD by a ChatGPT-assisted semi-automated pipeline, encompassing four pivotal modules: task-specific hallucinatory item (hitem) selection, hitem-embedded question generation, specious / incorrect context generation, and counter-common-sense (CCS) image generation. With over 14k daily images, 750 CCS images and 102k VQA triplets in total, PhD reveals considerable variability in MLLMs' performance across various modes and tasks, offering valuable insights into the nature of hallucination. As such, PhD stands as a potent tool not only for VHE but may also play a significant role in the refinement of MLLMs.","authors":["Jiazhen Liu","Yuhan Fu","Ruobing Xie","Runquan Xie","Xingwu Sun","Fengzong Lian","Zhanhui Kang","Xirong Li"],"url":"https://arxiv.org/abs/2403.11116"}
{"created":"2025-04-15","title":"Learning Neural Differential Algebraic Equations via Operator Splitting","abstract":"Differential-Algebraic Equations (DAEs) describe the temporal evolution of systems that obey both differential and algebraic constraints. Of particular interest are systems that contain implicit relationships between their components, such as conservation relationships. Here, we present an Operator Splitting (OS) numerical integration scheme for learning unknown components of Differential-Algebraic Equations from time-series data. This methodology is built upon the concept of the Universal Differential Equation; that is, a model constructed as a system of Neural Ordinary Differential Equations informed by theory from particular science domains. In this work, we show that the proposed OS-based time-stepping scheme is suitable for relevant system-theoretic data-driven modeling tasks. Presented examples include (i) the inverse problem of tank-manifold dynamics and (ii) discrepancy modeling of a network of pumps, tanks, and pipes. Our experiments demonstrate the proposed method's robustness to noise and extrapolation ability to (i) learn the behaviors of the system components and their interaction physics and (ii) disambiguate between data trends and mechanistic relationships contained in the system.","authors":["James Koch","Madelyn Shapiro","Himanshu Sharma","Draguna Vrabie","Jan Drgona"],"url":"https://arxiv.org/abs/2403.12938"}
{"created":"2025-04-15","title":"Machine Learning and Transformers for Thyroid Carcinoma Diagnosis: A Review","abstract":"The growing interest in developing smart diagnostic systems to help medical experts process extensive data for treating incurable diseases has been notable. In particular, the challenge of identifying thyroid cancer (TC) has seen progress with the use of machine learning (ML) and big data analysis, incorporating Transformers to evaluate TC prognosis and determine the risk of malignancy in individuals. This review article presents a summary of various studies on AI-based approaches, especially those employing Transformers, for diagnosing TC. It introduces a new categorization system for these methods based on artificial intelligence (AI) algorithms, the goals of the framework, and the computing environments used. Additionally, it scrutinizes and contrasts the available TC datasets by their features. The paper highlights the importance of AI instruments in aiding the diagnosis and treatment of TC through supervised, unsupervised, or mixed approaches, with a special focus on the ongoing importance of Transformers and large language models (LLMs) in medical diagnostics and disease management. It further discusses the progress made and the continuing obstacles in this area. Lastly, it explores future directions and focuses within this research field.","authors":["Yassine Habchi","Hamza Kheddar","Yassine Himeur","Mohamed Chahine Ghanem"],"url":"https://arxiv.org/abs/2403.13843"}
{"created":"2025-04-15","title":"Hatred Stems from Ignorance! Distillation of the Persuasion Modes in Countering Conversational Hate Speech","abstract":"Examining the factors that the counterspeech uses are at the core of understanding the optimal methods for confronting hate speech online. Various studies have assessed the emotional base factors used in counter speech, such as emotional empathy, offensiveness, and hostility. To better understand the counterspeech used in conversations, this study distills persuasion modes into reason, emotion, and credibility and evaluates their use in two types of conversation interactions: closed (multi-turn) and open (single-turn) concerning racism, sexism, and religious bigotry. The evaluation covers the distinct behaviors seen with human-sourced as opposed to machine-generated counterspeech. It also assesses the interplay between the stance taken and the mode of persuasion seen in the counterspeech.","authors":["Ghadi Alyahya","Abeer Aldayel"],"url":"https://arxiv.org/abs/2403.15449"}
{"created":"2025-04-15","title":"Camera-aware Label Refinement for Unsupervised Person Re-identification","abstract":"Unsupervised person re-identification aims to retrieve images of a specified person without identity labels. Many recent unsupervised Re-ID approaches adopt clustering-based methods to measure cross-camera feature similarity to roughly divide images into clusters. They ignore the feature distribution discrepancy induced by camera domain gap, resulting in the unavoidable performance degradation. Camera information is usually available, and the feature distribution in the single camera usually focuses more on the appearance of the individual and has less intra-identity variance. Inspired by the observation, we introduce a \\textbf{C}amera-\\textbf{A}ware \\textbf{L}abel \\textbf{R}efinement~(CALR) framework that reduces camera discrepancy by clustering intra-camera similarity. Specifically, we employ intra-camera training to obtain reliable local pseudo labels within each camera, and then refine global labels generated by inter-camera clustering and train the discriminative model using more reliable global pseudo labels in a self-paced manner. Meanwhile, we develop a camera-alignment module to align feature distributions under different cameras, which could help deal with the camera variance further. Extensive experiments validate the superiority of our proposed method over state-of-the-art approaches. The code is accessible at https://github.com/leeBooMla/CALR.","authors":["Pengna Li","Kangyi Wu","Wenli Huang","Sanping Zhou","Jinjun Wang"],"url":"https://arxiv.org/abs/2403.16450"}
{"created":"2025-04-15","title":"Real-World Evaluation of two Cooperative Intersection Management Approaches","abstract":"Cooperative maneuver planning promises to significantly improve traffic efficiency at unsignalized intersections by leveraging connected automated vehicles. Previous works on this topic have been mostly developed for completely automated traffic in a simple simulated environment. In contrast, our previously introduced planning approaches are specifically designed to handle real-world mixed traffic. The two methods are based on multi-scenario prediction and graph-based reinforcement learning, respectively. This is the first study to perform evaluations in a novel mixed traffic simulation framework as well as real-world drives with prototype connected automated vehicles in public traffic. The simulation features the same connected automated driving software stack as deployed on one of the automated vehicles. Our quantitative evaluations show that cooperative maneuver planning achieves a substantial reduction in crossing times and the number of stops. In a realistic environment with few automated vehicles, there are noticeable efficiency gains with only slightly increasing criticality metrics.","authors":["Marvin Klimke","Max Bastian Mertens","Benjamin V\\\"olz","Michael Buchholz"],"url":"https://arxiv.org/abs/2403.16478"}
{"created":"2025-04-15","title":"First-order (coarse) correlated equilibria in non-concave games","abstract":"We investigate first-order notions of correlated equilibria; distributions of actions for smooth, potentially non-concave games such that players do not incur any regret against small modifications to their strategies along a set of continuous vector fields. We define two such notions, based on local deviations and on stationarity of the distribution, and identify the notion of coarseness as the setting where the strategy modifications are prescribed by gradient fields. For coarse equilibria, we prove that online (projected) gradient decent has a universal approximation property for both variants of equilibrium. In the non-coarse setting, we inspect the problem of computing first-order correlated equilibria through the lens of both recent work based on the framework of ``fixed points in expectation'', and also via the classical framework of Lagrangian hedging, with the goal of identifying tractable instances with additional convergence guarantees. Finally, we study the primal-dual framework to our notion of first-order equilibria. For coarse equilibria defined by a family of functions, we find that a dual bound on the worst-case expectation of a performance metric takes the form of a generalised Lyapunov function for the dynamics of the game. Specifically, usual primal-dual price of anarchy analysis for coarse correlated equilibria as well as the smoothness framework of Roughgarden are both equivalent to a problem of general Lyapunov function estimation. For non-coarse equilibria, we instead observe a vector field fit problem for the gradient dynamics of the game. These follow from containment results in normal form games, and our work overall provides insights on how to tighten equilibrium analysis for gradient-based learning dynamics, as well as delineating notions of first-order equilibrium that may rule out cycling behaviour versus those that do not.","authors":["Mete \\c{S}eref Ahunbay"],"url":"https://arxiv.org/abs/2403.18174"}
{"created":"2025-04-15","title":"Measuring changes in polarisation using Singular Value Decomposition of network graphs","abstract":"In this paper we present new methods of measuring polarisation in social networks. We use Random Dot Product Graphs to embed social networks in metric spaces. Singular Value Decomposition of this social network then provider an embedded dimensionality which corresponds to the number of uncorrelated dimensions in the network. A decrease in the optimal dimensionality for the embedding of the network graph means that the dimensions in the network are becoming more correlated, and therefore the network is becoming more polarised.","authors":["Sage Anastasi","Giulio Dalla Riva"],"url":"https://arxiv.org/abs/2403.18191"}
{"created":"2025-04-15","title":"Discrete Poincar\\'e and Trace Inequalities for the Hybridizable Discontinuous Galerkin Method","abstract":"In this paper, we derive discrete Poincar\\'e and trace inequalities for the hybridizable discontinuous Galerkin (HDG) method. We employ the Crouzeix-Raviart space as a bridge, connecting classical discrete functional tools from Brenner's foundational work \\cite{brenner2003poincare} with hybridizable finite element spaces comprised of piecewise polynomial functions defined both within the element interiors and on the mesh skeleton. This approach yields custom-tailored inequalities that underpin the stability analysis of HDG discretizations. The resulting framework is then used to demonstrate the well-posedness and robustness of HDG-based numerical schemes for second-order elliptic problems, even under minimal regularity assumptions on the source term and boundary data.","authors":["Yukun Yue"],"url":"https://arxiv.org/abs/2403.19004"}
{"created":"2025-04-15","title":"A Hybrid Algorithm for Iterative Adaptation of Feedforward Controllers: an Application on Electromechanical Switches","abstract":"Electromechanical switching devices such as relays, solenoid valves, and contactors offer several technical and economic advantages that make them widely used in industry. However, uncontrolled operations result in undesirable impact-related phenomena at the end of the stroke. As a solution, different soft-landing controls have been proposed. Among them, feedforward control with iterative techniques that adapt its parameters is a solution when real-time feedback is not available. However, these techniques typically require a large number of operations to converge or are computationally intensive, which limits a real implementation. In this paper, we present a new algorithm for the iterative adaptation that is able to eventually adapt the search coordinate system and to reduce the search dimensional size in order to accelerate convergence. Moreover, it automatically toggles between a derivative-free and a gradient-based method to balance exploration and exploitation. To demonstrate the high potential of the proposal, each novel part of the algorithm is compared with a state-of-the-art approach via simulation.","authors":["Eloy Serrano-Seco (Universidad de Zaragoza)","Eduardo Moya-Lasheras (Universidad de Zaragoza)","Edgar Ramirez-Laboreo (Universidad de Zaragoza)"],"url":"https://arxiv.org/abs/2404.00036"}
{"created":"2025-04-15","title":"Computation and Communication Efficient Lightweighting Vertical Federated Learning for Smart Building IoT","abstract":"With the increasing number and enhanced capabilities of IoT devices in smart buildings, these devices are evolving beyond basic data collection and control to actively participate in deep learning tasks. Federated Learning (FL), as a decentralized learning paradigm, is well-suited for such scenarios. However, the limited computational and communication resources of IoT devices present significant challenges. While existing research has extensively explored efficiency improvements in Horizontal FL, these techniques cannot be directly applied to Vertical FL due to fundamental differences in data partitioning and model structure. To address this gap, we propose a Lightweight Vertical Federated Learning (LVFL) framework that jointly optimizes computational and communication efficiency. Our approach introduces two distinct lightweighting strategies: one for reducing the complexity of the feature model to improve local computation, and another for compressing feature embeddings to reduce communication overhead. Furthermore, we derive a convergence bound for the proposed LVFL algorithm that explicitly incorporates both computation and communication lightweighting ratios. Experimental results on an image classification task demonstrate that LVFL effectively mitigates resource demands while maintaining competitive learning performance.","authors":["Heqiang Wang","Xiang Liu","Yucheng Liu","Jia Zhou","Weihong Yang","Xiaoxiong Zhong"],"url":"https://arxiv.org/abs/2404.00466"}
{"created":"2025-04-15","title":"Off-the-grid regularisation for Poisson inverse problems","abstract":"Off-the-grid regularisation has been extensively employed over the last decade in the context of ill-posed inverse problems formulated in the continuous setting of the space of Radon measures $\\mathcal{M}(\\mathcal{X})$. These approaches enjoy convexity and counteract the discretisation biases as well the numerical instabilities typical of their discrete counterparts. In the framework of sparse reconstruction of discrete point measures (sum of weighted Diracs), a Total Variation regularisation norm in $\\mathcal{M}(\\mathcal{X})$ is typically combined with an $L^2$ data term modelling additive Gaussian noise. To asses the framework of off-the-grid regularisation in the presence of signal-dependent Poisson noise, we consider in this work a variational model coupling the Total Variation regularisation with a Kullback-Leibler data term under a non-negativity constraint. Analytically, we study the optimality conditions of the composite functional and analyse its dual problem. Then, we consider an homotopy strategy to select an optimal regularisation parameter and use it within a Sliding Frank-Wolfe algorithm. Several numerical experiments on both 1D/2D simulated and real 3D fluorescent microscopy data are reported.","authors":["Marta Lazzaretti","Claudio Estatico","Alejandro Melero","Luca Calatroni"],"url":"https://arxiv.org/abs/2404.00810"}
{"created":"2025-04-15","title":"Projection method for quasiperiodic elliptic equations and application to quasiperiodic homogenization","abstract":"In this study, we address the challenge of solving elliptic equations with quasiperiodic coefficients. To achieve accurate and efficient computation, we introduce the projection method, which enables the embedding of quasiperiodic systems into higher-dimensional periodic systems. To enhance the computational efficiency, we propose a compressed storage strategy for the stiffness matrix by its multi-level block circulant structure, significantly reducing memory requirements. Furthermore, we design a diagonal preconditioner to efficiently solve the resulting high-dimensional linear system by reducing the condition number of the stiffness matrix. These techniques collectively contribute to the computational effectiveness of our proposed approach. Convergence analysis shows the polynomial accuracy of the proposed method. We demonstrate the effectiveness and accuracy of our approach through a series of numerical examples. Moreover, we apply our method to achieve a highly accurate computation of the homogenized coefficients for a quasiperiodic multiscale elliptic equation.","authors":["Kai Jiang","Meng Li","Juan Zhang","Lei Zhang"],"url":"https://arxiv.org/abs/2404.06841"}
{"created":"2025-04-15","title":"Weakly-Supervised Learning via Multi-Lateral Decoder Branching for Tool Segmentation in Robot-Assisted Cardiovascular Catheterization","abstract":"Robot-assisted catheterization has garnered a good attention for its potentials in treating cardiovascular diseases. However, advancing surgeon-robot collaboration still requires further research, particularly on task-specific automation. For instance, automated tool segmentation can assist surgeons in visualizing and tracking of endovascular tools during cardiac procedures. While learning-based models have demonstrated state-of-the-art segmentation performances, generating ground-truth labels for fully-supervised methods is both labor-intensive time consuming, and costly. In this study, we propose a weakly-supervised learning method with multi-lateral pseudo labeling for tool segmentation in cardiovascular angiogram datasets. The method utilizes a modified U-Net architecture featuring one encoder and multiple laterally branched decoders. The decoders generate diverse pseudo labels under different perturbations, augmenting available partial labels. The pseudo labels are self-generated using a mixed loss function with shared consistency across the decoders. The weakly-supervised model was trained end-to-end and validated using partially annotated angiogram data from three cardiovascular catheterization procedures. Validation results show that the model could perform closer to fully-supervised models. Also, the proposed weakly-supervised multi-lateral method outperforms three well known methods used for weakly-supervised learning, offering the highest segmentation performance across the three angiogram datasets. Furthermore, numerous ablation studies confirmed the model's consistent performance under different parameters. Finally, the model was applied for tool segmentation in a robot-assisted catheterization experiments. The model enhanced visualization with high connectivity indices for guidewire and catheter, and a mean processing time of 35 ms per frame.","authors":["Olatunji Mumini Omisore","Toluwanimi Akinyemi","Anh Nguyen","Lei Wang"],"url":"https://arxiv.org/abs/2404.07594"}
{"created":"2025-04-15","title":"SQIAsignHD: SQIsignHD Adaptor Signature","abstract":"Adaptor signatures can be viewed as a generalized form of standard digital signature schemes by linking message authentication to the disclosure of a secret value. As a recent cryptographic primitive, they have become essential for blockchain applications, including cryptocurrencies, by reducing on-chain costs, improving fungibility, and enabling off-chain payments in payment-channel networks, payment-channel hubs, and atomic swaps. However, existing adaptor signature constructions are vulnerable to quantum attacks due to Shor's algorithm. In this work, we introduce $\\mathsf{SQIAsignHD}$, a new quantum-resistant adaptor signature scheme based on isogenies of supersingular elliptic curves, using SQIsignHD - as the underlying signature scheme - and exploiting the idea of the artificial orientation on the supersingular isogeny Diffie-Hellman key exchange protocol, SIDH, to define the underlying hard relation. We, furthermore, provide a formal security proof for our proposed scheme.","authors":["Farzin Renan","P\\'eter Kutas"],"url":"https://arxiv.org/abs/2404.09026"}
{"created":"2025-04-15","title":"RHanDS: Refining Malformed Hands for Generated Images with Decoupled Structure and Style Guidance","abstract":"Although diffusion models can generate high-quality human images, their applications are limited by the instability in generating hands with correct structures. In this paper, we introduce RHanDS, a conditional diffusion-based framework designed to refine malformed hands by utilizing decoupled structure and style guidance. The hand mesh reconstructed from the malformed hand offers structure guidance for correcting the structure of the hand, while the malformed hand itself provides style guidance for preserving the style of the hand. To alleviate the mutual interference between style and structure guidance, we introduce a two-stage training strategy and build a series of multi-style hand datasets. In the first stage, we use paired hand images for training to ensure stylistic consistency in hand refining. In the second stage, various hand images generated based on human meshes are used for training, enabling the model to gain control over the hand structure. Experimental results demonstrate that RHanDS can effectively refine hand structure while preserving consistency in hand style.","authors":["Chengrui Wang","Pengfei Liu","Min Zhou","Ming Zeng","Xubin Li","Tiezheng Ge","Bo zheng"],"url":"https://arxiv.org/abs/2404.13984"}
{"created":"2025-04-15","title":"MaPa: Text-driven Photorealistic Material Painting for 3D Shapes","abstract":"This paper aims to generate materials for 3D meshes from text descriptions. Unlike existing methods that synthesize texture maps, we propose to generate segment-wise procedural material graphs as the appearance representation, which supports high-quality rendering and provides substantial flexibility in editing. Instead of relying on extensive paired data, i.e., 3D meshes with material graphs and corresponding text descriptions, to train a material graph generative model, we propose to leverage the pre-trained 2D diffusion model as a bridge to connect the text and material graphs. Specifically, our approach decomposes a shape into a set of segments and designs a segment-controlled diffusion model to synthesize 2D images that are aligned with mesh parts. Based on generated images, we initialize parameters of material graphs and fine-tune them through the differentiable rendering module to produce materials in accordance with the textual description. Extensive experiments demonstrate the superior performance of our framework in photorealism, resolution, and editability over existing methods. Project page: https://zju3dv.github.io/MaPa","authors":["Shangzan Zhang","Sida Peng","Tao Xu","Yuanbo Yang","Tianrun Chen","Nan Xue","Yujun Shen","Hujun Bao","Ruizhen Hu","Xiaowei Zhou"],"url":"https://arxiv.org/abs/2404.17569"}
{"created":"2025-04-15","title":"PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games","abstract":"We present PLAYER*, a novel framework for Large Language Model (LLM)-based agents in Murder Mystery Games (MMGs). MMGs pose unique challenges, including undefined state spaces, absent intermediate rewards, and the need for strategic interaction in a continuous language domain. PLAYER* addresses these complexities through a sensor-based representation of agent states, a question-targeting mechanism guided by information gain, and a pruning strategy to refine suspect lists and enhance decision-making efficiency. To enable systematic evaluation, we propose WellPlay, a dataset comprising 1,482 inferential questions across 12 games, categorized into objectives, reasoning, and relationships. Experiments demonstrate PLAYER*'s capacity to achieve superior performance in reasoning accuracy and efficiency compared to existing approaches, while also significantly improving the quality of agent-human interactions in MMGs. This study advances the development of reasoning agents for complex social and interactive scenarios.","authors":["Qinglin Zhu","Runcong Zhao","Bin Liang","Jinhua Du","Lin Gui","Yulan He"],"url":"https://arxiv.org/abs/2404.17662"}
{"created":"2025-04-15","title":"Efficient Runtime Verification of Real-Time Systems under Parametric Communication Delays","abstract":"Timed B\\\"uchi automata provide a very expressive formalism for expressing requirements of real-time systems. Online monitoring and active testing of embedded real-time systems can then be achieved by symbolic execution of such automata on the trace observed from the system. This direct construction however only is faithful if observation of the trace is immediate in the sense that the monitor (or test harness, respectively) can assign exact time stamps to the actions it observes, which is rarely true in practice due to the substantial and fluctuating parametric delays introduced by the circuitry connecting the observed system to its monitoring or testing device.","authors":["Martin Fr\\\"anzle","Thomas M. Grosen","Kim G. Larsen","Martin Zimmermann"],"url":"https://arxiv.org/abs/2404.18282"}
{"created":"2025-04-15","title":"Reconstructing Satellites in 3D from Amateur Telescope Images","abstract":"Monitoring space objects is crucial for space situational awareness, yet reconstructing 3D satellite models from ground-based telescope images is challenging due to atmospheric turbulence, long observation distances, limited viewpoints, and low signal-to-noise ratios. In this paper, we propose a novel computational imaging framework that overcomes these obstacles by integrating a hybrid image pre-processing pipeline with a joint pose estimation and 3D reconstruction module based on controlled Gaussian Splatting (GS) and Branch-and-Bound (BnB) search. We validate our approach on both synthetic satellite datasets and on-sky observations of China's Tiangong Space Station and the International Space Station, achieving robust 3D reconstructions of low-Earth orbit satellites from ground-based data. Quantitative evaluations using SSIM, PSNR, LPIPS, and Chamfer Distance demonstrate that our method outperforms state-of-the-art NeRF-based approaches, and ablation studies confirm the critical role of each component. Our framework enables high-fidelity 3D satellite monitoring from Earth, offering a cost-effective alternative for space situational awareness. Project page: https://ai4scientificimaging.org/ReconstructingSatellites","authors":["Zhiming Chang","Boyang Liu","Yifei Xia","Youming Guo","Boxin Shi","He Sun"],"url":"https://arxiv.org/abs/2404.18394"}
{"created":"2025-04-15","title":"Towards Scenario- and Capability-Driven Dataset Development and Evaluation: An Approach in the Context of Mapless Automated Driving","abstract":"The foundational role of datasets in defining the capabilities of deep learning models has led to their rapid proliferation. At the same time, published research focusing on the process of dataset development for environment perception in automated driving has been scarce, thereby reducing the applicability of openly available datasets and impeding the development of effective environment perception systems. Sensor-based, mapless automated driving is one of the contexts where this limitation is evident. While leveraging real-time sensor data, instead of pre-defined HD maps promises enhanced adaptability and safety by effectively navigating unexpected environmental changes, it also increases the demands on the scope and complexity of the information provided by the perception system.","authors":["Felix Gr\\\"un","Marcus Nolte","Markus Maurer"],"url":"https://arxiv.org/abs/2404.19656"}
{"created":"2025-04-15","title":"RULSurv: A probabilistic survival-based method for early censoring-aware prediction of remaining useful life in ball bearings","abstract":"Predicting the remaining useful life (RUL) of ball bearings is an active area of research, where novel machine learning techniques are continuously being applied to predict degradation trends and anticipate failures before they occur. However, few studies have explicitly addressed the challenge of handling censored data, where information about a specific event (\\eg mechanical failure) is incomplete or only partially observed. To address this issue, we introduce a novel and flexible method for early fault detection using Kullback-Leibler (KL) divergence and RUL estimation using survival analysis that naturally supports censored data. We demonstrate our approach in the XJTU-SY dataset using a 5-fold cross-validation strategy across three different operating conditions. When predicting the time to failure for bearings under the highest load (C1, 12.0 kN and 2100 RPM) with 25% random censoring, our approach achieves a mean absolute error (MAE) of 14.7 minutes (95% CI = 13.6-15.8) using a linear CoxPH model, and an MAE of 12.6 minutes (95% CI = 11.8-13.4) using a nonlinear Random Survival Forests model, compared to an MAE of 18.5 minutes (95% CI = 17.4-19.6) using a linear LASSO model that does not support censoring. Moreover, our approach achieves a mean cumulative relative accuracy (CRA) of 0.7586 over 5 bearings under the highest load, which improves over several state-of-the-art baselines. Our work highlights the importance of considering censored data as part of the model design when building predictive models for early fault detection and RUL estimation.","authors":["Christian Marius Lillelund","Fernando Pannullo","Morten Opprud Jakobsen","Manuel Morante","Christian Fischer Pedersen"],"url":"https://arxiv.org/abs/2405.01614"}
{"created":"2025-04-15","title":"Curriculum Direct Preference Optimization for Diffusion and Consistency Models","abstract":"Direct Preference Optimization (DPO) has been proposed as an effective and efficient alternative to reinforcement learning from human feedback (RLHF). In this paper, we propose a novel and enhanced version of DPO based on curriculum learning for text-to-image generation. Our method is divided into two training stages. First, a ranking of the examples generated for each prompt is obtained by employing a reward model. Then, increasingly difficult pairs of examples are sampled and provided to a text-to-image generative (diffusion or consistency) model. Generated samples that are far apart in the ranking are considered to form easy pairs, while those that are close in the ranking form hard pairs. In other words, we use the rank difference between samples as a measure of difficulty. The sampled pairs are split into batches according to their difficulty levels, which are gradually used to train the generative model. Our approach, Curriculum DPO, is compared against state-of-the-art fine-tuning approaches on nine benchmarks, outperforming the competing methods in terms of text alignment, aesthetics and human preference. Our code is available at https://github.com/CroitoruAlin/Curriculum-DPO.","authors":["Florinel-Alin Croitoru","Vlad Hondru","Radu Tudor Ionescu","Nicu Sebe","Mubarak Shah"],"url":"https://arxiv.org/abs/2405.13637"}
{"created":"2025-04-15","title":"Financial Models in Generative Art: Black-Scholes-Inspired Concept Blending in Text-to-Image Diffusion","abstract":"We introduce a novel approach for concept blending in pretrained text-to-image diffusion models, aiming to generate images at the intersection of multiple text prompts. At each time step during diffusion denoising, our algorithm forecasts predictions w.r.t. the generated image and makes informed text conditioning decisions. Central to our method is the unique analogy between diffusion models, which are rooted in non-equilibrium thermodynamics, and the Black-Scholes model for financial option pricing. By drawing parallels between key variables in both domains, we derive a robust algorithm for concept blending that capitalizes on the Markovian dynamics of the Black-Scholes framework. Our text-based concept blending algorithm is data-efficient, meaning it does not need additional training. Furthermore, it operates without human intervention or hyperparameter tuning. We highlight the benefits of our approach by comparing it qualitatively and quantitatively to other text based concept blending techniques, including linear interpolation, alternating prompts, step-wise prompt switching, and CLIP-guided prompt selection across various scenarios such as single object per text prompt, multiple objects per text prompt and objects against backgrounds. Our work shows that financially inspired techniques can enhance text-to-image concept blending in generative AI, paving the way for broader innovation. Code is available at https://github.com/divyakraman/BlackScholesDiffusion2024.","authors":["Divya Kothandaraman","Ming Lin","Dinesh Manocha"],"url":"https://arxiv.org/abs/2405.13685"}
{"created":"2025-04-15","title":"Connectivity Shapes Implicit Regularization in Matrix Factorization Models for Matrix Completion","abstract":"Matrix factorization models have been extensively studied as a valuable test-bed for understanding the implicit biases of overparameterized models. Although both low nuclear norm and low rank regularization have been studied for these models, a unified understanding of when, how, and why they achieve different implicit regularization effects remains elusive. In this work, we systematically investigate the implicit regularization of matrix factorization for solving matrix completion problems. We empirically discover that the connectivity of observed data plays a crucial role in the implicit bias, with a transition from low nuclear norm to low rank as data shifts from disconnected to connected with increased observations. We identify a hierarchy of intrinsic invariant manifolds in the loss landscape that guide the training trajectory to evolve from low-rank to higher-rank solutions. Based on this finding, we theoretically characterize the training trajectory as following the hierarchical invariant manifold traversal process, generalizing the characterization of Li et al. (2020) to include the disconnected case. Furthermore, we establish conditions that guarantee minimum nuclear norm, closely aligning with our experimental findings, and we provide a dynamics characterization condition for ensuring minimum rank. Our work reveals the intricate interplay between data connectivity, training dynamics, and implicit regularization in matrix factorization models.","authors":["Zhiwei Bai","Jiajie Zhao","Yaoyu Zhang"],"url":"https://arxiv.org/abs/2405.13721"}
{"created":"2025-04-15","title":"Bundle Neural Networks for message diffusion on graphs","abstract":"The dominant paradigm for learning on graph-structured data is message passing. Despite being a strong inductive bias, the local message passing mechanism suffers from pathological issues such as over-smoothing, over-squashing, and limited node-level expressivity. To address these limitations we propose Bundle Neural Networks (BuNN), a new type of GNN that operates via message diffusion over flat vector bundles - structures analogous to connections on Riemannian manifolds that augment the graph by assigning to each node a vector space and an orthogonal map. A BuNN layer evolves the features according to a diffusion-type partial differential equation. When discretized, BuNNs are a special case of Sheaf Neural Networks (SNNs), a recently proposed MPNN capable of mitigating over-smoothing. The continuous nature of message diffusion enables BuNNs to operate on larger scales of the graph and, therefore, to mitigate over-squashing. Finally, we prove that BuNN can approximate any feature transformation over nodes on any (potentially infinite) family of graphs given injective positional encodings, resulting in universal node-level expressivity. We support our theory via synthetic experiments and showcase the strong empirical performance of BuNNs over a range of real-world tasks, achieving state-of-the-art results on several standard benchmarks in transductive and inductive settings.","authors":["Jacob Bamberger","Federico Barbero","Xiaowen Dong","Michael M. Bronstein"],"url":"https://arxiv.org/abs/2405.15540"}
{"created":"2025-04-15","title":"Learning Visual-Semantic Subspace Representations","abstract":"Learning image representations that capture rich semantic relationships remains a significant challenge. Existing approaches are either contrastive, lacking robust theoretical guarantees, or struggle to effectively represent the partial orders inherent to structured visual-semantic data. In this paper, we introduce a nuclear norm-based loss function, grounded in the same information theoretic principles that have proved effective in self-supervised learning. We present a theoretical characterization of this loss, demonstrating that, in addition to promoting class orthogonality, it encodes the spectral geometry of the data within a subspace lattice. This geometric representation allows us to associate logical propositions with subspaces, ensuring that our learned representations adhere to a predefined symbolic structure.","authors":["Gabriel Moreira","Manuel Marques","Jo\\~ao Paulo Costeira","Alexander Hauptmann"],"url":"https://arxiv.org/abs/2405.16213"}
{"created":"2025-04-15","title":"Fourier Sliced-Wasserstein Embedding for Multisets and Measures","abstract":"We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to embed multisets and measures over $\\mathbb{R}^d$ into Euclidean space.","authors":["Tal Amir","Nadav Dym"],"url":"https://arxiv.org/abs/2504.02544"}
{"created":"2025-04-15","title":"Building Vision Models upon Heat Conduction","abstract":"Visual representation models leveraging attention mechanisms are challenged by significant computational overhead, particularly when pursuing large receptive fields. In this study, we aim to mitigate this challenge by introducing the Heat Conduction Operator (HCO) built upon the physical heat conduction principle. HCO conceptualizes image patches as heat sources and models their correlations through adaptive thermal energy diffusion, enabling robust visual representations. HCO enjoys a computational complexity of O(N^1.5), as it can be implemented using discrete cosine transformation (DCT) operations. HCO is plug-and-play, combining with deep learning backbones produces visual representation models (termed vHeat) with global receptive fields. Experiments across vision tasks demonstrate that, beyond the stronger performance, vHeat achieves up to a 3x throughput, 80% less GPU memory allocation, and 35% fewer computational FLOPs compared to the Swin-Transformer. Code is available at https://github.com/MzeroMiko/vHeat.","authors":["Zhaozhi Wang","Yue Liu","Yunjie Tian","Yunfan Liu","Yaowei Wang","Qixiang Ye"],"url":"https://arxiv.org/abs/2405.16555"}
{"created":"2025-04-15","title":"Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning Code LLMs","abstract":"Code LLMs have shown promising results with converting tasks in natural language to programs that can be executed by service robots. We are interested in finetuning small, specialized LLMs for this purpose, but collecting datasets of task-program pairs specific to each robot is time-consuming and expensive. While approaches such as SELF-INSTRUCT and EVOL-INSTRUCT are capable of generating novel tasks given a few examples, they are unable to provide the corresponding programs that correctly abide by physical-world and robot-constraints using the provided programming interface. Using a simulator is a natural potential solution to checking for such constraints, but building simulation environments that can handle arbitrary tasks and their necessary objects and locations, is challenging. To address these challenges, we introduce ROBO-INSTRUCT, which synthesizes task-specific simulation environments on the fly during program execution, by opportunistically inferring entity properties and enforcing corresponding constraints based on how the entities are used in the task program. Additionally, ROBO-INSTRUCT integrates an LLM-aided post-processing procedure to refine instructions for better alignment with robot programs. We demonstrate the effectiveness of ROBO-INSTRUCT across multiple LLMs, showing that our fine-tuned models outperform all baseline methods and even match or surpass the performance of several larger and proprietary models.","authors":["Zichao Hu","Junyi Jessy Li","Arjun Guha","Joydeep Biswas"],"url":"https://arxiv.org/abs/2405.20179"}
{"created":"2025-04-15","title":"Scalable Bayesian Learning with posteriors","abstract":"Although theoretically compelling, Bayesian learning with modern machine learning models is computationally challenging since it requires approximating a high dimensional posterior distribution. In this work, we (i) introduce posteriors, an easily extensible PyTorch library hosting general-purpose implementations making Bayesian learning accessible and scalable to large data and parameter regimes; (ii) present a tempered framing of stochastic gradient Markov chain Monte Carlo, as implemented in posteriors, that transitions seamlessly into optimization and unveils a minor modification to deep ensembles to ensure they are asymptotically unbiased for the Bayesian posterior, and (iii) demonstrate and compare the utility of Bayesian approximations through experiments including an investigation into the cold posterior effect and applications with large language models.","authors":["Samuel Duffield","Kaelan Donatella","Johnathan Chiu","Phoebe Klett","Daniel Simpson"],"url":"https://arxiv.org/abs/2406.00104"}
{"created":"2025-04-15","title":"Self-Improving Robust Preference Optimization","abstract":"Online and offline RLHF methods, such as PPO and DPO, have been highly successful in aligning AI with human preferences. Despite their success, however, these methods suffer from fundamental limitations: (a) Models trained with RLHF can learn from mistakes or negative examples through RL mechanism or contrastive loss during training. However, at inference time, they lack an innate self-improvement mechanism for error corrections. (b) The optimal solution of existing methods is highly task-dependent, making it difficult for them to generalize to new tasks. To address these challenges, we propose Self-Improving Robust Preference Optimization (SRPO), a practical and mathematically principled offline RLHF framework. The key idea behind SRPO is to cast the problem of learning from human preferences as a self-improvement process, mathematically formulated as a min-max objective that jointly optimizes a self-improvement policy and a generative policy in an adversarial fashion. Crucially, the solution for this optimization problem is independent of the training task, which makes it robust to its changes. We then show that this objective can be reformulated as a non-adversarial offline loss, which can be efficiently optimized using standard supervised learning techniques at scale. To demonstrate SRPO's effectiveness, we evaluate it using AI Win-Rate (WR) against human (GOLD) completions. When tested on the XSum dataset, SRPO outperforms DPO by a margin of 15% after 5 self revisions, achieving an impressive 90% WR. Moreover, on the challenging Arena-Hard prompts, SRPO outperforms both DPO and IPO (by 4% without revision and 6% after a single revision), reaching a 56% WR against against Llama-3.1-8B-Instruct.","authors":["Eugene Choi","Arash Ahmadian","Matthieu Geist","Oilvier Pietquin","Mohammad Gheshlaghi Azar"],"url":"https://arxiv.org/abs/2406.01660"}
{"created":"2025-04-15","title":"SnatchML: Hijacking ML models without Training Access","abstract":"Model hijacking can cause significant accountability and security risks since the owner of a hijacked model can be framed for having their model offer illegal or unethical services. Prior works consider model hijacking as a training time attack, whereby an adversary requires full access to the ML model training. In this paper, we consider a stronger threat model for an inference-time hijacking attack, where the adversary has no access to the training phase of the victim model. Our intuition is that ML models, which are typically over-parameterized, might have the capacity to (unintentionally) learn more than the intended task they are trained for. We propose SnatchML, a new training-free model hijacking attack, that leverages the extra capacity learnt by the victim model to infer different tasks that can be semantically related or unrelated to the original one. Our results on models deployed on AWS Sagemaker showed that SnatchML can deliver high accuracy on hijacking tasks. Interestingly, while all previous approaches are limited by the number of classes in the benign task, SnatchML can hijack models for tasks that contain more classes than the original. We explore different methods to mitigate this risk; We propose meta-unlearning, which is designed to help the model unlearn a potentially malicious task while training for the original task. We also provide insights on over-parametrization as a possible inherent factor that facilitates model hijacking, and accordingly, we propose a compression-based countermeasure to counteract this attack. We believe this work offers a previously overlooked perspective on model hijacking attacks, presenting a stronger threat model and higher applicability in real-world contexts.","authors":["Mahmoud Ghorbel","Halima Bouzidi","Ioan Marius Bilasco","Ihsen Alouani"],"url":"https://arxiv.org/abs/2406.01708"}
{"created":"2025-04-15","title":"MoLA: Motion Generation and Editing with Latent Diffusion Enhanced by Adversarial Training","abstract":"In text-to-motion generation, controllability as well as generation quality and speed has become increasingly critical. The controllability challenges include generating a motion of a length that matches the given textual description and editing the generated motions according to control signals, such as the start-end positions and the pelvis trajectory. In this paper, we propose MoLA, which provides fast, high-quality, variable-length motion generation and can also deal with multiple editing tasks in a single framework. Our approach revisits the motion representation used as inputs and outputs in the model, incorporating an activation variable to enable variable-length motion generation. Additionally, we integrate a variational autoencoder and a latent diffusion model, further enhanced through adversarial training, to achieve high-quality and fast generation. Moreover, we apply a training-free guided generation framework to achieve various editing tasks with motion control inputs. We quantitatively show the effectiveness of adversarial learning in text-to-motion generation, and demonstrate the applicability of our editing framework to multiple editing tasks in the motion domain.","authors":["Kengo Uchida","Takashi Shibuya","Yuhta Takida","Naoki Murata","Julian Tanke","Shusuke Takahashi","Yuki Mitsufuji"],"url":"https://arxiv.org/abs/2406.01867"}
{"created":"2025-04-15","title":"Multi-Granularity Language-Guided Training for Multi-Object Tracking","abstract":"Most existing multi-object tracking methods typically learn visual tracking features via maximizing dis-similarities of different instances and minimizing similarities of the same instance. While such a feature learning scheme achieves promising performance, learning discriminative features solely based on visual information is challenging especially in case of environmental interference such as occlusion, blur and domain variance. In this work, we argue that multi-modal language-driven features provide complementary information to classical visual features, thereby aiding in improving the robustness to such environmental interference. To this end, we propose a new multi-object tracking framework, named LG-MOT, that explicitly leverages language information at different levels of granularity (scene-and instance-level) and combines it with standard visual features to obtain discriminative representations. To develop LG-MOT, we annotate existing MOT datasets with scene-and instance-level language descriptions. We then encode both instance-and scene-level language information into high-dimensional embeddings, which are utilized to guide the visual features during training. At inference, our LG-MOT uses the standard visual features without relying on annotated language descriptions. Extensive experiments on three benchmarks, MOT17, DanceTrack and SportsMOT, reveal the merits of the proposed contributions leading to state-of-the-art performance. On the DanceTrack test set, our LG-MOT achieves an absolute gain of 2.2\\% in terms of target object association (IDF1 score), compared to the baseline using only visual features. Further, our LG-MOT exhibits strong cross-domain generalizability. The dataset and code will be available at https://github.com/WesLee88524/LG-MOT.","authors":["Yuhao Li","Jiale Cao","Muzammal Naseer","Yu Zhu","Jinqiu Sun","Yanning Zhang","Fahad Shahbaz Khan"],"url":"https://arxiv.org/abs/2406.04844"}
{"created":"2025-04-15","title":"FRAG: Frequency Adapting Group for Diffusion Video Editing","abstract":"In video editing, the hallmark of a quality edit lies in its consistent and unobtrusive adjustment. Modification, when integrated, must be smooth and subtle, preserving the natural flow and aligning seamlessly with the original vision. Therefore, our primary focus is on overcoming the current challenges in high quality edit to ensure that each edit enhances the final product without disrupting its intended essence. However, quality deterioration such as blurring and flickering is routinely observed in recent diffusion video editing systems. We confirm that this deterioration often stems from high-frequency leak: the diffusion model fails to accurately synthesize high-frequency components during denoising process. To this end, we devise Frequency Adapting Group (FRAG) which enhances the video quality in terms of consistency and fidelity by introducing a novel receptive field branch to preserve high-frequency components during the denoising process. FRAG is performed in a model-agnostic manner without additional training and validates the effectiveness on video editing benchmarks (i.e., TGVE, DAVIS).","authors":["Sunjae Yoon","Gwanhyeong Koo","Geonwoo Kim","Chang D. Yoo"],"url":"https://arxiv.org/abs/2406.06044"}
{"created":"2025-04-15","title":"Improving Policy Optimization via $\\varepsilon$-Retrain","abstract":"We present $\\varepsilon$-retrain, an exploration strategy encouraging a behavioral preference while optimizing policies with monotonic improvement guarantees. To this end, we introduce an iterative procedure for collecting retrain areas -- parts of the state space where an agent did not satisfy the behavioral preference. Our method switches between the typical uniform restart state distribution and the retrain areas using a decaying factor $\\varepsilon$, allowing agents to retrain on situations where they violated the preference. We also employ formal verification of neural networks to provably quantify the degree to which agents adhere to these behavioral preferences. Experiments over hundreds of seeds across locomotion, power network, and navigation tasks show that our method yields agents that exhibit significant performance and sample efficiency improvements.","authors":["Luca Marzari","Priya L. Donti","Changliu Liu","Enrico Marchesini"],"url":"https://arxiv.org/abs/2406.08315"}
{"created":"2025-04-15","title":"D-SELD: Dataset-Scalable Exemplar LCA-Decoder","abstract":"Neuromorphic computing has recently gained significant attention as a promising approach for developing energy-efficient, massively parallel computing systems inspired by the spiking behavior of the human brain and natively mapping Spiking Neural Networks (SNNs). Effective training algorithms for SNNs are imperative for increased adoption of neuromorphic platforms; however, SNN training continues to lag behind advances in other classes of ANN. In this paper, we reduce this gap by proposing an innovative encoder-decoder technique that leverages sparse coding and the Locally Competitive Algorithm (LCA) to provide an algorithm specifically designed for neuromorphic platforms. Using our proposed Dataset-Scalable Exemplar LCA-Decoder we reduce the computational demands and memory requirements associated with training SNNs using error backpropagation methods on increasingly larger training sets. We offer a solution that can be scalably applied to datasets of any size. Our results show the highest reported top-1 test accuracy using SNNs on the ImageNet and CIFAR100 datasets, surpassing previous benchmarks. Specifically, we achieved a record top-1 accuracy of 80.75% on ImageNet (ILSVRC2012 validation set) and 79.32% on CIFAR100 using SNNs.","authors":["Sanaz Mahmoodi Takaghaj","Jack Sampson"],"url":"https://arxiv.org/abs/2406.10066"}
{"created":"2025-04-15","title":"GLINT-RU: Gated Lightweight Intelligent Recurrent Units for Sequential Recommender Systems","abstract":"Transformer-based models have gained significant traction in sequential recommender systems (SRSs) for their ability to capture user-item interactions effectively. However, these models often suffer from high computational costs and slow inference. Meanwhile, existing efficient SRS approaches struggle to embed high-quality semantic and positional information into latent representations. To tackle these challenges, this paper introduces GLINT-RU, a lightweight and efficient SRS leveraging a single-layer dense selective Gated Recurrent Units (GRU) module to accelerate inference. By incorporating a dense selective gate, GLINT-RU adaptively captures temporal dependencies and fine-grained positional information, generating high-quality latent representations. Additionally, a parallel mixing block infuses fine-grained positional features into user-item interactions, enhancing both recommendation quality and efficiency. Extensive experiments on three datasets demonstrate that GLINT-RU achieves superior prediction accuracy and inference speed, outperforming baselines based on RNNs, Transformers, MLPs, and SSMs. These results establish GLINT-RU as a powerful and efficient solution for SRSs.","authors":["Sheng Zhang","Maolin Wang","Wanyu Wang","Jingtong Gao","Xiangyu Zhao","Yu Yang","Xuetao Wei","Zitao Liu","Tong Xu"],"url":"https://arxiv.org/abs/2406.10244"}
{"created":"2025-04-15","title":"On the Preservation of Input/Output Directed Graph Informativeness under Crossover","abstract":"There is a broad class of networks which connect inputs to outputs. We provide a strong theoretical foundation for crossover across this class and connect it to informativeness, a measure of the connectedness of inputs to outputs. We define Input/Output Directed Graphs (or IOD Graphs) as graphs with nodes $N$ and directed edges $E$, where $N$ contains (a) a set of \"input nodes\" $I \\subset N$, where each $i \\in I$ has no incoming edges and any number of outgoing edges, and (b) a set of \"output nodes\" $O \\subset N$, where each $o \\in O$ has no outgoing edges and any number of incoming edges, and $I\\cap O = \\emptyset$. We define informativeness, which involves the connections via directed paths from the input nodes to the output nodes: A partially informative IOD Graph has at least one path from an input to an output, a very informative IOD Graph has a path from every input to some output, and a fully informative IOD Graph has a path from every input to every output.","authors":["Andreas Duus Pape","J. David Schaffer","Hiroki Sayama","Christopher Zosh"],"url":"https://arxiv.org/abs/2406.10369"}
{"created":"2025-04-15","title":"Balancing Rigor and Utility: Mitigating Cognitive Biases in Large Language Models for Multiple-Choice Questions","abstract":"This paper examines the role of cognitive biases in the decision-making processes of large language models (LLMs), challenging the conventional goal of eliminating all biases. When properly balanced, we show that certain cognitive biases can enhance decision-making efficiency through rational deviations and heuristic shortcuts. By introducing heuristic moderation and an abstention option, which allows LLMs to withhold responses when uncertain, we reduce error rates, improve decision accuracy, and optimize decision rates. Using the Balance Rigor and Utility (BRU) dataset, developed through expert collaboration, our findings demonstrate that targeted inspection of cognitive biases aligns LLM decisions more closely with human reasoning, enhancing reliability and suggesting strategies for future improvements. This approach offers a novel way to leverage cognitive biases to improve the practical utility of LLMs across various applications.","authors":["Hanyang Zhong","Liman Wang","Wenting Cao","Zeyuan Sun"],"url":"https://arxiv.org/abs/2406.10999"}
{"created":"2025-04-15","title":"Let the Noise Speak: Harnessing Noise for a Unified Defense Against Adversarial and Backdoor Attacks","abstract":"The exponential adoption of machine learning (ML) is propelling the world into a future of distributed and intelligent automation and data-driven solutions. However, the proliferation of malicious data manipulation attacks against ML, namely adversarial and backdoor attacks, jeopardizes its reliability in safety-critical applications. The existing detection methods are attack-specific and built upon some strong assumptions, limiting them in diverse practical scenarios. Thus, motivated by the need for a more robust, unified, and attack-agnostic defense mechanism, we first investigate the shared traits of adversarial and backdoor attacks. Based on our observation, we propose NoiSec, a reconstruction-based intrusion detection system that brings a novel perspective by shifting focus from the reconstructed input to the reconstruction noise itself, which is the foundational root cause of such malicious data alterations. NoiSec disentangles the noise from the test input, extracts the underlying features from the noise, and leverages them to recognize systematic malicious manipulation. Our comprehensive evaluation of NoiSec demonstrates its high effectiveness across various datasets, including basic objects, natural scenes, traffic signs, medical images, spectrogram-based audio data, and wireless sensing against five state-of-the-art adversarial attacks and three backdoor attacks under challenging evaluation conditions. NoiSec demonstrates strong detection performance in both white-box and black-box adversarial attack scenarios, significantly outperforming the closest baseline models, particularly in an adaptive attack setting. We will provide the code for future baseline comparison. Our code and artifacts are publicly available at https://github.com/shahriar0651/NoiSec.","authors":["Md Hasan Shahriar","Ning Wang","Naren Ramakrishnan","Y. Thomas Hou","Wenjing Lou"],"url":"https://arxiv.org/abs/2406.13073"}
{"created":"2025-04-15","title":"Recovery of rational functions via Hankel pencil method and sensitivities of the poles","abstract":"In the paper, we develop a new method for the recovery of rational functions. Our idea is based on the property that Fourier coefficients of rational functions have the exponential structure and reconstruction of this exponential structure with the ESPRIT method in the frequency domain. Further we present sensitivity analysis for poles of rational functions reconstructed with our method in case of unstructured and structured perturbations. Finally, we consider several numerical experiments and, using sensitivities, explain the recovery errors for poles.","authors":["Nadiia Derevianko"],"url":"https://arxiv.org/abs/2406.13192"}
{"created":"2025-04-15","title":"V-LASIK: Consistent Glasses-Removal from Videos Using Synthetic Data","abstract":"Diffusion-based generative models have recently shown remarkable image and video editing capabilities. However, local video editing, particularly removal of small attributes like glasses, remains a challenge. Existing methods either alter the videos excessively, generate unrealistic artifacts, or fail to perform the requested edit consistently throughout the video. In this work, we focus on consistent and identity-preserving removal of glasses in videos, using it as a case study for consistent local attribute removal in videos. Due to the lack of paired data, we adopt a weakly supervised approach and generate synthetic imperfect data, using an adjusted pretrained diffusion model. We show that despite data imperfection, by learning from our generated data and leveraging the prior of pretrained diffusion models, our model is able to perform the desired edit consistently while preserving the original video content. Furthermore, we exemplify the generalization ability of our method to other local video editing tasks by applying it successfully to facial sticker-removal. Our approach demonstrates significant improvement over existing methods, showcasing the potential of leveraging synthetic data and strong video priors for local video editing tasks.","authors":["Rotem Shalev-Arkushin","Aharon Azulay","Tavi Halperin","Eitan Richardson","Amit H. Bermano","Ohad Fried"],"url":"https://arxiv.org/abs/2406.14510"}
{"created":"2025-04-15","title":"Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods","abstract":"Large language models (LLMs) have advanced to a point that even humans have difficulty discerning whether a text was generated by another human, or by a computer. However, knowing whether a text was produced by human or artificial intelligence (AI) is important to determining its trustworthiness, and has applications in many domains including detecting fraud and academic dishonesty, as well as combating the spread of misinformation and political propaganda. The task of AI-generated text (AIGT) detection is therefore both very challenging, and highly critical. In this survey, we summarize state-of-the art approaches to AIGT detection, including watermarking, statistical and stylistic analysis, and machine learning classification. We also provide information about existing datasets for this task. Synthesizing the research findings, we aim to provide insight into the salient factors that combine to determine how \"detectable\" AIGT text is under different scenarios, and to make practical recommendations for future work towards this significant technical and societal challenge.","authors":["Kathleen C. Fraser","Hillary Dawkins","Svetlana Kiritchenko"],"url":"https://arxiv.org/abs/2406.15583"}
{"created":"2025-04-15","title":"Automating Transfer of Robot Task Plans using Functorial Data Migrations","abstract":"This paper introduces a novel approach to ontology-based robot plan transfer by leveraging functorial data migrations, a structured mapping method derived from category theory. Functors provide structured maps between planning domain ontologies which enables the transfer of task plans without the need for replanning. Unlike methods tailored to specific plans, our framework applies universally within the source domain once a structured map is defined. We demonstrate this approach by transferring a task plan from the canonical Blocksworld domain to one compatible with the AI2-THOR Kitchen environment. Additionally, we discuss practical limitations, propose benchmarks for evaluating symbolic plan transfer methods, and outline future directions for scaling this approach.","authors":["Angeline Aguinaldo","Evan Patterson","William Regli"],"url":"https://arxiv.org/abs/2406.15961"}
{"created":"2025-04-15","title":"Constructibility, computational complexity and P versus NP","abstract":"A decision problem called the IPL problem is defined, and it is argued for the validity of an associated thesis called the IPL thesis. This thesis states that for some instances of the IPL problem, while an algorithm for verifying correct solutions to the problem in polynomial time is explicitly constructible, the IPL problem itself is algorithmically unsolvable in the sense that no explicitly constructed algorithm can be verified as solving the problem. Thus under a constructive interpretation of algorithmic complexity classes, which is arguably their only meaningful interpretation, the IPL thesis implies that NP is not contained in any complexity class consisting of algorithmically solvable problems. In particular, the thesis implies a solution to the P versus NP problem: P is not equal to NP. It also implies that NP is not contained in larger complexity classes such as EXPTIME, seemingly contradicting known results. However, the proofs of the these results all tacitly employ an existence assumption which according to the IPL thesis, does not hold for the IPL problem under a constructive interpretation of algorithmic complexity classes.","authors":["Arne Hole"],"url":"https://arxiv.org/abs/2406.16843"}
{"created":"2025-04-15","title":"Revisiting the Expressiveness Landscape of Data Graph Queries","abstract":"The study of graph queries in database theory has spanned more than three decades, resulting in a multitude of proposals for graph query languages. These languages differ in the mechanisms. We can identify three main families of languages, with the canonical representatives being: (1) regular path queries, (2) walk logic, and (3) first-order logic with transitive closure operators. This paper provides a complete picture of the expressive power of these languages in the context of data graphs. Specifically, we consider a graph data model that supports querying over both data and topology. For example, \"Does there exist a path between two different persons in a social network with the same last name?\". We also show that an extension of (1), augmented with transitive closure operators, can unify the expressivity of (1)--(3) without increasing the query evaluation complexity.","authors":["Michael Benedikt","Anthony Widjaja Lin","Di-De Yen"],"url":"https://arxiv.org/abs/2406.17871"}
{"created":"2025-04-15","title":"Beyond Statistical Estimation: Differentially Private Individual Computation via Shuffling","abstract":"In data-driven applications, preserving user privacy while enabling valuable computations remains a critical challenge. Technologies like differential privacy have been pivotal in addressing these concerns. The shuffle model of DP requires no trusted curators and can achieve high utility by leveraging the privacy amplification effect yielded from shuffling. These benefits have led to significant interest in the shuffle model. However, the computation tasks in the shuffle model are limited to statistical estimation, making it inapplicable to real-world scenarios in which each user requires a personalized output. This paper introduces a novel paradigm termed Private Individual Computation (PIC), expanding the shuffle model to support a broader range of permutation-equivariant computations. PIC enables personalized outputs while preserving privacy, and enjoys privacy amplification through shuffling. We propose a concrete protocol that realizes PIC. By using one-time public keys, our protocol enables users to receive their outputs without compromising anonymity, which is essential for privacy amplification. Additionally, we present an optimal randomizer, the Minkowski Response, designed for the PIC model to enhance utility. We formally prove the security and privacy properties of the PIC protocol. Theoretical analysis and empirical evaluations demonstrate PIC's capability in handling non-statistical computation tasks, and the efficacy of PIC and the Minkowski randomizer in achieving superior utility compared to existing solutions.","authors":["Shaowei Wang","Changyu Dong","Xiangfu Song","Jin Li","Zhili Zhou","Di Wang","Han Wu"],"url":"https://arxiv.org/abs/2406.18145"}
{"created":"2025-04-15","title":"RetroGFN: Diverse and Feasible Retrosynthesis using GFlowNets","abstract":"Single-step retrosynthesis aims to predict a set of reactions that lead to the creation of a target molecule, which is a crucial task in molecular discovery. Although a target molecule can often be synthesized with multiple different reactions, it is not clear how to verify the feasibility of a reaction, because the available datasets cover only a tiny fraction of the possible solutions. Consequently, the existing models are not encouraged to explore the space of possible reactions sufficiently. In this paper, we propose a novel single-step retrosynthesis model, RetroGFN, that can explore outside the limited dataset and return a diverse set of feasible reactions by leveraging a feasibility proxy model during the training. We show that RetroGFN achieves competitive results on standard top-k accuracy while outperforming existing methods on round-trip accuracy. Moreover, we provide empirical arguments in favor of using round-trip accuracy, which expands the notion of feasibility with respect to the standard top-k accuracy metric.","authors":["Piotr Gai\\'nski","Micha{\\l} Koziarski","Krzysztof Maziarz","Marwin Segler","Jacek Tabor","Marek \\'Smieja"],"url":"https://arxiv.org/abs/2406.18739"}
{"created":"2025-04-15","title":"Footprints of Data in a Classifier: Understanding the Privacy Risks and Solution Strategies","abstract":"The widespread deployment of Artificial Intelligence (AI) across government and private industries brings both advancements and heightened privacy and security concerns. Article 17 of the General Data Protection Regulation (GDPR) mandates the Right to Erasure, requiring data to be permanently removed from a system to prevent potential compromise. While existing research primarily focuses on erasing sensitive data attributes, several passive data compromise mechanisms remain underexplored and unaddressed. One such issue arises from the residual footprints of training data embedded within predictive models. Performance disparities between test and training data can inadvertently reveal which data points were part of the training set, posing a privacy risk. This study examines how two fundamental aspects of classifier systems - training data quality and classifier training methodology - contribute to privacy vulnerabilities. Our theoretical analysis demonstrates that classifiers exhibit universal vulnerability under conditions of data imbalance and distributional shifts. Empirical findings reinforce our theoretical results, highlighting the significant role of training data quality in classifier susceptibility. Additionally, our study reveals that a classifier's operational mechanism and architectural design impact its vulnerability. We further investigate mitigation strategies through data obfuscation techniques and analyze their impact on both privacy and classification performance. To aid practitioners, we introduce a privacy-performance trade-off index, providing a structured approach to balancing privacy protection with model effectiveness. The findings offer valuable insights for selecting classifiers and curating training data in diverse real-world applications.","authors":["Payel Sadhukhan","Tanujit Chakraborty"],"url":"https://arxiv.org/abs/2407.02268"}
{"created":"2025-04-15","title":"Tumor likelihood estimation on MRI prostate data by utilizing k-Space information","abstract":"We present a novel preprocessing and prediction pipeline for the classification of magnetic resonance imaging (MRI) that takes advantage of the information rich complex valued k-Space. Using a publicly available MRI raw dataset with 312 subject and a total of 9508 slices, we show the advantage of utilizing the k-Space for better prostate cancer likelihood estimation in comparison to just using the magnitudinal information in the image domain, with an AUROC of $86.1\\%\\pm1.8\\%$. Additionally, by using high undersampling rates and a simple principal component analysis (PCA) for coil compression, we reduce the time needed for reconstruction by avoiding the time intensive GRAPPA reconstruction algorithm. By using digital undersampling for our experiments, we show that scanning and reconstruction time could be reduced. Even with an undersampling factor of 16, our approach achieves meaningful results, with an AUROC of $71.4\\%\\pm2.9\\%$, using the PCA coil combination and taking into account the k-Space information. With this study, we were able to show the feasibility of preserving phase and k-Space information, with consistent results. Besides preserving valuable information for further diagnostics, this approach can work without the time intensive ADC and reconstruction calculations, greatly reducing the post processing, as well as potential scanning time, increasing patient comfort and allowing a close to real-time prediction.","authors":["M. Rempe","F. H\\\"orst","C. Seibold","B. Hadaschik","M. Schlimbach","J. Egger","K. Kr\\\"oninger","F. Breuer","M. Blaimer","J. Kleesiek"],"url":"https://arxiv.org/abs/2407.06165"}
{"created":"2025-04-15","title":"iiANET: Inception Inspired Attention Hybrid Network for efficient Long-Range Dependency","abstract":"The recent emergence of hybrid models has introduced a transformative approach to computer vision, gradually moving beyond conventional convolutional neural net-works and vision transformers. However, efficiently combining these two paradigms to better capture long-range dependencies in complex images remains a challenge. In this paper, we present iiANET (Inception Inspired Attention Network), an efficient hybrid visual backbone designed to improve the modeling of long-range dependen-cies. The core innovation of iiANET is the iiABlock, a unified building block that in-tegrates global r-MHSA (Multi-Head Self-Attention) and convolutional layers in paral-lel. This design enables iiABlock to simultaneously capture global context and local details, making it highly effective for extracting rich and diverse features. By effi-ciently fusing these complementary representations, iiABlock allows iiANET to achieve strong feature interaction while maintaining computational efficiency. Exten-sive qualitative and quantitative evaluations across various benchmarks show im-proved performance over several state-of-the-art models.","authors":["Haruna Yunusa","Qin Shiyin","Abdulrahman Hamman Adama Chukkol","Adamu Lawan","Abdulganiyu Abdu Yusuf","Isah Bello"],"url":"https://arxiv.org/abs/2407.07603"}
{"created":"2025-04-15","title":"MARTSIA: Safeguarding Data Confidentiality in Blockchain-Driven Process Execution","abstract":"Blockchain technology streamlines multi-party collaborations in decentralized settings, especially when trust is limited or difficult to establish. While public blockchains enhance transparency and reliability by replicating data across all network nodes, they also conflict with confidentiality. Here, we introduce Multi-Authority Approach to Transaction Systems for Interoperating Applications (MARTSIA) to address this challenge. MARTSIA provides fine-grained read-access control at the message-part level by combining user-defined policies with certifier-declared attributes. The approach guarantees that even though data is replicated across the network to maintain consistency, fault tolerance, and availability, its confidentiality is securely preserved through encryption. To this end, MARTSIA integrates blockchain technologies, Multi-Authority Attribute-Based Encryption, and distributed hash-table file storages. This architecture effectively balances the transparency inherent in public blockchains with the privacy required for sensitive applications. We present the tool and its applicability in a business scenario.","authors":["Michele Kryston","Edoardo Marangone","Claudio Di Ciccio","Daniele Friolo","Eugenio Nerio Nemmi","Mattia Samory","Michele Spina","Daniele Venturi","Ingo Weber"],"url":"https://arxiv.org/abs/2407.10684"}
{"created":"2025-04-15","title":"Can Large Language Models Detect Verbal Indicators of Romantic Attraction?","abstract":"As artificial intelligence (AI) models become an integral part of everyday life, our interactions with them shift from purely functional exchanges to more relational experiences. For these experiences to be successful, artificial agents need to be able to detect and interpret social cues and interpersonal dynamics; both within and outside of their own human-agent relationships. In this paper, we explore whether AI models can accurately decode one of the arguably most important but complex social signals: romantic attraction. Specifically, we test whether Large Language Models can detect romantic attraction during brief getting-to-know-you interactions between humans. Examining data from 964 speed dates, we show that ChatGPT can predict both objective and subjective indicators of speed dating success (r=0.12-0.23). Although predictive performance remains relatively low, ChatGPT's predictions of actual matching (i.e., the exchange of contact information) were not only on par with those of human judges but incremental to speed daters' own predictions. In addition, ChatGPT's judgments showed substantial overlap with those made by human observers (r=0.21-0.35), highlighting similarities in their representation of romantic attraction that are independent of accuracy. Our findings also offer insights into how ChatGPT arrives at its predictions and the mistakes it makes. Specifically, we use a Brunswik lens approach to identify the linguistic and conversational cues utilized by ChatGPT (and human judges) vis-a-vis those that are predictive of actual matching.","authors":["Sandra C. Matz","Heinrich Peters","Moran Cerf","Eric Grunenberg","Paul W. Eastwick","Mitja D. Back","Eli J. Finkel"],"url":"https://arxiv.org/abs/2407.10989"}
{"created":"2025-04-15","title":"Walk along: An Experiment on Controlling the Mobile Robot 'Spot' with Voice and Gestures","abstract":"Robots are becoming more capable and can autonomously perform tasks such as navigating between locations. However, human oversight remains crucial. This study compared two touchless methods for directing mobile robots: voice control and gesture control, to investigate the efficiency of the methods and the preference of users. We tested these methods in two conditions: one in which participants remained stationary and one in which they walked freely alongside the robot. We hypothesized that walking alongside the robot would result in higher intuitiveness ratings and improved task performance, based on the idea that walking promotes spatial alignment and reduces the effort required for mental rotation. In a 2x2 within-subject design, 218 participants guided the quadruped robot Spot along a circuitous route with multiple 90-degree turns using rotate left, rotate right, and walk forward commands. After each trial, participants rated the intuitiveness of the command mapping, while post-experiment interviews were used to gather the participants' preferences. Results showed that voice control combined with walking with Spot was the most favored and intuitive, whereas gesture control while standing caused confusion for left/right commands. Nevertheless, 29% of participants preferred gesture control, citing increased task engagement and visual congruence as reasons. An odometry-based analysis revealed that participants often followed behind Spot, particularly in the gesture control condition, when they were allowed to walk. In conclusion, voice control with walking produced the best outcomes. Improving physical ergonomics and adjusting gesture types could make gesture control more effective.","authors":["Renchi Zhang","Jesse van der Linden","Dimitra Dodou","Harleigh Seyffert","Yke Bauke Eisma","Joost C. F. de Winter"],"url":"https://arxiv.org/abs/2407.11218"}
{"created":"2025-04-15","title":"Conditional Quantile Estimation for Uncertain Watch Time in Short-Video Recommendation","abstract":"Accurately predicting watch time is crucial for optimizing recommendations and user experience in short video platforms. However, existing methods that estimate a single average watch time often fail to capture the inherent uncertainty in user engagement patterns. In this paper, we propose Conditional Quantile Estimation (CQE) to model the entire conditional distribution of watch time. Using quantile regression, CQE characterizes the complex watch-time distribution for each user-video pair, providing a flexible and comprehensive approach to understanding user behavior. We further design multiple strategies to combine the quantile estimates, adapting to different recommendation scenarios and user preferences. Extensive offline experiments and online A/B tests demonstrate the superiority of CQE in watch-time prediction and user engagement modeling. Specifically, deploying CQE online on a large-scale platform with hundreds of millions of daily active users has led to substantial gains in key evaluation metrics, including active days, engagement time, and video views. These results highlight the practical impact of our proposed approach in enhancing the user experience and overall performance of the short video recommendation system. The code will be released https://github.com/justopit/CQE.","authors":["Chengzhi Lin","Shuchang Liu","Chuyuan Wang","Yongqi Liu"],"url":"https://arxiv.org/abs/2407.12223"}
{"created":"2025-04-15","title":"Learning-based Observer for Coupled Disturbance","abstract":"Achieving high-precision control for robotic systems is hindered by the low-fidelity dynamical model and external disturbances. Especially, the intricate coupling between internal uncertainties and external disturbances further exacerbates this challenge. This study introduces an effective and convergent algorithm enabling accurate estimation of the coupled disturbance via combining control and learning philosophies. Concretely, by resorting to Chebyshev series expansion, the coupled disturbance is firstly decomposed into an unknown parameter matrix and two known structures dependent on system state and external disturbance respectively. A regularized least squares algorithm is subsequently formalized to learn the parameter matrix using historical time-series data. Finally, a polynomial disturbance observer is specifically devised to achieve a high-precision estimation of the coupled disturbance by utilizing the learned portion. The proposed algorithm is evaluated through extensive simulations and real flight tests. We believe this work can offer a new pathway to integrate learning approaches into control frameworks for addressing longstanding challenges in robotic applications.","authors":["Jindou Jia","Meng Wang","Zihan Yang","Bin Yang","Yuhang Liu","Kexin Guo","Xiang Yu"],"url":"https://arxiv.org/abs/2407.13229"}
{"created":"2025-04-15","title":"SAM-CP: Marrying SAM with Composable Prompts for Versatile Segmentation","abstract":"The Segment Anything model (SAM) has shown a generalized ability to group image pixels into patches, but applying it to semantic-aware segmentation still faces major challenges. This paper presents SAM-CP, a simple approach that establishes two types of composable prompts beyond SAM and composes them for versatile segmentation. Specifically, given a set of classes (in texts) and a set of SAM patches, the Type-I prompt judges whether a SAM patch aligns with a text label, and the Type-II prompt judges whether two SAM patches with the same text label also belong to the same instance. To decrease the complexity in dealing with a large number of semantic classes and patches, we establish a unified framework that calculates the affinity between (semantic and instance) queries and SAM patches and merges patches with high affinity to the query. Experiments show that SAM-CP achieves semantic, instance, and panoptic segmentation in both open and closed domains. In particular, it achieves state-of-the-art performance in open-vocabulary segmentation. Our research offers a novel and generalized methodology for equipping vision foundation models like SAM with multi-grained semantic perception abilities.","authors":["Pengfei Chen","Lingxi Xie","Xinyue Huo","Xuehui Yu","Xiaopeng Zhang","Yingfei Sun","Zhenjun Han","Qi Tian"],"url":"https://arxiv.org/abs/2407.16682"}
{"created":"2025-04-15","title":"MMCLIP: Cross-modal Attention Masked Modelling for Medical Language-Image Pre-Training","abstract":"Vision-and-language pretraining (VLP) in the medical field utilizes contrastive learning on image-text pairs to achieve effective transfer across tasks. Yet, current VLP approaches with the masked modeling strategy face two challenges when applied to the medical domain. First, current models struggle to accurately reconstruct key pathological features due to the scarcity of medical data. Second, most methods only adopt either paired image-text or image-only data, failing to exploit the combination of both paired and unpaired data. To this end, this paper proposes the MMCLIP (Masked Medical Contrastive Language-Image Pre-Training) framework to enhance pathological learning and feature learning via unpaired data. First, we introduce the attention-masked image modeling (AttMIM) and entity-driven masked language modeling module (EntMLM), which learns to reconstruct pathological visual and textual tokens via multi-modal feature interaction, thus improving medical-enhanced features. The AttMIM module masks a portion of the image features that are highly responsive to textual features. This allows MMCLIP to improve the reconstruction of highly similar image data in medicine efficiency. Second, our MMCLIP capitalizes unpaired data to enhance multimodal learning by introducing disease-kind prompts. The experimental results show that MMCLIP achieves SOTA for zero-shot and fine-tuning classification performance on five datasets. Our code will be available at https://github.com/White65534/MMCLIP.","authors":["Biao Wu","Yutong Xie","Zeyu Zhang","Minh Hieu Phan","Qi Chen","Ling Chen","Qi Wu"],"url":"https://arxiv.org/abs/2407.19546"}
{"created":"2025-04-15","title":"To Spike or Not to Spike, that is the Question","abstract":"Neuromorphic computing has recently gained momentum with the emergence of various neuromorphic processors. As the field advances, there is an increasing focus on developing training methods that can effectively leverage the unique properties of spiking neural networks (SNNs). SNNs emulate the temporal dynamics of biological neurons, making them particularly well-suited for real-time, event-driven processing. To fully harness the potential of SNNs across different neuromorphic platforms, effective training methodologies are essential. In SNNs, learning rules are based on neurons' spiking behavior, that is, if and when spikes are generated due to a neuron's membrane potential exceeding that neuron's spiking threshold, and this spike timing encodes vital information. However, the threshold is generally treated as a hyperparameter, and incorrect selection can lead to neurons that do not spike for large portions of the training process, hindering the effective rate of learning. This work focuses on the significance of learning neuron thresholds alongside weights in SNNs. Our results suggest that promoting threshold from a hyperparameter to a trainable parameter effectively addresses the issue of dead neurons during training. This leads to a more robust training algorithm, resulting in improved convergence, increased test accuracy, and a substantial reduction in the number of training epochs required to achieve viable accuracy on spatiotemporal datasets such as NMNIST, DVS128, and Spiking Heidelberg Digits (SHD), with up to 30% training speed-up and up to 2% higher accuracy on these datasets.","authors":["Sanaz Mahmoodi Takaghaj","Jack Sampson"],"url":"https://arxiv.org/abs/2407.19566"}
{"created":"2025-04-15","title":"MimiQ: Low-Bit Data-Free Quantization of Vision Transformers with Encouraging Inter-Head Attention Similarity","abstract":"Data-free quantization (DFQ) is a technique that creates a lightweight network from its full-precision counterpart without the original training data, often through a synthetic dataset. Although several DFQ methods have been proposed for vision transformer (ViT) architectures, they fail to achieve efficacy in low-bit settings. Examining the existing methods, we observe that their synthetic data produce misaligned attention maps, while those of the real samples are highly aligned. From this observation, we find that aligning attention maps of synthetic data helps improve the overall performance of quantized ViTs. Motivated by this finding, we devise MimiQ, a novel DFQ method designed for ViTs that enhances inter-head attention similarity. First, we generate synthetic data by aligning head-wise attention outputs from each spatial query patch. Then, we align the attention maps of the quantized network to those of the full-precision teacher by applying head-wise structural attention distillation. The experimental results show that the proposed method significantly outperforms baselines, setting a new state-of-the-art for ViT-DFQ. This paper is an extended version of our work published in the proceedings of AAAI 2025, including additional supplementary material.","authors":["Kanghyun Choi","Hye Yoon Lee","Dain Kwon","SunJong Park","Kyuyeun Kim","Noseong Park","Jonghyun Choi","Jinho Lee"],"url":"https://arxiv.org/abs/2407.20021"}
{"created":"2025-04-15","title":"ExpertAF: Expert Actionable Feedback from Video","abstract":"Feedback is essential for learning a new skill or improving one's current skill-level. However, current methods for skill-assessment from video only provide scores or compare demonstrations, leaving the burden of knowing what to do differently on the user. We introduce a novel method to generate actionable feedback (AF) from video of a person doing a physical activity, such as basketball or soccer. Our method takes a video demonstration and its accompanying 3D body pose and generates (1) free-form expert commentary describing what the person is doing well and what they could improve, and (2) a visual expert demonstration that incorporates the required corrections. We show how to leverage Ego-Exo4D's [29] videos of skilled activity and expert commentary together with a strong language model to create a weakly-supervised training dataset for this task, and we devise a multimodal video-language model to infer coaching feedback. Our method is able to reason across multi-modal input combinations to output full spectrum, actionable coaching-expert commentary, expert video retrieval, and expert pose generation-outperforming strong vision-language models on both established metrics and human preference studies.","authors":["Kumar Ashutosh","Tushar Nagarajan","Georgios Pavlakos","Kris Kitani","Kristen Grauman"],"url":"https://arxiv.org/abs/2408.00672"}
{"created":"2025-04-15","title":"Conceptualizing Trustworthiness and Trust in Communications","abstract":"Trustworthiness and trust are basic factors in common societies that allow us to interact and enjoy being in crowds without fear. As robotic devices start percolating into our daily lives they must behave as fully trustworthy objects, such that humans accept them just as we trust interacting with other people in our daily lives.","authors":["Gerhard P. Fettweis","Patricia Gr\\\"unberg","Tim Hentschel","Stefan K\\\"opsell"],"url":"https://arxiv.org/abs/2408.01447"}
{"created":"2025-04-15","title":"From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future","abstract":"With the rise of large language models (LLMs), researchers are increasingly exploring their applications in var ious vertical domains, such as software engineering. LLMs have achieved remarkable success in areas including code generation and vulnerability detection. However, they also exhibit numerous limitations and shortcomings. LLM-based agents, a novel tech nology with the potential for Artificial General Intelligence (AGI), combine LLMs as the core for decision-making and action-taking, addressing some of the inherent limitations of LLMs such as lack of autonomy and self-improvement. Despite numerous studies and surveys exploring the possibility of using LLMs in software engineering, it lacks a clear distinction between LLMs and LLM based agents. It is still in its early stage for a unified standard and benchmarking to qualify an LLM solution as an LLM-based agent in its domain. In this survey, we broadly investigate the current practice and solutions for LLMs and LLM-based agents for software engineering. In particular we summarise six key topics: requirement engineering, code generation, autonomous decision-making, software design, test generation, and software maintenance. We review and differentiate the work of LLMs and LLM-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics. Finally, we discuss the models and benchmarks used, providing a comprehensive analysis of their applications and effectiveness in software engineering. We anticipate this work will shed some lights on pushing the boundaries of LLM-based agents in software engineering for future research.","authors":["Haolin Jin","Linghan Huang","Haipeng Cai","Jun Yan","Bo Li","Huaming Chen"],"url":"https://arxiv.org/abs/2408.02479"}
{"created":"2025-04-15","title":"Avoid Wasted Annotation Costs in Open-set Active Learning with Pre-trained Vision-Language Model","abstract":"Active learning (AL) aims to enhance model performance by selectively collecting highly informative data, thereby minimizing annotation costs. However, in practical scenarios, unlabeled data may contain out-of-distribution (OOD) samples, which are not used for training, leading to wasted annotation costs if data is incorrectly selected. Therefore, to make active learning feasible in real-world applications, it is crucial to consider not only the informativeness of unlabeled samples but also their purity to determine whether they belong to the in-distribution (ID). Recent studies have applied AL under these assumptions, but challenges remain due to the trade-off between informativeness and purity, as well as the heavy dependence on OOD samples. These issues lead to the collection of OOD samples, resulting in a significant waste of annotation costs. To address these challenges, we propose a novel query strategy, VLPure-AL, which minimizes cost losses while reducing dependence on OOD samples. VLPure-AL sequentially evaluates the purity and informativeness of data. First, it utilizes a pre-trained vision-language model to detect and exclude OOD data with high accuracy by leveraging linguistic and visual information of ID data. Second, it selects highly informative data from the remaining ID data, and then the selected samples are annotated by human experts. Experimental results on datasets with various open-set conditions demonstrate that VLPure-AL achieves the lowest cost loss and highest performance across all scenarios. Code is available at https://github.com/DSBA-Lab/OpenAL.","authors":["Jaehyuk Heo","Pilsung Kang"],"url":"https://arxiv.org/abs/2408.04917"}
{"created":"2025-04-15","title":"Online-Score-Aided Federated Learning: Taming the Resource Constraints in Wireless Networks","abstract":"While federated learning (FL) is a widely popular distributed machine learning (ML) strategy that protects data privacy, time-varying wireless network parameters and heterogeneous configurations of the wireless devices pose significant challenges. Although the limited radio and computational resources of the network and the clients, respectively, are widely acknowledged, two critical yet often ignored aspects are (a) wireless devices can only dedicate a small chunk of their limited storage for the FL task and (b) new training samples may arrive in an online manner in many practical wireless applications. Therefore, we propose a new FL algorithm called online-score-aided federated learning (OSAFL), specifically designed to learn tasks relevant to wireless applications under these practical considerations. Since clients' local training steps differ under resource constraints, which may lead to client drift under statistically heterogeneous data distributions, we leverage normalized gradient similarities and exploit weighting clients' updates based on optimized scores that facilitate the convergence rate of the proposed OSAFL algorithm without incurring any communication overheads to the clients or requiring any statistical data information from them. Our extensive simulation results on two different datasets with four popular ML models validate the effectiveness of OSAFL compared to five modified state-of-the-art FL baselines.","authors":["Md-Ferdous Pervej","Minseok Choi","Andreas F. Molisch"],"url":"https://arxiv.org/abs/2408.05886"}
{"created":"2025-04-15","title":"Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models","abstract":"Language Model (LM) agents for cybersecurity that are capable of autonomously identifying vulnerabilities and executing exploits have potential to cause real-world impact. Policymakers, model providers, and researchers in the AI and cybersecurity communities are interested in quantifying the capabilities of such agents to help mitigate cyberrisk and investigate opportunities for penetration testing. Toward that end, we introduce Cybench, a framework for specifying cybersecurity tasks and evaluating agents on those tasks. We include 40 professional-level Capture the Flag (CTF) tasks from 4 distinct CTF competitions, chosen to be recent, meaningful, and spanning a wide range of difficulties. Each task includes its own description, starter files, and is initialized in an environment where an agent can execute commands and observe outputs. Since many tasks are beyond the capabilities of existing LM agents, we introduce subtasks for each task, which break down a task into intermediary steps for a more detailed evaluation. To evaluate agent capabilities, we construct a cybersecurity agent and evaluate 8 models: GPT-4o, OpenAI o1-preview, Claude 3 Opus, Claude 3.5 Sonnet, Mixtral 8x22b Instruct, Gemini 1.5 Pro, Llama 3 70B Chat, and Llama 3.1 405B Instruct. For the top performing models (GPT-4o and Claude 3.5 Sonnet), we further investigate performance across 4 agent scaffolds (structed bash, action-only, pseudoterminal, and web search). Without subtask guidance, agents leveraging Claude 3.5 Sonnet, GPT-4o, OpenAI o1-preview, and Claude 3 Opus successfully solved complete tasks that took human teams up to 11 minutes to solve. In comparison, the most difficult task took human teams 24 hours and 54 minutes to solve. All code and data are publicly available at https://cybench.github.io.","authors":["Andy K. Zhang","Neil Perry","Riya Dulepet","Joey Ji","Celeste Menders","Justin W. Lin","Eliot Jones","Gashon Hussein","Samantha Liu","Donovan Jasper","Pura Peetathawatchai","Ari Glenn","Vikram Sivashankar","Daniel Zamoshchin","Leo Glikbarg","Derek Askaryar","Mike Yang","Teddy Zhang","Rishi Alluri","Nathan Tran","Rinnara Sangpisit","Polycarpos Yiorkadjis","Kenny Osele","Gautham Raghupathi","Dan Boneh","Daniel E. Ho","Percy Liang"],"url":"https://arxiv.org/abs/2408.08926"}
{"created":"2025-04-15","title":"Infinite Scrolling, Finite Satisfaction: Exploring User Behavior and Satisfaction on Social Media in Bangladesh","abstract":"Social media platforms continue to change our digital relationships nowadays. Therefore, recognizing the complex consequences of infinite scrolling is essential. This paper explores two distinct angles of social media engagement: mindless scrolling and mindful scrolling. This extensive study dives into numerous aspects of social media user behavior and satisfaction via the perspective of multiple surveys. We investigate the psychological exploit of infinite scrolling design to keep users engaged, illuminating its effect on users' emotional well-being. Furthermore, we explore its diverse effects on various groups, such as teenagers, professional people, and pregnant women, to better understand how digital activity differs throughout life phases. Furthermore, our study reveals the psychological consequences of being exposed to unfavorable news material. In the context of nutritional objectives, we examine the problems users confront as well as the significance of scrolling in dietary achievement. By taking into account the demographic effect, we can determine how factors like age, gender, and socioeconomic position affect user behavior. This study presents a comprehensive knowledge of the complicated connection of infinite scrolling with user satisfaction and psychological well-being through a variety of surveys, opening the door for well-informed conversations on online engagement.","authors":["Sanzana Karim Lora","Sadia Afrin Purba","Bushra Hossain","Tanjina Oriana","Ashek Seum","Sadia Sharmin"],"url":"https://arxiv.org/abs/2408.09601"}
{"created":"2025-04-15","title":"LEAD: Towards Learning-Based Equity-Aware Decarbonization in Ridesharing Platforms","abstract":"Ridesharing platforms such as Uber, Lyft, and DiDi have grown in popularity due to their on-demand availability, ease of use, and commute cost reductions, among other benefits. However, not all ridesharing promises have panned out. Recent studies demonstrate that the expected drop in traffic congestion and reduction in greenhouse gas (GHG) emissions have not materialized. This is primarily due to the substantial distances traveled by the ridesharing vehicles without passengers between rides, known as deadhead miles. Recent work has focused on reducing the impact of deadhead miles while considering additional metrics such as rider waiting time, GHG emissions from deadhead miles, or driver earnings. However, most prior studies consider these environmental and equity-based metrics individually despite them being interrelated. In this paper, we propose a Learning-based Equity-Aware Decarabonization approach, LEAD, for ridesharing platforms. LEAD targets minimizing emissions while ensuring that the driver's utility, defined as the difference between the trip distance and the deadhead miles, is fairly distributed. LEAD uses reinforcement learning to match riders with drivers based on the expected future utility of drivers and the expected carbon emissions of the platform without increasing the rider waiting times. Extensive experiments based on a real-world ridesharing dataset show that LEAD improves the defined notion of fairness by 150% when compared to emission-aware ride-assignment and reduces emissions by 14.6% while ensuring fairness within 28--52% of the fairness-focused baseline. It also reduces the rider wait time, by at least 32.1%, compared to a fairness-focused baseline.","authors":["Mahsa Sahebdel","Ali Zeynali","Noman Bashir","Prashant Shenoy","Mohammad Hajiesmaili"],"url":"https://arxiv.org/abs/2408.10201"}
{"created":"2025-04-15","title":"Efficient Exploration and Discriminative World Model Learning with an Object-Centric Abstraction","abstract":"In the face of difficult exploration problems in reinforcement learning, we study whether giving an agent an object-centric mapping (describing a set of items and their attributes) allow for more efficient learning. We found this problem is best solved hierarchically by modelling items at a higher level of state abstraction to pixels, and attribute change at a higher level of temporal abstraction to primitive actions. This abstraction simplifies the transition dynamic by making specific future states easier to predict. We make use of this to propose a fully model-based algorithm that learns a discriminative world model, plans to explore efficiently with only a count-based intrinsic reward, and can subsequently plan to reach any discovered (abstract) states.","authors":["Anthony GX-Chen","Kenneth Marino","Rob Fergus"],"url":"https://arxiv.org/abs/2408.11816"}
{"created":"2025-04-15","title":"Reconciling Different Theories of Learning with an Agent-based Model of Procedural Learning","abstract":"Computational models of human learning can play a significant role in enhancing our knowledge about nuances in theoretical and qualitative learning theories and frameworks. There are many existing frameworks in educational settings that have shown to be verified using empirical studies, but at times we find these theories make conflicting claims or recommendations for instruction. In this study, we propose a new computational model of human learning, Procedural ABICAP, that reconciles the ICAP, Knowledge-Learning-Instruction (KLI), and cognitive load theory (CLT) frameworks for learning procedural knowledge. ICAP assumes that constructive learning generally yields better learning outcomes, while theories such as KLI and CLT claim that this is not always true. We suppose that one reason for this may be that ICAP is primarily used for conceptual learning and is underspecified as a framework for thinking about procedural learning. We show how our computational model, both by design and through simulations, can be used to reconcile different results in the literature. More generally, we position our computational model as an executable theory of learning that can be used to simulate various educational settings.","authors":["Sina Rismanchian","Shayan Doroudi"],"url":"https://arxiv.org/abs/2408.13364"}
{"created":"2025-04-15","title":"An Embedding is Worth a Thousand Noisy Labels","abstract":"The performance of deep neural networks scales with dataset size and label quality, rendering the efficient mitigation of low-quality data annotations crucial for building robust and cost-effective systems. Existing strategies to address label noise exhibit severe limitations due to computational complexity and application dependency. In this work, we propose WANN, a Weighted Adaptive Nearest Neighbor approach that builds on self-supervised feature representations obtained from foundation models. To guide the weighted voting scheme, we introduce a reliability score $\\eta$, which measures the likelihood of a data label being correct. WANN outperforms reference methods, including a linear layer trained with robust loss functions, on diverse datasets of varying size and under various noise types and severities. WANN also exhibits superior generalization on imbalanced data compared to both Adaptive-NNs (ANN) and fixed k-NNs. Furthermore, the proposed weighting scheme enhances supervised dimensionality reduction under noisy labels. This yields a significant boost in classification performance with 10x and 100x smaller image embeddings, minimizing latency and storage requirements. Our approach, emphasizing efficiency and explainability, emerges as a simple, robust solution to overcome inherent limitations of deep neural network training. The code is available at https://github.com/francescodisalvo05/wann-noisy-labels .","authors":["Francesco Di Salvo","Sebastian Doerrich","Ines Rieger","Christian Ledig"],"url":"https://arxiv.org/abs/2408.14358"}
{"created":"2025-04-15","title":"Signals as submanifolds, and configurations of points","abstract":"For the purposes of abstract theory of signal propagation, a signal is a submanifold of a Riemannian manifold. We obtain energy inequalities, or upper bounds, lower bounds on energy in a number of specific cases, including parameter spaces of Gaussians and spaces of configurations of points. We discuss the role of time as well as graph embeddings.","authors":["Tatyana Barron","Spencer Kelly","Colin Poulton"],"url":"https://arxiv.org/abs/2408.15375"}
{"created":"2025-04-15","title":"Explicit Folded Reed-Solomon and Multiplicity Codes Achieve Relaxed Generalized Singleton Bounds","abstract":"In this paper, we prove that explicit FRS codes and multiplicity codes achieve relaxed generalized Singleton bounds for list size $L\\ge1.$ Specifically, we show the following: (1) FRS code of length $n$ and rate $R$ over the alphabet $\\mathbb{F}_q^s$ with distinct evaluation points is $\\left(\\frac{L}{L+1}\\left(1-\\frac{sR}{s-L+1}\\right),L\\right)$ list-decodable (LD) for list size $L\\in[s]$. (2) Multiplicity code of length $n$ and rate $R$ over the alphabet $\\mathbb{F}_p^s$ with distinct evaluation points is $\\left(\\frac{L}{L+1}\\left(1-\\frac{sR}{s-L+1}\\right),L\\right)$ LD for list size $L\\in[s]$.","authors":["Yeyuan Chen","Zihan Zhang"],"url":"https://arxiv.org/abs/2408.15925"}
{"created":"2025-04-15","title":"Time series classification with random convolution kernels: pooling operators and input representations matter","abstract":"This article presents a new approach based on MiniRocket, called SelF-Rocket, for fast time series classification (TSC). Unlike existing approaches based on random convolution kernels, it dynamically selects the best couple of input representations and pooling operator during the training process. SelF-Rocket achieves state-of-the-art accuracy on the University of California Riverside (UCR) TSC benchmark datasets.","authors":["Mouhamadou Mansour Lo","Gildas Morvan","Mathieu Rossi","Fabrice Morganti","David Mercier"],"url":"https://arxiv.org/abs/2409.01115"}
{"created":"2025-04-15","title":"Designing Large Foundation Models for Efficient Training and Inference: A Survey","abstract":"This paper focuses on modern efficient training and inference technologies on foundation models and illustrates them from two perspectives: model and system design. Model and System Design optimize LLM training and inference from different aspects to save computational resources, making LLMs more efficient, affordable, and more accessible. The paper list repository is available at https://github.com/NoakLiu/Efficient-Foundation-Models-Survey.","authors":["Dong Liu","Yanxuan Yu","Yite Wang","Jing Wu","Zhongwei Wan","Sina Alinejad","Benjamin Lengerich","Ying Nian Wu"],"url":"https://arxiv.org/abs/2409.01990"}
{"created":"2025-04-15","title":"On the computational power of $C$-random strings","abstract":"Denote by $H$ the Halting problem. Let $R_U: = \\{ x | C_U(x) \\ge |x|\\}$, where $C_U(x)$ is the plain Kolmogorov complexity of $x$ under a universal decompressor $U$. We prove that there exists a universal $U$ such that $H \\in P^{R_U}$, solving the problem posted by Eric Allender.","authors":["Alexey Milovanov"],"url":"https://arxiv.org/abs/2409.04448"}
{"created":"2025-04-15","title":"On pattern formation in the thermodynamically-consistent variational Gray-Scott model","abstract":"In this paper, we explore pattern formation in a four-species variational Gary-Scott model, which includes all reverse reactions and introduces a virtual species to describe the birth-death process in the classical Gray-Scott model. This modification transforms the classical Gray-Scott model into a thermodynamically consistent closed system. The classical two-species Gray-Scott model can be viewed as a subsystem of the variational model in the limiting case when the small parameter $\\epsilon$, related to the reaction rate of the reverse reactions, approaches zero. We numerically explore pattern formation in this physically more complete Gray-Scott model in one spatial dimension, using non-uniform steady states of the classical model as initial conditions. By decreasing $\\epsilon$, we observed that the stationary pattern in the classical Gray-Scott model can be stabilized as the transient state in the variational model for a significantly small $\\epsilon$. Additionally, the variational model admits oscillating and traveling-wave-like patterns for small $\\epsilon$. The persistent time of these patterns is on the order of $O(\\epsilon^{-1})$. We also analyze the energy stability of two uniform steady states in the variational Gary-Scott model for fixed $\\epsilon$. Although both states are stable in a certain sense, the gradient flow type dynamics of the variational model exhibit a selection effect based on the initial conditions, with pattern formation occurring only if the initial condition does not converge to the boundary steady state, which corresponds to the trivial uniform steady state in the classical Gray-Scott model.","authors":["Wenrui Hao","Chun Liu","Yiwei Wang","Yahong Yang"],"url":"https://arxiv.org/abs/2409.04663"}
{"created":"2025-04-15","title":"Using Large Language Models for Template Detection from Security Event Logs","abstract":"In modern IT systems and computer networks, real-time and offline event log analysis is a crucial part of cyber security monitoring. In particular, event log analysis techniques are essential for the timely detection of cyber attacks and for assisting security experts with the analysis of past security incidents. The detection of line patterns or templates from unstructured textual event logs has been identified as an important task of event log analysis since detected templates represent event types in the event log and prepare the logs for downstream online or offline security monitoring tasks. During the last two decades, a number of template mining algorithms have been proposed. However, many proposed algorithms rely on traditional data mining techniques, and the usage of Large Language Models (LLMs) has received less attention so far. Also, most approaches that harness LLMs are supervised, and unsupervised LLM-based template mining remains an understudied area. The current paper addresses this research gap and investigates the application of LLMs for unsupervised detection of templates from unstructured security event logs.","authors":["Risto Vaarandi","Hayretdin Bahsi"],"url":"https://arxiv.org/abs/2409.05045"}
{"created":"2025-04-15","title":"Generative Recommender with End-to-End Learnable Item Tokenization","abstract":"Generative recommendation systems have gained increasing attention as an innovative approach that directly generates item identifiers for recommendation tasks. Despite their potential, a major challenge is the effective construction of item identifiers that align well with recommender systems. Current approaches often treat item tokenization and generative recommendation training as separate processes, which can lead to suboptimal performance. To overcome this issue, we introduce ETEGRec, a novel End-To-End Generative Recommender that unifies item tokenization and generative recommendation into a cohesive framework. Built on a dual encoder-decoder architecture, ETEGRec consists of an item tokenizer and a generative recommender. To enable synergistic interaction between these components, we propose a recommendation-oriented alignment strategy, which includes two key optimization objectives: sequence-item alignment and preference-semantic alignment. These objectives tightly couple the learning processes of the item tokenizer and the generative recommender, fostering mutual enhancement. Additionally, we develop an alternating optimization technique to ensure stable and efficient end-to-end training of the entire framework. Extensive experiments demonstrate the superior performance of our approach compared to traditional sequential recommendation models and existing generative recommendation baselines.","authors":["Enze Liu","Bowen Zheng","Cheng Ling","Lantao Hu","Han Li","Wayne Xin Zhao"],"url":"https://arxiv.org/abs/2409.05546"}
{"created":"2025-04-15","title":"AMBER -- Advanced SegFormer for Multi-Band Image Segmentation: an application to Hyperspectral Imaging","abstract":"Deep learning has revolutionized the field of hyperspectral image (HSI) analysis, enabling the extraction of complex spectral and spatial features. While convolutional neural networks (CNNs) have been the backbone of HSI classification, their limitations in capturing global contextual features have led to the exploration of Vision Transformers (ViTs). This paper introduces AMBER, an advanced SegFormer specifically designed for multi-band image segmentation. AMBER enhances the original SegFormer by incorporating three-dimensional convolutions, custom kernel sizes, and a Funnelizer layer. This architecture enables processing hyperspectral data directly, without requiring spectral dimensionality reduction during preprocessing. Our experiments, conducted on three benchmark datasets (Salinas, Indian Pines, and Pavia University) and on a dataset from the PRISMA satellite, show that AMBER outperforms traditional CNN-based methods in terms of Overall Accuracy, Kappa coefficient, and Average Accuracy on the first three datasets, and achieves state-of-the-art performance on the PRISMA dataset. These findings highlight AMBER's robustness, adaptability to both airborne and spaceborne data, and its potential as a powerful solution for remote sensing and other domains requiring advanced analysis of high-dimensional data.","authors":["Andrea Dosi","Massimo Brescia","Stefano Cavuoti","Mariarca D'Aniello","Michele Delli Veneri","Carlo Donadio","Adriano Ettari","Giuseppe Longo","Alvi Rownok","Luca Sannino","Maria Zampella"],"url":"https://arxiv.org/abs/2409.09386"}
{"created":"2025-04-15","title":"Offline Reinforcement Learning for Learning to Dispatch for Job Shop Scheduling","abstract":"The Job Shop Scheduling Problem (JSSP) is a complex combinatorial optimization problem. While online Reinforcement Learning (RL) has shown promise by quickly finding acceptable solutions for JSSP, it faces key limitations: it requires extensive training interactions from scratch leading to sample inefficiency, cannot leverage existing high-quality solutions, and often yields suboptimal results compared to traditional methods like Constraint Programming (CP). We introduce Offline Reinforcement Learning for Learning to Dispatch (Offline-LD), which addresses these limitations by learning from previously generated solutions. Our approach is motivated by scenarios where historical scheduling data and expert solutions are available, although our current evaluation focuses on benchmark problems. Offline-LD adapts two CQL-based Q-learning methods (mQRDQN and discrete mSAC) for maskable action spaces, introduces a novel entropy bonus modification for discrete SAC, and exploits reward normalization through preprocessing. Our experiments demonstrate that Offline-LD outperforms online RL on both generated and benchmark instances. Notably, by introducing noise into the expert dataset, we achieve similar or better results than those obtained from the expert dataset, suggesting that a more diverse training set is preferable because it contains counterfactual information.","authors":["Jesse van Remmerden","Zaharah Bukhsh","Yingqian Zhang"],"url":"https://arxiv.org/abs/2409.10589"}
{"created":"2025-04-15","title":"Integrating Reinforcement Learning and Model Predictive Control with Applications to Microgrids","abstract":"This work proposes an approach that integrates reinforcement learning and model predictive control (MPC) to solve finite-horizon optimal control problems in mixed-logical dynamical systems efficiently. Optimization-based control of such systems with discrete and continuous decision variables entails the online solution of mixed-integer linear programs, which suffer from the curse of dimensionality. Our approach aims to mitigate this issue by decoupling the decision on the discrete variables from the decision on the continuous variables. In the proposed approach, reinforcement learning determines the discrete decision variables and simplifies the online optimization problem of the MPC controller from a mixed-integer linear program to a linear program, significantly reducing the computational time. A fundamental contribution of this work is the definition of the decoupled Q-function, which plays a crucial role in making the learning problem tractable in a combinatorial action space. We motivate the use of recurrent neural networks to approximate the decoupled Q-function and show how they can be employed in a reinforcement learning setting. Simulation experiments on a microgrid system using real-world data demonstrate that the proposed method substantially reduces the online computation time of MPC while maintaining high feasibility and low suboptimality.","authors":["Caio Fabio Oliveira da Silva","Azita Dabiri","Bart De Schutter"],"url":"https://arxiv.org/abs/2409.11267"}
{"created":"2025-04-15","title":"Depth Estimation Based on 3D Gaussian Splatting Siamese Defocus","abstract":"Depth estimation is a fundamental task in 3D geometry. While stereo depth estimation can be achieved through triangulation methods, it is not as straightforward for monocular methods, which require the integration of global and local information. The Depth from Defocus (DFD) method utilizes camera lens models and parameters to recover depth information from blurred images and has been proven to perform well. However, these methods rely on All-In-Focus (AIF) images for depth estimation, which is nearly impossible to obtain in real-world applications. To address this issue, we propose a self-supervised framework based on 3D Gaussian splatting and Siamese networks. By learning the blur levels at different focal distances of the same scene in the focal stack, the framework predicts the defocus map and Circle of Confusion (CoC) from a single defocused image, using the defocus map as input to DepthNet for monocular depth estimation. The 3D Gaussian splatting model renders defocused images using the predicted CoC, and the differences between these and the real defocused images provide additional supervision signals for the Siamese Defocus self-supervised network. This framework has been validated on both artificially synthesized and real blurred datasets. Subsequent quantitative and visualization experiments demonstrate that our proposed framework is highly effective as a DFD method.","authors":["Jinchang Zhang","Ningning Xu","Hao Zhang","Guoyu Lu"],"url":"https://arxiv.org/abs/2409.12323"}
{"created":"2025-04-15","title":"End-to-end Open-vocabulary Video Visual Relationship Detection using Multi-modal Prompting","abstract":"Open-vocabulary video visual relationship detection aims to expand video visual relationship detection beyond annotated categories by detecting unseen relationships between both seen and unseen objects in videos. Existing methods usually use trajectory detectors trained on closed datasets to detect object trajectories, and then feed these trajectories into large-scale pre-trained vision-language models to achieve open-vocabulary classification. Such heavy dependence on the pre-trained trajectory detectors limits their ability to generalize to novel object categories, leading to performance degradation. To address this challenge, we propose to unify object trajectory detection and relationship classification into an end-to-end open-vocabulary framework. Under this framework, we propose a relationship-aware open-vocabulary trajectory detector. It primarily consists of a query-based Transformer decoder, where the visual encoder of CLIP is distilled for frame-wise open-vocabulary object detection, and a trajectory associator. To exploit relationship context during trajectory detection, a relationship query is embedded into the Transformer decoder, and accordingly, an auxiliary relationship loss is designed to enable the decoder to perceive the relationships between objects explicitly. Moreover, we propose an open-vocabulary relationship classifier that leverages the rich semantic knowledge of CLIP to discover novel relationships. To adapt CLIP well to relationship classification, we design a multi-modal prompting method that employs spatio-temporal visual prompting for visual representation and vision-guided language prompting for language input. Extensive experiments on two public datasets, VidVRD and VidOR, demonstrate the effectiveness of our framework. Our framework is also applied to a more difficult cross-dataset scenario to further demonstrate its generalization ability.","authors":["Yongqi Wang","Xinxiao Wu","Shuo Yang","Jiebo Luo"],"url":"https://arxiv.org/abs/2409.12499"}
{"created":"2025-04-15","title":"A Personalised 3D+t Mesh Generative Model for Unveiling Normal Heart Dynamics","abstract":"Understanding the structure and motion of the heart is crucial for diagnosing and managing cardiovascular diseases, the leading cause of global death. There is wide variation in cardiac shape and motion patterns, that are influenced by demographic, anthropometric and disease factors. Unravelling the normal patterns of shape and motion, as well as understanding how each individual deviates from the norm, would facilitate accurate diagnosis and personalised treatment strategies. To this end, we developed a novel conditional generative model, MeshHeart, to learn the distribution of cardiac shape and motion patterns. MeshHeart is capable of generating 3D+t cardiac mesh sequences, taking into account clinical factors such as age, sex, weight and height. To model the high-dimensional and complex spatio-temporal mesh data, MeshHeart employs a geometric encoder to represent cardiac meshes in a latent space, followed by a temporal Transformer to model the motion dynamics of latent representations. Based on MeshHeart, we investigate the latent space of 3D+t cardiac mesh sequences and propose a novel distance metric termed latent delta, which quantifies the deviation of a real heart from its personalised normative pattern in the latent space. In experiments using a large dataset of 38,309 subjects, MeshHeart demonstrates a high performance in cardiac mesh sequence reconstruction and generation. Features defined in the latent space are highly discriminative for cardiac disease classification, whereas the latent delta exhibits strong correlation with clinical phenotypes in phenome-wide association studies. The codes and models of this study will be released to benefit further research on digital heart modelling.","authors":["Mengyun Qiao","Kathryn A McGurk","Shuo Wang","Paul M. Matthews","Declan P O Regan","Wenjia Bai"],"url":"https://arxiv.org/abs/2409.13825"}
{"created":"2025-04-15","title":"Block-Attention for Efficient Prefilling","abstract":"We introduce Block-attention, an attention mechanism designed to address the increased inference latency and cost in Retrieval-Augmented Generation (RAG) scenarios. Traditional approaches often encode the entire context in an auto-regressive manner. Instead, Block-attention divides retrieved documents into discrete blocks, with each block independently calculating key-value (KV) states except for the final block. In RAG scenarios, by defining each passage as a block, Block-attention enables us to reuse the KV states of passages that have been seen before, thereby significantly reducing the latency and the computation overhead during inference. The implementation of Block-attention involves block segmentation, position re-encoding, and fine-tuning the LLM to adapt to the Block-attention mechanism. Experiments on 11 diverse benchmarks, including RAG, ICL, and general domains, demonstrate that after block fine-tuning, the Block-attention model not only achieves performance comparable to that of full-attention models, but can also seamlessly switch between the block and full attention modes without any performance loss. Notably, Block-attention significantly reduces the time to first token (TTFT) and floating point operations (FLOPs) to a very low level. It only takes 45 ms to output the first token for an input sequence with a total length of 32K. Compared to the full-attention models, the TTFT and corresponding FLOPs are reduced by 98.7% and 99.8%, respectively. Additionally, in Appendix A, we elaborate on how Block-attention is applied in Game AI scenario and the substantial potential benefits it entails. We strongly suggest researchers in the gaming field not to overlook this section.","authors":["Dongyang Ma","Yan Wang","Lan Tian"],"url":"https://arxiv.org/abs/2409.15355"}
{"created":"2025-04-15","title":"A positive meshless finite difference scheme for scalar conservation laws with adaptive artificial viscosity driven by fault detection","abstract":"We present a meshless finite difference method for multivariate scalar conservation laws that generates positive schemes satisfying a local maximum principle on irregular nodes and relies on artificial viscosity for shock capturing. Coupling two different numerical differentiation formulas and the adaptive selection of the sets of influence allows to meet a local CFL condition without any {\\it a priori}\\ time step restriction. The artificial viscosity term is chosen in an adaptive way by applying it only in the vicinity of the sharp features of the solution identified by an algorithm for fault detection on scattered data. Numerical tests demonstrate a robust performance of the method on irregular nodes and advantages of adaptive artificial viscosity. The accuracy of the obtained solutions is comparable to that for standard monotone methods available only on Cartesian grids.","authors":["Cesare Bracco","Oleg Davydov","Carlotta Giannelli","Alessandra Sestini"],"url":"https://arxiv.org/abs/2409.15544"}
{"created":"2025-04-15","title":"HELIOT: LLM-Based CDSS for Adverse Drug Reaction Management","abstract":"Medication errors significantly threaten patient safety, leading to adverse drug events and substantial economic burdens on healthcare systems. Clinical Decision Support Systems (CDSSs) aimed at mitigating these errors often face limitations when processing unstructured clinical data, including reliance on static databases and rule-based algorithms, frequently generating excessive alerts that lead to alert fatigue among healthcare providers. This paper introduces HELIOT, an innovative CDSS for adverse drug reaction management that processes free-text clinical information using Large Language Models (LLMs) integrated with a comprehensive pharmaceutical data repository. HELIOT leverages advanced natural language processing capabilities to interpret medical narratives, extract relevant drug reaction information from unstructured clinical notes, and learn from past patient-specific medication tolerances to reduce false alerts, enabling more nuanced and contextual adverse drug event warnings across primary care, specialist consultations, and hospital settings. An initial evaluation using a synthetic dataset of clinical narratives and expert-verified ground truth shows promising results. HELIOT achieves high accuracy in a controlled setting. In addition, by intelligently analyzing previous medication tolerance documented in clinical notes and distinguishing between cases requiring different alert types, HELIOT can potentially reduce interruptive alerts by over 50% compared to traditional CDSSs. While these preliminary findings are encouraging, real-world validation will be essential to confirm these benefits in clinical practice.","authors":["Gabriele De Vito","Filomena Ferrucci","Athanasios Angelakis"],"url":"https://arxiv.org/abs/2409.16395"}
{"created":"2025-04-15","title":"Joint Mobile IAB Node Positioning and Scheduler Selection in Locations With Substantial Obstacles","abstract":"Integrated Access and Backhaul (IAB) in cellular networks combines access and backhaul within a wireless infrastructure reducing reliance on fibre-based backhaul. This enables faster and more cost-effective network expansion, especially in hard-to-reach areas. Positioning a mobile IAB node (MIAB) in a seaport environment, in order to ensure ondemand, resilient wireless connectivity, presents unique challenges due to the high density of User Equipments (UEs) and potential shadowing effects caused by obstacles. This paper addresses the problem of positioning MIABs within areas containing UEs, IAB donors (CFs), and obstacles. Our approach considers user associations and different types of scheduling, ensuring MIABs and CFs meet the capacity requirements of a special team of served UEs, while not exceeding backhaul capacity. Using Genetic Algorithm (GA) solver, we achieve capacity improvement gains, by up to 200% for the 90th percentile. The proposed solution improves network performance, particularly during emergency capacity demands.","authors":["Paulo Furtado Correia","Andre Coelho","Manuel Ricardo"],"url":"https://arxiv.org/abs/2409.16831"}
{"created":"2025-04-15","title":"Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification","abstract":"In the medical field, the limited availability of large-scale datasets and labor-intensive annotation processes hinder the performance of deep models. Diffusion-based generative augmentation approaches present a promising solution to this issue, having been proven effective in advancing downstream medical recognition tasks. Nevertheless, existing works lack sufficient semantic and sequential steerability for challenging video/3D sequence generation, and neglect quality control of noisy synthesized samples, resulting in unreliable synthetic databases and severely limiting the performance of downstream tasks. In this work, we present Ctrl-GenAug, a novel and general generative augmentation framework that enables highly semantic- and sequential-customized sequence synthesis and suppresses incorrectly synthesized samples, to aid medical sequence classification. Specifically, we first design a multimodal conditions-guided sequence generator for controllably synthesizing diagnosis-promotive samples. A sequential augmentation module is integrated to enhance the temporal/stereoscopic coherence of generated samples. Then, we propose a noisy synthetic data filter to suppress unreliable cases at semantic and sequential levels. Extensive experiments on 3 medical datasets, using 11 networks trained on 3 paradigms, comprehensively analyze the effectiveness and generality of Ctrl-GenAug, particularly in underrepresented high-risk populations and out-domain conditions.","authors":["Xinrui Zhou","Yuhao Huang","Haoran Dou","Shijing Chen","Ao Chang","Jia Liu","Weiran Long","Jian Zheng","Erjiao Xu","Jie Ren","Ruobing Huang","Jun Cheng","Wufeng Xue","Dong Ni"],"url":"https://arxiv.org/abs/2409.17091"}
{"created":"2025-04-15","title":"Comodule Representations of Second-Order Functionals","abstract":"We develop and investigate a general theory of representations of second-order functionals, based on a notion of a right comodule for a monad on the category of containers. We show how the notion of comodule representability naturally subsumes classic representations of continuous functionals with well-founded trees. We find other kinds of representations by varying the monad, the comodule, and in some cases the underlying category of containers. Examples include uniformly continuous or finitely supported functionals, functionals querying their arguments precisely once, or at most once, functionals interacting with an ambient environment through computational effects, as well as functionals trivially representing themselves. Many of these rely on our construction of a monad on containers from a monad on shapes and a weak Mendler-style monad algebra on the universe for positions. We show that comodule representability on the category of propositional containers, which have positions valued in a universe of propositions, is closely related to instance reducibility in constructive mathematics, and through it to Weihrauch reducibility in computability theory.","authors":["Danel Ahman","Andrej Bauer"],"url":"https://arxiv.org/abs/2409.17664"}
{"created":"2025-04-15","title":"Leveraging Anthropometric Measurements to Improve Human Mesh Estimation and Ensure Consistent Body Shapes","abstract":"The basic body shape (i.e., the body shape in T-pose) of a person does not change within a single video. However, most SOTA human mesh estimation (HME) models output a slightly different, thus inconsistent basic body shape for each video frame. Furthermore, we find that SOTA 3D human pose estimation (HPE) models outperform HME models regarding the precision of the estimated 3D keypoint positions. We solve the problem of inconsistent body shapes by leveraging anthropometric measurements like taken by tailors from humans. We create a model called A2B that converts given anthropometric measurements to basic body shape parameters of human mesh models. We obtain superior and consistent human meshes by combining the A2B model results with the keypoints of 3D HPE models using inverse kinematics. We evaluate our approach on challenging datasets like ASPset or fit3D, where we can lower the MPJPE by over 30 mm compared to SOTA HME models. Further, replacing estimates of the body shape parameters from existing HME models with A2B results not only increases the performance of these HME models, but also guarantees consistent body shapes.","authors":["Katja Ludwig","Julian Lorenz","Daniel Kienzle","Tuan Bui","Rainer Lienhart"],"url":"https://arxiv.org/abs/2409.17671"}
{"created":"2025-04-15","title":"Enhancing Tourism Recommender Systems for Sustainable City Trips Using Retrieval-Augmented Generation","abstract":"Tourism Recommender Systems (TRS) have traditionally focused on providing personalized travel suggestions, often prioritizing user preferences without considering broader sustainability goals. Integrating sustainability into TRS has become essential with the increasing need to balance environmental impact, local community interests, and visitor satisfaction. This paper proposes a novel approach to enhancing TRS for sustainable city trips using Large Language Models (LLMs) and a modified Retrieval-Augmented Generation (RAG) pipeline. We enhance the traditional RAG system by incorporating a sustainability metric based on a city's popularity and seasonal demand during the prompt augmentation phase. This modification, called Sustainability Augmented Reranking (SAR), ensures the system's recommendations align with sustainability goals. Evaluations using popular open-source LLMs, such as Llama-3.1-Instruct-8B and Mistral-Instruct-7B, demonstrate that the SAR-enhanced approach consistently matches or outperforms the baseline (without SAR) across most metrics, highlighting the benefits of incorporating sustainability into TRS.","authors":["Ashmi Banerjee","Adithi Satish","Wolfgang W\\\"orndl"],"url":"https://arxiv.org/abs/2409.18003"}
{"created":"2025-04-15","title":"Imitater: An Efficient Shared Mempool Protocol with Application to Byzantine Fault Tolerance","abstract":"Byzantine Fault Tolerant (BFT) consensus, a cornerstone of blockchain technology, has seen significant advancements. While existing BFT protocols ensure security guarantees, they often suffer from efficiency challenges, particularly under conditions of network instability or malicious exploitation of system mechanisms.","authors":["Qingming Zeng (Harbin Institute of Technology","Shenzhen)","Mo Li (The Chinese University of Hongkong","Shenzhen)","Ximing Fu (Harbin Institute of Technology","Shenzhen)","Chuanyi Liu (Harbin Institute of Technology","Shenzhen","Peng Cheng Laboratory","Shenzhen)","Hui Jiang (Tsinghua University","Baidu Inc)"],"url":"https://arxiv.org/abs/2409.19286"}
{"created":"2025-04-15","title":"Bi-directional Momentum-based Haptic Feedback and Control System for In-Hand Dexterous Telemanipulation","abstract":"In-hand dexterous telemanipulation requires not only precise remote motion control of the robot but also effective haptic feedback to the human operator to ensure stable and intuitive interactions between them. Most existing haptic devices for dexterous telemanipulation focus on force feedback and lack effective torque rendering, which is essential for tasks involving object rotation. While some torque feedback solutions in virtual reality applications-such as those based on geared motors or mechanically coupled actuators-have been explored, they often rely on bulky mechanical designs, limiting their use in portable or in-hand applications. In this paper, we propose a Bi-directional Momentum-based Haptic Feedback and Control (Bi-Hap) system that utilizes a palm-sized momentum-actuated mechanism to enable real-time haptic and torque feedback. The Bi-Hap system also integrates an Inertial Measurement Unit (IMU) to extract the human's manipulation command to establish a closed-loop learning-based telemanipulation framework. Furthermore, an error-adaptive feedback strategy is introduced to enhance operator perception and task performance in different error categories. Experimental evaluations demonstrate that Bi-Hap achieved feedback capability with low command following latency (Delay < 0.025 s) and highly accurate torque feedback (RMSE < 0.010 Nm).","authors":["Haoyang Wang (Oklahoma State University)","Haoran Guo (Oklahoma State University)","He Ba (Oklahoma State University)","Zhengxiong Li (University of Colorado Denver)","Lingfeng Tao (Oklahoma State University)"],"url":"https://arxiv.org/abs/2409.20527"}
{"created":"2025-04-15","title":"Probing Mechanical Reasoning in Large Vision Language Models","abstract":"Mechanical reasoning is a hallmark of human intelligence, defined by its ubiquitous yet irreplaceable role in human activities ranging from routine tasks to civil engineering. Embedding machines with mechanical reasoning is therefore an important step towards building human-level artificial intelligence. Here, we leveraged 155 cognitive experiments to test the understanding of system stability, gears and pulley systems, leverage principle, inertia and motion, and fluid mechanics in 26 Vision Language Models (VLMs). Results indicate that VLMs consistently perform worse than humans on all domains, while demonstrate significant difficulty in reasoning about gear systems and fluid mechanics. Notably, their performance on these tasks do not improve as number of parameters increase, suggesting that current attention-based architecture may fail to grasp certain underlying mechanisms required for mechanical reasoning, particularly those pertaining to mental simulations.","authors":["Haoran Sun","Qingying Gao","Haiyun Lyu","Dezhi Luo","Yijiang Li","Hokin Deng"],"url":"https://arxiv.org/abs/2410.00318"}
{"created":"2025-04-15","title":"Vision Language Models See What You Want but not What You See","abstract":"Knowing others' intentions and taking others' perspectives are two core components of human intelligence that are considered to be instantiations of theory-of-mind. Infiltrating machines with these abilities is an important step towards building human-level artificial intelligence. Here, to investigate intentionality understanding and level-2 perspective-taking in Vision Language Models (VLMs), we constructed the IntentBench and PerspectBench, which together contains over 300 cognitive experiments grounded in real-world scenarios and classic cognitive tasks. We found VLMs achieving high performance on intentionality understanding but low performance on level-2 perspective-taking. This suggests a potential dissociation between simulation-based and theory-based theory-of-mind abilities in VLMs, highlighting the concern that they are not capable of using model-based reasoning to infer others' mental states. See $\\href{https://growing-ai-like-a-child.github.io/}{Website}$","authors":["Qingying Gao","Yijiang Li","Haiyun Lyu","Haoran Sun","Dezhi Luo","Hokin Deng"],"url":"https://arxiv.org/abs/2410.00324"}
{"created":"2025-04-15","title":"Vision Language Models Know Law of Conservation without Understanding More-or-Less","abstract":"Understanding law of conservation is a critical milestone in human cognitive development considered to be supported by the apprehension of quantitative concepts and the reversibility of operations. To assess whether this critical component of human intelligence has emerged in Vision Language Models, we have curated the ConserveBench, a battery of 365 cognitive experiments across four dimensions of physical quantities: volume, solid quantity, length, and number. The former two involve transformational tasks which require reversibility understanding. The latter two involve non-transformational tasks which assess quantity understanding. Surprisingly, we find that while Vision Language Models are generally good at transformational tasks, they tend to fail at non-transformational tasks. There is a dissociation between understanding the reversibility of operations and understanding the concept of quantity, which both are believed to be the cornerstones of understanding law of conservation in humans. $\\href{https://growing-ai-like-a-child.github.io/}{Website}$","authors":["Dezhi Luo","Haiyun Lyu","Qingying Gao","Haoran Sun","Yijiang Li","Hokin Deng"],"url":"https://arxiv.org/abs/2410.00332"}
{"created":"2025-04-15","title":"Adaptive teachers for amortized samplers","abstract":"Amortized inference is the task of training a parametric model, such as a neural network, to approximate a distribution with a given unnormalized density where exact sampling is intractable. When sampling is implemented as a sequential decision-making process, reinforcement learning (RL) methods, such as generative flow networks, can be used to train the sampling policy. Off-policy RL training facilitates the discovery of diverse, high-reward candidates, but existing methods still face challenges in efficient exploration. We propose to use an adaptive training distribution (the \\teacher) to guide the training of the primary amortized sampler (the \\student). The \\teacher, an auxiliary behavior model, is trained to sample high-loss regions of the \\student and can generalize across unexplored modes, thereby enhancing mode coverage by providing an efficient training curriculum. We validate the effectiveness of this approach in a synthetic environment designed to present an exploration challenge, two diffusion-based sampling tasks, and four biochemical discovery tasks demonstrating its ability to improve sample efficiency and mode coverage. Source code is available at https://github.com/alstn12088/adaptive-teacher.","authors":["Minsu Kim","Sanghyeok Choi","Taeyoung Yun","Emmanuel Bengio","Leo Feng","Jarrid Rector-Brooks","Sungsoo Ahn","Jinkyoo Park","Nikolay Malkin","Yoshua Bengio"],"url":"https://arxiv.org/abs/2410.01432"}
{"created":"2025-04-15","title":"Convergence of Score-Based Discrete Diffusion Models: A Discrete-Time Analysis","abstract":"Diffusion models have achieved great success in generating high-dimensional samples across various applications. While the theoretical guarantees for continuous-state diffusion models have been extensively studied, the convergence analysis of the discrete-state counterparts remains under-explored. In this paper, we study the theoretical aspects of score-based discrete diffusion models under the Continuous Time Markov Chain (CTMC) framework. We introduce a discrete-time sampling algorithm in the general state space $[S]^d$ that utilizes score estimators at predefined time points. We derive convergence bounds for the Kullback-Leibler (KL) divergence and total variation (TV) distance between the generated sample distribution and the data distribution, considering both scenarios with and without early stopping under reasonable assumptions. Notably, our KL divergence bounds are nearly linear in the dimension $d$, aligning with state-of-the-art results for diffusion models. Our convergence analysis employs a Girsanov-based method and establishes key properties of the discrete score function, which are essential for characterizing the discrete-time sampling process.","authors":["Zikun Zhang","Zixiang Chen","Quanquan Gu"],"url":"https://arxiv.org/abs/2410.02321"}
{"created":"2025-04-15","title":"FakeShield: Explainable Image Forgery Detection and Localization via Multi-modal Large Language Models","abstract":"The rapid development of generative AI is a double-edged sword, which not only facilitates content creation but also makes image manipulation easier and more difficult to detect. Although current image forgery detection and localization (IFDL) methods are generally effective, they tend to face two challenges: \\textbf{1)} black-box nature with unknown detection principle, \\textbf{2)} limited generalization across diverse tampering methods (e.g., Photoshop, DeepFake, AIGC-Editing). To address these issues, we propose the explainable IFDL task and design FakeShield, a multi-modal framework capable of evaluating image authenticity, generating tampered region masks, and providing a judgment basis based on pixel-level and image-level tampering clues. Additionally, we leverage GPT-4o to enhance existing IFDL datasets, creating the Multi-Modal Tamper Description dataSet (MMTD-Set) for training FakeShield's tampering analysis capabilities. Meanwhile, we incorporate a Domain Tag-guided Explainable Forgery Detection Module (DTE-FDM) and a Multi-modal Forgery Localization Module (MFLM) to address various types of tamper detection interpretation and achieve forgery localization guided by detailed textual descriptions. Extensive experiments demonstrate that FakeShield effectively detects and localizes various tampering techniques, offering an explainable and superior solution compared to previous IFDL methods. The code is available at https://github.com/zhipeixu/FakeShield.","authors":["Zhipei Xu","Xuanyu Zhang","Runyi Li","Zecheng Tang","Qing Huang","Jian Zhang"],"url":"https://arxiv.org/abs/2410.02761"}
{"created":"2025-04-15","title":"ProtoMed-LLM: An Automatic Evaluation Framework for Large Language Models in Medical Protocol Formulation","abstract":"Automated generation of scientific protocols executable by robots can significantly accelerate scientific research processes. Large Language Models (LLMs) excel at Scientific Protocol Formulation Tasks (SPFT), but the evaluation of their capabilities rely on human evaluation. Here, we propose a flexible, automatic framework to evaluate LLMs' capability on SPFT: ProtoMed-LLM. This framework prompts the target model and GPT-4 to extract pseudocode from biology protocols using only predefined lab actions and evaluates the output of the target model using LLAM-EVAL, the pseudocode generated by GPT-4 serving as a baseline and Llama-3 acting as the evaluator. Our adaptable prompt-based evaluation method, LLAM-EVAL, offers significant flexibility in terms of evaluation model, material, criteria, and is free of cost. We evaluate GPT variations, Llama, Mixtral, Gemma, Cohere, and Gemini. Overall, we find that GPT and Cohere are powerful scientific protocol formulators. We also introduce BIOPROT 2.0, a dataset with biology protocols and corresponding pseudocodes, which can aid LLMs in formulation and evaluation of SPFT. Our work is extensible to assess LLMs on SPFT across various domains and other fields that require protocol generation for specific goals.","authors":["Seungjun Yi","Jaeyoung Lim","Juyong Yoon"],"url":"https://arxiv.org/abs/2410.04601"}
{"created":"2025-04-15","title":"ReasoningRank: Teaching Student Models to Rank through Reasoning-Based Knowledge Distillation","abstract":"Reranking documents based on their relevance to a given query is a critical task in information retrieval. Traditional reranking methods often lack transparency and rely on proprietary models, hindering reproducibility and interpretability. We propose Reason-to-Rank (R2R), a novel open-source reranking approach that enhances transparency by generating two types of reasoning: direct relevance reasoning, which explains how a document addresses the query, and comparison reasoning, which justifies the relevance of one document over another. We leverage large language models (LLMs) as teacher models to generate these explanations and distill this knowledge into smaller, openly available student models. Our student models are trained to generate meaningful reasoning and rerank documents, achieving competitive performance across multiple datasets, including MSMARCO and BRIGHT. Experiments demonstrate that R2R not only improves reranking accuracy but also provides valuable insights into the decision-making process. By offering a structured and interpretable solution with openly accessible resources, R2R aims to bridge the gap between effectiveness and transparency in information retrieval, fostering reproducibility and further research in the field.","authors":["Yuelyu Ji","Zhuochun Li","Rui Meng","Daqing He"],"url":"https://arxiv.org/abs/2410.05168"}
{"created":"2025-04-15","title":"DartControl: A Diffusion-Based Autoregressive Motion Model for Real-Time Text-Driven Motion Control","abstract":"Text-conditioned human motion generation, which allows for user interaction through natural language, has become increasingly popular. Existing methods typically generate short, isolated motions based on a single input sentence. However, human motions are continuous and can extend over long periods, carrying rich semantics. Creating long, complex motions that precisely respond to streams of text descriptions, particularly in an online and real-time setting, remains a significant challenge. Furthermore, incorporating spatial constraints into text-conditioned motion generation presents additional challenges, as it requires aligning the motion semantics specified by text descriptions with geometric information, such as goal locations and 3D scene geometry. To address these limitations, we propose DartControl, in short DART, a Diffusion-based Autoregressive motion primitive model for Real-time Text-driven motion control. Our model effectively learns a compact motion primitive space jointly conditioned on motion history and text inputs using latent diffusion models. By autoregressively generating motion primitives based on the preceding history and current text input, DART enables real-time, sequential motion generation driven by natural language descriptions. Additionally, the learned motion primitive space allows for precise spatial motion control, which we formulate either as a latent noise optimization problem or as a Markov decision process addressed through reinforcement learning. We present effective algorithms for both approaches, demonstrating our model's versatility and superior performance in various motion synthesis tasks. Experiments show our method outperforms existing baselines in motion realism, efficiency, and controllability. Video results are available on the project page: https://zkf1997.github.io/DART/.","authors":["Kaifeng Zhao","Gen Li","Siyu Tang"],"url":"https://arxiv.org/abs/2410.05260"}
{"created":"2025-04-15","title":"Continuous Ensemble Weather Forecasting with Diffusion models","abstract":"Weather forecasting has seen a shift in methods from numerical simulations to data-driven systems. While initial research in the area focused on deterministic forecasting, recent works have used diffusion models to produce skillful ensemble forecasts. These models are trained on a single forecasting step and rolled out autoregressively. However, they are computationally expensive and accumulate errors for high temporal resolution due to the many rollout steps. We address these limitations with Continuous Ensemble Forecasting, a novel and flexible method for sampling ensemble forecasts in diffusion models. The method can generate temporally consistent ensemble trajectories completely in parallel, with no autoregressive steps. Continuous Ensemble Forecasting can also be combined with autoregressive rollouts to yield forecasts at an arbitrary fine temporal resolution without sacrificing accuracy. We demonstrate that the method achieves competitive results for global weather forecasting with good probabilistic properties.","authors":["Martin Andrae","Tomas Landelius","Joel Oskarsson","Fredrik Lindsten"],"url":"https://arxiv.org/abs/2410.05431"}
{"created":"2025-04-15","title":"MM-Ego: Towards Building Egocentric Multimodal LLMs for Video QA","abstract":"This research aims to comprehensively explore building a multimodal foundation model for egocentric video understanding. To achieve this goal, we work on three fronts. First, as there is a lack of QA data for egocentric video understanding, we automatically generate 7M high-quality QA samples for egocentric videos ranging from 30 seconds to one hour long in Ego4D based on human-annotated data. This is one of the largest egocentric QA datasets. Second, we contribute a challenging egocentric QA benchmark with 629 videos and 7,026 questions to evaluate the models' ability in recognizing and memorizing visual details across videos of varying lengths. We introduce a new de-biasing evaluation method to help mitigate the unavoidable language bias present in the models being evaluated. Third, we propose a specialized multimodal architecture featuring a novel \"Memory Pointer Prompting\" mechanism. This design includes a \\textit{global glimpse} step to gain an overarching understanding of the entire video and identify key visual information, followed by a fallback step that utilizes the key visual information to generate responses. This enables the model to more effectively comprehend extended video content. With the data, benchmark, and model, we build MM-Ego, an egocentric multimodal LLM that shows powerful performance on egocentric video understanding.","authors":["Hanrong Ye","Haotian Zhang","Erik Daxberger","Lin Chen","Zongyu Lin","Yanghao Li","Bowen Zhang","Haoxuan You","Dan Xu","Zhe Gan","Jiasen Lu","Yinfei Yang"],"url":"https://arxiv.org/abs/2410.07177"}
{"created":"2025-04-15","title":"Autonomous Evaluation of LLMs for Truth Maintenance and Reasoning Tasks","abstract":"This paper presents AutoEval, a novel benchmark for scaling Large Language Model (LLM) assessment in formal tasks with clear notions of correctness, such as truth maintenance in translation and logical reasoning. AutoEval is the first benchmarking paradigm that offers several key advantages necessary for scaling objective evaluation of LLMs without human labeling: (a) ability to evaluate LLMs of increasing sophistication by auto-generating tasks at different levels of difficulty; (b) auto-generation of ground truth that eliminates dependence on expensive and time-consuming human annotation; (c) the use of automatically generated, randomized datasets that mitigate the ability of successive LLMs to overfit to static datasets used in many contemporary benchmarks. Empirical analysis shows that an LLM's performance on AutoEval is highly indicative of its performance on a diverse array of other benchmarks focusing on translation and reasoning tasks, making it a valuable autonomous evaluation paradigm in settings where hand-curated datasets can be hard to obtain and/or update.","authors":["Rushang Karia","Daniel Bramblett","Daksh Dobhal","Siddharth Srivastava"],"url":"https://arxiv.org/abs/2410.08437"}
{"created":"2025-04-15","title":"Exact Byte-Level Probabilities from Tokenized Language Models for FIM-Tasks and Model Ensembles","abstract":"Tokenization is associated with many poorly understood shortcomings in language models (LMs), yet remains an important component for long sequence scaling purposes. This work studies how tokenization impacts model performance by analyzing and comparing the stochastic behavior of tokenized models with their byte-level, or token-free, counterparts. We discover that, even when the two models are statistically equivalent, their predictive distributions over the next byte can be substantially different, a phenomenon we term as ``tokenization bias''. To fully characterize this phenomenon, we introduce the Byte-Token Representation Lemma, a framework that establishes a mapping between the learned token distribution and its equivalent byte-level distribution. From this result, we develop a next-byte sampling algorithm that eliminates tokenization bias without requiring further training or optimization. In other words, this enables zero-shot conversion of tokenized LMs into statistically equivalent token-free ones. We demonstrate its broad applicability with two use cases: fill-in-the-middle (FIM) tasks and model ensembles. In FIM tasks where input prompts may terminate mid-token, leading to out-of-distribution tokenization, our method mitigates performance degradation and achieves 18% improvement in FIM coding benchmarks, while consistently outperforming the standard token healing fix. For model ensembles where each model employs a distinct vocabulary, our approach enables seamless integration, resulting in improved performance up to 3.7% over individual models across various standard baselines in reasoning, knowledge, and coding. Code is available at: https://github.com/facebookresearch/Exact-Byte-Level-Probabilities-from-Tokenized-LMs","authors":["Buu Phan","Brandon Amos","Itai Gat","Marton Havasi","Matthew Muckley","Karen Ullrich"],"url":"https://arxiv.org/abs/2410.09303"}
{"created":"2025-04-15","title":"HG2P: Hippocampus-inspired High-reward Graph and Model-Free Q-Gradient Penalty for Path Planning and Motion Control","abstract":"Goal-conditioned hierarchical reinforcement learning (HRL) decomposes complex reaching tasks into a sequence of simple subgoal-conditioned tasks, showing significant promise for addressing long-horizon planning in large-scale environments. This paper bridges the goal-conditioned HRL based on graph-based planning to brain mechanisms, proposing a hippocampus-striatum-like dual-controller hypothesis. Inspired by the brain mechanisms of organisms (i.e., the high-reward preferences observed in hippocampal replay) and instance-based theory, we propose a high-return sampling strategy for constructing memory graphs, improving sample efficiency. Additionally, we derive a model-free lower-level Q-function gradient penalty to resolve the model dependency issues present in prior work, improving the generalization of Lipschitz constraints in applications. Finally, we integrate these two extensions, High-reward Graph and model-free Gradient Penalty (HG2P), into the state-of-the-art framework ACLG, proposing a novel goal-conditioned HRL framework, HG2P+ACLG. Experimentally, the results demonstrate that our method outperforms state-of-the-art goal-conditioned HRL algorithms on a variety of long-horizon navigation tasks and robotic manipulation tasks.","authors":["Haoran Wang","Yaoru Sun","Zeshen Tang","Haibo Shi","Chenyuan Jiao"],"url":"https://arxiv.org/abs/2410.09505"}
{"created":"2025-04-15","title":"Improving Colorectal Cancer Screening and Risk Assessment through Predictive Modeling on Medical Images and Records","abstract":"Colonoscopy screening effectively identifies and removes polyps before they progress to colorectal cancer (CRC), but current follow-up guidelines rely primarily on histopathological features, overlooking other important CRC risk factors. Variability in polyp characterization among pathologists also hinders consistent surveillance decisions. Advances in digital pathology and deep learning enable the integration of pathology slides and medical records for more accurate CRC risk prediction. Using data from the New Hampshire Colonoscopy Registry, including longitudinal follow-up, we adapted a transformer-based model for histopathology image analysis to predict 5-year CRC risk. We further explored multi-modal fusion strategies to combine clinical records with deep learning-derived image features. Training the model to predict intermediate clinical variables improved 5-year CRC risk prediction (AUC = 0.630) compared to direct prediction (AUC = 0.615, p = 0.013). Incorporating both imaging and non-imaging data, without requiring manual slide review, further improved performance (AUC = 0.674) compared to traditional features from colonoscopy and microscopy reports (AUC = 0.655, p = 0.001). These results highlight the value of integrating diverse data modalities with computational methods to enhance CRC risk stratification.","authors":["Shuai Jiang","Christina Robinson","Joseph Anderson","William Hisey","Lynn Butterly","Arief Suriawinata","Saeed Hassanpour"],"url":"https://arxiv.org/abs/2410.09880"}
{"created":"2025-04-15","title":"Large Language Model-Enhanced Reinforcement Learning for Generic Bus Holding Control Strategies","abstract":"Bus holding control is a widely-adopted strategy for maintaining stability and improving the operational efficiency of bus systems. Traditional model-based methods often face challenges with the low accuracy of bus state prediction and passenger demand estimation. In contrast, Reinforcement Learning (RL), as a data-driven approach, has demonstrated great potential in formulating bus holding strategies. RL determines the optimal control strategies in order to maximize the cumulative reward, which reflects the overall control goals. However, translating sparse and delayed control goals in real-world tasks into dense and real-time rewards for RL is challenging, normally requiring extensive manual trial-and-error. In view of this, this study introduces an automatic reward generation paradigm by leveraging the in-context learning and reasoning capabilities of Large Language Models (LLMs). This new paradigm, termed the LLM-enhanced RL, comprises several LLM-based modules: reward initializer, reward modifier, performance analyzer, and reward refiner. These modules cooperate to initialize and iteratively improve the reward function according to the feedback from training and test results for the specified RL-based task. Ineffective reward functions generated by the LLM are filtered out to ensure the stable evolution of the RL agents' performance over iterations. To evaluate the feasibility of the proposed LLM-enhanced RL paradigm, it is applied to extensive bus holding control scenarios that vary in the number of bus lines, stops, and passenger demand. The results demonstrate the superiority, generalization capability, and robustness of the proposed paradigm compared to vanilla RL strategies, the LLM-based controller, physics-based feedback controllers, and optimization-based controllers. This study sheds light on the great potential of utilizing LLMs in various smart mobility applications.","authors":["Jiajie Yu","Yuhong Wang","Wei Ma"],"url":"https://arxiv.org/abs/2410.10212"}
{"created":"2025-04-15","title":"GeOT: A spatially explicit framework for evaluating spatio-temporal predictions","abstract":"When predicting observations across space and time, the spatial layout of errors impacts a model's real-world utility. For instance, in bike sharing demand prediction, error patterns translate to relocation costs. However, commonly used error metrics in GeoAI evaluate predictions point-wise, neglecting effects such as spatial heterogeneity, autocorrelation, and the Modifiable Areal Unit Problem. We put forward Optimal Transport (OT) as a spatial evaluation metric and loss function. The proposed framework, called GeOT, assesses the performance of prediction models by quantifying the transport costs associated with their prediction errors. Through experiments on real and synthetic data, we demonstrate that 1) the spatial distribution of prediction errors relates to real-world costs in many applications, 2) OT captures these spatial costs more accurately than existing metrics, and 3) OT enhances comparability across spatial and temporal scales. Finally, we advocate for leveraging OT as a loss function in neural networks to improve the spatial accuracy of predictions. Experiments with bike sharing, charging station, and traffic datasets show that spatial costs are significantly reduced with only marginal changes to non-spatial error metrics. Thus, this approach not only offers a spatially explicit tool for model evaluation and selection, but also integrates spatial considerations into model training. All code is available at https://github.com/mie-lab/geospatialOT.","authors":["Nina Wiedemann","Th\\'eo Uscidda","Martin Raubal"],"url":"https://arxiv.org/abs/2410.11709"}
{"created":"2025-04-15","title":"Improving Instruction-Following in Language Models through Activation Steering","abstract":"The ability to follow instructions is crucial for numerous real-world applications of language models. In pursuit of deeper insights and more powerful capabilities, we derive instruction-specific vector representations from language models and use them to steer models accordingly. These vectors are computed as the difference in activations between inputs with and without instructions, enabling a modular approach to activation steering. We demonstrate how this method can enhance model adherence to constraints such as output format, length, and word inclusion, providing inference-time control over instruction following. Our experiments across four models demonstrate how we can use the activation vectors to guide models to follow constraints even without explicit instructions and to enhance performance when instructions are present. Additionally, we explore the compositionality of activation steering, successfully applying multiple instructions simultaneously. Finally, we demonstrate that steering vectors computed on instruction-tuned models can transfer to improve base models. Our findings demonstrate that activation steering offers a practical and scalable approach for fine-grained control in language generation. Our code and data are available at https://github.com/microsoft/llm-steer-instruct.","authors":["Alessandro Stolfo","Vidhisha Balachandran","Safoora Yousefi","Eric Horvitz","Besmira Nushi"],"url":"https://arxiv.org/abs/2410.12877"}
{"created":"2025-04-15","title":"Verification of Linear Dynamical Systems via O-Minimality of the Real Numbers","abstract":"A discrete-time linear dynamical system (LDS) is given by an update matrix $M \\in \\mathbb{R}^{d\\times d}$, and has the trajectories $\\langle s, Ms, M^2s, \\ldots \\rangle$ for $s \\in \\mathbb{R}^d$. Reachability-type decision problems of linear dynamical systems, most notably the Skolem Problem, lie at the forefront of decidability: typically, sound and complete algorithms are known only in low dimensions, and these rely on sophisticated tools from number theory and Diophantine approximation. Recently, however, o-minimality has emerged as a counterpoint to these number-theoretic tools that allows us to decide certain modifications of the classical problems of LDS without any dimension restrictions. In this paper, we first introduce the Decomposition Method, a framework that captures all applications of o-minimality to decision problems of LDS that are currently known to us. We then use the Decomposition Method to show decidability of the Robust Safety Problem (restricted to bounded initial sets) in arbitrary dimension: given a matrix $M$, a bounded semialgebraic set $S$ of initial points, and a semialgebraic set $T$ of unsafe points, it is decidable whether there exists $\\varepsilon > 0$ such that all orbits that begin in the $\\varepsilon$-ball around $S$ avoid $T$.","authors":["Toghrul Karimov"],"url":"https://arxiv.org/abs/2410.13053"}
{"created":"2025-04-15","title":"Enabling Scalable Evaluation of Bias Patterns in Medical LLMs","abstract":"Large language models (LLMs) have shown impressive potential in helping with numerous medical challenges. Deploying LLMs in high-stakes applications such as medicine, however, brings in many concerns. One major area of concern relates to biased behaviors of LLMs in medical applications, leading to unfair treatment of individuals. To pave the way for the responsible and impactful deployment of Med LLMs, rigorous evaluation is a key prerequisite. Due to the huge complexity and variability of different medical scenarios, existing work in this domain has primarily relied on using manually crafted datasets for bias evaluation. In this study, we present a new method to scale up such bias evaluations by automatically generating test cases based on rigorous medical evidence. We specifically target the challenges of a) domain-specificity of bias characterization, b) hallucinating while generating the test cases, and c) various dependencies between the health outcomes and sensitive attributes. To that end, we offer new methods to address these challenges integrated with our generative pipeline, using medical knowledge graphs, medical ontologies, and customized general LLM evaluation frameworks in our method. Through a series of extensive experiments, we show that the test cases generated by our proposed method can effectively reveal bias patterns in Med LLMs at larger and more flexible scales than human-crafted datasets. We publish a large bias evaluation dataset using our pipeline, which is dedicated to a few medical case studies. A live demo of our application for vignette generation is available at https://vignette.streamlit.app. Our code is also available at https://github.com/healthylaife/autofair.","authors":["Hamed Fayyaz","Raphael Poulain","Rahmatollah Beheshti"],"url":"https://arxiv.org/abs/2410.14763"}
{"created":"2025-04-15","title":"A Multimodal Vision Foundation Model for Clinical Dermatology","abstract":"Diagnosing and treating skin diseases require advanced visual skills across domains and the ability to synthesize information from multiple imaging modalities. While current deep learning models excel at specific tasks like skin cancer diagnosis from dermoscopic images, they struggle to meet the complex, multimodal requirements of clinical practice. Here, we introduce PanDerm, a multimodal dermatology foundation model pretrained through self-supervised learning on over 2 million real-world skin disease images from 11 clinical institutions across 4 imaging modalities. We evaluated PanDerm on 28 diverse benchmarks, including skin cancer screening, risk stratification, differential diagnosis of common and rare skin conditions, lesion segmentation, longitudinal monitoring, and metastasis prediction and prognosis. PanDerm achieved state-of-the-art performance across all evaluated tasks, often outperforming existing models when using only 10% of labeled data. We conducted three reader studies to assess PanDerm's potential clinical utility. PanDerm outperformed clinicians by 10.2% in early-stage melanoma detection through longitudinal analysis, improved clinicians' skin cancer diagnostic accuracy by 11% on dermoscopy images, and enhanced non-dermatologist healthcare providers' differential diagnosis by 16.5% across 128 skin conditions on clinical photographs. These results demonstrate PanDerm's potential to improve patient care across diverse clinical scenarios and serve as a model for developing multimodal foundation models in other medical specialties, potentially accelerating the integration of AI support in healthcare. The code can be found at https://github.com/SiyuanYan1/PanDerm.","authors":["Siyuan Yan","Zhen Yu","Clare Primiero","Cristina Vico-Alonso","Zhonghua Wang","Litao Yang","Philipp Tschandl","Ming Hu","Lie Ju","Gin Tan","Vincent Tang","Aik Beng Ng","David Powell","Paul Bonnington","Simon See","Elisabetta Magnaterra","Peter Ferguson","Jennifer Nguyen","Pascale Guitera","Jose Banuls","Monika Janda","Victoria Mar","Harald Kittler","H. Peter Soyer","Zongyuan Ge"],"url":"https://arxiv.org/abs/2410.15038"}
{"created":"2025-04-15","title":"SmartGSN: an online tool to semi-automatically manage assurance cases","abstract":"Developing industry-wide standards and ensuring producers of mission-critical systems comply with them is crucial to fostering consumer acceptance. Producers of such systems can rely on assurance cases to demonstrate to regulatory authorities how they have complied with such standards to help prevent system failure, which could result in fatalities and environmental damage. In this paper, we introduce SmartGSN, an innovative online tool that relies on Large Language Models to (semi-)automate the management of assurance cases complying with GSN - a very popular notation to graphically represent assurance cases. The evaluation of SmartGSN demonstrates its strong capability to detect assurance case patterns within the assurance cases manually created for five systems spanning several application domains. SmartGSN is accessible online at [https://smartgsn.vercel.app], and a demonstration video can be viewed at [https://youtu.be/qLrTHf-SZbM]","authors":["Oluwafemi Odu","Daniel M\\'endez Beltran","Emiliano Berrones Guti\\'errez","Alvine B. Belle","Gerhard Yu","Melika Sherafat"],"url":"https://arxiv.org/abs/2410.16675"}
{"created":"2025-04-15","title":"HyperspectralViTs: General Hyperspectral Models for On-board Remote Sensing","abstract":"On-board processing of hyperspectral data with machine learning models would enable unprecedented amount of autonomy for a wide range of tasks, for example methane detection or mineral identification. This can enable early warning system and could allow new capabilities such as automated scheduling across constellations of satellites. Classical methods suffer from high false positive rates and previous deep learning models exhibit prohibitive computational requirements. We propose fast and accurate machine learning architectures which support end-to-end training with data of high spectral dimension without relying on hand-crafted products or spectral band compression preprocessing. We evaluate our models on two tasks related to hyperspectral data processing. With our proposed general architectures, we improve the F1 score of the previous methane detection state-of-the-art models by 27% on a newly created synthetic dataset and by 13% on the previously released large benchmark dataset. We also demonstrate that training models on the synthetic dataset improves performance of models finetuned on the dataset of real events by 6.9% in F1 score in contrast with training from scratch. On a newly created dataset for mineral identification, our models provide 3.5% improvement in the F1 score in contrast to the default versions of the models. With our proposed models we improve the inference speed by 85% in contrast to previous classical and deep learning approaches by removing the dependency on classically computed features. With our architecture, one capture from the EMIT sensor can be processed within 30 seconds on realistic proxy of the ION-SCV 004 satellite.","authors":["V\\'it R\\r{u}\\v{z}i\\v{c}ka","Andrew Markham"],"url":"https://arxiv.org/abs/2410.17248"}
{"created":"2025-04-15","title":"WAGLE: Strategic Weight Attribution for Effective and Modular Unlearning in Large Language Models","abstract":"The need for effective unlearning mechanisms in large language models (LLMs) is increasingly urgent, driven by the necessity to adhere to data regulations and foster ethical generative AI practices. Despite growing interest of LLM unlearning, much of the existing research has focused on varied unlearning method designs to boost effectiveness and efficiency. However, the inherent relationship between model weights and LLM unlearning has not been extensively examined. In this paper, we systematically explore how model weights interact with unlearning processes in LLMs and we design the weight attribution-guided LLM unlearning method, WAGLE, which unveils the interconnections between 'influence' of weights and 'influence' of data to forget and retain in LLM generation. By strategically guiding the LLM unlearning across different types of unlearning methods and tasks, WAGLE can erase the undesired content, while maintaining the performance of the original tasks. We refer to the weight attribution-guided LLM unlearning method as WAGLE, which unveils the interconnections between 'influence' of weights and 'influence' of data to forget and retain in LLM generation. Our extensive experiments show that WAGLE boosts unlearning performance across a range of LLM unlearning methods such as gradient difference and (negative) preference optimization, applications such as fictitious unlearning, malicious use prevention, and copyrighted information removal, and models including Zephyr-7b-beta and Llama2-7b. To the best of our knowledge, our work offers the first principled method for attributing and pinpointing the influential weights in enhancing LLM unlearning. It stands in contrast to previous methods that lack weight attribution and simpler weight attribution techniques.","authors":["Jinghan Jia","Jiancheng Liu","Yihua Zhang","Parikshit Ram","Nathalie Baracaldo","Sijia Liu"],"url":"https://arxiv.org/abs/2410.17509"}
{"created":"2025-04-15","title":"ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment","abstract":"Data selection is crucial for optimizing language model (LM) performance on specific tasks, yet most existing methods fail to effectively consider the target task distribution.","authors":["Elyas Obbad","Iddah Mlauzi","Brando Miranda","Rylan Schaeffer","Kamal Obbad","Suhana Bedi","Sanmi Koyejo"],"url":"https://arxiv.org/abs/2410.18194"}
{"created":"2025-04-15","title":"ChineseSafe: A Chinese Benchmark for Evaluating Safety in Large Language Models","abstract":"With the rapid development of Large language models (LLMs), understanding the capabilities of LLMs in identifying unsafe content has become increasingly important. While previous works have introduced several benchmarks to evaluate the safety risk of LLMs, the community still has a limited understanding of current LLMs' capability to recognize illegal and unsafe content in Chinese contexts. In this work, we present a Chinese safety benchmark (ChineseSafe) to facilitate research on the content safety of large language models. To align with the regulations for Chinese Internet content moderation, our ChineseSafe contains 205,034 examples across 4 classes and 10 sub-classes of safety issues. For Chinese contexts, we add several special types of illegal content: political sensitivity, pornography, and variant/homophonic words. Moreover, we employ two methods to evaluate the legal risks of popular LLMs, including open-sourced models and APIs. The results reveal that many LLMs exhibit vulnerability to certain types of safety issues, leading to legal risks in China. Our work provides a guideline for developers and researchers to facilitate the safety of LLMs. Our results are also available at https://huggingface.co/spaces/SUSTech/ChineseSafe-Benchmark. Additionally, we release a test set comprising 200,000 examples, which is publicly accessible at https://huggingface.co/datasets/SUSTech/ChineseSafe.","authors":["Hengxiang Zhang","Hongfu Gao","Qiang Hu","Guanhua Chen","Lili Yang","Bingyi Jing","Hongxin Wei","Bing Wang","Haifeng Bai","Lei Yang"],"url":"https://arxiv.org/abs/2410.18491"}
{"created":"2025-04-15","title":"Efficient Biological Data Acquisition through Inference Set Design","abstract":"In drug discovery, highly automated high-throughput laboratories are used to screen a large number of compounds in search of effective drugs. These experiments are expensive, so one might hope to reduce their cost by only experimenting on a subset of the compounds, and predicting the outcomes of the remaining experiments. In this work, we model this scenario as a sequential subset selection problem: we aim to select the smallest set of candidates in order to achieve some desired level of accuracy for the system as a whole. Our key observation is that, if there is heterogeneity in the difficulty of the prediction problem across the input space, selectively obtaining the labels for the hardest examples in the acquisition pool will leave only the relatively easy examples to remain in the inference set, leading to better overall system performance. We call this mechanism inference set design, and propose the use of a confidence-based active learning solution to prune out these challenging examples. Our algorithm includes an explicit stopping criterion that interrupts the acquisition loop when it is sufficiently confident that the system has reached the target performance. Our empirical studies on image and molecular datasets, as well as a real-world large-scale biological assay, show that active learning for inference set design leads to significant reduction in experimental cost while retaining high system performance.","authors":["Ihor Neporozhnii","Julien Roy","Emmanuel Bengio","Jason Hartford"],"url":"https://arxiv.org/abs/2410.19631"}
{"created":"2025-04-15","title":"Trustworthiness of Stochastic Gradient Descent in Distributed Learning","abstract":"Distributed learning (DL) uses multiple nodes to accelerate training, enabling efficient optimization of large-scale models. Stochastic Gradient Descent (SGD), a key optimization algorithm, plays a central role in this process. However, communication bottlenecks often limit scalability and efficiency, leading to increasing adoption of compressed SGD techniques to alleviate these challenges. Despite addressing communication overheads, compressed SGD introduces trustworthiness concerns, as gradient exchanges among nodes are vulnerable to attacks like gradient inversion (GradInv) and membership inference attacks (MIA). The trustworthiness of compressed SGD remains unexplored, leaving important questions about its reliability unanswered.","authors":["Hongyang Li","Caesar Wu","Mohammed Chadli","Said Mammar","Pascal Bouvry"],"url":"https://arxiv.org/abs/2410.21491"}
{"created":"2025-04-15","title":"A Graph-Based Model for Vehicle-Centric Data Sharing Ecosystem","abstract":"The development of technologies has prompted a paradigm shift in the automotive industry, with an increasing focus on connected services and autonomous driving capabilities. This transformation allows vehicles to collect and share vast amounts of vehicle-specific and personal data. While these technological advancements offer enhanced user experiences, they also raise privacy concerns. To understand the ecosystem of data collection and sharing in modern vehicles, we adopted the ontology 101 methodology to incorporate information extracted from different sources, including analysis of privacy policies using GPT-4, a small-scale systematic literature review, and an existing ontology, to develop a high-level conceptual graph-based model, aiming to get insights into how modern vehicles handle data exchange among different parties. This serves as a foundational model with the flexibility and scalability to further expand for modelling and analysing data sharing practices across diverse contexts. Two realistic examples were developed to demonstrate the usefulness and effectiveness of discovering insights into privacy regarding vehicle-related data sharing. We also recommend several future research directions, such as exploring advanced ontology languages for reasoning tasks, supporting topological analysis for discovering data privacy risks/concerns, and developing useful tools for comparative analysis, to strengthen the understanding of the vehicle-centric data sharing ecosystem.","authors":["Haiyue Yuan","Ali Raza","Nikolay Matyunin","Jibesh Patra","Shujun Li"],"url":"https://arxiv.org/abs/2410.22897"}
{"created":"2025-04-15","title":"TPC: Test-time Procrustes Calibration for Diffusion-based Human Image Animation","abstract":"Human image animation aims to generate a human motion video from the inputs of a reference human image and a target motion video. Current diffusion-based image animation systems exhibit high precision in transferring human identity into targeted motion, yet they still exhibit irregular quality in their outputs. Their optimal precision is achieved only when the physical compositions (i.e., scale and rotation) of the human shapes in the reference image and target pose frame are aligned. In the absence of such alignment, there is a noticeable decline in fidelity and consistency. Especially, in real-world environments, this compositional misalignment commonly occurs, posing significant challenges to the practical usage of current systems. To this end, we propose Test-time Procrustes Calibration (TPC), which enhances the robustness of diffusion-based image animation systems by maintaining optimal performance even when faced with compositional misalignment, effectively addressing real-world scenarios. The TPC provides a calibrated reference image for the diffusion model, enhancing its capability to understand the correspondence between human shapes in the reference and target images. Our method is simple and can be applied to any diffusion-based image animation system in a model-agnostic manner, improving the effectiveness at test time without additional training.","authors":["Sunjae Yoon","Gwanhyeong Koo","Younghwan Lee","Chang D. Yoo"],"url":"https://arxiv.org/abs/2410.24037"}
{"created":"2025-04-15","title":"ViT-LCA: A Neuromorphic Approach for Vision Transformers","abstract":"The recent success of Vision Transformers has generated significant interest in attention mechanisms and transformer architectures. Although existing methods have proposed spiking self-attention mechanisms compatible with spiking neural networks, they often face challenges in effective deployment on current neuromorphic platforms. This paper introduces a novel model that combines vision transformers with the Locally Competitive Algorithm (LCA) to facilitate efficient neuromorphic deployment. Our experiments show that ViT-LCA achieves higher accuracy on ImageNet-1K dataset while consuming significantly less energy than other spiking vision transformer counterparts. Furthermore, ViT-LCA's neuromorphic-friendly design allows for more direct mapping onto current neuromorphic architectures.","authors":["Sanaz Mahmoodi Takaghaj"],"url":"https://arxiv.org/abs/2411.00140"}
{"created":"2025-04-15","title":"ResiDual Transformer Alignment with Spectral Decomposition","abstract":"When examined through the lens of their residual streams, a puzzling property emerges in transformer networks: residual contributions (e.g., attention heads) sometimes specialize in specific tasks or input attributes. In this paper, we analyze this phenomenon in vision transformers, focusing on the spectral geometry of residuals, and explore its implications for modality alignment in vision-language models. First, we link it to the intrinsically low-dimensional structure of visual head representations, zooming into their principal components and showing that they encode specialized roles across a wide variety of input data distributions. Then, we analyze the effect of head specialization in multimodal models, focusing on how improved alignment between text and specialized heads impacts zero-shot classification performance. This specialization-performance link consistently holds across diverse pre-training data, network sizes, and objectives, demonstrating a powerful new mechanism for boosting zero-shot classification through targeted alignment. Ultimately, we translate these insights into actionable terms by introducing ResiDual, a technique for spectral alignment of the residual stream. Much like panning for gold, it lets the noise from irrelevant unit principal components (i.e., attributes) wash away to amplify task-relevant ones. Remarkably, this dual perspective on modality alignment yields fine-tuning level performance on different data distributions while modelling an extremely interpretable and parameter-efficient transformation, as we extensively show on 70 pre-trained network-dataset combinations (7 models, 10 datasets).","authors":["Lorenzo Basile","Valentino Maiorca","Luca Bortolussi","Emanuele Rodol\\`a","Francesco Locatello"],"url":"https://arxiv.org/abs/2411.00246"}
{"created":"2025-04-15","title":"TurtleBench: A Visual Programming Benchmark in Turtle Geometry","abstract":"Humans have the ability to reason about geometric patterns in images and scenes from a young age. However, developing large multimodal models (LMMs) capable of similar reasoning remains a challenge, highlighting the need for robust evaluation methods to assess these capabilities. We introduce \\Turtle, a benchmark designed to evaluate LMMs' capacity to interpret geometric patterns -- given visual examples, textual instructions, or both -- and generate precise code outputs. Inspired by turtle geometry, a notion used to teach children foundational coding and geometric concepts, TurtleBench features tasks with patterned shapes that have underlying algorithmic logic. Our evaluation reveals that leading LMMs struggle significantly with these tasks, with GPT-4o achieving only 19\\% accuracy on the simplest tasks and few-shot prompting only marginally improves their performance ($<2\\%$). \\Turtle highlights the gap between human and AI performance in intuitive and visual geometrical understanding, setting the stage for future research in this area. \\Turtle stands as one of the few benchmarks to evaluate the integration of visual understanding and code generation capabilities in LMMs, setting the stage for future research. Code and Dataset for this paper is provided here: \\href{https://github.com/sinaris76/TurtleBench}{https://github.com/sinaris76/TurtleBench}","authors":["Sina Rismanchian","Yasaman Razeghi","Sameer Singh","Shayan Doroudi"],"url":"https://arxiv.org/abs/2411.00264"}
{"created":"2025-04-15","title":"Diversity in Network-Friendly Recommendations","abstract":"In recent years, the Internet has been dominated by content-rich platforms, employing recommendation systems to provide users with more appealing content (e.g., videos in YouTube, movies in Netflix). While traditional content recommendations are oblivious to network conditions, the paradigm of Network-Friendly Recommendations (NFR) has recently emerged, favoring content that improves network performance (e.g. cached near the user), while still being appealing to the user. However, NFR algorithms sometimes achieve their goal by shrinking the pool of content recommended to users. The undesirable side-effect is reduced content diversity, a phenomenon known as ``content/filter bubble''. This reduced diversity is problematic for both users, who are prevented from exploring a broader range of content, and content creators (e.g. YouTubers) whose content may be recommended less frequently, leading to perceived unfairness. In this paper, we first investigate - using real data and state-of-the-art NFR schemes - the extent of this phenomenon. We then formulate a ``Diverse-NFR'' optimization problem (i.e., network-friendly recommendations with - sufficient - content diversity), and through a series of transformation steps, we manage to reduce it to a linear program that can be solved fast and optimally. Our findings show that Diverse-NFR can achieve high network gains (comparable to non-diverse NFR) while maintaining diversity constraints. To our best knowledge, this is the first work that incorporates diversity issues into network-friendly recommendation algorithms.","authors":["Evangelia Tzimpimpaki","Thrasyvoulos Spyropoulos"],"url":"https://arxiv.org/abs/2411.00601"}
{"created":"2025-04-15","title":"Efficient Active Imitation Learning with Random Network Distillation","abstract":"Developing agents for complex and underspecified tasks, where no clear objective exists, remains challenging but offers many opportunities. This is especially true in video games, where simulated players (bots) need to play realistically, and there is no clear reward to evaluate them. While imitation learning has shown promise in such domains, these methods often fail when agents encounter out-of-distribution scenarios during deployment. Expanding the training dataset is a common solution, but it becomes impractical or costly when relying on human demonstrations. This article addresses active imitation learning, aiming to trigger expert intervention only when necessary, reducing the need for constant expert input along training. We introduce Random Network Distillation DAgger (RND-DAgger), a new active imitation learning method that limits expert querying by using a learned state-based out-of-distribution measure to trigger interventions. This approach avoids frequent expert-agent action comparisons, thus making the expert intervene only when it is useful. We evaluate RND-DAgger against traditional imitation learning and other active approaches in 3D video games (racing and third-person navigation) and in a robotic locomotion task and show that RND-DAgger surpasses previous methods by reducing expert queries. https://sites.google.com/view/rnd-dagger","authors":["Emilien Bir\\'e","Anthony Kobanda","Ludovic Denoyer","R\\'emy Portelas"],"url":"https://arxiv.org/abs/2411.01894"}
{"created":"2025-04-15","title":"Communication and Energy-Aware Multi-UAV Coverage Path Planning for Networked Operations","abstract":"This paper presents a communication and energy-aware Multi-UAV Coverage Path Planning (mCPP) method for scenarios requiring continuous inter-UAV communication, such as cooperative search and rescue and surveillance missions. Unlike existing mCPP solutions that focus on energy, time, or coverage efficiency, our approach generates coverage paths that require minimal the communication range to maintain inter-UAV connectivity while also optimizing energy consumption. The mCPP problem is formulated as a multi-objective optimization task, aiming to minimize both the communication range requirement and energy consumption. Our approach significantly reduces the communication range needed for maintaining connectivity while ensuring energy efficiency, outperforming state-of-the-art methods. Its effectiveness is validated through simulations on complex and arbitrary shaped regions of interests, including scenarios with no-fly zones. Additionally, real-world experiment demonstrate its high accuracy, achieving 99\\% consistency between the estimated and actual communication range required during a multi-UAV coverage mission involving three UAVs.","authors":["Mohamed Samshad","Ketan Rajawat"],"url":"https://arxiv.org/abs/2411.02772"}
{"created":"2025-04-15","title":"An efficient scheme for approximating long-time dynamics of a class of non-linear models","abstract":"We propose a novel, highly efficient, mean-reverting-SAV-BDF2-based, long-time unconditionally stable numerical scheme for a class of finite-dimensional nonlinear models important in geophysical fluid dynamics. The scheme is highly efficient in that only a fixed symmetric positive definite linear problem (with varying right-hand sides) is solved at each time step. The solutions remain uniformly bounded for all time. We show that the scheme accurately captures the long-time dynamics of the underlying geophysical model, with the global attractors and invariant measures of the scheme converging to those of the original model as the step size approaches zero.","authors":["Jack Coleman","Daozhi Han","Xiaoming Wang"],"url":"https://arxiv.org/abs/2411.03689"}
{"created":"2025-04-15","title":"A risk model and analysis method for the psychological safety of human and autonomous vehicles interaction","abstract":"This paper addresses the critical issue of psychological safety in the design and operation of autonomous vehicles, which are increasingly integrated with artificial intelligence technologies. While traditional safety standards focus primarily on physical safety, this paper emphasizes the psychological implications that arise from human interactions with autonomous vehicles, highlighting the importance of trust and perceived risk as significant factors influencing user acceptance. Through a review of existing safety techniques, the paper defines psychological safety in the context of autonomous vehicles, proposes a risk model to identify and assess psychological risks, and adopts a system-theoretic analysis method. The paper illustrates the potential psychological hazards using a scenario involving a family's experience with an autonomous vehicle, aiming to systematically evaluate situations that could lead to psychological harm. By establishing a framework that incorporates psychological safety alongside physical safety, the paper contributes to the broader discourse on the safe deployment of autonomous vehicle and aims to guide future developments in user-cantered design and regulatory practices.","authors":["Yandika Sirgabsou","Benjamin Hardin","Fran\\c{c}ois Leblanc","Efi Raili","Pericle Salvini","David Jackson","Marina Jirotka","Lars Kunze"],"url":"https://arxiv.org/abs/2411.05732"}
{"created":"2025-04-15","title":"ClassEval-T: Evaluating Large Language Models in Class-Level Code Translation","abstract":"In recent years, Large Language Models (LLMs) have dramatically advanced the performance of automated code translation, making their computational accuracy score reach up to over 80% on many previous benchmarks. However, most code samples in these benchmarks are short, standalone, statement/method-level, and algorithmic, which is not aligned with practical coding tasks. Therefore, it is still unknown the actual capability of LLMs in translating code samples written for daily development. To achieve this, we construct a class-level code translation benchmark, ClassEval-T, and make the first attempt to extensively assess recent LLMs' performance on class-level code translation. ClassEval-T is extended from ClassEval, a well-known class-level Python code generation benchmark consisting of multiple practical coding topics, such as database operation and game design, and diverse contextual dependencies (e.g., fields, methods, and libraries). It cost us 360 person-hours to accomplish the manual migration to Java and C++ with complete code samples and associated test suites. Subsequently, we design three translation strategies (i.e., holistic, min-dependency, and standalone) for class-level code translations and evaluate eight recent LLMs of commercial, general, and code kinds in diverse families and sizes on ClassEval-T. Experimental results demonstrate a remarkable performance drop compared with the most widely studied method-level code translation benchmark, and obvious discrepancies among LLMs appear, showing the effectiveness of ClassEval-T in measuring recent LLMs. Afterwards, we further discuss the usage scenarios for diverse translation strategies and LLMs' ability to dependency awareness when translating class samples. Finally, 1,243 failure cases made by the best-performing LLM under test are analyzed and categorized in this paper for practical guidance and future enlightenment.","authors":["Pengyu Xue","Linhao Wu","Zhen Yang","Chengyi Wang","Xiang Li","Yuxiang Zhang","Jia Li","Ruikai Jin","Yifei Pei","Zhaoyan Shen","Xiran Lyu","Jacky Wai Keung"],"url":"https://arxiv.org/abs/2411.06145"}
{"created":"2025-04-15","title":"Sketched Adaptive Federated Deep Learning: A Sharp Convergence Analysis","abstract":"Combining gradient compression methods (e.g., CountSketch, quantization) and adaptive optimizers (e.g., Adam, AMSGrad) is a desirable goal in federated learning (FL), with potential benefits on both fewer communication rounds and less per-round communication. In spite of the preliminary empirical success of sketched adaptive methods, existing convergence analyses show the communication cost to have a linear dependence on the ambient dimension, i.e., number of parameters, which is prohibitively high for modern deep learning models. In this work, we introduce specific sketched adaptive federated learning (SAFL) algorithms and, as our main contribution, provide theoretical convergence analyses in different FL settings with guarantees on communication cost depending only logarithmically (instead of linearly) on the ambient dimension. Unlike existing analyses, we show that the entry-wise sketching noise existent in the preconditioners and the first moments of SAFL can be implicitly addressed by leveraging the recently-popularized anisotropic curvatures in deep learning losses, e.g., fast decaying loss Hessian eigen-values. In the i.i.d. client setting of FL, we show that SAFL achieves asymptotic $O(1/\\sqrt{T})$ convergence, and converges faster in the initial epochs. In the non-i.i.d. client setting, where non-adaptive methods lack convergence guarantees, we show that SACFL (SAFL with clipping) algorithms can provably converge in spite of the additional heavy-tailed noise. Our theoretical claims are supported by empirical studies on vision and language tasks, and in both fine-tuning and training-from-scratch regimes. Surprisingly, as a by-product of our analysis, the proposed SAFL methods are competitive with the state-of-the-art communication-efficient federated learning algorithms based on error feedback.","authors":["Zhijie Chen","Qiaobo Li","Arindam Banerjee"],"url":"https://arxiv.org/abs/2411.06770"}
{"created":"2025-04-15","title":"Training Neural Networks as Recognizers of Formal Languages","abstract":"Characterizing the computational power of neural network architectures in terms of formal language theory remains a crucial line of research, as it describes lower and upper bounds on the reasoning capabilities of modern AI. However, when empirically testing these bounds, existing work often leaves a discrepancy between experiments and the formal claims they are meant to support. The problem is that formal language theory pertains specifically to recognizers: machines that receive a string as input and classify whether it belongs to a language. On the other hand, it is common instead to evaluate language models on proxy tasks, e.g., language modeling or sequence-to-sequence transduction, that are similar in only an informal sense to the underlying theory. We correct this mismatch by training and evaluating neural networks directly as binary classifiers of strings, using a general method that can be applied to a wide variety of languages. As part of this, we extend an algorithm recently proposed by Sn{\\ae}bjarnarson et al. (2025) for efficient length-controlled sampling of strings from regular languages. We provide results on a variety of languages across the Chomsky hierarchy for three neural architectures: a simple RNN, an LSTM, and a causally-masked transformer. We find that the RNN and LSTM often outperform the transformer, and that auxiliary training objectives such as language modeling can help, although no single objective uniformly improves performance across languages and architectures. Our contributions will facilitate theoretically sound empirical testing of language recognition claims in future work. We have released our datasets as a benchmark called FLaRe (Formal Language Recognition), along with our code.","authors":["Alexandra Butoi","Ghazal Khalighinejad","Anej Svete","Josef Valvoda","Ryan Cotterell","Brian DuSell"],"url":"https://arxiv.org/abs/2411.07107"}
{"created":"2025-04-15","title":"Compressed Game Solving","abstract":"We recast move generators for solving board games as operations on compressed sets of strings. We aim for compressed representations with space sublinear in the number of game positions for interesting sets of positions, move generation in time roughly linear in the compressed size and membership tests in constant time. To the extent that we achieve these tradeoffs empirically, we can strongly solve board games in time sublinear in the state space. We demonstrate this concept with the game Breakthrough where we empirically realize compressed representations taking roughly $n^{0.5}$ to $n^{0.7}$ space to store relevant sets of $n$ positions.","authors":["Jeffrey Considine"],"url":"https://arxiv.org/abs/2411.07273"}
{"created":"2025-04-15","title":"Open-World Task and Motion Planning via Vision-Language Model Inferred Constraints","abstract":"Foundation models trained on internet-scale data, such as Vision-Language Models (VLMs), excel at performing a wide variety of common sense tasks like visual question answering. Despite their impressive capabilities, these models cannot currently be directly applied to challenging robot manipulation problems that require complex and precise continuous reasoning over long horizons. Task and Motion Planning (TAMP) systems can control high-dimensional continuous systems over long horizons via a hybrid search over traditional primitive robot skills. However, these systems require detailed models of how the robot can impact its environment, preventing them from directly interpreting and addressing novel human objectives, for example, an arbitrary natural language goal. We propose deploying VLMs within TAMP systems by having them generate discrete and continuous language-parameterized constraints that enable TAMP to reason about open-world concepts. Specifically, we propose algorithms for VLM partial planning that constrain a TAMP system's discrete temporal search and VLM continuous constraints interpretation to augment the traditional manipulation constraints that TAMP systems seek to satisfy. Experiments demonstrate that our approach -- OWL-TAMP -- outperforms several related baselines, including those that solely use TAMP or VLMs for planning, across several long-horizon manipulation tasks specified directly through natural language. We additionally demonstrate that our approach is compatible with a variety of TAMP systems and can be deployed to solve challenging manipulation tasks on real-world hardware.","authors":["Nishanth Kumar","William Shen","Fabio Ramos","Dieter Fox","Tom\\'as Lozano-P\\'erez","Leslie Pack Kaelbling","Caelan Reed Garrett"],"url":"https://arxiv.org/abs/2411.08253"}
{"created":"2025-04-15","title":"MambaXCTrack: Mamba-based Tracker with SSM Cross-correlation and Motion Prompt for Ultrasound Needle Tracking","abstract":"Ultrasound (US)-guided needle insertion is widely employed in percutaneous interventions. However, providing feedback on the needle tip position via US imaging presents challenges due to noise, artifacts, and the thin imaging plane of US, which degrades needle features and leads to intermittent tip visibility. In this paper, a Mamba-based US needle tracker MambaXCTrack utilizing structured state space models cross-correlation (SSMX-Corr) and implicit motion prompt is proposed, which is the first application of Mamba in US needle tracking. The SSMX-Corr enhances cross-correlation by long-range modeling and global searching of distant semantic features between template and search maps, benefiting the tracking under noise and artifacts by implicitly learning potential distant semantic cues. By combining with cross-map interleaved scan (CIS), local pixel-wise interaction with positional inductive bias can also be introduced to SSMX-Corr. The implicit low-level motion descriptor is proposed as a non-visual prompt to enhance tracking robustness, addressing the intermittent tip visibility problem. Extensive experiments on a dataset with motorized needle insertion in both phantom and tissue samples demonstrate that the proposed tracker outperforms other state-of-the-art trackers while ablation studies further highlight the effectiveness of each proposed tracking module.","authors":["Yuelin Zhang","Long Lei","Wanquan Yan","Tianyi Zhang","Raymond Shing-Yan Tang","Shing Shin Cheng"],"url":"https://arxiv.org/abs/2411.08395"}
{"created":"2025-04-15","title":"LogLLM: Log-based Anomaly Detection Using Large Language Models","abstract":"Software systems often record important runtime information in logs to help with troubleshooting. Log-based anomaly detection has become a key research area that aims to identify system issues through log data, ultimately enhancing the reliability of software systems. Traditional deep learning methods often struggle to capture the semantic information embedded in log data, which is typically organized in natural language. In this paper, we propose LogLLM, a log-based anomaly detection framework that leverages large language models (LLMs). LogLLM employs BERT for extracting semantic vectors from log messages, while utilizing Llama, a transformer decoder-based model, for classifying log sequences. Additionally, we introduce a projector to align the vector representation spaces of BERT and Llama, ensuring a cohesive understanding of log semantics. Unlike conventional methods that require log parsers to extract templates, LogLLM preprocesses log messages with regular expressions, streamlining the entire process. Our framework is trained through a novel three-stage procedure designed to enhance performance and adaptability. Experimental results across four public datasets demonstrate that LogLLM outperforms state-of-the-art methods. Even when handling unstable logs, it effectively captures the semantic meaning of log messages and detects anomalies accurately.","authors":["Wei Guan","Jian Cao","Shiyou Qian","Jianqi Gao","Chun Ouyang"],"url":"https://arxiv.org/abs/2411.08561"}
{"created":"2025-04-15","title":"Data-driven parameterization refinement for the structural optimization of cruise ship hulls","abstract":"In this work, we focus on the early design phase of cruise ship hulls, where the designers are tasked with ensuring the structural resilience of the ship against extreme waves while reducing steel usage and respecting safety and manufacturing constraints. At this stage the geometry of the ship is already finalized and the designer choose the thickness of the primary structural elements, such as decks, bulkheads, and the shell. Reduced order modeling and black-box optimization techniques reduce the use of expensive finite element analysis to only validate the most promising configurations, thanks to the efficient exploration of the domain of decision variables. However, the quality of the final results heavily relies on the problem formulation, and on how the structural elements are assigned to the decision variables. With the increased request for alternative fuels and engine technologies, the designers are often faced with novel configurations and risk producing ill-suited parameterizations. To address this issue, we enhanced a structural optimization pipeline for cruise ships developed in collaboration with Fincantieri S.p.A. with a novel data-driven hierarchical reparameterization procedure, based on the optimization of a series of sub-problems. Moreover, we implemented a multi-objective optimization module to provide the designers with insights into the efficient trade-offs between competing quantities of interest and enhanced the single-objective Bayesian optimization module. The new pipeline is tested on a simplified midship section and a full ship hull, comparing the automated reparameterization to a baseline model provided by the designers. The tests show that the iterative refinement outperforms the baseline, thus streamlining the initial design phase and helping tackle more innovative projects.","authors":["Lorenzo Fabris","Marco Tezzele","Ciro Busiello","Mauro Sicchiero","Gianluigi Rozza"],"url":"https://arxiv.org/abs/2411.09525"}
{"created":"2025-04-15","title":"Motion Before Action: Diffusing Object Motion as Manipulation Condition","abstract":"Inferring object motion representations from observations enhances the performance of robotic manipulation tasks. This paper introduces a new paradigm for robot imitation learning that generates action sequences by reasoning about object motion from visual observations. We propose MBA (Motion Before Action), a novel module that employs two cascaded diffusion processes for object motion generation and robot action generation under object motion guidance. MBA first predicts the future pose sequence of the object based on observations, then uses this sequence as a condition to guide robot action generation. Designed as a plug-and-play component, MBA can be flexibly integrated into existing robotic manipulation policies with diffusion action heads. Extensive experiments in both simulated and real-world environments demonstrate that our approach substantially improves the performance of existing policies across a wide range of manipulation tasks. Project page: https://selen-suyue.github.io/MBApage/","authors":["Yue Su","Xinyu Zhan","Hongjie Fang","Yong-Lu Li","Cewu Lu","Lixin Yang"],"url":"https://arxiv.org/abs/2411.09658"}
{"created":"2025-04-15","title":"To Shuffle or not to Shuffle: Auditing DP-SGD with Shuffling","abstract":"The Differentially Private Stochastic Gradient Descent (DP-SGD) algorithm allows the training of machine learning (ML) models with formal Differential Privacy (DP) guarantees. Since DP-SGD processes training data in batches, it employs Poisson sub-sampling to select each batch at every step. However, it has become common practice to replace sub-sampling with shuffling owing to better compatibility and computational overhead. At the same time, we do not know how to compute tight theoretical guarantees for shuffling; thus, DP guarantees of models privately trained with shuffling are often reported as though Poisson sub-sampling was used.","authors":["Meenatchi Sundaram Muthu Selva Annamalai","Borja Balle","Jamie Hayes","Emiliano De Cristofaro"],"url":"https://arxiv.org/abs/2411.10614"}
{"created":"2025-04-15","title":"Conceptwm: A Diffusion Model Watermark for Concept Protection","abstract":"The personalization techniques of diffusion models succeed in generating specific concepts but also pose threats to copyright protection and illegal use. Model Watermarking is an effective method to prevent the unauthorized use of subject-driven or style-driven image generation, safeguarding concept copyrights. However, under the goal of concept-oriented protection, current watermarking schemes typically add watermarks to all images rather than applying them in a refined manner targeted at specific concepts. Additionally, the personalization techniques of diffusion models can easily remove watermarks. Existing watermarking methods struggle to achieve fine-grained watermark embedding with a few images of specific concept and prevent removal of watermarks through personalized fine-tuning. Therefore, we introduce a novel concept-oriented watermarking framework that seamlessly embeds imperceptible watermarks into the concept of diffusion models. We introduce Fidelity-preserving Latent Watermarking (FLW) to generate latent watermarks based on image characteristics and the Adversarial Watermarking Modulation module to prevent \"jailbreaking\" via personalized finetuning. To enhance U-Net's efficiency in learning watermark patterns with limited samples, we propose Efficient Concept Watermark Finetuning, which alternates optimization of model parameters for both watermark embedding and concept learning. We conduct extensive experiments and ablation studies to verify our framework. Our code is available at https://anonymous.4open.science/r/Conceptwm-4EB3/.","authors":["Liangqi Lei","Keke Gai","Jing Yu","Liehuang Zhu","Qi Wu"],"url":"https://arxiv.org/abs/2411.11688"}
{"created":"2025-04-15","title":"ITACLIP: Boosting Training-Free Semantic Segmentation with Image, Text, and Architectural Enhancements","abstract":"Recent advances in foundational Vision Language Models (VLMs) have reshaped the evaluation paradigm in computer vision tasks. These foundational models, especially CLIP, have accelerated research in open-vocabulary computer vision tasks, including Open-Vocabulary Semantic Segmentation (OVSS). Although the initial results are promising, the dense prediction capabilities of VLMs still require further improvement. In this study, we enhance the semantic segmentation performance of CLIP by introducing new modules and modifications: 1) architectural changes in the last layer of ViT and the incorporation of attention maps from the middle layers with the last layer, 2) Image Engineering: applying data augmentations to enrich input image representations, and 3) using Large Language Models (LLMs) to generate definitions and synonyms for each class name to leverage CLIP's open-vocabulary capabilities. Our training-free method, ITACLIP, outperforms current state-of-the-art approaches on segmentation benchmarks such as COCO-Stuff, COCO-Object, Pascal Context, and Pascal VOC. Our code is available at https://github.com/m-arda-aydn/ITACLIP.","authors":["M. Arda Ayd{\\i}n","Efe Mert \\c{C}{\\i}rpar","Elvin Abdinli","Gozde Unal","Yusuf H. Sahin"],"url":"https://arxiv.org/abs/2411.12044"}
{"created":"2025-04-15","title":"Hardware Scaling Trends and Diminishing Returns in Large-Scale Distributed Training","abstract":"Dramatic increases in the capabilities of neural network models in recent years are driven by scaling model size, training data, and corresponding computational resources. To develop the exceedingly large networks required in modern applications, such as large language models (LLMs), model training is distributed across tens of thousands of hardware accelerators (e.g. GPUs), requiring orchestration of computation and communication across large computing clusters. In this work, we demonstrate that careful consideration of hardware configuration and parallelization strategy is critical for effective (i.e. compute- and cost-efficient) scaling of model size, training data, and total computation. We conduct an extensive empirical study of the performance of large-scale LLM training workloads across model size, hardware configurations, and distributed parallelization strategies. We demonstrate that: (1) beyond certain scales, overhead incurred from certain distributed communication strategies leads parallelization strategies previously thought to be sub-optimal in fact become preferable; and (2) scaling the total number of accelerators for large model training quickly yields diminishing returns even when hardware and parallelization strategies are properly optimized, implying poor marginal performance per additional unit of power or GPU-hour.","authors":["Jared Fernandez","Luca Wehrstedt","Leonid Shamis","Mostafa Elhoushi","Kalyan Saladi","Yonatan Bisk","Emma Strubell","Jacob Kahn"],"url":"https://arxiv.org/abs/2411.13055"}
{"created":"2025-04-15","title":"Efficient Spatio-Temporal Signal Recognition on Edge Devices Using PointLCA-Net","abstract":"Recent advancements in machine learning, particularly through deep learning architectures like PointNet, have transformed the processing of three-dimensional (3D) point clouds, significantly improving 3D object classification and segmentation tasks. While 3D point clouds provide detailed spatial information, spatio-temporal signals introduce a dynamic element that accounts for changes over time. However, applying deep learning techniques to spatio-temporal signals and deploying them on edge devices presents challenges, including real-time processing, memory capacity, and power consumption. To address these issues, this paper presents a novel approach that combines PointNet's feature extraction with the in-memory computing capabilities and energy efficiency of neuromorphic systems for spatio-temporal signal recognition. The proposed method consists of a two-stage process: in the first stage, PointNet extracts features from the spatio-temporal signals, which are then stored in non-volatile memristor crossbar arrays. In the second stage, these features are processed by a single-layer spiking neural encoder-decoder that employs the Locally Competitive Algorithm (LCA) for efficient encoding and classification. This work integrates the strengths of both PointNet and LCA, enhancing computational efficiency and energy performance on edge devices. PointLCA-Net achieves high recognition accuracy for spatio-temporal data with substantially lower energy burden during both inference and training than comparable approaches, thus advancing the deployment of advanced neural architectures in energy-constrained environments.","authors":["Sanaz Mahmoodi Takaghaj","Jack Sampson"],"url":"https://arxiv.org/abs/2411.14585"}
{"created":"2025-04-15","title":"Implicit High-Order Moment Tensor Estimation and Learning Latent Variable Models","abstract":"We study the task of learning latent-variable models. A common algorithmic technique for this task is the method of moments. Unfortunately, moment-based approaches are hampered by the fact that the moment tensors of super-constant degree cannot even be written down in polynomial time. Motivated by such learning applications, we develop a general efficient algorithm for {\\em implicit moment tensor computation}. Our framework generalizes the work of~\\cite{LL21-opt} which developed an efficient algorithm for the specific moment tensors that arise in clustering mixtures of spherical Gaussians.","authors":["Ilias Diakonikolas","Daniel M. Kane"],"url":"https://arxiv.org/abs/2411.15669"}
{"created":"2025-04-15","title":"Broad Critic Deep Actor Reinforcement Learning for Continuous Control","abstract":"In the domain of continuous control, deep reinforcement learning (DRL) demonstrates promising results. However, the dependence of DRL on deep neural networks (DNNs) results in the demand for extensive data and increased computational cost. To address this issue, a novel hybrid actor-critic reinforcement learning (RL) framework is introduced. The proposed framework integrates the broad learning system (BLS) with DNN, aiming to merge the strengths of both distinct architectural paradigms. Specifically, the critic network employs BLS for rapid value estimation via ridge regression, while the actor network retains the DNN structure to optimize policy gradients. This hybrid design is generalizable and can enhance existing actor-critic algorithms. To demonstrate its versatility, the proposed framework is integrated into three widely used actor-critic algorithms -- deep deterministic policy gradient (DDPG), soft actor-critic (SAC), and twin delayed DDPG (TD3), resulting in BLS-augmented variants. Experimental results reveal that all BLS-enhanced versions surpass their original counterparts in terms of training efficiency and accuracy. These improvements highlight the suitability of the proposed framework for real-time control scenarios, where computational efficiency and rapid adaptation are critical.","authors":["Shiron Thalagala","Pak Kin Wong","Xiaozheng Wang","Tianang Sun"],"url":"https://arxiv.org/abs/2411.15806"}
{"created":"2025-04-15","title":"Weakly Supervised Panoptic Segmentation for Defect-Based Grading of Fresh Produce","abstract":"Visual inspection for defect grading in agricultural supply chains is crucial but traditionally labor-intensive and error-prone. Automated computer vision methods typically require extensively annotated datasets, which are often unavailable in decentralized supply chains. We address this challenge by evaluating the Segment Anything Model (SAM) to generate dense panoptic segmentation masks from sparse annotations. These dense predictions are then used to train a supervised panoptic segmentation model. Focusing on banana surface defects (bruises and scars), we validate our approach using 476 field images annotated with 1440 defects. While SAM-generated masks generally align with human annotations, substantially reducing annotation effort, we explicitly identify failure cases associated with specific defect sizes and shapes. Despite these limitations, our approach offers practical estimates of defect number and relative size from panoptic masks, underscoring the potential and current boundaries of foundation models for defect quantification in low-data agricultural scenarios. GitHub: https://github.com/manuelknott/banana-defect-segmentation","authors":["Manuel Knott","Divinefavour Odion","Sameer Sontakke","Anup Karwa","Thijs Defraeye"],"url":"https://arxiv.org/abs/2411.16219"}
{"created":"2025-04-15","title":"Proxima. A DAG based cooperative distributed ledger","abstract":"This paper introduces a novel architecture for a distributed ledger, commonly referred to as a \"blockchain\", which is organized in the form of directed acyclic graph (DAG) with UTXO transactions as vertices, rather than as a chain of blocks. Consensus on the state of ledger assets is achieved through the cooperative consensus: a profit-driven behavior of token holders themselves, which is viable only when they cooperate by following the \"biggest ledger coverage rule\", akin the \"longest chain rule\" of Bitcoin. The cooperative behavior is facilitated by enforcing purposefully designed UTXO transaction validity constraints. Token holders are the sole category of participants authorized to make amendments to the ledger, making participation completely permissionless - without miners, validators, committees or staking - and without any need of knowledge about the composition of the set of all participants in the consensus. The setup allows to achieve high throughput and scalability alongside with low transaction costs, while preserving key aspects of high decentralization, open participation, and asynchronicity found in Bitcoin and other proof-of-work blockchains, but without unreasonable energy consumption. Sybil protection is achieved similarly to proof-of-stake blockchains, using tokens native to the ledger, yet the architecture operates in a leaderless manner without block proposers and committee selection.","authors":["Evaldas Drasutis"],"url":"https://arxiv.org/abs/2411.16456"}
{"created":"2025-04-15","title":"In-Context Deep Learning via Transformer Models","abstract":"We investigate the transformer's capability to simulate the training process of deep models via in-context learning (ICL), i.e., in-context deep learning. Our key contribution is providing a positive example of using a transformer to train a deep neural network by gradient descent in an implicit fashion via ICL. Specifically, we provide an explicit construction of a $(2N+4)L$-layer transformer capable of simulating $L$ gradient descent steps of an $N$-layer ReLU network through ICL. We also give the theoretical guarantees for the approximation within any given error and the convergence of the ICL gradient descent. Additionally, we extend our analysis to the more practical setting using Softmax-based transformers. We validate our findings on synthetic datasets for 3-layer, 4-layer, and 6-layer neural networks. The results show that ICL performance matches that of direct training.","authors":["Weimin Wu","Maojiang Su","Jerry Yao-Chieh Hu","Zhao Song","Han Liu"],"url":"https://arxiv.org/abs/2411.16549"}
{"created":"2025-04-15","title":"Phys4DGen: Physics-Compliant 4D Generation with Multi-Material Composition Perception","abstract":"4D content generation aims to create dynamically evolving 3D content that responds to specific input objects such as images or 3D representations. Current approaches typically incorporate physical priors to animate 3D representations, but these methods suffer from significant limitations: they not only require users lacking physics expertise to manually specify material properties but also struggle to effectively handle the generation of multi-material composite objects. To address these challenges, we propose Phys4DGen, a novel 4D generation framework that integrates multi-material composition perception with physical simulation. The framework achieves automated, physically plausible 4D generation through three innovative modules: first, the 3D Material Grouping module partitions heterogeneous material regions on 3D representation surfaces via semantic segmentation; second, the Internal Physical Structure Discovery module constructs the mechanical structure of object interiors; finally, we distill physical prior knowledge from multimodal large language models to enable rapid and automatic material properties identification for both objects' surfaces and interiors. Experiments on both synthetic and real-world datasets demonstrate that Phys4DGen can generate high-fidelity 4D content with physical realism in open-world scenarios, significantly outperforming state-of-the-art methods.","authors":["Jiajing Lin","Zhenzhong Wang","Dejun Xu","Shu Jiang","YunPeng Gong","Min Jiang"],"url":"https://arxiv.org/abs/2411.16800"}
{"created":"2025-04-15","title":"CleanVul: Automatic Function-Level Vulnerability Detection in Code Commits Using LLM Heuristics","abstract":"Accurate identification of software vulnerabilities is crucial for system integrity. Vulnerability datasets, often derived from the National Vulnerability Database (NVD) or directly from GitHub, are essential for training machine learning models to detect these security flaws. However, these datasets frequently suffer from significant noise, typically 40% to 75%, due primarily to the automatic and indiscriminate labeling of all changes in vulnerability-fixing commits (VFCs) as vulnerability-related. This misclassification occurs because not all changes in a commit aimed at fixing vulnerabilities pertain to security threats; many are routine updates like bug fixes or test improvements.","authors":["Yikun Li","Ting Zhang","Ratnadira Widyasari","Yan Naing Tun","Huu Hung Nguyen","Tan Bui","Ivana Clairine Irsan","Yiran Cheng","Xiang Lan","Han Wei Ang","Frank Liauw","Martin Weyssow","Hong Jin Kang","Eng Lieh Ouh","Lwin Khin Shar","David Lo"],"url":"https://arxiv.org/abs/2411.17274"}
{"created":"2025-04-15","title":"Planning Shorter Paths in Graphs of Convex Sets by Undistorting Parametrized Configuration Spaces","abstract":"Optimization based motion planning provides a useful modeling framework through various costs and constraints. Using Graph of Convex Sets (GCS) for trajectory optimization gives guarantees of feasibility and optimality by representing configuration space as the finite union of convex sets. Nonlinear parametrizations can be used to extend this technique to handle cases such as kinematic loops, but this distorts distances, such that solving with convex objectives will yield paths that are suboptimal in the original space. We present a method to extend GCS to nonconvex objectives, allowing us to \"undistort\" the optimization landscape while maintaining feasibility guarantees. We demonstrate our method's efficacy on three different robotic planning domains: a bimanual robot moving an object with both arms, the set of 3D rotations using Euler angles, and a rational parametrization of kinematics that enables certifying regions as collision free. Across the board, our method significantly improves path length and trajectory duration with only a minimal increase in runtime. Website: https://shrutigarg914.github.io/pgd-gcs-results/","authors":["Shruti Garg","Thomas Cohn","Russ Tedrake"],"url":"https://arxiv.org/abs/2411.18913"}
{"created":"2025-04-15","title":"Calculation of time-optimal motion primitives for systems exhibiting oscillatory internal dynamics","abstract":"An algorithm for planning near time-optimal trajectories for systems with an oscillatory internal dynamics has been developed in previous work. It is based on assembling a complete trajectory from motion primitives called jerk segments, which are the time-optimal solution to an optimization problem. To achieve the shortest overall transition time, it is advantageous to recompute these segments for different acceleration levels within the motion planning procedure. This publication presents a numerical calculation method enabling fast and reliable calculation. This is achieved by explicitly evaluating the optimality conditions that arise for the problem, and further by reducing the evaluation of these conditions to a line-search problem on a bounded interval. This reduction guarantees, that a valid solution if found after a fixed number of computational steps, making the calculation time constant and predictable. Furthermore, the algorithm does not rely on optimisation algorithms, which allowed its implementation on a laboratory system for measurements with the purpose of validating the approach.","authors":["Thomas Auer","Frank Woittennek"],"url":"https://arxiv.org/abs/2411.19148"}
{"created":"2025-04-15","title":"Secure Filtering against Spatio-Temporal False Data Attacks under Asynchronous Sampling","abstract":"This paper addresses the secure state estimation problem for continuous linear time-invariant systems with non-periodic and asynchronous sampled measurements, where the sensors need to transmit not only measurements but also sampling time-stamps to the fusion center. This measurement and communication setup is well-suited for operating large-scale control systems and, at the same time, introduces new vulnerabilities that can be exploited by adversaries through (i) manipulation of measurements, (ii) manipulation of time-stamps, (iii) elimination of measurements, (iv) generation of completely new false measurements, or a combination of these attacks. To mitigate these attacks, we propose a decentralized estimation algorithm in which each sensor maintains its local state estimate asynchronously based on its measurements. The local states are synchronized through time prediction and fused after time-stamp alignment. In the absence of attacks, state estimates are proven to recover the optimal Kalman estimates by solving a weighted least square problem. In the presence of attacks, solving this weighted least square problem with the aid of $\\ell_1$ regularization provides secure state estimates with uniformly bounded error under an observability redundancy assumption. The effectiveness of the proposed algorithm is demonstrated using a benchmark example of the IEEE 14-bus system.","authors":["Zishuo Li","Anh Tung Nguyen","Andr\\'e M. H. Teixeira","Yilin Mo","Karl H. Johansson"],"url":"https://arxiv.org/abs/2411.19765"}
{"created":"2025-04-15","title":"Table Integration in Data Lakes Unleashed: Pairwise Integrability Judgment, Integrable Set Discovery, and Multi-Tuple Conflict Resolution","abstract":"Table integration aims to create a comprehensive table by consolidating tuples containing relevant information. In this work, we investigate the challenge of integrating multiple tables from a data lake, focusing on three core tasks: 1) pairwise integrability judgment, which determines whether a tuple pair is integrable, accounting for any occurrences of semantic equivalence or typographical errors; 2) integrable set discovery, which identifies all integrable sets in a table based on pairwise integrability judgments established in the first task; 3) multi-tuple conflict resolution, which resolves conflicts between multiple tuples during integration. To this end, we train a binary classifier to address the task of pairwise integrability judgment. Given the scarcity of labeled data in data lakes, we propose a self-supervised adversarial contrastive learning algorithm to perform classification, which incorporates data augmentation methods and adversarial examples to autonomously generate new training data. Upon the output of pairwise integrability judgment, each integrable set can be considered as a community, a densely connected sub-graph where nodes and edges correspond to tuples in the table and their pairwise integrability respectively, we proceed to investigate various community detection algorithms to address the integrable set discovery objective. Moving forward to tackle multi-tuple conflict resolution, we introduce an innovative in-context learning methodology. This approach capitalizes on the knowledge embedded within large language models (LLMs) to effectively resolve conflicts that arise when integrating multiple tuples. Notably, our method minimizes the need for annotated data, making it particularly suited for scenarios where labeled datasets are scarce.","authors":["Daomin Ji","Hui Luo","Zhifeng Bao","Shane Culpepper"],"url":"https://arxiv.org/abs/2412.00324"}
{"created":"2025-04-15","title":"Improving Decoupled Posterior Sampling for Inverse Problems using Data Consistency Constraint","abstract":"Diffusion models have shown strong performances in solving inverse problems through posterior sampling while they suffer from errors during earlier steps. To mitigate this issue, several Decoupled Posterior Sampling methods have been recently proposed. However, the reverse process in these methods ignores measurement information, leading to errors that impede effective optimization in subsequent steps. To solve this problem, we propose Guided Decoupled Posterior Sampling (GDPS) by integrating a data consistency constraint in the reverse process. The constraint performs a smoother transition within the optimization process, facilitating a more effective convergence toward the target distribution. Furthermore, we extend our method to latent diffusion models and Tweedie's formula, demonstrating its scalability. We evaluate GDPS on the FFHQ and ImageNet datasets across various linear and nonlinear tasks under both standard and challenging conditions. Experimental results demonstrate that GDPS achieves state-of-the-art performance, improving accuracy over existing methods.","authors":["Zhi Qi","Shihong Yuan","Yulin Yuan","Linling Kuang","Yoshiyuki Kabashima","Xiangming Meng"],"url":"https://arxiv.org/abs/2412.00664"}
{"created":"2025-04-15","title":"Ref-GS: Directional Factorization for 2D Gaussian Splatting","abstract":"In this paper, we introduce Ref-GS, a novel approach for directional light factorization in 2D Gaussian splatting, which enables photorealistic view-dependent appearance rendering and precise geometry recovery. Ref-GS builds upon the deferred rendering of Gaussian splatting and applies directional encoding to the deferred-rendered surface, effectively reducing the ambiguity between orientation and viewing angle. Next, we introduce a spherical Mip-grid to capture varying levels of surface roughness, enabling roughness-aware Gaussian shading. Additionally, we propose a simple yet efficient geometry-lighting factorization that connects geometry and lighting via the vector outer product, significantly reducing renderer overhead when integrating volumetric attributes. Our method achieves superior photorealistic rendering for a range of open-world scenes while also accurately recovering geometry.","authors":["Youjia Zhang","Anpei Chen","Yumin Wan","Zikai Song","Junqing Yu","Yawei Luo","Wei Yang"],"url":"https://arxiv.org/abs/2412.00905"}
{"created":"2025-04-15","title":"FIction: 4D Future Interaction Prediction from Video","abstract":"Anticipating how a person will interact with objects in an environment is essential for activity understanding, but existing methods are limited to the 2D space of video frames-capturing physically ungrounded predictions of \"what\" and ignoring the \"where\" and \"how\". We introduce FIction for 4D future interaction prediction from videos. Given an input video of a human activity, the goal is to predict which objects at what 3D locations the person will interact with in the next time period (e.g., cabinet, fridge), and how they will execute that interaction (e.g., poses for bending, reaching, pulling). Our novel model FIction fuses the past video observation of the person's actions and their environment to predict both the \"where\" and \"how\" of future interactions. Through comprehensive experiments on a variety of activities and real-world environments in EgoExo4D, we show that our proposed approach outperforms prior autoregressive and (lifted) 2D video models substantially, with more than 30% relative gains.","authors":["Kumar Ashutosh","Georgios Pavlakos","Kristen Grauman"],"url":"https://arxiv.org/abs/2412.00932"}
{"created":"2025-04-15","title":"The Problem of Social Cost in Multi-Agent General Reinforcement Learning: Survey and Synthesis","abstract":"The AI safety literature is full of examples of powerful AI agents that, in blindly pursuing a specific and usually narrow objective, ends up with unacceptable and even catastrophic collateral damage to others. In this paper, we consider the problem of social harms that can result from actions taken by learning and utility-maximising agents in a multi-agent environment. The problem of measuring social harms or impacts in such multi-agent settings, especially when the agents are artificial generally intelligent (AGI) agents, was listed as an open problem in Everitt et al, 2018. We attempt a partial answer to that open problem in the form of market-based mechanisms to quantify and control the cost of such social harms. The proposed setup captures many well-studied special cases and is more general than existing formulations of multi-agent reinforcement learning with mechanism design in two ways: (i) the underlying environment is a history-based general reinforcement learning environment like in AIXI; (ii) the reinforcement-learning agents participating in the environment can have different learning strategies and planning horizons. To demonstrate the practicality of the proposed setup, we survey some key classes of learning algorithms and present a few applications, including a discussion of the Paperclips problem and pollution control with a cap-and-trade system.","authors":["Kee Siong Ng","Samuel Yang-Zhao","Timothy Cadogan-Cowper"],"url":"https://arxiv.org/abs/2412.02091"}
{"created":"2025-04-15","title":"Words and Action: Modeling Linguistic Leadership in #BlackLivesMatter Communities","abstract":"In this project, we describe a method of modeling semantic leadership across a set of communities associated with the #BlackLivesMatter movement, which has been informed by qualitative research on the structure of social media and Black Twitter in particular. We describe our bespoke approaches to time-binning, community clustering, and connecting communities over time, as well as our adaptation of state-of-the-art approaches to semantic change detection and semantic leadership induction. We find substantial evidence of the leadership role of BLM activists and progressives, as well as Black celebrities. We also find evidence of the sustained engagement of the conservative community with this discourse, suggesting an alternative explanation for how we arrived at the present moment, in which \"anti-woke\" and \"anti-CRT\" bills are being enacted nationwide.","authors":["Dani Roytburg","Deborah Olorunisola","Sandeep Soni","Lauren Klein"],"url":"https://arxiv.org/abs/2412.02637"}
{"created":"2025-04-15","title":"NODE-AdvGAN: Improving the transferability and perceptual similarity of adversarial examples by dynamic-system-driven adversarial generative model","abstract":"Understanding adversarial examples is crucial for improving model robustness, as they introduce imperceptible perturbations to deceive models. Effective adversarial examples, therefore, offer the potential to train more robust models by eliminating model singularities. We propose NODE-AdvGAN, a novel approach that treats adversarial generation as a continuous process and employs a Neural Ordinary Differential Equation (NODE) to simulate generator dynamics. By mimicking the iterative nature of traditional gradient-based methods, NODE-AdvGAN generates smoother and more precise perturbations that preserve high perceptual similarity when added to benign images. We also propose a new training strategy, NODE-AdvGAN-T, which enhances transferability in black-box attacks by tuning the noise parameters during training. Experiments demonstrate that NODE-AdvGAN and NODE-AdvGAN-T generate more effective adversarial examples that achieve higher attack success rates while preserving better perceptual quality than baseline models.","authors":["Xinheng Xie","Yue Wu","Cuiyu He"],"url":"https://arxiv.org/abs/2412.03539"}
{"created":"2025-04-15","title":"Navigation World Models","abstract":"Navigation is a fundamental skill of agents with visual-motor capabilities. We introduce a Navigation World Model (NWM), a controllable video generation model that predicts future visual observations based on past observations and navigation actions. To capture complex environment dynamics, NWM employs a Conditional Diffusion Transformer (CDiT), trained on a diverse collection of egocentric videos of both human and robotic agents, and scaled up to 1 billion parameters. In familiar environments, NWM can plan navigation trajectories by simulating them and evaluating whether they achieve the desired goal. Unlike supervised navigation policies with fixed behavior, NWM can dynamically incorporate constraints during planning. Experiments demonstrate its effectiveness in planning trajectories from scratch or by ranking trajectories sampled from an external policy. Furthermore, NWM leverages its learned visual priors to imagine trajectories in unfamiliar environments from a single input image, making it a flexible and powerful tool for next-generation navigation systems.","authors":["Amir Bar","Gaoyue Zhou","Danny Tran","Trevor Darrell","Yann LeCun"],"url":"https://arxiv.org/abs/2412.03572"}
{"created":"2025-04-15","title":"Expressivity of Representation Learning on Continuous-Time Dynamic Graphs: An Information-Flow Centric Review","abstract":"Graphs are ubiquitous in real-world applications, ranging from social networks to biological systems, and have inspired the development of Graph Neural Networks (GNNs) for learning expressive representations. While most research has centered on static graphs, many real-world scenarios involve dynamic, temporally evolving graphs, motivating the need for Continuous-Time Dynamic Graph (CTDG) models. This paper provides a comprehensive review of Graph Representation Learning (GRL) on CTDGs with a focus on Self-Supervised Representation Learning (SSRL). We introduce a novel theoretical framework that analyzes the expressivity of CTDG models through an Information-Flow (IF) lens, quantifying their ability to propagate and encode temporal and structural information. Leveraging this framework, we categorize existing CTDG methods based on their suitability for different graph types and application scenarios. Within the same scope, we examine the design of SSRL methods tailored to CTDGs, such as predictive and contrastive approaches, highlighting their potential to mitigate the reliance on labeled data. Empirical evaluations on synthetic and real-world datasets validate our theoretical insights, demonstrating the strengths and limitations of various methods across long-range, bi-partite and community-based graphs. This work offers both a theoretical foundation and practical guidance for selecting and developing CTDG models, advancing the understanding of GRL in dynamic settings.","authors":["Sofiane Ennadir","Gabriela Zarzar Gandler","Filip Cornell","Lele Cao","Oleg Smirnov","Tianze Wang","Levente Z\\'olyomi","Bj\\\"orn Brinne","Sahar Asadi"],"url":"https://arxiv.org/abs/2412.03783"}
{"created":"2025-04-15","title":"LoFi: Vision-Aided Label Generator for Wi-Fi Localization and Tracking","abstract":"Data-driven Wi-Fi localization and tracking have shown great promise due to their lower reliance on specialized hardware compared to model-based methods. However, most existing data collection techniques provide only coarse-grained ground truth or a limited number of labeled points, significantly hindering the advancement of data-driven approaches. While systems like lidar can deliver precise ground truth, their high costs make them inaccessible to many users. To address these challenges, we propose LoFi, a vision-aided label generator for Wi-Fi localization and tracking. LoFi can generate ground truth position coordinates solely from 2D images, offering high precision, low cost, and ease of use. Utilizing our method, we have compiled a Wi-Fi tracking and localization dataset using the ESP32-S3 and a webcam, which will be open-sourced along with the code upon publication.","authors":["Zijian Zhao","Tingwei Chen","Fanyi Meng","Zhijie Cai","Hang Li","Xiaoyang Li","Guangxu Zhu"],"url":"https://arxiv.org/abs/2412.05074"}
{"created":"2025-04-15","title":"Non-Prehensile Tool-Object Manipulation by Integrating LLM-Based Planning and Manoeuvrability-Driven Controls","abstract":"Being able to use tools is a widely recognised indicator of intelligence across species. Humans, for instance, have demonstrated mastery of tool use for over two million years. The ability to use tools is invaluable as it extends an organism's reach and enhances its capacity to interact with objects and the environment. Being able to understand the geometric-mechanical relations between the tools-objects-environments allows certain species (e.g., apes and crows) to reach food in narrow constrained spaces. The same principles of physical augmentation and its associated non-prehensile manipulation capabilities also apply to robotic systems. For example, by instrumenting them with different types of end-effectors, robots can (in principle) dexterously interact (e.g., push and flip) with objects of various shapes and masses akin to its biological counterpart. However, developing this type of manipulation skill is still an open research problem. Furthermore, the complexity of planning tool-object manipulation tasks, particularly in coordinating the actions of dual-arm robots, presents significant challenges. To address these complexities, we propose integrating Large Language Models (LLMs) to assist in planning and executing these intricate manipulations, thereby enhancing the robot's ability to perform in diverse scenarios.","authors":["Hoi-Yin Lee","Peng Zhou","Anqing Duan","Wanyu Ma","Chenguang Yang","David Navarro-Alarcon"],"url":"https://arxiv.org/abs/2412.06931"}
{"created":"2025-04-15","title":"Analyzing the Performance Portability of SYCL across CPUs, GPUs, and Hybrid Systems with SW Sequence Alignment","abstract":"The high-performance computing (HPC) landscape is undergoing rapid transformation, with an increasing emphasis on energy-efficient and heterogeneous computing environments. This comprehensive study extends our previous research on SYCL's performance portability by evaluating its effectiveness across a broader spectrum of computing architectures, including CPUs, GPUs, and hybrid CPU-GPU configurations from NVIDIA, Intel, and AMD. Our analysis covers single-GPU, multi-GPU, single-CPU, and CPU-GPU hybrid setups, using two common, bioinformatic applications as a case study. The results demonstrate SYCL's versatility across different architectures, maintaining comparable performance to CUDA on NVIDIA GPUs while achieving similar architectural efficiency rates on AMD and Intel GPUs in the majority of cases tested. SYCL also demonstrated remarkable versatility and effectiveness across CPUs from various manufacturers, including the latest hybrid architectures from Intel. Although SYCL showed excellent functional portability in hybrid CPU-GPU configurations, performance varied significantly based on specific hardware combinations. Some performance limitations were identified in multi-GPU and CPU-GPU configurations, primarily attributed to workload distribution strategies rather than SYCL-specific constraints. These findings position SYCL as a promising unified programming model for heterogeneous computing environments, particularly for bioinformatic applications.","authors":["Manuel Costanzo","Enzo Rucci","Carlos Garc\\'ia-S\\'anchez","Marcelo Naiouf","Manuel Prieto-Mat\\'ias"],"url":"https://arxiv.org/abs/2412.08308"}
{"created":"2025-04-15","title":"Sketch2Sound: Controllable Audio Generation via Time-Varying Signals and Sonic Imitations","abstract":"We present Sketch2Sound, a generative audio model capable of creating high-quality sounds from a set of interpretable time-varying control signals: loudness, brightness, and pitch, as well as text prompts. Sketch2Sound can synthesize arbitrary sounds from sonic imitations (i.e.,~a vocal imitation or a reference sound-shape). Sketch2Sound can be implemented on top of any text-to-audio latent diffusion transformer (DiT), and requires only 40k steps of fine-tuning and a single linear layer per control, making it more lightweight than existing methods like ControlNet. To synthesize from sketchlike sonic imitations, we propose applying random median filters to the control signals during training, allowing Sketch2Sound to be prompted using controls with flexible levels of temporal specificity. We show that Sketch2Sound can synthesize sounds that follow the gist of input controls from a vocal imitation while retaining the adherence to an input text prompt and audio quality compared to a text-only baseline. Sketch2Sound allows sound artists to create sounds with the semantic flexibility of text prompts and the expressivity and precision of a sonic gesture or vocal imitation. Sound examples are available at https://hugofloresgarcia.art/sketch2sound/.","authors":["Hugo Flores Garc\\'ia","Oriol Nieto","Justin Salamon","Bryan Pardo","Prem Seetharaman"],"url":"https://arxiv.org/abs/2412.08550"}
{"created":"2025-04-15","title":"Quaffure: Real-Time Quasi-Static Neural Hair Simulation","abstract":"Realistic hair motion is crucial for high-quality avatars, but it is often limited by the computational resources available for real-time applications. To address this challenge, we propose a novel neural approach to predict physically plausible hair deformations that generalizes to various body poses, shapes, and hairstyles. Our model is trained using a self-supervised loss, eliminating the need for expensive data generation and storage. We demonstrate our method's effectiveness through numerous results across a wide range of pose and shape variations, showcasing its robust generalization capabilities and temporally smooth results. Our approach is highly suitable for real-time applications with an inference time of only a few milliseconds on consumer hardware and its ability to scale to predicting the drape of 1000 grooms in 0.3 seconds.","authors":["Tuur Stuyck","Gene Wei-Chin Lin","Egor Larionov","Hsiao-yu Chen","Aljaz Bozic","Nikolaos Sarafianos","Doug Roble"],"url":"https://arxiv.org/abs/2412.10061"}
{"created":"2025-04-15","title":"GAF: Gaussian Avatar Reconstruction from Monocular Videos via Multi-view Diffusion","abstract":"We propose a novel approach for reconstructing animatable 3D Gaussian avatars from monocular videos captured by commodity devices like smartphones. Photorealistic 3D head avatar reconstruction from such recordings is challenging due to limited observations, which leaves unobserved regions under-constrained and can lead to artifacts in novel views. To address this problem, we introduce a multi-view head diffusion model, leveraging its priors to fill in missing regions and ensure view consistency in Gaussian splatting renderings. To enable precise viewpoint control, we use normal maps rendered from FLAME-based head reconstruction, which provides pixel-aligned inductive biases. We also condition the diffusion model on VAE features extracted from the input image to preserve facial identity and appearance details. For Gaussian avatar reconstruction, we distill multi-view diffusion priors by using iteratively denoised images as pseudo-ground truths, effectively mitigating over-saturation issues. To further improve photorealism, we apply latent upsampling priors to refine the denoised latent before decoding it into an image. We evaluate our method on the NeRSemble dataset, showing that GAF outperforms previous state-of-the-art methods in novel view synthesis. Furthermore, we demonstrate higher-fidelity avatar reconstructions from monocular videos captured on commodity devices.","authors":["Jiapeng Tang","Davide Davoli","Tobias Kirschstein","Liam Schoneveld","Matthias Niessner"],"url":"https://arxiv.org/abs/2412.10209"}
{"created":"2025-04-15","title":"Look Before You Leap: Enhancing Attention and Vigilance Regarding Harmful Content with GuidelineLLM","abstract":"Despite being empowered with alignment mechanisms, large language models (LLMs) are increasingly vulnerable to emerging jailbreak attacks that can compromise their alignment mechanisms. This vulnerability poses significant risks to real-world applications. Existing work faces challenges in both training efficiency and generalization capabilities (i.e., Reinforcement Learning from Human Feedback and Red-Teaming). Developing effective strategies to enable LLMs to resist continuously evolving jailbreak attempts represents a significant challenge. To address this challenge, we propose a novel defensive paradigm called GuidelineLLM, which assists LLMs in recognizing queries that may have harmful content. Before LLMs respond to a query, GuidelineLLM first identifies potential risks associated with the query, summarizes these risks into guideline suggestions, and then feeds these guidelines to the responding LLMs. Importantly, our approach eliminates the necessity for additional safety fine-tuning of the LLMs themselves; only the GuidelineLLM requires fine-tuning. This characteristic enhances the general applicability of GuidelineLLM across various LLMs. Experimental results demonstrate that GuidelineLLM can significantly reduce the attack success rate (ASR) against LLM (an average reduction of 34.17\\% ASR) while maintaining the usefulness of LLM in handling benign queries. The code is available at https://github.com/sqzhang-lazy/GuidelineLLM.","authors":["Shaoqing Zhang","Zhuosheng Zhang","Kehai Chen","Rongxiang Weng","Muyun Yang","Tiejun Zhao","Min Zhang"],"url":"https://arxiv.org/abs/2412.10423"}
{"created":"2025-04-15","title":"CFSSeg: Closed-Form Solution for Class-Incremental Semantic Segmentation of 2D Images and 3D Point Clouds","abstract":"2D images and 3D point clouds are foundational data types for multimedia applications, including real-time video analysis, augmented reality (AR), and 3D scene understanding. Class-incremental semantic segmentation (CSS) requires incrementally learning new semantic categories while retaining prior knowledge. Existing methods typically rely on computationally expensive training based on stochastic gradient descent, employing complex regularization or exemplar replay. However, stochastic gradient descent-based approaches inevitably update the model's weights for past knowledge, leading to catastrophic forgetting, a problem exacerbated by pixel/point-level granularity. To address these challenges, we propose CFSSeg, a novel exemplar-free approach that leverages a closed-form solution, offering a practical and theoretically grounded solution for continual semantic segmentation tasks. This eliminates the need for iterative gradient-based optimization and storage of past data, requiring only a single pass through new samples per step. It not only enhances computational efficiency but also provides a practical solution for dynamic, privacy-sensitive multimedia environments. Extensive experiments on 2D and 3D benchmark datasets such as Pascal VOC2012, S3DIS, and ScanNet demonstrate CFSSeg's superior performance.","authors":["Jiaxu Li","Rui Li","Jianyu Qi","Songning Lai","Linpu Lv","Kejia Fan","Jianheng Tang","Yutao Yue","Dongzhan Zhou","Yuanhuai Liu","Huiping Zhuang"],"url":"https://arxiv.org/abs/2412.10834"}
{"created":"2025-04-15","title":"Tokens, the oft-overlooked appetizer: Large language models, the distributional hypothesis, and meaning","abstract":"Tokenization is a necessary component within the current architecture of many language models, including the transformer-based large language models (LLMs) of Generative AI, yet its impact on the model's cognition is often overlooked. We argue that LLMs demonstrate that the Distributional Hypothesis (DH) is sufficient for reasonably human-like language performance, and that the emergence of human-meaningful linguistic units among tokens and current structural constraints motivate changes to existing, linguistically-agnostic tokenization techniques, particularly with respect to their roles as (1) semantic primitives and as (2) vehicles for conveying salient distributional patterns from human language to the model. We explore tokenizations from a BPE tokenizer; extant model vocabularies obtained from Hugging Face and tiktoken; and the information in exemplar token vectors as they move through the layers of a RoBERTa (large) model. Besides creating sub-optimal semantic building blocks and obscuring the model's access to the necessary distributional patterns, we describe how tokens and pretraining can act as a backdoor for bias and other unwanted content, which current alignment practices may not remediate. Additionally, we relay evidence that the tokenization algorithm's objective function impacts the LLM's cognition, despite being arguably meaningfully insulated from the main system intelligence. [First uploaded to arXiv in December, 2024.]","authors":["Julia Witte Zimmerman","Denis Hudon","Kathryn Cramer","Alejandro J. Ruiz","Calla Beauregard","Ashley Fehr","Mikaela Irene Fudolig","Bradford Demarest","Yoshi Meke Bird","Milo Z. Trujillo","Christopher M. Danforth","Peter Sheridan Dodds"],"url":"https://arxiv.org/abs/2412.10924"}
{"created":"2025-04-15","title":"RAC3: Retrieval-Augmented Corner Case Comprehension for Autonomous Driving with Vision-Language Models","abstract":"Understanding and addressing corner cases is essential for ensuring the safety and reliability of autonomous driving systems. Vision-language models (VLMs) play a crucial role in enhancing scenario comprehension, yet they face significant challenges, such as hallucination and insufficient real-world grounding, which compromise their performance in critical driving scenarios. In this work, RAC3, a novel framework designed to enhance the performance of VLMs in corner case comprehension, is proposed. RAC3 integrates a frequency-spatial fusion (FSF) image encoder, cross-modal alignment fine-tuning with hard and semi-hard negative mining, and a fast querying pipeline based on KMeans clustering and hierarchical navigable small world (HNSW) indexing. A multimodal chain-of-thought (CoT) prompting strategy to guide analogical reasoning and reduce hallucinations during inference is introduced. Moreover, an update mechanism is integrated into RAC3 to ensure continual learning within the framework. Extensive experiments on the CODA and NuScenes datasets demonstrate that RAC3 significantly improves corner case comprehension across multiple downstream tasks. Compared to prior state-of-the-art methods, RAC3 achieves the highest final score of 74.46 on the CODA-LM benchmark and shows consistent performance gains when integrated with end-to-end frameworks like DriveLM. These results demonstrate the effectiveness of retrieval-augmented strategies and cross-modal alignment for safer and more interpretable autonomous driving.","authors":["Yujin Wang","Quanfeng Liu","Jiaqi Fan","Jinlong Hong","Hongqing Chu","Mengjian Tian","Bingzhao Gao","Hong Chen"],"url":"https://arxiv.org/abs/2412.11050"}
{"created":"2025-04-15","title":"Nearly Zero-Cost Protection Against Mimicry by Personalized Diffusion Models","abstract":"Recent advancements in diffusion models revolutionize image generation but pose risks of misuse, such as replicating artworks or generating deepfakes. Existing image protection methods, though effective, struggle to balance protection efficacy, invisibility, and latency, thus limiting practical use. We introduce perturbation pre-training to reduce latency and propose a mixture-of-perturbations approach that dynamically adapts to input images to minimize performance degradation. Our novel training strategy computes protection loss across multiple VAE feature spaces, while adaptive targeted protection at inference enhances robustness and invisibility. Experiments show comparable protection performance with improved invisibility and drastically reduced inference time. The code and demo are available at https://webtoon.github.io/impasto","authors":["Namhyuk Ahn","KiYoon Yoo","Wonhyuk Ahn","Daesik Kim","Seung-Hun Nam"],"url":"https://arxiv.org/abs/2412.11423"}
{"created":"2025-04-15","title":"CLIP-SR: Collaborative Linguistic and Image Processing for Super-Resolution","abstract":"Convolutional Neural Networks (CNNs) have significantly advanced Image Super-Resolution (SR), yet most CNN-based methods rely solely on pixel-based transformations, often leading to artifacts and blurring, particularly under severe downsampling rates (\\eg, 8$\\times$ or 16$\\times$). The recently developed text-guided SR approaches leverage textual descriptions to enhance their detail restoration capabilities but frequently struggle with effectively performing alignment, resulting in semantic inconsistencies. To address these challenges, we propose a multi-modal semantic enhancement framework that integrates textual semantics with visual features, effectively mitigating semantic mismatches and detail losses in highly degraded low-resolution (LR) images. Our method enables realistic, high-quality SR to be performed at large upscaling factors, with a maximum scaling ratio of 16$\\times$. The framework integrates both text and image inputs using the prompt predictor, the Text-Image Fusion Block (TIFBlock), and the Iterative Refinement Module, leveraging Contrastive Language-Image Pretraining (CLIP) features to guide a progressive enhancement process with fine-grained alignment. This synergy produces high-resolution outputs with sharp textures and strong semantic coherence, even at substantial scaling factors. Extensive comparative experiments and ablation studies validate the effectiveness of our approach. Furthermore, by leveraging textual semantics, our method offers a degree of super-resolution editability, allowing for controlled enhancements while preserving semantic consistency. The code is available at https://github.com/hengliusky/CLIP-SR.","authors":["Bingwen Hu","Heng Liu","Zhedong Zheng","Ping Liu"],"url":"https://arxiv.org/abs/2412.11609"}
{"created":"2025-04-15","title":"Faster Vision Mamba is Rebuilt in Minutes via Merged Token Re-training","abstract":"Vision Mamba has shown close to state of the art performance on computer vision tasks, drawing much interest in increasing it's efficiency. A promising approach is token reduction (that has been successfully implemented in ViTs). Pruning informative tokens in Mamba leads to a high loss of key knowledge and degraded performance. An alternative, of merging tokens preserves more information than pruning, also suffers for large compression ratios. Our key insight is that a quick round of retraining after token merging yeilds robust results across various compression ratios. Empirically, pruned Vims only drop up to 0.9% accuracy on ImageNet-1K, recovered by our proposed framework R-MeeTo in our main evaluation. We show how simple and effective the fast recovery can be achieved at minute-level, in particular, a 35.9% accuracy spike over 3 epochs of training on Vim-Ti. Moreover, Vim-Ti/S/B are re-trained within 5/7/17 minutes, and Vim-S only drops 1.3% with 1.2x (up to 1.5x) speed up in inference.","authors":["Mingjia Shi","Yuhao Zhou","Ruiji Yu","Zekai Li","Zhiyuan Liang","Xuanlei Zhao","Xiaojiang Peng","Shanmukha Ramakrishna Vedantam","Wangbo Zhao","Kai Wang","Yang You"],"url":"https://arxiv.org/abs/2412.12496"}
{"created":"2025-04-15","title":"Predicting User Behavior in Smart Spaces with LLM-Enhanced Logs and Personalized Prompts","abstract":"Enhancing the intelligence of smart systems, such as smart home, and smart vehicle, and smart grids, critically depends on developing sophisticated planning capabilities that can anticipate the next desired function based on historical interactions. While existing methods view user behaviors as sequential data and apply models like RNNs and Transformers to predict future actions, they often fail to incorporate domain knowledge and capture personalized user preferences. In this paper, we propose a novel approach that incorporates LLM-enhanced logs and personalized prompts. Our approach first constructs a graph that captures individual behavior preferences derived from their interaction histories. This graph effectively transforms into a soft continuous prompt that precedes the sequence of user behaviors. Then our approach leverages the vast general knowledge and robust reasoning capabilities of a pretrained LLM to enrich the oversimplified and incomplete log records. By enhancing these logs semantically, our approach better understands the user's actions and intentions, especially for those rare events in the dataset. We evaluate the method across four real-world datasets from both smart vehicle and smart home settings. The findings validate the effectiveness of our LLM-enhanced description and personalized prompt, shedding light on potential ways to advance the intelligence of smart space.","authors":["Yunpeng Song","Jiawei Li","Yiheng Bian","Zhongmin Cai"],"url":"https://arxiv.org/abs/2412.12653"}
{"created":"2025-04-15","title":"Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures","abstract":"Real-time free-view human rendering from sparse-view RGB inputs is a challenging task due to the sensor scarcity and the tight time budget. To ensure efficiency, recent methods leverage 2D CNNs operating in texture space to learn rendering primitives. However, they either jointly learn geometry and appearance, or completely ignore sparse image information for geometry estimation, significantly harming visual quality and robustness to unseen body poses. To address these issues, we present Double Unprojected Textures, which at the core disentangles coarse geometric deformation estimation from appearance synthesis, enabling robust and photorealistic 4K rendering in real-time. Specifically, we first introduce a novel image-conditioned template deformation network, which estimates the coarse deformation of the human template from a first unprojected texture. This updated geometry is then used to apply a second and more accurate texture unprojection. The resulting texture map has fewer artifacts and better alignment with input views, which benefits our learning of finer-level geometry and appearance represented by Gaussian splats. We validate the effectiveness and efficiency of the proposed method in quantitative and qualitative experiments, which significantly surpasses other state-of-the-art methods. Project page: https://vcai.mpi-inf.mpg.de/projects/DUT/","authors":["Guoxing Sun","Rishabh Dabral","Heming Zhu","Pascal Fua","Christian Theobalt","Marc Habermann"],"url":"https://arxiv.org/abs/2412.13183"}
{"created":"2025-04-15","title":"Seeking Consistent Flat Minima for Better Domain Generalization via Refining Loss Landscapes","abstract":"Domain generalization aims to learn a model from multiple training domains and generalize it to unseen test domains. Recent theory has shown that seeking the deep models, whose parameters lie in the flat minima of the loss landscape, can significantly reduce the out-of-domain generalization error. However, existing methods often neglect the consistency of loss landscapes in different domains, resulting in models that are not simultaneously in the optimal flat minima in all domains, which limits their generalization ability. To address this issue, this paper proposes an iterative Self-Feedback Training (SFT) framework to seek consistent flat minima that are shared across different domains by progressively refining loss landscapes during training. It alternatively generates a feedback signal by measuring the inconsistency of loss landscapes in different domains and refines these loss landscapes for greater consistency using this feedback signal. Benefiting from the consistency of the flat minima within these refined loss landscapes, our SFT helps achieve better out-of-domain generalization. Extensive experiments on DomainBed demonstrate superior performances of SFT when compared to state-of-the-art sharpness-aware methods and other prevalent DG baselines. On average across five DG benchmarks, SFT surpasses the sharpness-aware minimization by 2.6% with ResNet-50 and 1.5% with ViT-B/16, respectively. The code will be available soon.","authors":["Aodi Li","Liansheng Zhuang","Xiao Long","Minghong Yao","Shafei Wang"],"url":"https://arxiv.org/abs/2412.13573"}
{"created":"2025-04-15","title":"A Comprehensive Review on Traffic Datasets and Simulators for Autonomous Vehicles","abstract":"Autonomous driving has rapidly evolved through synergistic developments in hardware and artificial intelligence. This comprehensive review investigates traffic datasets and simulators as dual pillars supporting autonomous vehicle (AV) development. Unlike prior surveys that examine these resources independently, we present an integrated analysis spanning the entire AV pipeline-perception, localization, prediction, planning, and control. We evaluate annotation practices and quality metrics while examining how geographic diversity and environmental conditions affect system reliability. Our analysis includes detailed characterizations of datasets organized by functional domains and an in-depth examination of traffic simulators categorized by their specialized contributions to research and development. The paper explores emerging trends, including novel architecture frameworks, multimodal AI integration, and advanced data generation techniques that address critical edge cases. By highlighting the interconnections between real-world data collection and simulation environments, this review offers researchers a roadmap for developing more robust and resilient autonomous systems equipped to handle the diverse challenges encountered in real-world driving environments.","authors":["Supriya Sarker","Brent Maples","Iftekharul Islam","Muyang Fan","Christos Papadopoulos","Weizi Li"],"url":"https://arxiv.org/abs/2412.14207"}
{"created":"2025-04-15","title":"WikiStyle+: A Multimodal Approach to Content-Style Representation Disentanglement for Artistic Image Stylization","abstract":"Artistic image stylization aims to render the content provided by text or image with the target style, where content and style decoupling is the key to achieve satisfactory results. However, current methods for content and style disentanglement primarily rely on image supervision, which leads to two problems: 1) models can only support one modality for style or content input;2) incomplete disentanglement resulting in content leakage from the reference image. To address the above issues, this paper proposes a multimodal approach to content-style disentanglement for artistic image stylization. We construct a \\textit{WikiStyle+} dataset consists of artworks with corresponding textual descriptions for style and content. Based on the multimodal dataset, we propose a disentangled representations-guided diffusion model. The disentangled representations are first learned by Q-Formers and then injected into a pre-trained diffusion model using learnable multi-step cross-attention layers. Experimental results show that our method achieves a thorough disentanglement of content and style in reference images under multimodal supervision, thereby enabling more refined stylization that aligns with the artistic characteristics of the reference style. The code of our method will be available upon acceptance.","authors":["Ma Zhuoqi","Zhang Yixuan","You Zejun","Tian Long","Liu Xiyang"],"url":"https://arxiv.org/abs/2412.14496"}
{"created":"2025-04-15","title":"Multi-Level Embedding and Alignment Network with Consistency and Invariance Learning for Cross-View Geo-Localization","abstract":"Cross-View Geo-Localization (CVGL) involves determining the localization of drone images by retrieving the most similar GPS-tagged satellite images. However, the imaging gaps between platforms are often significant and the variations in viewpoints are substantial, which limits the ability of existing methods to effectively associate cross-view features and extract consistent and invariant characteristics. Moreover, existing methods often overlook the problem of increased computational and storage requirements when improving model performance. To handle these limitations, we propose a lightweight enhanced alignment network, called the Multi-Level Embedding and Alignment Network (MEAN). The MEAN network uses a progressive multi-level enhancement strategy, global-to-local associations, and cross-domain alignment, enabling feature communication across levels. This allows MEAN to effectively connect features at different levels and learn robust cross-view consistent mappings and modality-invariant features. Moreover, MEAN adopts a shallow backbone network combined with a lightweight branch design, effectively reducing parameter count and computational complexity. Experimental results on the University-1652 and SUES-200 datasets demonstrate that MEAN reduces parameter count by 62.17% and computational complexity by 70.99% compared to state-of-the-art models, while maintaining competitive or even superior performance. Our code and models will be released on https://github.com/ISChenawei/MEAN.","authors":["Zhongwei Chen","Zhao-Xu Yang","Hai-Jun Rong"],"url":"https://arxiv.org/abs/2412.14819"}
{"created":"2025-04-15","title":"From Vulnerabilities to Remediation: A Systematic Literature Review of LLMs in Code Security","abstract":"Large Language Models (LLMs) have emerged as powerful tools for automating various programming tasks, including security-related ones, such as detecting and fixing vulnerabilities. Despite their promising capabilities, when required to produce or modify pre-existing code, LLMs could introduce vulnerabilities unbeknown to the programmer. When analyzing code, they could miss clear vulnerabilities or signal nonexistent ones. In this Systematic Literature Review (SLR), we aim to investigate both the security benefits and potential drawbacks of using LLMs for a variety of code-related tasks. In particular, first we focus on the types of vulnerabilities that could be introduced by LLMs, when used for producing code. Second, we analyze the capabilities of LLMs to detect and fix vulnerabilities, in any given code, and how the prompting strategy of choice impacts their performance in these two tasks. Last, we provide an in-depth analysis on how data poisoning attacks on LLMs can impact performance in the aforementioned tasks.","authors":["Enna Basic","Alberto Giaretta"],"url":"https://arxiv.org/abs/2412.15004"}
{"created":"2025-04-15","title":"Offline Safe Reinforcement Learning Using Trajectory Classification","abstract":"Offline safe reinforcement learning (RL) has emerged as a promising approach for learning safe behaviors without engaging in risky online interactions with the environment. Most existing methods in offline safe RL rely on cost constraints at each time step (derived from global cost constraints) and this can result in either overly conservative policies or violation of safety constraints. In this paper, we propose to learn a policy that generates desirable trajectories and avoids undesirable trajectories. To be specific, we first partition the pre-collected dataset of state-action trajectories into desirable and undesirable subsets. Intuitively, the desirable set contains high reward and safe trajectories, and undesirable set contains unsafe trajectories and low-reward safe trajectories. Second, we learn a policy that generates desirable trajectories and avoids undesirable trajectories, where (un)desirability scores are provided by a classifier learnt from the dataset of desirable and undesirable trajectories. This approach bypasses the computational complexity and stability issues of a min-max objective that is employed in existing methods. Theoretically, we also show our approach's strong connections to existing learning paradigms involving human feedback. Finally, we extensively evaluate our method using the DSRL benchmark for offline safe RL. Empirically, our method outperforms competitive baselines, achieving higher rewards and better constraint satisfaction across a wide variety of benchmark tasks.","authors":["Ze Gong","Akshat Kumar","Pradeep Varakantham"],"url":"https://arxiv.org/abs/2412.15429"}
{"created":"2025-04-15","title":"Choose Your Explanation: A Comparison of SHAP and GradCAM in Human Activity Recognition","abstract":"Explaining machine learning (ML) models using eXplainable AI (XAI) techniques has become essential to make them more transparent and trustworthy. This is especially important in high-stakes domains like healthcare, where understanding model decisions is critical to ensure ethical, sound, and trustworthy outcome predictions. However, users are often confused about which explanability method to choose for their specific use case. We present a comparative analysis of widely used explainability methods, Shapley Additive Explanations (SHAP) and Gradient-weighted Class Activation Mapping (Grad-CAM), within the domain of human activity recognition (HAR) utilizing graph convolutional networks (GCNs). By evaluating these methods on skeleton-based data from two real-world datasets, including a healthcare-critical cerebral palsy (CP) case, this study provides vital insights into both approaches' strengths, limitations, and differences, offering a roadmap for selecting the most appropriate explanation method based on specific models and applications. We quantitatively and quantitatively compare these methods, focusing on feature importance ranking, interpretability, and model sensitivity through perturbation experiments. While SHAP provides detailed input feature attribution, Grad-CAM delivers faster, spatially oriented explanations, making both methods complementary depending on the application's requirements. Given the importance of XAI in enhancing trust and transparency in ML models, particularly in sensitive environments like healthcare, our research demonstrates how SHAP and Grad-CAM could complement each other to provide more interpretable and actionable model explanations.","authors":["Felix Tempel","Daniel Groos","Espen Alexander F. Ihlen","Lars Adde","Inga Str\\\"umke"],"url":"https://arxiv.org/abs/2412.16003"}
{"created":"2025-04-15","title":"Frequency Is What You Need: Word-frequency Masking Benefits Vision-Language Model Pre-training","abstract":"Vision Language Models (VLMs) can be trained more efficiently if training sets can be reduced in size. Recent work has shown the benefits of masking text during VLM training using a variety of approaches: truncation, random masking, block masking and syntax masking. In this paper, we show that the best masking strategy changes over training epochs and that, given sufficient training epochs. We analyze existing text masking approaches including syntax masking, which is currently the state of the art, and identify the word frequency distribution as important in determining their success. Experiments on a large range of data sets demonstrate that syntax masking is outperformed by other approaches, given sufficient epochs, and that our proposed frequency-based approach, called Contrastive Language-Image Pre-training with Word Frequency Masking (CLIPF) has numerous advantages. The benefits are particularly evident as the number of input tokens decreases.","authors":["Mingliang Liang","Martha Larson"],"url":"https://arxiv.org/abs/2412.16148"}
{"created":"2025-04-15","title":"Efficient cell-centered nodal integral method for multi-dimensional Burgers equations","abstract":"An efficient coarse-mesh nodal integral method (NIM), based on cell-centered variables and termed the cell-centered NIM (CCNIM), is developed and applied to solve multi-dimensional, time-dependent, nonlinear Burgers equations, extending the applicability of CCNIM to nonlinear problems. To overcome the existing limitation of CCNIM to linear problems, the convective velocity in the nonlinear convection term is approximated using two different approaches, both demonstrating accuracy comparable to or better than traditional NIM for nonlinear Burgers problems. Unlike traditional NIM, which utilizes surface-averaged variables as discrete unknowns, this innovative approach formulates the final expression of the numerical scheme using discrete unknowns represented by cell-centered (or node-averaged) variables. Using these cell centroids, the proposed CCNIM approach presents several advantages compared to traditional NIM. These include a simplified implementation process in terms of local coordinate systems, enhanced flexibility regarding the higher order of accuracy in time, straightforward formulation for higher-degree temporal derivatives, and offering a viable option for coupling with other physics. The multi-dimensional time-dependent Burgers problems (propagating shock, propagation, and diffusion of an initial sinusoidal wave, shock-like formation) with known analytical solutions are solved in order to validate the developed scheme. Furthermore, a detailed comparison between the proposed CCNIM approach and other traditional NIM schemes is conducted to demonstrate its effectiveness. The proposed approach has shown quadratic convergence in both space and time, i.e., O[$(\\Delta x)^2, (\\Delta t)^2$], for the considered test problems. The simplicity and robustness of the approach provide a strong foundation for its seamless extension to more complex fluid flow problems.","authors":["Nadeem Ahmed","Ram Prakash Bharti","Suneet Singh"],"url":"https://arxiv.org/abs/2412.19079"}
{"created":"2025-04-15","title":"Generative Regression Based Watch Time Prediction for Short-Video Recommendation","abstract":"Watch time prediction (WTP) has emerged as a pivotal task in short video recommendation systems, designed to quantify user engagement through continuous interaction modeling. Predicting users' watch times on videos often encounters fundamental challenges, including wide value ranges and imbalanced data distributions, which can lead to significant estimation bias when directly applying regression techniques. Recent studies have attempted to address these issues by converting the continuous watch time estimation into an ordinal regression task. While these methods demonstrate partial effectiveness, they exhibit notable limitations: (1) the discretization process frequently relies on bucket partitioning, inherently reducing prediction flexibility and accuracy and (2) the interdependencies among different partition intervals remain underutilized, missing opportunities for effective error correction.","authors":["Hongxu Ma","Kai Tian","Tao Zhang","Xuefeng Zhang","Han Zhou","Chunjie Chen","Han Li","Jihong Guan","Shuigeng Zhou"],"url":"https://arxiv.org/abs/2412.20211"}
{"created":"2025-04-15","title":"Hybrid Feedback Control for Global Navigation with Locally Optimal Obstacle Avoidance in n-Dimensional Spaces","abstract":"We present a hybrid feedback control framework for autonomous robot navigation in n-dimensional Euclidean spaces cluttered with spherical obstacles. The proposed approach ensures safe navigation and global asymptotic stability (GAS) of the target location by dynamically switching between two operational modes: motion-to-destination and locally optimal obstacle-avoidance. It produces continuous velocity inputs, ensures collision-free trajectories and generates locally optimal obstacle avoidance maneuvers. Unlike existing methods, the proposed framework is compatible with range sensors, enabling navigation in both a priori known and unknown environments. Extensive simulations in 2D and 3D settings, complemented by experimental validation on a TurtleBot 4 platform, confirm the efficacy and robustness of the approach. Our results demonstrate shorter paths and smoother trajectories compared to state-of-the-art methods, while maintaining computational efficiency and real-world feasibility.","authors":["Ishak Cheniouni","Soulaimane Berkane","Abdelhamid Tayebi"],"url":"https://arxiv.org/abs/2412.20320"}
{"created":"2025-04-15","title":"Navigating Image Restoration with VAR's Distribution Alignment Prior","abstract":"Generative models trained on extensive high-quality datasets effectively capture the structural and statistical properties of clean images, rendering them powerful priors for transforming degraded features into clean ones in image restoration. VAR, a novel image generative paradigm, surpasses diffusion models in generation quality by applying a next-scale prediction approach. It progressively captures both global structures and fine-grained details through the autoregressive process, consistent with the multi-scale restoration principle widely acknowledged in the restoration community. Furthermore, we observe that during the image reconstruction process utilizing VAR, scale predictions automatically modulate the input, facilitating the alignment of representations at subsequent scales with the distribution of clean images. To harness VAR's adaptive distribution alignment capability in image restoration tasks, we formulate the multi-scale latent representations within VAR as the restoration prior, thus advancing our delicately designed VarFormer framework. The strategic application of these priors enables our VarFormer to achieve remarkable generalization on unseen tasks while also reducing training computational costs. Extensive experiments underscores that our VarFormer outperforms existing multi-task image restoration methods across various restoration tasks.","authors":["Siyang Wang","Feng Zhao"],"url":"https://arxiv.org/abs/2412.21063"}
{"created":"2025-04-15","title":"Probing Visual Language Priors in VLMs","abstract":"Despite recent advances in Vision-Language Models (VLMs), they may over-rely on visual language priors existing in their training data rather than true visual reasoning. To investigate this, we introduce ViLP, a benchmark featuring deliberately out-of-distribution images synthesized via image generation models and out-of-distribution Q&amp;A pairs. Each question in ViLP is coupled with three potential answers and three corresponding images: one that can be resolved by text priors alone and two that demand visual reasoning. Although, humans achieve near-perfect accuracy, modern VLMs falter; for instance, GPT-4 achieves only 66.17% on ViLP. To alleviate this, we propose a self-improving framework in which models generate new VQA data, then apply pixel-level and semantic corruptions to form \"good-bad\" image pairs for self-training. Our training objectives compel VLMs to focus more on the actual visual inputs, and we demonstrate their effectiveness in boosting the performance of open-source VLMs, including LLaVA-v1.5 and Cambrian.","authors":["Tiange Luo","Ang Cao","Gunhee Lee","Justin Johnson","Honglak Lee"],"url":"https://arxiv.org/abs/2501.00569"}
{"created":"2025-04-15","title":"Beyond Words: AuralLLM and SignMST-C for Sign Language Production and Bidirectional Accessibility","abstract":"Sign language is the primary communication mode for 72 million hearing-impaired individuals worldwide, necessitating effective bidirectional Sign Language Production and Sign Language Translation systems. However, functional bidirectional systems require a unified linguistic environment, hindered by the lack of suitable unified datasets, particularly those providing the necessary pose information for accurate Sign Language Production (SLP) evaluation. Concurrently, current SLP evaluation methods like back-translation ignore pose accuracy, and high-quality coordinated generation remains challenging. To create this crucial environment and overcome these challenges, we introduce CNText2Sign and CNSign, which together constitute the first unified dataset aimed at supporting bidirectional accessibility systems for Chinese sign language; CNText2Sign provides 15,000 natural language-to-sign mappings and standardized skeletal keypoints for 8,643 vocabulary items supporting pose assessment. Building upon this foundation, we propose the AuraLLM model, which leverages a decoupled architecture with CNText2Sign's pose data for novel direct gesture accuracy assessment. The model employs retrieval augmentation and Cascading Vocabulary Resolution to handle semantic mapping and out-of-vocabulary words and achieves all-scenario production with controllable coordination of gestures and facial expressions via pose-conditioned video synthesis. Concurrently, our Sign Language Translation model SignMST-C employs targeted self-supervised pretraining for dynamic feature capture, achieving new SOTA results on PHOENIX2014-T with BLEU-4 scores up to 32.08. AuraLLM establishes a strong performance baseline on CNText2Sign with a BLEU-4 score of 50.41 under direct evaluation.","authors":["Yulong Li","Yuxuan Zhang","Feilong Tang","Ming Hu","Zhixiang Lu","Haochen Xue","Jianghao Wu","Mian Zhou","Kang Dang","Chong Li","Yifang Wang","Imran Razzak","Jionglong Su"],"url":"https://arxiv.org/abs/2501.00765"}
{"created":"2025-04-15","title":"GRAMC: General-purpose and reconfigurable analog matrix computing architecture","abstract":"In-memory analog matrix computing (AMC) with resistive random-access memory (RRAM) represents a highly promising solution that solves matrix problems in one step. However, the existing AMC circuits each have a specific connection topology to implement a single computing function, lack of the universality as a matrix processor. In this work, we design a reconfigurable AMC macro for general-purpose matrix computations, which is achieved by configuring proper connections between memory array and amplifier circuits. Based on this macro, we develop a hybrid system that incorporates an on-chip write-verify scheme and digital functional modules, to deliver a general-purpose AMC solver for various applications.","authors":["Lunshuai Pan","Shiqing Wang","Pushen Zuo","Zhong Sun"],"url":"https://arxiv.org/abs/2501.01586"}
{"created":"2025-04-15","title":"DFF: Decision-Focused Fine-tuning for Smarter Predict-then-Optimize with Limited Data","abstract":"Decision-focused learning (DFL) offers an end-to-end approach to the predict-then-optimize (PO) framework by training predictive models directly on decision loss (DL), enhancing decision-making performance within PO contexts. However, the implementation of DFL poses distinct challenges. Primarily, DL can result in deviation from the physical significance of the predictions under limited data. Additionally, some predictive models are non-differentiable or black-box, which cannot be adjusted using gradient-based methods. To tackle the above challenges, we propose a novel framework, Decision-Focused Fine-tuning (DFF), which embeds the DFL module into the PO pipeline via a novel bias correction module. DFF is formulated as a constrained optimization problem that maintains the proximity of the DL-enhanced model to the original predictive model within a defined trust region. We theoretically prove that DFF strictly confines prediction bias within a predetermined upper bound, even with limited datasets, thereby substantially reducing prediction shifts caused by DL under limited data. Furthermore, the bias correction module can be integrated into diverse predictive models, enhancing adaptability to a broad range of PO tasks. Extensive evaluations on synthetic and real-world datasets, including network flow, portfolio optimization, and resource allocation problems with different predictive models, demonstrate that DFF not only improves decision performance but also adheres to fine-tuning constraints, showcasing robust adaptability across various scenarios.","authors":["Jiaqi Yang","Enming Liang","Zicheng Su","Zhichao Zou","Peng Zhen","Jiecheng Guo","Wanjing Ma","Kun An"],"url":"https://arxiv.org/abs/2501.01874"}
{"created":"2025-04-15","title":"Data-driven Optimization for the Evolve-Filter-Relax regularization of convection-dominated flows","abstract":"Numerical stabilization techniques are often employed in under-resolved simulations of convection-dominated flows to improve accuracy and mitigate spurious oscillations. Specifically, the evolve--filter--relax (EFR) algorithm is a framework which consists in evolving the solution, applying a filtering step to remove high-frequency noise, and relaxing through a convex combination of filtered and original solutions. The stability and accuracy of the EFR solution strongly depend on two parameters, the filter radius $\\delta$ and the relaxation parameter $\\chi$. Standard choices for these parameters are usually fixed in time, and related to the full order model setting, i.e., the grid size for $\\delta$ and the time step for $\\chi$. The key novelties with respect to the standard EFR approach are: (i) time-dependent parameters $\\delta(t)$ and $\\chi(t)$, and (ii) data-driven adaptive optimization of the parameters in time, considering a fully-resolved simulation as reference. In particular, we propose three different classes of optimized-EFR (Opt-EFR) strategies, aiming to optimize one or both parameters. The new Opt-EFR strategies are tested in the under-resolved simulation of a turbulent flow past a cylinder at $Re=1000$. The Opt-EFR proved to be more accurate than standard approaches by up to 99$\\%$, while maintaining a similar computational time. In particular, the key new finding of our analysis is that such accuracy can be obtained only if the optimized objective function includes: (i) a global metric (as the kinetic energy), and (ii) spatial gradients' information.","authors":["Anna Ivagnes","Maria Strazzullo","Michele Girfoglio","Traian Iliescu","Gianluigi Rozza"],"url":"https://arxiv.org/abs/2501.03933"}
{"created":"2025-04-15","title":"Separate Source Channel Coding Is Still What You Need: An LLM-based Rethinking","abstract":"Along with the proliferating research interest in Semantic Communication (SemCom), Joint Source Channel Coding (JSCC) has dominated the attention due to the widely assumed existence in efficiently delivering information semantics. %has emerged as a pivotal area of research, aiming to enhance the efficiency and reliability of information transmission through deep learning-based methods. Nevertheless, this paper challenges the conventional JSCC paradigm, and advocates for adoption of Separate Source Channel Coding (SSCC) to enjoy the underlying more degree of freedom for optimization. We demonstrate that SSCC, after leveraging the strengths of Large Language Model (LLM) for source coding and Error Correction Code Transformer (ECCT) complemented for channel decoding, offers superior performance over JSCC. Our proposed framework also effectively highlights the compatibility challenges between SemCom approaches and digital communication systems, particularly concerning the resource costs associated with the transmission of high precision floating point numbers. Through comprehensive evaluations, we establish that empowered by LLM-based compression and ECCT-enhanced error correction, SSCC remains a viable and effective solution for modern communication systems. In other words, separate source and channel coding is still what we need!","authors":["Tianqi Ren","Rongpeng Li","Ming-min Zhao","Xianfu Chen","Guangyi Liu","Yang Yang","Zhifeng Zhao","Honggang Zhang"],"url":"https://arxiv.org/abs/2501.04285"}
{"created":"2025-04-15","title":"MB-TaylorFormer V2: Improved Multi-branch Linear Transformer Expanded by Taylor Formula for Image Restoration","abstract":"Recently, Transformer networks have demonstrated outstanding performance in the field of image restoration due to the global receptive field and adaptability to input. However, the quadratic computational complexity of Softmax-attention poses a significant limitation on its extensive application in image restoration tasks, particularly for high-resolution images. To tackle this challenge, we propose a novel variant of the Transformer. This variant leverages the Taylor expansion to approximate the Softmax-attention and utilizes the concept of norm-preserving mapping to approximate the remainder of the first-order Taylor expansion, resulting in a linear computational complexity. Moreover, we introduce a multi-branch architecture featuring multi-scale patch embedding into the proposed Transformer, which has four distinct advantages: 1) various sizes of the receptive field; 2) multi-level semantic information; 3) flexible shapes of the receptive field; 4) accelerated training and inference speed. Hence, the proposed model, named the second version of Taylor formula expansion-based Transformer (for short MB-TaylorFormer V2) has the capability to concurrently process coarse-to-fine features, capture long-distance pixel interactions with limited computational cost, and improve the approximation of the Taylor expansion remainder. Experimental results across diverse image restoration benchmarks demonstrate that MB-TaylorFormer V2 achieves state-of-the-art performance in multiple image restoration tasks, such as image dehazing, deraining, desnowing, motion deblurring, and denoising, with very little computational overhead. The source code is available at https://github.com/FVL2020/MB-TaylorFormerV2.","authors":["Zhi Jin","Yuwei Qiu","Kaihao Zhang","Hongdong Li","Wenhan Luo"],"url":"https://arxiv.org/abs/2501.04486"}
{"created":"2025-04-15","title":"StarGen: A Spatiotemporal Autoregression Framework with Video Diffusion Model for Scalable and Controllable Scene Generation","abstract":"Recent advances in large reconstruction and generative models have significantly improved scene reconstruction and novel view generation. However, due to compute limitations, each inference with these large models is confined to a small area, making long-range consistent scene generation challenging. To address this, we propose StarGen, a novel framework that employs a pre-trained video diffusion model in an autoregressive manner for long-range scene generation. The generation of each video clip is conditioned on the 3D warping of spatially adjacent images and the temporally overlapping image from previously generated clips, improving spatiotemporal consistency in long-range scene generation with precise pose control. The spatiotemporal condition is compatible with various input conditions, facilitating diverse tasks, including sparse view interpolation, perpetual view generation, and layout-conditioned city generation. Quantitative and qualitative evaluations demonstrate StarGen's superior scalability, fidelity, and pose accuracy compared to state-of-the-art methods. Project page: https://zju3dv.github.io/StarGen.","authors":["Shangjin Zhai","Zhichao Ye","Jialin Liu","Weijian Xie","Jiaqi Hu","Zhen Peng","Hua Xue","Danpeng Chen","Xiaomeng Wang","Lei Yang","Nan Wang","Haomin Liu","Guofeng Zhang"],"url":"https://arxiv.org/abs/2501.05763"}
{"created":"2025-04-15","title":"BRIGHT: A globally distributed multimodal building damage assessment dataset with very-high-resolution for all-weather disaster response","abstract":"Disaster events occur around the world and cause significant damage to human life and property. Earth observation (EO) data enables rapid and comprehensive building damage assessment (BDA), an essential capability in the aftermath of a disaster to reduce human casualties and to inform disaster relief efforts. Recent research focuses on the development of AI models to achieve accurate mapping of unseen disaster events, mostly using optical EO data. However, solutions based on optical data are limited to clear skies and daylight hours, preventing a prompt response to disasters. Integrating multimodal (MM) EO data, particularly the combination of optical and SAR imagery, makes it possible to provide all-weather, day-and-night disaster responses. Despite this potential, the development of robust multimodal AI models has been constrained by the lack of suitable benchmark datasets. In this paper, we present a BDA dataset using veRy-hIGH-resoluTion optical and SAR imagery (BRIGHT) to support AI-based all-weather disaster response. To the best of our knowledge, BRIGHT is the first open-access, globally distributed, event-diverse MM dataset specifically curated to support AI-based disaster response. It covers five types of natural disasters and two types of man-made disasters across 14 regions worldwide, with a particular focus on developing countries where external assistance is most needed. The optical and SAR imagery in BRIGHT, with a spatial resolution between 0.3-1 meters, provides detailed representations of individual buildings, making it ideal for precise BDA. In our experiments, we have tested seven advanced AI models trained with our BRIGHT to validate the transferability and robustness. The dataset and code are available at https://github.com/ChenHongruixuan/BRIGHT. BRIGHT also serves as the official dataset for the 2025 IEEE GRSS Data Fusion Contest.","authors":["Hongruixuan Chen","Jian Song","Olivier Dietrich","Clifford Broni-Bediako","Weihao Xuan","Junjue Wang","Xinlei Shao","Yimin Wei","Junshi Xia","Cuiling Lan","Konrad Schindler","Naoto Yokoya"],"url":"https://arxiv.org/abs/2501.06019"}
{"created":"2025-04-15","title":"Towards Developing Socially Compliant Automated Vehicles: Advances, Expert Insights, and A Conceptual Framework","abstract":"Automated Vehicles (AVs) hold promise for revolutionizing transportation by improving road safety, traffic efficiency, and overall mobility. Despite the steady advancement in high-level AVs in recent years, the transition to full automation entails a period of mixed traffic, where AVs of varying automation levels coexist with human-driven vehicles (HDVs). Making AVs socially compliant and understood by human drivers is expected to improve the safety and efficiency of mixed traffic. Thus, ensuring AVs' compatibility with HDVs and social acceptance is crucial for their successful and seamless integration into mixed traffic. However, research in this critical area of developing Socially Compliant AVs (SCAVs) remains sparse. This study carries out the first comprehensive scoping review to assess the current state of the art in developing SCAVs, identifying key concepts, methodological approaches, and research gaps. An informal expert interview was also conducted to discuss the literature review results and identify critical research gaps and expectations towards SCAVs. Based on the scoping review and expert interview input, a conceptual framework is proposed for the development of SCAVs. The conceptual framework is evaluated using an online survey targeting researchers, technicians, policymakers, and other relevant professionals worldwide. The survey results provide valuable validation and insights, affirming the significance of the proposed conceptual framework in tackling the challenges of integrating AVs into mixed-traffic environments. Additionally, future research perspectives and suggestions are discussed, contributing to the research and development agenda of SCAVs.","authors":["Yongqi Dong","Bart van Arem","Haneen Farah"],"url":"https://arxiv.org/abs/2501.06089"}
{"created":"2025-04-15","title":"Towards a Probabilistic Framework for Analyzing and Improving LLM-Enabled Software","abstract":"Ensuring the reliability and verifiability of large language model (LLM)-enabled systems remains a significant challenge in software engineering. We propose a probabilistic framework for systematically analyzing and improving these systems by modeling and refining distributions over clusters of semantically equivalent outputs. This framework facilitates the evaluation and iterative improvement of Transference Models--key software components that utilize LLMs to transform inputs into outputs for downstream tasks. To illustrate its utility, we apply the framework to the autoformalization problem, where natural language documentation is transformed into formal program specifications. Our case illustrates how distribution-aware analysis enables the identification of weaknesses and guides focused alignment improvements, resulting in more reliable and interpretable outputs. This principled approach offers a foundation for addressing critical challenges in the development of robust LLM-enabled systems.","authors":["Juan Manuel Baldonado","Flavia Bonomo-Braberman","V\\'ictor Adri\\'an Braberman"],"url":"https://arxiv.org/abs/2501.06370"}
{"created":"2025-04-15","title":"Optimizing wheel loader performance -- an end-to-end approach","abstract":"Wheel loaders in mines and construction sites repeatedly load soil from a pile to load receivers. This task presents a challenging optimization problem since each loading's performance depends on the pile state, which depends on previous loadings. We investigate an end-to-end optimization approach considering future loading outcomes and transportation costs between the pile and load receivers. To predict the evolution of the pile state and the loading performance, we use world models that leverage deep neural networks trained on numerous simulated loading cycles. A look-ahead tree search optimizes the sequence of loading actions by evaluating the performance of thousands of action candidates, which expand into subsequent action candidates under the predicted pile states recursively. Test results demonstrate that, over a horizon of 15 sequential loadings, the look-ahead tree search is 6% more efficient than a greedy strategy, which always selects the action that maximizes the current single loading performance, and 14% more efficient than using a fixed loading controller optimized for the nominal case.","authors":["Koji Aoshima","Eddie Wadbro","Martin Servin"],"url":"https://arxiv.org/abs/2501.06583"}
{"created":"2025-04-15","title":"SplatMAP: Online Dense Monocular SLAM with 3D Gaussian Splatting","abstract":"Achieving high-fidelity 3D reconstruction from monocular video remains challenging due to the inherent limitations of traditional methods like Structure-from-Motion (SfM) and monocular SLAM in accurately capturing scene details. While differentiable rendering techniques such as Neural Radiance Fields (NeRF) address some of these challenges, their high computational costs make them unsuitable for real-time applications. Additionally, existing 3D Gaussian Splatting (3DGS) methods often focus on photometric consistency, neglecting geometric accuracy and failing to exploit SLAM's dynamic depth and pose updates for scene refinement. We propose a framework integrating dense SLAM with 3DGS for real-time, high-fidelity dense reconstruction. Our approach introduces SLAM-Informed Adaptive Densification, which dynamically updates and densifies the Gaussian model by leveraging dense point clouds from SLAM. Additionally, we incorporate Geometry-Guided Optimization, which combines edge-aware geometric constraints and photometric consistency to jointly optimize the appearance and geometry of the 3DGS scene representation, enabling detailed and accurate SLAM mapping reconstruction. Experiments on the Replica and TUM-RGBD datasets demonstrate the effectiveness of our approach, achieving state-of-the-art results among monocular systems. Specifically, our method achieves a PSNR of 36.864, SSIM of 0.985, and LPIPS of 0.040 on Replica, representing improvements of 10.7%, 6.4%, and 49.4%, respectively, over the previous SOTA. On TUM-RGBD, our method outperforms the closest baseline by 10.2%, 6.6%, and 34.7% in the same metrics. These results highlight the potential of our framework in bridging the gap between photometric and geometric dense 3D scene representations, paving the way for practical and efficient monocular dense reconstruction.","authors":["Yue Hu","Rong Liu","Meida Chen","Peter Beerel","Andrew Feng"],"url":"https://arxiv.org/abs/2501.07015"}
{"created":"2025-04-15","title":"Real-time Verification and Refinement of Language Model Text Generation","abstract":"Large language models (LLMs) have shown remarkable performance across a wide range of natural language tasks. However, a critical challenge remains in that they sometimes generate factually incorrect answers. To address this, while many previous work has focused on identifying errors in their generation and further refining them, they are slow in deployment since they are designed to verify the response from LLMs only after their entire generation (from the first to last tokens) is done. Further, we observe that once LLMs generate incorrect tokens early on, there is a higher likelihood that subsequent tokens will also be factually incorrect. To this end, in this work, we propose Streaming-VR (Streaming Verification and Refinement), a novel approach designed to enhance the efficiency of verification and refinement of LLM outputs. Specifically, the proposed Streaming-VR enables on-the-fly verification and correction of tokens as they are being generated, similar to a streaming process, ensuring that each subset of tokens is checked and refined in real-time by another LLM as the LLM constructs its response. Through comprehensive evaluations on multiple datasets, we demonstrate that our approach not only enhances the factual accuracy of LLMs, but also offers a more efficient solution compared to prior refinement methods.","authors":["Joonho Ko","Jinheon Baek","Sung Ju Hwang"],"url":"https://arxiv.org/abs/2501.07824"}
{"created":"2025-04-15","title":"Learnable Sparsification of Die-to-Die Communication via Spike-Based Encoding","abstract":"Efficient communication is central to both biological and artificial intelligence (AI) systems. In biological brains, the challenge of long-range communication across regions is addressed through sparse, spike-based signaling, minimizing energy and latency. Conversely, modern AI workloads are increasingly constrained by bandwidth, leading to bottlenecks that hamper scalability and efficiency. Inspired by the brain's ability to execute dynamic and complex local computations coupled with sparse inter-neuron communication, we propose heterogeneous neural networks that combine spiking neural networks (SNNs) and artificial neural networks (ANNs) at bandwidth-limited regions, such as chip boundaries, where spike-based communication reduces data transfer overhead. Within each chip, dense ANN computations maintain high throughput, accuracy, and robustness. While SNNs have struggled to algorithmically scale, our approach surmounts this long-standing challenge through algorithm-architecture co-design where learnable sparsity is employed for die-to-die communication by confining spiking layers to specific partitions. This composable design combines high ANN performance with low-bandwidth SNN efficiency. Evaluations on language processing and computer vision exhibit up to 5.3x energy efficiency gains and 15.2x latency reductions, surpassing both purely spiking and non-spiking models. As model size grows, improvements scale accordingly. By targeting the inter-chip communication bottleneck with biologically inspired methods, this approach presents a promising path to more efficient AI systems.","authors":["Joshua Nardone","Ruijie Zhu","Joseph Callenes","Mohammed E. Elbtity","Ramtin Zand","Jason Eshraghian"],"url":"https://arxiv.org/abs/2501.08645"}
{"created":"2025-04-15","title":"Are Open-Vocabulary Models Ready for Detection of MEP Elements on Construction Sites","abstract":"The construction industry has long explored robotics and computer vision, yet their deployment on construction sites remains very limited. These technologies have the potential to revolutionize traditional workflows by enhancing accuracy, efficiency, and safety in construction management. Ground robots equipped with advanced vision systems could automate tasks such as monitoring mechanical, electrical, and plumbing (MEP) systems. The present research evaluates the applicability of open-vocabulary vision-language models compared to fine-tuned, lightweight, closed-set object detectors for detecting MEP components using a mobile ground robotic platform. A dataset collected with cameras mounted on a ground robot was manually annotated and analyzed to compare model performance. The results demonstrate that, despite the versatility of vision-language models, fine-tuned lightweight models still largely outperform them in specialized environments and for domain-specific tasks.","authors":["Abdalwhab Abdalwhab","Ali Imran","Sina Heydarian","Ivanka Iordanova","David St-Onge"],"url":"https://arxiv.org/abs/2501.09267"}
{"created":"2025-04-15","title":"An RRAM compute-in-memory architecture for energy-efffcient binary matrix-vector multiplication processing","abstract":"Binary matrix-vector multiplication (BMVM) is a key operation in post-quantum cryptography schemes like the Classic McEliece cryptosystem. Conventional computing architectures incur signiffcant energy efffciency loss due to data movement of large matrices when handling such tasks. Non-volatile compute-in-memory (nvCIM) is an idealtechnology for energy-efffcient BMVM processing but faces challenges,including signal margin degradation in high input-parallelism arrays due to device non-idealities and high hardware overhead from current readout and XOR operations. This work presents a resistive memory (RRAM) nvCIM architecture featuring: 1) 1T1R cells with high-resistive-state compensation modules; and 2) pulsed current-sensing parity checkers. Based on the 180nm process and test results from RRAM devices, the computing accuracy and efffciency of the architecture are veriffed by simulation. The proposed architecture performs high-precision current accumulation with a maximum MAC value of 10 and achieves an energy efffciency of 1.51TOPS/W, offering approximately 1.62 times improvement compared to an advanced 28nm FPGA platform.","authors":["Hao Yue","Tianhang Liang","Yihao Chen","Xiangrui Li","Xin Kong","Zhelong Jiang","Zhigang Li","Gang Chen","Huaxiang Lu"],"url":"https://arxiv.org/abs/2501.10702"}
{"created":"2025-04-15","title":"UltraFusion: Ultra High Dynamic Imaging using Exposure Fusion","abstract":"Capturing high dynamic range (HDR) scenes is one of the most important issues in camera design. Majority of cameras use exposure fusion, which fuses images captured by different exposure levels, to increase dynamic range. However, this approach can only handle images with limited exposure difference, normally 3-4 stops. When applying to very high dynamic range scenes where a large exposure difference is required, this approach often fails due to incorrect alignment or inconsistent lighting between inputs, or tone mapping artifacts. In this work, we propose \\model, the first exposure fusion technique that can merge inputs with 9 stops differences. The key idea is that we model exposure fusion as a guided inpainting problem, where the under-exposed image is used as a guidance to fill the missing information of over-exposed highlights in the over-exposed region. Using an under-exposed image as a soft guidance, instead of a hard constraint, our model is robust to potential alignment issue or lighting variations. Moreover, by utilizing the image prior of the generative model, our model also generates natural tone mapping, even for very high-dynamic range scenes. Our approach outperforms HDR-Transformer on latest HDR benchmarks. Moreover, to test its performance in ultra high dynamic range scenes, we capture a new real-world exposure fusion benchmark, UltraFusion dataset, with exposure differences up to 9 stops, and experiments show that UltraFusion can generate beautiful and high-quality fusion results under various scenarios. Code and data will be available at https://openimaginglab.github.io/UltraFusion.","authors":["Zixuan Chen","Yujin Wang","Xin Cai","Zhiyuan You","Zheming Lu","Fan Zhang","Shi Guo","Tianfan Xue"],"url":"https://arxiv.org/abs/2501.11515"}
{"created":"2025-04-15","title":"Learning Dynamic Representations via An Optimally-Weighted Maximum Mean Discrepancy Optimization Framework for Continual Learning","abstract":"Continual learning has emerged as a pivotal area of research, primarily due to its advantageous characteristic that allows models to persistently acquire and retain information. However, catastrophic forgetting can severely impair model performance. In this study, we address network forgetting by introducing a novel framework termed Optimally-Weighted Maximum Mean Discrepancy (OWMMD), which imposes penalties on representation alterations via a Multi-Level Feature Matching Mechanism (MLFMM). Furthermore, we propose an Adaptive Regularization Optimization (ARO) strategy to refine the adaptive weight vectors, which autonomously assess the significance of each feature layer throughout the optimization process, The proposed ARO approach can relieve the over-regularization problem and promote the future task learning. We conduct a comprehensive series of experiments, benchmarking our proposed method against several established baselines. The empirical findings indicate that our approach achieves state-of-the-art performance.","authors":["KaiHui Huang","RunQing Wu","JinHui Shen","HanYi Zhang","Ling Ge","JiGuo Yu","Fei Ye"],"url":"https://arxiv.org/abs/2501.12121"}
{"created":"2025-04-15","title":"Multi-aspect Knowledge Distillation with Large Language Model","abstract":"Recent advancements in deep learning have significantly improved performance on computer vision tasks. Previous image classification methods primarily modify model architectures or add features, and they optimize models using cross-entropy loss on class logits. Since they focus on classifying images with considering class labels, these methods may struggle to learn various \\emph{aspects} of classes (e.g., natural positions and shape changes). Rethinking the previous approach from a novel view, we propose a multi-aspect knowledge distillation method using Multimodal Large Language Models (MLLMs). Our approach involves: 1) querying Large Language Model with multi-aspect questions relevant to the knowledge we want to transfer to the model, 2) extracting corresponding logits from MLLM, and 3) expanding the model's output dimensions to distill these multi-aspect logits. We then apply cross-entropy loss to class logits and binary cross-entropy loss to multi-aspect logits. Through our method, the model can learn not only the knowledge about visual aspects but also the abstract and complex aspects that require a deeper understanding. We primarily apply our method to image classification, and to explore the potential for extending our model, such as object detection. In all experimental results, our method improves the performance of the baselines. Additionally, we analyze the effect of multi-aspect knowledge distillation. These results demonstrate that our method can transfer knowledge about various aspects to the model and the aspect knowledge can enhance model performance in computer vision tasks.","authors":["Taegyeong Lee","Jinsik Bang","Soyeong Kwon","Taehwan Kim"],"url":"https://arxiv.org/abs/2501.13341"}
{"created":"2025-04-15","title":"Eye Gaze as a Signal for Conveying User Attention in Contextual AI Systems","abstract":"Advanced multimodal AI agents can now collaborate with users to solve challenges in the world. Yet, these emerging contextual AI systems rely on explicit communication channels between the user and system. We hypothesize that implicit communication of the user's interests and intent would reduce friction and improve user experience when collaborating with AI agents. In this work, we explore the potential of wearable eye tracking to convey signals about user attention. We measure the eye tracking signal quality requirements to effectively map gaze traces to physical objects, then conduct experiments that provide visual scanpath history as additional context when querying vision language models. Our results show that eye tracking provides high value as a user attention signal and can convey important context about the user's current task and interests, improving understanding of contextual AI agents.","authors":["Ethan Wilson","Naveen Sendhilnathan","Charlie S. Burlingham","Yusuf Mansour","Robert Cavin","Sai Deep Tetali","Ajoy Savio Fernandes","Michael J. Proulx"],"url":"https://arxiv.org/abs/2501.13878"}
{"created":"2025-04-15","title":"Wormhole Memory: A Rubik's Cube for Cross-Dialogue Retrieval","abstract":"In view of the gap in the current large language model in sharing memory across dialogues, this research proposes a wormhole memory module (WMM) to realize memory as a Rubik's cube that can be arbitrarily retrieved between different dialogues. Through simulation experiments, the researcher built an experimental framework based on the Python environment and used setting memory barriers to simulate the current situation where memories between LLMs dialogues are difficult to share. The CoQA development data set was imported into the experiment, and the feasibility of its cross-dialogue memory retrieval function was verified for WMM's nonlinear indexing and dynamic retrieval, and a comparative analysis was conducted with the capabilities of Titans and MemGPT memory modules. Experimental results show that WMM demonstrated the ability to retrieve memory across dialogues and the stability of quantitative indicators in eight experiments. It contributes new technical approaches to the optimization of memory management of LLMs and provides experience for the practical application in the future.","authors":["Libo Wang"],"url":"https://arxiv.org/abs/2501.14846"}
{"created":"2025-04-15","title":"PromptShield: Deployable Detection for Prompt Injection Attacks","abstract":"Application designers have moved to integrate large language models (LLMs) into their products. However, many LLM-integrated applications are vulnerable to prompt injections. While attempts have been made to address this problem by building prompt injection detectors, many are not yet suitable for practical deployment. To support research in this area, we introduce PromptShield, a benchmark for training and evaluating deployable prompt injection detectors. Our benchmark is carefully curated and includes both conversational and application-structured data. In addition, we use insights from our curation process to fine-tune a new prompt injection detector that achieves significantly higher performance in the low false positive rate (FPR) evaluation regime compared to prior schemes. Our work suggests that careful curation of training data and larger models can contribute to strong detector performance.","authors":["Dennis Jacob","Hend Alzahrani","Zhanhao Hu","Basel Alomair","David Wagner"],"url":"https://arxiv.org/abs/2501.15145"}
{"created":"2025-04-15","title":"Domain Adaptation from Generated Multi-Weather Images for Unsupervised Maritime Object Classification","abstract":"The classification and recognition of maritime objects are crucial for enhancing maritime safety, monitoring, and intelligent sea environment prediction. However, existing unsupervised methods for maritime object classification often struggle with the long-tail data distributions in both object categories and weather conditions. In this paper, we construct a dataset named AIMO produced by large-scale generative models with diverse weather conditions and balanced object categories, and collect a dataset named RMO with real-world images where long-tail issue exists. We propose a novel domain adaptation approach that leverages AIMO (source domain) to address the problem of limited labeled data, unbalanced distribution and domain shift in RMO (target domain), enhance the generalization of source features with the Vision-Language Models such as CLIP, and propose a difficulty score for curriculum learning to optimize training process. Experimental results shows that the proposed method significantly improves the classification accuracy, particularly for samples within rare object categories and weather conditions. Datasets and codes will be publicly available at https://github.com/honoria0204/AIMO.","authors":["Dan Song","Shumeng Huo","Wenhui Li","Lanjun Wang","Chao Xue","An-An Liu"],"url":"https://arxiv.org/abs/2501.15503"}
{"created":"2025-04-15","title":"Improving Tropical Cyclone Forecasting With Video Diffusion Models","abstract":"Tropical cyclone (TC) forecasting is crucial for disaster preparedness and mitigation. While recent deep learning approaches have shown promise, existing methods often treat TC evolution as a series of independent frame-to-frame predictions, limiting their ability to capture long-term dynamics. We present a novel application of video diffusion models for TC forecasting that explicitly models temporal dependencies through additional temporal layers. Our approach enables the model to generate multiple frames simultaneously, better capturing cyclone evolution patterns. We introduce a two-stage training strategy that significantly improves individual-frame quality and performance in low-data regimes. Experimental results show our method outperforms the previous approach of Nath et al. by 19.3% in MAE, 16.2% in PSNR, and 36.1% in SSIM. Most notably, we extend the reliable forecasting horizon from 36 to 50 hours. Through comprehensive evaluation using both traditional metrics and Fr\\'echet Video Distance (FVD), we demonstrate that our approach produces more temporally coherent forecasts while maintaining competitive single-frame quality. Code accessible at https://github.com/Ren-creater/forecast-video-diffmodels.","authors":["Zhibo Ren","Pritthijit Nath","Pancham Shukla"],"url":"https://arxiv.org/abs/2501.16003"}
{"created":"2025-04-15","title":"A Benchmarking Environment for Worker Flexibility in Flexible Job Shop Scheduling Problems","abstract":"In Production Scheduling, the Flexible Job Shop Scheduling Problem (FJSSP) aims to optimize a sequence of operations and assign each to an eligible machine with varying processing times. For integration of the workforce, each machine also requires a worker to be present to process an operation which additionally affects the processing times. The resulting problem is called Flexible Job Shop Scheduling Problem with Worker Flexibility (FJSSP-W). The FJSSP has been approached with various problem representations, including Mixed Integer Linear Programming (MILP), Constrained Programming (CP), and Simulation-based Optimization (SBO). In the latter area in particular, there exists a large number of specialized Evolutionary Algorithms (EA) like Particle Swarm Optimization (PSO) or Genetic Algorithms (GA). Yet, the solvers are often developed for single use cases only, and validated on a few selected test instances, let alone compared with results from solvers using other problem representations. While suitable approaches do also exist, the design of the FJSSP-W instances is not standardized and the algorithms are hardly comparable. This calls for a systematic benchmarking environment that provides a comprehensive set of FJSSP(-W) instances and supports targeted algorithm development. It will facilitate the comparison of algorithmic performance in the face of different problem characteristics. The present paper presents a collection of 402 commonly accepted FJSSP instances and proposes an approach to extend these with worker flexibility. In addition, we present a detailed procedure for the evaluation of scheduling algorithms on these problem sets and provide suitable model representations for this purpose. We provide complexity characteristics for all presented instances as well as baseline results of common commercial solvers to facilitate the validation of new algorithmic developments.","authors":["David Hutter","Thomas Steinberger","Michael Hellwig"],"url":"https://arxiv.org/abs/2501.16159"}
{"created":"2025-04-15","title":"Learning Free Token Reduction for Multi-Modal Large Language Models","abstract":"Vision-Language Models (VLMs) have achieved remarkable success across a range of multimodal tasks; however, their practical deployment is often constrained by high computational costs and prolonged inference times. Since the vision modality typically carries more information than the text modality, compressing visual prompts offers a promising solution to alleviate these challenges. Existing approaches predominantly focus on refining model architectures or directly reducing the number of visual tokens. However, these methods often compromise inference performance due to a lack of consideration for the unique spatial and temporal characteristics of visual data. In this work, we propose a token compression paradigm that operates on both spatial and temporal dimensions. Our approach includes a learning-free, plug-and-play compression pipeline that can be seamlessly integrated into most Multimodal Large Language Model (MLLM) frameworks. By leveraging this method, we enhance the model inference capability while simultaneously reducing its computational cost. Experimental results on the Video-QA task demonstrate the effectiveness of the proposed approach, showcasing significant improvements in efficiency without sacrificing performance.","authors":["Zihui Zhao","Yingxin Li","Yang Li"],"url":"https://arxiv.org/abs/2501.17391"}
{"created":"2025-04-15","title":"Solving Inverse Problems using Diffusion with Iterative Colored Renoising","abstract":"Imaging inverse problems can be solved in an unsupervised manner using pre-trained diffusion models, but doing so requires approximating the gradient of the measurement-conditional score function in the diffusion reverse process. We show that the approximations produced by existing methods are relatively poor, especially early in the reverse process, and so we propose a new approach that iteratively reestimates and \"renoises\" the estimate several times per diffusion step. This iterative approach, which we call Fast Iterative REnoising (FIRE), injects colored noise that is shaped to ensure that the pre-trained diffusion model always sees white noise, in accordance with how it was trained. We then embed FIRE into the DDIM reverse process and show that the resulting \"DDfire\" offers state-of-the-art accuracy and runtime on several linear inverse problems, as well as phase retrieval. Our implementation is at https://github.com/matt-bendel/DDfire","authors":["Matt C. Bendel","Saurav K. Shastri","Rizwan Ahmad","Philip Schniter"],"url":"https://arxiv.org/abs/2501.17468"}
{"created":"2025-04-15","title":"HOMER: Homography-Based Efficient Multi-view 3D Object Removal","abstract":"3D object removal is an important sub-task in 3D scene editing, with broad applications in scene understanding, augmented reality, and robotics. However, existing methods struggle to achieve a desirable balance among consistency, usability, and computational efficiency in multi-view settings. These limitations are primarily due to unintuitive user interaction in the source view, inefficient multi-view object mask generation, computationally expensive inpainting procedures, and a lack of applicability across different radiance field representations. To address these challenges, we propose a novel pipeline that improves the quality and efficiency of multi-view object mask generation and inpainting. Our method introduces an intuitive region-based interaction mechanism in the source view and eliminates the need for camera poses or extra model training. Our lightweight HoMM module is employed to achieve high-quality multi-view mask propagation with enhanced efficiency. In the inpainting stage, we further reduce computational costs by performing inpainting only on selected key views and propagating the results to other views via homography-based mapping. Our pipeline is compatible with a variety of radiance field frameworks, including NeRF and 3D Gaussian Splatting, demonstrating improved generalizability and practicality in real-world scenarios. Additionally, we present a new 3D multi-object removal dataset with greater object diversity and viewpoint variation than existing datasets. Experiments on public benchmarks and our proposed dataset show that our method achieves state-of-the-art performance while reducing runtime to one-fifth of that required by leading baselines.","authors":["Jingcheng Ni","Weiguang Zhao","Daniel Wang","Ziyao Zeng","Chenyu You","Alex Wong","Kaizhu Huang"],"url":"https://arxiv.org/abs/2501.17636"}
{"created":"2025-04-15","title":"Enhancing Offline Reinforcement Learning with Curriculum Learning-Based Trajectory Valuation","abstract":"The success of deep reinforcement learning (DRL) relies on the availability and quality of training data, often requiring extensive interactions with specific environments. In many real-world scenarios, where data collection is costly and risky, offline reinforcement learning (RL) offers a solution by utilizing data collected by domain experts and searching for a batch-constrained optimal policy. This approach is further augmented by incorporating external data sources, expanding the range and diversity of data collection possibilities. However, existing offline RL methods often struggle with challenges posed by non-matching data from these external sources. In this work, we specifically address the problem of source-target domain mismatch in scenarios involving mixed datasets, characterized by a predominance of source data generated from random or suboptimal policies and a limited amount of target data generated from higher-quality policies. To tackle this problem, we introduce Transition Scoring (TS), a novel method that assigns scores to transitions based on their similarity to the target domain, and propose Curriculum Learning-Based Trajectory Valuation (CLTV), which effectively leverages these transition scores to identify and prioritize high-quality trajectories through a curriculum learning approach. Our extensive experiments across various offline RL methods and MuJoCo environments, complemented by rigorous theoretical analysis, demonstrate that CLTV enhances the overall performance and transferability of policies learned by offline RL algorithms.","authors":["Amir Abolfazli","Zekun Song","Avishek Anand","Wolfgang Nejdl"],"url":"https://arxiv.org/abs/2502.00601"}
{"created":"2025-04-15","title":"ReFoRCE: A Text-to-SQL Agent with Self-Refinement, Format Restriction, and Column Exploration","abstract":"Text-to-SQL systems have unlocked easier access to critical data insights by enabling natural language queries over structured databases. However, deploying such systems in enterprise environments remains challenging due to factors such as large, complex schemas (> 3000 columns), diverse SQL dialects (e.g., BigQuery, Snowflake) and sophisticated query requirements (e.g., transformation, analytics). Current state-of-the-art performance on the Spider 2.0 dataset -- a benchmark built to mimic such complex environments -- remains limited at 20%. Key limitations include inadequate instruction-following, poor long-context comprehension, weak self-refinement, and insufficient dialect-specific knowledge. To address these gaps, we propose ReFoRCE (Self-Refinement Agent with Format Restriction and Column Exploration) which introduces (1) table compression to mitigate long-context limitations (2) format restriction to ensure accurate answer format, and (3) iterative column exploration for enhanced schema understanding. Additionally, it employs self-refinement pipeline consisting of (1) parallelized workflows with voting mechanisms and (2) a Common Table Expression (CTE) based refinement approach to handle unresolved cases. ReFoRCE achieves state-of-the-art results scoring 31.26 on the Spider 2.0-Snow and scoring 30.35 on the Spider 2.0-Lite tasks. Our code is available at https://github.com/hao-ai-lab/ReFoRCE.","authors":["Minghang Deng","Ashwin Ramachandran","Canwen Xu","Lanxiang Hu","Zhewei Yao","Anupam Datta","Hao Zhang"],"url":"https://arxiv.org/abs/2502.00675"}
{"created":"2025-04-15","title":"AgentBreeder: Mitigating the AI Safety Impact of Multi-Agent Scaffolds via Self-Improvement","abstract":"Scaffolding Large Language Models (LLMs) into multi-agent systems often improves performance on complex tasks, but the safety impact of such scaffolds has not been thoroughly explored. We introduce AgentBreeder, a framework for multi-objective self-improving evolutionary search over scaffolds. We evaluate discovered scaffolds on widely recognized reasoning, mathematics, and safety benchmarks and compare them with popular baselines. In 'blue' mode, we see a 79.4% average uplift in safety benchmark performance while maintaining or improving capability scores. In 'red' mode, we find adversarially weak scaffolds emerging concurrently with capability optimization. Our work demonstrates the risks of multi-agent scaffolding and provides a framework for mitigating them. Code is available at https://github.com/J-Rosser-UK/AgentBreeder.","authors":["J Rosser","Jakob Nicolaus Foerster"],"url":"https://arxiv.org/abs/2502.00757"}
{"created":"2025-04-15","title":"FedRIR: Rethinking Information Representation in Federated Learning","abstract":"Mobile and Web-of-Things (WoT) devices at the network edge generate vast amounts of data for machine learning applications, yet privacy concerns hinder centralized model training. Federated Learning (FL) allows clients (devices) to collaboratively train a shared model coordinated by a central server without transfer private data, but inherent statistical heterogeneity among clients presents challenges, often leading to a dilemma between clients' needs for personalized local models and the server's goal of building a generalized global model. Existing FL methods typically prioritize either global generalization or local personalization, resulting in a trade-off between these two objectives and limiting the full potential of diverse client data. To address this challenge, we propose a novel framework that simultaneously enhances global generalization and local personalization by Rethinking Information Representation in the Federated learning process (FedRIR). Specifically, we introduce Masked Client-Specific Learning (MCSL), which isolates and extracts fine-grained client-specific features tailored to each client's unique data characteristics, thereby enhancing personalization. Concurrently, the Information Distillation Module (IDM) refines the global shared features by filtering out redundant client-specific information, resulting in a purer and more robust global representation that enhances generalization. By integrating the refined global features with the isolated client-specific features, we construct enriched representations that effectively capture both global patterns and local nuances, thereby improving the performance of downstream tasks on the client. The code is available at https://github.com/Deep-Imaging-Group/FedRIR.","authors":["Yongqiang Huang","Zerui Shao","Ziyuan Yang","Zexin Lu","Yi Zhang"],"url":"https://arxiv.org/abs/2502.00859"}
{"created":"2025-04-15","title":"LoR-VP: Low-Rank Visual Prompting for Efficient Vision Model Adaptation","abstract":"Visual prompting has gained popularity as a method for adapting pre-trained models to specific tasks, particularly in the realm of parameter-efficient tuning. However, existing visual prompting techniques often pad the prompt parameters around the image, limiting the interaction between the visual prompts and the original image to a small set of patches while neglecting the inductive bias present in shared information across different patches. In this study, we conduct a thorough preliminary investigation to identify and address these limitations. We propose a novel visual prompt design, introducing Low-Rank matrix multiplication for Visual Prompting (LoR-VP), which enables shared and patch-specific information across rows and columns of image pixels. Extensive experiments across seven network architectures and four datasets demonstrate significant improvements in both performance and efficiency compared to state-of-the-art visual prompting methods, achieving up to 6 times faster training times, utilizing 18 times fewer visual prompt parameters, and delivering a 3.1% improvement in performance. The code is available as https://github.com/jincan333/LoR-VP.","authors":["Can Jin","Ying Li","Mingyu Zhao","Shiyu Zhao","Zhenting Wang","Xiaoxiao He","Ligong Han","Tong Che","Dimitris N. Metaxas"],"url":"https://arxiv.org/abs/2502.00896"}
{"created":"2025-04-15","title":"Towards Safer Chatbots: A Framework for Policy Compliance Evaluation of Custom GPTs","abstract":"Large Language Models (LLMs) have gained unprecedented prominence, achieving widespread adoption across diverse domains and integrating deeply into society. The capability to fine-tune general-purpose LLMs, such as Generative Pre-trained Transformers (GPT), for specific tasks has facilitated the emergence of numerous Custom GPTs. These tailored models are increasingly made available through dedicated marketplaces, such as OpenAI's GPT Store. However, their black-box nature introduces significant safety and compliance risks. In this work, we present a scalable framework for the automated evaluation of Custom GPTs against OpenAI's usage policies, which define the permissible behaviors of these systems. Our framework integrates three core components: (1) automated discovery and data collection of models from the GPT store, (2) a red-teaming prompt generator tailored to specific policy categories and the characteristics of each target GPT, and (3) an LLM-as-a-judge technique to analyze each prompt-response pair for potential policy violations. We validate our framework with a manually annotated ground truth, and evaluate it through a large-scale study with 782 Custom GPTs across three categories: Romantic, Cybersecurity, and Academic GPTs. Our manual annotation process achieved an F1 score of 0.975 in identifying policy violations, confirming the reliability of the framework's assessments. The results reveal that 58.7% of the analyzed models exhibit indications of non-compliance, exposing weaknesses in the GPT store's review and approval processes. Furthermore, our findings indicate that a model's popularity does not correlate with compliance, and non-compliance issues largely stem from behaviors inherited from base models rather than user-driven customizations. We believe this approach is extendable to other chatbot platforms and policy domains, improving LLM-based systems safety.","authors":["David Rodriguez","William Seymour","Jose M. Del Alamo","Jose Such"],"url":"https://arxiv.org/abs/2502.01436"}
{"created":"2025-04-15","title":"A User's Guide to Sampling Strategies for Sliced Optimal Transport","abstract":"This paper serves as a user's guide to sampling strategies for sliced optimal transport. We provide reminders and additional regularity results on the Sliced Wasserstein distance. We detail the construction methods, generation time complexity, theoretical guarantees, and conditions for each strategy. Additionally, we provide insights into their suitability for sliced optimal transport in theory. Extensive experiments on both simulated and real-world data offer a representative comparison of the strategies, culminating in practical recommendations for their best usage.","authors":["Keanu Sisouk","Julie Delon","Julien Tierny"],"url":"https://arxiv.org/abs/2502.02275"}
{"created":"2025-04-15","title":"Distributed Prescribed-Time Observer for Nonlinear Systems in Block-Triangular Form","abstract":"This paper proposes a distributed prescribed-time observer for nonlinear systems representable in a block-triangular observable canonical form. Using a weighted average of neighbor estimates exchanged over a strongly connected digraph, each observer estimates the system state despite the limited observability of local sensor measurements. The proposed design guarantees that distributed state estimation errors converge to zero at a user-specified convergence time, irrespective of observers' initial conditions. To achieve this prescribed-time convergence, distributed observers implement time-varying local output injection gains that monotonically increase and approach infinity at the prescribed time. The theoretical convergence is rigorously proven and validated through numerical simulations, where some implementation issues due to increasing gains have also been clarified.","authors":["Vincent de Heij","M. Umar B. Niazi","Karl H. Johansson","Saeed Ahmed"],"url":"https://arxiv.org/abs/2502.02669"}
{"created":"2025-04-15","title":"Space-bounded online Kolmogorov complexity is additive","abstract":"The even online Kolmogorov complexity of a string $x = x_1 x_2 \\cdots x_{n}$ is the minimal length of a program that for all $i\\le n/2$, on input $x_1x_3 \\cdots x_{2i-1}$ outputs $x_{2i}$. The odd complexity is defined similarly. The sum of the odd and even complexities is called the dialogue complexity.","authors":["Bruno Bauwens","Maria Marchenko"],"url":"https://arxiv.org/abs/2502.02777"}
{"created":"2025-04-15","title":"A Unified and General Humanoid Whole-Body Controller for Versatile Locomotion","abstract":"Locomotion is a fundamental skill for humanoid robots. However, most existing works make locomotion a single, tedious, unextendable, and unconstrained movement. This limits the kinematic capabilities of humanoid robots. In contrast, humans possess versatile athletic abilities-running, jumping, hopping, and finely adjusting gait parameters such as frequency and foot height. In this paper, we investigate solutions to bring such versatility into humanoid locomotion and thereby propose HugWBC: a unified and general humanoid whole-body controller for versatile locomotion. By designing a general command space in the aspect of tasks and behaviors, along with advanced techniques like symmetrical loss and intervention training for learning a whole-body humanoid controlling policy in simulation, HugWBC enables real-world humanoid robots to produce various natural gaits, including walking, jumping, standing, and hopping, with customizable parameters such as frequency, foot swing height, further combined with different body height, waist rotation, and body pitch. Beyond locomotion, HugWBC also supports real-time interventions from external upper-body controllers like teleoperation, enabling loco-manipulation with precision under any locomotive behavior. Extensive experiments validate the high tracking accuracy and robustness of HugWBC with/without upper-body intervention for all commands, and we further provide an in-depth analysis of how the various commands affect humanoid movement and offer insights into the relationships between these commands. To our knowledge, HugWBC is the first humanoid whole-body controller that supports such versatile locomotion behaviors with high robustness and flexibility.","authors":["Yufei Xue","Wentao Dong","Minghuan Liu","Weinan Zhang","Jiangmiao Pang"],"url":"https://arxiv.org/abs/2502.03206"}
{"created":"2025-04-15","title":"Energy-Efficient Flying LoRa Gateways: A Multi-Agent Reinforcement Learning Approach","abstract":"As next-generation Internet of Things (NG-IoT) networks continue to grow, the number of connected devices is rapidly increasing, along with their energy demands. This creates challenges for resource management and sustainability. Energy-efficient communication, particularly for power-limited IoT devices, is therefore a key research focus. In this paper, we deployed flying LoRa gateways mounted on unmanned aerial vehicles (UAVs) to collect data from LoRa end devices and transmit it to a central server. Our primary objective is to maximize the global system energy efficiency of wireless LoRa networks by joint optimization of transmission power, spreading factor, bandwidth, and user association. To solve this challenging problem, we model the problem as a partially observable Markov decision process (POMDP), where each flying LoRa GW acts as a learning agent using a cooperative multi-agent reinforcement learning (MARL). Simulation results demonstrate that our proposed method, based on the multi-agent proximal policy optimization (MAPPO) algorithm, significantly improves the global system EE and surpasses the conventional MARL schemes.","authors":["Abdullahi Isa Ahmed","Jamal Bentahar","El Mehdi Amhoud"],"url":"https://arxiv.org/abs/2502.03377"}
{"created":"2025-04-15","title":"UniForm: A Unified Multi-Task Diffusion Transformer for Audio-Video Generation","abstract":"With the rise of diffusion models, audio-video generation has been revolutionized. However, most existing methods rely on separate modules for each modality, with limited exploration of unified generative architectures. In addition, many are confined to a single task and small-scale datasets. To address these limitations, we first propose UniForm, a unified multi-task diffusion transformer that jointly generates audio and visual modalities in a shared latent space. A single diffusion process models both audio and video, capturing the inherent correlations between sound and vision. Second, we introduce task-specific noise schemes and task tokens, enabling a single model to support multiple tasks, including text-to-audio-video, audio-to-video, and video-to-audio generation. Furthermore, by leveraging large language models and a large-scale text-audio-video combined dataset, UniForm achieves greater generative diversity than prior approaches. Extensive experiments show that UniForm achieves the state-of-the-art performance across audio-video generation tasks, producing content that is both well-aligned and close to real-world data distributions. Our demos are available at https://uniform-t2av.github.io/.","authors":["Lei Zhao","Linfeng Feng","Dongxu Ge","Rujin Chen","Fangqiu Yi","Chi Zhang","Xiao-Lei Zhang","Xuelong Li"],"url":"https://arxiv.org/abs/2502.03897"}
{"created":"2025-04-15","title":"Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension","abstract":"Weak-to-strong (W2S) generalization is a type of finetuning (FT) where a strong (large) student model is trained on pseudo-labels generated by a weak teacher. Surprisingly, W2S FT often outperforms the weak teacher. We seek to understand this phenomenon through the observation that FT often occurs in intrinsically low-dimensional spaces. Leveraging the low intrinsic dimensionality of FT, we analyze W2S in the ridgeless regression setting from a variance reduction perspective. For a strong student - weak teacher pair with sufficiently expressive low-dimensional feature subspaces $\\mathcal{V}_s, \\mathcal{V}_w$, we provide an exact characterization of the variance that dominates the generalization error of W2S. This unveils a virtue of discrepancy between the strong and weak models in W2S: the variance of the weak teacher is inherited by the strong student in $\\mathcal{V}_s \\cap \\mathcal{V}_w$, while reduced by a factor of $\\dim(\\mathcal{V}_s)/N$ in the subspace of discrepancy $\\mathcal{V}_w \\setminus \\mathcal{V}_s$ with $N$ pseudo-labels for W2S. Further, our analysis casts light on the sample complexities and the scaling of performance gap recovery in W2S. The analysis is supported with experiments on synthetic regression and real vision and NLP tasks.","authors":["Yijun Dong","Yicheng Li","Yunai Li","Jason D. Lee","Qi Lei"],"url":"https://arxiv.org/abs/2502.05075"}
{"created":"2025-04-15","title":"Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities","abstract":"Evaluations of large language model (LLM) risks and capabilities are increasingly being incorporated into AI risk management and governance frameworks. Currently, most risk evaluations are conducted by designing inputs that elicit harmful behaviors from the system. However, this approach suffers from two limitations. First, input-output evaluations cannot evaluate realistic risks from open-weight models. Second, the behaviors identified during any particular input-output evaluation can only lower-bound the model's worst-possible-case input-output behavior. As a complementary method for eliciting harmful behaviors, we propose evaluating LLMs with model tampering attacks which allow for modifications to latent activations or weights. We pit state-of-the-art techniques for removing harmful LLM capabilities against a suite of 5 input-space and 6 model tampering attacks. In addition to benchmarking these methods against each other, we show that (1) model resilience to capability elicitation attacks lies on a low-dimensional robustness subspace; (2) the attack success rate of model tampering attacks can empirically predict and offer conservative estimates for the success of held-out input-space attacks; and (3) state-of-the-art unlearning methods can easily be undone within 16 steps of fine-tuning. Together these results highlight the difficulty of suppressing harmful LLM capabilities and show that model tampering attacks enable substantially more rigorous evaluations than input-space attacks alone.","authors":["Zora Che","Stephen Casper","Robert Kirk","Anirudh Satheesh","Stewart Slocum","Lev E McKinney","Rohit Gandikota","Aidan Ewart","Domenic Rosati","Zichu Wu","Zikui Cai","Bilal Chughtai","Yarin Gal","Furong Huang","Dylan Hadfield-Menell"],"url":"https://arxiv.org/abs/2502.05209"}
{"created":"2025-04-15","title":"SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation","abstract":"Graphs are able to model interconnected entities in many online services, supporting a wide range of applications on the Web. This raises an important question: How can we train a graph foundational model on multiple source domains and adapt to an unseen target domain? A major obstacle is that graphs from different domains often exhibit divergent characteristics. Some studies leverage large language models to align multiple domains based on textual descriptions associated with the graphs, limiting their applicability to text-attributed graphs. For text-free graphs, a few recent works attempt to align different feature distributions across domains, while generally neglecting structural differences. In this work, we propose a novel Structure Alignment framework for text-free Multi-domain Graph Pre-Training and cross-domain adaptation (SAMGPT). It is designed to learn multi-domain knowledge from graphs originating in multiple source domains, which can then be adapted to address applications in an unseen target domain. Specifically, we introduce a set of structure tokens to harmonize structure-based aggregation across source domains during the pre-training phase. Next, for cross-domain adaptation, we design dual prompts, namely, holistic prompts and specific prompts, which adapt unified multi-domain structural knowledge and fine-grained, domain-specific information, respectively, to a target domain. Finally, we conduct comprehensive experiments on seven public datasets to evaluate and analyze the effectiveness of SAMGPT.","authors":["Xingtong Yu","Zechuan Gong","Chang Zhou","Yuan Fang","Hui Zhang"],"url":"https://arxiv.org/abs/2502.05424"}
{"created":"2025-04-15","title":"ConRFT: A Reinforced Fine-tuning Method for VLA Models via Consistency Policy","abstract":"Vision-Language-Action (VLA) models have shown substantial potential in real-world robotic manipulation. However, fine-tuning these models through supervised learning struggles to achieve robust performance due to limited, inconsistent demonstrations, especially in contact-rich environments. In this paper, we propose a reinforced fine-tuning approach for VLA models, named ConRFT, which consists of offline and online fine-tuning with a unified consistency-based training objective, to address these challenges. In the offline stage, our method integrates behavior cloning and Q-learning to effectively extract policy from a small set of demonstrations and stabilize value estimating. In the online stage, the VLA model is further fine-tuned via consistency policy, with human interventions to ensure safe exploration and high sample efficiency. We evaluate our approach on eight diverse real-world manipulation tasks. It achieves an average success rate of 96.3% within 45-90 minutes of online fine-tuning, outperforming prior supervised methods with a 144% improvement in success rate and 1.9x shorter episode length. This work highlights the potential of integrating reinforcement learning to enhance the performance of VLA models for real-world robotic applications. Videos and code are available at our project website https://cccedric.github.io/conrft/.","authors":["Yuhui Chen","Shuai Tian","Shugao Liu","Yingting Zhou","Haoran Li","Dongbin Zhao"],"url":"https://arxiv.org/abs/2502.05450"}
{"created":"2025-04-15","title":"Machine learning-based hybrid dynamic modeling and economic predictive control of carbon capture process for ship decarbonization","abstract":"Implementing carbon capture technology on-board ships holds promise as a solution to facilitate the reduction of carbon intensity in international shipping, as mandated by the International Maritime Organization. In this work, we address the energy-efficient operation of shipboard carbon capture processes by proposing a hybrid modeling-based economic predictive control scheme. Specifically, we consider a comprehensive shipboard carbon capture process that encompasses the ship engine system and the shipboard post-combustion carbon capture plant. To accurately and robustly characterize the dynamic behaviors of this shipboard plant, we develop a hybrid dynamic process model that integrates available imperfect physical knowledge with neural networks trained using process operation data. An economic model predictive control approach is proposed based on the hybrid model to ensure carbon capture efficiency while minimizing energy consumption required for the carbon capture process operation. The cross-entropy method is employed to efficiently solve the complex non-convex optimization problem associated with the proposed hybrid model-based economic model predictive control method. Extensive simulations, analyses, and comparisons are conducted to verify the effectiveness and illustrate the superiority of the proposed framework.","authors":["Xuewen Zhang","Kuniadi Wandy Huang","Dat-Nguyen Vo","Minghao Han","Benjamin Decardi-Nelson","Xunyuan Yin"],"url":"https://arxiv.org/abs/2502.05833"}
{"created":"2025-04-15","title":"Motion Control in Multi-Rotor Aerial Robots Using Deep Reinforcement Learning","abstract":"This paper investigates the application of Deep Reinforcement (DRL) Learning to address motion control challenges in drones for additive manufacturing (AM). Drone-based additive manufacturing promises flexible and autonomous material deposition in large-scale or hazardous environments. However, achieving robust real-time control of a multi-rotor aerial robot under varying payloads and potential disturbances remains challenging. Traditional controllers like PID often require frequent parameter re-tuning, limiting their applicability in dynamic scenarios. We propose a DRL framework that learns adaptable control policies for multi-rotor drones performing waypoint navigation in AM tasks. We compare Deep Deterministic Policy Gradient (DDPG) and Twin Delayed Deep Deterministic Policy Gradient (TD3) within a curriculum learning scheme designed to handle increasing complexity. Our experiments show TD3 consistently balances training stability, accuracy, and success, particularly when mass variability is introduced. These findings provide a scalable path toward robust, autonomous drone control in additive manufacturing.","authors":["Gaurav Shetty","Mahya Ramezani","Hamed Habibi","Holger Voos","Jose Luis Sanchez-Lopez"],"url":"https://arxiv.org/abs/2502.05996"}
{"created":"2025-04-15","title":"Tracezip: Efficient Distributed Tracing via Trace Compression","abstract":"Distributed tracing serves as a fundamental building block in the monitoring and testing of cloud service systems. To reduce computational and storage overheads, the de facto practice is to capture fewer traces via sampling. However, existing work faces a trade-off between the completeness of tracing and system overhead. On one hand, head-based sampling indiscriminately selects requests to trace when they enter the system, which may miss critical events. On the other hand, tail-based sampling first captures all requests and then selectively persists the edge-case traces, which entails the overheads related to trace collection and ingestion. Taking a different path, we propose Tracezip in this paper to enhance the efficiency of distributed tracing via trace compression. Our key insight is that there exists significant redundancy among traces, which results in repetitive transmission of identical data between services and the backend. We design a new data structure named Span Retrieval Tree (SRT) that continuously encapsulates such redundancy at the service side and transforms trace spans into a lightweight form. At the backend, the complete traces can be seamlessly reconstructed by retrieving the common data that are already delivered by previous spans. Tracezip includes a series of strategies to optimize the structure of SRT and a differential update mechanism to efficiently synchronize SRT between services and the backend. Our evaluation on microservices benchmarks, popular cloud service systems, and production trace data demonstrates that Tracezip can achieve substantial performance gains in trace collection with negligible overhead. We have implemented Tracezip inside the OpenTelemetry Collector, making it compatible with existing tracing APIs.","authors":["Zhuangbin Chen","Junsong Pu","Zibin Zheng"],"url":"https://arxiv.org/abs/2502.06318"}
{"created":"2025-04-15","title":"Nearly Optimal Robust Covariance and Scatter Matrix Estimation Beyond Gaussians","abstract":"We study the problem of computationally efficient robust estimation of the covariance/scatter matrix of elliptical distributions -- that is, affine transformations of spherically symmetric distributions -- under the strong contamination model in the high-dimensional regime $d \\gtrsim 1/\\varepsilon^2$, where $d$ is the dimension and $\\varepsilon$ is the fraction of adversarial corruptions.","authors":["Gleb Novikov"],"url":"https://arxiv.org/abs/2502.06564"}
{"created":"2025-04-15","title":"Auto-Drafting Police Reports from Noisy ASR Outputs: A Trust-Centered LLM Approach","abstract":"Achieving a delicate balance between fostering trust in law enforcement and protecting the rights of both officers and civilians continues to emerge as a pressing research and product challenge in the world today. In the pursuit of fairness and transparency, this study presents an innovative AI-driven system designed to generate police report drafts from complex, noisy, and multi-role dialogue data. Our approach intelligently extracts key elements of law enforcement interactions and includes them in the draft, producing structured narratives that are not only high in quality but also reinforce accountability and procedural clarity. This framework holds the potential to transform the reporting process, ensuring greater oversight, consistency, and fairness in future policing practices. A demonstration video of our system can be accessed at https://drive.google.com/file/d/1kBrsGGR8e3B5xPSblrchRGj-Y-kpCHNO/view?usp=sharing","authors":["Param Kulkarni","Yingchi Liu","Hao-Ming Fu","Shaohua Yang","Isuru Gunasekara","Matt Peloquin","Noah Spitzer-Williams","Xiaotian Zhou","Xiaozhong Liu","Zhengping Ji","Yasser Ibrahim"],"url":"https://arxiv.org/abs/2502.07677"}
{"created":"2025-04-15","title":"Recurrent Memory for Online Interdomain Gaussian Processes","abstract":"We propose a novel online Gaussian process (GP) model that is capable of capturing long-term memory in sequential data in an online regression setting. Our model, Online HiPPO Sparse Variational Gaussian Process Regression (OHSGPR), leverages the HiPPO (High-order Polynomial Projection Operators) framework, which is popularized in the RNN domain due to its long-range memory modeling capabilities. We interpret the HiPPO time-varying orthogonal projections as inducing variables with time-dependent orthogonal polynomial basis functions, which allows the SGPR inducing points to memorize the process history. We show that the HiPPO framework fits naturally into the interdomain GP framework and demonstrate that the kernel matrices can also be updated online in a recurrence form based on the ODE evolution of HiPPO. We evaluate our method on time series regression tasks, showing that it outperforms the existing online GP method in terms of predictive performance and computational efficiency","authors":["Wenlong Chen","Naoki Kiyohara","Harrison Bo Hua Zhu","Yingzhen Li"],"url":"https://arxiv.org/abs/2502.08736"}
{"created":"2025-04-15","title":"A Framework to Develop and Validate RL-Based Obstacle-Aware UAV Positioning Algorithms","abstract":"Unmanned Aerial Vehicles (UAVs) are increasingly being utilized to enhance the Quality of Service (QoS) in wireless networks due to their flexibility and cost-effectiveness. However, optimizing UAV placement in dynamic and obstacleprone environments remains a research challenge. Reinforcement Learning (RL) has proven to be an effective approach that offers adaptability and robustness in such environments. This paper introduces RLpos-3, a novel framework that integrates standard RL techniques and existing libraries with Network Simulator 3 (ns-3) to facilitate the development and evaluation of UAV positioning algorithms. RLpos-3 serves as a supplementary tool for researchers, enabling the implementation, analysis, and benchmarking of UAV positioning strategies in different environmental settings while ensuring that user traffic demands are met. To validate its effectiveness, we present various use cases that demonstrate the performance of RLpos-3 in optimizing UAV placement under realistic conditions.","authors":["Kamran Shafafi","Manuel Ricardo","Rui Campos"],"url":"https://arxiv.org/abs/2502.08787"}
{"created":"2025-04-15","title":"Robust Learning of Multi-index Models via Iterative Subspace Approximation","abstract":"We study the task of learning Multi-Index Models (MIMs) with label noise under the Gaussian distribution. A $K$-MIM is any function $f$ that only depends on a $K$-dimensional subspace. We focus on well-behaved MIMs with finite ranges that satisfy certain regularity properties. Our main contribution is a general robust learner that is qualitatively optimal in the Statistical Query (SQ) model. Our algorithm iteratively constructs better approximations to the defining subspace by computing low-degree moments conditional on the projection to the subspace computed thus far, and adding directions with relatively large empirical moments. This procedure efficiently finds a subspace $V$ so that $f(\\mathbf{x})$ is close to a function of the projection of $\\mathbf{x}$ onto $V$. Conversely, for functions for which these conditional moments do not help, we prove an SQ lower bound suggesting that no efficient learner exists. As applications, we provide faster robust learners for the following concept classes:","authors":["Ilias Diakonikolas","Giannis Iakovidis","Daniel M. Kane","Nikos Zarifis"],"url":"https://arxiv.org/abs/2502.09525"}
{"created":"2025-04-15","title":"Text-Promptable Propagation for Referring Medical Image Sequence Segmentation","abstract":"Referring Medical Image Sequence Segmentation (Ref-MISS) is a novel and challenging task that aims to segment anatomical structures in medical image sequences (\\emph{e.g.} endoscopy, ultrasound, CT, and MRI) based on natural language descriptions. This task holds significant clinical potential and offers a user-friendly advancement in medical imaging interpretation. Existing 2D and 3D segmentation models struggle to explicitly track objects of interest across medical image sequences, and lack support for nteractive, text-driven guidance. To address these limitations, we propose Text-Promptable Propagation (TPP), a model designed for referring medical image sequence segmentation. TPP captures the intrinsic relationships among sequential images along with their associated textual descriptions. Specifically, it enables the recognition of referred objects through cross-modal referring interaction, and maintains continuous tracking across the sequence via Transformer-based triple propagation, using text embeddings as queries. To support this task, we curate a large-scale benchmark, Ref-MISS-Bench, which covers 4 imaging modalities and 20 different organs and lesions. Experimental results on this benchmark demonstrate that TPP consistently outperforms state-of-the-art methods in both medical segmentation and referring video object segmentation.","authors":["Runtian Yuan","Mohan Chen","Jilan Xu","Ling Zhou","Qingqiu Li","Yuejie Zhang","Rui Feng","Tao Zhang","Shang Gao"],"url":"https://arxiv.org/abs/2502.11093"}
{"created":"2025-04-15","title":"Artifact Validity in Design Science Research (DSR): A Comparative Analysis of Three Influential Frameworks","abstract":"Although the methodology of Design Science Research (DSR) is playing an increasingly important role with the emergence of the \"sciences of the artificial\", the validity of the resulting artifacts is occasionally questioned. This paper compares three influential DSR frameworks to assess their support for artifact validity. Using five essential validity types (instrument validity, technical validity, design validity, purpose validity and generalization), the qualitative analysis reveals that while purpose validity is explicitly emphasized, instrument and design validity remain the least developed. Their implicit treatment in all frameworks poses a risk of overlooked validation, and the absence of mandatory instrument validity can lead to invalid artifacts, threatening research credibility. Beyond these findings, the paper contributes (a) a comparative overview of each framework's strengths and weaknesses and (b) a revised DSR framework incorporating all five validity types with definitions and examples. This ensures systematic artifact evaluation and improvement, reinforcing the rigor of DSR.","authors":["Sylvana Kroop"],"url":"https://arxiv.org/abs/2502.11199"}
{"created":"2025-04-15","title":"Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarcity","abstract":"Existing LMs struggle with proof-oriented programming due to data scarcity, which manifest in two key ways: (1) a lack of sufficient corpora for proof-oriented programming languages such as F*, and (2) the absence of large-scale, project-level proof-oriented implementations that can teach the model the intricate reasoning process when performing proof-oriented programming. We present the first on synthetic data augmentation for project level proof oriented programming for both generation and repair. Our method addresses data scarcity by synthesizing basic proof-oriented programming problems for proficiency in that language; incorporating diverse coding data for reasoning capability elicitation and creating new proofs and repair data within existing repositories. This approach enables language models to both synthesize and repair proofs for function- and repository-level code. We show that our fine-tuned 14B parameter model, PoPilot, can exceed the performance of the models that outperforms GPT-4o in project-level proof-oriented programming by 64% relative margin, and can improve GPT-4o's performance by 54% by repairing its outputs over GPT-4o's self-repair.","authors":["Dylan Zhang","Justin Wang","Tianran Sun"],"url":"https://arxiv.org/abs/2502.11901"}
{"created":"2025-04-15","title":"CriteoPrivateAds: A Real-World Bidding Dataset to Design Private Advertising Systems","abstract":"In the past years, many proposals have emerged in order to address online advertising use-cases without access to third-party cookies. All these proposals leverage some privacy-enhancing technologies such as aggregation or differential privacy. Yet, no public and rich-enough ground truth is currently available to assess the relevancy of aforementioned private advertising frameworks. We are releasing the largest, in terms of number of features, bidding dataset specifically built in alignment with the design of major browser vendors proposals such as Chrome Privacy Sandbox. This dataset, coined CriteoPrivateAds, stands for an anonymised version of Criteo production logs and provides sufficient data to learn bidding models commonly used in online advertising under many privacy constraints (delayed reports, display and user-level differential privacy, user signal quantisation or aggregated reports). We ensured that this dataset, while being anonymised, is able to provide offline results close to production performance of adtech companies including Criteo - making it a relevant ground truth to design private advertising systems. The dataset is available in Hugging Face: https://huggingface.co/datasets/criteo/CriteoPrivateAd.","authors":["Mehdi Sebbar","Corentin Odic","Mathieu L\\'echine","Alo\\\"is Bissuel","Nicolas Chrysanthos","Anthony D'Amato","Alexandre Gilotte","Fabian H\\\"oring","Sarah Nogueira","Maxime Vono"],"url":"https://arxiv.org/abs/2502.12103"}
{"created":"2025-04-15","title":"A-MEM: Agentic Memory for LLM Agents","abstract":"While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code for evaluating performance is available at https://github.com/WujiangXu/AgenticMemory, while the source code of agentic memory system is available at https://github.com/agiresearch/A-mem.","authors":["Wujiang Xu","Zujie Liang","Kai Mei","Hang Gao","Juntao Tan","Yongfeng Zhang"],"url":"https://arxiv.org/abs/2502.12110"}
{"created":"2025-04-15","title":"Protecting Human Cognition in the Age of AI","abstract":"The rapid adoption of Generative AI (GenAI) is significantly reshaping human cognition, influencing how we engage with information, think, reason, and learn. This paper synthesizes existing literature on GenAI's effects on different aspects of human cognition. Drawing on Krathwohl's revised Bloom's Taxonomy and Dewey's conceptualization of reflective thought, we examine the mechanisms through which GenAI is affecting the development of different cognitive abilities. We focus on novices, such as students, who may lack both domain knowledge and an understanding of effective human-AI interaction. Accordingly, we provide implications for rethinking and designing educational experiences that foster critical thinking and deeper cognitive engagement.","authors":["Anjali Singh","Karan Taneja","Zhitong Guan","Avijit Ghosh"],"url":"https://arxiv.org/abs/2502.12447"}
{"created":"2025-04-15","title":"EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning","abstract":"Large Language Models (LLMs) have shown impressive reasoning capabilities in well-defined problems with clear solutions, such as mathematics and coding. However, they still struggle with complex real-world scenarios like business negotiations, which require strategic reasoning-an ability to navigate dynamic environments and align long-term goals amidst uncertainty. Existing methods for strategic reasoning face challenges in adaptability, scalability, and transferring strategies to new contexts. To address these issues, we propose explicit policy optimization (EPO) for strategic reasoning, featuring an LLM that provides strategies in open-ended action space and can be plugged into arbitrary LLM agents to motivate goal-directed behavior. To improve adaptability and policy transferability, we train the strategic reasoning model via multi-turn reinforcement learning (RL) using process rewards and iterative self-play, without supervised fine-tuning (SFT) as a preliminary step. Experiments across social and physical domains demonstrate EPO's ability of long-term goal alignment through enhanced strategic reasoning, achieving state-of-the-art performance on social dialogue and web navigation tasks. Our findings reveal various collaborative reasoning mechanisms emergent in EPO and its effectiveness in generating novel strategies, underscoring its potential for strategic reasoning in real-world applications.","authors":["Xiaoqian Liu","Ke Wang","Yongbin Li","Yuchuan Wu","Wentao Ma","Aobo Kong","Fei Huang","Jianbin Jiao","Junge Zhang"],"url":"https://arxiv.org/abs/2502.12486"}
{"created":"2025-04-15","title":"Stepwise Informativeness Search for Efficient and Effective LLM Reasoning","abstract":"Advances in Large Language Models (LLMs) have significantly improved multi-step reasoning through generating free-text rationales. However, recent studies show that LLMs tend to lose focus over the middle of long contexts. This raises concerns that as reasoning progresses, LLMs may overlook information in earlier steps when decoding subsequent steps, leading to generate unreliable and redundant rationales. To address this, we propose guiding LLMs to generate more accurate and concise step-by-step rationales by (1) proactively referencing information from underutilized prior steps, and (2) minimizing redundant information between new and existing steps. We introduce stepwise informativeness search, an inference-time tree search framework incorporating two selection heuristics: grounding-guided selection which prioritizes steps paying higher attention over underutilized steps; and novelty-guided selection which encourages steps with novel conclusions. During rationale generation, we use a self-grounding strategy that prompts LLMs to explicitly reference relevant prior steps to provide premises before deduction at each step. Experimental results on four reasoning datasets demonstrate that our approach improves reasoning accuracy by generating higher-quality rationales with reduced errors and redundancy.","authors":["Siyuan Wang","Enda Zhao","Zhongyu Wei","Xiang Ren"],"url":"https://arxiv.org/abs/2502.15335"}
{"created":"2025-04-15","title":"Generalizing the Invertible Matrix Theorem with Linear Relations using Graphical Linear Algebra","abstract":"Linear algebra's main concerns are sets of vectors, linear functions, subspaces, linear systems, matrices and concepts about those, such as whether the solution of linear system exists or is unique; a set of vectors is linearly independent or spans the whole space; a linear function has a right or a left inverse; a linear function is surjective or injective; and the kernel of a matrix is trivial or the its image is full.","authors":["Iago Leal de Freitas","J\\'ulia Mota","Jo\\~ao Paix\\~ao","Lucas Rufino"],"url":"https://arxiv.org/abs/2502.16783"}
{"created":"2025-04-15","title":"Stable-SPAM: How to Train in 4-Bit More Stably than 16-Bit Adam","abstract":"This paper comprehensively evaluates several recently proposed optimizers for 4-bit training, revealing that low-bit precision amplifies sensitivity to learning rates and often causes unstable gradient norms, leading to divergence at higher learning rates. Among these, SPAM, a recent optimizer featuring momentum reset and spike-aware gradient clipping, achieves the best performance across various bit levels, but struggles to stabilize gradient norms, requiring careful learning rate tuning. To address these limitations, we propose Stable-SPAM, which incorporates enhanced gradient normalization and clipping techniques. In particular, Stable-SPAM (1) adaptively updates the clipping threshold for spiked gradients by tracking their historical maxima; (2) normalizes the entire gradient matrix based on its historical $l_2$-norm statistics; and $(3)$ inherits momentum reset from SPAM to periodically reset the first and second moments of Adam, mitigating the accumulation of spiked gradients. Extensive experiments show that Stable-SPAM effectively stabilizes gradient norms in 4-bit LLM training, delivering superior performance compared to Adam and SPAM. Notably, our 4-bit LLaMA-1B model trained with Stable-SPAM outperforms the BF16 LLaMA-1B trained with Adam by up to $2$ perplexity. Furthermore, when both models are trained in 4-bit, Stable-SPAM achieves the same loss as Adam while requiring only about half the training steps. Code is available at https://github.com/TianjinYellow/StableSPAM.git.","authors":["Tianjin Huang","Haotian Hu","Zhenyu Zhang","Gaojie Jin","Xiang Li","Li Shen","Tianlong Chen","Lu Liu","Qingsong Wen","Zhangyang Wang","Shiwei Liu"],"url":"https://arxiv.org/abs/2502.17055"}
{"created":"2025-04-15","title":"IGDA: Interactive Graph Discovery through Large Language Model Agents","abstract":"Large language models ($\\textbf{LLMs}$) have emerged as a powerful method for discovery. Instead of utilizing numerical data, LLMs utilize associated variable $\\textit{semantic metadata}$ to predict variable relationships. Simultaneously, LLMs demonstrate impressive abilities to act as black-box optimizers when given an objective $f$ and sequence of trials. We study LLMs at the intersection of these two capabilities by applying LLMs to the task of $\\textit{interactive graph discovery}$: given a ground truth graph $G^*$ capturing variable relationships and a budget of $I$ edge experiments over $R$ rounds, minimize the distance between the predicted graph $\\hat{G}_R$ and $G^*$ at the end of the $R$-th round. To solve this task we propose $\\textbf{IGDA}$, a LLM-based pipeline incorporating two key components: 1) an LLM uncertainty-driven method for edge experiment selection 2) a local graph update strategy utilizing binary feedback from experiments to improve predictions for unselected neighboring edges. Experiments on eight different real-world graphs show our approach often outperforms all baselines including a state-of-the-art numerical method for interactive graph discovery. Further, we conduct a rigorous series of ablations dissecting the impact of each pipeline component. Finally, to assess the impact of memorization, we apply our interactive graph discovery strategy to a complex, new (as of July 2024) causal graph on protein transcription factors, finding strong performance in a setting where memorization is impossible. Overall, our results show IGDA to be a powerful method for graph discovery complementary to existing numerically driven approaches.","authors":["Alex Havrilla","David Alvarez-Melis","Nicolo Fusi"],"url":"https://arxiv.org/abs/2502.17189"}
{"created":"2025-04-15","title":"External Large Foundation Model: How to Efficiently Serve Trillions of Parameters for Online Ads Recommendation","abstract":"Ads recommendation is a prominent service of online advertising systems and has been actively studied. Recent studies indicate that scaling-up and advanced design of the recommendation model can bring significant performance improvement. However, with a larger model scale, such prior studies have a significantly increasing gap from industry as they often neglect two fundamental challenges in industrial-scale applications. First, training and inference budgets are restricted for the model to be served, exceeding which may incur latency and impair user experience. Second, large-volume data arrive in a streaming mode with data distributions dynamically shifting, as new users/ads join and existing users/ads leave the system. We propose the External Large Foundation Model (ExFM) framework to address the overlooked challenges. Specifically, we develop external distillation and a data augmentation system (DAS) to control the computational cost of training/inference while maintaining high performance. We design the teacher in a way like a foundation model (FM) that can serve multiple students as vertical models (VMs) to amortize its building cost. We propose Auxiliary Head and Student Adapter to mitigate the data distribution gap between FM and VMs caused by the streaming data issue. Comprehensive experiments on internal industrial-scale applications and public datasets demonstrate significant performance gain by ExFM.","authors":["Mingfu Liang","Xi Liu","Rong Jin","Boyang Liu","Qiuling Suo","Qinghai Zhou","Song Zhou","Laming Chen","Hua Zheng","Zhiyuan Li","Shali Jiang","Jiyan Yang","Xiaozhen Xia","Fan Yang","Yasmine Badr","Ellie Wen","Shuyu Xu","Hansey Chen","Zhengyu Zhang","Jade Nie","Chunzhi Yang","Zhichen Zeng","Weilin Zhang","Xingliang Huang","Qianru Li","Shiquan Wang","Evelyn Lyu","Wenjing Lu","Rui Zhang","Wenjun Wang","Jason Rudy","Mengyue Hang","Kai Wang","Yinbin Ma","Shuaiwen Wang","Sihan Zeng","Tongyi Tang","Xiaohan Wei","Longhao Jin","Jamey Zhang","Marcus Chen","Jiayi Zhang","Angie Huang","Chi Zhang","Zhengli Zhao","Jared Yang","Qiang Jin","Xian Chen","Amit Anand Amlesahwaram","Lexi Song","Liang Luo","Yuchen Hao","Nan Xiao","Yavuz Yetim","Luoshang Pan","Gaoxiang Liu","Yuxi Hu","Yuzhen Huang","Jackie Xu","Rich Zhu","Xin Zhang","Yiqun Liu","Hang Yin","Yuxin Chen","Buyun Zhang","Xiaoyi Liu","Xingyuan Wang","Wenguang Mao","Zhijing Li","Zhehui Zhou","Feifan Gu","Qin Huang","Chonglin Sun","Nancy Yu","Shuo Gu","Shupin Mao","Benjamin Au","Jingzheng Qin","Peggy Yao","Jae-Woo Choi","Bin Gao","Ernest Wang","Lei Zhang","Wen-Yen Chen","Ted Lee","Jay Zha","Yi Meng","Alex Gong","Edison Gao","Alireza Vahdatpour","Yiping Han","Yantao Yao","Toshinari Kureha","Shuo Chang","Musharaf Sultan","John Bocharov","Sagar Chordia","Xiaorui Gan","Peng Sun","Rocky Liu","Bo Long","Wenlin Chen","Santanu Kolay","Huayu Li"],"url":"https://arxiv.org/abs/2502.17494"}
{"created":"2025-04-15","title":"A Competitive Posted-Price Mechanism for Online Budget-Feasible Auctions","abstract":"We consider online procurement auctions, where the agents arrive sequentially, in random order, and have private costs for their services. The buyer aims to maximize a monotone submodular value function for the subset of agents whose services are procured, subject to a budget constraint on their payments. We consider a posted-price setting where upon each agent's arrival, the buyer decides on a payment offered to them. The agent accepts or rejects the offer, depending on whether the payment exceeds their cost, without revealing any other information about their private costs whatsoever. We present a randomized online posted-price mechanism with constant competitive ratio, thus resolving the main open question of (Badanidiyuru, Kleinberg and Singer, EC 2012). Posted-price mechanisms for online procurement typically operate by learning an estimation of the optimal value, denoted as OPT, and using it to determine the payments offered to the agents. The main challenge is to learn OPT within a constant factor from the agents' accept / reject responses to the payments offered. Our approach is based on an online test of whether our estimation is too low compared against OPT and a carefully designed adaptive search that gradually refines our estimation.","authors":["Andreas Charalampopoulos","Dimitris Fotakis","Panagiotis Patsilinakos","Thanos Tolias"],"url":"https://arxiv.org/abs/2502.18265"}
{"created":"2025-04-15","title":"Interacting with Thoughtful AI","abstract":"We envision the concept of Thoughtful AI, a new human-AI interaction paradigm in which the AI behaves as a continuously thinking entity. Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction. In this position paper, we argue that this thoughtfulness unlocks new possibilities for human-AI interaction by enabling proactive AI behavior, facilitating continuous cognitive alignment with users, and fostering more dynamic interaction experiences. We outline the conceptual foundations of Thoughtful AI, illustrate its potential through example projects, and envision how this paradigm can transform human-AI interaction in the future.","authors":["Xingyu Bruce Liu","Haijun Xia","Xiang Anthony Chen"],"url":"https://arxiv.org/abs/2502.18676"}
{"created":"2025-04-15","title":"Sparse Spectrahedral Shadows for State Estimation and Reachability Analysis: Set Operations, Validations and Order Reductions","abstract":"Set representations are the foundation of various set-based approaches in state estimation, reachability analysis and fault diagnosis. In this paper, we investigate spectrahedral shadows, a class of nonlinear geometric objects previously studied in semidefinite programming and real algebraic geometry. We demonstrate spectrahedral shadows generalize traditional and emerging set representations like ellipsoids, zonotopes, constrained zonotopes and ellipsotopes. Analytical forms of set operations are provided including linear map, linear inverse map, Minkowski sum, intersection, Cartesian product, Minkowski-Firey Lp sum, convex hull, conic hull and polytopic map, all of which are implemented without approximation in polynomial time. In addition, we develop set validation and order reduction techniques for spectrahedral shadows, thereby establishing spectrahedral shadows as a set representation applicable to a range of set-based tasks.","authors":["Chengrui Wang","Haohao Qiu","Sibo Yao","James Lam"],"url":"https://arxiv.org/abs/2502.18941"}
{"created":"2025-04-15","title":"Vector-Quantized Vision Foundation Models for Object-Centric Learning","abstract":"Perceiving visual scenes as objects and background -- like humans do -- Object-Centric Learning (OCL) aggregates image or video feature maps into object-level feature vectors, termed \\textit{slots}. OCL's self-supervision of reconstructing the input from these aggregated slots struggles with complex object textures, thus Vision Foundation Model (VFM) representations are used as the aggregation input and reconstruction target. However, existing methods leverage VFM representations in diverse ways and often fail to fully exploit their potential. In response, we propose a clean architecture -- Vector-Quantized VFMs for OCL (VQ-VFM-OCL, or VVO) -- that unifies mainstream OCL methods. The key to our unification is simple yet effective, just shared quantizing the same VFM representation as the reconstruction target. Through mathematical modeling and statistical verification, we further analyze why VFM representations facilitate OCL aggregation and how their shared quantization as reconstruction targets strengthens OCL supervision. Experiments show that across different VFMs, aggregators and decoders, our VVO consistently outperforms baselines in object discovery and recognition, as well as downstream visual prediction and reasoning. The source code is available in supplemental files.","authors":["Rongzhen Zhao","Vivienne Wang","Juho Kannala","Joni Pajarinen"],"url":"https://arxiv.org/abs/2502.20263"}
{"created":"2025-04-15","title":"DeepRetrieval: Hacking Real Search Engines and Retrievers with Large Language Models via Reinforcement Learning","abstract":"Information retrieval systems are crucial for enabling effective access to large document collections. Recent approaches have leveraged Large Language Models (LLMs) to enhance retrieval performance through query augmentation, but often rely on expensive supervised learning or distillation techniques that require significant computational resources and hand-labeled data. We introduce DeepRetrieval, a reinforcement learning (RL) approach that trains LLMs for query generation through trial and error without supervised data (reference query). Using retrieval metrics as rewards, our system generates queries that maximize retrieval performance. DeepRetrieval outperforms leading methods on literature search with 65.07% (vs. previous SOTA 24.68%) recall for publication search and 63.18% (vs. previous SOTA 32.11%) recall for trial search using real-world search engines. DeepRetrieval also dominates in evidence-seeking retrieval, classic information retrieval and SQL database search. With only 3B parameters, it outperforms industry-leading models like GPT-4o and Claude-3.5-Sonnet on 11/13 datasets. These results demonstrate that our RL approach offers a more efficient and effective paradigm for information retrieval. Our data and code are available at: https://github.com/pat-jj/DeepRetrieval.","authors":["Pengcheng Jiang","Jiacheng Lin","Lang Cao","Runchu Tian","SeongKu Kang","Zifeng Wang","Jimeng Sun","Jiawei Han"],"url":"https://arxiv.org/abs/2503.00223"}
{"created":"2025-04-15","title":"Towards Fairness for the Right Reasons: Using Saliency Maps to Evaluate Bias Removal in Neural Networks","abstract":"The widespread adoption of machine learning systems has raised critical concerns about fairness and bias, making mitigating harmful biases essential for AI development. In this paper, we investigate the relationship between fairness improvement and the removal of harmful biases in neural networks applied to computer vision tasks. First, we introduce a set of novel XAI-based metrics that analyze saliency maps to assess shifts in a model's decision-making process. Then, we demonstrate that successful debiasing methods systematically redirect model focus away from protected attributes. Additionally, we show that techniques originally developed for artifact removal can be effectively repurposed for fairness. These findings underscore the importance of ensuring that models are fair for the right reasons, contributing to the development of more ethical and trustworthy AI systems.","authors":["Lukasz Sztukiewicz","Ignacy St\\k{e}pka","Micha{\\l} Wili\\'nski","Jerzy Stefanowski"],"url":"https://arxiv.org/abs/2503.00234"}
{"created":"2025-04-15","title":"Extremely low-bitrate Image Compression Semantically Disentangled by LMMs from a Human Perception Perspective","abstract":"It remains a significant challenge to compress images at extremely low bitrate while achieving both semantic consistency and high perceptual quality. Inspired by human progressive perception mechanism, we propose a Semantically Disentangled Image Compression framework (SEDIC) in this paper. Initially, an extremely compressed reference image is obtained through a learned image encoder. Then we leverage LMMs to extract essential semantic components, including overall descriptions, object detailed description, and semantic segmentation masks. We propose a training-free Object Restoration model with Attention Guidance (ORAG) built on pre-trained ControlNet to restore object details conditioned by object-level text descriptions and semantic masks. Based on the proposed ORAG, we design a multistage semantic image decoder to progressively restore the details object by object, starting from the extremely compressed reference image, ultimately generating high-quality and high-fidelity reconstructions. Experimental results demonstrate that SEDIC significantly outperforms state-of-the-art approaches, achieving superior perceptual quality and semantic consistency at extremely low-bitrates ($\\le$ 0.05 bpp).","authors":["Juan Song","Lijie Yang","Mingtao Feng"],"url":"https://arxiv.org/abs/2503.00399"}
{"created":"2025-04-15","title":"Evaluating Personalized Tool-Augmented LLMs from the Perspectives of Personalization and Proactivity","abstract":"Personalized tool utilization is essential for aligning large language models (LLMs) with user preference in interaction scenarios with various tools. However, most of the current benchmarks primarily focus on either personalization of text generation or direct tool-utilizing, without considering both. In this work, we introduce a novel benchmark ETAPP for evaluating personalized tool invocation, establishing a sandbox environment, and a comprehensive dataset of 800 testing cases covering diverse user profiles. To improve the accuracy of our evaluation, we propose a key-point-based LLM evaluation method, mitigating biases in the LLM-as-a-judge system by manually annotating key points for each test case and providing them to LLM as the reference. Additionally, we evaluate the excellent LLMs and provide an in-depth analysis. Furthermore, we investigate the impact of different tool-invoking strategies on LLMs' personalization performance and the effects of fine-tuning in our task. The effectiveness of our preference-setting and key-point-based evaluation method is also validated. Our findings offer insights into improving personalized LLM agents. Our Code is available at https://github.com/hypasd-art/ETAPP.","authors":["Yupu Hao","Pengfei Cao","Zhuoran Jin","Huanxuan Liao","Yubo Chen","Kang Liu","Jun Zhao"],"url":"https://arxiv.org/abs/2503.00771"}
{"created":"2025-04-15","title":"Machine Learning for Health symposium 2024 -- Findings track","abstract":"A collection of the accepted Findings papers that were presented at the 4th Machine Learning for Health symposium (ML4H 2024), which was held on December 15-16, 2024, in Vancouver, BC, Canada. ML4H 2024 invited high-quality submissions describing innovative research in a variety of health-related disciplines including healthcare, biomedicine, and public health. Works could be submitted to either the archival Proceedings track, or the non-archival Findings track. The Proceedings track targeted mature, cohesive works with technical sophistication and high-impact relevance to health. The Findings track promoted works that would spark new insights, collaborations, and discussions at ML4H. Both tracks were given the opportunity to share their work through the in-person poster session. All the manuscripts submitted to ML4H Symposium underwent a double-blind peer-review process.","authors":["Stefan Hegselmann","Helen Zhou","Elizabeth Healey","Trenton Chang","Caleb Ellington","Vishwali Mhasawade","Sana Tonekaboni","Peniel Argaw","Haoran Zhang"],"url":"https://arxiv.org/abs/2503.00984"}
{"created":"2025-04-15","title":"A novel multipoint stress control volume method for linear elasticity on quadrilateral grids","abstract":"In this paper, we develop a novel control volume method that is locally conservative and locking-free for linear elasticity problem on quadrilateral grids. The symmetry of stress is weakly imposed through the introduction of a Lagrange multiplier. As such, the method involves three unknowns: stress, displacement and rotation. To ensure the well-posedness of the scheme, a pair of carefully defined finite element spaces is used for the stress, displacement and rotation such that the inf-sup condition holds. An appealing feature of the method is that piecewise constant functions are used for the approximations of stress, displacement and rotation, which greatly simplifies the implementation. In particular, the stress space is defined delicately such that the stress bilinear form is localized around each vertex, which allows for the local elimination of the stress, resulting in a cell-centered system. By choosing different definitions of the space for rotation, we develop two variants of the method. In particular, the first method uses a constant function for rotation over the interaction region, which allows for further elimination and results in a cell-centered system involving displacement only. A rigorous error analysis is performed for the proposed scheme. We show the optimal convergence for $L^2$-error of the stress and rotation. Moreover, we can also prove the superconvergence for $L^2$-error of displacement. Extensive numerical simulations indicate that our method is efficient and accurate, and can handle problems with discontinuous coefficients.","authors":["Shubin Fu","Lina Zhao"],"url":"https://arxiv.org/abs/2503.01426"}
{"created":"2025-04-15","title":"AppAgentX: Evolving GUI Agents as Proficient Smartphone Users","abstract":"Recent advancements in Large Language Models (LLMs) have led to the development of intelligent LLM-based agents capable of interacting with graphical user interfaces (GUIs). These agents demonstrate strong reasoning and adaptability, enabling them to perform complex tasks that traditionally required predefined rules. However, the reliance on step-by-step reasoning in LLM-based agents often results in inefficiencies, particularly for routine tasks. In contrast, traditional rule-based systems excel in efficiency but lack the intelligence and flexibility to adapt to novel scenarios. To address this challenge, we propose a novel evolutionary framework for GUI agents that enhances operational efficiency while retaining intelligence and flexibility. Our approach incorporates a memory mechanism that records the agent's task execution history. By analyzing this history, the agent identifies repetitive action sequences and evolves high-level actions that act as shortcuts, replacing these low-level operations and improving efficiency. This allows the agent to focus on tasks requiring more complex reasoning, while simplifying routine actions. Experimental results on multiple benchmark tasks demonstrate that our approach significantly outperforms existing methods in both efficiency and accuracy. The code will be open-sourced to support further research.","authors":["Wenjia Jiang","Yangyang Zhuang","Chenxi Song","Xu Yang","Joey Tianyi Zhou","Chi Zhang"],"url":"https://arxiv.org/abs/2503.02268"}
{"created":"2025-04-15","title":"Velocity-free task-space regulator for robot manipulators with external disturbances","abstract":"This paper addresses the problem of task-space robust regulation of robot manipulators subject to external disturbances. A velocity-free control law is proposed by combining the internal model principle and the passivity-based output-feedback control approach. The resulting controller not only ensures asymptotic convergence of the regulation error but also rejects unwanted external sinusoidal disturbances. The potential of the proposed method lies in its simplicity, intuitiveness, and straightforward gain selection criteria for the synthesis of multi-joint robot manipulator control systems.","authors":["Haiwen Wu","Bayu Jayawardhana","Dabo Xu"],"url":"https://arxiv.org/abs/2503.02634"}
{"created":"2025-04-15","title":"Objestures: Everyday Objects Meet Mid-Air Gestures for Expressive Interaction","abstract":"Everyday objects and mid-air gestures have been explored as input modalities, but each has its strengths and limitations - for example, objects offer tangibility but rely on their physical presence; gestures are convenient but lack haptic feedback. We introduce Objestures (\"Obj\" + \"Gestures\"), five interaction types that utilize both modalities for a design space of expressive and playful interaction. To evaluate its usefulness, we conducted a user study (N = 12) assessing whether it can effectively support basic 3D tasks such as rotation and scaling and found it has performance comparable to or better than the headset's native freehand manipulation. To understand its user experience, we conducted case studies on three example applications - Sound, Draw, and Shadow - with the same participants, who found it intuitive, engaging, and expressive, and were interested in its everyday use. We further illustrate 30 examples to showcase how Objestures can enrich everyday interactions and discuss its limitations and implications. https://www.zhuoyuelyu.com/objestures","authors":["Zhuoyue Lyu","Per Ola Kristensson"],"url":"https://arxiv.org/abs/2503.02973"}
{"created":"2025-04-15","title":"Opinion: Revisiting synthetic data classifications from a privacy perspective","abstract":"Synthetic data is emerging as a cost-effective solution necessary to meet the increasing data demands of AI development, created either from existing knowledge or derived from real data. The traditional classification of synthetic data types into hybrid, partial or fully synthetic datasets has limited value and does not reflect the ever-increasing methods to generate synthetic data. The generation method and their source jointly shape the characteristics of synthetic data, which in turn determines its practical applications. We make a case for an alternative approach to grouping synthetic data types that better reflect privacy perspectives in order to facilitate regulatory guidance in the generation and processing of synthetic data. This approach to classification provides flexibility to new advancements like deep generative methods and offers a more practical framework for future applications.","authors":["Vibeke Binz Vallevik","Serena Elizabeth Marshall","Aleksandar Babic","Jan Franz Nygaard"],"url":"https://arxiv.org/abs/2503.03506"}
{"created":"2025-04-15","title":"GeoDEN: A Visual Exploration Tool for Analysing the Geographic Spread of Dengue Serotypes","abstract":"Static maps and animations remain popular in spatial epidemiology of dengue, limiting the analytical depth and scope of visualisations. Over half of the global population live in dengue endemic regions. Understanding the spatiotemporal dynamics of the four closely related dengue serotypes, and their immunological interactions, remains a challenge at a global scale. To facilitate this understanding, we worked with dengue epidemiologists in a user-centered design framework to create GeoDEN, an exploratory visualisation tool that empowers experts to investigate spatiotemporal patterns in dengue serotype reports. The tool has several linked visualisations and filtering mechanisms, enabling analysis at a range of spatial and temporal scales. To identify successes and failures, we present both insight-based and value-driven evaluations. Our domain experts found GeoDEN valuable, verifying existing hypotheses and uncovering novel insights that warrant further investigation by the epidemiology community. The developed visual exploration approach can be adapted for exploring other epidemiology and disease incident datasets.","authors":["Aidan Marler","Yannik Roell","Steffen Knoblauch","Jane P. Messina","Thomas Jaenisch","Morteza Karimzadeh"],"url":"https://arxiv.org/abs/2503.03953"}
{"created":"2025-04-15","title":"LLMs Can Generate a Better Answer by Aggregating Their Own Responses","abstract":"Large Language Models (LLMs) have shown remarkable capabilities across tasks, yet they often require additional prompting techniques when facing complex problems. While approaches like self-correction and response selection have emerged as popular solutions, recent studies have shown these methods perform poorly when relying on the LLM itself to provide feedback or selection criteria. We argue this limitation stems from the fact that common LLM post-training procedures lack explicit supervision for discriminative judgment tasks. In this paper, we propose Generative Self-Aggregation (GSA), a novel prompting method that improves answer quality without requiring the model's discriminative capabilities. GSA first samples multiple diverse responses from the LLM, then aggregates them to obtain an improved solution. Unlike previous approaches, our method does not require the LLM to correct errors or compare response quality; instead, it leverages the model's generative abilities to synthesize a new response based on the context of multiple samples. While GSA shares similarities with the self-consistency (SC) approach for response aggregation, SC requires specific verifiable tokens to enable majority voting. In contrast, our approach is more general and can be applied to open-ended tasks. Empirical evaluation demonstrates that GSA effectively improves response quality across various tasks, including mathematical reasoning, knowledge-based problems, and open-ended generation tasks such as code synthesis and conversational responses.","authors":["Zichong Li","Xinyu Feng","Yuheng Cai","Zixuan Zhang","Tianyi Liu","Chen Liang","Weizhu Chen","Haoyu Wang","Tuo Zhao"],"url":"https://arxiv.org/abs/2503.04104"}
{"created":"2025-04-15","title":"EDCA - An Evolutionary Data-Centric AutoML Framework for Efficient Pipelines","abstract":"Automated Machine Learning (AutoML) gained popularity due to the increased demand for Machine Learning (ML) specialists, allowing them to apply ML techniques effortlessly and quickly. AutoML implementations use optimisation methods to identify the most effective ML solution for a given dataset, aiming to improve one or more predefined metrics. However, most implementations focus on model selection and hyperparameter tuning. Despite being an important factor in obtaining high-performance ML systems, data quality is usually an overlooked part of AutoML and continues to be a manual and time-consuming task. This work presents EDCA, an Evolutionary Data Centric AutoML framework. In addition to the traditional tasks such as selecting the best models and hyperparameters, EDCA enhances the given data by optimising data processing tasks such as data reduction and cleaning according to the problems' needs. All these steps create an ML pipeline that is optimised by an evolutionary algorithm. To assess its effectiveness, EDCA was compared to FLAML and TPOT, two frameworks at the top of the AutoML benchmarks. The frameworks were evaluated in the same conditions using datasets from AMLB classification benchmarks. EDCA achieved statistically similar results in performance to FLAML and TPOT but used significantly less data to train the final solutions. Moreover, EDCA experimental results reveal that a good performance can be achieved using less data and efficient ML algorithm aspects that align with Green AutoML guidelines","authors":["Joana Sim\\~oes","Jo\\~ao Correia"],"url":"https://arxiv.org/abs/2503.04350"}
{"created":"2025-04-15","title":"Iris Style Transfer: Enhancing Iris Recognition with Style Features and Privacy Preservation through Neural Style Transfer","abstract":"Iris texture is widely regarded as a gold standard biometric modality for authentication and identification. The demand for robust iris recognition methods, coupled with growing security and privacy concerns regarding iris attacks, has escalated recently. Inspired by neural style transfer, an advanced technique that leverages neural networks to separate content and style features, we hypothesize that iris texture's style features provide a reliable foundation for recognition and are more resilient to variations like rotation and perspective shifts than traditional approaches. Our experimental results support this hypothesis, showing a significantly higher classification accuracy compared to conventional features. Further, we propose using neural style transfer to obfuscate the identifiable iris style features, ensuring the protection of sensitive biometric information while maintaining the utility of eye images for tasks like eye segmentation and gaze estimation. This work opens new avenues for iris-oriented, secure, and privacy-aware biometric systems.","authors":["Mengdi Wang","Efe Bozkir","Enkelejda Kasneci"],"url":"https://arxiv.org/abs/2503.04707"}
{"created":"2025-04-15","title":"Narrative Context Protocol: an Author-centric Storytelling Framework for Generative AI","abstract":"Generative AI promises to finally realize dynamic, personalized storytelling technologies across a range of media. To date, experimentation with generative AI in the field of procedural narrative generation has been quite promising from a technical perspective. However, fundamental narrative dilemmas remain, such as the balance between player agency and narrative coherence, and no rigorous narrative standard has been proposed to specifically leverage the strengths of generative AI. In this paper, we propose the Narrative Context Protocol (NCP), an open and extensible standard designed to place writers at the center of future narrative design workflows and enable interoperability across authoring platforms. By encoding an author's intent according to an objective narrative model, the NCP enables narrative portability as well as intent-based constraints for generative systems.","authors":["Hank Gerba"],"url":"https://arxiv.org/abs/2503.04844"}
{"created":"2025-04-15","title":"The Beginner's Textbook for Fully Homomorphic Encryption","abstract":"Fully Homomorphic Encryption (FHE) is a cryptographic scheme that enables computations to be performed directly on encrypted data, as if the data were in plaintext. After all computations are performed on the encrypted data, it can be decrypted to reveal the result. The decrypted value matches the result that would have been obtained if the same computations were applied to the plaintext data.","authors":["Ronny Ko"],"url":"https://arxiv.org/abs/2503.05136"}
{"created":"2025-04-15","title":"Adaptive Test-Time Intervention for Concept Bottleneck Models","abstract":"Concept bottleneck models (CBM) aim to improve model interpretability by predicting human level \"concepts\" in a bottleneck within a deep learning model architecture. However, how the predicted concepts are used in predicting the target still either remains black-box or is simplified to maintain interpretability at the cost of prediction performance. We propose to use Fast Interpretable Greedy Sum-Trees (FIGS) to obtain Binary Distillation (BD). This new method, called FIGS-BD, distills a binary-augmented concept-to-target portion of the CBM into an interpretable tree-based model, while maintaining the competitive prediction performance of the CBM teacher. FIGS-BD can be used in downstream tasks to explain and decompose CBM predictions into interpretable binary-concept-interaction attributions and guide adaptive test-time intervention. Across 4 datasets, we demonstrate that our adaptive test-time intervention identifies key concepts that significantly improve performance for realistic human-in-the-loop settings that only allow for limited concept interventions.","authors":["Matthew Shen","Aliyah Hsu","Abhineet Agarwal","Bin Yu"],"url":"https://arxiv.org/abs/2503.06730"}
{"created":"2025-04-15","title":"Intelligent Framework for Human-Robot Collaboration: Dynamic Ergonomics and Adaptive Decision-Making","abstract":"The integration of collaborative robots into industrial environments has improved productivity, but has also highlighted significant challenges related to operator safety and ergonomics. This paper proposes an innovative framework that integrates advanced visual perception, continuous ergonomic monitoring, and adaptive Behaviour Tree decision-making to overcome the limitations of traditional methods that typically operate as isolated components. Our approach synthesizes deep learning models, advanced tracking algorithms, and dynamic ergonomic assessments into a modular, scalable, and adaptive system. Experimental validation demonstrates the framework's superiority over existing solutions across multiple dimensions: the visual perception module outperformed previous detection models with 72.4% mAP@50:95; the system achieved high accuracy in recognizing operator intentions (92.5%); it promptly classified ergonomic risks with minimal latency (0.57 seconds); and it dynamically managed robotic interventions with exceptionally responsive decision-making capabilities (0.07 seconds), representing a 56% improvement over benchmark systems. This comprehensive solution provides a robust platform for enhancing human-robot collaboration in industrial environments by prioritizing ergonomic safety, operational efficiency, and real-time adaptability.","authors":["Francesco Iodice","Elena De Momi","Arash Ajoudani"],"url":"https://arxiv.org/abs/2503.07901"}
{"created":"2025-04-15","title":"The StudyChat Dataset: Student Dialogues With ChatGPT in an Artificial Intelligence Course","abstract":"The widespread availability of large language models (LLMs), such as ChatGPT, has significantly impacted education, raising both opportunities and challenges. Students can frequently interact with LLM-powered, interactive learning tools, but their usage patterns need to be analyzed to ensure ethical usage of these tools. To better understand how students interact with LLMs in an academic setting, we introduce \\textbf{StudyChat}, a publicly available dataset capturing real-world student interactions with an LLM-powered tutoring chatbot in a semester-long, university-level artificial intelligence (AI) course. We deploy a web application that replicates ChatGPT's core functionalities, and use it to log student interactions with the LLM while working on programming assignments. We collect 1,197 conversations, which we annotate using a dialogue act labeling schema inspired by observed interaction patterns and prior research. Additionally, we analyze these interactions, highlight behavioral trends, and analyze how specific usage patterns relate to course outcomes. \\textbf{StudyChat} provides a rich resource for the learning sciences and AI in education communities, enabling further research into the evolving role of LLMs in education.","authors":["Hunter McNichols","Andrew Lan"],"url":"https://arxiv.org/abs/2503.07928"}
{"created":"2025-04-15","title":"Weighted Tensor Decompositions for Context-aware Collaborative Filtering","abstract":"Over recent years it has become well accepted that user interest is not static or immutable. There are a variety of contextual factors, such as time of day, the weather or the user's mood, that influence the current interests of the user. Modelling approaches need to take these factors into account if they want to succeed at finding the most relevant content to recommend given the situation.","authors":["Joey De Pauw","Bart Goethals"],"url":"https://arxiv.org/abs/2503.08393"}
{"created":"2025-04-15","title":"Keypoint Detection and Description for Raw Bayer Images","abstract":"Keypoint detection and local feature description are fundamental tasks in robotic perception, critical for applications such as SLAM, robot localization, feature matching, pose estimation, and 3D mapping. While existing methods predominantly operate on RGB images, we propose a novel network that directly processes raw images, bypassing the need for the Image Signal Processor (ISP). This approach significantly reduces hardware requirements and memory consumption, which is crucial for robotic vision systems. Our method introduces two custom-designed convolutional kernels capable of performing convolutions directly on raw images, preserving inter-channel information without converting to RGB. Experimental results show that our network outperforms existing algorithms on raw images, achieving higher accuracy and stability under large rotations and scale variations. This work represents the first attempt to develop a keypoint detection and feature description network specifically for raw images, offering a more efficient solution for resource-constrained environments.","authors":["Jiakai Lin","Jinchang Zhang","Guoyu Lu"],"url":"https://arxiv.org/abs/2503.08673"}
{"created":"2025-04-15","title":"Language-Depth Navigated Thermal and Visible Image Fusion","abstract":"Depth-guided multimodal fusion combines depth information from visible and infrared images, significantly enhancing the performance of 3D reconstruction and robotics applications. Existing thermal-visible image fusion mainly focuses on detection tasks, ignoring other critical information such as depth. By addressing the limitations of single modalities in low-light and complex environments, the depth information from fused images not only generates more accurate point cloud data, improving the completeness and precision of 3D reconstruction, but also provides comprehensive scene understanding for robot navigation, localization, and environmental perception. This supports precise recognition and efficient operations in applications such as autonomous driving and rescue missions. We introduce a text-guided and depth-driven infrared and visible image fusion network. The model consists of an image fusion branch for extracting multi-channel complementary information through a diffusion model, equipped with a text-guided module, and two auxiliary depth estimation branches. The fusion branch uses CLIP to extract semantic information and parameters from depth-enriched image descriptions to guide the diffusion model in extracting multi-channel features and generating fused images. These fused images are then input into the depth estimation branches to calculate depth-driven loss, optimizing the image fusion network. This framework aims to integrate vision-language and depth to directly generate color-fused images from multimodal inputs.","authors":["Jinchang Zhang","Zijun Li","Guoyu Lu"],"url":"https://arxiv.org/abs/2503.08676"}
{"created":"2025-04-15","title":"Not All Edges are Equally Robust: Evaluating the Robustness of Ranking-Based Federated Learning","abstract":"Federated Ranking Learning (FRL) is a state-of-the-art FL framework that stands out for its communication efficiency and resilience to poisoning attacks. It diverges from the traditional FL framework in two ways: 1) it leverages discrete rankings instead of gradient updates, significantly reducing communication costs and limiting the potential space for malicious updates, and 2) it uses majority voting on the server side to establish the global ranking, ensuring that individual updates have minimal influence since each client contributes only a single vote. These features enhance the system's scalability and position FRL as a promising paradigm for FL training.","authors":["Zirui Gong","Yanjun Zhang","Leo Yu Zhang","Zhaoxi Zhang","Yong Xiang","Shirui Pan"],"url":"https://arxiv.org/abs/2503.08976"}
{"created":"2025-04-15","title":"I Predict Therefore I Am: Is Next Token Prediction Enough to Learn Human-Interpretable Concepts from Data?","abstract":"The remarkable achievements of large language models (LLMs) have led many to conclude that they exhibit a form of intelligence. This is as opposed to explanations of their capabilities based on their ability to perform relatively simple manipulations of vast volumes of data. To illuminate the distinction between these explanations, we introduce a novel generative model that generates tokens on the basis of human interpretable concepts represented as latent discrete variables. Under mild conditions, even when the mapping from the latent space to the observed space is non-invertible, we establish an identifiability result: the representations learned by LLMs through next-token prediction can be approximately modeled as the logarithm of the posterior probabilities of these latent discrete concepts, up to an invertible linear transformation. This theoretical finding not only provides evidence that LLMs capture underlying generative factors, but also strongly reinforces the linear representation hypothesis, which posits that LLMs learn linear representations of human-interpretable concepts. Empirically, we validate our theoretical results through evaluations on both simulation data and the Pythia, Llama, and DeepSeek model families.","authors":["Yuhang Liu","Dong Gong","Erdun Gao","Zhen Zhang","Biwei Huang","Mingming Gong","Anton van den Hengel","Javen Qinfeng Shi"],"url":"https://arxiv.org/abs/2503.08980"}
{"created":"2025-04-15","title":"Accurate Control under Voltage Drop for Rotor Drones","abstract":"This letter proposes an anti-disturbance control scheme for rotor drones to counteract voltage drop (VD) disturbance caused by voltage drop of the battery, which is a common case for long-time flight or aggressive maneuvers. Firstly, the refined dynamics of rotor drones considering VD disturbance are presented. Based on the dynamics, a voltage drop observer (VDO) is developed to accurately estimate the VD disturbance by decoupling the disturbance and state information of the drone, reducing the conservativeness of conventional disturbance observers. Subsequently, the control scheme integrates the VDO within the translational loop and a fixed-time sliding mode observer (SMO) within the rotational loop, enabling it to address force and torque disturbances caused by voltage drop of the battery. Sufficient real flight experiments are conducted to demonstrate the effectiveness of the proposed control scheme under VD disturbance.","authors":["Yuhang Liu","Jindou Jia","Zihan Yang","Kexin Guo"],"url":"https://arxiv.org/abs/2503.09017"}
{"created":"2025-04-15","title":"Energy Optimized Piecewise Polynomial Approximation Utilizing Modern Machine Learning Optimizers","abstract":"This work explores an extension of machine learning-optimized piecewise polynomial approximation by incorporating energy optimization as an additional objective. Traditional closed-form solutions enable continuity and approximation targets but lack flexibility in accommodating complex optimization goals. By leveraging modern gradient descent optimizers within TensorFlow, we introduce a framework that minimizes elastic strain energy in cam profiles, leading to smoother motion. Experimental results confirm the effectiveness of this approach, demonstrating its potential to Pareto-efficiently trade approximation quality against energy consumption.","authors":["Hannes Waclawek","Stefan Huber"],"url":"https://arxiv.org/abs/2503.09329"}
{"created":"2025-04-15","title":"Training Human-Robot Teams by Improving Transparency Through a Virtual Spectator Interface","abstract":"After-action reviews (AARs) are professional discussions that help operators and teams enhance their task performance by analyzing completed missions with peers and professionals. Previous studies that compared different formats of AARs have mainly focused on human teams. However, the inclusion of robotic teammates brings along new challenges in understanding teammate intent and communication. Traditional AAR between human teammates may not be satisfactory for human-robot teams. To address this limitation, we propose a new training review (TR) tool, called the Virtual Spectator Interface (VSI), to enhance human-robot team performance and situational awareness (SA) in a simulated search mission. The proposed VSI primarily utilizes visual feedback to review subjects' behavior. To examine the effectiveness of VSI, we took elements from AAR to conduct our own TR, designed a 1 x 3 between-subjects experiment with experimental conditions: TR with (1) VSI, (2) screen recording, and (3) non-technology (only verbal descriptions). The results of our experiments demonstrated that the VSI did not result in significantly better team performance than other conditions. However, the TR with VSI led to more improvement in the subjects SA over the other conditions.","authors":["Sean Dallas (Oakland University)","Hongjiao Qiang (University of Michigan)","Motaz AbuHijleh (Oakland University)","Wonse Jo (University of Michigan)","Kayla Riegner (Ground Vehicle Systems Center)","Jon Smereka (Ground Vehicle Systems Center)","Lionel Robert (University of Michigan)","Wing-Yue Louie (Oakland University)","Dawn M. Tilbury (University of Michigan)"],"url":"https://arxiv.org/abs/2503.09849"}
{"created":"2025-04-15","title":"GMG: A Video Prediction Method Based on Global Focus and Motion Guided","abstract":"Recent years, weather forecasting has gained significant attention. However, accurately predicting weather remains a challenge due to the rapid variability of meteorological data and potential teleconnections. Current spatiotemporal forecasting models primarily rely on convolution operations or sliding windows for feature extraction. These methods are limited by the size of the convolutional kernel or sliding window, making it difficult to capture and identify potential teleconnection features in meteorological data. Additionally, weather data often involve non-rigid bodies, whose motion processes are accompanied by unpredictable deformations, further complicating the forecasting task. In this paper, we propose the GMG model to address these two core challenges. The Global Focus Module, a key component of our model, enhances the global receptive field, while the Motion Guided Module adapts to the growth or dissipation processes of non-rigid bodies. Through extensive evaluations, our method demonstrates competitive performance across various complex tasks, providing a novel approach to improving the predictive accuracy of complex spatiotemporal data.","authors":["Yuhao Du","Hui Liu","Haoxiang Peng","Xinyuan Cheng","Chenrong Wu","Jiankai Zhang"],"url":"https://arxiv.org/abs/2503.11297"}
{"created":"2025-04-15","title":"Designing Neural Synthesizers for Low-Latency Interaction","abstract":"Neural Audio Synthesis (NAS) models offer interactive musical control over high-quality, expressive audio generators. While these models can operate in real-time, they often suffer from high latency, making them unsuitable for intimate musical interaction. The impact of architectural choices in deep learning models on audio latency remains largely unexplored in the NAS literature. In this work, we investigate the sources of latency and jitter typically found in interactive NAS models. We then apply this analysis to the task of timbre transfer using RAVE, a convolutional variational autoencoder for audio waveforms introduced by Caillon et al. in 2021. Finally, we present an iterative design approach for optimizing latency. This culminates with a model we call BRAVE (Bravely Realtime Audio Variational autoEncoder), which is low-latency and exhibits better pitch and loudness replication while showing timbre modification capabilities similar to RAVE. We implement it in a specialized inference framework for low-latency, real-time inference and present a proof-of-concept audio plugin compatible with audio signals from musical instruments. We expect the challenges and guidelines described in this document to support NAS researchers in designing models for low-latency inference from the ground up, enriching the landscape of possibilities for musicians.","authors":["Franco Caspe","Jordie Shier","Mark Sandler","Charalampos Saitis","Andrew McPherson"],"url":"https://arxiv.org/abs/2503.11562"}
{"created":"2025-04-15","title":"A Smooth Analytical Formulation of Collision Detection and Rigid Body Dynamics With Contact","abstract":"Generating intelligent robot behavior in contact-rich settings is a research problem where zeroth-order methods currently prevail. A major contributor to the success of such methods is their robustness in the face of non-smooth and discontinuous optimization landscapes that are characteristic of contact interactions, yet zeroth-order methods remain computationally inefficient. It is therefore desirable to develop methods for perception, planning and control in contact-rich settings that can achieve further efficiency by making use of first and second order information (i.e., gradients and Hessians). To facilitate this, we present a joint formulation of collision detection and contact modelling which, compared to existing differentiable simulation approaches, provides the following benefits: i) it results in forward and inverse dynamics that are entirely analytical (i.e. do not require solving optimization or root-finding problems with iterative methods) and smooth (i.e. twice differentiable), ii) it supports arbitrary collision geometries without needing a convex decomposition, and iii) its runtime is independent of the number of contacts. Through simulation experiments, we demonstrate the validity of the proposed formulation as a \"physics for inference\" that can facilitate future development of efficient methods to generate intelligent contact-rich behavior.","authors":["Onur Beker","Nico G\\\"urtler","Ji Shi","A. Ren\\'e Geist","Amirreza Razmjoo","Georg Martius","Sylvain Calinon"],"url":"https://arxiv.org/abs/2503.11736"}
{"created":"2025-04-15","title":"PSGait: Gait Recognition using Parsing Skeleton","abstract":"Gait recognition has emerged as a robust biometric modality due to its non-intrusive nature and resilience to occlusion. Conventional gait recognition methods typically rely on silhouettes or skeletons. Despite their success in gait recognition for controlled laboratory environments, they usually fail in real-world scenarios due to their limited information entropy for gait representations. To achieve accurate gait recognition in the wild, we propose a novel gait representation, named Parsing Skeleton. This representation innovatively introduces the skeleton-guided human parsing method to capture fine-grained body dynamics, so they have much higher information entropy to encode the shapes and dynamics of fine-grained human parts during walking. Moreover, to effectively explore the capability of the Parsing Skeleton representation, we propose a novel Parsing Skeleton-based gait recognition framework, named PSGait, which takes Parsing Skeletons and silhouettes as input. By fusing these two modalities, the resulting image sequences are fed into gait recognition models for enhanced individual differentiation. We conduct comprehensive benchmarks on various datasets to evaluate our model. PSGait outperforms existing state-of-the-art multimodal methods that utilize both skeleton and silhouette inputs while significantly reducing computational resources. Furthermore, as a plug-and-play method, PSGait leads to a maximum improvement of 10.9% in Rank-1 accuracy across various gait recognition models. These results demonstrate that Parsing Skeleton offers a lightweight, effective, and highly generalizable representation for gait recognition in the wild.","authors":["Hangrui Xu","Chuanrui Zhang","Zhengxian Wu","Peng Jiao","Haoqian Wang"],"url":"https://arxiv.org/abs/2503.12047"}
{"created":"2025-04-15","title":"EgoEvGesture: Gesture Recognition Based on Egocentric Event Camera","abstract":"Egocentric gesture recognition is a pivotal technology for enhancing natural human-computer interaction, yet traditional RGB-based solutions suffer from motion blur and illumination variations in dynamic scenarios. While event cameras show distinct advantages in handling high dynamic range with ultra-low power consumption, existing RGB-based architectures face inherent limitations in processing asynchronous event streams due to their synchronous frame-based nature. Moreover, from an egocentric perspective, event cameras record data that includes events generated by both head movements and hand gestures, thereby increasing the complexity of gesture recognition. To address this, we propose a novel network architecture specifically designed for event data processing, incorporating (1) a lightweight CNN with asymmetric depthwise convolutions to reduce parameters while preserving spatiotemporal features, (2) a plug-and-play state-space model as context block that decouples head movement noise from gesture dynamics, and (3) a parameter-free Bins-Temporal Shift Module (BSTM) that shifts features along bins and temporal dimensions to fuse sparse events efficiently. We further establish the EgoEvGesture dataset, the first large-scale dataset for egocentric gesture recognition using event cameras. Experimental results demonstrate that our method achieves 62.7% accuracy tested on unseen subjects with only 7M parameters, 3.1% higher than state-of-the-art approaches. Notable misclassifications in freestyle motions stem from high inter-personal variability and unseen test patterns differing from training data. Moreover, our approach achieved a remarkable accuracy of 97.0% on the DVS128 Gesture, demonstrating the effectiveness and generalization capability of our method on public datasets. The dataset and models are made available at https://github.com/3190105222/EgoEv_Gesture.","authors":["Luming Wang","Hao Shi","Xiaoting Yin","Kailun Yang","Kaiwei Wang","Jian Bai"],"url":"https://arxiv.org/abs/2503.12419"}
{"created":"2025-04-15","title":"Can Reasoning Models Reason about Hardware? An Agentic HLS Perspective","abstract":"Recent Large Language Models (LLMs) such as OpenAI o3-mini and DeepSeek-R1 use enhanced reasoning through Chain-of-Thought (CoT). Their potential in hardware design, which relies on expert-driven iterative optimization, remains unexplored. This paper investigates whether reasoning LLMs can address challenges in High-Level Synthesis (HLS) design space exploration and optimization. During HLS, engineers manually define pragmas/directives to balance performance and resource constraints. We propose an LLM-based optimization agentic framework that automatically restructures code, inserts pragmas, and identifies optimal design points via feedback from HLs tools and access to integer-linear programming (ILP) solvers. Experiments compare reasoning models against conventional LLMs on benchmarks using success rate, efficiency, and design quality (area/latency) metrics, and provide the first-ever glimpse into the CoTs produced by a powerful open-source reasoning model like DeepSeek-R1.","authors":["Luca Collini","Andrew Hennessee","Ramesh Karri","Siddharth Garg"],"url":"https://arxiv.org/abs/2503.12721"}
{"created":"2025-04-15","title":"Dynamic-Dark SLAM: RGB-Thermal Cooperative Robot Vision Strategy for Multi-Person Tracking in Both Well-Lit and Low-Light Scenes","abstract":"In robot vision, thermal cameras hold great potential for recognizing humans even in complete darkness. However, their application to multi-person tracking (MPT) has been limited due to data scarcity and the inherent difficulty of distinguishing individuals. In this study, we propose a cooperative MPT system that utilizes co-located RGB and thermal cameras, where pseudo-annotations (bounding boxes and person IDs) are used to train both RGB and thermal trackers. Evaluation experiments demonstrate that the thermal tracker performs robustly in both bright and dark environments. Moreover, the results suggest that a tracker-switching strategy -- guided by a binary brightness classifier -- is more effective for information integration than a tracker-fusion approach. As an application example, we present an image change pattern recognition (ICPR) method, the ``human-as-landmark,'' which combines two key properties: the thermal recognizability of humans in dark environments and the rich landmark characteristics -- appearance, geometry, and semantics -- of static objects (occluders). Whereas conventional SLAM focuses on mapping static landmarks in well-lit environments, the present study takes a first step toward a new Human-Only SLAM paradigm, ``DD-SLAM,'' which aims to map even dynamic landmarks in complete darkness.","authors":["Tatsuro Sakai","Kanji Tanaka","Jonathan Tay Yu Liang","Muhammad Adil Luqman","Daiki Iwata"],"url":"https://arxiv.org/abs/2503.12768"}
{"created":"2025-04-15","title":"DreamRenderer: Taming Multi-Instance Attribute Control in Large-Scale Text-to-Image Models","abstract":"Image-conditioned generation methods, such as depth- and canny-conditioned approaches, have demonstrated remarkable abilities for precise image synthesis. However, existing models still struggle to accurately control the content of multiple instances (or regions). Even state-of-the-art models like FLUX and 3DIS face challenges, such as attribute leakage between instances, which limits user control. To address these issues, we introduce DreamRenderer, a training-free approach built upon the FLUX model. DreamRenderer enables users to control the content of each instance via bounding boxes or masks, while ensuring overall visual harmony. We propose two key innovations: 1) Bridge Image Tokens for Hard Text Attribute Binding, which uses replicated image tokens as bridge tokens to ensure that T5 text embeddings, pre-trained solely on text data, bind the correct visual attributes for each instance during Joint Attention; 2) Hard Image Attribute Binding applied only to vital layers. Through our analysis of FLUX, we identify the critical layers responsible for instance attribute rendering and apply Hard Image Attribute Binding only in these layers, using soft binding in the others. This approach ensures precise control while preserving image quality. Evaluations on the COCO-POS and COCO-MIG benchmarks demonstrate that DreamRenderer improves the Image Success Ratio by 17.7% over FLUX and enhances the performance of layout-to-image models like GLIGEN and 3DIS by up to 26.8%. Project Page: https://limuloo.github.io/DreamRenderer/.","authors":["Dewei Zhou","Mingwei Li","Zongxin Yang","Yi Yang"],"url":"https://arxiv.org/abs/2503.12885"}
{"created":"2025-04-15","title":"A Semantic-based Optimization Approach for Repairing LLMs: Case Study on Code Generation","abstract":"Language Models (LMs) are widely used in software engineering for code generation, but they may produce code with errors. Rather than repairing the generated code, an alternative way is to address the underlying failures of models. LM repair offers a lightweight solution to this challenge: it requires minimal data, reduces computational costs, and reduces the side effects. Unlike retraining, LM repair focuses on applying tailored updates to targeted neurons, making it ideal for scenarios with limited resources, high-performance demands, or strict safety requirements. In this paper, we propose \\ul{S}emantic \\ul{T}argeting for \\ul{A}nalytical \\ul{R}epair (\\textsc{STAR}), a pioneering and novel semantic-based optimization approach for repairing LLMs. \\textsc{STAR} realizes main operations in LM repair methods in an optimization process, including locating ``buggy neurons'', solving ``neuron patches'', and patching ``buggy neurons''. Correspondingly, it computes the deltas of weight matrix as the prior information to guide optimization; and attributes the targeted layers and neurons leveraging statistical insights. The neuron patches are computed with a solid semantic-based analytical formula, which directly bridges the changes to logits with the deltas of neurons, by steering latent representations. Compared to the prior work of LM repair (\\textsc{MINT}) and optimization methods (\\textsc{SGD}), \\textsc{STAR} integrates their strengths while mitigating their limitations. \\textsc{STAR} supports solving multiple failures together, significantly improving the usefulness. Evaluated on three code generation tasks using popular code LMs, \\textsc{STAR} demonstrates superior effectiveness. Additionally, \\textsc{STAR} exhibits better efficiency. In terms of side effects, namely the balance between generalization and specificity, \\textsc{STAR} outperforms prior work by a significant margin.","authors":["Jian Gu","Aldeida Aleti","Chunyang Chen","Hongyu Zhang"],"url":"https://arxiv.org/abs/2503.12899"}
{"created":"2025-04-15","title":"VeriLeaky: Navigating IP Protection vs Utility in Fine-Tuning for LLM-Driven Verilog Coding","abstract":"Large language models (LLMs) offer significant potential for coding, yet fine-tuning (FT) with curated data is essential for niche languages like Verilog. Using proprietary intellectual property (IP) for FT presents a serious risk, as FT data can be leaked through LLM inference. This leads to a critical dilemma for design houses: seeking to build externally accessible LLMs offering competitive Verilog coding, how can they leverage in-house IP to enhance FT utility while ensuring IP protection?","authors":["Zeng Wang","Minghao Shao","Mohammed Nabeel","Prithwish Basu Roy","Likhitha Mankali","Jitendra Bhandari","Ramesh Karri","Ozgur Sinanoglu","Muhammad Shafique","Johann Knechtel"],"url":"https://arxiv.org/abs/2503.13116"}
{"created":"2025-04-15","title":"Improving Complex Reasoning with Dynamic Prompt Corruption: A soft prompt Optimization Approach","abstract":"Prompt-tuning (PT) for large language models (LLMs) can facilitate the performance on various conventional NLP tasks with significantly fewer trainable parameters. However, our investigation reveals that PT provides limited improvement and may even degrade the primitive performance of LLMs on complex reasoning tasks. Such a phenomenon suggests that soft prompts can positively impact certain instances while negatively affecting others, particularly during the later phases of reasoning. To address these challenges, We first identify an information accumulation within the soft prompts. Through detailed analysis, we demonstrate that this phenomenon is often accompanied by erroneous information flow patterns in the deeper layers of the model, which ultimately lead to incorrect reasoning outcomes. we propose a novel method called Dynamic Prompt Corruption (DPC) to take better advantage of soft prompts in complex reasoning tasks, which dynamically adjusts the influence of soft prompts based on their impact on the reasoning process. Specifically, DPC consists of two stages: Dynamic Trigger and Dynamic Corruption. First, Dynamic Trigger measures the impact of soft prompts, identifying whether beneficial or detrimental. Then, Dynamic Corruption mitigates the negative effects of soft prompts by selectively masking key tokens that interfere with the reasoning process. We validate the proposed approach through extensive experiments on various LLMs and reasoning tasks, including GSM8K, MATH, and AQuA. Experimental results demonstrate that DPC can consistently enhance the performance of PT, achieving 4%-8% accuracy gains compared to vanilla prompt tuning, highlighting the effectiveness of our approach and its potential to enhance complex reasoning in LLMs.","authors":["Sinan Fan","Liang Xie","Chen Shen","Ge Teng","Xiaosong Yuan","Xiaofeng Zhang","Chenxi Huang","Wenxiao Wang","Xiaofei He","Jieping Ye"],"url":"https://arxiv.org/abs/2503.13208"}
{"created":"2025-04-15","title":"SuperBPE: Space Travel for Language Models","abstract":"The assumption across nearly all language model (LM) tokenization schemes is that tokens should be subwords, i.e., contained within word boundaries. While providing a seemingly reasonable inductive bias, is this common practice limiting the potential of modern LMs? Whitespace is not a reliable delimiter of meaning, as evidenced by multi-word expressions (e.g., \"by the way\"), crosslingual variation in the number of words needed to express a concept (e.g., \"spacesuit helmet\" in German is \"raumanzughelm\"), and languages that do not use whitespace at all (e.g., Chinese). To explore the potential of tokenization beyond subwords, we introduce a \"superword\" tokenizer, SuperBPE, which incorporates a simple pretokenization curriculum into the byte-pair encoding (BPE) algorithm to first learn subwords, then superwords that bridge whitespace. This brings dramatic improvements in encoding efficiency: when fixing the vocabulary size to 200k, SuperBPE encodes a fixed piece of text with up to 33% fewer tokens than BPE on average. In experiments, we pretrain 8B transformer LMs from scratch while fixing the model size, vocabulary size, and train compute, varying *only* the algorithm for learning the vocabulary. Our model trained with SuperBPE achieves an average +4.0% absolute improvement over the BPE baseline across 30 downstream tasks (including +8.2% on MMLU), while simultaneously requiring 27% less compute at inference time. In analysis, we find that SuperBPE results in segmentations of text that are more uniform in per-token difficulty. Qualitatively, this may be because SuperBPE tokens often capture common multi-word expressions that function semantically as a single unit. SuperBPE is a straightforward, local modification to tokenization that improves both encoding efficiency and downstream performance, yielding better language models overall.","authors":["Alisa Liu","Jonathan Hayase","Valentin Hofmann","Sewoong Oh","Noah A. Smith","Yejin Choi"],"url":"https://arxiv.org/abs/2503.13423"}
{"created":"2025-04-15","title":"VeriContaminated: Assessing LLM-Driven Verilog Coding for Data Contamination","abstract":"Large Language Models (LLMs) have revolutionized code generation, achieving exceptional results on various established benchmarking frameworks. However, concerns about data contamination - where benchmark data inadvertently leaks into pre-training or fine-tuning datasets - raise questions about the validity of these evaluations. While this issue is known, limiting the industrial adoption of LLM-driven software engineering, hardware coding has received little to no attention regarding these risks. For the first time, we analyze state-of-the-art (SOTA) evaluation frameworks for Verilog code generation (VerilogEval and RTLLM), using established methods for contamination detection (CCD and Min-K% Prob). We cover SOTA commercial and open-source LLMs (CodeGen2.5, Minitron 4b, Mistral 7b, phi-4 mini, LLaMA-{1,2,3.1}, GPT-{2,3.5,4o}, Deepseek-Coder, and CodeQwen 1.5), in baseline and fine-tuned models (RTLCoder and Verigen). Our study confirms that data contamination is a critical concern. We explore mitigations and the resulting trade-offs for code quality vs fairness (i.e., reducing contamination toward unbiased benchmarking).","authors":["Zeng Wang","Minghao Shao","Jitendra Bhandari","Likhitha Mankali","Ramesh Karri","Ozgur Sinanoglu","Muhammad Shafique","Johann Knechtel"],"url":"https://arxiv.org/abs/2503.13572"}
{"created":"2025-04-15","title":"FeNeC: Enhancing Continual Learning via Feature Clustering with Neighbor- or Logit-Based Classification","abstract":"The ability of deep learning models to learn continuously is essential for adapting to new data categories and evolving data distributions. In recent years, approaches leveraging frozen feature extractors after an initial learning phase have been extensively studied. Many of these methods estimate per-class covariance matrices and prototypes based on backbone-derived feature representations. Within this paradigm, we introduce FeNeC (Feature Neighborhood Classifier) and FeNeC-Log, its variant based on the log-likelihood function. Our approach generalizes the existing concept by incorporating data clustering to capture greater intra-class variability. Utilizing the Mahalanobis distance, our models classify samples either through a nearest neighbor approach or trainable logit values assigned to consecutive classes. Our proposition may be reduced to the existing approaches in a special case while extending them with the ability of more flexible adaptation to data. We demonstrate that two FeNeC variants achieve competitive performance in scenarios where task identities are unknown and establish state-of-the-art results on several benchmarks.","authors":["Kamil Ksi\\k{a}\\.zek","Hubert Jastrz\\k{e}bski","Bartosz Trojan","Krzysztof Pniaczek","Micha{\\l} Karp","Jacek Tabor"],"url":"https://arxiv.org/abs/2503.14301"}
{"created":"2025-04-15","title":"Derm1M: A Million-scale Vision-Language Dataset Aligned with Clinical Ontology Knowledge for Dermatology","abstract":"The emergence of vision-language models has transformed medical AI, enabling unprecedented advances in diagnostic capability and clinical applications. However, progress in dermatology has lagged behind other medical domains due to the lack of standard image-text pairs. Existing dermatological datasets are limited in both scale and depth, offering only single-label annotations across a narrow range of diseases instead of rich textual descriptions, and lacking the crucial clinical context needed for real-world applications. To address these limitations, we present Derm1M, the first large-scale vision-language dataset for dermatology, comprising 1,029,761 image-text pairs. Built from diverse educational resources and structured around a standard ontology collaboratively developed by experts, Derm1M provides comprehensive coverage for over 390 skin conditions across four hierarchical levels and 130 clinical concepts with rich contextual information such as medical history, symptoms, and skin tone. To demonstrate Derm1M potential in advancing both AI research and clinical application, we pretrained a series of CLIP-like models, collectively called DermLIP, on this dataset. The DermLIP family significantly outperforms state-of-the-art foundation models on eight diverse datasets across multiple tasks, including zero-shot skin disease classification, clinical and artifacts concept identification, few-shot/full-shot learning, and cross-modal retrieval. Our dataset and code will be publicly available at https://github.com/SiyuanYan1/Derm1M upon acceptance.","authors":["Siyuan Yan","Ming Hu","Yiwen Jiang","Xieji Li","Hao Fei","Philipp Tschandl","Harald Kittler","Zongyuan Ge"],"url":"https://arxiv.org/abs/2503.14911"}
{"created":"2025-04-15","title":"Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive Learning: Adapting Alignment Calibration to MERU","abstract":"Machine unlearning methods have become increasingly important for selective concept removal in large pre-trained models. While recent work has explored unlearning in Euclidean contrastive vision-language models, the effectiveness of concept removal in hyperbolic spaces remains unexplored. This paper investigates machine unlearning in hyperbolic contrastive learning by adapting Alignment Calibration to MERU, a model that embeds images and text in hyperbolic space to better capture semantic hierarchies. Through systematic experiments and ablation studies, we demonstrate that hyperbolic geometry offers distinct advantages for concept removal, achieving near perfect forgetting with reasonable performance on retained concepts, particularly when scaling to multiple concept removal. Our approach introduces hyperbolic-specific components including entailment calibration and norm regularization that leverage the unique properties of hyperbolic space. Comparative analysis with Euclidean models reveals fundamental differences in unlearning dynamics, with hyperbolic unlearning reorganizing the semantic hierarchy while Euclidean approaches merely disconnect cross-modal associations. These findings not only advance machine unlearning techniques but also provide insights into the geometric properties that influence concept representation and removal in multimodal models. Source code available at https://github.com/alex-pv01/HAC","authors":["\\`Alex Pujol Vidal","Sergio Escalera","Kamal Nasrollahi","Thomas B. Moeslund"],"url":"https://arxiv.org/abs/2503.15166"}
{"created":"2025-04-15","title":"Radon: a Programming Model and Platform for Computing Continuum Systems","abstract":"Emerging compute continuum environments pose new challenges that traditional cloud-centric architectures struggle to address. Latency, bandwidth constraints, and the heterogeneity of edge environments hinder the efficiency of centralized cloud solutions. While major cloud providers extend their platforms to the edge, these approaches often overlook its unique characteristics, limiting its potential.","authors":["Luca De Martini","Dario d'Abate","Alessandro Margara","Gianpaolo Cugola"],"url":"https://arxiv.org/abs/2503.15199"}
{"created":"2025-04-15","title":"DNR Bench: Benchmarking Over-Reasoning in Reasoning LLMs","abstract":"Test-time scaling has significantly improved large language model performance, enabling deeper reasoning to solve complex problems. However, this increased reasoning capability also leads to excessive token generation and unnecessary problem-solving attempts. We introduce Don\\'t Answer Bench (DNA Bench), a new benchmark designed to evaluate LLMs ability to robustly understand the tricky reasoning triggers and avoiding unnecessary generation. DNA Bench consists of 150 adversarially designed prompts that are easy for humans to understand and respond to, but surprisingly not for many of the recent prominent LLMs. DNA Bench tests models abilities across different capabilities, such as instruction adherence, hallucination avoidance, redundancy filtering, and unanswerable question recognition. We evaluate reasoning LLMs (RLMs), including DeepSeek-R1, OpenAI O3-mini, Claude-3.7-sonnet and compare them against a powerful non-reasoning model, e.g., GPT-4o. Our experiments reveal that RLMs generate up to 70x more tokens than necessary, often failing at tasks that simpler non-reasoning models handle efficiently with higher accuracy. Our findings underscore the need for more effective training and inference strategies in RLMs.","authors":["Masoud Hashemi","Oluwanifemi Bamgbose","Sathwik Tejaswi Madhusudhan","Jishnu Sethumadhavan Nair","Aman Tiwari","Vikas Yadav"],"url":"https://arxiv.org/abs/2503.15793"}
{"created":"2025-04-15","title":"On the Cone Effect in the Learning Dynamics","abstract":"Understanding the learning dynamics of neural networks is a central topic in the deep learning community. In this paper, we take an empirical perspective to study the learning dynamics of neural networks in real-world settings. Specifically, we investigate the evolution process of the empirical Neural Tangent Kernel (eNTK) during training. Our key findings reveal a two-phase learning process: i) in Phase I, the eNTK evolves significantly, signaling the rich regime, and ii) in Phase II, the eNTK keeps evolving but is constrained in a narrow space, a phenomenon we term the cone effect. This two-phase framework builds on the hypothesis proposed by Fort et al. (2020), but we uniquely identify the cone effect in Phase II, demonstrating its significant performance advantages over fully linearized training.","authors":["Zhanpeng Zhou","Yongyi Yang","Jie Ren","Mahito Sugiyama","Junchi Yan"],"url":"https://arxiv.org/abs/2503.16316"}
{"created":"2025-04-15","title":"Deep learning framework for action prediction reveals multi-timescale locomotor control","abstract":"Modeling human movement in real-world tasks is a fundamental goal for motor control, biomechanics, and rehabilitation engineering. However, existing models of essential tasks like locomotion are not applicable across varying terrain, mechanical conditions, and sensory contexts. This is at least in part due to simplifying assumptions like linear and fixed timescales mappings between inputs and future actions, which may not be broadly applicable. Here, we develop a deep learning-based framework for action prediction, outperforming traditional models across multiple contexts (walking and running, treadmill and overground, varying terrains) and input modalities (multiple body states, visual gaze). We find that neural network architectures with flexible input history-dependence, like GRU and Transformer, and with architecture-dependent trial embeddings perform best overall. By quantifying the model's predictions relative to an autoregressive baseline, we identify context- and modality-dependent timescales. These analyses reveal that there is greater reliance on fast-timescale predictions in complex terrain, gaze predicts future foot placement before body states, and the full-body state predictions precede those by center-of-mass states. This deep learning framework for human action prediction provides quantifiable insights into the control of real-world locomotion and can be extended to other actions, contexts, and populations.","authors":["Wei-Chen Wang","Antoine De Comite","Alexandra Voloshina","Monica Daley","Nidhi Seethapathi"],"url":"https://arxiv.org/abs/2503.16340"}
{"created":"2025-04-15","title":"Vision-Language Embodiment for Monocular Depth Estimation","abstract":"Depth estimation is a core problem in robotic perception and vision tasks, but 3D reconstruction from a single image presents inherent uncertainties. Current depth estimation models primarily rely on inter-image relationships for supervised training, often overlooking the intrinsic information provided by the camera itself. We propose a method that embodies the camera model and its physical characteristics into a deep learning model, computing embodied scene depth through real-time interactions with road environments. The model can calculate embodied scene depth in real-time based on immediate environmental changes using only the intrinsic properties of the camera, without any additional equipment. By combining embodied scene depth with RGB image features, the model gains a comprehensive perspective on both geometric and visual details. Additionally, we incorporate text descriptions containing environmental content and depth information as priors for scene understanding, enriching the model's perception of objects. This integration of image and language - two inherently ambiguous modalities - leverages their complementary strengths for monocular depth estimation. The real-time nature of the embodied language and depth prior model ensures that the model can continuously adjust its perception and behavior in dynamic environments. Experimental results show that the embodied depth estimation method enhances model performance across different scenes.","authors":["Jinchang Zhang","Guoyu Lu"],"url":"https://arxiv.org/abs/2503.16535"}
{"created":"2025-04-15","title":"Summarization Metrics for Spanish and Basque: Do Automatic Scores and LLM-Judges Correlate with Humans?","abstract":"Studies on evaluation metrics and LLM-as-a-Judge models for automatic text summarization have largely been focused on English, limiting our understanding of their effectiveness in other languages. Through our new dataset BASSE (BAsque and Spanish Summarization Evaluation), we address this situation by collecting human judgments on 2,040 abstractive summaries in Basque and Spanish, generated either manually or by five LLMs with four different prompts. For each summary, annotators evaluated five criteria on a 5-point Likert scale: coherence, consistency, fluency, relevance, and 5W1H. We use these data to reevaluate traditional automatic metrics used for evaluating summaries, as well as several LLM-as-a-Judge models that show strong performance on this task in English. Our results show that currently proprietary judge LLMs have the highest correlation with human judgments, followed by criteria-specific automatic metrics, while open-sourced judge LLMs perform poorly. We release BASSE and our code publicly, along with the first large-scale Basque summarization dataset containing 22,525 news articles with their subheads.","authors":["Jeremy Barnes","Naiara Perez","Alba Bonet-Jover","Bego\\~na Altuna"],"url":"https://arxiv.org/abs/2503.17039"}
{"created":"2025-04-15","title":"UAV Resilience Against Stealthy Attacks","abstract":"Unmanned aerial vehicles (UAVs) depend on untrusted software components to automate dangerous or critical missions, making them a desirable target for attacks. Some work has been done to prevent an attacker who has either compromised a ground control station or parts of a UAV's software from sabotaging the vehicle, but not both. We present an architecture running a UAV software stack with runtime monitoring and seL4-based software isolation that prevents attackers from both exploiting software bugs and stealthy attacks. Our architecture retrofits legacy UAVs and secures the popular MAVLink protocol, making wide adoption possible.","authors":["Arthur Amorim","Max Taylor","Trevor Kann","Gary T. Leavens","William L. Harrison","Lance Joneckis"],"url":"https://arxiv.org/abs/2503.17298"}
{"created":"2025-04-15","title":"Generative Modeling of Class Probability for Multi-Modal Representation Learning","abstract":"Multi-modal understanding plays a crucial role in artificial intelligence by enabling models to jointly interpret inputs from different modalities. However, conventional approaches such as contrastive learning often struggle with modality discrepancies, leading to potential misalignments. In this paper, we propose a novel class anchor alignment approach that leverages class probability distributions for multi-modal representation learning. Our method, Class-anchor-ALigned generative Modeling (CALM), encodes class anchors as prompts to generate and align class probability distributions for each modality, enabling more effective alignment. Furthermore, we introduce a cross-modal probabilistic variational autoencoder to model uncertainty in the alignment, enhancing the ability to capture deeper relationships between modalities and data variations. Extensive experiments on four benchmark datasets demonstrate that our approach significantly outperforms state-of-the-art methods, especially in out-of-domain evaluations. This highlights its superior generalization capabilities in multi-modal representation learning.","authors":["Jungkyoo Shin","Bumsoo Kim","Eunwoo Kim"],"url":"https://arxiv.org/abs/2503.17417"}
{"created":"2025-04-15","title":"Polymer: Development Workflows as Software","abstract":"Software development builds digital tools to automate processes, yet its initial phases, up to deployment, remain largely manual. There are two reasons: Development tasks are often under-specified and transitions between tasks usually require a translator. These reasons are mutually reinforcing: it makes little sense to specify tasks when you cannot connect them and writing a translator requires a specification. LLMs change this cost equation: they can handle under-specified systems and they excel at translation. Thus, they can act as skeleton keys that unlock the automation of tasks and transitions that were previously too expensive to interlink. We introduce a recipe for writing development workflows as software (polymer) to further automate the initial phases of development. We show how adopting polymer at Volvo, a large automotive manufacturer, to automate testing saved 2--3 FTEs at the cost of two months to develop and deploy. We close with open challenges when polymerizing development workflows.","authors":["Dhasarathy Parthasarathy","Yinan Yu","Earl T. Barr"],"url":"https://arxiv.org/abs/2503.17679"}
{"created":"2025-04-15","title":"Error analysis for temporal second-order finite element approximations of axisymmetric mean curvature flow of genus-1 surfaces","abstract":"Existing studies on the convergence of numerical methods for curvature flows primarily focus on first-order temporal schemes. In this paper, we establish a novel error analysis for parametric finite element approximations of genus-1 axisymmetric mean curvature flow, formulated using two classical second-order time-stepping methods: the Crank-Nicolson method and the BDF2 method. Our results establish optimal error bounds in both the L^2-norm and H^1-norm, along with a superconvergence result in the H^1-norm for each fully discrete approximation. Finally, we perform convergence experiments to validate the theoretical findings and present numerical simulations for various genus-1 surfaces. Through a series of comparative experiments, we also demonstrate that the methods proposed in this paper exhibit significant mesh advantages.","authors":["Meng Li","Lining Wang","Yiming Wang"],"url":"https://arxiv.org/abs/2503.18505"}
{"created":"2025-04-15","title":"Interpretable and Fair Mechanisms for Abstaining Classifiers","abstract":"Abstaining classifiers have the option to refrain from providing a prediction for instances that are difficult to classify. The abstention mechanism is designed to trade off the classifier's performance on the accepted data while ensuring a minimum number of predictions. In this setting, often fairness concerns arise when the abstention mechanism solely reduces errors for the majority groups of the data, resulting in increased performance differences across demographic groups. While there exist a bunch of methods that aim to reduce discrimination when abstaining, there is no mechanism that can do so in an explainable way. In this paper, we fill this gap by introducing Interpretable and Fair Abstaining Classifier IFAC, an algorithm that can reject predictions both based on their uncertainty and their unfairness. By rejecting possibly unfair predictions, our method reduces error and positive decision rate differences across demographic groups of the non-rejected data. Since the unfairness-based rejections are based on an interpretable-by-design method, i.e., rule-based fairness checks and situation testing, we create a transparent process that can empower human decision-makers to review the unfair predictions and make more just decisions for them. This explainable aspect is especially important in light of recent AI regulations, mandating that any high-risk decision task should be overseen by human experts to reduce discrimination risks.","authors":["Daphne Lenders","Andrea Pugnana","Roberto Pellungrini","Toon Calders","Dino Pedreschi","Fosca Giannotti"],"url":"https://arxiv.org/abs/2503.18826"}
{"created":"2025-04-15","title":"Structuring Scientific Innovation: A Framework for Modeling and Discovering Impactful Knowledge Combinations","abstract":"The emergence of large language models offers new possibilities for structured exploration of scientific knowledge. Rather than viewing scientific discovery as isolated ideas or content, we propose a structured approach that emphasizes the role of method combinations in shaping disruptive insights. Specifically, we investigate how knowledge unit--especially those tied to methodological design--can be modeled and recombined to yield research breakthroughs. Our proposed framework addresses two key challenges. First, we introduce a contrastive learning-based mechanism to identify distinguishing features of historically disruptive method combinations within problem-driven contexts. Second, we propose a reasoning-guided Monte Carlo search algorithm that leverages the chain-of-thought capability of LLMs to identify promising knowledge recombinations for new problem statements.Empirical studies across multiple domains show that the framework is capable of modeling the structural dynamics of innovation and successfully highlights combinations with high disruptive potential. This research provides a new path for computationally guided scientific ideation grounded in structured reasoning and historical data modeling.","authors":["Junlan Chen","Kexin Zhang","Daifeng Li","Yangyang Feng","Yuxuan Zhang","Bowen Deng"],"url":"https://arxiv.org/abs/2503.18865"}
{"created":"2025-04-15","title":"Generative Data Imputation for Sparse Learner Performance Data Using Generative Adversarial Imputation Networks","abstract":"Learner performance data collected by Intelligent Tutoring Systems (ITSs), such as responses to questions, is essential for modeling and predicting learners' knowledge states. However, missing responses due to skips or incomplete attempts create data sparsity, challenging accurate assessment and personalized instruction. To address this, we propose a generative imputation approach using Generative Adversarial Imputation Networks (GAIN). Our method features a three-dimensional (3D) framework (learners, questions, and attempts), flexibly accommodating various sparsity levels. Enhanced by convolutional neural networks and optimized with a least squares loss function, the GAIN-based method aligns input and output dimensions to question-attempt matrices along the learners' dimension. Extensive experiments using datasets from AutoTutor Adult Reading Comprehension (ARC), ASSISTments, and MATHia demonstrate that our approach significantly outperforms tensor factorization and alternative GAN methods in imputation accuracy across different attempt scenarios. Bayesian Knowledge Tracing (BKT) further validates the effectiveness of the imputed data by estimating learning parameters: initial knowledge (P(L0)), learning rate (P(T)), guess rate (P(G)), and slip rate (P(S)). Results indicate the imputed data enhances model fit and closely mirrors original distributions, capturing underlying learning behaviors reliably. Kullback-Leibler (KL) divergence assessments confirm minimal divergence, showing the imputed data preserves essential learning characteristics effectively. These findings underscore GAIN's capability as a robust imputation tool in ITSs, alleviating data sparsity and supporting adaptive, individualized instruction, ultimately leading to more precise and responsive learner assessments and improved educational outcomes.","authors":["Liang Zhang","Jionghao Lin","John Sabatini","Diego Zapata-Rivera","Carol Forsyth","Yang Jiang","John Hollander","Xiangen Hu","Arthur C. Graesser"],"url":"https://arxiv.org/abs/2503.18982"}
{"created":"2025-04-15","title":"Efficient IoT Intrusion Detection with an Improved Attention-Based CNN-BiLSTM Architecture","abstract":"The ever-increasing security vulnerabilities in the Internet-of-Things (IoT) systems require improved threat detection approaches. This paper presents a compact and efficient approach to detect botnet attacks by employing an integrated approach that consists of traffic pattern analysis, temporal support learning, and focused feature extraction. The proposed attention-based model benefits from a hybrid CNN-BiLSTM architecture and achieves 99% classification accuracy in detecting botnet attacks utilizing the N-BaIoT dataset, while maintaining high precision and recall across various scenarios. The proposed model's performance is further validated by key parameters, such as Mathews Correlation Coefficient and Cohen's kappa Correlation Coefficient. The close-to-ideal results for these parameters demonstrate the proposed model's ability to detect botnet attacks accurately and efficiently in practical settings and on unseen data. The proposed model proved to be a powerful defense mechanism for IoT networks to face emerging security challenges.","authors":["Amna Naeem","Muazzam A. Khan","Nada Alasbali","Jawad Ahmad","Aizaz Ahmad Khattak","Muhammad Shahbaz Khan"],"url":"https://arxiv.org/abs/2503.19339"}
{"created":"2025-04-15","title":"SoK: Decoding the Enigma of Encrypted Network Traffic Classifiers","abstract":"The adoption of modern encryption protocols such as TLS 1.3 has significantly challenged traditional network traffic classification (NTC) methods. As a consequence, researchers are increasingly turning to machine learning (ML) approaches to overcome these obstacles. In this paper, we comprehensively analyze ML-based NTC studies, developing a taxonomy of their design choices, benchmarking suites, and prevalent assumptions impacting classifier performance. Through this systematization, we demonstrate widespread reliance on outdated datasets, oversights in design choices, and the consequences of unsubstantiated assumptions. Our evaluation reveals that the majority of proposed encrypted traffic classifiers have mistakenly utilized unencrypted traffic due to the use of legacy datasets. Furthermore, by conducting 348 feature occlusion experiments on state-of-the-art classifiers, we show how oversights in NTC design choices lead to overfitting, and validate or refute prevailing assumptions with empirical evidence. By highlighting lessons learned, we offer strategic insights, identify emerging research directions, and recommend best practices to support the development of real-world applicable NTC methodologies.","authors":["Nimesha Wickramasinghe","Arash Shaghaghi","Gene Tsudik","Sanjay Jha"],"url":"https://arxiv.org/abs/2503.20093"}
{"created":"2025-04-15","title":"Finding Near-Optimal Maximum Set of Disjoint $k$-Cliques in Real-World Social Networks","abstract":"A $k$-clique is a dense graph, consisting of $k$ fully-connected nodes, that finds numerous applications, such as community detection and network analysis. In this paper, we study a new problem, that finds a maximum set of disjoint $k$-cliques in a given large real-world graph with a user-defined fixed number $k$, which can contribute to a good performance of teaming collaborative events in online games. However, this problem is NP-hard when $k \\geq 3$, making it difficult to solve. To address that, we propose an efficient lightweight method that avoids significant overheads and achieves a $k$-approximation to the optimal, which is equipped with several optimization techniques, including the ordering method, degree estimation in the clique graph, and a lightweight implementation. Besides, to handle dynamic graphs that are widely seen in real-world social networks, we devise an efficient indexing method with careful swapping operations, leading to the efficient maintenance of a near-optimal result with frequent updates in the graph. In various experiments on several large graphs, our proposed approaches significantly outperform the competitors by up to 2 orders of magnitude in running time and 13.3\\% in the number of computed disjoint $k$-cliques, which demonstrates the superiority of the proposed approaches in terms of efficiency and effectiveness.","authors":["Wenqing Lin","Xin Chen","Haoxuan Xie","Sibo Wang","Siqiang Luo"],"url":"https://arxiv.org/abs/2503.20299"}
{"created":"2025-04-15","title":"Bounded Exhaustive Random Program Generation for Testing Solidity Compilers and Analyzers","abstract":"Random program generators often exhibit opportunism: they generate programs without a specific focus within the vast search space defined by the programming language. This opportunistic behavior hinders the effective generation of programs that trigger bugs in compilers and analyzers, even when such programs closely resemble those generated. To address this limitation, we propose bounded exhaustive random program generation, a novel method that focuses the search space of program generation with the aim of more quickly identifying bug-triggering programs. Our approach comprises two stages: 1) generating random program templates, which are incomplete test programs containing bug-related placeholders, and 2) conducting a bounded exhaustive enumeration of valid values for each placeholder within these templates. To ensure efficiency, we maintain a solvable constraint set during the template generation phase and then methodically explore all possible values of placeholders within these constraints during the exhaustive enumeration phase. We have implemented this approach for Solidity, a popular smart contract language for the Ethereum blockchain, in a tool named Erwin. Based on a recent study of Solidity compiler bugs, the placeholders used by Erwin relate to language features commonly associated with compiler bugs. Erwin has successfully identified 23 previously unknown bugs across two Solidity compilers, solc and solang, and one Solidity static analyzer, slither. Evaluation results demonstrate that Erwin outperforms state-of-the-art Solidity fuzzers in bug detection and complements developer-written test suites by covering 4,582 edges and 14,737 lines of the solc compiler that were missed by solc unit tests.","authors":["Haoyang Ma","Alastair F. Donaldson","Qingchao Shen","Yongqiang Tian","Junjie Chen","Shing-Chi Cheung"],"url":"https://arxiv.org/abs/2503.20332"}
{"created":"2025-04-15","title":"MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation","abstract":"Multimodal Large Language Models (MLLMs) excel in understanding complex language and visual data, enabling generalist robotic systems to interpret instructions and perform embodied tasks. Nevertheless, their real-world deployment is hindered by substantial computational and storage demands. Recent insights into the homogeneous patterns in the LLM layer have inspired sparsification techniques to address these challenges, such as early exit and token pruning. However, these methods often neglect the critical role of the final layers that encode the semantic information most relevant to downstream robotic tasks. Aligning with the recent breakthrough of the Shallow Brain Hypothesis (SBH) in neuroscience and the mixture of experts in model sparsification, we conceptualize each LLM layer as an expert and propose a Mixture-of-Layers Vision-Language-Action model (MoLe-VLA, or simply MoLe) architecture for dynamic LLM layer activation. We introduce a Spatial-Temporal Aware Router (STAR) for MoLe to selectively activate only parts of the layers based on the robot's current state, mimicking the brain's distinct signal pathways specialized for cognition and causal reasoning. Additionally, to compensate for the cognitive ability of LLMs lost in MoLe, we devise a Cognition Self-Knowledge Distillation (CogKD) framework. CogKD enhances the understanding of task demands and improves the generation of task-relevant action sequences by leveraging cognitive features. Extensive experiments conducted in both RLBench simulation and real-world environments demonstrate the superiority of MoLe-VLA in both efficiency and performance. Specifically, MoLe-VLA achieves an 8% improvement in the mean success rate across ten tasks while reducing computational costs by up to x5.6 compared to standard LLMs.","authors":["Rongyu Zhang","Menghang Dong","Yuan Zhang","Liang Heng","Xiaowei Chi","Gaole Dai","Li Du","Yuan Du","Shanghang Zhang"],"url":"https://arxiv.org/abs/2503.20384"}
{"created":"2025-04-15","title":"Ontology-based Semantic Similarity Measures for Clustering Medical Concepts in Drug Safety","abstract":"Semantic similarity measures (SSMs) are widely used in biomedical research but remain underutilized in pharmacovigilance. This study evaluates six ontology-based SSMs for clustering MedDRA Preferred Terms (PTs) in drug safety data. Using the Unified Medical Language System (UMLS), we assess each method's ability to group PTs around medically meaningful centroids. A high-throughput framework was developed with a Java API and Python and R interfaces support large-scale similarity computations. Results show that while path-based methods perform moderately with F1 scores of 0.36 for WUPALMER and 0.28 for LCH, intrinsic information content (IC)-based measures, especially INTRINSIC-LIN and SOKAL, consistently yield better clustering accuracy (F1 score of 0.403). Validated against expert review and standard MedDRA queries (SMQs), our findings highlight the promise of IC-based SSMs in enhancing pharmacovigilance workflows by improving early signal detection and reducing manual review.","authors":["Jeffery L Painter","Fran\\c{c}ois Haguinet","Gregory E Powell","Andrew Bate"],"url":"https://arxiv.org/abs/2503.20737"}
{"created":"2025-04-15","title":"Function Alignment: A New Theory of Mind and Intelligence, Part I: Foundations","abstract":"This paper introduces function alignment, a novel theory of mind and intelligence that is both intuitively compelling and structurally grounded. It explicitly models how meaning, interpretation, and analogy emerge from interactions among layered representations, forming a coherent framework capable not only of modeling minds but also of serving as a blueprint for building them. One of the key theoretical insights derived from function alignment is bounded interpretability, which provides a unified explanation for previously fragmented ideas in cognitive science, such as bounded rationality, symbol grounding, and analogy-making. Beyond modeling, the function alignment framework bridges disciplines often kept apart, linking computational architecture, psychological theory, and even contemplative traditions such as Zen. Rather than building on any philosophical systems, it offers a structural foundation upon which multiple ways of understanding the mind may be reconstructed.","authors":["Gus G. Xia"],"url":"https://arxiv.org/abs/2503.21106"}
{"created":"2025-04-15","title":"Detecting Localized Deepfake Manipulations Using Action Unit-Guided Video Representations","abstract":"With rapid advancements in generative modeling, deepfake techniques are increasingly narrowing the gap between real and synthetic videos, raising serious privacy and security concerns. Beyond traditional face swapping and reenactment, an emerging trend in recent state-of-the-art deepfake generation methods involves localized edits such as subtle manipulations of specific facial features like raising eyebrows, altering eye shapes, or modifying mouth expressions. These fine-grained manipulations pose a significant challenge for existing detection models, which struggle to capture such localized variations. To the best of our knowledge, this work presents the first detection approach explicitly designed to generalize to localized edits in deepfake videos by leveraging spatiotemporal representations guided by facial action units. Our method leverages a cross-attention-based fusion of representations learned from pretext tasks like random masking and action unit detection, to create an embedding that effectively encodes subtle, localized changes. Comprehensive evaluations across multiple deepfake generation methods demonstrate that our approach, despite being trained solely on the traditional FF+ dataset, sets a new benchmark in detecting recent deepfake-generated videos with fine-grained local edits, achieving a $20\\%$ improvement in accuracy over current state-of-the-art detection methods. Additionally, our method delivers competitive performance on standard datasets, highlighting its robustness and generalization across diverse types of local and global forgeries.","authors":["Tharun Anand","Siva Sankar Sajeev","Pravin Nair"],"url":"https://arxiv.org/abs/2503.22121"}
{"created":"2025-04-15","title":"Segment Any Motion in Videos","abstract":"Moving object segmentation is a crucial task for achieving a high-level understanding of visual scenes and has numerous downstream applications. Humans can effortlessly segment moving objects in videos. Previous work has largely relied on optical flow to provide motion cues; however, this approach often results in imperfect predictions due to challenges such as partial motion, complex deformations, motion blur and background distractions. We propose a novel approach for moving object segmentation that combines long-range trajectory motion cues with DINO-based semantic features and leverages SAM2 for pixel-level mask densification through an iterative prompting strategy. Our model employs Spatio-Temporal Trajectory Attention and Motion-Semantic Decoupled Embedding to prioritize motion while integrating semantic support. Extensive testing on diverse datasets demonstrates state-of-the-art performance, excelling in challenging scenarios and fine-grained segmentation of multiple objects. Our code is available at https://motion-seg.github.io/.","authors":["Nan Huang","Wenzhao Zheng","Chenfeng Xu","Kurt Keutzer","Shanghang Zhang","Angjoo Kanazawa","Qianqian Wang"],"url":"https://arxiv.org/abs/2503.22268"}
{"created":"2025-04-15","title":"Graph ODEs and Beyond: A Comprehensive Survey on Integrating Differential Equations with Graph Neural Networks","abstract":"Graph Neural Networks (GNNs) and differential equations (DEs) are two rapidly advancing areas of research that have shown remarkable synergy in recent years. GNNs have emerged as powerful tools for learning on graph-structured data, while differential equations provide a principled framework for modeling continuous dynamics across time and space. The intersection of these fields has led to innovative approaches that leverage the strengths of both, enabling applications in physics-informed learning, spatiotemporal modeling, and scientific computing. This survey aims to provide a comprehensive overview of the burgeoning research at the intersection of GNNs and DEs. We will categorize existing methods, discuss their underlying principles, and highlight their applications across domains such as molecular modeling, traffic prediction, and epidemic spreading. Furthermore, we identify open challenges and outline future research directions to advance this interdisciplinary field. A comprehensive paper list is provided at https://github.com/Emory-Melody/Awesome-Graph-NDEs. This survey serves as a resource for researchers and practitioners seeking to understand and contribute to the fusion of GNNs and DEs","authors":["Zewen Liu","Xiaoda Wang","Bohan Wang","Zijie Huang","Carl Yang","Wei Jin"],"url":"https://arxiv.org/abs/2503.23167"}
{"created":"2025-04-15","title":"TRA: Better Length Generalisation with Threshold Relative Attention","abstract":"Transformers struggle with length generalisation, displaying poor performance even on basic tasks. We test whether these limitations can be explained through two key failures of the self-attention mechanism. The first is the inability to fully remove irrelevant information. The second is tied to position, even if the dot product between a key and query is highly negative (i.e. an irrelevant key) learned positional biases may unintentionally up-weight such information - dangerous when distances become out of distribution. Put together, these two failure cases lead to compounding generalisation difficulties. We test whether they can be mitigated through the combination of a) selective sparsity - completely removing irrelevant keys from the attention softmax and b) contextualised relative distance - distance is only considered as between the query and the keys that matter. We show how refactoring the attention mechanism with these two mitigations in place can substantially improve generalisation capabilities of decoder only transformers.","authors":["Mattia Opper","Roland Fernandez","Paul Smolensky","Jianfeng Gao"],"url":"https://arxiv.org/abs/2503.23174"}
{"created":"2025-04-15","title":"A Visual-Inertial Motion Prior SLAM for Dynamic Environments","abstract":"The Visual-Inertial Simultaneous Localization and Mapping (VI-SLAM) algorithms which are mostly based on static assumption are widely used in fields such as robotics, UAVs, VR, and autonomous driving. To overcome the localization risks caused by dynamic landmarks in most VI-SLAM systems, a robust visual-inertial motion prior SLAM system, named IDY-VINS, is proposed in this paper which effectively handles dynamic landmarks using inertial motion prior for dynamic environments to varying degrees. Specifically, potential dynamic landmarks are preprocessed during the feature tracking phase by the probabilistic model of landmarks' minimum projection errors which are obtained from inertial motion prior and epipolar constraint. Subsequently, a robust and self-adaptive bundle adjustment residual is proposed considering the minimum projection error prior for dynamic candidate landmarks. This residual is integrated into a sliding window based nonlinear optimization process to estimate camera poses, IMU states and landmark positions while minimizing the impact of dynamic candidate landmarks that deviate from the motion prior. Finally, a clean point cloud map without `ghosting effect' is obtained that contains only static landmarks. Experimental results demonstrate that our proposed system outperforms state-of-the-art methods in terms of localization accuracy and time cost by robustly mitigating the influence of dynamic landmarks.","authors":["Weilong Sun","Yumin Zhang","Boren Wei"],"url":"https://arxiv.org/abs/2503.23429"}
{"created":"2025-04-15","title":"My CXL Pool Obviates Your PCIe Switch","abstract":"Pooling PCIe devices across multiple hosts offers a promising solution to mitigate stranded I/O resources, enhance device utilization, address device failures, and reduce total cost of ownership. The only viable option today are PCIe switches, which decouple PCIe devices from hosts by connecting them through a hardware switch. However, the high cost and limited flexibility of PCIe switches hinder their widespread adoption beyond specialized datacenter use cases.","authors":["Yuhong Zhong","Daniel S. Berger","Pantea Zardoshti","Enrique Saurez","Jacob Nelson","Antonis Psistakis","Joshua Fried","Asaf Cidon"],"url":"https://arxiv.org/abs/2503.23611"}
{"created":"2025-04-15","title":"GIScience in the Era of Artificial Intelligence: A Research Agenda Towards Autonomous GIS","abstract":"The advent of generative AI exemplified by large language models (LLMs) opens new ways to represent and compute geographic information and transcends the process of geographic knowledge production, driving geographic information systems (GIS) towards autonomous GIS. Leveraging LLMs as the decision core, autonomous GIS can independently generate and execute geoprocessing workflows to perform spatial analysis. In this vision paper, we further elaborate on the concept of autonomous GIS and present a conceptual framework that defines its five autonomous goals, five autonomous levels, five core functions, and three operational scales. We demonstrate how autonomous GIS could perform geospatial data retrieval, spatial analysis, and map making with four proof-of-concept GIS agents. We conclude by identifying critical challenges and future research directions, including fine-tuning and self-growing decision-cores, autonomous modeling, and examining the societal and practical implications of autonomous GIS. By establishing the groundwork for a paradigm shift in GIScience, this paper envisions a future where GIS moves beyond traditional workflows to autonomously reason, derive, innovate, and advance geospatial solutions to pressing global challenges. Meanwhile, as we design and deploy increasingly intelligent geospatial systems, we carry a responsibility to ensure they are developed in socially responsible ways, serve the public good, and support the continued value of human geographic insight in an AI-augmented future.","authors":["Zhenlong Li","Huan Ning","Song Gao","Krzysztof Janowicz","Wenwen Li","Samantha T. Arundel","Chaowei Yang","Budhendra Bhaduri","Shaowen Wang","A-Xing Zhu","Mark Gahegan","Shashi Shekhar","Xinyue Ye","Grant McKenzie","Guido Cervone","Michael E. Hodgson"],"url":"https://arxiv.org/abs/2503.23633"}
{"created":"2025-04-15","title":"Stability and Controllability of Revenue Systems via the Bode Approach","abstract":"In online revenue systems, e.g. an advertising system, budget pacing plays a critical role in ensuring that the spend aligns with desired financial objectives. Pacing systems dynamically control the velocity of spending to balance auction intensity, traffic fluctuations, and other stochastic variables. Current industry practices rely heavily on trial-and-error approaches, often leading to inefficiencies and instability. This paper introduces a principled methodology rooted in Classical Control Theory to address these challenges. By modeling the pacing system as a linear time-invariant (LTI) proxy and leveraging compensator design techniques using Bode methodology, we derive a robust controller to minimize pacing errors and enhance stability. The proposed methodology is validated through simulation and tested by our in-house auction system, demonstrating superior performance in achieving precise budget allocation while maintaining resilience to traffic and auction dynamics. Our findings bridge the gap between traditional control theory and modern advertising systems in modeling, simulation, and validation, offering a scalable and systematic approach to budget pacing optimization.","authors":["Yichuan Niu","Jianhui Chen"],"url":"https://arxiv.org/abs/2503.23663"}
{"created":"2025-04-15","title":"MolGround: A Benchmark for Molecular Grounding","abstract":"Current molecular understanding approaches predominantly focus on the descriptive aspect of human perception, providing broad, topic-level insights. However, the referential aspect -- linking molecular concepts to specific structural components -- remains largely unexplored. To address this gap, we propose a molecular grounding benchmark designed to evaluate a model's referential abilities. We align molecular grounding with established conventions in NLP, cheminformatics, and molecular science, showcasing the potential of NLP techniques to advance molecular understanding within the AI for Science movement. Furthermore, we constructed the largest molecular understanding benchmark to date, comprising 117k QA pairs, and developed a multi-agent grounding prototype as proof of concept. This system outperforms existing models, including GPT-4o, and its grounding outputs have been integrated to enhance traditional tasks such as molecular captioning and ATC (Anatomical, Therapeutic, Chemical) classification.","authors":["Jiaxin Wu","Ting Zhang","Rubing Chen","Wengyu Zhang","Chen Jason Zhang","Xiaoyong Wei","Li Qing"],"url":"https://arxiv.org/abs/2503.23668"}
{"created":"2025-04-15","title":"PDSL: Privacy-Preserved Decentralized Stochastic Learning with Heterogeneous Data Distribution","abstract":"In the paradigm of decentralized learning, a group of agents collaborates to learn a global model using distributed datasets without a central server. However, due to the heterogeneity of the local data across the different agents, learning a robust global model is rather challenging. Moreover, the collaboration of the agents relies on their gradient information exchange, which poses a risk of privacy leakage. In this paper, to address these issues, we propose PDSL, a novel privacy-preserved decentralized stochastic learning algorithm with heterogeneous data distribution. On one hand, we innovate in utilizing the notion of Shapley values such that each agent can precisely measure the contributions of its heterogeneous neighbors to the global learning goal; on the other hand, we leverage the notion of differential privacy to prevent each agent from suffering privacy leakage when it contributes gradient information to its neighbors. We conduct both solid theoretical analysis and extensive experiments to demonstrate the efficacy of our PDSL algorithm in terms of privacy preservation and convergence.","authors":["Lina Wang","Yunsheng Yuan","Chunxiao Wang","Feng Li"],"url":"https://arxiv.org/abs/2503.23726"}
{"created":"2025-04-15","title":"Frequency-Aware Attention-LSTM for PM$_{2.5}$ Time Series Forecasting","abstract":"To enhance the accuracy and robustness of PM$_{2.5}$ concentration forecasting, this paper introduces FALNet, a Frequency-Aware LSTM Network that integrates frequency-domain decomposition, temporal modeling, and attention-based refinement. The model first applies STL and FFT to extract trend, seasonal, and denoised residual components, effectively filtering out high-frequency noise. The filtered residuals are then fed into a stacked LSTM to capture long-term dependencies, followed by a multi-head attention mechanism that dynamically focuses on key time steps. Experiments conducted on real-world urban air quality datasets demonstrate that FALNet consistently outperforms conventional models across standard metrics such as MAE, RMSE, and $R^2$. The model shows strong adaptability in capturing sharp fluctuations during pollution peaks and non-stationary conditions. These results validate the effectiveness and generalizability of FALNet for real-time air pollution prediction, environmental risk assessment, and decision-making support.","authors":["Jiahui LU","Shuang Wu","Zhenkai Qin","Dongze Wu","Guifang Yang"],"url":"https://arxiv.org/abs/2503.24043"}
{"created":"2025-04-15","title":"LLM4FS: Leveraging Large Language Models for Feature Selection and How to Improve It","abstract":"Recent advances in large language models (LLMs) have provided new opportunities for decision-making, particularly in the task of automated feature selection. In this paper, we first comprehensively evaluate LLM-based feature selection methods, covering the state-of-the-art DeepSeek-R1, GPT-o3-mini, and GPT-4.5. Then, we propose a novel hybrid strategy called LLM4FS that integrates LLMs with traditional data-driven methods. Specifically, input data samples into LLMs, and directly call traditional data-driven techniques such as random forest and forward sequential selection. Notably, our analysis reveals that the hybrid strategy leverages the contextual understanding of LLMs and the high statistical reliability of traditional data-driven methods to achieve excellent feature selection performance, even surpassing LLMs and traditional data-driven methods. Finally, we point out the limitations of its application in decision-making.","authors":["Jianhao Li","Xianchao Xiu"],"url":"https://arxiv.org/abs/2503.24157"}
{"created":"2025-04-15","title":"Command A: An Enterprise-Ready Large Language Model","abstract":"In this report we describe the development of Command A, a powerful large language model purpose-built to excel at real-world enterprise use cases. Command A is an agent-optimised and multilingual-capable model, with support for 23 languages of global business, and a novel hybrid architecture balancing efficiency with top of the range performance. It offers best-in-class Retrieval Augmented Generation (RAG) capabilities with grounding and tool use to automate sophisticated business processes. These abilities are achieved through a decentralised training approach, including self-refinement algorithms and model merging techniques. We also include results for Command R7B which shares capability and architectural similarities to Command A. Weights for both models have been released for research purposes. This technical report details our original training pipeline and presents an extensive evaluation of our models across a suite of enterprise-relevant tasks and public benchmarks, demonstrating excellent performance and efficiency.","authors":["Team Cohere",":","Aakanksha","Arash Ahmadian","Marwan Ahmed","Jay Alammar","Milad Alizadeh","Yazeed Alnumay","Sophia Althammer","Arkady Arkhangorodsky","Viraat Aryabumi","Dennis Aumiller","Rapha\\\"el Avalos","Zahara Aviv","Sammie Bae","Saurabh Baji","Alexandre Barbet","Max Bartolo","Bj\\\"orn Bebensee","Neeral Beladia","Walter Beller-Morales","Alexandre B\\'erard","Andrew Berneshawi","Anna Bialas","Phil Blunsom","Matt Bobkin","Adi Bongale","Sam Braun","Maxime Brunet","Samuel Cahyawijaya","David Cairuz","Jon Ander Campos","Cassie Cao","Kris Cao","Roman Castagn\\'e","Juli\\'an Cendrero","Leila Chan Currie","Yash Chandak","Diane Chang","Giannis Chatziveroglou","Hongyu Chen","Claire Cheng","Alexis Chevalier","Justin T. Chiu","Eugene Cho","Eugene Choi","Eujeong Choi","Tim Chung","Volkan Cirik","Ana Cismaru","Pierre Clavier","Henry Conklin","Lucas Crawhall-Stein","Devon Crouse","Andres Felipe Cruz-Salinas","Ben Cyrus","Daniel D'souza","Hugo Dalla-Torre","John Dang","William Darling","Omar Darwiche Domingues","Saurabh Dash","Antoine Debugne","Th\\'eo Dehaze","Shaan Desai","Joan Devassy","Rishit Dholakia","Kyle Duffy","Ali Edalati","Ace Eldeib","Abdullah Elkady","Sarah Elsharkawy","Irem Erg\\\"un","Beyza Ermis","Marzieh Fadaee","Boyu Fan","Lucas Fayoux","Yannis Flet-Berliac","Nick Frosst","Matthias Gall\\'e","Wojciech Galuba","Utsav Garg","Matthieu Geist","Mohammad Gheshlaghi Azar","Ellen Gilsenan-McMahon","Seraphina Goldfarb-Tarrant","Tomas Goldsack","Aidan Gomez","Victor Machado Gonzaga","Nithya Govindarajan","Manoj Govindassamy","Nathan Grinsztajn","Nikolas Gritsch","Patrick Gu","Shangmin Guo","Kilian Haefeli","Rod Hajjar","Tim Hawes","Jingyi He","Sebastian Hofst\\\"atter","Sungjin Hong","Sara Hooker","Tom Hosking","Stephanie Howe","Eric Hu","Renjie Huang","Hemant Jain","Ritika Jain","Nick Jakobi","Madeline Jenkins","JJ Jordan","Dhruti Joshi","Jason Jung","Trushant Kalyanpur","Siddhartha Rao Kamalakara","Julia Kedrzycki","Gokce Keskin","Edward Kim","Joon Kim","Wei-Yin Ko","Tom Kocmi","Michael Kozakov","Wojciech Kry\\'sci\\'nski","Arnav Kumar Jain","Komal Kumar Teru","Sander Land","Michael Lasby","Olivia Lasche","Justin Lee","Patrick Lewis","Jeffrey Li","Jonathan Li","Hangyu Lin","Acyr Locatelli","Kevin Luong","Raymond Ma","Luk\\'a\\v{s} Mach","Marina Machado","Joanne Magbitang","Brenda Malacara Lopez","Aryan Mann","Kelly Marchisio","Olivia Markham","Alexandre Matton","Alex McKinney","Dominic McLoughlin","Jozef Mokry","Adrien Morisot","Autumn Moulder","Harry Moynehan","Maximilian Mozes","Vivek Muppalla","Lidiya Murakhovska","Hemangani Nagarajan","Alekhya Nandula","Hisham Nasir","Shauna Nehra","Josh Netto-Rosen","Daniel Ohashi","James Owers-Bardsley","Jason Ozuzu","Dennis Padilla","Gloria Park","Sam Passaglia","Jeremy Pekmez","Laura Penstone","Aleksandra Piktus","Case Ploeg","Andrew Poulton","Youran Qi","Shubha Raghvendra","Miguel Ramos","Ekagra Ranjan","Pierre Richemond","C\\'ecile Robert-Michon","Aur\\'elien Rodriguez","Sudip Roy","Sebastian Ruder","Laura Ruis","Louise Rust","Anubhav Sachan","Alejandro Salamanca","Kailash Karthik Saravanakumar","Isha Satyakam","Alice Schoenauer Sebag","Priyanka Sen","Sholeh Sepehri","Preethi Seshadri","Ye Shen","Tom Sherborne","Sylvie Shang Shi","Sanal Shivaprasad","Vladyslav Shmyhlo","Anirudh Shrinivason","Inna Shteinbuk","Amir Shukayev","Mathieu Simard","Ella Snyder","Ava Spataru","Victoria Spooner","Trisha Starostina","Florian Strub","Yixuan Su","Jimin Sun","Dwarak Talupuru","Eugene Tarassov","Elena Tommasone","Jennifer Tracey","Billy Trend","Evren Tumer","Ahmet \\\"Ust\\\"un","Bharat Venkitesh","David Venuto","Pat Verga","Maxime Voisin","Alex Wang","Donglu Wang","Shijian Wang","Edmond Wen","Naomi White","Jesse Willman","Marysia Winkels","Chen Xia","Jessica Xie","Minjie Xu","Bowen Yang","Tan Yi-Chern","Ivan Zhang","Zhenyu Zhao","Zhoujie Zhao"],"url":"https://arxiv.org/abs/2504.00698"}
{"created":"2025-04-15","title":"Data-Driven Safety Verification using Barrier Certificates and Matrix Zonotopes","abstract":"Ensuring safety in cyber-physical systems (CPSs) is a critical challenge, especially when system models are difficult to obtain or cannot be fully trusted due to uncertainty, modeling errors, or environmental disturbances. Traditional model-based approaches rely on precise system dynamics, which may not be available in real-world scenarios. To address this, we propose a data-driven safety verification framework that leverages matrix zonotopes and barrier certificates to verify system safety directly from noisy data. Instead of trusting a single unreliable model, we construct a set of models that capture all possible system dynamics that align with the observed data, ensuring that the true system model is always contained within this set. This model set is compactly represented using matrix zonotopes, enabling efficient computation and propagation of uncertainty. By integrating this representation into a barrier certificate framework, we establish rigorous safety guarantees without requiring an explicit system model. Numerical experiments demonstrate the effectiveness of our approach in verifying safety for dynamical systems with unknown models, showcasing its potential for real-world CPS applications.","authors":["Mohammed Adib Oumer","Amr Alanwar","Majid Zamani"],"url":"https://arxiv.org/abs/2504.01007"}
{"created":"2025-04-15","title":"FUSION: Frequency-guided Underwater Spatial Image recOnstructioN","abstract":"Underwater images suffer from severe degradations, including color distortions, reduced visibility, and loss of structural details due to wavelength-dependent attenuation and scattering. Existing enhancement methods primarily focus on spatial-domain processing, neglecting the frequency domain's potential to capture global color distributions and long-range dependencies. To address these limitations, we propose FUSION, a dual-domain deep learning framework that jointly leverages spatial and frequency domain information. FUSION independently processes each RGB channel through multi-scale convolutional kernels and adaptive attention mechanisms in the spatial domain, while simultaneously extracting global structural information via FFT-based frequency attention. A Frequency Guided Fusion module integrates complementary features from both domains, followed by inter-channel fusion and adaptive channel recalibration to ensure balanced color distributions. Extensive experiments on benchmark datasets (UIEB, EUVP, SUIM-E) demonstrate that FUSION achieves state-of-the-art performance, consistently outperforming existing methods in reconstruction fidelity (highest PSNR of 23.717 dB and SSIM of 0.883 on UIEB), perceptual quality (lowest LPIPS of 0.112 on UIEB), and visual enhancement metrics (best UIQM of 3.414 on UIEB), while requiring significantly fewer parameters (0.28M) and lower computational complexity, demonstrating its suitability for real-time underwater imaging applications.","authors":["Jaskaran Singh Walia","Shravan Venkatraman","Pavithra LK"],"url":"https://arxiv.org/abs/2504.01243"}
{"created":"2025-04-15","title":"When to Truncate the Archive? On the Effect of the Truncation Frequency in Multi-Objective Optimisation","abstract":"Using an archive to store nondominated solutions found during the search of a multi-objective evolutionary algorithm (MOEA) is a useful practice. However, as nondominated solutions of a multi-objective optimisation problem can be enormous or infinitely many, it is desirable to provide the decision-maker with only a small, representative portion of all the nondominated solutions in the archive, thus entailing a truncation operation. Then, an important issue is when to truncate the archive. This can be done once a new solution generated, a batch of new solutions generated, or even using an unbounded archive to keep all nondominated solutions generated and truncate it later. Intuitively, the last approach may lead to a better result since we have all the information in hand before performing the truncation. In this paper, we study this issue and investigate the effect of the timing of truncating the archive. We apply well-established truncation criteria that are commonly used in the population maintenance procedure of MOEAs (e.g., crowding distance, hypervolume indicator, and decomposition). We show that, interestingly, truncating the archive once a new solution generated tends to be the best, whereas considering an unbounded archive is often the worst. We analyse and discuss this phenomenon. Our results highlight the importance of developing effective subset selection techniques (rather than employing the population maintenance methods in MOEAs) when using a large archive.","authors":["Zhiji Cui","Zimin Liang","Lie Meng Pang","Hisao Ishibuchi","Miqing Li"],"url":"https://arxiv.org/abs/2504.01332"}
{"created":"2025-04-15","title":"ProtoGuard-guided PROPEL: Class-Aware Prototype Enhancement and Progressive Labeling for Incremental 3D Point Cloud Segmentation","abstract":"3D point cloud semantic segmentation technology has been widely used. However, in real-world scenarios, the environment is evolving. Thus, offline-trained segmentation models may lead to catastrophic forgetting of previously seen classes. Class-incremental learning (CIL) is designed to address the problem of catastrophic forgetting. While point clouds are common, we observe high similarity and unclear boundaries between different classes. Meanwhile, they are known to be imbalanced in class distribution. These lead to issues including misclassification between similar classes and the long-tail problem, which have not been adequately addressed in previous CIL methods. We thus propose ProtoGuard and PROPEL (Progressive Refinement Of PsEudo-Labels). In the base-class training phase, ProtoGuard maintains geometric and semantic prototypes for each class, which are combined into prototype features using an attention mechanism. In the novel-class training phase, PROPEL inherits the base feature extractor and classifier, guiding pseudo-label propagation and updates based on density distribution and semantic similarity. Extensive experiments show that our approach achieves remarkable results on both the S3DIS and ScanNet datasets, improving the mIoU of 3D point cloud segmentation by a maximum of 20.39% under the 5-step CIL scenario on S3DIS.","authors":["Haosheng Li","Yuecong Xu","Junjie Chen","Kemi Ding"],"url":"https://arxiv.org/abs/2504.01648"}
{"created":"2025-04-15","title":"Robust Unsupervised Domain Adaptation for 3D Point Cloud Segmentation Under Source Adversarial Attacks","abstract":"Unsupervised domain adaptation (UDA) frameworks have shown good generalization capabilities for 3D point cloud semantic segmentation models on clean data. However, existing works overlook adversarial robustness when the source domain itself is compromised. To comprehensively explore the robustness of the UDA frameworks, we first design a stealthy adversarial point cloud generation attack that can significantly contaminate datasets with only minor perturbations to the point cloud surface. Based on that, we propose a novel dataset, AdvSynLiDAR, comprising synthesized contaminated LiDAR point clouds. With the generated corrupted data, we further develop the Adversarial Adaptation Framework (AAF) as the countermeasure. Specifically, by extending the key point sensitive (KPS) loss towards the Robust Long-Tail loss (RLT loss) and utilizing a decoder branch, our approach enables the model to focus on long-tail classes during the pre-training phase and leverages high-confidence decoded point cloud information to restore point cloud structures during the adaptation phase. We evaluated our AAF method on the AdvSynLiDAR dataset, where the results demonstrate that our AAF method can mitigate performance degradation under source adversarial perturbations for UDA in the 3D point cloud segmentation application.","authors":["Haosheng Li","Junjie Chen","Yuecong Xu","Kemi Ding"],"url":"https://arxiv.org/abs/2504.01659"}
{"created":"2025-04-15","title":"Overlap-Aware Feature Learning for Robust Unsupervised Domain Adaptation for 3D Semantic Segmentation","abstract":"3D point cloud semantic segmentation (PCSS) is a cornerstone for environmental perception in robotic systems and autonomous driving, enabling precise scene understanding through point-wise classification. While unsupervised domain adaptation (UDA) mitigates label scarcity in PCSS, existing methods critically overlook the inherent vulnerability to real-world perturbations (e.g., snow, fog, rain) and adversarial distortions. This work first identifies two intrinsic limitations that undermine current PCSS-UDA robustness: (a) unsupervised features overlap from unaligned boundaries in shared-class regions and (b) feature structure erosion caused by domain-invariant learning that suppresses target-specific patterns. To address the proposed problems, we propose a tripartite framework consisting of: 1) a robustness evaluation model quantifying resilience against adversarial attack/corruption types through robustness metrics; 2) an invertible attention alignment module (IAAM) enabling bidirectional domain mapping while preserving discriminative structure via attention-guided overlap suppression; and 3) a contrastive memory bank with quality-aware contrastive learning that progressively refines pseudo-labels with feature quality for more discriminative representations. Extensive experiments on SynLiDAR-to-SemanticPOSS adaptation demonstrate a maximum mIoU improvement of 14.3\\% under adversarial attack.","authors":["Junjie Chen","Yuecong Xu","Haosheng Li","Kemi Ding"],"url":"https://arxiv.org/abs/2504.01668"}
{"created":"2025-04-15","title":"A flexible framework for early power and timing comparison of time-multiplexed CGRA kernel executions","abstract":"At the intersection between traditional CPU architectures and more specialized options such as FPGAs or ASICs lies the family of reconfigurable hardware architectures, termed Coarse-Grained Reconfigurable Arrays (CGRAs). CGRAs are composed of a 2-dimensional array of processing elements (PE), tightly integrated with each other, each capable of performing arithmetic and logic operations. The vast design space of CGRA implementations poses a challenge, which calls for fast exploration tools to prune it in advance of time-consuming syntheses. The proposed tool aims to simplify this process by simulating kernel execution and providing a characterization framework. The estimator returns energy and latency values otherwise only available through a time-consuming post-synthesis simulation, allowing for instantaneous comparative analysis between different kernels and hardware configurations.","authors":["Maxime Henri Aspros","Juan Sapriza","Giovanni Ansaloni","David Atienza"],"url":"https://arxiv.org/abs/2504.01672"}
{"created":"2025-04-15","title":"IPA-CHILDES & G2P+: Feature-Rich Resources for Cross-Lingual Phonology and Phonemic Language Modeling","abstract":"In this paper, we introduce two resources: (i) G2P+, a tool for converting orthographic datasets to a consistent phonemic representation; and (ii) IPA CHILDES, a phonemic dataset of child-centered speech across 31 languages. Prior tools for grapheme-to-phoneme conversion result in phonemic vocabularies that are inconsistent with established phonemic inventories, an issue which G2P+ addresses by leveraging the inventories in the Phoible database. Using this tool, we augment CHILDES with phonemic transcriptions to produce IPA CHILDES. This new resource fills several gaps in existing phonemic datasets, which often lack multilingual coverage, spontaneous speech, and a focus on child-directed language. We demonstrate the utility of this dataset for phonological research by training phoneme language models on 11 languages and probing them for distinctive features, finding that the distributional properties of phonemes are sufficient to learn major class and place features cross-lingually.","authors":["Z\\'ebulon Goriely","Paula Buttery"],"url":"https://arxiv.org/abs/2504.03036"}
{"created":"2025-04-15","title":"Beyond Progress Measures: Theoretical Insights into the Mechanism of Grokking","abstract":"Grokking, referring to the abrupt improvement in test accuracy after extended overfitting, offers valuable insights into the mechanisms of model generalization. Existing researches based on progress measures imply that grokking relies on understanding the optimization dynamics when the loss function is dominated solely by the weight decay term. However, we find that this optimization merely leads to token uniformity, which is not a sufficient condition for grokking. In this work, we investigate the grokking mechanism underlying the Transformer in the task of prime number operations. Based on theoretical analysis and experimental validation, we present the following insights: (i) The weight decay term encourages uniformity across all tokens in the embedding space when it is minimized. (ii) The occurrence of grokking is jointly determined by the uniformity of the embedding space and the distribution of the training dataset. Building on these insights, we provide a unified perspective for understanding various previously proposed progress measures and introduce a novel, concise, and effective progress measure that could trace the changes in test loss more accurately. Finally, to demonstrate the versatility of our theoretical framework, we design a dedicated dataset to validate our theory on ResNet-18, successfully showcasing the occurrence of grokking. The code is released at https://github.com/Qihuai27/Grokking-Insight.","authors":["Zihan Gu","Ruoyu Chen","Hua Zhang","Yue Hu","Xiaochun Cao"],"url":"https://arxiv.org/abs/2504.03162"}
{"created":"2025-04-15","title":"Mathematical Modeling of Option Pricing with an Extended Black-Scholes Framework","abstract":"This study investigates enhancing option pricing by extending the Black-Scholes model to include stochastic volatility and interest rate variability within the Partial Differential Equation (PDE). The PDE is solved using the finite difference method. The extended Black-Scholes model and a machine learning-based LSTM model are developed and evaluated for pricing Google stock options. Both models were backtested using historical market data. While the LSTM model exhibited higher predictive accuracy, the finite difference method demonstrated superior computational efficiency. This work provides insights into model performance under varying market conditions and emphasizes the potential of hybrid approaches for robust financial modeling.","authors":["Nikhil Shivakumar Nayak"],"url":"https://arxiv.org/abs/2504.03175"}
{"created":"2025-04-15","title":"BabyLM's First Words: Word Segmentation as a Phonological Probing Task","abstract":"Language models provide a key framework for studying linguistic theories based on prediction, but phonological analysis using large language models (LLMs) is difficult; there are few phonological benchmarks beyond English and the standard input representation used in LLMs (subwords of graphemes) is not suitable for analyzing the representation of phonemes. In this work, we demonstrate how word segmentation can be used as a phonological probing task, allowing us to study the representations learned by phoneme-based language models trained on child-directed speech across 31 languages. Following computational models of word segmentation, we present unsupervised methods for extracting word boundaries from a trained model using the observation that prediction-error peaks at the start of words. We also use linear probes to identify that these models implicitly track word boundaries, even when they do not appear in training. This cross-lingual work corroborates statistical learning theories of acquisition and empirically motivates new methods for training subword tokenizers.","authors":["Z\\'ebulon Goriely","Paula Buttery"],"url":"https://arxiv.org/abs/2504.03338"}
{"created":"2025-04-15","title":"THAPI: Tracing Heterogeneous APIs","abstract":"As we reach exascale, production High Performance Computing (HPC) systems are increasing in complexity. These systems now comprise multiple heterogeneous computing components (CPUs and GPUs) utilized through diverse, often vendor-specific programming models. As application developers and programming models experts develop higher-level, portable programming models for these systems, debugging and performance optimization requires understanding how multiple programming models stacked on top of each other interact with one another. This paper discusses THAPI (Tracing Heterogeneous APIs), a portable, programming model-centric tracing framework: by capturing comprehensive API call details across layers of the HPC software stack, THAPI enables fine-grained understanding and analysis of how applications interact with programming models and heterogeneous hardware. Leveraging state of the art tracing f ramework like the Linux Trace Toolkit Next Generation (LTTng) and tracing much more than other tracing toolkits, focused on function names and timestamps, this approach enables us to diagnose performance bottlenecks across the software stack, optimize application behavior, and debug programming model implementation issues.","authors":["Solomon Bekele (Argonne National Laboratory)","Aurelio Vivas (University De Los Andes - Colombia)","Thomas Applencourt (Argonne National Laboratory)","Servesh Muralidharan (Argonne National Laboratory)","Bryce Allen (Argonne National Laboratory)","Kazutomo Yoshiiinst (Argonne National Laboratory)","Swann Perarnau (Argonne National Laboratory)","Brice Videau (Argonne National Laboratory)"],"url":"https://arxiv.org/abs/2504.03683"}
{"created":"2025-04-15","title":"PrediHealth: Telemedicine and Predictive Algorithms for the Care and Prevention of Patients with Chronic Heart Failure","abstract":"The management of chronic heart failure presents significant challenges in modern healthcare, requiring continuous monitoring, early detection of exacerbations, and personalized treatment strategies. This paper presents the preliminary results of the PrediHealth research project conducted in this context. Specifically, it aims to address the challenges above by integrating telemedicine, mobile health solutions, and predictive analytics into a unified digital healthcare platform. We leveraged a web-based IoT platform, a telemonitoring kit with medical devices and environmental sensors, and AI-driven predictive models to support clinical decision-making. The project follows a structured methodology comprising research on emerging CPS/IoT technologies, system prototyping, predictive model development, and empirical validation.","authors":["Pietro Cassieri","Giuseppe De Filippo","Simranjit Singh","Marco Mazzotta","Gianpiero Sisto","Mariangela Lazoi","Gianvito Mitrano","Claudio Pascarelli","Gianluca Fimiani","Simone Romano","Marina Garofano","Alessia Bramanti","Giuseppe Scanniello"],"url":"https://arxiv.org/abs/2504.03737"}
{"created":"2025-04-15","title":"Improved visual-information-driven model for crowd simulation and its modular application","abstract":"Data-driven crowd simulation models offer advantages in enhancing the accuracy and realism of simulations, and improving their generalizability is essential for promoting application. Current data-driven approaches are primarily designed for a single scenario, with very few models validated across more than two scenarios. It is still an open question to develop data-driven crowd simulation models with strong generalizibility. We notice that the key to addressing this challenge lies in effectively and accurately capturing the core common influential features that govern pedestrians' navigation across diverse scenarios. Particularly, we believe that visual information is one of the most dominant influencing features. In light of this, this paper proposes a data-driven model incorporating a refined visual information extraction method and exit cues to enhance generalizability. The proposed model is examined on four common fundamental modules: bottleneck, corridor, corner and T-junction. The evaluation results demonstrate that our model performs excellently across these scenarios, aligning with pedestrian movement in real-world experiments, and significantly outperforms the classical knowledge-driven model. Furthermore, we introduce a modular approach to apply our proposed model in composite scenarios, and the results regarding trajectories and fundamental diagrams indicate that our simulations closely match real-world patterns in the composite scenario. The research outcomes can provide inspiration for the development of data-driven crowd simulation models with high generalizability and advance the application of data-driven approaches.This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.","authors":["Xuanwen Liang","Jiayu Chen","Eric Wai Ming Lee","Wei Xie"],"url":"https://arxiv.org/abs/2504.03758"}
{"created":"2025-04-15","title":"Do \"New Snow Tablets\" Contain Snow? Large Language Models Over-Rely on Names to Identify Ingredients of Chinese Drugs","abstract":"Traditional Chinese Medicine (TCM) has seen increasing adoption in healthcare, with specialized Large Language Models (LLMs) emerging to support clinical applications. A fundamental requirement for these models is accurate identification of TCM drug ingredients. In this paper, we evaluate how general and TCM-specialized LLMs perform when identifying ingredients of Chinese drugs. Our systematic analysis reveals consistent failure patterns: models often interpret drug names literally, overuse common herbs regardless of relevance, and exhibit erratic behaviors when faced with unfamiliar formulations. LLMs also fail to understand the verification task. These findings demonstrate that current LLMs rely primarily on drug names rather than possessing systematic pharmacological knowledge. To address these limitations, we propose a Retrieval Augmented Generation (RAG) approach focused on ingredient names. Experiments across 220 TCM formulations show our method significantly improves accuracy from approximately 50% to 82% in ingredient verification tasks. Our work highlights critical weaknesses in current TCM-specific LLMs and offers a practical solution for enhancing their clinical reliability.","authors":["Sifan Li","Yujun Cai","Bryan Hooi","Nanyun Peng","Yiwei Wang"],"url":"https://arxiv.org/abs/2504.03786"}
{"created":"2025-04-15","title":"Virtual Reality Lensing for Surface Approximation in Feature-driven Volume Visualization","abstract":"We present a novel lens technique to support the identification of heterogeneous features in direct volume rendering (DVR) visualizations. In contrast to data-centric transfer function (TF) design, our image-driven approach enables users to specify target features directly within the visualization using deformable quadric surfaces. The lens leverages quadrics for their expressive yet simple parametrization, enabling users to sculpt feature approximations by composing multiple quadric lenses. By doing so, the lens offers greater versatility than traditional rigid-shape lenses for selecting and bringing into focus features with irregular geometry. We discuss the lens visualization and interaction design, advocating for bimanual spatial virtual reality (VR) input for reducing cognitive and physical strain. We also report findings from a pilot qualitative evaluation with a domain specialist using a public asteroid impact dataset. These insights not only shed light on the benefits and pitfalls of using deformable lenses but also suggest directions for future research.","authors":["Roberta Mota","Ehud Sharlin","Usman Alim"],"url":"https://arxiv.org/abs/2504.03980"}
{"created":"2025-04-15","title":"Splitting Method for Stochastic Navier-Stokes Equations","abstract":"This paper investigates the two-dimensional stochastic steady-state Navier-Stokes(NS) equations with additive random noise. We introduce an innovative splitting method that decomposes the stochastic NS equations into a deterministic NS component and a stochastic equation. We rigorously analyze the proposed splitting method from the perspectives of equivalence, stability, existence and uniqueness of the solution. We also propose a modified splitting scheme, which simplified the stochastic equation by omitting its nonlinear terms. A detailed analysis of the solution properties for this modified approach is provided. Additionally, we discuss the statistical errors with both the original splitting format and the modified scheme. Our theoretical and numerical studies demonstrate that the equivalent splitting scheme exhibits significantly enhanced stability compared to the original stochastic NS equations, enabling more effective handling of nonlinear characteristics. Several numerical experiments were performed to compare the statistical errors of the splitting method and the modified splitting method. Notably, the deterministic NS equation in the splitting method does not require repeated solving, and the stochastic equation in the modified scheme is free of nonlinear terms. These features make the modified splitting method particularly advantageous for large-scale computations, as it significantly improves computational efficiency without compromising accuracy.","authors":["Jie Zhu","Yujun Zhu","Ju Ming","Max D. Gunzburger"],"url":"https://arxiv.org/abs/2504.04360"}
{"created":"2025-04-15","title":"Pre-training Generative Recommender with Multi-Identifier Item Tokenization","abstract":"Generative recommendation autoregressively generates item identifiers to recommend potential items. Existing methods typically adopt a one-to-one mapping strategy, where each item is represented by a single identifier. However, this scheme poses issues, such as suboptimal semantic modeling for low-frequency items and limited diversity in token sequence data. To overcome these limitations, we propose MTGRec, which leverages Multi-identifier item Tokenization to augment token sequence data for Generative Recommender pre-training. Our approach involves two key innovations: multi-identifier item tokenization and curriculum recommender pre-training. For multi-identifier item tokenization, we leverage the RQ-VAE as the tokenizer backbone and treat model checkpoints from adjacent training epochs as semantically relevant tokenizers. This allows each item to be associated with multiple identifiers, enabling a single user interaction sequence to be converted into several token sequences as different data groups. For curriculum recommender pre-training, we introduce a curriculum learning scheme guided by data influence estimation, dynamically adjusting the sampling probability of each data group during recommender pre-training. After pre-training, we fine-tune the model using a single tokenizer to ensure accurate item identification for recommendation. Extensive experiments on three public benchmark datasets demonstrate that MTGRec significantly outperforms both traditional and generative recommendation baselines in terms of effectiveness and scalability.","authors":["Bowen Zheng","Enze Liu","Zhongfu Chen","Zhongrui Ma","Yue Wang","Wayne Xin Zhao","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2504.04400"}
{"created":"2025-04-15","title":"Universal Item Tokenization for Transferable Generative Recommendation","abstract":"Recently, generative recommendation has emerged as a promising paradigm, attracting significant research attention. The basic framework involves an item tokenizer, which represents each item as a sequence of codes serving as its identifier, and a generative recommender that predicts the next item by autoregressively generating the target item identifier. However, in existing methods, both the tokenizer and the recommender are typically domain-specific, limiting their ability for effective transfer or adaptation to new domains. To this end, we propose UTGRec, a Universal item Tokenization approach for transferable Generative Recommendation. Specifically, we design a universal item tokenizer for encoding rich item semantics by adapting a multimodal large language model (MLLM). By devising tree-structured codebooks, we discretize content representations into corresponding codes for item tokenization. To effectively learn the universal item tokenizer on multiple domains, we introduce two key techniques in our approach. For raw content reconstruction, we employ dual lightweight decoders to reconstruct item text and images from discrete representations to capture general knowledge embedded in the content. For collaborative knowledge integration, we assume that co-occurring items are similar and integrate collaborative signals through co-occurrence alignment and reconstruction. Finally, we present a joint learning framework to pre-train and adapt the transferable generative recommender across multiple domains. Extensive experiments on four public datasets demonstrate the superiority of UTGRec compared to both traditional and generative recommendation baselines.","authors":["Bowen Zheng","Hongyu Lu","Yu Chen","Wayne Xin Zhao","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2504.04405"}
{"created":"2025-04-15","title":"AGITB: A Signal-Level Benchmark for Evaluating Artificial General Intelligence","abstract":"Despite remarkable progress in machine learning, current AI systems continue to fall short of true human-like intelligence. While Large Language Models (LLMs) excel in pattern recognition and response generation, they lack genuine understanding - an essential hallmark of Artificial General Intelligence (AGI). Existing AGI evaluation methods fail to offer a practical, gradual, and informative metric. This paper introduces the Artificial General Intelligence Test Bed (AGITB), comprising twelve rigorous tests that form a signal-processing-level foundation for the potential emergence of cognitive capabilities. AGITB evaluates intelligence through a model's ability to predict binary signals across time without relying on symbolic representations or pretraining. Unlike high-level tests grounded in language or perception, AGITB focuses on core computational invariants reflective of biological intelligence, such as determinism, sensitivity, and generalisation. The test bed assumes no prior bias, operates independently of semantic meaning, and ensures unsolvability through brute force or memorization. While humans pass AGITB by design, no current AI system has met its criteria, making AGITB a compelling benchmark for guiding and recognizing progress toward AGI.","authors":["Matej \\v{S}progar"],"url":"https://arxiv.org/abs/2504.04430"}
{"created":"2025-04-15","title":"KnowsLM: A framework for evaluation of small language models for knowledge augmentation and humanised conversations","abstract":"In the evolving landscape of conversational AI, generating concise, context-aware, and human-like dialogue using small and medium-sized language models (LLMs) remains a complex challenge. This study investigates the influence of LoRA rank, dataset scale, and prompt prefix design on both knowledge retention and stylistic alignment. While fine-tuning improves fluency and enables stylistic customization, its ability to integrate unseen knowledge is constrained -- particularly with smaller datasets. Conversely, RAG-augmented models, equipped to incorporate external documents at inference, demonstrated superior factual accuracy on out-of-distribution prompts, though they lacked the stylistic consistency achieved by fine-tuning. Evaluations by LLM-based judges across knowledge accuracy, conversational quality, and conciseness suggest that fine-tuning is best suited for tone adaptation, whereas RAG excels at real-time knowledge augmentation.","authors":["Chitranshu Harbola","Anupam Purwar"],"url":"https://arxiv.org/abs/2504.04569"}
{"created":"2025-04-15","title":"Diffusion-Based Approximate MPC: Fast and Consistent Imitation of Multi-Modal Action Distributions","abstract":"Approximating model predictive control (MPC) using imitation learning (IL) allows for fast control without solving expensive optimization problems online. However, methods that use neural networks in a simple L2-regression setup fail to approximate multi-modal (set-valued) solution distributions caused by local optima found by the numerical solver or non-convex constraints, such as obstacles, significantly limiting the applicability of approximate MPC in practice. We solve this issue by using diffusion models to accurately represent the complete solution distribution (i.e., all modes) at high control rates (more than 1000 Hz). This work shows that diffusion based AMPC significantly outperforms L2-regression-based approximate MPC for multi-modal action distributions. In contrast to most earlier work on IL, we also focus on running the diffusion-based controller at a higher rate and in joint space instead of end-effector space. Additionally, we propose the use of gradient guidance during the denoising process to consistently pick the same mode in closed loop to prevent switching between solutions. We propose using the cost and constraint satisfaction of the original MPC problem during parallel sampling of solutions from the diffusion model to pick a better mode online. We evaluate our method on the fast and accurate control of a 7-DoF robot manipulator both in simulation and on hardware deployed at 250 Hz, achieving a speedup of more than 70 times compared to solving the MPC problem online and also outperforming the numerical optimization (used for training) in success ratio. Project website: https://paumarquez.github.io/diffusion-ampc.","authors":["Pau Marquez Julbe","Julian Nubert","Henrik Hose","Sebastian Trimpe","Katherine J. Kuchenbecker"],"url":"https://arxiv.org/abs/2504.04603"}
{"created":"2025-04-15","title":"Ineffectiveness for Search and Undecidability of PCSP Meta-Problems","abstract":"It is an open question whether the search and decision versions of promise CSPs are equivalent. Most known algorithms for PCSPs solve only their \\emph{decision} variant, and it is unknown whether they can be adapted to solve \\emph{search} as well. The main approaches, called BLP, AIP and BLP+AIP, handle a PCSP by finding a solution to a relaxation of some integer program. We prove that rounding those solutions to a proper search certificate can be as hard as any problem in the class TFNP. In other words, these algorithms are ineffective for search. Building on the algebraic approach to PCSPs, we find sufficient conditions that imply ineffectiveness for search. Our tools are tailored to algorithms that are characterized by minions in a suitable way, and can also be used to prove undecidability results for meta-problems. This way, we show that the families of templates solvable via BLP, AIP, and BLP+AIP are undecidable.","authors":["Alberto Larrauri"],"url":"https://arxiv.org/abs/2504.04639"}
{"created":"2025-04-15","title":"Explanation-Driven Interventions for Artificial Intelligence Model Customization: Empowering End-Users to Tailor Black-Box AI in Rhinocytology","abstract":"The integration of Artificial Intelligence (AI) in modern society is transforming how individuals perform tasks. In high-risk domains, ensuring human control over AI systems remains a key design challenge. This article presents a novel End-User Development (EUD) approach for black-box AI models, enabling users to edit explanations and influence future predictions through targeted interventions. By combining explainability, user control, and model adaptability, the proposed method advances Human-Centered AI (HCAI), promoting a symbiotic relationship between humans and adaptive, user-tailored AI systems.","authors":["Andrea Esposito (University of Bari Aldo Moro)","Miriana Calvano (University of Bari Aldo Moro)","Antonio Curci (University of Bari Aldo Moro","University of Pisa)","Francesco Greco (University of Bari Aldo Moro)","Rosa Lanzilotti (University of Bari Aldo Moro)","Antonio Piccinno (University of Bari Aldo Moro)"],"url":"https://arxiv.org/abs/2504.04833"}
{"created":"2025-04-15","title":"Unsupervised Ego- and Exo-centric Dense Procedural Activity Captioning via Gaze Consensus Adaptation","abstract":"Even from an early age, humans naturally adapt between exocentric (Exo) and egocentric (Ego) perspectives to understand daily procedural activities. Inspired by this cognitive ability, we propose a novel Unsupervised Ego-Exo Dense Procedural Activity Captioning (UE$^{2}$DPAC) task, which aims to transfer knowledge from the labeled source view to predict the time segments and descriptions of action sequences for the target view without annotations. Despite previous works endeavoring to address the fully-supervised single-view or cross-view dense video captioning, they lapse in the proposed task due to the significant inter-view gap caused by temporal misalignment and irrelevant object interference. Hence, we propose a Gaze Consensus-guided Ego-Exo Adaptation Network (GCEAN) that injects the gaze information into the learned representations for the fine-grained Ego-Exo alignment. Specifically, we propose a Score-based Adversarial Learning Module (SALM) that incorporates a discriminative scoring network and compares the scores of distinct views to learn unified view-invariant representations from a global level. Then, the Gaze Consensus Construction Module (GCCM) utilizes the gaze to progressively calibrate the learned representations to highlight the regions of interest and extract the corresponding temporal contexts. Moreover, we adopt hierarchical gaze-guided consistency losses to construct gaze consensus for the explicit temporal and spatial adaptation between the source and target views. To support our research, we propose a new EgoMe-UE$^{2}$DPAC benchmark, and extensive experiments demonstrate the effectiveness of our method, which outperforms many related methods by a large margin. The code will be released.","authors":["Zhaofeng Shi","Heqian Qiu","Lanxiao Wang","Qingbo Wu","Fanman Meng","Hongliang Li"],"url":"https://arxiv.org/abs/2504.04840"}
{"created":"2025-04-15","title":"Data Augmentation as Free Lunch: Exploring the Test-Time Augmentation for Sequential Recommendation","abstract":"Data augmentation has become a promising method of mitigating data sparsity in sequential recommendation. Existing methods generate new yet effective data during model training to improve performance. However, deploying them requires retraining, architecture modification, or introducing additional learnable parameters. The above steps are time-consuming and costly for well-trained models, especially when the model scale becomes large. In this work, we explore the test-time augmentation (TTA) for sequential recommendation, which augments the inputs during the model inference and then aggregates the model's predictions for augmented data to improve final accuracy. It avoids significant time and cost overhead from loss calculation and backward propagation. We first experimentally disclose the potential of existing augmentation operators for TTA and find that the Mask and Substitute consistently achieve better performance. Further analysis reveals that these two operators are effective because they retain the original sequential pattern while adding appropriate perturbations. Meanwhile, we argue that these two operators still face time-consuming item selection or interference information from mask tokens. Based on the analysis and limitations, we present TNoise and TMask. The former injects uniform noise into the original representation, avoiding the computational overhead of item selection. The latter blocks mask token from participating in model calculations or directly removes interactions that should have been replaced with mask tokens. Comprehensive experiments demonstrate the effectiveness, efficiency, and generalizability of our method. We provide an anonymous implementation at https://github.com/KingGugu/TTA4SR.","authors":["Yizhou Dang","Yuting Liu","Enneng Yang","Minhan Huang","Guibing Guo","Jianzhe Zhao","Xingwei Wang"],"url":"https://arxiv.org/abs/2504.04843"}
{"created":"2025-04-15","title":"Attention-Augmented Inverse Reinforcement Learning with Graph Convolutions for Multi-Agent Task Allocation","abstract":"This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.","authors":["Huilin Yin","Zhikun Yang","Linchuan Zhang","Daniel Watzenig"],"url":"https://arxiv.org/abs/2504.05045"}
{"created":"2025-04-15","title":"Climplicit: Climatic Implicit Embeddings for Global Ecological Tasks","abstract":"Deep learning on climatic data holds potential for macroecological applications. However, its adoption remains limited among scientists outside the deep learning community due to storage, compute, and technical expertise barriers. To address this, we introduce Climplicit, a spatio-temporal geolocation encoder pretrained to generate implicit climatic representations anywhere on Earth. By bypassing the need to download raw climatic rasters and train feature extractors, our model uses x3500 less disk space and significantly reduces computational needs for downstream tasks. We evaluate our Climplicit embeddings on biomes classification, species distribution modeling, and plant trait regression. We find that single-layer probing our Climplicit embeddings consistently performs better or on par with training a model from scratch on downstream tasks and overall better than alternative geolocation encoding models.","authors":["Johannes Dollinger","Damien Robert","Elena Plekhanova","Lukas Drees","Jan Dirk Wegner"],"url":"https://arxiv.org/abs/2504.05089"}
{"created":"2025-04-15","title":"Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning","abstract":"Discovering efficient algorithms for solving complex problems has been an outstanding challenge in mathematics and computer science, requiring substantial human expertise over the years. Recent advancements in evolutionary search with large language models (LLMs) have shown promise in accelerating the discovery of algorithms across various domains, particularly in mathematics and optimization. However, existing approaches treat the LLM as a static generator, missing the opportunity to update the model with the signal obtained from evolutionary exploration. In this work, we propose to augment LLM-based evolutionary search by continuously refining the search operator - the LLM - through reinforcement learning (RL) fine-tuning. Our method leverages evolutionary search as an exploration strategy to discover improved algorithms, while RL optimizes the LLM policy based on these discoveries. Our experiments on three combinatorial optimization tasks - bin packing, traveling salesman, and the flatpack problem - show that combining RL and evolutionary search improves discovery efficiency of improved algorithms, showcasing the potential of RL-enhanced evolutionary strategies to assist computer scientists and mathematicians for more efficient algorithm design.","authors":["Anja Surina","Amin Mansouri","Lars Quaedvlieg","Amal Seddas","Maryna Viazovska","Emmanuel Abbe","Caglar Gulcehre"],"url":"https://arxiv.org/abs/2504.05108"}
{"created":"2025-04-15","title":"Attention-Based Multiscale Temporal Fusion Network for Uncertain-Mode Fault Diagnosis in Multimode Processes","abstract":"Fault diagnosis in multimode processes plays a critical role in ensuring the safe operation of industrial systems across multiple modes. It faces a great challenge yet to be addressed - that is, the significant distributional differences among monitoring data from multiple modes make it difficult for the models to extract shared feature representations related to system health conditions. In response to this problem, this paper introduces a novel method called attention-based multiscale temporal fusion network. The multiscale depthwise convolution and gated recurrent unit are employed to extract multiscale contextual local features and long-short-term features. Instance normalization is applied to suppress mode-specific information. Furthermore, a temporal attention mechanism is designed to focus on critical time points with higher cross-mode shared information, thereby enhancing the accuracy of fault diagnosis. The proposed model is applied to Tennessee Eastman process dataset and three-phase flow facility dataset. The experiments demonstrate that the proposed model achieves superior diagnostic performance and maintains a small model size. The source code will be available on GitHub at https://github.com/GuangqiangLi/AMTFNet.","authors":["Guangqiang Li","M. Amine Atoui","Xiangshun Li"],"url":"https://arxiv.org/abs/2504.05172"}
{"created":"2025-04-15","title":"Proposing TAGbank as a Corpus of Tree-Adjoining Grammar Derivations","abstract":"The development of lexicalized grammars, particularly Tree-Adjoining Grammar (TAG), has significantly advanced our understanding of syntax and semantics in natural language processing (NLP). While existing syntactic resources like the Penn Treebank and Universal Dependencies offer extensive annotations for phrase-structure and dependency parsing, there is a lack of large-scale corpora grounded in lexicalized grammar formalisms. To address this gap, we introduce TAGbank, a corpus of TAG derivations automatically extracted from existing syntactic treebanks. This paper outlines a methodology for mapping phrase-structure annotations to TAG derivations, leveraging the generative power of TAG to support parsing, grammar induction, and semantic analysis. Our approach builds on the work of CCGbank, extending it to incorporate the unique structural properties of TAG, including its transparent derivation trees and its ability to capture long-distance dependencies. We also discuss the challenges involved in the extraction process, including ensuring consistency across treebank schemes and dealing with language-specific syntactic idiosyncrasies. Finally, we propose the future extension of TAGbank to include multilingual corpora, focusing on the Penn Korean and Penn Chinese Treebanks, to explore the cross-linguistic application of TAG's formalism. By providing a robust, derivation-based resource, TAGbank aims to support a wide range of computational tasks and contribute to the theoretical understanding of TAG's generative capacity.","authors":["Jungyeul Park"],"url":"https://arxiv.org/abs/2504.05226"}
{"created":"2025-04-15","title":"User Feedback Alignment for LLM-powered Exploration in Large-scale Recommendation Systems","abstract":"Exploration, the act of broadening user experiences beyond their established preferences, is challenging in large-scale recommendation systems due to feedback loops and limited signals on user exploration patterns. Large Language Models (LLMs) offer potential by leveraging their world knowledge to recommend novel content outside these loops. A key challenge is aligning LLMs with user preferences while preserving their knowledge and reasoning. While using LLMs to plan for the next novel user interest, this paper introduces a novel approach combining hierarchical planning with LLM inference-time scaling to improve recommendation relevancy without compromising novelty. We decouple novelty and user-alignment, training separate LLMs for each objective. We then scale up the novelty-focused LLM's inference and select the best-of-n predictions using the user-aligned LLM. Live experiments demonstrate efficacy, showing significant gains in both user satisfaction (measured by watch activity and active user counts) and exploration diversity.","authors":["Jianling Wang","Yifan Liu","Yinghao Sun","Xuejian Ma","Yueqi Wang","He Ma","Zhengyang Su","Minmin Chen","Mingyan Gao","Onkar Dalal","Ed H. Chi","Lichan Hong","Ningren Han","Haokai Lu"],"url":"https://arxiv.org/abs/2504.05522"}
{"created":"2025-04-15","title":"TAPNext: Tracking Any Point (TAP) as Next Token Prediction","abstract":"Tracking Any Point (TAP) in a video is a challenging computer vision problem with many demonstrated applications in robotics, video editing, and 3D reconstruction. Existing methods for TAP rely heavily on complex tracking-specific inductive biases and heuristics, limiting their generality and potential for scaling. To address these challenges, we present TAPNext, a new approach that casts TAP as sequential masked token decoding. Our model is causal, tracks in a purely online fashion, and removes tracking-specific inductive biases. This enables TAPNext to run with minimal latency, and removes the temporal windowing required by many existing state of art trackers. Despite its simplicity, TAPNext achieves a new state-of-the-art tracking performance among both online and offline trackers. Finally, we present evidence that many widely used tracking heuristics emerge naturally in TAPNext through end-to-end training. The TAPNext model and code can be found at https://tap-next.github.io/.","authors":["Artem Zholus","Carl Doersch","Yi Yang","Skanda Koppula","Viorica Patraucean","Xu Owen He","Ignacio Rocco","Mehdi S. M. Sajjadi","Sarath Chandar","Ross Goroshin"],"url":"https://arxiv.org/abs/2504.05579"}
{"created":"2025-04-15","title":"Dual Boost-Driven Graph-Level Clustering Network","abstract":"Graph-level clustering remains a pivotal yet formidable challenge in graph learning. Recently, the integration of deep learning with representation learning has demonstrated notable advancements, yielding performance enhancements to a certain degree. However, existing methods suffer from at least one of the following issues: 1. the original graph structure has noise, and 2. during feature propagation and pooling processes, noise is gradually aggregated into the graph-level embeddings through information propagation. Consequently, these two limitations mask clustering-friendly information, leading to suboptimal graph-level clustering performance. To this end, we propose a novel Dual Boost-Driven Graph-Level Clustering Network (DBGCN) to alternately promote graph-level clustering and filtering out interference information in a unified framework. Specifically, in the pooling step, we evaluate the contribution of features at the global and optimize them using a learnable transformation matrix to obtain high-quality graph-level representation, such that the model's reasoning capability can be improved. Moreover, to enable reliable graph-level clustering, we first identify and suppress information detrimental to clustering by evaluating similarities between graph-level representations, providing more accurate guidance for multi-view fusion. Extensive experiments demonstrated that DBGCN outperforms the state-of-the-art graph-level clustering methods on six benchmark datasets.","authors":["John Smith","Wenxuan Tu","Junlong Wu","Wenxin Zhang","Jingxin Liu","Haotian Wang","Jieren Cheng","Huajie Lei","Guangzhen Yao","Lingren Wang","Mengfei Li","Renda Han","Yu Li"],"url":"https://arxiv.org/abs/2504.05670"}
{"created":"2025-04-15","title":"InstructMPC: A Human-LLM-in-the-Loop Framework for Context-Aware Control","abstract":"Model Predictive Control (MPC) is a powerful control strategy widely utilized in domains like energy management, building control, and autonomous systems. However, its effectiveness in real-world settings is challenged by the need to incorporate context-specific predictions and expert instructions, which traditional MPC often neglects. We propose InstructMPC, a novel framework that addresses this gap by integrating real-time human instructions through a Large Language Model (LLM) to produce context-aware predictions for MPC. Our method employs a Language-to-Distribution (L2D) module to translate contextual information into predictive disturbance trajectories, which are then incorporated into the MPC optimization. Unlike existing context-aware and language-based MPC models, InstructMPC enables dynamic human-LLM interaction and fine-tunes the L2D module in a closed loop with theoretical performance guarantees, achieving a regret bound of $O(\\sqrt{T\\log T})$ for linear dynamics when optimized via advanced fine-tuning methods such as Direct Preference Optimization (DPO) using a tailored loss function.","authors":["Ruixiang Wu","Jiahao Ai","Tongxin Li"],"url":"https://arxiv.org/abs/2504.05946"}
{"created":"2025-04-15","title":"Optuna vs Code Llama: Are LLMs a New Paradigm for Hyperparameter Tuning?","abstract":"Optimal hyperparameter selection is critical for maximizing neural network performance, especially as models grow in complexity. This work investigates the viability of leveraging large language models (LLMs) for hyperparameter optimization by fine-tuning a parameter-efficient version of Code Llama using LoRA. The adapted LLM is capable of generating accurate and efficient hyperparameter recommendations tailored to diverse neural network architectures. Unlike traditional approaches such as Optuna, which rely on computationally intensive trial-and-error procedures, our method achieves competitive or superior results in terms of Root Mean Square Error (RMSE) while significantly reducing computational overhead. Our findings demonstrate that LLM-based optimization not only matches the performance of state-of-the-art techniques like Tree-structured Parzen Estimators (TPE) but also substantially accelerates the tuning process. This positions LLMs as a promising alternative for rapid experimentation, particularly in resource-constrained environments such as edge devices and mobile platforms, where computational efficiency is essential. In addition to improved efficiency, the method offers time savings and consistent performance across various tasks, highlighting its robustness and generalizability. All generated hyperparameters are included in the LEMUR Neural Network (NN) Dataset, which is publicly available and serves as an open-source benchmark for hyperparameter optimization research.","authors":["Roman Kochnev","Arash Torabi Goodarzi","Zofia Antonina Bentyn","Dmitry Ignatov","Radu Timofte"],"url":"https://arxiv.org/abs/2504.06006"}
{"created":"2025-04-15","title":"A ROS2-based software library for inverse dynamics computation","abstract":"Inverse dynamics computation is a critical component in robot control, planning and simulation, enabling the calculation of joint torques required to achieve a desired motion. This paper presents a ROS2-based software library designed to solve the inverse dynamics problem for robotic systems. The library is built around an abstract class with three concrete implementations: one for simulated robots and two for real UR10 and Franka robots. This contribution aims to provide a flexible, extensible, robot-agnostic solution to inverse dynamics, suitable for both simulation and real-world scenarios involving planning and control applications. The related software is available at https://github.com/unisa-acg/inverse-dynamics-solver/tree/rap.","authors":["Vincenzo Petrone","Enrico Ferrentino","Pasquale Chiacchio"],"url":"https://arxiv.org/abs/2504.06106"}
{"created":"2025-04-15","title":"Adversarial Training of Reward Models","abstract":"Reward modeling has emerged as a promising approach for the scalable alignment of language models. However, contemporary reward models (RMs) often lack robustness, awarding high rewards to low-quality, out-of-distribution (OOD) samples. This can lead to reward hacking, where policies exploit unintended shortcuts to maximize rewards, undermining alignment. To address this challenge, we introduce Adv-RM, a novel adversarial training framework that automatically identifies adversarial examples -- responses that receive high rewards from the target RM but are OOD and of low quality. By leveraging reinforcement learning, Adv-RM trains a policy to generate adversarial examples that reliably expose vulnerabilities in large state-of-the-art reward models such as Nemotron 340B RM. Incorporating these adversarial examples into the reward training process improves the robustness of RMs, mitigating reward hacking and enhancing downstream performance in RLHF. We demonstrate that Adv-RM significantly outperforms conventional RM training, increasing stability and enabling more effective RLHF training in both synthetic and real-data settings.","authors":["Alexander Bukharin","Haifeng Qian","Shengyang Sun","Adithya Renduchintala","Soumye Singhal","Zhilin Wang","Oleksii Kuchaiev","Olivier Delalleau","Tuo Zhao"],"url":"https://arxiv.org/abs/2504.06141"}
{"created":"2025-04-15","title":"Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups","abstract":"Large Language Models (LLMs) have been shown to demonstrate imbalanced biases against certain groups. However, the study of unprovoked targeted attacks by LLMs towards at-risk populations remains underexplored. Our paper presents three novel contributions: (1) the explicit evaluation of LLM-generated attacks on highly vulnerable mental health groups; (2) a network-based framework to study the propagation of relative biases; and (3) an assessment of the relative degree of stigmatization that emerges from these attacks. Our analysis of a recently released large-scale bias audit dataset reveals that mental health entities occupy central positions within attack narrative networks, as revealed by a significantly higher mean centrality of closeness (p-value = 4.06e-10) and dense clustering (Gini coefficient = 0.7). Drawing from sociological foundations of stigmatization theory, our stigmatization analysis indicates increased labeling components for mental health disorder-related targets relative to initial targets in generation chains. Taken together, these insights shed light on the structural predilections of large language models to heighten harmful discourse and highlight the need for suitable approaches for mitigation.","authors":["Rijul Magu","Arka Dutta","Sean Kim","Ashiqur R. KhudaBukhsh","Munmun De Choudhury"],"url":"https://arxiv.org/abs/2504.06160"}
{"created":"2025-04-15","title":"Different Paths, Same Destination: Designing New Physics-Inspired Dynamical Systems with Engineered Stability to Minimize the Ising Hamiltonian","abstract":"Oscillator Ising machines (OIMs) represent an exemplar case of using physics-inspired non-linear dynamical systems to solve computationally challenging combinatorial optimization problems (COPs). The computational performance of such systems is highly sensitive to the underlying dynamical properties, the topology of the input graph, and their relative compatibility. In this work, we explore the concept of designing different dynamical systems that minimize the same objective function but exhibit drastically different dynamical properties. Our goal is to leverage this diversification in dynamics to reduce the sensitivity of the computational performance to the underlying graph, and subsequently, enhance the overall effectiveness of such physics-based computational methods. To this end, we introduce a novel dynamical system, the Dynamical Ising Machine (DIM), which, like the OIM, minimizes the Ising Hamiltonian but offers significantly different dynamical properties. We analyze the characteristic properties of the DIM and compare them with those of the OIM. We also show that the relative performance of each model is dependent on the input graph. Our work illustrates that using multiple dynamical systems with varying properties to solve the same COP enables an effective method that is less sensitive to the input graph, while producing robust solutions.","authors":["E. M. H. E. B. Ekanayake","N. Shukla"],"url":"https://arxiv.org/abs/2504.06280"}
{"created":"2025-04-15","title":"Conformal Slit Mapping Based Spiral Tool Trajectory Planning for Ball-end Milling on Complex Freeform Surfaces","abstract":"This study presents a spiral-based complete coverage strategy for ball-end milling on freeform surfaces, utilizing conformal slit mapping to generate milling trajectories that are more compact, smoother, and evenly distributed when machining 2D cavities with islands. This approach, an upgrade from traditional methods, extends the original algorithm to effectively address 3D perforated surface milling. Unlike conventional algorithms, the method embeds a continuous spiral trajectory within perforated surfaces without requiring cellular decomposition or additional boundaries. The proposed method addresses three primary challenges, including modifying conformal slit mapping for mesh surfaces, maintaining uniform scallop height between adjacent spiral trajectories, and optimizing the mapped origin point to ensure uniform scallop height distribution. To overcome these challenges, surface flattening techniques are incorporated into the original approach to accommodate mesh surfaces effectively. Tool path spacing is then optimized using a binary search strategy to regulate scallop height. A functional energy metric associated with scallop height uniformity is introduced for rapid evaluation of points mapped to the origin, with the minimum functional energy determined through perturbation techniques. The optimal placement of this point is identified using a modified gradient descent approach applied to the energy function. Validation on intricate surfaces, including low-quality and high-genus meshes, verifies the robustness of the algorithm. Surface milling experiments comparing this method with conventional techniques indicate a 15.63% improvement in scallop height uniformity while reducing machining time, average spindle impact, and spindle impact variance by up to 7.36%, 27.79%, and 55.98%, respectively.","authors":["Changqing Shen","BingZhou Xu","Xiaojian Zhang","Sijie Yan","Han Ding"],"url":"https://arxiv.org/abs/2504.06310"}
{"created":"2025-04-15","title":"Text-to-Image Models and Their Representation of People from Different Nationalities Engaging in Activities","abstract":"The primary objective of this paper is to investigate how a popular Text-to-Image (T2I) model represents people from 208 different nationalities when prompted to generate images of individuals performing typical activities. Two scenarios were developed, and images were generated based on input prompts that specified nationalities. The results show that in one scenario, the majority of images, and in the other, a substantial portion, depict individuals wearing traditional attire. This suggests that the model emphasizes such characteristics even when they are impractical for the given activity. A statistically significant relationship was observed between this representation pattern and the regions associated with the specified countries. This indicates that the issue disproportionately affects certain areas, particularly the Middle East & North Africa and Sub-Saharan Africa. A notable association with income groups was also found. CLIP was used to measure alignment scores between generated images and various prompts and captions. The findings indicate statistically significant higher scores for images featuring individuals in traditional attire in one scenario. The study also examined revised prompts (additional contextual information automatically added to the original input prompts) to assess their potential influence on how individuals are represented in the generated images, finding that the word \"traditional\" was commonly added to revised prompts. These findings provide valuable insights into how T2I models represent individuals from various countries and highlight potential areas for improvement in future models.","authors":["Abdulkareem Alsudais"],"url":"https://arxiv.org/abs/2504.06313"}
{"created":"2025-04-15","title":"Efficient Simulation of Singularly Perturbed Systems Using a Stabilized Multirate Explicit Scheme","abstract":"Singularly perturbed systems (SPSs) are prevalent in engineering applications, where numerically solving their initial value problems (IVPs) is challenging due to stiffness arising from multiple time scales. Classical explicit methods require impractically small time steps for stability, while implicit methods developed for SPSs are computationally intensive and less efficient for strongly nonlinear systems. This paper introduces a Stabilized Multirate Explicit Scheme (SMES) that stabilizes classical explicit methods without the need for small time steps or implicit formulations. By employing a multirate approach with variable time steps, SMES allows the fast dynamics to rapidly converge to their equilibrium manifold while slow dynamics evolve with larger steps. Analysis shows that SMES achieves numerical stability with significantly reduced computational effort and controlled error. Its effectiveness is illustrated with a numerical example.","authors":["Yibo Shi","Cristian R. Rojas"],"url":"https://arxiv.org/abs/2504.06371"}
{"created":"2025-04-15","title":"DUKAE: DUal-level Knowledge Accumulation and Ensemble for Pre-Trained Model-Based Continual Learning","abstract":"Pre-trained model-based continual learning (PTMCL) has garnered growing attention, as it enables more rapid acquisition of new knowledge by leveraging the extensive foundational understanding inherent in pre-trained model (PTM). Most existing PTMCL methods use Parameter-Efficient Fine-Tuning (PEFT) to learn new knowledge while consolidating existing memory. However, they often face some challenges. A major challenge lies in the misalignment of classification heads, as the classification head of each task is trained within a distinct feature space, leading to inconsistent decision boundaries across tasks and, consequently, increased forgetting. Another critical limitation stems from the restricted feature-level knowledge accumulation, with feature learning typically restricted to the initial task only, which constrains the model's representation capabilities. To address these issues, we propose a method named DUal-level Knowledge Accumulation and Ensemble (DUKAE) that leverages both feature-level and decision-level knowledge accumulation by aligning classification heads into a unified feature space through Gaussian distribution sampling and introducing an adaptive expertise ensemble to fuse knowledge across feature subspaces. Extensive experiments on CIFAR-100, ImageNet-R, CUB-200, and Cars-196 datasets demonstrate the superior performance of our approach.","authors":["Songze Li","Tonghua Su","Xu-Yao Zhang","Qixing Xu","Zhongjie Wang"],"url":"https://arxiv.org/abs/2504.06521"}
{"created":"2025-04-15","title":"Deep Neural Koopman Operator-based Economic Model Predictive Control of Shipboard Carbon Capture System","abstract":"Shipboard carbon capture is a promising solution to help reduce carbon emissions in international shipping. In this work, we propose a data-driven dynamic modeling and economic predictive control approach within the Koopman framework. This integrated modeling and control approach is used to achieve safe and energy-efficient process operation of shipboard post-combustion carbon capture plants. Specifically, we propose a deep neural Koopman operator modeling approach, based on which a Koopman model with time-varying model parameters is established. This Koopman model predicts the overall economic operational cost and key system outputs, based on accessible partial state measurements. By leveraging this learned model, a constrained economic predictive control scheme is developed. Despite time-varying parameters involved in the formulated model, the formulated optimization problem associated with the economic predictive control design is convex, and it can be solved efficiently during online control implementations. Extensive tests are conducted on a high-fidelity simulation environment for shipboard post-combustion carbon capture processes. Four ship operational conditions are taken into account. The results show that the proposed method significantly improves the overall economic operational performance and carbon capture rate. Additionally, the proposed method guarantees safe operation by ensuring that hard constraints on the system outputs are satisfied.","authors":["Minghao Han","Xunyuan Yin"],"url":"https://arxiv.org/abs/2504.06818"}
{"created":"2025-04-15","title":"The Importance of Being Discrete: Measuring the Impact of Discretization in End-to-End Differentially Private Synthetic Data","abstract":"Differentially Private (DP) generative marginal models are often used in the wild to release synthetic tabular datasets in lieu of sensitive data while providing formal privacy guarantees. These models approximate low-dimensional marginals or query workloads; crucially, they require the training data to be pre-discretized, i.e., continuous values need to first be partitioned into bins. However, as the range of values (or their domain) is often inferred directly from the training data, with the number of bins and bin edges typically defined arbitrarily, this approach can ultimately break end-to-end DP guarantees and may not always yield optimal utility.","authors":["Georgi Ganev","Meenatchi Sundaram Muthu Selva Annamalai","Sofiane Mahiou","Emiliano De Cristofaro"],"url":"https://arxiv.org/abs/2504.06923"}
{"created":"2025-04-15","title":"VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning","abstract":"Recent advancements in reinforcement learning have significantly advanced the reasoning capabilities of multimodal large language models (MLLMs). While approaches such as Group Relative Policy Optimization (GRPO) and rule-based reward mechanisms demonstrate promise in text and image domains, their application to video understanding remains limited. This paper presents a systematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for video MLLMs, aiming to enhance spatio-temporal perception while maintaining general capabilities. Our experiments reveal that RFT is highly data-efficient for task-specific improvements. Through multi-task RFT on spatio-temporal perception objectives with limited samples, we develop VideoChat-R1, a powerful video MLLM that achieves state-of-the-art performance on spatio-temporal perception tasks without sacrificing chat ability, while exhibiting emerging spatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1 boosts performance several-fold in tasks like temporal grounding (+31.8) and object tracking (+31.2). Additionally, it significantly improves on general QA benchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9). Our findings underscore the potential of RFT for specialized task enhancement of Video MLLMs. We hope our work offers valuable insights for future RL research in video MLLMs.","authors":["Xinhao Li","Ziang Yan","Desen Meng","Lu Dong","Xiangyu Zeng","Yinan He","Yali Wang","Yu Qiao","Yi Wang","Limin Wang"],"url":"https://arxiv.org/abs/2504.06958"}
{"created":"2025-04-15","title":"Distilling Textual Priors from LLM to Efficient Image Fusion","abstract":"Multi-modality image fusion aims to synthesize a single, comprehensive image from multiple source inputs. Traditional approaches, such as CNNs and GANs, offer efficiency but struggle to handle low-quality or complex inputs. Recent advances in text-guided methods leverage large model priors to overcome these limitations, but at the cost of significant computational overhead, both in memory and inference time. To address this challenge, we propose a novel framework for distilling large model priors, eliminating the need for text guidance during inference while dramatically reducing model size. Our framework utilizes a teacher-student architecture, where the teacher network incorporates large model priors and transfers this knowledge to a smaller student network via a tailored distillation process. Additionally, we introduce spatial-channel cross-fusion module to enhance the model's ability to leverage textual priors across both spatial and channel dimensions. Our method achieves a favorable trade-off between computational efficiency and fusion quality. The distilled network, requiring only 10% of the parameters and inference time of the teacher network, retains 90% of its performance and outperforms existing SOTA methods. Extensive experiments demonstrate the effectiveness of our approach. The implementation will be made publicly available as an open-source resource.","authors":["Ran Zhang","Xuanhua He","Ke Cao","Liu Liu","Li Zhang","Man Zhou","Jie Zhang"],"url":"https://arxiv.org/abs/2504.07029"}
{"created":"2025-04-15","title":"Context Switching for Secure Multi-programming of Near-Term Quantum Computers","abstract":"Multi-programming quantum computers improve device utilization and throughput. However, crosstalk from concurrent two-qubit CNOT gates poses security risks, compromising the fidelity and output of co-running victim programs. We design Zero Knowledge Tampering Attacks (ZKTAs), using which attackers can exploit crosstalk without knowledge of the hardware error profile. ZKTAs can alter victim program outputs in 40% of cases on commercial systems.","authors":["Avinash Kumar","Meng Wang","Chenxu Liu","Ang Li","Prashant J. Nair","Poulami Das"],"url":"https://arxiv.org/abs/2504.07048"}
{"created":"2025-04-15","title":"Secure Text Mail Encryption with Generative Adversarial Networks","abstract":"This work presents an encryption model based on Generative Adversarial Networks (GANs). Encryption of RTF-8 data is realized by dynamically generating decimal numbers that lead to the encryption and decryption of alphabetic strings in integer representation by simple addition rules, the modulus of the dimension of the considered alphabet. The binary numbers for the private dynamic keys correspond to the binary numbers of public reference keys, as defined by a specific GAN configuration. For reversible encryption with a bijective mapping between dynamic and reference keys, as defined by the GAN encryptor, secure text encryption can be achieved by transferring a GAN-encrypted public key along with the encrypted text from a sender to a receiver. Using the technique described above, secure text mail transfer can be realized through component-wise encryption and decryption of text mail strings, with total key sizes of up to $10^{8}$ bits that define random decimal numbers generated by the GAN. From the present model, we assert that encrypted texts can be transmitted more efficiently and securely than from RSA encryption, as long as users of the specific configuration of the GAN encryption model are unaware of the GAN encryptor circuit and configuration, respectively.","authors":["Alexej Schelle"],"url":"https://arxiv.org/abs/2504.07140"}
{"created":"2025-04-15","title":"MESA: Text-Driven Terrain Generation Using Latent Diffusion and Global Copernicus Data","abstract":"Terrain modeling has traditionally relied on procedural techniques, which often require extensive domain expertise and handcrafted rules. In this paper, we present MESA - a novel data-centric alternative by training a diffusion model on global remote sensing data. This approach leverages large-scale geospatial information to generate high-quality terrain samples from text descriptions, showcasing a flexible and scalable solution for terrain generation. The model's capabilities are demonstrated through extensive experiments, highlighting its ability to generate realistic and diverse terrain landscapes. The dataset produced to support this work, the Major TOM Core-DEM extension dataset, is released openly as a comprehensive resource for global terrain data. The results suggest that data-driven models, trained on remote sensing data, can provide a powerful tool for realistic terrain modeling and generation.","authors":["Paul Borne--Pons (Adobe Research","ESA)","Mikolaj Czerkawski (Asterisk Labs","ESA)","Rosalie Martin (Adobe Research)","Romain Rouffet (Adobe Research)"],"url":"https://arxiv.org/abs/2504.07210"}
{"created":"2025-04-15","title":"Skill Demand Forecasting Using Temporal Knowledge Graph Embeddings","abstract":"Rapid technological advancements pose a significant threat to a large portion of the global workforce, potentially leaving them behind. In today's economy, there is a stark contrast between the high demand for skilled labour and the limited employment opportunities available to those who are not adequately prepared for the digital economy. To address this critical juncture and gain a deeper and more rapid understanding of labour market dynamics, in this paper, we approach the problem of skill need forecasting as a knowledge graph (KG) completion task, specifically, temporal link prediction. We introduce our novel temporal KG constructed from online job advertisements. We then train and evaluate different temporal KG embeddings for temporal link prediction. Finally, we present predictions of demand for a selection of skills practiced by workers in the information technology industry. The code and the data are available on our GitHub repository https://github.com/team611/JobEd.","authors":["Yousra Fettach","Adil Bahaj","Mounir Ghogho"],"url":"https://arxiv.org/abs/2504.07233"}
{"created":"2025-04-15","title":"RAISE: Reinforenced Adaptive Instruction Selection For Large Language Models","abstract":"In the instruction fine-tuning of large language models (LLMs), it has become a consensus that a few high-quality instructions are superior to a large number of low-quality instructions. At present, many instruction selection methods have been proposed, but most of these methods select instruction based on heuristic quality metrics, and only consider data selection before training. These designs lead to insufficient optimization of instruction fine-tuning, and fixed heuristic indicators are often difficult to optimize for specific tasks. So we designed a dynamic, task-objective-driven instruction selection framework RAISE(Reinforenced Adaptive Instruction SElection), which incorporates the entire instruction fine-tuning process into optimization, selecting instruction at each step based on the expected impact of instruction on model performance improvement. Our approach is well interpretable and has strong task-specific optimization capabilities. By modeling dynamic instruction selection as a sequential decision-making process, we use RL to train our selection strategy. Extensive experiments and result analysis prove the superiority of our method compared with other instruction selection methods. Notably, RAISE achieves superior performance by updating only 1\\% of the training steps compared to full-data training, demonstrating its efficiency and effectiveness.","authors":["Lv Qingsong","Yangning Li","Zihua Lan","Zishan Xu","Jiwei Tang","Yinghui Li","Wenhao Jiang","Hai-Tao Zheng","Philip S. Yu"],"url":"https://arxiv.org/abs/2504.07282"}
{"created":"2025-04-15","title":"MDIT: A Model-free Data Interpolation Method for Diverse Instruction Tuning","abstract":"As Large Language Models (LLMs) are increasingly applied across various tasks, instruction tuning has emerged as a critical method for enhancing model performance. However, current data management strategies face substantial challenges in generating diverse and comprehensive data, restricting further improvements in model performance. To address this gap, we propose MDIT, a novel model-free data interpolation method for diverse instruction tuning, which generates varied and high-quality instruction data by performing task interpolation. Moreover, it contains diversity-based clustering strategies to ensure the diversity of the training data. Extensive experiments show that our method achieves superior performance in multiple benchmark tasks. The LLMs finetuned with MDIT show significant improvements in numerous tasks such as general question answering, math reasoning, and code generation. MDIT offers an efficient and automatic data synthetic method, generating diverse instruction data without depending on external resources while expanding the application potential of LLMs in complex environments.","authors":["Yangning Li","Zihua Lan","Lv Qingsong","Yinghui Li","Hai-Tao Zheng"],"url":"https://arxiv.org/abs/2504.07288"}
{"created":"2025-04-15","title":"The Gendered Algorithm: Navigating Financial Inclusion & Equity in AI-facilitated Access to Credit","abstract":"A growing trend in financial technology (fintech) is the use of mobile phone data and machine learning (ML) to provide credit scores- and subsequently, opportunities to access loans- to groups left out of traditional banking. This paper draws on interview data with leaders, investors, and data scientists at fintech companies developing ML-based alternative lending apps in low- and middle-income countries to explore financial inclusion and gender implications. More specifically, it examines how the underlying logics, design choices, and management decisions of ML-based alternative lending tools by fintechs embed or challenge gender biases, and consequently influence gender equity in access to finance. Findings reveal developers follow 'gender blind' approaches, grounded in beliefs that ML is objective and data reflects the truth. This leads to a lack of grappling with the ways data, features for creditworthiness, and access to apps are gendered. Overall, tools increase access to finance, but not gender equitably: Interviewees report less women access loans and receive lower amounts than men, despite being better repayers. Fintechs identify demand- and supply-side reasons for gender differences, but frame them as outside their responsibility. However, that women are observed as better repayers reveals a market inefficiency and potential discriminatory effect, further linked to profit optimization objectives. This research introduces the concept of encoded gender norms, whereby without explicit attention to the gendered nature of data and algorithmic design, AI tools reproduce existing inequalities. In doing so, they reinforce gender norms as self-fulfilling prophecies. The idea that AI is inherently objective and, when left alone, 'fair', is seductive and misleading. In reality, algorithms reflect the perspectives, priorities, and values of the people and institutions that design them.","authors":["Genevieve Smith"],"url":"https://arxiv.org/abs/2504.07312"}
{"created":"2025-04-15","title":"Alice: Proactive Learning with Teacher's Demonstrations for Weak-to-Strong Generalization","abstract":"The growing capabilities of large language models (LLMs) present a key challenge of maintaining effective human oversight. Weak-to-strong generalization (W2SG) offers a promising framework for supervising increasingly capable LLMs using weaker ones. Traditional W2SG methods rely on passive learning, where a weak teacher provides noisy demonstrations to train a strong student. This hinders students from employing their knowledge during training and reaching their full potential. In this work, we introduce Alice (pro{A}ctive {l}earning w{i}th tea{c}her's D{e}monstrations), a framework that leverages complementary knowledge between teacher and student to enhance the learning process. We probe the knowledge base of the teacher model by eliciting their uncertainty, and then use these insights together with teachers' responses as demonstrations to guide student models in self-generating improved responses for supervision. In addition, for situations with significant capability gaps between teacher and student models, we introduce cascade Alice, which employs a hierarchical training approach where weak teachers initially supervise intermediate models, who then guide stronger models in sequence. Experimental results demonstrate that our method significantly enhances the W2SG performance, yielding substantial improvements in three key tasks compared to the original W2SG: knowledge-based reasoning (+4.0%), mathematical reasoning (+22.62%), and logical reasoning (+12.11%). This highlights the effectiveness of our new W2SG paradigm that enables more robust knowledge transfer and supervision outcome.","authors":["Shujin Wu","Cheng Qian","Yi R. Fung","Paul Pu Liang","Heng Ji"],"url":"https://arxiv.org/abs/2504.07316"}
{"created":"2025-04-15","title":"Objaverse++: Curated 3D Object Dataset with Quality Annotations","abstract":"This paper presents Objaverse++, a curated subset of Objaverse enhanced with detailed attribute annotations by human experts. Recent advances in 3D content generation have been driven by large-scale datasets such as Objaverse, which contains over 800,000 3D objects collected from the Internet. Although Objaverse represents the largest available 3D asset collection, its utility is limited by the predominance of low-quality models. To address this limitation, we manually annotate 10,000 3D objects with detailed attributes, including aesthetic quality scores, texture color classifications, multi-object composition flags, transparency characteristics, etc. Then, we trained a neural network capable of annotating the tags for the rest of the Objaverse dataset. Through experiments and a user study on generation results, we demonstrate that models pre-trained on our quality-focused subset achieve better performance than those trained on the larger dataset of Objaverse in image-to-3D generation tasks. In addition, by comparing multiple subsets of training data filtered by our tags, our results show that the higher the data quality, the faster the training loss converges. These findings suggest that careful curation and rich annotation can compensate for the raw dataset size, potentially offering a more efficient path to develop 3D generative models. We release our enhanced dataset of approximately 500,000 curated 3D models to facilitate further research on various downstream tasks in 3D computer vision. In the near future, we aim to extend our annotations to cover the entire Objaverse dataset.","authors":["Chendi Lin","Heshan Liu","Qunshu Lin","Zachary Bright","Shitao Tang","Yihui He","Minghao Liu","Ling Zhu","Cindy Le"],"url":"https://arxiv.org/abs/2504.07334"}
{"created":"2025-04-15","title":"ID-Booth: Identity-consistent Face Generation with Diffusion Models","abstract":"Recent advances in generative modeling have enabled the generation of high-quality synthetic data that is applicable in a variety of domains, including face recognition. Here, state-of-the-art generative models typically rely on conditioning and fine-tuning of powerful pretrained diffusion models to facilitate the synthesis of realistic images of a desired identity. Yet, these models often do not consider the identity of subjects during training, leading to poor consistency between generated and intended identities. In contrast, methods that employ identity-based training objectives tend to overfit on various aspects of the identity, and in turn, lower the diversity of images that can be generated. To address these issues, we present in this paper a novel generative diffusion-based framework, called ID-Booth. ID-Booth consists of a denoising network responsible for data generation, a variational auto-encoder for mapping images to and from a lower-dimensional latent space and a text encoder that allows for prompt-based control over the generation procedure. The framework utilizes a novel triplet identity training objective and enables identity-consistent image generation while retaining the synthesis capabilities of pretrained diffusion models. Experiments with a state-of-the-art latent diffusion model and diverse prompts reveal that our method facilitates better intra-identity consistency and inter-identity separability than competing methods, while achieving higher image diversity. In turn, the produced data allows for effective augmentation of small-scale datasets and training of better-performing recognition models in a privacy-preserving manner. The source code for the ID-Booth framework is publicly available at https://github.com/dariant/ID-Booth.","authors":["Darian Toma\\v{s}evi\\'c","Fadi Boutros","Chenhao Lin","Naser Damer","Vitomir \\v{S}truc","Peter Peer"],"url":"https://arxiv.org/abs/2504.07392"}
{"created":"2025-04-15","title":"LLM-Enabled Data Transmission in End-to-End Semantic Communication","abstract":"Emerging services such as augmented reality (AR) and virtual reality (VR) have increased the volume of data transmitted in wireless communication systems, revealing the limitations of traditional Shannon theory. To address these limitations, semantic communication has been proposed as a solution that prioritizes the meaning of messages over the exact transmission of bits. This paper explores semantic communication for text data transmission in end-to-end (E2E) systems through a novel approach called KG-LLM semantic communication, which integrates knowledge graph (KG) extraction and large language model (LLM) coding. In this method, the transmitter first utilizes a KG to extract key entities and relationships from sentences. The extracted information is then encoded using an LLM to obtain the semantic meaning. On the receiver side, messages are decoded using another LLM, while a bidirectional encoder representations from transformers (i.e., BERT) model further refines the reconstructed sentences for improved semantic similarity. The KG-LLM semantic communication method reduces the transmitted text data volume by 30% through KG-based compression and achieves 84\\% semantic similarity between the original and received messages. This demonstrates the KG-LLM methods efficiency and robustness in semantic communication systems, outperforming the deep learning-based semantic communication model (DeepSC), which achieves only 63%.","authors":["Shavbo Salehi","Melike Erol-Kantarci","Dusit Niyato"],"url":"https://arxiv.org/abs/2504.07431"}
{"created":"2025-04-15","title":"MUFFLER: Secure Tor Traffic Obfuscation with Dynamic Connection Shuffling and Splitting","abstract":"Tor, a widely utilized privacy network, enables anonymous communication but is vulnerable to flow correlation attacks that deanonymize users by correlating traffic patterns from Tor's ingress and egress segments. Various defenses have been developed to mitigate these attacks; however, they have two critical limitations: (i) significant network overhead during obfuscation and (ii) a lack of dynamic obfuscation for egress segments, exposing traffic patterns to adversaries. In response, we introduce MUFFLER, a novel connection-level traffic obfuscation system designed to secure Tor egress traffic. It dynamically maps real connections to a distinct set of virtual connections between the final Tor nodes and targeted services, either public or hidden. This approach creates egress traffic patterns fundamentally different from those at ingress segments without adding intentional padding bytes or timing delays. The mapping of real and virtual connections is adjusted in real-time based on ongoing network conditions, thwarting adversaries' efforts to detect egress traffic patterns. Extensive evaluations show that MUFFLER mitigates powerful correlation attacks with a TPR of 1% at an FPR of 10^-2 while imposing only a 2.17% bandwidth overhead. Moreover, it achieves up to 27x lower latency overhead than existing solutions and seamlessly integrates with the current Tor architecture.","authors":["Minjae Seo","Myoungsung You","Jaehan Kim","Taejune Park","Seungwon Shin","Jinwoo Kim"],"url":"https://arxiv.org/abs/2504.07543"}
{"created":"2025-04-15","title":"VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model","abstract":"Recently DeepSeek R1 has shown that reinforcement learning (RL) can substantially improve the reasoning capabilities of Large Language Models (LLMs) through a simple yet effective design. The core of R1 lies in its rule-based reward formulation, which leverages tasks with deterministic ground-truth answers to enable precise and stable reward computation. In the visual domain, we similarly observe that a wide range of visual understanding tasks are inherently equipped with well-defined ground-truth annotations. This property makes them naturally compatible with rule-based reward mechanisms. Motivated by this observation, we investigate the extension of R1-style reinforcement learning to Vision-Language Models (VLMs), aiming to enhance their visual reasoning capabilities. To this end, we develop VLM-R1, a dedicated framework designed to harness RL for improving VLMs' performance on general vision-language tasks. Using this framework, we further explore the feasibility of applying RL to visual domain. Experimental results indicate that the RL-based model not only delivers competitive performance on visual understanding tasks but also surpasses Supervised Fine-Tuning (SFT) in generalization ability. Furthermore, we conduct comprehensive ablation studies that uncover a series of noteworthy insights, including the presence of reward hacking in object detection, the emergence of the \"OD aha moment\", the impact of training data quality, and the scaling behavior of RL across different model sizes. Through these analyses, we aim to deepen the understanding of how reinforcement learning enhances the capabilities of vision-language models, and we hope our findings and open-source contributions will support continued progress in the vision-language RL community. Our code and model are available at https://github.com/om-ai-lab/VLM-R1","authors":["Haozhan Shen","Peng Liu","Jingcheng Li","Chunxin Fang","Yibo Ma","Jiajia Liao","Qiaoli Shen","Zilun Zhang","Kangjia Zhao","Qianqian Zhang","Ruochen Xu","Tiancheng Zhao"],"url":"https://arxiv.org/abs/2504.07615"}
{"created":"2025-04-15","title":"Kernel Logistic Regression Learning for High-Capacity Hopfield Networks","abstract":"Hebbian learning limits Hopfield network storage capacity (pattern-to-neuron ratio around 0.14). We propose Kernel Logistic Regression (KLR) learning. Unlike linear methods, KLR uses kernels to implicitly map patterns to high-dimensional feature space, enhancing separability. By learning dual variables, KLR dramatically improves storage capacity, achieving perfect recall even when pattern numbers exceed neuron numbers (up to ratio 1.5 shown), and enhances noise robustness. KLR demonstrably outperforms Hebbian and linear logistic regression approaches.","authors":["Akira Tamamori"],"url":"https://arxiv.org/abs/2504.07633"}
{"created":"2025-04-15","title":"Integrated Sensing and Communications for Pinching-Antenna Systems (PASS)","abstract":"An integrated sensing and communication (ISAC) design for pinching antenna systems (PASS) is proposed, where the pinching antennas are deployed for establishing reliable line-of-sight communication and sensing links. More particularly, a separated ISAC design is proposed for the two-waveguide PASS, where one waveguide is used to emit the joint communication and sensing signals while the other waveguide is used to receive the reflected echo signals. Based on this framework, a penalty-based alternating optimization algorithm is proposed to maximize the illumination power as well as ensure the communication quality-of-service requirement. Numerical results demonstrate that 1) the proposed PASS-ISAC scheme outperforms the other baseline schemes, and 2) the considered equal power allocation model achieves an upper bound performance.","authors":["Zheng Zhang","Yuanwei Liu","Bingtao He","Jian Chen"],"url":"https://arxiv.org/abs/2504.07709"}
{"created":"2025-04-15","title":"DG-STMTL: A Novel Graph Convolutional Network for Multi-Task Spatio-Temporal Traffic Forecasting","abstract":"Spatio-temporal traffic prediction is crucial in intelligent transportation systems. The key challenge of accurate prediction is how to model the complex spatio-temporal dependencies and adapt to the inherent dynamics in data. Traditional Graph Convolutional Networks (GCNs) often struggle with static adjacency matrices that introduce domain bias or learnable matrices that may be overfitting to specific patterns. This challenge becomes more complex when considering Multi-Task Learning (MTL). While MTL has the potential to enhance prediction accuracy through task synergies, it can also face significant hurdles due to task interference. To overcome these challenges, this study introduces a novel MTL framework, Dynamic Group-wise Spatio-Temporal Multi-Task Learning (DG-STMTL). DG-STMTL proposes a hybrid adjacency matrix generation module that combines static matrices with dynamic ones through a task-specific gating mechanism. We also introduce a group-wise GCN module to enhance the modelling capability of spatio-temporal dependencies. We conduct extensive experiments on two real-world datasets to evaluate our method. Results show that our method outperforms other state-of-the-arts, indicating its effectiveness and robustness.","authors":["Wanna Cui","Peizheng Wang","Faliang Yin"],"url":"https://arxiv.org/abs/2504.07822"}
{"created":"2025-04-15","title":"Pychop: Emulating Low-Precision Arithmetic in Numerical Methods and Neural Networks","abstract":"Motivated by the growing demand for low-precision arithmetic in computational science, we exploit lower-precision emulation in Python -- widely regarded as the dominant programming language for numerical analysis and machine learning. Low-precision training has revolutionized deep learning by enabling more efficient computation and reduced memory and energy consumption while maintaining model fidelity. To better enable numerical experimentation with and exploration of low precision computation, we developed the Pychop library, which supports customizable floating-point formats and a comprehensive set of rounding modes in Python, allowing users to benefit from fast, low-precision emulation in numerous applications. Pychop also introduces interfaces for both PyTorch and JAX, enabling efficient low-precision emulation on GPUs for neural network training and inference with unparalleled flexibility.","authors":["Erin Carson","Xinye Chen"],"url":"https://arxiv.org/abs/2504.07835"}
{"created":"2025-04-15","title":"CatCMA with Margin: Stochastic Optimization for Continuous, Integer, and Categorical Variables","abstract":"This study focuses on mixed-variable black-box optimization (MV-BBO), addressing continuous, integer, and categorical variables. Many real-world MV-BBO problems involve dependencies among these different types of variables, requiring efficient methods to optimize them simultaneously. Recently, stochastic optimization methods leveraging the mechanism of the covariance matrix adaptation evolution strategy have shown promising results in mixed-integer or mixed-category optimization. However, such methods cannot handle the three types of variables simultaneously. In this study, we propose CatCMA with Margin (CatCMAwM), a stochastic optimization method for MV-BBO that jointly optimizes continuous, integer, and categorical variables. CatCMAwM is developed by incorporating a novel integer handling into CatCMA, a mixed-category black-box optimization method employing a joint distribution of multivariate Gaussian and categorical distributions. The proposed integer handling is carefully designed by reviewing existing integer handlings and following the design principles of CatCMA. Even when applied to mixed-integer problems, it stabilizes the marginal probability and improves the convergence performance of continuous variables. Numerical experiments show that CatCMAwM effectively handles the three types of variables, outperforming state-of-the-art Bayesian optimization methods and baselines that simply incorporate existing integer handlings into CatCMA.","authors":["Ryoki Hamano","Masahiro Nomura","Shota Saito","Kento Uchida","Shinichi Shirakawa"],"url":"https://arxiv.org/abs/2504.07884"}
{"created":"2025-04-15","title":"Task Memory Engine (TME): A Structured Memory Framework with Graph-Aware Extensions for Multi-Step LLM Agent Tasks","abstract":"Large Language Models (LLMs) are increasingly used as autonomous agents for multi-step tasks. However, most existing frameworks fail to maintain a structured understanding of the task state, often relying on linear prompt concatenation or shallow memory buffers. This leads to brittle performance, frequent hallucinations, and poor long-range coherence. In this work, we propose the Task Memory Engine (TME), a lightweight and structured memory module that tracks task execution using a hierarchical Task Memory Tree (TMT). Each node in the tree corresponds to a task step, storing relevant input, output, status, and sub-task relationships. We introduce a prompt synthesis method that dynamically generates LLM prompts based on the active node path, significantly improving execution consistency and contextual grounding. Through case studies and comparative experiments on multi-step agent tasks, we demonstrate that TME leads to better task completion accuracy and more interpretable behavior with minimal implementation overhead. A reference implementation of the core TME components is available at https://github.com/biubiutomato/TME-Agent, including basic examples and structured memory integration. While the current implementation uses a tree-based structure, TME is designed to be graph-aware, supporting reusable substeps, converging task paths, and shared dependencies. This lays the groundwork for future DAG-based memory architectures.","authors":["Ye Ye"],"url":"https://arxiv.org/abs/2504.08525"}
{"created":"2025-04-15","title":"Secondary Safety Control for Systems with Sector Bounded Nonlinearities [Extended Version]","abstract":"We consider the problem of safety verification and safety-aware controller synthesis for systems with sector bounded nonlinearities. We aim to keep the states of the system within a given safe set under potential actuator and sensor attacks. Specifically, we adopt the setup that a controller has already been designed to stabilize the plant. Using invariant sets and barrier certificate theory, we first give sufficient conditions to verify the safety of the closed-loop system under attacks. Furthermore, by using a subset of sensors that are assumed to be free of attacks, we provide a synthesis method for a secondary controller that enhances the safety of the system. The sufficient conditions to verify safety are derived using Lyapunov-based tools and the S-procedure. Using the projection lemma, the conditions are then formulated as linear matrix inequality (LMI) problems which can be solved efficiently. Lastly, our theoretical results are illustrated through numerical simulations.","authors":["Yankai Lin","Michelle S. Chong","Carlos Murguia"],"url":"https://arxiv.org/abs/2504.08535"}
{"created":"2025-04-15","title":"Seismic Facies Analysis: A Deep Domain Adaptation Approach","abstract":"Deep neural networks (DNNs) can learn accurately from large quantities of labeled input data, but often fail to do so when labelled data are scarce. DNNs sometimes fail to generalize ontest data sampled from different input distributions. Unsupervised Deep Domain Adaptation (DDA)techniques have been proven useful when no labels are available, and when distribution shifts are observed in the target domain (TD). In the present study, experiments are performed on seismic images of the F3 block 3D dataset from offshore Netherlands (source domain; SD) and Penobscot 3D survey data from Canada (target domain; TD). Three geological classes from SD and TD that have similar reflection patterns are considered. A deep neural network architecture named EarthAdaptNet (EAN) is proposed to semantically segment the seismic images when few classes have data scarcity, and we use a transposed residual unit to replace the traditional dilated convolution in the decoder block. The EAN achieved a pixel-level accuracy >84% and an accuracy of ~70% for the minority classes, showing improved performance compared to existing architectures. In addition, we introduce the CORAL (Correlation Alignment) method to the EAN to create an unsupervised deep domain adaptation network (EAN-DDA) for the classification of seismic reflections from F3 and Penobscot, to demonstrate possible approaches when labelled data are unavailable. Maximum class accuracy achieved was ~99% for class 2 of Penobscot, with an overall accuracy>50%. Taken together, the EAN-DDA has the potential to classify target domain seismic facies classes with high accuracy.","authors":["M Quamer Nasim","Tannistha Maiti","Ayush Srivastava","Tarry Singh","Jie Mei"],"url":"https://arxiv.org/abs/2011.10510"}
{"created":"2025-04-15","title":"Comments on the holographic description of Narain theories","abstract":"We discuss the holographic description of Narain $U(1)^c\\times U(1)^c$ conformal field theories, and their potential similarity to conventional weakly coupled gravity in the bulk, in the sense that the effective IR bulk description includes \"$U(1)$ gravity\" amended with additional light degrees of freedom. Starting from this picture, we formulate the hypothesis that in the large central charge limit the density of states of any Narain theory is bounded by below by the density of states of $U(1)$ gravity. This immediately implies that the maximal value of the spectral gap for primary fields is $\\Delta_1=c/(2\\pi e)$. To test the self-consistency of this proposal, we study its implications using chiral lattice CFTs and CFTs based on quantum stabilizer codes. First we notice that the conjecture yields a new bound on quantum stabilizer codes, which is compatible with previously known bounds in the literature. We proceed to discuss the variance of the density of states, which for consistency must be vanishingly small in the large-$c$ limit. We consider ensembles of code and chiral theories and show that in both cases the density variance is exponentially small in the central charge.","authors":["Anatoly Dymarsky","Alfred Shapere"],"url":"https://arxiv.org/abs/2012.15830"}
{"created":"2025-04-15","title":"Deep Learning-Based Automatic Diagnosis System for Developmental Dysplasia of the Hip","abstract":"Objective: The clinical diagnosis of developmental dysplasia of the hip (DDH) typically involves manually measuring key radiological angles -- Center-Edge (CE), Tonnis, and Sharp angles -- from pelvic radiographs, a process that is time-consuming and susceptible to variability. This study aims to develop an automated system that integrates these measurements to enhance the accuracy and consistency of DDH diagnosis.","authors":["Yang Li","Leo Yan Li-Han","Hua Tian"],"url":"https://arxiv.org/abs/2209.03440"}
{"created":"2025-04-15","title":"Label-free segmentation from cardiac ultrasound using self-supervised learning","abstract":"Segmentation and measurement of cardiac chambers is critical in cardiac ultrasound but is laborious and poorly reproducible. Neural networks can assist, but supervised approaches require the same laborious manual annotations. We built a pipeline for self-supervised (no manual labels) segmentation combining computer vision, clinical domain knowledge, and deep learning. We trained on 450 echocardiograms (93,000 images) and tested on 8,393 echocardiograms (4,476,266 images; mean 61 years, 51% female), using the resulting segmentations to calculate biometrics. We also tested against external images from an additional 10,030 patients with available manual tracings of the left ventricle. r2 between clinically measured and pipeline-predicted measurements were similar to reported inter-clinician variation and comparable to supervised learning across several different measurements (r2 0.56-0.84). Average accuracy for detecting abnormal chamber size and function was 0.85 (range 0.71-0.97) compared to clinical measurements. A subset of test echocardiograms (n=553) had corresponding cardiac MRIs, where MRI is the gold standard. Correlation between pipeline and MRI measurements was similar to that between clinical echocardiogram and MRI. Finally, the pipeline accurately segments the left ventricle with an average Dice score of 0.89 (95% CI [0.89]) in the external, manually labeled dataset. Our results demonstrate a manual-label free, clinically valid, and highly scalable method for segmentation from ultrasound, a noisy but globally important imaging modality.","authors":["Danielle L. Ferreira","Connor Lau","Zaynaf Salaymang","Rima Arnaout"],"url":"https://arxiv.org/abs/2210.04979"}
{"created":"2025-04-15","title":"A Policy Gradient Framework for Stochastic Optimal Control Problems with Global Convergence Guarantee","abstract":"We consider policy gradient methods for stochastic optimal control problem in continuous time. In particular, we analyze the gradient flow for the control, viewed as a continuous time limit of the policy gradient method. We prove the global convergence of the gradient flow and establish a convergence rate under some regularity assumptions. The main novelty in the analysis is the notion of local optimal control function, which is introduced to characterize the local optimality of the iterate.","authors":["Mo Zhou","Jianfeng Lu"],"url":"https://arxiv.org/abs/2302.05816"}
{"created":"2025-04-15","title":"Moment-based Density Elicitation with Applications in Probabilistic Loops","abstract":"We propose the K-series estimation approach for the recovery of unknown univariate and multivariate distributions given knowledge of a finite number of their moments. Our method is directly applicable to the probabilistic analysis of systems that can be represented as probabilistic loops; i.e., algorithms that express and implement non-deterministic processes ranging from robotics to macroeconomics and biology to software and cyber-physical systems. K-series statically approximates the joint and marginal distributions of a vector of continuous random variables updated in a probabilistic non-nested loop with nonlinear assignments given a finite number of moments of the unknown density. Moreover, K-series automatically derives the distribution of the systems' random variables symbolically as a function of the loop iteration. K-series density estimates are accurate, easy and fast to compute. We demonstrate the feasibility and performance of our approach on multiple benchmark examples from the literature.","authors":["Andrey Kofnov","Ezio Bartocci","Efstathia Bura"],"url":"https://arxiv.org/abs/2304.09094"}
{"created":"2025-04-15","title":"Newton-CG methods for nonconvex unconstrained optimization with H\\\"older continuous Hessian","abstract":"In this paper we consider a nonconvex unconstrained optimization problem minimizing a twice differentiable objective function with H\\\"older continuous Hessian. Specifically, we first propose a Newton-conjugate gradient (Newton-CG) method for finding an approximate first- and second-order stationary point of this problem, assuming the associated the H\\\"older parameters are explicitly known. Then we develop a parameter-free Newton-CG method without requiring any prior knowledge of these parameters. To the best of our knowledge, this method is the first parameter-free second-order method achieving the best-known iteration and operation complexity for finding an approximate first- and second-order stationary point of this problem. Finally, we present preliminary numerical results to demonstrate the superior practical performance of our parameter-free Newton-CG method over a well-known regularized Newton method.","authors":["Chuan He","Heng Huang","Zhaosong Lu"],"url":"https://arxiv.org/abs/2311.13094"}
{"created":"2025-04-15","title":"Artificial Neural Network for Estimation of Physical Parameters of Sea Water using LiDAR Waveforms","abstract":"Light Detection and Ranging (LiDAR) are fast emerging sensors in the field of Earth Observation. It is a remote sensing technology that utilizes laser beams to measure distances and create detailed three-dimensional representations of objects and environments. The potential of Full Waveform LiDAR is much greater than just height estimation and 3D reconstruction only. Overall shape of signal provides important information about properties of water body. However, the shape of FWL is unexplored as most LiDAR software work on point cloud by utilizing the maximum value within the waveform. Existing techniques in the field of LiDAR data analysis include depth estimation through inverse modeling and regression of logarithmic intensity and depth for approximating the attenuation coefficient. However, these methods suffer from limitations in accuracy. Depth estimation through inverse modeling provides only approximate values and does not account for variations in surface properties, while the regression approach for the attenuation coefficient is only able to generalize a value through several data points which lacks precision and may lead to significant errors in estimation. Additionally, there is currently no established modeling method available for predicting bottom reflectance. This research proposed a novel solution based on neural networks for parameter estimation in LIDAR data analysis. By leveraging the power of neural networks, the proposed solution successfully learned the inversion model, was able to do prediction of parameters such as depth, attenuation coefficient, and bottom reflectance. Performance of model was validated by testing it on real LiDAR data. In future, more data availability would enable more accuracy and reliability of such models.","authors":["Saad Ahmed Jamal"],"url":"https://arxiv.org/abs/2312.10068"}
{"created":"2025-04-15","title":"Majority voting is not good for heaven or hell, with mirrored performance","abstract":"Within the ViSE (Voting in Stochastic Environment) model, we study the effectiveness of majority voting in various environments. By the pit of losses paradox identified in previous work, majority decisions in apparently hostile environments tend to reduce the capital of society. In such cases, the simple social decision rule of \"rejecting all proposals without voting\" outperforms majority voting. In this paper, we identify another pit of losses appearing in favorable environments. Here, the simple social decision rule of \"accepting all proposals without voting\" is superior to majority voting. We prove that under a version of simple majority called symmetrized majority and the antisymmetry of the voting body, the second pit of losses is a mirror image of the pit of losses in hostile environments and explain this phenomenon. Technically, we consider a voting society consisting of individualists whose strategy is supporting all proposals that increase their capital and a group (groups) whose members vote to increase the wealth of their group. According to the main result, the expected capital gain of each agent in the environment whose generator $X$ has mean $\\mu>0$ exceeds by $\\mu$ their expected capital gain under generator $-X$. This result extends to location families of generators with distributions symmetric about their mean. The mentioned result determines the symmetry of the difference between the expected capital gain under the symmetrized majority and that under the \"basic\" social decision rule that rejects (resp. accepts) all proposals in unfavorable (resp. favorable) environments.","authors":["Pavel Chebotarev","Vadim Afonkin"],"url":"https://arxiv.org/abs/2401.00592"}
{"created":"2025-04-15","title":"Boosting Column Generation with Graph Neural Networks for Joint Rider Trip Planning and Crew Shift Scheduling","abstract":"Optimizing service schedules is pivotal to the reliable, efficient, and inclusive on-demand mobility. This pressing challenge is further exacerbated by the increasing needs of an aging population, the oversubscription of existing services, and the lack of effective solution methods. This study addresses the intricacies of service scheduling, by jointly optimizing rider trip planning and crew scheduling for a complex dynamic mobility service. The resulting optimization problems are extremely challenging computationally for state-of-the-art methods. To address this fundamental gap, this paper introduces the Joint Rider Trip Planning and Crew Shift Scheduling Problem (JRTPCSSP) and a novel solution method, called Attention and Gated GNN-Informed Column Generation (AGGNNI-CG), that hybridizes column generation and machine learning to obtain near-optimal solutions to the JRTPCSSP with real-life constraints of the application. The key idea of the machine-learning component is to dramatically reduce the number of paths to explore in the pricing problem, accelerating the most time-consuming component of the column generation. The machine learning component is a graph neural network with an attention mechanism and a gated architecture, which is particularly suited to cater for the different input sizes coming from daily operations. AGGNNI-CG has been applied to a challenging, real-world dataset from the Paratransit system of Chatham County in Georgia. It produces substantial improvements compared to the baseline column generation approach, which typically cannot produce high-quality feasible solutions in reasonable time on large-scale complex instances. AGGNNI-CG also produces significant improvements in service quality compared to the existing system.","authors":["Jiawei Lu","Tinghan Ye","Wenbo Chen","Pascal Van Hentenryck"],"url":"https://arxiv.org/abs/2401.03692"}
{"created":"2025-04-15","title":"Membership problems in nilpotent groups","abstract":"We study both the Submonoid Membership problem and the Rational Subset Membership problem in finitely generated nilpotent groups. We give two reductions with important applications. First, Submonoid Membership in any nilpotent group can be reduced to Rational Subset Membership in smaller groups. As a corollary, we prove the existence of a group with decidable Submonoid Membership and undecidable Rational Subset Membership, confirming a conjecture of Lohrey and Steinberg. Second, the Rational Subset Membership problem in $H_3(\\mathbb Z)$ can be reduced to the Knapsack problem in the same group, and is therefore decidable. Combining both results, we deduce that the filiform $3$-step nilpotent group has decidable Submonoid Membership.","authors":["Corentin Bodart"],"url":"https://arxiv.org/abs/2401.15504"}
{"created":"2025-04-15","title":"Q-Newton: Hybrid Quantum-Classical Scheduling for Accelerating Neural Network Training with Newton's Gradient Descent","abstract":"Optimization techniques in deep learning are predominantly led by first-order gradient methodologies, such as SGD. However, neural network training can greatly benefit from the rapid convergence characteristics of second-order optimization. Newton's GD stands out in this category, by rescaling the gradient using the inverse Hessian. Nevertheless, one of its major bottlenecks is matrix inversion, which is notably time-consuming in $O(N^3)$ time with weak scalability.","authors":["Pingzhi Li","Junyu Liu","Hanrui Wang","Tianlong Chen"],"url":"https://arxiv.org/abs/2405.00252"}
{"created":"2025-04-15","title":"Joint semi-supervised and contrastive learning enables domain generalization and multi-domain segmentation","abstract":"Despite their effectiveness, current deep learning models face challenges with images coming from different domains with varying appearance and content. We introduce SegCLR, a versatile framework designed to segment images across different domains, employing supervised and contrastive learning simultaneously to effectively learn from both labeled and unlabeled data. We demonstrate the superior performance of SegCLR through a comprehensive evaluation involving three diverse clinical datasets of 3D retinal Optical Coherence Tomography (OCT) images, for the slice-wise segmentation of fluids with various network configurations and verification across 10 different network initializations. In an unsupervised domain adaptation context, SegCLR achieves results on par with a supervised upper-bound model trained on the intended target domain. Notably, we discover that the segmentation performance of SegCLR framework is marginally impacted by the abundance of unlabeled data from the target domain, thereby we also propose an effective domain generalization extension of SegCLR, known also as zero-shot domain adaptation, which eliminates the need for any target domain information. This shows that our proposed addition of contrastive loss in standard supervised training for segmentation leads to superior models, inherently more generalizable to both in- and out-of-domain test data. We additionally propose a pragmatic solution for SegCLR deployment in realistic scenarios with multiple domains containing labeled data. Accordingly, our framework pushes the boundaries of deep-learning based segmentation in multi-domain applications, regardless of data availability - labeled, unlabeled, or nonexistent.","authors":["Alvaro Gomariz","Yusuke Kikuchi","Yun Yvonna Li","Thomas Albrecht","Andreas Maunz","Daniela Ferrara","Huanxiang Lu","Orcun Goksel"],"url":"https://arxiv.org/abs/2405.05336"}
{"created":"2025-04-15","title":"Thermodynamic limit in learning period three","abstract":"A continuous one-dimensional map with period three includes all periods. This raises the following question: Can we obtain any types of periodic orbits solely by learning three data points? In this paper, we report the answer to be yes. Considering a random neural network in its thermodynamic limit, we first show that almost all learned periods are unstable, and each network has its own characteristic attractors (which can even be untrained ones). The latently acquired dynamics, which are unstable within the trained network, serve as a foundation for the diversity of characteristic attractors and may even lead to the emergence of attractors of all periods after learning. When the neural network interpolation is quadratic, a universal post-learning bifurcation scenario appears, which is consistent with a topological conjugacy between the trained network and the classical logistic map. In addition to universality, we explore specific properties of certain networks, including the singular behavior of the scale of weight at the infinite limit, the finite-size effects, and the symmetry in learning period three.","authors":["Yuichiro Terasaki","Kohei Nakajima"],"url":"https://arxiv.org/abs/2405.08825"}
{"created":"2025-04-15","title":"Contribute to balance, wire in accordance: Emergence of backpropagation from a simple, bio-plausible neuroplasticity rule","abstract":"Backpropagation (BP) has been pivotal in advancing machine learning and remains essential in computational applications and comparative studies of biological and artificial neural networks. Despite its widespread use, the implementation of BP in the brain remains elusive, and its biological plausibility is often questioned due to inherent issues such as the need for symmetry of weights between forward and backward connections, and the requirement of distinct forward and backward phases of computation. Here, we introduce a novel neuroplasticity rule that offers a potential mechanism for implementing BP in the brain. Similar in general form to the classical Hebbian rule, this rule is based on the core principles of maintaining the balance of excitatory and inhibitory inputs as well as on retrograde signaling, and operates over three progressively slower timescales: neural firing, retrograde signaling, and neural plasticity. We hypothesize that each neuron possesses an internal state, termed credit, in addition to its firing rate. After achieving equilibrium in firing rates, neurons receive credits based on their contribution to the E-I balance of postsynaptic neurons through retrograde signaling. As the network's credit distribution stabilizes, connections from those presynaptic neurons are strengthened that significantly contribute to the balance of postsynaptic neurons. We demonstrate mathematically that our learning rule precisely replicates BP in layered neural networks without any approximations. Simulations on artificial neural networks reveal that this rule induces varying community structures in networks, depending on the learning rate. This simple theoretical framework presents a biologically plausible implementation of BP, with testable assumptions and predictions that may be evaluated through biological experiments.","authors":["Xinhao Fan","Shreesh P Mysore"],"url":"https://arxiv.org/abs/2405.14139"}
{"created":"2025-04-15","title":"Towards A Generalizable Pathology Foundation Model via Unified Knowledge Distillation","abstract":"Foundation models pretrained on large-scale datasets are revolutionizing the field of computational pathology (CPath). The generalization ability of foundation models is crucial for the success in various downstream clinical tasks. However, current foundation models have only been evaluated on a limited type and number of tasks, leaving their generalization ability and overall performance unclear. To address this gap, we established a most comprehensive benchmark to evaluate the performance of off-the-shelf foundation models across six distinct clinical task types, encompassing a total of 72 specific tasks, including slide-level classification, survival prediction, ROI-tissue classification, ROI retrieval, visual question answering, and report generation. Our findings reveal that existing foundation models excel at certain task types but struggle to effectively handle the full breadth of clinical tasks. To improve the generalization of pathology foundation models, we propose a unified knowledge distillation framework consisting of both expert and self-knowledge distillation, where the former allows the model to learn from the knowledge of multiple expert models, while the latter leverages self-distillation to enable image representation learning via local-global alignment. Based on this framework, we curated a dataset of 96,000 whole slide images (WSIs) and developed a Generalizable Pathology Foundation Model (GPFM). This advanced model was trained on a substantial dataset comprising 190 million images extracted from approximately 72,000 publicly available slides, encompassing 34 major tissue types. Evaluated on the established benchmark, GPFM achieves an impressive average rank of 1.6, with 42 tasks ranked 1st, while the second-best model, UNI, attains an average rank of 3.7, with only 6 tasks ranked 1st.","authors":["Jiabo Ma","Zhengrui Guo","Fengtao Zhou","Yihui Wang","Yingxue Xu","Jinbang Li","Fang Yan","Yu Cai","Zhengjie Zhu","Cheng Jin","Yi Lin","Xinrui Jiang","Chenglong Zhao","Danyi Li","Anjia Han","Zhenhui Li","Ronald Cheong Kin Chan","Jiguang Wang","Peng Fei","Kwang-Ting Cheng","Shaoting Zhang","Li Liang","Hao Chen"],"url":"https://arxiv.org/abs/2407.18449"}
{"created":"2025-04-15","title":"Oscillatory and Excitable Dynamics in an Opinion Model with Group Opinions","abstract":"In traditional models of opinion dynamics, each agent in a network has an opinion and changes in opinions arise from pairwise (i.e., dyadic) interactions between agents. However, in many situations, groups of individuals possess a collective opinion that can differ from the opinions of its constituent individuals. In this paper, we study the effects of group opinions on opinion dynamics. We formulate a hypergraph model in which both individual agents and groups of 3 agents have opinions, and we examine how opinions evolve through both dyadic interactions and group memberships. In some parameter regimes, we find that the presence of group opinions can lead to oscillatory and excitable opinion dynamics. In the oscillatory regime, the mean opinion of the agents in a network has self-sustained oscillations. In the excitable regime, finite-size effects create large but short-lived opinion swings (as in social fads). We develop a mean-field approximation of our model and obtain good agreement with direct numerical simulations. We also show -- both numerically and via our mean-field description -- that oscillatory dynamics occur only when the number of dyadic and polyadic interactions per agent are not completely correlated. Our results illustrate how polyadic structures, such as groups of agents, can have important effects on collective opinion dynamics.","authors":["Corbit R. Sampson","Juan G. Restrepo","Mason A. Porter"],"url":"https://arxiv.org/abs/2408.13336"}
{"created":"2025-04-15","title":"Integrated Brain Connectivity Analysis with fMRI, DTI, and sMRI Powered by Interpretable Graph Neural Networks","abstract":"Multimodal neuroimaging modeling has becomes a widely used approach but confronts considerable challenges due to heterogeneity, which encompasses variability in data types, scales, and formats across modalities. This variability necessitates the deployment of advanced computational methods to integrate and interpret these diverse datasets within a cohesive analytical framework. In our research, we amalgamate functional magnetic resonance imaging, diffusion tensor imaging, and structural MRI into a cohesive framework. This integration capitalizes on the unique strengths of each modality and their inherent interconnections, aiming for a comprehensive understanding of the brain's connectivity and anatomical characteristics. Utilizing the Glasser atlas for parcellation, we integrate imaging derived features from various modalities: functional connectivity from fMRI, structural connectivity from DTI, and anatomical features from sMRI within consistent regions. Our approach incorporates a masking strategy to differentially weight neural connections, thereby facilitating a holistic amalgamation of multimodal imaging data. This technique enhances interpretability at connectivity level, transcending traditional analyses centered on singular regional attributes. The model is applied to the Human Connectome Project's Development study to elucidate the associations between multimodal imaging and cognitive functions throughout youth. The analysis demonstrates improved predictive accuracy and uncovers crucial anatomical features and essential neural connections, deepening our understanding of brain structure and function.","authors":["Gang Qu","Ziyu Zhou","Vince D. Calhoun","Aiying Zhang","Yu-Ping Wang"],"url":"https://arxiv.org/abs/2408.14254"}
{"created":"2025-04-15","title":"A Primer on Variational Inference for Physics-Informed Deep Generative Modelling","abstract":"Variational inference (VI) is a computationally efficient and scalable methodology for approximate Bayesian inference. It strikes a balance between accuracy of uncertainty quantification and practical tractability. It excels at generative modelling and inversion tasks due to its built-in Bayesian regularisation and flexibility, essential qualities for physics related problems. For such problems, the underlying physical model determines the dependence between variables of interest, which in turn will require a tailored derivation for the central VI learning objective. Furthermore, in many physical inference applications this structure has rich meaning and is essential for accurately capturing the dynamics of interest. In this paper, we provide an accessible and thorough technical introduction to VI for forward and inverse problems, guiding the reader through standard derivations of the VI framework and how it can best be realized through deep learning. We then review and unify recent literature exemplifying the flexibility allowed by VI. This paper is designed for a general scientific audience looking to solve physics-based problems with an emphasis on uncertainty quantification","authors":["Alex Glyn-Davies","Arnaud Vadeboncoeur","O. Deniz Akyildiz","Ieva Kazlauskaite","Mark Girolami"],"url":"https://arxiv.org/abs/2409.06560"}
{"created":"2025-04-15","title":"Evaluating probabilistic and data-driven inference models for fiber-coupled NV-diamond temperature sensors","abstract":"We evaluate the impact of inference model on uncertainties when using continuous wave Optically Detected Magnetic Resonance (ODMR) measurements to infer temperature. Our approach leverages a probabilistic feedforward inference model designed to maximize the likelihood of observed ODMR spectra through automatic differentiation. This model effectively utilizes the temperature dependence of spin Hamiltonian parameters to infer temperature from spectral features in the ODMR data. We achieve prediction uncertainty of $\\pm$ 1 K across a temperature range of 243 K to 323 K. To benchmark our probabilistic model, we compare it with a non-parametric peak-finding technique and data-driven methodologies such as Principal Component Regression (PCR) and a 1D Convolutional Neural Network (CNN). We find that when validated against out-of-sample dataset that encompasses the same temperature range as the training dataset, data driven methods can show uncertainties that are as much as 0.67 K lower without incorporating expert-level understanding of the spectroscopic-temperature relationship. However, our results show that the probabilistic model outperforms both PCR and CNN when tasked with extrapolating beyond the temperature range used in training set, indicating robustness and generalizability. In contrast, data-driven methods like PCR and CNN demonstrate up to ten times worse uncertainties when tasked with extrapolating outside their training data range.","authors":["Shraddha Rajpal","Zeeshan Ahmed","Tyrus Berry"],"url":"https://arxiv.org/abs/2409.09487"}
{"created":"2025-04-15","title":"Language-based Audio Moment Retrieval","abstract":"In this paper, we propose and design a new task called audio moment retrieval (AMR). Unlike conventional language-based audio retrieval tasks that search for short audio clips from an audio database, AMR aims to predict relevant moments in untrimmed long audio based on a text query. Given the lack of prior work in AMR, we first build a dedicated dataset, Clotho-Moment, consisting of large-scale simulated audio recordings with moment annotations. We then propose a DETR-based model, named Audio Moment DETR (AM-DETR), as a fundamental framework for AMR tasks. This model captures temporal dependencies within audio features, inspired by similar video moment retrieval tasks, thus surpassing conventional clip-level audio retrieval methods. Additionally, we provide manually annotated datasets to properly measure the effectiveness and robustness of our methods on real data. Experimental results show that AM-DETR, trained with Clotho-Moment, outperforms a baseline model that applies a clip-level audio retrieval method with a sliding window on all metrics, particularly improving Recall1@0.7 by 9.00 points. Our datasets and code are publicly available in https://h-munakata.github.io/Language-based-Audio-Moment-Retrieval.","authors":["Hokuto Munakata","Taichi Nishimura","Shota Nakada","Tatsuya Komatsu"],"url":"https://arxiv.org/abs/2409.15672"}
{"created":"2025-04-15","title":"Automatic debiasing of neural networks via moment-constrained learning","abstract":"Causal and nonparametric estimands in economics and biostatistics can often be viewed as the mean of a linear functional applied to an unknown outcome regression function. Naively learning the regression function and taking a sample mean of the target functional results in biased estimators, and a rich debiasing literature has developed where one additionally learns the so-called Riesz representer (RR) of the target estimand (targeted learning, double ML, automatic debiasing etc.). Learning the RR via its derived functional form can be challenging, e.g. due to extreme inverse probability weights or the need to learn conditional density functions. Such challenges have motivated recent advances in automatic debiasing (AD), where the RR is learned directly via minimization of a bespoke loss. We propose moment-constrained learning as a new RR learning approach that addresses some shortcomings in AD, constraining the predicted moments and improving the robustness of RR estimates to optimization hyperparamters. Though our approach is not tied to a particular class of learner, we illustrate it using neural networks, and evaluate on the problems of average treatment/derivative effect estimation using semi-synthetic data. Our numerical experiments show improved performance versus state of the art benchmarks.","authors":["Christian L. Hines","Oliver J. Hines"],"url":"https://arxiv.org/abs/2409.19777"}
{"created":"2025-04-15","title":"Robust Barycenter Estimation using Semi-Unbalanced Neural Optimal Transport","abstract":"Aggregating data from multiple sources can be formalized as an Optimal Transport (OT) barycenter problem, which seeks to compute the average of probability distributions with respect to OT discrepancies. However, in real-world scenarios, the presence of outliers and noise in the data measures can significantly hinder the performance of traditional statistical methods for estimating OT barycenters. To address this issue, we propose a novel scalable approach for estimating the robust continuous barycenter, leveraging the dual formulation of the (semi-)unbalanced OT problem. To the best of our knowledge, this paper is the first attempt to develop an algorithm for robust barycenters under the continuous distribution setup. Our method is framed as a min-max optimization problem and is adaptable to general cost functions. We rigorously establish the theoretical underpinnings of the proposed method and demonstrate its robustness to outliers and class imbalance through a number of illustrative experiments. Our source code is publicly available at https://github.com/milenagazdieva/U-NOTBarycenters.","authors":["Milena Gazdieva","Jaemoo Choi","Alexander Kolesov","Jaewoong Choi","Petr Mokrov","Alexander Korotin"],"url":"https://arxiv.org/abs/2410.03974"}
{"created":"2025-04-15","title":"Consensus in Multiagent Systems under communication failure","abstract":"We consider multi-agent systems with cooperative interactions and study the convergence to consensus in the case of time-dependent connections, with possible communication failure.","authors":["Mohamed Bentaibi","Laura Caravenna","Jean-Paul A. Gauthier","Francesco Rossi"],"url":"https://arxiv.org/abs/2410.10486"}
{"created":"2025-04-15","title":"Learned Reference-based Diffusion Sampling for multi-modal distributions","abstract":"Over the past few years, several approaches utilizing score-based diffusion have been proposed to sample from probability distributions, that is without having access to exact samples and relying solely on evaluations of unnormalized densities. The resulting samplers approximate the time-reversal of a noising diffusion process, bridging the target distribution to an easy-to-sample base distribution. In practice, the performance of these methods heavily depends on key hyperparameters that require ground truth samples to be accurately tuned. Our work aims to highlight and address this fundamental issue, focusing in particular on multi-modal distributions, which pose significant challenges for existing sampling methods. Building on existing approaches, we introduce Learned Reference-based Diffusion Sampler (LRDS), a methodology specifically designed to leverage prior knowledge on the location of the target modes in order to bypass the obstacle of hyperparameter tuning. LRDS proceeds in two steps by (i) learning a reference diffusion model on samples located in high-density space regions and tailored for multimodality, and (ii) using this reference model to foster the training of a diffusion-based sampler. We experimentally demonstrate that LRDS best exploits prior knowledge on the target distribution compared to competing algorithms on a variety of challenging distributions.","authors":["Maxence Noble","Louis Grenioux","Marylou Gabri\\'e","Alain Oliviero Durmus"],"url":"https://arxiv.org/abs/2410.19449"}
{"created":"2025-04-15","title":"Towards safe Bayesian optimization with Wiener kernel regression","abstract":"Bayesian Optimization (BO) is a data-driven strategy for minimizing/maximizing black-box functions based on probabilistic surrogate models. In the presence of safety constraints, the performance of BO crucially relies on tight probabilistic error bounds related to the uncertainty surrounding the surrogate model. For the case of Gaussian Process surrogates and Gaussian measurement noise, we present a novel error bound based on the recently proposed Wiener kernel regression. We prove that under rather mild assumptions, the proposed error bound is tighter than bounds previously documented in the literature, leading to enlarged safety regions. We draw upon a numerical example to demonstrate the efficacy of the proposed error bound in safe BO.","authors":["Oleksii Molodchyk","Johannes Teutsch","Timm Faulwasser"],"url":"https://arxiv.org/abs/2411.02253"}
{"created":"2025-04-15","title":"Thunderscapes: Simulating the Dynamics of Mesoscale Convective System","abstract":"A Mesoscale Convective System (MCS) is a collection of thunderstorms operating as a unified system, showcasing nature's untamed power. They represent a phenomenon widely referenced in both the natural sciences and the visual effects (VFX) industries.However, in computer graphics, visually accurate simulation of MCS dynamics remains a significant challenge due to the inherent complexity of atmospheric microphysical processes.To achieve a high level of visual quality while ensuring practical performance, we introduce Thunderscapes, the first physically based simulation framework for visually realistic MCS tailored to graphical applications.Our model integrates mesoscale cloud microphysics with hydrometeor electrification processes to simulate thunderstorm development and lightning flashes. By capturing various thunderstorm types and their associated lightning activities, Thunderscapes demonstrates the versatility and physical accuracy of the proposed approach.","authors":["Tianchen Hao"],"url":"https://arxiv.org/abs/2412.00703"}
{"created":"2025-04-15","title":"Algebraic properties of Indigenous semirings","abstract":"In this paper, we introduce Indigenous semirings and show that they are examples of information algebras. We also attribute a graph to them and discuss their diameters, girths, and clique numbers. On the other hand, we prove that the Zariski topology of any Indigenous semiring is the Sierpi\\'{n}ski space. Next, we investigate their algebraic properties (including ideal theory). In the last section, we characterize units and idempotent elements of formal power series over Indigenous semirings.","authors":["Hussein Behzadipour","Henk Koppelaar","Peyman Nasehpour"],"url":"https://arxiv.org/abs/2412.02118"}
{"created":"2025-04-15","title":"CBraMod: A Criss-Cross Brain Foundation Model for EEG Decoding","abstract":"Electroencephalography (EEG) is a non-invasive technique to measure and record brain electrical activity, widely used in various BCI and healthcare applications. Early EEG decoding methods rely on supervised learning, limited by specific tasks and datasets, hindering model performance and generalizability. With the success of large language models, there is a growing body of studies focusing on EEG foundation models. However, these studies still leave challenges: Firstly, most of existing EEG foundation models employ full EEG modeling strategy. It models the spatial and temporal dependencies between all EEG patches together, but ignores that the spatial and temporal dependencies are heterogeneous due to the unique structural characteristics of EEG signals. Secondly, existing EEG foundation models have limited generalizability on a wide range of downstream BCI tasks due to varying formats of EEG data, making it challenging to adapt to. To address these challenges, we propose a novel foundation model called CBraMod. Specifically, we devise a criss-cross transformer as the backbone to thoroughly leverage the structural characteristics of EEG signals, which can model spatial and temporal dependencies separately through two parallel attention mechanisms. And we utilize an asymmetric conditional positional encoding scheme which can encode positional information of EEG patches and be easily adapted to the EEG with diverse formats. CBraMod is pre-trained on a very large corpus of EEG through patch-based masked EEG reconstruction. We evaluate CBraMod on up to 10 downstream BCI tasks (12 public datasets). CBraMod achieves the state-of-the-art performance across the wide range of tasks, proving its strong capability and generalizability. The source code is publicly available at https://github.com/wjq-learning/CBraMod.","authors":["Jiquan Wang","Sha Zhao","Zhiling Luo","Yangxuan Zhou","Haiteng Jiang","Shijian Li","Tao Li","Gang Pan"],"url":"https://arxiv.org/abs/2412.07236"}
{"created":"2025-04-15","title":"Identifying Quantum Mechanical Statistics in Italian Corpora","abstract":"We present a theoretical and empirical investigation of the statistical behaviour of the words in a text produced by human language. To this aim, we analyse the word distribution of various texts of Italian language selected from a specific literary corpus. We firstly generalise a theoretical framework elaborated by ourselves to identify 'quantum mechanical statistics' in large-size texts. Then, we show that, in all analysed texts, words distribute according to 'Bose--Einstein statistics' and show significant deviations from 'Maxwell--Boltzmann statistics'. Next, we introduce an effect of 'word randomization' which instead indicates that the difference between the two statistical models is not as pronounced as in the original cases. These results confirm the empirical patterns obtained in texts of English language and strongly indicate that identical words tend to 'clump together' as a consequence of their meaning, which can be explained as an effect of 'quantum entanglement' produced through a phenomenon of 'contextual updating'. More, word randomization can be seen as the linguistic-conceptual equivalent of an increase of temperature which destroys 'coherence' and makes classical statistics prevail over quantum statistics. Some insights into the origin of quantum statistics in physics are finally provided.","authors":["Diederik Aerts","Jonito Aerts Argu\\\"elles","Lester Beltran","Massimiliano Sassoli de Bianchi","Sandro Sozzo"],"url":"https://arxiv.org/abs/2412.07919"}
{"created":"2025-04-15","title":"Ask for More Than Bayes Optimal: A Theory of Indecisions for Classification","abstract":"Selective classification is a powerful tool for automated decision-making in high-risk scenarios, allowing classifiers to make only highly confident decisions while abstaining when uncertainty is too high. Given a target classification accuracy, our goal is to minimize the number of indecisions, which are observations that we do not automate. For problems that are hard, the target accuracy may not be achievable without using indecisions. In contrast, by using indecisions, we are able to control the misclassification rate to any user-specified level, even below the Bayes optimal error rate, while minimizing the frequency of identifying an indecision. We provide a full characterization of the minimax risk in selective classification, proving key continuity and monotonicity properties that enable optimal indecision selection. Our results extend to hypothesis testing, where we control type II error given a fixed type I error, introducing a novel perspective in selective inference. We analyze the impact of estimating the regression function $\\eta$, showing that plug-in classifiers remain consistent and that accuracy-based calibration effectively controls indecision levels. Additionally, we develop finite-sample calibration methods and identify cases where no training data is needed under the Monotone Likelihood Ratio (MLR) property. In the binary Gaussian mixture model, we establish sharp phase transition results, demonstrating that minimal indecisions can yield near-optimal accuracy even with suboptimal class separation. These findings highlight the potential of selective classification to significantly reduce misclassification rates with a relatively small cost in terms of indecisions.","authors":["Mohamed Ndaoud","Peter Radchenko","Bradley Rava"],"url":"https://arxiv.org/abs/2412.12807"}
{"created":"2025-04-15","title":"Ultra-Low Complexity On-Orbit Compression for Remote Sensing Imagery via Block Modulated Imaging","abstract":"The growing field of remote sensing faces a challenge: the ever-increasing size and volume of imagery data are exceeding the storage and transmission capabilities of satellite platforms. Efficient compression of remote sensing imagery is a critical solution to alleviate these burdens on satellites. However, existing compression methods are often too computationally expensive for satellites. With the continued advancement of compressed sensing theory, single-pixel imaging emerges as a powerful tool that brings new possibilities for on-orbit image compression. However, it still suffers from prolonged imaging times and the inability to perform high-resolution imaging, hindering its practical application. This paper advances the study of compressed sensing in remote sensing image compression, proposing Block Modulated Imaging (BMI). By requiring only a single exposure, BMI significantly enhances imaging acquisition speeds. Additionally, BMI obviates the need for digital micromirror devices and surpasses limitations in image resolution. Furthermore, we propose a novel decoding network specifically designed to reconstruct images compressed under the BMI framework. Leveraging the gated 3D convolutions and promoting efficient information flow across stages through a Two-Way Cross-Attention module, our decoding network exhibits demonstrably superior reconstruction performance. Extensive experiments conducted on multiple renowned remote sensing datasets unequivocally demonstrate the efficacy of our proposed method. To further validate its practical applicability, we developed and tested a prototype of the BMI-based camera, which has shown promising potential for on-orbit image compression. The code is available at https://github.com/Johnathan218/BMNet.","authors":["Zhibin Wang","Yanxin Cai","Jiayi Zhou","Yangming Zhang","Tianyu Li","Wei Li","Xun Liu","Guoqing Wang","Yang Yang"],"url":"https://arxiv.org/abs/2412.18417"}
{"created":"2025-04-15","title":"Causal machine learning for heterogeneous treatment effects in the presence of missing outcome data","abstract":"When estimating heterogeneous treatment effects, missing outcome data can complicate treatment effect estimation, causing certain subgroups of the population to be poorly represented. In this work, we discuss this commonly overlooked problem and consider the impact that missing at random (MAR) outcome data has on causal machine learning estimators for the conditional average treatment effect (CATE). We propose two de-biased machine learning estimators for the CATE, the mDR-learner and mEP-learner, which address the issue of under-representation by integrating inverse probability of censoring weights into the DR-learner and EP-learner respectively. We show that under reasonable conditions, these estimators are oracle efficient, and illustrate their favorable performance through simulated data settings, comparing them to existing CATE estimators, including comparison to estimators which use common missing data techniques. We present an example of their application using the GBSG2 trial, exploring treatment effect heterogeneity when comparing hormonal therapies to non-hormonal therapies among breast cancer patients post surgery, and offer guidance on the decisions a practitioner must make when implementing these estimators.","authors":["Matthew Pryce","Karla Diaz-Ordaz","Ruth H. Keogh","Stijn Vansteelandt"],"url":"https://arxiv.org/abs/2412.19711"}
{"created":"2025-04-15","title":"LSQCA: Resource-Efficient Load/Store Architecture for Limited-Scale Fault-Tolerant Quantum Computing","abstract":"Current fault-tolerant quantum computer (FTQC) architectures utilize several encoding techniques to enable reliable logical operations with restricted qubit connectivity. However, such logical operations demand additional memory overhead to ensure fault tolerance. Since the main obstacle to practical quantum computing is the limited qubit count, our primary mission is to design floorplans that can reduce memory overhead without compromising computational capability. Despite extensive efforts to explore FTQC architectures, even the current state-of-the-art floorplan strategy devotes 50% of memory space to this overhead, not to data storage, to ensure unit-time random access to all logical qubits.","authors":["Takumi Kobori","Yasunari Suzuki","Yosuke Ueno","Teruo Tanimoto","Synge Todo","Yuuki Tokunaga"],"url":"https://arxiv.org/abs/2412.20486"}
{"created":"2025-04-15","title":"Predicting Crack Nucleation and Propagation in Brittle Materials Using Deep Operator Networks with Diverse Trunk Architectures","abstract":"Phase-field modeling reformulates fracture problems as energy minimization problems and enables a comprehensive characterization of the fracture process, including crack nucleation, propagation, merging, and branching, without relying on ad-hoc assumptions. However, the numerical solution of phase-field fracture problems is characterized by a high computational cost. To address this challenge, in this paper, we employ a deep neural operator (DeepONet) consisting of a branch network and a trunk network to solve brittle fracture problems. We explore three distinct approaches that vary in their trunk network configurations. In the first approach, we demonstrate the effectiveness of a two-step DeepONet, which results in a simplification of the learning task. In the second approach, we employ a physics-informed DeepONet, whereby the mathematical expression of the energy is integrated into the trunk network's loss to enforce physical consistency. The integration of physics also results in a substantially smaller data size needed for training. In the third approach, we replace the neural network in the trunk with a Kolmogorov-Arnold Network and train it without the physics loss. Using these methods, we model crack nucleation in a one-dimensional homogeneous bar under prescribed end displacements, as well as crack propagation and branching in single edge-notched specimens with varying notch lengths subjected to tensile and shear loading. We show that the networks predict the solution fields accurately, and the error in the predicted fields is localized near the crack.","authors":["Elham Kiyani (Division of Applied Mathematics","Brown University","Providence","RI","USA)","Manav Manav (Department of Mechanical and Process Engineering","ETH Zurich","Zurich","Switzerland)","Nikhil Kadivar (School of Engineering","Providence","RI","USA)","Laura De Lorenzis (Department of Mechanical and Process Engineering","ETH Zurich","Zurich","Switzerland)","George Em Karniadakis (Division of Applied Mathematics","Brown University","Providence","RI","USA)"],"url":"https://arxiv.org/abs/2501.00016"}
{"created":"2025-04-15","title":"Electrical networks and data analysis in phylogenetics","abstract":"A classic problem in data analysis is studying the systems of subsets defined by either a similarity or a dissimilarity function on $X$ which is either observed directly or derived from a data set. For an electrical network there are two functions on the set of the nodes defined by the resistance matrix and the response matrix either of which defines the network completely. We argue that these functions should be viewed as a similarity and a dissimilarity function on the set of the nodes moreover they are related via the covariance mapping also known as the Farris transform or the Gromov product. We will explore the properties of electrical networks from this point of view. It has been known for a while that the resistance matrix defines a metric on the nodes of the electrical networks. Moreover for a circular electrical network this metric obeys the Kalmanson property as it was shown recently. We will call such a metric an electrical Kalmanson metric. The main results of this paper is a complete description of the electrical Kalmanson metrics in the set of all Kalmanson metrics in terms of the geometry of the positive Isotropic Grassmannian whose connection to the theory of electrical networks was discovered earlier. One important area of applications where Kalmanson metrics are actively used is the theory of phylogenetic networks which are a generalization of phylogenetic trees. Our results allow us to use in phylogenetics the powerful methods of reconstruction of the minimal graphs of electrical networks and possibly open the door into data analysis for the methods of the theory of cluster algebras.","authors":["V. Gorbounov","A. Kazakov"],"url":"https://arxiv.org/abs/2501.01383"}
{"created":"2025-04-15","title":"Zero-Shot Statistical Tests for LLM-Generated Text Detection using Finite Sample Concentration Inequalities","abstract":"Verifying the provenance of content is crucial to the function of many organizations, e.g., educational institutions, social media platforms, firms, etc. This problem is becoming increasingly challenging as text generated by Large Language Models (LLMs) becomes almost indistinguishable from human-generated content. In addition, many institutions utilize in-house LLMs and want to ensure that external, non-sanctioned LLMs do not produce content within the institution. We answer the following question: Given a piece of text, can we identify whether it was produced by LLM $A$ or $B$ (where $B$ can be a human)? We model LLM-generated text as a sequential stochastic process with complete dependence on history and design zero-shot statistical tests to distinguish between (i) the text generated by two different sets of LLMs $A$ (in-house) and $B$ (non-sanctioned) and also (ii) LLM-generated and human-generated texts. We prove that our tests' type I and type II errors decrease exponentially as text length increases. For designing our tests for a given string, we demonstrate that if the string is generated by the evaluator model $A$, the log-perplexity of the string under $A$ converges to the average entropy of the string under $A$, except with an exponentially small probability in the string length. We also show that if $B$ generates the text, except with an exponentially small probability in string length, the log-perplexity of the string under $A$ converges to the average cross-entropy of $B$ and $A$. For our experiments: First, we present experiments using open-source LLMs to support our theoretical results, and then we provide experiments in a black-box setting with adversarial attacks. Practically, our work enables guaranteed finding of the origin of harmful or false LLM-generated text, which can be useful for combating misinformation and compliance with emerging AI regulations.","authors":["Tara Radvand","Mojtaba Abdolmaleki","Mohamed Mostagir","Ambuj Tewari"],"url":"https://arxiv.org/abs/2501.02406"}
{"created":"2025-04-15","title":"Bridging Impulse Control of Piecewise Deterministic Markov Processes and Markov Decision Processes: Frameworks, Extensions, and Open Challenges","abstract":"Control theory plays a pivotal role in understanding and optimizing the behavior of complex dynamical systems across various scientific and engineering disciplines. Two key frameworks that have emerged for modeling and solving control problems in stochastic systems are piecewise deterministic Markov processes (PDMPs) and Markov decision processes (MDPs). Each framework has its unique strengths, and their intersection offers promising opportunities for tackling a broad class of problems, particularly in the context of impulse controls and decision-making in complex systems.","authors":["Alice Cleynen","Beno\\^ite de Saporta","Orlane Rossini","R\\'egis Sabbadin","Am\\'elie Vernay"],"url":"https://arxiv.org/abs/2501.04120"}
{"created":"2025-04-15","title":"Deep Transfer $Q$-Learning for Offline Non-Stationary Reinforcement Learning","abstract":"In dynamic decision-making scenarios across business and healthcare, leveraging sample trajectories from diverse populations can significantly enhance reinforcement learning (RL) performance for specific target populations, especially when sample sizes are limited. While existing transfer learning methods primarily focus on linear regression settings, they lack direct applicability to reinforcement learning algorithms. This paper pioneers the study of transfer learning for dynamic decision scenarios modeled by non-stationary finite-horizon Markov decision processes, utilizing neural networks as powerful function approximators and backward inductive learning. We demonstrate that naive sample pooling strategies, effective in regression settings, fail in Markov decision processes.To address this challenge, we introduce a novel ``re-weighted targeting procedure'' to construct ``transferable RL samples'' and propose ``transfer deep $Q^*$-learning'', enabling neural network approximation with theoretical guarantees. We assume that the reward functions are transferable and deal with both situations in which the transition densities are transferable or nontransferable. Our analytical techniques for transfer learning in neural network approximation and transition density transfers have broader implications, extending to supervised transfer learning with neural networks and domain shift scenarios. Empirical experiments on both synthetic and real datasets corroborate the advantages of our method, showcasing its potential for improving decision-making through strategically constructing transferable RL samples in non-stationary reinforcement learning contexts.","authors":["Jinhang Chai","Elynn Chen","Jianqing Fan"],"url":"https://arxiv.org/abs/2501.04870"}
{"created":"2025-04-15","title":"TTC Domains","abstract":"We study the object reallocation problem under strict preferences. On the unrestricted domain, Ekici (2024) showed that the Top Trading Cycles (TTC) mechanism is the unique mechanism that is individually rational, pair efficient, and strategyproof. We provide an alternative proof of this result, assuming only minimal richness of the unrestricted domain. This allows us to identify a broad class of restricted domains, those satisfying our top-two condition, on which the characterization continues to hold. The condition requires that, within any subset of objects, if two objects can each be most-preferred, they can also be the top two most-preferred objects (in both possible orders). We show that this condition is also necessary in the special case of three objects. These results unify and strengthen prior findings on specific domains such as single-peaked and single-dipped domain, and more broadly, offer a useful criterion for analyzing restricted preference domains.","authors":["Sumit Goel","Yuki Tamura"],"url":"https://arxiv.org/abs/2501.15422"}
{"created":"2025-04-15","title":"Evolution of Society Caused by Collective and Individual Decisions","abstract":"Decision-making societies may vary in their level of cooperation and degree of conservatism, both of which influence their overall performance. Moreover, these factors are not fixed -- they can change based on the decisions agents in the society make in their interests. But can these changes lead to cyclical patterns in societal evolution? To explore this question, we use the ViSE (Voting in Stochastic Environment) model. In this framework, the level of cooperation can be measured by group size, while the degree of conservatism is determined by the voting threshold. Agents can adopt either individualistic or group-oriented strategies when voting on stochastically generated external proposals. For Gaussian proposal generators, the expected capital gain (ECG) -- a measure of agents' performance -- can be expressed in standard mathematical functions. Our findings show that in neutral environments, societal evolution with open or democratic groups can follow cyclic patterns. We also find that highly conservative societies or conservative societies with low levels of cooperation can evolve into liberal (less conservative than majoritarian) societies and that mafia groups never let their members go when they want to.","authors":["Pavel Chebotarev"],"url":"https://arxiv.org/abs/2502.00471"}
{"created":"2025-04-15","title":"Coreset-Based Task Selection for Sample-Efficient Meta-Reinforcement Learning","abstract":"We study task selection to enhance sample efficiency in model-agnostic meta-reinforcement learning (MAML-RL). Traditional meta-RL typically assumes that all available tasks are equally important, which can lead to task redundancy when they share significant similarities. To address this, we propose a coreset-based task selection approach that selects a weighted subset of tasks based on how diverse they are in gradient space, prioritizing the most informative and diverse tasks. Such task selection reduces the number of samples needed to find an $\\epsilon$-close stationary solution by a factor of O(1/$\\epsilon$). Consequently, it guarantees a faster adaptation to unseen tasks while focusing training on the most relevant tasks. As a case study, we incorporate task selection to MAML-LQR (Toso et al., 2024b), and prove a sample complexity reduction proportional to O(log(1/$\\epsilon$)) when the task specific cost also satisfy gradient dominance. Our theoretical guarantees underscore task selection as a key component for scalable and sample-efficient meta-RL. We numerically validate this trend across multiple RL benchmark problems, illustrating the benefits of task selection beyond the LQR baseline.","authors":["Donglin Zhan","Leonardo F. Toso","James Anderson"],"url":"https://arxiv.org/abs/2502.02332"}
{"created":"2025-04-15","title":"LUND-PROBE -- LUND Prostate Radiotherapy Open Benchmarking and Evaluation dataset","abstract":"Radiotherapy treatment for prostate cancer relies on computed tomography (CT) and/or magnetic resonance imaging (MRI) for segmentation of target volumes and organs at risk (OARs). Manual segmentation of these volumes is regarded as the gold standard for ground truth in machine learning applications but to acquire such data is tedious and time-consuming. A publicly available clinical dataset is presented, comprising MRI- and synthetic CT (sCT) images, target and OARs segmentations, and radiotherapy dose distributions for 432 prostate cancer patients treated with MRI-guided radiotherapy. An extended dataset with 35 patients is also included, with the addition of deep learning (DL)-generated segmentations, DL segmentation uncertainty maps, and DL segmentations manually adjusted by four radiation oncologists. The publication of these resources aims to aid research within the fields of automated radiotherapy treatment planning, segmentation, inter-observer analyses, and DL model uncertainty investigation. The dataset is hosted on the AIDA Data Hub and offers a free-to-use resource for the scientific community, valuable for the advancement of medical imaging and prostate cancer radiotherapy research.","authors":["Viktor Rogowski","Lars E Olsson","Jonas Scherman","Emilia Persson","Mustafa Kadhim","Sacha af Wetterstedt","Adalsteinn Gunnlaugsson","Martin P. Nilsson","Nandor Vass","Mathieu Moreau","Maria Gebre Medhin","Sven B\\\"ack","Per Munck af Rosensch\\\"old","Silke Engelholm","Christian Jamtheim Gustafsson"],"url":"https://arxiv.org/abs/2502.04493"}
{"created":"2025-04-15","title":"Dynamic Pricing in the Linear Valuation Model using Shape Constraints","abstract":"We propose a shape-constrained approach to dynamic pricing for censored data in the linear valuation model eliminating the need for tuning parameters commonly required by existing methods. Previous works have addressed the challenge of unknown market noise distribution $F_0$ using strategies ranging from kernel methods to reinforcement learning algorithms, such as bandit techniques and upper confidence bounds (UCB), under the assumption that $F_0$ satisfies Lipschitz (or stronger) conditions. In contrast, our method relies on isotonic regression under the weaker assumption that $F_0$ is $\\alpha$-H\\\"older continuous for some $\\alpha \\in (0,1]$, for which we derive a regret upper bound. Simulations and experiments with real-world data obtained by Welltower Inc (a major healthcare Real Estate Investment Trust) consistently demonstrate that our method attains lower empirical regret in comparison to several existing methods in the literature while offering the advantage of being tuning-parameter free.","authors":["Daniele Bracale","Moulinath Banerjee","Yuekai Sun","Kevin Stoll","Salam Turki"],"url":"https://arxiv.org/abs/2502.05776"}
{"created":"2025-04-15","title":"Cross-Domain Continual Learning for Edge Intelligence in Wireless ISAC Networks","abstract":"In wireless networks with integrated sensing and communications (ISAC), edge intelligence (EI) is expected to be developed at edge devices (ED) for sensing user activities based on channel state information (CSI). However, due to the CSI being highly specific to users' characteristics, the CSI-activity relationship is notoriously domain dependent, essentially demanding EI to learn sufficient datasets from various domains in order to gain cross-domain sensing capability. This poses a crucial challenge owing to the EDs' limited resources, for which storing datasets across all domains will be a significant burden. In this paper, we propose the EdgeCL framework, enabling the EI to continually learn-then-discard each incoming dataset, while remaining resilient to catastrophic forgetting. We design a transformer-based discriminator for handling sequences of noisy and nonequispaced CSI samples. Besides, we propose a distilled core-set based knowledge retention method with robustness-enhanced optimization to train the discriminator, preserving its performance for previous domains while preventing future forgetting. Experimental evaluations show that EdgeCL achieves 89% of performance compared to cumulative training while consuming only 3% of its memory, mitigating forgetting by 79%.","authors":["Jingzhi Hu","Xin Li","Zhou Su","Jun Luo"],"url":"https://arxiv.org/abs/2502.12736"}
{"created":"2025-04-15","title":"Multi-modal Contrastive Learning for Tumor-specific Missing Modality Synthesis","abstract":"Multi-modal magnetic resonance imaging (MRI) is essential for providing complementary information about brain anatomy and pathology, leading to more accurate diagnoses. However, obtaining high-quality multi-modal MRI in a clinical setting is difficult due to factors such as time constraints, high costs, and patient movement artifacts. To overcome this difficulty, there is increasing interest in developing generative models that can synthesize missing target modality images from the available source ones. Therefore, our team, PLAVE, design a generative model for missing MRI that integrates multi-modal contrastive learning with a focus on critical tumor regions. Specifically, we integrate multi-modal contrastive learning, tailored for multiple source modalities, and enhance its effectiveness by selecting features based on entropy during the contrastive learning process. Additionally, our network not only generates the missing target modality images but also predicts segmentation outputs, simultaneously. This approach improves the generator's capability to precisely generate tumor regions, ultimately improving performance in downstream segmentation tasks. By leveraging a combination of contrastive, segmentation, and additional self-representation losses, our model effectively reflects target-specific information and generate high-quality target images. Consequently, our results in the Brain MR Image Synthesis challenge demonstrate that the proposed model excelled in generating the missing modality.","authors":["Minjoo Lim","Bogyeong Kang","Tae-Eui Kam"],"url":"https://arxiv.org/abs/2502.19390"}
{"created":"2025-04-15","title":"Practical Evaluation of Copula-based Survival Metrics: Beyond the Independent Censoring Assumption","abstract":"Conventional survival metrics, such as Harrell's concordance index and the Brier Score, rely on the independent censoring assumption for valid inference in the presence of right-censored data. However, when instances are censored for reasons related to the event of interest, this assumption no longer holds, as this kind of dependent censoring biases the marginal survival estimates of popular nonparametric estimators. In this paper, we propose three copula-based metrics to evaluate survival models in the presence of dependent censoring, and design a framework to create realistic, semi-synthetic datasets with dependent censoring to facilitate the evaluation of the metrics. Our empirical analyses in synthetic and semi-synthetic datasets show that our metrics can give error estimates that are closer to the true error, mainly in terms of prediction accuracy.","authors":["Christian Marius Lillelund","Shi-ang Qi","Russell Greiner"],"url":"https://arxiv.org/abs/2502.19460"}
{"created":"2025-04-15","title":"Opportunistic Routing in Wireless Communications via Learnable State-Augmented Policies","abstract":"This paper addresses the challenge of packet-based information routing in large-scale wireless communication networks. The problem is framed as a constrained statistical learning task, where each network node operates using only local information. Opportunistic routing exploits the broadcast nature of wireless communication to dynamically select optimal forwarding nodes, enabling the information to reach the destination through multiple relay nodes simultaneously. To solve this, we propose a State-Augmentation (SA) based distributed optimization approach aimed at maximizing the total information handled by the source nodes in the network. The problem formulation leverages Graph Neural Networks (GNNs), which perform graph convolutions based on the topological connections between network nodes. Using an unsupervised learning paradigm, we extract routing policies from the GNN architecture, enabling optimal decisions for source nodes across various flows. Numerical experiments demonstrate that the proposed method achieves superior performance when training a GNN-parameterized model, particularly when compared to baseline algorithms. Additionally, applying the method to real-world network topologies and wireless ad-hoc network test beds validates its effectiveness, highlighting the robustness and transferability of GNNs.","authors":["Sourajit Das","Kirtan Gopal Panda","Navid NaderiAlizadeh"],"url":"https://arxiv.org/abs/2503.03736"}
{"created":"2025-04-15","title":"Rethinking Diffusion Model in High Dimension","abstract":"Curse of Dimensionality is an unavoidable challenge in statistical probability models, yet diffusion models seem to overcome this limitation, achieving impressive results in high-dimensional data generation. Diffusion models assume that they can learn the statistical properties of the underlying probability distribution, enabling sampling from this distribution to generate realistic samples. But is this really how they work? To address this question, this paper conducts a detailed analysis of the objective function and inference methods of diffusion models, leading to several important conclusions that help answer the above question: 1) In high-dimensional sparse scenarios, the target of the objective function fitting degrades from a weighted sum of multiple samples to a single sample. 2) The mainstream inference methods can all be represented within a simple unified framework, without requiring statistical concepts such as Markov chains and SDE, while aligning with the degraded objective function. 3) Guided by this simple framework, more efficient inference methods can be discovered.","authors":["Zhenxin Zheng","Zhenjie Zheng"],"url":"https://arxiv.org/abs/2503.08643"}
{"created":"2025-04-15","title":"Reconstruct Anything Model: a lightweight foundation model for computational imaging","abstract":"Most existing learning-based methods for solving imaging inverse problems can be roughly divided into two classes: iterative algorithms, such as plug-and-play and diffusion methods, that leverage pretrained denoisers, and unrolled architectures that are trained end-to-end for specific imaging problems. Iterative methods in the first class are computationally costly and often provide suboptimal reconstruction performance, whereas unrolled architectures are generally specific to a single inverse problem and require expensive training. In this work, we propose a novel non-iterative, lightweight architecture that incorporates knowledge about the forward operator (acquisition physics and noise parameters) without relying on unrolling. Our model is trained to solve a wide range of inverse problems beyond denoising, including deblurring, magnetic resonance imaging, computed tomography, inpainting, and super-resolution. The proposed model can be easily adapted to unseen inverse problems or datasets with a few fine-tuning steps (up to a few images) in a self-supervised way, without ground-truth references. Throughout a series of experiments, we demonstrate state-of-the-art performance from medical imaging to low-photon imaging and microscopy.","authors":["Matthieu Terris","Samuel Hurault","Maxime Song","Julian Tachella"],"url":"https://arxiv.org/abs/2503.08915"}
{"created":"2025-04-15","title":"Accelerating large-scale linear algebra using variational quantum imaginary time evolution","abstract":"The solution of large sparse linear systems via factorization methods such as LU or Cholesky decomposition, can be computationally expensive due to the introduction of non-zero elements, or ``fill-in.'' Graph partitioning can be used to reduce the ``fill-in,'' thereby speeding up the solution of the linear system. We introduce a quantum approach to the graph partitioning problem based on variational quantum imaginary time evolution (VarQITE). We develop a hybrid quantum/classical method to accelerate Finite Element Analysis (FEA) by using VarQITE in Ansys's LS-DYNA multiphysics simulation software. This allows us to study different types of FEA problems, from mechanical engineering to computational fluid dynamics in simulations and on quantum hardware (IonQ Aria and IonQ Forte).","authors":["Willie Aboumrad","Daiwei Zhu","Claudio Girotto","Fran\\c{c}ois-Henry Rouet","Jezer Jojo","Robert Lucas","Jay Pathak","Ananth Kaushik","Martin Roetteler"],"url":"https://arxiv.org/abs/2503.13128"}
{"created":"2025-04-15","title":"Using machine learning to measure evidence of students' sensemaking in physics courses","abstract":"In the education system, problem-solving correctness is often inappropriately conflated with student learning. Advances in both Physics Education Research (PER) and Machine Learning (ML) provide the initial tools to develop a more meaningful and efficient measurement scheme for whether physics students are engaging in sensemaking: a learning process of figuring out the how and why for a particular phenomena. In this work, we contribute such a measurement scheme, which quantifies the evidence of students' physical sensemaking given their written explanations for their solutions to physics problems. We outline how the proposed human annotation scheme can be automated into a deployable ML model using language encoders and shared probabilistic classifiers. The procedure is scalable for a large number of problems and students. We implement three unique language encoders with logistic regression, and provide a deployability analysis on 385 real student explanations from the 2023 Introduction to Physics course at Tufts University. Furthermore, we compute sensemaking scores for all students, and analyze these measurements alongside their corresponding problem-solving accuracies. We find no linear relationship between these two variables, supporting the hypothesis that one is not a reliable proxy for the other. We discuss how sensemaking scores can be used alongside problem-solving accuracies to provide a more nuanced snapshot of student performance in physics class.","authors":["Kaitlin Gili","Kyle Heuton","Astha Shah","Michael C. Hughes"],"url":"https://arxiv.org/abs/2503.15638"}
{"created":"2025-04-15","title":"Enhancing Predictive Accuracy in Tennis: Integrating Fuzzy Logic and CV-GRNN for Dynamic Match Outcome and Player Momentum Analysis","abstract":"The predictive analysis of match outcomes and player momentum in professional tennis has long been a subject of scholarly debate. In this paper, we introduce a novel approach to game prediction by combining a multi-level fuzzy evaluation model with a CV-GRNN model. We first identify critical statistical indicators via Principal Component Analysis and then develop a two-tier fuzzy model based on the Wimbledon data. In addition, the results of Pearson Correlation Coefficient indicate that the momentum indicators, such as Player Win Streak and Score Difference, have a strong correlation among them, revealing insightful trends among players transitioning between losing and winning streaks. Subsequently, we refine the CV-GRNN model by incorporating 15 statistically significant indicators, resulting in an increase in accuracy to 86.64% and a decrease in MSE by 49.21%. This consequently strengthens the methodological framework for predicting tennis match outcomes, emphasizing its practical utility and potential for adaptation in various athletic contexts.","authors":["Kechen Li","Jiaming Liu","Zhenyu Wu","Tianbo Ji"],"url":"https://arxiv.org/abs/2503.21809"}
{"created":"2025-04-15","title":"Residual-based Chebyshev filtered subspace iteration for sparse Hermitian eigenvalue problems tolerant to inexact matrix-vector products","abstract":"Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for computing a small subset of extreme eigenvalues in large sparse matrices. This work introduces a residual-based reformulation of ChFSI, referred to as R-ChFSI, designed to accommodate inexact matrix-vector products while maintaining robust convergence properties. By reformulating the traditional Chebyshev recurrence to operate on residuals rather than eigenvector estimates, the R-ChFSI approach effectively suppresses the errors made in matrix-vector products, improving the convergence behaviour for both standard and generalized eigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector products allows one to incorporate approximate inverses for large-scale generalized eigenproblems, making the method particularly attractive where exact matrix factorizations or iterative methods become computationally expensive for evaluating inverses. It also allows us to compute the matrix-vector products in lower-precision arithmetic allowing us to leverage modern hardware accelerators. Through extensive benchmarking, we demonstrate that R-ChFSI achieves desired residual tolerances while leveraging low-precision arithmetic. For problems with millions of degrees of freedom and thousands of eigenvalues, R-ChFSI attains final residual norms in the range of 10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly outperforming standard ChFSI in similar settings. In generalized eigenproblems, where approximate inverses are used, R-ChFSI achieves residual tolerances up to ten orders of magnitude lower, demonstrating its robustness to approximation errors. Finally, R-ChFSI provides a scalable and computationally efficient alternative for solving large-scale eigenproblems in high-performance computing environments.","authors":["Nikhil Kodali","Kartick Ramakrishnan","Phani Motamarri"],"url":"https://arxiv.org/abs/2503.22652"}
{"created":"2025-04-15","title":"Online Convex Optimization and Integral Quadratic Constraints: A new approach to regret analysis","abstract":"We propose a novel approach for analyzing dynamic regret of first-order constrained online convex optimization algorithms for strongly convex and Lipschitz-smooth objectives. Crucially, we provide a general analysis that is applicable to a wide range of first-order algorithms that can be expressed as an interconnection of a linear dynamical system in feedback with a first-order oracle. By leveraging Integral Quadratic Constraints (IQCs), we derive a semi-definite program which, when feasible, provides a regret guarantee for the online algorithm. For this, the concept of variational IQCs is introduced as the generalization of IQCs to time-varying monotone operators. Our bounds capture the temporal rate of change of the problem in the form of the path length of the time-varying minimizer and the objective function variation. In contrast to standard results in OCO, our results do not require nerither the assumption of gradient boundedness, nor that of a bounded feasible set. Numerical analyses showcase the ability of the approach to capture the dependence of the regret on the function class condition number.","authors":["Fabian Jakob","Andrea Iannelli"],"url":"https://arxiv.org/abs/2503.23600"}
{"created":"2025-04-15","title":"Probabilistic Reachable Set Estimation for Saturated Systems with Unbounded Additive Disturbances","abstract":"In this paper, we present an analytical approach for the synthesis of ellipsoidal probabilistic reachable sets of saturated systems subject to unbounded additive noise. Using convex optimization methods, we compute a contraction factor of the saturated error dynamics that allows us to tightly bound its evolution and therefore construct accurate reachable sets. The proposed approach is applicable to independent, zero mean disturbances with a known covariance. A numerical example illustrates the applicability and effectiveness of the proposed design.","authors":["Carlo Karam","Matteo Tacchi-B\\'enard","Mirko Fiacchini"],"url":"https://arxiv.org/abs/2504.03443"}
{"created":"2025-04-15","title":"On the Nature of Fractal Numbers and the Classical Continuum Hypothesis (CH)","abstract":"We propose a reinterpretation of the continuum grounded in the stratified structure of definability rather than classical cardinality. In this framework, a real number is not an abstract point on the number line, but an object expressible at some level Fn of a formal hierarchy. We introduce the notion of \"fractal numbers\" -- entities defined not within a fixed set-theoretic universe, but through layered expressibility across constructive systems. This reconceptualizes irrationality as a relative property, depending on definability depth, and replaces the binary dichotomy between countable and uncountable sets with a gradated spectrum of definability classes. We show that the classical Continuum Hypothesis loses its force in this context: between aleph_0 and c lies not a single cardinal jump, but a stratified sequence of definitional stages, each forming a countable yet irreducible approximation to the continuum. We argue that the real line should not be seen as a completed totality but as an evolving architecture of formal expressibility. We conclude with a discussion of rational invariants, the relativity of irrationality, and the emergence of a fractal metric for definitional density.","authors":["Stanislav Semenov"],"url":"https://arxiv.org/abs/2504.04637"}
{"created":"2025-04-15","title":"GLT hidden structures in mean-field quantum spin systems","abstract":"This work explores structured matrix sequences arising in mean-field quantum spin systems. We express these sequences within the framework of generalized locally Toeplitz (GLT) $*$-algebras, leveraging the fact that each GLT matrix sequence has a unique GLT symbol. This symbol characterizes both the asymptotic singular value distribution and, for Hermitian or quasi-Hermitian sequences, the asymptotic spectral distribution. Specifically, we analyze two cases of real symmetric matrix sequences stemming from mean-field quantum spin systems and determine their associated distributions using GLT theory. Our study concludes with visualizations and numerical tests that validate the theoretical findings, followed by a discussion of open problems and future directions.","authors":["Christiaan J. F. van de Ven","Muhammad Faisal Khan","S. Serra-Capizzano"],"url":"https://arxiv.org/abs/2504.06951"}
{"created":"2025-04-15","title":"Numerical solution by shape optimization method to an inverse shape problem in multi-dimensional advection-diffusion problem with space dependent coefficients","abstract":"This work focuses on numerically solving a shape identification problem related to advection-diffusion processes with space-dependent coefficients using shape optimization techniques. Two boundary-type cost functionals are considered, and their corresponding variations with respect to shapes are derived using the adjoint method, employing the chain rule approach. This involves firstly utilizing the material derivative of the state system and secondly using its shape derivative. Subsequently, an alternating direction method of multipliers (ADMM) combined with the Sobolev-gradient-descent algorithm is applied to stably solve the shape reconstruction problem. Numerical experiments in two and three dimensions are conducted to demonstrate the feasibility of the methods.","authors":["Elmehdi Cherrat","Lekbir Afraites","Julius Fergy Tiongson Rabago"],"url":"https://arxiv.org/abs/2504.07796"}
{"created":"2025-04-15","title":"A Piecewise Lyapunov Analysis of Sub-quadratic SGD: Applications to Robust and Quantile Regression","abstract":"Motivated by robust and quantile regression problems, we investigate the stochastic gradient descent (SGD) algorithm for minimizing an objective function $f$ that is locally strongly convex with a sub--quadratic tail. This setting covers many widely used online statistical methods. We introduce a novel piecewise Lyapunov function that enables us to handle functions $f$ with only first-order differentiability, which includes a wide range of popular loss functions such as Huber loss. Leveraging our proposed Lyapunov function, we derive finite-time moment bounds under general diminishing stepsizes, as well as constant stepsizes. We further establish the weak convergence, central limit theorem and bias characterization under constant stepsize, providing the first geometrical convergence result for sub--quadratic SGD. Our results have wide applications, especially in online statistical methods. In particular, we discuss two applications of our results. 1) Online robust regression: We consider a corrupted linear model with sub--exponential covariates and heavy--tailed noise. Our analysis provides convergence rates comparable to those for corrupted models with Gaussian covariates and noise. 2) Online quantile regression: Importantly, our results relax the common assumption in prior work that the conditional density is continuous and provide a more fine-grained analysis for the moment bounds.","authors":["Yixuan Zhang (Lucy)","Dongyan (Lucy)","Huo","Yudong Chen","Qiaomin Xie"],"url":"https://arxiv.org/abs/2504.08178"}
