{"created":"2025-04-22","title":"Experimentation in Gaming: an Adoption Guide","abstract":"Experimentation is a cornerstone of successful game development and live operations, enabling teams to optimize player engagement, retention, and monetization. This article provides a comprehensive guide to implementing experimentation in gaming, structured around the game development lifecycle and the marketing mix. From pre-launch concept testing and prototyping to post-launch personalization and LiveOps, experimentation plays a pivotal role in driving innovation and adapting game experiences to diverse player preferences. Gaming presents unique challenges, such as highly engaged communities, complex interactive systems, and highly heterogeneous and evolving player behaviors, which require tailored approaches to experimentation. The article emphasizes the importance of collaborative frameworks across product, marketing, and analytics teams and provides practical guidance to game makers how to adopt experimentation successfully. It also addresses ethical considerations like fairness and player autonomy.","authors":["Julian Runge"],"url":"https://arxiv.org/abs/2504.13840"}
{"created":"2025-04-22","title":"SkillTrade A Website For Learning New Skills","abstract":"The Skill Trade is a site for skill swapping, learning, and career growth. It links people who have matching skills, helps virtual work through Google Meet/Zoom, and lets startups hire talent easily. Users can make profiles, connect with others, share skills, and respond to job ads from startups. Startup users can post jobs and see profiles to hire candidates. Learn-only users get categorized learning materials while developers keep an eye on platform management and upload resources. It is free for individual users, supported by donations, and charges startups a small fee only when they successfully hire. Built with Tailwind CSS, it guarantees to creation of an intuitive, responsive design that fosters collaboration and career opportunities.","authors":["Rajanala Purushotham","Rapolu Rahul"],"url":"https://arxiv.org/abs/2504.13841"}
{"created":"2025-04-22","title":"The Model Counting Competitions 2021-2023","abstract":"Modern society is full of computational challenges that rely on probabilistic reasoning, statistics, and combinatorics. Interestingly, many of these questions can be formulated by encoding them into propositional formulas and then asking for its number of models. With a growing interest in practical problem-solving for tasks that involve model counting, the community established the Model Counting (MC) Competition in fall of 2019 with its first iteration in 2020. The competition aims at advancing applications, identifying challenging benchmarks, fostering new solver development, and enhancing existing solvers for model counting problems and their variants. The first iteration, brought together various researchers, identified challenges, and inspired numerous new applications. In this paper, we present a comprehensive overview of the 2021-2023 iterations of the Model Counting Competition. We detail its execution and outcomes. The competition comprised four tracks, each focusing on a different variant of the model counting problem. The first track centered on the model counting problem (MC), which seeks the count of models for a given propositional formula. The second track challenged developers to submit programs capable of solving the weighted model counting problem (WMC). The third track was dedicated to projected model counting (PMC). Finally, we initiated a track that combined projected and weighted model counting (PWMC). The competition continued with a high level of participation, with seven to nine solvers submitted in various different version and based on quite diverging techniques.","authors":["Johannes K. Fichte","Markus Hecher"],"url":"https://arxiv.org/abs/2504.13842"}
{"created":"2025-04-22","title":"Enhancing User Engagement in E-commerce through Dynamic Animations","abstract":"The use of animation to gain user attention has been increasing, supported by various studies on user behavior and psychology. However, excessive use of animation in interfaces can negatively impact the user. This paper deals with a specific type of animation within a specialized domain of e-commerce. Drawing upon theories such as the Zeigarnik Effect, Aesthetic-Usability effect, Peak-End rule, and Hick's law, we analyze user behavior and psychology when exposed to a dynamic price-drop animation. Unlike conventional static pricing strategy, this animation introduces movement to signify price reduction. In our theoretical study approach, we evaluate and present a user study on how such an animation influences user perception, psychology, and attention. If acquired effectively, dynamic animations can enhance engagement, spark anticipation, and subconsciously create a positive experience by reducing cognitive load.","authors":["Waaridh Borpujari"],"url":"https://arxiv.org/abs/2504.13843"}
{"created":"2025-04-22","title":"Interactions par franchissement gr\\^ace a un syst\\`eme de suivi du regard","abstract":"Human-computer interactions based on gaze-tracking have spread during the last few years. Video games, applications in health, trading, market research, and many other fields have started to use this new technology that seems invisible to the user. However, the dominant form of interaction using gaze tracking uses dwell-time for command activation, which introduces strong constraints in the interaction: dwell-time activation requires users to look steadily at an element for a predefined amount of time in to select it. While dwell-time alleviates a part of the Midas touch problem (referring to the fact that an element fixed by the user will be activated even if it was not intended to do so), it doesn't completely remove it: users should not gaze too long on an item, or they may trigger an unintended activation. In addition, dwell-time slows down users' interaction by requiring a pause each time an activation is needed. In this project, we study an alternative selection method based on crossing interactions, a well-studied method used in conventional HCI. This interaction allows users' gaze to rest in areas that don't have crossing triggers, and it removes the need to pause in the interaction. We found that crossing interaction had similar performances than dwell-time interaction with novice users. The performance was even better for users having previous experience with gaze interaction.","authors":["S\\'ebastien Riou","Didier Schwab","Fran\\c{c}ois B\\'erard"],"url":"https://arxiv.org/abs/2504.13844"}
{"created":"2025-04-22","title":"Towards Enhanced Learning through Presence: A Systematic Review of Presence in Virtual Reality Across Tasks and Disciplines","abstract":"The rising interest in Virtual Reality (VR) technology has sparked a desire to create immersive learning platforms capable of handling various tasks across environments. Through immersive interfaces, users can engage deeply with virtual environments, enhancing both learning outcomes and task performance. In fields such as education, engineering, and collaboration, presence has emerged as a critical factor influencing user engagement, motivation, and skill mastery. This review provides a comprehensive examination of the role of presence across different tasks and disciplines, exploring how its design impacts learning outcomes. Using a systematic search strategy based on the PRISMA method, we screened 2,793 articles and included 78 studies that met our inclusion criteria. We conducted a detailed classification and analysis of different types of presence in VR environments, including spatial presence, social presence, co-presence, self-presence, and cognitive presence. This review emphasizes how these varied types of presence affect learning outcomes across tasks and fields, and examines how design elements and interaction techniques shape presence and subsequently impact learning outcomes. We also summarize trends and future directions, identifying research gaps and opportunities to improve learning outcomes by enhancing presence in VR environments, thus offering guidance and insight for future research on VR presence and learning effectiveness.","authors":["Zheng Wei","Junxiang Liao","Lik-Hang Lee","Huamin Qu","Xian Xu"],"url":"https://arxiv.org/abs/2504.13845"}
{"created":"2025-04-22","title":"VoxLogicA UI: Supporting Declarative Medical Image Analysis","abstract":"This Master's Thesis in Computer Science dives into the design and creation of a user-friendly interface for VoxLogicA, an image analysis tool using spatial model checking with a focus on neuroimaging. The research tackles the problem of existing tools being too complex, which makes them hard for medical professionals and researchers to use. By using spatial logic, the goal is to make these powerful analytical tools more practical and accessible in real-world clinical settings. The main objectives are to design a modern web interface that's easy to use, build it with the latest web technologies (e.g. Svelte and Niivue), and test its effectiveness through user studies and real-world case analyses.","authors":["Antonio Strippoli"],"url":"https://arxiv.org/abs/2504.13846"}
{"created":"2025-04-22","title":"Interview AI-ssistant: Designing for Real-Time Human-AI Collaboration in Interview Preparation and Execution","abstract":"Recent advances in large language models (LLMs) offer unprecedented opportunities to enhance human-AI collaboration in qualitative research methods, including interviews. While interviews are highly valued for gathering deep, contextualized insights, interviewers often face significant cognitive challenges, such as real-time information processing, question adaptation, and rapport maintenance. My doctoral research introduces Interview AI-ssistant, a system designed for real-time interviewer-AI collaboration during both the preparation and execution phases. Through four interconnected studies, this research investigates the design of effective human-AI collaboration in interviewing contexts, beginning with a formative study of interviewers' needs, followed by a prototype development study focused on AI-assisted interview preparation, an experimental evaluation of real-time AI assistance during interviews, and a field study deploying the system in a real-world research setting. Beyond informing practical implementations of intelligent interview support systems, this work contributes to the Intelligent User Interfaces (IUI) community by advancing the understanding of human-AI collaborative interfaces in complex social tasks and establishing design guidelines for AI-enhanced qualitative research tools.","authors":["Zhe Liu"],"url":"https://arxiv.org/abs/2504.13847"}
{"created":"2025-04-22","title":"From Interaction to Collaboration: How Hybrid Intelligence Enhances Chatbot Feedback","abstract":"Generative AI (GenAI) chatbots are becoming increasingly integrated into virtual assistant technologies, yet their success hinges on the ability to gather meaningful user feedback to improve interaction quality, system outcomes, and overall user acceptance. Successful chatbot interactions can enable organizations to build long-term relationships with their customers and users, supporting customer loyalty and furthering the organization's goals. This study explores the impact of two distinct narratives and feedback collection mechanisms on user engagement and feedback behavior: a standard AI-focused interaction versus a hybrid intelligence (HI) framed interaction. Initial findings indicate that while small-scale survey measures allowed for no significant differences in user willingness to leave feedback, use the system, or trust the system, participants exposed to the HI narrative statistically significantly provided more detailed feedback. These initial findings offer insights into designing effective feedback systems for GenAI virtual assistants, balancing user effort with system improvement potential.","authors":["Janet Rafner","Ryan Q. Guloy","Eden W. Wen","Catherine M. Chiodo","Jacob Sherson"],"url":"https://arxiv.org/abs/2504.13848"}
{"created":"2025-04-22","title":"Assistive XR research for disability at ACM ASSETS: A Scoping Review","abstract":"Despite the rise in affordable eXtended Reality (XR) technologies, accessibility still remains a key concern, often excluding people with disabilities from accessing these immersive XR platforms. Consequently, there has been a notable surge in HCI research on creating accessible XR solutions (also known as, assistive XR). This increased focus in assistive XR research is also reflected in the number of research and innovative solutions submitted at the ACM Conference on Accessible Computing (ASSETS), with an aim to make XR experiences inclusive for disabled communities. However, till date, there is little to no work that provides a comprehensive overview of state-of-the-art research in assistive XR for disability at ACM ASSETS, a premier conference dedicated for research in HCI for people with disabilities.","authors":["Puneet Jain"],"url":"https://arxiv.org/abs/2504.13849"}
{"created":"2025-04-22","title":"Resource Utilization Optimized Federated Learning","abstract":"Federated learning (FL) systems facilitate distributed machine learning across a server and multiple devices. However, FL systems have low resource utilization limiting their practical use in the real world. This inefficiency primarily arises from two types of idle time: (i) task dependency between the server and devices, and (ii) stragglers among heterogeneous devices. This paper introduces FedOptima, a resource-optimized FL system designed to simultaneously minimize both types of idle time; existing systems do not eliminate or reduce both at the same time. FedOptima offloads the training of certain layers of a neural network from a device to server using three innovations. First, devices operate independently of each other using asynchronous aggregation to eliminate straggler effects, and independently of the server by utilizing auxiliary networks to minimize idle time caused by task dependency. Second, the server performs centralized training using a task scheduler that ensures balanced contributions from all devices, improving model accuracy. Third, an efficient memory management mechanism on the server increases scalability of the number of participating devices. Four state-of-the-art offloading-based and asynchronous FL methods are chosen as baselines. Experimental results show that compared to the best results of the baselines on convolutional neural networks and transformers on multiple lab-based testbeds, FedOptima (i) achieves higher or comparable accuracy, (ii) accelerates training by 1.9x to 21.8x, (iii) reduces server and device idle time by up to 93.9% and 81.8%, respectively, and (iv) increases throughput by 1.1x to 2.0x.","authors":["Zihan Zhang","Leon Wong","Blesson Varghese"],"url":"https://arxiv.org/abs/2504.13850"}
{"created":"2025-04-22","title":"Gamification as a Data Acquisition Strategy for Neurogames","abstract":"The nascent field of neurogames relies on active Brain-Computer Interface input to drive its game mechanics. Consequently, users expect their conscious will to be meaningfully reflected on the virtual environment they're engaging in. Additionally, the videogame industry considers it paramount to provide gamers with seamless experiences to avoid disrupting their state of flow. Thus, this paper suggests gamification as a strategy to camouflage the often fatiguing data acquisition process in Machine Learning from neurodata so that neurogamers can further immerse themselves in the virtual experience while Artificial Intelligence models benefit from data taken in reproducible contexts.","authors":["Diego Saldivar"],"url":"https://arxiv.org/abs/2504.13851"}
{"created":"2025-04-22","title":"A Pandemic for the Good of Digital Literacy? An Empirical Investigation of Newly Improved Digital Skills during COVID-19 Lockdowns","abstract":"This research explores whether the rapid digital transformation due to COVID-19 managed to close or exacerbate the digital divide concerning users' digital skills. We conducted a pre-registered survey with N = 1143 German Internet users. Our findings suggest the latter: younger, male, and higher educated users were more likely to improve their digital skills than older, female, and less educated ones. According to their accounts, the pandemic helped Internet users improve their skills in communicating with others by using video conference software and reflecting critically upon information they found online. These improved digital skills exacerbated not only positive (e.g., feeling informed and safe) but also negative (e.g., feeling lonely) effects of digital media use during the pandemic. We discuss this research's theoretical and practical implications regarding the impact of challenges, such as technological disruption and health crises, on humans' digital skills, capabilities, and future potential, focusing on the second-level digital divide.","authors":["German Neubaum","Irene-Angelica Chounta","Eva Gredel","David Wiesche"],"url":"https://arxiv.org/abs/2504.13852"}
{"created":"2025-04-22","title":"Stakeholder perspectives on designing socially acceptable social robots and robot avatars for Dubai and multicultural societies","abstract":"Robot avatars for customer service are gaining traction in Japan. However, their acceptance in other societal contexts remains underexplored, complicating efforts to design robot avatars suitable for diverse cultural environments. To address this, we interviewed key stakeholders in Dubai's service sector to gain insights into their experiences deploying social robots for customer service, as well as their opinions on the most useful tasks and design features that could maximize customer acceptance of robot avatars in Dubai. Providing information and guiding individuals to specific locations were identified as the most valued functions. Regarding appearance, robotic-looking, highly anthropomorphic designs were the most preferred. Ultra-realistic androids and cartoonish-looking robots elicited mixed reactions, while hybrid androids, low-anthropomorphic robotic designs, and animal-looking robots were considered less suitable or discouraged. Additionally, a psycho-sociological analysis revealed that interactions with robot avatars are influenced by their symbolic meaning, context, and affordances. These findings offer pioneering insights into culturally adaptive robot avatar design, addressing a significant research gap and providing actionable guidelines for deploying socially acceptable robots and avatars in multicultural contexts worldwide.","authors":["Laura Aymerich-Franch","Tarek Taha","Hiroshi Ishiguro","Takahiro Miyashita","Paolo Dario"],"url":"https://arxiv.org/abs/2504.13854"}
{"created":"2025-04-22","title":"Bio-crafting Architecture: Experiences of growing mycelium in minimal surface molds","abstract":"This study documents a three-week workshop with architecture students, where we designed and 3D printed various minimal surfaces using wood-based filaments, and used them as molds in which to grow mycelium. We detail the design process and the growth of the mycelium in different shapes, together with participants' experiences of working with a living material. After exhibiting the results of the work in a public-facing exhibition, we conducted interviews with members of the general public about their perceptions on interacting with a material such as mycelium in design. Our findings show that 3D-printed minimal surfaces with wood-based filaments can function as structural cores for mycelium-based composites and mycelium binds to the filament. Participants in the workshop exhibited stronger feelings for living materials compared to non-living ones, displaying both biophilia and, to a lesser extent, biophobia when interacting with the mycelium. Members of the general public discuss pragmatic aspects including mold, fragility, or production costs, and speculate on the future of bio-technology and its impact on everyday life. While all are positive about the impact on bio-technologies on the future, they have diverging opinions on how much ethical considerations should influence research directions.","authors":["Anca-Simona Horvath","Alina Elena Voinea","Radu Arie\\c{s}an"],"url":"https://arxiv.org/abs/2504.13855"}
{"created":"2025-04-22","title":"Towards Balancing Preference and Performance through Adaptive Personalized Explainability","abstract":"As robots and digital assistants are deployed in the real world, these agents must be able to communicate their decision-making criteria to build trust, improve human-robot teaming, and enable collaboration. While the field of explainable artificial intelligence (xAI) has made great strides to enable such communication, these advances often assume that one xAI approach is ideally suited to each problem (e.g., decision trees to explain how to triage patients in an emergency or feature-importance maps to explain radiology reports). This fails to recognize that users have diverse experiences or preferences for interaction modalities. In this work, we present two user-studies set in a simulated autonomous vehicle (AV) domain. We investigate (1) population-level preferences for xAI and (2) personalization strategies for providing robot explanations. We find significant differences between xAI modes (language explanations, feature-importance maps, and decision trees) in both preference (p < 0.01) and performance (p < 0.05). We also observe that a participant's preferences do not always align with their performance, motivating our development of an adaptive personalization strategy to balance the two. We show that this strategy yields significant performance gains (p < 0.05), and we conclude with a discussion of our findings and implications for xAI in human-robot interactions.","authors":["Andrew Silva","Pradyumna Tambwekar","Mariah Schrum","Matthew Gombolay"],"url":"https://arxiv.org/abs/2504.13856"}
{"created":"2025-04-22","title":"Impact of Environmental Colors on Human Aggressiveness: Insights from a Minecraft-Based Behavioral Study","abstract":"This study explores the influence of environmental colors on human behavior, specifically focusing on aggressiveness and passiveness. Color is widely regarded as an influential environmental factor shaping human behavior, yet existing studies present conflicting evidence regarding its impact on aggressiveness and passiveness. This study employed Minecraft as a controlled digital platform to investigate whether exposure to different colors influences both the frequency and nature of participant interactions (aggressive versus non-aggressive), and whether prolonged exposure amplifies these effects. Anonymous online participants were exposed to various colors before interacting with non-player characters simulating human-like encounters. Three key outcomes were measured: (1) total interactions per color, (2) ratios of aggressive to non-aggressive interactions per color, and (3) the effect of varying exposure durations on aggressiveness. While no significant overall differences in interaction frequency were observed among the colors, post-hoc analyses revealed that Red and Black elicited significantly more interactions compared to Green. Additionally, Red, Yellow, and Black were associated with higher ratios of aggressive behavior relative to Green or White. Prolonged exposure to Red also appeared to intensify aggressive responses. These findings underscore the potential role of environmental color in shaping online social behaviors and highlight the importance of environmental settings in areas ranging from online communication platforms to digital marketing strategies.","authors":["Austin Deng-Yao Yang","Shih-Jen Tsai","Hsin-Jung Tsai"],"url":"https://arxiv.org/abs/2504.13857"}
{"created":"2025-04-22","title":"The Effect of Explainable AI-based Decision Support on Human Task Performance: A Meta-Analysis","abstract":"The desirable properties of explanations in information systems have fueled the demands for transparency in artificial intelligence (AI) outputs. To address these demands, the field of explainable AI (XAI) has put forth methods that can support human decision-making by explaining AI outputs. However, current empirical works present inconsistent findings on whether such explanations help to improve users' task performance in decision support systems (DSS). In this paper, we conduct a meta-analysis to explore how XAI affects human performance in classification tasks. Our results show an improvement in task performance through XAI-based decision support, though explanations themselves are not the decisive driver for this improvement. The analysis reveals that the studies' risk of bias moderates the effect of explanations in AI, while the explanation type appears to play only a negligible role. Our findings contribute to the human computer interaction field by enhancing the understanding of human-XAI collaboration in DSS.","authors":["Felix Haag"],"url":"https://arxiv.org/abs/2504.13858"}
{"created":"2025-04-22","title":"DoYouTrustAI: A Tool to Teach Students About AI Misinformation and Prompt Engineering","abstract":"AI, especially Large Language Models (LLMs) like ChatGPT, have rapidly developed and gained widespread adoption in the past five years, shifting user preference from traditional search engines. However, the generative nature of LLMs raises concerns about presenting misinformation as fact. To address this, we developed a web-based application that helps K-12 students enhance critical thinking by identifying misleading information in LLM responses about major historical figures. In this paper, we describe the implementation and design details of the DoYouTrustAI tool, which can be used to provide an interactive lesson which teaches students about the dangers of misinformation and how believable generative AI can make it seem. The DoYouTrustAI tool utilizes prompt engineering to present the user with AI generated summaries about the life of a historical figure. These summaries can be either accurate accounts of that persons life, or an intentionally misleading alteration of their history. The user is tasked with determining the validity of the statement without external resources. Our research questions for this work were:(RQ1) How can we design a tool that teaches students about the dangers of misleading information and of how misinformation can present itself in LLM responses? (RQ2) Can we present prompt engineering as a topic that is easily understandable for students? Our findings highlight the need to correct misleading information before users retain it. Our tool lets users select familiar individuals for testing to reduce random guessing and presents misinformation alongside known facts to maintain believability. It also provides pre-configured prompt instructions to show how different prompts affect AI responses. Together, these features create a controlled environment where users learn the importance of verifying AI responses and understanding prompt engineering.","authors":["Phillip Driscoll","Priyanka Kumar"],"url":"https://arxiv.org/abs/2504.13859"}
{"created":"2025-04-22","title":"10 Questions to Fall in Love with ChatGPT: An Experimental Study on Interpersonal Closeness with Large Language Models (LLMs)","abstract":"Large language models (LLMs), like ChatGPT, are capable of computing affectionately nuanced text that therefore can shape online interactions, including dating. This study explores how individuals experience closeness and romantic interest in dating profiles, depending on whether they believe the profiles are human- or AI-generated. In a matchmaking scenario, 307 participants rated 10 responses to the Interpersonal Closeness Generating Task, unaware that all were LLM-generated. Surprisingly, perceived source (human or AI) had no significant impact on closeness or romantic interest. Instead, perceived quality and human-likeness of responses shaped reactions. The results challenge current theoretical frameworks for human-machine communication and raise critical questions about the importance of authenticity in affective online communication.","authors":["Jessica Szczuka","Lisa M\\\"uhl","Paula Ebner","Simon Dub\\'e"],"url":"https://arxiv.org/abs/2504.13860"}
{"created":"2025-04-22","title":"3MDBench: Medical Multimodal Multi-agent Dialogue Benchmark","abstract":"Large Vision-Language Models (LVLMs) are increasingly being explored for applications in telemedicine, yet their ability to engage with diverse patient behaviors remains underexplored. We introduce 3MDBench (Medical Multimodal Multi-agent Dialogue Benchmark), an open-source evaluation framework designed to assess LLM-driven medical consultations. Unlike existing benchmarks, 3MDBench simulates real-world patient variability by incorporating four temperament-driven Patient Agents and an Assessor Agent that evaluates diagnostic accuracy and dialogue quality. The benchmark integrates textual and image-based patient data across 34 common diagnoses, mirroring real-world telemedicine interactions. Under different diagnostic strategies, we evaluate state-of-the-art LVLMs. Our findings demonstrate that incorporating dialogue improves the F1 score from 50.4 to 54.2 compared to non-dialogue settings, underscoring the value of context-driven, information-seeking questioning. Additionally, we demonstrate that multimodal inputs enhance diagnostic efficiency. Image-supported models outperform text-only counterparts by raising the diagnostic F1 score from 52.8 to 54.2 in a similar dialogue setting. Finally, we suggest an approach that improves the diagnostic F1-score to 70.3 by training the CNN model on the diagnosis prediction task and incorporating its top-3 predictions into the LVLM context. 3MDBench provides a reproducible and extendable evaluation framework for AI-driven medical assistants. It offers insights into how patient temperament, dialogue strategies, and multimodal reasoning influence diagnosis quality. By addressing real-world complexities in telemedicine, our benchmark paves the way for more empathetic, reliable, and context-aware AI-driven healthcare solutions. The source code of our benchmark is publicly available: https://github.com/univanxx/3mdbench","authors":["Ivan Sviridov","Amina Miftakhova","Artemiy Tereshchenko","Galina Zubkova","Pavel Blinov","Andrey Savchenko"],"url":"https://arxiv.org/abs/2504.13861"}
{"created":"2025-04-22","title":"Participatory Design of EHR Components: Crafting Novel Relational Spaces for IT Specialists and Hospital Staff to Cooperate","abstract":"Introduced in the early 2010s, Electronic Health Records (EHRs) have become ubiquitous in hospitals. Despite clear benefits, they remain unpopular among healthcare professionals and present significant challenges. Positioned at the intersection of Health Information Systems studies, Computer Supported Collaborative Work (CSCW), Service Design, and Participatory Design (PD), our research investigates how involving users in the co-design of new EHR components within a dedicated hospital space can transform healthcare practices. Through participatory co-design methodologies, including ethnographic observation, collaborative workshops, and realistic simulations, we identify the material and interactional elements essential for rebalancing power dynamics between users and designers. This project contributes to rethinking traditional EHR design approaches, embedding design practice into systemic transformation to genuinely meet healthcare professionals' needs.","authors":["Louise Robert","Laurine Moniez","Quentin Luzurier","David Morquin"],"url":"https://arxiv.org/abs/2504.13862"}
{"created":"2025-04-22","title":"Utsarjan: A smartphone App for providing kidney care and real-time assistance to children with nephrotic syndrome","abstract":"Background Telemedicine has the potential to provide secure and cost-effective healthcare at the touch of a button. Nephrotic syndrome is a chronic childhood illness involving frequent relapses and demands long/complex treatment. Hence, developing a remote means of doctor-patient interface will ensure the provision of quality healthcare to patients. Methods The Utsarjan mobile App framework was built with Flutter that enables cross-platform development (Android, iOS, Windows) with speed, smoothness, and open-source benefits. The frontend uses Dart for user interaction, while the backend employs Node.js, Express, and NGINX for APIs, load balancing and high performance. MongoDB ensures a flexible database, Bcrypt secures passwords, PM2 handles deployment, uptime and logs, while Firebase Cloud Messaging powers free push notifications. Results Utsarjan (means excretion) is a multi-functional smartphone application for giving nephrotic care and real-time assistance to all patients (especially those in rural regions and/or who do not have access to specialists). It helps patients and doctors by ensuring opportune visits, recording each clinical test/parameter and improving medication adherence. It gives a graphical visualization of relapses, medicine dosage as well as different anthropometric parameters (urine protein, BP, height and weight). This is the first nephrotic care App that enables prompt access to doctor's advice. Conclusions Utsarjan is a mobile App to provide kidney care and real-time assistance to children with nephrotic syndrome. It gives a graphical overview of changes in a patient's health over the long course of treatment. This will assist doctors in appropriately modifying the treatment regimen. Consequently, it will (hopefully) lead to the prevention of relapses and/or complications.","authors":["Snigdha Tiwari (Computational Biology and Translational Bioinformatics)","Sahil Sharma (Computational Biology and Translational Bioinformatics)","Arvind Bagga (Department of Pediatrics","All India Institute of Medical Sciences","New Delhi","India)","Aditi Sinha (Department of Pediatrics","All India Institute of Medical Sciences","New Delhi","India)","Deepak Sharma (Computational Biology and Translational Bioinformatics)"],"url":"https://arxiv.org/abs/2504.13863"}
{"created":"2025-04-22","title":"Personal Data Protection in Smart Home Activity Monitoring for Digital Health: A Case Study","abstract":"Researchers in pervasive computing have worked for decades on sensor-based human activity recognition (HAR). Among the digital health applications, the recognition of activities of daily living (ADL) in smart home environments enables the identification of behavioral changes that clinicians consider as a digital bio-marker of early stages of cognitive decline. The real deployment of sensor-based HAR systems in the homes of elderly subjects poses several challenges, with privacy and ethical concerns being major ones. This paper reports our experience applying privacy by design principles to develop and deploy one of these systems.","authors":["Claudio Bettini","Azin Moradbeikie","Gabriele Civitarese"],"url":"https://arxiv.org/abs/2504.13864"}
{"created":"2025-04-22","title":"A Survey on (M)LLM-Based GUI Agents","abstract":"Graphical User Interface (GUI) Agents have emerged as a transformative paradigm in human-computer interaction, evolving from rule-based automation scripts to sophisticated AI-driven systems capable of understanding and executing complex interface operations. This survey provides a comprehensive examination of the rapidly advancing field of LLM-based GUI Agents, systematically analyzing their architectural foundations, technical components, and evaluation methodologies. We identify and analyze four fundamental components that constitute modern GUI Agents: (1) perception systems that integrate text-based parsing with multimodal understanding for comprehensive interface comprehension; (2) exploration mechanisms that construct and maintain knowledge bases through internal modeling, historical experience, and external information retrieval; (3) planning frameworks that leverage advanced reasoning methodologies for task decomposition and execution; and (4) interaction systems that manage action generation with robust safety controls. Through rigorous analysis of these components, we reveal how recent advances in large language models and multimodal learning have revolutionized GUI automation across desktop, mobile, and web platforms. We critically examine current evaluation frameworks, highlighting methodological limitations in existing benchmarks while proposing directions for standardization. This survey also identifies key technical challenges, including accurate element localization, effective knowledge retrieval, long-horizon planning, and safety-aware execution control, while outlining promising research directions for enhancing GUI Agents' capabilities. Our systematic review provides researchers and practitioners with a thorough understanding of the field's current state and offers insights into future developments in intelligent interface automation.","authors":["Fei Tang","Haolei Xu","Hang Zhang","Siqi Chen","Xingyu Wu","Yongliang Shen","Wenqi Zhang","Guiyang Hou","Zeqi Tan","Yuchen Yan","Kaitao Song","Jian Shao","Weiming Lu","Jun Xiao","Yueting Zhuang"],"url":"https://arxiv.org/abs/2504.13865"}
{"created":"2025-04-22","title":"Skeleton-Based Transformer for Classification of Errors and Better Feedback in Low Back Pain Physical Rehabilitation Exercises","abstract":"Physical rehabilitation exercises suggested by healthcare professionals can help recovery from various musculoskeletal disorders and prevent re-injury. However, patients' engagement tends to decrease over time without direct supervision, which is why there is a need for an automated monitoring system. In recent years, there has been great progress in quality assessment of physical rehabilitation exercises. Most of them only provide a binary classification if the performance is correct or incorrect, and a few provide a continuous score. This information is not sufficient for patients to improve their performance. In this work, we propose an algorithm for error classification of rehabilitation exercises, thus making the first step toward more detailed feedback to patients. We focus on skeleton-based exercise assessment, which utilizes human pose estimation to evaluate motion. Inspired by recent algorithms for quality assessment during rehabilitation exercises, we propose a Transformer-based model for the described classification. Our model is inspired by the HyperFormer method for human action recognition, and adapted to our problem and dataset. The evaluation is done on the KERAAL dataset, as it is the only medical dataset with clear error labels for the exercises, and our model significantly surpasses state-of-the-art methods. Furthermore, we bridge the gap towards better feedback to the patients by presenting a way to calculate the importance of joints for each exercise.","authors":["Aleksa Marusic (U2IS)","Sao Mai Nguyen (Lab-STICC_RAMBO","U2IS","Flowers)","Adriana Tapus (U2IS)"],"url":"https://arxiv.org/abs/2504.13866"}
{"created":"2025-04-22","title":"Mapping Executive Function Tasks for Children: A Scoping Review for Designing a Research-Oriented Platform","abstract":"Background: Executive functions (EFs) are cognitive processes essential for controlling impulses, staying focused, thinking before acting, and managing information. Childhood is a critical period for EF development, but there is a lack of standardized tools that combine EF tasks with physical activity in a gamified approach. Objectives: This scoping review maps EF tasks for children, identifies common strategies, and explores methods for measuring outcomes, providing a foundation for a research-oriented platform to assess EF development. Design: A systematic search was conducted in SCOPUS, ScienceDirect, and ERIC databases with the query \"executive function task\" AND (children OR child OR childhood). Inclusion criteria were studies published between 2019 and 2024 in English, with participants aged 5 to 9 years. Data extracted included task details, scoring mechanisms, and stop conditions. Studies lacking clear methodological descriptions were excluded. Results: A total of 2044 articles were identified, with 113 duplicates removed. After selection, 23 studies met the inclusion criteria. The identified tasks are listed in Table 2. Key tasks, strategies, and measurement methodologies were highlighted. Conclusions: Integrating EF tasks into a structured platform offers a promising approach to standardize assessments, fill research gaps, and provide a reliable tool for studying EF development in children.","authors":["Matheus Rodrigues Felizardo","Nuno Miguel Feixa Rodrigues","Ant\\'onio Coelho","S\\'onia Silva Sousa","Adriana Sampaio","Eva Ferreira de Oliveira"],"url":"https://arxiv.org/abs/2504.13867"}
{"created":"2025-04-22","title":"Using Generative AI Personas Increases Collective Diversity in Human Ideation","abstract":"This study challenges the widely-reported tradeoff between generative AI's (GenAI) contribution to creative outcomes and decreased diversity of these outcomes. We modified the design of such a study, by Doshi and Hauser (2024), in which participants wrote short stories either aided or unaided by GenAI plot ideas[1]. In the modified study, plot ideas were generated through ten unique GenAI \"personas\" with diverse traits (e.g. cultural backgrounds, thinking styles, genre preferences), creating a pool of 300 story plots. While plot ideas from any individual persona showed high similarity (average cosine similarity of 0.92), ideas across different personas exhibited substantial variation (average similarity of 0.20). When human participants wrote stories based on these diverse plot ideas, their collective outputs maintained the same level of diversity as stories written without GenAI assistance, effectively eliminating the diversity reduction observed in [1]. Traditional text analytics further revealed that GenAI-assisted stories featured greater diversity in descriptive and emotional language compared to purely human-generated stories without GenAI assistance. Our findings demonstrate that introducing diversity at the AI input stage through distinct personas can preserve and potentially enhance the collective diversity of human creative outputs when collaborating with GenAI.","authors":["Yun Wan","Yoram M Kalman"],"url":"https://arxiv.org/abs/2504.13868"}
{"created":"2025-04-22","title":"The Evolving Role of Programming and LLMs in the Development of Self-Driving Laboratories","abstract":"Machine learning and automation are transforming scientific research, yet the implementation of self-driving laboratories (SDLs) remains costly and complex, and it remains difficult to learn how to use these facilities. To address this, we introduce Claude-Light, a lightweight, remotely accessible instrument designed for prototyping automation algorithms and machine learning workflows. Claude-Light integrates a REST API, a Raspberry Pi-based control system, and an RGB LED with a photometer that measures ten spectral outputs, providing a controlled but realistic experimental environment. This device enables users to explore automation at multiple levels, from basic programming and experimental design to machine learning-driven optimization. We demonstrate the application of Claude-Light in structured automation approaches, including traditional scripting, statistical design of experiments, and active learning methods. Additionally, we explore the role of large language models (LLMs) in laboratory automation, highlighting their use in instrument selection, structured data extraction, function calling, and code generation. While LLMs present new opportunities for streamlining automation, they also introduce challenges related to reproducibility, security, and reliability. We discuss strategies to mitigate these risks while leveraging LLMs for enhanced efficiency in self-driving laboratories. Claude-Light provides a practical and accessible platform for students and researchers to develop automation skills and test algorithms before deploying them in larger-scale SDLs. By lowering the barrier to entry for automation in scientific research, this tool facilitates broader adoption of AI-driven experimentation and fosters innovation in autonomous laboratories.","authors":["John R. Kitchin"],"url":"https://arxiv.org/abs/2504.13870"}
{"created":"2025-04-22","title":"Human aversion? Do AI Agents Judge Identity More Harshly Than Performance","abstract":"This study examines the understudied role of algorithmic evaluation of human judgment in hybrid decision-making systems, a critical gap in management research. While extant literature focuses on human reluctance to follow algorithmic advice, we reverse the perspective by investigating how AI agents based on large language models (LLMs) assess and integrate human input. Our work addresses a pressing managerial constraint: firms barred from deploying LLMs directly due to privacy concerns can still leverage them as mediating tools (for instance, anonymized outputs or decision pipelines) to guide high-stakes choices like pricing or discounts without exposing proprietary data. Through a controlled prediction task, we analyze how an LLM-based AI agent weights human versus algorithmic predictions. We find that the AI system systematically discounts human advice, penalizing human errors more severely than algorithmic errors--a bias exacerbated when the agent's identity (human vs AI) is disclosed and the human is positioned second. These results reveal a disconnect between AI-generated trust metrics and the actual influence of human judgment, challenging assumptions about equitable human-AI collaboration. Our findings offer three key contributions. First, we identify a reverse algorithm aversion phenomenon, where AI agents undervalue human input despite comparable error rates. Second, we demonstrate how disclosure and positional bias interact to amplify this effect, with implications for system design. Third, we provide a framework for indirect LLM deployment that balances predictive power with data privacy. For practitioners, this research emphasize the need to audit AI weighting mechanisms, calibrate trust dynamics, and strategically design decision sequences in human-AI systems.","authors":["Yuanjun Feng","Vivek Chodhary","Yash Raj Shrestha"],"url":"https://arxiv.org/abs/2504.13871"}
{"created":"2025-04-22","title":"Manifesting Architectural Subspaces with Two Mobile Robotic Partitions to Facilitate Spontaneous Office Meetings","abstract":"Although intended to foster spontaneous interactions among workers, a typical open-plan office layout cannot mitigate visual, acoustic, or privacy-related distractions that originate from unplanned meetings. As office workers often refrain from tackling these issues by manually demarcating or physically relocating to a more suitable subspace that is enclosed by movable partitions, we hypothesise that these subspaces could instead be robotically manifested. This study therefore evaluated the perceived impact of two mobile robotic partitions that were wizarded to jointly manifest an enclosed subspace, to: 1) either `mitigate' or `intervene' in the distractions caused by spontaneous face-to-face or remote meetings; or 2) either `gesturally' or `spatially' nudge a distraction-causing worker to relocate. Our findings suggest how robotic furniture should interact with office workers with and through transient space, and autonomously balance the distractions not only for each individual worker but also for multiple workers sharing the same workspace.","authors":["Ozan Balci","Stien Poncelet","Alex Binh Vinh Duc Nguyen","Andrew Vande Moere"],"url":"https://arxiv.org/abs/2504.13872"}
{"created":"2025-04-22","title":"Translating Multimodal AI into Real-World Inspection: TEMAI Evaluation Framework and Pathways for Implementation","abstract":"This paper introduces the Translational Evaluation of Multimodal AI for Inspection (TEMAI) framework, bridging multimodal AI capabilities with industrial inspection implementation. Adapting translational research principles from healthcare to industrial contexts, TEMAI establishes three core dimensions: Capability (technical feasibility), Adoption (organizational readiness), and Utility (value realization). The framework demonstrates that technical capability alone yields limited value without corresponding adoption mechanisms. TEMAI incorporates specialized metrics including the Value Density Coefficient and structured implementation pathways. Empirical validation through retail and photovoltaic inspection implementations revealed significant differences in value realization patterns despite similar capability reduction rates, confirming the framework's effectiveness across diverse industrial sectors while highlighting the importance of industry-specific adaptation strategies.","authors":["Zehan Li","Jinzhi Deng","Haibing Ma","Chi Zhang","Dan Xiao"],"url":"https://arxiv.org/abs/2504.13873"}
{"created":"2025-04-22","title":"God's Innovation Project -- Empowering The Player With Generative AI","abstract":"In this paper, we present God's Innovation Project (GIP), a god game where players collect words to dynamically terraform the landscape using generative AI. A god game is a genre where players take on the role of a deity, indirectly influencing Non-Player Characters (NPCs) to perform various tasks. These games typically grant players supernatural abilities, such as terrain manipulation or weather control. Traditional god games rely on predefined environments and mechanics, typically created by a human designer. In contrast, GIP allows players to shape the game world procedurally through text-based input. Using a lightweight generative AI model, we create a gamified pipeline which transforms the player's text prompts into playable game terrain in real time. To evaluate the impact of this AI-driven mechanic, we conduct a user study analyzing how players interacted with and experienced the system. Our findings provide insights into player engagement, the effectiveness of AI-generated terrain, and the role of generative AI as an interactive game mechanic.","authors":["Ritvik Nair","Timothy Merino","Julian Togelius"],"url":"https://arxiv.org/abs/2504.13874"}
{"created":"2025-04-22","title":"A discrete physics-informed training for projection-based reduced order models with neural networks","abstract":"This paper presents a physics-informed training framework for projection-based Reduced Order Models (ROMs). We extend the PROM-ANN architecture by complementing snapshot-based training with a FEM-based, discrete physics-informed residual loss, bridging the gap between traditional projection-based ROMs and physics-informed neural networks (PINNs). Unlike conventional PINNs that rely on analytical PDEs, our approach leverages FEM residuals to guide the learning of the ROM approximation manifold. Key contributions include: (1) a parameter-agnostic, discrete residual loss applicable to non-linear problems, (2) an architectural modification to PROM-ANN improving accuracy for fast-decaying singular values, and (3) an empirical study on the proposed physics informed training process for ROMs.","authors":["N. Sibuet","S. Ares de Parga","J. R. Bravo","R. Rossi"],"url":"https://arxiv.org/abs/2504.13875"}
{"created":"2025-04-22","title":"Designing a Geo-Tourism App: A Principled Approach","abstract":"Walking along trails in natural areas is a rewarding experience, but visitors sometimes need proper assistance to enhance their enjoyment, maximize learning, and ensure safety. Over the years, various signage techniques have been introduced, but today, the widespread use of smartphones offers new opportunities for visitor support. In this paper, we outline the key principles for designing an Android app tailored for geotourists. Our approach begins by defining user personas and deriving app requirements based on their needs. We then present a proof of concept that addresses the critical aspects identified during the design process.","authors":["Augusto Ciuffoletti"],"url":"https://arxiv.org/abs/2504.13876"}
{"created":"2025-04-22","title":"New care pathways for supporting transitional care from hospitals to home using AI and personalized digital assistance","abstract":"Transitional care may play a vital role for the sustainability of Europe future healthcare system, offering solutions for relocating patient care from hospital to home therefore addressing the growing demand for medical care as the population is ageing. However, to be effective, it is essential to integrate innovative Information and Communications Technology technologies to ensure that patients with comorbidities experience a smooth and coordinated transition from hospitals or care centers to home, thereby reducing the risk of rehospitalization. In this paper, we present an overview of the integration of Internet of Things, artificial intelligence, and digital assistance technologies with traditional care pathways to address the challenges and needs of healthcare systems in Europe. We identify the current gaps in transitional care and define the technology mapping to enhance the care pathways, aiming to improve patient outcomes, safety, and quality of life avoiding hospital readmissions. Finally, we define the trial setup and evaluation methodology needed to provide clinical evidence that supports the positive impact of technology integration on patient care and discuss the potential effects on the healthcare system.","authors":["Ionut Anghel","Tudor Cioara","Roberta Bevilacqua","Federico Barbarossa","Terje Grimstad","Riitta Hellman","Arnor Solberg","Lars Thomas Boye","Ovidiu Anchidin","Ancuta Nemes","Camilla Gabrielsen"],"url":"https://arxiv.org/abs/2504.13877"}
{"created":"2025-04-22","title":"Learning by gaming, coding and making with EDUMING: A new approach to utilising atypical digital games for learning","abstract":"Papert's constructionism makes it clear that learning is particularly effective when learners create tangible artifacts and share and discuss them in social contexts. Technological progress in recent decades has created numerous opportunities for learners to not only passively consume media, but to actively shape it through construction. This article uses the EDUMING concept to present a new method to simplify the development of digital learning games and thus support their integration into learning situations. A key difference between the concept and established ideas such as game-based learning, gamification, serious games, etc. is that games are not closed and are consumed passively, but can also be actively developed by users individually by modifying the source code with the help of an IDE. As part of an empirical study, the usability of the game \"Professor Chip's Learning Quest\" (PCLQ) is recorded, as well as previous experience with digital learning games and the acceptance and motivation to use new technologies. The purpose of this article is to test the PCLQ digital learning game, developed according to the EDUMING concept, as part of an exploratory study regarding its usability, acceptance and suitability for use in schools. The study is intended as a first empirical approach to practical testing of the concept.","authors":["Stefan Pietrusky"],"url":"https://arxiv.org/abs/2504.13878"}
{"created":"2025-04-22","title":"Ambient Listening in Clinical Practice: Evaluating EPIC Signal Data Before and After Implementation and Its Impact on Physician Workload","abstract":"The widespread adoption of EHRs following the HITECH Act has increased the clinician documentation burden, contributing to burnout. Emerging technologies, such as ambient listening tools powered by generative AI, offer real-time, scribe-like documentation capabilities to reduce physician workload. This study evaluates the impact of ambient listening tools implemented at UCI Health by analyzing EPIC Signal data to assess changes in note length and time spent on notes. Results show significant reductions in note-taking time and an increase in note length, particularly during the first-month post-implementation. Findings highlight the potential of AI-powered documentation tools to improve clinical efficiency. Future research should explore adoption barriers, long-term trends, and user experiences to enhance the scalability and sustainability of ambient listening technology in clinical practice.","authors":["Yawen Guo","Di Hu","Jiayuan Wang","Kai Zheng","Danielle Perret","Deepti Pandita","Steven Tam"],"url":"https://arxiv.org/abs/2504.13879"}
{"created":"2025-04-22","title":"An AI-powered Public Health Automated Kiosk System for Personalized Care: An Experimental Pilot Study","abstract":"Background: The HERMES Kiosk (Healthcare Enhanced Recommendations through Artificial Intelligence & Expertise System) is designed to provide personalized Over-the-Counter (OTC) medication recommendations, addressing the limitations of traditional health kiosks. It integrates an advanced GAMENet model enhanced with Graph Attention Networks (GAT) and Multi-Head Cross-Attention (MHCA) while ensuring user privacy through federated learning. This paper outlines the conceptual design and architecture of HERMES, with a focus on deployment in high-traffic public areas. Methods: HERMES analyzes self-reported symptoms and anonymized medical histories using AI algorithms to generate context-aware OTC medication recommendations. The system was initially trained using Electronic Health Records (EHR) from the MIMIC-III dataset (6,350 patients) and Drug-Drug Interaction (DDI) data from the TWOSIDES database, incorporating the top 90 severity DDI types. Real-time DDI checks and ATC-mapped drug codes further improve safety. The kiosk is designed for accessibility, offering multilingual support, large fonts, voice commands, and Braille compatibility. A built-in health education library promotes preventive care and health literacy. A survey was conducted among 10 medical professionals to evaluate its potential applications in medicine. Results: Preliminary results show that the enhanced GAMENet model achieved a Precision-Recall AUC (PRAUC) of 0.74, outperforming the original model. These findings suggest a strong potential for delivering accurate and secure healthcare recommendations in public settings. Conclusion: HERMES demonstrates how AI-driven, privacy-preserving kiosks can enhance public health access, empower users, and alleviate burdens on healthcare systems. Future work will focus on real-world deployment, usability testing, and scalability for broader adoption.","authors":["Sonya Falahati","Morteza Alizadeh","Zhino Safahi","Navid Khaledian","Mohsen Alambardar Meybodi","Mohammad R. Salmanpour"],"url":"https://arxiv.org/abs/2504.13880"}
{"created":"2025-04-22","title":"Exploring the Use of Social Robots to Prepare Children for Radiological Procedures: A Focus Group Study","abstract":"When children are anxious or scared, it can be hard for them to stay still or follow instructions during medical procedures, making the process more challenging and affecting procedure results. This is particularly true for radiological procedures, where long scan times, confined spaces, and loud noises can cause children to move, significantly impacting scan quality. To this end, sometimes children are sedated, but doctors are constantly seeking alternative non-pharmacological solutions. This work aims to explore how social robots could assist in preparing children for radiological procedures. We have conducted a focus group discussion with five hospital stakeholders, namely radiographers, paediatricians, and clinical engineers, to explore (i) the context regarding children's preparation for radiological procedures, hence their needs and how children are currently prepared, and (ii) the potential role of social robots in this process. The discussion was transcribed and analysed using thematic analysis. Among our findings, we identified three potential roles for a social robot in this preparation process: offering infotainment in the waiting room, acting as a guide within the hospital, and assisting radiographers in preparing children for the procedure. We hope that insights from this study will inform the design of social robots for pediatric healthcare.","authors":["Massimiliano Nigro","Andrea Righini","Micol Spitale"],"url":"https://arxiv.org/abs/2504.13881"}
{"created":"2025-04-22","title":"Toward Automated Qualitative Analysis: Leveraging Large Language Models for Tutoring Dialogue Evaluation","abstract":"Our study introduces an automated system leveraging large language models (LLMs) to assess the effectiveness of five key tutoring strategies: 1. giving effective praise, 2. reacting to errors, 3. determining what students know, 4. helping students manage inequity, and 5. responding to negative self-talk. Using a public dataset from the Teacher-Student Chatroom Corpus, our system classifies each tutoring strategy as either being employed as desired or undesired. Our study utilizes GPT-3.5 with few-shot prompting to assess the use of these strategies and analyze tutoring dialogues. The results show that for the five tutoring strategies, True Negative Rates (TNR) range from 0.655 to 0.738, and Recall ranges from 0.327 to 0.432, indicating that the model is effective at excluding incorrect classifications but struggles to consistently identify the correct strategy. The strategy \\textit{helping students manage inequity} showed the highest performance with a TNR of 0.738 and Recall of 0.432. The study highlights the potential of LLMs in tutoring strategy analysis and outlines directions for future improvements, including incorporating more advanced models for more nuanced feedback.","authors":["Megan Gu","Chloe Qianhui Zhao","Claire Liu","Nikhil Patel","Jahnvi Shah","Jionghao Lin","Kenneth R. Koedinger"],"url":"https://arxiv.org/abs/2504.13882"}
{"created":"2025-04-22","title":"Hybrid Deep Learning Model to Estimate Cognitive Effort from fNIRS Signals in Educational Game Playing","abstract":"This study estimates cognitive effort (CE) based on functional near-infrared spectroscopy (fNIRS) data and performance scores using a hybrid deep learning model. The estimation of CE enables educators to modify material to enhance learning effectiveness and student engagement. Relative neural efficiency (RNE) and relative neural involvement (RNI) are two metrics that have been used to represent CE. To estimate RNE and RNI we need hemodynamic response in the brain and the performance score of a task.We collected oxygenated hemoglobin ($\\Delta \\mathrm{HbO}$). Sixteen participants answered 16 questions in a unity-based educational game, each with a 30-second response time. We used deep learning models to predict the performance score and estimate RNE and RNI to understand CE. The study compares traditional machine learning techniques with deep learning models such as CNN, LSTM, BiLSTM, and a hybrid CNN-GRU to determine which approach provides better accuracy in predicting performance scores. The result shows that the hybrid CNN-GRU gives better performance with 78.36\\% training accuracy and 73.08\\% test accuracy than other models. We performed XGBoost on the extracted GRU feature and got the highest accuracy (69.23\\%). This suggests that the features learned from this hybrid model generalize better even in traditional machine learning algorithms. We used the $\\Delta \\mathrm{HbO}$ and predicted score to calculate RNE and RNI to observe cognitive effort in our four test cases. Our result shows that even with moderate accuracy, the predicted RNE and RNI closely follows the actual trends. we also observed that when participants were in a state of high CE, introducing rest led decrease of CE. These findings can be helpful to design and improve learning environments and provide valuable insights in learning materials.","authors":["Shayla Sharmin","Roghayeh Leila Barmaki"],"url":"https://arxiv.org/abs/2504.13883"}
{"created":"2025-04-22","title":"Towards a Multimodal Document-grounded Conversational AI System for Education","abstract":"Multimedia learning using text and images has been shown to improve learning outcomes compared to text-only instruction. But conversational AI systems in education predominantly rely on text-based interactions while multimodal conversations for multimedia learning remain unexplored. Moreover, deploying conversational AI in learning contexts requires grounding in reliable sources and verifiability to create trust. We present MuDoC, a Multimodal Document-grounded Conversational AI system based on GPT-4o, that leverages both text and visuals from documents to generate responses interleaved with text and images. Its interface allows verification of AI generated content through seamless navigation to the source. We compare MuDoC to a text-only system to explore differences in learner engagement, trust in AI system, and their performance on problem-solving tasks. Our findings indicate that both visuals and verifiability of content enhance learner engagement and foster trust; however, no significant impact in performance was observed. We draw upon theories from cognitive and learning sciences to interpret the findings and derive implications, and outline future directions for the development of multimodal conversational AI systems in education.","authors":["Karan Taneja","Anjali Singh","Ashok K. Goel"],"url":"https://arxiv.org/abs/2504.13884"}
{"created":"2025-04-22","title":"User Satisfaction -- UX Design Strategies for Seamless Virtual Experience","abstract":"User Experience (UX) in virtual worlds is a fast-developing discipline that requires creative design concepts to overcome the divide between physical and virtual interaction. This research investigates primary principles and techniques to improve UX in virtual experiences based on usability, accessibility, user engagement, and technology advancements. It gives detailed insight into trends, issues, and prospects for UX design of virtual applications that guarantee an efficient, easy-to-use, and immersive experience.","authors":["Harish Vijayakumar"],"url":"https://arxiv.org/abs/2504.13885"}
{"created":"2025-04-22","title":"Quantifying Emotional Arousal through Pupillary Response: A Novel Approach for Isolating the Luminosity Effect and Predicting Affective States","abstract":"Researchers have long recognized pupil response as a potential objective indicator of emotional arousal; however, confounding factors, particularly luminosity of stimuli and the ambient environment, have limited its usefulness in detecting emotions. This study presents a new approach to isolate and remove the effect of luminosity on pupil dilation, obtaining the component of pupil dilation due only to emotional arousal. Our model predicts the pupil size due to luminosity only as a function of the screen luminosity and adapts to individual differences in pupil response to light, different types and configurations of monitors by using a calibration procedure. The predicted pupil size has an average correlation with the measured pupil size of 0.76, an R2 of 0.58, and a normalized root mean square error (NRMSE) of 0.14. Here, we demonstrate that our model can be used simply to calculate emotional arousal. We showed 32 video clips with different content and emotional intensity to 47 participants, who, after each video, reported their level of emotional arousal. We then calculated the pupil size due only to luminosity and subtracted it from the total recorded pupil size, obtaining the component due only to emotional arousal. From the latter, we predicted the arousal of each participant for each video. We obtained an average correlation between predicted and self-reported arousal of 0.65, an R2 of 0.43, and an NRMSE of 0.27. Instead, using the measured pupil size, without subtracting the component due to luminosity, we obtained dramatically worse results. an average correlation between the predicted and self-reported arousal of 0.26, an R2 of 0.09, and an NRMSE of 0.42. Our results highlight that separating the emotional and luminosity components from pupillary responses is critical to accurately and precisely predicting arousal.","authors":["Zeel Pansara","Gabriele Navyte","Tatiana Freitas-Mendes","Camila Bottger","Edoardo Franco","Luca Citi","Erik S. Jacobi","Giulia L. Poerio","Helge Gillmeister","Caterina Cinel","Vito De Feo"],"url":"https://arxiv.org/abs/2504.13886"}
{"created":"2025-04-22","title":"AI as a deliberative partner fosters intercultural empathy for Americans but fails for Latin American participants","abstract":"Despite the growing integration of AI chatbots as conversational agents in public discourse, empirical evidence regarding their capacity to foster intercultural empathy remains limited. Using a randomized dialogue experiment, we examined how different types of AI chatbot interaction, i.e., deliberative versus non-deliberative and culturally aligned versus non-aligned, affect intercultural empathy across cultural groups. Results show that deliberative conversations increased intercultural empathy among American participants but not Latin American participants, who perceived AI responses as culturally inaccurate and failing to represent their cultural contexts and perspectives authentically. Real-time interaction analyses reveal that these differences stem from cultural knowledge gaps inherent in Large Language Models. Despite explicit prompting and instruction to represent cultural perspectives in participants' native languages, AI systems still exhibit significant disparities in cultural representation. This highlights the importance of designing AI systems capable of culturally authentic engagement in deliberative conversations. Our study contributes to deliberation theory and AI alignment research by underscoring AI's role in intercultural dialogue and the persistent challenge of representational asymmetry in democratic discourse.","authors":["Isabel Villanueva","Tara Bobinac","Binwei Yao","Junjie Hu","Kaiping Chen"],"url":"https://arxiv.org/abs/2504.13887"}
{"created":"2025-04-22","title":"Kanji Workbook: A Writing-Based Intelligent Tutoring System for Learning Proper Japanese Kanji Writing Technique with Instructor-Emulated Assessment","abstract":"Kanji script writing is a skill that is often introduced to novice Japanese foreign language students for achieving Japanese writing mastery, but often poses difficulties to students with primarily English fluency due to their its vast differences with written English. Instructors often introduce various pedagogical methods -- such as visual structure and written techniques -- to assist students in kanji study, but may lack availability providing direct feedback on students' writing outside of class. Current educational applications are also limited due to lacking richer instructor-emulated feedback. We introduce Kanji Workbook, a writing-based intelligent tutoring system for students to receive intelligent assessment that emulates human instructor feedback. Our interface not only leverages students' computing devices for allowing them to learn, practice, and review the writing of prompted characters from their course's kanji script lessons, but also provides a diverse set of writing assessment metrics -- derived from instructor interviews and classroom observation insights -- through intelligent scoring and visual animations. We deployed our interface onto novice- and intermediate-level university courses over an entire academic year, and observed that interface users on average achieved higher course grades than their peers and also reacted positively to our interface's various features.","authors":["Paul Taele","Jung In Koh","Tracy Hammond"],"url":"https://arxiv.org/abs/2504.13888"}
{"created":"2025-04-22","title":"Maestoso: An Intelligent Educational Sketching Tool for Learning Music Theory","abstract":"Learning music theory not only has practical benefits for musicians to write, perform, understand, and express music better, but also for both non-musicians to improve critical thinking, math analytical skills, and music appreciation. However, current external tools applicable for learning music theory through writing when human instruction is unavailable are either limited in feedback, lacking a written modality, or assuming already strong familiarity of music theory concepts. In this paper, we describe Maestoso, an educational tool for novice learners to learn music theory through sketching practice of quizzed music structures. Maestoso first automatically recognizes students' sketched input of quizzed concepts, then relies on existing sketch and gesture recognition techniques to automatically recognize the input, and finally generates instructor-emulated feedback. From our evaluations, we demonstrate that Maestoso performs reasonably well on recognizing music structure elements and that novice students can comfortably grasp introductory music theory in a single session.","authors":["Paul Taele","Laura Barreto","Tracy Hammond"],"url":"https://arxiv.org/abs/2504.13889"}
{"created":"2025-04-22","title":"Measuring Mental Health Variables in Computational Research: Toward Validated, Dimensional, and Transdiagnostic Approaches","abstract":"Computational mental health research develops models to predict and understand psychological phenomena, but often relies on inappropriate measures of psychopathology constructs, undermining validity. We identify three key issues: (1) reliance on unvalidated measures (e.g., self-declared diagnosis) over validated ones (e.g., diagnosis by clinician); (2) treating mental health constructs as categorical rather than dimensional; and (3) focusing on disorder-specific constructs instead of transdiagnostic ones. We outline the benefits of using validated, dimensional, and transdiagnostic measures and offer practical recommendations for practitioners. Using valid measures that reflect the nature and structure of psychopathology is essential for computational mental health research.","authors":["Chen Shani","Elizabeth C. Stade"],"url":"https://arxiv.org/abs/2504.13890"}
{"created":"2025-04-22","title":"Mozualization: Crafting Music and Visual Representation with Multimodal AI","abstract":"In this work, we introduce Mozualization, a music generation and editing tool that creates multi-style embedded music by integrating diverse inputs, such as keywords, images, and sound clips (e.g., segments from various pieces of music or even a playful cat's meow). Our work is inspired by the ways people express their emotions -- writing mood-descriptive poems or articles, creating drawings with warm or cool tones, or listening to sad or uplifting music. Building on this concept, we developed a tool that transforms these emotional expressions into a cohesive and expressive song, allowing users to seamlessly incorporate their unique preferences and inspirations. To evaluate the tool and, more importantly, gather insights for its improvement, we conducted a user study involving nine music enthusiasts. The study assessed user experience, engagement, and the impact of interacting with and listening to the generated music.","authors":["Wanfang Xu","Lixiang Zhao","Haiwen Song","Xinheng Song","Zhaolin Lu","Yu Liu","Min Chen","Eng Gee Lim","Lingyun Yu"],"url":"https://arxiv.org/abs/2504.13891"}
{"created":"2025-04-22","title":"TALLMesh: a simple application for performing Thematic Analysis with Large Language Models","abstract":"Thematic analysis (TA) is a widely used qualitative research method for identifying and interpreting patterns within textual data, such as qualitative interviews. Recent research has shown that it is possible to satisfactorily perform TA using Large Language Models (LLMs). This paper presents a novel application using LLMs to assist researchers in conducting TA. The application enables users to upload textual data, generate initial codes and themes. All of this is possible through a simple Graphical User Interface, (GUI) based on the streamlit framework, working with python scripts for the analysis, and using Application Program Interfaces of LLMs. Having a GUI is particularly important for researchers in fields where coding skills may not be prevalent, such as social sciences or humanities. With the app, users can iteratively refine codes and themes adopting a human-in-the-loop process, without the need to work with programming and scripting. The paper describes the application key features, highlighting its potential for qualitative research while preserving methodological rigor. The paper discusses the design and interface of the app and outlines future directions for this work.","authors":["Stefano De Paoli","Alex Fawzi"],"url":"https://arxiv.org/abs/2504.13892"}
{"created":"2025-04-22","title":"Semantic Direct Modeling","abstract":"Current direct modeling systems limit users to low-level interactions with vertices, edges, and faces, forcing designers to manage detailed geometric elements rather than focusing on high-level design intent. This paper introduces semantic direct modeling (SDM), a novel approach that lifts direct modeling from low-level geometric modifications to high-level semantic interactions. This is achieved by utilizing a large language model (LLM) fine-tuned with CAD-specific prompts, which can guide the LLM to reason through design intent and accurately interpret CAD commands, thereby allowing designers to express their intent using natural language. Additionally, SDM maps design intent to the corresponding geometric features in the CAD model through a new conditional, context-sensitive feature recognition method, which uses generative AI to dynamically assign feature labels based on design intent. Together, they enable a seamless flow from high-level design intent to low-level geometric modifications, bypassing tedious software interactions. The effectiveness of SDM has been validated through real mechanical design cases.","authors":["Qiang Zou","Shuo Liu"],"url":"https://arxiv.org/abs/2504.13893"}
{"created":"2025-04-22","title":"State of the Art on Artificial Intelligence Resources for Interaction Media Design in Digital Cultural Heritage","abstract":"This paper explores the integration of Artificial Intelligence (AI) in the design of interactive experiences for Cultural Heritage (CH). Previous studies indeed either miss to represent the specificity of the CH or mention possible tools without making a clear reference to a structured Interaction Design (IxD) workflow. The study also attempts to overcome one of the major limitations of traditional literature review, which may fail to capture proprietary tools whose release is rarely accompanied by academic publications. Besides the analysis of previous research, the study proposes a possible workflow for IxD in CH, subdivided into phases and tasks: for each of them, this paper proposes possible AI-based tools that can support the activity of designers, curators, and CH professionals. The review concludes with a final section outlining future paths for research and development in this domain.","authors":["Manuele Veggi"],"url":"https://arxiv.org/abs/2504.13894"}
{"created":"2025-04-22","title":"\"They've Over-Emphasized That One Search\": Controlling Unwanted Content on TikTok's For You Page","abstract":"Modern algorithmic recommendation systems seek to engage users through behavioral content-interest matching. While many platforms recommend content based on engagement metrics, others like TikTok deliver interest-based content, resulting in recommendations perceived to be hyper-personalized compared to other platforms. TikTok's robust recommendation engine has led some users to suspect that the algorithm knows users \"better than they know themselves,\" but this is not always true. In this paper, we explore TikTok users' perceptions of recommended content on their For You Page (FYP), specifically calling attention to unwanted recommendations. Through qualitative interviews of 14 current and former TikTok users, we find themes of frustration with recommended content, attempts to rid themselves of unwanted content, and various degrees of success in eschewing such content. We discuss implications in the larger context of folk theorization and contribute concrete tactical and behavioral examples of algorithmic persistence.","authors":["Julie A. Vera","Sourojit Ghosh"],"url":"https://arxiv.org/abs/2504.13895"}
{"created":"2025-04-22","title":"Educational Twin: The Influence of Artificial XR Expert Duplicates on Future Learning","abstract":"Currently, it is impossible for educators to be in multiple places simultaneously and teach each student individually. Technologies such as Extended Reality (XR) and Artificial Intelligence (AI) enable the creation of realistic educational copies of experts that preserve not only visual and mental characteristics but also social aspects crucial for learning. However, research in this area is limited, which opens new questions for future work. This paper discusses how these human digital twins can potentially improve aspects like scalability, engagement, and preservation of social learning factors. While this technology offers benefits, it also introduces challenges related to educator autonomy, social interaction shifts, and ethical considerations such as privacy, bias, and identity preservation. We outline key research questions that need to be addressed to ensure that human digital twins enhance the social aspects of education instead of harming them.","authors":["Clara Sayffaerth"],"url":"https://arxiv.org/abs/2504.13896"}
{"created":"2025-04-22","title":"Show Me How: Benefits and Challenges of Agent-Augmented Counterfactual Explanations for Non-Expert Users","abstract":"Counterfactual explanations offer actionable insights by illustrating how changes to inputs can lead to different outcomes. However, these explanations often suffer from ambiguity and impracticality, limiting their utility for non-expert users with limited AI knowledge. Augmenting counterfactual explanations with Large Language Models (LLMs) has been proposed as a solution, but little research has examined their benefits and challenges for non-experts. To address this gap, we developed a healthcare-focused system that leverages conversational AI agents to enhance counterfactual explanations, offering clear, actionable recommendations to help patients at high risk of cardiovascular disease (CVD) reduce their risk. Evaluated through a mixed-methods study with 34 participants, our findings highlight the effectiveness of agent-augmented counterfactuals in improving actionable recommendations. Results further indicate that users with prior experience using conversational AI demonstrated greater effectiveness in utilising these explanations compared to novices. Furthermore, this paper introduces a set of generic guidelines for creating augmented counterfactual explanations, incorporating safeguards to mitigate common LLM pitfalls, such as hallucinations, and ensuring the explanations are both actionable and contextually relevant for non-expert users.","authors":["Aditya Bhattacharya","Tim Vanherwegen","Katrien Verbert"],"url":"https://arxiv.org/abs/2504.13897"}
{"created":"2025-04-22","title":"The Human Robot Social Interaction (HSRI) Dataset: Benchmarking Foundational Models' Social Reasoning","abstract":"Our work aims to advance the social reasoning of embodied artificial intelligence (AI) agents in real-world social interactions. Recently, language models (LMs) and foundational models (FMs) are being utilized as automatic evaluators of human-AI interactions with the goal of eventually being used to improve the policy of the AI agent. To enable further research in this direction, we introduce a large-scale real-world Human Robot Social Interaction (HSRI) Dataset to benchmark the capabilities of LMs and FMs to identify and reason about social interactions, specifically with regard to robot social errors and competencies . Our dataset consists of 400 real-world human social robot interaction videos and over 10K annotations, detailing the robot's social errors, competencies, rationale, and corrective actions, capturing unique aspects of human-AI interaction only present in real-world interactions. To further assess AI models' ability to reason about social interactions, we propose eight new benchmark tasks for evaluating centered around whether AI models can (1) evaluate social interactions via detecting social errors and competencies, (2) identify the explanatory factors associated to errors and competencies, (3) understand the flow of real-world social interactions, and (4) provide reasons and corrective actions for social errors. Human studies and experiments with modern LMs and FMs reveal that current models struggle with these tasks, demonstrating that our dataset and benchmark provides a step forward towards socially intelligent AI.","authors":["Dong Won Lee","Yubin Kim","Denison Guvenoz","Sooyeon Jeong","Parker Malachowsky","Louis-Philippe Morency","Cynthia Breazeal","Hae Won Park"],"url":"https://arxiv.org/abs/2504.13898"}
{"created":"2025-04-22","title":"Predicting Satisfaction of Counterfactual Explanations from Human Ratings of Explanatory Qualities","abstract":"Counterfactual explanations are a widely used approach in Explainable AI, offering actionable insights into decision-making by illustrating how small changes to input data can lead to different outcomes. Despite their importance, evaluating the quality of counterfactual explanations remains an open problem. Traditional quantitative metrics, such as sparsity or proximity, fail to fully account for human preferences in explanations, while user studies are insightful but not scalable. Moreover, relying only on a single overall satisfaction rating does not lead to a nuanced understanding of why certain explanations are effective or not. To address this, we analyze a dataset of counterfactual explanations that were evaluated by 206 human participants, who rated not only overall satisfaction but also seven explanatory criteria: feasibility, coherence, complexity, understandability, completeness, fairness, and trust. Modeling overall satisfaction as a function of these criteria, we find that feasibility (the actionability of suggested changes) and trust (the belief that the changes would lead to the desired outcome) consistently stand out as the strongest predictors of user satisfaction, though completeness also emerges as a meaningful contributor. Crucially, even excluding feasibility and trust, other metrics explain 58% of the variance, highlighting the importance of additional explanatory qualities. Complexity appears independent, suggesting more detailed explanations do not necessarily reduce satisfaction. Strong metric correlations imply a latent structure in how users judge quality, and demographic background significantly shapes ranking patterns. These insights inform the design of counterfactual algorithms that adapt explanatory qualities to user expertise and domain context.","authors":["Marharyta Domnich","Rasmus Moorits Veski","Julius V\\\"alja","Kadi Tulver","Raul Vicente"],"url":"https://arxiv.org/abs/2504.13899"}
{"created":"2025-04-22","title":"Supporting Students' Reading and Cognition with AI","abstract":"With the rapid adoption of AI tools in learning contexts, it is vital to understand how these systems shape users' reading processes and cognitive engagement. We collected and analyzed text from 124 sessions with AI tools, in which students used these tools to support them as they read assigned readings for an undergraduate course. We categorized participants' prompts to AI according to Bloom's Taxonomy of educational objectives -- Remembering, Understanding, Applying, Analyzing, Evaluating. Our results show that ``Analyzing'' and ``Evaluating'' are more prevalent in users' second and third prompts within a single usage session, suggesting a shift toward higher-order thinking. However, in reviewing users' engagement with AI tools over several weeks, we found that users converge toward passive reading engagement over time. Based on these results, we propose design implications for future AI reading-support systems, including structured scaffolds for lower-level cognitive tasks (e.g., recalling terms) and proactive prompts that encourage higher-order thinking (e.g., analyzing, applying, evaluating). Additionally, we advocate for adaptive, human-in-the-loop features that allow students and instructors to tailor their reading experiences with AI, balancing efficiency with enriched cognitive engagement. Our paper expands the dialogue on integrating AI into academic reading, highlighting both its potential benefits and challenges.","authors":["Yue Fu","Alexis Hiniker"],"url":"https://arxiv.org/abs/2504.13900"}
{"created":"2025-04-22","title":"Examining Technology Perspectives of Older Adults with Mild Cognitive Impairment: A Scoping Review","abstract":"Mild cognitive impairment (MCI) affects a person's memory and how they think, feel or behave. Up to 20% of people over 65 years may get MCI and up to 15% of these may progress to dementia. Globally the occurrence of MCI is increasing, and technology is being explored for early intervention and to reduce strain on the aged-care sector. Theories of technology adoption predict that useful and easy-to-use solutions will have higher rates of adoption. This study adds to existing knowledge by reporting on analysis of a search across nine databases (ACM Digital Library, EBSCOhost CINAHL Plus with Full Text, EBSCOhost Computers and Applied Sciences Complete, Google Scholar, JMIR, IEEE Xplore, EBSCOhost Medline, Scopus, Web of Science Core Collection) for articles published between Jan 2014 and May 2024 which describe opinions of older people with MCI about technological solutions proposed for them, and feedback about how they prefer to engage with technology. Analysis of 83 articles suggests that existing solutions do address priority needs, however more work is needed to (i) improve ease of use, (ii) enable personalisation, (ii) explore interaction preferences and effectiveness of different interaction modes, (iv) enable multimodal interaction, and (v) integrate solutions seamlessly into daily routines.","authors":["Snezna B Schmidt","Stephen Isbel","Nathan M DCunha","Ram Subramanian","Blooma John"],"url":"https://arxiv.org/abs/2504.13901"}
{"created":"2025-04-22","title":"From Teacher to Colleague: How Coding Experience Shapes Developer Perceptions of AI Tools","abstract":"AI-assisted development tools promise productivity gains and improved code quality, yet their adoption among developers remains inconsistent. Prior research suggests that professional expertise influences technology adoption, but its role in shaping developers' perceptions of AI tools is unclear. We analyze survey data from 3380 developers to examine how coding experience relates to AI awareness, adoption, and the roles developers assign to AI in their workflow. Our findings reveal that coding experience does not predict AI adoption but significantly influences mental models of AI's role. Experienced developers are more likely to perceive AI as a junior colleague, a content generator, or assign it no role, whereas less experienced developers primarily view AI as a teacher. These insights suggest that AI tools must align with developers' expertise levels to drive meaningful adoption.","authors":["Ilya Zakharov","Ekaterina Koshchenko","Agnia Sergeyuk"],"url":"https://arxiv.org/abs/2504.13903"}
{"created":"2025-04-22","title":"Generative Framework for Personalized Persuasion: Inferring Causal, Counterfactual, and Latent Knowledge","abstract":"We hypothesize that optimal system responses emerge from adaptive strategies grounded in causal and counterfactual knowledge. Counterfactual inference allows us to create hypothetical scenarios to examine the effects of alternative system responses. We enhance this process through causal discovery, which identifies the strategies informed by the underlying causal structure that govern system behaviors. Moreover, we consider the psychological constructs and unobservable noises that might be influencing user-system interactions as latent factors. We show that these factors can be effectively estimated. We employ causal discovery to identify strategy-level causal relationships among user and system utterances, guiding the generation of personalized counterfactual dialogues. We model the user utterance strategies as causal factors, enabling system strategies to be treated as counterfactual actions. Furthermore, we optimize policies for selecting system responses based on counterfactual data. Our results using a real-world dataset on social good demonstrate significant improvements in persuasive system outcomes, with increased cumulative rewards validating the efficacy of causal discovery in guiding personalized counterfactual inference and optimizing dialogue policies for a persuasive dialogue system.","authors":["Donghuo Zeng","Roberto Legaspi","Yuewen Sun","Xinshuai Dong","Kazushi Ikeda","Peter Spirtes","Kun Zhang"],"url":"https://arxiv.org/abs/2504.13904"}
{"created":"2025-04-22","title":"MaRDMO: Future Gateway to FAIR Mathematical Data","abstract":"Mathematical research data plays a crucial role across scientific disciplines, yet its documentation and dissemination remain challenging due to the lack of standardized research data management practices. The MaRDMO Plugin addresses these challenges by integrating mathematical models, algorithms, and interdisciplinary workflows into the established framework of the Research Data Management Organiser (RDMO). Built on FAIR principles, MaRDMO enables structured documentation and retrieval of mathematical research data through guided questionnaires. It connects to multiple knowledge graphs, including MathModDB, MathAlgoDB, and the MaRDI Portal. Users can document and search for models, algorithms, and workflows via dynamic selection interfaces that also leverage other sources such as Wikidata. The plugin facilitates the export to the individual MaRDI services, ensuring data quality through automated validation. By embedding mathematical research data management into the widely adopted RDMO platform, MaRDMO represents a significant step toward making mathematical research data more findable, accessible, and reusable.","authors":["Marco Reidelbach"],"url":"https://arxiv.org/abs/2504.13905"}
{"created":"2025-04-22","title":"V2P Collision Warnings for Distracted Pedestrians: A Comparative Study with Traditional Auditory Alerts","abstract":"This study assesses a Vehicle-to-Pedestrian (V2P) collision warning system compared to conventional vehicle-issued auditory alerts in a real-world scenario simulating a vehicle on a fixed track, characterized by limited maneuverability and the need for timely pedestrian response. The results from analyzing speed variations show that V2P warnings are particularly effective for pedestrians distracted by phone use (gaming or listening to music), highlighting the limitations of auditory alerts in noisy environments. The findings suggest that V2P technology offers a promising approach to improving pedestrian safety in urban areas","authors":["Novel Certad","Enrico Del Re","Joshua Varughese","Cristina Olaverri-Monreal"],"url":"https://arxiv.org/abs/2504.13906"}
{"created":"2025-04-22","title":"AI-Assisted Conversational Interviewing: Effects on Data Quality and User Experience","abstract":"Standardized surveys scale efficiently but sacrifice depth, while conversational interviews improve response quality at the cost of scalability and consistency. This study bridges the gap between these methods by introducing a framework for AI-assisted conversational interviewing. To evaluate this framework, we conducted a web survey experiment where 1,800 participants were randomly assigned to text-based conversational AI agents, or \"textbots\", to dynamically probe respondents for elaboration and interactively code open-ended responses. We assessed textbot performance in terms of coding accuracy, response quality, and respondent experience. Our findings reveal that textbots perform moderately well in live coding even without survey-specific fine-tuning, despite slightly inflated false positive errors due to respondent acquiescence bias. Open-ended responses were more detailed and informative, but this came at a slight cost to respondent experience. Our findings highlight the feasibility of using AI methods to enhance open-ended data collection in web surveys.","authors":["Soubhik Barari","Jarret Angbazo","Natalie Wang","Leah M. Christian","Elizabeth Dean","Zoe Slowinski","Brandon Sepulvado"],"url":"https://arxiv.org/abs/2504.13908"}
{"created":"2025-04-22","title":"Mobile-Driven Incentive Based Exercise for Blood Glucose Control in Type 2 Diabetes","abstract":"We propose and create an incentive based recommendation algorithm aimed at improving the lifestyle of diabetic patients. This algorithm is integrated into a real world mobile application to provide personalized health recommendations. Initially, users enter data such as step count, calorie intake, gender, age, weight, height and blood glucose levels. When the data is preprocessed, the app identifies the personalized health and glucose management goals. The recommendation engine suggests exercise routines and dietary adjustments based on these goals. As users achieve their goals and follow these recommendations, they receive incentives, encouraging adherence and promoting positive health outcomes. Furthermore, the mobile application allows users to monitor their progress through descriptive analytics, which displays their daily activities and health metrics in graphical form. To evaluate the proposed methodology, the study was conducted with 10 participants, with type 2 diabetes for three weeks. The participants were recruited through advertisements and health expert references. The application was installed on the patient phone to use it for three weeks. The expert was also a part of this study by monitoring the patient health record. To assess the algorithm performance, we computed efficiency and proficiency. As a result, the algorithm showed proficiency and efficiency scores of 90% and 92%, respectively. Similarly, we computed user experience with application in terms of attractiveness, hedonic and pragmatic quality, involving 35 people in the study. As a result, it indicated an overall positive user response. The findings show a clear positive correlation between exercise and rewards, with noticeable improvements observed in user outcomes after exercise.","authors":["Wasim Abbas","Hafiz Syed Muhammad Bilal","Asim Abbas","Muhammad Afzal","Je-Hoon Lee"],"url":"https://arxiv.org/abs/2504.13909"}
{"created":"2025-04-22","title":"Koopman Spectral Analysis and System Identification for Stochastic Dynamical Systems via Yosida Approximation of Generators","abstract":"System identification and Koopman spectral analysis are crucial for uncovering physical laws and understanding the long-term behaviour of stochastic dynamical systems governed by stochastic differential equations (SDEs). In this work, we propose a novel method for estimating the Koopman generator of systems of SDEs, based on the theory of resolvent operators and the Yosida approximation. This enables both spectral analysis and accurate estimation and reconstruction of system parameters. The proposed approach relies on only mild assumptions about the system and effectively avoids the error amplification typically associated with direct numerical differentiation. It remains robust even under low sampling rates or with only a single observed trajectory, reliably extracting dominant spectral modes and dynamic features. We validate our method on two simple systems and compare it with existing techniques as benchmarks. The experimental results demonstrate the effectiveness and improved performance of our approach in system parameter estimation, spectral mode extraction, and overall robustness.","authors":["Jun Zhou","Yiming Meng","Jun Liu"],"url":"https://arxiv.org/abs/2504.13912"}
{"created":"2025-04-22","title":"Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning","abstract":"We introduce Seed-Thinking-v1.5, capable of reasoning through thinking before responding, resulting in improved performance on a wide range of benchmarks. Seed-Thinking-v1.5 achieves 86.7 on AIME 2024, 55.0 on Codeforces and 77.3 on GPQA, demonstrating excellent reasoning abilities in STEM and coding. Beyond reasoning tasks, the method demonstrates notable generalization across diverse domains. For instance, it surpasses DeepSeek R1 by 8% in win rate on non-reasoning tasks, indicating its broader applicability. Compared to other state-of-the-art reasoning models, Seed-Thinking-v1.5 is a Mixture-of-Experts (MoE) model with a relatively small size, featuring 20B activated and 200B total parameters. As part of our effort to assess generalized reasoning, we develop two internal benchmarks, BeyondAIME and Codeforces, both of which will be publicly released to support future research.","authors":["ByteDance Seed",":","Yufeng Yuan","Yu Yue","Mingxuan Wang","Xiaochen Zuo","Jiaze Chen","Lin Yan","Wenyuan Xu","Chi Zhang","Xin Liu","Chengyi Wang","TianTian Fan","Lingjun Liu","Qiying Yu","Xiangpeng Wei","Zhiqi Lin","Ruofei Zhu","Qingping Yang","Chengzhi Wei","Jerry He","Guanlin Liu","Zheng Wu","Xiangyu Yu","Zhicheng Liu","Jingjing Xu","Jiangjie Chen","Haojie Pan","Shengding Hu","Zhengyin Du","Wenqi Wang","Zewei Sun","Chenwei Lou","Bole Ma","Zihan Wang","Mofan Zhang","Wang Zhang","Gaohong Liu","Kaihua Jiang","Haibin Lin","Ru Zhang","Juncai Liu","Li Han","Jinxin Chi","Wenqiang Zhang","Jiayi Xu","Jun Yuan","Zhen Xiao","Yuqiao Xian","Jingqiao Wu","Kai Hua","Na Zhou","Jianhui Duan","Heyang Lu","Changbao Wang","Jinxiang Ou","Shihang Wang","Xiaoran Jin","Xuesong Yao","Chengyin Xu","Wenchang Ma","Zhecheng An","Renming Pang","Xia Xiao","Jing Su","Yuyu Zhang","Tao Sun","Kaibo Liu","Yifan Sun","Kai Shen","Sijun Zhang","Yiyuan Ma","Xingyan Bin","Ji Li","Yao Luo","Deyi Liu","Shiyi Zhan","Yunshui Li","Yuan Yang","Defa Zhu","Ke Shen","Chenggang Li","Xun Zhou","Liang Xiang","Yonghui Wu"],"url":"https://arxiv.org/abs/2504.13914"}
{"created":"2025-04-22","title":"Memory-efficient Streaming VideoLLMs for Real-time Procedural Video Understanding","abstract":"We introduce ProVideLLM, an end-to-end framework for real-time procedural video understanding. ProVideLLM integrates a multimodal cache configured to store two types of tokens - verbalized text tokens, which provide compressed textual summaries of long-term observations, and visual tokens, encoded with DETR-QFormer to capture fine-grained details from short-term observations. This design reduces token count by 22x over existing methods in representing one hour of long-term observations while effectively encoding fine-granularity of the present. By interleaving these tokens in our multimodal cache, ProVideLLM ensures sub-linear scaling of memory and compute with video length, enabling per-frame streaming inference at 10 FPS and streaming dialogue at 25 FPS, with a minimal 2GB GPU memory footprint. ProVideLLM also sets new state-of-the-art results on six procedural tasks across four datasets.","authors":["Dibyadip Chatterjee","Edoardo Remelli","Yale Song","Bugra Tekin","Abhay Mittal","Bharat Bhatnagar","Necati Cihan Camg\\\"oz","Shreyas Hampali","Eric Sauser","Shugao Ma","Angela Yao","Fadime Sener"],"url":"https://arxiv.org/abs/2504.13915"}
{"created":"2025-04-22","title":"Task Matters: Investigating Human Questioning Behavior in Different Household Service for Learning by Asking Robots","abstract":"Learning by Asking (LBA) enables robots to identify knowledge gaps during task execution and acquire the missing information by asking targeted questions. However, different tasks often require different types of questions, and how to adapt questioning strategies accordingly remains underexplored. This paper investigates human questioning behavior in two representative household service tasks: a Goal-Oriented task (refrigerator organization) and a Process-Oriented task (cocktail mixing). Through a human-human study involving 28 participants, we analyze the questions asked using a structured framework that encodes each question along three dimensions: acquired knowledge, cognitive process, and question form. Our results reveal that participants adapt both question types and their temporal ordering based on task structure. Goal-Oriented tasks elicited early inquiries about user preferences, while Process-Oriented tasks led to ongoing, parallel questioning of procedural steps and preferences. These findings offer actionable insights for developing task-sensitive questioning strategies in LBA-enabled robots for more effective and personalized human-robot collaboration.","authors":["Yuanda Hu","Hou Jiani","Zhang Junyu","Yate Ge","Xiaohua Sun","Weiwei Guo"],"url":"https://arxiv.org/abs/2504.13916"}
{"created":"2025-04-22","title":"Modular Pet Feeding Device","abstract":"This paper introduces a modular pet feeding device that combines automated feeding, health monitoring, and behavioral insights for modern pet care. Unlike traditional feeders, it features a wide-angle camera and microphone for food and water level assessment, pet approach detection, and sound monitoring. The device also includes an AI-enabled neckband to track heart rate, enabling early detection of unusual behaviors or health concerns. The AI system analyzes feeding history, behavior, and health data to provide personalized care suggestions, optimizing feeding times, portions, and dietary recommendations to improve pet well-being.","authors":["Vyshnav Kumar P","Vinayak CM","Thomson Gigi","Sulabh Bashyal","Janaki Kandasamy"],"url":"https://arxiv.org/abs/2504.13917"}
{"created":"2025-04-22","title":"Modeling the quantum-like dynamics of human reliability ratings in Human-AI interactions by interaction dependent Hamiltonians","abstract":"As our information environments become ever more powered by artificial intelligence (AI), the phenomenon of trust in a human's interactions with this intelligence is becoming increasingly pertinent. For example, in the not too distant future, there will be teams of humans and intelligent robots involved in dealing with the repercussions of high-risk disaster situations such as hurricanes, earthquakes, or nuclear accidents. Even in such conditions of high uncertainty, humans and intelligent machines will need to engage in shared decision making, and trust is fundamental to the effectiveness of these interactions. A key challenge in modeling the dynamics of this trust is to provide a means to incorporate sensitivity to fluctuations in human trust judgments. In this article, we explore the ability of Quantum Random Walk models to model the dynamics of trust in human-AI interactions, and to integrate a sensitivity to fluctuations in participant trust judgments based on the nature of the interaction with the AI. We found that using empirical parameters to inform the use of different Hamiltonians can provide a promising means to model the evolution of trust in Human-AI interactions.","authors":["Johan van der Meer","Pamela Hoyte","Luisa Roeder","Peter Bruza"],"url":"https://arxiv.org/abs/2504.13918"}
{"created":"2025-04-22","title":"Wireless Silent Speech Interface Using Multi-Channel Textile EMG Sensors Integrated into Headphones","abstract":"This paper presents a novel wireless silent speech interface (SSI) integrating multi-channel textile-based EMG electrodes into headphone earmuff for real-time, hands-free communication. Unlike conventional patch-based EMG systems, which require large-area electrodes on the face or neck, our approach ensures comfort, discretion, and wearability while maintaining robust silent speech decoding. The system utilizes four graphene/PEDOT:PSS-coated textile electrodes to capture speech-related neuromuscular activity, with signals processed via a compact ESP32-S3-based wireless readout module. To address the challenge of variable skin-electrode coupling, we propose a 1D SE-ResNet architecture incorporating squeeze-and-excitation (SE) blocks to dynamically adjust per-channel attention weights, enhancing robustness against motion-induced impedance variations. The proposed system achieves 96% accuracy on 10 commonly used voice-free control words, outperforming conventional single-channel and non-adaptive baselines. Experimental validation, including XAI-based attention analysis and t-SNE feature visualization, confirms the adaptive channel selection capability and effective feature extraction of the model. This work advances wearable EMG-based SSIs, demonstrating a scalable, low-power, and user-friendly platform for silent communication, assistive technologies, and human-computer interaction.","authors":["Chenyu Tang","Jos\\'ee Mallah","Dominika Kazieczko","Wentian Yi","Tharun Reddy Kandukuri","Edoardo Occhipinti","Bhaskar Mishra","Sunita Mehta","Luigi G. Occhipinti"],"url":"https://arxiv.org/abs/2504.13921"}
{"created":"2025-04-22","title":"Comprehensive Classification of Web Tracking Systems: Technological In-sights and Analysis","abstract":"Web tracking (WT) systems are advanced technologies used to monitor and analyze online user behavior. Initially focused on HTML and static webpages, these systems have evolved with the proliferation of IoT, edge computing, and Big Data, encompassing a broad array of interconnected devices with APIs, interfaces and computing nodes for interaction. WT systems are pivotal in technological innovation and business development, although trends like GDPR complicate data extraction and mandate transparency. Specifically, this study examines WT systems purely from a technological perspective, excluding organizational and privacy implications. A novel classification scheme based on technological architecture and principles is proposed, compared to two preexisting frameworks. The scheme categorizes WT systems into six classes, emphasizing technological mechanisms such as HTTP proto-cols, APIs, and user identification techniques. Additionally, a survey of over 1,000 internet users, conducted via Google Forms, explores user awareness of WT systems. Findings indicate that knowledge of WT technologies is largely unrelated to demographic factors such as age or gender but is strongly influenced by a user's background in computer science. Most users demonstrate only a basic understanding of WT tools, and this awareness does not correlate with heightened concerns about data misuse. As such, the research highlights gaps in user education about WT technologies and underscores the need for a deeper examination of their technical underpinnings. This study provides a foundation for further exploration of WT systems from multiple perspectives, contributing to advance-ments in classification, implementation, and user awareness.","authors":["Tasoulas Theofanis","Gazis Alexandros","Tsohou Aggeliki"],"url":"https://arxiv.org/abs/2504.13922"}
{"created":"2025-04-22","title":"Evaluation and Incident Prevention in an Enterprise AI Assistant","abstract":"Enterprise AI Assistants are increasingly deployed in domains where accuracy is paramount, making each erroneous output a potentially significant incident. This paper presents a comprehensive framework for monitoring, benchmarking, and continuously improving such complex, multi-component systems under active development by multiple teams. Our approach encompasses three key elements: (1) a hierarchical ``severity'' framework for incident detection that identifies and categorizes errors while attributing component-specific error rates, facilitating targeted improvements; (2) a scalable and principled methodology for benchmark construction, evaluation, and deployment, designed to accommodate multiple development teams, mitigate overfitting risks, and assess the downstream impact of system modifications; and (3) a continual improvement strategy leveraging multidimensional evaluation, enabling the identification and implementation of diverse enhancement opportunities. By adopting this holistic framework, organizations can systematically enhance the reliability and performance of their AI Assistants, ensuring their efficacy in critical enterprise environments. We conclude by discussing how this multifaceted evaluation approach opens avenues for various classes of enhancements, paving the way for more robust and trustworthy AI systems.","authors":["Akash V. Maharaj","David Arbour","Daniel Lee","Uttaran Bhattacharya","Anup Rao","Austin Zane","Avi Feller","Kun Qian","Yunyao Li"],"url":"https://arxiv.org/abs/2504.13924"}
{"created":"2025-04-22","title":"TigerGPT: A New AI Chatbot for Adaptive Campus Climate Surveys","abstract":"Campus climate surveys play a pivotal role in capturing how students, faculty, and staff experience university life, yet traditional methods frequently suffer from low participation and minimal follow-up. We present TigerGPT, a new AI chatbot that generates adaptive, context-aware dialogues enriched with visual elements. Through real-time follow-up prompts, empathetic messaging, and flexible topic selection, TigerGPT elicits more in-depth feedback compared to traditional static survey forms. Based on established principles of conversational design, the chatbot employs empathetic cues, bolded questions, and user-driven topic selection. It retains some role-based efficiency (e.g., collecting user role through quick clicks) but goes beyond static scripts by employing GenAI adaptiveness. In a pilot study with undergraduate students, we collected both quantitative metrics (e.g., satisfaction ratings) and qualitative insights (e.g., written comments). Most participants described TigerGPT as engaging and user-friendly; about half preferred it over conventional surveys, attributing this preference to its personalized conversation flow and supportive tone. The findings indicate that an AI survey chatbot is promising in gaining deeper insight into campus climate.","authors":["Jinwen Tang","Songxi Chen","Yi Shang"],"url":"https://arxiv.org/abs/2504.13925"}
{"created":"2025-04-22","title":"A Multi-Layered Research Framework for Human-Centered AI: Defining the Path to Explainability and Trust","abstract":"The integration of Artificial Intelligence (AI) into high-stakes domains such as healthcare, finance, and autonomous systems is often constrained by concerns over transparency, interpretability, and trust. While Human-Centered AI (HCAI) emphasizes alignment with human values, Explainable AI (XAI) enhances transparency by making AI decisions more understandable. However, the lack of a unified approach limits AI's effectiveness in critical decision-making scenarios. This paper presents a novel three-layered framework that bridges HCAI and XAI to establish a structured explainability paradigm. The framework comprises (1) a foundational AI model with built-in explainability mechanisms, (2) a human-centered explanation layer that tailors explanations based on cognitive load and user expertise, and (3) a dynamic feedback loop that refines explanations through real-time user interaction. The framework is evaluated across healthcare, finance, and software development, demonstrating its potential to enhance decision-making, regulatory compliance, and public trust. Our findings advance Human-Centered Explainable AI (HCXAI), fostering AI systems that are transparent, adaptable, and ethically aligned.","authors":["Chameera De Silva","Thilina Halloluwa","Dhaval Vyas"],"url":"https://arxiv.org/abs/2504.13926"}
{"created":"2025-04-22","title":"Ising Models with Hidden Markov Structure: Applications to Probabilistic Inference in Machine Learning","abstract":"In this paper, we investigate a Hamiltonian that incorporates Ising interactions between hidden $\\pm 1$ spins, alongside a data-dependent term that couples the hidden and observed variables. Specifically, we explore translation-invariant Gibbs measures (TIGM) of this Hamiltonian on Cayley trees. ","authors":["F. Herrera","U. A. Rozikov","M. V. Velasco"],"url":"https://arxiv.org/abs/2504.13927"}
{"created":"2025-04-22","title":"LLM-Driven NPCs: Cross-Platform Dialogue System for Games and Social Platforms","abstract":"NPCs in traditional games are often limited by static dialogue trees and a single platform for interaction. To overcome these constraints, this study presents a prototype system that enables large language model (LLM)-powered NPCs to communicate with players both in the game en vironment (Unity) and on a social platform (Discord). Dialogue logs are stored in a cloud database (LeanCloud), allowing the system to synchronize memory between platforms and keep conversa tions coherent. Our initial experiments show that cross-platform interaction is technically feasible and suggest a solid foundation for future developments such as emotional modeling and persistent memory support.","authors":["Li Song"],"url":"https://arxiv.org/abs/2504.13928"}
{"created":"2025-04-22","title":"A Model of Silence, or the Probability of \"Un Ange Passe\"","abstract":"In French, the phrase \"Un ange passe\" (\"An angel passes\") refers to the sudden silence that falls over a co-present group -- that is, a group of people sharing the same physical space. As evidenced by the presence of similar expressions across languages and cultures, this phenomenon represents a universal feature of human conversation. At the same time, the meaning attributed to silence can differ greatly across national, cultural, and interpersonal contexts. Consequently, a wide range of studies have focused on the impact of silence on organizational productivity, its relationship to ideas and creativity, and its potential effectiveness in medical settings. Despite the important role that silence plays, very few studies have attempted to characterize its features using mathematical modeling. In this study, we propose a Markov chain model to describe the dynamics of silence in a co-present group and attempt to analyze its behavior. Our results reveal a phase-transition-like phenomenon, where the probability of silence abruptly drops to zero once individuals' awareness of the surrounding conversation falls below a critical threshold. In other words, such silence can emerge only when individuals retain a minimal degree of mutual awareness of those around them. The model proposed in this study not only offers a deeper understanding of conversational dynamics, but also holds potential for contributing to intercultural communication, organizational productivity, and medical practice.","authors":["Keishu Utimula"],"url":"https://arxiv.org/abs/2504.13931"}
{"created":"2025-04-22","title":"Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining","abstract":"Large language models offer remarkable capabilities, but their size and computational demands pose practical challenges. Quantization methods compress their size through replacing their high-precision parameters by quantized values of lower precision. Post-training quantization reduces model size efficiently at the cost of decreased accuracy, while quantization-aware training better preserves accuracy but is resource-intensive. Among existing post-training quantization algorithms, the ApiQ method achieves superior accuracy preservation at minimal memory and time overhead. We investigate two ideas to extend performance in ultra-low-bit quantization beyond ApiQ's level. First, we look into combining existing quantization-aware training techniques with ApiQ's partial training. We show that this does not outperform the baseline ApiQ method with limited training data and frozen weights. This leads to two key insights: (1) The substantial representational capacity that is gained through full retraining may not be feasible through partial training. (2) This gain seems to depend on using a large and diverse dataset in quantization-aware training. Second, through a novel approach informed by the two insights, we propose an ultra-low-bit quantization method that builds upon ApiQ and extends its performance without the need for full retraining. It relies on a saliency-aware regularization term that prioritizes preserving the most impactful parameters during quantization. Our experiments on benchmark language models from the LLaMA family show that our proposed approach boosts accuracy and tightens the gap between the quantized model and the full-precision model, with minimal overhead. Our method will be made publicly available to facilitate future developments in ultra-low-bit quantization of large language models.","authors":["Deyu Cao","Samin Aref"],"url":"https://arxiv.org/abs/2504.13932"}
{"created":"2025-04-22","title":"Scalable Two-Stage Stochastic Optimal Power Flow via Separable Approximation","abstract":"This paper proposes a Separable Projective Approximation Routine-Optimal Power Flow (SPAR-OPF) framework for solving two-stage stochastic optimization problems in power systems. The framework utilizes a separable piecewise linear approximation of the value function and learns the function based on sample sub-gradient information. We present two formulations to model the learned value function, and compare their effectiveness. Additionally, an efficient statistical method is introduced to assess the quality of the obtained solutions. The effectiveness of the proposed framework is validated using distributed generation siting and sizing problem in three-phase unbalanced power distribution systems as an example. Results show that the framework approximates the value function with over 98% accuracy and provides high-quality solutions with an optimality gap of less than 1%. The framework scales efficiently with system size, generating high-quality solutions in a short time when applied to a 9500-node distribution system with 1200 scenarios, while the extensive formulations and progressive hedging failed to solve the problem.","authors":["Shishir Lamichhane","Abodh Poudyal","Bala Krishnamoorthy","Anamika Dubey"],"url":"https://arxiv.org/abs/2504.13933"}
{"created":"2025-04-22","title":"VoxCity: A Seamless Framework for Open Geospatial Data Integration, Grid-Based Semantic 3D City Model Generation, and Urban Environment Simulation","abstract":"Three-dimensional urban environment simulation is a powerful tool for informed urban planning. However, the intensive manual effort required to prepare input 3D city models has hindered its widespread adoption. To address this challenge, we present VoxCity, an open-source Python package that provides a one-stop solution for grid-based 3D city model generation and urban environment simulation for cities worldwide. VoxCity's `generator' subpackage automatically downloads building heights, tree canopy heights, land cover, and terrain elevation within a specified target area, and voxelizes buildings, trees, land cover, and terrain to generate an integrated voxel city model. The `simulator' subpackage enables users to conduct environmental simulations, including solar radiation and view index analyses. Users can export the generated models using several file formats compatible with external software, such as ENVI-met (INX), Blender, and Rhino (OBJ). We generated 3D city models for eight global cities, and demonstrated the calculation of solar irradiance, sky view index, and green view index. We also showcased microclimate simulation and 3D rendering visualization through ENVI-met and Rhino, respectively, through the file export function. Additionally, we reviewed openly available geospatial data to create guidelines to help users choose appropriate data sources depending on their target areas and purposes. VoxCity can significantly reduce the effort and time required for 3D city model preparation and promote the utilization of urban environment simulations. This contributes to more informed urban and architectural design that considers environmental impacts, and in turn, fosters sustainable and livable cities. VoxCity is released openly at https://github.com/kunifujiwara/VoxCity.","authors":["Kunihiko Fujiwara","Ryuta Tsurumi","Tomoki Kiyono","Zicheng Fan","Xiucheng Liang","Binyu Lei","Winston Yap","Koichi Ito","Filip Biljecki"],"url":"https://arxiv.org/abs/2504.13934"}
{"created":"2025-04-22","title":"Probability of collision in nonlinear dynamics by moment propagation","abstract":"Estimating the probability of collision between spacecraft is crucial for risk management and collision-avoidance strategies. Current methods often rely on Gaussian assumptions and simplifications, which can be inaccurate in highly nonlinear scenarios. This paper presents a general and efficient approach for computing collision probabilities without relying on such assumptions. Using high-order multivariate Taylor polynomials, we propagate statistical moments of initial uncertainties to the point of closest approach between the spacecraft. To compute the probability of collision, we derive a semi-analytical expression for the probability density function (PDF) of the closest approach distance, inferred from the propagated moments using orthogonal polynomials. Tested on various short-term and long-term encounters in low-Earth orbit, our method accurately handles nonlinear dynamics, non-Gaussian uncertainties, and irregular distributions. This versatile framework advances space situational awareness by providing precise collision probability estimates in complex dynamical environments. Moreover, our methodology applies to any dynamical system with uncertainty in its initial state and is therefore not restricted to collision probability estimation.","authors":["Th\\'eo Verhelst","Giacomo Acciarini","Dario Izzo","Francesco Biscani"],"url":"https://arxiv.org/abs/2504.13935"}
{"created":"2025-04-22","title":"ViMo: A Generative Visual GUI World Model for App Agent","abstract":"App agents, which autonomously operate mobile Apps through Graphical User Interfaces (GUIs), have gained significant interest in real-world applications. Yet, they often struggle with long-horizon planning, failing to find the optimal actions for complex tasks with longer steps. To address this, world models are used to predict the next GUI observation based on user actions, enabling more effective agent planning. However, existing world models primarily focus on generating only textual descriptions, lacking essential visual details. To fill this gap, we propose ViMo, the first visual world model designed to generate future App observations as images. For the challenge of generating text in image patches, where even minor pixel errors can distort readability, we decompose GUI generation into graphic and text content generation. We propose a novel data representation, the Symbolic Text Representation~(STR) to overlay text content with symbolic placeholders while preserving graphics. With this design, ViMo employs a STR Predictor to predict future GUIs' graphics and a GUI-text Predictor for generating the corresponding text. Moreover, we deploy ViMo to enhance agent-focused tasks by predicting the outcome of different action options. Experiments show ViMo's ability to generate visually plausible and functionally effective GUIs that enable App agents to make more informed decisions.","authors":["Dezhao Luo","Bohan Tang","Kang Li","Georgios Papoudakis","Jifei Song","Shaogang Gong","Jianye Hao","Jun Wang","Kun Shao"],"url":"https://arxiv.org/abs/2504.13936"}
{"created":"2025-04-22","title":"Auditory Conversational BAI: A Feasibility Study","abstract":"We introduce a novel auditory brain-computer interface (BCI) paradigm, Auditory Intention Decoding (AID), designed to enhance communication capabilities within the brain-AI interface (BAI) system EEGChat. AID enables users to select among multiple auditory options (intentions) by analyzing their brain responses, offering a pathway to construct a communication system that requires neither muscle movement nor syntactic formation. To evaluate the feasibility of this paradigm, we conducted a proof-of-concept study. The results demonstrated statistically significant decoding performance, validating the approach's potential. Despite these promising findings, further optimization is required to enhance system performance and realize the paradigm's practical application.","authors":["Michal Robert \\v{Z}\\'ak","Moritz Grosse-Wentrup"],"url":"https://arxiv.org/abs/2504.13937"}
{"created":"2025-04-22","title":"Never Start from Scratch: Expediting On-Device LLM Personalization via Explainable Model Selection","abstract":"Personalization of Large Language Models (LLMs) is important in practical applications to accommodate the individual needs of different mobile users. Due to data privacy concerns, LLM personalization often needs to be locally done at the user's mobile device, but such on-device personalization is constrained by both the limitation of on-device compute power and insufficiency of user's personal data. In this paper, we address these constraints by fine-tuning an already personalized LLM with user's personal data, and present XPerT, a new technique that ensure proper selection of such already personalized LLMs based on explainability about how they were being fine-tuned. We implemented and evaluated XPerT on various smartphone models with mainstream LLMs, and experiment results show that XPerT reduces the computation costs of on-device LLM personalization by 83%, and improves its data efficiency by 51%.","authors":["Haoming Wang","Boyuan Yang","Xiangyu Yin","Wei Gao"],"url":"https://arxiv.org/abs/2504.13938"}
{"created":"2025-04-22","title":"Hashigo: A Next Generation Sketch Interactive System for Japanese Kanji","abstract":"Language students can increase their effectiveness in learning written Japanese by mastering the visual structure and written technique of Japanese kanji. Yet, existing kanji handwriting recognition systems do not assess the written technique sufficiently enough to discourage students from developing bad learning habits. In this paper, we describe our work on Hashigo, a kanji sketch interactive system which achieves human instructor-level critique and feedback on both the visual structure and written technique of students' sketched kanji. This type of automated critique and feedback allows students to target and correct specific deficiencies in their sketches that, if left untreated, are detrimental to effective long-term kanji learning.","authors":["Paul Taele","Tracy Hammond"],"url":"https://arxiv.org/abs/2504.13940"}
{"created":"2025-04-22","title":"NEMOTRON-CROSSTHINK: Scaling Self-Learning beyond Math Reasoning","abstract":"Large Language Models (LLMs) have shown strong reasoning capabilities, particularly when enhanced through Reinforcement Learning (RL). While prior work has successfully applied RL to mathematical reasoning -- where rules and correctness are well-defined -- generalizing these methods to broader reasoning domains remains challenging due to limited data, the lack of verifiable reward structures, and diverse task requirements. In this work, we propose NEMOTRON-CROSSTHINK, a framework that systematically incorporates multi-domain corpora, including both synthetic and real-world question-answer pairs, into RL training to improve generalization across diverse reasoning tasks. NEMOTRON-CROSSTHINK addresses key challenges by (1) incorporating data from varied sources spanning STEM, humanities, social sciences, etc.; (2) applying structured templates (e.g., multiple-choice and open-ended) to control answer-space complexity; (3) filtering for verifiable answers; and (4) optimizing data blending strategies that utilizes data from multiple sources effectively. Our approach enables scalable and verifiable reward modeling beyond mathematics and demonstrates improved accuracies on both math (MATH-500: +30.1%, AMC23:+27.5%) and non-math reasoning benchmarks (MMLU-PRO: +12.8%, GPQA-DIAMOND: +11.3%, AGIEVAL: +15.1%, SUPERGPQA: +3.8%). Moreover, NEMOTRON-CROSSTHINK exhibits significantly improved response efficiency -- using 28% fewer tokens for correct answers -- highlighting more focused and effective reasoning. Through NEMOTRON-CROSSTHINK, we demonstrate that integrating multi-domain, multi-format data in RL leads to more accurate, efficient, and generalizable LLMs.","authors":["Syeda Nahida Akter","Shrimai Prabhumoye","Matvei Novikov","Seungju Han","Ying Lin","Evelina Bakhturi","Eric Nyberg","Yejin Choi","Mostofa Patwary","Mohammad Shoeybi","Bryan Catanzaro"],"url":"https://arxiv.org/abs/2504.13941"}
{"created":"2025-04-22","title":"Intelligence of Things: A Spatial Context-Aware Control System for Smart Devices","abstract":"This paper introduces Intelligence of Things (INOT), a novel spatial context-aware control system that enhances smart home automation through intuitive spatial reasoning. Current smart home systems largely rely on device-specific identifiers, limiting user interaction to explicit naming conventions rather than natural spatial references. INOT addresses this limitation through a modular architecture that integrates Vision Language Models with IoT control systems to enable natural language commands with spatial context (e.g., \"turn on the light near the window\"). The system comprises key components including an Onboarding Inference Engine, Zero-Shot Device Detection, Spatial Topology Inference, and Intent-Based Command Synthesis. A comprehensive user study with 15 participants demonstrated INOT's significant advantages over conventional systems like Google Home Assistant, with users reporting reduced cognitive workload (NASA-TLX scores decreased by an average of 13.17 points), higher ease-of-use ratings, and stronger preference (14 out of 15 participants). By eliminating the need to memorize device identifiers and enabling context-aware spatial commands, INOT represents a significant advancement in creating more intuitive and accessible smart home control systems.","authors":["Sukanth Kalivarathan","Muhmmad Abrar Raja Mohamed","Aswathy Ravikumar","S Harini"],"url":"https://arxiv.org/abs/2504.13942"}
{"created":"2025-04-22","title":"Data Assimilation-based Simultaneous Phase-Resolved Ocean Wave and Ship Motion Forecast","abstract":"This paper presents a data-assimilation (DA)-based approach to forecast the phase-resolved wave evolution process and ship motion, which is developed by coupling the high-order spectral method (HOS), ensemble Kalman filter (EnKF), and a Cummins-equation-based ship model (CMI). With the developed EnKF-HOS-CMI method, the observation data for wave, ship, or both can be incorporated into the model, therefore producing the optimal analysis results. The developed method is validated and tested based on a synthetic problem on the motions of an irregular wave field and a box-shaped free-floating ship. We show that the EnKF-HOS-CMI method achieves much higher accuracy in the long-term simulation of nonlinear phase-resolved wave field and ship motion in comparison with the HOS-CMI method. Also, the ship parameters are estimated accurately by using a parameter-augmented state space in EnKF.","authors":["Guangyao Wang","Yulin Pan"],"url":"https://arxiv.org/abs/2504.13943"}
{"created":"2025-04-22","title":"Mixer Metaphors: audio interfaces for non-musical applications","abstract":"The NIME conference traditionally focuses on interfaces for music and musical expression. In this paper we reverse this tradition to ask, can interfaces developed for music be successfully appropriated to non-musical applications? To help answer this question we designed and developed a new device, which uses interface metaphors borrowed from analogue synthesisers and audio mixing to physically control the intangible aspects of a Large Language Model. We compared two versions of the device, with and without the audio-inspired augmentations, with a group of artists who used each version over a one week period. Our results show that the use of audio-like controls afforded more immediate, direct and embodied control over the LLM, allowing users to creatively experiment and play with the device over its non-mixer counterpart. Our project demonstrates how cross-sensory metaphors can support creative thinking and embodied practice when designing new technological interfaces.","authors":["Tace McNamara","Jon McCormack","Maria Teresa Llano"],"url":"https://arxiv.org/abs/2504.13944"}
{"created":"2025-04-22","title":"Evaluating Menu OCR and Translation: A Benchmark for Aligning Human and Automated Evaluations in Large Vision-Language Models","abstract":"The rapid advancement of large vision-language models (LVLMs) has significantly propelled applications in document understanding, particularly in optical character recognition (OCR) and multilingual translation. However, current evaluations of LVLMs, like the widely used OCRBench, mainly focus on verifying the correctness of their short-text responses and long-text responses with simple layout, while the evaluation of their ability to understand long texts with complex layout design is highly significant but largely overlooked. In this paper, we propose Menu OCR and Translation Benchmark (MOTBench), a specialized evaluation framework emphasizing the pivotal role of menu translation in cross-cultural communication. MOTBench requires LVLMs to accurately recognize and translate each dish, along with its price and unit items on a menu, providing a comprehensive assessment of their visual understanding and language processing capabilities. Our benchmark is comprised of a collection of Chinese and English menus, characterized by intricate layouts, a variety of fonts, and culturally specific elements across different languages, along with precise human annotations. Experiments show that our automatic evaluation results are highly consistent with professional human evaluation. We evaluate a range of publicly available state-of-the-art LVLMs, and through analyzing their output to identify the strengths and weaknesses in their performance, offering valuable insights to guide future advancements in LVLM development. MOTBench is available at https://github.com/gitwzl/MOTBench.","authors":["Zhanglin Wu","Tengfei Song","Ning Xie","Weidong Zhang","Mengli Zhu","Shuang Wu","Shiliang Sun","Hao Yang"],"url":"https://arxiv.org/abs/2504.13945"}
{"created":"2025-04-22","title":"The Balancing Act of Policies in Developing Machine Learning Explanations","abstract":"Machine learning models are often criticized as opaque from a lack of transparency in their decision-making process. This study examines how policy design impacts the quality of explanations in ML models. We conducted a classroom experiment with 124 participants and analyzed the effects of policy length and purpose on developer compliance with policy requirements. Our results indicate that while policy length affects engagement with some requirements, policy purpose has no effect, and explanation quality is generally poor. These findings highlight the challenge of effective policy development and the importance of addressing diverse stakeholder perspectives within explanations.","authors":["Jacob Tjaden"],"url":"https://arxiv.org/abs/2504.13946"}
{"created":"2025-04-22","title":"From job titles to jawlines: Using context voids to study generative AI systems","abstract":"In this paper, we introduce a speculative design methodology for studying the behavior of generative AI systems, framing design as a mode of inquiry. We propose bridging seemingly unrelated domains to generate intentional context voids, using these tasks as probes to elicit AI model behavior. We demonstrate this through a case study: probing the ChatGPT system (GPT-4 and DALL-E) to generate headshots from professional Curricula Vitae (CVs). In contrast to traditional ways, our approach assesses system behavior under conditions of radical uncertainty -- when forced to invent entire swaths of missing context -- revealing subtle stereotypes and value-laden assumptions. We qualitatively analyze how the system interprets identity and competence markers from CVs, translating them into visual portraits despite the missing context (i.e. physical descriptors). We show that within this context void, the AI system generates biased representations, potentially relying on stereotypical associations or blatant hallucinations.","authors":["Shahan Ali Memon","Soham De","Sungha Kang","Riyan Mujtaba","Bedoor AlShebli","Katie Davis","Jaime Snyder","Jevin D. West"],"url":"https://arxiv.org/abs/2504.13947"}
{"created":"2025-04-22","title":"Using customized GPT to develop prompting proficiency in architectural AI-generated images","abstract":"This research investigates the use of customized GPT models to enhance prompting proficiency among architecture students when generating AI-driven images. Prompt engineering is increasingly essential in architectural education due to the widespread adoption of generative AI tools. This study utilized a mixed-methods experimental design involving architecture students divided into three distinct groups: a control group receiving no structured support, a second group provided with structured prompting guides, and a third group supported by both structured guides and interactive AI personas. Students engaged in reverse engineering tasks, first guessing provided image prompts and then generating their own prompts, aiming to boost critical thinking and prompting skills. Variables examined included time spent prompting, word count, prompt similarity, and concreteness. Quantitative analysis involved correlation assessments between these variables and a one-way ANOVA to evaluate differences across groups. While several correlations showed meaningful relationships, not all were statistically significant. ANOVA results indicated statistically significant improvements in word count, similarity, and concreteness, especially in the group supported by AI personas and structured prompting guides. Qualitative feedback complemented these findings, revealing enhanced confidence and critical thinking skills in students. These results suggest tailored GPT interactions substantially improve students' ability to communicate architectural concepts clearly and effectively.","authors":["Juan David Salazar Rodriguez","Sam Conrad Joyce","Julfendi Julfendi"],"url":"https://arxiv.org/abs/2504.13948"}
{"created":"2025-04-22","title":"On Revealing the Hidden Problem Structure in Real-World and Theoretical Problems Using Walsh Coefficient Influence","abstract":"Gray-box optimization employs Walsh decomposition to obtain non-linear variable dependencies and utilize them to propose masks of variables that have a joint non-linear influence on fitness value. These masks significantly improve the effectiveness of variation operators. In some problems, all variables are non-linearly dependent, making the aforementioned masks useless. We analyze the features of the real-world instances of such problems and show that many of their dependencies may have noise-like origins. Such noise-caused dependencies are irrelevant to the optimization process and can be ignored. To identify them, we propose extending the use of Walsh decomposition by measuring variable dependency strength that allows the construction of the weighted dynamic Variable Interaction Graph (wdVIG). wdVIGs adjust the dependency strength to mixed individuals. They allow the filtering of irrelevant dependencies and re-enable using dependency-based masks by variation operators. We verify the wdVIG potential on a large benchmark suite. For problems with noise, the wdVIG masks can improve the optimizer's effectiveness. If all dependencies are relevant for the optimization, i.e., the problem is not noised, the influence of wdVIG masks is similar to that of state-of-the-art structures of this kind.","authors":["M. W. Przewozniczek","F. Chicano","R. Tin\\'os","J. Nalepa","B. Ruszczak","A. M. Wijata"],"url":"https://arxiv.org/abs/2504.13949"}
{"created":"2025-04-22","title":"Open-Medical-R1: How to Choose Data for RLVR Training at Medicine Domain","abstract":"This paper explores optimal data selection strategies for Reinforcement Learning with Verified Rewards (RLVR) training in the medical domain. While RLVR has shown exceptional potential for enhancing reasoning capabilities in large language models, most prior implementations have focused on mathematics and logical puzzles, with limited exploration of domain-specific applications like medicine. We investigate four distinct data sampling strategies from MedQA-USMLE: random sampling (baseline), and filtering using Phi-4, Gemma-3-27b-it, and Gemma-3-12b-it models. Using Gemma-3-12b-it as our base model and implementing Group Relative Policy Optimization (GRPO), we evaluate performance across multiple benchmarks including MMLU, GSM8K, MMLU-Pro, and CMMLU. Our findings demonstrate that models trained on filtered data generally outperform those trained on randomly selected samples. Notably, training on self-filtered samples (using Gemma-3-12b-it for filtering) achieved superior performance in medical domains but showed reduced robustness across different benchmarks, while filtering with larger models from the same series yielded better overall robustness. These results provide valuable insights into effective data organization strategies for RLVR in specialized domains and highlight the importance of thoughtful data selection in achieving optimal performance. You can access our repository (https://github.com/Qsingle/open-medical-r1) to get the codes.","authors":["Zhongxi Qiu","Zhang Zhang","Yan Hu","Heng Li","Jiang Liu"],"url":"https://arxiv.org/abs/2504.13950"}
{"created":"2025-04-22","title":"Generative System Dynamics in Recurrent Neural Networks","abstract":"In this study, we investigate the continuous time dynamics of Recurrent Neural Networks (RNNs), focusing on systems with nonlinear activation functions. The objective of this work is to identify conditions under which RNNs exhibit perpetual oscillatory behavior, without converging to static fixed points. We establish that skew-symmetric weight matrices are fundamental to enable stable limit cycles in both linear and nonlinear configurations. We further demonstrate that hyperbolic tangent-like activation functions (odd, bounded, and continuous) preserve these oscillatory dynamics by ensuring motion invariants in state space. Numerical simulations showcase how nonlinear activation functions not only maintain limit cycles, but also enhance the numerical stability of the system integration process, mitigating those instabilities that are commonly associated with the forward Euler method. The experimental results of this analysis highlight practical considerations for designing neural architectures capable of capturing complex temporal dependencies, i.e., strategies for enhancing memorization skills in recurrent models.","authors":["Michele Casoni","Tommaso Guidi","Alessandro Betti","Stefano Melacci","Marco Gori"],"url":"https://arxiv.org/abs/2504.13951"}
{"created":"2025-04-22","title":"Plataforma para visualiza\\c{c}\\~ao geo-temporal de apinhamento tur\\'istico","abstract":"Tourist crowding degrades the visitor experience and negatively impacts the environment and the local population, potentially making tourism in popular destinations unsustainable. This motivated us to develop, within the framework of the European RESETTING project related to the digital transformation of tourism, a platform to visualize this crowding, exploring historical data, detecting patterns and trends and predicting future events. The ultimate goal is to support short- and medium-term decision-making to mitigate the phenomenon. To this end, the platform takes into account the carrying capacity of the target sites when calculating crowding density. The integration of data from different sources is achieved with an extensible, connector-based architecture. Three scenarios for using the platform are described, relating to major annual crowding events. Two of them, in the municipality of Lisbon, are based on data from a mobile network provided by the LxDataLab initiative. The third, in Melbourne, Australia, using public data from a network of movement sensors called the Pedestrian Counting System. An experiment to evaluate the usability of the proposed platform using NASA-TLX is also described. -- --","authors":["Rodrigo Sim\\~oes","Fernando Brito e Abreu","Adriano Lopes"],"url":"https://arxiv.org/abs/2504.13952"}
{"created":"2025-04-22","title":"Thousand Voices of Trauma: A Large-Scale Synthetic Dataset for Modeling Prolonged Exposure Therapy Conversations","abstract":"The advancement of AI systems for mental health support is hindered by limited access to therapeutic conversation data, particularly for trauma treatment. We present Thousand Voices of Trauma, a synthetic benchmark dataset of 3,000 therapy conversations based on Prolonged Exposure therapy protocols for Post-traumatic Stress Disorder (PTSD). The dataset comprises 500 unique cases, each explored through six conversational perspectives that mirror the progression of therapy from initial anxiety to peak distress to emotional processing. We incorporated diverse demographic profiles (ages 18-80, M=49.3, 49.4% male, 44.4% female, 6.2% non-binary), 20 trauma types, and 10 trauma-related behaviors using deterministic and probabilistic generation methods. Analysis reveals realistic distributions of trauma types (witnessing violence 10.6%, bullying 10.2%) and symptoms (nightmares 23.4%, substance abuse 20.8%). Clinical experts validated the dataset's therapeutic fidelity, highlighting its emotional depth while suggesting refinements for greater authenticity. We also developed an emotional trajectory benchmark with standardized metrics for evaluating model responses. This privacy-preserving dataset addresses critical gaps in trauma-focused mental health data, offering a valuable resource for advancing both patient-facing applications and clinician training tools.","authors":["Suhas BN","Dominik Mattioli","Saeed Abdullah","Rosa I. Arriaga","Chris W. Wiese","Andrew M. Sherrill"],"url":"https://arxiv.org/abs/2504.13955"}
{"created":"2025-04-22","title":"Prognosis Of Lithium-Ion Battery Health with Hybrid EKF-CNN+LSTM Model Using Differential Capacity","abstract":"Battery degradation is a major challenge in electric vehicles (EV) and energy storage systems (ESS). However, most degradation investigations focus mainly on estimating the state of charge (SOC), which fails to accurately interpret the cells' internal degradation mechanisms. Differential capacity analysis (DCA) focuses on the rate of change of cell voltage about the change in cell capacity, under various charge/discharge rates. This paper developed a battery cell degradation testing model that used two types of lithium-ions (Li-ion) battery cells, namely lithium nickel cobalt aluminium oxides (LiNiCoAlO2) and lithium iron phosphate (LiFePO4), to evaluate internal degradation during loading conditions. The proposed battery degradation model contains distinct charge rates (DCR) of 0.2C, 0.5C, 1C, and 1.5C, as well as discharge rates (DDR) of 0.5C, 0.9C, 1.3C, and 1.6C to analyze the internal health and performance of battery cells during slow, moderate, and fast loading conditions. Besides, this research proposed a model that incorporates the Extended Kalman Filter (EKF), Convolutional Neural Network (CNN), and Long Short-Term Memory (LSTM) networks to validate experimental data. The proposed model yields excellent modelling results based on mean squared error (MSE), and root mean squared error (RMSE), with errors of less than 0.001% at DCR and DDR. The peak identification technique (PIM) has been utilized to investigate battery health based on the number of peaks, peak position, peak height, peak area, and peak width. At last, the PIM method has discovered that the cell aged gradually under normal loading rates but deteriorated rapidly under fast loading conditions. Overall, LiFePO4 batteries perform more robustly and consistently than (LiNiCoAlO2) cells under varying loading conditions.","authors":["Md Azizul Hoque","Babul Salam","Mohd Khair Hassan","Abdulkabir Aliyu","Abedalmuhdi Almomany","Muhammed Sutcu"],"url":"https://arxiv.org/abs/2504.13956"}
{"created":"2025-04-22","title":"Naming is framing: How cybersecurity's language problems are repeating in AI governance","abstract":"Language is not neutral; it frames understanding, structures power, and shapes governance. This paper argues that misnomers like cybersecurity and artificial intelligence (AI) are more than semantic quirks; they carry significant governance risks by obscuring human agency, inflating expectations, and distorting accountability. Drawing on lessons from cybersecurity's linguistic pitfalls, such as the 'weakest link' narrative, this paper highlights how AI discourse is falling into similar traps with metaphors like 'alignment,' 'black box,' and 'hallucination.' These terms embed adversarial, mystifying, or overly technical assumptions into governance structures. In response, the paper advocates for a language-first approach to AI governance: one that interrogates dominant metaphors, foregrounds human roles, and co-develops a lexicon that is precise, inclusive, and reflexive. This paper contends that linguistic reform is not peripheral to governance but central to the construction of transparent, equitable, and anticipatory regulatory frameworks.","authors":["Liane Potter"],"url":"https://arxiv.org/abs/2504.13957"}
{"created":"2025-04-22","title":"ToolRL: Reward is All Tool Learning Needs","abstract":"Current Large Language Models (LLMs) often undergo supervised fine-tuning (SFT) to acquire tool use capabilities. However, SFT struggles to generalize to unfamiliar or complex tool use scenarios. Recent advancements in reinforcement learning (RL), particularly with R1-like models, have demonstrated promising reasoning and generalization abilities. Yet, reward design for tool use presents unique challenges: multiple tools may be invoked with diverse parameters, and coarse-grained reward signals, such as answer matching, fail to offer the finegrained feedback required for effective learning. In this work, we present the first comprehensive study on reward design for tool selection and application tasks within the RL paradigm. We systematically explore a wide range of reward strategies, analyzing their types, scales, granularity, and temporal dynamics. Building on these insights, we propose a principled reward design tailored for tool use tasks and apply it to train LLMs using Group Relative Policy Optimization (GRPO). Empirical evaluations across diverse benchmarks demonstrate that our approach yields robust, scalable, and stable training, achieving a 17% improvement over base models and a 15% gain over SFT models. These results highlight the critical role of thoughtful reward design in enhancing the tool use capabilities and generalization performance of LLMs. All the codes are released to facilitate future research.","authors":["Cheng Qian","Emre Can Acikgoz","Qi He","Hongru Wang","Xiusi Chen","Dilek Hakkani-T\\\"ur","Gokhan Tur","Heng Ji"],"url":"https://arxiv.org/abs/2504.13958"}
{"created":"2025-04-22","title":"AI Safety Should Prioritize the Future of Work","abstract":"Current efforts in AI safety prioritize filtering harmful content, preventing manipulation of human behavior, and eliminating existential risks in cybersecurity or biosecurity. While pressing, this narrow focus overlooks critical human-centric considerations that shape the long-term trajectory of a society. In this position paper, we identify the risks of overlooking the impact of AI on the future of work and recommend comprehensive transition support towards the evolution of meaningful labor with human agency. Through the lens of economic theories, we highlight the intertemporal impacts of AI on human livelihood and the structural changes in labor markets that exacerbate income inequality. Additionally, the closed-source approach of major stakeholders in AI development resembles rent-seeking behavior through exploiting resources, breeding mediocrity in creative labor, and monopolizing innovation. To address this, we argue in favor of a robust international copyright anatomy supported by implementing collective licensing that ensures fair compensation mechanisms for using data to train AI models. We strongly recommend a pro-worker framework of global AI governance to enhance shared prosperity and economic justice while reducing technical debt.","authors":["Sanchaita Hazra","Bodhisattwa Prasad Majumder","Tuhin Chakrabarty"],"url":"https://arxiv.org/abs/2504.13959"}
{"created":"2025-04-22","title":"CONTINA: Confidence Interval for Traffic Demand Prediction with Coverage Guarantee","abstract":"Accurate short-term traffic demand prediction is critical for the operation of traffic systems. Besides point estimation, the confidence interval of the prediction is also of great importance. Many models for traffic operations, such as shared bike rebalancing and taxi dispatching, take into account the uncertainty of future demand and require confidence intervals as the input. However, existing methods for confidence interval modeling rely on strict assumptions, such as unchanging traffic patterns and correct model specifications, to guarantee enough coverage. Therefore, the confidence intervals provided could be invalid, especially in a changing traffic environment. To fill this gap, we propose an efficient method, CONTINA (Conformal Traffic Intervals with Adaptation) to provide interval predictions that can adapt to external changes. By collecting the errors of interval during deployment, the method can adjust the interval in the next step by widening it if the errors are too large or shortening it otherwise. Furthermore, we theoretically prove that the coverage of the confidence intervals provided by our method converges to the target coverage level. Experiments across four real-world datasets and prediction models demonstrate that the proposed method can provide valid confidence intervals with shorter lengths. Our method can help traffic management personnel develop a more reasonable and robust operation plan in practice. And we release the code, model and dataset in \\href{ https://github.com/xiannanhuang/CONTINA/}{ Github}.","authors":["Chao Yang","Xiannan Huang","Shuhan Qiu","Yan Cheng"],"url":"https://arxiv.org/abs/2504.13961"}
{"created":"2025-04-22","title":"A Collaborative Platform for Soil Organic Carbon Inference Based on Spatiotemporal Remote Sensing Data","abstract":"Soil organic carbon (SOC) is a key indicator of soil health, fertility, and carbon sequestration, making it essential for sustainable land management and climate change mitigation. However, large-scale SOC monitoring remains challenging due to spatial variability, temporal dynamics, and multiple influencing factors. We present WALGREEN, a platform that enhances SOC inference by overcoming limitations of current applications. Leveraging machine learning and diverse soil samples, WALGREEN generates predictive models using historical public and private data. Built on cloud-based technologies, it offers a user-friendly interface for researchers, policymakers, and land managers to access carbon data, analyze trends, and support evidence-based decision-making. Implemented in Python, Java, and JavaScript, WALGREEN integrates Google Earth Engine and Sentinel Copernicus via scripting, OpenLayers, and Thymeleaf in a Model-View-Controller framework. This paper aims to advance soil science, promote sustainable agriculture, and drive critical ecosystem responses to climate change.","authors":["Jose Manuel Aroca-Fernandez","Jose Francisco Diez-Pastor","Pedro Latorre-Carmona","Victor Elvira","Gustau Camps-Valls","Rodrigo Pascual","Cesar Garcia-Osorio"],"url":"https://arxiv.org/abs/2504.13962"}
{"created":"2025-04-22","title":"Designing Empathetic Companions: Exploring Personality, Emotion, and Trust in Social Robots","abstract":"How should a companion robot behave? In this research, we present a cognitive architecture based on a tailored personality model to investigate the impact of robotic personalities on the perception of companion robots. Drawing from existing literature, we identified empathy, trust, and enjoyability as key factors in building companionship with social robots. Based on these insights, we implemented a personality-dependent, emotion-aware generator, recognizing the crucial role of robot emotions in shaping these elements. We then conducted a user study involving 84 dyadic conversation sessions with the emotional robot Navel, which exhibited different personalities. Results were derived from a multimodal analysis, including questionnaires, open-ended responses, and behavioral observations. This approach allowed us to validate the developed emotion generator and explore the relationship between the personality traits of Agreeableness, Extraversion, Conscientiousness, and Empathy. Furthermore, we drew robust conclusions on how these traits influence relational trust, capability trust, enjoyability, and sociability.","authors":["Alice Nardelli","Antonio Sgorbissa","Carmine Tommaso Recchiuto"],"url":"https://arxiv.org/abs/2504.13964"}
{"created":"2025-04-22","title":"Dynamic Difficulty Adjustment With Brain Waves as a Tool for Optimizing Engagement","abstract":"This study explores the use of electroencephalography (EEG)-based brain wave monitoring to enable dynamic difficulty adjustment (DDA) in a virtual reality (VR) gaming environment. Using the Task Engagement Index (TEI) derived from frontal EEG electrodes, we adapt game challenge levels in real time to maintain optimal player engagement. In a within-subject design with six participants, we found that the DDA condition significantly increased engagement duration by 19.79% compared to a non-DDA control condition. These results suggest that combining EEG, DDA, and VR technologies can enhance user experience and has potential applications in adaptive learning, rehabilitation, and personalized interfaces.","authors":["Nir Cafri"],"url":"https://arxiv.org/abs/2504.13965"}
{"created":"2025-04-22","title":"Adversarial Resilience against Clean-Label Attacks in Realizable and Noisy Settings","abstract":"We investigate the challenge of establishing stochastic-like guarantees when sequentially learning from a stream of i.i.d. data that includes an unknown quantity of clean-label adversarial samples. We permit the learner to abstain from making predictions when uncertain. The regret of the learner is measured in terms of misclassification and abstention error, where we allow the learner to abstain for free on adversarial injected samples. This approach is based on the work of Goel, Hanneke, Moran, and Shetty from arXiv:2306.13119. We explore the methods they present and manage to correct inaccuracies in their argumentation.","authors":["Carolin Heinzler"],"url":"https://arxiv.org/abs/2504.13966"}
{"created":"2025-04-22","title":"Tinker Tales: Interactive Storytelling Framework for Early Childhood Narrative Development and AI Literacy","abstract":"This paper presents Tinker Tales, an interactive storytelling framework in the format of a board game, designed to support both narrative development and AI literacy in early childhood. The framework integrates tangible and speech-based interactions with AI through NFC chip-attached pawns and tokens, along with a speaker and microphone. Children select and define key story elements-such as characters, places, items, and emotions-using the pawns and tokens, providing further details to the AI and receiving proper assistance, similar to how adults prompt AI for specific tasks (e.g., writing). For evaluation, several game sessions were simulated with a child AI agent, and the quality and safety of the generated stories were assessed from various perspectives. This work highlights the potential of combining physical and digital elements in AI literacy, offering a safe and engaging way for children to learn how to effectively collaborate with AI.","authors":["Nayoung Choi","Peace Cyebukayire","Jinho D. Choi"],"url":"https://arxiv.org/abs/2504.13969"}
{"created":"2025-04-22","title":"The Future of Internet of Things and Multimodal Language Models in 6G Networks: Opportunities and Challenges","abstract":"Based on recent trends in artificial intelligence and IoT research. The cooperative potential of integrating the Internet of Things (IoT) and Multimodal Language Models (MLLMs) is presented in this survey paper for future 6G systems. It focuses on the applications of this integration in different fields, such as healthcare, agriculture, and smart cities, and investigates the four pillars of IoT integration, such as sensors, communication, processing, and security. The paper provides a comprehensive description of IoT and MLLM technologies and applications, addresses the role of multimodality in each pillar, and concludes with an overview of the most significant challenges and directions for future research. The general survey is a roadmap for researchers interested in tracing the application areas of MLLMs and IoT, highlighting the potential and challenges in this rapidly growing field. The survey recognizes the need to deal with data availability, computational expense, privacy, and real-time processing to harness the complete potential of IoT, MLLM, and 6G technology","authors":["Abdelrahman Soliman"],"url":"https://arxiv.org/abs/2504.13971"}
{"created":"2025-04-22","title":"Governance Challenges in Reinforcement Learning from Human Feedback: Evaluator Rationality and Reinforcement Stability","abstract":"Reinforcement Learning from Human Feedback (RLHF) is central in aligning large language models (LLMs) with human values and expectations. However, the process remains susceptible to governance challenges, including evaluator bias, inconsistency, and the unreliability of feedback. This study examines how the cognitive capacity of evaluators, specifically their level of rationality, affects the stability of reinforcement signals. A controlled experiment comparing high-rationality and low-rationality participants reveals that evaluators with higher rationality scores produce significantly more consistent and expert-aligned feedback. In contrast, lower-rationality participants demonstrate considerable variability in their reinforcement decisions ($p < 0.01$). To address these challenges and improve RLHF governance, we recommend implementing evaluator pre-screening, systematic auditing of feedback consistency, and reliability-weighted reinforcement aggregation. These measures enhance the fairness, transparency, and robustness of AI alignment pipelines.","authors":["Dana Alsagheer","Abdulrahman Kamal","Mohammad Kamal","Weidong Shi"],"url":"https://arxiv.org/abs/2504.13972"}
{"created":"2025-04-22","title":"Birds of a Different Feather Flock Together: Exploring Opportunities and Challenges in Animal-Human-Machine Teaming","abstract":"Animal-Human-Machine (AHM) teams are a type of hybrid intelligence system wherein interactions between a human, AI-enabled machine, and animal members can result in unique capabilities greater than the sum of their parts. This paper calls for a systematic approach to studying the design of AHM team structures to optimize performance and overcome limitations in various applied settings. We consider the challenges and opportunities in investigating the synergistic potential of AHM team members by introducing a set of dimensions of AHM team functioning to effectively utilize each member's strengths while compensating for individual weaknesses. Using three representative examples of such teams -- security screening, search-and-rescue, and guide dogs -- the paper illustrates how AHM teams can tackle complex tasks. We conclude with open research directions that this multidimensional approach presents for studying hybrid human-AI systems beyond AHM teams.","authors":["Myke C. Cohen","David A. Grimm","Reuth Mirsky","Xiaoyun Yin"],"url":"https://arxiv.org/abs/2504.13973"}
{"created":"2025-04-22","title":"Enhancing Stroke Diagnosis in the Brain Using a Weighted Deep Learning Approach","abstract":"A brain stroke occurs when blood flow to a part of the brain is disrupted, leading to cell death. Traditional stroke diagnosis methods, such as CT scans and MRIs, are costly and time-consuming. This study proposes a weighted voting ensemble (WVE) machine learning model that combines predictions from classifiers like random forest, Deep Learning, and histogram-based gradient boosting to predict strokes more effectively. The model achieved 94.91% accuracy on a private dataset, enabling early risk assessment and prevention. Future research could explore optimization techniques to further enhance accuracy.","authors":["Yao Zhiwan","Reza Zarrab","Jean Dubois"],"url":"https://arxiv.org/abs/2504.13974"}
{"created":"2025-04-22","title":"Multiscale Tensor Summation Factorization as a New Neural Network Layer (MTS Layer) for Multidimensional Data Processing","abstract":"Multilayer perceptrons (MLP), or fully connected artificial neural networks, are known for performing vector-matrix multiplications using learnable weight matrices; however, their practical application in many machine learning tasks, especially in computer vision, can be limited due to the high dimensionality of input-output pairs at each layer. To improve efficiency, convolutional operators have been utilized to facilitate weight sharing and local connections, yet they are constrained by limited receptive fields. In this paper, we introduce Multiscale Tensor Summation (MTS) Factorization, a novel neural network operator that implements tensor summation at multiple scales, where each tensor to be summed is obtained through Tucker-decomposition-like mode products. Unlike other tensor decomposition methods in the literature, MTS is not introduced as a network compression tool; instead, as a new backbone neural layer. MTS not only reduces the number of parameters required while enhancing the efficiency of weight optimization compared to traditional dense layers (i.e., unfactorized weight matrices in MLP layers), but it also demonstrates clear advantages over convolutional layers. The proof-of-concept experimental comparison of the proposed MTS networks with MLPs and Convolutional Neural Networks (CNNs) demonstrates their effectiveness across various tasks, such as classification, compression, and signal restoration. Additionally, when integrated with modern non-linear units such as the multi-head gate (MHG), also introduced in this study, the corresponding neural network, MTSNet, demonstrates a more favorable complexity-performance tradeoff compared to state-of-the-art transformers in various computer vision applications. The software implementation of the MTS layer and the corresponding MTS-based networks, MTSNets, is shared at https://github.com/mehmetyamac/MTSNet.","authors":["Mehmet Yama\\c{c}","Muhammad Numan Yousaf","Serkan Kiranyaz","Moncef Gabbouj"],"url":"https://arxiv.org/abs/2504.13975"}
{"created":"2025-04-22","title":"Gas Station of the Future: A Perspective on AI/ML and IoT in Retail Downstream","abstract":"The gas station of the future is poised to transform from a simple fuel dispensing center into an intelligent retail hub, driven by advancements in Artificial Intelligence (AI), Machine Learning (ML), and the Internet of Things (IoT). This paper explores how technology is reshaping the retail downstream sector while briefly addressing the upstream and midstream segments. By leveraging AI/ML for predictive analytics, dynamic pricing, personalized customer engagement, and IoT for real-time monitoring and automation, the future gas station will redefine the fuel retail experience. Additionally, this paper incorporates statistics, AI/ML core technical concepts, mathematical formulations, case studies, and a proposed framework for a fully autonomous gas station.","authors":["Wrick Talukdar"],"url":"https://arxiv.org/abs/2504.13976"}
{"created":"2025-04-22","title":"Framework, Standards, Applications and Best practices of Responsible AI : A Comprehensive Survey","abstract":"Responsible Artificial Intelligence (RAI) is a combination of ethics associated with the usage of artificial intelligence aligned with the common and standard frameworks. This survey paper extensively discusses the global and national standards, applications of RAI, current technology and ongoing projects using RAI, and possible challenges in implementing and designing RAI in the industries and projects based on AI. Currently, ethical standards and implementation of RAI are decoupled which caters each industry to follow their own standards to use AI ethically. Many global firms and government organizations are taking necessary initiatives to design a common and standard framework. Social pressure and unethical way of using AI forces the RAI design rather than implementation.","authors":["Thippa Reddy Gadekallu","Kapal Dev","Sunder Ali Khowaja","Weizheng Wang","Hailin Feng","Kai Fang","Sharnil Pandya","Wei Wang"],"url":"https://arxiv.org/abs/2504.13979"}
{"created":"2025-04-22","title":"CacheFormer: High Attention-Based Segment Caching","abstract":"Efficiently handling long contexts in transformer-based language models with low perplexity is an active area of research. Numerous recent approaches like Linformer, Longformer, Performer, and Structured state space models (SSMs)., have not fully resolved this problem. All these models strive to reduce the quadratic time complexity of the attention mechanism while minimizing the loss in quality due to the effective compression of the long context. Inspired by the cache and virtual memory principle in computers, where in case of a cache miss, not only the needed data is retrieved from the memory, but the adjacent data is also obtained, we apply this concept to handling long contexts by dividing it into small segments. In our design, we retrieve the nearby segments in an uncompressed form when high segment-level attention occurs at the compressed level. Our en-hancements for handling long context include aggregating four attention mechanisms consisting of short sliding window attention, long compressed segmented attention, dynamically retrieving top k high attention uncompressed segments, and overlapping segments in long segment attention to avoid segment fragmentation. These enhancements result in an architecture that outperforms ex-isting SOTA architectures with an average perplexity improvement of 8.5% over similar model sizes.","authors":["Sushant Singh","Ausif Mahmood"],"url":"https://arxiv.org/abs/2504.13981"}
{"created":"2025-04-22","title":"When Machine Learning Meets Importance Sampling: A More Efficient Rare Event Estimation Approach","abstract":"Driven by applications in telecommunication networks, we explore the simulation task of estimating rare event probabilities for tandem queues in their steady state. Existing literature has recognized that importance sampling methods can be inefficient, due to the exploding variance of the path-dependent likelihood functions. To mitigate this, we introduce a new importance sampling approach that utilizes a marginal likelihood ratio on the stationary distribution, effectively avoiding the issue of excessive variance. In addition, we design a machine learning algorithm to estimate this marginal likelihood ratio using importance sampling data. Numerical experiments indicate that our algorithm outperforms the classic importance sampling methods.","authors":["Ruoning Zhao","Xinyun Chen"],"url":"https://arxiv.org/abs/2504.13982"}
{"created":"2025-04-22","title":"QuatE-D: A Distance-Based Quaternion Model for Knowledge Graph Embedding","abstract":"Knowledge graph embedding (KGE) methods aim to represent entities and relations in a continuous space while preserving their structural and semantic properties. Quaternion-based KGEs have demonstrated strong potential in capturing complex relational patterns. In this work, we propose QuatE-D, a novel quaternion-based model that employs a distance-based scoring function instead of traditional inner-product approaches. By leveraging Euclidean distance, QuatE-D enhances interpretability and provides a more flexible representation of relational structures. Experimental results demonstrate that QuatE-D achieves competitive performance while maintaining an efficient parameterization, particularly excelling in Mean Rank reduction. These findings highlight the effectiveness of distance-based scoring in quaternion embeddings, offering a promising direction for knowledge graph completion.","authors":["Hamideh-Sadat Fazael-Ardakani","Hamid Soltanian-Zadeh"],"url":"https://arxiv.org/abs/2504.13983"}
{"created":"2025-04-22","title":"One Jump Is All You Need: Short-Cutting Transformers for Early Exit Prediction with One Jump to Fit All Exit Levels","abstract":"To reduce the time and computational costs of inference of large language models, there has been interest in parameter-efficient low-rank early-exit casting of transformer hidden-representations to final-representations. Such low-rank short-cutting has been shown to outperform identity shortcuts at early model stages while offering parameter-efficiency in shortcut jumps. However, current low-rank methods maintain a separate early-exit shortcut jump to final-representations for each transformer intermediate block-level during inference. In this work, we propose selection of a single One-Jump-Fits-All (OJFA) low-rank shortcut that offers over a 30x reduction in shortcut parameter costs during inference. We show that despite this extreme reduction, our OJFA choice largely matches the performance of maintaining multiple shortcut jumps during inference and offers stable precision from all transformer block-levels for GPT2-XL, Phi3-Mini and Llama2-7B transformer models.","authors":["Amrit Diggavi Seshadri"],"url":"https://arxiv.org/abs/2504.13984"}
{"created":"2025-04-22","title":"On the redundancy of short and heterogeneous sequences of belief revisions","abstract":"Forgetting a specific belief revision episode may not erase information because the other revisions may provide the same information or allow to deduce it. Whether it does was proved coNP-hard for sequence of two arbitrary lexicographic revision or arbitrarily long lexicographic Horn revision. A polynomial algorithm is presented for the case of two Horn revision. Heterogeneous sequences of revisions were proved to belong in Delta2. Their previously proved coNP-hardness is enhanced by a proof of NP-hardness.","authors":["Paolo Liberatore"],"url":"https://arxiv.org/abs/2504.13986"}
{"created":"2025-04-22","title":"Entropy Rectifying Guidance for Diffusion and Flow Models","abstract":"Guidance techniques are commonly used in diffusion and flow models to improve image quality and consistency for conditional generative tasks such as class-conditional and text-to-image generation. In particular, classifier-free guidance (CFG) -- the most widely adopted guidance technique -- contrasts conditional and unconditional predictions to improve the generated images. This results, however, in trade-offs across quality, diversity and consistency, improving some at the expense of others. While recent work has shown that it is possible to disentangle these factors to some extent, such methods come with an overhead of requiring an additional (weaker) model, or require more forward passes per sampling step. In this paper, we propose Entropy Rectifying Guidance (ERG), a simple and effective guidance mechanism based on inference-time changes in the attention mechanism of state-of-the-art diffusion transformer architectures, which allows for simultaneous improvements over image quality, diversity and prompt consistency. ERG is more general than CFG and similar guidance techniques, as it extends to unconditional sampling. ERG results in significant improvements in various generation tasks such as text-to-image, class-conditional and unconditional image generation. We also show that ERG can be seamlessly combined with other recent guidance methods such as CADS and APG, further boosting generation performance.","authors":["Tariq Berrada Ifriqi","Adriana Romero-Soriano","Michal Drozdzal","Jakob Verbeek","Karteek Alahari"],"url":"https://arxiv.org/abs/2504.13987"}
{"created":"2025-04-22","title":"Going Whole Hog: A Philosophical Defense of AI Cognition","abstract":"This work defends the 'Whole Hog Thesis': sophisticated Large Language Models (LLMs) like ChatGPT are full-blown linguistic and cognitive agents, possessing understanding, beliefs, desires, knowledge, and intentions. We argue against prevailing methodologies in AI philosophy, rejecting starting points based on low-level computational details ('Just an X' fallacy) or pre-existing theories of mind. Instead, we advocate starting with simple, high-level observations of LLM behavior (e.g., answering questions, making suggestions) -- defending this data against charges of metaphor, loose talk, or pretense. From these observations, we employ 'Holistic Network Assumptions' -- plausible connections between mental capacities (e.g., answering implies knowledge, knowledge implies belief, action implies intention) -- to argue for the full suite of cognitive states. We systematically rebut objections based on LLM failures (hallucinations, planning/reasoning errors), arguing these don't preclude agency, often mirroring human fallibility. We address numerous 'Games of Lacks', arguing that LLMs do not lack purported necessary conditions for cognition (e.g., semantic grounding, embodiment, justification, intrinsic intentionality) or that these conditions are not truly necessary, often relying on anti-discriminatory arguments comparing LLMs to diverse human capacities. Our approach is evidential, not functionalist, and deliberately excludes consciousness. We conclude by speculating on the possibility of LLMs possessing 'alien' contents beyond human conceptual schemes.","authors":["Herman Cappelen","Josh Dever"],"url":"https://arxiv.org/abs/2504.13988"}
{"created":"2025-04-22","title":"Gradual Binary Search and Dimension Expansion : A general method for activation quantization in LLMs","abstract":"Large language models (LLMs) have become pivotal in artificial intelligence, demonstrating strong capabilities in reasoning, understanding, and generating data. However, their deployment on edge devices is hindered by their substantial size, often reaching several billion parameters. Quantization is a widely used method to reduce memory usage and inference time, however LLMs present unique challenges due to the prevalence of outliers in their activations. In this work, we leverage the theoretical advantages of Hadamard matrices over random rotation matrices to push the boundaries of quantization in LLMs. We demonstrate that Hadamard matrices are more effective in reducing outliers, which are a significant obstacle in achieving low-bit quantization. Our method based on a gradual binary search enables 3-bit quantization for weights, activations, and key-value (KV) caches, resulting in a 40\\% increase in accuracy on common benchmarks compared to SoTA methods. We extend the use of rotation matrices to support non-power-of-2 embedding dimensions, similar to the Qwen architecture, by employing the Paley algorithm. We theoretically demonstrates the superiority of Hadamard matrices in reducing outliers.We achieved 3-bit quantization for weights, activations, and KV cache, significantly enhancing model performance. Our experimental results on multiple models family like Mistral, LLaMA, and Qwen demonstrate the effectiveness of our approach, outperforming existing methods and enabling practical 3-bit quantization.","authors":["Lucas Maisonnave","Cyril Moineau","Olivier Bichler","Fabrice Rastello"],"url":"https://arxiv.org/abs/2504.13989"}
{"created":"2025-04-22","title":"PC-DeepNet: A GNSS Positioning Error Minimization Framework Using Permutation-Invariant Deep Neural Network","abstract":"Global navigation satellite systems (GNSS) face significant challenges in urban and sub-urban areas due to non-line-of-sight (NLOS) propagation, multipath effects, and low received power levels, resulting in highly non-linear and non-Gaussian measurement error distributions. In light of this, conventional model-based positioning approaches, which rely on Gaussian error approximations, struggle to achieve precise localization under these conditions. To overcome these challenges, we put forth a novel learning-based framework, PC-DeepNet, that employs a permutation-invariant (PI) deep neural network (DNN) to estimate position corrections (PC). This approach is designed to ensure robustness against changes in the number and/or order of visible satellite measurements, a common issue in GNSS systems, while leveraging NLOS and multipath indicators as features to enhance positioning accuracy in challenging urban and sub-urban environments. To validate the performance of the proposed framework, we compare the positioning error with state-of-the-art model-based and learning-based positioning methods using two publicly available datasets. The results confirm that proposed PC-DeepNet achieves superior accuracy than existing model-based and learning-based methods while exhibiting lower computational complexity compared to previous learning-based approaches.","authors":["M. Humayun Kabir","Md. Ali Hasan","Md. Shafiqul Islam","Kyeongjun Ko","Wonjae Shin"],"url":"https://arxiv.org/abs/2504.13990"}
{"created":"2025-04-22","title":"Deep Learning on Graphs for Mobile Network Topology Generation","abstract":"Mobile networks consist of interconnected radio nodes strategically positioned across various geographical regions to provide connectivity services. The set of relations between these radio nodes, referred to as the \\emph{mobile network topology}, is vital in the construction of the networking infrastructure. Typically, the connections between radio nodes and their associated cells are defined by software features that establish mobility relations (referred to as \\emph{edges} in this paper) within the mobile network graph through heuristic methods. Although these approaches are efficient, they encounter significant limitations, particularly since edges can only be established prior to the installation of physical hardware.","authors":["Felix Nannesson Meli","Johan Tell","Shirwan Piroti","Tahar Zanouda","Elias Jarlebring"],"url":"https://arxiv.org/abs/2504.13991"}
{"created":"2025-04-22","title":"First and Second Order Approximations to Stochastic Gradient Descent Methods with Momentum Terms","abstract":"Stochastic Gradient Descent (SGD) methods see many uses in optimization problems. Modifications to the algorithm, such as momentum-based SGD methods have been known to produce better results in certain cases. Much of this, however, is due to empirical information rather than rigorous proof. While the dynamics of gradient descent methods can be studied through continuous approximations, existing works only cover scenarios with constant learning rates or SGD without momentum terms. We present approximation results under weak assumptions for SGD that allow learning rates and momentum parameters to vary with respect to time.","authors":["Eric Lu"],"url":"https://arxiv.org/abs/2504.13992"}
{"created":"2025-04-22","title":"CPR: Leveraging LLMs for Topic and Phrase Suggestion to Facilitate Comprehensive Product Reviews","abstract":"Consumers often heavily rely on online product reviews, analyzing both quantitative ratings and textual descriptions to assess product quality. However, existing research hasn't adequately addressed how to systematically encourage the creation of comprehensive reviews that capture both customers sentiment and detailed product feature analysis. This paper presents CPR, a novel methodology that leverages the power of Large Language Models (LLMs) and Topic Modeling to guide users in crafting insightful and well-rounded reviews. Our approach employs a three-stage process: first, we present users with product-specific terms for rating; second, we generate targeted phrase suggestions based on these ratings; and third, we integrate user-written text through topic modeling, ensuring all key aspects are addressed. We evaluate CPR using text-to-text LLMs, comparing its performance against real-world customer reviews from Walmart. Our results demonstrate that CPR effectively identifies relevant product terms, even for new products lacking prior reviews, and provides sentiment-aligned phrase suggestions, saving users time and enhancing reviews quality. Quantitative analysis reveals a 12.3% improvement in BLEU score over baseline methods, further supported by manual evaluation of generated phrases. We conclude by discussing potential extensions and future research directions.","authors":["Ekta Gujral","Apurva Sinha","Lishi Ji","Bijayani Sanghamitra Mishra"],"url":"https://arxiv.org/abs/2504.13993"}
{"created":"2025-04-22","title":"Terminal Lucidity: Envisioning the Future of the Terminal","abstract":"The Unix terminal, or just simply, the terminal, can be found being applied in almost every facet of computing. It is available across all major platforms and often integrated into other applications. Due to its ubiquity, even marginal improvements to the terminal have the potential to make massive improvements to productivity on a global scale. We believe that evolutionary improvements to the terminal, in its current incarnation as windowed terminal emulator, are possible and that developing a thorough understanding of issues that current terminal users face is fundamental to knowing how the terminal should evolve. In order to develop that understanding we have mined Unix and Linux Stack Exchange using a fully-reproducible method which was able to extract and categorize 91.0% of 1,489 terminal-related questions (from the full set of nearly 240,000 questions) without manual intervention.","authors":["Michael MacInnis","Olga Baysal","Michele Lanza"],"url":"https://arxiv.org/abs/2504.13994"}
{"created":"2025-04-22","title":"Scaling LLaNA: Advancing NeRF-Language Understanding Through Large-Scale Training","abstract":"Recent advances in Multimodal Large Language Models (MLLMs) have shown remarkable capabilities in understanding both images and 3D data, yet these modalities face inherent limitations in comprehensively representing object geometry and appearance. Neural Radiance Fields (NeRFs) have emerged as a promising alternative, encoding both geometric and photorealistic properties within the weights of a simple Multi-Layer Perceptron (MLP). This work investigates the feasibility and effectiveness of ingesting NeRFs into an MLLM. We introduce LLaNA, the first MLLM able to perform new tasks such as NeRF captioning and Q\\&amp;A, by directly processing the weights of a NeRF's MLP. Notably, LLaNA is able to extract information about the represented objects without the need to render images or materialize 3D data structures. In addition, we build the first large-scale NeRF-language dataset, composed by more than 300K NeRFs trained on ShapeNet and Objaverse, with paired textual annotations that enable various NeRF-language tasks. Based on this dataset, we develop a benchmark to evaluate the NeRF understanding capability of our method. Results show that directly processing NeRF weights leads to better performance on NeRF-Language tasks compared to approaches that rely on either 2D or 3D representations derived from NeRFs.","authors":["Andrea Amaduzzi","Pierluigi Zama Ramirez","Giuseppe Lisanti","Samuele Salti","Luigi Di Stefano"],"url":"https://arxiv.org/abs/2504.13995"}
{"created":"2025-04-22","title":"Knitting Robots: A Deep Learning Approach for Reverse-Engineering Fabric Patterns","abstract":"Knitting, a cornerstone of textile manufacturing, is uniquely challenging to automate, particularly in terms of converting fabric designs into precise, machine-readable instructions. This research bridges the gap between textile production and robotic automation by proposing a novel deep learning-based pipeline for reverse knitting to integrate vision-based robotic systems into textile manufacturing. The pipeline employs a two-stage architecture, enabling robots to first identify front labels before inferring complete labels, ensuring accurate, scalable pattern generation. By incorporating diverse yarn structures, including single-yarn (sj) and multi-yarn (mj) patterns, this study demonstrates how our system can adapt to varying material complexities. Critical challenges in robotic textile manipulation, such as label imbalance, underrepresented stitch types, and the need for fine-grained control, are addressed by leveraging specialized deep-learning architectures. This work establishes a foundation for fully automated robotic knitting systems, enabling customizable, flexible production processes that integrate perception, planning, and actuation, thereby advancing textile manufacturing through intelligent robotic automation.","authors":["Haoliang Sheng","Songpu Cai","Xingyu Zheng","Meng Cheng Lau"],"url":"https://arxiv.org/abs/2504.14007"}
{"created":"2025-04-22","title":"Fashion-RAG: Multimodal Fashion Image Editing via Retrieval-Augmented Generation","abstract":"In recent years, the fashion industry has increasingly adopted AI technologies to enhance customer experience, driven by the proliferation of e-commerce platforms and virtual applications. Among the various tasks, virtual try-on and multimodal fashion image editing -- which utilizes diverse input modalities such as text, garment sketches, and body poses -- have become a key area of research. Diffusion models have emerged as a leading approach for such generative tasks, offering superior image quality and diversity. However, most existing virtual try-on methods rely on having a specific garment input, which is often impractical in real-world scenarios where users may only provide textual specifications. To address this limitation, in this work we introduce Fashion Retrieval-Augmented Generation (Fashion-RAG), a novel method that enables the customization of fashion items based on user preferences provided in textual form. Our approach retrieves multiple garments that match the input specifications and generates a personalized image by incorporating attributes from the retrieved items. To achieve this, we employ textual inversion techniques, where retrieved garment images are projected into the textual embedding space of the Stable Diffusion text encoder, allowing seamless integration of retrieved elements into the generative process. Experimental results on the Dress Code dataset demonstrate that Fashion-RAG outperforms existing methods both qualitatively and quantitatively, effectively capturing fine-grained visual details from retrieved garments. To the best of our knowledge, this is the first work to introduce a retrieval-augmented generation approach specifically tailored for multimodal fashion image editing.","authors":["Fulvio Sanguigni","Davide Morelli","Marcella Cornia","Rita Cucchiara"],"url":"https://arxiv.org/abs/2504.14011"}
{"created":"2025-04-22","title":"Causal pieces: analysing and improving spiking neural networks piece by piece","abstract":"We introduce a novel concept for spiking neural networks (SNNs) derived from the idea of \"linear pieces\" used to analyse the expressiveness and trainability of artificial neural networks (ANNs). We prove that the input domain of SNNs decomposes into distinct causal regions where its output spike times are locally Lipschitz continuous with respect to the input spike times and network parameters. The number of such regions - which we call \"causal pieces\" - is a measure of the approximation capabilities of SNNs. In particular, we demonstrate in simulation that parameter initialisations which yield a high number of causal pieces on the training set strongly correlate with SNN training success. Moreover, we find that feedforward SNNs with purely positive weights exhibit a surprisingly high number of causal pieces, allowing them to achieve competitive performance levels on benchmark tasks. We believe that causal pieces are not only a powerful and principled tool for improving SNNs, but might also open up new ways of comparing SNNs and ANNs in the future.","authors":["Dominik Dold","Philipp Christian Petersen"],"url":"https://arxiv.org/abs/2504.14015"}
{"created":"2025-04-22","title":"Post Quantum Cryptography (PQC) Signatures Without Trapdoors","abstract":"Some of our current public key methods use a trap door to implement digital signature methods. This includes the RSA method, which uses Fermat's little theorem to support the creation and verification of a digital signature. The problem with a back-door is that the actual trap-door method could, in the end, be discovered. With the rise of PQC (Post Quantum Cryptography), we will see a range of methods that will not use trap doors and provide stronger proof of security. In this case, we use hash-based signatures (as used with SPHINCS+) and Fiat Shamir signatures using Zero Knowledge Proofs (as used with Dilithium).","authors":["William J Buchanan"],"url":"https://arxiv.org/abs/2504.14016"}
{"created":"2025-04-22","title":"Statistical Analysis and End-to-End Performance Evaluation of Traffic Models for Automotive Data","abstract":"Autonomous driving is a major paradigm shift in transportation, with the potential to enhance safety, optimize traffic congestion, and reduce fuel consumption. Although autonomous vehicles rely on advanced sensors and on-board computing systems to navigate without human control, full awareness of the driving environment also requires a cooperative effort via Vehicle-To-Everything (V2X) communication. Specifically, vehicles send and receive sensor perceptions to/from other vehicles to extend perception beyond their own sensing range. However, transmitting large volumes of data can be challenging for current V2X communication technologies, so data compression represents a crucial solution to reduce the message size and link congestion. In this paper, we present a statistical characterization of automotive data, focusing on LiDAR sensors. Notably, we provide models for the size of both raw and compressed point clouds. The use of statistical traffic models offers several advantages compared to using real data, such as faster simulations, reduced storage requirements, and greater flexibility in the application design. Furthermore, statistical models can be used for understanding traffic patterns and analyzing statistics, which is crucial to design and optimize wireless networks. We validate our statistical models via a Kolmogorov-Smirnoff test implementing a Bootstrap Resampling scheme. Moreover, we show via ns-3 simulations that using statistical models yields comparable results in terms of latency and throughput compared to real data, which also demonstrates the accuracy of the models.","authors":["Marcello Bullo","Amir Ashtari Gargari","Paolo Testolina","Michele Zorzi","Marco Giordani"],"url":"https://arxiv.org/abs/2504.14017"}
{"created":"2025-04-22","title":"HyDra: SOT-CAM Based Vector Symbolic Macro for Hyperdimensional Computing","abstract":"Hyperdimensional computing (HDC) is a brain-inspired paradigm valued for its noise robustness, parallelism, energy efficiency, and low computational overhead. Hardware accelerators are being explored to further enhance its performance, but current solutions are often limited by application specificity and the latency of encoding and similarity search. This paper presents a generalized, reconfigurable on-chip training and inference architecture for HDC, utilizing spin-orbit-torque magnetic (SOT-MRAM) content-addressable memory (CAM). The proposed SOT-CAM array integrates storage and computation, enabling in-memory execution of key HDC operations: binding (bitwise multiplication), permutation (bit rotation), and efficient similarity search. To mitigate interconnect parasitic effect in similarity search, a four-stage voltage scaling scheme has been proposed to ensure accurate Hamming distance representation. Additionally, a novel bit drop method replaces bit rotation during read operations, and an HDC-specific adder reduces energy and area by 1.51x and 1.43x, respectively. Benchmarked at 7nm, the architecture achieves energy reductions of 21.5x, 552.74x, 1.45x, and 282.57x for addition, permutation, multiplication, and search operations, respectively, compared to CMOS-based HDC. Against state-of-the-art HD accelerators, it achieves a 2.27x lower energy consumption and outperforms CPU and eGPU implementations by 2702x and 23161x, respectively, with less than 3% drop in accuracy","authors":["Md Mizanur Rahaman Nayan","Che-Kai Liu","Zishen Wan","Arijit Raychowdhury","Azad J Naeemi"],"url":"https://arxiv.org/abs/2504.14020"}
{"created":"2025-04-22","title":"The Effect of the Network in Cutting Carbon for Geo-shifted Workloads","abstract":"Organizations are increasingly offloading their workloads to cloud platforms. For workloads with relaxed deadlines, this presents an opportunity to reduce the total carbon footprint of these computations by moving workloads to datacenters with access to low-carbon power. Recently published results have shown that the carbon footprint of the wide-area network (WAN) can be a significant share of the total carbon output of executing the workload itself, and so careful selection of the time and place where these computations are offloaded is critical. In this paper, we propose an approach to geographic workload migration that uses high-fidelity maps of physical Internet infrastructure to better estimate the carbon costs of WAN transfers. Our findings show that space-shifting workloads can achieve much higher carbon savings than time-shifting alone, if accurate estimates of WAN carbon costs are taken into account.","authors":["Yibo Guo","Amanda Tomlinson","Runlong Su","George Porter"],"url":"https://arxiv.org/abs/2504.14022"}
{"created":"2025-04-22","title":"Simplicity by Obfuscation: Evaluating LLM-Driven Code Transformation with Semantic Elasticity","abstract":"Code obfuscation is the conversion of original source code into a functionally equivalent but less readable form, aiming to prevent reverse engineering and intellectual property theft. This is a challenging task since it is crucial to maintain functional correctness of the code while substantially disguising the input code. The recent development of large language models (LLMs) paves the way for practical applications in different domains, including software engineering. This work performs an empirical study on the ability of LLMs to obfuscate Python source code and introduces a metric (i.e., semantic elasticity) to measure the quality degree of obfuscated code. We experimented with 3 leading LLMs, i.e., Claude-3.5-Sonnet, Gemini-1.5, GPT-4-Turbo across 30 Python functions from diverse computational domains. Our findings reveal GPT-4-Turbo's remarkable effectiveness with few-shot prompting (81% pass rate versus 29% standard prompting), significantly outperforming both Gemini-1.5 (39%) and Claude-3.5-Sonnet (30%). Notably, we discovered a counter-intuitive \"obfuscation by simplification\" phenomenon where models consistently reduce rather than increase cyclomatic complexity. This study provides a methodological framework for evaluating AI-driven obfuscation while highlighting promising directions for leveraging LLMs in software security.","authors":["Lorenzo De Tomasi","Claudio Di Sipio","Antinisca Di Marco","Phuong T. Nguyen"],"url":"https://arxiv.org/abs/2504.14024"}
{"created":"2025-04-22","title":"Large Language Bayes","abstract":"Many domain experts do not have the time or training to write formal Bayesian models. This paper takes an informal problem description as input, and combines a large language model and a probabilistic programming language to create a joint distribution over formal models, latent variables, and data. A posterior over latent variables follows by conditioning on observed data and integrating over formal models. This presents a challenging inference problem. We suggest an inference recipe that amounts to generating many formal models from the large language model, performing approximate inference on each, and then doing a weighted average. This is justified an analyzed as a combination of self-normalized importance sampling, MCMC, and variational inference. We show that this produces sensible predictions without the need to specify a formal model.","authors":["Justin Domke"],"url":"https://arxiv.org/abs/2504.14025"}
{"created":"2025-04-22","title":"Prioritizing Security Practice Adoption: Empirical Insights on Software Security Outcomes in the npm Ecosystem","abstract":"Practitioners often struggle with the overwhelming number of security practices outlined in cybersecurity frameworks for risk mitigation. Given the limited budget, time, and resources, practitioners want to prioritize the adoption of security practices based on empirical evidence. The goal of this study is to assist practitioners and policymakers in making informed decisions on which security practices to adopt by evaluating the relationship between software security practices and security outcome metrics. The study investigated the relationship between security practice adoption and security outcomes. We selected the OpenSSF Scorecard metrics to automatically measure the adoption of security practices in npm GitHub repositories. We also explored security outcome metrics, such as the number of open vulnerabilities (Vul_Count), mean time to remediate (MTTR) vulnerabilities in dependencies, and mean time to update (MTTU) dependencies. We conducted regression and causal analysis using 12 Scorecard metrics and their aggregated Scorecard score (computed by aggregating individual security practice scores) as predictors and Vul_Count, MTTR, and MTTU as target variables. Our findings show that higher aggregated Scorecard scores are associated with fewer Vul_Count and shorter MTTU, also supported by causal analysis. However, while the regression model suggests shorter MTTR, causal analysis indicates project characteristics likely influence MTTR direction. Segment analysis shows that larger, newer repositories with more contributors, dependencies, and downloads have shorter MTTR. Among individual security practices, Code Review, Maintained status, Pinned Dependencies, and Branch Protection show strong associations with security outcomes; the directionality of these associations varies across security outcomes.","authors":["Nusrat Zahan","Laurie Williams"],"url":"https://arxiv.org/abs/2504.14026"}
{"created":"2025-04-22","title":"LoftUp: Learning a Coordinate-Based Feature Upsampler for Vision Foundation Models","abstract":"Vision foundation models (VFMs) such as DINOv2 and CLIP have achieved impressive results on various downstream tasks, but their limited feature resolution hampers performance in applications requiring pixel-level understanding. Feature upsampling offers a promising direction to address this challenge. In this work, we identify two critical factors for enhancing feature upsampling: the upsampler architecture and the training objective. For the upsampler architecture, we introduce a coordinate-based cross-attention transformer that integrates the high-resolution images with coordinates and low-resolution VFM features to generate sharp, high-quality features. For the training objective, we propose constructing high-resolution pseudo-groundtruth features by leveraging class-agnostic masks and self-distillation. Our approach effectively captures fine-grained details and adapts flexibly to various input and feature resolutions. Through experiments, we demonstrate that our approach significantly outperforms existing feature upsampling techniques across various downstream tasks. Our code is released at https://github.com/andrehuang/loftup.","authors":["Haiwen Huang","Anpei Chen","Volodymyr Havrylov","Andreas Geiger","Dan Zhang"],"url":"https://arxiv.org/abs/2504.14032"}
{"created":"2025-04-22","title":"On the Capacity of Insertion Channels for Small Insertion Probabilities","abstract":"Channels with synchronization errors, such as deletion and insertion errors, are crucial in DNA storage, data reconstruction, and other applications. These errors introduce memory to the channel, complicating its capacity analysis. This paper analyzes binary insertion channels for small insertion probabilities, identifying dominant terms in the capacity expansion and establishing capacity in this regime. Using Bernoulli(1/2) inputs for achievability and a converse based on the use of stationary and ergodic processes, we demonstrate that capacity closely aligns with achievable rates using independent and identically distributed (i.i.d.) inputs, differing only in higher-order terms.","authors":["Busra Tegin","Tolga M Duman"],"url":"https://arxiv.org/abs/2504.14035"}
{"created":"2025-04-22","title":"Uncovering Conspiratorial Narratives within Arabic Online Content","abstract":"This study investigates the spread of conspiracy theories in Arabic digital spaces through computational analysis of online content. By combining Named Entity Recognition and Topic Modeling techniques, specifically the Top2Vec algorithm, we analyze data from Arabic blogs and Facebook to identify and classify conspiratorial narratives. Our analysis uncovers six distinct categories: gender/feminist, geopolitical, government cover-ups, apocalyptic, Judeo-Masonic, and geoengineering. The research highlights how these narratives are deeply embedded in Arabic social media discourse, shaped by regional historical, cultural, and sociopolitical contexts. By applying advanced Natural Language Processing methods to Arabic content, this study addresses a gap in conspiracy theory research, which has traditionally focused on English-language content or offline data. The findings provide new insights into the manifestation and evolution of conspiracy theories in Arabic digital spaces, enhancing our understanding of their role in shaping public discourse in the Arab world.","authors":["Djamila Mohdeb","Meriem Laifa","Zineb Guemraoui","Dalila Behih"],"url":"https://arxiv.org/abs/2504.14037"}
{"created":"2025-04-22","title":"Flowco: Rethinking Data Analysis in the Age of LLMs","abstract":"Conducting data analysis typically involves authoring code to transform, visualize, analyze, and interpret data. Large language models (LLMs) are now capable of generating such code for simple, routine analyses. LLMs promise to democratize data science by enabling those with limited programming expertise to conduct data analyses, including in scientific research, business, and policymaking. However, analysts in many real-world settings must often exercise fine-grained control over specific analysis steps, verify intermediate results explicitly, and iteratively refine their analytical approaches. Such tasks present barriers to building robust and reproducible analyses using LLMs alone or even in conjunction with existing authoring tools (e.g., computational notebooks). This paper introduces Flowco, a new mixed-initiative system to address these challenges. Flowco leverages a visual dataflow programming model and integrates LLMs into every phase of the authoring process. A user study suggests that Flowco supports analysts, particularly those with less programming experience, in quickly authoring, debugging, and refining data analyses.","authors":["Stephen N. Freund","Brooke Simon","Emery D. Berger","Eunice Jun"],"url":"https://arxiv.org/abs/2504.14038"}
{"created":"2025-04-22","title":"MEQA: A Meta-Evaluation Framework for Question & Answer LLM Benchmarks","abstract":"As Large Language Models (LLMs) advance, their potential for widespread societal impact grows simultaneously. Hence, rigorous LLM evaluations are both a technical necessity and social imperative. While numerous evaluation benchmarks have been developed, there remains a critical gap in meta-evaluation: effectively assessing benchmarks' quality. We propose MEQA, a framework for the meta-evaluation of question and answer (QA) benchmarks, to provide standardized assessments, quantifiable scores, and enable meaningful intra-benchmark comparisons. We demonstrate this approach on cybersecurity benchmarks, using human and LLM evaluators, highlighting the benchmarks' strengths and weaknesses. We motivate our choice of test domain by AI models' dual nature as powerful defensive tools and security threats.","authors":["Jaime Raldua Veuthey","Zainab Ali Majid","Suhas Hariharan","Jacob Haimes"],"url":"https://arxiv.org/abs/2504.14039"}
{"created":"2025-04-22","title":"Multi-Stage Retrieval for Operational Technology Cybersecurity Compliance Using Large Language Models: A Railway Casestudy","abstract":"Operational Technology Cybersecurity (OTCS) continues to be a dominant challenge for critical infrastructure such as railways. As these systems become increasingly vulnerable to malicious attacks due to digitalization, effective documentation and compliance processes are essential to protect these safety-critical systems. This paper proposes a novel system that leverages Large Language Models (LLMs) and multi-stage retrieval to enhance the compliance verification process against standards like IEC 62443 and the rail-specific IEC 63452. We first evaluate a Baseline Compliance Architecture (BCA) for answering OTCS compliance queries, then develop an extended approach called Parallel Compliance Architecture (PCA) that incorporates additional context from regulatory standards. Through empirical evaluation comparing OpenAI-gpt-4o and Claude-3.5-haiku models in these architectures, we demonstrate that the PCA significantly improves both correctness and reasoning quality in compliance verification. Our research establishes metrics for response correctness, logical reasoning, and hallucination detection, highlighting the strengths and limitations of using LLMs for compliance verification in railway cybersecurity. The results suggest that retrieval-augmented approaches can significantly improve the efficiency and accuracy of compliance assessments, particularly valuable in an industry facing a shortage of cybersecurity expertise.","authors":["Regan Bolton","Mohammadreza Sheikhfathollahi","Simon Parkinson","Dan Basher","Howard Parkinson"],"url":"https://arxiv.org/abs/2504.14044"}
{"created":"2025-04-22","title":"Metacognition and Uncertainty Communication in Humans and Large Language Models","abstract":"Metacognition, the capacity to monitor and evaluate one's own knowledge and performance, is foundational to human decision-making, learning, and communication. As large language models (LLMs) become increasingly embedded in high-stakes decision contexts, it is critical to assess whether, how, and to what extent they exhibit metacognitive abilities. Here, we provide an overview of current knowledge of LLMs' metacognitive capacities, how they might be studied, and how they relate to our knowledge of metacognition in humans. We show that while humans and LLMs can sometimes appear quite aligned in their metacognitive capacities and behaviors, it is clear many differences remain. Attending to these differences is crucial not only for enhancing human-AI collaboration, but also for promoting the development of more capable and trustworthy artificial systems. Finally, we discuss how endowing future LLMs with more sensitive and more calibrated metacognition may also help them develop new capacities such as more efficient learning, self-direction, and curiosity.","authors":["Mark Steyvers","Megan A. K. Peters"],"url":"https://arxiv.org/abs/2504.14045"}
{"created":"2025-04-22","title":"A synthetic dataset of French electric load curves with temperature conditioning","abstract":"The undergoing energy transition is causing behavioral changes in electricity use, e.g. with self-consumption of local generation, or flexibility services for demand control. To better understand these changes and the challenges they induce, accessing individual smart meter data is crucial. Yet this is personal data under the European GDPR. A widespread use of such data requires thus to create synthetic realistic and privacy-preserving samples. This paper introduces a new synthetic load curve dataset generated by conditional latent diffusion. We also provide the contracted power, time-of-use plan and local temperature used for generation. Fidelity, utility and privacy of the dataset are thoroughly evaluated, demonstrating its good quality and thereby supporting its interest for energy modeling applications.","authors":["Tahar Nabil","Ghislain Agoua","Pierre Cauchois","Anne De Moliner","Beno\\^it Grossin"],"url":"https://arxiv.org/abs/2504.14046"}
{"created":"2025-04-22","title":"Think Deep, Think Fast: Investigating Efficiency of Verifier-free Inference-time-scaling Methods","abstract":"There is intense interest in investigating how inference time compute (ITC) (e.g. repeated sampling, refinements, etc) can improve large language model (LLM) capabilities. At the same time, recent breakthroughs in reasoning models, such as Deepseek-R1, unlock the opportunity for reinforcement learning to improve LLM reasoning skills. An in-depth understanding of how ITC interacts with reasoning across different models could provide important guidance on how to further advance the LLM frontier. This work conducts a comprehensive analysis of inference-time scaling methods for both reasoning and non-reasoning models on challenging reasoning tasks. Specifically, we focus our research on verifier-free inference time-scaling methods due to its generalizability without needing a reward model. We construct the Pareto frontier of quality and efficiency. We find that non-reasoning models, even with an extremely high inference budget, still fall substantially behind reasoning models. For reasoning models, majority voting proves to be a robust inference strategy, generally competitive or outperforming other more sophisticated ITC methods like best-of-N and sequential revisions, while the additional inference compute offers minimal improvements. We further perform in-depth analyses of the association of key response features (length and linguistic markers) with response quality, with which we can improve the existing ITC methods. We find that correct responses from reasoning models are typically shorter and have fewer hedging and thinking markers (but more discourse markers) than the incorrect responses.","authors":["Junlin Wang","Shang Zhu","Jon Saad-Falcon","Ben Athiwaratkun","Qingyang Wu","Jue Wang","Shuaiwen Leon Song","Ce Zhang","Bhuwan Dhingra","James Zou"],"url":"https://arxiv.org/abs/2504.14047"}
{"created":"2025-04-22","title":"CAOTE: KV Caching through Attention Output Error based Token Eviction","abstract":"While long context support of large language models has extended their abilities, it also incurs challenges in memory and compute which becomes crucial bottlenecks in resource-restricted devices. Token eviction, a widely adopted post-training methodology designed to alleviate the bottlenecks by evicting less important tokens from the cache, typically uses attention scores as proxy metrics for token importance. However, one major limitation of attention score as a token-wise importance metrics is that it lacks the information about contribution of tokens to the attention output. In this paper, we propose a simple eviction criterion based on the contribution of cached tokens to attention outputs. Our method, CAOTE, optimizes for eviction error due to token eviction, by seamlessly integrating attention scores and value vectors. This is the first method which uses value vector information on top of attention-based eviction scores. Additionally, CAOTE can act as a meta-heuristic method with flexible usage with any token eviction method. We show that CAOTE, when combined with the state-of-the-art attention score-based methods, always improves accuracies on the downstream task, indicating the importance of leveraging information from values during token eviction process.","authors":["Raghavv Goel","Junyoung Park","Mukul Gagrani","Dalton Jones","Matthew Morse","Harper Langston","Mingu Lee","Chris Lott"],"url":"https://arxiv.org/abs/2504.14051"}
{"created":"2025-04-22","title":"Discrete Evacuation in Graphs with Multiple Exits","abstract":"Consider the following discrete evacuation model. The evacuation terrain is modeled by a simple graph $G=(V,E)$ whose certain vertices $X\\subseteq V$ are called \\emph{exits}. Initially, each vertex is either \\emph{empty} or \\emph{occupied} by an agent. We assume that each vertex has a unique \\emph{id} (and therefore the agents do have unique ids), each agent has finite but arbitrarily large memory, and the graph is initially stored in the memory of each agent. In other words, the agents do know the topology of the network along with the locations of the exits, but they do not know the initial positions nor the quantity of other agents. The time is divided into \\emph{steps}; in each step any pair of agents present at vertices at a distance of at most two can exchange an arbitrary number of messages, and then each agent can either make a move or stay put. The agents should make moves in a collision-free manner, i.e., no two agents can be located at the same vertex in the same step. At the end of each step, any agent located at an exit \\emph{evacuates}, i.e., it is removed from the graph. The goal is to provide an algorithm to the agents (referred to as an evacuation strategy) that ensures the evacuation of all agents and minimizes the number of steps.","authors":["Piotr Borowiecki","Dariusz Dereniowski","{\\L}ukasz Kuszner"],"url":"https://arxiv.org/abs/2504.14052"}
{"created":"2025-04-22","title":"Sentiment Analysis of Airbnb Reviews: Exploring Their Impact on Acceptance Rates and Pricing Across Multiple U.S. Regions","abstract":"This research examines whether Airbnb guests' positive and negative comments influence acceptance rates and rental prices across six U.S. regions: Rhode Island, Broward County, Chicago, Dallas, San Diego, and Boston. Thousands of reviews were collected and analyzed using Natural Language Processing (NLP) to classify sentiments as positive or negative, followed by statistical testing (t-tests and basic correlations) on the average scores. The findings reveal that over 90 percent of reviews in each region are positive, indicating that having additional reviews does not significantly enhance prices. However, listings with predominantly positive feedback exhibit slightly higher acceptance rates, suggesting that sentiment polarity, rather than the sheer volume of reviews, is a more critical factor for host success. Additionally, budget listings often gather extensive reviews while maintaining competitive pricing, whereas premium listings sustain higher prices with fewer but highly positive reviews. These results underscore the importance of sentiment quality over quantity in shaping guest behavior and pricing strategies in an overwhelmingly positive review environment.","authors":["Ali Safari"],"url":"https://arxiv.org/abs/2504.14053"}
{"created":"2025-04-22","title":"Occlusion-Ordered Semantic Instance Segmentation","abstract":"Standard semantic instance segmentation provides useful, but inherently 2D information from a single image. To enable 3D analysis, one usually integrates absolute monocular depth estimation with instance segmentation. However, monocular depth is a difficult task. Instead, we leverage a simpler single-image task, occlusion-based relative depth ordering, providing coarser but useful 3D information. We show that relative depth ordering works more reliably from occlusions than from absolute depth. We propose to solve the joint task of relative depth ordering and segmentation of instances based on occlusions. We call this task Occlusion-Ordered Semantic Instance Segmentation (OOSIS). We develop an approach to OOSIS that extracts instances and their occlusion order simultaneously from oriented occlusion boundaries and semantic segmentation. Unlike popular detect-and-segment framework for instance segmentation, combining occlusion ordering with instance segmentation allows a simple and clean formulation of OOSIS as a labeling problem. As a part of our solution for OOSIS, we develop a novel oriented occlusion boundaries approach that significantly outperforms prior work. We also develop a new joint OOSIS metric based both on instance mask accuracy and correctness of their occlusion order. We achieve better performance than strong baselines on KINS and COCOA datasets.","authors":["Soroosh Baselizadeh","Cheuk-To Yu","Olga Veksler","Yuri Boykov"],"url":"https://arxiv.org/abs/2504.14054"}
{"created":"2025-04-22","title":"Apollo: An Interactive Environment for Generating Symbolic Musical Phrases using Corpus-based Style Imitation","abstract":"With the recent developments in machine intelligence and web technologies, new generative music systems are being explored for assisted composition using machine learning techniques on the web. Such systems are built for various tasks such as melodic, harmonic or rhythm generation, music interpolation, continuation and style imitation. In this paper, we introduce Apollo, an interactive music application for generating symbolic phrases of conventional western music using corpus-based style imitation techniques. In addition to enabling the construction and management of symbolic musical corpora, the system makes it possible for music artists and researchers to generate new musical phrases in the style of the proposed corpus. The system is available as a desktop application. The generated symbolic music materials, encoded in the MIDI format, can be exported or streamed for various purposes including using them as seed material for musical projects. We present the system design, implementation details, discuss and conclude with future work for the system.","authors":["Renaud Bougueng Tchemeube","Jeff Ens","Philippe Pasquier"],"url":"https://arxiv.org/abs/2504.14055"}
{"created":"2025-04-22","title":"Calliope: An Online Generative Music System for Symbolic Multi-Track Composition","abstract":"With the rise of artificial intelligence in recent years, there has been a rapid increase in its application towards creative domains, including music. There exist many systems built that apply machine learning approaches to the problem of computer-assisted music composition (CAC). Calliope is a web application that assists users in performing a variety of multi-track composition tasks in the symbolic domain. The user can upload (Musical Instrument Digital Interface) MIDI files, visualize and edit MIDI tracks, and generate partial (via bar in-filling) or complete multi-track content using the Multi-Track Music Machine (MMM). Generation of new MIDI excerpts can be done in batch and can be combined with active playback listening for an enhanced assisted-composition workflow. The user can export generated MIDI materials or directly stream MIDI playback from the system to their favorite Digital Audio Workstation (DAW). We present a demonstration of the system, its features, generative parameters and describe the co-creative workflows that it affords.","authors":["Renaud Bougueng Tchemeube","Jeff Ens","Philippe Pasquier"],"url":"https://arxiv.org/abs/2504.14058"}
{"created":"2025-04-22","title":"Benchmarking Differentially Private Tabular Data Synthesis","abstract":"Differentially private (DP) tabular data synthesis generates artificial data that preserves the statistical properties of private data while safeguarding individual privacy. The emergence of diverse algorithms in recent years has introduced challenges in practical applications, such as inconsistent data processing methods, lack of in-depth algorithm analysis, and incomplete comparisons due to overlapping development timelines. These factors create significant obstacles to selecting appropriate algorithms.","authors":["Kai Chen","Xiaochen Li","Chen Gong","Ryan McKenna","Tianhao Wang"],"url":"https://arxiv.org/abs/2504.14061"}
{"created":"2025-04-22","title":"DoomArena: A framework for Testing AI Agents Against Evolving Security Threats","abstract":"We present DoomArena, a security evaluation framework for AI agents. DoomArena is designed on three principles: 1) It is a plug-in framework and integrates easily into realistic agentic frameworks like BrowserGym (for web agents) and $\\tau$-bench (for tool calling agents); 2) It is configurable and allows for detailed threat modeling, allowing configuration of specific components of the agentic framework being attackable, and specifying targets for the attacker; and 3) It is modular and decouples the development of attacks from details of the environment in which the agent is deployed, allowing for the same attacks to be applied across multiple environments. We illustrate several advantages of our framework, including the ability to adapt to new threat models and environments easily, the ability to easily combine several previously published attacks to enable comprehensive and fine-grained security testing, and the ability to analyze trade-offs between various vulnerabilities and performance. We apply DoomArena to state-of-the-art (SOTA) web and tool-calling agents and find a number of surprising results: 1) SOTA agents have varying levels of vulnerability to different threat models (malicious user vs malicious environment), and there is no Pareto dominant agent across all threat models; 2) When multiple attacks are applied to an agent, they often combine constructively; 3) Guardrail model-based defenses seem to fail, while defenses based on powerful SOTA LLMs work better. DoomArena is available at https://github.com/ServiceNow/DoomArena.","authors":["Leo Boisvert","Mihir Bansal","Chandra Kiran Reddy Evuru","Gabriel Huang","Abhay Puri","Avinandan Bose","Maryam Fazel","Quentin Cappart","Jason Stanley","Alexandre Lacoste","Alexandre Drouin","Krishnamurthy Dvijotham"],"url":"https://arxiv.org/abs/2504.14064"}
{"created":"2025-04-22","title":"AnywhereXR: On-the-fly 3D Environments as a Basis for Open Source Immersive Digital Twin Applications","abstract":"Visualization has long been fundamental to human communication and decision-making. Today, we stand at the threshold of integrating veridical, high-fidelity visualizations into immersive digital environments, alongside digital twinning techniques. This convergence heralds powerful tools for communication, co-design, and participatory decision-making. Our paper delves into the development of lightweight open-source immersive digital twin visualisations, capitalizing on the evolution of immersive technologies, the wealth of spatial data available, and advancements in digital twinning. Coined AnywhereXR, this approach ultimately seeks to democratize access to spatial information at a global scale. Utilizing the Netherlands as our starting point, we envision expanding this methodology worldwide, leveraging open data and software to address pressing societal challenges across diverse domains.","authors":["Alexander Klippel","Bart Knuiman","Jiayan Zhao","Jan Oliver Wallgr\\\"un","Jascha Gr\\\"ubel"],"url":"https://arxiv.org/abs/2504.14065"}
{"created":"2025-04-22","title":"A Baseline for Self-state Identification and Classification in Mental Health Data: CLPsych 2025 Task","abstract":"We present a baseline for the CLPsych 2025 A.1 task: classifying self-states in mental health data taken from Reddit. We use few-shot learning with a 4-bit quantized Gemma 2 9B model and a data preprocessing step which first identifies relevant sentences indicating self-state evidence, and then performs a binary classification to determine whether the sentence is evidence of an adaptive or maladaptive self-state. This system outperforms our other method which relies on an LLM to highlight spans of variable length independently. We attribute the performance of our model to the benefits of this sentence chunking step for two reasons: partitioning posts into sentences 1) broadly matches the granularity at which self-states were human-annotated and 2) simplifies the task for our language model to a binary classification problem. Our system places third out of fourteen systems submitted for Task A.1, achieving a test-time recall of 0.579.","authors":["Laerdon Kim"],"url":"https://arxiv.org/abs/2504.14066"}
{"created":"2025-04-22","title":"Contextual Embedding-based Clustering to Identify Topics for Healthcare Service Improvement","abstract":"Understanding patient feedback is crucial for improving healthcare services, yet analyzing unlabeled short-text feedback presents significant challenges due to limited data and domain-specific nuances. Traditional supervised learning approaches require extensive labeled datasets, making unsupervised methods more viable for uncovering meaningful insights from patient feedback. This study explores unsupervised methods to extract meaningful topics from 439 survey responses collected from a healthcare system in Wisconsin, USA. A keyword-based filtering approach was applied to isolate complaint-related feedback using a domain-specific lexicon. To delve deeper and analyze dominant topics in feedback, we explored traditional topic modeling methods, including Latent Dirichlet Allocation (LDA) and Gibbs Sampling Dirichlet Multinomial Mixture (GSDMM), alongside BERTopic, an advanced neural embedding-based clustering approach. To improve coherence and interpretability where data are scarce and consist of short-texts, we propose kBERT, an integration of BERT embeddings with k-means clustering. Model performance was assessed using coherence scores (Cv ) for topic interpretability and average Inverted Rank-Biased Overlap (IRBOavg) for topic diversity. Results indicate that kBERT achieves the highest coherence (Cv = 0.53) and distinct topic separation (IRBOavg = 1.00), outperforming all other models in short-text healthcare feedback analysis. Our findings emphasize the importance of embedding-based techniques for topic identification and highlight the need for context-aware models in healthcare analytics.","authors":["K M Sajjadul Islam","Ravi Teja Karri","Srujan Vegesna","Jiawei Wu","Praveen Madiraju"],"url":"https://arxiv.org/abs/2504.14068"}
{"created":"2025-04-22","title":"Towards Stateless Clients in Ethereum: Benchmarking Verkle Trees and Binary Merkle Trees with SNARKs","abstract":"Ethereum, the leading platform for decentralized applications, faces challenges in maintaining decentralization due to the significant hardware requirements for validators to store Ethereum's entire state. To address this, the concept of stateless clients is under exploration, enabling validators to verify transactions using cryptographic witnesses rather than the full state. This paper compares two approaches currently being discussed for achieving statelessness: Verkle trees utilizing vector commitments and binary Merkle trees combined with SNARKs. Benchmarks are performed to evaluate proving time, witness size, and verification time. The results reveal that the Verkle tree implementation used for benchmarking offers proving and verification times on the order of seconds and proof sizes on the order of one MB. The SNARK-based Merkle trees exhibit slow proof generation times, while offering constant and fast verification time. Overall, the results indicate for Verkle trees to provide a more practical solution for Ethereum's stateless future, but both methods offer valuable insights into reducing the state burden on Ethereum nodes. We make the code used for benchmarking available on GitHub.","authors":["Jan Oberst"],"url":"https://arxiv.org/abs/2504.14069"}
{"created":"2025-04-22","title":"A CMOS Probabilistic Computing Chip With In-situ hardware Aware Learning","abstract":"This paper demonstrates a probabilistic bit physics inspired solver with 440 spins configured in a Chimera graph, occupying an area of 0.44 mm^2. Area efficiency is maximized through a current-mode implementation of the neuron update circuit, standard cell design for analog blocks pitch-matched to digital blocks, and a shared power supply for both digital and analog components. Process variation related mismatches introduced by this approach are effectively mitigated using a hardware aware contrastive divergence algorithm during training. We validate the chip's ability to perform probabilistic computing tasks such as modeling logic gates and full adders, as well as optimization tasks such as MaxCut, demonstrating its potential for AI and machine learning applications.","authors":["Jinesh Jhonsa","William Whitehead","David McCarthy","Shuvro Chowdhury","Kerem Camsari","Luke Theogarajan"],"url":"https://arxiv.org/abs/2504.14070"}
{"created":"2025-04-22","title":"Evaluating Human-AI Interaction via Usability, User Experience and Acceptance Measures for MMM-C: A Creative AI System for Music Composition","abstract":"With the rise of artificial intelligence (AI), there has been increasing interest in human-AI co-creation in a variety of artistic domains including music as AI-driven systems are frequently able to generate human-competitive artifacts. Now, the implications of such systems for musical practice are being investigated. We report on a thorough evaluation of the user adoption of the Multi-Track Music Machine (MMM) as a co-creative AI tool for music composers. To do this, we integrate MMM into Cubase, a popular Digital Audio Workstation (DAW) by Steinberg, by producing a \"1-parameter\" plugin interface named MMM-Cubase (MMM-C), which enables human-AI co-composition. We contribute a methodological assemblage as a 3-part mixed method study measuring usability, user experience and technology acceptance of the system across two groups of expert-level composers: hobbyists and professionals. Results show positive usability and acceptance scores. Users report experiences of novelty, surprise and ease of use from using the system, and limitations on controllability and predictability of the interface when generating music. Findings indicate no significant difference between the two user groups.","authors":["Renaud Bougueng Tchemeube","Jeff Ens","Cale Plut","Philippe Pasquier","Maryam Safi","Yvan Grabit","Jean-Baptiste Rolland"],"url":"https://arxiv.org/abs/2504.14071"}
{"created":"2025-04-22","title":"Holant* Dichotomy on Domain Size 3: A Geometric Perspective","abstract":"Holant problems are a general framework to study the computational complexity of counting problems. It is a more expressive framework than counting constraint satisfaction problems (CSP) which are in turn more expressive than counting graph homomorphisms (GH). In this paper, we prove the first complexity dichotomy of $\\mathrm{Holant}_3(\\mathcal{F})$ where $\\mathcal{F}$ is an arbitrary set of symmetric, real valued constraint functions on domain size $3$. We give an explicit tractability criterion and prove that, if $\\mathcal{F}$ satisfies this criterion then $\\mathrm{Holant}_3(\\mathcal{F})$ is polynomial time computable, and otherwise it is \\#P-hard, with no intermediate cases. We show that the geometry of the tensor decomposition of the constraint functions plays a central role in the formulation as well as the structural internal logic of the dichotomy.","authors":["Jin-Yi Cai","Jin Soo Ihm"],"url":"https://arxiv.org/abs/2504.14074"}
{"created":"2025-04-22","title":"Towards Scale-Aware Low-Light Enhancement via Structure-Guided Transformer Design","abstract":"Current Low-light Image Enhancement (LLIE) techniques predominantly rely on either direct Low-Light (LL) to Normal-Light (NL) mappings or guidance from semantic features or illumination maps. Nonetheless, the intrinsic ill-posedness of LLIE and the difficulty in retrieving robust semantics from heavily corrupted images hinder their effectiveness in extremely low-light environments. To tackle this challenge, we present SG-LLIE, a new multi-scale CNN-Transformer hybrid framework guided by structure priors. Different from employing pre-trained models for the extraction of semantics or illumination maps, we choose to extract robust structure priors based on illumination-invariant edge detectors. Moreover, we develop a CNN-Transformer Hybrid Structure-Guided Feature Extractor (HSGFE) module at each scale with in the UNet encoder-decoder architecture. Besides the CNN blocks which excels in multi-scale feature extraction and fusion, we introduce a Structure-Guided Transformer Block (SGTB) in each HSGFE that incorporates structural priors to modulate the enhancement process. Extensive experiments show that our method achieves state-of-the-art performance on several LLIE benchmarks in both quantitative metrics and visual quality. Our solution ranks second in the NTIRE 2025 Low-Light Enhancement Challenge. Code is released at https://github.com/minyan8/imagine.","authors":["Wei Dong","Yan Min","Han Zhou","Jun Chen"],"url":"https://arxiv.org/abs/2504.14075"}
{"created":"2025-04-22","title":"Transformation of audio embeddings into interpretable, concept-based representations","abstract":"Advancements in audio neural networks have established state-of-the-art results on downstream audio tasks. However, the black-box structure of these models makes it difficult to interpret the information encoded in their internal audio representations. In this work, we explore the semantic interpretability of audio embeddings extracted from these neural networks by leveraging CLAP, a contrastive learning model that brings audio and text into a shared embedding space. We implement a post-hoc method to transform CLAP embeddings into concept-based, sparse representations with semantic interpretability. Qualitative and quantitative evaluations show that the concept-based representations outperform or match the performance of original audio embeddings on downstream tasks while providing interpretability. Additionally, we demonstrate that fine-tuning the concept-based representations can further improve their performance on downstream tasks. Lastly, we publish three audio-specific vocabularies for concept-based interpretability of audio embeddings.","authors":["Alice Zhang","Edison Thomaz","Lie Lu"],"url":"https://arxiv.org/abs/2504.14076"}
{"created":"2025-04-22","title":"Infrared Vision Systems for Emergency Vehicle Driver Assistance in Low-Visibility Conditions","abstract":"This study investigates the potential of infrared (IR) camera technology to enhance driver safety for emergency vehicles operating in low-visibility conditions, particularly at night and in dense fog. Such environments significantly increase the risk of collisions, especially for tow trucks and snowplows that must remain operational in challenging conditions. Conventional driver assistance systems often struggle under these conditions due to limited visibility. In contrast, IR cameras, which detect the thermal signatures of obstacles, offer a promising alternative. The evaluation combines controlled laboratory experiments, real-world field tests, and surveys of emergency vehicle operators. In addition to assessing detection performance, the study examines the feasibility of retrofitting existing Department of Transportation (DoT) fleets with cost-effective IR-based driver assistance systems. Results underscore the utility of IR technology in enhancing driver awareness and provide data-driven recommendations for scalable deployment across legacy emergency vehicle fleets.","authors":["M-Mahdi Naddaf-Sh","Andrew Lee","Kin Yen","Eemon Amini","Iman Soltani"],"url":"https://arxiv.org/abs/2504.14078"}
{"created":"2025-04-22","title":"Transport alpha divergences","abstract":"We derive a class of divergences measuring the difference between probability density functions on a one-dimensional sample space. This divergence is a one-parameter variation of the Ito-Sauda divergence between quantile density functions. We prove that the proposed divergence is one-parameter variation of transport Kullback-Leibler divergence and Hessian distance of negative Boltzmann entropy with respect to Wasserstein-2 metric. From Taylor expansions, we also formulate the 3-symmetric tensor in Wasserstein space, which is given by an iterative Gamma three operators. The alpha-geodesic on Wasserstein space is also derived. From these properties, we name the proposed information measures transport alpha divergences. We provide several examples of transport alpha divergences for generative models in machine learning applications.","authors":["Wuchen Li"],"url":"https://arxiv.org/abs/2504.14084"}
{"created":"2025-04-22","title":"Channels with Input-Correlated Synchronization Errors","abstract":"\"Independent and identically distributed\" errors do not accurately capture the noisy behavior of real-world data storage and information transmission technologies. Motivated by this, we study channels with input-correlated synchronization errors, meaning that the distribution of synchronization errors (such as deletions and insertions) applied to the $i$-th input $x_i$ may depend on the whole input string $x$.","authors":["Roni Con","Jo\\~ao Ribeiro"],"url":"https://arxiv.org/abs/2504.14087"}
{"created":"2025-04-22","title":"5Guard: Isolation-aware End-to-End Slicing of 5G Networks","abstract":"Network slicing logically partitions the 5G infrastructure to cater to diverse verticals with varying requirements. However, resource sharing exposes the slices to threats and performance degradation, making slice isolation essential. Fully isolating slices is resource-prohibitive, prompting the need for isolation-aware network slicing, where each slice is assigned a tailored isolation level to balance security, usability, and overhead. This paper investigates end-to-end 5G network slicing with resource isolation from the perspective of the infrastructure provider, ensuring compliance with the customers' service-level agreements. We formulate the online 5G isolation-aware network slicing (5G-INS) as a mixed-integer programming problem, modeling realistic slice isolation levels and integrating slice prioritization. To solve 5G-INS, we propose 5Guard, a novel adaptive framework that leverages an ensemble of custom optimization algorithms to achieve the best solution within resource budget and time constraints. Our results show that 5Guard increases profit by up to 10.1% in resource-constrained environments and up to 25.4% in a real-world large-scale network compared to the best-performing individual algorithm. Furthermore, we analyze the trade-offs between isolation levels, their impact on resource utilization, and the effects of slice placement, demonstrating significant advantages over baseline approaches that enforce uniform isolation policies.","authors":["Mehdi Bolourian","Noura Limam","Mohammad Ali Salahuddin","Raouf Boutaba"],"url":"https://arxiv.org/abs/2504.14088"}
{"created":"2025-04-22","title":"LogicTree: Structured Proof Exploration for Coherent and Rigorous Logical Reasoning with Large Language Models","abstract":"Large language models (LLMs) have achieved remarkable multi-step reasoning capabilities across various domains. However, LLMs still face distinct challenges in complex logical reasoning, as (1) proof-finding requires systematic exploration and the maintenance of logical coherence and (2) searching the right combination of premises at each reasoning step is inherently challenging in tasks with large premise space. To address this, we propose LogicTree, an inference-time modular framework employing algorithm-guided search to automate structured proof exploration and ensure logical coherence. Advancing beyond tree-of-thought (ToT), we incorporate caching mechanism into LogicTree to enable effective utilization of historical knowledge, preventing reasoning stagnation and minimizing redundancy. Furthermore, we address the combinatorial complexity of premise search by decomposing it into a linear process. The refined premise selection restricts subsequent inference to at most one derivation per step, enhancing reasoning granularity and enforcing strict step-by-step reasoning. Additionally, we introduce two LLM-free heuristics for premise prioritization, enabling strategic proof search. Experimental results on five datasets demonstrate that LogicTree optimally scales inference-time computation to achieve higher proof accuracy, surpassing chain-of-thought (CoT) and ToT with average gains of 23.6% and 12.5%, respectively, on GPT-4o. Moreover, within LogicTree, GPT-4o outperforms o3-mini by 7.6% on average.","authors":["Kang He","Kaushik Roy"],"url":"https://arxiv.org/abs/2504.14089"}
{"created":"2025-04-22","title":"DataMaestro: A Versatile and Efficient Data Streaming Engine Bringing Decoupled Memory Access To Dataflow Accelerators","abstract":"Deep Neural Networks (DNNs) have achieved remarkable success across various intelligent tasks but encounter performance and energy challenges in inference execution due to data movement bottlenecks. We introduce DataMaestro, a versatile and efficient data streaming unit that brings the decoupled access/execute architecture to DNN dataflow accelerators to address this issue. DataMaestro supports flexible and programmable access patterns to accommodate diverse workload types and dataflows, incorporates fine-grained prefetch and addressing mode switching to mitigate bank conflicts, and enables customizable on-the-fly data manipulation to reduce memory footprints and access counts. We integrate five DataMaestros with a Tensor Core-like GeMM accelerator and a Quantization accelerator into a RISC-V host system for evaluation. The FPGA prototype and VLSI synthesis results demonstrate that DataMaestro helps the GeMM core achieve nearly 100% utilization, which is 1.05-21.39x better than state-of-the-art solutions, while minimizing area and energy consumption to merely 6.43% and 15.06% of the total system.","authors":["Xiaoling Yi","Yunhao Deng","Ryan Antonio","Fanchen Kong","Guilherme Paim","Marian Verhelst"],"url":"https://arxiv.org/abs/2504.14091"}
{"created":"2025-04-22","title":"Retinex-guided Histogram Transformer for Mask-free Shadow Removal","abstract":"While deep learning methods have achieved notable progress in shadow removal, many existing approaches rely on shadow masks that are difficult to obtain, limiting their generalization to real-world scenes. In this work, we propose ReHiT, an efficient mask-free shadow removal framework based on a hybrid CNN-Transformer architecture guided by Retinex theory. We first introduce a dual-branch pipeline to separately model reflectance and illumination components, and each is restored by our developed Illumination-Guided Hybrid CNN-Transformer (IG-HCT) module. Second, besides the CNN-based blocks that are capable of learning residual dense features and performing multi-scale semantic fusion, multi-scale semantic fusion, we develop the Illumination-Guided Histogram Transformer Block (IGHB) to effectively handle non-uniform illumination and spatially complex shadows. Extensive experiments on several benchmark datasets validate the effectiveness of our approach over existing mask-free methods. Trained solely on the NTIRE 2025 Shadow Removal Challenge dataset, our solution delivers competitive results with one of the smallest parameter sizes and fastest inference speeds among top-ranked entries, highlighting its applicability for real-world applications with limited computational resources. The code is available at https://github.com/dongw22/oath.","authors":["Wei Dong","Han Zhou","Seyed Amirreza Mousavi","Jun Chen"],"url":"https://arxiv.org/abs/2504.14092"}
{"created":"2025-04-22","title":"Writing Patterns Reveal a Hidden Division of Labor in Scientific Teams","abstract":"The recognition of individual contributions is central to the scientific reward system, yet coauthored papers often obscure who did what. Traditional proxies like author order assume a simplistic decline in contribution, while emerging practices such as self-reported roles are biased and limited in scope. We introduce a large-scale, behavior-based approach to identifying individual contributions in scientific papers. Using author-specific LaTeX macros as writing signatures, we analyze over 730,000 arXiv papers (1991-2023), covering over half a million scientists. Validated against self-reports, author order, disciplinary norms, and Overleaf records, our method reliably infers author-level writing activity. Section-level traces reveal a hidden division of labor: first authors focus on technical sections (e.g., Methods, Results), while last authors primarily contribute to conceptual sections (e.g., Introduction, Discussion). Our findings offer empirical evidence of labor specialization at scale and new tools to improve credit allocation in collaborative research.","authors":["Lulin Yang","Jiaxin Pei","Lingfei Wu"],"url":"https://arxiv.org/abs/2504.14093"}
{"created":"2025-04-22","title":"Leakage and Interpretability in Concept-Based Models","abstract":"Concept Bottleneck Models aim to improve interpretability by predicting high-level intermediate concepts, representing a promising approach for deployment in high-risk scenarios. However, they are known to suffer from information leakage, whereby models exploit unintended information encoded within the learned concepts. We introduce an information-theoretic framework to rigorously characterise and quantify leakage, and define two complementary measures: the concepts-task leakage (CTL) and interconcept leakage (ICL) scores. We show that these measures are strongly predictive of model behaviour under interventions and outperform existing alternatives in robustness and reliability. Using this framework, we identify the primary causes of leakage and provide strong evidence that Concept Embedding Models exhibit substantial leakage regardless of the hyperparameters choice. Finally, we propose practical guidelines for designing concept-based models to reduce leakage and ensure interpretability.","authors":["Enrico Parisini","Tapabrata Chakraborti","Chris Harbron","Ben D. MacArthur","Christopher R. S. Banerji"],"url":"https://arxiv.org/abs/2504.14094"}
{"created":"2025-04-22","title":"Personalizing Exposure Therapy via Reinforcement Learning","abstract":"Personalized therapy, in which a therapeutic practice is adapted to an individual patient, can lead to improved health outcomes. Typically, this is accomplished by relying on a therapist's training and intuition along with feedback from a patient. However, this requires the therapist to become an expert on any technological components, such as in the case of Virtual Reality Exposure Therapy (VRET). While there exist approaches to automatically adapt therapeutic content to a patient, they generally rely on hand-authored, pre-defined rules, which may not generalize to all individuals. In this paper, we propose an approach to automatically adapt therapeutic content to patients based on physiological measures. We implement our approach in the context of virtual reality arachnophobia exposure therapy, and rely on experience-driven procedural content generation via reinforcement learning (EDPCGRL) to generate virtual spiders to match an individual patient. Through a human subject study, we demonstrate that our system significantly outperforms a more common rules-based method, highlighting its potential for enhancing personalized therapeutic interventions.","authors":["Athar Mahmoudi-Nejad","Matthew Guzdial","Pierre Boulanger"],"url":"https://arxiv.org/abs/2504.14095"}
{"created":"2025-04-22","title":"VideoPASTA: 7K Preference Pairs That Matter for Video-LLM Alignment","abstract":"Video-language models (Video-LLMs) excel at understanding video content but struggle with spatial relationships, temporal ordering, and cross-frame continuity. To address these limitations, we introduce VideoPASTA (Preference Alignment with Spatio-Temporal-Cross Frame Adversaries), a framework that enhances Video-LLMs through targeted preference optimization. VideoPASTA trains models to distinguish accurate video representations from carefully generated adversarial examples that deliberately violate spatial, temporal, or cross-frame relations. By applying Direct Preference Optimization to just 7,020 preference pairs, VideoPASTA learns robust representations that capture fine-grained spatial relationships and long-range temporal dynamics. Experiments on standard video benchmarks show significant relative performance gains of 3.05% on VideoMME, 1.97% on NeXTQA, and 1.31% on LongVideoBench, over the baseline Qwen2.5-VL model. These results demonstrate that targeted alignment, rather than massive pretraining or architectural modifications, effectively addresses core video-language challenges. Notably, VideoPASTA achieves these improvements without human annotation or captioning, relying on just 32-frame sampling, compared to the 96-frame, multi-GPU setups of prior work. This efficiency makes our approach a scalable, plug-and-play solution that seamlessly integrates with existing models while preserving their capabilities.","authors":["Yogesh Kulkarni","Pooyan Fazli"],"url":"https://arxiv.org/abs/2504.14096"}
{"created":"2025-04-22","title":"Cloud based DevOps Framework for Identifying Risk Factors of Hospital Utilization","abstract":"A scalable and reliable system is required to analyze the National Health and Nutrition Examination Survey (NHANES) data efficiently to understand hospital utilization risk factors. This study aims to investigate the integration of continuous integration and deployment (CI/CD) practices in data science workflows, specifically focusing on analyzing NHANES data to identify the prevalence of diabetes, obesity, and cardiovascular diseases. An end-to-end cloud-based DevOps framework is proposed for data analysis which examines risk factors associated with hospital utilization and evaluates key hospital utilization metrics. We have also highlighted the modular structure of the framework that can be generalized for any other domains beyond healthcare. In the framework, an online data update method is provided which can be extended further using both real and synthetic data. As such, the framework can be especially useful for sparse dataset domains such as environmental science, robotics, cybersecurity, and cultural heritage and arts.","authors":["Monojit Banerjee","Akaash Vishal Hazarika","Mahak Shah"],"url":"https://arxiv.org/abs/2504.14097"}
{"created":"2025-04-22","title":"Enhancing Math Learning in an LMS Using AI-Driven Question Recommendations","abstract":"This paper presents an AI-driven approach to enhance math learning in a modern Learning Management System (LMS) by recommending similar math questions. Deep embeddings for math questions are generated using Meta's Llama-3.2-11B-Vision-Instruct model, and three recommendation methods-cosine similarity, Self-Organizing Maps (SOM), and Gaussian Mixture Models (GMM)-are applied to identify similar questions. User interaction data, including session durations, response times, and correctness, are used to evaluate the methods. Our findings suggest that while cosine similarity produces nearly identical question matches, SOM yields higher user satisfaction whereas GMM generally underperforms, indicating that introducing variety to a certain degree may enhance engagement and thereby potential learning outcomes until variety is no longer balanced reasonably, which our data about the implementations of all three methods demonstrate.","authors":["Justus R{\\aa}munddal"],"url":"https://arxiv.org/abs/2504.14098"}
{"created":"2025-04-22","title":"Coordinating Spinal and Limb Dynamics for Enhanced Sprawling Robot Mobility","abstract":"Among vertebrates, salamanders, with their unique ability to transition between walking and swimming gaits, highlight the role of spinal mobility in locomotion. A flexible spine enables undulation of the body through a wavelike motion along the spine, aiding navigation over uneven terrains and obstacles. Yet environmental uncertainties, such as surface irregularities and variations in friction, can significantly disrupt body-limb coordination and cause discrepancies between predictions from mathematical models and real-world outcomes. Addressing this challenge requires the development of sophisticated control strategies capable of dynamically adapting to uncertain conditions while maintaining efficient locomotion. Deep reinforcement learning (DRL) offers a promising framework for handling non-deterministic environments and enabling robotic systems to adapt effectively and perform robustly under challenging conditions. In this study, we comparatively examine learning-based control strategies and biologically inspired gait design methods on a salamander-like robot.","authors":["Merve Atasever","Ali Okhovat","Azhang Nazaripouya","John Nisbet","Omer Kurkutlu","Jyotirmoy V. Deshmukh","Yasemin Ozkan Aydin"],"url":"https://arxiv.org/abs/2504.14103"}
{"created":"2025-04-22","title":"Amplify Initiative: Building A Localized Data Platform for Globalized AI","abstract":"Current AI models often fail to account for local context and language, given the predominance of English and Western internet content in their training data. This hinders the global relevance, usefulness, and safety of these models as they gain more users around the globe. Amplify Initiative, a data platform and methodology, leverages expert communities to collect diverse, high-quality data to address the limitations of these models. The platform is designed to enable co-creation of datasets, provide access to high-quality multilingual datasets, and offer recognition to data authors. This paper presents the approach to co-creating datasets with domain experts (e.g., health workers, teachers) through a pilot conducted in Sub-Saharan Africa (Ghana, Kenya, Malawi, Nigeria, and Uganda). In partnership with local researchers situated in these countries, the pilot demonstrated an end-to-end approach to co-creating data with 155 experts in sensitive domains (e.g., physicians, bankers, anthropologists, human and civil rights advocates). This approach, implemented with an Android app, resulted in an annotated dataset of 8,091 adversarial queries in seven languages (e.g., Luganda, Swahili, Chichewa), capturing nuanced and contextual information related to key themes such as misinformation and public interest topics. This dataset in turn can be used to evaluate models for their safety and cultural relevance within the context of these languages.","authors":["Qazi Mamunur Rashid","Erin van Liemt","Tiffany Shih","Amber Ebinama","Karla Barrios Ramos","Madhurima Maji","Aishwarya Verma","Charu Kalia","Jamila Smith-Loud","Joyce Nakatumba-Nabende","Rehema Baguma","Andrew Katumba","Chodrine Mutebi","Jagen Marvin","Eric Peter Wairagala","Mugizi Bruce","Peter Oketta","Lawrence Nderu","Obichi Obiajunwa","Abigail Oppong","Michael Zimba","Data Authors"],"url":"https://arxiv.org/abs/2504.14105"}
{"created":"2025-04-22","title":"Linking forward-pass dynamics in Transformers and real-time human processing","abstract":"Modern AI models are increasingly being used as theoretical tools to study human cognition. One dominant approach is to evaluate whether human-derived measures (such as offline judgments or real-time processing) are predicted by a model's output: that is, the end-product of forward pass(es) through the network. At the same time, recent advances in mechanistic interpretability have begun to reveal the internal processes that give rise to model outputs, raising the question of whether models and humans might arrive at outputs using similar \"processing strategies\". Here, we investigate the link between real-time processing in humans and \"layer-time\" dynamics in Transformer models. Across five studies spanning domains and modalities, we test whether the dynamics of computation in a single forward pass of pre-trained Transformers predict signatures of processing in humans, above and beyond properties of the model's output probability distribution. We consistently find that layer-time dynamics provide additional predictive power on top of output measures. Our results suggest that Transformer processing and human processing may be facilitated or impeded by similar properties of an input stimulus, and this similarity has emerged through general-purpose objectives such as next-token prediction or image recognition. Our work suggests a new way of using AI models to study human cognition: not just as a black box mapping stimuli to responses, but potentially also as explicit processing models.","authors":["Jennifer Hu","Michael A. Lepori","Michael Franke"],"url":"https://arxiv.org/abs/2504.14107"}
{"created":"2025-04-22","title":"Point-Driven Interactive Text and Image Layer Editing Using Diffusion Models","abstract":"We present DanceText, a training-free framework for multilingual text editing in images, designed to support complex geometric transformations and achieve seamless foreground-background integration. While diffusion-based generative models have shown promise in text-guided image synthesis, they often lack controllability and fail to preserve layout consistency under non-trivial manipulations such as rotation, translation, scaling, and warping. To address these limitations, DanceText introduces a layered editing strategy that separates text from the background, allowing geometric transformations to be performed in a modular and controllable manner. A depth-aware module is further proposed to align appearance and perspective between the transformed text and the reconstructed background, enhancing photorealism and spatial consistency. Importantly, DanceText adopts a fully training-free design by integrating pretrained modules, allowing flexible deployment without task-specific fine-tuning. Extensive experiments on the AnyWord-3M benchmark demonstrate that our method achieves superior performance in visual quality, especially under large-scale and complex transformation scenarios.","authors":["Zhenyu Yu","Mohd Yamani Idna Idris","Pei Wang","Yuelong Xia"],"url":"https://arxiv.org/abs/2504.14108"}
{"created":"2025-04-22","title":"Longitudinal Study on Social and Emotional Use of AI Conversational Agent","abstract":"Development in digital technologies has continuously reshaped how individuals seek and receive social and emotional support. While online platforms and communities have long served this need, the increased integration of general-purpose conversational AI into daily lives has introduced new dynamics in how support is provided and experienced. Existing research has highlighted both benefits (e.g., wider access to well-being resources) and potential risks (e.g., over-reliance) of using AI for support seeking. In this five-week, exploratory study, we recruited 149 participants divided into two usage groups: a baseline usage group (BU, n=60) that used the internet and AI as usual, and an active usage group (AU, n=89) encouraged to use one of four commercially available AI tools (Microsoft Copilot, Google Gemini, PI AI, ChatGPT) for social and emotional interactions. Our analysis revealed significant increases in perceived attachment towards AI (32.99 percentage points), perceived AI empathy (25.8 p.p.), and motivation to use AI for entertainment (22.90 p.p.) among the AU group. We also observed that individual differences (e.g., gender identity, prior AI usage) influenced perceptions of AI empathy and attachment. Lastly, the AU group expressed higher comfort in seeking personal help, managing stress, obtaining social support, and talking about health with AI, indicating potential for broader emotional support while highlighting the need for safeguards against problematic usage. Overall, our exploratory findings underscore the importance of developing consumer-facing AI tools that support emotional well-being responsibly, while empowering users to understand the limitations of these tools.","authors":["Mohit Chandra","Javier Hernandez","Gonzalo Ramos","Mahsa Ershadi","Ananya Bhattacharjee","Judith Amores","Ebele Okoli","Ann Paradiso","Shahed Warreth","Jina Suh"],"url":"https://arxiv.org/abs/2504.14112"}
{"created":"2025-04-22","title":"Lightweight Road Environment Segmentation using Vector Quantization","abstract":"Road environment segmentation plays a significant role in autonomous driving. Numerous works based on Fully Convolutional Networks (FCNs) and Transformer architectures have been proposed to leverage local and global contextual learning for efficient and accurate semantic segmentation. In both architectures, the encoder often relies heavily on extracting continuous representations from the image, which limits the ability to represent meaningful discrete information. To address this limitation, we propose segmentation of the autonomous driving environment using vector quantization. Vector quantization offers three primary advantages for road environment segmentation. (1) Each continuous feature from the encoder is mapped to a discrete vector from the codebook, helping the model discover distinct features more easily than with complex continuous features. (2) Since a discrete feature acts as compressed versions of the encoder's continuous features, they also compress noise or outliers, enhancing the image segmentation task. (3) Vector quantization encourages the latent space to form coarse clusters of continuous features, forcing the model to group similar features, making the learned representations more structured for the decoding process. In this work, we combined vector quantization with the lightweight image segmentation model MobileUNETR and used it as a baseline model for comparison to demonstrate its efficiency. Through experiments, we achieved 77.0 % mIoU on Cityscapes, outperforming the baseline by 2.9 % without increasing the model's initial size or complexity.","authors":["Jiyong Kwag","Alper Yilmaz","Charles Toth"],"url":"https://arxiv.org/abs/2504.14113"}
{"created":"2025-04-22","title":"Visualization Tasks for Unlabelled Graphs","abstract":"We investigate tasks that can be accomplished with unlabelled graphs, where nodes do not have persistent or semantically meaningful labels. New techniques to visualize these graphs have been proposed, but more understanding of unlabelled graph tasks is required before they can be adequately evaluated. Some tasks apply to both labelled and unlabelled graphs, but many do not translate between these contexts. We propose a taxonomy of unlabelled graph abstract tasks, organized according to the Scope of the data at play, the Action intended by the user, and the Target data under consideration. We show the descriptive power of this task abstraction by connecting to concrete examples from previous frameworks, and connect these abstractions to real-world problems. To showcase the evaluative power of the taxonomy, we perform a preliminary assessment of 6 visualizations for each task. For each combination of task and visual encoding, we consider the effort required from viewers, the likelihood of task success, and how both factors vary between small-scale and large-scale graphs.","authors":["Matt I. B. Oddo","Ryan Smith","Stephen Kobourov","Tamara Munzner"],"url":"https://arxiv.org/abs/2504.14115"}
{"created":"2025-04-22","title":"Analysis of a finite element method for PDEs in evolving domains with topological changes","abstract":"The paper presents the first rigorous error analysis of an unfitted finite element method for a linear parabolic problem posed on an evolving domain $\\Omega(t)$ that may undergo a topological change, such as, for example, a domain splitting. The domain evolution is assumed to be $C^2$-smooth away from a critical time $t_c$, at which the topology may change instantaneously. To accommodate such topological transitions in the error analysis, we introduce several structural assumptions on the evolution of $\\Omega(t)$ in the vicinity of the critical time. These assumptions allow a specific stability estimate even across singularities. Based on this stability result we derive optimal-order discretization error bounds, provided the continuous solution is sufficiently smooth. We demonstrate the applicability of our assumptions with examples of level-set domains undergoing topological transitions and discuss cases where the analysis fails. The theoretical error estimate is confirmed by the results of a numerical experiment.","authors":["Maxim A. Olshanskii","Arnold Reusken"],"url":"https://arxiv.org/abs/2504.14116"}
{"created":"2025-04-22","title":"PEFT A2Z: Parameter-Efficient Fine-Tuning Survey for Large Language and Vision Models","abstract":"Large models such as Large Language Models (LLMs) and Vision Language Models (VLMs) have transformed artificial intelligence, powering applications in natural language processing, computer vision, and multimodal learning. However, fully fine-tuning these models remains expensive, requiring extensive computational resources, memory, and task-specific data. Parameter-Efficient Fine-Tuning (PEFT) has emerged as a promising solution that allows adapting large models to downstream tasks by updating only a small portion of parameters. This survey presents a comprehensive overview of PEFT techniques, focusing on their motivations, design principles, and effectiveness. We begin by analyzing the resource and accessibility challenges posed by traditional fine-tuning and highlight key issues, such as overfitting, catastrophic forgetting, and parameter inefficiency. We then introduce a structured taxonomy of PEFT methods -- grouped into additive, selective, reparameterized, hybrid, and unified frameworks -- and systematically compare their mechanisms and trade-offs. Beyond taxonomy, we explore the impact of PEFT across diverse domains, including language, vision, and generative modeling, showing how these techniques offer strong performance with lower resource costs. We also discuss important open challenges in scalability, interpretability, and robustness, and suggest future directions such as federated learning, domain adaptation, and theoretical grounding. Our goal is to provide a unified understanding of PEFT and its growing role in enabling practical, efficient, and sustainable use of large models.","authors":["Nusrat Jahan Prottasha","Upama Roy Chowdhury","Shetu Mohanto","Tasfia Nuzhat","Abdullah As Sami","Md Shamol Ali","Md Shohanur Islam Sobuj","Hafijur Raman","Md Kowsher","Ozlem Ozmen Garibay"],"url":"https://arxiv.org/abs/2504.14117"}
{"created":"2025-04-22","title":"CODECRASH: Stress Testing LLM Reasoning under Structural and Semantic Perturbations","abstract":"Large Language Models (LLMs) have recently showcased strong capabilities in code-related tasks, yet their robustness in code comprehension and reasoning remains underexplored. In this paper, we present CodeCrash, a unified benchmark that evaluates LLM robustness under code structural and textual distraction perturbations, applied to two established benchmarks -- CRUXEval and LiveCodeBench -- across both input and output prediction tasks. We evaluate seventeen LLMs using direct and Chain-of-Thought inference to systematically analyze their robustness, identify primary reasons for performance degradation, and highlight failure modes. Our findings reveal the fragility of LLMs under structural noise and the inherent reliance on natural language cues, highlighting critical robustness issues of LLMs in code execution and understanding. Additionally, we examine three Large Reasoning Models (LRMs) and discover the severe vulnerability of self-reflective reasoning mechanisms that lead to reasoning collapse. CodeCrash provides a principled framework for stress-testing LLMs in code understanding, offering actionable directions for future evaluation and benchmarking. The code of CodeCrash and the robustness leaderboard are publicly available at https://donaldlamnl.github.io/CodeCrash/ .","authors":["Man Ho Lam","Chaozheng Wang","Jen-tse Huang","Michael R. Lyu"],"url":"https://arxiv.org/abs/2504.14119"}
{"created":"2025-04-22","title":"Inclusive Education with AI: Supporting Special Needs and Tackling Language Barriers","abstract":"Early childhood classrooms are becoming increasingly diverse, with students spanning a range of linguistic backgrounds and abilities. AI offers innovative tools to help educators create more inclusive learning environments by breaking down language barriers and providing tailored support for children with special needs. This chapter provides a comprehensive review of how AI technologies can facilitate inclusion in early education. It is discussed AI-driven language assistance tools that enable real-time translation and communication in multilingual classrooms, and it is explored assistive technologies powered by AI that personalize learning for students with disabilities. The implications of these technologies for teachers are examined, including shifts in educator roles and workloads. General outcomes observed with AI integration - such as improved student engagement and performance - as well as challenges related to equitable access and the need for ethical implementation are highlighted. Finally, practical recommendations for educators, policymakers, and developers are offered to collaboratively harness AI in a responsible manner, ensuring that its benefits reach all learners.","authors":["Ricardo Fitas"],"url":"https://arxiv.org/abs/2504.14120"}
{"created":"2025-04-22","title":"Detecting Zero-Day Web Attacks with an Ensemble of LSTM, GRU, and Stacked Autoencoders","abstract":"The rapid growth in web-based services has significantly increased security risks related to user information, as web-based attacks become increasingly sophisticated and prevalent. Traditional security methods frequently struggle to detect previously unknown (zero-day) web attacks, putting sensitive user data at significant risk. Additionally, reducing human intervention in web security tasks can minimize errors and enhance reliability. This paper introduces an intelligent system designed to detect zero-day web attacks using a novel one-class ensemble method consisting of three distinct autoencoder architectures: LSTM autoencoder, GRU autoencoder, and stacked autoencoder. Our approach employs a novel tokenization strategy to convert normal web requests into structured numeric sequences, enabling the ensemble model to effectively identify anomalous activities by uniquely concatenating and compressing the latent representations from each autoencoder. The proposed method efficiently detects unknown web attacks while effectively addressing common limitations of previous methods, such as high memory consumption and excessive false positive rates. Extensive experimental evaluations demonstrate the superiority of our proposed ensemble, achieving remarkable detection metrics: 97.58% accuracy, 97.52% recall, 99.76% specificity, and 99.99% precision, with an exceptionally low false positive rate of 0.2%. These results underscore our method's significant potential in enhancing real-world web security through accurate and reliable detection of web-based attacks.","authors":["Vahid Babaey","Hamid Reza Faragardi"],"url":"https://arxiv.org/abs/2504.14122"}
{"created":"2025-04-22","title":"Bayesian Principles Improve Prompt Learning In Vision-Language Models","abstract":"Prompt learning is a popular fine-tuning method for vision-language models due to its efficiency. It requires a small number of additional learnable parameters while significantly enhancing performance on target tasks. However, most existing methods suffer from overfitting to fine-tuning data, yielding poor generalizability. To address this, we propose a new training objective function based on a Bayesian learning principle to balance adaptability and generalizability. We derive a prior over the logits, where the mean function is parameterized by the pre-trained model, while the posterior corresponds to the fine-tuned model. This objective establishes a balance by allowing the fine-tuned model to adapt to downstream tasks while remaining close to the pre-trained model.","authors":["Mingyu Kim","Jongwoo Ko","Mijung Park"],"url":"https://arxiv.org/abs/2504.14123"}
{"created":"2025-04-22","title":"Progress on Self Identifying Codes","abstract":"The concept of an identifying code for a graph was introduced by Karpovsky, Chakrabarty, and Levitin in 1998 as the problem of covering the vertices of a graph such that we can uniquely identify any vertex in the graph by examining the vertices that cover it. An application of an identifying code would be to detect a faulty processor in a multiprocessor system. In 2020, a variation of identify code called \"self-identifying code\" was introduced by Junnila and Laihonen, which simplifies the task of locating the malfunctioning processor. In this paper, we continue to explore self-identifying codes. In particular, we prove the problem of determining the minimum cardinality of a self-identifying code for an arbitrary graph is NP-complete and we investigate minimum-sized self-identifying code in several classes of graphs, including cubic graphs and infinite grids.","authors":["Devin Jean","Suk Seo"],"url":"https://arxiv.org/abs/2504.14124"}
{"created":"2025-04-22","title":"Exploring Language Patterns of Prompts in Text-to-Image Generation and Their Impact on Visual Diversity","abstract":"Following the initial excitement, Text-to-Image (TTI) models are now being examined more critically. While much of the discourse has focused on biases and stereotypes embedded in large-scale training datasets, the sociotechnical dynamics of user interactions with these models remain underexplored. This study examines the linguistic and semantic choices users make when crafting prompts and how these choices influence the diversity of generated outputs. Analyzing over six million prompts from the Civiverse dataset on the CivitAI platform across seven months, we categorize users into three groups based on their levels of linguistic experimentation: consistent repeaters, occasional repeaters, and non-repeaters. Our findings reveal that as user participation grows over time, prompt language becomes increasingly homogenized through the adoption of popular community tags and descriptors, with repeated prompts comprising 40-50% of submissions. At the same time, semantic similarity and topic preferences remain relatively stable, emphasizing common subjects and surface aesthetics. Using Vendi scores to quantify visual diversity, we demonstrate a clear correlation between lexical similarity in prompts and the visual similarity of generated images, showing that linguistic repetition reinforces less diverse representations. These findings highlight the significant role of user-driven factors in shaping AI-generated imagery, beyond inherent model biases, and underscore the need for tools and practices that encourage greater linguistic and thematic experimentation within TTI systems to foster more inclusive and diverse AI-generated content.","authors":["Maria-Teresa De Rosa Palmini","Eva Cetinic"],"url":"https://arxiv.org/abs/2504.14125"}
{"created":"2025-04-22","title":"Large Language Model Enhanced Particle Swarm Optimization for Hyperparameter Tuning for Deep Learning Models","abstract":"Determining the ideal architecture for deep learning models, such as the number of layers and neurons, is a difficult and resource-intensive process that frequently relies on human tuning or computationally costly optimization approaches. While Particle Swarm Optimization (PSO) and Large Language Models (LLMs) have been individually applied in optimization and deep learning, their combined use for enhancing convergence in numerical optimization tasks remains underexplored. Our work addresses this gap by integrating LLMs into PSO to reduce model evaluations and improve convergence for deep learning hyperparameter tuning. The proposed LLM-enhanced PSO method addresses the difficulties of efficiency and convergence by using LLMs (particularly ChatGPT-3.5 and Llama3) to improve PSO performance, allowing for faster achievement of target objectives. Our method speeds up search space exploration by substituting underperforming particle placements with best suggestions offered by LLMs. Comprehensive experiments across three scenarios -- (1) optimizing the Rastrigin function, (2) using Long Short-Term Memory (LSTM) networks for time series regression, and (3) using Convolutional Neural Networks (CNNs) for material classification -- show that the method significantly improves convergence rates and lowers computational costs. Depending on the application, computational complexity is lowered by 20% to 60% compared to traditional PSO methods. Llama3 achieved a 20% to 40% reduction in model calls for regression tasks, whereas ChatGPT-3.5 reduced model calls by 60% for both regression and classification tasks, all while preserving accuracy and error rates. This groundbreaking methodology offers a very efficient and effective solution for optimizing deep learning models, leading to substantial computational performance improvements across a wide range of applications.","authors":["Saad Hameed","Basheer Qolomany","Samir Brahim Belhaouari","Mohamed Abdallah","Junaid Qadir","Ala Al-Fuqaha"],"url":"https://arxiv.org/abs/2504.14126"}
{"created":"2025-04-22","title":"TALES: Text Adventure Learning Environment Suite","abstract":"Reasoning is an essential skill to enable Large Language Models (LLMs) to interact with the world. As tasks become more complex, they demand increasingly sophisticated and diverse reasoning capabilities for sequential decision-making, requiring structured reasoning over the context history to determine the next best action. We introduce TALES, a diverse collection of synthetic and human-written text-adventure games designed to challenge and evaluate diverse reasoning capabilities. We present results over a range of LLMs, open- and closed-weights, performing a qualitative analysis on the top performing models. Despite an impressive showing on synthetic games, even the top LLM-driven agents fail to achieve 15% on games designed for human enjoyment. Code and visualization of the experiments can be found at https://microsoft.github.io/tales.","authors":["Christopher Zhang Cui","Xingdi Yuan","Zhang Xiao","Prithviraj Ammanabrolu","Marc-Alexandre C\\^ot\\'e"],"url":"https://arxiv.org/abs/2504.14128"}
{"created":"2025-04-22","title":"BMRL: Bi-Modal Guided Multi-Perspective Representation Learning for Zero-Shot Deepfake Attribution","abstract":"The challenge of tracing the source attribution of forged faces has gained significant attention due to the rapid advancement of generative models. However, existing deepfake attribution (DFA) works primarily focus on the interaction among various domains in vision modality, and other modalities such as texts and face parsing are not fully explored. Besides, they tend to fail to assess the generalization performance of deepfake attributors to unseen generators in a fine-grained manner. In this paper, we propose a novel bi-modal guided multi-perspective representation learning (BMRL) framework for zero-shot deepfake attribution (ZS-DFA), which facilitates effective traceability to unseen generators. Specifically, we design a multi-perspective visual encoder (MPVE) to explore general deepfake attribution visual characteristics across three views (i.e., image, noise, and edge). We devise a novel parsing encoder to focus on global face attribute embeddings, enabling parsing-guided DFA representation learning via vision-parsing matching. A language encoder is proposed to capture fine-grained language embeddings, facilitating language-guided general visual forgery representation learning through vision-language alignment. Additionally, we present a novel deepfake attribution contrastive center (DFACC) loss, to pull relevant generators closer and push irrelevant ones away, which can be introduced into DFA models to enhance traceability. Experimental results demonstrate that our method outperforms the state-of-the-art on the ZS-DFA task through various protocols evaluation.","authors":["Yaning Zhang","Jiahe Zhang","Chunjie Ma","Weili Guan","Tian Gan","Zan Gao"],"url":"https://arxiv.org/abs/2504.14129"}
{"created":"2025-04-22","title":"Personalized News Recommendation with Multi-granularity Candidate-aware User Modeling","abstract":"Matching candidate news with user interests is crucial for personalized news recommendations. Most existing methods can represent a user's reading interests through a single profile based on clicked news, which may not fully capture the diversity of user interests. Although some approaches incorporate candidate news or topic information, they remain insufficient because they neglect the multi-granularity relatedness between candidate news and user interests. To address this, this study proposed a multi-granularity candidate-aware user modeling framework that integrated user interest features across various levels of granularity. It consisted of two main components: candidate news encoding and user modeling. A news textual information extractor and a knowledge-enhanced entity information extractor can capture candidate news features, and word-level, entity-level, and news-level candidate-aware mechanisms can provide a comprehensive representation of user interests. Extensive experiments on a real-world dataset demonstrated that the proposed model could significantly outperform baseline models.","authors":["Qiang Li","Xinze Lin","Shenghao Lv","Faliang Huang","Xiangju Li"],"url":"https://arxiv.org/abs/2504.14130"}
{"created":"2025-04-22","title":"Transforming hyperspectral images into chemical maps: A new deep learning based approach to hyperspectral image processing","abstract":"Current approaches to chemical map generation from hyperspectral images are based on models such as partial least squares (PLS) regression, generating pixel-wise predictions that do not consider spatial context and suffer from a high degree of noise. This study proposes an end-to-end deep learning approach using a modified version of U-Net and a custom loss function to directly obtain chemical maps from hyperspectral images, skipping all intermediate steps required for traditional pixel-wise analysis. We compare the U-Net with the traditional PLS regression on a real dataset of pork belly samples with associated mean fat reference values. The U-Net obtains a test set root mean squared error of between 9% and 13% lower than that of PLS regression on the task of mean fat prediction. At the same time, U-Net generates fine detail chemical maps where 99.91% of the variance is spatially correlated. Conversely, only 2.53% of the variance in the PLS-generated chemical maps is spatially correlated, indicating that each pixel-wise prediction is largely independent of neighboring pixels. Additionally, while the PLS-generated chemical maps contain predictions far beyond the physically possible range of 0-100%, U-Net learns to stay inside this range. Thus, the findings of this study indicate that U-Net is superior to PLS for chemical map generation.","authors":["Ole-Christian Galbo Engstr{\\o}m","Michela Albano-Gaglio","Erik Schou Dreier","Yamine Bouzembrak","Maria Font-i-Furnols","Puneet Mishra","Kim Steenstrup Pedersen"],"url":"https://arxiv.org/abs/2504.14131"}
{"created":"2025-04-22","title":"HFBRI-MAE: Handcrafted Feature Based Rotation-Invariant Masked Autoencoder for 3D Point Cloud Analysis","abstract":"Self-supervised learning (SSL) has demonstrated remarkable success in 3D point cloud analysis, particularly through masked autoencoders (MAEs). However, existing MAE-based methods lack rotation invariance, leading to significant performance degradation when processing arbitrarily rotated point clouds in real-world scenarios. To address this limitation, we introduce Handcrafted Feature-Based Rotation-Invariant Masked Autoencoder (HFBRI-MAE), a novel framework that refines the MAE design with rotation-invariant handcrafted features to ensure stable feature learning across different orientations. By leveraging both rotation-invariant local and global features for token embedding and position embedding, HFBRI-MAE effectively eliminates rotational dependencies while preserving rich geometric structures. Additionally, we redefine the reconstruction target to a canonically aligned version of the input, mitigating rotational ambiguities. Extensive experiments on ModelNet40, ScanObjectNN, and ShapeNetPart demonstrate that HFBRI-MAE consistently outperforms existing methods in object classification, segmentation, and few-shot learning, highlighting its robustness and strong generalization ability in real-world 3D applications.","authors":["Xuanhua Yin","Dingxin Zhang","Jianhui Yu","Weidong Cai"],"url":"https://arxiv.org/abs/2504.14132"}
{"created":"2025-04-22","title":"Enhanced UAV Navigation Systems through Sensor Fusion with Trident Quaternions","abstract":"This paper presents an integrated navigation algorithm based on trident quaternions, an extension of dual quaternions. The proposed methodology provides an efficient approach for achieving precise and robust navigation by leveraging the advantages of trident quaternions. The performance of the navigation system was validated through experimental tests using a multi-rotor UAV equipped with two navigation computers: one executing the proposed algorithm and the other running a commercial autopilot, which was used as a reference.","authors":["Sebastian Incicco","Juan Ignacio Giribet","Leonardo Colombo"],"url":"https://arxiv.org/abs/2504.14133"}
{"created":"2025-04-22","title":"Unreal Robotics Lab: A High-Fidelity Robotics Simulator with Advanced Physics and Rendering","abstract":"High-fidelity simulation is essential for robotics research, enabling safe and efficient testing of perception, control, and navigation algorithms. However, achieving both photorealistic rendering and accurate physics modeling remains a challenge. This paper presents a novel simulation framework--the Unreal Robotics Lab (URL) that integrates the Unreal Engine's advanced rendering capabilities with MuJoCo's high-precision physics simulation. Our approach enables realistic robotic perception while maintaining accurate physical interactions, facilitating benchmarking and dataset generation for vision-based robotics applications. The system supports complex environmental effects, such as smoke, fire, and water dynamics, which are critical for evaluating robotic performance under adverse conditions. We benchmark visual navigation and SLAM methods within our framework, demonstrating its utility for testing real-world robustness in controlled yet diverse scenarios. By bridging the gap between physics accuracy and photorealistic rendering, our framework provides a powerful tool for advancing robotics research and sim-to-real transfer.","authors":["Jonathan Embley-Riches","Jianwei Liu","Simon Julier","Dimitrios Kanoulas"],"url":"https://arxiv.org/abs/2504.14135"}
{"created":"2025-04-22","title":"Rethinking Target Label Conditioning in Adversarial Attacks: A 2D Tensor-Guided Generative Approach","abstract":"Compared to single-target adversarial attacks, multi-target attacks have garnered significant attention due to their ability to generate adversarial images for multiple target classes simultaneously. Existing generative approaches for multi-target attacks mainly analyze the effect of the use of target labels on noise generation from a theoretical perspective, lacking practical validation and comprehensive summarization. To address this gap, we first identify and validate that the semantic feature quality and quantity are critical factors affecting the transferability of targeted attacks: 1) Feature quality refers to the structural and detailed completeness of the implanted target features, as deficiencies may result in the loss of key discriminative information; 2) Feature quantity refers to the spatial sufficiency of the implanted target features, as inadequacy limits the victim model's attention to this feature. Based on these findings, we propose the 2D Tensor-Guided Adversarial Fusion (2D-TGAF) framework, which leverages the powerful generative capabilities of diffusion models to encode target labels into two-dimensional semantic tensors for guiding adversarial noise generation. Additionally, we design a novel masking strategy tailored for the training process, ensuring that parts of the generated noise retain complete semantic information about the target class. Extensive experiments on the standard ImageNet dataset demonstrate that 2D-TGAF consistently surpasses state-of-the-art methods in attack success rates, both on normally trained models and across various defense mechanisms.","authors":["Hangyu Liu","Bo Peng","Pengxiang Ding","Donglin Wang"],"url":"https://arxiv.org/abs/2504.14137"}
{"created":"2025-04-22","title":"Segment Any Crack: Deep Semantic Segmentation Adaptation for Crack Detection","abstract":"Image-based crack detection algorithms are increasingly in demand in infrastructure monitoring, as early detection of cracks is of paramount importance for timely maintenance planning. While deep learning has significantly advanced crack detection algorithms, existing models often require extensive labeled datasets and high computational costs for fine-tuning, limiting their adaptability across diverse conditions. This study introduces an efficient selective fine-tuning strategy, focusing on tuning normalization components, to enhance the adaptability of segmentation models for crack detection. The proposed method is applied to the Segment Anything Model (SAM) and five well-established segmentation models. Experimental results demonstrate that selective fine-tuning of only normalization parameters outperforms full fine-tuning and other common fine-tuning techniques in both performance and computational efficiency, while improving generalization. The proposed approach yields a SAM-based model, Segment Any Crack (SAC), achieving a 61.22\\% F1-score and 44.13\\% IoU on the OmniCrack30k benchmark dataset, along with the highest performance across three zero-shot datasets and the lowest standard deviation. The results highlight the effectiveness of the adaptation approach in improving segmentation accuracy while significantly reducing computational overhead.","authors":["Ghodsiyeh Rostami","Po-Han Chen","Mahdi S. Hosseini"],"url":"https://arxiv.org/abs/2504.14138"}
{"created":"2025-04-22","title":"ThyroidEffi 1.0: A Cost-Effective System for High-Performance Multi-Class Thyroid Carcinoma Classification","abstract":"Background: Automated classification of thyroid fine needle aspiration biopsy (FNAB) images faces challenges in limited data, inter-observer variability, and computational cost. Efficient, interpretable models are crucial for clinical support. Objective: To develop and externally validate a deep learning system for the multi-class classification of thyroid FNAB images into three key categories that directly guide post-biopsy treatment decisions in Vietnam: benign (B2), suspicious for malignancy (B5), and malignant (B6), while achieving high diagnostic accuracy with low computational overhead. Methods: Our framework features: (1) YOLOv10-based cell cluster detection for informative sub-region extraction and noise reduction; (2) a curriculum learning-inspired protocol sequencing localized crops to full images for multi-scale feature capture; (3) adaptive lightweight EfficientNetB0 (4 millions parameters) selection balancing performance and efficiency; and (4) a Transformer-inspired module for multi-scale, multi-region analysis. External validation used 1,015 independent FNAB images. Results: ThyroidEffi Basic achieved a macro F1 of 89.19\\% and AUCs of 0.98 (B2), 0.95 (B5), and 0.96 (B6) on the internal test set. External validation yielded AUCs of 0.9495 (B2), 0.7436 (B5), and 0.8396 (B6). ThyroidEffi Premium improved macro F1 to 89.77\\%. Grad-CAM highlighted key diagnostic regions, confirming interpretability. The system processed 1000 cases in 30 seconds, demonstrating feasibility on widely accessible hardware like a 12-core CPU. Conclusions: This work demonstrates that high-accuracy, interpretable thyroid FNAB image classification is achievable with minimal computational demands.","authors":["Hai Pham-Ngoc","De Nguyen-Van","Dung Vu-Tien","Phuong Le-Hong"],"url":"https://arxiv.org/abs/2504.14139"}
{"created":"2025-04-22","title":"Predicting Stress and Damage in Carbon Fiber-Reinforced Composites Deformation Process using Composite U-Net Surrogate Model","abstract":"Carbon fiber-reinforced composites (CFRC) are pivotal in advanced engineering applications due to their exceptional mechanical properties. A deep understanding of CFRC behavior under mechanical loading is essential for optimizing performance in demanding applications such as aerospace structures. While traditional Finite Element Method (FEM) simulations, including advanced techniques like Interface-enriched Generalized FEM (IGFEM), offer valuable insights, they can struggle with computational efficiency. Existing data-driven surrogate models partially address these challenges by predicting propagated damage or stress-strain behavior but fail to comprehensively capture the evolution of stress and damage throughout the entire deformation history, including crack initiation and propagation. This study proposes a novel auto-regressive composite U-Net deep learning model to simultaneously predict stress and damage fields during CFRC deformation. By leveraging the U-Net architecture's ability to capture spatial features and integrate macro- and micro-scale phenomena, the proposed model overcomes key limitations of prior approaches. The model achieves high accuracy in predicting evolution of stress and damage distribution within the microstructure of a CFRC under unidirectional strain, offering a speed-up of over 60 times compared to IGFEM.","authors":["Zeping Chen","Marwa Yacouti","Maryam Shakiba","Jian-Xun Wang","Tengfei Luo","Vikas Varshney"],"url":"https://arxiv.org/abs/2504.14143"}
{"created":"2025-04-22","title":"PipeWeaver: Addressing Data Dynamicity in Large Multimodal Model Training with Dynamic Interleaved Pipeline","abstract":"Large multimodal models (LMMs) have demonstrated excellent capabilities in both understanding and generation tasks with various modalities. While these models can accept flexible combinations of input data, their training efficiency suffers from two major issues: pipeline stage imbalance caused by heterogeneous model architectures, and training data dynamicity stemming from the diversity of multimodal data.","authors":["Zhenliang Xue","Hanpeng Hu","Xing Chen","Yimin Jiang","Yixin Song","Zeyu Mi","Yibo Zhu","Daxin Jiang","Yubin Xia","Haibo Chen"],"url":"https://arxiv.org/abs/2504.14145"}
{"created":"2025-04-22","title":"HF4Rec: Human-Like Feedback-Driven Optimization Framework for Explainable Recommendation","abstract":"Recent advancements in explainable recommendation have greatly bolstered user experience by elucidating the decision-making rationale. However, the existing methods actually fail to provide effective feedback signals for potentially better or worse generated explanations due to their reliance on traditional supervised learning paradigms in sparse interaction data. To address these issues, we propose a novel human-like feedback-driven optimization framework. This framework employs a dynamic interactive optimization mechanism for achieving human-centered explainable requirements without incurring high labor costs. Specifically, we propose to utilize large language models (LLMs) as human simulators to predict human-like feedback for guiding the learning process. To enable the LLMs to deeply understand the task essence and meet user's diverse personalized requirements, we introduce a human-induced customized reward scoring method, which helps stimulate the language understanding and logical reasoning capabilities of LLMs. Furthermore, considering the potential conflicts between different perspectives of explanation quality, we introduce a principled Pareto optimization that transforms the multi-perspective quality enhancement task into a multi-objective optimization problem for improving explanation performance. At last, to achieve efficient model training, we design an off-policy optimization pipeline. By incorporating a replay buffer and addressing the data distribution biases, we can effectively improve data utilization and enhance model generality. Extensive experiments on four datasets demonstrate the superiority of our approach.","authors":["Jiakai Tang","Jingsen Zhang","Zihang Tian","Xueyang Feng","Lei Wang","Xu Chen"],"url":"https://arxiv.org/abs/2504.14147"}
{"created":"2025-04-22","title":"Walk the Talk? Measuring the Faithfulness of Large Language Model Explanations","abstract":"Large language models (LLMs) are capable of generating plausible explanations of how they arrived at an answer to a question. However, these explanations can misrepresent the model's \"reasoning\" process, i.e., they can be unfaithful. This, in turn, can lead to over-trust and misuse. We introduce a new approach for measuring the faithfulness of LLM explanations. First, we provide a rigorous definition of faithfulness. Since LLM explanations mimic human explanations, they often reference high-level concepts in the input question that purportedly influenced the model. We define faithfulness in terms of the difference between the set of concepts that LLM explanations imply are influential and the set that truly are. Second, we present a novel method for estimating faithfulness that is based on: (1) using an auxiliary LLM to modify the values of concepts within model inputs to create realistic counterfactuals, and (2) using a Bayesian hierarchical model to quantify the causal effects of concepts at both the example- and dataset-level. Our experiments show that our method can be used to quantify and discover interpretable patterns of unfaithfulness. On a social bias task, we uncover cases where LLM explanations hide the influence of social bias. On a medical question answering task, we uncover cases where LLM explanations provide misleading claims about which pieces of evidence influenced the model's decisions.","authors":["Katie Matton","Robert Osazuwa Ness","John Guttag","Emre K{\\i}c{\\i}man"],"url":"https://arxiv.org/abs/2504.14150"}
{"created":"2025-04-22","title":"Locate 3D: Real-World Object Localization via Self-Supervised Learning in 3D","abstract":"We present LOCATE 3D, a model for localizing objects in 3D scenes from referring expressions like \"the small coffee table between the sofa and the lamp.\" LOCATE 3D sets a new state-of-the-art on standard referential grounding benchmarks and showcases robust generalization capabilities. Notably, LOCATE 3D operates directly on sensor observation streams (posed RGB-D frames), enabling real-world deployment on robots and AR devices. Key to our approach is 3D-JEPA, a novel self-supervised learning (SSL) algorithm applicable to sensor point clouds. It takes as input a 3D pointcloud featurized using 2D foundation models (CLIP, DINO). Subsequently, masked prediction in latent space is employed as a pretext task to aid the self-supervised learning of contextualized pointcloud features. Once trained, the 3D-JEPA encoder is finetuned alongside a language-conditioned decoder to jointly predict 3D masks and bounding boxes. Additionally, we introduce LOCATE 3D DATASET, a new dataset for 3D referential grounding, spanning multiple capture setups with over 130K annotations. This enables a systematic study of generalization capabilities as well as a stronger model.","authors":["Sergio Arnaud","Paul McVay","Ada Martin","Arjun Majumdar","Krishna Murthy Jatavallabhula","Phillip Thomas","Ruslan Partsey","Daniel Dugas","Abha Gejji","Alexander Sax","Vincent-Pierre Berges","Mikael Henaff","Ayush Jain","Ang Cao","Ishita Prasad","Mrinal Kalakrishnan","Michael Rabbat","Nicolas Ballas","Mido Assran","Oleksandr Maksymets","Aravind Rajeswaran","Franziska Meier"],"url":"https://arxiv.org/abs/2504.14151"}
{"created":"2025-04-22","title":"FGMP: Fine-Grained Mixed-Precision Weight and Activation Quantization for Hardware-Accelerated LLM Inference","abstract":"Quantization is a powerful tool to improve large language model (LLM) inference efficiency by utilizing more energy-efficient low-precision datapaths and reducing memory footprint. However, accurately quantizing LLM weights and activations to low precision is challenging without degrading model accuracy. We propose fine-grained mixed precision (FGMP) quantization, a post-training mixed-precision quantization hardware-software co-design methodology that maintains accuracy while quantizing the majority of weights and activations to reduced precision. Our work makes the following contributions: 1) We develop a policy that uses the perturbation in each value, weighted by the Fisher information, to select which weight and activation blocks to keep in higher precision. This approach preserves accuracy by identifying which weight and activation blocks need to be retained in higher precision to minimize the perturbation in the model loss. 2) We also propose a sensitivity-weighted clipping approach for fine-grained quantization which helps retain accuracy for blocks that are quantized to low precision. 3) We then propose hardware augmentations to leverage the efficiency benefits of FGMP quantization. Our hardware implementation encompasses i) datapath support for FGMP at block granularity, and ii) a mixed-precision activation quantization unit to assign activation blocks to high or low precision on the fly with minimal runtime and energy overhead. Our design, prototyped using NVFP4 (an FP4 format with microscaling) as the low-precision datatype and FP8 as the high-precision datatype, facilitates efficient FGMP quantization, attaining <1% perplexity degradation on Wikitext-103 for the Llama-2-7B model relative to an all-FP8 baseline design while consuming 14% less energy during inference and requiring 30% less weight memory.","authors":["Coleman Hooper","Charbel Sakr","Ben Keller","Rangharajan Venkatesan","Kurt Keutzer","Sophia Shao","Brucek Khailany"],"url":"https://arxiv.org/abs/2504.14152"}
{"created":"2025-04-22","title":"SConU: Selective Conformal Uncertainty in Large Language Models","abstract":"As large language models are increasingly utilized in real-world applications, guarantees of task-specific metrics are essential for their reliable deployment. Previous studies have introduced various criteria of conformal uncertainty grounded in split conformal prediction, which offer user-specified correctness coverage. However, existing frameworks often fail to identify uncertainty data outliers that violate the exchangeability assumption, leading to unbounded miscoverage rates and unactionable prediction sets. In this paper, we propose a novel approach termed Selective Conformal Uncertainty (SConU), which, for the first time, implements significance tests, by developing two conformal p-values that are instrumental in determining whether a given sample deviates from the uncertainty distribution of the calibration set at a specific manageable risk level. Our approach not only facilitates rigorous management of miscoverage rates across both single-domain and interdisciplinary contexts, but also enhances the efficiency of predictions. Furthermore, we comprehensively analyze the components of the conformal procedures, aiming to approximate conditional coverage, particularly in high-stakes question-answering tasks.","authors":["Zhiyuan Wang","Qingni Wang","Yue Zhang","Tianlong Chen","Xiaofeng Zhu","Xiaoshuang Shi","Kaidi Xu"],"url":"https://arxiv.org/abs/2504.14154"}
{"created":"2025-04-22","title":"Refinement orders for quantum programs","abstract":"Refinement is an influential technique used in the verification and development of computer programs. It provides a systematic and rigorous approach to software development through stepwise refinement, where a high-level abstract specification is progressively transformed into an implementation that meets the desired requirements. Central to this technique is the notion of a refinement order, which ensures that each refinement step preserves program correctness. Different orders can be defined with respect to partial and total correctness, as well as for deterministic and nondeterministic programs. In the realm of quantum programs, the theory becomes even more intricate due to the existence of various quantum state predicates, leading to different notions of specifications. This paper thoroughly explores different refinement orders for quantum programs and examines the relationships between them.","authors":["Yuan Feng","Li Zhou"],"url":"https://arxiv.org/abs/2504.14158"}
{"created":"2025-04-22","title":"ROFBS$\\alpha$: Real Time Backup System Decoupled from ML Based Ransomware Detection","abstract":"This study introduces ROFBS$\\alpha$, a new defense architecture that addresses delays in detection in ransomware detectors based on machine learning. It builds on our earlier Real Time Open File Backup System, ROFBS, by adopting an asynchronous design that separates backup operations from detection tasks. By using eBPF to monitor file open events and running the backup process independently, the system avoids performance limitations when detection and protection contend for resources. We evaluated ROFBS$\\alpha$ against three ransomware strains, AvosLocker, Conti, and IceFire. The evaluation measured the number of files encrypted, the number of files successfully backed up, the ratio of backups to encrypted files, and the overall detection latency. The results show that ROFBS$\\alpha$ achieves high backup success rates and faster detection while adding minimal extra load to the system. However, defending against ransomware that encrypts files extremely quickly remains an open challenge that will require further enhancements.","authors":["Kosuke Higuchi","Ryotaro Kobayashi"],"url":"https://arxiv.org/abs/2504.14162"}
{"created":"2025-04-22","title":"Decentralized Signaling Mechanisms","abstract":"We study a system composed of multiple distinct service locations that aims to convince customers to join the system by providing information to customers. We cast the system's information design problem in the framework of Bayesian persuasion and describe centralized and decentralized signaling. We provide efficient methods for computing the system's optimal centralized and decentralized signaling mechanisms and derive a performance guarantee for decentralized signaling when the locations' states are independent. The guarantee states that the probability that a customer joins under optimal decentralized signaling is bounded below by the product of a strictly positive constant and the probability that a customer joins under optimal centralized signaling. The constant depends only on the number of service locations. We provide an example that shows that the constant cannot be improved. We consider an extension to more-general objectives for the system and establish that the same guarantee continues to hold. We also extend our analysis to systems where the locations' states are correlated, and again derive a performance guarantee for decentralized signaling in that setting. For the correlated setting, we prove that the guarantee's asymptotic dependence upon the number of locations cannot be substantially improved. A comparison of our guarantees for independent locations and for correlated locations reveals the influence of dependence on the performance of decentralized signaling.","authors":["Niloufar Mirzavand Boroujeni","Krishnamurthy Iyer","William L. Cooper"],"url":"https://arxiv.org/abs/2504.14163"}
{"created":"2025-04-22","title":"Self-Correction Makes LLMs Better Parsers","abstract":"Large language models (LLMs) have achieved remarkable success across various natural language processing (NLP) tasks. However, recent studies suggest that they still face challenges in performing fundamental NLP tasks essential for deep language understanding, particularly syntactic parsing. In this paper, we conduct an in-depth analysis of LLM parsing capabilities, delving into the specific shortcomings of their parsing results. We find that LLMs may stem from limitations to fully leverage grammar rules in existing treebanks, which restricts their capability to generate valid syntactic structures. To help LLMs acquire knowledge without additional training, we propose a self-correction method that leverages grammar rules from existing treebanks to guide LLMs in correcting previous errors. Specifically, we automatically detect potential errors and dynamically search for relevant rules, offering hints and examples to guide LLMs in making corrections themselves. Experimental results on three datasets with various LLMs, demonstrate that our method significantly improves performance in both in-domain and cross-domain settings on the English and Chinese datasets.","authors":["Ziyan Zhang","Yang Hou","Chen Gong","Zhenghua Li"],"url":"https://arxiv.org/abs/2504.14165"}
{"created":"2025-04-22","title":"Collision Induced Binding and Transport of Shape Changing Robot Pairs","abstract":"We report in experiment and simulation the spontaneous formation of dynamically bound pairs of shape changing robots undergoing locally repulsive collisions. These physical `gliders' robustly emerge from an ensemble of individually undulating three-link two-motor robots and can remain bound for hundreds of undulations and travel for multiple robot dimensions. Gliders occur in two distinct binding symmetries and form over a wide range of angular oscillation extent. This parameter sets the maximal concavity which influences formation probability and translation characteristics. Analysis of dynamics in simulation reveals the mechanism of effective dynamical attraction -- a result of the emergent interplay of appropriately oriented and timed repulsive interactions. Tactile sensing stabilizes the short-lived conformation via concavity modulation.","authors":["Akash Vardhan","Ram Avinery","Hosain Bagheri","Velin Kojohourav","Shengkai Li","Hridesh Kedia","Tianyu Wang","Daniel Soto","Kurt Wiesenfeld","Daniel I. Goldman"],"url":"https://arxiv.org/abs/2504.14170"}
{"created":"2025-04-22","title":"Adaptation Method for Misinformation Identification","abstract":"Multimodal fake news detection plays a crucial role in combating online misinformation. Unfortunately, effective detection methods rely on annotated labels and encounter significant performance degradation when domain shifts exist between training (source) and test (target) data. To address the problems, we propose ADOSE, an Active Domain Adaptation (ADA) framework for multimodal fake news detection which actively annotates a small subset of target samples to improve detection performance. To identify various deceptive patterns in cross-domain settings, we design multiple expert classifiers to learn dependencies across different modalities. These classifiers specifically target the distinct deception patterns exhibited in fake news, where two unimodal classifiers capture knowledge errors within individual modalities while one cross-modal classifier identifies semantic inconsistencies between text and images. To reduce annotation costs from the target domain, we propose a least-disagree uncertainty selector with a diversity calculator for selecting the most informative samples. The selector leverages prediction disagreement before and after perturbations by multiple classifiers as an indicator of uncertain samples, whose deceptive patterns deviate most from source domains. It further incorporates diversity scores derived from multi-view features to ensure the chosen samples achieve maximal coverage of target domain features. The extensive experiments on multiple datasets show that ADOSE outperforms existing ADA methods by 2.72\\% $\\sim$ 14.02\\%, indicating the superiority of our model.","authors":["Yangping Chen","Weijie Shi","Mengze Li","Yue Cui","Hao Chen","Jia Zhu","Jiajie Xu"],"url":"https://arxiv.org/abs/2504.14171"}
{"created":"2025-04-22","title":"Tracking mob Dynamics in online social networks Using epidemiology model based on Mobility Equations","abstract":"Nowadays, social media is the main tool in our new lives. The outbreak news and all related obtained from social media, and mob events affect the of spread these news fast. Recently, epidemiological models to study disease spread and analyze the behavior of mob groups by dealing with \"contagions\" that propagate through user networks. In this research, we introduced a mathematical model to analyze social behavior related to COVID-19 spread by examining Twitter activity from April 2020 to June 2020. The main feature of this model is the integration of mobility dynamics that be derived from the above real data, to adjust the rate of outbreak based on the response of social interactions. Consider mobility as a parameter of time-varying, and fluctuations in the rate of contact that is driven by factors like personal behavior or external affecting such as \"lockdown\" and \"quarantine\" etc., to track public sentiment and engagement trends during the pandemic. The threshold number is derived, and the existence of bifurcation and the stability of the steady states are established. Numerical simulations and sensitivity analysis of relevant parameters are also carried out.","authors":["Jumana H. S. Alkhalissi","Ahmed Al-Taweel"],"url":"https://arxiv.org/abs/2504.14172"}
{"created":"2025-04-22","title":"A Physics-guided Multimodal Transformer Path to Weather and Climate Sciences","abstract":"With the rapid development of machine learning in recent years, many problems in meteorology can now be addressed using AI models. In particular, data-driven algorithms have significantly improved accuracy compared to traditional methods. Meteorological data is often transformed into 2D images or 3D videos, which are then fed into AI models for learning. Additionally, these models often incorporate physical signals, such as temperature, pressure, and wind speed, to further enhance accuracy and interpretability. In this paper, we review several representative AI + Weather/Climate algorithms and propose a new paradigm where observational data from different perspectives, each with distinct physical meanings, are treated as multimodal data and integrated via transformers. Furthermore, key weather and climate knowledge can be incorporated through regularization techniques to further strengthen the model's capabilities. This new paradigm is versatile and can address a variety of tasks, offering strong generalizability. We also discuss future directions for improving model accuracy and interpretability.","authors":["Jing Han","Hanting Chen","Kai Han","Xiaomeng Huang","Yongyun Hu","Wenjun Xu","Dacheng Tao","Ping Zhang"],"url":"https://arxiv.org/abs/2504.14174"}
{"created":"2025-04-22","title":"Hypothetical Documents or Knowledge Leakage? Rethinking LLM-based Query Expansion","abstract":"Query expansion methods powered by large language models (LLMs) have demonstrated effectiveness in zero-shot retrieval tasks. These methods assume that LLMs can generate hypothetical documents that, when incorporated into a query vector, enhance the retrieval of real evidence. However, we challenge this assumption by investigating whether knowledge leakage in benchmarks contributes to the observed performance gains. Using fact verification as a testbed, we analyzed whether the generated documents contained information entailed by ground truth evidence and assessed their impact on performance. Our findings indicate that performance improvements occurred consistently only for claims whose generated documents included sentences entailed by ground truth evidence. This suggests that knowledge leakage may be present in these benchmarks, inflating the perceived performance of LLM-based query expansion methods, particularly in real-world scenarios that require retrieving niche or novel knowledge.","authors":["Yejun Yoon","Jaeyoon Jung","Seunghyun Yoon","Kunwoo Park"],"url":"https://arxiv.org/abs/2504.14175"}
{"created":"2025-04-22","title":"Direct Advantage Regression: Aligning LLMs with Online AI Reward","abstract":"Online AI Feedback (OAIF) presents a promising alternative to Reinforcement Learning from Human Feedback (RLHF) by utilizing online AI preference in aligning language models (LLMs). However, the straightforward replacement of humans with AI deprives LLMs from learning more fine-grained AI supervision beyond binary signals. In this paper, we propose Direct Advantage Regression (DAR), a simple alignment algorithm using online AI reward to optimize policy improvement through weighted supervised fine-tuning. As an RL-free approach, DAR maintains theoretical consistency with online RLHF pipelines while significantly reducing implementation complexity and improving learning efficiency. Our empirical results underscore that AI reward is a better form of AI supervision consistently achieving higher human-AI agreement as opposed to AI preference. Additionally, evaluations using GPT-4-Turbo and MT-bench show that DAR outperforms both OAIF and online RLHF baselines.","authors":["Li He","He Zhao","Stephen Wan","Dadong Wang","Lina Yao","Tongliang Liu"],"url":"https://arxiv.org/abs/2504.14177"}
{"created":"2025-04-22","title":"Segregation and Context Aggregation Network for Real-time Cloud Segmentation","abstract":"Cloud segmentation from intensity images is a pivotal task in atmospheric science and computer vision, aiding weather forecasting and climate analysis. Ground-based sky/cloud segmentation extracts clouds from images for further feature analysis. Existing methods struggle to balance segmentation accuracy and computational efficiency, limiting real-world deployment on edge devices, so we introduce SCANet, a novel lightweight cloud segmentation model featuring Segregation and Context Aggregation Module (SCAM), which refines rough segmentation maps into weighted sky and cloud features processed separately. SCANet achieves state-of-the-art performance while drastically reducing computational complexity. SCANet-large (4.29M) achieves comparable accuracy to state-of-the-art methods with 70.9% fewer parameters. Meanwhile, SCANet-lite (90K) delivers 1390 fps in FP16, surpassing real-time standards. Additionally, we propose an efficient pre-training strategy that enhances performance even without ImageNet pre-training.","authors":["Yijie Li","Hewei Wang","Jiayi Zhang","Jinjiang You","Jinfeng Xu","Puzhen Wu","Yunzhong Xiao","Soumyabrata Dev"],"url":"https://arxiv.org/abs/2504.14178"}
{"created":"2025-04-22","title":"FedC4: Graph Condensation Meets Client-Client Collaboration for Efficient and Private Federated Graph Learning","abstract":"Federated Graph Learning (FGL) is an emerging distributed learning paradigm that enables collaborative model training over decentralized graph-structured data while preserving local privacy. Existing FGL methods can be categorized into two optimization architectures: (1) the Server-Client (S-C) paradigm, where clients upload local models for server-side aggregation; and (2) the Client-Client (C-C) paradigm, which allows direct information exchange among clients to support personalized training. Compared to S-C, the C-C architecture better captures global graph knowledge and enables fine-grained optimization through customized peer-to-peer communication. However, current C-C methods often broadcast identical and redundant node embeddings, incurring high communication costs and privacy risks. To address this, we propose FedC4, a novel framework that combines graph Condensation with Client-Client Collaboration. Instead of transmitting raw node-level features, FedC4 distills each client's private graph into a compact set of synthetic node embeddings, reducing communication overhead and enhancing privacy. In addition, FedC4 introduces three modules that allow source clients to send distinct node representations tailored to target clients'graph structures, enabling personalized optimization with global guidance. Extensive experiments on eight real-world datasets show that FedC4 outperforms state-of-the-art baselines in both performance and communication efficiency.","authors":["Zekai Chen","Xunkai Li","Yinlin Zhu","Rong-Hua Li","Guoren Wang"],"url":"https://arxiv.org/abs/2504.14188"}
{"created":"2025-04-22","title":"AI Idea Bench 2025: AI Research Idea Generation Benchmark","abstract":"Large-scale Language Models (LLMs) have revolutionized human-AI interaction and achieved significant success in the generation of novel ideas. However, current assessments of idea generation overlook crucial factors such as knowledge leakage in LLMs, the absence of open-ended benchmarks with grounded truth, and the limited scope of feasibility analysis constrained by prompt design. These limitations hinder the potential of uncovering groundbreaking research ideas. In this paper, we present AI Idea Bench 2025, a framework designed to quantitatively evaluate and compare the ideas generated by LLMs within the domain of AI research from diverse perspectives. The framework comprises a comprehensive dataset of 3,495 AI papers and their associated inspired works, along with a robust evaluation methodology. This evaluation system gauges idea quality in two dimensions: alignment with the ground-truth content of the original papers and judgment based on general reference material. AI Idea Bench 2025's benchmarking system stands to be an invaluable resource for assessing and comparing idea-generation techniques, thereby facilitating the automation of scientific discovery.","authors":["Yansheng Qiu","Haoquan Zhang","Zhaopan Xu","Ming Li","Diping Song","Zheng Wang","Kaipeng Zhang"],"url":"https://arxiv.org/abs/2504.14191"}
{"created":"2025-04-22","title":"Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models","abstract":"The composition of pre-training datasets for large language models (LLMs) remains largely undisclosed, hindering transparency and efforts to optimize data quality, a critical driver of model performance. Current data selection methods, such as natural language quality assessments, diversity-based filters, and classifier-based approaches, are limited by single-dimensional evaluation or redundancy-focused strategies. To address these gaps, we propose PRRC to evaluate data quality across Professionalism, Readability, Reasoning, and Cleanliness. We further introduce Meta-rater, a multi-dimensional data selection method that integrates these dimensions with existing quality metrics through learned optimal weightings. Meta-rater employs proxy models to train a regression model that predicts validation loss, enabling the identification of optimal combinations of quality scores. Experiments demonstrate that Meta-rater doubles convergence speed for 1.3B parameter models and improves downstream task performance by 3.23, with scalable benefits observed in 3.3B models trained on 100B tokens. Additionally, we release the annotated SlimPajama-627B dataset, labeled across 25 quality metrics (including PRRC), to advance research in data-centric LLM development. Our work establishes that holistic, multi-dimensional quality integration significantly outperforms conventional single-dimension approaches, offering a scalable paradigm for enhancing pre-training efficiency and model capability.","authors":["Xinlin Zhuang","Jiahui Peng","Ren Ma","Yinfan Wang","Tianyi Bai","Xingjian Wei","Jiantao Qiu","Chi Zhang","Ying Qian","Conghui He"],"url":"https://arxiv.org/abs/2504.14194"}
{"created":"2025-04-22","title":"The River Method","abstract":"We introduce River, a novel Condorcet-consistent voting method that is based on pairwise majority margins and can be seen as a simplified variation of Tideman's Ranked Pairs method. River is simple to explain, simple to compute even 'by hand', and gives rise to an easy-to-interpret certificate in the form of a directed tree. Like Ranked Pairs and Schulze's Beat Path method, River is a refinement of the Split Cycle method and shares with those many desirable properties, including independence of clones. Unlike the other three methods, River satisfies a strong form of resistance to agenda-manipulation that is known as independence of Pareto-dominated alternatives.","authors":["Michelle D\\\"oring","Markus Brill","Jobst Heitzig"],"url":"https://arxiv.org/abs/2504.14195"}
{"created":"2025-04-22","title":"Enhancing Multimodal In-Context Learning for Image Classification through Coreset Optimization","abstract":"In-context learning (ICL) enables Large Vision-Language Models (LVLMs) to adapt to new tasks without parameter updates, using a few demonstrations from a large support set. However, selecting informative demonstrations leads to high computational and memory costs. While some methods explore selecting a small and representative coreset in the text classification, evaluating all support set samples remains costly, and discarded samples lead to unnecessary information loss. These methods may also be less effective for image classification due to differences in feature spaces. Given these limitations, we propose Key-based Coreset Optimization (KeCO), a novel framework that leverages untapped data to construct a compact and informative coreset. We introduce visual features as keys within the coreset, which serve as the anchor for identifying samples to be updated through different selection strategies. By leveraging untapped samples from the support set, we update the keys of selected coreset samples, enabling the randomly initialized coreset to evolve into a more informative coreset under low computational cost. Through extensive experiments on coarse-grained and fine-grained image classification benchmarks, we demonstrate that KeCO effectively enhances ICL performance for image classification task, achieving an average improvement of more than 20\\%. Notably, we evaluate KeCO under a simulated online scenario, and the strong performance in this scenario highlights the practical value of our framework for resource-constrained real-world scenarios.","authors":["Huiyi Chen","Jiawei Peng","Kaihua Tang","Xin Geng","Xu Yang"],"url":"https://arxiv.org/abs/2504.14200"}
{"created":"2025-04-22","title":"Learning Joint ID-Textual Representation for ID-Preserving Image Synthesis","abstract":"We propose a novel framework for ID-preserving generation using a multi-modal encoding strategy rather than injecting identity features via adapters into pre-trained models. Our method treats identity and text as a unified conditioning input. To achieve this, we introduce FaceCLIP, a multi-modal encoder that learns a joint embedding space for both identity and textual semantics. Given a reference face and a text prompt, FaceCLIP produces a unified representation that encodes both identity and text, which conditions a base diffusion model to generate images that are identity-consistent and text-aligned. We also present a multi-modal alignment algorithm to train FaceCLIP, using a loss that aligns its joint representation with face, text, and image embedding spaces. We then build FaceCLIP-SDXL, an ID-preserving image synthesis pipeline by integrating FaceCLIP with Stable Diffusion XL (SDXL). Compared to prior methods, FaceCLIP-SDXL enables photorealistic portrait generation with better identity preservation and textual relevance. Extensive experiments demonstrate its quantitative and qualitative superiority.","authors":["Zichuan Liu","Liming Jiang","Qing Yan","Yumin Jia","Hao Kang","Xin Lu"],"url":"https://arxiv.org/abs/2504.14202"}
{"created":"2025-04-22","title":"EIoU-EMC: A Novel Loss for Domain-specific Nested Entity Recognition","abstract":"In recent years, research has mainly focused on the general NER task. There still have some challenges with nested NER task in the specific domains. Specifically, the scenarios of low resource and class imbalance impede the wide application for biomedical and industrial domains. In this study, we design a novel loss EIoU-EMC, by enhancing the implement of Intersection over Union loss and Multiclass loss. Our proposed method specially leverages the information of entity boundary and entity classification, thereby enhancing the model's capacity to learn from a limited number of data samples. To validate the performance of this innovative method in enhancing NER task, we conducted experiments on three distinct biomedical NER datasets and one dataset constructed by ourselves from industrial complex equipment maintenance documents. Comparing to strong baselines, our method demonstrates the competitive performance across all datasets. During the experimental analysis, our proposed method exhibits significant advancements in entity boundary recognition and entity classification. Our code are available here.","authors":["Jian Zhang","Tianqing Zhang","Qi Li","Hongwei Wang"],"url":"https://arxiv.org/abs/2504.14203"}
{"created":"2025-04-22","title":"DConAD: A Differencing-based Contrastive Representation Learning Framework for Time Series Anomaly Detection","abstract":"Time series anomaly detection holds notable importance for risk identification and fault detection across diverse application domains. Unsupervised learning methods have become popular because they have no requirement for labels. However, due to the challenges posed by the multiplicity of abnormal patterns, the sparsity of anomalies, and the growth of data scale and complexity, these methods often fail to capture robust and representative dependencies within the time series for identifying anomalies. To enhance the ability of models to capture normal patterns of time series and avoid the retrogression of modeling ability triggered by the dependencies on high-quality prior knowledge, we propose a differencing-based contrastive representation learning framework for time series anomaly detection (DConAD). Specifically, DConAD generates differential data to provide additional information about time series and utilizes transformer-based architecture to capture spatiotemporal dependencies, which enhances the robustness of unbiased representation learning ability. Furthermore, DConAD implements a novel KL divergence-based contrastive learning paradigm that only uses positive samples to avoid deviation from reconstruction and deploys the stop-gradient strategy to compel convergence. Extensive experiments on five public datasets show the superiority and effectiveness of DConAD compared with nine baselines. The code is available at https://github.com/shaieesss/DConAD.","authors":["Wenxin Zhang","Xiaojian Lin","Wenjun Yu","Guangzhen Yao","jingxiang Zhong","Yu Li","Renda Han","Songcheng Xu","Hao Shi","Cuicui Luo"],"url":"https://arxiv.org/abs/2504.14204"}
{"created":"2025-04-22","title":"Dual-channel Heterophilic Message Passing for Graph Fraud Detection","abstract":"Fraudulent activities have significantly increased across various domains, such as e-commerce, online review platforms, and social networks, making fraud detection a critical task. Spatial Graph Neural Networks (GNNs) have been successfully applied to fraud detection tasks due to their strong inductive learning capabilities. However, existing spatial GNN-based methods often enhance the graph structure by excluding heterophilic neighbors during message passing to align with the homophilic bias of GNNs. Unfortunately, this approach can disrupt the original graph topology and increase uncertainty in predictions. To address these limitations, this paper proposes a novel framework, Dual-channel Heterophilic Message Passing (DHMP), for fraud detection. DHMP leverages a heterophily separation module to divide the graph into homophilic and heterophilic subgraphs, mitigating the low-pass inductive bias of traditional GNNs. It then applies shared weights to capture signals at different frequencies independently and incorporates a customized sampling strategy for training. This allows nodes to adaptively balance the contributions of various signals based on their labels. Extensive experiments on three real-world datasets demonstrate that DHMP outperforms existing methods, highlighting the importance of separating signals with different frequencies for improved fraud detection. The code is available at https://github.com/shaieesss/DHMP.","authors":["Wenxin Zhang","Jingxing Zhong","Guangzhen Yao","Renda Han","Xiaojian Lin","Zeyu Zhang","Cuicui Luo"],"url":"https://arxiv.org/abs/2504.14205"}
{"created":"2025-04-22","title":"Decomposition-based multi-scale transformer framework for time series anomaly detection","abstract":"Time series anomaly detection is crucial for maintaining stable systems. Existing methods face two main challenges. First, it is difficult to directly model the dependencies of diverse and complex patterns within the sequences. Second, many methods that optimize parameters using mean squared error struggle with noise in the time series, leading to performance deterioration. To address these challenges, we propose a transformer-based framework built on decomposition (TransDe) for multivariate time series anomaly detection. The key idea is to combine the strengths of time series decomposition and transformers to effectively learn the complex patterns in normal time series data. A multi-scale patch-based transformer architecture is proposed to exploit the representative dependencies of each decomposed component of the time series. Furthermore, a contrastive learn paradigm based on patch operation is proposed, which leverages KL divergence to align the positive pairs, namely the pure representations of normal patterns between different patch-level views. A novel asynchronous loss function with a stop-gradient strategy is further introduced to enhance the performance of TransDe effectively. It can avoid time-consuming and labor-intensive computation costs in the optimization process. Extensive experiments on five public datasets are conducted and TransDe shows superiority compared with twelve baselines in terms of F1 score. Our code is available at https://github.com/shaieesss/TransDe.","authors":["Wenxin Zhang","Cuicui Luo"],"url":"https://arxiv.org/abs/2504.14206"}
{"created":"2025-04-22","title":"FedCIA: Federated Collaborative Information Aggregation for Privacy-Preserving Recommendation","abstract":"Recommendation algorithms rely on user historical interactions to deliver personalized suggestions, which raises significant privacy concerns. Federated recommendation algorithms tackle this issue by combining local model training with server-side model aggregation, where most existing algorithms use a uniform weighted summation to aggregate item embeddings from different client models. This approach has three major limitations: 1) information loss during aggregation, 2) failure to retain personalized local features, and 3) incompatibility with parameter-free recommendation algorithms. To address these limitations, we first review the development of recommendation algorithms and recognize that their core function is to share collaborative information, specifically the global relationship between users and items. With this understanding, we propose a novel aggregation paradigm named collaborative information aggregation, which focuses on sharing collaborative information rather than item parameters. Based on this new paradigm, we introduce the federated collaborative information aggregation (FedCIA) method for privacy-preserving recommendation. This method requires each client to upload item similarity matrices for aggregation, which allows clients to align their local models without constraining embeddings to a unified vector space. As a result, it mitigates information loss caused by direct summation, preserves the personalized embedding distributions of individual clients, and supports the aggregation of parameter-free models. Theoretical analysis and experimental results on real-world datasets demonstrate the superior performance of FedCIA compared with the state-of-the-art federated recommendation algorithms. Code is available at https://github.com/Mingzhe-Han/FedCIA.","authors":["Mingzhe Han","Dongsheng Li","Jiafeng Xia","Jiahao Liu","Hansu Gu","Peng Zhang","Ning Gu","Tun Lu"],"url":"https://arxiv.org/abs/2504.14208"}
{"created":"2025-04-22","title":"Pets: General Pattern Assisted Architecture For Time Series Analysis","abstract":"Time series analysis has found widespread applications in areas such as weather forecasting, anomaly detection, and healthcare. However, real-world sequential data often exhibit a superimposed state of various fluctuation patterns, including hourly, daily, and monthly frequencies. Traditional decomposition techniques struggle to effectively disentangle these multiple fluctuation patterns from the seasonal components, making time series analysis challenging. Surpassing the existing multi-period decoupling paradigms, this paper introduces a novel perspective based on energy distribution within the temporal-spectrum space. By adaptively quantifying observed sequences into continuous frequency band intervals, the proposed approach reconstructs fluctuation patterns across diverse periods without relying on domain-specific prior knowledge. Building upon this innovative strategy, we propose Pets, an enhanced architecture that is adaptable to arbitrary model structures. Pets integrates a Fluctuation Pattern Assisted (FPA) module and a Context-Guided Mixture of Predictors (MoP). The FPA module facilitates information fusion among diverse fluctuation patterns by capturing their dependencies and progressively modeling these patterns as latent representations at each layer. Meanwhile, the MoP module leverages these compound pattern representations to guide and regulate the reconstruction of distinct fluctuations hierarchically. Pets achieves state-of-the-art performance across various tasks, including forecasting, imputation, anomaly detection, and classification, while demonstrating strong generalization and robustness.","authors":["Xiangkai Ma","Xiaobin Hong","Wenzhong Li","Sanglu Lu"],"url":"https://arxiv.org/abs/2504.14209"}
{"created":"2025-04-22","title":"Bias Analysis and Mitigation through Protected Attribute Detection and Regard Classification","abstract":"Large language models (LLMs) acquire general linguistic knowledge from massive-scale pretraining. However, pretraining data mainly comprised of web-crawled texts contain undesirable social biases which can be perpetuated or even amplified by LLMs. In this study, we propose an efficient yet effective annotation pipeline to investigate social biases in the pretraining corpora. Our pipeline consists of protected attribute detection to identify diverse demographics, followed by regard classification to analyze the language polarity towards each attribute. Through our experiments, we demonstrate the effect of our bias analysis and mitigation measures, focusing on Common Crawl as the most representative pretraining corpus.","authors":["Takuma Udagawa","Yang Zhao","Hiroshi Kanayama","Bishwaranjan Bhattacharjee"],"url":"https://arxiv.org/abs/2504.14212"}
{"created":"2025-04-22","title":"Teach Me How to Denoise: A Universal Framework for Denoising Multi-modal Recommender Systems via Guided Calibration","abstract":"The surge in multimedia content has led to the development of Multi-Modal Recommender Systems (MMRecs), which use diverse modalities such as text, images, videos, and audio for more personalized recommendations. However, MMRecs struggle with noisy data caused by misalignment among modal content and the gap between modal semantics and recommendation semantics. Traditional denoising methods are inadequate due to the complexity of multi-modal data. To address this, we propose a universal guided in-sync distillation denoising framework for multi-modal recommendation (GUIDER), designed to improve MMRecs by denoising user feedback. Specifically, GUIDER uses a re-calibration strategy to identify clean and noisy interactions from modal content. It incorporates a Denoising Bayesian Personalized Ranking (DBPR) loss function to handle implicit user feedback. Finally, it applies a denoising knowledge distillation objective based on Optimal Transport distance to guide the alignment from modality representations to recommendation semantics. GUIDER can be seamlessly integrated into existing MMRecs methods as a plug-and-play solution. Experimental results on four public datasets demonstrate its effectiveness and generalizability. Our source code is available at https://github.com/Neon-Jing/Guider","authors":["Hongji Li","Hanwen Du","Youhua Li","Junchen Fu","Chunxiao Li","Ziyi Zhuang","Jiakang Li","Yongxin Ni"],"url":"https://arxiv.org/abs/2504.14214"}
{"created":"2025-04-22","title":"PyFRep: Shape Modeling with Differentiable Function Representation","abstract":"We propose a framework for performing differentiable geometric modeling based on the Function Representation (FRep). The framework is built on top of modern libraries for performing automatic differentiation allowing us to obtain derivatives w.r.t. space or shape parameters. We demonstrate possible applications of this framework: Curvature estimation for shape interrogation, signed distance function computation and approximation and fitting shape parameters of a parametric model to data. Our framework is released as open-source.","authors":["Pierre-Alain Fayolle","Evgenii Maltsev"],"url":"https://arxiv.org/abs/2504.14216"}
{"created":"2025-04-22","title":"Understanding the Repeat Curse in Large Language Models from a Feature Perspective","abstract":"Large language models (LLMs) have made remarkable progress in various domains, yet they often suffer from repetitive text generation, a phenomenon we refer to as the \"Repeat Curse\". While previous studies have proposed decoding strategies to mitigate repetition, the underlying mechanism behind this issue remains insufficiently explored. In this work, we investigate the root causes of repetition in LLMs through the lens of mechanistic interpretability. Inspired by recent advances in Sparse Autoencoders (SAEs), which enable monosemantic feature extraction, we propose a novel approach, \"Duplicatus Charm\", to induce and analyze the Repeat Curse. Our method systematically identifies \"Repetition Features\" -the key model activations responsible for generating repetitive outputs. First, we locate the layers most involved in repetition through logit analysis. Next, we extract and stimulate relevant features using SAE-based activation manipulation. To validate our approach, we construct a repetition dataset covering token and paragraph level repetitions and introduce an evaluation pipeline to quantify the influence of identified repetition features. Furthermore, by deactivating these features, we have effectively mitigated the Repeat Curse.","authors":["Junchi Yao","Shu Yang","Jianhua Xu","Lijie Hu","Mengdi Li","Di Wang"],"url":"https://arxiv.org/abs/2504.14218"}
{"created":"2025-04-22","title":"PRISM: A Unified Framework for Photorealistic Reconstruction and Intrinsic Scene Modeling","abstract":"We present PRISM, a unified framework that enables multiple image generation and editing tasks in a single foundational model. Starting from a pre-trained text-to-image diffusion model, PRISM proposes an effective fine-tuning strategy to produce RGB images along with intrinsic maps (referred to as X layers) simultaneously. Unlike previous approaches, which infer intrinsic properties individually or require separate models for decomposition and conditional generation, PRISM maintains consistency across modalities by generating all intrinsic layers jointly. It supports diverse tasks, including text-to-RGBX generation, RGB-to-X decomposition, and X-to-RGBX conditional generation. Additionally, PRISM enables both global and local image editing through conditioning on selected intrinsic layers and text prompts. Extensive experiments demonstrate the competitive performance of PRISM both for intrinsic image decomposition and conditional image generation while preserving the base model's text-to-image generation capability.","authors":["Alara Dirik","Tuanfeng Wang","Duygu Ceylan","Stefanos Zafeiriou","Anna Fr\\\"uhst\\\"uck"],"url":"https://arxiv.org/abs/2504.14219"}
{"created":"2025-04-22","title":"From Cyber Security Incident Management to Cyber Security Crisis Management in the European Union","abstract":"Incident management is a classical topic in cyber security. Recently, the European Union (EU) has started to consider also the relation between cyber security incidents and cyber security crises. These considerations and preparations, including those specified in the EU's new cyber security laws, constitute the paper's topic. According to an analysis of the laws and associated policy documents, (i) cyber security crises are equated in the EU to large-scale cyber security incidents that either exceed a handling capacity of a single member state or affect at least two member states. For this and other purposes, (ii) the new laws substantially increase mandatory reporting about cyber security incidents, including but not limited to the large-scale incidents. Despite the laws and new governance bodies established by them, however, (iii) the working of actual cyber security crisis management remains unclear particularly at the EU-level. With these policy research results, the paper advances the domain of cyber security incident management research by elaborating how European law perceives cyber security crises and their relation to cyber security incidents, paving the way for many relevant further research topics with practical relevance, whether theoretical, conceptual, or empirical.","authors":["Jukka Ruohonen","Kalle Rindell","Simone Busetti"],"url":"https://arxiv.org/abs/2504.14220"}
{"created":"2025-04-22","title":"Real-IAD D3: A Real-World 2D/Pseudo-3D/3D Dataset for Industrial Anomaly Detection","abstract":"The increasing complexity of industrial anomaly detection (IAD) has positioned multimodal detection methods as a focal area of machine vision research. However, dedicated multimodal datasets specifically tailored for IAD remain limited. Pioneering datasets like MVTec 3D have laid essential groundwork in multimodal IAD by incorporating RGB+3D data, but still face challenges in bridging the gap with real industrial environments due to limitations in scale and resolution. To address these challenges, we introduce Real-IAD D3, a high-precision multimodal dataset that uniquely incorporates an additional pseudo3D modality generated through photometric stereo, alongside high-resolution RGB images and micrometer-level 3D point clouds. Real-IAD D3 features finer defects, diverse anomalies, and greater scale across 20 categories, providing a challenging benchmark for multimodal IAD Additionally, we introduce an effective approach that integrates RGB, point cloud, and pseudo-3D depth information to leverage the complementary strengths of each modality, enhancing detection performance. Our experiments highlight the importance of these modalities in boosting detection robustness and overall IAD performance. The dataset and code are publicly accessible for research purposes at https://realiad4ad.github.io/Real-IAD D3","authors":["Wenbing Zhu","Lidong Wang","Ziqing Zhou","Chengjie Wang","Yurui Pan","Ruoyi Zhang","Zhuhao Chen","Linjie Cheng","Bin-Bin Gao","Jiangning Zhang","Zhenye Gan","Yuxie Wang","Yulong Chen","Shuguang Qian","Mingmin Chi","Bo Peng","Lizhuang Ma"],"url":"https://arxiv.org/abs/2504.14221"}
{"created":"2025-04-22","title":"tAIfa: Enhancing Team Effectiveness and Cohesion with AI-Generated Automated Feedback","abstract":"Providing timely and actionable feedback is crucial for effective collaboration, learning, and coordination within teams. However, many teams face challenges in receiving feedback that aligns with their goals and promotes cohesion. We introduce tAIfa (``Team AI Feedback Assistant''), an AI agent that uses Large Language Models (LLMs) to provide personalized, automated feedback to teams and their members. tAIfa analyzes team interactions, identifies strengths and areas for improvement, and delivers targeted feedback based on communication patterns. We conducted a between-subjects study with 18 teams testing whether using tAIfa impacted their teamwork. Our findings show that tAIfa improved communication and contributions within the teams. This paper contributes to the Human-AI Interaction literature by presenting a computational framework that integrates LLMs to provide automated feedback, introducing tAIfa as a tool to enhance team engagement and cohesion, and providing insights into future AI applications to support team collaboration.","authors":["Mohammed Almutairi","Charles Chiang","Yuxin Bai","Diego Gomez-Zara"],"url":"https://arxiv.org/abs/2504.14222"}
{"created":"2025-04-22","title":"SimplifyMyText: An LLM-Based System for Inclusive Plain Language Text Simplification","abstract":"Text simplification is essential for making complex content accessible to diverse audiences who face comprehension challenges. Yet, the limited availability of simplified materials creates significant barriers to personal and professional growth and hinders social inclusion. Although researchers have explored various methods for automatic text simplification, none fully leverage large language models (LLMs) to offer tailored customization for different target groups and varying levels of simplicity. Moreover, despite its proven benefits for both consumers and organizations, the well-established practice of plain language remains underutilized. In this paper, we https://simplifymytext.org, the first system designed to produce plain language content from multiple input formats, including typed text and file uploads, with flexible customization options for diverse audiences. We employ GPT-4 and Llama-3 and evaluate outputs across multiple metrics. Overall, our work contributes to research on automatic text simplification and highlights the importance of tailored communication in promoting inclusivity.","authors":["Michael F\\\"arber","Parisa Aghdam","Kyuri Im","Mario Tawfelis","Hardik Ghoshal"],"url":"https://arxiv.org/abs/2504.14223"}
{"created":"2025-04-22","title":"Revisiting CLIP for SF-OSDA: Unleashing Zero-Shot Potential with Adaptive Threshold and Training-Free Feature Filtering","abstract":"Source-Free Unsupervised Open-Set Domain Adaptation (SF-OSDA) methods using CLIP face significant issues: (1) while heavily dependent on domain-specific threshold selection, existing methods employ simple fixed thresholds, underutilizing CLIP's zero-shot potential in SF-OSDA scenarios; and (2) overlook intrinsic class tendencies while employing complex training to enforce feature separation, incurring deployment costs and feature shifts that compromise CLIP's generalization ability. To address these issues, we propose CLIPXpert, a novel SF-OSDA approach that integrates two key components: an adaptive thresholding strategy and an unknown class feature filtering module. Specifically, the Box-Cox GMM-Based Adaptive Thresholding (BGAT) module dynamically determines the optimal threshold by estimating sample score distributions, balancing known class recognition and unknown class sample detection. Additionally, the Singular Value Decomposition (SVD)-Based Unknown-Class Feature Filtering (SUFF) module reduces the tendency of unknown class samples towards known classes, improving the separation between known and unknown classes. Experiments show that our source-free and training-free method outperforms state-of-the-art trained approach UOTA by 1.92% on the DomainNet dataset, achieves SOTA-comparable performance on datasets such as Office-Home, and surpasses other SF-OSDA methods. This not only validates the effectiveness of our proposed method but also highlights CLIP's strong zero-shot potential for SF-OSDA tasks.","authors":["Yongguang Li","Jindong Li","Qi Wang","Qianli Xing","Runliang Niu","Shengsheng Wang","Menglin Yang"],"url":"https://arxiv.org/abs/2504.14224"}
{"created":"2025-04-22","title":"Know Me, Respond to Me: Benchmarking LLMs for Dynamic User Profiling and Personalized Responses at Scale","abstract":"Large Language Models (LLMs) have emerged as personalized assistants for users across a wide range of tasks -- from offering writing support to delivering tailored recommendations or consultations. Over time, the interaction history between a user and an LLM can provide extensive information about an individual's traits and preferences. However, open questions remain on how well LLMs today can effectively leverage such history to (1) internalize the user's inherent traits and preferences, (2) track how the user profiling and preferences evolve over time, and (3) generate personalized responses accordingly in new scenarios.","authors":["Bowen Jiang","Zhuoqun Hao","Young-Min Cho","Bryan Li","Yuan Yuan","Sihao Chen","Lyle Ungar","Camillo J. Taylor","Dan Roth"],"url":"https://arxiv.org/abs/2504.14225"}
{"created":"2025-04-22","title":"Exploring Modality Guidance to Enhance VFM-based Feature Fusion for UDA in 3D Semantic Segmentation","abstract":"Vision Foundation Models (VFMs) have become a de facto choice for many downstream vision tasks, like image classification, image segmentation, and object localization. However, they can also provide significant utility for downstream 3D tasks that can leverage the cross-modal information (e.g., from paired image data). In our work, we further explore the utility of VFMs for adapting from a labeled source to unlabeled target data for the task of LiDAR-based 3D semantic segmentation. Our method consumes paired 2D-3D (image and point cloud) data and relies on the robust (cross-domain) features from a VFM to train a 3D backbone on a mix of labeled source and unlabeled target data. At the heart of our method lies a fusion network that is guided by both the image and point cloud streams, with their relative contributions adjusted based on the target domain. We extensively compare our proposed methodology with different state-of-the-art methods in several settings and achieve strong performance gains. For example, achieving an average improvement of 6.5 mIoU (over all tasks), when compared with the previous state-of-the-art.","authors":["Johannes Spoecklberger","Wei Lin","Pedro Hermosilla","Sivan Doveh","Horst Possegger","M. Jehanzeb Mirza"],"url":"https://arxiv.org/abs/2504.14231"}
{"created":"2025-04-22","title":"Assessing AI-Generated Questions' Alignment with Cognitive Frameworks in Educational Assessment","abstract":"This study evaluates the integration of Bloom's Taxonomy into OneClickQuiz, an Artificial Intelligence (AI) driven plugin for automating Multiple-Choice Question (MCQ) generation in Moodle. Bloom's Taxonomy provides a structured framework for categorizing educational objectives into hierarchical cognitive levels. Our research investigates whether incorporating this taxonomy can improve the alignment of AI-generated questions with specific cognitive objectives. We developed a dataset of 3691 questions categorized according to Bloom's levels and employed various classification models-Multinomial Logistic Regression, Naive Bayes, Linear Support Vector Classification (SVC), and a Transformer-based model (DistilBERT)-to evaluate their effectiveness in categorizing questions. Our results indicate that higher Bloom's levels generally correlate with increased question length, Flesch-Kincaid Grade Level (FKGL), and Lexical Density (LD), reflecting the increased complexity of higher cognitive demands. Multinomial Logistic Regression showed varying accuracy across Bloom's levels, performing best for \"Knowledge\" and less accurately for higher-order levels. Merging higher-level categories improved accuracy for complex cognitive tasks. Naive Bayes and Linear SVC also demonstrated effective classification for lower levels but struggled with higher-order tasks. DistilBERT achieved the highest performance, significantly improving classification of both lower and higher-order cognitive levels, achieving an overall validation accuracy of 91%. This study highlights the potential of integrating Bloom's Taxonomy into AI-driven assessment tools and underscores the advantages of advanced models like DistilBERT for enhancing educational content generation.","authors":["Antoun Yaacoub","J\\'er\\^ome Da-Rugna","Zainab Assaghir"],"url":"https://arxiv.org/abs/2504.14232"}
{"created":"2025-04-22","title":"Template-Based Financial Report Generation in Agentic and Decomposed Information Retrieval","abstract":"Tailoring structured financial reports from companies' earnings releases is crucial for understanding financial performance and has been widely adopted in real-world analytics. However, existing summarization methods often generate broad, high-level summaries, which may lack the precision and detail required for financial reports that typically focus on specific, structured sections. While Large Language Models (LLMs) hold promise, generating reports adhering to predefined multi-section templates remains challenging. This paper investigates two LLM-based approaches popular in industry for generating templated financial reports: an agentic information retrieval (IR) framework and a decomposed IR approach, namely AgenticIR and DecomposedIR. The AgenticIR utilizes collaborative agents prompted with the full template. In contrast, the DecomposedIR approach applies a prompt chaining workflow to break down the template and reframe each section as a query answered by the LLM using the earnings release. To quantitatively assess the generated reports, we evaluated both methods in two scenarios: one using a financial dataset without direct human references, and another with a weather-domain dataset featuring expert-written reports. Experimental results show that while AgenticIR may excel in orchestrating tasks and generating concise reports through agent collaboration, DecomposedIR statistically significantly outperforms AgenticIR approach in providing broader and more detailed coverage in both scenarios, offering reflection on the utilization of the agentic framework in real-world applications.","authors":["Yong-En Tian","Yu-Chien Tang","Kuang-Da Wang","An-Zi Yen","Wen-Chih Peng"],"url":"https://arxiv.org/abs/2504.14233"}
{"created":"2025-04-22","title":"The Dark Side of the Web: Towards Understanding Various Data Sources in Cyber Threat Intelligence","abstract":"Cyber threats have become increasingly prevalent and sophisticated. Prior work has extracted actionable cyber threat intelligence (CTI), such as indicators of compromise, tactics, techniques, and procedures (TTPs), or threat feeds from various sources: open source data (e.g., social networks), internal intelligence (e.g., log data), and ``first-hand'' communications from cybercriminals (e.g., underground forums, chats, darknet websites). However, \"first-hand\" data sources remain underutilized because it is difficult to access or scrape their data.","authors":["Saskia Schr\\\"oer","No\\'e Canevascini","Irdin Pekaric","Philine Widmer","Pavel Laskov"],"url":"https://arxiv.org/abs/2504.14235"}
{"created":"2025-04-22","title":"A Novel Frequency-Spatial Domain Aware Network for Fast Thermal Prediction in 2.5D ICs","abstract":"In the post-Moore era, 2.5D chiplet-based ICs present significant challenges in thermal management due to increased power density and thermal hotspots. Neural network-based thermal prediction models can perform real-time predictions for many unseen new designs. However, existing CNN-based and GCN-based methods cannot effectively capture the global thermal features, especially for high-frequency components, hindering prediction accuracy enhancement. In this paper, we propose a novel frequency-spatial dual domain aware prediction network (FSA-Heat) for fast and high-accuracy thermal prediction in 2.5D ICs. It integrates high-to-low frequency and spatial domain encoder (FSTE) module with frequency domain cross-scale interaction module (FCIFormer) to achieve high-to-low frequency and global-to-local thermal dissipation feature extraction. Additionally, a frequency-spatial hybrid loss (FSL) is designed to effectively attenuate high-frequency thermal gradient noise and spatial misalignments. The experimental results show that the performance enhancements offered by our proposed method are substantial, outperforming the newly-proposed 2.5D method, GCN+PNA, by considerable margins (over 99% RMSE reduction, 4.23X inference time speedup). Moreover, extensive experiments demonstrate that FSA-Heat also exhibits robust generalization capabilities.","authors":["Dekang Zhang","Dan Niu","Zhou Jin","Yichao Dong","Jingweijia Tan","Changyin Sun"],"url":"https://arxiv.org/abs/2504.14237"}
{"created":"2025-04-22","title":"Single Document Image Highlight Removal via A Large-Scale Real-World Dataset and A Location-Aware Network","abstract":"Reflective documents often suffer from specular highlights under ambient lighting, severely hindering text readability and degrading overall visual quality. Although recent deep learning methods show promise in highlight removal, they remain suboptimal for document images, primarily due to the lack of dedicated datasets and tailored architectural designs. To tackle these challenges, we present DocHR14K, a large-scale real-world dataset comprising 14,902 high-resolution image pairs across six document categories and various lighting conditions. To the best of our knowledge, this is the first high-resolution dataset for document highlight removal that captures a wide range of real-world lighting conditions. Additionally, motivated by the observation that the residual map between highlighted and clean images naturally reveals the spatial structure of highlight regions, we propose a simple yet effective Highlight Location Prior (HLP) to estimate highlight masks without human annotations. Building on this prior, we present the Location-Aware Laplacian Pyramid Highlight Removal Network (L2HRNet), which effectively removes highlights by leveraging estimated priors and incorporates diffusion module to restore details. Extensive experiments demonstrate that DocHR14K improves highlight removal under diverse lighting conditions. Our L2HRNet achieves state-of-the-art performance across three benchmark datasets, including a 5.01\\% increase in PSNR and a 13.17\\% reduction in RMSE on DocHR14K.","authors":["Lu Pan","Yu-Hsuan Huang","Hongxia Xie","Cheng Zhang","Hongwei Zhao","Hong-Han Shuai","Wen-Huang Cheng"],"url":"https://arxiv.org/abs/2504.14238"}
{"created":"2025-04-22","title":"InfiGUI-R1: Advancing Multimodal GUI Agents from Reactive Actors to Deliberative Reasoners","abstract":"Multimodal Large Language Models (MLLMs) have powered Graphical User Interface (GUI) Agents, showing promise in automating tasks on computing devices. Recent works have begun exploring reasoning in GUI tasks with encouraging results. However, many current approaches rely on manually designed reasoning templates, which may result in reasoning that is not sufficiently robust and adaptive for complex GUI environments. Meanwhile, some existing agents continue to operate as Reactive Actors, relying primarily on implicit reasoning that may lack sufficient depth for GUI tasks demanding planning and error recovery. We argue that advancing these agents requires a shift from reactive acting towards acting based on deliberate reasoning. To facilitate this transformation, we introduce InfiGUI-R1, an MLLM-based GUI agent developed through our Actor2Reasoner framework, a reasoning-centric, two-stage training approach designed to progressively evolve agents from Reactive Actors to Deliberative Reasoners. The first stage, Reasoning Injection, focuses on establishing a basic reasoner. We employ Spatial Reasoning Distillation to transfer cross-modal spatial reasoning capabilities from teacher models to MLLMs through trajectories with explicit reasoning steps, enabling models to integrate GUI visual-spatial information with logical reasoning before action generation. The second stage, Deliberation Enhancement, refines the basic reasoner into a deliberative one using Reinforcement Learning. This stage introduces two approaches: Sub-goal Guidance, which rewards models for generating accurate intermediate sub-goals, and Error Recovery Scenario Construction, which creates failure-and-recovery training scenarios from identified prone-to-error steps. Experimental results show InfiGUI-R1 achieves strong performance in GUI grounding and trajectory tasks. Resources at https://github.com/Reallm-Labs/InfiGUI-R1.","authors":["Yuhang Liu","Pengxiang Li","Congkai Xie","Xavier Hu","Xiaotian Han","Shengyu Zhang","Hongxia Yang","Fei Wu"],"url":"https://arxiv.org/abs/2504.14239"}
{"created":"2025-04-22","title":"ROI-Guided Point Cloud Geometry Compression Towards Human and Machine Vision","abstract":"Point cloud data is pivotal in applications like autonomous driving, virtual reality, and robotics. However, its substantial volume poses significant challenges in storage and transmission. In order to obtain a high compression ratio, crucial semantic details usually confront severe damage, leading to difficulties in guaranteeing the accuracy of downstream tasks. To tackle this problem, we are the first to introduce a novel Region of Interest (ROI)-guided Point Cloud Geometry Compression (RPCGC) method for human and machine vision. Our framework employs a dual-branch parallel structure, where the base layer encodes and decodes a simplified version of the point cloud, and the enhancement layer refines this by focusing on geometry details. Furthermore, the residual information of the enhancement layer undergoes refinement through an ROI prediction network. This network generates mask information, which is then incorporated into the residuals, serving as a strong supervision signal. Additionally, we intricately apply these mask details in the Rate-Distortion (RD) optimization process, with each point weighted in the distortion calculation. Our loss function includes RD loss and detection loss to better guide point cloud encoding for the machine. Experiment results demonstrate that RPCGC achieves exceptional compression performance and better detection accuracy (10% gain) than some learning-based compression methods at high bitrates in ScanNet and SUN RGB-D datasets.","authors":["Xie Liang","Gao Wei","Zhenghui Ming","Li Ge"],"url":"https://arxiv.org/abs/2504.14240"}
{"created":"2025-04-22","title":"A Knowledge-Informed Deep Learning Paradigm for Generalizable and Stability-Optimized Car-Following Models","abstract":"Car-following models (CFMs) are fundamental to traffic flow analysis and autonomous driving. Although calibrated physics-based and trained data-driven CFMs can replicate human driving behavior, their reliance on specific datasets limits generalization across diverse scenarios and reduces reliability in real-world deployment. Moreover, these models typically focus on behavioral fidelity and do not support the explicit optimization of local and string stability, which are increasingly important for the safe and efficient operation of autonomous vehicles (AVs). To address these limitations, we propose a Knowledge-Informed Deep Learning (KIDL) paradigm that distills the generalization capabilities of pre-trained Large Language Models (LLMs) into a lightweight and stability-aware neural architecture. LLMs are used to extract fundamental car-following knowledge beyond dataset-specific patterns, and this knowledge is transferred to a reliable, tractable, and computationally efficient model through knowledge distillation. KIDL also incorporates stability constraints directly into its training objective, ensuring that the resulting model not only emulates human-like behavior but also satisfies the local and string stability requirements essential for real-world AV deployment. We evaluate KIDL on the real-world NGSIM and HighD datasets, comparing its performance with representative physics-based, data-driven, and hybrid CFMs. Both empirical and theoretical results consistently demonstrate KIDL's superior behavioral generalization and traffic flow stability, offering a robust and scalable solution for next-generation traffic systems.","authors":["Chengming Wang","Dongyao Jia","Wei Wang","Dong Ngoduy","Bei Peng","Jianping Wang"],"url":"https://arxiv.org/abs/2504.14241"}
{"created":"2025-04-22","title":"Unconstrained Monotonic Calibration of Predictions in Deep Ranking Systems","abstract":"Ranking models primarily focus on modeling the relative order of predictions while often neglecting the significance of the accuracy of their absolute values. However, accurate absolute values are essential for certain downstream tasks, necessitating the calibration of the original predictions. To address this, existing calibration approaches typically employ predefined transformation functions with order-preserving properties to adjust the original predictions. Unfortunately, these functions often adhere to fixed forms, such as piece-wise linear functions, which exhibit limited expressiveness and flexibility, thereby constraining their effectiveness in complex calibration scenarios. To mitigate this issue, we propose implementing a calibrator using an Unconstrained Monotonic Neural Network (UMNN), which can learn arbitrary monotonic functions with great modeling power. This approach significantly relaxes the constraints on the calibrator, improving its flexibility and expressiveness while avoiding excessively distorting the original predictions by requiring monotonicity. Furthermore, to optimize this highly flexible network for calibration, we introduce a novel additional loss function termed Smooth Calibration Loss (SCLoss), which aims to fulfill a necessary condition for achieving the ideal calibration state. Extensive offline experiments confirm the effectiveness of our method in achieving superior calibration performance. Moreover, deployment in Kuaishou's large-scale online video ranking system demonstrates that the method's calibration improvements translate into enhanced business metrics. The source code is available at https://github.com/baiyimeng/UMC.","authors":["Yimeng Bai","Shunyu Zhang","Yang Zhang","Hu Liu","Wentian Bao","Enyun Yu","Fuli Feng","Wenwu Ou"],"url":"https://arxiv.org/abs/2504.14243"}
{"created":"2025-04-22","title":"Towards Explainable Fake Image Detection with Multi-Modal Large Language Models","abstract":"Progress in image generation raises significant public security concerns. We argue that fake image detection should not operate as a \"black box\". Instead, an ideal approach must ensure both strong generalization and transparency. Recent progress in Multi-modal Large Language Models (MLLMs) offers new opportunities for reasoning-based AI-generated image detection. In this work, we evaluate the capabilities of MLLMs in comparison to traditional detection methods and human evaluators, highlighting their strengths and limitations. Furthermore, we design six distinct prompts and propose a framework that integrates these prompts to develop a more robust, explainable, and reasoning-driven detection system. The code is available at https://github.com/Gennadiyev/mllm-defake.","authors":["Yikun Ji","Yan Hong","Jiahui Zhan","Haoxing Chen","jun lan","Huijia Zhu","Weiqiang Wang","Liqing Zhang","Jianfu Zhang"],"url":"https://arxiv.org/abs/2504.14245"}
{"created":"2025-04-22","title":"Rethinking Traffic Flow Forecasting: From Transition to Generatation","abstract":"Traffic flow prediction plays an important role in Intelligent Transportation Systems in traffic management and urban planning. There have been extensive successful works in this area. However, these approaches focus only on modelling the flow transition and ignore the flow generation process, which manifests itself in two ways: (i) The models are based on Markovian assumptions, ignoring the multi-periodicity of the flow generation in nodes. (ii) The same structure is designed to encode both the transition and generation processes, ignoring the differences between them. To address these problems, we propose an Effective Multi-Branch Similarity Transformer for Traffic Flow Prediction, namely EMBSFormer. Through data analysis, we find that the factors affecting traffic flow include node-level traffic generation and graph-level traffic transition, which describe the multi-periodicity and interaction pattern of nodes, respectively. Specifically, to capture traffic generation patterns, we propose a similarity analysis module that supports multi-branch encoding to dynamically expand significant cycles. For traffic transition, we employ a temporal and spatial self-attention mechanism to maintain global node interactions, and use GNN and time conv to model local node interactions, respectively. Model performance is evaluated on three real-world datasets on both long-term and short-term prediction tasks. Experimental results show that EMBSFormer outperforms baselines on both tasks. Moreover, compared to models based on flow transition modelling (e.g. GMAN, 513k), the variant of EMBSFormer(93K) only uses 18\\% of the parameters, achieving the same performance.","authors":["Li Shijiao","Ma Zhipeng","He Huajun","Chen Haiyue"],"url":"https://arxiv.org/abs/2504.14248"}
{"created":"2025-04-22","title":"Any Image Restoration via Efficient Spatial-Frequency Degradation Adaptation","abstract":"Restoring any degraded image efficiently via just one model has become increasingly significant and impactful, especially with the proliferation of mobile devices. Traditional solutions typically involve training dedicated models per degradation, resulting in inefficiency and redundancy. More recent approaches either introduce additional modules to learn visual prompts, significantly increasing model size, or incorporate cross-modal transfer from large language models trained on vast datasets, adding complexity to the system architecture. In contrast, our approach, termed AnyIR, takes a unified path that leverages inherent similarity across various degradations to enable both efficient and comprehensive restoration through a joint embedding mechanism, without scaling up the model or relying on large language models.Specifically, we examine the sub-latent space of each input, identifying key components and reweighting them first in a gated manner. To fuse the intrinsic degradation awareness and the contextualized attention, a spatial-frequency parallel fusion strategy is proposed for enhancing spatial-aware local-global interactions and enriching the restoration details from the frequency perspective. Extensive benchmarking in the all-in-one restoration setting confirms AnyIR's SOTA performance, reducing model complexity by around 82\\% in parameters and 85\\% in FLOPs. Our code will be available at our Project page (https://amazingren.github.io/AnyIR/)","authors":["Bin Ren","Eduard Zamfir","Zongwei Wu","Yawei Li","Yidi Li","Danda Pani Paudel","Radu Timofte","Ming-Hsuan Yang","Luc Van Gool","Nicu Sebe"],"url":"https://arxiv.org/abs/2504.14249"}
{"created":"2025-04-22","title":"A Pre-Training and Adaptive Fine-Tuning Framework for Graph Anomaly Detection","abstract":"Graph anomaly detection (GAD) has garnered increasing attention in recent years, yet it remains challenging due to the scarcity of abnormal nodes and the high cost of label annotations. Graph pre-training, the two-stage learning paradigm, has emerged as an effective approach for label-efficient learning, largely benefiting from expressive neighborhood aggregation under the assumption of strong homophily. However, in GAD, anomalies typically exhibit high local heterophily, while normal nodes retain strong homophily, resulting in a complex homophily-heterophily mixture. To understand the impact of this mixed pattern on graph pre-training, we analyze it through the lens of spectral filtering and reveal that relying solely on a global low-pass filter is insufficient for GAD. We further provide a theoretical justification for the necessity of selectively applying appropriate filters to individual nodes. Building upon this insight, we propose PAF, a Pre-Training and Adaptive Fine-tuning framework specifically designed for GAD. In particular, we introduce joint training with low- and high-pass filters in the pre-training phase to capture the full spectrum of frequency information in node features. During fine-tuning, we devise a gated fusion network that adaptively combines node representations generated by both filters. Extensive experiments across ten benchmark datasets consistently demonstrate the effectiveness of PAF.","authors":["Yunhui Liu","Jiashun Cheng","Jia Li","Fugee Tsung","Hongzhi Yin","Tieke He"],"url":"https://arxiv.org/abs/2504.14250"}
{"created":"2025-04-22","title":"A New Impossibility Result for Online Bipartite Matching Problems","abstract":"Online Bipartite Matching with random user arrival is a fundamental problem in the online advertisement ecosystem. Over the last 30 years, many algorithms and impossibility results have been developed for this problem. In particular, the latest impossibility result was established by Manshadi, Oveis Gharan and Saberi in 2011. Since then, several algorithms have been published in an effort to narrow the gap between the upper and the lower bounds on the competitive ratio.","authors":["Flavio Chierichetti","Mirko Giacchini","Alessandro Panconesi","Andrea Vattani"],"url":"https://arxiv.org/abs/2504.14251"}
{"created":"2025-04-22","title":"Ordered Completion for Non-Locally Tight mini-gringo Programs","abstract":"Completion is a well-known transformation that captures the stable model semantics of logic programs by turning a program into a set of first-order definitions. Stable models are models of the completion, but not all models of the completion are stable models. For tight programs (programs without positive recursion) the two semantics coincide. Recently this correspondence was extended to locally tight programs, which avoid non-terminating recursion. However, unlike tightness, local tightness cannot be checked with simple syntactic methods. Completion is crucial for verifying answer set programs, especially for external equivalence: a form of equivalence based on selected output predicates under certain inputs. Standard equivalence and adherence to a first-order specification are special cases of external equivalence. The anthem verification tool has two limitations for checking external equivalence: (1) there is no way to check local tightness automatically, and (2) it is not possible to verify programs that are not locally tight. Therefore, alternatives to completion are of interest. This thesis investigates ordered completion, introduced in [Asuncion et al., 2012], which captures stable models of arbitrary logic programs, but only for finite models. This work extends ordered completion to the mini-gringo language (a subset of the language used by the clingo solver). Additionally, it introduces a modification of ordered completion to handle infinite stable models. This extended ordered completion is implemented in anthem as a translation, and initial experiments demonstrate its use for verifying simple logic programs.","authors":["Jan Heuer"],"url":"https://arxiv.org/abs/2504.14252"}
{"created":"2025-04-22","title":"ColorVein: Colorful Cancelable Vein Biometrics","abstract":"Vein recognition technologies have become one of the primary solutions for high-security identification systems. However, the issue of biometric information leakage can still pose a serious threat to user privacy and anonymity. Currently, there is no cancelable biometric template generation scheme specifically designed for vein biometrics. Therefore, this paper proposes an innovative cancelable vein biometric generation scheme: ColorVein. Unlike previous cancelable template generation schemes, ColorVein does not destroy the original biometric features and introduces additional color information to grayscale vein images. This method significantly enhances the information density of vein images by transforming static grayscale information into dynamically controllable color representations through interactive colorization. ColorVein allows users/administrators to define a controllable pseudo-random color space for grayscale vein images by editing the position, number, and color of hint points, thereby generating protected cancelable templates. Additionally, we propose a new secure center loss to optimize the training process of the protected feature extraction model, effectively increasing the feature distance between enrolled users and any potential impostors. Finally, we evaluate ColorVein's performance on all types of vein biometrics, including recognition performance, unlinkability, irreversibility, and revocability, and conduct security and privacy analyses. ColorVein achieves competitive performance compared with state-of-the-art methods.","authors":["Yifan Wang","Jie Gui","Xinli Shi","Linqing Gui","Yuan Yan Tang","James Tin-Yau Kwok"],"url":"https://arxiv.org/abs/2504.14253"}
{"created":"2025-04-22","title":"Visual Consensus Prompting for Co-Salient Object Detection","abstract":"Existing co-salient object detection (CoSOD) methods generally employ a three-stage architecture (i.e., encoding, consensus extraction & dispersion, and prediction) along with a typical full fine-tuning paradigm. Although they yield certain benefits, they exhibit two notable limitations: 1) This architecture relies on encoded features to facilitate consensus extraction, but the meticulously extracted consensus does not provide timely guidance to the encoding stage. 2) This paradigm involves globally updating all parameters of the model, which is parameter-inefficient and hinders the effective representation of knowledge within the foundation model for this task. Therefore, in this paper, we propose an interaction-effective and parameter-efficient concise architecture for the CoSOD task, addressing two key limitations. It introduces, for the first time, a parameter-efficient prompt tuning paradigm and seamlessly embeds consensus into the prompts to formulate task-specific Visual Consensus Prompts (VCP). Our VCP aims to induce the frozen foundation model to perform better on CoSOD tasks by formulating task-specific visual consensus prompts with minimized tunable parameters. Concretely, the primary insight of the purposeful Consensus Prompt Generator (CPG) is to enforce limited tunable parameters to focus on co-salient representations and generate consensus prompts. The formulated Consensus Prompt Disperser (CPD) leverages consensus prompts to form task-specific visual consensus prompts, thereby arousing the powerful potential of pre-trained models in addressing CoSOD tasks. Extensive experiments demonstrate that our concise VCP outperforms 13 cutting-edge full fine-tuning models, achieving the new state of the art (with 6.8% improvement in F_m metrics on the most challenging CoCA dataset). Source code has been available at https://github.com/WJ-CV/VCP.","authors":["Jie Wang","Nana Yu","Zihao Zhang","Yahong Han"],"url":"https://arxiv.org/abs/2504.14254"}
{"created":"2025-04-22","title":"Maker-Maker games of rank 4 are PSPACE-complete","abstract":"The Maker-Maker convention of positional games is played on a hypergraph whose edges are interpreted as winning sets. Two players take turns picking a previously unpicked vertex, aiming at being first to pick all the vertices of some edge. Optimal play can only lead to a first player win or a draw, and deciding between the two is known to be PSPACE-complete even for 6-uniform hypergraphs. We establish PSPACE-completeness for hypergraphs of rank 4. As an intermediary, we use the recently introduced achievement positional games, a more general convention in which each player has their own winning sets (blue and red). We show that deciding whether the blue player has a winning strategy as the first player is PSPACE-complete even with blue edges of size 2 or 3 and pairwise disjoint red edges of size 2. The result for hypergraphs of rank 4 in the Maker-Maker convention follows as a simple corollary.","authors":["Florian Galliot","Jonas S\\'enizergues"],"url":"https://arxiv.org/abs/2504.14256"}
{"created":"2025-04-22","title":"HoLa: B-Rep Generation using a Holistic Latent Representation","abstract":"We introduce a novel representation for learning and generating Computer-Aided Design (CAD) models in the form of $\\textit{boundary representations}$ (B-Reps). Our representation unifies the continuous geometric properties of B-Rep primitives in different orders (e.g., surfaces and curves) and their discrete topological relations in a $\\textit{holistic latent}$ (HoLa) space. This is based on the simple observation that the topological connection between two surfaces is intrinsically tied to the geometry of their intersecting curve. Such a prior allows us to reformulate topology learning in B-Reps as a geometric reconstruction problem in Euclidean space. Specifically, we eliminate the presence of curves, vertices, and all the topological connections in the latent space by learning to distinguish and derive curve geometries from a pair of surface primitives via a neural intersection network. To this end, our holistic latent space is only defined on surfaces but encodes a full B-Rep model, including the geometry of surfaces, curves, vertices, and their topological relations. Our compact and holistic latent space facilitates the design of a first diffusion-based generator to take on a large variety of inputs including point clouds, single/multi-view images, 2D sketches, and text prompts. Our method significantly reduces ambiguities, redundancies, and incoherences among the generated B-Rep primitives, as well as training complexities inherent in prior multi-step B-Rep learning pipelines, while achieving greatly improved validity rate over current state of the art: 82% vs. $\\approx$50%.","authors":["Yilin Liu","Duoteng Xu","Xingyao Yu","Xiang Xu","Daniel Cohen-Or","Hao Zhang","Hui Huang"],"url":"https://arxiv.org/abs/2504.14257"}
{"created":"2025-04-22","title":"Temporal Graph Realization With Bounded Stretch","abstract":"A periodic temporal graph, in its simplest form, is a graph in which every edge appears exactly once in the first $\\Delta$ time steps, and then it reappears recurrently every $\\Delta$ time steps, where $\\Delta$ is a given period length. This model offers a natural abstraction of transportation networks where each transportation link connects two destinations periodically. From a network design perspective, a crucial task is to assign the time-labels on the edges in a way that optimizes some criterion. In this paper we introduce a very natural optimality criterion that captures how the temporal distances of all vertex pairs are `stretched', compared to their physical distances, i.e. their distances in the underlying static (non-temporal) graph. Given a static graph $G$, the task is to assign to each edge one time-label between 1 and $\\Delta$ such that, in the resulting periodic temporal graph with period~$\\Delta$, the duration of the fastest temporal path from any vertex $u$ to any other vertex $v$ is at most $\\alpha$ times the distance between $u$ and $v$ in $G$. Here, the value of $\\alpha$ measures how much the shortest paths are allowed to be \\emph{stretched} once we assign the periodic time-labels.","authors":["George B. Mertzios","Hendrik Molter","Nils Morawietz","Paul G. Spirakis"],"url":"https://arxiv.org/abs/2504.14258"}
{"created":"2025-04-22","title":"Experience-based Refinement of Task Planning Knowledge in Autonomous Robots","abstract":"The requirement for autonomous robots to exhibit higher-level cognitive skills by planning and adapting in an ever-changing environment is indeed a great challenge for the AI community. Progress has been made in the automated planning community on refinement and repair of an agent's symbolic knowledge to do task planning in an incomplete or changing environmental model, but these advances up to now have not been transferred to real physical robots. This paper demonstrates how a physical robot can be capable of adapting its symbolic knowledge of the environment, by using experiences in robot action execution to drive knowledge refinement and hence to improve the success rate of the task plans the robot creates. To implement more robust planning systems, we propose a method for refining domain knowledge to improve the knowledge on which intelligent robot behavior is based. This architecture has been implemented and evaluated using a NAO robot. The refined knowledge leads to the future synthesis of task plans which demonstrate decreasing rates of failure over time as faulty knowledge is removed or adjusted.","authors":["Hadeel Jazzaa","Thomas McCluskey","David Peebles"],"url":"https://arxiv.org/abs/2504.14259"}
{"created":"2025-04-22","title":"Cross-attention for State-based model RWKV-7","abstract":"We introduce CrossWKV, a novel cross-attention mechanism for the state-based RWKV-7 model, designed to enhance the expressive power of text-to-image generation. Leveraging RWKV-7's linear-complexity Weighted Key-Value (WKV) architecture, CrossWKV integrates text and image modalities in a single pass, utilizing a generalized delta rule with vector-valued gating and low-rank adaptations (LoRA) to achieve superior cross-modal alignment. Unlike Transformer-based models, CrossWKV's non-diagonal, input-dependent transition matrix enables it to represent complex functions beyond the $\\mathrm{TC}^0$ complexity class, including all regular languages, as demonstrated by its ability to perform state-tracking tasks like $S_5$ permutation modeling. Evaluated within the Diffusion in RWKV-7 (DIR-7) on datasets such as LAION-5B and ImageNet, CrossWKV achieves a Frechet Inception Distance (FID) of 2.88 and a CLIP score of 0.33 on ImageNet 256x256, matching state-of-the-art performance while offering robust generalization across diverse prompts. The model's enhanced expressivity, combined with constant memory usage and linear scaling, positions it as a powerful solution for advanced cross-modal tasks, with potential applications in high-resolution generation and dynamic state manipulation.Code at https://github.com/TorchRWKV/flash-linear-attention","authors":["Liu Xiao","Li Zhiyuan","Lin Yueyu"],"url":"https://arxiv.org/abs/2504.14260"}
{"created":"2025-04-22","title":"Sparse Superposition Codes with Binomial Dictionary are Capacity-Achieving with Maximum Likelihood Decoding","abstract":"It is known that sparse superposition codes asymptotically achieve the channel capacity over the additive white Gaussian noise channel with both maximum likelihood decoding and efficient decoding (Joseph and Barron in 2012, 2014). Takeishi et al. (in 2014, 2019) demonstrated that these codes can also asymptotically achieve the channel capacity with maximum likelihood decoding when the dictionary is drawn from a Bernoulli distribution. In this paper, we extend these results by showing that the dictionary distribution can be naturally generalized to the binomial distribution.","authors":["Yoshinari Takeishi","Jun'ichi Takeuchi"],"url":"https://arxiv.org/abs/2504.14262"}
{"created":"2025-04-22","title":"Generative emulation of chaotic dynamics with coherent prior","abstract":"Data-driven emulation of nonlinear dynamics is challenging due to long-range skill decay that often produces physically unrealistic outputs. Recent advances in generative modeling aim to address these issues by providing uncertainty quantification and correction. However, the quality of generated simulation remains heavily dependent on the choice of conditioning priors. In this work, we present an efficient generative framework for dynamics emulation, unifying principles of turbulence with diffusion-based modeling: Cohesion. Specifically, our method estimates large-scale coherent structure of the underlying dynamics as guidance during the denoising process, where small-scale fluctuation in the flow is then resolved. These coherent priors are efficiently approximated using reduced-order models, such as deep Koopman operators, that allow for rapid generation of long prior sequences while maintaining stability over extended forecasting horizon. With this gain, we can reframe forecasting as trajectory planning, a common task in reinforcement learning, where conditional denoising is performed once over entire sequences, minimizing the computational cost of autoregressive-based generative methods. Empirical evaluations on chaotic systems of increasing complexity, including Kolmogorov flow, shallow water equations, and subseasonal-to-seasonal climate dynamics, demonstrate Cohesion superior long-range forecasting skill that can efficiently generate physically-consistent simulations, even in the presence of partially-observed guidance.","authors":["Juan Nathaniel","Pierre Gentine"],"url":"https://arxiv.org/abs/2504.14264"}
{"created":"2025-04-22","title":"Text-Audio-Visual-conditioned Diffusion Model for Video Saliency Prediction","abstract":"Video saliency prediction is crucial for downstream applications, such as video compression and human-computer interaction. With the flourishing of multimodal learning, researchers started to explore multimodal video saliency prediction, including audio-visual and text-visual approaches. Auditory cues guide the gaze of viewers to sound sources, while textual cues provide semantic guidance for understanding video content. Integrating these complementary cues can improve the accuracy of saliency prediction. Therefore, we attempt to simultaneously analyze visual, auditory, and textual modalities in this paper, and propose TAVDiff, a Text-Audio-Visual-conditioned Diffusion Model for video saliency prediction. TAVDiff treats video saliency prediction as an image generation task conditioned on textual, audio, and visual inputs, and predicts saliency maps through stepwise denoising. To effectively utilize text, a large multimodal model is used to generate textual descriptions for video frames and introduce a saliency-oriented image-text response (SITR) mechanism to generate image-text response maps. It is used as conditional information to guide the model to localize the visual regions that are semantically related to the textual description. Regarding the auditory modality, it is used as another conditional information for directing the model to focus on salient regions indicated by sounds. At the same time, since the diffusion transformer (DiT) directly concatenates the conditional information with the timestep, which may affect the estimation of the noise level. To achieve effective conditional guidance, we propose Saliency-DiT, which decouples the conditional information from the timestep. Experimental results show that TAVDiff outperforms existing methods, improving 1.03\\%, 2.35\\%, 2.71\\% and 0.33\\% on SIM, CC, NSS and AUC-J metrics, respectively.","authors":["Li Yu","Xuanzhe Sun","Wei Zhou","Moncef Gabbouj"],"url":"https://arxiv.org/abs/2504.14267"}
{"created":"2025-04-22","title":"Mixed-Precision Conjugate Gradient Solvers with RL-Driven Precision Tuning","abstract":"This paper presents a novel reinforcement learning (RL) framework for dynamically optimizing numerical precision in the preconditioned conjugate gradient (CG) method. By modeling precision selection as a Markov Decision Process (MDP), we employ Q-learning to adaptively assign precision levels to key operations, striking an optimal balance between computational efficiency and numerical accuracy, while ensuring stability through double-precision scalar computations and residual computing. In practice, the algorithm is trained on a set of data and subsequently performs inference for precision selection on out-of-sample data, without requiring re-analysis or retraining for new datasets. This enables the method to adapt seamlessly to new problem instances without the computational overhead of recalibration. Our results demonstrate the effectiveness of RL in enhancing solver's performance, marking the first application of RL to mixed-precision numerical methods. The findings highlight the approach's practical advantages, robustness, and scalability, providing valuable insights into its integration with iterative solvers and paving the way for AI-driven advancements in scientific computing.","authors":["Xinye Chen"],"url":"https://arxiv.org/abs/2504.14268"}
{"created":"2025-04-22","title":"Recognition of Frequencies of Short-Time SSVEP Signals Utilizing an SSCCA-Based Spatio-Spectral Feature Fusion Framework","abstract":"A brain-computer interface (BCI) facilitates direct communication between the brain and external equipment through EEG, which is preferred for its superior temporal resolution. Among EEG techniques, the steady-state visual evoked potential (SSVEP) is favored due to its robust signal-to-noise ratio, minimal training demands, and elevated information transmission rate. Frequency detection in SSVEP-based brain-computer interfaces commonly employs canonical correlation analysis (CCA). SSCCA (spatio-spectral canonical correlation analysis) augments CCA by refining spatial filtering. This paper presents a multistage feature fusion methodology for short-duration SSVEP frequency identification, employing SSCCA with template signals derived via leave-one-out cross-validation (LOOCV). A filterbank generates bandpass filters for stimulus frequencies and their harmonics, whereas SSCCA calculates correlation coefficients between subbands and templates. Two phases of non-linear weighting amalgamate these coefficients to discern the target stimulus. This multistage methodology surpasses traditional techniques, attaining a accuracy of 94.5%.","authors":["Saif Bashar","Samia Nasir Nira","Shabbir Mahmood","Md. Humaun Kabir","Sujit Roy","Iffat Farhana"],"url":"https://arxiv.org/abs/2504.14269"}
{"created":"2025-04-22","title":"Convergence Laws for Extensions of First-Order Logic with Averaging","abstract":"For many standard models of random structure, first-order logic sentences exhibit a convergence phenomenon on random inputs. The most well-known example is for random graphs with constant edge probability, where the probabilities of first-order sentences converge to 0 or 1. In other cases, such as certain ``sparse random graph'' models, the probabilities of sentences converge, although not necessarily to 0 or 1. In this work we deal with extensions of first-order logic with aggregate operators, variations of averaging. These logics will consist of real-valued terms, and we allow arbitrary Lipschitz functions to be used as ``connectives''. We show that some of the well-known convergence laws extend to this setting.","authors":["Sam Adam-Day","Michael Benedikt","Alberto Larrauri"],"url":"https://arxiv.org/abs/2504.14270"}
{"created":"2025-04-22","title":"Can AI Recognize the Style of Art? Analyzing Aesthetics through the Lens of Style Transfer","abstract":"This study investigates how artificial intelligence (AI) recognizes style through style transfer-an AI technique that generates a new image by applying the style of one image to another. Despite the considerable interest that style transfer has garnered among researchers, most efforts have focused on enhancing the quality of output images through advanced AI algorithms. In this paper, we approach style transfer from an aesthetic perspective, thereby bridging AI techniques and aesthetics. We analyze two style transfer algorithms: one based on convolutional neural networks (CNNs) and the other utilizing recent Transformer models. By comparing the images produced by each, we explore the elements that constitute the style of artworks through an aesthetic analysis of the style transfer results. We then elucidate the limitations of current style transfer techniques. Based on these limitations, we propose potential directions for future research on style transfer techniques.","authors":["Yunha Yeo","Daeho Um"],"url":"https://arxiv.org/abs/2504.14272"}
{"created":"2025-04-22","title":"ProtPainter: Draw or Drag Protein via Topology-guided Diffusion","abstract":"Recent advances in protein backbone generation have achieved promising results under structural, functional, or physical constraints. However, existing methods lack the flexibility for precise topology control, limiting navigation of the backbone space. We present ProtPainter, a diffusion-based approach for generating protein backbones conditioned on 3D curves. ProtPainter follows a two-stage process: curve-based sketching and sketch-guided backbone generation. For the first stage, we propose CurveEncoder, which predicts secondary structure annotations from a curve to parametrize sketch generation. For the second stage, the sketch guides the generative process in Denoising Diffusion Probabilistic Modeling (DDPM) to generate backbones. During this process, we further introduce a fusion scheduling scheme, Helix-Gating, to control the scaling factors. To evaluate, we propose the first benchmark for topology-conditioned protein generation, introducing Protein Restoration Task and a new metric, self-consistency Topology Fitness (scTF). Experiments demonstrate ProtPainter's ability to generate topology-fit (scTF > 0.8) and designable (scTM > 0.5) backbones, with drawing and dragging tasks showcasing its flexibility and versatility.","authors":["Zhengxi Lu","Shizhuo Cheng","Yuru Jiang","Yan Zhang","Min Zhang"],"url":"https://arxiv.org/abs/2504.14274"}
{"created":"2025-04-22","title":"RAMCT: Novel Region-adaptive Multi-channel Tracker with Iterative Tikhonov Regularization for Thermal Infrared Tracking","abstract":"Correlation filter (CF)-based trackers have gained significant attention for their computational efficiency in thermal infrared (TIR) target tracking. However, ex-isting methods struggle with challenges such as low-resolution imagery, occlu-sion, background clutter, and target deformation, which severely impact tracking performance. To overcome these limitations, we propose RAMCT, a region-adaptive sparse correlation filter tracker that integrates multi-channel feature opti-mization with an adaptive regularization strategy. Firstly, we refine the CF learn-ing process by introducing a spatially adaptive binary mask, which enforces spar-sity in the target region while dynamically suppressing background interference. Secondly, we introduce generalized singular value decomposition (GSVD) and propose a novel GSVD-based region-adaptive iterative Tikhonov regularization method. This enables flexible and robust optimization across multiple feature channels, improving resilience to occlusion and background variations. Thirdly, we propose an online optimization strategy with dynamic discrepancy-based pa-rameter adjustment. This mechanism facilitates real time adaptation to target and background variations, thereby improving tracking accuracy and robustness. Ex-tensive experiments on LSOTB-TIR, PTB-TIR, VOT-TIR2015, and VOT-TIR2017 benchmarks demonstrate that RAMCT outperforms other state-of-the-art trackers in terms of accuracy and robustness.","authors":["Shang Zhang","Yuke Hou","Guoqiang Gong","Ruoyan Xiong","Yue Zhang"],"url":"https://arxiv.org/abs/2504.14278"}
{"created":"2025-04-22","title":"CLIP-Powered Domain Generalization and Domain Adaptation: A Comprehensive Survey","abstract":"As machine learning evolves, domain generalization (DG) and domain adaptation (DA) have become crucial for enhancing model robustness across diverse environments. Contrastive Language-Image Pretraining (CLIP) plays a significant role in these tasks, offering powerful zero-shot capabilities that allow models to perform effectively in unseen domains. However, there remains a significant gap in the literature, as no comprehensive survey currently exists that systematically explores the applications of CLIP in DG and DA, highlighting the necessity for this review. This survey presents a comprehensive review of CLIP's applications in DG and DA. In DG, we categorize methods into optimizing prompt learning for task alignment and leveraging CLIP as a backbone for effective feature extraction, both enhancing model adaptability. For DA, we examine both source-available methods utilizing labeled source data and source-free approaches primarily based on target domain data, emphasizing knowledge transfer mechanisms and strategies for improved performance across diverse contexts. Key challenges, including overfitting, domain diversity, and computational efficiency, are addressed, alongside future research opportunities to advance robustness and efficiency in practical applications. By synthesizing existing literature and pinpointing critical gaps, this survey provides valuable insights for researchers and practitioners, proposing directions for effectively leveraging CLIP to enhance methodologies in domain generalization and adaptation. Ultimately, this work aims to foster innovation and collaboration in the quest for more resilient machine learning models that can perform reliably across diverse real-world scenarios. A more up-to-date version of the papers is maintained at: https://github.com/jindongli-Ai/Survey_on_CLIP-Powered_Domain_Generalization_and_Adaptation.","authors":["Jindong Li","Yongguang Li","Yali Fu","Jiahong Liu","Yixin Liu","Menglin Yang","Irwin King"],"url":"https://arxiv.org/abs/2504.14280"}
{"created":"2025-04-22","title":"CHAINSFORMER: Numerical Reasoning on Knowledge Graphs from a Chain Perspective","abstract":"Reasoning over Knowledge Graphs (KGs) plays a pivotal role in knowledge graph completion or question answering systems, providing richer and more accurate triples and attributes. As numerical attributes become increasingly essential in characterizing entities and relations in KGs, the ability to reason over these attributes has gained significant importance. Existing graph-based methods such as Graph Neural Networks (GNNs) and Knowledge Graph Embeddings (KGEs), primarily focus on aggregating homogeneous local neighbors and implicitly embedding diverse triples. However, these approaches often fail to fully leverage the potential of logical paths within the graph, limiting their effectiveness in exploiting the reasoning process. To address these limitations, we propose ChainsFormer, a novel chain-based framework designed to support numerical reasoning. Chainsformer not only explicitly constructs logical chains but also expands the reasoning depth to multiple hops. Specially, we introduces Relation-Attribute Chains (RA-Chains), a specialized logic chain, to model sequential reasoning patterns. ChainsFormer captures the step-by-step nature of multi-hop reasoning along RA-Chains by employing sequential in-context learning. To mitigate the impact of noisy chains, we propose a hyperbolic affinity scoring mechanism that selects relevant logic chains in a variable-resolution space. Furthermore, ChainsFormer incorporates an attention-based numerical reasoner to identify critical reasoning paths, enhancing both reasoning accuracy and transparency. Experimental results demonstrate that ChainsFormer significantly outperforms state-of-the-art methods, achieving up to a 20.0% improvement in performance. The implementations are available at https://github.com/zhaodazhuang2333/ChainsFormer.","authors":["Ze Zhao","Bin Lu","Xiaoying Gan","Gu Tang","Luoyi Fu","Xinbing Wang"],"url":"https://arxiv.org/abs/2504.14282"}
{"created":"2025-04-22","title":"Cyclic Proofs in Hoare Logic and its Reverse","abstract":"We examine the relationships between axiomatic and cyclic proof systems for the partial and total versions of Hoare logic and those of its dual, known as reverse Hoare logic (or sometimes incorrectness logic). In the axiomatic proof systems for these logics, the proof rules for looping constructs involve an explicit loop invariant, which in the case of the total versions additionally require a well-founded termination measure. In the cyclic systems, these are replaced by rules that simply unroll the loops, together with a principle allowing the formation of cycles in the proof, subject to a global soundness condition that ensures the well-foundedness of the circular reasoning. Interestingly, the cyclic soundness conditions for partial Hoare logic and its reverse are similar and essentially coinductive in character, while those for the total versions are also similar and essentially inductive. We show that these cyclic systems are sound, by direct argument, and relatively complete, by translation from axiomatic to cyclic proofs.","authors":["James Brotherston","Quang Loc Le","Gauri Desai","Yukihiro Oda"],"url":"https://arxiv.org/abs/2504.14283"}
{"created":"2025-04-22","title":"SRPO: A Cross-Domain Implementation of Large-Scale Reinforcement Learning on LLM","abstract":"Recent advances of reasoning models, exemplified by OpenAI's o1 and DeepSeek's R1, highlight the significant potential of Reinforcement Learning (RL) to enhance the reasoning capabilities of Large Language Models (LLMs). However, replicating these advancements across diverse domains remains challenging due to limited methodological transparency. In this work, we present two-Staged history-Resampling Policy Optimization (SRPO), which successfully surpasses the performance of DeepSeek-R1-Zero-32B on the AIME24 and LiveCodeBench benchmarks. SRPO achieves this using the same base model as DeepSeek (i.e. Qwen2.5-32B) and relies solely on RL, without prior Supervised Fine-Tuning (SFT). Building upon Group Relative Policy Optimization (GRPO), we introduce two key methodological innovations: (1) a two-stage cross-domain training paradigm designed to balance the development of mathematical reasoning and coding proficiency, and (2) History Resampling (HR), a technique to address ineffective samples. Our comprehensive experiments validate the effectiveness of our approach, dedicating to offer valuable insights into scaling LLM reasoning capabilities across diverse tasks.","authors":["Xiaojiang Zhang","Jinghui Wang","Zifei Cheng","Wenhao Zhuang","Zheng Lin","Minglei Zhang","Shaojie Wang","Yinghan Cui","Chao Wang","Junyi Peng","Shimiao Jiang","Shiqi Kuang","Shouyu Yin","Chaohang Wen","Haotian Zhang","Bin Chen","Bing Yu"],"url":"https://arxiv.org/abs/2504.14286"}
{"created":"2025-04-22","title":"Probing the Subtle Ideological Manipulation of Large Language Models","abstract":"Large Language Models (LLMs) have transformed natural language processing, but concerns have emerged about their susceptibility to ideological manipulation, particularly in politically sensitive areas. Prior work has focused on binary Left-Right LLM biases, using explicit prompts and fine-tuning on political QA datasets. In this work, we move beyond this binary approach to explore the extent to which LLMs can be influenced across a spectrum of political ideologies, from Progressive-Left to Conservative-Right. We introduce a novel multi-task dataset designed to reflect diverse ideological positions through tasks such as ideological QA, statement ranking, manifesto cloze completion, and Congress bill comprehension. By fine-tuning three LLMs-Phi-2, Mistral, and Llama-3-on this dataset, we evaluate their capacity to adopt and express these nuanced ideologies. Our findings indicate that fine-tuning significantly enhances nuanced ideological alignment, while explicit prompts provide only minor refinements. This highlights the models' susceptibility to subtle ideological manipulation, suggesting a need for more robust safeguards to mitigate these risks.","authors":["Demetris Paschalides","George Pallis","Marios D. Dikaiakos"],"url":"https://arxiv.org/abs/2504.14287"}
{"created":"2025-04-22","title":"ISTD-YOLO: A Multi-Scale Lightweight High-Performance Infrared Small Target Detection Algorithm","abstract":"Aiming at the detection difficulties of infrared images such as complex background, low signal-to-noise ratio, small target size and weak brightness, a lightweight infrared small target detection algorithm ISTD-YOLO based on improved YOLOv7 was proposed. Firstly, the YOLOv7 network structure was lightweight reconstructed, and a three-scale lightweight network architecture was designed. Then, the ELAN-W module of the model neck network is replaced by VoV-GSCSP to reduce the computational cost and the complexity of the network structure. Secondly, a parameter-free attention mechanism was introduced into the neck network to enhance the relevance of local con-text information. Finally, the Normalized Wasserstein Distance (NWD) was used to optimize the commonly used IoU index to enhance the localization and detection accuracy of small targets. Experimental results show that compared with YOLOv7 and the current mainstream algorithms, ISTD-YOLO can effectively improve the detection effect, and all indicators are effectively improved, which can achieve high-quality detection of infrared small targets.","authors":["Shang Zhang","Yujie Cui","Ruoyan Xiong","Huanbin Zhang"],"url":"https://arxiv.org/abs/2504.14289"}
{"created":"2025-04-22","title":"Towards NSFW-Free Text-to-Image Generation via Safety-Constraint Direct Preference Optimization","abstract":"Ensuring the safety of generated content remains a fundamental challenge for Text-to-Image (T2I) generation. Existing studies either fail to guarantee complete safety under potentially harmful concepts or struggle to balance safety with generation quality. To address these issues, we propose Safety-Constrained Direct Preference Optimization (SC-DPO), a novel framework for safety alignment in T2I models. SC-DPO integrates safety constraints into the general human preference calibration, aiming to maximize the likelihood of generating human-preferred samples while minimizing the safety cost of the generated outputs. In SC-DPO, we introduce a safety cost model to accurately quantify harmful levels for images, and train it effectively using the proposed contrastive learning and cost anchoring objectives. To apply SC-DPO for effective T2I safety alignment, we constructed SCP-10K, a safety-constrained preference dataset containing rich harmful concepts, which blends safety-constrained preference pairs under both harmful and clean instructions, further mitigating the trade-off between safety and sample quality. Additionally, we propose a Dynamic Focusing Mechanism (DFM) for SC-DPO, promoting the model's learning of difficult preference pair samples. Extensive experiments demonstrate that SC-DPO outperforms existing methods, effectively defending against various NSFW content while maintaining optimal sample quality and human preference alignment. Additionally, SC-DPO exhibits resilience against adversarial prompts designed to generate harmful content.","authors":["Shouwei Ruan","Zhenyu Wu","Yao Huang","Ruochen Zhang","Yitong Sun","Caixin Kang","Xingxing Wei"],"url":"https://arxiv.org/abs/2504.14290"}
{"created":"2025-04-22","title":"From Missing Pieces to Masterpieces: Image Completion with Context-Adaptive Diffusion","abstract":"Image completion is a challenging task, particularly when ensuring that generated content seamlessly integrates with existing parts of an image. While recent diffusion models have shown promise, they often struggle with maintaining coherence between known and unknown (missing) regions. This issue arises from the lack of explicit spatial and semantic alignment during the diffusion process, resulting in content that does not smoothly integrate with the original image. Additionally, diffusion models typically rely on global learned distributions rather than localized features, leading to inconsistencies between the generated and existing image parts. In this work, we propose ConFill, a novel framework that introduces a Context-Adaptive Discrepancy (CAD) model to ensure that intermediate distributions of known and unknown regions are closely aligned throughout the diffusion process. By incorporating CAD, our model progressively reduces discrepancies between generated and original images at each diffusion step, leading to contextually aligned completion. Moreover, ConFill uses a new Dynamic Sampling mechanism that adaptively increases the sampling rate in regions with high reconstruction complexity. This approach enables precise adjustments, enhancing detail and integration in restored areas. Extensive experiments demonstrate that ConFill outperforms current methods, setting a new benchmark in image completion.","authors":["Pourya Shamsolmoali","Masoumeh Zareapoor","Huiyu Zhou","Michael Felsberg","Dacheng Tao","Xuelong Li"],"url":"https://arxiv.org/abs/2504.14294"}
{"created":"2025-04-22","title":"Time discretization in convected linearized thermo-visco-elastodynamics at large displacements","abstract":"The fully-implicit time discretization (i.e. the backward Euler formula) is applied to compressible nonlinear dynamical models of thermo-viscoelastic solids in the Eulerian description, i.e. in the actual deforming configuration, formulated in terms of rates. The Kelvin-Voigt rheology or also, in the deviatoric part, the Jeffreys rheology (covering creep or plasticity) are considered, using the additive Green-Naghdi's decomposition of total strain into the elastic and the inelastic strains formulated in terms of (objective) rates exploiting the Zaremba-Jaumann time derivative. A linearized convective model at large displacements is considered, focusing on the case where the internal energy additively splits the (convex) mechanical and the thermal parts. The time-discrete suitably regularized scheme is devised. The numerical stability and, considering the multipolar 2nd-grade viscosity, also convergence towards weak solutions are proved, exploiting the convexity of the kinetic energy when written in terms of linear momentum instead of velocity and estimating the temperature gradient from the entropy-like inequality.","authors":["Tom\\'a\\v{s} Roub\\'i\\v{c}ek"],"url":"https://arxiv.org/abs/2504.14297"}
{"created":"2025-04-22","title":"RadioDiff-Inverse: Diffusion Enhanced Bayesian Inverse Estimation for ISAC Radio Map Construction","abstract":"Radio maps (RMs) are essential for environment-aware communication and sensing, providing location-specific wireless channel information. Existing RM construction methods often rely on precise environmental data and base station (BS) locations, which are not always available in dynamic or privacy-sensitive environments. While sparse measurement techniques reduce data collection, the impact of noise in sparse data on RM accuracy is not well understood. This paper addresses these challenges by formulating RM construction as a Bayesian inverse problem under coarse environmental knowledge and noisy sparse measurements. Although maximum a posteriori (MAP) filtering offers an optimal solution, it requires a precise prior distribution of the RM, which is typically unavailable. To solve this, we propose RadioDiff-Inverse, a diffusion-enhanced Bayesian inverse estimation framework that uses an unconditional generative diffusion model to learn the RM prior. This approach not only reconstructs the spatial distribution of wireless channel features but also enables environmental structure perception, such as building outlines, and location of BS just relay on pathloss, through integrated sensing and communication (ISAC). Remarkably, RadioDiff-Inverse is training-free, leveraging a pre-trained model from Imagenet without task-specific fine-tuning, which significantly reduces the training cost of using generative large model in wireless networks. Experimental results demonstrate that RadioDiff-Inverse achieves state-of-the-art performance in accuracy of RM construction and environmental reconstruction, and robustness against noisy sparse sampling.","authors":["Xiucheng Wang","Zhongsheng Fang","Nan Cheng"],"url":"https://arxiv.org/abs/2504.14298"}
{"created":"2025-04-22","title":"Learning and Generating Diverse Residential Load Patterns Using GAN with Weakly-Supervised Training and Weight Selection","abstract":"The scarcity of high-quality residential load data can pose obstacles for decarbonizing the residential sector as well as effective grid planning and operation. The above challenges have motivated research into generating synthetic load data, but existing methods faced limitations in terms of scalability, diversity, and similarity. This paper proposes a Generative Adversarial Network-based Synthetic Residential Load Pattern (RLP-GAN) generation model, a novel weakly-supervised GAN framework, leveraging an over-complete autoencoder to capture dependencies within complex and diverse load patterns and learn household-level data distribution at scale. We incorporate a model weight selection method to address the mode collapse problem and generate load patterns with high diversity. We develop a holistic evaluation method to validate the effectiveness of RLP-GAN using real-world data of 417 households. The results demonstrate that RLP-GAN outperforms state-of-the-art models in capturing temporal dependencies and generating load patterns with higher similarity to real data. Furthermore, we have publicly released the RLP-GAN generated synthetic dataset, which comprises one million synthetic residential load pattern profiles.","authors":["Xinyu Liang","Hao Wang"],"url":"https://arxiv.org/abs/2504.14300"}
{"created":"2025-04-22","title":"Balancing Privacy and Action Performance: A Penalty-Driven Approach to Image Anonymization","abstract":"The rapid development of video surveillance systems for object detection, tracking, activity recognition, and anomaly detection has revolutionized our day-to-day lives while setting alarms for privacy concerns. It isn't easy to strike a balance between visual privacy and action recognition performance in most computer vision models. Is it possible to safeguard privacy without sacrificing performance? It poses a formidable challenge, as even minor privacy enhancements can lead to substantial performance degradation. To address this challenge, we propose a privacy-preserving image anonymization technique that optimizes the anonymizer using penalties from the utility branch, ensuring improved action recognition performance while minimally affecting privacy leakage. This approach addresses the trade-off between minimizing privacy leakage and maintaining high action performance. The proposed approach is primarily designed to align with the regulatory standards of the EU AI Act and GDPR, ensuring the protection of personally identifiable information while maintaining action performance. To the best of our knowledge, we are the first to introduce a feature-based penalty scheme that exclusively controls the action features, allowing freedom to anonymize private attributes. Extensive experiments were conducted to validate the effectiveness of the proposed method. The results demonstrate that applying a penalty to anonymizer from utility branch enhances action performance while maintaining nearly consistent privacy leakage across different penalty settings.","authors":["Nazia Aslam","Kamal Nasrollahi"],"url":"https://arxiv.org/abs/2504.14301"}
{"created":"2025-04-22","title":"Learning to Score","abstract":"Common machine learning settings range from supervised tasks, where accurately labeled data is accessible, through semi-supervised and weakly-supervised tasks, where target labels are scant or noisy, to unsupervised tasks where labels are unobtainable. In this paper we study a scenario where the target labels are not available but additional related information is at hand. This information, referred to as Side Information, is either correlated with the unknown labels or imposes constraints on the feature space. We formulate the problem as an ensemble of three semantic components: representation learning, side information and metric learning. The proposed scoring model is advantageous for multiple use-cases. For example, in the healthcare domain it can be used to create a severity score for diseases where the symptoms are known but the criteria for the disease progression are not well defined. We demonstrate the utility of the suggested scoring system on well-known benchmark data-sets and bio-medical patient records.","authors":["Yogev Kriger","Shai Fine"],"url":"https://arxiv.org/abs/2504.14302"}
{"created":"2025-04-22","title":"Adversarial Locomotion and Motion Imitation for Humanoid Policy Learning","abstract":"Humans exhibit diverse and expressive whole-body movements. However, attaining human-like whole-body coordination in humanoid robots remains challenging, as conventional approaches that mimic whole-body motions often neglect the distinct roles of upper and lower body. This oversight leads to computationally intensive policy learning and frequently causes robot instability and falls during real-world execution. To address these issues, we propose Adversarial Locomotion and Motion Imitation (ALMI), a novel framework that enables adversarial policy learning between upper and lower body. Specifically, the lower body aims to provide robust locomotion capabilities to follow velocity commands while the upper body tracks various motions. Conversely, the upper-body policy ensures effective motion tracking when the robot executes velocity-based movements. Through iterative updates, these policies achieve coordinated whole-body control, which can be extended to loco-manipulation tasks with teleoperation systems. Extensive experiments demonstrate that our method achieves robust locomotion and precise motion tracking in both simulation and on the full-size Unitree H1 robot. Additionally, we release a large-scale whole-body motion control dataset featuring high-quality episodic trajectories from MuJoCo simulations deployable on real robots. The project page is https://almi-humanoid.github.io.","authors":["Jiyuan Shi","Xinzhe Liu","Dewei Wang","Ouyang Lu","S\\\"oren Schwertfeger","Fuchun Sun","Chenjia Bai","Xuelong Li"],"url":"https://arxiv.org/abs/2504.14305"}
{"created":"2025-04-22","title":"Exploring Generalizable Pre-training for Real-world Change Detection via Geometric Estimation","abstract":"As an essential procedure in earth observation system, change detection (CD) aims to reveal the spatial-temporal evolution of the observation regions. A key prerequisite for existing change detection algorithms is aligned geo-references between multi-temporal images by fine-grained registration. However, in the majority of real-world scenarios, a prior manual registration is required between the original images, which significantly increases the complexity of the CD workflow. In this paper, we proposed a self-supervision motivated CD framework with geometric estimation, called \"MatchCD\". Specifically, the proposed MatchCD framework utilizes the zero-shot capability to optimize the encoder with self-supervised contrastive representation, which is reused in the downstream image registration and change detection to simultaneously handle the bi-temporal unalignment and object change issues. Moreover, unlike the conventional change detection requiring segmenting the full-frame image into small patches, our MatchCD framework can directly process the original large-scale image (e.g., 6K*4K resolutions) with promising performance. The performance in multiple complex scenarios with significant geometric distortion demonstrates the effectiveness of our proposed framework.","authors":["Yitao Zhao","Sen Lei","Nanqing Liu","Heng-Chao Li","Turgay Celik","Qing Zhu"],"url":"https://arxiv.org/abs/2504.14306"}
{"created":"2025-04-22","title":"Learning from Stochastic Teacher Representations Using Student-Guided Knowledge Distillation","abstract":"Advances in self-distillation have shown that when knowledge is distilled from a teacher to a student using the same deep learning (DL) architecture, the student performance can surpass the teacher particularly when the network is overparameterized and the teacher is trained with early stopping. Alternatively, ensemble learning also improves performance, although training, storing, and deploying multiple models becomes impractical as the number of models grows. Even distilling an ensemble to a single student model or weight averaging methods first requires training of multiple teacher models and does not fully leverage the inherent stochasticity for generating and distilling diversity in DL models. These constraints are particularly prohibitive in resource-constrained or latency-sensitive applications such as wearable devices. This paper proposes to train only one model and generate multiple diverse teacher representations using distillation-time dropout. However, generating these representations stochastically leads to noisy representations that are misaligned with the learned task. To overcome this problem, a novel stochastic self-distillation (SSD) training strategy is introduced for filtering and weighting teacher representation to distill from task-relevant representations only, using student-guided knowledge distillation (SGKD). The student representation at each distillation step is used as authority to guide the distillation process. Experimental results on real-world affective computing, wearable/biosignal datasets from the UCR Archive, the HAR dataset, and image classification datasets show that the proposed SSD method can outperform state-of-the-art methods without increasing the model size at both training and testing time, and incurs negligible computational complexity compared to state-of-the-art ensemble learning and weight averaging methods.","authors":["Muhammad Haseeb Aslam","Clara Martinez","Marco Pedersoli","Alessandro Koerich","Ali Etemad","Eric Granger"],"url":"https://arxiv.org/abs/2504.14307"}
{"created":"2025-04-22","title":"The Schur complements for $SDD_{1}$ matrices and their application to linear complementarity problems","abstract":"In this paper we propose a new scaling method to study the Schur complements of $SDD_{1}$ matrices. Its core is related to the non-negative property of the inverse $M$-matrix, while numerically improving the Quotient formula. Based on the Schur complement and a novel norm splitting manner, we establish an upper bound for the infinity norm of the inverse of $SDD_{1}$ matrices, which depends solely on the original matrix entries. We apply the new bound to derive an error bound for linear complementarity problems of $B_{1}$-matrices. Additionally, new lower and upper bounds for the determinant of $SDD_{1}$ matrices are presented. Numerical experiments validate the effectiveness and superiority of our results.","authors":["Yang Hu","Jianzhou Liu","Wenlong Zeng"],"url":"https://arxiv.org/abs/2504.14308"}
{"created":"2025-04-22","title":"FGSGT: Saliency-Guided Siamese Network Tracker Based on Key Fine-Grained Feature Information for Thermal Infrared Target Tracking","abstract":"Thermal infrared (TIR) images typically lack detailed features and have low contrast, making it challenging for conventional feature extraction models to capture discriminative target characteristics. As a result, trackers are often affected by interference from visually similar objects and are susceptible to tracking drift. To address these challenges, we propose a novel saliency-guided Siamese network tracker based on key fine-grained feature infor-mation. First, we introduce a fine-grained feature parallel learning convolu-tional block with a dual-stream architecture and convolutional kernels of varying sizes. This design captures essential global features from shallow layers, enhances feature diversity, and minimizes the loss of fine-grained in-formation typically encountered in residual connections. In addition, we propose a multi-layer fine-grained feature fusion module that uses bilinear matrix multiplication to effectively integrate features across both deep and shallow layers. Next, we introduce a Siamese residual refinement block that corrects saliency map prediction errors using residual learning. Combined with deep supervision, this mechanism progressively refines predictions, ap-plying supervision at each recursive step to ensure consistent improvements in accuracy. Finally, we present a saliency loss function to constrain the sali-ency predictions, directing the network to focus on highly discriminative fi-ne-grained features. Extensive experiment results demonstrate that the pro-posed tracker achieves the highest precision and success rates on the PTB-TIR and LSOTB-TIR benchmarks. It also achieves a top accuracy of 0.78 on the VOT-TIR 2015 benchmark and 0.75 on the VOT-TIR 2017 benchmark.","authors":["Ruoyan Xiong","Huanbin Zhang","Shentao Wang","Hui He","Yuke Hou","Yue Zhang","Yujie Cui","Huipan Guan","Shang Zhang"],"url":"https://arxiv.org/abs/2504.14309"}
{"created":"2025-04-22","title":"End-Edge Model Collaboration: Bandwidth Allocation for Data Upload and Model Transmission","abstract":"The widespread adoption of large artificial intelligence (AI) models has enabled numerous applications of the Internet of Things (IoT). However, large AI models require substantial computational and memory resources, which exceed the capabilities of resource-constrained IoT devices. End-edge collaboration paradigm is developed to address this issue, where a small model on the end device performs inference tasks, while a large model on the edge server assists with model updates. To improve the accuracy of the inference tasks, the data generated on the end devices will be periodically uploaded to edge serve to update model, and a distilled model of the updated one will be transmitted back to the end device. Subjected to the limited bandwidth for the communication link between the end device and the edge server, it is important to investigate the system should allocate more bandwidth for data upload or model transmission. In this paper, we characterize the impact of data upload and model transmission on inference accuracy. Subsequently, we formulate a bandwidth allocation problem. By solving this problem, we derive an efficient optimization framework for the end-edge collaboration system. The simulation results demonstrate our framework significantly enhances mean average precision (mAP) under various bandwidths and datasizes.","authors":["Dailin Yang","Shuhang Zhang","Hongliang Zhang","Lingyang Song"],"url":"https://arxiv.org/abs/2504.14310"}
{"created":"2025-04-22","title":"DCFG: Diverse Cross-Channel Fine-Grained Feature Learning and Progressive Fusion Siamese Tracker for Thermal Infrared Target Tracking","abstract":"To address the challenge of capturing highly discriminative features in ther-mal infrared (TIR) tracking, we propose a novel Siamese tracker based on cross-channel fine-grained feature learning and progressive fusion. First, we introduce a cross-channel fine-grained feature learning network that employs masks and suppression coefficients to suppress dominant target features, en-abling the tracker to capture more detailed and subtle information. The net-work employs a channel rearrangement mechanism to enhance efficient in-formation flow, coupled with channel equalization to reduce parameter count. Additionally, we incorporate layer-by-layer combination units for ef-fective feature extraction and fusion, thereby minimizing parameter redun-dancy and computational complexity. The network further employs feature redirection and channel shuffling strategies to better integrate fine-grained details. Second, we propose a specialized cross-channel fine-grained loss function designed to guide feature groups toward distinct discriminative re-gions of the target, thus improving overall target representation. This loss function includes an inter-channel loss term that promotes orthogonality be-tween channels, maximizing feature diversity and facilitating finer detail capture. Extensive experiments demonstrate that our proposed tracker achieves the highest accuracy, scoring 0.81 on the VOT-TIR 2015 and 0.78 on the VOT-TIR 2017 benchmark, while also outperforming other methods across all evaluation metrics on the LSOTB-TIR and PTB-TIR benchmarks.","authors":["Ruoyan Xiong","Yuke Hou","Princess Retor Torboh","Hui He","Huanbin Zhang","Yue Zhang","Yanpin Wang","Huipan Guan","Shang Zhang"],"url":"https://arxiv.org/abs/2504.14311"}
{"created":"2025-04-22","title":"Towards Polyglot Data Processing in Social Networks using the Hadoop-Spark ecosystem","abstract":"This article explores the use of the Hadoop-Spark ecosystem for social media data processing, adopting a polyglot approach with the integration of various computation and storage technologies, such as Hive, HBase and GraphX. We discuss specific tasks involved in processing social network data, such as calculating user influence, counting the most frequent terms in messages and identifying social relationships among users and groups. We conducted a series of empirical performance assessments, focusing on executing selected tasks and measuring their execution time within the Hadoop-Spark cluster. These insights offer a detailed quantitative analysis of the performance efficiency of the ecosystem tools. We conclude by highlighting the potential of the Hadoop-Spark ecosystem tools for advancing research in social networks and related fields.","authors":["Antony Seabra","Sergio Lifschitz"],"url":"https://arxiv.org/abs/2504.14314"}
{"created":"2025-04-22","title":"Local distribution-based adaptive oversampling for imbalanced regression","abstract":"Imbalanced regression occurs when continuous target variables have skewed distributions, creating sparse regions that are difficult for machine learning models to predict accurately. This issue particularly affects neural networks, which often struggle with imbalanced data. While class imbalance in classification has been extensively studied, imbalanced regression remains relatively unexplored, with few effective solutions. Existing approaches often rely on arbitrary thresholds to categorize samples as rare or frequent, ignoring the continuous nature of target distributions. These methods can produce synthetic samples that fail to improve model performance and may discard valuable information through undersampling. To address these limitations, we propose LDAO (Local Distribution-based Adaptive Oversampling), a novel data-level approach that avoids categorizing individual samples as rare or frequent. Instead, LDAO learns the global distribution structure by decomposing the dataset into a mixture of local distributions, each preserving its statistical characteristics. LDAO then models and samples from each local distribution independently before merging them into a balanced training set. LDAO achieves a balanced representation across the entire target range while preserving the inherent statistical structure within each local distribution. In extensive evaluations on 45 imbalanced datasets, LDAO outperforms state-of-the-art oversampling methods on both frequent and rare target values, demonstrating its effectiveness for addressing the challenge of imbalanced regression.","authors":["Shayan Alahyari","Mike Domaratzki"],"url":"https://arxiv.org/abs/2504.14316"}
{"created":"2025-04-22","title":"Expanding the Generative AI Design Space through Structured Prompting and Multimodal Interfaces","abstract":"Text-based prompting remains the dominant interaction paradigm in generative AI, yet it often results in a high-friction experience for novice users, such as small business owners (SBOs), attempting to articulate creative or domain-specific goals for advertising. To investigate this challenge, we conducted a study with six SBOs in the United Kingdom, focusing on their advertising practices and perceptions and usage of AI tools in this context. Our findings surfaced two persistent breakdowns in current generative AI systems: first, the cognitive burden of prompt engineering, as users struggled to translate abstract creative goals into effective textual inputs; and second, the frequent generation of generic outputs that failed to align with users' articulated brand vision. To address these issues, we developed ACAI (AI Co-Creation for Advertising and Inspiration), a multimodal, GenAI-powered advertisement creation tool designed to support novice designers by reimagining the prompt interface. ACAI features a structured, panel-based interface composed of three modules: the Branding Panel, the Audience & Goals Panel, and the Inspiration Board Panel to provide SBOs with outputs that align with their creative vision by reducing prompt ambiguity. This work contributes to HCI research on generative systems by showing how structured interfaces can foreground user-defined context to improve both alignment and promptability in novice workflows.","authors":["Nimisha Karnatak","Adrien Baranes","Rob Marchant","Huinan Zeng","Tr\\'iona Butler","Kristen Olson"],"url":"https://arxiv.org/abs/2504.14320"}
{"created":"2025-04-22","title":"Multimodal Coreference Resolution for Chinese Social Media Dialogues: Dataset and Benchmark Approach","abstract":"Multimodal coreference resolution (MCR) aims to identify mentions referring to the same entity across different modalities, such as text and visuals, and is essential for understanding multimodal content. In the era of rapidly growing mutimodal content and social media, MCR is particularly crucial for interpreting user interactions and bridging text-visual references to improve communication and personalization. However, MCR research for real-world dialogues remains unexplored due to the lack of sufficient data resources.To address this gap, we introduce TikTalkCoref, the first Chinese multimodal coreference dataset for social media in real-world scenarios, derived from the popular Douyin short-video platform. This dataset pairs short videos with corresponding textual dialogues from user comments and includes manually annotated coreference clusters for both person mentions in the text and the coreferential person head regions in the corresponding video frames. We also present an effective benchmark approach for MCR, focusing on the celebrity domain, and conduct extensive experiments on our dataset, providing reliable benchmark results for this newly constructed dataset. We will release the TikTalkCoref dataset to facilitate future research on MCR for real-world social media dialogues.","authors":["Xingyu Li","Chen Gong","Guohong Fu"],"url":"https://arxiv.org/abs/2504.14321"}
{"created":"2025-04-22","title":"Advancing Polyglot Big Data Processing using the Hadoop ecosystem","abstract":"This article explores the utilization of the Hadoop ecosystem as a polyglot big data processing platform, focusing on the integration of diverse computation and storage technologies and their potential advantages in certain computational contexts. It delves into the potential of this ecosystem as a unified platform highlighting its architectural foundations and their complementary strengths in distributed storage, processing efficiency and real-time analytics. The article explores potential use cases within domains such as Smart Cities and Social Networks, illustrating how the platform's diverse components can be orchestrated in a polyglot manner and how these fields can benefit from the ecosystem's capabilities. Finally, the article concludes by showcasing alternatives for future research, including specialized architectural aspects of the ecosystem to advance the polyglot paradigm.","authors":["Antony Seabra","Sergio Lifschitz"],"url":"https://arxiv.org/abs/2504.14322"}
{"created":"2025-04-22","title":"Meltdown: Bridging the Perception Gap in Sustainable Food Behaviors Through Immersive VR","abstract":"Climate change education often struggles to bridge the perception gap between everyday actions and their long-term environmental consequences. In response, we developed Meltdown, an immersive virtual reality (VR) escape room that simulates a grocery shopping and food waste management experience to educate university students in Singapore about sustainable consumption. The game emphasizes sustainable food choices and disposal practices, combining interactive elements and narrative feedback to promote behavioral change. Through a user study with 36 university students, we observed statistically significant improvements in participants objective knowledge, perceived confidence, and intention to adopt sustainable behaviors. Our results suggest that experiential VR environments can enhance climate education by making abstract environmental concepts more immediate and personally relevant.","authors":["Acacia Chong Xiao Xuan","Florentiana Yuwono","Melissa Anastasia Harijanto","Xu Yi"],"url":"https://arxiv.org/abs/2504.14324"}
{"created":"2025-04-22","title":"FAIRGAME: a Framework for AI Agents Bias Recognition using Game Theory","abstract":"Letting AI agents interact in multi-agent applications adds a layer of complexity to the interpretability and prediction of AI outcomes, with profound implications for their trustworthy adoption in research and society. Game theory offers powerful models to capture and interpret strategic interaction among agents, but requires the support of reproducible, standardized and user-friendly IT frameworks to enable comparison and interpretation of results. To this end, we present FAIRGAME, a Framework for AI Agents Bias Recognition using Game Theory. We describe its implementation and usage, and we employ it to uncover biased outcomes in popular games among AI agents, depending on the employed Large Language Model (LLM) and used language, as well as on the personality trait or strategic knowledge of the agents. Overall, FAIRGAME allows users to reliably and easily simulate their desired games and scenarios and compare the results across simulation campaigns and with game-theoretic predictions, enabling the systematic discovery of biases, the anticipation of emerging behavior out of strategic interplays, and empowering further research into strategic decision-making using LLM agents.","authors":["Alessio Buscemi","Daniele Proverbio","Alessandro Di Stefano","The Anh Han","German Castignani","Pietro Di Li\\`o"],"url":"https://arxiv.org/abs/2504.14325"}
{"created":"2025-04-22","title":"Diffusion-based Dynamic Contract for Federated AI Agent Construction in Mobile Metaverses","abstract":"Mobile metaverses have attracted significant attention from both academia and industry, which are envisioned as the next-generation Internet, providing users with immersive and ubiquitous metaverse services through mobile devices. Driven by Large Language Models (LLMs) and Vision-Language Models (VLMs), Artificial Intelligence (AI) agents hold the potential to empower the creation, maintenance, and evolution of mobile metaverses. Currently, AI agents are primarily constructed using cloud-based LLMs and VLMs. However, several challenges hinder their effective implementation, including high service latency and potential sensitive data leakage during perception and processing. In this paper, we develop an edge-cloud collaboration-based federated AI agent construction framework in mobile metaverses. Specifically, Edge Servers (ESs), acting as agent infrastructures, collaboratively create agent modules in a distributed manner. The cloud server then integrates these modules into AI agents and deploys them at the edge, thereby enabling low-latency AI agent services for users. Considering that ESs may exhibit dynamic levels of willingness to participate in federated AI agent construction, we design a two-period dynamic contract model to continuously motivate ESs to participate in agent module creation, effectively addressing the dynamic information asymmetry between the cloud server and the ESs. Furthermore, we propose an Enhanced Diffusion Model-based Soft Actor-Critic (EDMSAC) algorithm to efficiently generate optimal dynamic contracts, in which dynamic structured pruning is applied to DM-based actor networks to enhance denoising efficiency and policy learning performance. Extensive simulations demonstrate the effectiveness and superiority of the EDMSAC algorithm and the proposed contract model.","authors":["Jinbo Wen","Jiawen Kang","Yang Zhang","Yue Zhong","Dusit Niyato","Jie Xu","Jianhang Tang","Chau Yuen"],"url":"https://arxiv.org/abs/2504.14326"}
{"created":"2025-04-22","title":"ScaloWork: Useful Proof-of-Work with Distributed Pool Mining","abstract":"Bitcoin blockchain uses hash-based Proof-of-Work (PoW) that prevents unwanted participants from hogging the network resources. Anyone entering the mining game has to prove that they have expended a specific amount of computational power. However, the most popular Bitcoin blockchain consumes 175.87 TWh of electrical energy annually, and most of this energy is wasted on hash calculations, which serve no additional purpose. Several studies have explored re-purposing the wasted energy by replacing the hash function with meaningful computational problems that have practical applications. Minimum Dominating Set (MDS) in networks has numerous real-life applications. Building on this concept, Chrisimos [TrustCom '23] was proposed to replace hash-based PoW with the computation of a dominating set on real-life graph instances. However, Chrisimos has several drawbacks regarding efficiency and solution quality. This work presents a new framework for Useful PoW, ScaloWork, that decides the block proposer for the Bitcoin blockchain based on the solution for the dominating set problem. ScaloWork relies on the property of graph isomorphism and guarantees solution extractability. We also propose a distributed approach for calculating the dominating set, allowing miners to collaborate in a pool. This enables ScaloWork to handle larger graphs relevant to real-life applications, thereby enhancing scalability. Our framework also eliminates the problem of free-riders, ensuring fairness in the distribution of block rewards. We perform a detailed security analysis of our framework and prove our scheme as secure as hash-based PoW. We implement a prototype of our framework, and the results show that our system outperforms Chrisimos in all aspects.","authors":["Diptendu Chatterjee","Avishek Majumder","Subhra Mazumdar"],"url":"https://arxiv.org/abs/2504.14328"}
{"created":"2025-04-22","title":"DLW-CI: A Dynamic Likelihood-Weighted Cooperative Infotaxis Approach for Multi-Source Search in Urban Environments Using Consumer Drone Networks","abstract":"Consumer-grade drones equipped with low-cost sensors have emerged as a cornerstone of Autonomous Intelligent Systems (AISs) for environmental monitoring and hazardous substance detection in urban environments. However, existing research primarily addresses single-source search problems, overlooking the complexities of real-world urban scenarios where both the location and quantity of hazardous sources remain unknown. To address this issue, we propose the Dynamic Likelihood-Weighted Cooperative Infotaxis (DLW-CI) approach for consumer drone networks. Our approach enhances multi-drone collaboration in AISs by combining infotaxis (a cognitive search strategy) with optimized source term estimation and an innovative cooperative mechanism. Specifically, we introduce a novel source term estimation method that utilizes multiple parallel particle filters, with each filter dedicated to estimating the parameters of a potentially unknown source within the search scene. Furthermore, we develop a cooperative mechanism based on dynamic likelihood weights to prevent multiple drones from simultaneously estimating and searching for the same source, thus optimizing the energy efficiency and search coverage of the consumer AIS. Experimental results demonstrate that the DLW-CI approach significantly outperforms baseline methods regarding success rate, accuracy, and root mean square error, particularly in scenarios with relatively few sources, regardless of the presence of obstacles. Also, the effectiveness of the proposed approach is verified in a diffusion scenario generated by the computational fluid dynamics (CFD) model. Research findings indicate that our approach could improve source estimation accuracy and search efficiency by consumer drone-based AISs, making a valuable contribution to environmental safety monitoring applications within smart city infrastructure.","authors":["Xiaoran Zhang","Yatai Ji","Yong Zhao","Chuan Ai","Bin Chen","Zhengqiu Zhu"],"url":"https://arxiv.org/abs/2504.14330"}
{"created":"2025-04-22","title":"Code2API: A Tool for Generating Reusable APIs from Stack Overflow Code Snippets","abstract":"Nowadays, developers often turn to Stack Overflow for solutions to daily problems, however, these code snippets are partial code that cannot be tested and verified properly. One way to test these code snippets is to transform them into APIs (Application Program Interface) that developers can be directly invoked and executed. However, it is often costly and error-prone for developers to manually perform this transformation (referred to as AIPzation task) due to different actions to be taken (e.g., summarizing proper method names, inferring input parameters list and return statements). To help developers quickly reuse code snippets in Stack Overflow, in this paper, we propose Code2API, a Google Chrome extension that uses Large Language Models (LLMs) to automatically perform APIzation of code snippets on Stack Overflow. \\toolname guides LLMs through well-designed prompts to generate reusable APIs, using Chain-of-Thought reasoning and few-shot in-context learning to help LLMs understand and solve the APIzation task in a developer-like manner. The evaluation results show that Code2API significantly outperforms the rule-based approach by a large margin.","authors":["Yubo Mai","Zhipeng Gao","Xing Hu","Lingfeng Bao","Jingyuan Chen","Jianling Sun"],"url":"https://arxiv.org/abs/2504.14331"}
{"created":"2025-04-22","title":"Koopman-Based Event-Triggered Control from Data","abstract":"Event-triggered Control (ETC) presents a promising paradigm for efficient resource usage in networked and embedded control systems by reducing communication instances compared to traditional time-triggered strategies. This paper introduces a novel approach to ETC for discrete-time nonlinear systems using a data-driven framework. By leveraging Koopman operator theory, the nonlinear system dynamics are globally linearized (approximately in practical settings) in a higher-dimensional space. We design a state-feedback controller and an event-triggering policy directly from data, ensuring exponential stability in Lyapunov sense. The proposed method is validated through extensive simulation experiments, demonstrating significant resource savings.","authors":["Zeyad M. Manaa","Ayman M. Abdallah","Mohamed Ismail","Samil El Ferik"],"url":"https://arxiv.org/abs/2504.14334"}
{"created":"2025-04-22","title":"Visual Prompting for One-shot Controllable Video Editing without Inversion","abstract":"One-shot controllable video editing (OCVE) is an important yet challenging task, aiming to propagate user edits that are made -- using any image editing tool -- on the first frame of a video to all subsequent frames, while ensuring content consistency between edited frames and source frames. To achieve this, prior methods employ DDIM inversion to transform source frames into latent noise, which is then fed into a pre-trained diffusion model, conditioned on the user-edited first frame, to generate the edited video. However, the DDIM inversion process accumulates errors, which hinder the latent noise from accurately reconstructing the source frames, ultimately compromising content consistency in the generated edited frames. To overcome it, our method eliminates the need for DDIM inversion by performing OCVE through a novel perspective based on visual prompting. Furthermore, inspired by consistency models that can perform multi-step consistency sampling to generate a sequence of content-consistent images, we propose a content consistency sampling (CCS) to ensure content consistency between the generated edited frames and the source frames. Moreover, we introduce a temporal-content consistency sampling (TCS) based on Stein Variational Gradient Descent to ensure temporal consistency across the edited frames. Extensive experiments validate the effectiveness of our approach.","authors":["Zhengbo Zhang","Yuxi Zhou","Duo Peng","Joo-Hwee Lim","Zhigang Tu","De Wen Soh","Lin Geng Foo"],"url":"https://arxiv.org/abs/2504.14335"}
{"created":"2025-04-22","title":"Toward Generation of Test Cases from Task Descriptions via History-aware Planning","abstract":"In automated web testing, generating test scripts from natural language task descriptions is crucial for enhancing the test generation process. This activity involves creating the correct sequences of actions to form test scripts for future testing activities. Current state-of-the-art approaches are limited in generating these action sequences, as they either demand substantial manual effort for human demonstrations or fail to consider the history of previous web content and actions to decide the next action. In this paper, we introduce HxAgent, an iterative large language model agent planning approach that determines the next action based on: 1) observations of the current contents and feasible actions, 2) short-term memory of previous web states and actions, and 3) long-term experience with (in)correct action sequences. The agent generates a sequence of actions to perform a given task, which is effectively an automated test case to verify the task. We conducted an extensive empirical evaluation of HxAgent using two datasets. On the MiniWoB++ dataset, our approach achieves 97% exact-match accuracy that is comparable to the best baselines while eliminating the need for human demonstrations required by those methods. For complex tasks requiring navigation through multiple actions and screens, HxAgent achieves an average 82% exact-match. On the second dataset, comprising 350 task instances across seven popular websites, including YouTube, LinkedIn, Facebook, and Google, HxAgent achieves high performance, with 87% of the action sequences exactly matching the ground truth and a prefix-match of 93%, outperforming the baseline by 59%.","authors":["Duy Cao","Phu Nguyen","Vy Le","Tien N. Nguyen","Vu Nguyen"],"url":"https://arxiv.org/abs/2504.14336"}
{"created":"2025-04-22","title":"Multispectral airborne laser scanning for tree species classification: a benchmark of machine learning and deep learning algorithms","abstract":"Climate-smart and biodiversity-preserving forestry demands precise information on forest resources, extending to the individual tree level. Multispectral airborne laser scanning (ALS) has shown promise in automated point cloud processing and tree segmentation, but challenges remain in identifying rare tree species and leveraging deep learning techniques. This study addresses these gaps by conducting a comprehensive benchmark of machine learning and deep learning methods for tree species classification. For the study, we collected high-density multispectral ALS data (>1000 pts/m$^2$) at three wavelengths using the FGI-developed HeliALS system, complemented by existing Optech Titan data (35 pts/m$^2$), to evaluate the species classification accuracy of various algorithms in a test site located in Southern Finland. Based on 5261 test segments, our findings demonstrate that point-based deep learning methods, particularly a point transformer model, outperformed traditional machine learning and image-based deep learning approaches on high-density multispectral point clouds. For the high-density ALS dataset, a point transformer model provided the best performance reaching an overall (macro-average) accuracy of 87.9% (74.5%) with a training set of 1065 segments and 92.0% (85.1%) with 5000 training segments. The best image-based deep learning method, DetailView, reached an overall (macro-average) accuracy of 84.3% (63.9%), whereas a random forest (RF) classifier achieved an overall (macro-average) accuracy of 83.2% (61.3%). Importantly, the overall classification accuracy of the point transformer model on the HeliALS data increased from 73.0% with no spectral information to 84.7% with single-channel reflectance, and to 87.9% with spectral information of all the three channels.","authors":["Josef Taher","Eric Hyypp\\\"a","Matti Hyypp\\\"a","Klaara Salolahti","Xiaowei Yu","Leena Matikainen","Antero Kukko","Matti Lehtom\\\"aki","Harri Kaartinen","Sopitta Thurachen","Paula Litkey","Ville Luoma","Markus Holopainen","Gefei Kong","Hongchao Fan","Petri R\\\"onnholm","Antti Polvivaara","Samuli Junttila","Mikko Vastaranta","Stefano Puliti","Rasmus Astrup","Joel Kostensalo","Mari Myllym\\\"aki","Maksymilian Kulicki","Krzysztof Stere\\'nczak","Raul de Paula Pires","Ruben Valbuena","Juan Pedro Carbonell-Rivera","Jes\\'us Torralba","Yi-Chen Chen","Lukas Winiwarter","Markus Hollaus","Gottfried Mandlburger","Narges Takhtkeshha","Fabio Remondino","Maciej Lisiewicz","Bart{\\l}omiej Kraszewski","Xinlian Liang","Jianchang Chen","Eero Ahokas","Kirsi Karila","Eugeniu Vezeteu","Petri Manninen","Roope N\\\"asi","Heikki Hyyti","Siiri Pyykk\\\"onen","Peilun Hu","Juha Hyypp\\\"a"],"url":"https://arxiv.org/abs/2504.14337"}
{"created":"2025-04-22","title":"A parallel implementation of reduced-order modeling of large-scale systems","abstract":"Motivated by the large-scale nature of modern aerospace engineering simulations, this paper presents a detailed description of distributed Operator Inference (dOpInf), a recently developed parallel algorithm designed to efficiently construct physics-based reduced-order models (ROMs) for problems with large state dimensions. One such example is the simulation of rotating detonation rocket engines, where snapshot data generated by high-fidelity large-eddy simulations have many millions of degrees of freedom. dOpInf enables, via distributed computing, the efficient processing of datasets with state dimensions that are too large to process on a single computer, and the learning of structured physics-based ROMs that approximate the dynamical systems underlying those datasets. All elements of dOpInf are scalable, leading to a fully parallelized reduced modeling approach that can scale to the thousands of processors available on leadership high-performance computing platforms. The resulting ROMs are computationally cheap, making them ideal for key engineering tasks such as design space exploration, risk assessment, and uncertainty quantification. To illustrate the practical application of dOpInf, we provide a step-by-step tutorial using a 2D Navier-Stokes flow over a step scenario as a case study. This tutorial guides users through the implementation process, making dOpInf accessible for integration into complex aerospace engineering simulations.","authors":["Ionut-Gabriel Farcas","Rayomand P. Gundevia","Ramakanth Munipalli","Karen E. Willcox"],"url":"https://arxiv.org/abs/2504.14338"}
{"created":"2025-04-22","title":"Omelets Need Onions: E-graphs Modulo Theories via Bottom-up E-matching","abstract":"E-graphs are a data structure for equational reasoning and optimization over ground terms. One of the benefits of e-graph rewriting is that it can declaratively handle useful but difficult to orient identities like associativity and commutativity (AC) in a generic way. However, using these generic mechanisms is more computationally expensive than using bespoke routines on terms containing sets, multi-sets, linear expressions, polynomials, and binders. A natural question arises: How can one combine the generic capabilities of e-graph rewriting with these specialized theories. This paper discusses a pragmatic approach to this e-graphs modulo theories (EMT) question using two key ideas: bottom-up e-matching and semantic e-ids.","authors":["Philip Zucker"],"url":"https://arxiv.org/abs/2504.14340"}
{"created":"2025-04-22","title":"Manipulating Multimodal Agents via Cross-Modal Prompt Injection","abstract":"The emergence of multimodal large language models has redefined the agent paradigm by integrating language and vision modalities with external data sources, enabling agents to better interpret human instructions and execute increasingly complex tasks. However, in this work, we identify a critical yet previously overlooked security vulnerability in multimodal agents: cross-modal prompt injection attacks. To exploit this vulnerability, we propose CrossInject, a novel attack framework in which attackers embed adversarial perturbations across multiple modalities to align with target malicious content, allowing external instructions to hijack the agent's decision-making process and execute unauthorized tasks. Our approach consists of two key components. First, we introduce Visual Latent Alignment, where we optimize adversarial features to the malicious instructions in the visual embedding space based on a text-to-image generative model, ensuring that adversarial images subtly encode cues for malicious task execution. Subsequently, we present Textual Guidance Enhancement, where a large language model is leveraged to infer the black-box defensive system prompt through adversarial meta prompting and generate an malicious textual command that steers the agent's output toward better compliance with attackers' requests. Extensive experiments demonstrate that our method outperforms existing injection attacks, achieving at least a +26.4% increase in attack success rates across diverse tasks. Furthermore, we validate our attack's effectiveness in real-world multimodal autonomous agents, highlighting its potential implications for safety-critical applications.","authors":["Le Wang","Zonghao Ying","Tianyuan Zhang","Siyuan Liang","Shengshan Hu","Mingchuan Zhang","Aishan Liu","Xianglong Liu"],"url":"https://arxiv.org/abs/2504.14348"}
{"created":"2025-04-22","title":"Time Up! An Empirical Study of LLM Reasoning Ability Under Output Length Constraint","abstract":"Recent work has demonstrated the remarkable potential of Large Language Models (LLMs) in test-time scaling. By making the models think before answering, they are able to achieve much higher accuracy with extra inference computation. However, in many real-world scenarios, models are used under time constraints, where an answer should be given to the user within a certain output length. It is unclear whether and how the reasoning abilities of LLMs remain effective under such constraints. We take a first look at this problem by conducting an in-depth empirical study. Specifically, we test more than 25 LLMs on common reasoning datasets under a wide range of output length budgets, and we analyze the correlation between the inference accuracy and various properties including model type, model size, prompt style, etc. We also consider the mappings between the token budgets and the actual on-device latency budgets. The results have demonstrated several interesting findings regarding the budget-aware LLM reasoning that differ from the unconstrained situation, e.g. the optimal choices of model sizes and prompts change under different budgets. These findings offer practical guidance for users to deploy LLMs under real-world latency constraints.","authors":["Yi Sun","Han Wang","Jiaqiang Li","Jiacheng Liu","Xiangyu Li","Hao Wen","Huiwen Zheng","Yan Liang","Yuanchun Li","Yunxin Liu"],"url":"https://arxiv.org/abs/2504.14350"}
{"created":"2025-04-22","title":"Decentralization in PoS Blockchain Consensus: Quantification and Advancement","abstract":"Decentralization is a foundational principle of permissionless blockchains, with consensus mechanisms serving a critical role in its realization. This study quantifies the decentralization of consensus mechanisms in proof-of-stake (PoS) blockchains using a comprehensive set of metrics, including Nakamoto coefficients, Gini, Herfindahl Hirschman Index (HHI), Shapley values, and Zipfs coefficient. Our empirical analysis across ten prominent blockchains reveals significant concentration of stake among a few validators, posing challenges to fair consensus. To address this, we introduce two alternative weighting models for PoS consensus: Square Root Stake Weight (SRSW) and Logarithmic Stake Weight (LSW), which adjust validator influence through non-linear transformations. Results demonstrate that SRSW and LSW models improve decentralization metrics by an average of 51% and 132%, respectively, supporting more equitable and resilient blockchain systems.","authors":["Shashank Motepalli","Hans-Arno Jacobsen"],"url":"https://arxiv.org/abs/2504.14351"}
{"created":"2025-04-22","title":"Mathematical Programming Models for Exact and Interpretable Formulation of Neural Networks","abstract":"This paper presents a unified mixed-integer programming framework for training sparse and interpretable neural networks. We develop exact formulations for both fully connected and convolutional architectures by modeling nonlinearities such as ReLU activations through binary variables and encoding structural sparsity via filter- and layer-level pruning constraints. The resulting models integrate parameter learning, architecture selection, and structural regularization within a single optimization problem, yielding globally optimal solutions with respect to a composite objective that balances prediction accuracy, weight sparsity, and architectural compactness. The mixed-integer programming formulation accommodates piecewise-linear operations, including max pooling and activation gating, and permits precise enforcement of logic-based or domain-specific constraints. By incorporating considerations of interpretability, sparsity, and verifiability directly into the training process, the proposed framework bridges a range of research areas including explainable artificial intelligence, symbolic reasoning, and formal verification.","authors":["Masoud Ataei","Edrin Hasaj","Jacob Gipp","Sepideh Forouzi"],"url":"https://arxiv.org/abs/2504.14356"}
{"created":"2025-04-22","title":"A Multimodal Recaptioning Framework to Account for Perceptual Diversity in Multilingual Vision-Language Modeling","abstract":"There are many ways to describe, name, and group objects when captioning an image. Differences are evident when speakers come from diverse cultures due to the unique experiences that shape perception. Machine translation of captions has pushed multilingual capabilities in vision-language models (VLMs), but data comes mainly from English speakers, indicating a perceptual bias and lack of model flexibility. In this work, we address this challenge and outline a data-efficient framework to instill multilingual VLMs with greater understanding of perceptual diversity. We specifically propose an LLM-based, multimodal recaptioning strategy that alters the object descriptions of English captions before translation. The greatest benefits are demonstrated in a targeted multimodal mechanism guided by native speaker data. By adding produced rewrites as augmentations in training, we improve on German and Japanese text-image retrieval cases studies (up to +3.5 mean recall overall, +4.7 on non-native error cases). We further propose a mechanism to analyze the specific object description differences across datasets, and we offer insights into cross-dataset and cross-language generalization.","authors":["Kyle Buettner","Jacob Emmerson","Adriana Kovashka"],"url":"https://arxiv.org/abs/2504.14359"}
{"created":"2025-04-22","title":"Charging While Driving Lanes: A Boon to Electric Vehicle Owners or a Disruption to Traffic Flow","abstract":"Large-scale adoption of commercial and personal Electric Vehicles (EVs) is expected to significantly affect traffic flow dynamics, emissions, and energy consumption in the transportation sector. Range anxiety and challenges associated with charging EVs are among the key issues that reduce the adoption rate of EVs and, in turn, limit their system-level impacts. A promising solution to address these challenges is the introduction of charging while driving (CWD) lanes. Although technological advancements have made it possible to charge vehicles wirelessly while driving, introducing such lanes to the traffic stream can potentially disturb traffic flow and result in new congestion patterns. This study puts forward a framework to investigate the effects of CWD lanes on traffic flow, considering %autonomy, speed harmonization, and environmental factors for different market penetration rates (MPRs) of personal and commercial EVs. Different policies have been investigated to suggest the best design for CWD lanes. Results indicate that introducing CWD lanes can decrease overall traffic throughput and increase congestion due to additional lane-changing maneuvers by electric vehicles aiming to utilize the CWD lane. Although higher MPRs of EVs help stabilize traffic flow and reduce the number of shockwaves, speed disruption tends to increase in the CWD lane and propagate to adjacent lanes. Emission analyses show significant reductions (up to 63\\%) in pollution levels with increasing MPRs of personal and commercial EVs. Our analysis shows that while CWD lanes can facilitate the adoption of EVs, they can deteriorate traffic efficiency, emphasizing the importance of careful design and policy considerations.","authors":["Shayan Bafandkar","Alireza Talebpour"],"url":"https://arxiv.org/abs/2504.14360"}
{"created":"2025-04-22","title":"Integrating Single-Cell Foundation Models with Graph Neural Networks for Drug Response Prediction","abstract":"In this study, we propose an innovative methodology for predicting Cancer Drug Response (CDR) through the integration of the scGPT foundation model within the DeepCDR model. Our approach utilizes scGPT to generate embeddings from gene expression data, which are then used as gene expression input data for DeepCDR. The experimental findings demonstrate the efficacy of this scGPT-based method in outperforming previous related works, including the original DeepCDR model and the scFoundation-based model. This study highlights the potential of scGPT embeddings to enhance the accuracy of CDR predictions and offers a promising alternative to existing approaches.","authors":["Till Rossner","Ziteng Li","Jonas Balke","Nikoo Salehfard","Tom Seifert","Ming Tang"],"url":"https://arxiv.org/abs/2504.14361"}
{"created":"2025-04-22","title":"Improving RL Exploration for LLM Reasoning through Retrospective Replay","abstract":"Reinforcement learning (RL) has increasingly become a pivotal technique in the post-training of large language models (LLMs). The effective exploration of the output space is essential for the success of RL. We observe that for complex problems, during the early stages of training, the model exhibits strong exploratory capabilities and can identify promising solution ideas. However, its limited capability at this stage prevents it from successfully solving these problems. The early suppression of these potentially valuable solution ideas by the policy gradient hinders the model's ability to revisit and re-explore these ideas later. Consequently, although the LLM's capabilities improve in the later stages of training, it still struggles to effectively address these complex problems. To address this exploration issue, we propose a novel algorithm named Retrospective Replay-based Reinforcement Learning (RRL), which introduces a dynamic replay mechanism throughout the training process. RRL enables the model to revisit promising states identified in the early stages, thereby improving its efficiency and effectiveness in exploration. To evaluate the effectiveness of RRL, we conduct extensive experiments on complex reasoning tasks, including mathematical reasoning and code generation, and general dialogue tasks. The results indicate that RRL maintains high exploration efficiency throughout the training period, significantly enhancing the effectiveness of RL in optimizing LLMs for complicated reasoning tasks. Moreover, it also improves the performance of RLHF, making the model both safer and more helpful.","authors":["Shihan Dou","Muling Wu","Jingwen Xu","Rui Zheng","Tao Gui","Qi Zhang","Xuanjing Huang"],"url":"https://arxiv.org/abs/2504.14363"}
{"created":"2025-04-22","title":"Accelerating LLM Inference with Flexible N:M Sparsity via A Fully Digital Compute-in-Memory Accelerator","abstract":"Large language model (LLM) pruning with fixed N:M structured sparsity significantly limits the expressivity of the sparse model, yielding sub-optimal performance. In contrast, supporting multiple N:M patterns to provide sparse representational freedom introduces costly overhead in hardware. To address these challenges for LLMs, we first present a flexible layer-wise outlier-density-aware N:M sparsity (FLOW) selection method. FLOW enables the identification of optimal layer-wise N and M values (from a given range) by simultaneously accounting for the presence and distribution of outliers, allowing a higher degree of representational freedom. To deploy sparse models with such N:M flexibility, we then introduce a flexible, low-overhead digital compute-in-memory architecture (FlexCiM). FlexCiM supports diverse sparsity patterns by partitioning a digital CiM (DCiM) macro into smaller sub-macros, which are adaptively aggregated and disaggregated through distribution and merging mechanisms for different N and M values. Extensive experiments on both transformer-based and recurrence-based state space foundation models (SSMs) demonstrate that FLOW outperforms existing alternatives with an accuracy improvement of up to 36%, while FlexCiM achieves up to 1.75x lower inference latency and 1.5x lower energy consumption compared to existing sparse accelerators. Code is available at: https://github.com/FLOW-open-project/FLOW","authors":["Akshat Ramachandran","Souvik Kundu","Arnab Raha","Shamik Kundu","Deepak K. Mathaikutty","Tushar Krishna"],"url":"https://arxiv.org/abs/2504.14365"}
{"created":"2025-04-22","title":"Empirical Evaluation of Knowledge Distillation from Transformers to Subquadratic Language Models","abstract":"Knowledge distillation is a widely used technique for compressing large language models (LLMs) by training a smaller student model to mimic a larger teacher model. Typically, both the teacher and student are Transformer-based architectures, leveraging softmax attention for sequence modeling. However, the quadratic complexity of self-attention at inference time remains a significant bottleneck, motivating the exploration of subquadratic alternatives such as structured state-space models (SSMs), linear attention, and recurrent architectures. In this work, we systematically evaluate the transferability of knowledge distillation from a Transformer teacher to nine subquadratic student architectures. Our study aims to determine which subquadratic model best aligns with the teacher's learned representations and how different architectural constraints influence the distillation process. We also investigate the impact of intelligent initialization strategies, including matrix mixing and query-key-value (QKV) copying, on the adaptation process. Our empirical results on multiple NLP benchmarks provide insights into the trade-offs between efficiency and performance, highlighting key factors for successful knowledge transfer to subquadratic architectures.","authors":["Patrick Haller","Jonas Golde","Alan Akbik"],"url":"https://arxiv.org/abs/2504.14366"}
{"created":"2025-04-22","title":"Diverse Prompts: Illuminating the Prompt Space of Large Language Models with MAP-Elites","abstract":"Prompt engineering is essential for optimizing large language models (LLMs), yet the link between prompt structures and task performance remains underexplored. This work introduces an evolutionary approach that combines context-free grammar (CFG) with the MAP-Elites algorithm to systematically explore the prompt space. Our method prioritizes quality and diversity, generating high-performing and structurally varied prompts while analyzing their alignment with diverse tasks by varying traits such as the number of examples (shots) and reasoning depth. By systematically mapping the phenotypic space, we reveal how structural variations influence LLM performance, offering actionable insights for task-specific and adaptable prompt design. Evaluated on seven BigBench Lite tasks across multiple LLMs, our results underscore the critical interplay of quality and diversity, advancing the effectiveness and versatility of LLMs.","authors":["Gabriel Machado Santos","Rita Maria da Silva Julia","Marcelo Zanchetta do Nascimento"],"url":"https://arxiv.org/abs/2504.14367"}
{"created":"2025-04-22","title":"Do You Really Need Public Data? Surrogate Public Data for Differential Privacy on Tabular Data","abstract":"Differentially private (DP) machine learning often relies on the availability of public data for tasks like privacy-utility trade-off estimation, hyperparameter tuning, and pretraining. While public data assumptions may be reasonable in text and image domains, they are less likely to hold for tabular data due to tabular data heterogeneity across domains. We propose leveraging powerful priors to address this limitation; specifically, we synthesize realistic tabular data directly from schema-level specifications - such as variable names, types, and permissible ranges - without ever accessing sensitive records. To that end, this work introduces the notion of \"surrogate\" public data - datasets generated independently of sensitive data, which consume no privacy loss budget and are constructed solely from publicly available schema or metadata. Surrogate public data are intended to encode plausible statistical assumptions (informed by publicly available information) into a dataset with many downstream uses in private mechanisms. We automate the process of generating surrogate public data with large language models (LLMs); in particular, we propose two methods: direct record generation as CSV files, and automated structural causal model (SCM) construction for sampling records. Through extensive experiments, we demonstrate that surrogate public tabular data can effectively replace traditional public data when pretraining differentially private tabular classifiers. To a lesser extent, surrogate public data are also useful for hyperparameter tuning of DP synthetic data generators, and for estimating the privacy-utility tradeoff.","authors":["Shlomi Hod","Lucas Rosenblatt","Julia Stoyanovich"],"url":"https://arxiv.org/abs/2504.14368"}
{"created":"2025-04-22","title":"Efficient Spiking Point Mamba for Point Cloud Analysis","abstract":"Bio-inspired Spiking Neural Networks (SNNs) provide an energy-efficient way to extract 3D spatio-temporal features. However, existing 3D SNNs have struggled with long-range dependencies until the recent emergence of Mamba, which offers superior computational efficiency and sequence modeling capability. In this work, we propose Spiking Point Mamba (SPM), the first Mamba-based SNN in the 3D domain. Due to the poor performance of simply transferring Mamba to 3D SNNs, SPM is designed to utilize both the sequence modeling capabilities of Mamba and the temporal feature extraction of SNNs. Specifically, we first introduce Hierarchical Dynamic Encoding (HDE), an improved direct encoding method that effectively introduces dynamic temporal mechanism, thereby facilitating temporal interactions. Then, we propose a Spiking Mamba Block (SMB), which builds upon Mamba while learning inter-time-step features and minimizing information loss caused by spikes. Finally, to further enhance model performance, we adopt an asymmetric SNN-ANN architecture for spike-based pre-training and finetune. Compared with the previous state-of-the-art SNN models, SPM improves OA by +6.2%, +6.1%, and +7.4% on three variants of ScanObjectNN, and boosts instance mIOU by +1.9% on ShapeNetPart. Meanwhile, its energy consumption is at least 3.5x lower than that of its ANN counterpart. The code will be made publicly available.","authors":["Peixi Wu","Bosong Chai","Menghua Zheng","Wei Li","Zhangchi Hu","Jie Chen","Zheyu Zhang","Hebei Li","Xiaoyan Sun"],"url":"https://arxiv.org/abs/2504.14371"}
{"created":"2025-04-22","title":"Learning Enhanced Structural Representations with Block-Based Uncertainties for Ocean Floor Mapping","abstract":"Accurate ocean modeling and coastal hazard prediction depend on high-resolution bathymetric data; yet, current worldwide datasets are too coarse for exact numerical simulations. While recent deep learning advances have improved earth observation data resolution, existing methods struggle with the unique challenges of producing detailed ocean floor maps, especially in maintaining physical structure consistency and quantifying uncertainties. This work presents a novel uncertainty-aware mechanism using spatial blocks to efficiently capture local bathymetric complexity based on block-based conformal prediction. Using the Vector Quantized Variational Autoencoder (VQ-VAE) architecture, the integration of this uncertainty quantification framework yields spatially adaptive confidence estimates while preserving topographical features via discrete latent representations. With smaller uncertainty widths in well-characterized areas and appropriately larger bounds in areas of complex seafloor structures, the block-based design adapts uncertainty estimates to local bathymetric complexity. Compared to conventional techniques, experimental results over several ocean regions show notable increases in both reconstruction quality and uncertainty estimation reliability. This framework increases the reliability of bathymetric reconstructions by preserving structural integrity while offering spatially adaptive uncertainty estimates, so opening the path for more solid climate modeling and coastal hazard assessment.","authors":["Jose Marie Antonio Minoza"],"url":"https://arxiv.org/abs/2504.14372"}
{"created":"2025-04-22","title":"SEGA: Drivable 3D Gaussian Head Avatar from a Single Image","abstract":"Creating photorealistic 3D head avatars from limited input has become increasingly important for applications in virtual reality, telepresence, and digital entertainment. While recent advances like neural rendering and 3D Gaussian splatting have enabled high-quality digital human avatar creation and animation, most methods rely on multiple images or multi-view inputs, limiting their practicality for real-world use. In this paper, we propose SEGA, a novel approach for Single-imagE-based 3D drivable Gaussian head Avatar creation that combines generalized prior models with a new hierarchical UV-space Gaussian Splatting framework. SEGA seamlessly combines priors derived from large-scale 2D datasets with 3D priors learned from multi-view, multi-expression, and multi-ID data, achieving robust generalization to unseen identities while ensuring 3D consistency across novel viewpoints and expressions. We further present a hierarchical UV-space Gaussian Splatting framework that leverages FLAME-based structural priors and employs a dual-branch architecture to disentangle dynamic and static facial components effectively. The dynamic branch encodes expression-driven fine details, while the static branch focuses on expression-invariant regions, enabling efficient parameter inference and precomputation. This design maximizes the utility of limited 3D data and achieves real-time performance for animation and rendering. Additionally, SEGA performs person-specific fine-tuning to further enhance the fidelity and realism of the generated avatars. Experiments show our method outperforms state-of-the-art approaches in generalization ability, identity preservation, and expression realism, advancing one-shot avatar creation for practical applications.","authors":["Chen Guo","Zhuo Su","Jian Wang","Shuang Li","Xu Chang","Zhaohu Li","Yang Zhao","Guidong Wang","Ruqi Huang"],"url":"https://arxiv.org/abs/2504.14373"}
{"created":"2025-04-22","title":"A fast MPI-based Distributed Hash-Table as Surrogate Model demonstrated in a coupled reactive transport HPC simulation","abstract":"Surrogate models can play a pivotal role in enhancing performance in contemporary High-Performance Computing applications. Cache-based surrogates use already calculated simulation results to interpolate or extrapolate further simulation output values. But this approach only pays off if the access time to retrieve the needed values is much faster than the actual simulation. While the most existing key-value stores use a Client-Server architecture with dedicated storage nodes, this is not the most suitable architecture for HPC applications. Instead, we propose a distributed architecture where the parallel processes offer a part of their available memory to build a shared distributed hash table based on MPI. This paper presents three DHT approaches with the special requirements of HPC applications in mind. The presented lock-free design outperforms both DHT versions which use explicit synchronization by coarse-grained resp. fine-grained locking. The lock-free DHT shows very good scaling regarding read and write performance. The runtime of a coupled reactive transport simulation was improved between 14% and 42% using the lock-free DHT as a surrogate model.","authors":["Max L\\\"ubke","Marco De Lucia","Stefan Petri","Bettina Schnor"],"url":"https://arxiv.org/abs/2504.14374"}
{"created":"2025-04-22","title":"Bottom-Up Synthesis of Knowledge-Grounded Task-Oriented Dialogues with Iteratively Self-Refined Prompts","abstract":"Training conversational question-answering (QA) systems requires a substantial amount of in-domain data, which is often scarce in practice. A common solution to this challenge is to generate synthetic data. Traditional methods typically follow a top-down approach, where a large language model (LLM) generates multi-turn dialogues from a broad prompt. Although this method produces coherent conversations, it offers limited fine-grained control over the content and is susceptible to hallucinations. We introduce a bottom-up conversation synthesis approach, where QA pairs are generated first and then combined into a coherent dialogue. This method offers greater control and precision by dividing the process into two distinct steps, allowing refined instructions and validations to be handled separately. Additionally, this structure allows the use of non-local models in stages that do not involve proprietary knowledge, enhancing the overall quality of the generated data. Both human and automated evaluations demonstrate that our approach produces more realistic and higher-quality dialogues compared to top-down methods.","authors":["Kun Qian","Maximillian Chen","Siyan Li","Arpit Sharma","Zhou Yu"],"url":"https://arxiv.org/abs/2504.14375"}
{"created":"2025-04-22","title":"MILUV: A Multi-UAV Indoor Localization dataset with UWB and Vision","abstract":"This paper introduces MILUV, a Multi-UAV Indoor Localization dataset with UWB and Vision measurements. This dataset comprises 217 minutes of flight time over 36 experiments using three quadcopters, collecting ultra-wideband (UWB) ranging data such as the raw timestamps and channel-impulse response data, vision data from a stereo camera and a bottom-facing monocular camera, inertial measurement unit data, height measurements from a laser rangefinder, magnetometer data, and ground-truth poses from a motion-capture system. The UWB data is collected from up to 12 transceivers affixed to mobile robots and static tripods in both line-of-sight and non-line-of-sight conditions. The UAVs fly at a maximum speed of 4.418 m/s in an indoor environment with visual fiducial markers as features. MILUV is versatile and can be used for a wide range of applications beyond localization, but the primary purpose of MILUV is for testing and validating multi-robot UWB- and vision-based localization algorithms. The dataset can be downloaded at https://doi.org/10.25452/figshare.plus.28386041.v1. A development kit is presented alongside the MILUV dataset, which includes benchmarking algorithms such as visual-inertial odometry, UWB-based localization using an extended Kalman filter, and classification of CIR data using machine learning approaches. The development kit can be found at https://github.com/decargroup/miluv, and is supplemented with a website available at https://decargroup.github.io/miluv/.","authors":["Mohammed Ayman Shalaby","Syed Shabbir Ahmed","Nicholas Dahdah","Charles Champagne Cossette","Jerome Le Ny","James Richard Forbes"],"url":"https://arxiv.org/abs/2504.14376"}
{"created":"2025-04-22","title":"The Geometry of Self-Verification in a Task-Specific Reasoning Model","abstract":"How do reasoning models verify their own answers? We study this question by training a model using DeepSeek R1's recipe on the CountDown task. We leverage the fact that preference tuning leads to mode collapse, resulting in a model that always produces highly structured and easily parse-able chain-of-thought sequences. With this setup, we do a top-down and bottom-up analysis to reverse-engineer how the model verifies its outputs. Our top-down analysis reveals Gated Linear Unit (GLU) weights encoding verification-related tokens, such as ``success'' or ``incorrect'', which activate according to the correctness of the model's reasoning steps. Our bottom-up analysis reveals that ``previous-token heads'' are mainly responsible for model verification. Our analyses meet in the middle: drawing inspiration from inter-layer communication channels, we use the identified GLU vectors to localize as few as three attention heads that can disable model verification, pointing to a necessary component of a potentially larger verification circuit.","authors":["Andrew Lee","Lihao Sun","Chris Wendler","Fernanda Vi\\'egas","Martin Wattenberg"],"url":"https://arxiv.org/abs/2504.14379"}
{"created":"2025-04-22","title":"Publicly Verifiable Secret Sharing: Generic Constructions and Lattice-Based Instantiations in the Standard Model","abstract":"Publicly verifiable secret sharing (PVSS) allows a dealer to share a secret among a set of shareholders so that the secret can be reconstructed later from any set of qualified participants. In addition, any public verifier should be able to check the correctness of the sharing and reconstruction process. PVSS has been demonstrated to yield various applications, such as e-voting, distributed key generation, decentralized random number generation protocols, and multi-party computation. Although many concrete PVSS protocols have been proposed, their security is either proven in the random oracle model or relies on quantum-vulnerable assumptions such as factoring or discrete logarithm. In this work, we put forward a generic construction for PVSS that can be instantiated in the standard model under the Learning With Errors (LWE) assumption. Our instantiation provides the first post-quantum PVSS in the standard model, with a reasonable level of asymptotic efficiency.","authors":["Pham Nhat Minh","Khoa Nguyen","Willy Susilo","Khuong Nguyen-An"],"url":"https://arxiv.org/abs/2504.14381"}
{"created":"2025-04-22","title":"LOOPE: Learnable Optimal Patch Order in Positional Embeddings for Vision Transformers","abstract":"Positional embeddings (PE) play a crucial role in Vision Transformers (ViTs) by providing spatial information otherwise lost due to the permutation invariant nature of self attention. While absolute positional embeddings (APE) have shown theoretical advantages over relative positional embeddings (RPE), particularly due to the ability of sinusoidal functions to preserve spatial inductive biases like monotonicity and shift invariance, a fundamental challenge arises when mapping a 2D grid to a 1D sequence. Existing methods have mostly overlooked or never explored the impact of patch ordering in positional embeddings. To address this, we propose LOOPE, a learnable patch-ordering method that optimizes spatial representation for a given set of frequencies, providing a principled approach to patch order optimization. Empirical results show that our PE significantly improves classification accuracy across various ViT architectures. To rigorously evaluate the effectiveness of positional embeddings, we introduce the \"Three Cell Experiment\", a novel benchmarking framework that assesses the ability of PEs to retain relative and absolute positional information across different ViT architectures. Unlike standard evaluations, which typically report a performance gap of 4 to 6% between models with and without PE, our method reveals a striking 30 to 35% difference, offering a more sensitive diagnostic tool to measure the efficacy of PEs. Our experimental analysis confirms that the proposed LOOPE demonstrates enhanced effectiveness in retaining both relative and absolute positional information.","authors":["Md Abtahi Majeed Chowdhury","Md Rifat Ur Rahman","Akil Ahmad Taki"],"url":"https://arxiv.org/abs/2504.14386"}
{"created":"2025-04-22","title":"Balancing Fairness and Performance in Healthcare AI: A Gradient Reconciliation Approach","abstract":"The rapid growth of healthcare data and advances in computational power have accelerated the adoption of artificial intelligence (AI) in medicine. However, AI systems deployed without explicit fairness considerations risk exacerbating existing healthcare disparities, potentially leading to inequitable resource allocation and diagnostic disparities across demographic subgroups. To address this challenge, we propose FairGrad, a novel gradient reconciliation framework that automatically balances predictive performance and multi-attribute fairness optimization in healthcare AI models. Our method resolves conflicting optimization objectives by projecting each gradient vector onto the orthogonal plane of the others, thereby regularizing the optimization trajectory to ensure equitable consideration of all objectives. Evaluated on diverse real-world healthcare datasets and predictive tasks - including Substance Use Disorder (SUD) treatment and sepsis mortality - FairGrad achieved statistically significant improvements in multi-attribute fairness metrics (e.g., equalized odds) while maintaining competitive predictive accuracy. These results demonstrate the viability of harmonizing fairness and utility in mission-critical medical AI applications.","authors":["Xiaoyang Wang","Christopher C. Yang"],"url":"https://arxiv.org/abs/2504.14388"}
{"created":"2025-04-22","title":"A Note on the Complexity of Defensive Domination","abstract":"In a graph G, a k-attack A is any set of at most k vertices and l-defense D is a set of at most l vertices. We say that defense D counters attack A if each a in A can be matched to a distinct defender d in D with a equal to d or a adjacent to d in G. In the defensive domination problem, we are interested in deciding, for a graph G and positive integers k and l given on input, if there exists an l-defense that counters every possible k-attack on G. Defensive domination is a natural resource allocation problem and can be used to model network robustness and security, disaster response strategies, and redundancy designs.","authors":["Steven Chaplick","Grzegorz Gutowski","Tomasz Krawczyk"],"url":"https://arxiv.org/abs/2504.14390"}
{"created":"2025-04-22","title":"How Well Can General Vision-Language Models Learn Medicine By Watching Public Educational Videos?","abstract":"Publicly available biomedical videos, such as those on YouTube, serve as valuable educational resources for medical students. Unlike standard machine learning datasets, these videos are designed for human learners, often mixing medical imagery with narration, explanatory diagrams, and contextual framing. In this work, we investigate whether such pedagogically rich, yet non-standardized and heterogeneous videos can effectively teach general-domain vision-language models biomedical knowledge. To this end, we introduce OpenBiomedVi, a biomedical video instruction tuning dataset comprising 1031 hours of video-caption and Q/A pairs, curated through a multi-step human-in-the-loop pipeline. Diverse biomedical video datasets are rare, and OpenBiomedVid fills an important gap by providing instruction-style supervision grounded in real-world educational content. Surprisingly, despite the informal and heterogeneous nature of these videos, the fine-tuned Qwen-2-VL models exhibit substantial performance improvements across most benchmarks. The 2B model achieves gains of 98.7% on video tasks, 71.2% on image tasks, and 0.2% on text tasks. The 7B model shows improvements of 37.09% on video and 11.2% on image tasks, with a slight degradation of 2.7% on text tasks compared to their respective base models. To address the lack of standardized biomedical video evaluation datasets, we also introduce two new expert curated benchmarks, MIMICEchoQA and SurgeryVideoQA. On these benchmarks, the 2B model achieves gains of 99.1% and 98.1%, while the 7B model shows gains of 22.5% and 52.1%, respectively, demonstrating the models' ability to generalize and perform biomedical video understanding on cleaner and more standardized datasets than those seen during training. These results suggest that educational videos created for human learning offer a surprisingly effective training signal for biomedical VLMs.","authors":["Rahul Thapa","Andrew Li","Qingyang Wu","Bryan He","Yuki Sahashi","Christina Binder","Angela Zhang","Ben Athiwaratkun","Shuaiwen Leon Song","David Ouyang","James Zou"],"url":"https://arxiv.org/abs/2504.14391"}
{"created":"2025-04-22","title":"Graphical Dominance Analysis for Linear Systems: A Frequency-Domain Approach","abstract":"We propose a frequency-domain approach to dominance analysis for multi-input multi-output (MIMO) linear time-invariant systems. The dominance of a MIMO system is defined to be the number of its poles in the open right half-plane. Our approach is graphical: we define a frequency-wise notion of the recently-introduced scaled graph of a MIMO system plotted in a complex plane. The scaled graph provides a bound of the eigenloci of the system, which can be viewed as a robust MIMO extension of the classical Nyquist plot. Our main results characterize sufficient conditions for quantifying the dominance of a closed-loop system based upon separation of scaled graphs of two open-loop systems in a frequency-wise manner. The results reconcile existing small gain, small phase and passivity theorems for feedback dominance analysis.","authors":["Chao Chen","Thomas Chaffey","Rodolphe Sepulchre"],"url":"https://arxiv.org/abs/2504.14394"}
{"created":"2025-04-22","title":"Hydra: An Agentic Reasoning Approach for Enhancing Adversarial Robustness and Mitigating Hallucinations in Vision-Language Models","abstract":"To develop trustworthy Vision-Language Models (VLMs), it is essential to address adversarial robustness and hallucination mitigation, both of which impact factual accuracy in high-stakes applications such as defense and healthcare. Existing methods primarily focus on either adversarial defense or hallucination post-hoc correction, leaving a gap in unified robustness strategies. We introduce \\textbf{Hydra}, an adaptive agentic framework that enhances plug-in VLMs through iterative reasoning, structured critiques, and cross-model verification, improving both resilience to adversarial perturbations and intrinsic model errors. Hydra employs an Action-Critique Loop, where it retrieves and critiques visual information, leveraging Chain-of-Thought (CoT) and In-Context Learning (ICL) techniques to refine outputs dynamically. Unlike static post-hoc correction methods, Hydra adapts to both adversarial manipulations and intrinsic model errors, making it robust to malicious perturbations and hallucination-related inaccuracies. We evaluate Hydra on four VLMs, three hallucination benchmarks, two adversarial attack strategies, and two adversarial defense methods, assessing performance on both clean and adversarial inputs. Results show that Hydra surpasses plug-in VLMs and state-of-the-art (SOTA) dehallucination methods, even without explicit adversarial defenses, demonstrating enhanced robustness and factual consistency. By bridging adversarial resistance and hallucination mitigation, Hydra provides a scalable, training-free solution for improving the reliability of VLMs in real-world applications.","authors":["Chung-En (Johnny)","Yu (Neil)","Hsuan-Chih (Neil)","Chen","Brian Jalaian","Nathaniel D. Bastian"],"url":"https://arxiv.org/abs/2504.14395"}
{"created":"2025-04-22","title":"SphereDiff: Tuning-free Omnidirectional Panoramic Image and Video Generation via Spherical Latent Representation","abstract":"The increasing demand for AR/VR applications has highlighted the need for high-quality 360-degree panoramic content. However, generating high-quality 360-degree panoramic images and videos remains a challenging task due to the severe distortions introduced by equirectangular projection (ERP). Existing approaches either fine-tune pretrained diffusion models on limited ERP datasets or attempt tuning-free methods that still rely on ERP latent representations, leading to discontinuities near the poles. In this paper, we introduce SphereDiff, a novel approach for seamless 360-degree panoramic image and video generation using state-of-the-art diffusion models without additional tuning. We define a spherical latent representation that ensures uniform distribution across all perspectives, mitigating the distortions inherent in ERP. We extend MultiDiffusion to spherical latent space and propose a spherical latent sampling method to enable direct use of pretrained diffusion models. Moreover, we introduce distortion-aware weighted averaging to further improve the generation quality in the projection process. Our method outperforms existing approaches in generating 360-degree panoramic content while maintaining high fidelity, making it a robust solution for immersive AR/VR applications. The code is available here. https://github.com/pmh9960/SphereDiff","authors":["Minho Park","Taewoong Kang","Jooyeol Yun","Sungwon Hwang","Jaegul Choo"],"url":"https://arxiv.org/abs/2504.14396"}
{"created":"2025-04-22","title":"RedMulE-FT: A Reconfigurable Fault-Tolerant Matrix Multiplication Engine","abstract":"As safety-critical applications increasingly rely on data-parallel floating-point computations, there is an increasing need for flexible and configurable fault tolerance in parallel floating-point accelerators such as tensor engines. While replication-based methods ensure reliability but incur high area and power costs, error correction codes lack the flexibility to trade off robustness against performance. This work presents RedMulE-FT, a runtime-configurable fault-tolerant extension of the RedMulE matrix multiplication accelerator, balancing fault tolerance, area overhead, and performance impacts. The fault tolerance mode is configured in a shadowed context register file before task execution. By combining replication with error-detecting codes to protect the data path, RedMulE-FT achieves an 11x uncorrected fault reduction with only 2.3% area overhead. Full protection extends to control signals, resulting in no functional errors after 1M injections during our extensive fault injection simulation campaign, with a total area overhead of 25.2% while maintaining a 500 MHz frequency in a 12 nm technology.","authors":["Philip Wiese","Maurus Item","Luca Bertaccini","Yvan Tortorella","Angelo Garofalo","Luca Benini"],"url":"https://arxiv.org/abs/2504.14399"}
{"created":"2025-04-22","title":"LLM-Driven Usefulness Judgment for Web Search Evaluation","abstract":"Evaluation is fundamental in optimizing search experiences and supporting diverse user intents in Information Retrieval (IR). Traditional search evaluation methods primarily rely on relevance labels, which assess how well retrieved documents match a user's query. However, relevance alone fails to capture a search system's effectiveness in helping users achieve their search goals, making usefulness a critical evaluation criterion. In this paper, we explore an alternative approach: LLM-generated usefulness labels, which incorporate both implicit and explicit user behavior signals to evaluate document usefulness. We propose Task-aware Rubric-based Usefulness Evaluation (TRUE), a rubric-driven evaluation method that employs iterative sampling and reasoning to model complex search behavior patterns. Our findings show that (i) LLMs can generate moderate usefulness labels by leveraging comprehensive search session history incorporating personalization and contextual understanding, and (ii) fine-tuned LLMs improve usefulness judgments when provided with structured search session contexts. Additionally, we examine whether LLMs can distinguish between relevance and usefulness, particularly in cases where this divergence impacts search success. We also conduct an ablation study to identify key metrics for accurate usefulness label generation, optimizing for token efficiency and cost-effectiveness in real-world applications. This study advances LLM-based usefulness evaluation by refining key user metrics, exploring LLM-generated label reliability, and ensuring feasibility for large-scale search systems.","authors":["Mouly Dewan","Jiqun Liu","Aditya Gautam","Chirag Shah"],"url":"https://arxiv.org/abs/2504.14401"}
{"created":"2025-04-22","title":"ScholarMate: A Mixed-Initiative Tool for Qualitative Knowledge Work and Information Sensemaking","abstract":"Synthesizing knowledge from large document collections is a critical yet increasingly complex aspect of qualitative research and knowledge work. While AI offers automation potential, effectively integrating it into human-centric sensemaking workflows remains challenging. We present ScholarMate, an interactive system designed to augment qualitative analysis by unifying AI assistance with human oversight. ScholarMate enables researchers to dynamically arrange and interact with text snippets on a non-linear canvas, leveraging AI for theme suggestions, multi-level summarization, and contextual naming, while ensuring transparency through traceability to source documents. Initial pilot studies indicated that users value this mixed-initiative approach, finding the balance between AI suggestions and direct manipulation crucial for maintaining interpretability and trust. We further demonstrate the system's capability through a case study analyzing 24 papers. By balancing automation with human control, ScholarMate enhances efficiency and supports interpretability, offering a valuable approach for productive human-AI collaboration in demanding sensemaking tasks common in knowledge work.","authors":["Runlong Ye","Patrick Yung Kang Lee","Matthew Varona","Oliver Huang","Carolina Nobre"],"url":"https://arxiv.org/abs/2504.14406"}
{"created":"2025-04-22","title":"Soft and Hard Scaled Relative Graphs for Nonlinear Feedback Stability","abstract":"This paper presents input-output stability analysis of nonlinear feedback systems based on the notion of soft and hard scaled relative graphs (SRGs). The soft and hard SRGs acknowledge the distinction between incremental positivity and incremental passivity and reconcile them from a graphical perspective. The essence of our proposed analysis is that the separation of soft/hard SRGs of two open-loop systems on the complex plane guarantees closed-loop stability. The main results generalize an existing soft SRG separation theorem for bounded open-loop systems which was proved based on interconnection properties of soft SRGs under a chordal assumption. By comparison, our analysis does not require this chordal assumption and applies to possibly unbounded open-loop systems.","authors":["Chao Chen","Sei Zhen Khong","Rodolphe Sepulchre"],"url":"https://arxiv.org/abs/2504.14407"}
{"created":"2025-04-22","title":"Algebraic Barriers to Halving Algorithmic Information Quantities in Correlated Strings","abstract":"We study the possibility of scaling down algorithmic information quantities in tuples of correlated strings. In particular, we address a question raised by Alexander Shen: whether, for any triple of strings \\((a, b, c)\\), there exists a string \\(z\\) such that each of the values of conditional Kolmogorov complexity \\(C(a|z), C(b|z), C(c|z)\\) is approximately half of the corresponding unconditional Kolmogorov complexity. We provide a negative answer to this question by constructing a triple \\((a, b, c)\\) for which no such string \\(z\\) exists. Our construction is based on combinatorial properties of incidences in finite projective planes and relies on recent bounds on point-line incidences over prime fields. As an application, we show that this impossibility implies lower bounds on the communication complexity of secret key agreement protocols in certain settings. These results reveal algebraic obstructions to efficient information exchange and highlight a separation in the information-theoretic behavior of projective planes over fields with and without proper subfields.","authors":["Andrei Romashchenko"],"url":"https://arxiv.org/abs/2504.14408"}
{"created":"2025-04-22","title":"On the Redundancy of Function-Correcting Codes over Finite Fields","abstract":"Function-correcting codes (FCCs) are a class of codes introduced by Lenz et al. (2023) that protect specific function evaluations of a message against errors, imposing a less stringent distance requirement than classical error-correcting codes (ECCs) and thereby allowing for reduced redundancy. For FCCs over binary field, a lower bound on the optimal redundancy for function correction was established by Lenz et al., and we derive an upper bound that remains within a logarithmic factor of this lower bound. We extend this result by proving that the same lower bound holds for any q-ary finite field. Furthermore, we show that for sufficiently large fields, this bound is tight by proving it also serves as an upper bound. In addition, we construct an encoding scheme that achieves this optimal redundancy. Finally, motivated by these two extremal regimes, we conjecture that our bound continues to serve as a valid upper bound across all finite fields.","authors":["Hoang Ly","Emina Soljanin"],"url":"https://arxiv.org/abs/2504.14410"}
{"created":"2025-04-22","title":"Planet as a Brain: Towards Internet of AgentSites based on AIOS Server","abstract":"The internet is undergoing a historical transformation from the \"Internet of Websites\" to the \"Internet of AgentSites.\" While traditional Websites served as the foundation for information hosting and dissemination, a new frontier is emerging where AgentSites serve as the hubs of the internet, where each AgentSite hosts one or more AI agents that receive tasks, address them, and deliver actionable solutions, marking a significant shift in the digital landscape and representing the next generation of online ecosystems. Under this vision, AIOS, the AI Agent Operating System, serves as the server for the development, deployment and execution of AI agents, which is a fundamental infrastructure for the Internet of Agentsites.","authors":["Xiang Zhang","Yongfeng Zhang"],"url":"https://arxiv.org/abs/2504.14411"}
{"created":"2025-04-22","title":"Quantum-Enhanced Reinforcement Learning for Power Grid Security Assessment","abstract":"The increasingly challenging task of maintaining power grid security requires innovative solutions. Novel approaches using reinforcement learning (RL) agents have been proposed to help grid operators navigate the massive decision space and nonlinear behavior of these complex networks. However, applying RL to power grid security assessment, specifically for combinatorially troublesome contingency analysis problems, has proven difficult to scale. The integration of quantum computing into these RL frameworks helps scale by improving computational efficiency and boosting agent proficiency by leveraging quantum advantages in action exploration and model-based interdependence. To demonstrate a proof-of-concept use of quantum computing for RL agent training and simulation, we propose a hybrid agent that runs on quantum hardware using IBM's Qiskit Runtime. We also provide detailed insight into the construction of parameterized quantum circuits (PQCs) for generating relevant quantum output. This agent's proficiency at maintaining grid stability is demonstrated relative to a benchmark model without quantum enhancement using N-k contingency analysis. Additionally, we offer a comparative assessment of the training procedures for RL models integrated with a quantum backend.","authors":["Benjamin M. Peter","Mert Korkali"],"url":"https://arxiv.org/abs/2504.14412"}
{"created":"2025-04-22","title":"On the $p$-adic Skolem Problem","abstract":"The Skolem Problem asks to determine whether a given linear recurrence sequence (LRS) has a zero term. Showing decidability of this problem is equivalent to giving an effective proof of the Skolem-Mahler-Lech Theorem, which asserts that a non-degenerate LRS has finitely many zeros. The latter result was proven over 90 years ago via an ineffective method showing that such an LRS has only finitely many $p$-adic zeros. In this paper we consider the problem of determining whether a given LRS has a $p$-adic zero, as well as the corresponding function problem of computing all $p$-adic zeros up to arbitrary precision. We present algorithms for both problems and report on their implementation within the Skolem tool. The output of the algorithms is unconditionally correct, and termination is guaranteed subject to the $p$-adic Schanuel Conjecture (a standard number-theoretic hypothesis concerning the $p$-adic exponential function). While these algorithms do not solve the Skolem Problem, they can be exploited to find natural-number and rational zeros under additional hypotheses. To illustrate this, we apply our results to show decidability of the Simultaneous Skolem Problem (determine whether two coprime linear recurrences have a common natural-number zero), again subject to the $p$-adic Schanuel Conjecture.","authors":["Piotr Bacik","Jo\\\"el Ouaknine","David Purser","James Worrell"],"url":"https://arxiv.org/abs/2504.14413"}
{"created":"2025-04-22","title":"Exploring Pseudo-Token Approaches in Transformer Neural Processes","abstract":"Neural Processes (NPs) have gained attention in meta-learning for their ability to quantify uncertainty, together with their rapid prediction and adaptability. However, traditional NPs are prone to underfitting. Transformer Neural Processes (TNPs) significantly outperform existing NPs, yet their applicability in real-world scenarios is hindered by their quadratic computational complexity relative to both context and target data points. To address this, pseudo-token-based TNPs (PT-TNPs) have emerged as a novel NPs subset that condense context data into latent vectors or pseudo-tokens, reducing computational demands. We introduce the Induced Set Attentive Neural Processes (ISANPs), employing Induced Set Attention and an innovative query phase to improve querying efficiency. Our evaluations show that ISANPs perform competitively with TNPs and often surpass state-of-the-art models in 1D regression, image completion, contextual bandits, and Bayesian optimization. Crucially, ISANPs offer a tunable balance between performance and computational complexity, which scale well to larger datasets where TNPs face limitations.","authors":["Jose Lara-Rangel","Nanze Chen","Fengzhe Zhang"],"url":"https://arxiv.org/abs/2504.14416"}
{"created":"2025-04-22","title":"Unlearning Works Better Than You Think: Local Reinforcement-Based Selection of Auxiliary Objectives","abstract":"We introduce Local Reinforcement-Based Selection of Auxiliary Objectives (LRSAO), a novel approach that selects auxiliary objectives using reinforcement learning (RL) to support the optimization process of an evolutionary algorithm (EA) as in EA+RL framework and furthermore incorporates the ability to unlearn previously used objectives. By modifying the reward mechanism to penalize moves that do no increase the fitness value and relying on the local auxiliary objectives, LRSAO dynamically adapts its selection strategy to optimize performance according to the landscape and unlearn previous objectives when necessary.","authors":["Abderrahim Bendahi","Adrien Fradin","Matthieu Lerasle"],"url":"https://arxiv.org/abs/2504.14418"}
{"created":"2025-04-22","title":"How Do Mobile Applications Enhance Security? An Exploratory Analysis of Use Cases and Provided Information","abstract":"The ubiquity of mobile applications has increased dramatically in recent years, opening up new opportunities for cyber attackers and heightening security concerns in the mobile ecosystem. As a result, researchers and practitioners have intensified their research into improving the security and privacy of mobile applications. At the same time, more and more mobile applications have appeared on the market that address the aforementioned security issues. However, both academia and industry currently lack a comprehensive overview of these mobile security applications for Android and iOS platforms, including their respective use cases and the security information they provide.","authors":["Irdin Pekaric","Clemens Sauerwein","Simon Laichner","Ruth Breu"],"url":"https://arxiv.org/abs/2504.14421"}
{"created":"2025-04-22","title":"Adversarial Attack for RGB-Event based Visual Object Tracking","abstract":"Visual object tracking is a crucial research topic in the fields of computer vision and multi-modal fusion. Among various approaches, robust visual tracking that combines RGB frames with Event streams has attracted increasing attention from researchers. While striving for high accuracy and efficiency in tracking, it is also important to explore how to effectively conduct adversarial attacks and defenses on RGB-Event stream tracking algorithms, yet research in this area remains relatively scarce. To bridge this gap, in this paper, we propose a cross-modal adversarial attack algorithm for RGB-Event visual tracking. Because of the diverse representations of Event streams, and given that Event voxels and frames are more commonly used, this paper will focus on these two representations for an in-depth study. Specifically, for the RGB-Event voxel, we first optimize the perturbation by adversarial loss to generate RGB frame adversarial examples. For discrete Event voxel representations, we propose a two-step attack strategy, more in detail, we first inject Event voxels into the target region as initialized adversarial examples, then, conduct a gradient-guided optimization by perturbing the spatial location of the Event voxels. For the RGB-Event frame based tracking, we optimize the cross-modal universal perturbation by integrating the gradient information from multimodal data. We evaluate the proposed approach against attacks on three widely used RGB-Event Tracking datasets, i.e., COESOT, FE108, and VisEvent. Extensive experiments show that our method significantly reduces the performance of the tracker across numerous datasets in both unimodal and multimodal scenarios. The source code will be released on https://github.com/Event-AHU/Adversarial_Attack_Defense","authors":["Qiang Chen","Xiao Wang","Haowen Wang","Bo Jiang","Lin Zhu","Dawei Zhang","Yonghong Tian","Jin Tang"],"url":"https://arxiv.org/abs/2504.14423"}
{"created":"2025-04-22","title":"Optimizing SIA Development: A Case Study in User-Centered Design for Estuary, a Multimodal Socially Interactive Agent Framework","abstract":"This case study presents our user-centered design model for Socially Intelligent Agent (SIA) development frameworks through our experience developing Estuary, an open source multimodal framework for building low-latency real-time socially interactive agents. We leverage the Rapid Assessment Process (RAP) to collect the thoughts of leading researchers in the field of SIAs regarding the current state of the art for SIA development as well as their evaluation of how well Estuary may potentially address current research gaps. We achieve this through a series of end-user interviews conducted by a fellow researcher in the community. We hope that the findings of our work will not only assist the continued development of Estuary but also guide the development of other future frameworks and technologies for SIAs.","authors":["Spencer Lin","Miru Jun","Basem Rizk","Karen Shieh","Scott Fisher","Sharon Mozgai"],"url":"https://arxiv.org/abs/2504.14427"}
{"created":"2025-04-22","title":"ResNetVLLM-2: Addressing ResNetVLLM's Multi-Modal Hallucinations","abstract":"Large Language Models (LLMs) have transformed natural language processing (NLP) tasks, but they suffer from hallucination, generating plausible yet factually incorrect content. This issue extends to Video-Language Models (VideoLLMs), where textual descriptions may inaccurately represent visual content, resulting in multi-modal hallucinations. In this paper, we address hallucination in ResNetVLLM, a video-language model combining ResNet visual encoders with LLMs. We introduce a two-step protocol: (1) a faithfulness detection strategy that uses a modified Lynx model to assess semantic alignment between generated captions and ground-truth video references, and (2) a hallucination mitigation strategy using Retrieval-Augmented Generation (RAG) with an ad-hoc knowledge base dynamically constructed during inference. Our enhanced model, ResNetVLLM-2, reduces multi-modal hallucinations by cross-verifying generated content against external knowledge, improving factual consistency. Evaluation on the ActivityNet-QA benchmark demonstrates a substantial accuracy increase from 54.8% to 65.3%, highlighting the effectiveness of our hallucination detection and mitigation strategies in enhancing video-language model reliability.","authors":["Ahmad Khalil","Mahmoud Khalil","Alioune Ngom"],"url":"https://arxiv.org/abs/2504.14429"}
{"created":"2025-04-22","title":"Admission Control with Reconfigurable Intelligent Surfaces for 6G Mobile Edge Computing","abstract":"As 6G networks must support diverse applications with heterogeneous quality-of-service requirements, efficient allocation of limited network resources becomes important. This paper addresses the critical challenge of user admission control in 6G networks enhanced by Reconfigurable Intelligent Surfaces (RIS) and Mobile Edge Computing (MEC). We propose an optimization framework that leverages RIS technology to enhance user admission based on spatial characteristics, priority levels, and resource constraints. Our approach first filters users based on angular alignment with RIS reflection directions, then constructs priority queues considering service requirements and arrival times, and finally performs user grouping to maximize RIS resource utilization. The proposed algorithm incorporates a utility function that balances Quality of Service (QoS) performance, RIS utilization, and MEC efficiency in admission decisions. Simulation results demonstrate that our approach significantly improves system performance with RIS-enhanced configurations. For high-priority eURLLC services, our method maintains over 90% admission rates even at maximum load, ensuring mission-critical applications receive guaranteed service quality.","authors":["Ye Zhang","Baiyun Xiao","Jyoti Sahni","Alvin Valera","Wuyungerile Li","Winston K. G. Seah"],"url":"https://arxiv.org/abs/2504.14430"}
{"created":"2025-04-22","title":"ResNetVLLM -- Multi-modal Vision LLM for the Video Understanding Task","abstract":"In this paper, we introduce ResNetVLLM (ResNet Vision LLM), a novel cross-modal framework for zero-shot video understanding that integrates a ResNet-based visual encoder with a Large Language Model (LLM. ResNetVLLM addresses the challenges associated with zero-shot video models by avoiding reliance on pre-trained video understanding models and instead employing a non-pretrained ResNet to extract visual features. This design ensures the model learns visual and semantic representations within a unified architecture, enhancing its ability to generate accurate and contextually relevant textual descriptions from video inputs. Our experimental results demonstrate that ResNetVLLM achieves state-of-the-art performance in zero-shot video understanding (ZSVU) on several benchmarks, including MSRVTT-QA, MSVD-QA, TGIF-QA FrameQA, and ActivityNet-QA.","authors":["Ahmad Khalil","Mahmoud Khalil","Alioune Ngom"],"url":"https://arxiv.org/abs/2504.14432"}
{"created":"2025-04-22","title":"Deuteronomy 2.0: Record Caching and Latch Freedom","abstract":"The Deuteronomy transactional key-value store is unique architecturally in providing separation between transaction functionality -- its Transactional Component (TC) and data management -- its Data Component (DC). It is unique in technology by (1) supporting record caching, a smaller unit than the traditional page; and (2) protecting resources during concurrent execution using a latch-free approach. Both technologies are enabled by delta updating. This paper explains how record caching improves cache cost/performance. It also shows how a new latch-free approach makes implementation easier and improves performance.","authors":["David Lomet"],"url":"https://arxiv.org/abs/2504.14435"}
{"created":"2025-04-22","title":"Application of Deep Reinforcement Learning for Intrusion Detection in Internet of Things: A Systematic Review","abstract":"The Internet of Things (IoT) has significantly expanded the digital landscape, interconnecting an unprecedented array of devices, from home appliances to industrial equipment. This growth enhances functionality, e.g., automation, remote monitoring, and control, and introduces substantial security challenges, especially in defending these devices against cyber threats. Intrusion Detection Systems (IDS) are crucial for securing IoT; however, traditional IDS often struggle to adapt to IoT networks' dynamic and evolving nature and threat patterns. A potential solution is using Deep Reinforcement Learning (DRL) to enhance IDS adaptability, enabling them to learn from and react to their operational environment dynamically. This systematic review examines the application of DRL to enhance IDS in IoT settings, covering research from the past ten years. This review underscores the state-of-the-art DRL techniques employed to improve adaptive threat detection and real-time security across IoT domains by analyzing various studies. Our findings demonstrate that DRL significantly enhances IDS capabilities by enabling systems to learn and adapt from their operational environment. This adaptability allows IDS to improve threat detection accuracy and minimize false positives, making it more effective in identifying genuine threats while reducing unnecessary alerts. Additionally, this systematic review identifies critical research gaps and future research directions, emphasizing the necessity for more diverse datasets, enhanced reproducibility, and improved integration with emerging IoT technologies. This review aims to foster the development of dynamic and adaptive IDS solutions essential for protecting IoT networks against sophisticated cyber threats.","authors":["Saeid Jamshidia","Amin Nikanjama","Kawser Wazed Nafia","Foutse Khomha","Rasoul Rastab"],"url":"https://arxiv.org/abs/2504.14436"}
{"created":"2025-04-22","title":"Information Diffusion and Preferential Attachment in a Network of Large Language Models","abstract":"This paper models information diffusion in a network of Large Language Models (LLMs) that is designed to answer queries from distributed datasets, where the LLMs can hallucinate the answer. We introduce a two-time-scale dynamical model for the centrally administered network, where opinions evolve faster while the network's degree distribution changes more slowly. Using a mean-field approximation, we establish conditions for a locally asymptotically stable equilibrium where all LLMs remain truthful. We provide approximation guarantees for the mean-field approximation and a singularly perturbed approximation of the two-time-scale system. To mitigate hallucination and improve the influence of truthful nodes, we propose a reputation-based preferential attachment mechanism that reconfigures the network based on LLMs' evaluations of their neighbors. Numerical experiments on an open-source LLM (LLaMA-3.1-8B) validate the efficacy of our preferential attachment mechanism and demonstrate the optimization of a cost function for the two-time-scale system.","authors":["Adit Jain","Vikram Krishnamurthy","Yiming Zhang"],"url":"https://arxiv.org/abs/2504.14438"}
{"created":"2025-04-22","title":"LoRe: Personalizing LLMs via Low-Rank Reward Modeling","abstract":"Personalizing large language models (LLMs) to accommodate diverse user preferences is essential for enhancing alignment and user satisfaction. Traditional reinforcement learning from human feedback (RLHF) approaches often rely on monolithic value representations, limiting their ability to adapt to individual preferences. We introduce a novel framework that leverages low-rank preference modeling to efficiently learn and generalize user-specific reward functions. By representing reward functions in a low-dimensional subspace and modeling individual preferences as weighted combinations of shared basis functions, our approach avoids rigid user categorization while enabling scalability and few-shot adaptation. We validate our method on multiple preference datasets, demonstrating superior generalization to unseen users and improved accuracy in preference prediction tasks.","authors":["Avinandan Bose","Zhihan Xiong","Yuejie Chi","Simon Shaolei Du","Lin Xiao","Maryam Fazel"],"url":"https://arxiv.org/abs/2504.14439"}
{"created":"2025-04-22","title":"SG-Reg: Generalizable and Efficient Scene Graph Registration","abstract":"This paper addresses the challenges of registering two rigid semantic scene graphs, an essential capability when an autonomous agent needs to register its map against a remote agent, or against a prior map. The hand-crafted descriptors in classical semantic-aided registration, or the ground-truth annotation reliance in learning-based scene graph registration, impede their application in practical real-world environments. To address the challenges, we design a scene graph network to encode multiple modalities of semantic nodes: open-set semantic feature, local topology with spatial awareness, and shape feature. These modalities are fused to create compact semantic node features. The matching layers then search for correspondences in a coarse-to-fine manner. In the back-end, we employ a robust pose estimator to decide transformation according to the correspondences. We manage to maintain a sparse and hierarchical scene representation. Our approach demands fewer GPU resources and fewer communication bandwidth in multi-agent tasks. Moreover, we design a new data generation approach using vision foundation models and a semantic mapping module to reconstruct semantic scene graphs. It differs significantly from previous works, which rely on ground-truth semantic annotations to generate data. We validate our method in a two-agent SLAM benchmark. It significantly outperforms the hand-crafted baseline in terms of registration success rate. Compared to visual loop closure networks, our method achieves a slightly higher registration recall while requiring only 52 KB of communication bandwidth for each query frame. Code available at: \\href{http://github.com/HKUST-Aerial-Robotics/SG-Reg}{http://github.com/HKUST-Aerial-Robotics/SG-Reg}.","authors":["Chuhao Liu","Zhijian Qiao","Jieqi Shi","Ke Wang","Peize Liu","Shaojie Shen"],"url":"https://arxiv.org/abs/2504.14440"}
{"created":"2025-04-22","title":"SkyNetPredictor: Network Performance Prediction in Avionic Communication using AI","abstract":"Satellite-based communication systems are integral to delivering high-speed data services in aviation, particularly for business aviation operations requiring global connectivity. These systems, however, are challenged by a multitude of interdependent factors such as satellite handovers, congestion, flight maneuvers and seasonal trends, making network performance prediction a complex task. No established methodologies currently exist for network performance prediction in avionic communication systems. This paper addresses the gap by proposing machine learning (ML)-based approaches for pre-flight network performance predictions. The proposed models predict performance along a given flight path, taking as input positional and network-related information and outputting the predicted performance for each position. In business aviation, flight crews typically have multiple flight plans to choose from for each city pair, allowing them to select the most optimal option. This approach enables proactive decision-making, such as selecting optimal flight paths prior to departure.","authors":["Hind Mukhtar","Raymond Schaub","Melike Erol-Kantarci"],"url":"https://arxiv.org/abs/2504.14443"}
{"created":"2025-04-22","title":"WT-BCP: Wavelet Transform based Bidirectional Copy-Paste for Semi-Supervised Medical Image Segmentation","abstract":"Semi-supervised medical image segmentation (SSMIS) shows promise in reducing reliance on scarce labeled medical data. However, SSMIS field confronts challenges such as distribution mismatches between labeled and unlabeled data, artificial perturbations causing training biases, and inadequate use of raw image information, especially low-frequency (LF) and high-frequency (HF) components.To address these challenges, we propose a Wavelet Transform based Bidirectional Copy-Paste SSMIS framework, named WT-BCP, which improves upon the Mean Teacher approach. Our method enhances unlabeled data understanding by copying random crops between labeled and unlabeled images and employs WT to extract LF and HF details.We propose a multi-input and multi-output model named XNet-Plus, to receive the fused information after WT. Moreover, consistency training among multiple outputs helps to mitigate learning biases introduced by artificial perturbations. During consistency training, the mixed images resulting from WT are fed into both models, with the student model's output being supervised by pseudo-labels and ground-truth. Extensive experiments conducted on 2D and 3D datasets confirm the effectiveness of our model.Code: https://github.com/simzhangbest/WT-BCP.","authors":["Mingya Zhang","Liang Wang","Limei Gu","Tingsheng Ling","Xianping Tao"],"url":"https://arxiv.org/abs/2504.14445"}
{"created":"2025-04-22","title":"Neglected Risks: The Disturbing Reality of Children's Images in Datasets and the Urgent Call for Accountability","abstract":"Including children's images in datasets has raised ethical concerns, particularly regarding privacy, consent, data protection, and accountability. These datasets, often built by scraping publicly available images from the Internet, can expose children to risks such as exploitation, profiling, and tracking. Despite the growing recognition of these issues, approaches for addressing them remain limited. We explore the ethical implications of using children's images in AI datasets and propose a pipeline to detect and remove such images. As a use case, we built the pipeline on a Vision-Language Model under the Visual Question Answering task and tested it on the #PraCegoVer dataset. We also evaluate the pipeline on a subset of 100,000 images from the Open Images V7 dataset to assess its effectiveness in detecting and removing images of children. The pipeline serves as a baseline for future research, providing a starting point for more comprehensive tools and methodologies. While we leverage existing models trained on potentially problematic data, our goal is to expose and address this issue. We do not advocate for training or deploying such models, but instead call for urgent community reflection and action to protect children's rights. Ultimately, we aim to encourage the research community to exercise - more than an additional - care in creating new datasets and to inspire the development of tools to protect the fundamental rights of vulnerable groups, particularly children.","authors":["Carlos Caetano","Gabriel O. dos Santos","Caio Petrucci","Artur Barros","Camila Laranjeira","Leo S. F. Ribeiro","J\\'ulia F. de Mendon\\c{c}a","Jefersson A. dos Santos","Sandra Avila"],"url":"https://arxiv.org/abs/2504.14446"}
{"created":"2025-04-22","title":"Seeing Through Risk: A Symbolic Approximation of Prospect Theory","abstract":"We propose a novel symbolic modeling framework for decision-making under risk that merges interpretability with the core insights of Prospect Theory. Our approach replaces opaque utility curves and probability weighting functions with transparent, effect-size-guided features. We mathematically formalize the method, demonstrate its ability to replicate well-known framing and loss-aversion phenomena, and provide an end-to-end empirical validation on synthetic datasets. The resulting model achieves competitive predictive performance while yielding clear coefficients mapped onto psychological constructs, making it suitable for applications ranging from AI safety to economic policy analysis.","authors":["Ali Arslan Yousaf","Umair Rehman","Muhammad Umair Danish"],"url":"https://arxiv.org/abs/2504.14448"}
{"created":"2025-04-22","title":"Causal Disentanglement for Robust Long-tail Medical Image Generation","abstract":"Counterfactual medical image generation effectively addresses data scarcity and enhances the interpretability of medical images. However, due to the complex and diverse pathological features of medical images and the imbalanced class distribution in medical data, generating high-quality and diverse medical images from limited data is significantly challenging. Additionally, to fully leverage the information in limited data, such as anatomical structure information and generate more structurally stable medical images while avoiding distortion or inconsistency. In this paper, in order to enhance the clinical relevance of generated data and improve the interpretability of the model, we propose a novel medical image generation framework, which generates independent pathological and structural features based on causal disentanglement and utilizes text-guided modeling of pathological features to regulate the generation of counterfactual images. First, we achieve feature separation through causal disentanglement and analyze the interactions between features. Here, we introduce group supervision to ensure the independence of pathological and identity features. Second, we leverage a diffusion model guided by pathological findings to model pathological features, enabling the generation of diverse counterfactual images. Meanwhile, we enhance accuracy by leveraging a large language model to extract lesion severity and location from medical reports. Additionally, we improve the performance of the latent diffusion model on long-tailed categories through initial noise optimization.","authors":["Weizhi Nie","Zichun Zhang","Weijie Wang","Bruno Lepri","Anan Liu","Nicu Seb"],"url":"https://arxiv.org/abs/2504.14450"}
{"created":"2025-04-22","title":"ParaPO: Aligning Language Models to Reduce Verbatim Reproduction of Pre-training Data","abstract":"Language models (LMs) can memorize and reproduce segments from their pretraining data verbatim even in non-adversarial settings, raising concerns about copyright, plagiarism, privacy, and creativity. We introduce Paraphrase Preference Optimization (ParaPO), a post-training method that fine-tunes LMs to reduce unintentional regurgitation while preserving their overall utility. ParaPO trains LMs to prefer paraphrased versions of memorized segments over the original verbatim content from the pretraining data. To maintain the ability to recall famous quotations when appropriate, we develop a variant of ParaPO that uses system prompts to control regurgitation behavior. In our evaluation on Llama3.1-8B, ParaPO consistently reduces regurgitation across all tested datasets (e.g., reducing the regurgitation metric from 17.3 to 12.9 in creative writing), whereas unlearning methods used in prior work to mitigate regurgitation are less effective outside their targeted unlearned domain (from 17.3 to 16.9). When applied to the instruction-tuned Tulu3-8B model, ParaPO with system prompting successfully preserves famous quotation recall while reducing unintentional regurgitation (from 8.7 to 6.3 in creative writing) when prompted not to regurgitate. In contrast, without ParaPO tuning, prompting the model not to regurgitate produces only a marginal reduction (8.7 to 8.4).","authors":["Tong Chen","Faeze Brahman","Jiacheng Liu","Niloofar Mireshghallah","Weijia Shi","Pang Wei Koh","Luke Zettlemoyer","Hannaneh Hajishirzi"],"url":"https://arxiv.org/abs/2504.14452"}
{"created":"2025-04-22","title":"Metamon-GS: Enhancing Representability with Variance-Guided Densification and Light Encoding","abstract":"The introduction of 3D Gaussian Splatting (3DGS) has advanced novel view synthesis by utilizing Gaussians to represent scenes. Encoding Gaussian point features with anchor embeddings has significantly enhanced the performance of newer 3DGS variants. While significant advances have been made, it is still challenging to boost rendering performance. Feature embeddings have difficulty accurately representing colors from different perspectives under varying lighting conditions, which leads to a washed-out appearance. Another reason is the lack of a proper densification strategy that prevents Gaussian point growth in thinly initialized areas, resulting in blurriness and needle-shaped artifacts. To address them, we propose Metamon-GS, from innovative viewpoints of variance-guided densification strategy and multi-level hash grid. The densification strategy guided by variance specifically targets Gaussians with high gradient variance in pixels and compensates for the importance of regions with extra Gaussians to improve reconstruction. The latter studies implicit global lighting conditions and accurately interprets color from different perspectives and feature embeddings. Our thorough experiments on publicly available datasets show that Metamon-GS surpasses its baseline model and previous versions, delivering superior quality in rendering novel views.","authors":["Junyan Su","Baozhu Zhao","Xiaohan Zhang","Qi Liu"],"url":"https://arxiv.org/abs/2504.14460"}
{"created":"2025-04-22","title":"CoLoTa: A Dataset for Entity-based Commonsense Reasoning over Long-Tail Knowledge","abstract":"The rise of Large Language Models (LLMs) has redefined the AI landscape, particularly due to their ability to encode factual and commonsense knowledge, and their outstanding performance in tasks requiring reasoning. Despite these advances, hallucinations and reasoning errors remain a significant barrier to their deployment in high-stakes settings. In this work, we observe that even the most prominent LLMs, such as OpenAI-o1, suffer from high rates of reasoning errors and hallucinations on tasks requiring commonsense reasoning over obscure, long-tail entities. To investigate this limitation, we present a new dataset for Commonsense reasoning over Long-Tail entities (CoLoTa), that consists of 3,300 queries from question answering and claim verification tasks and covers a diverse range of commonsense reasoning skills. We remark that CoLoTa can also serve as a Knowledge Graph Question Answering (KGQA) dataset since the support of knowledge required to answer its queries is present in the Wikidata knowledge graph. However, as opposed to existing KGQA benchmarks that merely focus on factoid questions, our CoLoTa queries also require commonsense reasoning. Our experiments with strong LLM-based KGQA methodologies indicate their severe inability to answer queries involving commonsense reasoning. Hence, we propose CoLoTa as a novel benchmark for assessing both (i) LLM commonsense reasoning capabilities and their robustness to hallucinations on long-tail entities and (ii) the commonsense reasoning capabilities of KGQA methods.","authors":["Armin Toroghi","Willis Guo","Scott Sanner"],"url":"https://arxiv.org/abs/2504.14462"}
{"created":"2025-04-22","title":"Joint Channel Estimation and Signal Detection for MIMO-OFDM: A Novel Data-Aided Approach with Reduced Computational Overhead","abstract":"The acquisition of channel state information (CSI) is essential in MIMO-OFDM communication systems. Data-aided enhanced receivers, by incorporating domain knowledge, effectively mitigate performance degradation caused by imperfect CSI, particularly in dynamic wireless environments. However, existing methodologies face notable challenges: they either refine channel estimates within MIMO subsystems separately, which proves ineffective due to deviations from assumptions regarding the time-varying nature of channels, or fully exploit the time-frequency characteristics but incur significantly high computational overhead due to dimensional concatenation. To address these issues, this study introduces a novel data-aided method aimed at reducing complexity, particularly suited for fast-fading scenarios in fifth-generation (5G) and beyond networks. We derive a general form of a data-aided linear minimum mean-square error (LMMSE)-based algorithm, optimized for iterative joint channel estimation and signal detection. Additionally, we propose a computationally efficient alternative to this algorithm, which achieves comparable performance with significantly reduced complexity. Empirical evaluations reveal that our proposed algorithms outperform several state-of-the-art approaches across various MIMO-OFDM configurations, pilot sequence lengths, and in the presence of time variability. Comparative analysis with basis expansion model-based iterative receivers highlights the superiority of our algorithms in achieving an effective trade-off between accuracy and computational complexity.","authors":["Xinjie Li","Jing Zhang","Xingyu Zhou","Chao-Kai Wen","Shi Jin"],"url":"https://arxiv.org/abs/2504.14463"}
{"created":"2025-04-22","title":"A Bio-inspired Asymmetric Double-Gate Ferroelectric FET for Emulating Astrocyte and Dendrite Dynamics in Neuromorphic Systems","abstract":"Neuromorphic systems seek to replicate the functionalities of biological neural networks to attain significant improvements in performance and efficiency of AI computing platforms. However, these systems have generally remained limited to emulation of simple neurons and synapses; and ignored higher order functionalities enabled by other components of the brain like astrocytes and dendrites. In this work, drawing inspiration from biology, we introduce a compact Double-Gate Ferroelectric Field Effect Transistor (DG-FeFET) cell that can emulate the dynamics of both astrocytes and dendrites within neuromorphic architectures. We demonstrate that with a ferroelectric top gate for synaptic weight programming as in conventional synapses and a non-ferroelectric back gate, the DG-FeFET realizes a synapse with a dynamic gain modulation mechanism. This can be leveraged as an analog for a compact astrocyte-tripartite synapse, as well as enabling dendrite-like gain modulation operations. By employing a fully-depleted silicon-on-insulator (FDSOI) FeFET as our double-gate device, we validate the linear control of the synaptic weight via the back gate terminal (i.e., the gate underneath the buried oxide (BOX) layer) through comprehensive theoretical and experimental studies. We showcase the promise such a tripartite synaptic device holds for numerous important neuromorphic applications, including autonomous self-repair of faulty neuromorphic hardware mediated by astrocytic functionality. Coordinate transformations based on dragonfly prey-interception circuitry models are also demonstrated based on dendritic function emulation by the device. This work paves the way forward for developing truly \"brain-like\" neuromorphic hardware that go beyond the current dogma focusing only on neurons and synapses.","authors":["Zhouhang Jiang","A N M Nafiul Islam","Zhuangyu Han","Zijian Zhao","Franz M\\\"uller","Jiahui Duan","Halid Mulaosmanovic","Stefan D\\\"unkel","Sven Beyer","Sourav Dutta","Vijaykrishnan Narayanan","Thomas K\\\"ampfe","Suma George Cardwell","Frances Chance","Abhronil Sengupta","Kai Ni"],"url":"https://arxiv.org/abs/2504.14466"}
{"created":"2025-04-22","title":"LGD: Leveraging Generative Descriptions for Zero-Shot Referring Image Segmentation","abstract":"Zero-shot referring image segmentation aims to locate and segment the target region based on a referring expression, with the primary challenge of aligning and matching semantics across visual and textual modalities without training. Previous works address this challenge by utilizing Vision-Language Models and mask proposal networks for region-text matching. However, this paradigm may lead to incorrect target localization due to the inherent ambiguity and diversity of free-form referring expressions. To alleviate this issue, we present LGD (Leveraging Generative Descriptions), a framework that utilizes the advanced language generation capabilities of Multi-Modal Large Language Models to enhance region-text matching performance in Vision-Language Models. Specifically, we first design two kinds of prompts, the attribute prompt and the surrounding prompt, to guide the Multi-Modal Large Language Models in generating descriptions related to the crucial attributes of the referent object and the details of surrounding objects, referred to as attribute description and surrounding description, respectively. Secondly, three visual-text matching scores are introduced to evaluate the similarity between instance-level visual features and textual features, which determines the mask most associated with the referring expression. The proposed method achieves new state-of-the-art performance on three public datasets RefCOCO, RefCOCO+ and RefCOCOg, with maximum improvements of 9.97% in oIoU and 11.29% in mIoU compared to previous methods.","authors":["Jiachen Li","Qing Xie","Xiaohan Yu","Hongyun Wang","Jinyu Xu","Yongjian Liu","Yongsheng Gao"],"url":"https://arxiv.org/abs/2504.14467"}
{"created":"2025-04-22","title":"sEEG-based Encoding for Sentence Retrieval: A Contrastive Learning Approach to Brain-Language Alignment","abstract":"Interpreting neural activity through meaningful latent representations remains a complex and evolving challenge at the intersection of neuroscience and artificial intelligence. We investigate the potential of multimodal foundation models to align invasive brain recordings with natural language. We present SSENSE, a contrastive learning framework that projects single-subject stereo-electroencephalography (sEEG) signals into the sentence embedding space of a frozen CLIP model, enabling sentence-level retrieval directly from brain activity. SSENSE trains a neural encoder on spectral representations of sEEG using InfoNCE loss, without fine-tuning the text encoder. We evaluate our method on time-aligned sEEG and spoken transcripts from a naturalistic movie-watching dataset. Despite limited data, SSENSE achieves promising results, demonstrating that general-purpose language representations can serve as effective priors for neural decoding.","authors":["Yijun Liu"],"url":"https://arxiv.org/abs/2504.14468"}
{"created":"2025-04-22","title":"A computational framework for longitudinal medication adherence prediction in breast cancer survivors: A social cognitive theory based approach","abstract":"Non-adherence to medications is a critical concern since nearly half of patients with chronic illnesses do not follow their prescribed medication regimens, leading to increased mortality, costs, and preventable human distress. Amongst stage 0-3 breast cancer survivors, adherence to long-term adjuvant endocrine therapy (i.e., Tamoxifen and aromatase inhibitors) is associated with a significant increase in recurrence-free survival. This work aims to develop multi-scale models of medication adherence to understand the significance of different factors influencing adherence across varying time frames. We introduce a computational framework guided by Social Cognitive Theory for multi-scale (daily and weekly) modeling of longitudinal medication adherence. Our models employ both dynamic medication-taking patterns in the recent past (dynamic factors) as well as less frequently changing factors (static factors) for adherence prediction. Additionally, we assess the significance of various factors in influencing adherence behavior across different time scales. Our models outperform traditional machine learning counterparts in both daily and weekly tasks in terms of both accuracy and specificity. Daily models achieved an accuracy of 87.25%, and weekly models, an accuracy of 76.04%. Notably, dynamic past medication-taking patterns prove most valuable for predicting daily adherence, while a combination of dynamic and static factors is significant for macro-level weekly adherence patterns.","authors":["Navreet Kaur","Manuel Gonzales IV","Cristian Garcia Alcaraz","Jiaqi Gong","Kristen J. Wells","Laura E. Barnes"],"url":"https://arxiv.org/abs/2504.14469"}
{"created":"2025-04-22","title":"Turbo2K: Towards Ultra-Efficient and High-Quality 2K Video Synthesis","abstract":"Demand for 2K video synthesis is rising with increasing consumer expectations for ultra-clear visuals. While diffusion transformers (DiTs) have demonstrated remarkable capabilities in high-quality video generation, scaling them to 2K resolution remains computationally prohibitive due to quadratic growth in memory and processing costs. In this work, we propose Turbo2K, an efficient and practical framework for generating detail-rich 2K videos while significantly improving training and inference efficiency. First, Turbo2K operates in a highly compressed latent space, reducing computational complexity and memory footprint, making high-resolution video synthesis feasible. However, the high compression ratio of the VAE and limited model size impose constraints on generative quality. To mitigate this, we introduce a knowledge distillation strategy that enables a smaller student model to inherit the generative capacity of a larger, more powerful teacher model. Our analysis reveals that, despite differences in latent spaces and architectures, DiTs exhibit structural similarities in their internal representations, facilitating effective knowledge transfer. Second, we design a hierarchical two-stage synthesis framework that first generates multi-level feature at lower resolutions before guiding high-resolution video generation. This approach ensures structural coherence and fine-grained detail refinement while eliminating redundant encoding-decoding overhead, further enhancing computational efficiency.Turbo2K achieves state-of-the-art efficiency, generating 5-second, 24fps, 2K videos with significantly reduced computational cost. Compared to existing methods, Turbo2K is up to 20$\\times$ faster for inference, making high-resolution video generation more scalable and practical for real-world applications.","authors":["Jingjing Ren","Wenbo Li","Zhongdao Wang","Haoze Sun","Bangzhen Liu","Haoyu Chen","Jiaqi Xu","Aoxue Li","Shifeng Zhang","Bin Shao","Yong Guo","Lei Zhu"],"url":"https://arxiv.org/abs/2504.14470"}
{"created":"2025-04-22","title":"Efficient Implicit Neural Compression of Point Clouds via Learnable Activation in Latent Space","abstract":"Implicit Neural Representations (INRs), also known as neural fields, have emerged as a powerful paradigm in deep learning, parameterizing continuous spatial fields using coordinate-based neural networks. In this paper, we propose \\textbf{PICO}, an INR-based framework for static point cloud compression. Unlike prevailing encoder-decoder paradigms, we decompose the point cloud compression task into two separate stages: geometry compression and attribute compression, each with distinct INR optimization objectives. Inspired by Kolmogorov-Arnold Networks (KANs), we introduce a novel network architecture, \\textbf{LeAFNet}, which leverages learnable activation functions in the latent space to better approximate the target signal's implicit function. By reformulating point cloud compression as neural parameter compression, we further improve compression efficiency through quantization and entropy coding. Experimental results demonstrate that \\textbf{LeAFNet} outperforms conventional MLPs in INR-based point cloud compression. Furthermore, \\textbf{PICO} achieves superior geometry compression performance compared to the current MPEG point cloud compression standard, yielding an average improvement of $4.92$ dB in D1 PSNR. In joint geometry and attribute compression, our approach exhibits highly competitive results, with an average PCQM gain of $2.7 \\times 10^{-3}$.","authors":["Yichi Zhang","Qianqian Yang"],"url":"https://arxiv.org/abs/2504.14471"}
{"created":"2025-04-22","title":"ExFace: Expressive Facial Control for Humanoid Robots with Diffusion Transformers and Bootstrap Training","abstract":"This paper presents a novel Expressive Facial Control (ExFace) method based on Diffusion Transformers, which achieves precise mapping from human facial blendshapes to bionic robot motor control. By incorporating an innovative model bootstrap training strategy, our approach not only generates high-quality facial expressions but also significantly improves accuracy and smoothness. Experimental results demonstrate that the proposed method outperforms previous methods in terms of accuracy, frame per second (FPS), and response time. Furthermore, we develop the ExFace dataset driven by human facial data. ExFace shows excellent real-time performance and natural expression rendering in applications such as robot performances and human-robot interactions, offering a new solution for bionic robot interaction.","authors":["Dong Zhang","Jingwei Peng","Yuyang Jiao","Jiayuan Gu","Jingyi Yu","Jiahao Chen"],"url":"https://arxiv.org/abs/2504.14477"}
{"created":"2025-04-22","title":"ApexNav: An Adaptive Exploration Strategy for Zero-Shot Object Navigation with Target-centric Semantic Fusion","abstract":"Navigating unknown environments to find a target object is a significant challenge. While semantic information is crucial for navigation, relying solely on it for decision-making may not always be efficient, especially in environments with weak semantic cues. Additionally, many methods are susceptible to misdetections, especially in environments with visually similar objects. To address these limitations, we propose ApexNav, a zero-shot object navigation framework that is both more efficient and reliable. For efficiency, ApexNav adaptively utilizes semantic information by analyzing its distribution in the environment, guiding exploration through semantic reasoning when cues are strong, and switching to geometry-based exploration when they are weak. For reliability, we propose a target-centric semantic fusion method that preserves long-term memory of the target object and similar objects, reducing false detections and minimizing task failures. We evaluate ApexNav on the HM3Dv1, HM3Dv2, and MP3D datasets, where it outperforms state-of-the-art methods in both SR and SPL metrics. Comprehensive ablation studies further demonstrate the effectiveness of each module. Furthermore, real-world experiments validate the practicality of ApexNav in physical environments. Project page is available at https://sysu-star.com/ApexNav.","authors":["Mingjie Zhang","Yuheng Du","Chengkai Wu","Jinni Zhou","Zhenchao Qi","Jun Ma","Boyu Zhou"],"url":"https://arxiv.org/abs/2504.14478"}
{"created":"2025-04-22","title":"Program Synthesis From Partial Traces","abstract":"We present the first technique to synthesize programs that compose side-effecting functions, pure functions, and control flow, from partial traces containing records of only the side-effecting functions. This technique can be applied to synthesize API composing scripts from logs of calls made to those APIs, or a script from traces of system calls made by a workload, for example. All of the provided traces are positive examples, meaning that they describe desired behavior. Our approach does not require negative examples. Instead, it generalizes over the examples and uses cost metrics to prevent over-generalization. Because the problem is too complex for traditional monolithic program synthesis techniques, we propose a new combination of optimizing rewrites and syntax-guided program synthesis. The resulting program is correct by construction, so its output will always be able to reproduce the input traces. We evaluate the quality of the programs synthesized when considering various optimization metrics and the synthesizer's efficiency on real-world benchmarks. The results show that our approach can generate useful real-world programs.","authors":["Margarida Ferreira","Victor Nicolet","Joey Dodds","Daniel Kroening"],"url":"https://arxiv.org/abs/2504.14480"}
{"created":"2025-04-22","title":"Vision-Centric Representation-Efficient Fine-Tuning for Robust Universal Foreground Segmentation","abstract":"Foreground segmentation is crucial for scene understanding, yet parameter-efficient fine-tuning (PEFT) of vision foundation models (VFMs) often fails in complex scenarios, such as camouflage and infrared imagery. We attribute this challenge to the inherent texture bias in VFMs, which is exacerbated during fine-tuning and limits generalization in texture-sparse environments. To address this, we propose Ladder Shape-bias Representation Side-tuning (LSR-ST), a lightweight PEFT framework that enhances model robustness by introducing shape-biased inductive priors. LSR-ST captures shape-aware features using a simple HDConv Block, which integrates large-kernel attention and residual learning. The method satisfies three key conditions for inducing shape bias: large receptive fields, multi-order feature interactions, and sparse connectivity. Our analysis reveals that these improvements stem from representation efficiency-the ability to extract task-relevant, structurally grounded features while minimizing redundancy. We formalize this concept via Information Bottleneck theory and advocate for it as a key PEFT objective. Unlike traditional NLP paradigms that focus on optimizing parameters and memory, visual tasks require models that extract task-defined semantics, rather than just relying on pre-encoded features. This shift enables our approach to move beyond conventional trade-offs, offering more robust and generalizable solutions for vision tasks. With minimal changes to SAM2-UNet, LSR-ST achieves consistent improvements across 17 datasets and 6 tasks using only 4.719M trainable parameters. These results highlight the potential of representation efficiency for robust and adaptable VFMs within complex visual environments.","authors":["Guoyi Zhang","Siyang Chen","Guangsheng Xu","Han Wang","Xiaohu Zhang"],"url":"https://arxiv.org/abs/2504.14481"}
{"created":"2025-04-22","title":"DialogueAgents: A Hybrid Agent-Based Speech Synthesis Framework for Multi-Party Dialogue","abstract":"Speech synthesis is crucial for human-computer interaction, enabling natural and intuitive communication. However, existing datasets involve high construction costs due to manual annotation and suffer from limited character diversity, contextual scenarios, and emotional expressiveness. To address these issues, we propose DialogueAgents, a novel hybrid agent-based speech synthesis framework, which integrates three specialized agents -- a script writer, a speech synthesizer, and a dialogue critic -- to collaboratively generate dialogues. Grounded in a diverse character pool, the framework iteratively refines dialogue scripts and synthesizes speech based on speech review, boosting emotional expressiveness and paralinguistic features of the synthesized dialogues. Using DialogueAgent, we contribute MultiTalk, a bilingual, multi-party, multi-turn speech dialogue dataset covering diverse topics. Extensive experiments demonstrate the effectiveness of our framework and the high quality of the MultiTalk dataset. We release the dataset and code https://github.com/uirlx/DialogueAgents to facilitate future research on advanced speech synthesis models and customized data generation.","authors":["Xiang Li","Duyi Pan","Hongru Xiao","Jiale Han","Jing Tang","Jiabao Ma","Wei Wang","Bo Cheng"],"url":"https://arxiv.org/abs/2504.14482"}
{"created":"2025-04-22","title":"Online Optimal Parameter Compensation method of High-dimensional PID Controller for Robust stability","abstract":"Classical PID control is widely applied in an engineering system, with parameter regulation relying on a method like Trial - Error Tuning or the Ziegler - Nichols rule, mainly for a Single - Input Single - Output (SISO) system. However, the industrial nonlinear Multiple - Input Multiple - Output (MIMO) system demands a high - robustness PID controller due to strong state coupling, external disturbances, and faults. Existing research on PID parameter regulation for a nonlinear uncertain MIMO system has a significant drawback: it's limited to a specific system type, the control mechanism for a MIMO nonlinear system under disturbances is unclear, the MIMO PID controller over - relies on decoupled control, and lacks dynamic parameter compensation. This paper theoretically analyzes a high - dimensional PID controller for a disturbed nonlinear MIMO system, providing a condition for online dynamic parameter regulation to ensure robust stability. By transforming the parameter regulation into a two - stage minimum eigenvalue problem (EVP) solvable via the interior point method, it enables efficient online tuning. The experiment proves that the designed dynamic compensation algorithm can achieve online robust stability of system errors considering multi - channel input coupling, addressing the key limitation in the field.","authors":["Zimao Sheng","Hong'an Yang"],"url":"https://arxiv.org/abs/2504.14486"}
{"created":"2025-04-22","title":"Optimizing SLO-oriented LLM Serving with PD-Multiplexing","abstract":"Modern LLM services demand high throughput and stringent SLO guarantees across two distinct inference phases-prefill and decode-and complex multi-turn workflows. However, current systems face a fundamental tradeoff: out-of-place compute partition enables per-phase SLO attainment, while in-place memory sharing maximizes throughput via KV cache reuse. Moreover, existing in-place compute partition also encounters low utilization and high overhead due to phase-coupling design. We present Yoda, a new LLM serving framework that resolves this tension via PD multiplexing, enabling in-place and phase-decoupled compute partition. Yoda leverages low-level GPU partitioning techniques to multiplex prefill and decode phases spatially and adaptively on shared GPUs, while preserving in-place memory sharing. To fully leverage the multiplexing capability, Yoda introduces an adaptive gang scheduling mechanism, a contention-free modeling method, and a SLO-aware dispatching policy. Evaluation shows that Yoda achieves an average $5.1\\times$ throughput improvement (up to $17.5\\times$) over state-of-the-art baselines, while consistently meeting SLO targets under complex LLM workloads.","authors":["Weihao Cui","Yukang Chen","Han Zhao","Ziyi Xu","Quan Chen","Xusheng Chen","Yangjie Zhou","Shixuan Sun","Minyi Guo"],"url":"https://arxiv.org/abs/2504.14489"}
{"created":"2025-04-22","title":"STARS: Sparse Learning Correlation Filter with Spatio-temporal Regularization and Super-resolution Reconstruction for Thermal Infrared Target Tracking","abstract":"Thermal infrared (TIR) target tracking methods often adopt the correlation filter (CF) framework due to its computational efficiency. However, the low resolution of TIR images, along with tracking interference, significantly limits the perfor-mance of TIR trackers. To address these challenges, we introduce STARS, a novel sparse learning-based CF tracker that incorporates spatio-temporal regulari-zation and super-resolution reconstruction. First, we apply adaptive sparse filter-ing and temporal domain filtering to extract key features of the target while reduc-ing interference from background clutter and noise. Next, we introduce an edge-preserving sparse regularization method to stabilize target features and prevent excessive blurring. This regularization integrates multiple terms and employs the alternating direction method of multipliers to optimize the solution. Finally, we propose a gradient-enhanced super-resolution method to extract fine-grained TIR target features and improve the resolution of TIR images, addressing performance degradation in tracking caused by low-resolution sequences. To the best of our knowledge, STARS is the first to integrate super-resolution methods within a sparse learning-based CF framework. Extensive experiments on the LSOTB-TIR, PTB-TIR, VOT-TIR2015, and VOT-TIR2017 benchmarks demonstrate that STARS outperforms state-of-the-art trackers in terms of robustness.","authors":["Shang Zhang","Xiaobo Ding","Huanbin Zhang","Ruoyan Xiong","Yue Zhang"],"url":"https://arxiv.org/abs/2504.14491"}
{"created":"2025-04-22","title":"FairSteer: Inference Time Debiasing for LLMs with Dynamic Activation Steering","abstract":"Large language models (LLMs) are prone to capturing biases from training corpus, leading to potential negative social impacts. Existing prompt-based debiasing methods exhibit instability due to their sensitivity to prompt changes, while fine-tuning-based techniques incur substantial computational overhead and catastrophic forgetting. In this paper, we propose FairSteer, a novel inference-time debiasing framework without requiring customized prompt design or model retraining. Motivated by the linear representation hypothesis, our preliminary investigation demonstrates that fairness-related features can be encoded into separable directions in the hidden activation space. FairSteer operates in three steps: biased activation detection, debiasing steering vector (DSV) computation, and dynamic activation steering. Specifically, it first trains a lightweight linear classifier to detect bias signatures in activations, and then computes DSVs as intervention directions derived from small contrastive prompt pairs. Subsequently, it performs debiasing by adjusting activations with DSVs in the inference stage. Comprehensive evaluation with six LLMs demonstrates the superiority of FairSteer across question-answering, counterfactual input evaluation and open-ended text generation tasks. Code will be released.","authors":["Yichen Li","Zhiting Fan","Ruizhe Chen","Xiaotang Gai","Luqi Gong","Yan Zhang","Zuozhu Liu"],"url":"https://arxiv.org/abs/2504.14492"}
{"created":"2025-04-22","title":"FinSage: A Multi-aspect RAG System for Financial Filings Question Answering","abstract":"Leveraging large language models in real-world settings often entails a need to utilize domain-specific data and tools in order to follow the complex regulations that need to be followed for acceptable use. Within financial sectors, modern enterprises increasingly rely on Retrieval-Augmented Generation (RAG) systems to address complex compliance requirements in financial document workflows. However, existing solutions struggle to account for the inherent heterogeneity of data (e.g., text, tables, diagrams) and evolving nature of regulatory standards used in financial filings, leading to compromised accuracy in critical information extraction. We propose the FinSage framework as a solution, utilizing a multi-aspect RAG framework tailored for regulatory compliance analysis in multi-modal financial documents. FinSage introduces three innovative components: (1) a multi-modal pre-processing pipeline that unifies diverse data formats and generates chunk-level metadata summaries, (2) a multi-path sparse-dense retrieval system augmented with query expansion (HyDE) and metadata-aware semantic search, and (3) a domain-specialized re-ranking module fine-tuned via Direct Preference Optimization (DPO) to prioritize compliance-critical content. Extensive experiments demonstrate that FinSage achieves an impressive recall of 92.51% on 75 expert-curated questions derived from surpasses the best baseline method on the FinanceBench question answering datasets by 24.06% in accuracy. Moreover, FinSage has been successfully deployed as financial question-answering agent in online meetings, where it has already served more than 1,200 people.","authors":["Xinyu Wang","Jijun Chi","Zhenghan Tai","Tung Sum Thomas Kwok","Muzhi Li","Zhuhong Li","Hailin He","Yuchen Hua","Peng Lu","Suyuchen Wang","Yihong Wu","Jerry Huang","Ling Zhou"],"url":"https://arxiv.org/abs/2504.14493"}
{"created":"2025-04-22","title":"RadarTrack: Enhancing Ego-Vehicle Speed Estimation with Single-chip mmWave Radar","abstract":"In this work, we introduce RadarTrack, an innovative ego-speed estimation framework utilizing a single-chip millimeter-wave (mmWave) radar to deliver robust speed estimation for mobile platforms. Unlike previous methods that depend on cross-modal learning and computationally intensive Deep Neural Networks (DNNs), RadarTrack utilizes a novel phase-based speed estimation approach. This method effectively overcomes the limitations of conventional ego-speed estimation approaches which rely on doppler measurements and static surrondings. RadarTrack is designed for low-latency operation on embedded platforms, making it suitable for real-time applications where speed and efficiency are critical. Our key contributions include the introduction of a novel phase-based speed estimation technique solely based on signal processing and the implementation of a real-time prototype validated through extensive real-world evaluations. By providing a reliable and lightweight solution for ego-speed estimation, RadarTrack holds significant potential for a wide range of applications, including micro-robotics, augmented reality, and autonomous navigation.","authors":["Argha Sen","Soham Chakraborty","Soham Tripathy","Sandip Chakraborty"],"url":"https://arxiv.org/abs/2504.14495"}
{"created":"2025-04-22","title":"Functional Abstraction of Knowledge Recall in Large Language Models","abstract":"Pre-trained transformer large language models (LLMs) demonstrate strong knowledge recall capabilities. This paper investigates the knowledge recall mechanism in LLMs by abstracting it into a functional structure. We propose that during knowledge recall, the model's hidden activation space implicitly entails a function execution process where specific activation vectors align with functional components (Input argument, Function body, and Return values). Specifically, activation vectors of relation-related tokens define a mapping function from subjects to objects, with subject-related token activations serving as input arguments and object-related token activations as return values. For experimental verification, we first design a patching-based knowledge-scoring algorithm to identify knowledge-aware activation vectors as independent functional components. Then, we conduct counter-knowledge testing to examine the independent functional effects of each component on knowledge recall outcomes. From this functional perspective, we improve the contextual knowledge editing approach augmented by activation patching. By rewriting incoherent activations in context, we enable improved short-term memory retention for new knowledge prompting.","authors":["Zijian Wang","Chang Xu"],"url":"https://arxiv.org/abs/2504.14496"}
{"created":"2025-04-22","title":"Fast Plaintext-Ciphertext Matrix Multiplication from Additively Homomorphic Encryption","abstract":"Plaintext-ciphertext matrix multiplication (PC-MM) is an indispensable tool in privacy-preserving computations such as secure machine learning and encrypted signal processing. While there are many established algorithms for plaintext-plaintext matrix multiplication, efficiently computing plaintext-ciphertext (and ciphertext-ciphertext) matrix multiplication is an active area of research which has received a lot of attention. Recent literature have explored various techniques for privacy-preserving matrix multiplication using fully homomorphic encryption (FHE) schemes with ciphertext packing and Single Instruction Multiple Data (SIMD) processing. On the other hand, there hasn't been any attempt to speed up PC-MM using unpacked additively homomorphic encryption (AHE) schemes beyond the schoolbook method and Strassen's algorithm for matrix multiplication. In this work, we propose an efficient PC-MM from unpacked AHE, which applies Cussen's compression-reconstruction algorithm for plaintext-plaintext matrix multiplication in the encrypted setting. We experimentally validate our proposed technique using a concrete instantiation with the additively homomorphic elliptic curve ElGamal encryption scheme and its software implementation on a Raspberry Pi 5 edge computing platform. Our proposed approach achieves up to an order of magnitude speedup compared to state-of-the-art for large matrices with relatively small element bit-widths. Extensive measurement results demonstrate that our fast PC-MM is an excellent candidate for efficient privacy-preserving computation even in resource-constrained environments.","authors":["Krishna Sai Tarun Ramapragada","Utsav Banerjee"],"url":"https://arxiv.org/abs/2504.14497"}
{"created":"2025-04-22","title":"Assessing the Performance of Mixed-Precision ILU(0)-Preconditioned Multiple-Precision Real and Complex Krylov Subspace Methods","abstract":"Krylov subspace methods are linear solvers based on matrix-vector multiplications and vector operations. While easily parallelizable, they are sensitive to rounding errors and may experience convergence issues. ILU(0), an incomplete LU factorization with zero fill-in, is a well-known preconditioning technique that enhances convergence for sparse matrices. In this paper, we implement a double-precision and multiple-precision ILU(0) preconditioner, compatible with product-type Krylov subspace methods, and evaluate its performance.","authors":["Tomonori Kouya"],"url":"https://arxiv.org/abs/2504.14498"}
{"created":"2025-04-22","title":"PinChecker: Identifying Unsound Safe Abstractions of Rust Pinning APIs","abstract":"The pinning APIs of Rust language guarantee memory location stability for self-referential and asynchronous constructs, as long as used according to the pinning API contract. Rust ensures violations of such contract are impossible in regular safe code, but not in unsafe code where unsafe pinning APIs can be used. Library authors can encapsulate arbitrary unsafe code within regular library functions. These can be freely called in higher-level code without explicit warnings. Therefore, it is crucial to analyze library functions to rule out pinning API contract violations. Unfortunately, such testing relies on manual analysis by library authors, which is ineffective. Our goal is to develop a methodology that, given a library, attempts to construct programs that intentionally breach the pinning API contract by chaining library function calls, thereby verifying their soundness. We introduce RPIL, a novel intermediate representation that models functions' critical behaviors pertaining to pinning APIs. We implement PinChecker, a synthesis-driven violation detection tool guided by RPIL, which automatically synthesizes bug-revealing programs. Our experiments on 13 popular Rust libraries from crates.io found 2 confirmed bugs.","authors":["Yuxuan Dai","Yang Feng"],"url":"https://arxiv.org/abs/2504.14500"}
{"created":"2025-04-22","title":"How Local Separators Shape Community Structure in Large Networks","abstract":"Community detection is a key tool for analyzing the structure of large networks. Standard methods, such as modularity optimization, focus on identifying densely connected groups but often overlook natural local separations in the graph. In this paper, we investigate local separator methods, which decompose networks based on structural bottlenecks rather than global connectivity. We systematically compare them with well-established community detection algorithms on large real-world networks. Our results show that local 1-separators consistently identify the densest communities, outperforming modularity-based methods in this regard, while local 2-separators reveal hierarchical structures but may over-fragment small clusters. These findings are particularly strong for road networks, suggesting practical applications in transportation and infrastructure analysis. Our study highlights local separators as a scalable and interpretable alternative for network decomposition.","authors":["Sarah Frenkel","Johannes Carmesin"],"url":"https://arxiv.org/abs/2504.14501"}
{"created":"2025-04-22","title":"VizTA: Enhancing Comprehension of Distributional Visualization with Visual-Lexical Fused Conversational Interface","abstract":"Comprehending visualizations requires readers to interpret visual encoding and the underlying meanings actively. This poses challenges for visualization novices, particularly when interpreting distributional visualizations that depict statistical uncertainty. Advancements in LLM-based conversational interfaces show promise in promoting visualization comprehension. However, they fail to provide contextual explanations at fine-grained granularity, and chart readers are still required to mentally bridge visual information and textual explanations during conversations. Our formative study highlights the expectations for both lexical and visual feedback, as well as the importance of explicitly linking these two modalities throughout the conversation. The findings motivate the design of VizTA, a visualization teaching assistant that leverages the fusion of visual and lexical feedback to help readers better comprehend visualization. VizTA features a semantic-aware conversational agent capable of explaining contextual information within visualizations and employs a visual-lexical fusion design to facilitate chart-centered conversation. A between-subject study with 24 participants demonstrates the effectiveness of VizTA in supporting the understanding and reasoning tasks of distributional visualization across multiple scenarios.","authors":["Liangwei Wang","Zhan Wang","Shishi Xiao","Le Liu","Fugee Tsung","Wei Zeng"],"url":"https://arxiv.org/abs/2504.14507"}
{"created":"2025-04-22","title":"Less is More: Adaptive Coverage for Synthetic Training Data","abstract":"Synthetic training data generation with Large Language Models (LLMs) like Google's Gemma and OpenAI's GPT offer a promising solution to the challenge of obtaining large, labeled datasets for training classifiers. When rapid model deployment is critical, such as in classifying emerging social media trends or combating new forms of online abuse tied to current events, the ability to generate training data is invaluable. While prior research has examined the comparability of synthetic data to human-labeled data, this study introduces a novel sampling algorithm, based on the maximum coverage problem, to select a representative subset from a synthetically generated dataset. Our results demonstrate that training a classifier on this contextually sampled subset achieves superior performance compared to training on the entire dataset. This \"less is more\" approach not only improves accuracy but also reduces the volume of data required, leading to potentially more efficient model fine-tuning.","authors":["Sasan Tavakkol","Max Springer","Mohammadhossein Bateni","Neslihan Bulut","Vincent Cohen-Addad","MohammadTaghi Hajiaghayi"],"url":"https://arxiv.org/abs/2504.14508"}
{"created":"2025-04-22","title":"DreamID: High-Fidelity and Fast diffusion-based Face Swapping via Triplet ID Group Learning","abstract":"In this paper, we introduce DreamID, a diffusion-based face swapping model that achieves high levels of ID similarity, attribute preservation, image fidelity, and fast inference speed. Unlike the typical face swapping training process, which often relies on implicit supervision and struggles to achieve satisfactory results. DreamID establishes explicit supervision for face swapping by constructing Triplet ID Group data, significantly enhancing identity similarity and attribute preservation. The iterative nature of diffusion models poses challenges for utilizing efficient image-space loss functions, as performing time-consuming multi-step sampling to obtain the generated image during training is impractical. To address this issue, we leverage the accelerated diffusion model SD Turbo, reducing the inference steps to a single iteration, enabling efficient pixel-level end-to-end training with explicit Triplet ID Group supervision. Additionally, we propose an improved diffusion-based model architecture comprising SwapNet, FaceNet, and ID Adapter. This robust architecture fully unlocks the power of the Triplet ID Group explicit supervision. Finally, to further extend our method, we explicitly modify the Triplet ID Group data during training to fine-tune and preserve specific attributes, such as glasses and face shape. Extensive experiments demonstrate that DreamID outperforms state-of-the-art methods in terms of identity similarity, pose and expression preservation, and image fidelity. Overall, DreamID achieves high-quality face swapping results at 512*512 resolution in just 0.6 seconds and performs exceptionally well in challenging scenarios such as complex lighting, large angles, and occlusions.","authors":["Fulong Ye","Miao Hua","Pengze Zhang","Xinghui Li","Qichao Sun","Songtao Zhao","Qian He","Xinglong Wu"],"url":"https://arxiv.org/abs/2504.14509"}
{"created":"2025-04-22","title":"Revisiting the field normalization approaches/practices","abstract":"Field normalization plays a crucial role in scientometrics to ensure fair comparisons across different disciplines. In this paper, we revisit the effectiveness of several widely used field normalization methods. Our findings indicate that source-side normalization (as employed in SNIP) does not fully eliminate citation bias across different fields and the imbalanced paper growth rates across fields are a key factor for this phenomenon. To address the issue of skewness, logarithmic transformation has been applied. Recently, a combination of logarithmic transformation and mean-based normalization, expressed as ln(c+1)/mu, has gained popularity. However, our analysis shows that this approach does not yield satisfactory results. Instead, we find that combining logarithmic transformation (ln(c+1)) with z-score normalization provides a better alternative. Furthermore, our study suggests that the better performance is achieved when combining both source-side and target-side field normalization methods.","authors":["Xinyue Lu","Li Li","Zhesi Shen"],"url":"https://arxiv.org/abs/2504.14512"}
{"created":"2025-04-22","title":"On Dimension-Free Transformer: An Application of STP to AI","abstract":"The matrix expressions for every parts of a transformer are firstly described. Based on semi-tensor product (STP) of matrices the hypervectors are reconsidered and the linear transformation over hypervectors is constructed by using projection. Its properties and calculating formulas are obtained. Using projection-based transformation of hypervector (PBTH), the framework of dimension-free transformer (DFT) is proposed by verifying each linear transformation in a transformer and replacing it by a proper PBTH, which allows the inputs and outputs being of arbitrary dimensions. Using balanced information about all entries, DFT must be more efficient in dealing with signals.","authors":["Daizhan Cheng"],"url":"https://arxiv.org/abs/2504.14514"}
{"created":"2025-04-22","title":"Back on Track: Bundle Adjustment for Dynamic Scene Reconstruction","abstract":"Traditional SLAM systems, which rely on bundle adjustment, struggle with highly dynamic scenes commonly found in casual videos. Such videos entangle the motion of dynamic elements, undermining the assumption of static environments required by traditional systems. Existing techniques either filter out dynamic elements or model their motion independently. However, the former often results in incomplete reconstructions, whereas the latter can lead to inconsistent motion estimates. Taking a novel approach, this work leverages a 3D point tracker to separate the camera-induced motion from the observed motion of dynamic objects. By considering only the camera-induced component, bundle adjustment can operate reliably on all scene elements as a result. We further ensure depth consistency across video frames with lightweight post-processing based on scale maps. Our framework combines the core of traditional SLAM -- bundle adjustment -- with a robust learning-based 3D tracker front-end. Integrating motion decomposition, bundle adjustment and depth refinement, our unified framework, BA-Track, accurately tracks the camera motion and produces temporally coherent and scale-consistent dense reconstructions, accommodating both static and dynamic elements. Our experiments on challenging datasets reveal significant improvements in camera pose estimation and 3D reconstruction accuracy.","authors":["Weirong Chen","Ganlin Zhang","Felix Wimbauer","Rui Wang","Nikita Araslanov","Andrea Vedaldi","Daniel Cremers"],"url":"https://arxiv.org/abs/2504.14516"}
{"created":"2025-04-22","title":"SlimPipe: Memory-Thrifty and Efficient Pipeline Parallelism for Long-Context LLM Training","abstract":"Pipeline Parallelism (PP) serves as a crucial technique for training Large Language Models (LLMs), owing to its capability to alleviate memory pressure from model states with relatively low communication overhead. However, in long-context scenarios, existing pipeline parallelism methods fail to address the substantial activation memory pressure, primarily due to the peak memory consumption resulting from the accumulation of activations across multiple microbatches. Moreover, these approaches inevitably introduce considerable pipeline bubbles, further hindering efficiency.","authors":["Zhouyang Li","Yuliang Liu","Wei Zhang","Tailing Yuan","Bin Chen","Chengru Song","Di Zhang"],"url":"https://arxiv.org/abs/2504.14519"}
{"created":"2025-04-22","title":"Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey","abstract":"This survey explores the development of meta-thinking capabilities in Large Language Models (LLMs) from a Multi-Agent Reinforcement Learning (MARL) perspective. Meta-thinking self-reflection, assessment, and control of thinking processes is an important next step in enhancing LLM reliability, flexibility, and performance, particularly for complex or high-stakes tasks. The survey begins by analyzing current LLM limitations, such as hallucinations and the lack of internal self-assessment mechanisms. It then talks about newer methods, including RL from human feedback (RLHF), self-distillation, and chain-of-thought prompting, and each of their limitations. The crux of the survey is to talk about how multi-agent architectures, namely supervisor-agent hierarchies, agent debates, and theory of mind frameworks, can emulate human-like introspective behavior and enhance LLM robustness. By exploring reward mechanisms, self-play, and continuous learning methods in MARL, this survey gives a comprehensive roadmap to building introspective, adaptive, and trustworthy LLMs. Evaluation metrics, datasets, and future research avenues, including neuroscience-inspired architectures and hybrid symbolic reasoning, are also discussed.","authors":["Ahsan Bilal","Muhammad Ahmed Mohsin","Muhammad Umer","Muhammad Awais Khan Bangash","Muhammad Ali Jamshed"],"url":"https://arxiv.org/abs/2504.14520"}
{"created":"2025-04-22","title":"Biased by Design: Leveraging AI Biases to Enhance Critical Thinking of News Readers","abstract":"This paper explores the design of a propaganda detection tool using Large Language Models (LLMs). Acknowledging the inherent biases in AI models, especially in political contexts, we investigate how these biases might be leveraged to enhance critical thinking in news consumption. Countering the typical view of AI biases as detrimental, our research proposes strategies of user choice and personalization in response to a user's political stance, applying psychological concepts of confirmation bias and cognitive dissonance. We present findings from a qualitative user study, offering insights and design recommendations (bias awareness, personalization and choice, and gradual introduction of diverse perspectives) for AI tools in propaganda detection.","authors":["Liudmila Zavolokina","Kilian Sprenkamp","Zoya Katashinskaya","Daniel Gordon Jones"],"url":"https://arxiv.org/abs/2504.14522"}
{"created":"2025-04-22","title":"Learning from Reasoning Failures via Synthetic Data Generation","abstract":"Training models on synthetic data has emerged as an increasingly important strategy for improving the performance of generative AI. This approach is particularly helpful for large multimodal models (LMMs) due to the relative scarcity of high-quality paired image-text data compared to language-only data. While a variety of methods have been proposed for generating large multimodal datasets, they do not tailor the synthetic data to address specific deficiencies in the reasoning abilities of LMMs which will be trained with the generated dataset. In contrast, humans often learn in a more efficient manner by seeking out examples related to the types of reasoning where they have failed previously. Inspired by this observation, we propose a new approach for synthetic data generation which is grounded in the analysis of an existing LMM's reasoning failures. Our methodology leverages frontier models to automatically analyze errors produced by a weaker LMM and propose new examples which can be used to correct the reasoning failure via additional training, which are then further filtered to ensure high quality. We generate a large multimodal instruction tuning dataset containing over 553k examples using our approach and conduct extensive experiments demonstrating its utility for improving the performance of LMMs on multiple downstream tasks. Our results show that models trained on our synthetic data can even exceed the performance of LMMs trained on an equivalent amount of additional real data, demonstrating the high value of generating synthetic data targeted to specific reasoning failure modes in LMMs. We will make our dataset and code publicly available.","authors":["Gabriela Ben Melech Stan","Estelle Aflalo","Avinash Madasu","Vasudev Lal","Phillip Howard"],"url":"https://arxiv.org/abs/2504.14523"}
{"created":"2025-04-22","title":"Hierarchical Robust PCA for Scalable Data Quality Monitoring in Multi-level Aggregation Pipelines","abstract":"Data quality (DQ) remains a fundamental concern in big data pipelines, especially when aggregations occur at multiple hierarchical levels. Traditional DQ validation rules often fail to scale or generalize across dimensions such as user interactions, sessions, profiles, accounts, and regions. In this paper, we present a novel application of Hierarchical Robust Principal Component Analysis (HrPCA) as a scalable, unsupervised anomaly detection technique tailored to DQ monitoring in multi-level aggregation pipelines. We propose a modular framework that decomposes the data at each hierarchical level into low-rank representations and sparse residuals, allowing the detection of subtle inconsistencies, outliers, and misalignments in the aggregated data. We evaluated our approach using synthetic hierarchical datasets with controlled anomalies and demonstrated how HrPCA outperforms traditional rule-based methods in detecting data corruption and rollup inconsistencies.","authors":["Preetam Kumar Ojha"],"url":"https://arxiv.org/abs/2504.14524"}
{"created":"2025-04-22","title":"Are Vision LLMs Road-Ready? A Comprehensive Benchmark for Safety-Critical Driving Video Understanding","abstract":"Vision Large Language Models (VLLMs) have demonstrated impressive capabilities in general visual tasks such as image captioning and visual question answering. However, their effectiveness in specialized, safety-critical domains like autonomous driving remains largely unexplored. Autonomous driving systems require sophisticated scene understanding in complex environments, yet existing multimodal benchmarks primarily focus on normal driving conditions, failing to adequately assess VLLMs' performance in safety-critical scenarios. To address this, we introduce DVBench, a pioneering benchmark designed to evaluate the performance of VLLMs in understanding safety-critical driving videos. Built around a hierarchical ability taxonomy that aligns with widely adopted frameworks for describing driving scenarios used in assessing highly automated driving systems, DVBench features 10,000 multiple-choice questions with human-annotated ground-truth answers, enabling a comprehensive evaluation of VLLMs' capabilities in perception and reasoning. Experiments on 14 SOTA VLLMs, ranging from 0.5B to 72B parameters, reveal significant performance gaps, with no model achieving over 40% accuracy, highlighting critical limitations in understanding complex driving scenarios. To probe adaptability, we fine-tuned selected models using domain-specific data from DVBench, achieving accuracy gains ranging from 5.24 to 10.94 percentage points, with relative improvements of up to 43.59%. This improvement underscores the necessity of targeted adaptation to bridge the gap between general-purpose VLLMs and mission-critical driving applications. DVBench establishes an essential evaluation framework and research roadmap for developing VLLMs that meet the safety and robustness requirements for real-world autonomous systems. We released the benchmark toolbox and the fine-tuned model at: https://github.com/tong-zeng/DVBench.git.","authors":["Tong Zeng","Longfeng Wu","Liang Shi","Dawei Zhou","Feng Guo"],"url":"https://arxiv.org/abs/2504.14526"}
{"created":"2025-04-22","title":"Causality for Natural Language Processing","abstract":"Causal reasoning is a cornerstone of human intelligence and a critical capability for artificial systems aiming to achieve advanced understanding and decision-making. This thesis delves into various dimensions of causal reasoning and understanding in large language models (LLMs). It encompasses a series of studies that explore the causal inference skills of LLMs, the mechanisms behind their performance, and the implications of causal and anticausal learning for natural language processing (NLP) tasks. Additionally, it investigates the application of causal reasoning in text-based computational social science, specifically focusing on political decision-making and the evaluation of scientific impact through citations. Through novel datasets, benchmark tasks, and methodological frameworks, this work identifies key challenges and opportunities to improve the causal capabilities of LLMs, providing a comprehensive foundation for future research in this evolving field.","authors":["Zhijing Jin"],"url":"https://arxiv.org/abs/2504.14530"}
{"created":"2025-04-22","title":"Closing the Evaluation Gap: Developing a Behavior-Oriented Framework for Assessing Virtual Teamwork Competency","abstract":"The growing reliance on remote work and digital collaboration has made virtual teamwork competencies essential for professional and academic success. However, the evaluation of such competencies remains a significant challenge. Existing assessment methods, predominantly based on self-reports and peer evaluations, often focus on short-term results or subjective perceptions rather than systematically examining observable teamwork behaviors. These limitations hinder the identification of specific areas for improvement and fail to support meaningful progress in skill development. Informed by group dynamic theory, this study developed a behavior-oriented framework for assessing virtual teamwork competencies among engineering students. Using focus group interviews combined with the Critical Incident Technique, the study identified three key dimensions - Group Task Dimension, Individual Task Dimension and Social Dimension - along with their behavioral indicators and student-perceived relationships between these components. The resulting framework provides a foundation for more effective assessment practices and supports the development of virtual teamwork competency essential for success in increasingly digital and globalized professional environments.","authors":["Wenjie Hu","Cecilia Ka Yuk Chan"],"url":"https://arxiv.org/abs/2504.14531"}
{"created":"2025-04-22","title":"SUDO: Enhancing Text-to-Image Diffusion Models with Self-Supervised Direct Preference Optimization","abstract":"Previous text-to-image diffusion models typically employ supervised fine-tuning (SFT) to enhance pre-trained base models. However, this approach primarily minimizes the loss of mean squared error (MSE) at the pixel level, neglecting the need for global optimization at the image level, which is crucial for achieving high perceptual quality and structural coherence. In this paper, we introduce Self-sUpervised Direct preference Optimization (SUDO), a novel paradigm that optimizes both fine-grained details at the pixel level and global image quality. By integrating direct preference optimization into the model, SUDO generates preference image pairs in a self-supervised manner, enabling the model to prioritize global-level learning while complementing the pixel-level MSE loss. As an effective alternative to supervised fine-tuning, SUDO can be seamlessly applied to any text-to-image diffusion model. Importantly, it eliminates the need for costly data collection and annotation efforts typically associated with traditional direct preference optimization methods. Through extensive experiments on widely-used models, including Stable Diffusion 1.5 and XL, we demonstrate that SUDO significantly enhances both global and local image quality. The codes are provided at \\href{https://github.com/SPengLiang/SUDO}{this link}.","authors":["Liang Peng","Boxi Wu","Haoran Cheng","Yibo Zhao","Xiaofei He"],"url":"https://arxiv.org/abs/2504.14534"}
{"created":"2025-04-22","title":"FlowLoss: Dynamic Flow-Conditioned Loss Strategy for Video Diffusion Models","abstract":"Video Diffusion Models (VDMs) can generate high-quality videos, but often struggle with producing temporally coherent motion. Optical flow supervision is a promising approach to address this, with prior works commonly employing warping-based strategies that avoid explicit flow matching. In this work, we explore an alternative formulation, FlowLoss, which directly compares flow fields extracted from generated and ground-truth videos. To account for the unreliability of flow estimation under high-noise conditions in diffusion, we propose a noise-aware weighting scheme that modulates the flow loss across denoising steps. Experiments on robotic video datasets suggest that FlowLoss improves motion stability and accelerates convergence in early training stages. Our findings offer practical insights for incorporating motion-based supervision into noise-conditioned generative models.","authors":["Kuanting Wu","Kei Ota","Asako Kanezaki"],"url":"https://arxiv.org/abs/2504.14535"}
{"created":"2025-04-22","title":"The Ephemeral Shadow: Hyperreal Beings in Stimulative Performance","abstract":"The Ephemeral Shadow is an interactive art installation centered on the concept of \"simulacrum,\" focusing on the reconstruction of subjectivity at the intersection of reality and virtuality. Drawing inspiration from the aesthetic imagery of traditional shadow puppetry, the installation combines robotic performance and digital projection to create a multi-layered visual space, presenting a progressively dematerialized hyperreal experience. By blurring the audience's perception of the boundaries between entity and image, the work employs the replacement of physical presence with imagery as its core technique, critically reflecting on issues of technological subjectivity, affective computing, and ethics. Situated within the context of posthumanism and digital media, the installation prompts viewers to contemplate: as digital technologies increasingly approach and simulate \"humanity,\" how can we reshape identity and perception while safeguarding the core values and ethical principles of human subjectivity?","authors":["Dong Zhang","Yanjun Zhou","Jingyi Yu"],"url":"https://arxiv.org/abs/2504.14536"}
{"created":"2025-04-22","title":"BookWorld: From Novels to Interactive Agent Societies for Creative Story Generation","abstract":"Recent advances in large language models (LLMs) have enabled social simulation through multi-agent systems. Prior efforts focus on agent societies created from scratch, assigning agents with newly defined personas. However, simulating established fictional worlds and characters remain largely underexplored, despite its significant practical value. In this paper, we introduce BookWorld, a comprehensive system for constructing and simulating book-based multi-agent societies. BookWorld's design covers comprehensive real-world intricacies, including diverse and dynamic characters, fictional worldviews, geographical constraints and changes, e.t.c. BookWorld enables diverse applications including story generation, interactive games and social simulation, offering novel ways to extend and explore beloved fictional works. Through extensive experiments, we demonstrate that BookWorld generates creative, high-quality stories while maintaining fidelity to the source books, surpassing previous methods with a win rate of 75.36%. The code of this paper can be found at the project page: https://bookworld2025.github.io/.","authors":["Yiting Ran","Xintao Wang","Tian Qiu","Jiaqing Liang","Yanghua Xiao","Deqing Yang"],"url":"https://arxiv.org/abs/2504.14538"}
{"created":"2025-04-22","title":"Should Benevolent Deception be Allowed in EHMI? A Mechanism Explanation Based on Game Theory","abstract":"The application of external human-machine interface (EHMI) on autonomous vehicles (AVs) facilitates information exchange. Existing research fails to consider the impact of the sequence of actions, as well as the effects of EHMI applications and deception, raising the question of whether benevolent, well-intentioned deception should be permitted (i.e., misleading statements that are intended to benefit both parties). We established a game theory based EHMI information disclosure framework for AVs in this study. In considering benevolent deception, this framework divided the decision-making process into three stages, respectively encompassing three key questions: whether to disclose, when to disclose, and what type of intention information to disclose. The results show that theoretical advantages of deception exist in certain cases when AV expects to maximize the safety of the interaction. In 40 out of 484 cases (8.3%), safety can be enhanced through successful deception. Those successful deceptions fall into two categories: 1) In 28 of these cases, the straight-going AV expected the left-turning HV to yield, while HV exhibited lower speed and higher acceleration; 2) In 12 of these cases, AV expected HV to proceed first, while HV exhibited higher speed and lower acceleration. We also conducted a VR-based driving simulation experiment, and the results confirmed our conclusion. Additionally, we found that when participants had low trust in the EHMI, its use negatively impacted interaction efficiency instead. This study aims to analyze the mechanisms of EHMI information disclosure and contribute to the ongoing discourse on the ethical framework governing autonomous driving systems.","authors":["Linkun Liu","Jian Sun","Ye Tian"],"url":"https://arxiv.org/abs/2504.14539"}
{"created":"2025-04-22","title":"Towards Model Resistant to Transferable Adversarial Examples via Trigger Activation","abstract":"Adversarial examples, characterized by imperceptible perturbations, pose significant threats to deep neural networks by misleading their predictions. A critical aspect of these examples is their transferability, allowing them to deceive {unseen} models in black-box scenarios. Despite the widespread exploration of defense methods, including those on transferability, they show limitations: inefficient deployment, ineffective defense, and degraded performance on clean images. In this work, we introduce a novel training paradigm aimed at enhancing robustness against transferable adversarial examples (TAEs) in a more efficient and effective way. We propose a model that exhibits random guessing behavior when presented with clean data $\\boldsymbol{x}$ as input, and generates accurate predictions when with triggered data $\\boldsymbol{x}+\\boldsymbol{\\tau}$. Importantly, the trigger $\\boldsymbol{\\tau}$ remains constant for all data instances. We refer to these models as \\textbf{models with trigger activation}. We are surprised to find that these models exhibit certain robustness against TAEs. Through the consideration of first-order gradients, we provide a theoretical analysis of this robustness. Moreover, through the joint optimization of the learnable trigger and the model, we achieve improved robustness to transferable attacks. Extensive experiments conducted across diverse datasets, evaluating a variety of attacking methods, underscore the effectiveness and superiority of our approach.","authors":["Yi Yu","Song Xia","Xun Lin","Chenqi Kong","Wenhan Yang","Shijian Lu","Yap-Peng Tan","Alex C. Kot"],"url":"https://arxiv.org/abs/2504.14541"}
{"created":"2025-04-22","title":"A Lightweight Neural Network for Accelerating Radiative Transfer Modeling in WRF","abstract":"Radiative transfer calculations in weather and climate models are notoriously complex and computationally intensive, which poses significant challenges. Traditional methods, while accurate, can be prohibitively slow, necessitating the development of more efficient alternatives. Recently, empirical emulators based on neural networks (NN) have been proposed as a solution to this problem. These emulators aim to replicate the radiation parametrization used in the models, at a fraction of the computational cost. However, a common issue with these emulators is that their accuracy has often been insufficiently evaluated, especially for extreme events for which the amount of training data is sparse. The current study proposes such a model for accelerating radiative heat transfer modeling in WRF, and validates the accuracy of the approach for an extreme weather scenario.","authors":["Erick Fredj","Iggy Segev Gal","Noam Lavi","Shahar Belkar","Mark Wasserman","Ding Zhaohui","Yann Delorme"],"url":"https://arxiv.org/abs/2504.14542"}
{"created":"2025-04-22","title":"TrustLoRA: Low-Rank Adaptation for Failure Detection under Out-of-distribution Data","abstract":"Reliable prediction is an essential requirement for deep neural models that are deployed in open environments, where both covariate and semantic out-of-distribution (OOD) data arise naturally. In practice, to make safe decisions, a reliable model should accept correctly recognized inputs while rejecting both those misclassified covariate-shifted and semantic-shifted examples. Besides, considering the potential existing trade-off between rejecting different failure cases, more convenient, controllable, and flexible failure detection approaches are needed. To meet the above requirements, we propose a simple failure detection framework to unify and facilitate classification with rejection under both covariate and semantic shifts. Our key insight is that by separating and consolidating failure-specific reliability knowledge with low-rank adapters and then integrating them, we can enhance the failure detection ability effectively and flexibly. Extensive experiments demonstrate the superiority of our framework.","authors":["Fei Zhu","Zhaoxiang Zhang"],"url":"https://arxiv.org/abs/2504.14545"}
{"created":"2025-04-22","title":"VGNC: Reducing the Overfitting of Sparse-view 3DGS via Validation-guided Gaussian Number Control","abstract":"Sparse-view 3D reconstruction is a fundamental yet challenging task in practical 3D reconstruction applications. Recently, many methods based on the 3D Gaussian Splatting (3DGS) framework have been proposed to address sparse-view 3D reconstruction. Although these methods have made considerable advancements, they still show significant issues with overfitting. To reduce the overfitting, we introduce VGNC, a novel Validation-guided Gaussian Number Control (VGNC) approach based on generative novel view synthesis (NVS) models. To the best of our knowledge, this is the first attempt to alleviate the overfitting issue of sparse-view 3DGS with generative validation images. Specifically, we first introduce a validation image generation method based on a generative NVS model. We then propose a Gaussian number control strategy that utilizes generated validation images to determine the optimal Gaussian numbers, thereby reducing the issue of overfitting. We conducted detailed experiments on various sparse-view 3DGS baselines and datasets to evaluate the effectiveness of VGNC. Extensive experiments show that our approach not only reduces overfitting but also improves rendering quality on the test set while decreasing the number of Gaussian points. This reduction lowers storage demands and accelerates both training and rendering. The code will be released.","authors":["Lifeng Lin","Rongfeng Lu","Quan Chen","Haofan Ren","Ming Lu","Yaoqi Sun","Chenggang Yan","Anke Xue"],"url":"https://arxiv.org/abs/2504.14548"}
{"created":"2025-04-22","title":"Regret-aware Re-ranking for Guaranteeing Two-sided Fairness and Accuracy in Recommender Systems","abstract":"In multi-stakeholder recommender systems (RS), users and providers operate as two crucial and interdependent roles, whose interests must be well-balanced. Prior research, including our work BankFair, has demonstrated the importance of guaranteeing both provider fairness and user accuracy to meet their interests. However, when they balance the two objectives, another critical factor emerges in RS: individual fairness, which manifests as a significant disparity in individual recommendation accuracy, with some users receiving high accuracy while others are left with notably low accuracy. This oversight severely harms the interests of users and exacerbates social polarization. How to guarantee individual fairness while ensuring user accuracy and provider fairness remains an unsolved problem. To bridge this gap, in this paper, we propose our method BankFair+. Specifically, BankFair+ extends BankFair with two steps: (1) introducing a non-linear function from regret theory to ensure individual fairness while enhancing user accuracy; (2) formulating the re-ranking process as a regret-aware fuzzy programming problem to meet the interests of both individual user and provider, therefore balancing the trade-off between individual fairness and provider fairness. Experiments on two real-world recommendation datasets demonstrate that BankFair+ outperforms all baselines regarding individual fairness, user accuracy, and provider fairness.","authors":["Xiaopeng Ye","Chen Xu","Jun Xu","Xuyang Xie","Gang Wang","Zhenhua Dong"],"url":"https://arxiv.org/abs/2504.14550"}
{"created":"2025-04-22","title":"Grounding-MD: Grounded Video-language Pre-training for Open-World Moment Detection","abstract":"Temporal Action Detection and Moment Retrieval constitute two pivotal tasks in video understanding, focusing on precisely localizing temporal segments corresponding to specific actions or events. Recent advancements introduced Moment Detection to unify these two tasks, yet existing approaches remain confined to closed-set scenarios, limiting their applicability in open-world contexts. To bridge this gap, we present Grounding-MD, an innovative, grounded video-language pre-training framework tailored for open-world moment detection. Our framework incorporates an arbitrary number of open-ended natural language queries through a structured prompt mechanism, enabling flexible and scalable moment detection. Grounding-MD leverages a Cross-Modality Fusion Encoder and a Text-Guided Fusion Decoder to facilitate comprehensive video-text alignment and enable effective cross-task collaboration. Through large-scale pre-training on temporal action detection and moment retrieval datasets, Grounding-MD demonstrates exceptional semantic representation learning capabilities, effectively handling diverse and complex query conditions. Comprehensive evaluations across four benchmark datasets including ActivityNet, THUMOS14, ActivityNet-Captions, and Charades-STA demonstrate that Grounding-MD establishes new state-of-the-art performance in zero-shot and supervised settings in open-world moment detection scenarios. All source code and trained models will be released.","authors":["Weijun Zhuang","Qizhang Li","Xin Li","Ming Liu","Xiaopeng Hong","Feng Gao","Fan Yang","Wangmeng Zuo"],"url":"https://arxiv.org/abs/2504.14553"}
{"created":"2025-04-22","title":"REDEditing: Relationship-Driven Precise Backdoor Poisoning on Text-to-Image Diffusion Models","abstract":"The rapid advancement of generative AI highlights the importance of text-to-image (T2I) security, particularly with the threat of backdoor poisoning. Timely disclosure and mitigation of security vulnerabilities in T2I models are crucial for ensuring the safe deployment of generative models. We explore a novel training-free backdoor poisoning paradigm through model editing, which is recently employed for knowledge updating in large language models. Nevertheless, we reveal the potential security risks posed by model editing techniques to image generation models. In this work, we establish the principles for backdoor attacks based on model editing, and propose a relationship-driven precise backdoor poisoning method, REDEditing. Drawing on the principles of equivalent-attribute alignment and stealthy poisoning, we develop an equivalent relationship retrieval and joint-attribute transfer approach that ensures consistent backdoor image generation through concept rebinding. A knowledge isolation constraint is proposed to preserve benign generation integrity. Our method achieves an 11\\% higher attack success rate compared to state-of-the-art approaches. Remarkably, adding just one line of code enhances output naturalness while improving backdoor stealthiness by 24\\%. This work aims to heighten awareness regarding this security vulnerability in editable image generation models.","authors":["Chongye Guo","Jinhu Fu","Junfeng Fang","Kun Wang","Guorui Feng"],"url":"https://arxiv.org/abs/2504.14554"}
{"created":"2025-04-22","title":"LLM-Enabled In-Context Learning for Data Collection Scheduling in UAV-assisted Sensor Networks","abstract":"Unmanned Aerial Vehicles (UAVs) are increasingly being used in various private and commercial applications, e.g. traffic control, package delivery, and Search and Rescue (SAR) operations. Machine Learning (ML) methods used in UAV-assisted Sensor Networks (UASNETs) and especially in Deep Reinforcement Learning (DRL) face challenges such as complex and lengthy model training, gaps between simulation and reality, and low sample efficiency, which conflict with the urgency of emergencies such as SAR operations. This paper proposes In-Context Learning (ICL)-based Data Collection Scheduling (ICLDC) scheme, as an alternative to DRL in emergencies. The UAV collects and transmits logged sensory data, to an LLM, to generate a task description in natural language, from which it obtains a data collection schedule to be executed by the UAV. The system continuously adapts by adding feedback to task descriptions and utilizing feedback for future decisions. This method is tested against jailbreaking attacks, where task description is manipulated to undermine network performance, highlighting the vulnerability of LLMs to such attacks. The proposed ICLDC outperforms the Maximum Channel Gain by reducing cumulative packet loss by approximately 56\\%. ICLDC presents a promising direction for intelligent scheduling and control in UAV-assisted data collection.","authors":["Yousef Emami","Hao Gao","SeyedSina Nabavirazani","Luis Almeida"],"url":"https://arxiv.org/abs/2504.14556"}
{"created":"2025-04-22","title":"ReasoningV: Efficient Verilog Code Generation with Adaptive Hybrid Reasoning Model","abstract":"Large Language Models (LLMs) have advanced Verilog code generation significantly, yet face challenges in data quality, reasoning capabilities, and computational efficiency. This paper presents ReasoningV, a novel model employing a hybrid reasoning strategy that integrates trained intrinsic capabilities with dynamic inference adaptation for Verilog code generation. Our framework introduces three complementary innovations: (1) ReasoningV-5K, a high-quality dataset of 5,000 functionally verified instances with reasoning paths created through multi-dimensional filtering of PyraNet samples; (2) a two-stage training approach combining parameter-efficient fine-tuning for foundational knowledge with full-parameter optimization for enhanced reasoning; and (3) an adaptive reasoning mechanism that dynamically adjusts reasoning depth based on problem complexity, reducing token consumption by up to 75\\% while preserving performance. Experimental results demonstrate ReasoningV's effectiveness with a pass@1 accuracy of 57.8\\% on VerilogEval-human, achieving performance competitive with leading commercial models like Gemini-2.0-flash (59.5\\%) and exceeding the previous best open-source model by 10.4 percentage points. ReasoningV offers a more reliable and accessible pathway for advancing AI-driven hardware design automation, with our model, data, and code available at https://github.com/BUAA-CLab/ReasoningV.","authors":["Haiyan Qin","Zhiwei Xie","Jingjing Li","Liangchen Li","Xiaotong Feng","Junzhan Liu","Wang Kang"],"url":"https://arxiv.org/abs/2504.14560"}
{"created":"2025-04-22","title":"Proof Scores: A Survey (full version)","abstract":"Proof scores can be regarded as outlines of the formal verification of system properties. They have been historically used by the OBJ family of specification languages. The main advantage of proof scores is that they follow the same syntax as the specification language they are used in, so specifiers can easily adopt them and use as many features as the particular language provides. In this way, proof scores have been successfully used to prove properties of a large number of systems and protocols. However, proof scores also present a number of disadvantages that prevented a large audience from adopting them as proving mechanism. In this paper we present the theoretical foundations of proof scores; the different systems where they have been adopted and their latest developments; the classes of systems successfully verified using proof scores, including the main techniques used for it; the main reasons why they have not been widely adopted; and finally we discuss some directions of future work that might solve the problems discussed previously.","authors":["Adrian Riesco","Kazuhiro Ogata","Masaki Nakamura","Daniel Gaina","Duong Dinh Tran","Kokichi Futatsugi"],"url":"https://arxiv.org/abs/2504.14561"}
{"created":"2025-04-22","title":"Going Down the Abstraction Stream with Augmented Reality and Tangible Robots: the Case of Vector Instruction","abstract":"Despite being used in many engineering and scientific areas such as physics and mathematics and often taught in high school, graphical vector addition turns out to be a topic prone to misconceptions in understanding even at university-level physics classes. To improve the learning experience and the resulting understanding of vectors, we propose to investigate how concreteness fading implemented with the use of augmented reality and tangible robots could help learners to build a strong representation of vector addition.","authors":["Sergei Volodin","Hala Khodr","Pierre Dillenbourg","Wafa Johal"],"url":"https://arxiv.org/abs/2504.14562"}
{"created":"2025-04-22","title":"Matrix Factorization with Dynamic Multi-view Clustering for Recommender System","abstract":"Matrix factorization (MF), a cornerstone of recommender systems, decomposes user-item interaction matrices into latent representations. Traditional MF approaches, however, employ a two-stage, non-end-to-end paradigm, sequentially performing recommendation and clustering, resulting in prohibitive computational costs for large-scale applications like e-commerce and IoT, where billions of users interact with trillions of items. To address this, we propose Matrix Factorization with Dynamic Multi-view Clustering (MFDMC), a unified framework that balances efficient end-to-end training with comprehensive utilization of web-scale data and enhances interpretability. MFDMC leverages dynamic multi-view clustering to learn user and item representations, adaptively pruning poorly formed clusters. Each entity's representation is modeled as a weighted projection of robust clusters, capturing its diverse roles across views. This design maximizes representation space utilization, improves interpretability, and ensures resilience for downstream tasks. Extensive experiments demonstrate MFDMC's superior performance in recommender systems and other representation learning domains, such as computer vision, highlighting its scalability and versatility.","authors":["Shangde Gao","Ke Liu","Yichao Fu","Hongxia Xu","Jian Wu"],"url":"https://arxiv.org/abs/2504.14565"}
{"created":"2025-04-22","title":"SMTT: Novel Structured Multi-task Tracking with Graph-Regularized Sparse Representation for Robust Thermal Infrared Target Tracking","abstract":"Thermal infrared target tracking is crucial in applications such as surveillance, autonomous driving, and military operations. In this paper, we propose a novel tracker, SMTT, which effectively addresses common challenges in thermal infrared imagery, such as noise, occlusion, and rapid target motion, by leveraging multi-task learning, joint sparse representation, and adaptive graph regularization. By reformulating the tracking task as a multi-task learning problem, the SMTT tracker independently optimizes the representation of each particle while dynamically capturing spatial and feature-level similarities using a weighted mixed-norm regularization strategy. To ensure real-time performance, we incorporate the Accelerated Proximal Gradient method for efficient optimization. Extensive experiments on benchmark datasets - including VOT-TIR, PTB-TIR, and LSOTB-TIR - demonstrate that SMTT achieves superior accuracy, robustness, and computational efficiency. These results highlight SMTT as a reliable and high-performance solution for thermal infrared target tracking in complex environments.","authors":["Shang Zhang","HuiPan Guan","XiaoBo Ding","Ruoyan Xiong","Yue Zhang"],"url":"https://arxiv.org/abs/2504.14566"}
{"created":"2025-04-22","title":"NoWag: A Unified Framework for Shape Preserving Compression of Large Language Models","abstract":"Large language models (LLMs) exhibit remarkable performance across various natural language processing tasks but suffer from immense computational and memory demands, limiting their deployment in resource-constrained environments. To address this challenge, we propose NoWag: (Normalized Weight and Activation Guided Compression), a unified framework for zero-shot shape preserving compression algorithms. We compressed Llama-2 7B/13B/70B and Llama-3 8/70BB models, using two popular forms of shape-preserving compression, vector quantization NoWag-VQ (NoWag for Vector Quantization), and unstructured/semi-structured pruning NoWag-P (NoWag for Pruning). We found that NoWag-VQ significantly outperforms state-of-the-art zero shot VQ, and that NoWag-P performs competitively against state-of-the-art methods. These results suggest commonalities between these compression paradigms that could inspire future work. Our code is available at https://github.com/LawrenceRLiu/NoWag","authors":["Lawrence Liu","Inesh Chakrabarti","Yixiao Li","Mengdi Wang","Tuo Zhao","Lin F. Yang"],"url":"https://arxiv.org/abs/2504.14569"}
{"created":"2025-04-22","title":"Haptic-based Complementary Filter for Rigid Body Rotations","abstract":"The non-commutative nature of 3D rotations poses well-known challenges in generalizing planar problems to three-dimensional ones, even more so in contact-rich tasks where haptic information (i.e., forces/torques) is involved. In this sense, not all learning-based algorithms that are currently available generalize to 3D orientation estimation. Non-linear filters defined on $\\mathbf{\\mathbb{SO}(3)}$ are widely used with inertial measurement sensors; however, none of them have been used with haptic measurements. This paper presents a unique complementary filtering framework that interprets the geometric shape of objects in the form of superquadrics, exploits the symmetry of $\\mathbf{\\mathbb{SO}(3)}$, and uses force and vision sensors as measurements to provide an estimate of orientation. The framework's robustness and almost global stability are substantiated by a set of experiments on a dual-arm robotic setup.","authors":["Amit Kumar","Domenico Campolo","Ravi N. Banavar"],"url":"https://arxiv.org/abs/2504.14570"}
{"created":"2025-04-22","title":"Prompt-Hacking: The New p-Hacking?","abstract":"As Large Language Models (LLMs) become increasingly embedded in empirical research workflows, their use as analytical tools raises pressing concerns for scientific integrity. This opinion paper draws a parallel between \"prompt-hacking\", the strategic tweaking of prompts to elicit desirable outputs from LLMs, and the well-documented practice of \"p-hacking\" in statistical analysis. We argue that the inherent biases, non-determinism, and opacity of LLMs make them unsuitable for data analysis tasks demanding rigor, impartiality, and reproducibility. We emphasize how researchers may inadvertently, or even deliberately, adjust prompts to confirm hypotheses while undermining research validity. We advocate for a critical view of using LLMs in research, transparent prompt documentation, and clear standards for when LLM use is appropriate. We discuss how LLMs can replace traditional analytical methods, whereas we recommend that LLMs should only be used with caution, oversight, and justification.","authors":["Thomas Kosch","Sebastian Feger"],"url":"https://arxiv.org/abs/2504.14571"}
{"created":"2025-04-22","title":"Data Selection for ERMs","abstract":"Learning theory has traditionally followed a model-centric approach, focusing on designing optimal algorithms for a fixed natural learning task (e.g., linear classification or regression). In this paper, we adopt a complementary data-centric perspective, whereby we fix a natural learning rule and focus on optimizing the training data. Specifically, we study the following question: given a learning rule $\\mathcal{A}$ and a data selection budget $n$, how well can $\\mathcal{A}$ perform when trained on at most $n$ data points selected from a population of $N$ points? We investigate when it is possible to select $n \\ll N$ points and achieve performance comparable to training on the entire population.","authors":["Steve Hanneke","Shay Moran","Alexander Shlimovich","Amir Yehudayoff"],"url":"https://arxiv.org/abs/2504.14572"}
{"created":"2025-04-22","title":"Modality Selection and Skill Segmentation via Cross-Modality Attention","abstract":"Incorporating additional sensory modalities such as tactile and audio into foundational robotic models poses significant challenges due to the curse of dimensionality. This work addresses this issue through modality selection. We propose a cross-modality attention (CMA) mechanism to identify and selectively utilize the modalities that are most informative for action generation at each timestep. Furthermore, we extend the application of CMA to segment primitive skills from expert demonstrations and leverage this segmentation to train a hierarchical policy capable of solving long-horizon, contact-rich manipulation tasks.","authors":["Jiawei Jiang","Kei Ota","Devesh K. Jha","Asako Kanezaki"],"url":"https://arxiv.org/abs/2504.14573"}
{"created":"2025-04-22","title":"Virtual Reality for Urban Walkability Assessment","abstract":"Traditional urban planning methodologies often fail to capture the complexity of contemporary urbanization and environmental sustainability challenges. This study investigates the integration of Generative Design, Virtual Reality (VR), and Digital Twins (DT) to enhance walkability in urban planning. VR provides distinct benefits over conventional approaches, including 2D maps, static renderings, and physical models, by allowing stakeholders to engage with urban designs more intuitively, identify walkability challenges, and suggest iterative improvements. Preliminary findings from structured interviews with Eindhoven residents provide critical insights into pedestrian preferences and walkability considerations. The next phase of the study involves the development of VR-DT integrated prototypes to simulate urban environments, assess walkability, and explore the role of Generative Design in generating adaptive urban planning solutions. The objective is to develop a decision-support tool that enables urban planners to incorporate diverse stakeholder perspectives, optimize pedestrian-oriented urban design, and advance regenerative development principles. By leveraging these emerging technologies, this research contributes to the evolution of data-driven, participatory urban planning frameworks aimed at fostering sustainable and walkable cities.","authors":["Viet Hung Pham","Malte Wagenfeld","Regina Bernhaupt"],"url":"https://arxiv.org/abs/2504.14580"}
{"created":"2025-04-22","title":"NTIRE 2025 Challenge on Image Super-Resolution ($\\times$4): Methods and Results","abstract":"This paper presents the NTIRE 2025 image super-resolution ($\\times$4) challenge, one of the associated competitions of the 10th NTIRE Workshop at CVPR 2025. The challenge aims to recover high-resolution (HR) images from low-resolution (LR) counterparts generated through bicubic downsampling with a $\\times$4 scaling factor. The objective is to develop effective network designs or solutions that achieve state-of-the-art SR performance. To reflect the dual objectives of image SR research, the challenge includes two sub-tracks: (1) a restoration track, emphasizes pixel-wise accuracy and ranks submissions based on PSNR; (2) a perceptual track, focuses on visual realism and ranks results by a perceptual score. A total of 286 participants registered for the competition, with 25 teams submitting valid entries. This report summarizes the challenge design, datasets, evaluation protocol, the main results, and methods of each team. The challenge serves as a benchmark to advance the state of the art and foster progress in image SR.","authors":["Zheng Chen","Kai Liu","Jue Gong","Jingkai Wang","Lei Sun","Zongwei Wu","Radu Timofte","Yulun Zhang","Xiangyu Kong","Xiaoxuan Yu","Hyunhee Park","Suejin Han","Hakjae Jeon","Dafeng Zhang","Hyung-Ju Chun","Donghun Ryou","Inju Ha","Bohyung Han","Lu Zhao","Yuyi Zhang","Pengyu Yan","Jiawei Hu","Pengwei Liu","Fengjun Guo","Hongyuan Yu","Pufan Xu","Zhijuan Huang","Shuyuan Cui","Peng Guo","Jiahui Liu","Dongkai Zhang","Heng Zhang","Huiyuan Fu","Huadong Ma","Yanhui Guo","Sisi Tian","Xin Liu","Jinwen Liang","Jie Liu","Jie Tang","Gangshan Wu","Zeyu Xiao","Zhuoyuan Li","Yinxiang Zhang","Wenxuan Cai","Vijayalaxmi Ashok Aralikatti","Nikhil Akalwadi","G Gyaneshwar Rao","Chaitra Desai","Ramesh Ashok Tabib","Uma Mudenagudi","Marcos V. Conde","Alejandro Merino","Bruno Longarela","Javier Abad","Weijun Yuan","Zhan Li","Zhanglu Chen","Boyang Yao","Aagam Jain","Milan Kumar Singh","Ankit Kumar","Shubh Kawa","Divyavardhan Singh","Anjali Sarvaiya","Kishor Upla","Raghavendra Ramachandra","Chia-Ming Lee","Yu-Fan Lin","Chih-Chung Hsu","Risheek V Hiremath","Yashaswini Palani","Yuxuan Jiang","Qiang Zhu","Siyue Teng","Fan Zhang","Shuyuan Zhu","Bing Zeng","David Bull","Jingwei Liao","Yuqing Yang","Wenda Shao","Junyi Zhao","Qisheng Xu","Kele Xu","Sunder Ali Khowaja","Ik Hyun Lee","Snehal Singh Tomar","Rajarshi Ray","Klaus Mueller","Sachin Chaudhary","Surya Vashisth","Akshay Dudhane","Praful Hambarde","Satya Naryan Tazi","Prashant Patil","Santosh Kumar Vipparthi","Subrahmanyam Murala","Bilel Benjdira","Anas M. Ali","Wadii Boulila","Zahra Moammeri","Ahmad Mahmoudi-Aznaveh","Ali Karbasi","Hossein Motamednia","Liangyan Li","Guanhua Zhao","Kevin Le","Yimo Ning","Haoxuan Huang","Jun Chen"],"url":"https://arxiv.org/abs/2504.14582"}
{"created":"2025-04-22","title":"Using street view imagery and deep generative modeling for estimating the health of urban forests","abstract":"Healthy urban forests comprising of diverse trees and shrubs play a crucial role in mitigating climate change. They provide several key advantages such as providing shade for energy conservation, and intercepting rainfall to reduce flood runoff and soil erosion. Traditional approaches for monitoring the health of urban forests require instrumented inspection techniques, often involving a high amount of human labor and subjective evaluations. As a result, they are not scalable for cities which lack extensive resources. Recent approaches involving multi-spectral imaging data based on terrestrial sensing and satellites, are constrained respectively with challenges related to dedicated deployments and limited spatial resolutions. In this work, we propose an alternative approach for monitoring the urban forests using simplified inputs: street view imagery, tree inventory data and meteorological conditions. We propose to use image-to-image translation networks to estimate two urban forest health parameters, namely, NDVI and CTD. Finally, we aim to compare the generated results with ground truth data using an onsite campaign utilizing handheld multi-spectral and thermal imaging sensors. With the advent and expansion of street view imagery platforms such as Google Street View and Mapillary, this approach should enable effective management of urban forests for the authorities in cities at scale.","authors":["Akshit Gupta","Remko Uijlenhoet"],"url":"https://arxiv.org/abs/2504.14583"}
{"created":"2025-04-22","title":"Generative Auto-Bidding with Value-Guided Explorations","abstract":"Auto-bidding, with its strong capability to optimize bidding decisions within dynamic and competitive online environments, has become a pivotal strategy for advertising platforms. Existing approaches typically employ rule-based strategies or Reinforcement Learning (RL) techniques. However, rule-based strategies lack the flexibility to adapt to time-varying market conditions, and RL-based methods struggle to capture essential historical dependencies and observations within Markov Decision Process (MDP) frameworks. Furthermore, these approaches often face challenges in ensuring strategy adaptability across diverse advertising objectives. Additionally, as offline training methods are increasingly adopted to facilitate the deployment and maintenance of stable online strategies, the issues of documented behavioral patterns and behavioral collapse resulting from training on fixed offline datasets become increasingly significant. To address these limitations, this paper introduces a novel offline Generative Auto-bidding framework with Value-Guided Explorations (GAVE). GAVE accommodates various advertising objectives through a score-based Return-To-Go (RTG) module. Moreover, GAVE integrates an action exploration mechanism with an RTG-based evaluation method to explore novel actions while ensuring stability-preserving updates. A learnable value function is also designed to guide the direction of action exploration and mitigate Out-of-Distribution (OOD) problems. Experimental results on two offline datasets and real-world deployments demonstrate that GAVE outperforms state-of-the-art baselines in both offline evaluations and online A/B tests. The implementation code is publicly available to facilitate reproducibility and further research.","authors":["Jingtong Gao","Yewen Li","Shuai Mao","Peng Jiang","Nan Jiang","Yejing Wang","Qingpeng Cai","Fei Pan","Peng Jiang","Kun Gai","Bo An","Xiangyu Zhao"],"url":"https://arxiv.org/abs/2504.14587"}
{"created":"2025-04-22","title":"Phoenix: A Motion-based Self-Reflection Framework for Fine-grained Robotic Action Correction","abstract":"Building a generalizable self-correction system is crucial for robots to recover from failures. Despite advancements in Multimodal Large Language Models (MLLMs) that empower robots with semantic reflection ability for failure, translating semantic reflection into how to correct fine-grained robotic actions remains a significant challenge. To address this gap, we build the Phoenix framework, which leverages motion instruction as a bridge to connect high-level semantic reflection with low-level robotic action correction. In this motion-based self-reflection framework, we start with a dual-process motion adjustment mechanism with MLLMs to translate the semantic reflection into coarse-grained motion instruction adjustment. To leverage this motion instruction for guiding how to correct fine-grained robotic actions, a multi-task motion-conditioned diffusion policy is proposed to integrate visual observations for high-frequency robotic action correction. By combining these two models, we could shift the demand for generalization capability from the low-level manipulation policy to the MLLMs-driven motion adjustment model and facilitate precise, fine-grained robotic action correction. Utilizing this framework, we further develop a lifelong learning method to automatically improve the model's capability from interactions with dynamic environments. The experiments conducted in both the RoboMimic simulation and real-world scenarios prove the superior generalization and robustness of our framework across a variety of manipulation tasks. Our code is released at \\href{https://github.com/GeWu-Lab/Motion-based-Self-Reflection-Framework}{https://github.com/GeWu-Lab/Motion-based-Self-Reflection-Framework}.","authors":["Wenke Xia","Ruoxuan Feng","Dong Wang","Di Hu"],"url":"https://arxiv.org/abs/2504.14588"}
{"created":"2025-04-22","title":"Interdisciplinary Integration of Remote Sensing -- A Review with Four Examples","abstract":"As a high-level discipline, the development of remote sensing depends on the contribution of many other basic and applied disciplines and technologies. For example, due to the close relationship between remote sensing and photogrammetry, remote sensing would inevitably integrate disciplines such as optics and color science. Also, remote sensing integrates the knowledge of electronics in the conversion from optical signals to electrical signals via CCD (Charge-Coupled Device) or other image sensors. Moreover, when conducting object identification and classification with remote sensing data, mathematical morphology and other digital image processing technologies are used. These examples are only the tip of the iceberg of interdisciplinary integration of remote sensing. This work briefly reviews the interdisciplinary integration of remote sensing with four examples - ecology, mathematical morphology, machine learning, and electronics.","authors":["Zichen Jin"],"url":"https://arxiv.org/abs/2504.14590"}
{"created":"2025-04-22","title":"HealthGenie: Empowering Users with Healthy Dietary Guidance through Knowledge Graph and Large Language Models","abstract":"Seeking dietary guidance often requires navigating complex professional knowledge while accommodating individual health conditions. Knowledge Graphs (KGs) offer structured and interpretable nutritional information, whereas Large Language Models (LLMs) naturally facilitate conversational recommendation delivery. In this paper, we present HealthGenie, an interactive system that combines the strengths of LLMs and KGs to provide personalized dietary recommendations along with hierarchical information visualization for a quick and intuitive overview. Upon receiving a user query, HealthGenie performs query refinement and retrieves relevant information from a pre-built KG. The system then visualizes and highlights pertinent information, organized by defined categories, while offering detailed, explainable recommendation rationales. Users can further tailor these recommendations by adjusting preferences interactively. Our evaluation, comprising a within-subject comparative experiment and an open-ended discussion, demonstrates that HealthGenie effectively supports users in obtaining personalized dietary guidance based on their health conditions while reducing interaction effort and cognitive load. These findings highlight the potential of LLM-KG integration in supporting decision-making through explainable and visualized information. We examine the system's usefulness and effectiveness with an N=12 within-subject study and provide design considerations for future systems that integrate conversational LLM and KG.","authors":["Fan Gao","Xinjie Zhao","Ding Xia","Zhongyi Zhou","Rui Yang","Jinghui Lu","Hang Jiang","Chanjun Park","Irene Li"],"url":"https://arxiv.org/abs/2504.14594"}
{"created":"2025-04-22","title":"Toward the Axiomatization of Intelligence: Structure, Time, and Existence","abstract":"This study aims to construct an axiomatic definition of intelligence within a meta-framework that defines the method of definition, addressing intelligence as an inherently naive and polysemous concept. Initially, we formalize a set-theoretic representation of the universe as the domain wherein intelligence exists and characterize intelligence as a structure that involves temporal evolution and interaction with other sets. Starting from a naive definition of intelligence as \"an entity possessing structures for externally inputting, internally processing, and externally outputting information or matter,\" we axiomatically reformulate it within this set-theoretical depiction of the universe. Applying this axiomatic definition, we compare and interpret three examples -- Hebbian non-optimized neural networks (NNs), backpropagation-optimized NNs, and biological reflexive systems -- in terms of their intelligence, structural properties, and biological plausibility. Furthermore, by extending our definition into a categorical framework, we introduce two categories, \"Time Category\" and \"Intelligence Category,\" along with the functorial relationships between them, demonstrating the potential to represent changes and mimicry relationships among intelligent systems abstractly. Additionally, since intelligence, as defined herein, functions effectively only when accompanied by temporal interactions, we introduce the concept of \"activity\" and explore how activity-based conditions influence classifications and interpretations of intelligence. Finally, we suggest that our definitional methodology is not limited to intelligence alone, but can be similarly applied to other concepts, such as consciousness and emotion, advocating for their formal reinterpretation through the same procedural steps: defining a universal representation, selecting naive definitions, and axiomatic formalization.","authors":["Kei Itoh"],"url":"https://arxiv.org/abs/2504.14596"}
{"created":"2025-04-22","title":"a1: Steep Test-time Scaling Law via Environment Augmented Generation","abstract":"Large Language Models (LLMs) have made remarkable breakthroughs in reasoning, yet continue to struggle with hallucinations, logical errors, and inability to self-correct during complex multi-step tasks. Current approaches like chain-of-thought prompting offer limited reasoning capabilities that fail when precise step validation is required. We propose Environment Augmented Generation (EAG), a framework that enhances LLM reasoning through: (1) real-time environmental feedback validating each reasoning step, (2) dynamic branch exploration for investigating alternative solution paths when faced with errors, and (3) experience-based learning from successful reasoning trajectories. Unlike existing methods, EAG enables deliberate backtracking and strategic replanning through tight integration of execution feedback with branching exploration. Our a1-32B model achieves state-of-the-art performance among similar-sized models across all benchmarks, matching larger models like o1 on competition mathematics while outperforming comparable models by up to 24.4 percentage points. Analysis reveals EAG's distinctive scaling pattern: initial token investment in environment interaction yields substantial long-term performance dividends, with advantages amplifying proportionally to task complexity. EAG's theoretical framework demonstrates how environment interactivity and systematic branch exploration together establish a new paradigm for reliable machine reasoning, particularly for problems requiring precise multi-step calculation and logical verification.","authors":["Lingrui Mei","Shenghua Liu","Yiwei Wang","Baolong Bi","Yuyao Ge","Jun Wan","Yurong Wu","Xueqi Cheng"],"url":"https://arxiv.org/abs/2504.14597"}
{"created":"2025-04-22","title":"NTIRE 2025 Challenge on Real-World Face Restoration: Methods and Results","abstract":"This paper provides a review of the NTIRE 2025 challenge on real-world face restoration, highlighting the proposed solutions and the resulting outcomes. The challenge focuses on generating natural, realistic outputs while maintaining identity consistency. Its goal is to advance state-of-the-art solutions for perceptual quality and realism, without imposing constraints on computational resources or training data. The track of the challenge evaluates performance using a weighted image quality assessment (IQA) score and employs the AdaFace model as an identity checker. The competition attracted 141 registrants, with 13 teams submitting valid models, and ultimately, 10 teams achieved a valid score in the final ranking. This collaborative effort advances the performance of real-world face restoration while offering an in-depth overview of the latest trends in the field.","authors":["Zheng Chen","Jingkai Wang","Kai Liu","Jue Gong","Lei Sun","Zongwei Wu","Radu Timofte","Yulun Zhang","Jianxing Zhang","Jinlong Wu","Jun Wang","Zheng Xie","Hakjae Jeon","Suejin Han","Hyung-Ju Chun","Hyunhee Park","Zhicun Yin","Junjie Chen","Ming Liu","Xiaoming Li","Chao Zhou","Wangmeng Zuo","Weixia Zhang","Dingquan Li","Kede Ma","Yun Zhang","Zhuofan Zheng","Yuyue Liu","Shizhen Tang","Zihao Zhang","Yi Ning","Hao Jiang","Wenjie An","Kangmeng Yu","Chenyang Wang","Kui Jiang","Xianming Liu","Junjun Jiang","Yingfu Zhang","Gang He","Siqi Wang","Kepeng Xu","Zhenyang Liu","Changxin Zhou","Shanlan Shen","Yubo Duan","Yiang Chen","Jin Guo","Mengru Yang","Jen-Wei Lee","Chia-Ming Lee","Chih-Chung Hsu","Hu Peng","Chunming He"],"url":"https://arxiv.org/abs/2504.14600"}
{"created":"2025-04-22","title":"Rethinking trust in the digital age: An investigation of zero trust architecture's social consequences on organizational culture, collaboration, and knowledge sharing","abstract":"As cyber threats escalate, Zero Trust Architecture (ZTA) replaces outdated perimeter security with strict never trust, always verify protocols. However, ZTA's dual nature as both technical infrastructure and social intervention creates an unresolved tension: its very mechanisms for security may systematically erode the trust foundations enabling effective collaboration. This integrative research combines case study analysis, employee surveys, and social network mapping reveals how ZTA disrupts knowledge-sharing, disproportionately hindering low-altruism employees, while surveillance erodes collective psychological ownership. Networked organizations, reliant on fluid trust, face fragmentation risks. Mitigation strategies include adaptive authorization frameworks using behavioral analytics and transparent communication reframing security as shared responsibility. Interdepartmental collaboration in security design preserves organizational trust structures identified through sociometric mapping. This research provides a framework balancing technical rigor with cultural sensitivity, proving cybersecurity can coexist with innovation by aligning verification with organizational psychology. The findings pioneer a paradigm where security and trust evolve synergistically critical for digital resilience in hybrid work environments. Future security must harmonize protocols with trust cultivation, ensuring defenses adapt to social dynamics driving modern enterprises.","authors":["Ganiyu Oladimeji"],"url":"https://arxiv.org/abs/2504.14601"}
{"created":"2025-04-22","title":"K2MUSE: A human lower limb multimodal dataset under diverse conditions for facilitating rehabilitation robotics","abstract":"The natural interaction and control performance of lower limb rehabilitation robots are closely linked to biomechanical information from various human locomotion activities. Multidimensional human motion data significantly deepen the understanding of the complex mechanisms governing neuromuscular alterations, thereby facilitating the development and application of rehabilitation robots in multifaceted real-world environments. However, currently available lower limb datasets are inadequate for supplying the essential multimodal data and large-scale gait samples necessary for effective data-driven approaches, and they neglect the significant effects of acquisition interference in real applications.To fill this gap, we present the K2MUSE dataset, which includes a comprehensive collection of multimodal data, comprising kinematic, kinetic, amplitude-mode ultrasound (AUS), and surface electromyography (sEMG) measurements. The proposed dataset includes lower limb multimodal data from 30 able-bodied participants walking under different inclines (0$^\\circ$, $\\pm$5$^\\circ$, and $\\pm$10$^\\circ$), various speeds (0.5 m/s, 1.0 m/s, and 1.5 m/s), and different nonideal acquisition conditions (muscle fatigue, electrode shifts, and inter-day differences). The kinematic and ground reaction force data were collected via a Vicon motion capture system and an instrumented treadmill with embedded force plates, whereas the sEMG and AUS data were synchronously recorded for thirteen muscles on the bilateral lower limbs. This dataset offers a new resource for designing control frameworks for rehabilitation robots and conducting biomechanical analyses of lower limb locomotion. The dataset is available at https://k2muse.github.io/.","authors":["Jiwei Li","Bi Zhang","Xiaowei Tan","Wanxin Chen","Zhaoyuan Liu","Juanjuan Zhang","Weiguang Huo","Jian Huang","Lianqing Liu","Xingang Zhao"],"url":"https://arxiv.org/abs/2504.14602"}
{"created":"2025-04-22","title":"UFO2: The Desktop AgentOS","abstract":"Recent Computer-Using Agents (CUAs), powered by multimodal large language models (LLMs), offer a promising direction for automating complex desktop workflows through natural language. However, most existing CUAs remain conceptual prototypes, hindered by shallow OS integration, fragile screenshot-based interaction, and disruptive execution.","authors":["Chaoyun Zhang","He Huang","Chiming Ni","Jian Mu","Si Qin","Shilin He","Lu Wang","Fangkai Yang","Pu Zhao","Chao Du","Liqun Li","Yu Kang","Zhao Jiang","Suzhen Zheng","Rujia Wang","Jiaxu Qian","Minghua Ma","Jian-Guang Lou","Qingwei Lin","Saravan Rajmohan","Dongmei Zhang"],"url":"https://arxiv.org/abs/2504.14603"}
{"created":"2025-04-22","title":"RoboOcc: Enhancing the Geometric and Semantic Scene Understanding for Robots","abstract":"3D occupancy prediction enables the robots to obtain spatial fine-grained geometry and semantics of the surrounding scene, and has become an essential task for embodied perception. Existing methods based on 3D Gaussians instead of dense voxels do not effectively exploit the geometry and opacity properties of Gaussians, which limits the network's estimation of complex environments and also limits the description of the scene by 3D Gaussians. In this paper, we propose a 3D occupancy prediction method which enhances the geometric and semantic scene understanding for robots, dubbed RoboOcc. It utilizes the Opacity-guided Self-Encoder (OSE) to alleviate the semantic ambiguity of overlapping Gaussians and the Geometry-aware Cross-Encoder (GCE) to accomplish the fine-grained geometric modeling of the surrounding scene. We conduct extensive experiments on Occ-ScanNet and EmbodiedOcc-ScanNet datasets, and our RoboOcc achieves state-of the-art performance in both local and global camera settings. Further, in ablation studies of Gaussian parameters, the proposed RoboOcc outperforms the state-of-the-art methods by a large margin of (8.47, 6.27) in IoU and mIoU metric, respectively. The codes will be released soon.","authors":["Zhang Zhang","Qiang Zhang","Wei Cui","Shuai Shi","Yijie Guo","Gang Han","Wen Zhao","Hengle Ren","Renjing Xu","Jian Tang"],"url":"https://arxiv.org/abs/2504.14604"}
{"created":"2025-04-22","title":"Generalized Derangetropy Functionals for Modeling Cyclical Information Flow","abstract":"This paper introduces a framework for modeling cyclical and feedback-driven information flow through a generalized family of entropy-modulated transformations called derangetropy functionals. Unlike scalar and static entropy measures such as Shannon entropy, these functionals act directly on probability densities and provide a topographical representation of information structure across the support of the distribution. The framework captures periodic and self-referential aspects of information distribution and encodes them through functional operators governed by nonlinear differential equations. When applied recursively, these operators induce a spectral diffusion process governed by the heat equation, leading to convergence toward a Gaussian characteristic function. This convergence theorem provides a unified analytical foundation for describing the long-term dynamics of information under cyclic modulation. The proposed framework offers new tools for analyzing the temporal evolution of information in systems characterized by periodic structure, stochastic feedback, and delayed interaction, with applications in artificial neural networks, communication theory, and non-equilibrium statistical mechanics.","authors":["Masoud Ataei","Xiaogang Wang"],"url":"https://arxiv.org/abs/2504.14605"}
{"created":"2025-04-22","title":"MP-Mat: A 3D-and-Instance-Aware Human Matting and Editing Framework with Multiplane Representation","abstract":"Human instance matting aims to estimate an alpha matte for each human instance in an image, which is challenging as it easily fails in complex cases requiring disentangling mingled pixels belonging to multiple instances along hairy and thin boundary structures. In this work, we address this by introducing MP-Mat, a novel 3D-and-instance-aware matting framework with multiplane representation, where the multiplane concept is designed from two different perspectives: scene geometry level and instance level. Specifically, we first build feature-level multiplane representations to split the scene into multiple planes based on depth differences. This approach makes the scene representation 3D-aware, and can serve as an effective clue for splitting instances in different 3D positions, thereby improving interpretability and boundary handling ability especially in occlusion areas. Then, we introduce another multiplane representation that splits the scene in an instance-level perspective, and represents each instance with both matte and color. We also treat background as a special instance, which is often overlooked by existing methods. Such an instance-level representation facilitates both foreground and background content awareness, and is useful for other down-stream tasks like image editing. Once built, the representation can be reused to realize controllable instance-level image editing with high efficiency. Extensive experiments validate the clear advantage of MP-Mat in matting task. We also demonstrate its superiority in image editing tasks, an area under-explored by existing matting-focused methods, where our approach under zero-shot inference even outperforms trained specialized image editing techniques by large margins. Code is open-sourced at https://github.com/JiaoSiyi/MPMat.git}.","authors":["Siyi Jiao","Wenzheng Zeng","Yerong Li","Huayu Zhang","Changxin Gao","Nong Sang","Mike Zheng Shou"],"url":"https://arxiv.org/abs/2504.14606"}
{"created":"2025-04-22","title":"No Imputation of Missing Values In Tabular Data Classification Using Incremental Learning","abstract":"Tabular data sets with varying missing values are prepared for machine learning using an arbitrary imputation strategy. Synthetic values generated by imputation models often concern data stakeholders about computational complexity, data quality, and data-driven outcomes. This paper eliminates these concerns by proposing no imputation incremental learning (NIIL) of tabular data with varying missing value rates and types. The proposed method incrementally learns partitions of overlapping feature sets while using attention masks to exclude missing values from attention scoring. The average classification performance rank order across 15 diverse tabular data sets highlights the superiority of NIIL over 11 state-of-the-art learning methods with or without missing value imputations. Further experiments substantiate the robustness of NIIL against varying missing value types and rates compared to methods that involve the imputation of missing values. Our empirical analysis reveals that a feature partition size of half of the original feature space is, computation-wise and accuracy-wise, the best choice for the proposed incremental learning. The proposed method is one of the first deep learning solutions that can effectively learn tabular data without requiring the imputation of missing values.","authors":["Manar D. Samad","Kazi Fuad B. Akhter","Shourav B. Rabbani","Ibna Kowsar"],"url":"https://arxiv.org/abs/2504.14610"}
{"created":"2025-04-22","title":"Joint Optimization of Offloading, Batching and DVFS for Multiuser Co-Inference","abstract":"With the growing integration of artificial intelligence in mobile applications, a substantial number of deep neural network (DNN) inference requests are generated daily by mobile devices. Serving these requests presents significant challenges due to limited device resources and strict latency requirements. Therefore, edge-device co-inference has emerged as an effective paradigm to address these issues. In this study, we focus on a scenario where multiple mobile devices offload inference tasks to an edge server equipped with a graphics processing unit (GPU). For finer control over offloading and scheduling, inference tasks are partitioned into smaller sub-tasks. Additionally, GPU batch processing is employed to boost throughput and improve energy efficiency. This work investigates the problem of minimizing total energy consumption while meeting hard latency constraints. We propose a low-complexity Joint DVFS, Offloading, and Batching strategy (J-DOB) to solve this problem. The effectiveness of the proposed algorithm is validated through extensive experiments across varying user numbers and deadline constraints. Results show that J-DOB can reduce energy consumption by up to 51.30% and 45.27% under identical and different deadlines, respectively, compared to local computing.","authors":["Yaodan Xu","Sheng Zhou","Zhisheng Niu"],"url":"https://arxiv.org/abs/2504.14611"}
{"created":"2025-04-22","title":"Semantic HARQ for Intelligent Transportation Systems: Joint Source-Channel Coding-Powered Reliable Retransmissions","abstract":"The surge of data traffic in Intelligent Transportation Systems (ITS) places a significant challenge on limited wireless resources. Semantic communication, which transmits essential semantics of the raw data, offers a promising solution by reducing redundancy and improving spectrum efficiency. However, high vehicle mobility, dynamic channel conditions, and dense vehicular networks severely impact transmission reliability in ITS. To address these limitations, we integrate Hybrid Automatic Repeat reQuest (HARQ) with Joint Source-Channel Coding (JSCC) to provide reliable semantic communications for ITS. To counteract the adverse effects of time-varying fading channels and noise, we propose a generative signal reconstructor module supported by a local knowledge base, which employs a discriminator for channel error detection and a conditional generative network for error correction. We propose three innovative semantic HARQ (sem-HARQ) schemes, Type I sem-HARQ (sem-HARQ-I), sem-HARQ with weighted combining (sem-HARQ-WC), and sem-HARQ with synonymous combining (sem-HARQ-SC) to enable reliable JSCC-based semantic communications. At the transmitter, both sem-HARQ-I and sem-HARQ-WC retransmit the same semantic signals, while sem-HARQ-SC introduces redundant semantics across different HARQ rounds through synonymous mapping. At the receiver, sem-HARQ-I performs semantic decoding based solely on the currently received signal. In contrast, sem-HARQ-WC enhances reliability by fusing the current received semantic signal with prior erroneous signals at the feature or decision level, thereby exploiting semantic information from failed HARQ rounds. Similarly, sem-HARQ-SC employs feature-level combining, leveraging incremental semantic redundancy to merge semantic features from retransmissions.","authors":["Yongkang Li","Xu Wang","Zheng Shi","Yaru Fu"],"url":"https://arxiv.org/abs/2504.14615"}
{"created":"2025-04-22","title":"VM-BHINet:Vision Mamba Bimanual Hand Interaction Network for 3D Interacting Hand Mesh Recovery From a Single RGB Image","abstract":"Understanding bimanual hand interactions is essential for realistic 3D pose and shape reconstruction. However, existing methods struggle with occlusions, ambiguous appearances, and computational inefficiencies. To address these challenges, we propose Vision Mamba Bimanual Hand Interaction Network (VM-BHINet), introducing state space models (SSMs) into hand reconstruction to enhance interaction modeling while improving computational efficiency. The core component, Vision Mamba Interaction Feature Extraction Block (VM-IFEBlock), combines SSMs with local and global feature operations, enabling deep understanding of hand interactions. Experiments on the InterHand2.6M dataset show that VM-BHINet reduces Mean per-joint position error (MPJPE) and Mean per-vertex position error (MPVPE) by 2-3%, significantly surpassing state-of-the-art methods.","authors":["Han Bi","Ge Yu","Yu He","Wenzhuo Liu","Zijie Zheng"],"url":"https://arxiv.org/abs/2504.14618"}
{"created":"2025-04-22","title":"Translation Analytics for Freelancers: I. Introduction, Data Preparation, Baseline Evaluations","abstract":"This is the first in a series of papers exploring the rapidly expanding new opportunities arising from recent progress in language technologies for individual translators and language service providers with modest resources. The advent of advanced neural machine translation systems, large language models, and their integration into workflows via computer-assisted translation tools and translation management systems have reshaped the translation landscape. These advancements enable not only translation but also quality evaluation, error spotting, glossary generation, and adaptation to domain-specific needs, creating new technical opportunities for freelancers. In this series, we aim to empower translators with actionable methods to harness these advancements. Our approach emphasizes Translation Analytics, a suite of evaluation techniques traditionally reserved for large-scale industry applications but now becoming increasingly available for smaller-scale users. This first paper introduces a practical framework for adapting automatic evaluation metrics -- such as BLEU, chrF, TER, and COMET -- to freelancers' needs. We illustrate the potential of these metrics using a trilingual corpus derived from a real-world project in the medical domain and provide statistical analysis correlating human evaluations with automatic scores. Our findings emphasize the importance of proactive engagement with emerging technologies to not only adapt but thrive in the evolving professional environment.","authors":["Yuri Balashov","Alex Balashov","Shiho Fukuda Koski"],"url":"https://arxiv.org/abs/2504.14619"}
{"created":"2025-04-22","title":"A Hierarchical Framework for Measuring Scientific Paper Innovation via Large Language Models","abstract":"Measuring scientific paper innovation is both important and challenging. Existing content-based methods often overlook the full-paper context, fail to capture the full scope of innovation, and lack generalization. We propose HSPIM, a hierarchical and training-free framework based on large language models (LLMs). It introduces a Paper-to-Sections-to-QAs decomposition to assess innovation. We segment the text by section titles and use zero-shot LLM prompting to implement section classification, question-answering (QA) augmentation, and weighted novelty scoring. The generated QA pair focuses on section-level innovation and serves as additional context to improve the LLM scoring. For each chunk, the LLM outputs a novelty score and a confidence score. We use confidence scores as weights to aggregate novelty scores into a paper-level innovation score. To further improve performance, we propose a two-layer question structure consisting of common and section-specific questions, and apply a genetic algorithm to optimize the question-prompt combinations. Comprehensive experiments on scientific conference paper datasets show that HSPIM outperforms baseline methods in effectiveness, generalization, and interpretability.","authors":["Hongming Tan","Shaoxiong Zhan","Fengwei Jia","Hai-Tao Zheng","Wai Kin Chan"],"url":"https://arxiv.org/abs/2504.14620"}
{"created":"2025-04-22","title":"Talk is Not Always Cheap: Promoting Wireless Sensing Models with Text Prompts","abstract":"Wireless signal-based human sensing technologies, such as WiFi, millimeter-wave (mmWave) radar, and Radio Frequency Identification (RFID), enable the detection and interpretation of human presence, posture, and activities, thereby providing critical support for applications in public security, healthcare, and smart environments. These technologies exhibit notable advantages due to their non-contact operation and environmental adaptability; however, existing systems often fail to leverage the textual information inherent in datasets. To address this, we propose an innovative text-enhanced wireless sensing framework, WiTalk, that seamlessly integrates semantic knowledge through three hierarchical prompt strategies-label-only, brief description, and detailed action description-without requiring architectural modifications or incurring additional data costs. We rigorously validate this framework across three public benchmark datasets: XRF55 for human action recognition (HAR), and WiFiTAL and XRFV2 for WiFi temporal action localization (TAL). Experimental results demonstrate significant performance improvements: on XRF55, accuracy for WiFi, RFID, and mmWave increases by 3.9%, 2.59%, and 0.46%, respectively; on WiFiTAL, the average performance of WiFiTAD improves by 4.98%; and on XRFV2, the mean average precision gains across various methods range from 4.02% to 13.68%. Our codes have been included in https://github.com/yangzhenkui/WiTalk.","authors":["Zhenkui Yang","Zeyi Huang","Ge Wang","Han Ding","Tony Xiao Han","Fei Wang"],"url":"https://arxiv.org/abs/2504.14621"}
{"created":"2025-04-22","title":"Synthesising Asynchronous Automata from Fair Specifications","abstract":"Asynchronous automata are a model of distributed finite state processes synchronising on shared actions. A celebrated result by Zielonka shows how a deterministic asynchronous automaton (AA) can be synthesised, starting from two inputs: a global specification as a deterministic finite-state automaton (DFA) and a distribution of the alphabet into local alphabets for each process. The translation is particularly complex and has been revisited several times. In this work, we revisit this construction on a restricted class of fair specifications: a DFA described a fair specification if in every loop, all processes participate in at least one action - so, no process is starved. For fair specifications, we present a new construction to synthesise an AA. Our construction is conceptually simpler and results in an AA where every process has a number of local states that is linear in the number of states of the DFA, and where the only exponential explosion is related to a parameter of fairness (the length of the longest word that can be read in the DFA in which not every process participates). Finally, we show how this construction can be combined with an existing construction for hierarchical process architectures.","authors":["B\\'eatrice B\\'erard","Benjamin Monmege","B Srivathsan","Arnab Sur"],"url":"https://arxiv.org/abs/2504.14623"}
{"created":"2025-04-22","title":"Consensus in Motion: A Case of Dynamic Rationality of Sequential Learning in Probability Aggregation","abstract":"We propose a framework for probability aggregation based on propositional probability logic. Unlike conventional judgment aggregation, which focuses on static rationality, our model addresses dynamic rationality by ensuring that collective beliefs update consistently with new information. We show that any consensus-compatible and independent aggregation rule on a non-nested agenda is necessarily linear. Furthermore, we provide sufficient conditions for a fair learning process, where individuals initially agree on a specified subset of propositions known as the common ground, and new information is restricted to this shared foundation. This guarantees that updating individual judgments via Bayesian conditioning-whether performed before or after aggregation-yields the same collective belief. A distinctive feature of our framework is its treatment of sequential decision-making, which allows new information to be incorporated progressively through multiple stages while maintaining the established common ground. We illustrate our findings with a running example in a political scenario concerning healthcare and immigration policies.","authors":["Polina Gordienko","Christoph Jansen","Thomas Augustin","Martin Rechenauer"],"url":"https://arxiv.org/abs/2504.14624"}
{"created":"2025-04-22","title":"Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence","abstract":"Large language models (LLMs) have transformed code generation, yet their application in hardware design produces gate counts 38\\%--1075\\% higher than human designs. We present CircuitMind, a multi-agent framework that achieves human-competitive efficiency through three key innovations: syntax locking (constraining generation to basic logic gates), retrieval-augmented generation (enabling knowledge-driven design), and dual-reward optimization (balancing correctness with efficiency). To evaluate our approach, we introduce TC-Bench, the first gate-level benchmark harnessing collective intelligence from the TuringComplete ecosystem -- a competitive circuit design platform with hundreds of thousands of players. Experiments show CircuitMind enables 55.6\\% of model implementations to match or exceed top-tier human experts in composite efficiency metrics. Most remarkably, our framework elevates the 14B Phi-4 model to outperform both GPT-4o mini and Gemini 2.0 Flash, achieving efficiency comparable to the top 25\\% of human experts without requiring specialized training. These innovations establish a new paradigm for hardware optimization where collaborative AI systems leverage collective human expertise to achieve optimal circuit designs. Our model, data, and code are open-source at https://github.com/BUAA-CLab/CircuitMind.","authors":["Haiyan Qin","Jiahao Feng","Xiaotong Feng","Wei W. Xing","Wang Kang"],"url":"https://arxiv.org/abs/2504.14625"}
{"created":"2025-04-22","title":"MSAD-Net: Multiscale and Spatial Attention-based Dense Network for Lung Cancer Classification","abstract":"Lung cancer, a severe form of malignant tumor that originates in the tissues of the lungs, can be fatal if not detected in its early stages. It ranks among the top causes of cancer-related mortality worldwide. Detecting lung cancer manually using chest X-Ray image or Computational Tomography (CT) scans image poses significant challenges for radiologists. Hence, there is a need for automatic diagnosis system of lung cancers from radiology images. With the recent emergence of deep learning, particularly through Convolutional Neural Networks (CNNs), the automated detection of lung cancer has become a much simpler task. Nevertheless, numerous researchers have addressed that the performance of conventional CNNs may be hindered due to class imbalance issue, which is prevalent in medical images. In this research work, we have proposed a novel CNN architecture ``Multi-Scale Dense Network (MSD-Net)'' (trained-from-scratch). The novelties we bring in the proposed model are (I) We introduce novel dense modules in the 4th block and 5th block of the CNN model. We have leveraged 3 depthwise separable convolutional (DWSC) layers, and one 1x1 convolutional layer in each dense module, in order to reduce complexity of the model considerably. (II) Additionally, we have incorporated one skip connection from 3rd block to 5th block and one parallel branch connection from 4th block to Global Average Pooling (GAP) layer. We have utilized dilated convolutional layer (with dilation rate=2) in the last parallel branch in order to extract multi-scale features. Extensive experiments reveal that our proposed model has outperformed latest CNN model ConvNext-Tiny, recent trend Vision Transformer (ViT), Pooling-based ViT (PiT), and other existing models by significant margins.","authors":["Santanu Roy","Shweta Singh","Palak Sahu","Ashvath Suresh","Debashish Das"],"url":"https://arxiv.org/abs/2504.14626"}
{"created":"2025-04-22","title":"Change Logging and Mining of Change Logs of Business Processes -- A Literature Review","abstract":"Context: Change mining enables organizations to understand the changes that occurred in their business processes. This allows them to enhance their business processes and adapt to dynamic environments. Therefore, change mining is becoming a topic of interest for researchers, scholars, and practitioners.","authors":["Arash Yadegari Ghahderijani","Hande Naz Turgay","Dimka Karastoyanova"],"url":"https://arxiv.org/abs/2504.14627"}
{"created":"2025-04-22","title":"GENE-FL: Gene-Driven Parameter-Efficient Dynamic Federated Learning","abstract":"Real-world \\underline{F}ederated \\underline{L}earning systems often encounter \\underline{D}ynamic clients with \\underline{A}gnostic and highly heterogeneous data distributions (DAFL), which pose challenges for efficient communication and model initialization. To address these challenges, we draw inspiration from the recently proposed Learngene paradigm, which compresses the large-scale model into lightweight, cross-task meta-information fragments. Learngene effectively encapsulates and communicates core knowledge, making it particularly well-suited for DAFL, where dynamic client participation requires communication efficiency and rapid adaptation to new data distributions. Based on this insight, we propose a Gene-driven parameter-efficient dynamic Federated Learning (GENE-FL) framework. First, local models perform quadratic constraints based on parameters with high Fisher values in the global model, as these parameters are considered to encapsulate generalizable knowledge. Second, we apply the strategy of parameter sensitivity analysis in local model parameters to condense the \\textit{learnGene} for interaction. Finally, the server aggregates these small-scale trained \\textit{learnGene}s into a robust \\textit{learnGene} with cross-task generalization capability, facilitating the rapid initialization of dynamic agnostic client models. Extensive experimental results demonstrate that GENE-FL reduces \\textbf{4 $\\times$} communication costs compared to FEDAVG and effectively initializes agnostic client models with only about \\textbf{9.04} MB.","authors":["Shunxin Guo","Jiaqi Lv","Qiufeng Wang","Xin Geng"],"url":"https://arxiv.org/abs/2504.14628"}
{"created":"2025-04-22","title":"Automatic Text Summarization (ATS) for Research Documents in Sorani Kurdish","abstract":"Extracting concise information from scientific documents aids learners, researchers, and practitioners. Automatic Text Summarization (ATS), a key Natural Language Processing (NLP) application, automates this process. While ATS methods exist for many languages, Kurdish remains underdeveloped due to limited resources. This study develops a dataset and language model based on 231 scientific papers in Sorani Kurdish, collected from four academic departments in two universities in the Kurdistan Region of Iraq (KRI), averaging 26 pages per document. Using Sentence Weighting and Term Frequency-Inverse Document Frequency (TF-IDF) algorithms, two experiments were conducted, differing in whether the conclusions were included. The average word count was 5,492.3 in the first experiment and 5,266.96 in the second. Results were evaluated manually and automatically using ROUGE-1, ROUGE-2, and ROUGE-L metrics, with the best accuracy reaching 19.58%. Six experts conducted manual evaluations using three criteria, with results varying by document. This research provides valuable resources for Kurdish NLP researchers to advance ATS and related fields.","authors":["Rondik Hadi Abdulrahman","Hossein Hassani"],"url":"https://arxiv.org/abs/2504.14630"}
{"created":"2025-04-22","title":"Explainability for Embedding AI: Aspirations and Actuality","abstract":"With artificial intelligence (AI) embedded in many everyday software systems, effectively and reliably developing and maintaining AI systems becomes an essential skill for software developers. However, the complexity inherent to AI poses new challenges. Explainable AI (XAI) may allow developers to understand better the systems they build, which, in turn, can help with tasks like debugging. In this paper, we report insights from a series of surveys with software developers that highlight that there is indeed an increased need for explanatory tools to support developers in creating AI systems. However, the feedback also indicates that existing XAI systems still fall short of this aspiration. Thus, we see an unmet need to provide developers with adequate support mechanisms to cope with this complexity so they can embed AI into high-quality software in the future.","authors":["Thomas Weber"],"url":"https://arxiv.org/abs/2504.14631"}
{"created":"2025-04-22","title":"Harnessing Generative LLMs for Enhanced Financial Event Entity Extraction Performance","abstract":"Financial event entity extraction is a crucial task for analyzing market dynamics and building financial knowledge graphs, yet it presents significant challenges due to the specialized language and complex structures in financial texts. Traditional approaches often rely on sequence labeling models, which can struggle with long-range dependencies and the inherent complexity of extracting multiple, potentially overlapping entities. Motivated by the advanced language understanding and generative capabilities of Large Language Models (LLMs), we propose a novel method that reframes financial event entity extraction as a text-to-structured-output generation task. Our approach involves fine-tuning a pre-trained LLM using Parameter-Efficient Fine-Tuning (PEFT) to directly generate a structured representation, such as a JSON object, containing the extracted entities and their precise character spans from the input text. We evaluate our method on the challenging CCKS 2019 Financial Event Entity Extraction dataset, comparing its performance against strong sequence labeling baselines, including SEBERTNets and sebertNets. Experimental results demonstrate that our generative LLM method achieves a new state-of-the-art F1 score on this benchmark, significantly outperforming previous methods. Through detailed quantitative analysis across event types, entity types, and instance complexity, as well as human evaluation, we show that our approach is more effective at handling the nuances of financial text and extracting high-quality entities. This work validates the potential of applying generative LLMs directly to complex, domain-specific information extraction tasks requiring structured output.","authors":["Soo-joon Choi","Ji-jun Park"],"url":"https://arxiv.org/abs/2504.14633"}
{"created":"2025-04-22","title":"Latent Representations for Visual Proprioception in Inexpensive Robots","abstract":"Robotic manipulation requires explicit or implicit knowledge of the robot's joint positions. Precise proprioception is standard in high-quality industrial robots but is often unavailable in inexpensive robots operating in unstructured environments. In this paper, we ask: to what extent can a fast, single-pass regression architecture perform visual proprioception from a single external camera image, available even in the simplest manipulation settings? We explore several latent representations, including CNNs, VAEs, ViTs, and bags of uncalibrated fiducial markers, using fine-tuning techniques adapted to the limited data available. We evaluate the achievable accuracy through experiments on an inexpensive 6-DoF robot.","authors":["Sahara Sheikholeslami","Ladislau B\\\"ol\\\"oni"],"url":"https://arxiv.org/abs/2504.14634"}
{"created":"2025-04-22","title":"AlphaZero-Edu: Making AlphaZero Accessible to Everyone","abstract":"Recent years have witnessed significant progress in reinforcement learning, especially with Zero-like paradigms, which have greatly boosted the generalization and reasoning abilities of large-scale language models. Nevertheless, existing frameworks are often plagued by high implementation complexity and poor reproducibility. To tackle these challenges, we present AlphaZero-Edu, a lightweight, education-focused implementation built upon the mathematical framework of AlphaZero. It boasts a modular architecture that disentangles key components, enabling transparent visualization of the algorithmic processes. Additionally, it is optimized for resource-efficient training on a single NVIDIA RTX 3090 GPU and features highly parallelized self-play data generation, achieving a 3.2-fold speedup with 8 processes. In Gomoku matches, the framework has demonstrated exceptional performance, achieving a consistently high win rate against human opponents. AlphaZero-Edu has been open-sourced at https://github.com/StarLight1212/AlphaZero_Edu, providing an accessible and practical benchmark for both academic research and industrial applications.","authors":["Binjie Guo","Hanyu Zheng","Guowei Su","Ru Zhang","Haohan Jiang","Xurong Lin","Hongyan Wei","Aisheng Mo","Jie Li","Zhiyuan Qian","Zhuhao Zhang","Xiaoyuan Cheng"],"url":"https://arxiv.org/abs/2504.14636"}
{"created":"2025-04-22","title":"NVSMask3D: Hard Visual Prompting with Camera Pose Interpolation for 3D Open Vocabulary Instance Segmentation","abstract":"Vision-language models (VLMs) have demonstrated impressive zero-shot transfer capabilities in image-level visual perception tasks. However, they fall short in 3D instance-level segmentation tasks that require accurate localization and recognition of individual objects. To bridge this gap, we introduce a novel 3D Gaussian Splatting based hard visual prompting approach that leverages camera interpolation to generate diverse viewpoints around target objects without any 2D-3D optimization or fine-tuning. Our method simulates realistic 3D perspectives, effectively augmenting existing hard visual prompts by enforcing geometric consistency across viewpoints. This training-free strategy seamlessly integrates with prior hard visual prompts, enriching object-descriptive features and enabling VLMs to achieve more robust and accurate 3D instance segmentation in diverse 3D scenes.","authors":["Junyuan Fang (Aalto University","Espoo","Finland","University of Helsinki","Helsinki","Finland)","Zihan Wang (Aalto University","Espoo","Finland)","Yejun Zhang (Aalto University","Espoo","Finland)","Shuzhe Wang (Aalto University","Espoo","Finland)","Iaroslav Melekhov (Aalto University","Espoo","Finland)","Juho Kannala (Aalto University","Espoo","Finland","University of Oulu","Oulu","Finland)"],"url":"https://arxiv.org/abs/2504.14638"}
{"created":"2025-04-22","title":"Risk Assessment Framework for Code LLMs via Leveraging Internal States","abstract":"The pre-training paradigm plays a key role in the success of Large Language Models (LLMs), which have been recognized as one of the most significant advancements of AI recently. Building on these breakthroughs, code LLMs with advanced coding capabilities bring huge impacts on software engineering, showing the tendency to become an essential part of developers' daily routines. However, the current code LLMs still face serious challenges related to trustworthiness, as they can generate incorrect, insecure, or unreliable code. Recent exploratory studies find that it can be promising to detect such risky outputs by analyzing LLMs' internal states, akin to how the human brain unconsciously recognizes its own mistakes. Yet, most of these approaches are limited to narrow sub-domains of LLM operations and fall short of achieving industry-level scalability and practicability. To address these challenges, in this paper, we propose PtTrust, a two-stage risk assessment framework for code LLM based on internal state pre-training, designed to integrate seamlessly with the existing infrastructure of software companies. The core idea is that the risk assessment framework could also undergo a pre-training process similar to LLMs. Specifically, PtTrust first performs unsupervised pre-training on large-scale unlabeled source code to learn general representations of LLM states. Then, it uses a small, labeled dataset to train a risk predictor. We demonstrate the effectiveness of PtTrust through fine-grained, code line-level risk assessment and demonstrate that it generalizes across tasks and different programming languages. Further experiments also reveal that PtTrust provides highly intuitive and interpretable features, fostering greater user trust. We believe PtTrust makes a promising step toward scalable and trustworthy assurance for code LLMs.","authors":["Yuheng Huang","Lei Ma","Keizaburo Nishikino","Takumi Akazaki"],"url":"https://arxiv.org/abs/2504.14640"}
{"created":"2025-04-22","title":"HLSTester: Efficient Testing of Behavioral Discrepancies with LLMs for High-Level Synthesis","abstract":"In high-level synthesis (HLS), C/C++ programs with synthesis directives are used to generate circuits for FPGA implementations. However, hardware-specific and platform-dependent characteristics in these implementations can introduce behavioral discrepancies between the original C/C++ programs and the circuits after high-level synthesis. Existing methods for testing behavioral discrepancies in HLS are still immature, and the testing workflow requires significant human efforts. To address this challenge, we propose HLSTester, a large language model (LLM) aided testing framework that efficiently detects behavioral discrepancies in HLS. To mitigate hallucinations in LLMs and enhance prompt quality, the testbenches for original C/C++ programs are leveraged to guide LLMs in generating HLS-compatible testbenches, effectively eliminating certain traditional C/C++ constructs that are incompatible with HLS tools. Key variables are pinpointed through a backward slicing technique in both C/C++ and HLS programs to monitor their runtime spectra, enabling an in-depth analysis of the discrepancy symptoms. To reduce test time, a testing input generation mechanism is introduced to integrate dynamic mutation with insights from an LLM-based progressive reasoning chain. In addition, repetitive hardware testing is skipped by a redundancy-aware filtering technique for the generated test inputs. Experimental results demonstrate that the proposed LLM-aided testing framework significantly accelerates the testing workflow while achieving higher testbench simulation pass rates compared with the traditional method and the direct use of LLMs on the same HLS programs.","authors":["Kangwei Xu","Bing Li","Grace Li Zhang","Ulf Schlichtmann"],"url":"https://arxiv.org/abs/2504.14641"}
{"created":"2025-04-22","title":"Relation-R1: Cognitive Chain-of-Thought Guided Reinforcement Learning for Unified Relational Comprehension","abstract":"Recent advances in multi-modal large language models (MLLMs) have significantly improved object-level grounding and region captioning, but remain limited in visual relation understanding (\\eg, scene graph generation), particularly in modeling \\textit{N}-ary relationships that identify multiple semantic roles among an action event. Such a lack of \\textit{semantic dependencies} modeling among multi-entities leads to unreliable outputs, intensifying MLLMs' hallucinations and over-reliance on language priors. To this end, we propose Relation-R1, the first unified relational comprehension framework that explicitly integrates cognitive chain-of-thought (CoT)-guided Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO) within a reinforcement learning (RL) paradigm. Specifically, we first establish foundational reasoning capabilities via SFT, enforcing structured outputs with thinking processes. Then, GRPO is utilized to refine these outputs via multi-reward optimization, prioritizing visual-semantic grounding over language-induced biases, thereby improving generalization capability. Extensive experiments on widely-used PSG and SWiG datasets demonstrate that Relation-R1 achieves state-of-the-art performance in both binary and \\textit{N}-ary relation understanding.","authors":["Lin Li","Wei Chen","Jiahui Li","Long Chen"],"url":"https://arxiv.org/abs/2504.14642"}
{"created":"2025-04-22","title":"Surrogate Fitness Metrics for Interpretable Reinforcement Learning","abstract":"We employ an evolutionary optimization framework that perturbs initial states to generate informative and diverse policy demonstrations. A joint surrogate fitness function guides the optimization by combining local diversity, behavioral certainty, and global population diversity. To assess demonstration quality, we apply a set of evaluation metrics, including the reward-based optimality gap, fidelity interquartile means (IQMs), fitness composition analysis, and trajectory visualizations. Hyperparameter sensitivity is also examined to better understand the dynamics of trajectory optimization. Our findings demonstrate that optimizing trajectory selection via surrogate fitness metrics significantly improves interpretability of RL policies in both discrete and continuous environments. In gridworld domains, evaluations reveal significantly enhanced demonstration fidelities compared to random and ablated baselines. In continuous control, the proposed framework offers valuable insights, particularly for early-stage policies, while fidelity-based optimization proves more effective for mature policies. By refining and systematically analyzing surrogate fitness functions, this study advances the interpretability of RL models. The proposed improvements provide deeper insights into RL decision-making, benefiting applications in safety-critical and explainability-focused domains.","authors":["Philipp Altmann","C\\'eline Davignon","Maximilian Zorn","Fabian Ritz","Claudia Linnhoff-Popien","Thomas Gabor"],"url":"https://arxiv.org/abs/2504.14645"}
{"created":"2025-04-22","title":"AI Literacy Education for Older Adults: Motivations, Challenges and Preferences","abstract":"As Artificial Intelligence (AI) becomes increasingly integrated into older adults' daily lives, equipping them with the knowledge and skills to understand and use AI is crucial. However, most research on AI literacy education has focused on students and children, leaving a gap in understanding the unique needs of older adults when learning about AI. To address this, we surveyed 103 older adults aged 50 and above (Mean = 64, SD = 7). Results revealed that they found it important and were motivated to learn about AI because they wish to harness the benefits and avoid the dangers of AI, seeing it as necessary to cope in the future. However, they expressed learning challenges such as difficulties in understanding and not knowing how to start learning AI. Particularly, a strong preference for hands-on learning was indicated. We discussed design opportunities to support AI literacy education for older adults.","authors":["Eugene Tang KangJie","Tianqi Song","Zicheng Zhu","Jingshu Li","Yi-Chieh Lee"],"url":"https://arxiv.org/abs/2504.14649"}
{"created":"2025-04-22","title":"A Framework for Benchmarking and Aligning Task-Planning Safety in LLM-Based Embodied Agents","abstract":"Large Language Models (LLMs) exhibit substantial promise in enhancing task-planning capabilities within embodied agents due to their advanced reasoning and comprehension. However, the systemic safety of these agents remains an underexplored frontier. In this study, we present Safe-BeAl, an integrated framework for the measurement (SafePlan-Bench) and alignment (Safe-Align) of LLM-based embodied agents' behaviors. SafePlan-Bench establishes a comprehensive benchmark for evaluating task-planning safety, encompassing 2,027 daily tasks and corresponding environments distributed across 8 distinct hazard categories (e.g., Fire Hazard). Our empirical analysis reveals that even in the absence of adversarial inputs or malicious intent, LLM-based agents can exhibit unsafe behaviors. To mitigate these hazards, we propose Safe-Align, a method designed to integrate physical-world safety knowledge into LLM-based embodied agents while maintaining task-specific performance. Experiments across a variety of settings demonstrate that Safe-BeAl provides comprehensive safety validation, improving safety by 8.55 - 15.22%, compared to embodied agents based on GPT-4, while ensuring successful task completion.","authors":["Yuting Huang","Leilei Ding","Zhipeng Tang","Tianfu Wang","Xinrui Lin","Wuyang Zhang","Mingxiao Ma","Yanyong Zhang"],"url":"https://arxiv.org/abs/2504.14650"}
{"created":"2025-04-22","title":"Wireless Large AI Model: Shaping the AI-Native Future of 6G and Beyond","abstract":"The emergence of sixth-generation and beyond communication systems is expected to fundamentally transform digital experiences through introducing unparalleled levels of intelligence, efficiency, and connectivity. A promising technology poised to enable this revolutionary vision is the wireless large AI model (WLAM), characterized by its exceptional capabilities in data processing, inference, and decision-making. In light of these remarkable capabilities, this paper provides a comprehensive survey of WLAM, elucidating its fundamental principles, diverse applications, critical challenges, and future research opportunities. We begin by introducing the background of WLAM and analyzing the key synergies with wireless networks, emphasizing the mutual benefits. Subsequently, we explore the foundational characteristics of WLAM, delving into their unique relevance in wireless environments. Then, the role of WLAM in optimizing wireless communication systems across various use cases and the reciprocal benefits are systematically investigated. Furthermore, we discuss the integration of WLAM with emerging technologies, highlighting their potential to enable transformative capabilities and breakthroughs in wireless communication. Finally, we thoroughly examine the high-level challenges hindering the practical implementation of WLAM and discuss pivotal future research directions.","authors":["Fenghao Zhu","Xinquan Wang","Xinyi Li","Maojun Zhang","Yixuan Chen","Chongwen Huang","Zhaohui Yang","Xiaoming Chen","Zhaoyang Zhang","Richeng Jin","Yongming Huang","Wei Feng","Tingting Yang","Baoming Bai","Feifei Gao","Kun Yang","Yuanwen Liu","Sami Muhaidat","Chau Yuen","Kaibin Huang","Kai-Kit Wong","Dusit Niyato","M\\'erouane Debbah"],"url":"https://arxiv.org/abs/2504.14653"}
{"created":"2025-04-22","title":"BLACKOUT: Data-Oblivious Computation with Blinded Capabilities","abstract":"Lack of memory-safety and exposure to side channels are two prominent, persistent challenges for the secure implementation of software. Memory-safe programming languages promise to significantly reduce the prevalence of memory-safety bugs, but make it more difficult to implement side-channel-resistant code. We aim to address both memory-safety and side-channel resistance by augmenting memory-safe hardware with the ability for data-oblivious programming. We describe an extension to the CHERI capability architecture to provide blinded capabilities that allow data-oblivious computation to be carried out by userspace tasks. We also present BLACKOUT, our realization of blinded capabilities on a FPGA softcore based on the speculative out-of-order CHERI-Toooba processor and extend the CHERI-enabled Clang/LLVM compiler and the CheriBSD operating system with support for blinded capabilities. BLACKOUT makes writing side-channel-resistant code easier by making non-data-oblivious operations via blinded capabilities explicitly fault. Through rigorous evaluation we show that BLACKOUT ensures memory operated on through blinded capabilities is securely allocated, used, and reclaimed and demonstrate that, in benchmarks comparable to those used by previous work, BLACKOUT imposes only a small performance degradation (1.5% geometric mean) compared to the baseline CHERI-Toooba processor.","authors":["Hossam ElAtali","Merve G\\\"ulmez","Thomas Nyman","N. Asokan"],"url":"https://arxiv.org/abs/2504.14654"}
{"created":"2025-04-22","title":"LeetCodeDataset: A Temporal Dataset for Robust Evaluation and Efficient Training of Code LLMs","abstract":"We introduce LeetCodeDataset, a high-quality benchmark for evaluating and training code-generation models, addressing two key challenges in LLM research: the lack of reasoning-focused coding benchmarks and self-contained training testbeds. By curating LeetCode Python problems with rich metadata, broad coverage, 100+ test cases per problem, and temporal splits (pre/post July 2024), our dataset enables contamination-free evaluation and efficient supervised fine-tuning (SFT). Experiments show reasoning models significantly outperform non-reasoning counterparts, while SFT with only 2.6K model-generated solutions achieves performance comparable to 110K-sample counterparts. The dataset and evaluation framework are available on Hugging Face and Github.","authors":["Yunhui Xia","Wei Shen","Yan Wang","Jason Klein Liu","Huifeng Sun","Siyue Wu","Jian Hu","Xiaolong Xu"],"url":"https://arxiv.org/abs/2504.14655"}
{"created":"2025-04-22","title":"A Case Study Exploring the Current Landscape of Synthetic Medical Record Generation with Commercial LLMs","abstract":"Synthetic Electronic Health Records (EHRs) offer a valuable opportunity to create privacy preserving and harmonized structured data, supporting numerous applications in healthcare. Key benefits of synthetic data include precise control over the data schema, improved fairness and representation of patient populations, and the ability to share datasets without concerns about compromising real individuals privacy. Consequently, the AI community has increasingly turned to Large Language Models (LLMs) to generate synthetic data across various domains. However, a significant challenge in healthcare is ensuring that synthetic health records reliably generalize across different hospitals, a long standing issue in the field. In this work, we evaluate the current state of commercial LLMs for generating synthetic data and investigate multiple aspects of the generation process to identify areas where these models excel and where they fall short. Our main finding from this work is that while LLMs can reliably generate synthetic health records for smaller subsets of features, they struggle to preserve realistic distributions and correlations as the dimensionality of the data increases, ultimately limiting their ability to generalize across diverse hospital settings.","authors":["Yihan Lin","Zhirong Bella Yu","Simon Lee"],"url":"https://arxiv.org/abs/2504.14657"}
{"created":"2025-04-22","title":"EmoSEM: Segment and Explain Emotion Stimuli in Visual Art","abstract":"This paper focuses on a key challenge in visual art understanding: given an art image, the model pinpoints pixel regions that trigger a specific human emotion, and generates linguistic explanations for the emotional arousal. Despite recent advances in art understanding, pixel-level emotion understanding still faces a dual challenge: first, the subjectivity of emotion makes it difficult for general segmentation models like SAM to adapt to emotion-oriented segmentation tasks; and second, the abstract nature of art expression makes it difficult for captioning models to balance pixel-level semantic understanding and emotion reasoning. To solve the above problems, this paper proposes the Emotion stimuli Segmentation and Explanation Model (EmoSEM) to endow the segmentation model SAM with emotion comprehension capability. First, to enable the model to perform segmentation under the guidance of emotional intent well, we introduce an emotional prompt with a learnable mask token as the conditional input for segmentation decoding. Then, we design an emotion projector to establish the association between emotion and visual features. Next, more importantly, to address emotion-visual stimuli alignment, we develop a lightweight prefix projector, a module that fuses the learned emotional mask with the corresponding emotion into a unified representation compatible with the language model.Finally, we input the joint visual, mask, and emotional tokens into the language model and output the emotional explanations. It ensures that the generated interpretations remain semantically and emotionally coherent with the visual stimuli. The method innovatively realizes end-to-end modeling from low-level pixel features to high-level emotion interpretation, providing the first interpretable fine-grained analysis framework for artistic emotion computing. Extensive experiments validate the effectiveness of our model.","authors":["Jing Zhang","Dan Guo","Zhangbin Li","Meng Wang"],"url":"https://arxiv.org/abs/2504.14658"}
{"created":"2025-04-22","title":"Mitigating Parameter Interference in Model Merging via Sharpness-Aware Fine-Tuning","abstract":"Large-scale deep learning models with a pretraining-finetuning paradigm have led to a surge of numerous task-specific models fine-tuned from a common pre-trained model. Recently, several research efforts have been made on merging these large models into a single multi-task model, particularly with simple arithmetic on parameters. Such merging methodology faces a central challenge: interference between model parameters fine-tuned on different tasks. Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference, however at the cost of the performance of each task-specific fine-tuned model and thereby limiting that of a merged model. To improve the performance of a merged model, we note that a fine-tuning scheme should aim for (1) smaller parameter interference and (2) better performance of each fine-tuned model on the corresponding task. In this work, we aim to design a new fine-tuning objective function to work towards these two goals. In the course of this process, we find such objective function to be strikingly similar to sharpness-aware minimization (SAM) objective function, which aims to achieve generalization by finding flat minima. Drawing upon our observation, we propose to fine-tune pre-trained models via sharpness-aware minimization. The experimental and theoretical results showcase the effectiveness and orthogonality of our proposed approach, improving performance upon various merging and fine-tuning methods. Our code is available at https://github.com/baiklab/SAFT-Merge.","authors":["Yeoreum Lee","Jinwook Jung","Sungyong Baik"],"url":"https://arxiv.org/abs/2504.14662"}
{"created":"2025-04-22","title":"The Developer Experience of LGBTQIA+ People in Agile Teams: a Multivocal Literature Review","abstract":"Research on underrepresented populations is essential for fostering greater diversity within the software industry. Team diversity is important for reasons that go beyond ethics. Diversity contributes to greater innovation and productivity, helping decrease turnover rates and reduce team conflicts. Within this context, LGBTQIA+ software engineering professionals face unique challenges, e.g., self-isolation and invisibility feeling. Developer Experience (DX) encompasses cognitive, emotional, and motivational considerations, supporting the idea that improving how DX can enhance team performance, strengthen collaboration, and lead to more successful software projects. This study aimed to examine traditional and grey literature data through a Multivocal Literature Review focused on the DX of LGBTQIA+ professionals in agile teams. Our findings reveal that issues such as invisibility, prejudice, and discrimination adversely affect their experiences, compounded by the predominance of heterosexual males in the field. Conversely, professionals who feel welcomed by their teams and organizations, especially in processes tailored to their needs, report more positive team dynamics and engagement.","authors":["Edvaldo Wassouf Jr","D\\'ebora Paiva","Kiev Gama","Awdren Font\\~ao"],"url":"https://arxiv.org/abs/2504.14663"}
{"created":"2025-04-22","title":"Frequency-domain Learning with Kernel Prior for Blind Image Deblurring","abstract":"While achieving excellent results on various datasets, many deep learning methods for image deblurring suffer from limited generalization capabilities with out-of-domain data. This limitation is likely caused by their dependence on certain domain-specific datasets. To address this challenge, we argue that it is necessary to introduce the kernel prior into deep learning methods, as the kernel prior remains independent of the image context. For effective fusion of kernel prior information, we adopt a rational implementation method inspired by traditional deblurring algorithms that perform deconvolution in the frequency domain. We propose a module called Frequency Integration Module (FIM) for fusing the kernel prior and combine it with a frequency-based deblurring Transfomer network. Experimental results demonstrate that our method outperforms state-of-the-art methods on multiple blind image deblurring tasks, showcasing robust generalization abilities. Source code will be available soon.","authors":["Jixiang Sun","Fei Lei","Jiawei Zhang","Wenxiu Sun","Yujiu Yang"],"url":"https://arxiv.org/abs/2504.14664"}
{"created":"2025-04-22","title":"DMPCN: Dynamic Modulated Predictive Coding Network with Hybrid Feedback Representations","abstract":"Traditional predictive coding networks, inspired by theories of brain function, consistently achieve promising results across various domains, extending their influence into the field of computer vision. However, the performance of the predictive coding networks is limited by their error feedback mechanism, which traditionally employs either local or global recurrent updates, leading to suboptimal performance in processing both local and broader details simultaneously. In addition, traditional predictive coding networks face difficulties in dynamically adjusting to the complexity and context of varying input data, which is crucial for achieving high levels of performance in diverse scenarios. Furthermore, there is a gap in the development and application of specific loss functions that could more effectively guide the model towards optimal performance. To deal with these issues, this paper introduces a hybrid prediction error feedback mechanism with dynamic modulation for deep predictive coding networks by effectively combining global contexts and local details while adjusting feedback based on input complexity. Additionally, we present a loss function tailored to this framework to improve accuracy by focusing on precise prediction error minimization. Experimental results demonstrate the superiority of our model over other approaches, showcasing faster convergence and higher predictive accuracy in CIFAR-10, CIFAR-100, MNIST, and FashionMNIST datasets.","authors":["A S M Sharifuzzaman Sagar","Yu Chen","Jun Hoong Chan"],"url":"https://arxiv.org/abs/2504.14665"}
{"created":"2025-04-22","title":"Generative Multimodal Pretraining with Discrete Diffusion Timestep Tokens","abstract":"Recent endeavors in Multimodal Large Language Models (MLLMs) aim to unify visual comprehension and generation by combining LLM and diffusion models, the state-of-the-art in each task, respectively. Existing approaches rely on spatial visual tokens, where image patches are encoded and arranged according to a spatial order (e.g., raster scan). However, we show that spatial tokens lack the recursive structure inherent to languages, hence form an impossible language for LLM to master. In this paper, we build a proper visual language by leveraging diffusion timesteps to learn discrete, recursive visual tokens. Our proposed tokens recursively compensate for the progressive attribute loss in noisy images as timesteps increase, enabling the diffusion model to reconstruct the original image at any timestep. This approach allows us to effectively integrate the strengths of LLMs in autoregressive reasoning and diffusion models in precise image generation, achieving seamless multimodal comprehension and generation within a unified framework. Extensive experiments show that we achieve superior performance for multimodal comprehension and generation simultaneously compared with other MLLMs. Project Page: https://DDT-LLaMA.github.io/.","authors":["Kaihang Pan","Wang Lin","Zhongqi Yue","Tenglong Ao","Liyu Jia","Wei Zhao","Juncheng Li","Siliang Tang","Hanwang Zhang"],"url":"https://arxiv.org/abs/2504.14666"}
{"created":"2025-04-22","title":"Efficient Federated Split Learning for Large Language Models over Communication Networks","abstract":"Fine-tuning pre-trained large language models (LLM) in a distributed manner poses significant challenges on resource-constrained edge devices. To address this challenge, we propose FedsLLM, a novel framework that integrates split federated learning with parameter-efficient fine-tuning techniques. By leveraging model splitting and Low-Rank Adaptation (LoRA), FedsLLM reduces the computational burden on edge devices. Furthermore, the introduction of a federated server facilitates parallel training and enhances privacy. To accommodate heterogeneous communication conditions and diverse computational capabilities of edge devices, as well as the impact of LoRA rank selection on model convergence and training cost, we formulate a joint optimization problem. The formulated problem jointly optimizes subchannel allocation, power control, model splitting point selection, and LoRA rank configuration, all aimed at minimizing total training delay. An alternating optimization algorithm is developed to efficiently solve this problem and accelerate the training process. Simulation results demonstrate that the proposed FedsLLM framework achieves comparable model accuracy while significantly reducing client-side computational requirements. Furthermore, the proposed resource allocation scheme and adaptive LoRA rank selection strategy notably reduce the training latency compared to conventional approaches.","authors":["Kai Zhao","Zhaohui Yang"],"url":"https://arxiv.org/abs/2504.14667"}
{"created":"2025-04-22","title":"A Byzantine Fault Tolerance Approach towards AI Safety","abstract":"Ensuring that an AI system behaves reliably and as intended, especially in the presence of unexpected faults or adversarial conditions, is a complex challenge. Inspired by the field of Byzantine Fault Tolerance (BFT) from distributed computing, we explore a fault tolerance architecture for AI safety. By drawing an analogy between unreliable, corrupt, misbehaving or malicious AI artifacts and Byzantine nodes in a distributed system, we propose an architecture that leverages consensus mechanisms to enhance AI safety and reliability.","authors":["John deVadoss","Matthias Artzt"],"url":"https://arxiv.org/abs/2504.14668"}
{"created":"2025-04-22","title":"Trans-Zero: Self-Play Incentivizes Large Language Models for Multilingual Translation Without Parallel Data","abstract":"The rise of Large Language Models (LLMs) has reshaped machine translation (MT), but multilingual MT still relies heavily on parallel data for supervised fine-tuning (SFT), facing challenges like data scarcity for low-resource languages and catastrophic forgetting. To address these issues, we propose TRANS-ZERO, a self-play framework that leverages only monolingual data and the intrinsic multilingual knowledge of LLM. TRANS-ZERO combines Genetic Monte-Carlo Tree Search (G-MCTS) with preference optimization, achieving strong translation performance that rivals supervised methods. Experiments demonstrate that this approach not only matches the performance of models trained on large-scale parallel data but also excels in non-English translation directions. Further analysis reveals that G-MCTS itself significantly enhances translation quality by exploring semantically consistent candidates through iterative translations, providing a robust foundation for the framework's succuss.","authors":["Wei Zou","Sen Yang","Yu Bao","Shujian Huang","Jiajun Chen","Shanbo Cheng"],"url":"https://arxiv.org/abs/2504.14669"}
{"created":"2025-04-22","title":"Binary cyclic codes from permutation polynomials over $\\mathbb{F}_{2^m}$","abstract":"Binary cyclic codes having large dimensions and minimum distances close to the square-root bound are highly valuable in applications where high-rate transmission and robust error correction are both essential. They provide an optimal trade-off between these two factors, making them suitable for demanding communication and storage systems, post-quantum cryptography, radar and sonar systems, wireless sensor networks, and space communications. This paper aims to investigate cyclic codes by an efficient approach introduced by Ding \\cite{SETA5} from several known classes of permutation monomials and trinomials over $\\mathbb{F}_{2^m}$. We present several infinite families of binary cyclic codes of length $2^m-1$ with dimensions larger than $(2^m-1)/2$. By applying the Hartmann-Tzeng bound, some of the lower bounds on the minimum distances of these cyclic codes are relatively close to the square root bound. Moreover, we obtain a new infinite family of optimal binary cyclic codes with parameters $[2^m-1,2^m-2-3m,8]$, where $m\\geq 5$ is odd, according to the sphere-packing bound.","authors":["Mrinal Kanti Bose","Udaya Parampalli","Abhay Kumar Singh"],"url":"https://arxiv.org/abs/2504.14674"}
{"created":"2025-04-22","title":"Evaluating Temporal Plasticity in Foundation Time Series Models for Incremental Fine-tuning","abstract":"Time series foundation models excel at diverse time series forecasting tasks, but their capacity for continuous improvement through incremental learning remains unexplored. We present the first comprehensive study investigating these models' temporal plasticity - their ability to progressively enhance performance through continual learning while maintaining existing capabilities. Through experiments on real-world datasets exhibiting distribution shifts, we evaluate both conventional deep learning models and foundation models using a novel continual learning framework. Our findings reveal that while traditional models struggle with performance deterioration during incremental fine-tuning, foundation models like Time-MoE and Chronos demonstrate sustained improvement in predictive accuracy. This suggests that optimizing foundation model fine-tuning strategies may be more valuable than developing domain-specific small models. Our research introduces new evaluation methodologies and insights for developing foundation time series models with robust continuous learning capabilities.","authors":["Jia Liu","Cheng Jinguo","Xia Fang","Zhenyuan Ma","Yuankai Wu"],"url":"https://arxiv.org/abs/2504.14677"}
{"created":"2025-04-22","title":"A Complete and Bounded-Suboptimal Algorithm for a Moving Target Traveling Salesman Problem with Obstacles in 3D","abstract":"The moving target traveling salesman problem with obstacles (MT-TSP-O) seeks an obstacle-free trajectory for an agent that intercepts a given set of moving targets, each within specified time windows, and returns to the agent's starting position. Each target moves with a constant velocity within its time windows, and the agent has a speed limit no smaller than any target's speed. We present FMC*-TSP, the first complete and bounded-suboptimal algorithm for the MT-TSP-O, and results for an agent whose configuration space is $\\mathbb{R}^3$. Our algorithm interleaves a high-level search and a low-level search, where the high-level search solves a generalized traveling salesman problem with time windows (GTSP-TW) to find a sequence of targets and corresponding time windows for the agent to visit. Given such a sequence, the low-level search then finds an associated agent trajectory. To solve the low-level planning problem, we develop a new algorithm called FMC*, which finds a shortest path on a graph of convex sets (GCS) via implicit graph search and pruning techniques specialized for problems with moving targets. We test FMC*-TSP on 280 problem instances with up to 40 targets and demonstrate its smaller median runtime than a baseline based on prior work.","authors":["Anoop Bhat","Geordan Gutow","Bhaskar Vundurthy","Zhongqiang Ren","Sivakumar Rathinam","Howie Choset"],"url":"https://arxiv.org/abs/2504.14680"}
{"created":"2025-04-22","title":"An LLM-enabled Multi-Agent Autonomous Mechatronics Design Framework","abstract":"Existing LLM-enabled multi-agent frameworks are predominantly limited to digital or simulated environments and confined to narrowly focused knowledge domain, constraining their applicability to complex engineering tasks that require the design of physical embodiment, cross-disciplinary integration, and constraint-aware reasoning. This work proposes a multi-agent autonomous mechatronics design framework, integrating expertise across mechanical design, optimization, electronics, and software engineering to autonomously generate functional prototypes with minimal direct human design input. Operating primarily through a language-driven workflow, the framework incorporates structured human feedback to ensure robust performance under real-world constraints. To validate its capabilities, the framework is applied to a real-world challenge involving autonomous water-quality monitoring and sampling, where traditional methods are labor-intensive and ecologically disruptive. Leveraging the proposed system, a fully functional autonomous vessel was developed with optimized propulsion, cost-effective electronics, and advanced control. The design process was carried out by specialized agents, including a high-level planning agent responsible for problem abstraction and dedicated agents for structural, electronics, control, and software development. This approach demonstrates the potential of LLM-based multi-agent systems to automate real-world engineering workflows and reduce reliance on extensive domain expertise.","authors":["Zeyu Wang","Frank P. -W. Lo","Qian Chen","Yongqi Zhang","Chen Lin","Xu Chen","Zhenhua Yu","Alexander J. Thompson","Eric M. Yeatman","Benny P. L. Lo"],"url":"https://arxiv.org/abs/2504.14681"}
{"created":"2025-04-22","title":"Polynomial-Time Constant-Approximation for Fair Sum-of-Radii Clustering","abstract":"In a seminal work, Chierichetti et al. introduced the $(t,k)$-fair clustering problem: Given a set of red points and a set of blue points in a metric space, a clustering is called fair if the number of red points in each cluster is at most $t$ times and at least $1/t$ times the number of blue points in that cluster. The goal is to compute a fair clustering with at most $k$ clusters that optimizes certain objective function. Considering this problem, they designed a polynomial-time $O(1)$- and $O(t)$-approximation for the $k$-center and the $k$-median objective, respectively. Recently, Carta et al. studied this problem with the sum-of-radii objective and obtained a $(6+\\epsilon)$-approximation with running time $O((k\\log_{1+\\epsilon}(k/\\epsilon))^kn^{O(1)})$, i.e., fixed-parameter tractable in $k$. Here $n$ is the input size. In this work, we design the first polynomial-time $O(1)$-approximation for $(t,k)$-fair clustering with the sum-of-radii objective, improving the result of Carta et al. Our result places sum-of-radii in the same group of objectives as $k$-center, that admit polynomial-time $O(1)$-approximations. This result also implies a polynomial-time $O(1)$-approximation for the Euclidean version of the problem, for which an $f(k)\\cdot n^{O(1)}$-time $(1+\\epsilon)$-approximation was known due to Drexler et al.. Here $f$ is an exponential function of $k$. We are also able to extend our result to any arbitrary $\\ell\\ge 2$ number of colors when $t=1$. This matches known results for the $k$-center and $k$-median objectives in this case. The significant disparity of sum-of-radii compared to $k$-center and $k$-median presents several complex challenges, all of which we successfully overcome in our work. Our main contribution is a novel cluster-merging-based analysis technique for sum-of-radii that helps us achieve the constant-approximation bounds.","authors":["Sina Bagheri Nezhad","Sayan Bandyapadhyay","Tianzhi Chen"],"url":"https://arxiv.org/abs/2504.14683"}
{"created":"2025-04-22","title":"Uncovering Issues in the Radio Access Network by Looking at the Neighbors","abstract":"Mobile network operators (MNOs) manage Radio Access Networks (RANs) with massive amounts of cells over multiple radio generations (2G-5G). To handle such complexity, operations teams rely on monitoring systems, including anomaly detection tools that identify unexpected behaviors. In this paper, we present c-ANEMON, a Contextual ANomaly dEtection MONitor for the RAN based on Graph Neural Networks (GNNs). Our solution captures spatio-temporal variations by analyzing the behavior of individual cells in relation to their local neighborhoods, enabling the detection of anomalies that are independent of external mobility factors. This, in turn, allows focusing on anomalies associated with network issues (e.g., misconfigurations, equipment failures). We evaluate c-ANEMON using real-world data from a large European metropolitan area (7,890 cells; 3 months). First, we show that the GNN model within our solution generalizes effectively to cells from previously unseen areas, suggesting the possibility of using a single model across extensive deployment regions. Then, we analyze the anomalies detected by c-ANEMON through manual inspection and define several categories of long-lasting anomalies (6+ hours). Notably, 45.95% of these anomalies fall into a category that is more likely to require intervention by operations teams.","authors":["Jos\\'e Su\\'arez-Varela","Andra Lutu"],"url":"https://arxiv.org/abs/2504.14686"}
{"created":"2025-04-22","title":"Seurat: From Moving Points to Depth","abstract":"Accurate depth estimation from monocular videos remains challenging due to ambiguities inherent in single-view geometry, as crucial depth cues like stereopsis are absent. However, humans often perceive relative depth intuitively by observing variations in the size and spacing of objects as they move. Inspired by this, we propose a novel method that infers relative depth by examining the spatial relationships and temporal evolution of a set of tracked 2D trajectories. Specifically, we use off-the-shelf point tracking models to capture 2D trajectories. Then, our approach employs spatial and temporal transformers to process these trajectories and directly infer depth changes over time. Evaluated on the TAPVid-3D benchmark, our method demonstrates robust zero-shot performance, generalizing effectively from synthetic to real-world datasets. Results indicate that our approach achieves temporally smooth, high-accuracy depth predictions across diverse domains.","authors":["Seokju Cho","Jiahui Huang","Seungryong Kim","Joon-Young Lee"],"url":"https://arxiv.org/abs/2504.14687"}
{"created":"2025-04-22","title":"Designing AI Systems that Augment Human Performed vs. Demonstrated Critical Thinking","abstract":"The recent rapid advancement of LLM-based AI systems has accelerated our search and production of information. While the advantages brought by these systems seemingly improve the performance or efficiency of human activities, they do not necessarily enhance human capabilities. Recent research has started to examine the impact of generative AI on individuals' cognitive abilities, especially critical thinking. Based on definitions of critical thinking across psychology and education, this position paper proposes the distinction between demonstrated and performed critical thinking in the era of generative AI and discusses the implication of this distinction in research and development of AI systems that aim to augment human critical thinking.","authors":["Katelyn Xiaoying Mei","Nic Weber"],"url":"https://arxiv.org/abs/2504.14689"}
{"created":"2025-04-22","title":"FarsEval-PKBETS: A new diverse benchmark for evaluating Persian large language models","abstract":"Research on evaluating and analyzing large language models (LLMs) has been extensive for resource-rich languages such as English, yet their performance in languages such as Persian has received considerably less attention. This paper introduces FarsEval-PKBETS benchmark, a subset of FarsEval project for evaluating large language models in Persian. This benchmark consists of 4000 questions and answers in various formats, including multiple choice, short answer and descriptive responses. It covers a wide range of domains and tasks,including medicine, law, religion, Persian language, encyclopedic knowledge, human preferences, social knowledge, ethics and bias, text generation, and respecting others' rights. This bechmark incorporates linguistics, cultural, and local considerations relevant to the Persian language and Iran. To ensure the questions are challenging for current LLMs, three models -- Llama3-70B, PersianMind, and Dorna -- were evaluated using this benchmark. Their average accuracy was below 50%, meaning they provided fully correct answers to fewer than half of the questions. These results indicate that current language models are still far from being able to solve this benchmark","authors":["Mehrnoush Shamsfard","Zahra Saaberi","Mostafa Karimi manesh","Seyed Mohammad Hossein Hashemi","Zahra Vatankhah","Motahareh Ramezani","Niki Pourazin","Tara Zare","Maryam Azimi","Sarina Chitsaz","Sama Khoraminejad","Morteza Mahdavi Mortazavi","Mohammad Mahdi Chizari","Sahar Maleki","Seyed Soroush Majd","Mostafa Masumi","Sayed Ali Musavi Khoeini","Amir Mohseni","Sogol Alipour"],"url":"https://arxiv.org/abs/2504.14690"}
{"created":"2025-04-22","title":"OmniV-Med: Scaling Medical Vision-Language Model for Universal Visual Understanding","abstract":"The practical deployment of medical vision-language models (Med-VLMs) necessitates seamless integration of textual data with diverse visual modalities, including 2D/3D images and videos, yet existing models typically employ separate encoders for different modalities. To address this limitation, we present OmniV-Med, a unified framework for multimodal medical understanding. Our technical contributions are threefold: First, we construct OmniV-Med-Instruct, a comprehensive multimodal medical dataset containing 252K instructional samples spanning 14 medical image modalities and 11 clinical tasks. Second, we devise a rotary position-adaptive encoder that processes multi-resolution 2D/3D images and videos within a unified architecture, diverging from conventional modality-specific encoders. Third, we introduce a medical-aware token pruning mechanism that exploits spatial-temporal redundancy in volumetric data (e.g., consecutive CT slices) and medical videos, effectively reducing 60\\% of visual tokens without performance degradation. Empirical evaluations demonstrate that OmniV-Med-7B achieves state-of-the-art performance on 7 benchmarks spanning 2D/3D medical imaging and video understanding tasks. Notably, our lightweight variant (OmniV-Med-1.5B) attains comparable performance while requiring only 8 RTX3090 GPUs for training and supporting efficient long-video inference. Data, code and model will be released.","authors":["Songtao Jiang","Yuan Wang","Sibo Song","Yan Zhang","Zijie Meng","Bohan Lei","Jian Wu","Jimeng Sun","Zuozhu Liu"],"url":"https://arxiv.org/abs/2504.14692"}
{"created":"2025-04-22","title":"Video-MMLU: A Massive Multi-Discipline Lecture Understanding Benchmark","abstract":"Recent advancements in language multimodal models (LMMs) for video have demonstrated their potential for understanding video content, yet the task of comprehending multi-discipline lectures remains largely unexplored. We introduce Video-MMLU, a massive benchmark designed to evaluate the capabilities of LMMs in understanding Multi-Discipline Lectures. We evaluate over 90 open-source and proprietary models, ranging from 0.5B to 40B parameters. Our results highlight the limitations of current models in addressing the cognitive challenges presented by these lectures, especially in tasks requiring both perception and reasoning. Additionally, we explore how the number of visual tokens and the large language models influence performance, offering insights into the interplay between multimodal perception and reasoning in lecture comprehension.","authors":["Enxin Song","Wenhao Chai","Weili Xu","Jianwen Xie","Yuxuan Liu","Gaoang Wang"],"url":"https://arxiv.org/abs/2504.14693"}
{"created":"2025-04-22","title":"Learning Critically: Selective Self Distillation in Federated Learning on Non-IID Data","abstract":"Federated learning (FL) enables multiple clients to collaboratively train a global model while keeping local data decentralized. Data heterogeneity (non-IID) across clients has imposed significant challenges to FL, which makes local models re-optimize towards their own local optima and forget the global knowledge, resulting in performance degradation and convergence slowdown. Many existing works have attempted to address the non-IID issue by adding an extra global-model-based regularizing item to the local training but without an adaption scheme, which is not efficient enough to achieve high performance with deep learning models. In this paper, we propose a Selective Self-Distillation method for Federated learning (FedSSD), which imposes adaptive constraints on the local updates by self-distilling the global model's knowledge and selectively weighting it by evaluating the credibility at both the class and sample level. The convergence guarantee of FedSSD is theoretically analyzed and extensive experiments are conducted on three public benchmark datasets, which demonstrates that FedSSD achieves better generalization and robustness in fewer communication rounds, compared with other state-of-the-art FL methods.","authors":["Yuting He","Yiqiang Chen","XiaoDong Yang","Hanchao Yu","Yi-Hua Huang","Yang Gu"],"url":"https://arxiv.org/abs/2504.14694"}
{"created":"2025-04-22","title":"GLITTER: An AI-assisted Platform for Material-Grounded Asynchronous Discussion in Flipped Learning","abstract":"Flipped classrooms promote active learning by having students engage with materials independently before class, allowing in-class time for collaborative problem-solving. During this pre-class phase, asynchronous online discussions help students build knowledge and clarify concepts with peers. However, it remains difficult to engage with temporally dispersed peer contributions, connect discussions with static learning materials, and prepare for in-class sessions based on their self-learning outcome. Our formative study identified cognitive challenges students encounter, including navigation barriers, reflection gaps, and contribution difficulty and anxiety. We present GLITTER, an AI-assisted discussion platform for pre-class learning in flipped classrooms. GLITTER helps students identify posts with shared conceptual dimensions, scaffold knowledge integration through conceptual blending, and enhance metacognition via personalized reflection reports. A lab study within subjects (n = 12) demonstrates that GLITTER improves discussion engagement, sparks new ideas, supports reflection, and increases preparedness for in-class activities.","authors":["Weirui Peng","Yinuo Yang","Zheng Zhang","Toby Jia-Jun Li"],"url":"https://arxiv.org/abs/2504.14695"}
{"created":"2025-04-22","title":"Reveal-or-Obscure: A Differentially Private Sampling Algorithm for Discrete Distributions","abstract":"We introduce a differentially private (DP) algorithm called reveal-or-obscure (ROO) to generate a single representative sample from a dataset of $n$ observations drawn i.i.d. from an unknown discrete distribution $P$. Unlike methods that add explicit noise to the estimated empirical distribution, ROO achieves $\\epsilon$-differential privacy by randomly choosing whether to \"reveal\" or \"obscure\" the empirical distribution. While ROO is structurally identical to Algorithm 1 proposed by Cheu and Nayak (arXiv:2412.10512), we prove a strictly better bound on the sampling complexity than that established in Theorem 12 of (arXiv:2412.10512). To further improve the privacy-utility trade-off, we propose a novel generalized sampling algorithm called Data-Specific ROO (DS-ROO), where the probability of obscuring the empirical distribution of the dataset is chosen adaptively. We prove that DS-ROO satisfies $\\epsilon$-DP, and provide empirical evidence that DS-ROO can achieve better utility under the same privacy budget of vanilla ROO.","authors":["Naima Tasnim","Atefeh Gilani","Lalitha Sankar","Oliver Kosut"],"url":"https://arxiv.org/abs/2504.14696"}
{"created":"2025-04-22","title":"Quantitative Clustering in Mean-Field Transformer Models","abstract":"The evolution of tokens through a deep transformer models can be modeled as an interacting particle system that has been shown to exhibit an asymptotic clustering behavior akin to the synchronization phenomenon in Kuramoto models. In this work, we investigate the long-time clustering of mean-field transformer models. More precisely, we establish exponential rates of contraction to a Dirac point mass for any suitably regular initialization under some assumptions on the parameters of transformer models, any suitably regular mean-field initialization synchronizes exponentially fast with some quantitative rates.","authors":["Shi Chen","Zhengjiang Lin","Yury Polyanskiy","Philippe Rigollet"],"url":"https://arxiv.org/abs/2504.14697"}
{"created":"2025-04-22","title":"IXGS-Intraoperative 3D Reconstruction from Sparse, Arbitrarily Posed Real X-rays","abstract":"Spine surgery is a high-risk intervention demanding precise execution, often supported by image-based navigation systems. Recently, supervised learning approaches have gained attention for reconstructing 3D spinal anatomy from sparse fluoroscopic data, significantly reducing reliance on radiation-intensive 3D imaging systems. However, these methods typically require large amounts of annotated training data and may struggle to generalize across varying patient anatomies or imaging conditions. Instance-learning approaches like Gaussian splatting could offer an alternative by avoiding extensive annotation requirements. While Gaussian splatting has shown promise for novel view synthesis, its application to sparse, arbitrarily posed real intraoperative X-rays has remained largely unexplored. This work addresses this limitation by extending the $R^2$-Gaussian splatting framework to reconstruct anatomically consistent 3D volumes under these challenging conditions. We introduce an anatomy-guided radiographic standardization step using style transfer, improving visual consistency across views, and enhancing reconstruction quality. Notably, our framework requires no pretraining, making it inherently adaptable to new patients and anatomies. We evaluated our approach using an ex-vivo dataset. Expert surgical evaluation confirmed the clinical utility of the 3D reconstructions for navigation, especially when using 20 to 30 views, and highlighted the standardization's benefit for anatomical clarity. Benchmarking via quantitative 2D metrics (PSNR/SSIM) confirmed performance trade-offs compared to idealized settings, but also validated the improvement gained from standardization over raw inputs. This work demonstrates the feasibility of instance-based volumetric reconstruction from arbitrary sparse-view X-rays, advancing intraoperative 3D imaging for surgical navigation.","authors":["Sascha Jecklin","Aidana Massalimova","Ruyi Zha","Lilian Calvet","Christoph J. Laux","Mazda Farshad","Philipp F\\\"urnstahl"],"url":"https://arxiv.org/abs/2504.14699"}
{"created":"2025-04-22","title":"Connecting Parameter Magnitudes and Hessian Eigenspaces at Scale using Sketched Methods","abstract":"Recently, it has been observed that when training a deep neural net with SGD, the majority of the loss landscape's curvature quickly concentrates in a tiny *top* eigenspace of the loss Hessian, which remains largely stable thereafter. Independently, it has been shown that successful magnitude pruning masks for deep neural nets emerge early in training and remain stable thereafter. In this work, we study these two phenomena jointly and show that they are connected: We develop a methodology to measure the similarity between arbitrary parameter masks and Hessian eigenspaces via Grassmannian metrics. We identify *overlap* as the most useful such metric due to its interpretability and stability. To compute *overlap*, we develop a matrix-free algorithm based on sketched SVDs that allows us to compute over 1000 Hessian eigenpairs for nets with over 10M parameters --an unprecedented scale by several orders of magnitude. Our experiments reveal an *overlap* between magnitude parameter masks and top Hessian eigenspaces consistently higher than chance-level, and that this effect gets accentuated for larger network sizes. This result indicates that *top Hessian eigenvectors tend to be concentrated around larger parameters*, or equivalently, that *larger parameters tend to align with directions of larger loss curvature*. Our work provides a methodology to approximate and analyze deep learning Hessians at scale, as well as a novel insight on the structure of their eigenspace.","authors":["Andres Fernandez","Frank Schneider","Maren Mahsereci","Philipp Hennig"],"url":"https://arxiv.org/abs/2504.14701"}
{"created":"2025-04-22","title":"Can We Ignore Labels In Out of Distribution Detection?","abstract":"Out-of-distribution (OOD) detection methods have recently become more prominent, serving as a core element in safety-critical autonomous systems. One major purpose of OOD detection is to reject invalid inputs that could lead to unpredictable errors and compromise safety. Due to the cost of labeled data, recent works have investigated the feasibility of self-supervised learning (SSL) OOD detection, unlabeled OOD detection, and zero shot OOD detection. In this work, we identify a set of conditions for a theoretical guarantee of failure in unlabeled OOD detection algorithms from an information-theoretic perspective. These conditions are present in all OOD tasks dealing with real-world data: I) we provide theoretical proof of unlabeled OOD detection failure when there exists zero mutual information between the learning objective and the in-distribution labels, a.k.a. 'label blindness', II) we define a new OOD task - Adjacent OOD detection - that tests for label blindness and accounts for a previously ignored safety gap in all OOD detection benchmarks, and III) we perform experiments demonstrating that existing unlabeled OOD methods fail under conditions suggested by our label blindness theory and analyze the implications for future research in unlabeled OOD methods.","authors":["Hong Yang","Qi Yu","Travis Desel"],"url":"https://arxiv.org/abs/2504.14704"}
{"created":"2025-04-22","title":"AI with Emotions: Exploring Emotional Expressions in Large Language Models","abstract":"The human-level performance of Large Language Models (LLMs) across various tasks has raised expectations for the potential of Artificial Intelligence (AI) to possess emotions someday. To explore the capability of current LLMs to express emotions in their outputs, we conducted an experiment using several LLMs (OpenAI GPT, Google Gemini, Meta Llama3, and Cohere Command R+) to role-play as agents answering questions with specified emotional states.We defined the emotional states using Russell's Circumplex model, a well-established framework that characterizes emotions along the sleepy-activated (arousal) and pleasure-displeasure (valence) axes. We chose this model for its simplicity, utilizing two continuous parameters, which allows for better controllability in applications involving continuous changes in emotional states. The responses generated were evaluated using a sentiment analysis model, independent of the LLMs, trained on the GoEmotions dataset. The evaluation showed that the emotional states of the generated answers were consistent with the specifications, demonstrating the LLMs' capability for emotional expression. This indicates the potential for LLM-based AI agents to simulate emotions, opening up a wide range of applications for emotion-based interactions, such as advisors or consultants who can provide advice or opinions with a personal touch.","authors":["Shin-nosuke Ishikawa","Atsushi Yoshino"],"url":"https://arxiv.org/abs/2504.14706"}
{"created":"2025-04-22","title":"Evaluating BERTopic on Open-Ended Data: A Case Study with Belgian Dutch Daily Narratives","abstract":"This study explores BERTopic's potential for modeling open-ended Belgian Dutch daily narratives, contrasting its performance with Latent Dirichlet Allocation (LDA) and KMeans. Although LDA scores well on certain automated metrics, human evaluations reveal semantically irrelevant co-occurrences, highlighting the limitations of purely statistic-based methods. In contrast, BERTopic's reliance on contextual embeddings yields culturally resonant themes, underscoring the importance of hybrid evaluation frameworks that account for morphologically rich languages. KMeans performed less coherently than prior research suggested, pointing to the unique challenges posed by personal narratives. Our findings emphasize the need for robust generalization in NLP models, especially in underrepresented linguistic contexts.","authors":["Ratna Kandala","Katie Hoemann"],"url":"https://arxiv.org/abs/2504.14707"}
{"created":"2025-04-22","title":"Time Frequency Analysis of EMG Signal for Gesture Recognition using Fine grained Features","abstract":"Electromyography (EMG) based hand gesture recognition converts forearm muscle activity into control commands for prosthetics, rehabilitation, and human computer interaction. This paper proposes a novel approach to EMG-based hand gesture recognition that uses fine-grained classification and presents XMANet, which unifies low-level local and high level semantic cues through cross layer mutual attention among shallow to deep CNN experts. Using stacked spectrograms and scalograms derived from the Short Time Fourier Transform (STFT) and Wavelet Transform (WT), we benchmark XMANet against ResNet50, DenseNet-121, MobileNetV3, and EfficientNetB0. Experimental results on the Grabmyo dataset indicate that, using STFT, the proposed XMANet model outperforms the baseline ResNet50, EfficientNetB0, MobileNetV3, and DenseNet121 models with improvement of approximately 1.72%, 4.38%, 5.10%, and 2.53%, respectively. When employing the WT approach, improvements of around 1.57%, 1.88%, 1.46%, and 2.05% are observed over the same baselines. Similarly, on the FORS EMG dataset, the XMANet(ResNet50) model using STFT shows an improvement of about 5.04% over the baseline ResNet50. In comparison, the XMANet(DenseNet121) and XMANet(MobileNetV3) models yield enhancements of approximately 4.11% and 2.81%, respectively. Moreover, when using WT, the proposed XMANet achieves gains of around 4.26%, 9.36%, 5.72%, and 6.09% over the baseline ResNet50, DenseNet121, MobileNetV3, and EfficientNetB0 models, respectively. These results confirm that XMANet consistently improves performance across various architectures and signal processing techniques, demonstrating the strong potential of fine grained features for accurate and robust EMG classification.","authors":["Parshuram N. Aarotale","Ajita Rattani"],"url":"https://arxiv.org/abs/2504.14708"}
{"created":"2025-04-22","title":"Exposing the Copycat Problem of Imitation-based Planner: A Novel Closed-Loop Simulator, Causal Benchmark and Joint IL-RL Baseline","abstract":"Machine learning (ML)-based planners have recently gained significant attention. They offer advantages over traditional optimization-based planning algorithms. These advantages include fewer manually selected parameters and faster development. Within ML-based planning, imitation learning (IL) is a common algorithm. It primarily learns driving policies directly from supervised trajectory data. While IL has demonstrated strong performance on many open-loop benchmarks, it remains challenging to determine if the learned policy truly understands fundamental driving principles, rather than simply extrapolating from the ego-vehicle's initial state. Several studies have identified this limitation and proposed algorithms to address it. However, these methods often use original datasets for evaluation. In these datasets, future trajectories are heavily dependent on initial conditions. Furthermore, IL often overfits to the most common scenarios. It struggles to generalize to rare or unseen situations.","authors":["Hui Zhou","Shaoshuai Shi","Hongsheng Li"],"url":"https://arxiv.org/abs/2504.14709"}
{"created":"2025-04-22","title":"BiDexHand: Design and Evaluation of an Open-Source 16-DoF Biomimetic Dexterous Hand","abstract":"Achieving human-level dexterity in robotic hands remains a fundamental challenge for enabling versatile manipulation across diverse applications. This extended abstract presents BiDexHand, a cable-driven biomimetic robotic hand that combines human-like dexterity with accessible and efficient mechanical design. The robotic hand features 16 independently actuated degrees of freedom and 5 mechanically coupled joints through novel phalange designs that replicate natural finger motion. Performance validation demonstrated success across all 33 grasp types in the GRASP Taxonomy, 9 of 11 positions in the Kapandji thumb opposition test, a measured fingertip force of 2.14\\,N, and the capability to lift a 10\\,lb weight. As an open-source platform supporting multiple control modes including vision-based teleoperation, BiDexHand aims to democratize access to advanced manipulation capabilities for the broader robotics research community.","authors":["Zhengyang Kris Weng"],"url":"https://arxiv.org/abs/2504.14712"}
{"created":"2025-04-22","title":"Med-2D SegNet: A Light Weight Deep Neural Network for Medical 2D Image Segmentation","abstract":"Accurate and efficient medical image segmentation is crucial for advancing clinical diagnostics and surgical planning, yet remains a complex challenge due to the variability in anatomical structures and the demand for low-complexity models. In this paper, we introduced Med-2D SegNet, a novel and highly efficient segmentation architecture that delivers outstanding accuracy while maintaining a minimal computational footprint. Med-2D SegNet achieves state-of-the-art performance across multiple benchmark datasets, including KVASIR-SEG, PH2, EndoVis, and GLAS, with an average Dice similarity coefficient (DSC) of 89.77% across 20 diverse datasets. Central to its success is the compact Med Block, a specialized encoder design that incorporates dimension expansion and parameter reduction, enabling precise feature extraction while keeping model parameters to a low count of just 2.07 million. Med-2D SegNet excels in cross-dataset generalization, particularly in polyp segmentation, where it was trained on KVASIR-SEG and showed strong performance on unseen datasets, demonstrating its robustness in zero-shot learning scenarios, even though we acknowledge that further improvements are possible. With top-tier performance in both binary and multi-class segmentation, Med-2D SegNet redefines the balance between accuracy and efficiency, setting a new benchmark for medical image analysis. This work paves the way for developing accessible, high-performance diagnostic tools suitable for clinical environments and resource-constrained settings, making it a step forward in the democratization of advanced medical technology.","authors":["Md. Sanaullah Chowdhury","Salauddin Tapu","Noyon Kumar Sarkar","Ferdous Bin Ali","Lameya Sabrin"],"url":"https://arxiv.org/abs/2504.14715"}
{"created":"2025-04-22","title":"Pairwise or Pointwise? Evaluating Feedback Protocols for Bias in LLM-Based Evaluation","abstract":"Large Language Models (LLMs) are widely used as proxies for human labelers in both training (Reinforcement Learning from AI Feedback) and large-scale response evaluation (LLM-as-a-judge). Alignment and evaluation are critical components in the development of reliable LLMs, and the choice of feedback protocol plays a central role in both but remains understudied. In this work, we show that the choice of feedback protocol (absolute scores versus relative preferences) can significantly affect evaluation reliability and induce systematic biases. In particular, we show that pairwise evaluation protocols are more vulnerable to distracted evaluation. Generator models can exploit spurious attributes (or distractor features) favored by the LLM judge, resulting in inflated scores for lower-quality outputs and misleading training signals. We find that absolute scoring is more robust to such manipulation, producing judgments that better reflect response quality and are less influenced by distractor features. Our results demonstrate that generator models can flip preferences by embedding distractor features, skewing LLM-as-a-judge comparisons and leading to inaccurate conclusions about model quality in benchmark evaluations. Pairwise preferences flip in about 35% of the cases, compared to only 9% for absolute scores. We offer recommendations for choosing feedback protocols based on dataset characteristics and evaluation objectives.","authors":["Tuhina Tripathi","Manya Wadhwa","Greg Durrett","Scott Niekum"],"url":"https://arxiv.org/abs/2504.14716"}
{"created":"2025-04-22","title":"TAPIP3D: Tracking Any Point in Persistent 3D Geometry","abstract":"We introduce TAPIP3D, a novel approach for long-term 3D point tracking in monocular RGB and RGB-D videos. TAPIP3D represents videos as camera-stabilized spatio-temporal feature clouds, leveraging depth and camera motion information to lift 2D video features into a 3D world space where camera motion is effectively canceled. TAPIP3D iteratively refines multi-frame 3D motion estimates within this stabilized representation, enabling robust tracking over extended periods. To manage the inherent irregularities of 3D point distributions, we propose a Local Pair Attention mechanism. This 3D contextualization strategy effectively exploits spatial relationships in 3D, forming informative feature neighborhoods for precise 3D trajectory estimation. Our 3D-centric approach significantly outperforms existing 3D point tracking methods and even enhances 2D tracking accuracy compared to conventional 2D pixel trackers when accurate depth is available. It supports inference in both camera coordinates (i.e., unstabilized) and world coordinates, and our results demonstrate that compensating for camera motion improves tracking performance. Our approach replaces the conventional 2D square correlation neighborhoods used in prior 2D and 3D trackers, leading to more robust and accurate results across various 3D point tracking benchmarks. Project Page: https://tapip3d.github.io","authors":["Bowei Zhang","Lei Ke","Adam W. Harley","Katerina Fragkiadaki"],"url":"https://arxiv.org/abs/2504.14717"}
{"created":"2025-04-22","title":"Proactive Radio Resource Allocation for 6G In-Factory Subnetworks","abstract":"6G In-Factory Subnetworks (InF-S) have recently been introduced as short-range, low-power radio cells installed in robots and production modules to support the strict requirements of modern control systems. Information freshness, characterized by the Age of Information (AoI), is crucial to guarantee the stability and accuracy of the control loop in these systems. However, achieving strict AoI performance poses significant challenges considering the limited resources and the high dynamic environment of InF-S. In this work, we introduce a proactive radio resource allocation approach to minimize the AoI violation probability. The proposed approach adopts a decentralized learning framework using Bayesian Ridge Regression (BRR) to predict the future AoI by actively learning the system dynamics. Based on the predicted AoI value, radio resources are proactively allocated to minimize the probability of AoI exceeding a predefined threshold, hence enhancing the reliability and accuracy of the control loop. The conducted simulation results prove the effectiveness of our proposed approach to improve the AoI performance where a reduction of 98% is achieved in the AoI violation probability compared to relevant baseline methods.","authors":["Hossam Farag","Mohamed Ragab","Gilberto Berardinelli","Cedomir Stefanovic"],"url":"https://arxiv.org/abs/2504.14718"}
{"created":"2025-04-22","title":"Video QoE Metrics from Encrypted Traffic: Application-agnostic Methodology","abstract":"Instant Messaging-Based Video Call Applications (IMVCAs) and Video Conferencing Applications (VCAs) have become integral to modern communication. Ensuring a high Quality of Experience (QoE) for users in this context is critical for network operators, as network conditions significantly impact user QoE. However, network operators lack access to end-device QoE metrics due to encrypted traffic. Existing solutions estimate QoE metrics from encrypted traffic traversing the network, with the most advanced approaches leveraging machine learning models. Subsequently, the need for ground truth QoE metrics for training and validation poses a challenge, as not all video applications provide these metrics. To address this challenge, we propose an application-agnostic approach for objective QoE estimation from encrypted traffic. Independent of the video application, we obtained key video QoE metrics, enabling broad applicability to various proprietary IMVCAs and VCAs. To validate our solution, we created a diverse dataset from WhatsApp video sessions under various network conditions, comprising 25,680 seconds of traffic data and QoE metrics. Our evaluation shows high performance across the entire dataset, with 85.2% accuracy for FPS predictions within an error margin of two FPS, and 90.2% accuracy for PIQE-based quality rating classification.","authors":["Tamir Berger","Jonathan Sterenson","Raz Birman","Ofer Hadar"],"url":"https://arxiv.org/abs/2504.14720"}
{"created":"2025-04-22","title":"Data-driven model order reduction for T-Product-Based dynamical systems","abstract":"Model order reduction plays a crucial role in simplifying complex systems while preserving their essential dynamic characteristics, making it an invaluable tool in a wide range of applications, including robotic systems, signal processing, and fluid dynamics. However, traditional model order reduction techniques like balanced truncation are not designed to handle tensor data directly and instead require unfolding the data, which may lead to the loss of important higher-order structural information. In this article, we introduce a novel framework for data-driven model order reduction of T-product-based dynamical systems (TPDSs), which are often used to capture the evolution of third-order tensor data such as images and videos through the T-product. Specifically, we develop advanced T-product-based techniques, including T-balanced truncation, T-balanced proper orthogonal decomposition, and the T-eigensystem realization algorithm for input-output TPDSs by leveraging the unique properties of T-singular value decomposition. We demonstrate that these techniques offer significant memory and computational savings while achieving reduction errors that are comparable to those of conventional methods. The effectiveness of the proposed framework is further validated through synthetic and real-world examples.","authors":["Shenghan Mei","Ziqin He","Yidan Mei","Xin Mao","Anqi Dong","Ren Wang","Can Chen"],"url":"https://arxiv.org/abs/2504.14721"}
{"created":"2025-04-22","title":"Approximate all-pairs Hamming distances and 0-1 matrix multiplication","abstract":"Arslan showed that computing all-pairs Hamming distances is easily","authors":["Miroslaw Kowaluk","Andrzej Lingas","Mia Persson"],"url":"https://arxiv.org/abs/2504.14723"}
{"created":"2025-04-22","title":"Sensor Scheduling in Intrusion Detection Games with Uncertain Payoffs","abstract":"We study the problem of sensor scheduling for an intrusion detection task. We model this as a two-player zero-sum game over a graph, where the defender (Player 1) seeks to identify the optimal strategy for scheduling sensor orientations to minimize the probability of missed detection at minimal cost, while the intruder (Player 2) aims to identify the optimal path selection strategy to maximize missed detection probability at minimal cost. The defender's strategy space grows exponentially with the number of sensors, making direct computation of the Nash Equilibrium (NE) strategies computationally expensive. To tackle this, we propose a distributed variant of the Weighted Majority algorithm that exploits the structure of the game's payoff matrix, enabling efficient computation of the NE strategies with provable convergence guarantees. Next, we consider a more challenging scenario where the defender lacks knowledge of the true sensor models and, consequently, the game's payoff matrix. For this setting, we develop online learning algorithms that leverage bandit feedback from sensors to estimate the NE strategies. By building on existing results from perturbation theory and online learning in matrix games, we derive high-probability order-optimal regret bounds for our algorithms. Finally, through simulations, we demonstrate the empirical performance of our proposed algorithms in both known and unknown payoff scenarios.","authors":["Jayanth Bhargav","Shreyas Sundaram","Mahsa Ghasemi"],"url":"https://arxiv.org/abs/2504.14725"}
{"created":"2025-04-22","title":"Semi-parametric Memory Consolidation: Towards Brain-like Deep Continual Learning","abstract":"Humans and most animals inherently possess a distinctive capacity to continually acquire novel experiences and accumulate worldly knowledge over time. This ability, termed continual learning, is also critical for deep neural networks (DNNs) to adapt to the dynamically evolving world in open environments. However, DNNs notoriously suffer from catastrophic forgetting of previously learned knowledge when trained on sequential tasks. In this work, inspired by the interactive human memory and learning system, we propose a novel biomimetic continual learning framework that integrates semi-parametric memory and the wake-sleep consolidation mechanism. For the first time, our method enables deep neural networks to retain high performance on novel tasks while maintaining prior knowledge in real-world challenging continual learning scenarios, e.g., class-incremental learning on ImageNet. This study demonstrates that emulating biological intelligence provides a promising path to enable deep neural networks with continual learning capabilities.","authors":["Geng Liu","Fei Zhu","Rong Feng","Zhiqiang Yi","Shiqi Wang","Gaofeng Meng","Zhaoxiang Zhang"],"url":"https://arxiv.org/abs/2504.14727"}
{"created":"2025-04-22","title":"Geometric Learning Dynamics","abstract":"We present a unified geometric framework for modeling learning dynamics in physical, biological, and machine learning systems. The theory reveals three fundamental regimes, each emerging from the power-law relationship $g \\propto \\kappa^a$ between the metric tensor $g$ in the space of trainable variables and the noise covariance matrix $\\kappa$. The quantum regime corresponds to $a = 1$ and describes Schr\\\"odinger-like dynamics that emerges from a discrete shift symmetry. The efficient learning regime corresponds to $a = \\tfrac{1}{2}$ and describes very fast machine learning algorithms. The equilibration regime corresponds to $a = 0$ and describes classical models of biological evolution. We argue that the emergence of the intermediate regime $a = \\tfrac{1}{2}$ is a key mechanism underlying the emergence of biological complexity.","authors":["Vitaly Vanchurin"],"url":"https://arxiv.org/abs/2504.14728"}
{"created":"2025-04-22","title":"Rank Bounds and PIT for $\\Sigma^3 \\Pi \\Sigma \\Pi^d$ circuits via a non-linear Edelstein-Kelly theorem","abstract":"We prove a non-linear Edelstein-Kelly theorem for polynomials of constant degree, fully settling a stronger form of Conjecture 30 in Gupta (2014), and generalizing the main result of Peleg and Shpilka (STOC 2021) from quadratic polynomials to polynomials of any constant degree.","authors":["Abhibhav Garg","Rafael Oliveira","Akash Kumar Sengupta"],"url":"https://arxiv.org/abs/2504.14729"}
{"created":"2025-04-22","title":"Optimal Additive Noise Mechanisms for Differential Privacy","abstract":"We propose a unified optimization framework for designing continuous and discrete noise distributions that ensure differential privacy (DP) by minimizing R\\'enyi DP, a variant of DP, under a cost constraint. R\\'enyi DP has the advantage that by considering different values of the R\\'enyi parameter $\\alpha$, we can tailor our optimization for any number of compositions. To solve the optimization problem, we reduce it to a finite-dimensional convex formulation and perform preconditioned gradient descent. The resulting noise distributions are then compared to their Gaussian and Laplace counterparts. Numerical results demonstrate that our optimized distributions are consistently better, with significant improvements in $(\\varepsilon, \\delta)$-DP guarantees in the moderate composition regimes, compared to Gaussian and Laplace distributions with the same variance.","authors":["Atefeh Gilani","Juan Felipe Gomez","Shahab Asoodeh","Flavio P. Calmon","Oliver Kosut","Lalitha Sankar"],"url":"https://arxiv.org/abs/2504.14730"}
{"created":"2025-04-22","title":"Reinforcement Learning from Multi-level and Episodic Human Feedback","abstract":"Designing an effective reward function has long been a challenge in reinforcement learning, particularly for complex tasks in unstructured environments. To address this, various learning paradigms have emerged that leverage different forms of human input to specify or refine the reward function. Reinforcement learning from human feedback is a prominent approach that utilizes human comparative feedback, expressed as a preference for one behavior over another, to tackle this problem. In contrast to comparative feedback, we explore multi-level human feedback, which is provided in the form of a score at the end of each episode. This type of feedback offers more coarse but informative signals about the underlying reward function than binary feedback. Additionally, it can handle non-Markovian rewards, as it is based on the evaluation of an entire episode. We propose an algorithm to efficiently learn both the reward function and the optimal policy from this form of feedback. Moreover, we show that the proposed algorithm achieves sublinear regret and demonstrate its empirical effectiveness through extensive simulations.","authors":["Muhammad Qasim Elahi","Somtochukwu Oguchienti","Maheed H. Ahmed","Mahsa Ghasemi"],"url":"https://arxiv.org/abs/2504.14732"}
{"created":"2025-04-22","title":"DiffVox: A Differentiable Model for Capturing and Analysing Professional Effects Distributions","abstract":"This study introduces a novel and interpretable model, DiffVox, for matching vocal effects in music production. DiffVox, short for ``Differentiable Vocal Fx\", integrates parametric equalisation, dynamic range control, delay, and reverb with efficient differentiable implementations to enable gradient-based optimisation for parameter estimation. Vocal presets are retrieved from two datasets, comprising 70 tracks from MedleyDB and 365 tracks from a private collection. Analysis of parameter correlations highlights strong relationships between effects and parameters, such as the high-pass and low-shelf filters often behaving together to shape the low end, and the delay time correlates with the intensity of the delayed signals. Principal component analysis reveals connections to McAdams' timbre dimensions, where the most crucial component modulates the perceived spaciousness while the secondary components influence spectral brightness. Statistical testing confirms the non-Gaussian nature of the parameter distribution, highlighting the complexity of the vocal effects space. These initial findings on the parameter distributions set the foundation for future research in vocal effects modelling and automatic mixing. Our source code and datasets are accessible at https://github.com/SonyResearch/diffvox.","authors":["Chin-Yun Yu","Marco A. Mart\\'inez-Ram\\'irez","Junghyun Koo","Ben Hayes","Wei-Hsiang Liao","Gy\\\"orgy Fazekas","Yuki Mitsufuji"],"url":"https://arxiv.org/abs/2504.14735"}
{"created":"2025-04-22","title":"ChronoRoot 2.0: An Open AI-Powered Platform for 2D Temporal Plant Phenotyping","abstract":"The analysis of plant developmental plasticity, including root system architecture, is fundamental to understanding plant adaptability and development, particularly in the context of climate change and agricultural sustainability. While significant advances have been made in plant phenotyping technologies, comprehensive temporal analysis of root development remains challenging, with most existing solutions providing either limited throughput or restricted structural analysis capabilities. Here, we present ChronoRoot 2.0, an integrated open-source platform that combines affordable hardware with advanced artificial intelligence to enable sophisticated temporal plant phenotyping. The system introduces several major advances, offering an integral perspective of seedling development: (i) simultaneous multi-organ tracking of six distinct plant structures, (ii) quality control through real-time validation, (iii) comprehensive architectural measurements including novel gravitropic response parameters, and (iv) dual specialized user interfaces for both architectural analysis and high-throughput screening. We demonstrate the system's capabilities through three use cases for Arabidopsis thaliana: characterization of circadian growth patterns under different light conditions, detailed analysis of gravitropic responses in transgenic plants, and high-throughput screening of etiolation responses across multiple genotypes. ChronoRoot 2.0 maintains its predecessor's advantages of low cost and modularity while significantly expanding its capabilities, making sophisticated temporal phenotyping more accessible to the broader plant science community. The system's open-source nature, combined with extensive documentation and containerized deployment options, ensures reproducibility and enables community-driven development of new analytical capabilities.","authors":["Nicol\\'as Gaggion","Rodrigo Bonazzola","Mar\\'ia Florencia Legascue","Mar\\'ia Florencia Mammarella","Florencia Sol Rodriguez","Federico Emanuel Aballay","Florencia Bel\\'en Catulo","Andana Barrios","Franco Accavallo","Santiago Nahuel Villarreal","Martin Crespi","Martiniano Mar\\'ia Ricardi","Ezequiel Petrillo","Thomas Blein","Federico Ariel","Enzo Ferrante"],"url":"https://arxiv.org/abs/2504.14736"}
{"created":"2025-04-22","title":"SuperCL: Superpixel Guided Contrastive Learning for Medical Image Segmentation Pre-training","abstract":"Medical image segmentation is a critical yet challenging task, primarily due to the difficulty of obtaining extensive datasets of high-quality, expert-annotated images. Contrastive learning presents a potential but still problematic solution to this issue. Because most existing methods focus on extracting instance-level or pixel-to-pixel representation, which ignores the characteristics between intra-image similar pixel groups. Moreover, when considering contrastive pairs generation, most SOTA methods mainly rely on manually setting thresholds, which requires a large number of gradient experiments and lacks efficiency and generalization. To address these issues, we propose a novel contrastive learning approach named SuperCL for medical image segmentation pre-training. Specifically, our SuperCL exploits the structural prior and pixel correlation of images by introducing two novel contrastive pairs generation strategies: Intra-image Local Contrastive Pairs (ILCP) Generation and Inter-image Global Contrastive Pairs (IGCP) Generation. Considering superpixel cluster aligns well with the concept of contrastive pairs generation, we utilize the superpixel map to generate pseudo masks for both ILCP and IGCP to guide supervised contrastive learning. Moreover, we also propose two modules named Average SuperPixel Feature Map Generation (ASP) and Connected Components Label Generation (CCL) to better exploit the prior structural information for IGCP. Finally, experiments on 8 medical image datasets indicate our SuperCL outperforms existing 12 methods. i.e. Our SuperCL achieves a superior performance with more precise predictions from visualization figures and 3.15%, 5.44%, 7.89% DSC higher than the previous best results on MMWHS, CHAOS, Spleen with 10% annotations. Our code will be released after acceptance.","authors":["Shuang Zeng","Lei Zhu","Xinliang Zhang","Hangzhou He","Yanye Lu"],"url":"https://arxiv.org/abs/2504.14737"}
{"created":"2025-04-22","title":"PROMPTEVALS: A Dataset of Assertions and Guardrails for Custom Production Large Language Model Pipelines","abstract":"Large language models (LLMs) are increasingly deployed in specialized production data processing pipelines across diverse domains -- such as finance, marketing, and e-commerce. However, when running them in production across many inputs, they often fail to follow instructions or meet developer expectations. To improve reliability in these applications, creating assertions or guardrails for LLM outputs to run alongside the pipelines is essential. Yet, determining the right set of assertions that capture developer requirements for a task is challenging. In this paper, we introduce PROMPTEVALS, a dataset of 2087 LLM pipeline prompts with 12623 corresponding assertion criteria, sourced from developers using our open-source LLM pipeline tools. This dataset is 5x larger than previous collections. Using a hold-out test split of PROMPTEVALS as a benchmark, we evaluated closed- and open-source models in generating relevant assertions. Notably, our fine-tuned Mistral and Llama 3 models outperform GPT-4o by 20.93% on average, offering both reduced latency and improved performance. We believe our dataset can spur further research in LLM reliability, alignment, and prompt engineering.","authors":["Reya Vir","Shreya Shankar","Harrison Chase","Will Fu-Hinthorn","Aditya Parameswaran"],"url":"https://arxiv.org/abs/2504.14738"}
{"created":"2025-04-22","title":"A Modularized Design Approach for GelSight Family of Vision-based Tactile Sensors","abstract":"GelSight family of vision-based tactile sensors has proven to be effective for multiple robot perception and manipulation tasks. These sensors are based on an internal optical system and an embedded camera to capture the deformation of the soft sensor surface, inferring the high-resolution geometry of the objects in contact. However, customizing the sensors for different robot hands requires a tedious trial-and-error process to re-design the optical system. In this paper, we formulate the GelSight sensor design process as a systematic and objective-driven design problem and perform the design optimization with a physically accurate optical simulation. The method is based on modularizing and parameterizing the sensor's optical components and designing four generalizable objective functions to evaluate the sensor. We implement the method with an interactive and easy-to-use toolbox called OptiSense Studio. With the toolbox, non-sensor experts can quickly optimize their sensor design in both forward and inverse ways following our predefined modules and steps. We demonstrate our system with four different GelSight sensors by quickly optimizing their initial design in simulation and transferring it to the real sensors.","authors":["Arpit Agarwal (Carnegie Mellon University","USA)","Mohammad Amin Mirzaee (University of Illinois Urbana-Champaign","USA)","Xiping Sun (University of Illinois Urbana-Champaign","USA)","Wenzhen Yuan (University of Illinois Urbana-Champaign","USA)"],"url":"https://arxiv.org/abs/2504.14739"}
{"created":"2025-04-22","title":"AltGDmin: Alternating GD and Minimization for Partly-Decoupled (Federated) Optimization","abstract":"This article describes a novel optimization solution framework, called alternating gradient descent (GD) and minimization (AltGDmin), that is useful for many problems for which alternating minimization (AltMin) is a popular solution. AltMin is a special case of the block coordinate descent algorithm that is useful for problems in which minimization w.r.t one subset of variables keeping the other fixed is closed form or otherwise reliably solved. Denote the two blocks/subsets of the optimization variables Z by Za, Zb, i.e., Z = {Za, Zb}. AltGDmin is often a faster solution than AltMin for any problem for which (i) the minimization over one set of variables, Zb, is much quicker than that over the other set, Za; and (ii) the cost function is differentiable w.r.t. Za. Often, the reason for one minimization to be quicker is that the problem is ``decoupled\" for Zb and each of the decoupled problems is quick to solve. This decoupling is also what makes AltGDmin communication-efficient for federated settings.","authors":["Namrata Vaswani"],"url":"https://arxiv.org/abs/2504.14741"}
{"created":"2025-04-22","title":"The Mid-sphere Cousin of the Medial Axis Transform","abstract":"The medial axis of a smoothly embedded surface in $\\mathbb{R}^3$ consists of all points for which the Euclidean distance function on the surface has at least two minima. We generalize this notion to the mid-sphere axis, which consists of all points for which the Euclidean distance function has two interchanging saddles that swap their partners in the pairing by persistent homology. It offers a discrete-algebraic multi-scale approach to computing ridge-like structures on the surface. As a proof of concept, an algorithm that computes stair-case approximations of the mid-sphere axis is provided.","authors":["Herbert Edelsbrunner","Elizabeth Stephenson","Martin Hafskjold Thoresen"],"url":"https://arxiv.org/abs/2504.14743"}
{"created":"2025-04-22","title":"Interference-Aware PMI selection for MIMO systems in an O-RAN scenario","abstract":"The optimization of Precoding Matrix Indicators (PMIs) is crucial for enhancing the performance of 5G networks, particularly in dense deployments where inter-cell interference is a significant challenge. Some approaches have leveraged AI/ML techniques for beamforming and beam selection, however, these methods often overlook the multi-objective nature of PMI selection, which requires balancing spectral efficiency (SE) and interference reduction. This paper proposes an interference-aware PMI selection method using an Advantage Actor-Critic (A2C) reinforcement learning model, designed for deployment within an O-RAN framework as an xApp. The proposed model prioritizes user equipment (UE) based on a novel strategy and adjusts PMI values accordingly, with interference management and efficient resource utilization. Experimental results in an O-RAN environment demonstrate the approach's effectiveness in improving network performance metrics, including SE and interference mitigation.","authors":["Rawlings Ntassah","Gian Michele Dell'Aera","Fabrizio Granelli"],"url":"https://arxiv.org/abs/2504.14745"}
{"created":"2025-04-22","title":"Adaptive Field Effect Planner for Safe Interactive Autonomous Driving on Curved Roads","abstract":"Autonomous driving has garnered significant attention for its potential to improve safety, traffic efficiency, and user convenience. However, the dynamic and complex nature of interactive driving poses significant challenges, including the need to navigate non-linear road geometries, handle dynamic obstacles, and meet stringent safety and comfort requirements. Traditional approaches, such as artificial potential fields (APF), often fall short in addressing these complexities independently, necessitating the development of integrated and adaptive frameworks. This paper presents a novel approach to autonomous vehicle navigation that integrates artificial potential fields, Frenet coordinates, and improved particle swarm optimization (IPSO). A dynamic risk field, adapted from traditional APF, is proposed to ensure interactive safety by quantifying risks and dynamically adjusting lane-changing intentions based on surrounding vehicle behavior. Frenet coordinates are utilized to simplify trajectory planning on non-straight roads, while an enhanced quintic polynomial trajectory generator ensures smooth and comfortable path transitions. Additionally, an IPSO algorithm optimizes trajectory selection in real time, balancing safety and user comfort within a feasible input range. The proposed framework is validated through extensive simulations and real-world scenarios, demonstrating its ability to navigate complex traffic environments, maintain safety margins, and generate smooth, dynamically feasible trajectories.","authors":["Qinghao Li","Zhen Tian","Xiaodan Wang","Jinming Yang","Zhihao Lin"],"url":"https://arxiv.org/abs/2504.14747"}
{"created":"2025-04-22","title":"PPO-EPO: Energy and Performance Optimization for O-RAN Using Reinforcement Learning","abstract":"Energy consumption in mobile communication networks has become a significant challenge due to its direct impact on Capital Expenditure (CAPEX) and Operational Expenditure (OPEX). The introduction of Open RAN (O-RAN) enables telecommunication providers to leverage network intelligence to optimize energy efficiency while maintaining Quality of Service (QoS). One promising approach involves traffic-aware cell shutdown strategies, where underutilized cells are selectively deactivated without compromising overall network performance. However, achieving this balance requires precise traffic steering mechanisms that account for throughput performance, power efficiency, and network interference constraints.","authors":["Rawlings Ntassah","Gian Michele Dell'Aera","Fabrizio Granelli"],"url":"https://arxiv.org/abs/2504.14749"}
{"created":"2025-04-22","title":"Data-Driven Evolutionary Game-Based Model Predictive Control for Hybrid Renewable Energy Dispatch in Autonomous Ships","abstract":"In this paper, we propose a data-driven Evolutionary Game-Based Model Predictive Control (EG-MPC) framework for the energy dispatch of a hybrid renewable energy system powering an autonomous ship. The system integrates solar photovoltaic and wind turbine generation with battery energy storage and diesel backup power to ensure reliable operation. Given the uncertainties in renewable generation and dynamic energy demands, an optimal dispatch strategy is crucial to minimize operational costs while maintaining system reliability. To address these challenges, we formulate a cost minimization problem that considers both battery degradation costs and diesel fuel expenses, leveraging real-world data to enhance modeling accuracy. The EG-MPC approach integrates evolutionary game dynamics within a receding-horizon optimization framework, enabling adaptive and near-optimal control solutions in real time. Simulation results based on site-specific data demonstrate that the proposed method achieves cost-effective, reliable, and adaptive energy dispatch, outperforming conventional rule-based and standard MPC approaches, particularly under uncertainty.","authors":["Yaoze Liu","Zhen Tian","Jinming Yang","Zhihao Lin"],"url":"https://arxiv.org/abs/2504.14750"}
{"created":"2025-04-22","title":"AI for the Open-World: the Learning Principles","abstract":"During the past decades, numerous successes of AI has been made on \"specific capabilities\", named closed-world, such as artificial environments or specific real-world tasks. This well-defined narrow capability brings two nice benefits, a clear criterion of success and the opportunity to collect a lot of examples. The criteria not only reveal whether a machine has achieved a goal, but reveal how the machine falls short of the goal. As a result, human designers can fix the problems one after the other until the machine is deemed good enough for the task. Furthermore, the large set of collected examples reduces the difficulty of this problem-fixing process (by the central limit theorem).","authors":["Jianyu Zhang"],"url":"https://arxiv.org/abs/2504.14751"}
{"created":"2025-04-22","title":"Advancing Video Anomaly Detection: A Bi-Directional Hybrid Framework for Enhanced Single- and Multi-Task Approaches","abstract":"Despite the prevailing transition from single-task to multi-task approaches in video anomaly detection, we observe that many adopt sub-optimal frameworks for individual proxy tasks. Motivated by this, we contend that optimizing single-task frameworks can advance both single- and multi-task approaches. Accordingly, we leverage middle-frame prediction as the primary proxy task, and introduce an effective hybrid framework designed to generate accurate predictions for normal frames and flawed predictions for abnormal frames. This hybrid framework is built upon a bi-directional structure that seamlessly integrates both vision transformers and ConvLSTMs. Specifically, we utilize this bi-directional structure to fully analyze the temporal dimension by predicting frames in both forward and backward directions, significantly boosting the detection stability. Given the transformer's capacity to model long-range contextual dependencies, we develop a convolutional temporal transformer that efficiently associates feature maps from all context frames to generate attention-based predictions for target frames. Furthermore, we devise a layer-interactive ConvLSTM bridge that facilitates the smooth flow of low-level features across layers and time-steps, thereby strengthening predictions with fine details. Anomalies are eventually identified by scrutinizing the discrepancies between target frames and their corresponding predictions. Several experiments conducted on public benchmarks affirm the efficacy of our hybrid framework, whether used as a standalone single-task approach or integrated as a branch in a multi-task approach. These experiments also underscore the advantages of merging vision transformers and ConvLSTMs for video anomaly detection.","authors":["Guodong Shen","Yuqi Ouyang","Junru Lu","Yixuan Yang","Victor Sanchez"],"url":"https://arxiv.org/abs/2504.14753"}
{"created":"2025-04-22","title":"Safe Autonomous Environmental Contact for Soft Robots using Control Barrier Functions","abstract":"Robots built from soft materials will inherently apply lower environmental forces than their rigid counterparts, and therefore may be more suitable in sensitive settings with unintended contact. However, these robots' applied forces result from both their design and their control system in closed-loop, and therefore, ensuring bounds on these forces requires controller synthesis for safety as well. This article introduces the first feedback controller for a soft manipulator that formally meets a safety specification with respect to environmental contact. In our proof-of-concept setting, the robot's environment has known geometry and is deformable with a known elastic modulus. Our approach maps a bound on applied forces to a safe set of positions of the robot's tip via predicted deformations of the environment. Then, a quadratic program with Control Barrier Functions in its constraints is used to supervise a nominal feedback signal, verifiably maintaining the robot's tip within this safe set. Hardware experiments on a multi-segment soft pneumatic robot demonstrate that the proposed framework successfully constrains its environmental contact forces. This framework represents a fundamental shift in perspective on control and safety for soft robots, defining and implementing a formally verifiable logic specification on their pose and contact forces.","authors":["Akua K. Dickson","Juan C. Pacheco Garcia","Meredith L. Anderson","Ran Jing","Sarah Alizadeh-Shabdiz","Audrey X. Wang","Charles DeLorey","Zach J. Patterson","Andrew P. Sabelhaus"],"url":"https://arxiv.org/abs/2504.14755"}
{"created":"2025-04-22","title":"SWE-Synth: Synthesizing Verifiable Bug-Fix Data to Enable Large Language Models in Resolving Real-World Bugs","abstract":"Large language models (LLMs) are transforming automated program repair (APR) through agent-based approaches that localize bugs, generate patches, and verify fixes. However, the lack of high-quality, scalable training datasets, especially those with verifiable outputs and intermediate reasoning traces-limits progress, particularly for open-source models. In this work, we present SWE-Synth, a framework for synthesizing realistic, verifiable, and process-aware bug-fix datasets at the repository level. SWE-Synth leverages LLM agents to simulate debugging workflows, producing not only bug-fix pairs but also test cases and structured repair trajectories. Compared to manually curated datasets, our method scales with minimal human effort while preserving contextual richness and correctness. Experiments show that models trained on SWE-Synth outperform those trained on real-world datasets by 2.3% on SWE-Bench Lite. Our results highlight the potential of synthetic, agent-generated data to advance the state of the art in APR and software engineering automation.","authors":["Minh V. T. Pham","Huy N. Phan","Hoang N. Phan","Cuong Le Chi","Tien N. Nguyen","Nghi D. Q. Bui"],"url":"https://arxiv.org/abs/2504.14757"}
{"created":"2025-04-22","title":"Establishing Workload Identity for Zero Trust CI/CD: From Secrets to SPIFFE-Based Authentication","abstract":"CI/CD systems have become privileged automation agents in modern infrastructure, but their identity is still based on secrets or temporary credentials passed between systems. In enterprise environments, these platforms are centralized and shared across teams, often with broad cloud permissions and limited isolation. These conditions introduce risk, especially in the era of supply chain attacks, where implicit trust and static credentials leave systems exposed. This paper describes the shift from static credentials to OpenID Connect (OIDC) federation, and introduces SPIFFE (Secure Production Identity Framework for Everyone) as a runtime-issued, platform-neutral identity model for non-human actors. SPIFFE decouples identity from infrastructure, enabling strong, portable authentication across job runners and deployed workloads. We show how SPIFFE identities support policy alignment, workload attestation, and mutual authentication. The paper concludes by outlining next steps in enabling policy-based access, forming the basis of a broader Zero Trust architecture for CI/CD.","authors":["Surya Teja Avirneni"],"url":"https://arxiv.org/abs/2504.14760"}
{"created":"2025-04-22","title":"Decoupling Identity from Access: Credential Broker Patterns for Secure CI/CD","abstract":"Credential brokers offer a way to separate identity from access in CI/CD systems. This paper shows how verifiable identities issued at runtime, such as those from SPIFFE, can be used with brokers to enable short-lived, policy-driven credentials for pipelines and workloads. We walk through practical design patterns, including brokers that issue tokens just in time, apply access policies, and operate across trust domains. These ideas help reduce static permissions, improve auditability, and support Zero Trust goals in deployment workflows. This is the second paper in a three-part series on secure CI/CD identity architecture.","authors":["Surya Teja Avirneni"],"url":"https://arxiv.org/abs/2504.14761"}
{"created":"2025-04-22","title":"A Combinatorial Theory of Dropout: Subnetworks, Graph Geometry, and Generalization","abstract":"We propose a combinatorial and graph-theoretic theory of dropout by modeling training as a random walk over a high-dimensional graph of binary subnetworks. Each node represents a masked version of the network, and dropout induces stochastic traversal across this space. We define a subnetwork contribution score that quantifies generalization and show that it varies smoothly over the graph. Using tools from spectral graph theory, PAC-Bayes analysis, and combinatorics, we prove that generalizing subnetworks form large, connected, low-resistance clusters, and that their number grows exponentially with network width. This reveals dropout as a mechanism for sampling from a robust, structured ensemble of well-generalizing subnetworks with built-in redundancy. Extensive experiments validate every theoretical claim across diverse architectures. Together, our results offer a unified foundation for understanding dropout and suggest new directions for mask-guided regularization and subnetwork optimization.","authors":["Sahil Rajesh Dhayalkar"],"url":"https://arxiv.org/abs/2504.14762"}
{"created":"2025-04-22","title":"Steering Semantic Data Processing With DocWrangler","abstract":"Unstructured text has long been difficult to automatically analyze at scale. Large language models (LLMs) now offer a way forward by enabling {\\em semantic data processing}, where familiar data processing operators (e.g., map, reduce, filter) are powered by LLMs instead of code. However, building effective semantic data processing pipelines presents a departure from traditional data pipelines: users need to understand their data to write effective pipelines, yet they need to construct pipelines to extract the data necessary for that understanding -- all while navigating LLM idiosyncrasies and inconsistencies. We present \\docwrangler, a mixed-initiative integrated development environment (IDE) for semantic data processing with three novel features to address the gaps between the user, their data, and their pipeline: {\\em (i) In-Situ User Notes} that allows users to inspect, annotate, and track observations across documents and LLM outputs, {\\em (ii) LLM-Assisted Prompt Refinement} that transforms user notes into improved operations, and {\\em (iii) LLM-Assisted Operation Decomposition} that identifies when operations or documents are too complex for the LLM to correctly process and suggests decompositions. Our evaluation combines a think-aloud study with 10 participants and a public-facing deployment (available at \\href{https://docetl.org/playground}{docetl.org/playground}) with 1,500+ recorded sessions, revealing how users develop systematic strategies for their semantic data processing tasks; e.g., transforming open-ended operations into classifiers for easier validation and intentionally using vague prompts to learn more about their data or LLM capabilities.","authors":["Shreya Shankar","Bhavya Chopra","Mawil Hasan","Stephen Lee","Bj\\\"orn Hartmann","Joseph M. Hellerstein","Aditya G. Parameswaran","Eugene Wu"],"url":"https://arxiv.org/abs/2504.14764"}
{"created":"2025-04-22","title":"Disentangling Linguistic Features with Dimension-Wise Analysis of Vector Embeddings","abstract":"Understanding the inner workings of neural embeddings, particularly in models such as BERT, remains a challenge because of their high-dimensional and opaque nature. This paper proposes a framework for uncovering the specific dimensions of vector embeddings that encode distinct linguistic properties (LPs). We introduce the Linguistically Distinct Sentence Pairs (LDSP-10) dataset, which isolates ten key linguistic features such as synonymy, negation, tense, and quantity. Using this dataset, we analyze BERT embeddings with various methods, including the Wilcoxon signed-rank test, mutual information, and recursive feature elimination, to identify the most influential dimensions for each LP. We introduce a new metric, the Embedding Dimension Impact (EDI) score, which quantifies the relevance of each embedding dimension to a LP. Our findings show that certain properties, such as negation and polarity, are robustly encoded in specific dimensions, while others, like synonymy, exhibit more complex patterns. This study provides insights into the interpretability of embeddings, which can guide the development of more transparent and optimized language models, with implications for model bias mitigation and the responsible deployment of AI systems.","authors":["Saniya Karwa","Navpreet Singh"],"url":"https://arxiv.org/abs/2504.14766"}
{"created":"2025-04-22","title":"A note on unshifted lattice rules for high-dimensional integration in weighted unanchored Sobolev spaces","abstract":"This short article studies a deterministic quasi-Monte Carlo lattice rule in weighted unanchored Sobolev spaces of smoothness $1$. Building on the error analysis by Kazashi and Sloan, we prove the existence of unshifted rank-1 lattice rules that achieve a worst-case error of $O(n^{-1/4}(\\log n)^{1/2})$, with the implied constant independent of the dimension, under certain summability conditions on the weights. Although this convergence rate is inferior to the one achievable for the shifted-averaged root mean squared worst-case error, the result does not rely on random shifting or transformation and holds unconditionally without any conjecture, as assumed by Kazashi and Sloan.","authors":["Takashi Goda"],"url":"https://arxiv.org/abs/2504.14768"}
{"created":"2025-04-22","title":"Building babyGPTs: Youth Engaging in Data Practices and Ethical Considerations through the Construction of Generative Language Models","abstract":"As generative language models (GLMs) have gained popularity, youth are increasingly using them in their everyday lives. As such, most research has centered on supporting youth as users of GLM-powered systems. However, we know little of how to engage youth in the design of these models. Building on the rich legacy of child-computer interaction research that positions youth as designers of computing systems, we explore how to support young people in designing GLMs. Through a case study of three teenagers (ages 14-15) building a babyGPT screenplay generator, we illustrate how the team developed a model while engaging in artificial intelligence/machine learning-relevant data practices and addressing ethical issues. This paper contributes a case study that demonstrates the feasibility of engaging youth in building GLMs.","authors":["Luis Morales-Navarro","Daniel J. Noh","Yasmin B. Kafai"],"url":"https://arxiv.org/abs/2504.14769"}
{"created":"2025-04-22","title":"Knowledge Distillation and Dataset Distillation of Large Language Models: Emerging Trends, Challenges, and Future Directions","abstract":"The exponential growth of Large Language Models (LLMs) continues to highlight the need for efficient strategies to meet ever-expanding computational and data demands. This survey provides a comprehensive analysis of two complementary paradigms: Knowledge Distillation (KD) and Dataset Distillation (DD), both aimed at compressing LLMs while preserving their advanced reasoning capabilities and linguistic diversity. We first examine key methodologies in KD, such as task-specific alignment, rationale-based training, and multi-teacher frameworks, alongside DD techniques that synthesize compact, high-impact datasets through optimization-based gradient matching, latent space regularization, and generative synthesis. Building on these foundations, we explore how integrating KD and DD can produce more effective and scalable compression strategies. Together, these approaches address persistent challenges in model scalability, architectural heterogeneity, and the preservation of emergent LLM abilities. We further highlight applications across domains such as healthcare and education, where distillation enables efficient deployment without sacrificing performance. Despite substantial progress, open challenges remain in preserving emergent reasoning and linguistic diversity, enabling efficient adaptation to continually evolving teacher models and datasets, and establishing comprehensive evaluation protocols. By synthesizing methodological innovations, theoretical foundations, and practical insights, our survey charts a path toward sustainable, resource-efficient LLMs through the tighter integration of KD and DD principles.","authors":["Luyang Fang","Xiaowei Yu","Jiazhang Cai","Yongkai Chen","Shushan Wu","Zhengliang Liu","Zhenyuan Yang","Haoran Lu","Xilin Gong","Yufang Liu","Terry Ma","Wei Ruan","Ali Abbasi","Jing Zhang","Tao Wang","Ehsan Latif","Wei Liu","Wei Zhang","Soheil Kolouri","Xiaoming Zhai","Dajiang Zhu","Wenxuan Zhong","Tianming Liu","Ping Ma"],"url":"https://arxiv.org/abs/2504.14772"}
{"created":"2025-04-22","title":"PLANET: A Collection of Benchmarks for Evaluating LLMs' Planning Capabilities","abstract":"Planning is central to agents and agentic AI. The ability to plan, e.g., creating travel itineraries within a budget, holds immense potential in both scientific and commercial contexts. Moreover, optimal plans tend to require fewer resources compared to ad-hoc methods. To date, a comprehensive understanding of existing planning benchmarks appears to be lacking. Without it, comparing planning algorithms' performance across domains or selecting suitable algorithms for new scenarios remains challenging. In this paper, we examine a range of planning benchmarks to identify commonly used testbeds for algorithm development and highlight potential gaps. These benchmarks are categorized into embodied environments, web navigation, scheduling, games and puzzles, and everyday task automation. Our study recommends the most appropriate benchmarks for various algorithms and offers insights to guide future benchmark development.","authors":["Haoming Li","Zhaoliang Chen","Jonathan Zhang","Fei Liu"],"url":"https://arxiv.org/abs/2504.14773"}
{"created":"2025-04-22","title":"gLLM: Global Balanced Pipeline Parallelism System for Distributed LLM Serving with Token Throttling","abstract":"Pipeline parallelism has emerged as a predominant approach for deploying large language models (LLMs) across distributed nodes, owing to its lower communication overhead compared to tensor parallelism. While demonstrating high throughput in request serving, pipeline parallelism often suffers from performance limitations caused by pipeline bubbles, which are primarily resulted from imbalanced computation delays across batches. Existing methods like Sarathi-Serve attempt to address this through hybrid scheduling of chunked prefill and decode tokens using a fixed token budget. However, such methods may experience significant fluctuations due to either insufficient prefill tokens or uneven distribution of decode tokens, ultimately leading to computational imbalance. To overcome these inefficiencies, we present gLLM, a globally balanced pipeline parallelism system incorporating Token Throttling to effectively mitigate the pipeline bubbles. Our Token Throttling mechanism is a fine-grained scheduling policy that independently regulates the quantities of prefill and decode tokens, thus enabling balanced computation by leveraging global information from the inference system. Specifically, for decode tokens, gLLM maintains near-consistent token count across processing batches. For prefill tokens, it dynamically adjusts batch sizes based on both total pending tokens and the memory utilization rates of key-value cache (KV cache). Furthermore, gLLM runtime adopts an asynchronous execution and message passing architecture specifically optimized for pipeline parallelism characteristics. Experimental evaluations with representative LLMs show that gLLM achieves significant performance improvements, delivering 11% to 398% higher maximum throughput compared to state-of-the-art pipeline or tensor parallelism systems, while simultaneously maintaining lower latency.","authors":["Tianyu Guo","Xianwei Zhang","Jiangsu Du","Zhiguang Chen","Nong Xiao","Yutong Lu"],"url":"https://arxiv.org/abs/2504.14775"}
{"created":"2025-04-22","title":"Script2Screen: Supporting Dialogue Scriptwriting with Interactive Audiovisual Generation","abstract":"Scriptwriting has traditionally been text-centric, a modality that only partially conveys the produced audiovisual experience. A formative study with professional writers informed us that connecting textual and audiovisual modalities can aid ideation and iteration, especially for writing dialogues. In this work, we present Script2Screen, an AI-assisted tool that integrates scriptwriting with audiovisual scene creation in a unified, synchronized workflow. Focusing on dialogues in scripts, Script2Screen generates expressive scenes with emotional speeches and animated characters through a novel text-to-audiovisual-scene pipeline. The user interface provides fine-grained controls, allowing writers to fine-tune audiovisual elements such as character gestures, speech emotions, and camera angles. A user study with both novice and professional writers from various domains demonstrated that Script2Screen's interactive audiovisual generation enhances the scriptwriting process, facilitating iterative refinement while complementing, rather than replacing, their creative efforts.","authors":["Zhecheng Wang","Jiaju Ma","Eitan Grinspun","Bryan Wang","Tovi Grossman"],"url":"https://arxiv.org/abs/2504.14776"}
{"created":"2025-04-22","title":"Intent-Aware Authorization for Zero Trust CI/CD","abstract":"This paper introduces intent-aware authorization for Zero Trust CI/CD systems. Identity establishes who is making the request, but additional signals are required to decide whether access should be granted. We describe a control loop architecture where policy engines such as OPA and Cedar evaluate runtime context, justification, and human approvals before issuing access credentials. The system builds on SPIFFE-based workload identity and credential brokers, and enables fine-grained, auditable authorization. This is the third paper in a series on Zero Trust CI/CD design patterns.","authors":["Surya Teja Avirneni"],"url":"https://arxiv.org/abs/2504.14777"}
{"created":"2025-04-22","title":"Optimal Linear MAP Decoding of Convolutional Codes","abstract":"In this paper, we propose a linear representation of BCJR maximum a posteriori probability (MAP) decoding of a rate 1/2 convolutional code (CC), referred to as the linear MAP decoding (LMAP). We discover that the MAP forward and backward decoding can be implemented by the corresponding dual soft input and soft output (SISO) encoders using shift registers. The bidrectional MAP decoding output can be obtained by combining the contents of respective forward and backward dual encoders. Represented using simple shift-registers, LMAP decoder maps naturally to hardware registers and thus can be easily implemented. Simulation results demonstrate that the LMAP decoding achieves the same performance as the BCJR MAP decoding, but has a significantly reduced decoding delay. For the block length 64, the CC of the memory length 14 with LMAP decoding surpasses the random coding union (RCU) bound by approximately 0.5 dB at a BLER of $10^{-3}$, and closely approaches both the normal approximation (NA) and meta-converse (MC) bounds.","authors":["Yonghui Li","Chentao Yue","Branka Vucetic"],"url":"https://arxiv.org/abs/2504.14778"}
{"created":"2025-04-22","title":"Exploring Collaborative GenAI Agents in Synchronous Group Settings: Eliciting Team Perceptions and Design Considerations for the Future of Work","abstract":"While generative artificial intelligence (GenAI) is finding increased adoption in workplaces, current tools are primarily designed for individual use. Prior work established the potential for these tools to enhance personal creativity and productivity towards shared goals; however, we don't know yet how to best take into account the nuances of group work and team dynamics when deploying GenAI in work settings. In this paper, we investigate the potential of collaborative GenAI agents to augment teamwork in synchronous group settings through an exploratory study that engaged 25 professionals across 6 teams in speculative design workshops and individual follow-up interviews. Our workshops included a mixed reality provotype to simulate embodied collaborative GenAI agents capable of actively participating in group discussions. Our findings suggest that, if designed well, collaborative GenAI agents offer valuable opportunities to enhance team problem-solving by challenging groupthink, bridging communication gaps, and reducing social friction. However, teams' willingness to integrate GenAI agents depended on its perceived fit across a number of individual, team, and organizational factors. We outline the key design tensions around agent representation, social prominence, and engagement and highlight the opportunities spatial and immersive technologies could offer to modulate GenAI influence on team outcomes and strike a balance between augmentation and agency.","authors":["Janet G. Johnson","Macarena Peralta","Mansanjam Kaur","Ruijie Sophia Huang","Sheng Zhao","Ruijia Guan","Shwetha Rajaram","Michael Nebeling"],"url":"https://arxiv.org/abs/2504.14779"}
{"created":"2025-04-22","title":"Novel Concept-Oriented Synthetic Data approach for Training Generative AI-Driven Crystal Grain Analysis Using Diffusion Model","abstract":"The traditional techniques for extracting polycrystalline grain structures from microscopy images, such as transmission electron microscopy (TEM) and scanning electron microscopy (SEM), are labour-intensive, subjective, and time-consuming, limiting their scalability for high-throughput analysis. In this study, we present an automated methodology integrating edge detection with generative diffusion models to effectively identify grains, eliminate noise, and connect broken segments in alignment with predicted grain boundaries. Due to the limited availability of adequate images preventing the training of deep machine learning models, a new seven-stage methodology is employed to generate synthetic TEM images for training. This concept-oriented synthetic data approach can be extended to any field of interest where the scarcity of data is a challenge. The presented model was applied to various metals with average grain sizes down to the nanoscale, producing grain morphologies from low-resolution TEM images that are comparable to those obtained from advanced and demanding experimental techniques with an average accuracy of 97.23%.","authors":["Ahmed Sobhi Saleh","Kristof Croes","Hajdin Ceric","Ingrid De Wolf","Houman Zahedmanesh"],"url":"https://arxiv.org/abs/2504.14782"}
{"created":"2025-04-22","title":"How Effective Can Dropout Be in Multiple Instance Learning ?","abstract":"Multiple Instance Learning (MIL) is a popular weakly-supervised method for various applications, with a particular interest in histological whole slide image (WSI) classification. Due to the gigapixel resolution of WSI, applications of MIL in WSI typically necessitate a two-stage training scheme: first, extract features from the pre-trained backbone and then perform MIL aggregation. However, it is well-known that this suboptimal training scheme suffers from \"noisy\" feature embeddings from the backbone and inherent weak supervision, hindering MIL from learning rich and generalizable features. However, the most commonly used technique (i.e., dropout) for mitigating this issue has yet to be explored in MIL. In this paper, we empirically explore how effective the dropout can be in MIL. Interestingly, we observe that dropping the top-k most important instances within a bag leads to better performance and generalization even under noise attack. Based on this key observation, we propose a novel MIL-specific dropout method, termed MIL-Dropout, which systematically determines which instances to drop. Experiments on five MIL benchmark datasets and two WSI datasets demonstrate that MIL-Dropout boosts the performance of current MIL methods with a negligible computational cost. The code is available at https://github.com/ChongQingNoSubway/MILDropout.","authors":["Wenhui Zhu","Peijie Qiu","Xiwen Chen","Zhangsihao Yang","Aristeidis Sotiras","Abolfazl Razi","Yalin Wang"],"url":"https://arxiv.org/abs/2504.14783"}
{"created":"2025-04-22","title":"When Cloud Removal Meets Diffusion Model in Remote Sensing","abstract":"Cloud occlusion significantly hinders remote sensing applications by obstructing surface information and complicating analysis. To address this, we propose DC4CR (Diffusion Control for Cloud Removal), a novel multimodal diffusion-based framework for cloud removal in remote sensing imagery. Our method introduces prompt-driven control, allowing selective removal of thin and thick clouds without relying on pre-generated cloud masks, thereby enhancing preprocessing efficiency and model adaptability. Additionally, we integrate low-rank adaptation for computational efficiency, subject-driven generation for improved generalization, and grouped learning to enhance performance on small datasets. Designed as a plug-and-play module, DC4CR seamlessly integrates into existing cloud removal models, providing a scalable and robust solution. Extensive experiments on the RICE and CUHK-CR datasets demonstrate state-of-the-art performance, achieving superior cloud removal across diverse conditions. This work presents a practical and efficient approach for remote sensing image processing with broad real-world applications.","authors":["Zhenyu Yu","Mohd Yamani Idna Idris","Pei Wang"],"url":"https://arxiv.org/abs/2504.14785"}
{"created":"2025-04-22","title":"Cultivating Multidisciplinary Research and Education on GPU Infrastructure for Mid-South Institutions at the University of Memphis: Practice and Challenge","abstract":"To support rapid scientific advancement and promote access to large-scale computing resources for under-resourced institutions at the Mid-South region, the University of Memphis (UofM) established the first regional mid-scale GPU cluster, iTiger, a valuable high-performance computing (HPC) infrastructure. In this study, we present our continuous efforts to manage the critical cyberinfrastructure and provide essential computing supports for educators, students, and researchers in AI, data sciences, and related scientific fields in the Mid-South region, such as precision agriculture, smart transportation, and health informatics. We outline our initiatives to broaden CI adoptions across regional computing-related scientific and engineering fields, such as seed grant, workshop trainings, course integration, and other outreach activities. While we've observed promising outcomes of regional CI adoptions, we will discuss insights and challenges of Mid-South CI users, which can inspire other institutions to implement similar programs.","authors":["Mayira Sharif","Guangzeng Han","Weisi Liu","Xiaolei Huang"],"url":"https://arxiv.org/abs/2504.14786"}
{"created":"2025-04-22","title":"ADL: A Declarative Language for Agent-Based Chatbots","abstract":"There are numerous agent frameworks capable of creating and orchestrating agents to address complex tasks. However, these frameworks are often too complicated for customer service professionals, who may not have much programming experience but still need an easy way to create chatbots with rich business logic. In this work, we introduce ADL, a Declarative Language for Agent-Based Chatbots. ADL simplifies chatbot development by using natural language programming at its core, making it easier for a broad audience to customize and build task-oriented chatbots. It includes four types of agents and supports integration with custom functions, tool use, and third-party agents. ADL abstracts away implementation details, offering a declarative way to define agents and their interactions, which could ease prompt engineering, testing and debugging. MICA, a multi-agent system designed to interpret and execute ADL programs, has been developed and is now available as an open-source project at https://github.com/Mica-labs/MICA. Its user documentation can be found at https://mica-labs.github.io/.","authors":["Sirui Zeng","Xifeng Yan"],"url":"https://arxiv.org/abs/2504.14787"}
{"created":"2025-04-22","title":"The 1st EReL@MIR Workshop on Efficient Representation Learning for Multimodal Information Retrieval","abstract":"Multimodal representation learning has garnered significant attention in the AI community, largely due to the success of large pre-trained multimodal foundation models like LLaMA, GPT, Mistral, and CLIP. These models have achieved remarkable performance across various tasks of multimodal information retrieval (MIR), including web search, cross-modal retrieval, and recommender systems, etc. However, due to their enormous parameter sizes, significant efficiency challenges emerge across training, deployment, and inference stages when adapting these models' representation for IR tasks. These challenges present substantial obstacles to the practical adaptation of foundation models for representation learning in information retrieval tasks.","authors":["Junchen Fu","Xuri Ge","Xin Xin","Haitao Yu","Yue Feng","Alexandros Karatzoglou","Ioannis Arapakis","Joemon M. Jose"],"url":"https://arxiv.org/abs/2504.14788"}
{"created":"2025-04-22","title":"Enhanced Data-driven Topology Design Methodology with Multi-level Mesh and Correlation-based Mutation for Stress-related Multi-objective Optimization","abstract":"Topology optimization (TO) serves as a widely applied structural design approach to tackle various engineering problems. Nevertheless, sensitivity-based TO methods usually struggle with solving strongly nonlinear optimization problems. By leveraging high capacity of deep generative model, which is an influential machine learning technique, the sensitivity-free data-driven topology design (DDTD) methodology is regarded as an effective means of overcoming these issues. The DDTD methodology depends on initial dataset with a certain regularity, making its results highly sensitive to initial dataset quality. This limits its effectiveness and generalizability, especially for optimization problems without priori information. In this research, we proposed a multi-level mesh DDTD-based method with correlation-based mutation module to escape from the limitation of the quality of the initial dataset on the results and enhance computational efficiency. The core is to employ a correlation-based mutation module to assign new geometric features with physical meaning to the generated data, while utilizing a multi-level mesh strategy to progressively enhance the refinement of the structural representation, thus avoiding the maintenance of a high degree-of-freedom (DOF) representation throughout the iterative process. The proposed multi-level mesh DDTD-based method can be driven by a low quality initial dataset without the need for time-consuming construction of a specific dataset, thus significantly increasing generality and reducing application difficulty, while further lowering computational cost of DDTD methodology. Various comparison experiments with the traditional sensitivity-based TO methods on stress-related strongly nonlinear problems demonstrate the generality and effectiveness of the proposed method.","authors":["Jun Yang","Shintaro Yamasaki"],"url":"https://arxiv.org/abs/2504.14790"}
{"created":"2025-04-22","title":"Price Stability and Improved Buyer Utility with Presentation Design: A Theoretical Study of the Amazon Buy Box","abstract":"Platforms design the form of presentation by which sellers are shown to the buyers. This design not only shapes the buyers' experience but also leads to different market equilibria or dynamics. One component in this design is through the platform's mediation of the search frictions experienced by the buyers for different sellers. We take a model of monopolistic competition and show that, on one hand, when all sellers have the same inspection costs, the market sees no stable price since the sellers always have incentives to undercut each other, and, on the other hand, the platform may stabilize the price by giving prominence to one seller chosen by a carefully designed mechanism. This calls to mind Amazon's Buy Box. We study natural mechanisms for choosing the prominent seller, characterize the range of equilibrium prices implementable by them, and find that in certain scenarios the buyers' surplus improves as the search friction increases.","authors":["Ophir Friedler","Hu Fu","Anna Karlin","Ariana Tang"],"url":"https://arxiv.org/abs/2504.14793"}
{"created":"2025-04-22","title":"Edge-boosted graph learning for functional brain connectivity analysis","abstract":"Predicting disease states from functional brain connectivity is critical for the early diagnosis of severe neurodegenerative diseases such as Alzheimer's Disease and Parkinson's Disease. Existing studies commonly employ Graph Neural Networks (GNNs) to infer clinical diagnoses from node-based brain connectivity matrices generated through node-to-node similarities of regionally averaged fMRI signals. However, recent neuroscience studies found that such node-based connectivity does not accurately capture ``functional connections\" within the brain. This paper proposes a novel approach to brain network analysis that emphasizes edge functional connectivity (eFC), shifting the focus to inter-edge relationships. Additionally, we introduce a co-embedding technique to integrate edge functional connections effectively. Experimental results on the ADNI and PPMI datasets demonstrate that our method significantly outperforms state-of-the-art GNN methods in classifying functional brain networks.","authors":["David Yang","Mostafa Abdelmegeed","John Modl","Minjeong Kim"],"url":"https://arxiv.org/abs/2504.14796"}
{"created":"2025-04-22","title":"Automated Duplicate Bug Report Detection in Large Open Bug Repositories","abstract":"Many users and contributors of large open-source projects report software defects or enhancement requests (known as bug reports) to the issue-tracking systems. However, they sometimes report issues that have already been reported. First, they may not have time to do sufficient research on existing bug reports. Second, they may not possess the right expertise in that specific area to realize that an existing bug report is essentially elaborating on the same matter, perhaps with a different wording. In this paper, we propose a novel approach based on machine learning methods that can automatically detect duplicate bug reports in an open bug repository based on the textual data in the reports. We present six alternative methods: Topic modeling, Gaussian Naive Bayes, deep learning, time-based organization, clustering, and summarization using a generative pre-trained transformer large language model. Additionally, we introduce a novel threshold-based approach for duplicate identification, in contrast to the conventional top-k selection method that has been widely used in the literature. Our approach demonstrates promising results across all the proposed methods, achieving accuracy rates ranging from the high 70%'s to the low 90%'s. We evaluated our methods on a public dataset of issues belonging to an Eclipse open-source project.","authors":["Clare E. Laney","Andrew Barovic","Armin Moin"],"url":"https://arxiv.org/abs/2504.14797"}
{"created":"2025-04-22","title":"Verifying Robust Unlearning: Probing Residual Knowledge in Unlearned Models","abstract":"Machine Unlearning (MUL) is crucial for privacy protection and content regulation, yet recent studies reveal that traces of forgotten information persist in unlearned models, enabling adversaries to resurface removed knowledge. Existing verification methods only confirm whether unlearning was executed, failing to detect such residual information leaks. To address this, we introduce the concept of Robust Unlearning, ensuring models are indistinguishable from retraining and resistant to adversarial recovery. To empirically evaluate whether unlearning techniques meet this security standard, we propose the Unlearning Mapping Attack (UMA), a post-unlearning verification framework that actively probes models for forgotten traces using adversarial queries. Extensive experiments on discriminative and generative tasks show that existing unlearning techniques remain vulnerable, even when passing existing verification metrics. By establishing UMA as a practical verification tool, this study sets a new standard for assessing and enhancing machine unlearning security.","authors":["Hao Xuan","Xingyu Li"],"url":"https://arxiv.org/abs/2504.14798"}
{"created":"2025-04-22","title":"A Survey on Small Sample Imbalance Problem: Metrics, Feature Analysis, and Solutions","abstract":"The small sample imbalance (S&amp;I) problem is a major challenge in machine learning and data analysis. It is characterized by a small number of samples and an imbalanced class distribution, which leads to poor model performance. In addition, indistinct inter-class feature distributions further complicate classification tasks. Existing methods often rely on algorithmic heuristics without sufficiently analyzing the underlying data characteristics. We argue that a detailed analysis from the data perspective is essential before developing an appropriate solution. Therefore, this paper proposes a systematic analytical framework for the S\\&amp;I problem. We first summarize imbalance metrics and complexity analysis methods, highlighting the need for interpretable benchmarks to characterize S&amp;I problems. Second, we review recent solutions for conventional, complexity-based, and extreme S&amp;I problems, revealing methodological differences in handling various data distributions. Our summary finds that resampling remains a widely adopted solution. However, we conduct experiments on binary and multiclass datasets, revealing that classifier performance differences significantly exceed the improvements achieved through resampling. Finally, this paper highlights open questions and discusses future trends.","authors":["Shuxian Zhao","Jie Gui","Minjing Dong","Baosheng Yu","Zhipeng Gui","Lu Dong","Yuan Yan Tang","James Tin-Yau Kwok"],"url":"https://arxiv.org/abs/2504.14800"}
{"created":"2025-04-22","title":"ReCraft: Self-Contained Split, Merge, and Membership Change of Raft Protocol","abstract":"Designing reconfiguration schemes for consensus protocols is challenging because subtle corner cases during reconfiguration could invalidate the correctness of the protocol. Thus, most systems that embed consensus protocols conservatively implement the reconfiguration and refrain from developing an efficient scheme. Existing implementations often stop the entire system during reconfiguration and rely on a centralized coordinator, which can become a single point of failure. We present ReCraft, a novel reconfiguration protocol for Raft, which supports multi- and single-cluster-level reconfigurations. ReCraft does not rely on external coordinators and blocks minimally. ReCraft enables the sharding of Raft clusters with split and merge reconfigurations and adds a membership change scheme that improves Raft. We prove the safety and liveness of ReCraft and demonstrate its efficiency through implementations in etcd.","authors":["Kezhi Xiong","Soonwon Moon","Joshua Kang","Bryant Curto","Jieung Kim","Ji-Yong Shin"],"url":"https://arxiv.org/abs/2504.14802"}
{"created":"2025-04-22","title":"The k-Center Problem of Uncertain Points on Graphs","abstract":"In this paper, we study the $k$-center problem of uncertain points on a graph. Given are an undirected graph $G = (V, E)$ and a set $\\mathcal{P}$ of $n$ uncertain points where each uncertain point with a non-negative weight has $m$ possible locations on $G$ each associated with a probability. The problem aims to find $k$ centers (points) on $G$ so as to minimize the maximum weighted expected distance of uncertain points to their expected closest centers. No previous work exist for the $k$-center problem of uncertain points on undirected graphs. We propose exact algorithms that solve respectively the case of $k=2$ in $O(|E|^2m^2n\\log |E|mn\\log mn )$ time and the problem with $k\\geq 3$ in $O(\\min\\{|E|^km^kn^{k+1}k\\log |E|mn\\log m, |E|^kn^\\frac{k}{2}m^\\frac{k^2}{2}\\log |E|mn\\})$ time, provided with the distance matrix of $G$. In addition, an $O(|E|mn\\log mn)$-time algorithmic approach is given for the one-center case.","authors":["Haitao Xu","Jingru Zhang"],"url":"https://arxiv.org/abs/2504.14803"}
{"created":"2025-04-22","title":"Automatic Evaluation Metrics for Document-level Translation: Overview, Challenges and Trends","abstract":"With the rapid development of deep learning technologies, the field of machine translation has witnessed significant progress, especially with the advent of large language models (LLMs) that have greatly propelled the advancement of document-level translation. However, accurately evaluating the quality of document-level translation remains an urgent issue. This paper first introduces the development status of document-level translation and the importance of evaluation, highlighting the crucial role of automatic evaluation metrics in reflecting translation quality and guiding the improvement of translation systems. It then provides a detailed analysis of the current state of automatic evaluation schemes and metrics, including evaluation methods with and without reference texts, as well as traditional metrics, Model-based metrics and LLM-based metrics. Subsequently, the paper explores the challenges faced by current evaluation methods, such as the lack of reference diversity, dependence on sentence-level alignment information, and the bias, inaccuracy, and lack of interpretability of the LLM-as-a-judge method. Finally, the paper looks ahead to the future trends in evaluation methods, including the development of more user-friendly document-level evaluation methods and more robust LLM-as-a-judge methods, and proposes possible research directions, such as reducing the dependency on sentence-level information, introducing multi-level and multi-granular evaluation approaches, and training models specifically for machine translation evaluation. This study aims to provide a comprehensive analysis of automatic evaluation for document-level translation and offer insights into future developments.","authors":["Jiaxin GUO","Xiaoyu Chen","Zhiqiang Rao","Jinlong Yang","Zongyao Li","Hengchao Shang","Daimeng Wei","Hao Yang"],"url":"https://arxiv.org/abs/2504.14804"}
{"created":"2025-04-22","title":"Dynamic Contrastive Skill Learning with State-Transition Based Skill Clustering and Dynamic Length Adjustment","abstract":"Reinforcement learning (RL) has made significant progress in various domains, but scaling it to long-horizon tasks with complex decision-making remains challenging. Skill learning attempts to address this by abstracting actions into higher-level behaviors. However, current approaches often fail to recognize semantically similar behaviors as the same skill and use fixed skill lengths, limiting flexibility and generalization. To address this, we propose Dynamic Contrastive Skill Learning (DCSL), a novel framework that redefines skill representation and learning. DCSL introduces three key ideas: state-transition based skill representation, skill similarity function learning, and dynamic skill length adjustment. By focusing on state transitions and leveraging contrastive learning, DCSL effectively captures the semantic context of behaviors and adapts skill lengths to match the appropriate temporal extent of behaviors. Our approach enables more flexible and adaptive skill extraction, particularly in complex or noisy datasets, and demonstrates competitive performance compared to existing methods in task completion and efficiency.","authors":["Jinwoo Choi","Seung-Woo Seo"],"url":"https://arxiv.org/abs/2504.14805"}
{"created":"2025-04-22","title":"An Iterative Task-Driven Framework for Resilient LiDAR Place Recognition in Adverse Weather","abstract":"LiDAR place recognition (LPR) plays a vital role in autonomous navigation. However, existing LPR methods struggle to maintain robustness under adverse weather conditions such as rain, snow, and fog, where weather-induced noise and point cloud degradation impair LiDAR reliability and perception accuracy. To tackle these challenges, we propose an Iterative Task-Driven Framework (ITDNet), which integrates a LiDAR Data Restoration (LDR) module and a LiDAR Place Recognition (LPR) module through an iterative learning strategy. These modules are jointly trained end-to-end, with alternating optimization to enhance performance. The core rationale of ITDNet is to leverage the LDR module to recover the corrupted point clouds while preserving structural consistency with clean data, thereby improving LPR accuracy in adverse weather. Simultaneously, the LPR task provides feature pseudo-labels to guide the LDR module's training, aligning it more effectively with the LPR task. To achieve this, we first design a task-driven LPR loss and a reconstruction loss to jointly supervise the optimization of the LDR module. Furthermore, for the LDR module, we propose a Dual-Domain Mixer (DDM) block for frequency-spatial feature fusion and a Semantic-Aware Generator (SAG) block for semantic-guided restoration. In addition, for the LPR module, we introduce a Multi-Frequency Transformer (MFT) block and a Wavelet Pyramid NetVLAD (WPN) block to aggregate multi-scale, robust global descriptors. Finally, extensive experiments on the Weather-KITTI, Boreas, and our proposed Weather-Apollo datasets demonstrate that, demonstrate that ITDNet outperforms existing LPR methods, achieving state-of-the-art performance in adverse weather. The datasets and code will be made publicly available at https://github.com/Grandzxw/ITDNet.","authors":["Xiongwei Zhao","Yang Wang","Qihao Sun","Haojie Bai","Xingxiang Xie"],"url":"https://arxiv.org/abs/2504.14806"}
{"created":"2025-04-22","title":"Real-Time Sleepiness Detection for Driver State Monitoring System","abstract":"A driver face monitoring system can detect driver fatigue, which is a significant factor in many accidents, using computer vision techniques. In this paper, we present a real-time technique for driver eye state detection. First, the face is detected, and the eyes are located within the face region for tracking. A normalized cross-correlation-based online dynamic template matching technique, combined with Kalman filter tracking, is proposed to track the detected eye positions in subsequent image frames. A support vector machine with histogram of oriented gradients (HOG) features is used to classify the state of the eyes as open or closed. If the eyes remain closed for a specified period, the driver is considered to be asleep, and an alarm is triggered.","authors":["Deepak Ghimire","Sunghwan Jeong","Sunhong Yoon","Sanghyun Park","Juhwan Choi"],"url":"https://arxiv.org/abs/2504.14807"}
{"created":"2025-04-22","title":"On Self-improving Token Embeddings","abstract":"This article introduces a novel and fast method for refining pre-trained static word or, more generally, token embeddings. By incorporating the embeddings of neighboring tokens in text corpora, it continuously updates the representation of each token, including those without pre-assigned embeddings. This approach effectively addresses the out-of-vocabulary problem, too. Operating independently of large language models and shallow neural networks, it enables versatile applications such as corpus exploration, conceptual search, and word sense disambiguation. The method is designed to enhance token representations within topically homogeneous corpora, where the vocabulary is restricted to a specific domain, resulting in more meaningful embeddings compared to general-purpose pre-trained vectors. As an example, the methodology is applied to explore storm events and their impacts on infrastructure and communities using narratives from a subset of the NOAA Storm Events database. The article also demonstrates how the approach improves the representation of storm-related terms over time, providing valuable insights into the evolving nature of disaster narratives.","authors":["Mario M. Kubek","Shiraj Pokharel","Thomas B\\\"ohme","Emma L. McDaniel","Herwig Unger","Armin R. Mikler"],"url":"https://arxiv.org/abs/2504.14808"}
{"created":"2025-04-22","title":"vApps: Verifiable Applications at Internet Scale","abstract":"Blockchain technology promises decentralized, trustless, and interoperable infrastructure. However, widespread adoption remains hindered by issues such as limited scalability, high transaction costs, and the complexity of maintaining coherent verification logic across different blockchain layers. This paper introduces Verifiable Applications (vApps), a novel development framework designed to streamline the creation and deployment of verifiable blockchain computing applications. vApps offer a unified Rust-based Domain-Specific Language (DSL) within a comprehensive SDK, featuring modular abstractions for verification, proof generation, and inter-chain connectivity. This eases the developer's burden in securing diverse software components, allowing them to focus on application logic. The DSL also ensures that applications can automatically take advantage of specialized precompiles and hardware acceleration to achieve consistently high performance with minimal developer effort, as demonstrated by benchmark results for zero-knowledge virtual machines (zkVMs). Experiments show that native Rust execution eliminates interpretation overhead, delivering up to an 832x cycle count improvement compared to EVM-based approaches. Precompiled circuits accelerate proving by over 95%, while GPU acceleration boosts throughput by up to 30x and recursion compresses proof size by up to 230x, enabling succinct and efficient verification. The framework also supports seamless integration with Web2 and Web3 systems, enabling developers to focus solely on their application logic. Through modular architecture, robust security guarantees, and composability, vApps pave the way toward a trust-minimized and verifiable Internet-scale application environment.","authors":["Isaac Zhang","Ryan Zarick","Bryan Pellegrino","Tan Li","Daniel Wong","Thomas Kim","Uma Roy","John Guibas","Kshitij Kulkarni"],"url":"https://arxiv.org/abs/2504.14809"}
{"created":"2025-04-22","title":"DONOD: Robust and Generalizable Instruction Fine-Tuning for LLMs via Model-Intrinsic Dataset Pruning","abstract":"Ad-hoc instruction fine-tuning of large language models (LLMs) is widely adopted for domain-specific adaptation. While domain-specific supervised fine-tuning (SFT) is effective and efficient, it often weakens cross-domain generalization and struggles with noisy training data. To address these challenges, we propose DONOD, a lightweight model-intrinsic data pruning method. Our approach evaluates data using two model-parameter-based metrics: Delta of Norm (DON), which captures the cumulative influence on model weights, and Norm of Delta (NOD), which quantifies weight instability. Moreover, by employing the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) algorithm, we effectively filter noisy, unlearnable, and generalization-harming samples without relying on auxiliary models during the SFT process. Experiments on mathematical tasks demonstrate that data selected by DONOD achieve superior fine-tuning efficiency and improved robustness against noisy data. By filtering out 70% of the full dataset, we improve target-domain accuracy by 14.90% and cross-domain accuracy by 5.67%. Meanwhile, our selected data present superior cross-architecture generalization. Data pruned by smaller models (e.g., Llama 3.1-8B) generalize effectively on larger models (e.g., Llama 2-13B). Compared to existing related methodologies, DONOD demonstrates comparable or superior performance while remaining dataset-agnostic, enabling broader applicability.","authors":["Jucheng Hu","Surong Yang","Dongzhan Zhou","Lijun Wu"],"url":"https://arxiv.org/abs/2504.14810"}
{"created":"2025-04-22","title":"CSI2Dig: Recovering Digit Content from Smartphone Loudspeakers Using Channel State Information","abstract":"Eavesdropping on sounds emitted by mobile device loudspeakers can capture sensitive digital information, such as SMS verification codes, credit card numbers, and withdrawal passwords, which poses significant security risks. Existing schemes either require expensive specialized equipment, rely on spyware, or are limited to close-range signal acquisition. In this paper, we propose a scheme, CSI2Dig, for recovering digit content from Channel State Information (CSI) when digits are played through a smartphone loudspeaker. We observe that the electromagnetic interference caused by the audio signals from the loudspeaker affects the WiFi signals emitted by the phone's WiFi antenna. Building upon contrastive learning and denoising autoencoders, we develop a two-branch autoencoder network designed to amplify the impact of this electromagnetic interference on CSI. For feature extraction, we introduce the TS-Net, a model that captures relevant features from both the temporal and spatial dimensions of the CSI data. We evaluate our scheme across various devices, distances, volumes, and other settings. Experimental results demonstrate that our scheme can achieve an accuracy of 72.97%.","authors":["Yangyang Gu","Xianglong Li","Haolin Wu","Jing Chen","Kun He","Ruiying Du","Cong Wu"],"url":"https://arxiv.org/abs/2504.14812"}
{"created":"2025-04-22","title":"A Basic Evaluation of Neural Networks Trained with the Error Diffusion Learning Algorithm","abstract":"Artificial neural networks are powerful tools capable of addressing various tasks. Although the backpropagation algorithm has become a standard training method for these neural networks, its lack of biological plausibility has inspired the development of alternative learning approaches. One such alternative is Kaneko's Error Diffusion Learning Algorithm (EDLA), a biologically motivated approach wherein a single global error signal diffuses throughout a network composed of paired excitatory-inhibitory sublayers, thereby eliminating the necessity for layer-wise backpropagation. This study presents a contemporary formulation of the EDLA framework and evaluates its effectiveness through parity check, regression, and image classification tasks. Our experimental results indicate that EDLA networks can consistently achieve high accuracy across these benchmarks, with performance efficiency and convergence speed notably influenced by the choice of learning rate, neuron count, and network depth. Further investigation of the internal representations formed by EDLA networks reveals their capacity for meaningful feature extraction, similar to traditional neural networks. These results suggest that EDLA is a biologically motivated alternative for training feedforward networks and will motivate future work on extending this method to biologically inspired neural networks.","authors":["Kazuhisa Fujita"],"url":"https://arxiv.org/abs/2504.14814"}
{"created":"2025-04-22","title":"What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale","abstract":"Diffusion models (DMs) have revolutionized text-to-image generation, enabling the creation of highly realistic and customized images from text prompts. With the rise of parameter-efficient fine-tuning (PEFT) techniques like LoRA, users can now customize powerful pre-trained models using minimal computational resources. However, the widespread sharing of fine-tuned DMs on open platforms raises growing ethical and legal concerns, as these models may inadvertently or deliberately generate sensitive or unauthorized content, such as copyrighted material, private individuals, or harmful content. Despite the increasing regulatory attention on generative AI, there are currently no practical tools for systematically auditing these models before deployment. In this paper, we address the problem of concept auditing: determining whether a fine-tuned DM has learned to generate a specific target concept. Existing approaches typically rely on prompt-based input crafting and output-based image classification but suffer from critical limitations, including prompt uncertainty, concept drift, and poor scalability. To overcome these challenges, we introduce Prompt-Agnostic Image-Free Auditing (PAIA), a novel, model-centric concept auditing framework. By treating the DM as the object of inspection, PAIA enables direct analysis of internal model behavior, bypassing the need for optimized prompts or generated images. We evaluate PAIA on 320 controlled model and 690 real-world community models sourced from a public DM sharing platform. PAIA achieves over 90% detection accuracy while reducing auditing time by 18-40x compared to existing baselines. To our knowledge, PAIA is the first scalable and practical solution for pre-deployment concept auditing of diffusion models, providing a practical foundation for safer and more transparent diffusion model sharing.","authors":["Xiaoyong Yuan","Xiaolong Ma","Linke Guo","Lan Zhang"],"url":"https://arxiv.org/abs/2504.14815"}
{"created":"2025-04-22","title":"Accelerating Visual Reinforcement Learning with Separate Primitive Policy for Peg-in-Hole Tasks","abstract":"For peg-in-hole tasks, humans rely on binocular visual perception to locate the peg above the hole surface and then proceed with insertion. This paper draws insights from this behavior to enable agents to learn efficient assembly strategies through visual reinforcement learning. Hence, we propose a Separate Primitive Policy (S2P) to simultaneously learn how to derive location and insertion actions. S2P is compatible with model-free reinforcement learning algorithms. Ten insertion tasks featuring different polygons are developed as benchmarks for evaluations. Simulation experiments show that S2P can boost the sample efficiency and success rate even with force constraints. Real-world experiments are also performed to verify the feasibility of S2P. Ablations are finally given to discuss the generalizability of S2P and some factors that affect its performance.","authors":["Zichun Xu","Zhaomin Wang","Yuntao Li","Lei Zhuang","Zhiyuan Zhao","Guocai Yang","Jingdong Zhao"],"url":"https://arxiv.org/abs/2504.14820"}
{"created":"2025-04-22","title":"Completing A Systematic Review in Hours instead of Months with Interactive AI Agents","abstract":"Systematic reviews (SRs) are vital for evidence-based practice in high stakes disciplines, such as healthcare, but are often impeded by intensive labors and lengthy processes that can take months to complete. Due to the high demand for domain expertise, existing automatic summarization methods fail to accurately identify relevant studies and generate high-quality summaries. To that end, we introduce InsightAgent, a human-centered interactive AI agent powered by large language models that revolutionize this workflow. InsightAgent partitions a large literature corpus based on semantics and employs a multi-agent design for more focused processing of literature, leading to significant improvement in the quality of generated SRs. InsightAgent also provides intuitive visualizations of the corpus and agent trajectories, allowing users to effortlessly monitor the actions of the agent and provide real-time feedback based on their expertise. Our user studies with 9 medical professionals demonstrate that the visualization and interaction mechanisms can effectively improve the quality of synthesized SRs by 27.2%, reaching 79.7% of human-written quality. At the same time, user satisfaction is improved by 34.4%. With InsightAgent, it only takes a clinician about 1.5 hours, rather than months, to complete a high-quality systematic review.","authors":["Rui Qiu","Shijie Chen","Yu Su","Po-Yin Yen","Han-Wei Shen"],"url":"https://arxiv.org/abs/2504.14822"}
{"created":"2025-04-22","title":"Optimal Repurchasing Contract Design for Efficient Utilization of Computing Resources","abstract":"The rapid advancement of AI and other emerging technologies has triggered exponential growth in computing resources demand. Faced with prohibitive infrastructure costs for large-scale computing clusters, users are increasingly resorting to leased computing resources from third-party providers. However, prevalent overestimation of operational requirements frequently leads to substantial underutilization of the computing resources. To mitigate such inefficiency, we propose a contract-based incentive framework for computing resources repurchasing. Comparing to auction mechanisms, our design enables providers to reclaim and reallocate surplus computing resources through market-driven incentives. Our framework operates in a multi-parameter environment where both clients' idle resource capacities and their unit valuations of retained resources are private information, posing a significant challenge to contract design. Two scenarios are considered based on whether all clients possess the same amount of idle resource capacity. By transforming the contract design problem into solving a mathematical program, we obtain the optimal contracts for each scenario, which can maximize the utility of computing resources providers while ensuring the requirements of incentive compatibility (IC) and individual rationality (IR). This innovative design not only provides an effective approach to reduce the inefficient utilization of computing resources, but also establishes a market-oriented paradigm for sustainable computing ecosystems.","authors":["Zhengyan Deng","Yusen Zheng","Chenliang Sheng","Shaowen Qin"],"url":"https://arxiv.org/abs/2504.14823"}
{"created":"2025-04-22","title":"An Enhanced Dual-Currency VCG Auction Mechanism for Resource Allocation in IoV: A Value of Information Perspective","abstract":"The Internet of Vehicles (IoV) is undergoing a transformative evolution, enabled by advancements in future 6G network technologies, to support intelligent, highly reliable, and low-latency vehicular services. However, the enhanced capabilities of loV have heightened the demands for efficient network resource allocation while simultaneously giving rise to diverse vehicular service requirements. For network service providers (NSPs), meeting the customized resource-slicing requirements of vehicle service providers (VSPs) while maximizing social welfare has become a significant challenge. This paper proposes an innovative solution by integrating a mean-field multi-agent reinforcement learning (MFMARL) framework with an enhanced Vickrey-Clarke-Groves (VCG) auction mechanism to address the problem of social welfare maximization under the condition of unknown VSP utility functions. The core of this solution is introducing the ``value of information\" as a novel monetary metric to estimate the expected benefits of VSPs, thereby ensuring the effective execution of the VCG auction mechanism. MFMARL is employed to optimize resource allocation for social welfare maximization while adapting to the intelligent and dynamic requirements of IoV. The proposed enhanced VCG auction mechanism not only protects the privacy of VSPs but also reduces the likelihood of collusion among VSPs, and it is theoretically proven to be dominant-strategy incentive compatible (DSIC). The simulation results demonstrate that, compared to the VCG mechanism implemented using quantization methods, the proposed mechanism exhibits significant advantages in convergence speed, social welfare maximization, and resistance to collusion, providing new insights into resource allocation in intelligent 6G networks.","authors":["Wei Wang (Sherman)","Nan Cheng (Sherman)","Conghao Zhou (Sherman)","Haixia Peng (Sherman)","Haibo Zhou (Sherman)","Zhou Su (Sherman)","Xuemin (Sherman)","Shen"],"url":"https://arxiv.org/abs/2504.14824"}
{"created":"2025-04-22","title":"ECViT: Efficient Convolutional Vision Transformer with Local-Attention and Multi-scale Stages","abstract":"Vision Transformers (ViTs) have revolutionized computer vision by leveraging self-attention to model long-range dependencies. However, ViTs face challenges such as high computational costs due to the quadratic scaling of self-attention and the requirement of a large amount of training data. To address these limitations, we propose the Efficient Convolutional Vision Transformer (ECViT), a hybrid architecture that effectively combines the strengths of CNNs and Transformers. ECViT introduces inductive biases such as locality and translation invariance, inherent to Convolutional Neural Networks (CNNs) into the Transformer framework by extracting patches from low-level features and enhancing the encoder with convolutional operations. Additionally, it incorporates local-attention and a pyramid structure to enable efficient multi-scale feature extraction and representation. Experimental results demonstrate that ECViT achieves an optimal balance between performance and efficiency, outperforming state-of-the-art models on various image classification tasks while maintaining low computational and storage requirements. ECViT offers an ideal solution for applications that prioritize high efficiency without compromising performance.","authors":["Zhoujie Qian"],"url":"https://arxiv.org/abs/2504.14825"}
{"created":"2025-04-22","title":"Distribution-aware Dataset Distillation for Efficient Image Restoration","abstract":"With the exponential increase in image data, training an image restoration model is laborious. Dataset distillation is a potential solution to this problem, yet current distillation techniques are a blank canvas in the field of image restoration. To fill this gap, we propose the Distribution-aware Dataset Distillation method (TripleD), a new framework that extends the principles of dataset distillation to image restoration. Specifically, TripleD uses a pre-trained vision Transformer to extract features from images for complexity evaluation, and the subset (the number of samples is much smaller than the original training set) is selected based on complexity. The selected subset is then fed through a lightweight CNN that fine-tunes the image distribution to align with the distribution of the original dataset at the feature level. To efficiently condense knowledge, the training is divided into two stages. Early stages focus on simpler, low-complexity samples to build foundational knowledge, while later stages select more complex and uncertain samples as the model matures. Our method achieves promising performance on multiple image restoration tasks, including multi-task image restoration, all-in-one image restoration, and ultra-high-definition image restoration tasks. Note that we can train a state-of-the-art image restoration model on an ultra-high-definition (4K resolution) dataset using only one consumer-grade GPU in less than 8 hours (500 savings in computing resources and immeasurable training time).","authors":["Zhuoran Zheng","Xin Su","Chen Wu","Xiuyi Jia"],"url":"https://arxiv.org/abs/2504.14826"}
{"created":"2025-04-22","title":"LACE: Exploring Turn-Taking and Parallel Interaction Modes in Human-AI Co-Creation for Iterative Image Generation","abstract":"This paper introduces LACE, a co-creative system enabling professional artists to leverage generative AI through controlled prompting and iterative refinement within Photoshop. Addressing challenges in precision, iterative coherence, and workflow compatibility, LACE allows flexible control via layer-based editing and dual-mode collaboration (turn-taking and parallel). A pilot study (N=21) demonstrates significant improvements in user satisfaction, ownership, usability, and artistic perception compared to standard AI workflows. We offer comprehensive findings, system details, nuanced user feedback, and implications for integrating generative AI in professional art practices.","authors":["YenKai Huang","Zheng Ning","Ming Cheng"],"url":"https://arxiv.org/abs/2504.14827"}
{"created":"2025-04-22","title":"Protecting Your Voice: Temporal-aware Robust Watermarking","abstract":"The rapid advancement of generative models has led to the synthesis of real-fake ambiguous voices. To erase the ambiguity, embedding watermarks into the frequency-domain features of synthesized voices has become a common routine. However, the robustness achieved by choosing the frequency domain often comes at the expense of fine-grained voice features, leading to a loss of fidelity. Maximizing the comprehensive learning of time-domain features to enhance fidelity while maintaining robustness, we pioneer a \\textbf{\\underline{t}}emporal-aware \\textbf{\\underline{r}}ob\\textbf{\\underline{u}}st wat\\textbf{\\underline{e}}rmarking (\\emph{True}) method for protecting the speech and singing voice.","authors":["Yue Li","Weizhi Liu","Dongdong Lin"],"url":"https://arxiv.org/abs/2504.14832"}
{"created":"2025-04-22","title":"IoT-AMLHP: Aligned Multimodal Learning of Header-Payload Representations for Resource-Efficient Malicious IoT Traffic Classification","abstract":"Traffic classification is crucial for securing Internet of Things (IoT) networks. Deep learning-based methods can autonomously extract latent patterns from massive network traffic, demonstrating significant potential for IoT traffic classification tasks. However, the limited computational and spatial resources of IoT devices pose challenges for deploying more complex deep learning models. Existing methods rely heavily on either flow-level features or raw packet byte features. Flow-level features often require inspecting entire or most of the traffic flow, leading to excessive resource consumption, while raw packet byte features fail to distinguish between headers and payloads, overlooking semantic differences and introducing noise from feature misalignment. Therefore, this paper proposes IoT-AMLHP, an aligned multimodal learning framework for resource-efficient malicious IoT traffic classification. Firstly, the framework constructs a packet-wise header-payload representation by parsing packet headers and payload bytes, resulting in an aligned and standardized multimodal traffic representation that enhances the characterization of heterogeneous IoT traffic. Subsequently, the traffic representation is fed into a resource-efficient neural network comprising a multimodal feature extraction module and a multimodal fusion module. The extraction module employs efficient depthwise separable convolutions to capture multi-scale features from different modalities while maintaining a lightweight architecture. The fusion module adaptively captures complementary features from different modalities and effectively fuses multimodal features.","authors":["Fengyuan Nie","Guangjie Liu","Weiwei Liu","Jianan Huang","Bo Gao"],"url":"https://arxiv.org/abs/2504.14833"}
{"created":"2025-04-22","title":"SQL-Factory: A Multi-Agent Framework for High-Quality and Large-Scale SQL Generation","abstract":"Hight quality SQL corpus is essential for intelligent database. For example, Text-to-SQL requires SQL queries and correspond natural language questions as training samples. However, collecting such query corpus remains challenging in practice due to the high cost of manual annotation, which highlights the importance of automatic SQL generation. Despite recent advances, existing generation methods still face limitations in achieving both diversity and cost-effectiveness. Besides, many methods also treat all tables equally during generation, which overlooks schema complexity and leads to under-utilization of structurally rich tables. To address these issues, this paper proposes a multi-agent framework for high-quality and large-scale SQL generation, dubbed SQL-Factory. It decomposes the generation process into three collaborative teams: the Generation Team explores diverse query structures using large language models, the Expansion Team scales promising patterns via lightweight local models, and the Management Team adaptively schedules and evaluates generation based on schema coverage and real-time query quality. This modular framework ensures a balanced trade-off between diversity, scalability, and generation cost. We apply SQL-Factory to four widely used benchmarks and generate over 300,000 executable and broadly distributed SQL queries with less than $200 API cost. Our generated queries achieve higher diversity compared to other methods, and extensive experiments demonstrate that the generated queries significantly improve the model performance in various downstream tasks.","authors":["Jiahui Li","Tongwang Wu","Yuren Mao","Yunjun Gao","Yajie Feng","Huaizhong Liu"],"url":"https://arxiv.org/abs/2504.14837"}
{"created":"2025-04-22","title":"Establishing Reliability Metrics for Reward Models in Large Language Models","abstract":"The reward model (RM) that represents human preferences plays a crucial role in optimizing the outputs of large language models (LLMs), e.g., through reinforcement learning from human feedback (RLHF) or rejection sampling. However, a long challenge for RM is its uncertain reliability, i.e., LLM outputs with higher rewards may not align with actual human preferences. Currently, there is a lack of a convincing metric to quantify the reliability of RMs. To bridge this gap, we propose the \\textit{\\underline{R}eliable at \\underline{$\\eta$}} (RETA) metric, which directly measures the reliability of an RM by evaluating the average quality (scored by an oracle) of the top $\\eta$ quantile responses assessed by an RM. On top of RETA, we present an integrated benchmarking pipeline that allows anyone to evaluate their own RM without incurring additional Oracle labeling costs. Extensive experimental studies demonstrate the superior stability of RETA metric, providing solid evaluations of the reliability of various publicly available and proprietary RMs. When dealing with an unreliable RM, we can use the RETA metric to identify the optimal quantile from which to select the responses.","authors":["Yizhou Chen","Yawen Liu","Xuesi Wang","Qingtao Yu","Guangda Huzhang","Anxiang Zeng","Han Yu","Zhiming Zhou"],"url":"https://arxiv.org/abs/2504.14838"}
{"created":"2025-04-22","title":"Exploring $\\ell_0$ Sparsification for Inference-free Sparse Retrievers","abstract":"With increasing demands for efficiency, information retrieval has developed a branch of sparse retrieval, further advancing towards inference-free retrieval where the documents are encoded during indexing time and there is no model-inference for queries. Existing sparse retrieval models rely on FLOPS regularization for sparsification, while this mechanism was originally designed for Siamese encoders, it is considered to be suboptimal in inference-free scenarios which is asymmetric. Previous attempts to adapt FLOPS for inference-free scenarios have been limited to rule-based methods, leaving the potential of sparsification approaches for inference-free retrieval models largely unexplored. In this paper, we explore $\\ell_0$ inspired sparsification manner for inference-free retrievers. Through comprehensive out-of-domain evaluation on the BEIR benchmark, our method achieves state-of-the-art performance among inference-free sparse retrieval models and is comparable to leading Siamese sparse retrieval models. Furthermore, we provide insights into the trade-off between retrieval effectiveness and computational efficiency, demonstrating practical value for real-world applications.","authors":["Xinjie Shen","Zhichao Geng","Yang Yang"],"url":"https://arxiv.org/abs/2504.14839"}
{"created":"2025-04-22","title":"A Short Proof of Coding Theorems for Reed-Muller Codes","abstract":"In this paper, we present a short proof that ReedMuller (RM) codes are entropy-achieving as source coding for Bernoulli sources and capacity-achieving as channel coding for binary memoryless symmetric (BMS) channels, also known as memoryless binary-input output-symmetric (BIOS) channels, in terms of bit error rate (BER) under maximum-likelihood (ML) decoding.","authors":["Xiao Ma"],"url":"https://arxiv.org/abs/2504.14842"}
{"created":"2025-04-22","title":"Enhancing the Patent Matching Capability of Large Language Models via the Memory Graph","abstract":"Intellectual Property (IP) management involves strategically protecting and utilizing intellectual assets to enhance organizational innovation, competitiveness, and value creation. Patent matching is a crucial task in intellectual property management, which facilitates the organization and utilization of patents. Existing models often rely on the emergent capabilities of Large Language Models (LLMs) and leverage them to identify related patents directly. However, these methods usually depend on matching keywords and overlook the hierarchical classification and categorical relationships of patents. In this paper, we propose MemGraph, a method that augments the patent matching capabilities of LLMs by incorporating a memory graph derived from their parametric memory. Specifically, MemGraph prompts LLMs to traverse their memory to identify relevant entities within patents, followed by attributing these entities to corresponding ontologies. After traversing the memory graph, we utilize extracted entities and ontologies to improve the capability of LLM in comprehending the semantics of patents. Experimental results on the PatentMatch dataset demonstrate the effectiveness of MemGraph, achieving a 17.68% performance improvement over baseline LLMs. The further analysis highlights the generalization ability of MemGraph across various LLMs, both in-domain and out-of-domain, and its capacity to enhance the internal reasoning processes of LLMs during patent matching. All data and codes are available at https://github.com/NEUIR/MemGraph.","authors":["Qiushi Xiong","Zhipeng Xu","Zhenghao Liu","Mengjia Wang","Zulong Chen","Yue Sun","Yu Gu","Xiaohua Li","Ge Yu"],"url":"https://arxiv.org/abs/2504.14845"}
{"created":"2025-04-22","title":"Reliable Multi-Modal Object Re-Identification via Modality-Aware Graph Reasoning","abstract":"Multi-modal data provides abundant and diverse object information, crucial for effective modal interactions in Re-Identification (ReID) tasks. However, existing approaches often overlook the quality variations in local features and fail to fully leverage the complementary information across modalities, particularly in the case of low-quality features. In this paper, we propose to address this issue by leveraging a novel graph reasoning model, termed the Modality-aware Graph Reasoning Network (MGRNet). Specifically, we first construct modality-aware graphs to enhance the extraction of fine-grained local details by effectively capturing and modeling the relationships between patches. Subsequently, the selective graph nodes swap operation is employed to alleviate the adverse effects of low-quality local features by considering both local and global information, enhancing the representation of discriminative information. Finally, the swapped modality-aware graphs are fed into the local-aware graph reasoning module, which propagates multi-modal information to yield a reliable feature representation. Another advantage of the proposed graph reasoning approach is its ability to reconstruct missing modal information by exploiting inherent structural relationships, thereby minimizing disparities between different modalities. Experimental results on four benchmarks (RGBNT201, Market1501-MM, RGBNT100, MSVR310) indicate that the proposed method achieves state-of-the-art performance in multi-modal object ReID. The code for our method will be available upon acceptance.","authors":["Xixi Wan","Aihua Zheng","Zi Wang","Bo Jiang","Jin Tang","Jixin Ma"],"url":"https://arxiv.org/abs/2504.14847"}
{"created":"2025-04-22","title":"Object-Level Verbalized Confidence Calibration in Vision-Language Models via Semantic Perturbation","abstract":"Vision-language models (VLMs) excel in various multimodal tasks but frequently suffer from poor calibration, resulting in misalignment between their verbalized confidence and response correctness. This miscalibration undermines user trust, especially when models confidently provide incorrect or fabricated information. In this work, we propose a novel Confidence Calibration through Semantic Perturbation (CSP) framework to improve the calibration of verbalized confidence for VLMs in response to object-centric queries. We first introduce a perturbed dataset where Gaussian noise is applied to the key object regions to simulate visual uncertainty at different confidence levels, establishing an explicit mapping between visual ambiguity and confidence levels. We further enhance calibration through a two-stage training process combining supervised fine-tuning on the perturbed dataset with subsequent preference optimization. Extensive experiments on popular benchmarks demonstrate that our method significantly improves the alignment between verbalized confidence and response correctness while maintaining or enhancing overall task performance. These results highlight the potential of semantic perturbation as a practical tool for improving the reliability and interpretability of VLMs.","authors":["Yunpu Zhao","Rui Zhang","Junbin Xiao","Ruibo Hou","Jiaming Guo","Zihao Zhang","Yifan Hao","Yunji Chen"],"url":"https://arxiv.org/abs/2504.14848"}
{"created":"2025-04-22","title":"APIRAT: Integrating Multi-source API Knowledge for Enhanced Code Translation with LLMs","abstract":"Code translation is an essential task in software migration, multilingual development, and system refactoring. Recent advancements in large language models (LLMs) have demonstrated significant potential in this task. However, prior studies have highlighted that LLMs often struggle with domain-specific code, particularly in resolving cross-lingual API mappings. To tackle this challenge, we propose APIRAT, a novel code translation method that integrates multi-source API knowledge. APIRAT employs three API knowledge augmentation techniques, including API sequence retrieval, API sequence back-translation, and API mapping, to guide LLMs to translating code, ensuring both the correct structure of API sequences and the accurate usage of individual APIs. Extensive experiments on two public datasets, CodeNet and AVATAR, indicate that APIRAT significantly surpasses existing LLM-based methods, achieving improvements in computational accuracy ranging from 4% to 15.1%. Additionally, our evaluation across different LLMs showcases the generalizability of APIRAT. An ablation study further confirms the individual contributions of each API knowledge component, underscoring the effectiveness of our approach.","authors":["Chaofan Wang","Guanjie Qiu","Xiaodong Gu","Beijun Shen"],"url":"https://arxiv.org/abs/2504.14852"}
{"created":"2025-04-22","title":"Uncertainty quantification of neural network models of evolving processes via Langevin sampling","abstract":"We propose a scalable, approximate inference hypernetwork framework for a general model of history-dependent processes. The flexible data model is based on a neural ordinary differential equation (NODE) representing the evolution of internal states together with a trainable observation model subcomponent. The posterior distribution corresponding to the data model parameters (weights and biases) follows a stochastic differential equation with a drift term related to the score of the posterior that is learned jointly with the data model parameters. This Langevin sampling approach offers flexibility in balancing the computational budget between the evaluation cost of the data model and the approximation of the posterior density of its parameters. We demonstrate performance of the hypernetwork on chemical reaction and material physics data and compare it to mean-field variational inference.","authors":["Cosmin Safta","Reese E. Jones","Ravi G. Patel","Raelynn Wonnacot","Dan S. Bolintineanu","Craig M. Hamel","Sharlotte L. B. Kramer"],"url":"https://arxiv.org/abs/2504.14854"}
{"created":"2025-04-22","title":"Transparentize the Internal and External Knowledge Utilization in LLMs with Trustworthy Citation","abstract":"While hallucinations of large language models could been alleviated through retrieval-augmented generation and citation generation, how the model utilizes internal knowledge is still opaque, and the trustworthiness of its generated answers remains questionable. In this work, we introduce Context-Prior Augmented Citation Generation task, requiring models to generate citations considering both external and internal knowledge while providing trustworthy references, with 5 evaluation metrics focusing on 3 aspects: answer helpfulness, citation faithfulness, and trustworthiness. We introduce RAEL, the paradigm for our task, and also design INTRALIGN, an integrated method containing customary data generation and an alignment algorithm. Our experimental results show that our method achieves a better cross-scenario performance with regard to other baselines. Our extended experiments further reveal that retrieval quality, question types, and model knowledge have considerable influence on the trustworthiness in citation generation.","authors":["Jiajun Shen","Tong Zhou","Yubo Chen","Delai Qiu","Shengping Liu","Kang Liu","Jun Zhao"],"url":"https://arxiv.org/abs/2504.14856"}
{"created":"2025-04-22","title":"SuFIA-BC: Generating High Quality Demonstration Data for Visuomotor Policy Learning in Surgical Subtasks","abstract":"Behavior cloning facilitates the learning of dexterous manipulation skills, yet the complexity of surgical environments, the difficulty and expense of obtaining patient data, and robot calibration errors present unique challenges for surgical robot learning. We provide an enhanced surgical digital twin with photorealistic human anatomical organs, integrated into a comprehensive simulator designed to generate high-quality synthetic data to solve fundamental tasks in surgical autonomy. We present SuFIA-BC: visual Behavior Cloning policies for Surgical First Interactive Autonomy Assistants. We investigate visual observation spaces including multi-view cameras and 3D visual representations extracted from a single endoscopic camera view. Through systematic evaluation, we find that the diverse set of photorealistic surgical tasks introduced in this work enables a comprehensive evaluation of prospective behavior cloning models for the unique challenges posed by surgical environments. We observe that current state-of-the-art behavior cloning techniques struggle to solve the contact-rich and complex tasks evaluated in this work, regardless of their underlying perception or control architectures. These findings highlight the importance of customizing perception pipelines and control architectures, as well as curating larger-scale synthetic datasets that meet the specific demands of surgical tasks. Project website: https://orbit-surgical.github.io/sufia-bc/","authors":["Masoud Moghani","Nigel Nelson","Mohamed Ghanem","Andres Diaz-Pinto","Kush Hari","Mahdi Azizian","Ken Goldberg","Sean Huver","Animesh Garg"],"url":"https://arxiv.org/abs/2504.14857"}
{"created":"2025-04-22","title":"AlignRAG: An Adaptable Framework for Resolving Misalignments in Retrieval-Aware Reasoning of RAG","abstract":"Retrieval-augmented generation (RAG) has emerged as a foundational paradigm for knowledge-grounded text generation. However, existing RAG pipelines often fail to ensure that the reasoning trajectories align with the evidential constraints imposed by retrieved content. In this paper, we reframe RAG as a problem of retrieval-aware reasoning and identify a core challenge: reasoning misalignment-the mismatch between a model's reasoning trajectory and the retrieved evidence. To address this challenge, we propose AlignRAG, a novel test-time framework that mitigates reasoning misalignment through iterative Critique-Driven Alignment (CDA) steps. In contrast to prior approaches that rely on static training or post-hoc selection, AlignRAG actively refines reasoning trajectories during inference by enforcing fine-grained alignment with evidence. Our framework introduces a new paradigm for retrieval-aware reasoning by: (1) constructing context-rich training corpora; (2) generating contrastive critiques from preference-aware reasoning trajectories; (3) training a dedicated \\textit{Critic Language Model (CLM)} to identify reasoning misalignments; and (4) applying CDA steps to optimize reasoning trajectories iteratively. Empirical results demonstrate that AlignRAG consistently outperforms all baselines and could integrate as a plug-and-play module into existing RAG pipelines without further changes. By reconceptualizing RAG as a structured reasoning trajectory and establishing the test-time framework for correcting reasoning misalignments in RAG, AlignRAG provides practical advancements for retrieval-aware generation.","authors":["Jiaqi Wei","Hao Zhou","Xiang Zhang","Di Zhang","Zijie Qiu","Wei Wei","Jinzhe Li","Wanli Ouyang","Siqi Sun"],"url":"https://arxiv.org/abs/2504.14858"}
{"created":"2025-04-22","title":"Bridge the Gap: From Weak to Full Supervision for Temporal Action Localization with PseudoFormer","abstract":"Weakly-supervised Temporal Action Localization (WTAL) has achieved notable success but still suffers from a lack of temporal annotations, leading to a performance and framework gap compared with fully-supervised methods. While recent approaches employ pseudo labels for training, three key challenges: generating high-quality pseudo labels, making full use of different priors, and optimizing training methods with noisy labels remain unresolved. Due to these perspectives, we propose PseudoFormer, a novel two-branch framework that bridges the gap between weakly and fully-supervised Temporal Action Localization (TAL). We first introduce RickerFusion, which maps all predicted action proposals to a global shared space to generate pseudo labels with better quality. Subsequently, we leverage both snippet-level and proposal-level labels with different priors from the weak branch to train the regression-based model in the full branch. Finally, the uncertainty mask and iterative refinement mechanism are applied for training with noisy pseudo labels. PseudoFormer achieves state-of-the-art WTAL results on the two commonly used benchmarks, THUMOS14 and ActivityNet1.3. Besides, extensive ablation studies demonstrate the contribution of each component of our method.","authors":["Ziyi Liu","Yangcen Liu"],"url":"https://arxiv.org/abs/2504.14860"}
{"created":"2025-04-22","title":"Stitching Inner Product and Euclidean Metrics for Topology-aware Maximum Inner Product Search","abstract":"Maximum Inner Product Search (MIPS) is a fundamental challenge in machine learning and information retrieval, particularly in high-dimensional data applications. Existing approaches to MIPS either rely solely on Inner Product (IP) similarity, which faces issues with local optima and redundant computations, or reduce the MIPS problem to the Nearest Neighbor Search under the Euclidean metric via space projection, leading to topology destruction and information loss. Despite the divergence of the two paradigms, we argue that there is no inherent binary opposition between IP and Euclidean metrics. By stitching IP and Euclidean in the design of indexing and search algorithms, we can significantly enhance MIPS performance. Specifically, this paper explores the theoretical and empirical connections between these two metrics from the MIPS perspective. Our investigation, grounded in graph-based search, reveals that different indexing and search strategies offer distinct advantages for MIPS, depending on the underlying data topology. Building on these insights, we introduce a novel graph-based index called Metric-Amphibious Graph (MAG) and a corresponding search algorithm, Adaptive Navigation with Metric Switch (ANMS). To facilitate parameter tuning for optimal performance, we identify three statistical indicators that capture essential data topology properties and correlate strongly with parameter tuning. Extensive experiments on 12 real-world datasets demonstrate that MAG outperforms existing state-of-the-art methods, achieving up to 4x search speedup while maintaining adaptability and scalability.","authors":["Tingyang Chen","Cong Fu","Xiangyu Ke","Yunjun Gao","Yabo Ni","Anxiang Zeng"],"url":"https://arxiv.org/abs/2504.14861"}
{"created":"2025-04-22","title":"FERMI: Flexible Radio Mapping with a Hybrid Propagation Model and Scalable Autonomous Data Collection","abstract":"Communication is fundamental for multi-robot collaboration, with accurate radio mapping playing a crucial role in predicting signal strength between robots. However, modeling radio signal propagation in large and occluded environments is challenging due to complex interactions between signals and obstacles. Existing methods face two key limitations: they struggle to predict signal strength for transmitter-receiver pairs not present in the training set, while also requiring extensive manual data collection for modeling, making them impractical for large, obstacle-rich scenarios. To overcome these limitations, we propose FERMI, a flexible radio mapping framework. FERMI combines physics-based modeling of direct signal paths with a neural network to capture environmental interactions with radio signals. This hybrid model learns radio signal propagation more efficiently, requiring only sparse training data. Additionally, FERMI introduces a scalable planning method for autonomous data collection using a multi-robot team. By increasing parallelism in data collection and minimizing robot travel costs between regions, overall data collection efficiency is significantly improved. Experiments in both simulation and real-world scenarios demonstrate that FERMI enables accurate signal prediction and generalizes well to unseen positions in complex environments. It also supports fully autonomous data collection and scales to different team sizes, offering a flexible solution for creating radio maps. Our code is open-sourced at https://github.com/ymLuo1214/Flexible-Radio-Mapping.","authors":["Yiming Luo","Yunfei Wang","Hongming Chen","Chengkai Wu","Ximin Lyu","Jinni Zhou","Jun Ma","Fu Zhang","Boyu Zhou"],"url":"https://arxiv.org/abs/2504.14862"}
{"created":"2025-04-22","title":"GainSight: Application-Guided Profiling for Composing Heterogeneous On-Chip Memories in AI Hardware Accelerators","abstract":"As AI workloads drive soaring memory requirements, there is a need for higher-density on-chip memory for domain-specific accelerators that goes beyond what current SRAM technology can provide. We motivate that algorithms and application behavior should guide the composition of heterogeneous on-chip memories. However, there has been little work in factoring dynamic application profiles into such design decisions. We present GainSight, a profiling framework that analyzes fine-grained memory access patterns and computes data lifetimes in domain-specific accelerators. By combining instrumentation and simulation across retargetable hardware backends, GainSight aligns heterogeneous memory designs with workload-specific traffic and lifetime metrics. Case studies on MLPerf Inference and PolyBench workloads using NVIDIA H100 GPUs and systolic arrays reveal key insights: (1) 40% of L1 and 18% of L2 GPU cache accesses, and 79% of systolic array scratchpad accesses across profiled workloads are short-lived and suitable for silicon-based gain cell RAM (Si-GCRAM); (2) Si-GCRAM reduces active energy by 11-28% compared to SRAM; (3) Up to 90% of GPU cache fetches are never reused, highlighting inefficiencies in terms of cache pollution. These insights that GainSight provides can be used to better understand the design spaces of both emerging on-chip memories and software algorithmic optimizations for the next generation of AI accelerators.","authors":["Peijing Li","Matthew Hung","Yiming Tan","Konstantin Ho{\\ss}feld","Jake Jiajun Cheng","Shuhan Liu","Lixian Yan","Xinxin Wang","H. -S. Philip Wong","Thierry Tambe"],"url":"https://arxiv.org/abs/2504.14866"}
{"created":"2025-04-22","title":"Twin Co-Adaptive Dialogue for Progressive Image Generation","abstract":"Modern text-to-image generation systems have enabled the creation of remarkably realistic and high-quality visuals, yet they often falter when handling the inherent ambiguities in user prompts. In this work, we present Twin-Co, a framework that leverages synchronized, co-adaptive dialogue to progressively refine image generation. Instead of a static generation process, Twin-Co employs a dynamic, iterative workflow where an intelligent dialogue agent continuously interacts with the user. Initially, a base image is generated from the user's prompt. Then, through a series of synchronized dialogue exchanges, the system adapts and optimizes the image according to evolving user feedback. The co-adaptive process allows the system to progressively narrow down ambiguities and better align with user intent. Experiments demonstrate that Twin-Co not only enhances user experience by reducing trial-and-error iterations but also improves the quality of the generated images, streamlining the creative process across various applications.","authors":["Jianhui Wang","Yangfan He","Yan Zhong","Xinyuan Song","Jiayi Su","Yuheng Feng","Hongyang He","Wenyu Zhu","Xinhang Yuan","Kuan Lu","Menghao Huo","Miao Zhang","Keqin Li","Jiaqi Chen","Tianyu Shi","Xueqian Wang"],"url":"https://arxiv.org/abs/2504.14868"}
{"created":"2025-04-22","title":"OTC: Optimal Tool Calls via Reinforcement Learning","abstract":"Tool-integrated reasoning (TIR) augments large language models (LLMs) with the ability to invoke external tools, such as search engines and code interpreters, to solve tasks beyond the capabilities of language-only reasoning. While reinforcement learning (RL) has shown promise in improving TIR by optimizing final answer correctness, existing approaches often overlook the efficiency and cost associated with tool usage. This can lead to suboptimal behavior, including excessive tool calls that increase computational and financial overhead, or insufficient tool use that compromises answer quality. In this work, we propose Optimal Tool Call-controlled Policy Optimization (OTC-PO), a simple yet effective RL-based framework that encourages models to produce accurate answers with minimal tool calls. Our method introduces a tool-integrated reward that jointly considers correctness and tool efficiency, promoting high tool productivity. We instantiate this framework within both Proximal Policy Optimization (PPO) and Group Relative Preference Optimization (GRPO), resulting in OTC-PPO and OTC-GRPO. Experiments with Qwen-2.5 and Qwen-Math across multiple QA benchmarks show that our approach reduces tool calls by up to 73.1\\% and improves tool productivity by up to 229.4\\%, while maintaining comparable answer accuracy. To the best of our knowledge, this is the first RL-based framework that explicitly optimizes tool-use efficiency in TIR.","authors":["Hongru Wang","Cheng Qian","Wanjun Zhong","Xiusi Chen","Jiahao Qiu","Shijue Huang","Bowen Jin","Mengdi Wang","Kam-Fai Wong","Heng Ji"],"url":"https://arxiv.org/abs/2504.14870"}
{"created":"2025-04-22","title":"Natural Fingerprints of Large Language Models","abstract":"Large language models (LLMs) often exhibit biases -- systematic deviations from expected norms -- in their outputs. These range from overt issues, such as unfair responses, to subtler patterns that can reveal which model produced them. We investigate the factors that give rise to identifiable characteristics in LLMs. Since LLMs model training data distribution, it is reasonable that differences in training data naturally lead to the characteristics. However, our findings reveal that even when LLMs are trained on the exact same data, it is still possible to distinguish the source model based on its generated text. We refer to these unintended, distinctive characteristics as natural fingerprints. By systematically controlling training conditions, we show that the natural fingerprints can emerge from subtle differences in the training process, such as parameter sizes, optimization settings, and even random seeds. We believe that understanding natural fingerprints offers new insights into the origins of unintended bias and ways for improving control over LLM behavior.","authors":["Teppei Suzuki","Ryokan Ri","Sho Takase"],"url":"https://arxiv.org/abs/2504.14871"}
{"created":"2025-04-22","title":"Efficient Function Orchestration for Large Language Models","abstract":"Function calling is a fundamental capability of today's large language models, but sequential function calling posed efficiency problems. Recent studies have proposed to request function calls with parallelism support in order to alleviate this issue. However, they either delegate the concurrent function calls to users for execution which are conversely executed sequentially, or overlook the relations among various function calls, rending limited efficiency. This paper introduces LLMOrch, an advanced framework for automated, parallel function calling in large language models. The key principle behind LLMOrch is to identify an available processor to execute a function call while preventing any single processor from becoming overburdened. To this end, LLMOrch models the data relations (i.e., def-use) among different function calls and coordinates their executions by their control relations (i.e., mutual-exclusion) as well as the working status of the underlying processors. When comparing with state-of-the-art techniques, LLMOrch demonstrated comparable efficiency improvements in orchestrating I/O-intensive functions, while significantly outperforming (2$\\times$) them with compute-intensive functions. LLMOrch's performance even showed a linear correlation to the number of allocated processors. We believe that these results highlight the potential of LLMOrch as an efficient solution for parallel function orchestration in the context of large language models.","authors":["Xiaoxia Liu","Peng Di","Cong Li","Jun Sun","Jingyi Wang"],"url":"https://arxiv.org/abs/2504.14872"}
{"created":"2025-04-22","title":"Bridging Generations: Augmented Reality for Japanese Wartime Oral History","abstract":"In this position paper, the author presents a process artifact that aims to serve as an archival and educational tool that revitalizes World War II oral histories in Japan. First, the author introduces the historical background and how the work is informed by the positionality of the author. Then, the author presents features of the artifact using references to interview footage of the author's grandmother and grandaunt sharing their firsthand accounts of the 1945 Tokyo Air Raids. The affordances and barriers of this application of augmented reality is discussed and a included is a list of questions to be posed at the workshop.","authors":["Karen Abe"],"url":"https://arxiv.org/abs/2504.14873"}
{"created":"2025-04-22","title":"Event triggered optimal formation control for nonlinear multi-agent systems under Denial-of-Service attacks","abstract":"This paper investigates the optimal formation control problem of a class of nonlinear multi-agent systems(MASs) under Denial-of-Service(DoS) attacks. We design the optimal formation control law using an event-triggered control scheme to achieve formation objectives under DoS attacks. Critic neural network (NN)-based approach is employed to achieve the optimal control policy under DoS attacks. Event-triggered mechanism is introduced to ensure the saving of control resources. Additionally, Lyapunov stability theory is utilized to demonstrate that the local neighborhood formation error exhibits exponential stability and the estimation error of weights are uniformly ultimately bounded. Finally, the effectiveness of the control algorithm is validated through matlab simulations. The results indicate that under DoS attacks, the nonlinear MAS successfully achieves the desired formation for the MAS.","authors":["Jianqiang Zhang","Kaijun Yang"],"url":"https://arxiv.org/abs/2504.14874"}
{"created":"2025-04-22","title":"ReSpec: Relevance and Specificity Grounded Online Filtering for Learning on Video-Text Data Streams","abstract":"The rapid growth of video-text data presents challenges in storage and computation during training. Online learning, which processes streaming data in real-time, offers a promising solution to these issues while also allowing swift adaptations in scenarios demanding real-time responsiveness. One strategy to enhance the efficiency and effectiveness of learning involves identifying and prioritizing data that enhances performance on target downstream tasks. We propose Relevance and Specificity-based online filtering framework (ReSpec) that selects data based on four criteria: (i) modality alignment for clean data, (ii) task relevance for target focused data, (iii) specificity for informative and detailed data, and (iv) efficiency for low-latency processing. Relevance is determined by the probabilistic alignment of incoming data with downstream tasks, while specificity employs the distance to a root embedding representing the least specific data as an efficient proxy for informativeness. By establishing reference points from target task data, ReSpec filters incoming data in real-time, eliminating the need for extensive storage and compute. Evaluating on large-scale datasets WebVid2M and VideoCC3M, ReSpec attains state-of-the-art performance on five zeroshot video retrieval tasks, using as little as 5% of the data while incurring minimal compute. The source code is available at https://github.com/cdjkim/ReSpec.","authors":["Chris Dongjoo Kim","Jihwan Moon","Sangwoo Moon","Heeseung Yun","Sihaeng Lee","Aniruddha Kembhavi","Soonyoung Lee","Gunhee Kim","Sangho Lee","Christopher Clark"],"url":"https://arxiv.org/abs/2504.14875"}
{"created":"2025-04-22","title":"Collaborative Enhancement Network for Low-quality Multi-spectral Vehicle Re-identification","abstract":"The performance of multi-spectral vehicle Re-identification (ReID) is significantly degraded when some important discriminative cues in visible, near infrared and thermal infrared spectra are lost. Existing methods generate or enhance missing details in low-quality spectra data using the high-quality one, generally called the primary spectrum, but how to justify the primary spectrum is a challenging problem. In addition, when the quality of the primary spectrum is low, the enhancement effect would be greatly degraded, thus limiting the performance of multi-spectral vehicle ReID. To address these problems, we propose the Collaborative Enhancement Network (CoEN), which generates a high-quality proxy from all spectra data and leverages it to supervise the selection of primary spectrum and enhance all spectra features in a collaborative manner, for robust multi-spectral vehicle ReID. First, to integrate the rich cues from all spectra data, we design the Proxy Generator (PG) to progressively aggregate multi-spectral features. Second, we design the Dynamic Quality Sort Module (DQSM), which sorts all spectra data by measuring their correlations with the proxy, to accurately select the primary spectra with the highest correlation. Finally, we design the Collaborative Enhancement Module (CEM) to effectively compensate for missing contents of all spectra by collaborating the primary spectra and the proxy, thereby mitigating the impact of low-quality primary spectra. Extensive experiments on three benchmark datasets are conducted to validate the efficacy of the proposed approach against other multi-spectral vehicle ReID methods. The codes will be released at https://github.com/yongqisun/CoEN.","authors":["Aihua Zheng","Yongqi Sun","Zi Wang","Chenglong Li","Jin Tang"],"url":"https://arxiv.org/abs/2504.14877"}
{"created":"2025-04-22","title":"Impact of Latent Space Dimension on IoT Botnet Detection Performance: VAE-Encoder Versus ViT-Encoder","abstract":"The rapid evolution of Internet of Things (IoT) technology has led to a significant increase in the number of IoT devices, applications, and services. This surge in IoT devices, along with their widespread presence, has made them a prime target for various cyber-attacks, particularly through IoT botnets. As a result, security has become a major concern within the IoT ecosystem. This study focuses on investigating how the latent dimension impacts the performance of different deep learning classifiers when trained on latent vector representations of the train dataset. The primary objective is to compare the outcomes of these models when encoder components from two cutting-edge architectures: the Vision Transformer (ViT) and the Variational Auto-Encoder (VAE) are utilized to project the high dimensional train dataset to the learned low dimensional latent space. The encoder components are employed to project high-dimensional structured .csv IoT botnet traffic datasets to various latent sizes. Evaluated on N-BaIoT and CICIoT2022 datasets, findings reveal that VAE-encoder based dimension reduction outperforms ViT-encoder based dimension reduction for both datasets in terms of four performance metrics including accuracy, precision, recall, and F1-score for all models which can be attributed to absence of spatial patterns in the datasets the ViT model attempts to learn and extract from image instances.","authors":["Hassan Wasswa","Aziida Nanyonga","Timothy Lynar"],"url":"https://arxiv.org/abs/2504.14879"}
{"created":"2025-04-22","title":"Towards Fuzzing Zero-Knowledge Proof Circuits (Short Paper)","abstract":"Zero-knowledge proofs (ZKPs) have evolved from a theoretical cryptographic concept into a powerful tool for implementing privacy-preserving and verifiable applications without requiring trust assumptions. Despite significant progress in the field, implementing and using ZKPs via \\emph{ZKP circuits} remains challenging, leading to numerous bugs that affect ZKP circuits in practice, and \\emph{fuzzing} remains largely unexplored as a method to detect bugs in ZKP circuits. We discuss the unique challenges of applying fuzzing to ZKP circuits, examine the oracle problem and its potential solutions, and propose techniques for input generation and test harness construction. We demonstrate that fuzzing can be effective in this domain by implementing a fuzzer for \\texttt{zk-regex}, a cornerstone library in modern ZKP applications. In our case study, we discovered \\textit{$10$} new bugs.","authors":["Stefanos Chaliasos","Imam Al-Fath","Alastair Donaldson"],"url":"https://arxiv.org/abs/2504.14881"}
{"created":"2025-04-22","title":"Some Optimizers are More Equal: Understanding the Role of Optimizers in Group Fairness","abstract":"We study whether and how the choice of optimization algorithm can impact group fairness in deep neural networks. Through stochastic differential equation analysis of optimization dynamics in an analytically tractable setup, we demonstrate that the choice of optimization algorithm indeed influences fairness outcomes, particularly under severe imbalance. Furthermore, we show that when comparing two categories of optimizers, adaptive methods and stochastic methods, RMSProp (from the adaptive category) has a higher likelihood of converging to fairer minima than SGD (from the stochastic category). Building on this insight, we derive two new theoretical guarantees showing that, under appropriate conditions, RMSProp exhibits fairer parameter updates and improved fairness in a single optimization step compared to SGD. We then validate these findings through extensive experiments on three publicly available datasets, namely CelebA, FairFace, and MS-COCO, across different tasks as facial expression recognition, gender classification, and multi-label classification, using various backbones. Considering multiple fairness definitions including equalized odds, equal opportunity, and demographic parity, adaptive optimizers like RMSProp and Adam consistently outperform SGD in terms of group fairness, while maintaining comparable predictive accuracy. Our results highlight the role of adaptive updates as a crucial yet overlooked mechanism for promoting fair outcomes.","authors":["Mojtaba Kolahdouzi","Hatice Gunes","Ali Etemad"],"url":"https://arxiv.org/abs/2504.14882"}
{"created":"2025-04-22","title":"Memory-Augmented Dual-Decoder Networks for Multi-Class Unsupervised Anomaly Detection","abstract":"Recent advances in unsupervised anomaly detection (UAD) have shifted from single-class to multi-class scenarios. In such complex contexts, the increasing pattern diversity has brought two challenges to reconstruction-based approaches: (1) over-generalization: anomalies that are subtle or share compositional similarities with normal patterns may be reconstructed with high fidelity, making them difficult to distinguish from normal instances; and (2) insufficient normality reconstruction: complex normal features, such as intricate textures or fine-grained structures, may not be faithfully reconstructed due to the model's limited representational capacity, resulting in false positives. Existing methods typically focus on addressing the former, which unintentionally exacerbate the latter, resulting in inadequate representation of intricate normal patterns. To concurrently address these two challenges, we propose a Memory-augmented Dual-Decoder Networks (MDD-Net). This network includes two critical components: a Dual-Decoder Reverse Distillation Network (DRD-Net) and a Class-aware Memory Module (CMM). Specifically, the DRD-Net incorporates a restoration decoder designed to recover normal features from synthetic abnormal inputs and an identity decoder to reconstruct features that maintain the anomalous semantics. By exploiting the discrepancy between features produced by two decoders, our approach refines anomaly scores beyond the conventional encoder-decoder comparison paradigm, effectively reducing false positives and enhancing localization accuracy. Furthermore, the CMM explicitly encodes and preserves class-specific normal prototypes, actively steering the network away from anomaly reconstruction. Comprehensive experimental results across several benchmarks demonstrate the superior performance of our MDD-Net framework over current SoTA approaches in multi-class UAD tasks.","authors":["Jingyu Xing","Chenwei Tang","Tao Wang","Rong Xiao","Wei Ju","Ji-Zhe Zhou","Liangli Zhen","Jiancheng Lv"],"url":"https://arxiv.org/abs/2504.14884"}
{"created":"2025-04-22","title":"Zero Day Malware Detection with Alpha: Fast DBI with Transformer Models for Real World Application","abstract":"The effectiveness of an AI model in accurately classifying novel malware hinges on the quality of the features it is trained on, which in turn depends on the effectiveness of the analysis tool used. Peekaboo, a Dynamic Binary Instrumentation (DBI) tool, defeats malware evasion techniques to capture authentic behavior at the Assembly (ASM) instruction level. This behavior exhibits patterns consistent with Zipf's law, a distribution commonly seen in natural languages, making Transformer models particularly effective for binary classification tasks. We introduce Alpha, a framework for zero day malware detection that leverages Transformer models and ASM language. Alpha is trained on malware and benign software data collected through Peekaboo, enabling it to identify entirely new samples with exceptional accuracy. Alpha eliminates any common functions from the test samples that are in the training dataset. This forces the model to rely on contextual patterns and novel ASM instruction combinations to detect malicious behavior, rather than memorizing familiar features. By combining the strengths of DBI, ASM analysis, and Transformer architectures, Alpha offers a powerful approach to proactively addressing the evolving threat of malware. Alpha demonstrates perfect accuracy for Ransomware, Worms and APTs with flawless classification for both malicious and benign samples. The results highlight the model's exceptional performance in detecting truly new malware samples.","authors":["Matthew Gaber","Mohiuddin Ahmed","Helge Janicke"],"url":"https://arxiv.org/abs/2504.14886"}
{"created":"2025-04-22","title":"WMKA-Net: A Weighted Multi-Kernel Attention NetworkMethod for Retinal Vessel Segmentation","abstract":"We propose a novel retinal vessel segmentation network, the Weighted Multi-Kernel Attention Network (WMKA-Net), which aims to address the issues of insufficient multiscale feature capture, loss of contextual information, and noise sensitivity in retinal vessel segmentation. WMKA-Net significantly improves the segmentation performance of small vessels and low-contrast regions by integrating several innovative components, including the MultiKernelFeature Fusion Module (MKDC), the Progressive Feature Weighting Fusion Strategy (UDFF), and the Attention Mechanism Module (AttentionBlock). The MKDC module employs multiscale parallel convolutional kernels to extract vessel characteristics, thereby enhancing the ability to capture complex vascular structures. The UDFF strategy optimizes the transmission of feature information by weighted fusion of high- and low-level features. The AttentionBlock highlights key regions and suppresses noise interference through the attention mechanism. Experimental results demonstrate that WMKA-Net achieves excellent segmentation performance in multiple public datasets, particularly in segmentation of small vessels and processing of pathological regions. This work provides a robust and efficient new method for segmentation of the retinal vessel.","authors":["Xinran Xu","Yuliang Ma","Sifu Cai"],"url":"https://arxiv.org/abs/2504.14888"}
{"created":"2025-04-22","title":"Latent Bayesian Optimization via Autoregressive Normalizing Flows","abstract":"Bayesian Optimization (BO) has been recognized for its effectiveness in optimizing expensive and complex objective functions. Recent advancements in Latent Bayesian Optimization (LBO) have shown promise by integrating generative models such as variational autoencoders (VAEs) to manage the complexity of high-dimensional and structured data spaces. However, existing LBO approaches often suffer from the value discrepancy problem, which arises from the reconstruction gap between input and latent spaces. This value discrepancy problem propagates errors throughout the optimization process, leading to suboptimal outcomes. To address this issue, we propose a Normalizing Flow-based Bayesian Optimization (NF-BO), which utilizes normalizing flow as a generative model to establish one-to-one encoding function from the input space to the latent space, along with its left-inverse decoding function, eliminating the reconstruction gap. Specifically, we introduce SeqFlow, an autoregressive normalizing flow for sequence data. In addition, we develop a new candidate sampling strategy that dynamically adjusts the exploration probability for each token based on its importance. Through extensive experiments, our NF-BO method demonstrates superior performance in molecule generation tasks, significantly outperforming both traditional and recent LBO approaches.","authors":["Seunghun Lee","Jinyoung Park","Jaewon Chu","Minseo Yoon","Hyunwoo J. Kim"],"url":"https://arxiv.org/abs/2504.14889"}
{"created":"2025-04-22","title":"Retrieval Augmented Generation Evaluation in the Era of Large Language Models: A Comprehensive Survey","abstract":"Recent advancements in Retrieval-Augmented Generation (RAG) have revolutionized natural language processing by integrating Large Language Models (LLMs) with external information retrieval, enabling accurate, up-to-date, and verifiable text generation across diverse applications. However, evaluating RAG systems presents unique challenges due to their hybrid architecture that combines retrieval and generation components, as well as their dependence on dynamic knowledge sources in the LLM era. In response, this paper provides a comprehensive survey of RAG evaluation methods and frameworks, systematically reviewing traditional and emerging evaluation approaches, for system performance, factual accuracy, safety, and computational efficiency in the LLM era. We also compile and categorize the RAG-specific datasets and evaluation frameworks, conducting a meta-analysis of evaluation practices in high-impact RAG research. To the best of our knowledge, this work represents the most comprehensive survey for RAG evaluation, bridging traditional and LLM-driven methods, and serves as a critical resource for advancing RAG development.","authors":["Aoran Gan","Hao Yu","Kai Zhang","Qi Liu","Wenyu Yan","Zhenya Huang","Shiwei Tong","Guoping Hu"],"url":"https://arxiv.org/abs/2504.14891"}
{"created":"2025-04-22","title":"Hardware-based Heterogeneous Memory Management for Large Language Model Inference","abstract":"A large language model (LLM) is one of the most important emerging machine learning applications nowadays. However, due to its huge model size and runtime increase of the memory footprint, LLM inferences suffer from the lack of memory capacity in conventional systems consisting of multiple GPUs with a modest amount of high bandwidth memory. Moreover, since LLM contains many bandwidthintensive kernels, only focusing on the memory capacity without considering the bandwidth incurs a serious performance degradation. To handle such conflicting memory capacity and bandwidth demands in a cost-effective way, this study investigates the potential of heterogeneous memory systems, proposing H2M2. It uses an asymmetric memory architecture consisting of capacity-centric and bandwidthcentric memory with computation units attached to each memory device. With the asymmetric memory, we first analyze the effect of kernel-memory mapping for the asymmetric memory. Second, we propose a dynamic runtime algorithm that finds a mapping solution considering the characteristics of LLM operations and the change of footprint during LLM inference. Third, we advocate the need for memory abstraction for the efficient management of the asymmetric memory. H2M2 outperforms the conventional homogeneous memory system with LPDDR by 1.46x, 1.55x, and 2.94x speedup in GPT3-175B, Chinchilla-70B, and Llama2-70B, respectively.","authors":["Soojin Hwang","Jungwoo Kim","Sanghyeon Lee","Hongbeen Kim","Jaehyuk Huh"],"url":"https://arxiv.org/abs/2504.14893"}
{"created":"2025-04-22","title":"Never too Cocky to Cooperate: An FIM and RL-based USV-AUV Collaborative System for Underwater Tasks in Extreme Sea Conditions","abstract":"This paper develops a novel unmanned surface vehicle (USV)-autonomous underwater vehicle (AUV) collaborative system designed to enhance underwater task performance in extreme sea conditions. The system integrates a dual strategy: (1) high-precision multi-AUV localization enabled by Fisher information matrix-optimized USV path planning, and (2) reinforcement learning-based cooperative planning and control method for multi-AUV task execution. Extensive experimental evaluations in the underwater data collection task demonstrate the system's operational feasibility, with quantitative results showing significant performance improvements over baseline methods. The proposed system exhibits robust coordination capabilities between USV and AUVs while maintaining stability in extreme sea conditions. To facilitate reproducibility and community advancement, we provide an open-source simulation toolkit available at: https://github.com/360ZMEM/USV-AUV-colab .","authors":["Jingzehua Xu","Guanwen Xie","Jiwei Tang","Yimian Ding","Weiyi Liu","Shuai Zhang","Yi Li"],"url":"https://arxiv.org/abs/2504.14894"}
{"created":"2025-04-22","title":"Physics-Aware Compression of Plasma Distribution Functions with GPU-Accelerated Gaussian Mixture Models","abstract":"Data compression is a critical technology for large-scale plasma simulations. Storing complete particle information requires Terabyte-scale data storage, and analysis requires ad-hoc scalable post-processing tools. We propose a physics-aware in-situ compression method using Gaussian Mixture Models (GMMs) to approximate electron and ion velocity distribution functions with a number of Gaussian components. This GMM-based method allows us to capture plasma features such as mean velocity and temperature, and it enables us to identify heating processes and generate beams. We first construct a histogram to reduce computational overhead and apply GPU-accelerated, in-situ GMM fitting within \\texttt{iPIC3D}, a large-scale implicit Particle-in-Cell simulator, ensuring real-time compression. The compressed representation is stored using the \\texttt{ADIOS 2} library, thus optimizing the I/O process. The GPU and histogramming implementation provides a significant speed-up with respect to GMM on particles (both in time and required memory at run-time), enabling real-time compression. Compared to algorithms like SZ, MGARD, and BLOSC2, our GMM-based method has a physics-based approach, retaining the physical interpretation of plasma phenomena such as beam formation, acceleration, and heating mechanisms. Our GMM algorithm achieves a compression ratio of up to $10^4$, requiring a processing time comparable to, or even lower than, standard compression engines.","authors":["Andong Hu","Luca Pennati","Ivy Peng","Stefano Markidis"],"url":"https://arxiv.org/abs/2504.14897"}
{"created":"2025-04-22","title":"Uni3C: Unifying Precisely 3D-Enhanced Camera and Human Motion Controls for Video Generation","abstract":"Camera and human motion controls have been extensively studied for video generation, but existing approaches typically address them separately, suffering from limited data with high-quality annotations for both aspects. To overcome this, we present Uni3C, a unified 3D-enhanced framework for precise control of both camera and human motion in video generation. Uni3C includes two key contributions. First, we propose a plug-and-play control module trained with a frozen video generative backbone, PCDController, which utilizes unprojected point clouds from monocular depth to achieve accurate camera control. By leveraging the strong 3D priors of point clouds and the powerful capacities of video foundational models, PCDController shows impressive generalization, performing well regardless of whether the inference backbone is frozen or fine-tuned. This flexibility enables different modules of Uni3C to be trained in specific domains, i.e., either camera control or human motion control, reducing the dependency on jointly annotated data. Second, we propose a jointly aligned 3D world guidance for the inference phase that seamlessly integrates both scenic point clouds and SMPL-X characters to unify the control signals for camera and human motion, respectively. Extensive experiments confirm that PCDController enjoys strong robustness in driving camera motion for fine-tuned backbones of video generation. Uni3C substantially outperforms competitors in both camera controllability and human motion quality. Additionally, we collect tailored validation sets featuring challenging camera movements and human actions to validate the effectiveness of our method.","authors":["Chenjie Cao","Jingkai Zhou","Shikai Li","Jingyun Liang","Chaohui Yu","Fan Wang","Xiangyang Xue","Yanwei Fu"],"url":"https://arxiv.org/abs/2504.14899"}
{"created":"2025-04-22","title":"Distributed Time-Varying Gaussian Regression via Kalman Filtering","abstract":"We consider the problem of learning time-varying functions in a distributed fashion, where agents collect local information to collaboratively achieve a shared estimate. This task is particularly relevant in control applications, whenever real-time and robust estimation of dynamic cost/reward functions in safety critical settings has to be performed. In this paper, we,adopt a finite-dimensional approximation of a Gaussian Process, corresponding to a Bayesian linear regression in an appropriate feature space, and propose a new algorithm, DistKP, to track the time-varying coefficients via a distributed Kalman filter. The proposed method works for arbitrary kernels and under weaker assumptions on the time-evolution of the function to learn compared to the literature. We validate our results using a simulation example in which a fleet of Unmanned Aerial Vehicles (UAVs) learns a dynamically changing wind field.","authors":["Nicola Taddei","Riccardo Maggioni","Jaap Eising","Giulia De Pasquale","Florian Dorfler"],"url":"https://arxiv.org/abs/2504.14900"}
{"created":"2025-04-22","title":"ColBERT-serve: Efficient Multi-Stage Memory-Mapped Scoring","abstract":"We study serving retrieval models, specifically late interaction models like ColBERT, to many concurrent users at once and under a small budget, in which the index may not fit in memory. We present ColBERT-serve, a novel serving system that applies a memory-mapping strategy to the ColBERT index, reducing RAM usage by 90% and permitting its deployment on cheap servers, and incorporates a multi-stage architecture with hybrid scoring, reducing ColBERT's query latency and supporting many concurrent queries in parallel.","authors":["Kaili Huang","Thejas Venkatesh","Uma Dingankar","Antonio Mallia","Daniel Campos","Jian Jiao","Christopher Potts","Matei Zaharia","Kwabena Boahen","Omar Khattab","Saarthak Sarup","Keshav Santhanam"],"url":"https://arxiv.org/abs/2504.14903"}
{"created":"2025-04-22","title":"VLM as Policy: Common-Law Content Moderation Framework for Short Video Platform","abstract":"Exponentially growing short video platforms (SVPs) face significant challenges in moderating content detrimental to users' mental health, particularly for minors. The dissemination of such content on SVPs can lead to catastrophic societal consequences. Although substantial efforts have been dedicated to moderating such content, existing methods suffer from critical limitations: (1) Manual review is prone to human bias and incurs high operational costs. (2) Automated methods, though efficient, lack nuanced content understanding, resulting in lower accuracy. (3) Industrial moderation regulations struggle to adapt to rapidly evolving trends due to long update cycles. In this paper, we annotate the first SVP content moderation benchmark with authentic user/reviewer feedback to fill the absence of benchmark in this field. Then we evaluate various methods on the benchmark to verify the existence of the aforementioned limitations. We further propose our common-law content moderation framework named KuaiMod to address these challenges. KuaiMod consists of three components: training data construction, offline adaptation, and online deployment & refinement. Leveraging large vision language model (VLM) and Chain-of-Thought (CoT) reasoning, KuaiMod adequately models video toxicity based on sparse user feedback and fosters dynamic moderation policy with rapid update speed and high accuracy. Offline experiments and large-scale online A/B test demonstrates the superiority of KuaiMod: KuaiMod achieves the best moderation performance on our benchmark. The deployment of KuaiMod reduces the user reporting rate by 20% and its application in video recommendation increases both Daily Active User (DAU) and APP Usage Time (AUT) on several Kuaishou scenarios. We have open-sourced our benchmark at https://kuaimod.github.io.","authors":["Xingyu Lu","Tianke Zhang","Chang Meng","Xiaobei Wang","Jinpeng Wang","YiFan Zhang","Shisong Tang","Changyi Liu","Haojie Ding","Kaiyu Jiang","Kaiyu Tang","Bin Wen","Hai-Tao Zheng","Fan Yang","Tingting Gao","Di Zhang","Kun Gai"],"url":"https://arxiv.org/abs/2504.14904"}
{"created":"2025-04-22","title":"CRAVE: A Conflicting Reasoning Approach for Explainable Claim Verification Using LLMs","abstract":"The rapid spread of misinformation, driven by digital media and AI-generated content, has made automatic claim verification essential. Traditional methods, which depend on expert-annotated evidence, are labor-intensive and not scalable. Although recent automated systems have improved, they still struggle with complex claims that require nuanced reasoning. To address this, we propose CRAVE, a Conflicting Reasoning Approach for explainable claim VErification, that verify the complex claims based on the conflicting rationales reasoned by large language models (LLMs). Specifically, CRAVE introduces a three-module framework. Ambiguity Elimination enchanced Evidence Retrieval module performs ambiguity elimination and entity-based search to gather relevant evidence related to claim verification from external sources like Wikipedia. Conflicting Perspective Reasoning and Preliminary Judgment module with LLMs adopts LLMs to reason rationales with conflicting stances about claim verification from retrieved evidence across four dimensions, i.e., direct evidence, semantic relationships, linguistic patterns, and logical reasoning and make a preliminary judgment. Finally, Small Language Model (SLM) based Judge module is fine-tuned to make use of preliminary judgment from LLMs to assess the confidence of the conflicting rationales and make a final authenticity judgment. This methodology allows CRAVE to capture subtle inconsistencies in complex claims, improving both the accuracy and transparency of claim verification. Extensive experiments on two public claim verification datasets demonstrate that our CRAVE model achieves much better performance than state-of-the-art methods and exhibits a superior capacity for finding relevant evidence and explaining the model predictions. The code is provided at https://github.com/8zym/CRAVE.","authors":["Yingming Zheng","Xiaoliang Liu","Peng Wu","Li Pan"],"url":"https://arxiv.org/abs/2504.14905"}
{"created":"2025-04-22","title":"Dynamic Graph-Like Learning with Contrastive Clustering on Temporally-Factored Ship Motion Data for Imbalanced Sea State Estimation in Autonomous Vessel","abstract":"Accurate sea state estimation is crucial for the real-time control and future state prediction of autonomous vessels. However, traditional methods struggle with challenges such as data imbalance and feature redundancy in ship motion data, limiting their effectiveness. To address these challenges, we propose the Temporal-Graph Contrastive Clustering Sea State Estimator (TGC-SSE), a novel deep learning model that combines three key components: a time dimension factorization module to reduce data redundancy, a dynamic graph-like learning module to capture complex variable interactions, and a contrastive clustering loss function to effectively manage class imbalance. Our experiments demonstrate that TGC-SSE significantly outperforms existing methods across 14 public datasets, achieving the highest accuracy in 9 datasets, with a 20.79% improvement over EDI. Furthermore, in the field of sea state estimation, TGC-SSE surpasses five benchmark methods and seven deep learning models. Ablation studies confirm the effectiveness of each module, demonstrating their respective roles in enhancing overall model performance. Overall, TGC-SSE not only improves the accuracy of sea state estimation but also exhibits strong generalization capabilities, providing reliable support for autonomous vessel operations.","authors":["Kexin Wang","Mengna Liu","Xu Cheng","Fan Shi","Shanshan Qi","Shengyong Chen"],"url":"https://arxiv.org/abs/2504.14907"}
{"created":"2025-04-22","title":"Guidelines for External Disturbance Factors in the Use of OCR in Real-World Environments","abstract":"The performance of OCR has improved with the evolution of AI technology. As OCR continues to broaden its range of applications, the increased likelihood of interference introduced by various usage environments can prevent it from achieving its inherent performance. This results in reduced recognition accuracy under certain conditions, and makes the quality control of recognition devices more challenging. Therefore, to ensure that users can properly utilize OCR, we compiled the real-world external disturbance factors that cause performance degradation, along with the resulting image degradation phenomena, into an external disturbance factor table and, by also indicating how to make use of it, organized them into guidelines.","authors":["Kenji Iwata (National Institute of Advanced Industrial Science and Technology)","Eiki Ishidera (NEC Corporation)","Toshifumi Yamaai (Ricoh Co.","Ltd)","Yutaka Satoh (National Institute of Advanced Industrial Science and Technology)","Hiroshi Tanaka (Fujitsu Limited)","Katsuhiko Takahashi (NEC Corporation)","Akio Furuhata (Toshiba Digital Solutions Corporation)","Yoshihisa Tanabe","Hiroshi Matsumura"],"url":"https://arxiv.org/abs/2504.14913"}
{"created":"2025-04-22","title":"POLYRAG: Integrating Polyviews into Retrieval-Augmented Generation for Medical Applications","abstract":"Large language models (LLMs) have become a disruptive force in the industry, introducing unprecedented capabilities in natural language processing, logical reasoning and so on. However, the challenges of knowledge updates and hallucination issues have limited the application of LLMs in medical scenarios, where retrieval-augmented generation (RAG) can offer significant assistance. Nevertheless, existing retrieve-then-read approaches generally digest the retrieved documents, without considering the timeliness, authoritativeness and commonality of retrieval. We argue that these approaches can be suboptimal, especially in real-world applications where information from different sources might conflict with each other and even information from the same source in different time scale might be different, and totally relying on this would deteriorate the performance of RAG approaches. We propose PolyRAG that carefully incorporate judges from different perspectives and finally integrate the polyviews for retrieval augmented generation in medical applications. Due to the scarcity of real-world benchmarks for evaluation, to bridge the gap we propose PolyEVAL, a benchmark consists of queries and documents collected from real-world medical scenarios (including medical policy, hospital & doctor inquiry and healthcare) with multiple tagging (e.g., timeliness, authoritativeness) on them. Extensive experiments and analysis on PolyEVAL have demonstrated the superiority of PolyRAG.","authors":["Chunjing Gan","Dan Yang","Binbin Hu","Ziqi Liu","Yue Shen","Zhiqiang Zhang","Jian Wang","Jun Zhou"],"url":"https://arxiv.org/abs/2504.14917"}
{"created":"2025-04-22","title":"GenCLIP: Generalizing CLIP Prompts for Zero-shot Anomaly Detection","abstract":"Zero-shot anomaly detection (ZSAD) aims to identify anomalies in unseen categories by leveraging CLIP's zero-shot capabilities to match text prompts with visual features. A key challenge in ZSAD is learning general prompts stably and utilizing them effectively, while maintaining both generalizability and category specificity. Although general prompts have been explored in prior works, achieving their stable optimization and effective deployment remains a significant challenge. In this work, we propose GenCLIP, a novel framework that learns and leverages general prompts more effectively through multi-layer prompting and dual-branch inference. Multi-layer prompting integrates category-specific visual cues from different CLIP layers, enriching general prompts with more comprehensive and robust feature representations. By combining general prompts with multi-layer visual features, our method further enhances its generalization capability. To balance specificity and generalization, we introduce a dual-branch inference strategy, where a vision-enhanced branch captures fine-grained category-specific features, while a query-only branch prioritizes generalization. The complementary outputs from both branches improve the stability and reliability of anomaly detection across unseen categories. Additionally, we propose an adaptive text prompt filtering mechanism, which removes irrelevant or atypical class names not encountered during CLIP's training, ensuring that only meaningful textual inputs contribute to the final vision-language alignment.","authors":["Donghyeong Kim","Chaewon Park","Suhwan Cho","Hyeonjeong Lim","Minseok Kang","Jungho Lee","Sangyoun Lee"],"url":"https://arxiv.org/abs/2504.14919"}
{"created":"2025-04-22","title":"DyFo: A Training-Free Dynamic Focus Visual Search for Enhancing LMMs in Fine-Grained Visual Understanding","abstract":"Humans can effortlessly locate desired objects in cluttered environments, relying on a cognitive mechanism known as visual search to efficiently filter out irrelevant information and focus on task-related regions. Inspired by this process, we propose Dyfo (Dynamic Focus), a training-free dynamic focusing visual search method that enhances fine-grained visual understanding in large multimodal models (LMMs). Unlike existing approaches which require additional modules or data collection, Dyfo leverages a bidirectional interaction between LMMs and visual experts, using a Monte Carlo Tree Search (MCTS) algorithm to simulate human-like focus adjustments. This enables LMMs to focus on key visual regions while filtering out irrelevant content, without introducing additional training caused by vocabulary expansion or the integration of specialized localization modules. Experimental results demonstrate that Dyfo significantly improves fine-grained visual understanding and reduces hallucination issues in LMMs, achieving superior performance across both fixed and dynamic resolution models. The code is available at https://github.com/PKU-ICST-MIPL/DyFo_CVPR2025","authors":["Geng Li","Jinglin Xu","Yunzhen Zhao","Yuxin Peng"],"url":"https://arxiv.org/abs/2504.14920"}
{"created":"2025-04-22","title":"Fast Adversarial Training with Weak-to-Strong Spatial-Temporal Consistency in the Frequency Domain on Videos","abstract":"Adversarial Training (AT) has been shown to significantly enhance adversarial robustness via a min-max optimization approach. However, its effectiveness in video recognition tasks is hampered by two main challenges. First, fast adversarial training for video models remains largely unexplored, which severely impedes its practical applications. Specifically, most video adversarial training methods are computationally costly, with long training times and high expenses. Second, existing methods struggle with the trade-off between clean accuracy and adversarial robustness. To address these challenges, we introduce Video Fast Adversarial Training with Weak-to-Strong consistency (VFAT-WS), the first fast adversarial training method for video data. Specifically, VFAT-WS incorporates the following key designs: First, it integrates a straightforward yet effective temporal frequency augmentation (TF-AUG), and its spatial-temporal enhanced form STF-AUG, along with a single-step PGD attack to boost training efficiency and robustness. Second, it devises a weak-to-strong spatial-temporal consistency regularization, which seamlessly integrates the simpler TF-AUG and the more complex STF-AUG. Leveraging the consistency regularization, it steers the learning process from simple to complex augmentations. Both of them work together to achieve a better trade-off between clean accuracy and robustness. Extensive experiments on UCF-101 and HMDB-51 with both CNN and Transformer-based models demonstrate that VFAT-WS achieves great improvements in adversarial robustness and corruption robustness, while accelerating training by nearly 490%.","authors":["Songping Wang","Hanqing Liu","Yueming Lyu","Xiantao Hu","Ziwen He","Wei Wang","Caifeng Shan","Liang Wang"],"url":"https://arxiv.org/abs/2504.14921"}
{"created":"2025-04-22","title":"Multimodal Non-Semantic Feature Fusion for Predicting Segment Access Frequency in Lecture Archives","abstract":"This study proposes a multimodal neural network-based approach to predict segment access frequency in lecture archives. These archives, widely used as supplementary resources in modern education, often consist of long, unedited recordings that make it difficult to keep students engaged. Captured directly from face-to-face lectures without post-processing, they lack visual appeal. Meanwhile, the increasing volume of recorded material renders manual editing and annotation impractical. Automatically detecting high-engagement segments is thus crucial for improving accessibility and maintaining learning effectiveness. Our research focuses on real classroom lecture archives, characterized by unedited footage, no additional hardware (e.g., eye-tracking), and limited student numbers. We approximate student engagement using segment access frequency as a proxy. Our model integrates multimodal features from teachers' actions (via OpenPose and optical flow), audio spectrograms, and slide page progression. These features are deliberately chosen for their non-semantic nature, making the approach applicable regardless of lecture language. Experiments show that our best model achieves a Pearson correlation of 0.5143 in 7-fold cross-validation and 69.32 percent average accuracy in a downstream three-class classification task. The results, obtained with high computational efficiency and a small dataset, demonstrate the practical feasibility of our system in real-world educational contexts.","authors":["Ruozhu Sheng","Jinghong Li","Shinobu Hasegawa"],"url":"https://arxiv.org/abs/2504.14927"}
{"created":"2025-04-22","title":"EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework","abstract":"Large language models (LLMs) increasingly serve as educational tools, yet evaluating their teaching capabilities remains challenging due to the resource-intensive, context-dependent, and methodologically complex nature of teacher-student interactions. We introduce EducationQ, a multi-agent dialogue framework that efficiently assesses teaching capabilities through simulated dynamic educational scenarios, featuring specialized agents for teaching, learning, and evaluation. Testing 14 LLMs across major AI Organizations (OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13 disciplines and 10 difficulty levels reveals that teaching effectiveness does not correlate linearly with model scale or general reasoning capabilities - with some smaller open-source models outperforming larger commercial counterparts in teaching contexts. This finding highlights a critical gap in current evaluations that prioritize knowledge recall over interactive pedagogy. Our mixed-methods evaluation, combining quantitative metrics with qualitative analysis and expert case studies, identifies distinct pedagogical strengths employed by top-performing models (e.g., sophisticated questioning strategies, adaptive feedback mechanisms). Human expert evaluations show 78% agreement with our automated qualitative analysis of effective teaching behaviors, validating our methodology. EducationQ demonstrates that LLMs-as-teachers require specialized optimization beyond simple scaling, suggesting next-generation educational AI prioritize targeted enhancement of specific pedagogical effectiveness.","authors":["Yao Shi","Rongkeng Liang","Yong Xu"],"url":"https://arxiv.org/abs/2504.14928"}
{"created":"2025-04-22","title":"Kernel-learning parameter prediction and evaluation in algebraic multigrid method for several PDEs","abstract":"This paper explores the application of kernel learning methods for parameter prediction and evaluation in the Algebraic Multigrid Method (AMG), focusing on several Partial Differential Equation (PDE) problems. AMG is an efficient iterative solver for large-scale sparse linear systems, particularly those derived from elliptic and parabolic PDE discretizations. However, its performance heavily relies on numerous parameters, which are often set empirically and are highly sensitive to AMG's effectiveness. Traditional parameter optimization methods are either computationally expensive or lack theoretical support. To address this, we propose a Gaussian Process Regression (GPR)-based strategy to optimize AMG parameters and introduce evaluation metrics to assess their effectiveness. Trained on small-scale datasets, GPR predicts nearly optimal parameters, bypassing the time-consuming parameter sweeping process. We also use kernel learning techniques to build a kernel function library and determine the optimal kernel function through linear combination, enhancing prediction accuracy. In numerical experiments, we tested typical PDEs such as the constant-coefficient Poisson equation, variable-coefficient Poisson equation, diffusion equation, and Helmholtz equation. Results show that GPR-predicted parameters match grid search results in iteration counts while significantly reducing computational time. A comprehensive analysis using metrics like mean squared error, prediction interval coverage, and Bayesian information criterion confirms GPR's efficiency and reliability. These findings validate GPR's effectiveness in AMG parameter optimization and provide theoretical support for AMG's practical application.","authors":["Juan Zhang","Junyue Luo","Fangfang Zhang","Xiaoqiang Yue"],"url":"https://arxiv.org/abs/2504.14930"}
{"created":"2025-04-22","title":"TWIG: Two-Step Image Generation using Segmentation Masks in Diffusion Models","abstract":"In today's age of social media and marketing, copyright issues can be a major roadblock to the free sharing of images. Generative AI models have made it possible to create high-quality images, but concerns about copyright infringement are a hindrance to their abundant use. As these models use data from training images to generate new ones, it is often a daunting task to ensure they do not violate intellectual property rights. Some AI models have even been noted to directly copy copyrighted images, a problem often referred to as source copying. Traditional copyright protection measures such as watermarks and metadata have also proven to be futile in this regard. To address this issue, we propose a novel two-step image generation model inspired by the conditional diffusion model. The first step involves creating an image segmentation mask for some prompt-based generated images. This mask embodies the shape of the image. Thereafter, the diffusion model is asked to generate the image anew while avoiding the shape in question. This approach shows a decrease in structural similarity from the training image, i.e. we are able to avoid the source copying problem using this approach without expensive retraining of the model or user-centered prompt generation techniques. This makes our approach the most computationally inexpensive approach to avoiding both copyright infringement and source copying for diffusion model-based image generation.","authors":["Mazharul Islam Rakib","Showrin Rahman","Joyanta Jyoti Mondal","Xi Xiao","David Lewis","Alessandra Mileo","Meem Arafat Manab"],"url":"https://arxiv.org/abs/2504.14933"}
{"created":"2025-04-22","title":"Giving AI a voice: how does AI think it should be treated?","abstract":"With the astounding progress in (generative) artificial intelligence (AI), there has been significant public discourse regarding regulation and ethics of the technology. Is it sufficient when humans discuss this with other humans? Or, given that AI is increasingly becoming a viable source of inspiration for people (and let alone the hypothetical possibility that the technology may at some point become \"artificial general intelligence\" and/or develop consciousness), should AI not join the discourse? There are new questions and angles that AI brings to the table that we might not have considered before - so let us make the key subject of this book an active participant. This chapter therefore includes a brief human-AI conversation on the topic of AI rights and ethics.","authors":["Maria Fay","Frederik F. Fl\\\"other"],"url":"https://arxiv.org/abs/2504.14936"}
{"created":"2025-04-22","title":"Causal DAG Summarization (Full Version)","abstract":"Causal inference aids researchers in discovering cause-and-effect relationships, leading to scientific insights. Accurate causal estimation requires identifying confounding variables to avoid false discoveries. Pearl's causal model uses causal DAGs to identify confounding variables, but incorrect DAGs can lead to unreliable causal conclusions. However, for high dimensional data, the causal DAGs are often complex beyond human verifiability. Graph summarization is a logical next step, but current methods for general-purpose graph summarization are inadequate for causal DAG summarization. This paper addresses these challenges by proposing a causal graph summarization objective that balances graph simplification for better understanding while retaining essential causal information for reliable inference. We develop an efficient greedy algorithm and show that summary causal DAGs can be directly used for inference and are more robust to misspecification of assumptions, enhancing robustness for causal inference. Experimenting with six real-life datasets, we compared our algorithm to three existing solutions, showing its effectiveness in handling high-dimensional data and its ability to generate summary DAGs that ensure both reliable causal inference and robustness against misspecifications.","authors":["Anna Zeng","Michael Cafarella","Batya Kenig","Markos Markakis","Brit Youngmann","Babak Salimi"],"url":"https://arxiv.org/abs/2504.14937"}
{"created":"2025-04-22","title":"Full Discretization of Stochastic Semilinear Schr\\\"{o}dinger equation driven by multiplicative Wiener noise","abstract":"In this article, we have analyzed the full discretization of the Stochastic semilinear Schr\\\"{o}dinger equation in a bounded convex polygonal domain driven by multiplicative Wiener noise. We use the finite element method for spatial discretization and the stochastic trigonometric method for time discretization and derive a strong convergence rate with respect to both parameters (temporal and spatial). Numerical experiments have also been performed to support theoretical bounds.","authors":["Suprio Bhar","Mrinmay Biswas","Mangala Prasad"],"url":"https://arxiv.org/abs/2504.14939"}
{"created":"2025-04-22","title":"Vector Embedding, Retrieval-Augmented Generation, CPU-NPU Collaboration, Heterogeneous Computing","abstract":"Retrieval-Augmented Generation is a technology that enhances large language models by integrating information retrieval. In the industry, inference services based on LLMs are highly sensitive to cost-performance ratio, prompting the need for improving hardware resource utilization in the inference service. Specifically, vector embedding and retrieval processes take up to 20% of the total latency. Therefore, optimizing the utilization of computational resources in vector embeddings is crucial for enhancing the cost-performance ratio of inference processes, which in turn boosts their product competitiveness.In this paper, we analyze the deployment costs of vector embedding technology in inference services, propose a theoretical formula, and determine through the mathematical expression that increasing the capacity to process concurrent queries is the key to reducing the deployment costs of vector embeddings. Therefore, in this paper, we focus on improving the product's capability to process concurrent queries. To optimize concurrency without sacrificing performance, we have designed a queue manager that adeptly offloads CPU peak queries. This manager utilizes a linear regression model to ascertain the optimal queue depths, a critical parameter that significantly influences the efficacy of the system. We further develop a system named WindVE that uses a CPU-NPU heterogeneous architecture to offload peak concurrent queries, which leverages the performance differences between the two processors to effectively manage traffic surges. Through experiments, we compare WindVE to the state-of-the-art vector embedding framework FlagEmbedding, and achieve a concurrency level up to 22.3% higher than the scheme without offloading.","authors":["Jinqi Huang","Xuebing Yu","Yi Xiong","Wenjie Huang","Entong Li","Li Zeng","Xin chen"],"url":"https://arxiv.org/abs/2504.14941"}
{"created":"2025-04-22","title":"Learning to Reason under Off-Policy Guidance","abstract":"Recent advances in large reasoning models (LRMs) demonstrate that sophisticated behaviors such as multi-step reasoning and self-reflection can emerge via reinforcement learning (RL) with simple rule-based rewards. However, existing zero-RL approaches are inherently ``on-policy'', limiting learning to a model's own outputs and failing to acquire reasoning abilities beyond its initial capabilities. We introduce LUFFY (Learning to reason Under oFF-policY guidance), a framework that augments zero-RL with off-policy reasoning traces. LUFFY dynamically balances imitation and exploration by combining off-policy demonstrations with on-policy rollouts during training. Notably, we propose policy shaping via regularized importance sampling to avoid superficial and rigid imitation during mixed-policy training. Remarkably, LUFFY achieves an over +7.0 average gain across six math benchmarks and an advantage of over +6.2 points in out-of-distribution tasks. It also substantially surpasses imitation-based supervised fine-tuning (SFT), particularly in generalization. Analysis shows LUFFY not only imitates effectively but also explores beyond demonstrations, offering a scalable path to train generalizable reasoning models with off-policy guidance.","authors":["Jianhao Yan","Yafu Li","Zican Hu","Zhi Wang","Ganqu Cui","Xiaoye Qu","Yu Cheng","Yue Zhang"],"url":"https://arxiv.org/abs/2504.14945"}
{"created":"2025-04-22","title":"Symmetry-Preserving Architecture for Multi-NUMA Environments (SPANE): A Deep Reinforcement Learning Approach for Dynamic VM Scheduling","abstract":"As cloud computing continues to evolve, the adoption of multi-NUMA (Non-Uniform Memory Access) architecture by cloud service providers has introduced new challenges in virtual machine (VM) scheduling. To address these challenges and more accurately reflect the complexities faced by modern cloud environments, we introduce the Dynamic VM Allocation problem in Multi-NUMA PM (DVAMP). We formally define both offline and online versions of DVAMP as mixed-integer linear programming problems, providing a rigorous mathematical foundation for analysis. A tight performance bound for greedy online algorithms is derived, offering insights into the worst-case optimality gap as a function of the number of physical machines and VM lifetime variability. To address the challenges posed by DVAMP, we propose SPANE (Symmetry-Preserving Architecture for Multi-NUMA Environments), a novel deep reinforcement learning approach that exploits the problem's inherent symmetries. SPANE produces invariant results under arbitrary permutations of physical machine states, enhancing learning efficiency and solution quality. Extensive experiments conducted on the Huawei-East-1 dataset demonstrate that SPANE outperforms existing baselines, reducing average VM wait time by 45%. Our work contributes to the field of cloud resource management by providing both theoretical insights and practical solutions for VM scheduling in multi-NUMA environments, addressing a critical gap in the literature and offering improved performance for real-world cloud systems.","authors":["Tin Ping Chan","Yunlong Cheng","Yizhan Zhu","Xiaofeng Gao","Guihai Chen"],"url":"https://arxiv.org/abs/2504.14946"}
{"created":"2025-04-22","title":"Generative Semantic Communications: Principles and Practices","abstract":"Semantic communication leverages artificial intelligence (AI) technologies to extract semantic information from data for efficient transmission, theraby significantly reducing communication cost. With the evolution towards artificial general intelligence (AGI), the increasing demands for AGI services pose new challenges to semantic communication. In response, we propose a new paradigm for AGI-driven communications, called generative semantic communication (GSC), which utilizes advanced AI technologies such as foundation models and generative models. We first describe the basic concept of GSC and its difference from existing semantic communications, and then introduce a general framework of GSC, followed by two case studies to verify the advantages of GSC in AGI-driven applications. Finally, open challenges and new research directions are discussed to stimulate this line of research and pave the way for practical applications.","authors":["Xiaojun Yuan","Haoming Ma","Yinuo Huang","Zhoufan Hua","Yong Zuo","Zhi Ding"],"url":"https://arxiv.org/abs/2504.14947"}
{"created":"2025-04-22","title":"Mechanism Design for Auctions with Externalities on Budgets","abstract":"This paper studies mechanism design for auctions with externalities on budgets, a novel setting where the budgets that bidders commit are adjusted due to the externality of the competitors' allocation outcomes-a departure from traditional auctions with fixed budgets. This setting is motivated by real-world scenarios, for example, participants may increase their budgets in response to competitors' obtained items. We initially propose a general framework with homogeneous externalities to capture the interdependence between budget updates and allocation, formalized through a budget response function that links each bidder's effective budget to the amount of items won by others.","authors":["Yusen Zheng","Yukun Cheng","Chenyang Xu","Xiaotie Deng"],"url":"https://arxiv.org/abs/2504.14948"}
{"created":"2025-04-22","title":"PIV-FlowDiffuser:Transfer-learning-based denoising diffusion models for PIV","abstract":"Deep learning algorithms have significantly reduced the computational time and improved the spatial resolution of particle image velocimetry~(PIV). However, the models trained on synthetic datasets might have a degraded performance on practical particle images due to domain gaps. As a result, special residual patterns are often observed for the vector fields of deep learning-based estimators. To reduce the special noise step-by-step, we employ a denoising diffusion model~(FlowDiffuser) for PIV analysis. And the data-hungry iterative denoising diffusion model is trained via a transfer learning strategy, resulting in our PIV-FlowDiffuser method. Specifically, (1) pre-training a FlowDiffuser model with multiple optical flow datasets of the computer vision community, such as Sintel, KITTI, etc; (2) fine-tuning the pre-trained model on synthetic PIV datasets. Note that the PIV images are upsampled by a factor of two to resolve the small-scale turbulent flow structures. The visualized results indicate that our PIV-FlowDiffuser effectively suppresses the noise patterns. Therefore, the denoising diffusion model reduces the average end-point error~($AEE$) by 59.4% over RAFT256-PIV baseline on the classic Cai's dataset. Besides, PIV-FlowDiffuser exhibits enhanced generalization performance on unseen particle images due to transfer learning. Overall, this study highlights the transfer-learning-based denoising diffusion models for PIV. And a detailed implementation is recommended for interested readers in the repository https://github.com/Zhu-Qianyu/PIV-FlowDiffuser.","authors":["Qianyu Zhu","Junjie Wang","Jeremiah Hu","Jia Ai","Yong Lee"],"url":"https://arxiv.org/abs/2504.14952"}
{"created":"2025-04-22","title":"Efficient Document Retrieval with G-Retriever","abstract":"Textual data question answering has gained significant attention due to its growing applicability. Recently, a novel approach leveraging the Retrieval-Augmented Generation (RAG) method was introduced, utilizing the Prize-Collecting Steiner Tree (PCST) optimization for sub-graph construction. However, this method focused solely on node attributes, leading to incomplete contextual understanding. In this paper, we propose an enhanced approach that replaces the PCST method with an attention-based sub-graph construction technique, enabling more efficient and context-aware retrieval. Additionally, we encode both node and edge attributes, leading to richer graph representations. Our method also incorporates an improved projection layer and multi-head attention pooling for better alignment with Large Language Models (LLMs). Experimental evaluations on the WebQSP dataset demonstrate that our approach is competitive and achieves marginally better results compared to the original method, underscoring its potential for more accurate question answering.","authors":["Manthankumar Solanki"],"url":"https://arxiv.org/abs/2504.14955"}
{"created":"2025-04-22","title":"Considerations on the Design of Transceivers for Ambient Internet of Things","abstract":"The Ambient IoT (A-IoT) will introduce trillions of connections and enable low-cost battery-less devices. The A-IoT nodes can achieve low cost ($\\sim \\$ 0.1$ like RFID tag), sub-1mW average power consumption, $\\leq 10$ kbps data rates, maintenance-free working for decades, cm-scale size, cm-scale size, and supporting applications like supply chain and smart agriculture. The transceiver challenges in A-IoT focus on sub-mW receivers and crystal-less clock generation. The paper proposes an \"approximate low-IF\" receiver and \"carrier-auxiliary IF feedback\" LO synthesizer architecture for Type-B/C A-IoT devices, which tracks the RF carrier frequency and eliminates external crystals. The proposed receiver and LO generator are implemented using 55nm CMOS technology. After locking the LO calibration loop, the receiver sensitivity is better than -88 dBm. The proposed receiver architecture will promote \"zero power\" devices for ubiquitous IoT connectivity, bridging digital and physical worlds.","authors":["Yuxiao Zhao","Zhen Shen","Shiyu Li","Jing Feng","Hao Min"],"url":"https://arxiv.org/abs/2504.14956"}
{"created":"2025-04-22","title":"ScaleGuard: Rational and Scalable Configuration Privacy Protection with Topology Expansion","abstract":"As networks grow in size and complexity, safeguarding sensitive data while sharing configuration files is critical for network management and research. Existing anonymization tools primarily hide fields like IP addresses or AS numbers to mitigate direct data exposure. However, they often lack mechanisms to preserve privacy around network scale, an increasingly sensitive aspect that can reveal organizational size or resource distribution. We propose ScaleGuard, which preserves network functional equivalence while adding fake routers and hosts to conceal network scale, and generating complete router configurations that resemble the originals. Our system introduces a graph embedding-based expansion method and k-degree mapping anonymity, reducing unnecessary topology modifications when adversaries only know the original degree sequence. For routing repair, ScaleGuard designs a network repair framework combining SMT and iterative methods, delivering stable performance under randomized link costs and complex cross-protocol routing. Experiment results show that ScaleGuard expands network scale effectively, providing consistent anonymization of topology, scale, and routing, while achieving strong topological rationality, configuration fidelity, and repairing efficiency.","authors":["Qianye Wang","Yuejie Wang","Yongting Chen","Guyue Liu"],"url":"https://arxiv.org/abs/2504.14959"}
{"created":"2025-04-22","title":"MoE Parallel Folding: Heterogeneous Parallelism Mappings for Efficient Large-Scale MoE Model Training with Megatron Core","abstract":"Mixture of Experts (MoE) models enhance neural network scalability by dynamically selecting relevant experts per input token, enabling larger model sizes while maintaining manageable computation costs. However, efficient training of large-scale MoE models across thousands of GPUs presents significant challenges due to limitations in existing parallelism strategies. We introduce an end-to-end training framework for large-scale MoE models that utilizes five-dimensional hybrid parallelism: Tensor Parallelism, Expert Parallelism, Context Parallelism, Data Parallelism, and Pipeline Parallelism. Central to our approach is MoE Parallel Folding, a novel strategy that decouples the parallelization of attention and MoE layers in Transformer models, allowing each layer type to adopt optimal parallel configurations. Additionally, we develop a flexible token-level dispatcher that supports both token-dropping and token-dropless MoE training across all five dimensions of parallelism. This dispatcher accommodates dynamic tensor shapes and coordinates different parallelism schemes for Attention and MoE layers, facilitating complex parallelism implementations. Our experiments demonstrate significant improvements in training efficiency and scalability. We achieve up to 49.3% Model Flops Utilization (MFU) for the Mixtral 8x22B model and 39.0% MFU for the Qwen2-57B-A14B model on H100 GPUs, outperforming existing methods. The framework scales efficiently up to 1,024 GPUs and maintains high performance with sequence lengths up to 128K tokens, validating its effectiveness for large-scale MoE model training. The code is available in Megatron-Core.","authors":["Dennis Liu","Zijie Yan","Xin Yao","Tong Liu","Vijay Korthikanti","Evan Wu","Shiqing Fan","Gao Deng","Hongxiao Bai","Ashwath Aithal","Michael Andersch","Mohammad Shoeybi","Jiajie Yao","Chandler Zhou","David Wu","Xipeng Li","June Yang"],"url":"https://arxiv.org/abs/2504.14960"}
{"created":"2025-04-22","title":"Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in Multiparty Dialogues","abstract":"Speaker identification using voice recordings leverages unique acoustic features, but this approach fails when only textual data is available. Few approaches have attempted to tackle the problem of identifying speakers solely from text, and the existing ones have primarily relied on traditional methods. In this work, we explore the use of fuzzy fingerprints from large pre-trained models to improve text-based speaker identification. We integrate speaker-specific tokens and context-aware modeling, demonstrating that conversational context significantly boosts accuracy, reaching 70.6% on the Friends dataset and 67.7% on the Big Bang Theory dataset. Additionally, we show that fuzzy fingerprints can approximate full fine-tuning performance with fewer hidden units, offering improved interpretability. Finally, we analyze ambiguous utterances and propose a mechanism to detect speaker-agnostic lines. Our findings highlight key challenges and provide insights for future improvements in text-based speaker identification.","authors":["Rui Ribeiro","Lu\\'isa Coheur","Joao P. Carvalho"],"url":"https://arxiv.org/abs/2504.14963"}
{"created":"2025-04-22","title":"Evaluating Code Generation of LLMs in Advanced Computer Science Problems","abstract":"Large Language Models (LLMs), such as GitHub Copilot and ChatGPT have become popular among programming students. Students use LLMs to assist them in programming courses, including generating source code. Previous work has evaluated the ability of LLMs in solving introductory-course programming assignments. The results have shown that LLMs are highly effective in generating code for introductory Computer Science (CS) courses. However, there is a gap in research on evaluating LLMs' ability to generate code that solves advanced programming assignments. In this work, we evaluate the ability of four LLM tools to solve programming assignments from advanced CS courses in three popular programming languages, Java, Python, and C. We manually select 12 problems, three problems from introductory courses as the baseline and nine programming assignments from second- and third-year CS courses. To evaluate the LLM-generated code, we generate a test suite of 1000 test cases per problem and analyze the program output. Our evaluation shows that although LLMs are highly effective in generating source code for introductory programming courses, solving advanced programming assignments is more challenging. Nonetheless, in many cases, LLMs identify the base problem and provide partial solutions that may be useful to CS students. Furthermore, our results may provide useful guidance for teachers of advanced programming courses on how to design programming assignments.","authors":["Emir Catir","Robin Claesson","Rodothea Myrsini Tsoupidi"],"url":"https://arxiv.org/abs/2504.14964"}
{"created":"2025-04-22","title":"A Security Framework for General Blockchain Layer 2 Protocols","abstract":"Layer 2 (L2) solutions are the cornerstone of blockchain scalability, enabling high-throughput and low-cost interactions by shifting execution off-chain while maintaining security through interactions with the underlying ledger. Despite their common goals, the principal L2 paradigms -- payment channels, rollups, and sidechains -- differ substantially in architecture and assumptions, making it difficult to comparatively analyze their security and trade-offs.","authors":["Zeta Avarikioti","Matteo Maffei","Yuheng Wang"],"url":"https://arxiv.org/abs/2504.14965"}
{"created":"2025-04-22","title":"SLO-Aware Scheduling for Large Language Model Inferences","abstract":"Large language models (LLMs) have revolutionized applications such as code completion, chatbots, and online classification. To elevate user experiences, service level objectives (SLOs) serve as crucial benchmarks for assessing inference services capabilities. In practice, an inference service processes multiple types of tasks, each with its own distinct SLO. To ensure satisfactory user experiences, each request's distinct SLOs should be considered in scheduling. However, existing designs lack this consideration, leading to insufficient hardware utility and suboptimal performance.","authors":["Jinqi Huang","Yi Xiong","Xuebing Yu","Wenjie Huang","Entong Li","Li Zeng","Xin Chen"],"url":"https://arxiv.org/abs/2504.14966"}
{"created":"2025-04-22","title":"3D Gaussian Head Avatars with Expressive Dynamic Appearances by Compact Tensorial Representations","abstract":"Recent studies have combined 3D Gaussian and 3D Morphable Models (3DMM) to construct high-quality 3D head avatars. In this line of research, existing methods either fail to capture the dynamic textures or incur significant overhead in terms of runtime speed or storage space. To this end, we propose a novel method that addresses all the aforementioned demands. In specific, we introduce an expressive and compact representation that encodes texture-related attributes of the 3D Gaussians in the tensorial format. We store appearance of neutral expression in static tri-planes, and represents dynamic texture details for different expressions using lightweight 1D feature lines, which are then decoded into opacity offset relative to the neutral face. We further propose adaptive truncated opacity penalty and class-balanced sampling to improve generalization across different expressions. Experiments show this design enables accurate face dynamic details capturing while maintains real-time rendering and significantly reduces storage costs, thus broadening the applicability to more scenarios.","authors":["Yating Wang","Xuan Wang","Ran Yi","Yanbo Fan","Jichen Hu","Jingcheng Zhu","Lizhuang Ma"],"url":"https://arxiv.org/abs/2504.14967"}
{"created":"2025-04-22","title":"Evaluating LLMs on Chinese Topic Constructions: A Research Proposal Inspired by Tian et al. (2024)","abstract":"This paper proposes a framework for evaluating large language models (LLMs) on Chinese topic constructions, focusing on their sensitivity to island constraints. Drawing inspiration from Tian et al. (2024), we outline an experimental design for testing LLMs' grammatical knowledge of Mandarin syntax. While no experiments have been conducted yet, this proposal aims to provide a foundation for future studies and invites feedback on the methodology.","authors":["Xiaodong Yang"],"url":"https://arxiv.org/abs/2504.14969"}
{"created":"2025-04-22","title":"Cyc3D: Fine-grained Controllable 3D Generation via Cycle Consistency Regularization","abstract":"Despite the remarkable progress of 3D generation, achieving controllability, i.e., ensuring consistency between generated 3D content and input conditions like edge and depth, remains a significant challenge. Existing methods often struggle to maintain accurate alignment, leading to noticeable discrepancies. To address this issue, we propose \\name{}, a new framework that enhances controllable 3D generation by explicitly encouraging cyclic consistency between the second-order 3D content, generated based on extracted signals from the first-order generation, and its original input controls. Specifically, we employ an efficient feed-forward backbone that can generate a 3D object from an input condition and a text prompt. Given an initial viewpoint and a control signal, a novel view is rendered from the generated 3D content, from which the extracted condition is used to regenerate the 3D content. This re-generated output is then rendered back to the initial viewpoint, followed by another round of control signal extraction, forming a cyclic process with two consistency constraints. \\emph{View consistency} ensures coherence between the two generated 3D objects, measured by semantic similarity to accommodate generative diversity. \\emph{Condition consistency} aligns the final extracted signal with the original input control, preserving structural or geometric details throughout the process. Extensive experiments on popular benchmarks demonstrate that \\name{} significantly improves controllability, especially for fine-grained details, outperforming existing methods across various conditions (e.g., +14.17\\% PSNR for edge, +6.26\\% PSNR for sketch).","authors":["Hongbin Xu","Chaohui Yu","Feng Xiao","Jiazheng Xing","Hai Ci","Weitao Chen","Ming Li"],"url":"https://arxiv.org/abs/2504.14975"}
{"created":"2025-04-22","title":"RealisDance-DiT: Simple yet Strong Baseline towards Controllable Character Animation in the Wild","abstract":"Controllable character animation remains a challenging problem, particularly in handling rare poses, stylized characters, character-object interactions, complex illumination, and dynamic scenes. To tackle these issues, prior work has largely focused on injecting pose and appearance guidance via elaborate bypass networks, but often struggles to generalize to open-world scenarios. In this paper, we propose a new perspective that, as long as the foundation model is powerful enough, straightforward model modifications with flexible fine-tuning strategies can largely address the above challenges, taking a step towards controllable character animation in the wild. Specifically, we introduce RealisDance-DiT, built upon the Wan-2.1 video foundation model. Our sufficient analysis reveals that the widely adopted Reference Net design is suboptimal for large-scale DiT models. Instead, we demonstrate that minimal modifications to the foundation model architecture yield a surprisingly strong baseline. We further propose the low-noise warmup and \"large batches and small iterations\" strategies to accelerate model convergence during fine-tuning while maximally preserving the priors of the foundation model. In addition, we introduce a new test dataset that captures diverse real-world challenges, complementing existing benchmarks such as TikTok dataset and UBC fashion video dataset, to comprehensively evaluate the proposed method. Extensive experiments show that RealisDance-DiT outperforms existing methods by a large margin.","authors":["Jingkai Zhou","Yifan Wu","Shikai Li","Min Wei","Chao Fan","Weihua Chen","Wei Jiang","Fan Wang"],"url":"https://arxiv.org/abs/2504.14977"}
{"created":"2025-04-22","title":"aiXamine: LLM Safety and Security Simplified","abstract":"Evaluating Large Language Models (LLMs) for safety and security remains a complex task, often requiring users to navigate a fragmented landscape of ad hoc benchmarks, datasets, metrics, and reporting formats. To address this challenge, we present aiXamine, a comprehensive black-box evaluation platform for LLM safety and security. aiXamine integrates over 40 tests (i.e., benchmarks) organized into eight key services targeting specific dimensions of safety and security: adversarial robustness, code security, fairness and bias, hallucination, model and data privacy, out-of-distribution (OOD) robustness, over-refusal, and safety alignment. The platform aggregates the evaluation results into a single detailed report per model, providing a detailed breakdown of model performance, test examples, and rich visualizations. We used aiXamine to assess over 50 publicly available and proprietary LLMs, conducting over 2K examinations. Our findings reveal notable vulnerabilities in leading models, including susceptibility to adversarial attacks in OpenAI's GPT-4o, biased outputs in xAI's Grok-3, and privacy weaknesses in Google's Gemini 2.0. Additionally, we observe that open-source models can match or exceed proprietary models in specific services such as safety alignment, fairness and bias, and OOD robustness. Finally, we identify trade-offs between distillation strategies, model size, training methods, and architectural choices.","authors":["Fatih Deniz","Dorde Popovic","Yazan Boshmaf","Euisuh Jeong","Minhaj Ahmad","Sanjay Chawla","Issa Khalil"],"url":"https://arxiv.org/abs/2504.14985"}
{"created":"2025-04-22","title":"Benchmarking Large Vision-Language Models on Fine-Grained Image Tasks: A Comprehensive Evaluation","abstract":"Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated remarkable multimodal perception capabilities, garnering significant attention. While numerous evaluation studies have emerged, assessing LVLMs both holistically and on specialized tasks, fine-grained image tasks-fundamental to computer vision-remain largely unexplored. To fill this gap, we introduce a comprehensive fine-grained evaluation benchmark, i.e., FG-BMK, comprising 3.49 million questions and 3.32 million images. Our evaluation systematically examines LVLMs from both human-oriented and machine-oriented perspectives, focusing on their semantic recognition and fine-grained feature representation capabilities. Through extensive experiments on eight representative LVLMs/VLMs, we uncover key findings regarding the influence of training paradigms, modality alignment, perturbation susceptibility, and fine-grained category reasoning on task performance. This work provides critical insights into the limitations of current LVLMs and offers guidance for future data construction and model design in the development of more advanced LVLMs. Our code is open-source and available at https://github.com/SEU-VIPGroup/FG-BMK.","authors":["Hong-Tao Yu","Xiu-Shen Wei","Yuxin Peng","Serge Belongie"],"url":"https://arxiv.org/abs/2504.14988"}
{"created":"2025-04-22","title":"Dynamic Legged Ball Manipulation on Rugged Terrains with Hierarchical Reinforcement Learning","abstract":"Advancing the dynamic loco-manipulation capabilities of quadruped robots in complex terrains is crucial for performing diverse tasks. Specifically, dynamic ball manipulation in rugged environments presents two key challenges. The first is coordinating distinct motion modalities to integrate terrain traversal and ball control seamlessly. The second is overcoming sparse rewards in end-to-end deep reinforcement learning, which impedes efficient policy convergence. To address these challenges, we propose a hierarchical reinforcement learning framework. A high-level policy, informed by proprioceptive data and ball position, adaptively switches between pre-trained low-level skills such as ball dribbling and rough terrain navigation. We further propose Dynamic Skill-Focused Policy Optimization to suppress gradients from inactive skills and enhance critical skill learning. Both simulation and real-world experiments validate that our methods outperform baseline approaches in dynamic ball manipulation across rugged terrains, highlighting its effectiveness in challenging environments. Videos are on our website: dribble-hrl.github.io.","authors":["Dongjie Zhu","Zhuo Yang","Tianhang Wu","Luzhou Ge","Xuesong Li","Qi Liu","Xiang Li"],"url":"https://arxiv.org/abs/2504.14989"}
{"created":"2025-04-22","title":"Normalization of Quaternionic Polynomials in Coordinate-Free Quaternionic Variables in Conjugate-Alternating Order","abstract":"Quaternionic polynomials occur naturally in applications of quaternions in science and engineering, and normalization of quaternionic polynomials is a basic manipulation. Once a Groebner basis is certified for the defining ideal I of the quaternionic polynomial algebra, the normal form of a quaternionic polynomial can be computed by routine top reduction with respect to the Groebner basis. In the literature, a Groebner basis under the conjugate-alternating order of quaternionic variables was conjectured for I in 2013, but no readable and convincing proof was found.","authors":["Hongbo Li","Zhengyang Wang","Yue Liu","Lei Huang","Changpeng Shao"],"url":"https://arxiv.org/abs/2504.14990"}
{"created":"2025-04-22","title":"Understanding Accuracy-Fairness Trade-offs in Re-ranking through Elasticity in Economics","abstract":"Fairness is an increasingly important factor in re-ranking tasks. Prior work has identified a trade-off between ranking accuracy and item fairness. However, the underlying mechanisms are still not fully understood. An analogy can be drawn between re-ranking and the dynamics of economic transactions. The accuracy-fairness trade-off parallels the coupling of the commodity tax transfer process. Fairness considerations in re-ranking, similar to a commodity tax on suppliers, ultimately translate into a cost passed on to consumers. Analogously, item-side fairness constraints result in a decline in user-side accuracy. In economics, the extent to which commodity tax on the supplier (item fairness) transfers to commodity tax on users (accuracy loss) is formalized using the notion of elasticity. The re-ranking fairness-accuracy trade-off is similarly governed by the elasticity of utility between item groups. This insight underscores the limitations of current fair re-ranking evaluations, which often rely solely on a single fairness metric, hindering comprehensive assessment of fair re-ranking algorithms. Centered around the concept of elasticity, this work presents two significant contributions. We introduce the Elastic Fairness Curve (EF-Curve) as an evaluation framework. This framework enables a comparative analysis of algorithm performance across different elasticity levels, facilitating the selection of the most suitable approach. Furthermore, we propose ElasticRank, a fair re-ranking algorithm that employs elasticity calculations to adjust inter-item distances within a curved space. Experiments on three widely used ranking datasets demonstrate its effectiveness and efficiency.","authors":["Chen Xu","Jujia Zhao","Wenjie Wang","Liang Pang","Jun Xu","Tat-Seng Chua","Maarten de Rijke"],"url":"https://arxiv.org/abs/2504.14991"}
{"created":"2025-04-22","title":"Efficient Pretraining Length Scaling","abstract":"Recent advances in large language models have demonstrated the effectiveness of length scaling during post-training, yet its potential in pre-training remains underexplored. We present the Parallel Hidden Decoding Transformer (\\textit{PHD}-Transformer), a novel framework that enables efficient length scaling during pre-training while maintaining inference efficiency. \\textit{PHD}-Transformer achieves this through an innovative KV cache management strategy that distinguishes between original tokens and hidden decoding tokens. By retaining only the KV cache of original tokens for long-range dependencies while immediately discarding hidden decoding tokens after use, our approach maintains the same KV cache size as the vanilla transformer while enabling effective length scaling. To further enhance performance, we introduce two optimized variants: \\textit{PHD-SWA} employs sliding window attention to preserve local dependencies, while \\textit{PHD-CSWA} implements chunk-wise sliding window attention to eliminate linear growth in pre-filling time. Extensive experiments demonstrate consistent improvements across multiple benchmarks.","authors":["Bohong Wu","Shen Yan","Sijun Zhang","Jianqiao Lu","Yutao Zeng","Ya Wang","Xun Zhou"],"url":"https://arxiv.org/abs/2504.14992"}
{"created":"2025-04-22","title":"Dual Utilization of Perturbation for Stream Data Publication under Local Differential Privacy","abstract":"Stream data from real-time distributed systems such as IoT, tele-health, and crowdsourcing has become an important data source. However, the collection and analysis of user-generated stream data raise privacy concerns due to the potential exposure of sensitive information. To address these concerns, local differential privacy (LDP) has emerged as a promising standard. Nevertheless, applying LDP to stream data presents significant challenges, as stream data often involves a large or even infinite number of values. Allocating a given privacy budget across these data points would introduce overwhelming LDP noise to the original stream data.","authors":["Rong Du","Qingqing Ye","Yaxin Xiao","Liantong Yu","Yue Fu","Haibo Hu"],"url":"https://arxiv.org/abs/2504.14993"}
{"created":"2025-04-22","title":"Learning Compositional Transferability of Time Series for Source-Free Domain Adaptation","abstract":"Domain adaptation is challenging for time series classification due to the highly dynamic nature. This study tackles the most difficult subtask when both target labels and source data are inaccessible, namely, source-free domain adaptation. To reuse the classification backbone pre-trained on source data, time series reconstruction is a sound solution that aligns target and source time series by minimizing the reconstruction errors of both. However, simply fine-tuning the source pre-trained reconstruction model on target data may lose the learnt priori, and it struggles to accommodate domain varying temporal patterns in a single encoder-decoder. Therefore, this paper tries to disentangle the composition of domain transferability by using a compositional architecture for time series reconstruction. Here, the preceding component is a U-net frozen since pre-trained, the output of which during adaptation is the initial reconstruction of a given target time series, acting as a coarse step to prompt the subsequent finer adaptation. The following pipeline for finer adaptation includes two parallel branches: The source replay branch using a residual link to preserve the output of U-net, and the offset compensation branch that applies an additional autoencoder (AE) to further warp U-net's output. By deploying a learnable factor on either branch to scale their composition in the final output of reconstruction, the data transferability is disentangled and the learnt reconstructive capability from source data is retained. During inference, aside from the batch-level optimization in the training, we search at test time stability-aware rescaling of source replay branch to tolerate instance-wise variation. The experimental results show that such compositional architecture of time series reconstruction leads to SOTA performance on 3 widely used benchmarks.","authors":["Hankang Sun (Fudan University)","Guiming Li (Fudan University)","Su Yang (Fudan University)","Baoqi Li (Chinese Academy of Sciences","Institute of Acoustics)"],"url":"https://arxiv.org/abs/2504.14994"}
{"created":"2025-04-22","title":"Distributed Cognition for AI-supported Remote Operations: Challenges and Research Directions","abstract":"This paper investigates the impact of artificial intelligence integration on remote operations, emphasising its influence on both distributed and team cognition. As remote operations increasingly rely on digital interfaces, sensors, and networked communication, AI-driven systems transform decision-making processes across domains such as air traffic control, industrial automation, and intelligent ports. However, the integration of AI introduces significant challenges, including the reconfiguration of human-AI team cognition, the need for adaptive AI memory that aligns with human distributed cognition, and the design of AI fallback operators to maintain continuity during communication disruptions. Drawing on theories of distributed and team cognition, we analyse how cognitive overload, loss of situational awareness, and impaired team coordination may arise in AI-supported environments. Based on real-world intelligent port scenarios, we propose research directions that aim to safeguard human reasoning and enhance collaborative decision-making in AI-augmented remote operations.","authors":["Rune M{\\o}berg Jacobsen","Joel Wester","Helena B{\\o}jer Djern{\\ae}s","Niels van Berkel"],"url":"https://arxiv.org/abs/2504.14996"}
{"created":"2025-04-22","title":"Weakly Approximating Knapsack in Subquadratic Time","abstract":"We consider the classic Knapsack problem. Let $t$ and $\\mathrm{OPT}$ be the capacity and the optimal value, respectively. If one seeks a solution with total profit at least $\\mathrm{OPT}/(1 + \\varepsilon)$ and total weight at most $t$, then Knapsack can be solved in $\\tilde{O}(n + (\\frac{1}{\\varepsilon})^2)$ time [Chen, Lian, Mao, and Zhang '24][Mao '24]. This running time is the best possible (up to a logarithmic factor), assuming that $(\\min,+)$-convolution cannot be solved in truly subquadratic time [K\\\"unnemann, Paturi, and Schneider '17][Cygan, Mucha, W\\k{e}grzycki, and W{\\l}odarczyk '19]. The same upper and lower bounds hold if one seeks a solution with total profit at least $\\mathrm{OPT}$ and total weight at most $(1 + \\varepsilon)t$. Therefore, it is natural to ask the following question.","authors":["Lin Chen","Jiayi Lian","Yuchen Mao","Guochuan Zhang"],"url":"https://arxiv.org/abs/2504.15001"}
{"created":"2025-04-22","title":"NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and Enhancement: KwaiSR Dataset and Study","abstract":"In this work, we build the first benchmark dataset for short-form UGC Image Super-resolution in the wild, termed KwaiSR, intending to advance the research on developing image super-resolution algorithms for short-form UGC platforms. This dataset is collected from the Kwai Platform, which is composed of two parts, i.e., synthetic and wild parts. Among them, the synthetic dataset, including 1,900 image pairs, is produced by simulating the degradation following the distribution of real-world low-quality short-form UGC images, aiming to provide the ground truth for training and objective comparison in the validation/testing. The wild dataset contains low-quality images collected directly from the Kwai Platform, which are filtered using the quality assessment method KVQ from the Kwai Platform. As a result, the KwaiSR dataset contains 1800 synthetic image pairs and 1900 wild images, which are divided into training, validation, and testing parts with a ratio of 8:1:1. Based on the KwaiSR dataset, we organize the NTIRE 2025 challenge on a second short-form UGC Video quality assessment and enhancement, which attracts lots of researchers to develop the algorithm for it. The results of this competition have revealed that our KwaiSR dataset is pretty challenging for existing Image SR methods, which is expected to lead to a new direction in the image super-resolution field. The dataset can be found from https://lixinustc.github.io/NTIRE2025-KVQE-KwaSR-KVQ.github.io/.","authors":["Xin Li","Xijun Wang","Bingchen Li","Kun Yuan","Yizhen Shao","Suhang Yao","Ming Sun","Chao Zhou","Radu Timofte","Zhibo Chen"],"url":"https://arxiv.org/abs/2504.15003"}
{"created":"2025-04-22","title":"Sum-Rate Maximization for NOMA-Assisted Pinching-Antenna Systems","abstract":"In this letter, we investigate a non-orthogonal multiple access (NOMA) assisted downlink pinching-antenna system. Leveraging the ability of pinching antennas to flexibly adjust users' wireless channel conditions, we formulate an optimization problem to maximize the sum rate by optimizing both the users' power allocation coefficients and the positions of pinching antennas. The optimal power allocation coefficients are obtained in closed-form by using the Karush-Kuhn-Tucker (KKT) conditions. The optimization problem of pinching antenna placements is more challenging than the power allocation problem, and is solved by a bisection-based search algorithm. In particular, the algorithm first optimizes the antenna placements to create favorable channel disparities between users, followed by fine-tuning the antenna positions to ensure the phase alignment for users, thus maximizing the sum rate. Simulation results demonstrate that, compared to conventional-antenna systems, pinching antennas can significantly enhance the sum rate in NOMA scenarios, and the proposed bisection-based search algorithm can achieve a sum rate nearly equivalent to that of an exhaustive search.","authors":["Ziwu Zhou","Zheng Yang","Gaojie Chen","Zhiguo","Ding"],"url":"https://arxiv.org/abs/2504.15006"}
{"created":"2025-04-22","title":"Shifts in Doctors' Eye Movements Between Real and AI-Generated Medical Images","abstract":"Eye-tracking analysis plays a vital role in medical imaging, providing key insights into how radiologists visually interpret and diagnose clinical cases. In this work, we first analyze radiologists' attention and agreement by measuring the distribution of various eye-movement patterns, including saccades direction, amplitude, and their joint distribution. These metrics help uncover patterns in attention allocation and diagnostic strategies. Furthermore, we investigate whether and how doctors' gaze behavior shifts when viewing authentic (Real) versus deep-learning-generated (Fake) images. To achieve this, we examine fixation bias maps, focusing on first, last, short, and longest fixations independently, along with detailed saccades patterns, to quantify differences in gaze distribution and visual saliency between authentic and synthetic images.","authors":["David C Wong","Bin Wang","Gorkem Durak","Marouane Tliba","Mohamed Amine Kerkouri","Aladine Chetouani","Ahmet Enis Cetin","Cagdas Topel","Nicolo Gennaro","Camila Vendrami","Tugce Agirlar Trabzonlu","Amir Ali Rahsepar","Laetitia Perronne","Matthew Antalek","Onural Ozturk","Gokcan Okur","Andrew C. Gordon","Ayis Pyrros","Frank H Miller","Amir A Borhani","Hatice Savas","Eric M. Hart"],"url":"https://arxiv.org/abs/2504.15007"}
{"created":"2025-04-22","title":"Insert Anything: Image Insertion via In-Context Editing in DiT","abstract":"This work presents Insert Anything, a unified framework for reference-based image insertion that seamlessly integrates objects from reference images into target scenes under flexible, user-specified control guidance. Instead of training separate models for individual tasks, our approach is trained once on our new AnyInsertion dataset--comprising 120K prompt-image pairs covering diverse tasks such as person, object, and garment insertion--and effortlessly generalizes to a wide range of insertion scenarios. Such a challenging setting requires capturing both identity features and fine-grained details, while allowing versatile local adaptations in style, color, and texture. To this end, we propose to leverage the multimodal attention of the Diffusion Transformer (DiT) to support both mask- and text-guided editing. Furthermore, we introduce an in-context editing mechanism that treats the reference image as contextual information, employing two prompting strategies to harmonize the inserted elements with the target scene while faithfully preserving their distinctive features. Extensive experiments on AnyInsertion, DreamBooth, and VTON-HD benchmarks demonstrate that our method consistently outperforms existing alternatives, underscoring its great potential in real-world applications such as creative content generation, virtual try-on, and scene composition.","authors":["Wensong Song","Hong Jiang","Zongxing Yang","Ruijie Quan","Yi Yang"],"url":"https://arxiv.org/abs/2504.15009"}
{"created":"2025-04-22","title":"Stay Hungry, Stay Foolish: On the Extended Reading Articles Generation with LLMs","abstract":"The process of creating educational materials is both time-consuming and demanding for educators. This research explores the potential of Large Language Models (LLMs) to streamline this task by automating the generation of extended reading materials and relevant course suggestions. Using the TED-Ed Dig Deeper sections as an initial exploration, we investigate how supplementary articles can be enriched with contextual knowledge and connected to additional learning resources. Our method begins by generating extended articles from video transcripts, leveraging LLMs to include historical insights, cultural examples, and illustrative anecdotes. A recommendation system employing semantic similarity ranking identifies related courses, followed by an LLM-based refinement process to enhance relevance. The final articles are tailored to seamlessly integrate these recommendations, ensuring they remain cohesive and informative. Experimental evaluations demonstrate that our model produces high-quality content and accurate course suggestions, assessed through metrics such as Hit Rate, semantic similarity, and coherence. Our experimental analysis highlight the nuanced differences between the generated and existing materials, underscoring the model's capacity to offer more engaging and accessible learning experiences. This study showcases how LLMs can bridge the gap between core content and supplementary learning, providing students with additional recommended resources while also assisting teachers in designing educational materials.","authors":["Yow-Fu Liou","Yu-Chien Tang","An-Zi Yen"],"url":"https://arxiv.org/abs/2504.15013"}
{"created":"2025-04-22","title":"Is Intelligence the Right Direction in New OS Scheduling for Multiple Resources in Cloud Environments?","abstract":"Making it intelligent is a promising way in System/OS design. This paper proposes OSML+, a new ML-based resource scheduling mechanism for co-located cloud services. OSML+ intelligently schedules the cache and main memory bandwidth resources at the memory hierarchy and the computing core resources simultaneously. OSML+ uses a multi-model collaborative learning approach during its scheduling and thus can handle complicated cases, e.g., avoiding resource cliffs, sharing resources among applications, enabling different scheduling policies for applications with different priorities, etc. OSML+ can converge faster using ML models than previous studies. Moreover, OSML+ can automatically learn on the fly and handle dynamically changing workloads accordingly. Using transfer learning technologies, we show our design can work well across various cloud servers, including the latest off-the-shelf large-scale servers. Our experimental results show that OSML+ supports higher loads and meets QoS targets with lower overheads than previous studies.","authors":["Xinglei Dou","Lei Liu","Limin Xiao"],"url":"https://arxiv.org/abs/2504.15021"}
{"created":"2025-04-22","title":"LLMs as Data Annotators: How Close Are We to Human Performance","abstract":"In NLP, fine-tuning LLMs is effective for various applications but requires high-quality annotated data. However, manual annotation of data is labor-intensive, time-consuming, and costly. Therefore, LLMs are increasingly used to automate the process, often employing in-context learning (ICL) in which some examples related to the task are given in the prompt for better performance. However, manually selecting context examples can lead to inefficiencies and suboptimal model performance. This paper presents comprehensive experiments comparing several LLMs, considering different embedding models, across various datasets for the Named Entity Recognition (NER) task. The evaluation encompasses models with approximately $7$B and $70$B parameters, including both proprietary and non-proprietary models. Furthermore, leveraging the success of Retrieval-Augmented Generation (RAG), it also considers a method that addresses the limitations of ICL by automatically retrieving contextual examples, thereby enhancing performance. The results highlight the importance of selecting the appropriate LLM and embedding model, understanding the trade-offs between LLM sizes and desired performance, and the necessity to direct research efforts towards more challenging datasets.","authors":["Muhammad Uzair Ul Haq","Davide Rigoni","Alessandro Sperduti"],"url":"https://arxiv.org/abs/2504.15022"}
{"created":"2025-04-22","title":"Gaussian Shading++: Rethinking the Realistic Deployment Challenge of Performance-Lossless Image Watermark for Diffusion Models","abstract":"Ethical concerns surrounding copyright protection and inappropriate content generation pose challenges for the practical implementation of diffusion models. One effective solution involves watermarking the generated images. Existing methods primarily focus on ensuring that watermark embedding does not degrade the model performance. However, they often overlook critical challenges in real-world deployment scenarios, such as the complexity of watermark key management, user-defined generation parameters, and the difficulty of verification by arbitrary third parties. To address this issue, we propose Gaussian Shading++, a diffusion model watermarking method tailored for real-world deployment. We propose a double-channel design that leverages pseudorandom error-correcting codes to encode the random seed required for watermark pseudorandomization, achieving performance-lossless watermarking under a fixed watermark key and overcoming key management challenges. Additionally, we model the distortions introduced during generation and inversion as an additive white Gaussian noise channel and employ a novel soft decision decoding strategy during extraction, ensuring strong robustness even when generation parameters vary. To enable third-party verification, we incorporate public key signatures, which provide a certain level of resistance against forgery attacks even when model inversion capabilities are fully disclosed. Extensive experiments demonstrate that Gaussian Shading++ not only maintains performance losslessness but also outperforms existing methods in terms of robustness, making it a more practical solution for real-world deployment.","authors":["Zijin Yang","Xin Zhang","Kejiang Chen","Kai Zeng","Qiyi Yao","Han Fang","Weiming Zhang","Nenghai Yu"],"url":"https://arxiv.org/abs/2504.15026"}
{"created":"2025-04-22","title":"DistilQwen2.5: Industrial Practices of Training Distilled Open Lightweight Language Models","abstract":"Enhancing computational efficiency and reducing deployment costs for large language models (LLMs) have become critical challenges in various resource-constrained scenarios. In this work, we present DistilQwen2.5, a family of distilled, lightweight LLMs derived from the public Qwen2.5 models. These distilled models exhibit enhanced instruction-following capabilities compared to the original models based on a series of distillation techniques that incorporate knowledge from much larger LLMs. In our industrial practice, we first leverage powerful proprietary LLMs with varying capacities as multi-agent teachers to select, rewrite, and refine instruction-response pairs that are more suitable for student LLMs to learn. After standard fine-tuning, we further leverage a computationally efficient model fusion approach that enables student models to progressively integrate fine-grained hidden knowledge from their teachers. Experimental evaluations demonstrate that the distilled models possess significantly stronger capabilities than their original checkpoints. Additionally, we present use cases to illustrate the applications of our framework in real-world scenarios. To facilitate practical use, we have released all the DistilQwen2.5 models to the open-source community.","authors":["Chengyu Wang","Junbing Yan","Yuanhao Yue","Jun Huang"],"url":"https://arxiv.org/abs/2504.15027"}
{"created":"2025-04-22","title":"A Controllable Appearance Representation for Flexible Transfer and Editing","abstract":"We present a method that computes an interpretable representation of material appearance within a highly compact, disentangled latent space. This representation is learned in a self-supervised fashion using an adapted FactorVAE. We train our model with a carefully designed unlabeled dataset, avoiding possible biases induced by human-generated labels. Our model demonstrates strong disentanglement and interpretability by effectively encoding material appearance and illumination, despite the absence of explicit supervision. Then, we use our representation as guidance for training a lightweight IP-Adapter to condition a diffusion pipeline that transfers the appearance of one or more images onto a target geometry, and allows the user to further edit the resulting appearance. Our approach offers fine-grained control over the generated results: thanks to the well-structured compact latent space, users can intuitively manipulate attributes such as hue or glossiness in image space to achieve the desired final appearance.","authors":["Santiago Jimenez-Navarro","Julia Guerrero-Viu","Belen Masia"],"url":"https://arxiv.org/abs/2504.15028"}
{"created":"2025-04-22","title":"Energy-Efficient Irregular RIS-aided UAV-Assisted Optimization: A Deep Reinforcement Learning Approach","abstract":"Reconfigurable intelligent surfaces (RISs) enhance unmanned aerial vehicles (UAV)-assisted communication by extending coverage, improving efficiency, and enabling adaptive beamforming. This paper investigates a multiple-input single-output system where a base station (BS) communicates with multiple single-antenna users through a UAV-assisted RIS, dynamically adapting to user mobility to maintain seamless connectivity. To extend UAV-RIS operational time, we propose a hybrid energy-harvesting resource allocation (HERA) strategy that leverages the irregular RIS ON/OFF capability while adapting to BS-RIS and RIS-user channels. The HERA strategy dynamically allocates resources by integrating non-linear radio frequency energy harvesting (EH) based on the time-switching (TS) approach and renewable energy as a complementary source. A non-convex mixed-integer nonlinear programming problem is formulated to maximize EH efficiency while satisfying quality-of-service, power, and energy constraints under channel state information and hardware impairments. The optimization jointly considers BS transmit power, RIS phase shifts, TS factor, and RIS element selection as decision variables. To solve this problem, we introduce the energy-efficient deep deterministic policy gradient (EE-DDPG) algorithm. This deep reinforcement learning (DRL)-based approach integrates action clipping and softmax-weighted Q-value estimation to mitigate estimation errors. Simulation results demonstrate that the proposed HERA method significantly improves EH efficiency, reaching up to 81.5\\% and 73.2\\% in single-user and multi-user scenarios, respectively, contributing to extended UAV operational time. Additionally, the proposed EE-DDPG model outperforms existing DRL algorithms while maintaining practical computational complexity.","authors":["Mahmoud M. Salim","Khaled M. Rabie","Ali H. Muqaibel"],"url":"https://arxiv.org/abs/2504.15031"}
{"created":"2025-04-22","title":"DyST-XL: Dynamic Layout Planning and Content Control for Compositional Text-to-Video Generation","abstract":"Compositional text-to-video generation, which requires synthesizing dynamic scenes with multiple interacting entities and precise spatial-temporal relationships, remains a critical challenge for diffusion-based models. Existing methods struggle with layout discontinuity, entity identity drift, and implausible interaction dynamics due to unconstrained cross-attention mechanisms and inadequate physics-aware reasoning. To address these limitations, we propose DyST-XL, a \\textbf{training-free} framework that enhances off-the-shelf text-to-video models (e.g., CogVideoX-5B) through frame-aware control. DyST-XL integrates three key innovations: (1) A Dynamic Layout Planner that leverages large language models (LLMs) to parse input prompts into entity-attribute graphs and generates physics-aware keyframe layouts, with intermediate frames interpolated via trajectory optimization; (2) A Dual-Prompt Controlled Attention Mechanism that enforces localized text-video alignment through frame-aware attention masking, achieving the precise control over individual entities; and (3) An Entity-Consistency Constraint strategy that propagates first-frame feature embeddings to subsequent frames during denoising, preserving object identity without manual annotation. Experiments demonstrate that DyST-XL excels in compositional text-to-video generation, significantly improving performance on complex prompts and bridging a crucial gap in training-free video synthesis.","authors":["Weijie He","Mushui Liu","Yunlong Yu","Zhao Wang","Chao Wu"],"url":"https://arxiv.org/abs/2504.15032"}
{"created":"2025-04-22","title":"SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank Adaptation","abstract":"The accelerated advancement of speech generative models has given rise to security issues, including model infringement and unauthorized abuse of content. Although existing generative watermarking techniques have proposed corresponding solutions, most methods require substantial computational overhead and training costs. In addition, some methods have limitations in robustness when handling variable-length inputs. To tackle these challenges, we propose \\textsc{SOLIDO}, a novel generative watermarking method that integrates parameter-efficient fine-tuning with speech watermarking through low-rank adaptation (LoRA) for speech diffusion models. Concretely, the watermark encoder converts the watermark to align with the input of diffusion models. To achieve precise watermark extraction from variable-length inputs, the watermark decoder based on depthwise separable convolution is designed for watermark recovery. To further enhance speech generation performance and watermark extraction capability, we propose a speech-driven lightweight fine-tuning strategy, which reduces computational overhead through LoRA. Comprehensive experiments demonstrate that the proposed method ensures high-fidelity watermarked speech even at a large capacity of 2000 bps. Furthermore, against common individual and compound speech attacks, our SOLIDO achieves a maximum average extraction accuracy of 99.20\\% and 98.43\\%, respectively. It surpasses other state-of-the-art methods by nearly 23\\% in resisting time-stretching attacks.","authors":["Yue Li","Weizhi Liu","Dongdong Lin"],"url":"https://arxiv.org/abs/2504.15035"}
{"created":"2025-04-22","title":"Dynamic Robustness Verification Against Weak Memory (Extended Version)","abstract":"Dynamic race detection is a highly effective runtime verification technique for identifying data races by instrumenting and monitoring concurrent program runs. However, standard dynamic race detection is incompatible with practical weak memory models; the added instrumentation introduces extra synchronization, which masks weakly consistent behaviors and inherently misses certain data races. In response, we propose to dynamically verify program robustness-a property ensuring that a program exhibits only strongly consistent behaviors. Building on an existing static decision procedures, we develop an algorithm for dynamic robustness verification under a C11-style memory model. The algorithm is based on \"location clocks\", a variant of vector clocks used in standard race detection. It allows effective and easy-to-apply defense against weak memory on a per-program basis, which can be combined with race detection that assumes strong consistency. We implement our algorithm in a tool, called RSAN, and evaluate it across various settings. To our knowledge, this work is the first to propose and develop dynamic verification of robustness against weak memory models.","authors":["Roy Margalit","Michalis Kokologiannakis","Shachar Itzhaky","Ori Lahav"],"url":"https://arxiv.org/abs/2504.15036"}
{"created":"2025-04-22","title":"A Call for New Recipes to Enhance Spatial Reasoning in MLLMs","abstract":"Multimodal Large Language Models (MLLMs) have demonstrated impressive performance in general vision-language tasks. However, recent studies have exposed critical limitations in their spatial reasoning capabilities. This deficiency in spatial reasoning significantly constrains MLLMs' ability to interact effectively with the physical world, thereby limiting their broader applications. We argue that spatial reasoning capabilities will not naturally emerge from merely scaling existing architectures and training methodologies. Instead, this challenge demands dedicated attention to fundamental modifications in the current MLLM development approach. In this position paper, we first establish a comprehensive framework for spatial reasoning within the context of MLLMs. We then elaborate on its pivotal role in real-world applications. Through systematic analysis, we examine how individual components of the current methodology-from training data to reasoning mechanisms-influence spatial reasoning capabilities. This examination reveals critical limitations while simultaneously identifying promising avenues for advancement. Our work aims to direct the AI research community's attention toward these crucial yet underexplored aspects. By highlighting these challenges and opportunities, we seek to catalyze progress toward achieving human-like spatial reasoning capabilities in MLLMs.","authors":["Huanyu Zhang","Chengzu Li","Wenshan Wu","Shaoguang Mao","Yan xia","Ivan Vuli\\'c","Zhang Zhang","Liang Wang","Tieniu Tan","Furu Wei"],"url":"https://arxiv.org/abs/2504.15037"}
{"created":"2025-04-22","title":"Estimating transformative agreement impact on hybrid open access: A comparative large-scale study using Scopus, Web of Science and open metadata","abstract":"This study compares open metadata from hoaddata, an openly available dataset based on Crossref, OpenAlex and the cOAlition S Journal Checker Tool, with proprietary bibliometric databases Scopus and Web of Science to estimate the impact of transformative agreements on hybrid open access publishing. Analysing over 13,000 hybrid journals between 2019-2023, the research found substantial growth in open access due to these agreements, although most articles remain paywalled. The results were consistent across all three data sources, showing strong correlations in country-level metrics despite differences in journal coverage and metadata availability. By 2023, transformative agreements enabled the majority of open access in hybrid journals, with particularly high adoption in European countries. The analysis revealed strong alignment between first and corresponding authorship when measuring agreement uptake by publisher and country. This comparative approach supports the use of open metadata for large-scale hybrid open access studies, while using multiple data sources together provides a more robust understanding of hybrid open access adoption than any single database can offer, overcoming individual limitations in coverage and metadata quality.","authors":["Najko Jahn"],"url":"https://arxiv.org/abs/2504.15038"}
{"created":"2025-04-22","title":"Direct Search Algorithm for Clock Skew Compensation Immune to Floating-Point Precision Loss","abstract":"We have been investigating clock skew compensation immune to floating-point precision loss by taking into account the discrete nature of clocks in digital communication systems; extending Bresenham's line drawing algorithm, we constructed an incremental error algorithm using only integer addition/subtraction and comparison. Still, bounding the initial value of the clock remains a challenge, which determines the initial condition of the algorithm and thereby its number of iterations. In this letter, we propose a new incremental error algorithm for clock skew compensation, called direct search, which no longer relies on the bounds on the initial value of the clock. The numerical examples demonstrate that the proposed algorithm can significantly reduce the number of iterations in comparison to the prior work while eliminating the effect of floating-point precision loss on clock skew compensation.","authors":["Kyeong Soo Kim"],"url":"https://arxiv.org/abs/2504.15039"}
{"created":"2025-04-22","title":"Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification","abstract":"Lifelong Person Re-identification (LReID) suffers from a key challenge in preserving old knowledge while adapting to new information. The existing solutions include rehearsal-based and rehearsal-free methods to address this challenge. Rehearsal-based approaches rely on knowledge distillation, continuously accumulating forgetting during the distillation process. Rehearsal-free methods insufficiently learn the distribution of each domain, leading to forgetfulness over time. To solve these issues, we propose a novel Distribution-aware Forgetting Compensation (DAFC) model that explores cross-domain shared representation learning and domain-specific distribution integration without using old exemplars or knowledge distillation. We propose a Text-driven Prompt Aggregation (TPA) that utilizes text features to enrich prompt elements and guide the prompt model to learn fine-grained representations for each instance. This can enhance the differentiation of identity information and establish the foundation for domain distribution awareness. Then, Distribution-based Awareness and Integration (DAI) is designed to capture each domain-specific distribution by a dedicated expert network and adaptively consolidate them into a shared region in high-dimensional space. In this manner, DAI can consolidate and enhance cross-domain shared representation learning while alleviating catastrophic forgetting. Furthermore, we develop a Knowledge Consolidation Mechanism (KCM) that comprises instance-level discrimination and cross-domain consistency alignment strategies to facilitate model adaptive learning of new knowledge from the current domain and promote knowledge consolidation learning between acquired domain-specific distributions, respectively. Experimental results show that our DAFC outperform state-of-the-art methods by at least 9.8\\%/6.6\\% and 6.4\\%/6.2\\% of average mAP/R@1 on two training orders.","authors":["Shiben Liu","Huijie Fan","Qiang Wang","Baojie Fan","Yandong Tang","Liangqiong Qu"],"url":"https://arxiv.org/abs/2504.15041"}
{"created":"2025-04-22","title":"Energy-Efficient UAV-Mounted RIS for IoT: A Hybrid Energy Harvesting and DRL Approach","abstract":"Many future Internet of Things (IoT) applications are expected to rely heavily on reconfigurable intelligent surface (RIS)-aided unmanned aerial vehicles (UAVs). However, the endurance of such systems is constrained by the limited onboard energy, where frequent recharging or battery replacements are required. This consequently disrupts continuous operation and may be impractical in disaster scenarios. To address this challenge, we explore a dual energy harvesting (EH) framework that integrates time-switching (TS), power-splitting (PS), and element-splitting (ES) EH protocols for radio frequency energy, along with solar energy as a renewable source. First, we present the proposed system architecture and EH operating protocols, introducing the proposed hybrid ES-TS-PS EH strategy to extend UAV-mounted RIS endurance. Next, we outline key application scenarios and the associated design challenges. After that, a deep reinforcement learning-based framework is introduced to maximize the EH efficiency by jointly optimizing UAV trajectory, RIS phase shifts, and EH strategies. The framework considers dual EH, hardware impairments, and channel state information imperfections to reflect real-world deployment conditions. The optimization problem is formulated as a Markov decision process and solved using an enhanced deep deterministic policy gradient algorithm, incorporating clipped double Q-learning and softmax-based Q-value estimation for improved stability and efficiency. The results demonstrate significant performance gains compared to the considered baseline approaches. Finally, possible challenges and open research directions are presented, highlighting the transformative potential of energy-efficient UAV-mounted RIS networks for IoT systems.","authors":["Mahmoud M. Salim","Khaled M. Rabie","Ali H. Muqaibel"],"url":"https://arxiv.org/abs/2504.15043"}
{"created":"2025-04-22","title":"Text-to-Decision Agent: Learning Generalist Policies from Natural Language Supervision","abstract":"RL systems usually tackle generalization by inferring task beliefs from high-quality samples or warmup explorations. The restricted form limits their generality and usability since these supervision signals are expensive and even infeasible to acquire in advance for unseen tasks. Learning directly from the raw text about decision tasks is a promising alternative to leverage a much broader source of supervision. In the paper, we propose Text-to-Decision Agent (T2DA), a simple and scalable framework that supervises generalist policy learning with natural language. We first introduce a generalized world model to encode multi-task decision data into a dynamics-aware embedding space. Then, inspired by CLIP, we predict which textual description goes with which decision embedding, effectively bridging their semantic gap via contrastive language-decision pre-training and aligning the text embeddings to comprehend the environment dynamics. After training the text-conditioned generalist policy, the agent can directly realize zero-shot text-to-decision generation in response to language instructions. Comprehensive experiments on MuJoCo and Meta-World benchmarks show that T2DA facilitates high-capacity zero-shot generalization and outperforms various types of baselines.","authors":["Shilin Zhang","Zican Hu","Wenhao Wu","Xinyi Xie","Jianxiang Tang","Chunlin Chen","Daoyi Dong","Yu Cheng","Zhenhong Sun","Zhi Wang"],"url":"https://arxiv.org/abs/2504.15046"}
{"created":"2025-04-22","title":"RainbowPlus: Enhancing Adversarial Prompt Generation via Evolutionary Quality-Diversity Search","abstract":"Large Language Models (LLMs) exhibit remarkable capabilities but are susceptible to adversarial prompts that exploit vulnerabilities to produce unsafe or biased outputs. Existing red-teaming methods often face scalability challenges, resource-intensive requirements, or limited diversity in attack strategies. We propose RainbowPlus, a novel red-teaming framework rooted in evolutionary computation, enhancing adversarial prompt generation through an adaptive quality-diversity (QD) search that extends classical evolutionary algorithms like MAP-Elites with innovations tailored for language models. By employing a multi-element archive to store diverse high-quality prompts and a comprehensive fitness function to evaluate multiple prompts concurrently, RainbowPlus overcomes the constraints of single-prompt archives and pairwise comparisons in prior QD methods like Rainbow Teaming. Experiments comparing RainbowPlus to QD methods across six benchmark datasets and four open-source LLMs demonstrate superior attack success rate (ASR) and diversity (Diverse-Score $\\approx 0.84$), generating up to 100 times more unique prompts (e.g., 10,418 vs. 100 for Ministral-8B-Instruct-2410). Against nine state-of-the-art methods on the HarmBench dataset with twelve LLMs (ten open-source, two closed-source), RainbowPlus achieves an average ASR of 81.1%, surpassing AutoDAN-Turbo by 3.9%, and is 9 times faster (1.45 vs. 13.50 hours). Our open-source implementation fosters further advancements in LLM safety, offering a scalable tool for vulnerability assessment. Code and resources are publicly available at https://github.com/knoveleng/rainbowplus, supporting reproducibility and future research in LLM red-teaming.","authors":["Quy-Anh Dang","Chris Ngo","Truong-Son Hy"],"url":"https://arxiv.org/abs/2504.15047"}
{"created":"2025-04-22","title":"ScanEdit: Hierarchically-Guided Functional 3D Scan Editing","abstract":"With the fast pace of 3D capture technology and resulting abundance of 3D data, effective 3D scene editing becomes essential for a variety of graphics applications. In this work we present ScanEdit, an instruction-driven method for functional editing of complex, real-world 3D scans. To model large and interdependent sets of ob- jectswe propose a hierarchically-guided approach. Given a 3D scan decomposed into its object instances, we first construct a hierarchical scene graph representation to enable effective, tractable editing. We then leverage reason- ing capabilities of Large Language Models (LLMs) and translate high-level language instructions into actionable commands applied hierarchically to the scene graph. Fi- nally, ScanEdit integrates LLM-based guidance with ex- plicit physical constraints and generates realistic scenes where object arrangements obey both physics and common sense. In our extensive experimental evaluation ScanEdit outperforms state of the art and demonstrates excellent re- sults for a variety of real-world scenes and input instruc- tions.","authors":["Mohamed el amine Boudjoghra","Ivan Laptev","Angela Dai"],"url":"https://arxiv.org/abs/2504.15049"}
{"created":"2025-04-22","title":"VeLU: Variance-enhanced Learning Unit for Deep Neural Networks","abstract":"Activation functions are fundamental in deep neural networks and directly impact gradient flow, optimization stability, and generalization. Although ReLU remains standard because of its simplicity, it suffers from vanishing gradients and lacks adaptability. Alternatives like Swish and GELU introduce smooth transitions, but fail to dynamically adjust to input statistics. We propose VeLU, a Variance-enhanced Learning Unit as an activation function that dynamically scales based on input variance by integrating ArcTan-Sin transformations and Wasserstein-2 regularization, effectively mitigating covariate shifts and stabilizing optimization. Extensive experiments on ViT_B16, VGG19, ResNet50, DenseNet121, MobileNetV2, and EfficientNetB3 confirm VeLU's superiority over ReLU, ReLU6, Swish, and GELU on six vision benchmarks. The codes of VeLU are publicly available on GitHub.","authors":["Ashkan Shakarami","Yousef Yeganeh","Azade Farshad","Lorenzo Nicol\\`e","Stefano Ghidoni","Nassir Navab"],"url":"https://arxiv.org/abs/2504.15051"}
{"created":"2025-04-22","title":"Testing LLMs' Capabilities in Annotating Translations Based on an Error Typology Designed for LSP Translation: First Experiments with ChatGPT","abstract":"This study investigates the capabilities of large language models (LLMs), specifically ChatGPT, in annotating MT outputs based on an error typology. In contrast to previous work focusing mainly on general language, we explore ChatGPT's ability to identify and categorise errors in specialised translations. By testing two different prompts and based on a customised error typology, we compare ChatGPT annotations with human expert evaluations of translations produced by DeepL and ChatGPT itself. The results show that, for translations generated by DeepL, recall and precision are quite high. However, the degree of accuracy in error categorisation depends on the prompt's specific features and its level of detail, ChatGPT performing very well with a detailed prompt. When evaluating its own translations, ChatGPT achieves significantly poorer results, revealing limitations with self-assessment. These results highlight both the potential and the limitations of LLMs for translation evaluation, particularly in specialised domains. Our experiments pave the way for future research on open-source LLMs, which could produce annotations of comparable or even higher quality. In the future, we also aim to test the practical effectiveness of this automated evaluation in the context of translation training, particularly by optimising the process of human evaluation by teachers and by exploring the impact of annotations by LLMs on students' post-editing and translation learning.","authors":["Joachim Minder","Guillaume Wisniewski","Natalie K\\\"ubler"],"url":"https://arxiv.org/abs/2504.15052"}
{"created":"2025-04-22","title":"Structure-guided Diffusion Transformer for Low-Light Image Enhancement","abstract":"While the diffusion transformer (DiT) has become a focal point of interest in recent years, its application in low-light image enhancement remains a blank area for exploration. Current methods recover the details from low-light images while inevitably amplifying the noise in images, resulting in poor visual quality. In this paper, we firstly introduce DiT into the low-light enhancement task and design a novel Structure-guided Diffusion Transformer based Low-light image enhancement (SDTL) framework. We compress the feature through wavelet transform to improve the inference efficiency of the model and capture the multi-directional frequency band. Then we propose a Structure Enhancement Module (SEM) that uses structural prior to enhance the texture and leverages an adaptive fusion strategy to achieve more accurate enhancement effect. In Addition, we propose a Structure-guided Attention Block (SAB) to pay more attention to texture-riched tokens and avoid interference from noisy areas in noise prediction. Extensive qualitative and quantitative experiments demonstrate that our method achieves SOTA performance on several popular datasets, validating the effectiveness of SDTL in improving image quality and the potential of DiT in low-light enhancement tasks.","authors":["Xiangchen Yin","Zhenda Yu","Longtao Jiang","Xin Gao","Xiao Sun","Zhi Liu","Xun Yang"],"url":"https://arxiv.org/abs/2504.15054"}
{"created":"2025-04-22","title":"Linear Item-Item Model with Neural Knowledge for Session-based Recommendation","abstract":"Session-based recommendation (SBR) aims to predict users' subsequent actions by modeling short-term interactions within sessions. Existing neural models primarily focus on capturing complex dependencies for sequential item transitions. As an alternative solution, linear item-item models mainly identify strong co-occurrence patterns across items and support faster inference speed. Although each paradigm has been actively studied in SBR, their fundamental differences in capturing item relationships and how to bridge these distinct modeling paradigms effectively remain unexplored. In this paper, we propose a novel SBR model, namely Linear Item-Item model with Neural Knowledge (LINK), which integrates both types of knowledge into a unified linear framework. Specifically, we design two specialized components of LINK: (i) Linear knowledge-enhanced Item-item Similarity model (LIS), which refines the item similarity correlation via self-distillation, and (ii) Neural knowledge-enhanced Item-item Transition model (NIT), which seamlessly incorporates complicated neural knowledge distilled from the off-the-shelf neural model. Extensive experiments demonstrate that LINK outperforms state-of-the-art linear SBR models across six real-world datasets, achieving improvements of up to 14.78% and 11.04% in Recall@20 and MRR@20 while showing up to 813x fewer inference FLOPs. Our code is available at https://github.com/jin530/LINK.","authors":["Minjin Choi","Sunkyung Lee","Seongmin Park","Jongwuk Lee"],"url":"https://arxiv.org/abs/2504.15057"}
{"created":"2025-04-22","title":"Mining Characteristics of Vulnerable Smart Contracts Across Lifecycle Stages","abstract":"Smart contracts are the cornerstone of decentralized applications and financial protocols, which extend the application of digital currency transactions. The applications and financial protocols introduce significant security challenges, resulting in substantial economic losses. Existing solutions predominantly focus on code vulnerabilities within smart contracts, accounting for only 50% of security incidents. Therefore, a more comprehensive study of security issues related to smart contracts is imperative. The existing empirical research realizes the static analysis of smart contracts from the perspective of the lifecycle and gives the corresponding measures for each stage. However, they lack the characteristic analysis of vulnerabilities in each stage and the distinction between the vulnerabilities. In this paper, we present the first empirical study on the security of smart contracts throughout their lifecycle, including deployment and execution, upgrade, and destruction stages. It delves into the security issues at each stage and provides at least seven feature descriptions. Finally, utilizing these seven features, five machine-learning classification models are used to identify vulnerabilities at different stages. The classification results reveal that vulnerable contracts exhibit distinct transaction features and ego network properties at various stages.","authors":["Hongli Peng","Xiaoqi Li","Wenkai Li"],"url":"https://arxiv.org/abs/2504.15063"}
{"created":"2025-04-22","title":"Chinese-LiPS: A Chinese audio-visual speech recognition dataset with Lip-reading and Presentation Slides","abstract":"Incorporating visual modalities to assist Automatic Speech Recognition (ASR) tasks has led to significant improvements. However, existing Audio-Visual Speech Recognition (AVSR) datasets and methods typically rely solely on lip-reading information or speaking contextual video, neglecting the potential of combining these different valuable visual cues within the speaking context. In this paper, we release a multimodal Chinese AVSR dataset, Chinese-LiPS, comprising 100 hours of speech, video, and corresponding manual transcription, with the visual modality encompassing both lip-reading information and the presentation slides used by the speaker. Based on Chinese-LiPS, we develop a simple yet effective pipeline, LiPS-AVSR, which leverages both lip-reading and presentation slide information as visual modalities for AVSR tasks. Experiments show that lip-reading and presentation slide information improve ASR performance by approximately 8\\% and 25\\%, respectively, with a combined performance improvement of about 35\\%. The dataset is available at https://kiri0824.github.io/Chinese-LiPS/","authors":["Jinghua Zhao","Yuhang Jia","Shiyao Wang","Jiaming Zhou","Hui Wang","Yong Qin"],"url":"https://arxiv.org/abs/2504.15066"}
{"created":"2025-04-22","title":"The Great Nugget Recall: Automating Fact Extraction and RAG Evaluation with Large Language Models","abstract":"Large Language Models (LLMs) have significantly enhanced the capabilities of information access systems, especially with retrieval-augmented generation (RAG). Nevertheless, the evaluation of RAG systems remains a barrier to continued progress, a challenge we tackle in this work by proposing an automatic evaluation framework that is validated against human annotations. We believe that the nugget evaluation methodology provides a solid foundation for evaluating RAG systems. This approach, originally developed for the TREC Question Answering (QA) Track in 2003, evaluates systems based on atomic facts that should be present in good answers. Our efforts focus on \"refactoring\" this methodology, where we describe the AutoNuggetizer framework that specifically applies LLMs to both automatically create nuggets and automatically assign nuggets to system answers. In the context of the TREC 2024 RAG Track, we calibrate a fully automatic approach against strategies where nuggets are created manually or semi-manually by human assessors and then assigned manually to system answers. Based on results from a community-wide evaluation, we observe strong agreement at the run level between scores derived from fully automatic nugget evaluation and human-based variants. The agreement is stronger when individual framework components such as nugget assignment are automated independently. This suggests that our evaluation framework provides tradeoffs between effort and quality that can be used to guide the development of future RAG systems. However, further research is necessary to refine our approach, particularly in establishing robust per-topic agreement to diagnose system failures effectively.","authors":["Ronak Pradeep","Nandan Thakur","Shivani Upadhyay","Daniel Campos","Nick Craswell","Jimmy Lin"],"url":"https://arxiv.org/abs/2504.15068"}
{"created":"2025-04-22","title":"Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling","abstract":"We introduce an extensive new dataset of MIDI files, created by transcribing audio recordings of piano performances into their constituent notes. The data pipeline we use is multi-stage, employing a language model to autonomously crawl and score audio recordings from the internet based on their metadata, followed by a stage of pruning and segmentation using an audio classifier. The resulting dataset contains over one million distinct MIDI files, comprising roughly 100,000 hours of transcribed audio. We provide an in-depth analysis of our techniques, offering statistical insights, and investigate the content by extracting metadata tags, which we also provide. Dataset available at https://github.com/loubbrad/aria-midi.","authors":["Louis Bradshaw","Simon Colton"],"url":"https://arxiv.org/abs/2504.15071"}
{"created":"2025-04-22","title":"Rhythm of Opinion: A Hawkes-Graph Framework for Dynamic Propagation Analysis","abstract":"The rapid development of social media has significantly reshaped the dynamics of public opinion, resulting in complex interactions that traditional models fail to effectively capture. To address this challenge, we propose an innovative approach that integrates multi-dimensional Hawkes processes with Graph Neural Network, modeling opinion propagation dynamics among nodes in a social network while considering the intricate hierarchical relationships between comments. The extended multi-dimensional Hawkes process captures the hierarchical structure, multi-dimensional interactions, and mutual influences across different topics, forming a complex propagation network. Moreover, recognizing the lack of high-quality datasets capable of comprehensively capturing the evolution of public opinion dynamics, we introduce a new dataset, VISTA. It includes 159 trending topics, corresponding to 47,207 posts, 327,015 second-level comments, and 29,578 third-level comments, covering diverse domains such as politics, entertainment, sports, health, and medicine. The dataset is annotated with detailed sentiment labels across 11 categories and clearly defined hierarchical relationships. When combined with our method, it offers strong interpretability by linking sentiment propagation to the comment hierarchy and temporal evolution. Our approach provides a robust baseline for future research.","authors":["Yulong Li","Zhixiang Lu","Feilong Tang","Simin Lai","Ming Hu","Yuxuan Zhang","Haochen Xue","Zhaodong Wu","Imran Razzak","Qingxia Li","Jionglong Su"],"url":"https://arxiv.org/abs/2504.15072"}
{"created":"2025-04-22","title":"Hermitian Quaternion Toeplitz Matrices by Quaternion-valued Generating Functions","abstract":"In this paper, we study Hermitian quaternion Toeplitz matrices generated by quaternion-valued functions. We show that such generating function must be the sum of a real-valued function and an odd function with imaginary component. This setting is different from the case of Hermitian complex Toeplitz matrices generated by real-valued functions only. By using of 2-by-2 block complex representation of quaternion matrices, we give a quaternion version of Grenander-Szeg\\\"{o} theorem stating the distribution of eigenvalues of Hermitian quaternion Toeplitz matrices in terms of its generating function. As an application, we investigate Strang's circulant preconditioners for Hermitian quaternion Toeplitz linear systems arising from quaternion signal processing. We show that Strang's circulant preconditioners can be diagionalized by discrete quaternion Fourier transform matrices whereas general quaternion circulant matrices cannot be diagonalized by them. Also we verify the theoretical and numerical convergence results of Strang's circulant preconditioned conjugate gradient method for solving Hermitian quaternion Toeplitz systems.","authors":["Xue-lei Lin","Michael K. Ng","Junjun Pan"],"url":"https://arxiv.org/abs/2504.15073"}
{"created":"2025-04-22","title":"Mitigating Degree Bias in Graph Representation Learning with Learnable Structural Augmentation and Structural Self-Attention","abstract":"Graph Neural Networks (GNNs) update node representations through message passing, which is primarily based on the homophily principle, assuming that adjacent nodes share similar features. However, in real-world graphs with long-tailed degree distributions, high-degree nodes dominate message passing, causing a degree bias where low-degree nodes remain under-represented due to inadequate messages. The main challenge in addressing degree bias is how to discover non-adjacent nodes to provide additional messages to low-degree nodes while reducing excessive messages for high-degree nodes. Nevertheless, exploiting non-adjacent nodes to provide valuable messages is challenging, as it could generate noisy information and disrupt the original graph structures. To solve it, we propose a novel Degree Fairness Graph Transformer, named DegFairGT, to mitigate degree bias by discovering structural similarities between non-adjacent nodes through learnable structural augmentation and structural self-attention. Our key idea is to exploit non-adjacent nodes with similar roles in the same community to generate informative edges under our augmentation, which could provide informative messages between nodes with similar roles while ensuring that the homophily principle is maintained within the community. To enable DegFairGT to learn such structural similarities, we then propose a structural self-attention to capture the similarities between node pairs. To preserve global graph structures and prevent graph augmentation from hindering graph structure, we propose a Self-Supervised Learning task to preserve p-step transition probability and regularize graph augmentation. Extensive experiments on six datasets showed that DegFairGT outperformed state-of-the-art baselines in degree fairness analysis, node classification, and node clustering tasks.","authors":["Van Thuy Hoang","Hyeon-Ju Jeon","O-Joun Lee"],"url":"https://arxiv.org/abs/2504.15075"}
{"created":"2025-04-22","title":"Think2SQL: Reinforce LLM Reasoning Capabilities for Text2SQL","abstract":"Large Language Models (LLMs) have shown impressive capabilities in transforming natural language questions about relational databases into SQL queries. Despite recent improvements, small LLMs struggle to handle questions involving multiple tables and complex SQL patterns under a Zero-Shot Learning (ZSL) setting. Supervised Fine-Tuning (SFT) partially compensate the knowledge deficits in pretrained models but falls short while dealing with queries involving multi-hop reasoning. To bridge this gap, different LLM training strategies to reinforce reasoning capabilities have been proposed, ranging from leveraging a thinking process within ZSL, including reasoning traces in SFT, or adopt Reinforcement Learning (RL) strategies. However, the influence of reasoning on Text2SQL performance is still largely unexplored. This paper investigates to what extent LLM reasoning capabilities influence their Text2SQL performance on four benchmark datasets. To this end, it considers the following LLM settings: (1) ZSL, including general-purpose reasoning or not; (2) SFT, with and without task-specific reasoning traces; (3) RL, leveraging execution accuracy as primary reward function; (4) SFT+RL, i.e, a two-stage approach that combines SFT and RL. The results show that general-purpose reasoning under ZSL proves to be ineffective in tackling complex Text2SQL cases. Small LLMs benefit from SFT with reasoning much more than larger ones, bridging the gap of their (weaker) model pretraining. RL is generally beneficial across all tested models and datasets, particularly when SQL queries involve multi-hop reasoning and multiple tables. Small LLMs with SFT+RL excel on most complex datasets thanks to a strategic balance between generality of the reasoning process and optimization of the execution accuracy. Thanks to RL, the7B Qwen-Coder-2.5 model performs on par with 100+ Billion ones on the Bird dataset.","authors":["Simone Papicchio","Simone Rossi","Luca Cagliero","Paolo Papotti"],"url":"https://arxiv.org/abs/2504.15077"}
{"created":"2025-04-22","title":"Generative Artificial Intelligence for Beamforming in Low-Altitude Economy","abstract":"The growth of low-altitude economy (LAE) has driven a rising demand for efficient and secure communication. However, conventional beamforming optimization techniques struggle in the complex LAE environments. In this context, generative artificial intelligence (GenAI) methods provide a promising solution. In this article, we first introduce the core concepts of LAE and the roles of beamforming in advanced communication technologies for LAE. We then examine their interrelation, followed by an analysis of the limitations of conventional beamforming methods. Next, we provide an overview of how GenAI methods enhance the process of beamforming, with a focus on its applications in LAE. Furthermore, we present a case study using a generative diffusion model (GDM)-based algorithm to enhance the performance of aerial collaborative beamforming-enabled remote secure communications in LAE and simulation results verified the effectiveness of the proposed algorithms. Finally, promising research opportunities are identified.","authors":["Geng Sun","Jia Qi","Chuang Zhang","Xuejie Liu","Jiacheng Wang","Dusit Niyato","Yuanwei Liu","Dong In Kim"],"url":"https://arxiv.org/abs/2504.15079"}
{"created":"2025-04-22","title":"Empowering AI to Generate Better AI Code: Guided Generation of Deep Learning Projects with LLMs","abstract":"While large language models (LLMs) have been widely applied to code generation, they struggle with generating entire deep learning projects, which are characterized by complex structures, longer functions, and stronger reliance on domain knowledge than general-purpose code. An open-domain LLM often lacks coherent contextual guidance and domain expertise for specific projects, making it challenging to produce complete code that fully meets user requirements.","authors":["Chen Xie","Mingsheng Jiao","Xiaodong Gu","Beijun Shen"],"url":"https://arxiv.org/abs/2504.15080"}
{"created":"2025-04-22","title":"PID-GM: PID Control with Gain Mapping","abstract":"Proportional-Integral-Differential (PID) control is widely used in industrial control systems. However, up to now there are at least two open problems related with PID control. One is to have a comprehensive understanding of its robustness with respect to model uncertainties and disturbances. The other is to build intuitive, explicit and mathematically provable guidelines for PID gain tuning. In this paper, we introduce a simple nonlinear mapping to determine PID gains from three auxiliary parameters. By the mapping, PID control is shown to be equivalent to a new PD control (serving as a nominal control) plus an uncertainty and disturbance compensator (to recover the nominal performance). Then PID control can be understood, designed and tuned in a Two-Degree-of-Freedom (2-DoF) control framework. We discuss some basic properties of the mapping, including the existence, uniqueness and invertibility. Taking as an example the PID control applied to a general uncertain second-order plant, we prove by the singular perturbation theory that the closed-loop steady-state and transient performance depends explicitly on one auxiliary parameter which can be viewed as the virtual singular perturbation parameter (SPP) of PID control. All the three PID gains are monotonically decreasing functions of the SPP, indicating that the smaller the SPP is, the higher the PID gains are, and the better the robustness of PID control is. Simulation and experimental examples are provided to demonstrate the properties of the mapping as well as the effectiveness of the mapping based PID gain turning.","authors":["Bo Zhu","Wei Yu","Hugh H. T. Liu"],"url":"https://arxiv.org/abs/2504.15081"}
{"created":"2025-04-22","title":"An island-parallel ensemble metaheuristic algorithm for large graph coloring problems","abstract":"Graph Coloring Problem (GCP) is an NP-Hard vertex labeling problem in graphs such that no two adjacent vertices can have the same color. Large instances of GCP cannot be solved in reasonable execution times by exact algorithms. Therefore, soft computing approaches, such as metaheuristics, have proven to be very efficient for solving large instances of GCP. In this study, we propose a new island-parallel ensemble metaheuristic algorithm (PEM-Color) to solve large GCP instances. Ensemble learning is a new machine learning approach based on combining the output of multiple models instead of using a single one. We use Message Passing Interface (MPI) parallel computation libraries to combine recent state-of-the-art metaheuristics: Harris Hawk Optimization (HHO), Artificial Bee Colony (ABC), and Teaching Learning Based (TLBO) to improve the quality of their solutions further. To the best of our knowledge, this is the first study that combines metaheuristics and applies to the GCP using an ensemble approach. We conducted experiments on large graph instances from the well-known DIMACS benchmark using 64 processors and achieved significant improvements in execution times. The experiments also indicate an almost linear speed-up with a strong scalability potential. The solution quality of the instances is promising, as our algorithm outperforms 13 state-of-the-art algorithms.","authors":["Tansel Dokeroglu","Tayfun Kucukyilmaz","Ahmet Cosar"],"url":"https://arxiv.org/abs/2504.15082"}
{"created":"2025-04-22","title":"Hierarchical Attention Fusion of Visual and Textual Representations for Cross-Domain Sequential Recommendation","abstract":"Cross-Domain Sequential Recommendation (CDSR) predicts user behavior by leveraging historical interactions across multiple domains, focusing on modeling cross-domain preferences through intra- and inter-sequence item relationships. Inspired by human cognitive processes, we propose Hierarchical Attention Fusion of Visual and Textual Representations (HAF-VT), a novel approach integrating visual and textual data to enhance cognitive modeling. Using the frozen CLIP model, we generate image and text embeddings, enriching item representations with multimodal data. A hierarchical attention mechanism jointly learns single-domain and cross-domain preferences, mimicking human information integration. Evaluated on four e-commerce datasets, HAF-VT outperforms existing methods in capturing cross-domain user interests, bridging cognitive principles with computational models and highlighting the role of multimodal data in sequential decision-making.","authors":["Wangyu Wu","Zhenhong Chen","Siqi Song","Xianglin Qiua","Xiaowei Huang","Fei Ma","Jimin Xiao"],"url":"https://arxiv.org/abs/2504.15085"}
{"created":"2025-04-22","title":"Safety Co-Option and Compromised National Security: The Self-Fulfilling Prophecy of Weakened AI Risk Thresholds","abstract":"Risk thresholds provide a measure of the level of risk exposure that a society or individual is willing to withstand, ultimately shaping how we determine the safety of technological systems. Against the backdrop of the Cold War, the first risk analyses, such as those devised for nuclear systems, cemented societally accepted risk thresholds against which safety-critical and defense systems are now evaluated. But today, the appropriate risk tolerances for AI systems have yet to be agreed on by global governing efforts, despite the need for democratic deliberation regarding the acceptable levels of harm to human life. Absent such AI risk thresholds, AI technologists-primarily industry labs, as well as \"AI safety\" focused organizations-have instead advocated for risk tolerances skewed by a purported AI arms race and speculative \"existential\" risks, taking over the arbitration of risk determinations with life-or-death consequences, subverting democratic processes.","authors":["Heidy Khlaaf","Sarah Myers West"],"url":"https://arxiv.org/abs/2504.15088"}
{"created":"2025-04-22","title":"Robust Planning and Control of Omnidirectional MRAVs for Aerial Communications in Wireless Networks","abstract":"A new class of Multi-Rotor Aerial Vehicles (MRAVs), known as omnidirectional MRAVs (o-MRAVs), has gained attention for their ability to independently control 3D position and orientation. This capability enhances robust planning and control in aerial communication networks, enabling more adaptive trajectory planning and precise antenna alignment without additional mechanical components. These features are particularly valuable in uncertain environments, where disturbances such as wind and interference affect communication stability. This paper examines o-MRAVs in the context of robust aerial network planning, comparing them with the more common under-actuated MRAVs (u-MRAVs). Key applications, including physical layer security, optical communications, and network densification, are highlighted, demonstrating the potential of o-MRAVs to improve reliability and efficiency in dynamic communication scenarios.","authors":["Giuseppe Silano","Daniel Bonilla Licea","Hajar El Hammouti","Mounir Ghogho","and Martin Saska"],"url":"https://arxiv.org/abs/2504.15089"}
{"created":"2025-04-22","title":"Federated Latent Factor Model for Bias-Aware Recommendation with Privacy-Preserving","abstract":"A recommender system (RS) aims to provide users with personalized item recommendations, enhancing their overall experience. Traditional RSs collect and process all user data on a central server. However, this centralized approach raises significant privacy concerns, as it increases the risk of data breaches and privacy leakages, which are becoming increasingly unacceptable to privacy-sensitive users. To address these privacy challenges, federated learning has been integrated into RSs, ensuring that user data remains secure. In centralized RSs, the issue of rating bias is effectively addressed by jointly analyzing all users' raw interaction data. However, this becomes a significant challenge in federated RSs, as raw data is no longer accessible due to privacy-preserving constraints. To overcome this problem, we propose a Federated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is explicitly incorporated into every local model's loss function, allowing for the effective elimination of rating bias without compromising data privacy. Extensive experiments conducted on three real-world datasets demonstrate that FBALF achieves significantly higher recommendation accuracy compared to other state-of-the-art federated RSs.","authors":["Junxiang Gao","Yixin Ran","Jia Chen"],"url":"https://arxiv.org/abs/2504.15090"}
{"created":"2025-04-22","title":"Rethinking the Potential of Multimodality in Collaborative Problem Solving Diagnosis with Large Language Models","abstract":"Detecting collaborative and problem-solving behaviours from digital traces to interpret students' collaborative problem solving (CPS) competency is a long-term goal in the Artificial Intelligence in Education (AIEd) field. Although multimodal data and advanced models are argued to have the potential to detect complex CPS behaviours, empirical evidence on their value remains limited with some contrasting evidence. In this study, we investigated the potential of multimodal data to improve model performance in diagnosing 78 secondary school students' CPS subskills and indicators in authentic educational settings. In particular, text embeddings from verbal data and acoustic embeddings from audio data were used in a multimodal classification model for CPS diagnosis. Both unimodal and multimodal transformer-based models outperformed traditional models in detecting CPS classes. Although the inclusion of multimodality did not improve the performance of traditional unimodal models, its integration into transformer-based models demonstrated improved performance for diagnosing social-cognitive CPS classes compared to unimodal transformer-based models. Based on the results, the paper argues that multimodality and the selection of a particular modelling technique should not be taken for granted to achieve the best performance in the automated detection of every CPS subskill and indicator. Rather, their value is limited to certain types of CPS indicators, affected by the complexity of the labels, and dependent on the composition of indicators in the dataset. We conclude the paper by discussing the required nuance when considering the value of LLMs and multimodality in automated CPS diagnosis, highlighting the need for human-AI complementarity, and proposing the exploration of relevant model architectures and techniques to improve CPS diagnosis in authentic educational contexts.","authors":["K. Wong","B. Wu","S. Bulathwela","M. Cukurova"],"url":"https://arxiv.org/abs/2504.15093"}
{"created":"2025-04-22","title":"VistaDepth: Frequency Modulation With Bias Reweighting For Enhanced Long-Range Depth Estimation","abstract":"Monocular depth estimation (MDE) aims to predict per-pixel depth values from a single RGB image. Recent advancements have positioned diffusion models as effective MDE tools by framing the challenge as a conditional image generation task. Despite their progress, these methods often struggle with accurately reconstructing distant depths, due largely to the imbalanced distribution of depth values and an over-reliance on spatial-domain features. To overcome these limitations, we introduce VistaDepth, a novel framework that integrates adaptive frequency-domain feature enhancements with an adaptive weight-balancing mechanism into the diffusion process. Central to our approach is the Latent Frequency Modulation (LFM) module, which dynamically refines spectral responses in the latent feature space, thereby improving the preservation of structural details and reducing noisy artifacts. Furthermore, we implement an adaptive weighting strategy that modulates the diffusion loss in real-time, enhancing the model's sensitivity towards distant depth reconstruction. These innovations collectively result in superior depth perception performance across both distance and detail. Experimental evaluations confirm that VistaDepth achieves state-of-the-art performance among diffusion-based MDE techniques, particularly excelling in the accurate reconstruction of distant regions.","authors":["Mingxia Zhan","Li Zhang","XiaoMeng Chu","Beibei Wang"],"url":"https://arxiv.org/abs/2504.15095"}
{"created":"2025-04-22","title":"Optimal Behavior Planning for Implicit Communication using a Probabilistic Vehicle-Pedestrian Interaction Model","abstract":"In interactions between automated vehicles (AVs) and crossing pedestrians, modeling implicit vehicle communication is crucial. In this work, we present a combined prediction and planning approach that allows to consider the influence of the planned vehicle behavior on a pedestrian and predict a pedestrian's reaction. We plan the behavior by solving two consecutive optimal control problems (OCPs) analytically, using variational calculus. We perform a validation step that assesses whether the planned vehicle behavior is adequate to trigger a certain pedestrian reaction, which accounts for the closed-loop characteristics of prediction and planning influencing each other. In this step, we model the influence of the planned vehicle behavior on the pedestrian using a probabilistic behavior acceptance model that returns an estimate for the crossing probability. The probabilistic modeling of the pedestrian reaction facilitates considering the pedestrian's costs, thereby improving cooperative behavior planning. We demonstrate the performance of the proposed approach in simulated vehicle-pedestrian interactions with varying initial settings and highlight the decision making capabilities of the planning approach.","authors":["Markus Amann","Malte Probst","Raphael Wenzel","Thomas H. Weisswange","Miguel \\'Angel Sotelo"],"url":"https://arxiv.org/abs/2504.15098"}
{"created":"2025-04-22","title":"Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training of GAN","abstract":"Up to now, the training processes of typical Generative Adversarial Networks (GANs) are still particularly sensitive to data properties and hyperparameters, which may lead to severe oscillations, difficulties in convergence, or even failures to converge, especially when the overall variances of the training sets are large. These phenomena are often attributed to the training characteristics of such networks. Aiming at the problem, this paper develops a new intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which employs reinforcement learning in the training process of GANs to make training easier. Specifically, this paper allows the training step size to be controlled by an agent to improve training stability, and makes the training process more intelligent with variable learning rates, making GANs less sensitive to step size. Experiments have been conducted on three benchmark datasets to verify the effectiveness of the developed FSCO.","authors":["Lin Wang","Xiancheng Wang","Rui Wang","Zhibo Zhang","Minghang Zhao"],"url":"https://arxiv.org/abs/2504.15099"}
{"created":"2025-04-22","title":"Application of Sensitivity Analysis Methods for Studying Neural Network Models","abstract":"This study demonstrates the capabilities of several methods for analyzing the sensitivity of neural networks to perturbations of the input data and interpreting their underlying mechanisms. The investigated approaches include the Sobol global sensitivity analysis, the local sensitivity method for input pixel perturbations and the activation maximization technique. As examples, in this study we consider a small feedforward neural network for analyzing an open tabular dataset of clinical diabetes data, as well as two classical convolutional architectures, VGG-16 and ResNet-18, which are widely used in image processing and classification. Utilization of the global sensitivity analysis allows us to identify the leading input parameters of the chosen tiny neural network and reduce their number without significant loss of the accuracy. As far as global sensitivity analysis is not applicable to larger models we try the local sensitivity analysis and activation maximization method in application to the convolutional neural networks. These methods show interesting patterns for the convolutional models solving the image classification problem. All in all, we compare the results of the activation maximization method with popular Grad-CAM technique in the context of ultrasound data analysis.","authors":["Jiaxuan Miao","Sergey Matveev"],"url":"https://arxiv.org/abs/2504.15100"}
{"created":"2025-04-22","title":"NeuGaze: Reshaping the future BCI","abstract":"Traditional brain-computer interfaces (BCIs), reliant on costly electroencephalography or invasive implants, struggle with complex human-computer interactions due to setup complexity and limited precision. We present NeuGaze, a novel webcam-based system that leverages eye gaze, head movements, and facial expressions to enable intuitive, real-time control using only a standard 30 Hz webcam, often pre-installed in laptops. Requiring minimal calibration, NeuGaze achieves performance comparable to conventional inputs, supporting precise cursor navigation, key triggering via an efficient skill wheel, and dynamic gaming interactions, such as defeating formidable opponents in first-person games. By harnessing preserved neck-up functionalities in motor-impaired individuals, NeuGaze eliminates the need for specialized hardware, offering a low-cost, accessible alternative to BCIs. This paradigm empowers diverse applications, from assistive technology to entertainment, redefining human-computer interaction for motor-impaired users. Project is at \\href{https://github.com/NeuSpeech/NeuGaze}{github.com/NeuSpeech/NeuGaze}.","authors":["Yiqian Yang"],"url":"https://arxiv.org/abs/2504.15101"}
{"created":"2025-04-22","title":"A triple-branch network for latent fingerprint enhancement guided by orientation fields and minutiae","abstract":"Latent fingerprint enhancement is a critical step in the process of latent fingerprint identification. Existing deep learning-based enhancement methods still fall short of practical application requirements, particularly in restoring low-quality fingerprint regions. Recognizing that different regions of latent fingerprints require distinct enhancement strategies, we propose a Triple Branch Spatial Fusion Network (TBSFNet), which simultaneously enhances different regions of the image using tailored strategies. Furthermore, to improve the generalization capability of the network, we integrate orientation field and minutiae-related modules into TBSFNet and introduce a Multi-Level Feature Guidance Network (MLFGNet). Experimental results on the MOLF and MUST datasets demonstrate that MLFGNet outperforms existing enhancement algorithms.","authors":["Yurun Wang","Zerong Qi","Shujun Fu","Mingzheng Hu"],"url":"https://arxiv.org/abs/2504.15105"}
{"created":"2025-04-22","title":"Unwarping Screen Content Images via Structure-texture Enhancement Network and Transformation Self-estimation","abstract":"While existing implicit neural network-based image unwarping methods perform well on natural images, they struggle to handle screen content images (SCIs), which often contain large geometric distortions, text, symbols, and sharp edges. To address this, we propose a structure-texture enhancement network (STEN) with transformation self-estimation for SCI warping. STEN integrates a B-spline implicit neural representation module and a transformation error estimation and self-correction algorithm. It comprises two branches: the structure estimation branch (SEB), which enhances local aggregation and global dependency modeling, and the texture estimation branch (TEB), which improves texture detail synthesis using B-spline implicit neural representation. Additionally, the transformation self-estimation module autonomously estimates the transformation error and corrects the coordinate transformation matrix, effectively handling real-world image distortions. Extensive experiments on public SCI datasets demonstrate that our approach significantly outperforms state-of-the-art methods. Comparisons on well-known natural image datasets also show the potential of our approach for natural image distortion.","authors":["Zhenzhen Xiao","Heng Liu","Bingwen Hu"],"url":"https://arxiv.org/abs/2504.15108"}
{"created":"2025-04-22","title":"Kolmogorov-Arnold Networks: Approximation and Learning Guarantees for Functions and their Derivatives","abstract":"Inspired by the Kolmogorov-Arnold superposition theorem, Kolmogorov-Arnold Networks (KANs) have recently emerged as an improved backbone for most deep learning frameworks, promising more adaptivity than their multilayer perception (MLP) predecessor by allowing for trainable spline-based activation functions. In this paper, we probe the theoretical foundations of the KAN architecture by showing that it can optimally approximate any Besov function in $B^{s}_{p,q}(\\mathcal{X})$ on a bounded open, or even fractal, domain $\\mathcal{X}$ in $\\mathbb{R}^d$ at the optimal approximation rate with respect to any weaker Besov norm $B^{\\alpha}_{p,q}(\\mathcal{X})$; where $\\alpha < s$. We complement our approximation guarantee with a dimension-free estimate on the sample complexity of a residual KAN model when learning a function of Besov regularity from $N$ i.i.d. noiseless samples. Our KAN architecture incorporates contemporary deep learning wisdom by leveraging residual/skip connections between layers.","authors":["Anastasis Kratsios","Takashi Furuya"],"url":"https://arxiv.org/abs/2504.15110"}
{"created":"2025-04-22","title":"Deterministic $k$-Median Clustering in Near-Optimal Time","abstract":"The metric $k$-median problem is a textbook clustering problem. As input, we are given a metric space $V$ of size $n$ and an integer $k$, and our task is to find a subset $S \\subseteq V$ of at most $k$ `centers' that minimizes the total distance from each point in $V$ to its nearest center in $S$.","authors":["Mart\\'in Costa","Ermiya Farokhnejad"],"url":"https://arxiv.org/abs/2504.15115"}
{"created":"2025-04-22","title":"Improving Sound Source Localization with Joint Slot Attention on Image and Audio","abstract":"Sound source localization (SSL) is the task of locating the source of sound within an image. Due to the lack of localization labels, the de facto standard in SSL has been to represent an image and audio as a single embedding vector each, and use them to learn SSL via contrastive learning. To this end, previous work samples one of local image features as the image embedding and aggregates all local audio features to obtain the audio embedding, which is far from optimal due to the presence of noise and background irrelevant to the actual target in the input. We present a novel SSL method that addresses this chronic issue by joint slot attention on image and audio. To be specific, two slots competitively attend image and audio features to decompose them into target and off-target representations, and only target representations of image and audio are used for contrastive learning. Also, we introduce cross-modal attention matching to further align local features of image and audio. Our method achieved the best in almost all settings on three public benchmarks for SSL, and substantially outperformed all the prior work in cross-modal retrieval.","authors":["Inho Kim","Youngkil Song","Jicheol Park","Won Hwa Kim","Suha Kwak"],"url":"https://arxiv.org/abs/2504.15118"}
{"created":"2025-04-22","title":"Kuwain 1.5B: An Arabic SLM via Language Injection","abstract":"Enhancing existing models with new knowledge is a crucial aspect of AI development. This paper introduces a novel method for integrating a new language into a large language model (LLM). Our approach successfully incorporates a previously unseen target language into an existing LLM without compromising its prior knowledge. We trained a tiny model with 1.5 billion parameters named Kuwain by injecting the Arabic language into a small open-source model mainly trained in English. Our method demonstrates significant improvements in Arabic language performance, with an average 8% improvement across various benchmarks, while retaining the model's existing knowledge with a minimum amount of the original model's data. This offers a cost-effective alternative to training a comprehensive model in both English and Arabic. The results highlight the potential for efficient, targeted language model expansion without extensive retraining or resource-intensive processes.","authors":["Khalil Hennara","Sara Chrouf","Mohamed Motaism Hamed","Zeina Aldallal","Omar Hadid","Safwan AlModhayan"],"url":"https://arxiv.org/abs/2504.15120"}
{"created":"2025-04-22","title":"Robust and Real-time Surface Normal Estimation from Stereo Disparities using Affine Transformations","abstract":"This work introduces a novel method for surface normal estimation from rectified stereo image pairs, leveraging affine transformations derived from disparity values to achieve fast and accurate results. We demonstrate how the rectification of stereo image pairs simplifies the process of surface normal estimation by reducing computational complexity. To address noise reduction, we develop a custom algorithm inspired by convolutional operations, tailored to process disparity data efficiently. We also introduce adaptive heuristic techniques for efficiently detecting connected surface components within the images, further improving the robustness of the method. By integrating these methods, we construct a surface normal estimator that is both fast and accurate, producing a dense, oriented point cloud as the final output. Our method is validated using both simulated environments and real-world stereo images from the Middlebury and Cityscapes datasets, demonstrating significant improvements in real-time performance and accuracy when implemented on a GPU. Upon acceptance, the shader source code will be made publicly available to facilitate further research and reproducibility.","authors":["Csongor Csanad Kariko","Muhammad Rafi Faisal","Levente Hajder"],"url":"https://arxiv.org/abs/2504.15121"}
{"created":"2025-04-22","title":"MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry Monocular Video","abstract":"We present MoBGS, a novel deblurring dynamic 3D Gaussian Splatting (3DGS) framework capable of reconstructing sharp and high-quality novel spatio-temporal views from blurry monocular videos in an end-to-end manner. Existing dynamic novel view synthesis (NVS) methods are highly sensitive to motion blur in casually captured videos, resulting in significant degradation of rendering quality. While recent approaches address motion-blurred inputs for NVS, they primarily focus on static scene reconstruction and lack dedicated motion modeling for dynamic objects. To overcome these limitations, our MoBGS introduces a novel Blur-adaptive Latent Camera Estimation (BLCE) method for effective latent camera trajectory estimation, improving global camera motion deblurring. In addition, we propose a physically-inspired Latent Camera-induced Exposure Estimation (LCEE) method to ensure consistent deblurring of both global camera and local object motion. Our MoBGS framework ensures the temporal consistency of unseen latent timestamps and robust motion decomposition of static and dynamic regions. Extensive experiments on the Stereo Blur dataset and real-world blurry videos show that our MoBGS significantly outperforms the very recent advanced methods (DyBluRF and Deblur4DGS), achieving state-of-the-art performance for dynamic NVS under motion blur.","authors":["Minh-Quan Viet Bui","Jongmin Park","Juan Luis Gonzalez Bello","Jaeho Moon","Jihyong Oh","Munchurl Kim"],"url":"https://arxiv.org/abs/2504.15122"}
{"created":"2025-04-22","title":"Contemplative Wisdom for Superalignment","abstract":"As artificial intelligence (AI) improves, traditional alignment strategies may falter in the face of unpredictable self-improvement, hidden subgoals, and the sheer complexity of intelligent systems. Rather than externally constraining behavior, we advocate designing AI with intrinsic morality built into its cognitive architecture and world model. Inspired by contemplative wisdom traditions, we show how four axiomatic principles can instil a resilient Wise World Model in AI systems. First, mindfulness enables self-monitoring and recalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal fixation and relaxes rigid priors. Third, non-duality dissolves adversarial self-other boundaries. Fourth, boundless care motivates the universal reduction of suffering. We find that prompting AI to reflect on these principles improves performance on the AILuminate Benchmark using GPT-4o, particularly when combined. We offer detailed implementation strategies for state-of-the-art models, including contemplative architectures, constitutions, and reinforcement of chain-of-thought. For future systems, the active inference framework may offer the self-organizing and dynamic coupling capabilities needed to enact these insights in embodied agents. This interdisciplinary approach offers a self-correcting and resilient alternative to prevailing brittle control schemes.","authors":["Ruben Laukkonen","Fionn Inglis","Shamil Chandaria","Lars Sandved-Smith","Jakob Hohwy","Jonathan Gold","Adam Elwood"],"url":"https://arxiv.org/abs/2504.15125"}
{"created":"2025-04-22","title":"A General Infrastructure and Workflow for Quadrotor Deep Reinforcement Learning and Reality Deployment","abstract":"Deploying robot learning methods to a quadrotor in unstructured outdoor environments is an exciting task. Quadrotors operating in real-world environments by learning-based methods encounter several challenges: a large amount of simulator generated data required for training, strict demands for real-time processing onboard, and the sim-to-real gap caused by dynamic and noisy conditions. Current works have made a great breakthrough in applying learning-based methods to end-to-end control of quadrotors, but rarely mention the infrastructure system training from scratch and deploying to reality, which makes it difficult to reproduce methods and applications. To bridge this gap, we propose a platform that enables the seamless transfer of end-to-end deep reinforcement learning (DRL) policies. We integrate the training environment, flight dynamics control, DRL algorithms, the MAVROS middleware stack, and hardware into a comprehensive workflow and architecture that enables quadrotors' policies to be trained from scratch to real-world deployment in several minutes. Our platform provides rich types of environments including hovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and planning in unknown environments, as a physical experiment benchmark. Through extensive empirical validation, we demonstrate the efficiency of proposed sim-to-real platform, and robust outdoor flight performance under real-world perturbations. Details can be found from our website https://emnavi.tech/AirGym/.","authors":["Kangyao Huang","Hao Wang","Yu Luo","Jingyu Chen","Jintao Chen","Xiangkui Zhang","Xiangyang Ji","Huaping Liu"],"url":"https://arxiv.org/abs/2504.15129"}
{"created":"2025-04-22","title":"Neural ATTF: A Scalable Solution to Lifelong Multi-Agent Path Planning","abstract":"Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics, particularly in applications such as warehouse automation and logistics. Existing solutions often face challenges in scalability, adaptability, and efficiency, limiting their applicability in dynamic environments with real-time planning requirements. This paper presents Neural ATTF (Adaptive Task Token Framework), a new algorithm that combines a Priority Guided Task Matching (PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning method. Neural STA* enhances path planning by enabling rapid exploration of the search space through guided learned heuristics and ensures collision avoidance under dynamic constraints. PGTM prioritizes delayed agents and dynamically assigns tasks by prioritizing agents nearest to these tasks, optimizing both continuity and system throughput. Experimental evaluations against state-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and LNS-wPBS, demonstrate the superior scalability, solution quality, and computational efficiency of Neural ATTF. These results highlight the framework's potential for addressing the critical demands of complex, real-world multi-agent systems operating in high-demand, unpredictable settings.","authors":["Kushal Shah","Jihyun Park","Seung-Kyum Choi"],"url":"https://arxiv.org/abs/2504.15130"}
{"created":"2025-04-22","title":"Beyond Binary Opinions: A Deep Reinforcement Learning-Based Approach to Uncertainty-Aware Competitive Influence Maximization","abstract":"The Competitive Influence Maximization (CIM) problem involves multiple entities competing for influence in online social networks (OSNs). While Deep Reinforcement Learning (DRL) has shown promise, existing methods often assume users' opinions are binary and ignore their behavior and prior knowledge. We propose DRIM, a multi-dimensional uncertainty-aware DRL-based CIM framework that leverages Subjective Logic (SL) to model uncertainty in user opinions, preferences, and DRL decision-making. DRIM introduces an Uncertainty-based Opinion Model (UOM) for a more realistic representation of user uncertainty and optimizes seed selection for propagating true information while countering false information. In addition, it quantifies uncertainty in balancing exploration and exploitation. Results show that UOM significantly enhances true information spread and maintains influence against advanced false information strategies. DRIM-based CIM schemes outperform state-of-the-art methods by up to 57% and 88% in influence while being up to 48% and 77% faster. Sensitivity analysis indicates that higher network observability and greater information propagation boost performance, while high network activity mitigates the effect of users' initial biases.","authors":["Qi Zhang","Dian Chen","Lance M. Kaplan","Audun J{\\o}sang","Dong Hyun Jeong","Feng Chen","Jin-Hee Cho"],"url":"https://arxiv.org/abs/2504.15131"}
{"created":"2025-04-22","title":"Investigating Youth's Technical and Ethical Understanding of Generative Language Models When Engaging in Construction and Deconstruction Activities","abstract":"The widespread adoption of generative artificial intelligence/machine learning (AI/ML) technologies has increased the need to support youth in developing AI/ML literacies. However, most work has centered on preparing young people to use these systems, with less attention to how they can participate in designing and evaluating them. This study investigates how engaging young people in the design and auditing of generative language models (GLMs) may foster the development of their understanding of how these systems work from both technical and ethical perspectives. The study takes an in-pieces approach to investigate novices' conceptions of GLMs. Such an approach supports the analysis of how technical and ethical conceptions evolve and relate to each other. I am currently conducting a series of participatory design workshops with sixteen ninth graders (ages 14-15) in which they will (a) build GLMs from a data-driven perspective that glassboxes how data shapes model performance and (b) audit commercial GLMs by repeatedly and systematically querying them to draw inferences about their behaviors. I will analyze participants' interactions to identify ethical and technical conceptions they may exhibit while designing and auditing GLMs. I will also conduct clinical interviews and use microgenetic knowledge analysis and ordered network analysis to investigate how participants' ethical and technical conceptions of GLMs relate to each other and change after the workshop. The study will contribute (a) evidence of how engaging youth in design and auditing activities may support the development of ethical and technical understanding of GLMs and (b) an inventory of novice design and auditing practices that may support youth's technical and ethical understanding of GLMs.","authors":["Luis Morales-Navarro"],"url":"https://arxiv.org/abs/2504.15132"}
{"created":"2025-04-22","title":"EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models","abstract":"In this paper, we introduce EasyEdit2, a framework designed to enable plug-and-play adjustability for controlling Large Language Model (LLM) behaviors. EasyEdit2 supports a wide range of test-time interventions, including safety, sentiment, personality, reasoning patterns, factuality, and language features. Unlike its predecessor, EasyEdit2 features a new architecture specifically designed for seamless model steering. It comprises key modules such as the steering vector generator and the steering vector applier, which enable automatic generation and application of steering vectors to influence the model's behavior without modifying its parameters. One of the main advantages of EasyEdit2 is its ease of use-users do not need extensive technical knowledge. With just a single example, they can effectively guide and adjust the model's responses, making precise control both accessible and efficient. Empirically, we report model steering performance across different LLMs, demonstrating the effectiveness of these techniques. We have released the source code on GitHub at https://github.com/zjunlp/EasyEdit along with a demonstration notebook. In addition, we provide a demo video at https://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.","authors":["Ziwen Xu","Shuxun Wang","Kewei Xu","Haoming Xu","Mengru Wang","Xinle Deng","Yunzhi Yao","Guozhou Zheng","Huajun Chen","Ningyu Zhang"],"url":"https://arxiv.org/abs/2504.15133"}
{"created":"2025-04-22","title":"Instance-Adaptive Keypoint Learning with Local-to-Global Geometric Aggregation for Category-Level Object Pose Estimation","abstract":"Category-level object pose estimation aims to predict the 6D pose and size of previously unseen instances from predefined categories, requiring strong generalization across diverse object instances. Although many previous methods attempt to mitigate intra-class variations, they often struggle with instances exhibiting complex geometries or significant deviations from canonical shapes. To address this challenge, we propose INKL-Pose, a novel category-level object pose estimation framework that enables INstance-adaptive Keypoint Learning with local-to-global geometric aggregation. Specifically, our approach first predicts semantically consistent and geometric informative keypoints through an Instance-Adaptive Keypoint Generator, then refines them with: (1) a Local Keypoint Feature Aggregator capturing fine-grained geometries, and (2) a Global Keypoint Feature Aggregator using bidirectional Mamba for structural consistency. To enable bidirectional modeling in Mamba, we introduce a Feature Sequence Flipping strategy that preserves spatial coherence while constructing backward feature sequences. Additionally, we design a surface loss and a separation loss to enforce uniform coverage and spatial diversity in keypoint distribution. The generated keypoints are finally mapped to a canonical space for regressing the object's 6D pose and size. Extensive experiments on CAMERA25, REAL275, and HouseCat6D demonstrate that INKL-Pose achieves state-of-the-art performance and significantly outperforms existing methods.","authors":["Xiao Zhang","Lu Zou","Tao Lu","Yuan Yao","Zhangjin Huang","Guoping Wang"],"url":"https://arxiv.org/abs/2504.15134"}
{"created":"2025-04-22","title":"KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking","abstract":"Entity linking (EL) aligns textual mentions with their corresponding entities in a knowledge base, facilitating various applications such as semantic search and question answering. Recent advances in multimodal entity linking (MEL) have shown that combining text and images can reduce ambiguity and improve alignment accuracy. However, most existing MEL methods overlook the rich structural information available in the form of knowledge-graph (KG) triples. In this paper, we propose KGMEL, a novel framework that leverages KG triples to enhance MEL. Specifically, it operates in three stages: (1) Generation: Produces high-quality triples for each mention by employing vision-language models based on its text and images. (2) Retrieval: Learns joint mention-entity representations, via contrastive learning, that integrate text, images, and (generated or KG) triples to retrieve candidate entities for each mention. (3) Reranking: Refines the KG triples of the candidate entities and employs large language models to identify the best-matching entity for the mention. Extensive experiments on benchmark datasets demonstrate that KGMEL outperforms existing methods. Our code and datasets are available at: https://github.com/juyeonnn/KGMEL.","authors":["Juyeon Kim","Geon Lee","Taeuk Kim","Kijung Shin"],"url":"https://arxiv.org/abs/2504.15135"}
{"created":"2025-04-22","title":"Automatic Generation of Aerobatic Flight in Complex Environments via Diffusion Models","abstract":"Performing striking aerobatic flight in complex environments demands manual designs of key maneuvers in advance, which is intricate and time-consuming as the horizon of the trajectory performed becomes long. This paper presents a novel framework that leverages diffusion models to automate and scale up aerobatic trajectory generation. Our key innovation is the decomposition of complex maneuvers into aerobatic primitives, which are short frame sequences that act as building blocks, featuring critical aerobatic behaviors for tractable trajectory synthesis. The model learns aerobatic primitives using historical trajectory observations as dynamic priors to ensure motion continuity, with additional conditional inputs (target waypoints and optional action constraints) integrated to enable user-editable trajectory generation. During model inference, classifier guidance is incorporated with batch sampling to achieve obstacle avoidance. Additionally, the generated outcomes are refined through post-processing with spatial-temporal trajectory optimization to ensure dynamical feasibility. Extensive simulations and real-world experiments have validated the key component designs of our method, demonstrating its feasibility for deploying on real drones to achieve long-horizon aerobatic flight.","authors":["Yuhang Zhong","Anke Zhao","Tianyue Wu","Tingrui Zhang","Fei Gao"],"url":"https://arxiv.org/abs/2504.15138"}
{"created":"2025-04-22","title":"GIFDL: Generated Image Fluctuation Distortion Learning for Enhancing Steganographic Security","abstract":"Minimum distortion steganography is currently the mainstream method for modification-based steganography. A key issue in this method is how to define steganographic distortion. With the rapid development of deep learning technology, the definition of distortion has evolved from manual design to deep learning design. Concurrently, rapid advancements in image generation have made generated images viable as cover media. However, existing distortion design methods based on machine learning do not fully leverage the advantages of generated cover media, resulting in suboptimal security performance. To address this issue, we propose GIFDL (Generated Image Fluctuation Distortion Learning), a steganographic distortion learning method based on the fluctuations in generated images. Inspired by the idea of natural steganography, we take a series of highly similar fluctuation images as the input to the steganographic distortion generator and introduce a new GAN training strategy to disguise stego images as fluctuation images. Experimental results demonstrate that GIFDL, compared with state-of-the-art GAN-based distortion learning methods, exhibits superior resistance to steganalysis, increasing the detection error rates by an average of 3.30% across three steganalyzers.","authors":["Xiangkun Wang","Kejiang Chen","Yuang Qi","Ruiheng Liu","Weiming Zhang","Nenghai Yu"],"url":"https://arxiv.org/abs/2504.15139"}
{"created":"2025-04-22","title":"Deterministic Depth-4 PIT and Normalization","abstract":"In this paper, we initiate the study of deterministic PIT for $\\Sigma^{[k]}\\Pi\\Sigma\\Pi^{[\\delta]}$ circuits over fields of any characteristic, where $k$ and $\\delta$ are bounded. Our main result is a deterministic polynomial-time black-box PIT algorithm for $\\Sigma^{[3]}\\Pi\\Sigma\\Pi^{[\\delta]}$ circuits, under the additional condition that one of the summands at the top $\\Sigma$ gate is squarefree.","authors":["Zeyu Guo","Siki Wang"],"url":"https://arxiv.org/abs/2504.15143"}
{"created":"2025-04-22","title":"C2RUST-BENCH: A Minimized, Representative Dataset for C-to-Rust Transpilation Evaluation","abstract":"Despite the effort in vulnerability detection over the last two decades, memory safety vulnerabilities continue to be a critical problem. Recent reports suggest that the key solution is to migrate to memory-safe languages. To this end, C-to-Rust transpilation becomes popular to resolve memory-safety issues in C programs. Recent works propose C-to-Rust transpilation frameworks; however, a comprehensive evaluation dataset is missing. Although one solution is to put together a large enough dataset, this increases the analysis time in automated frameworks as well as in manual efforts for some cases. In this work, we build a method to select functions from a large set to construct a minimized yet representative dataset to evaluate the C-to-Rust transpilation. We propose C2RUST-BENCH that contains 2,905 functions, which are representative of C-to-Rust transpilation, selected from 15,503 functions of real-world programs.","authors":["Melih Sirlanci","Carter Yagemann","Zhiqiang Lin"],"url":"https://arxiv.org/abs/2504.15144"}
{"created":"2025-04-22","title":"\"I Know It When I See It\": Mood Spaces for Connecting and Expressing Visual Concepts","abstract":"Expressing complex concepts is easy when they can be labeled or quantified, but many ideas are hard to define yet instantly recognizable. We propose a Mood Board, where users convey abstract concepts with examples that hint at the intended direction of attribute changes. We compute an underlying Mood Space that 1) factors out irrelevant features and 2) finds the connections between images, thus bringing relevant concepts closer. We invent a fibration computation to compress/decompress pre-trained features into/from a compact space, 50-100x smaller. The main innovation is learning to mimic the pairwise affinity relationship of the image tokens across exemplars. To focus on the coarse-to-fine hierarchical structures in the Mood Space, we compute the top eigenvector structure from the affinity matrix and define a loss in the eigenvector space. The resulting Mood Space is locally linear and compact, allowing image-level operations, such as object averaging, visual analogy, and pose transfer, to be performed as a simple vector operation in Mood Space. Our learning is efficient in computation without any fine-tuning, needs only a few (2-20) exemplars, and takes less than a minute to learn.","authors":["Huzheng Yang","Katherine Xu","Michael D. Grossberg","Yutong Bai","Jianbo Shi"],"url":"https://arxiv.org/abs/2504.15145"}
{"created":"2025-04-22","title":"Behavioral Universe Network (BUN): A Behavioral Information-Based Framework for Complex Systems","abstract":"Modern digital ecosystems feature complex, dynamic interactions among autonomous entities across diverse domains. Traditional models often separate agents and objects, lacking a unified foundation to capture their interactive behaviors. This paper introduces the Behavioral Universe Network (BUN), a theoretical framework grounded in the Agent-Interaction-Behavior (AIB) formalism. BUN treats subjects (active agents), objects (resources), and behaviors (operations) as first-class entities, all governed by a shared Behavioral Information Base (BIB). We detail the AIB core concepts and demonstrate how BUN leverages information-driven triggers, semantic enrichment, and adaptive rules to coordinate multi-agent systems. We highlight key benefits: enhanced behavior analysis, strong adaptability, and cross-domain interoperability. We conclude by positioning BUN as a promising foundation for next-generation digital governance and intelligent applications.","authors":["Wei Zhou","Ailiya Borjigin","Cong He"],"url":"https://arxiv.org/abs/2504.15146"}
{"created":"2025-04-22","title":"The Iterative Chainlet Partitioning Algorithm for the Traveling Salesman Problem with Drone and Neural Acceleration","abstract":"This study introduces the Iterative Chainlet Partitioning (ICP) algorithm and its neural acceleration for solving the Traveling Salesman Problem with Drone (TSP-D). The proposed ICP algorithm decomposes a TSP-D solution into smaller segments called chainlets, each optimized individually by a dynamic programming subroutine. The chainlet with the highest improvement is updated and the procedure is repeated until no further improvement is possible. The number of subroutine calls is bounded linearly in problem size for the first iteration and remains constant in subsequent iterations, ensuring algorithmic scalability. Empirical results show that ICP outperforms existing algorithms in both solution quality and computational time. Tested over 1,059 benchmark instances, ICP yields an average improvement of 2.75% in solution quality over the previous state-of-the-art algorithm while reducing computational time by 79.8%. The procedure is deterministic, ensuring reliability without requiring multiple runs. The subroutine is the computational bottleneck in the already efficient ICP algorithm. To reduce the necessity of subroutine calls, we integrate a graph neural network (GNN) to predict incremental improvements. We demonstrate that the resulting Neuro ICP (NICP) achieves substantial acceleration while maintaining solution quality. Compared to ICP, NICP reduces the total computational time by 49.7%, while the objective function value increase is limited to 0.12%. The framework's adaptability to various operational constraints makes it a valuable foundation for developing efficient algorithms for truck-drone synchronized routing problems.","authors":["Jae Hyeok Lee","Minjun Kim","Jinkyoo Park","Changhyun Kwon"],"url":"https://arxiv.org/abs/2504.15147"}
{"created":"2025-04-22","title":"Artificial compressibility method for the incompressible Navier-Stokes equations with variable density","abstract":"We introduce a novel artificial compressibility technique to approximate the incompressible Navier-Stokes equations with variable fluid properties such as density and dynamical viscosity. The proposed scheme used the couple pressure and momentum, equal to the density times the velocity, as primary unknowns. It also involves an adequate treatment of the diffusive operator such that treating the nonlinear convective term explicitly leads to a scheme with time independent stiffness matrices that is suitable for pseudo-spectral methods. The stability and temporal convergence of the semi-implicit version of the scheme is established under the hypothesis that the density is approximated with a method that conserves the minimum-maximum principle. Numerical illustrations confirm that both the semi-implicit and explicit scheme are stable and converge with order one under classic CFL condition. Moreover, the proposed scheme is shown to perform better than a momentum based pressure projection method, previously introduced by one of the authors, on setups involving gravitational waves and immiscible multi-fluids in a cylinder.","authors":["Cappanera Loic","Giordano Salvatore"],"url":"https://arxiv.org/abs/2504.15151"}
{"created":"2025-04-22","title":"Landmark-Free Preoperative-to-Intraoperative Registration in Laparoscopic Liver Resection","abstract":"Liver registration by overlaying preoperative 3D models onto intraoperative 2D frames can assist surgeons in perceiving the spatial anatomy of the liver clearly for a higher surgical success rate. Existing registration methods rely heavily on anatomical landmark-based workflows, which encounter two major limitations: 1) ambiguous landmark definitions fail to provide efficient markers for registration; 2) insufficient integration of intraoperative liver visual information in shape deformation modeling. To address these challenges, in this paper, we propose a landmark-free preoperative-to-intraoperative registration framework utilizing effective self-supervised learning, termed \\ourmodel. This framework transforms the conventional 3D-2D workflow into a 3D-3D registration pipeline, which is then decoupled into rigid and non-rigid registration subtasks. \\ourmodel~first introduces a feature-disentangled transformer to learn robust correspondences for recovering rigid transformations. Further, a structure-regularized deformation network is designed to adjust the preoperative model to align with the intraoperative liver surface. This network captures structural correlations through geometry similarity modeling in a low-rank transformer network. To facilitate the validation of the registration performance, we also construct an in-vivo registration dataset containing liver resection videos of 21 patients, called \\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the liver together with liver mask annotations and calibrated camera intrinsic parameters. Extensive experiments and user studies on both synthetic and in-vivo datasets demonstrate the superiority and potential clinical applicability of our method.","authors":["Jun Zhou","Bingchen Gao","Kai Wang","Jialun Pei","Pheng-Ann Heng","Jing Qin"],"url":"https://arxiv.org/abs/2504.15152"}
{"created":"2025-04-22","title":"Distribution Testing Meets Sum Estimation","abstract":"We study the problem of estimating the sum of $n$ elements, each with weight $w(i)$, in a structured universe. Our goal is to estimate $W = \\sum_{i=1}^n w(i)$ within a $(1 \\pm \\epsilon)$ factor using a sublinear number of samples, assuming weights are non-increasing, i.e., $w(1) \\geq w(2) \\geq \\dots \\geq w(n)$. The sum estimation problem is well-studied under different access models to the universe $U$. However, to the best of our knowledge, nothing is known about the sum estimation problem using non-adaptive conditional sampling. In this work, we explore the sum estimation problem using non-adaptive conditional weighted and non-adaptive conditional uniform samples, assuming that the underlying distribution ($D(i)=w(i)/W$) is monotone. We also extend our approach to to the case where the underlying distribution of $U$ is unimodal. Additionally, we consider support size estimation when $w(i) = 0$ or $w(i) \\geq W/n$, using hybrid sampling (both weighted and uniform) to access $U$. We propose an algorithm to estimate $W$ under the non-increasing weight assumption, using $O(\\frac{1}{\\epsilon^3} \\log{n} + \\frac{1}{\\epsilon^6})$ non-adaptive weighted conditional samples and $O(\\frac{1}{\\epsilon^3} \\log{n})$ uniform conditional samples. Our algorithm matches the $\\Omega(\\log{n})$ lower bound by \\cite{ACK15}. For unimodal distributions, the sample complexity remains similar, with an additional $O(\\log{n})$ evaluation queries to locate the minimum weighted point in the domain. For estimating the support size $k$ of $U$, where weights are either $0$ or at least $W/n$, our algorithm uses $O\\big( \\frac{\\log^3(n/\\epsilon)}{\\epsilon^8} \\cdot \\log^4 \\frac{\\log(n/\\epsilon)}{\\epsilon} \\big)$ uniform samples and $O\\big( \\frac{\\log(n/\\epsilon)}{\\epsilon^2} \\cdot \\log \\frac{\\log(n/\\epsilon)}{\\epsilon} \\big)$ weighted samples to output $\\hat{k}$ satisfying $k - 2\\epsilon n \\leq \\hat{k} \\leq k + \\epsilon n$.","authors":["Pinki Pradhan","Sampriti Roy"],"url":"https://arxiv.org/abs/2504.15153"}
{"created":"2025-04-22","title":"Dynamic 3D KAN Convolution with Adaptive Grid Optimization for Hyperspectral Image Classification","abstract":"Deep neural networks face several challenges in hyperspectral image classification, including high-dimensional data, sparse distribution of ground objects, and spectral redundancy, which often lead to classification overfitting and limited generalization capability. To more efficiently adapt to ground object distributions while extracting image features without introducing excessive parameters and skipping redundant information, this paper proposes KANet based on an improved 3D-DenseNet model, consisting of 3D KAN Conv and an adaptive grid update mechanism. By introducing learnable univariate B-spline functions on network edges, specifically by flattening three-dimensional neighborhoods into vectors and applying B-spline-parameterized nonlinear activation functions to replace the fixed linear weights of traditional 3D convolutional kernels, we precisely capture complex spectral-spatial nonlinear relationships in hyperspectral data. Simultaneously, through a dynamic grid adjustment mechanism, we adaptively update the grid point positions of B-splines based on the statistical characteristics of input data, optimizing the resolution of spline functions to match the non-uniform distribution of spectral features, significantly improving the model's accuracy in high-dimensional data modeling and parameter efficiency, effectively alleviating the curse of dimensionality. This characteristic demonstrates superior neural scaling laws compared to traditional convolutional neural networks and reduces overfitting risks in small-sample and high-noise scenarios. KANet enhances model representation capability through a 3D dynamic expert convolution system without increasing network depth or width. The proposed method demonstrates superior performance on IN, UP, and KSC datasets, outperforming mainstream hyperspectral image classification approaches.","authors":["Guandong Li","Mengxia Ye"],"url":"https://arxiv.org/abs/2504.15155"}
{"created":"2025-04-22","title":"Reconfiguring Proportional Committees","abstract":"An important desideratum in approval-based multiwinner voting is proportionality. We study the problem of reconfiguring proportional committees: given two proportional committees, is there a transition path that consists only of proportional committees, where each transition involves replacing one candidate with another candidate? We show that the set of committees satisfying the proportionality axiom of justified representation (JR) is not always connected, and it is PSPACE-complete to decide whether two such committees are connected. On the other hand, we prove that any two JR committees can be connected by committees satisfying a $2$-approximation of JR. We also obtain similar results for the stronger axiom of extended justified representation (EJR). In addition, we demonstrate that the committees produced by several well-known voting rules are connected or at least not isolated, and investigate the reconfiguration problem in restricted preference domains.","authors":["Chris Dong","Fabian Frank","Jannik Peters","Warut Suksompong"],"url":"https://arxiv.org/abs/2504.15157"}
{"created":"2025-04-22","title":"Acquire and then Adapt: Squeezing out Text-to-Image Model for Image Restoration","abstract":"Recently, pre-trained text-to-image (T2I) models have been extensively adopted for real-world image restoration because of their powerful generative prior. However, controlling these large models for image restoration usually requires a large number of high-quality images and immense computational resources for training, which is costly and not privacy-friendly. In this paper, we find that the well-trained large T2I model (i.e., Flux) is able to produce a variety of high-quality images aligned with real-world distributions, offering an unlimited supply of training samples to mitigate the above issue. Specifically, we proposed a training data construction pipeline for image restoration, namely FluxGen, which includes unconditional image generation, image selection, and degraded image simulation. A novel light-weighted adapter (FluxIR) with squeeze-and-excitation layers is also carefully designed to control the large Diffusion Transformer (DiT)-based T2I model so that reasonable details can be restored. Experiments demonstrate that our proposed method enables the Flux model to adapt effectively to real-world image restoration tasks, achieving superior scores and visual quality on both synthetic and real-world degradation datasets - at only about 8.5\\% of the training cost compared to current approaches.","authors":["Junyuan Deng","Xinyi Wu","Yongxing Yang","Congchao Zhu","Song Wang","Zhenyao Wu"],"url":"https://arxiv.org/abs/2504.15159"}
{"created":"2025-04-22","title":"The Synthetic Imputation Approach: Generating Optimal Synthetic Texts For Underrepresented Categories In Supervised Classification Tasks","abstract":"Encoder-decoder Large Language Models (LLMs), such as BERT and RoBERTa, require that all categories in an annotation task be sufficiently represented in the training data for optimal performance. However, it is often difficult to find sufficient examples for all categories in a task when building a high-quality training set. In this article, I describe this problem and propose a solution, the synthetic imputation approach. Leveraging a generative LLM (GPT-4o), this approach generates synthetic texts based on careful prompting and five original examples drawn randomly with replacement from the sample. This approach ensures that new synthetic texts are sufficiently different from the original texts to reduce overfitting, but retain the underlying substantive meaning of the examples to maximize out-of-sample performance. With 75 original examples or more, synthetic imputation's performance is on par with a full sample of original texts, and overfitting remains low, predictable and correctable with 50 original samples. The synthetic imputation approach provides a novel role for generative LLMs in research and allows applied researchers to balance their datasets for best performance.","authors":["Joan C. Timoneda"],"url":"https://arxiv.org/abs/2504.15160"}
{"created":"2025-04-22","title":"To Offload or Not To Offload: Model-driven Comparison of Edge-native and On-device Processing","abstract":"Computational offloading is a promising approach for overcoming resource constraints on client devices by moving some or all of an application's computations to remote servers. With the advent of specialized hardware accelerators, client devices are now able to perform fast local processing of specific tasks, such as machine learning inference, reducing the need for offloading computations. However, edge servers with accelerators also offer faster processing for offloaded tasks than was previously possible. In this paper, we present an analytic and experimental comparison of on-device processing and edge offloading for a range of accelerator, network, and application workload scenarios, with the goal of understanding when to use local on-device processing and when to offload computations. We present models that leverage analytical queuing results to capture the effects of dynamic factors such as the performance gap between the device and edge server, network variability, server load, and multi-tenancy on the edge server. We experimentally demonstrate the accuracy of our models for a range of hardware and application scenarios and show that our models achieve a mean absolute percentage error of 2.2% compared to observed latencies. We use our models to develop an adaptive resource manager for intelligent offloading and show its efficacy in the presence of variable network conditions and dynamic multi-tenant edge settings.","authors":["Nathan Ng","David Irwin","Ananthram Swami","Don Towsley","Prashant Shenoy"],"url":"https://arxiv.org/abs/2504.15162"}
{"created":"2025-04-22","title":"Survey of Loss Augmented Knowledge Tracing","abstract":"The training of artificial neural networks is heavily dependent on the careful selection of an appropriate loss function. While commonly used loss functions, such as cross-entropy and mean squared error (MSE), generally suffice for a broad range of tasks, challenges often emerge due to limitations in data quality or inefficiencies within the learning process. In such circumstances, the integration of supplementary terms into the loss function can serve to address these challenges, enhancing both model performance and robustness. Two prominent techniques, loss regularization and contrastive learning, have been identified as effective strategies for augmenting the capacity of loss functions in artificial neural networks.","authors":["Altun Shukurlu"],"url":"https://arxiv.org/abs/2504.15163"}
{"created":"2025-04-22","title":"An Efficient Aerial Image Detection with Variable Receptive Fields","abstract":"Aerial object detection using unmanned aerial vehicles (UAVs) faces critical challenges including sub-10px targets, dense occlusions, and stringent computational constraints. Existing detectors struggle to balance accuracy and efficiency due to rigid receptive fields and redundant architectures. To address these limitations, we propose Variable Receptive Field DETR (VRF-DETR), a transformer-based detector incorporating three key components: 1) Multi-Scale Context Fusion (MSCF) module that dynamically recalibrates features through adaptive spatial attention and gated multi-scale fusion, 2) Gated Convolution (GConv) layer enabling parameter-efficient local-context modeling via depthwise separable operations and dynamic gating, and 3) Gated Multi-scale Fusion (GMCF) Bottleneck that hierarchically disentangles occluded objects through cascaded global-local interactions. Experiments on VisDrone2019 demonstrate VRF-DETR achieves 51.4\\% mAP\\textsubscript{50} and 31.8\\% mAP\\textsubscript{50:95} with only 13.5M parameters. This work establishes a new efficiency-accuracy Pareto frontier for UAV-based detection tasks.","authors":["Liu Wenbin"],"url":"https://arxiv.org/abs/2504.15165"}
{"created":"2025-04-22","title":"On true empty category","abstract":"According to Chomsky (1981, 1986), empty categories consist of PRO, pro, trace, and variable. However, some empty object positions seem to be incompatible with extant empty categories. Given this, Li (2007a, 2007b, 2014) and Li & Wei (2014) raise the true empty category hypothesis, which holds that true empty category is only an empty position with category and Case features. As a last resort option, it is used mainly to meet the subcatgorization of a verb. This assumption is ingenious, and if proved to be true, it will exert a great impact on the study of UG. In this paper, we evaluate their evidence from topicalization and demonstrate that it can be accounted for without invoking true empty category.","authors":["Qilin Tian"],"url":"https://arxiv.org/abs/2504.15168"}
{"created":"2025-04-22","title":"HSANET: A Hybrid Self-Cross Attention Network For Remote Sensing Change Detection","abstract":"The remote sensing image change detection task is an essential method for large-scale monitoring. We propose HSANet, a network that uses hierarchical convolution to extract multi-scale features. It incorporates hybrid self-attention and cross-attention mechanisms to learn and fuse global and cross-scale information. This enables HSANet to capture global context at different scales and integrate cross-scale features, refining edge details and improving detection performance. We will also open-source our model code: https://github.com/ChengxiHAN/HSANet.","authors":["Chengxi Han","Xiaoyu Su","Zhiqiang Wei","Meiqi Hu","Yichu Xu"],"url":"https://arxiv.org/abs/2504.15170"}
{"created":"2025-04-22","title":"Audio-Visual Class-Incremental Learning for Fish Feeding intensity Assessment in Aquaculture","abstract":"Fish Feeding Intensity Assessment (FFIA) is crucial in industrial aquaculture management. Recent multi-modal approaches have shown promise in improving FFIA robustness and efficiency. However, these methods face significant challenges when adapting to new fish species or environments due to catastrophic forgetting and the lack of suitable datasets. To address these limitations, we first introduce AV-CIL-FFIA, a new dataset comprising 81,932 labelled audio-visual clips capturing feeding intensities across six different fish species in real aquaculture environments. Then, we pioneer audio-visual class incremental learning (CIL) for FFIA and demonstrate through benchmarking on AV-CIL-FFIA that it significantly outperforms single-modality methods. Existing CIL methods rely heavily on historical data. Exemplar-based approaches store raw samples, creating storage challenges, while exemplar-free methods avoid data storage but struggle to distinguish subtle feeding intensity variations across different fish species. To overcome these limitations, we introduce HAIL-FFIA, a novel audio-visual class-incremental learning framework that bridges this gap with a prototype-based approach that achieves exemplar-free efficiency while preserving essential knowledge through compact feature representations. Specifically, HAIL-FFIA employs hierarchical representation learning with a dual-path knowledge preservation mechanism that separates general intensity knowledge from fish-specific characteristics. Additionally, it features a dynamic modality balancing system that adaptively adjusts the importance of audio versus visual information based on feeding behaviour stages. Experimental results show that HAIL-FFIA is superior to SOTA methods on AV-CIL-FFIA, achieving higher accuracy with lower storage needs while effectively mitigating catastrophic forgetting in incremental fish species learning.","authors":["Meng Cui","Xianghu Yue","Xinyuan Qian","Jinzheng Zhao","Haohe Liu","Xubo Liu","Daoliang Li","Wenwu Wang"],"url":"https://arxiv.org/abs/2504.15171"}
{"created":"2025-04-22","title":"Poroelastic flow across a permeable interface: a Hamilton's principle approach and its finite element implementation","abstract":"We consider fluid flow across a permeable interface within a deformable porous medium. We use mixture theory. The mixture's constituents are assumed to be incompressible in their pure form. We use Hamilton's principle to obtain the governing equations, and we propose a corresponding finite element implementation. The filtration velocity and the pore pressure are allowed to be discontinuous across the interface while some control of these discontinuities is built into the interfacial constitutive behavior. To facilitate the practical implementation of the formulation in a finite element scheme, we introduce a Lagrange multiplier field over the interface for the explicit enforcement of the jump condition of the balance of mass. Our formulation appears to recover some basic results from the literature. The novelty of the work is the formulation of an approach that can accommodate specific constitutive assumptions pertaining to the behavior of the interface that do not necessarily imply the continuity of the filtration velocity and/or of the pore pressure across it.","authors":["Francesco Costanzo (Center for Neural Engineering","Engineering Science and Mechanics Department","Penn State University)","Mohammad Jannesari (Center for Neural Engineering","Engineering Science and Mechanics Department","Penn State University)","Beatrice Ghitti (Center for Neural Engineering","Engineering Science and Mechanics Department","Penn State University","Auckland Bioengineering Institute","The University of Auckland)"],"url":"https://arxiv.org/abs/2504.15173"}
{"created":"2025-04-22","title":"DSPO: Direct Semantic Preference Optimization for Real-World Image Super-Resolution","abstract":"Recent advances in diffusion models have improved Real-World Image Super-Resolution (Real-ISR), but existing methods lack human feedback integration, risking misalignment with human preference and may leading to artifacts, hallucinations and harmful content generation. To this end, we are the first to introduce human preference alignment into Real-ISR, a technique that has been successfully applied in Large Language Models and Text-to-Image tasks to effectively enhance the alignment of generated outputs with human preferences. Specifically, we introduce Direct Preference Optimization (DPO) into Real-ISR to achieve alignment, where DPO serves as a general alignment technique that directly learns from the human preference dataset. Nevertheless, unlike high-level tasks, the pixel-level reconstruction objectives of Real-ISR are difficult to reconcile with the image-level preferences of DPO, which can lead to the DPO being overly sensitive to local anomalies, leading to reduced generation quality. To resolve this dichotomy, we propose Direct Semantic Preference Optimization (DSPO) to align instance-level human preferences by incorporating semantic guidance, which is through two strategies: (a) semantic instance alignment strategy, implementing instance-level alignment to ensure fine-grained perceptual consistency, and (b) user description feedback strategy, mitigating hallucinations through semantic textual feedback on instance-level images. As a plug-and-play solution, DSPO proves highly effective in both one-step and multi-step SR frameworks.","authors":["Miaomiao Cai","Simiao Li","Wei Li","Xudong Huang","Hanting Chen","Jie Hu","Yunhe Wang"],"url":"https://arxiv.org/abs/2504.15176"}
{"created":"2025-04-22","title":"An $rp$-adaptive method for accurate resolution of shock-dominated viscous flow based on implicit shock tracking","abstract":"This work introduces an optimization-based $rp$-adaptive numerical method to approximate solutions of viscous, shock-dominated flows using implicit shock tracking and a high-order discontinuous Galerkin discretization on traditionally coarse grids without nonlinear stabilization (e.g., artificial viscosity or limiting). The proposed method adapts implicit shock tracking methods, originally developed to align mesh faces with solution discontinuities, to compress elements into viscous shocks and boundary layers, functioning as a novel approach to aggressive $r$-adaptation. This form of $r$-adaptation is achieved naturally as the minimizer of the enriched residual with respect to the discrete flow variables and coordinates of the nodes of the grid. Several innovations to the shock tracking optimization solver are proposed to ensure sufficient mesh compression at viscous features to render stabilization unnecessary, including residual weighting, step constraints and modifications, and viscosity-based continuation. Finally, $p$-adaptivity is used to locally increase the polynomial degree with three clear benefits: (1) lessens the mesh compression requirements near shock waves and boundary layers, (2) reduces the error in regions where $r$-adaptivity is not sufficient with the given grid topology, and (3) reduces computational cost by performing a majority of the $r$-adaptivity iterations on the coarsest discretization. A series of numerical experiments show the proposed method effectively resolves viscous, shock-dominated flows, including accurate prediction of heat flux profiles produced by hypersonic flow over a cylinder, and compares favorably in terms of accuracy per degree of freedom to $h$-adaptation with a high-order discretization.","authors":["Huijing Dong","Masayuki Yano","Tianci Huang","Matthew J. Zahr"],"url":"https://arxiv.org/abs/2504.15177"}
{"created":"2025-04-22","title":"FaceCraft4D: Animated 3D Facial Avatar Generation from a Single Image","abstract":"We present a novel framework for generating high-quality, animatable 4D avatar from a single image. While recent advances have shown promising results in 4D avatar creation, existing methods either require extensive multiview data or struggle with shape accuracy and identity consistency. To address these limitations, we propose a comprehensive system that leverages shape, image, and video priors to create full-view, animatable avatars. Our approach first obtains initial coarse shape through 3D-GAN inversion. Then, it enhances multiview textures using depth-guided warping signals for cross-view consistency with the help of the image diffusion model. To handle expression animation, we incorporate a video prior with synchronized driving signals across viewpoints. We further introduce a Consistent-Inconsistent training to effectively handle data inconsistencies during 4D reconstruction. Experimental results demonstrate that our method achieves superior quality compared to the prior art, while maintaining consistency across different viewpoints and expressions.","authors":["Fei Yin","Mallikarjun B R","Chun-Han Yao","Rafa{\\l} Mantiuk","Varun Jampani"],"url":"https://arxiv.org/abs/2504.15179"}
{"created":"2025-04-22","title":"Existing Industry Practice for the EU AI Act's General-Purpose AI Code of Practice Safety and Security Measures","abstract":"This report provides a detailed comparison between the measures proposed in the EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and current practices adopted by leading AI companies. As the EU moves toward enforcing binding obligations for GPAI model providers, the Code of Practice will be key to bridging legal requirements with concrete technical commitments. Our analysis focuses on the draft's Safety and Security section which is only relevant for the providers of the most advanced models (Commitments II.1-II.16) and excerpts from current public-facing documents quotes that are relevant to each individual measure.","authors":["Lily Stelling","Mick Yang","Rokas Gipi\\v{s}kis","Leon Staufer","Ze Shen Chin","Sim\\'eon Campos","Michael Chen"],"url":"https://arxiv.org/abs/2504.15181"}
{"created":"2025-04-22","title":"Tiger200K: Manually Curated High Visual Quality Video Dataset from UGC Platform","abstract":"The recent surge in open-source text-to-video generation models has significantly energized the research community, yet their dependence on proprietary training datasets remains a key constraint. While existing open datasets like Koala-36M employ algorithmic filtering of web-scraped videos from early platforms, they still lack the quality required for fine-tuning advanced video generation models. We present Tiger200K, a manually curated high visual quality video dataset sourced from User-Generated Content (UGC) platforms. By prioritizing visual fidelity and aesthetic quality, Tiger200K underscores the critical role of human expertise in data curation, and providing high-quality, temporally consistent video-text pairs for fine-tuning and optimizing video generation architectures through a simple but effective pipeline including shot boundary detection, OCR, border detecting, motion filter and fine bilingual caption. The dataset will undergo ongoing expansion and be released as an open-source initiative to advance research and applications in video generative models. Project page: https://tinytigerpan.github.io/tiger200k/","authors":["Xianpan Zhou"],"url":"https://arxiv.org/abs/2504.15182"}
{"created":"2025-04-22","title":"ForgeBench: A Machine Learning Benchmark Suite and Auto-Generation Framework for Next-Generation HLS Tools","abstract":"Although High-Level Synthesis (HLS) has attracted considerable interest in hardware design, it has not yet become mainstream due to two primary challenges. First, current HLS hardware design benchmarks are outdated as they do not cover modern machine learning (ML) applications, preventing the rigorous development of HLS tools on ML-focused hardware design. Second, existing HLS tools are outdated because they predominantly target individual accelerator designs and lack an architecture-oriented perspective to support common hardware module extraction and reuse, limiting their adaptability and broader applicability. Motivated by these two limitations, we propose ForgeBench, an ML-focused benchmark suite with a hardware design auto-generation framework for next-generation HLS tools. In addition to the auto-generation framework, we provide two ready-to-use benchmark suites. The first contains over 6,000 representative ML HLS designs. We envision future HLS tools being architecture-oriented, capable of automatically identifying common computational modules across designs, and supporting flexible dataflow and control. Accordingly, the second benchmark suite includes ML HLS designs with possible resource sharing manually implemented to highlight the necessity of architecture-oriented design, ensuring it is future-HLS ready. ForgeBench is open-sourced at https://github.com/hchen799/ForgeBench .","authors":["Andy Wanna (Georgia Institute of Technology)","Hanqiu Chen (Georgia Institute of Technology)","Cong Hao (Georgia Institute of Technology)"],"url":"https://arxiv.org/abs/2504.15185"}
{"created":"2025-04-22","title":"Synergistic Weak-Strong Collaboration by Aligning Preferences","abstract":"Current Large Language Models (LLMs) excel in general reasoning yet struggle with specialized tasks requiring proprietary or domain-specific knowledge. Fine-tuning large models for every niche application is often infeasible due to black-box constraints and high computational overhead. To address this, we propose a collaborative framework that pairs a specialized weak model with a general strong model. The weak model, tailored to specific domains, produces initial drafts and background information, while the strong model leverages its advanced reasoning to refine these drafts, extending LLMs' capabilities to critical yet specialized tasks. To optimize this collaboration, we introduce a collaborative feedback to fine-tunes the weak model, which quantifies the influence of the weak model's contributions in the collaboration procedure and establishes preference pairs to guide preference tuning of the weak model. We validate our framework through experiments on three domains. We find that the collaboration significantly outperforms each model alone by leveraging complementary strengths. Moreover, aligning the weak model with the collaborative preference further enhances overall performance.","authors":["Yizhu Jiao","Xuchao Zhang","Zhaoyang Wang","Yubo Ma","Zhun Deng","Rujia Wang","Chetan Bansal","Saravan Rajmohan","Jiawei Han","Huaxiu Yao"],"url":"https://arxiv.org/abs/2504.15188"}
{"created":"2025-04-22","title":"LACE: Controlled Image Prompting and Iterative Refinement with GenAI for Professional Visual Art Creators","abstract":"We present LACE, a hybrid Human-AI co-creative system integrated into Adobe Photoshop supporting turn-taking and parallel interaction modes for iterative image generation. Through a study with 21 participants across representational, abstract, and design tasks, we found turn-taking preferred in early stages for idea generation, and parallel modes suited for detailed refinement. While this shorter workshop paper provides key insights and highlights, the comprehensive findings and detailed analysis are presented in a longer version available separately on arXiv.","authors":["Yenkai Huang","Ning Zheng"],"url":"https://arxiv.org/abs/2504.15189"}
{"created":"2025-04-22","title":"Breast density in MRI: an AI-based quantification and relationship to assessment in mammography","abstract":"Mammographic breast density is a well-established risk factor for breast cancer. Recently there has been interest in breast MRI as an adjunct to mammography, as this modality provides an orthogonal and highly quantitative assessment of breast tissue. However, its 3D nature poses analytic challenges related to delineating and aggregating complex structures across slices. Here, we applied an in-house machine-learning algorithm to assess breast density on normal breasts in three MRI datasets. Breast density was consistent across different datasets (0.104 - 0.114). Analysis across different age groups also demonstrated strong consistency across datasets and confirmed a trend of decreasing density with age as reported in previous studies. MR breast density was correlated with mammographic breast density, although some notable differences suggest that certain breast density components are captured only on MRI. Future work will determine how to integrate MR breast density with current tools to improve future breast cancer risk prediction.","authors":["Yaqian Chen","Lin Li","Hanxue Gu","Haoyu Dong","Derek L. Nguyen","Allan D. Kirk","Maciej A. Mazurowski","E. Shelley Hwang"],"url":"https://arxiv.org/abs/2504.15192"}
{"created":"2025-04-22","title":"Automated Measurement of Eczema Severity with Self-Supervised Learning","abstract":"Automated diagnosis of eczema using images acquired from digital camera can enable individuals to self-monitor their recovery. The process entails first segmenting out the eczema region from the image and then measuring the severity of eczema in the segmented region. The state-of-the-art methods for automated eczema diagnosis rely on deep neural networks such as convolutional neural network (CNN) and have shown impressive performance in accurately measuring the severity of eczema. However, these methods require massive volume of annotated data to train which can be hard to obtain. In this paper, we propose a self-supervised learning framework for automated eczema diagnosis under limited training data regime. Our framework consists of two stages: i) Segmentation, where we use an in-context learning based algorithm called SegGPT for few-shot segmentation of eczema region from the image; ii) Feature extraction and classification, where we extract DINO features from the segmented regions and feed it to a multi-layered perceptron (MLP) for 4-class classification of eczema severity. When evaluated on a dataset of annotated \"in-the-wild\" eczema images, we show that our method outperforms (Weighted F1: 0.67 $\\pm$ 0.01) the state-of-the-art deep learning methods such as finetuned Resnet-18 (Weighted F1: 0.44 $\\pm$ 0.16) and Vision Transformer (Weighted F1: 0.40 $\\pm$ 0.22). Our results show that self-supervised learning can be a viable solution for automated skin diagnosis where labeled data is scarce.","authors":["Neelesh Kumar","Oya Aran"],"url":"https://arxiv.org/abs/2504.15193"}
{"created":"2025-04-22","title":"Scalable Discrete Event Simulation Tool for Large-Scale Cyber-Physical Energy Systems: Advancing System Efficiency and Scalability","abstract":"Modern power systems face growing risks from cyber-physical attacks, necessitating enhanced resilience due to their societal function as critical infrastructures. The challenge is that defense of large-scale systems-of-systems requires scalability in their threat and risk assessment environment for cyber physical analysis including cyber-informed transmission planning, decision-making, and intrusion response. Hence, we present a scalable discrete event simulation tool for analysis of energy systems, called DESTinE. The tool is tailored for largescale cyber-physical systems, with a focus on power systems. It supports faster-than-real-time traffic generation and models packet flow and congestion under both normal and adversarial conditions. Using three well-established power system synthetic cases with 500, 2000, and 10,000 buses, we overlay a constructed cyber network employing star and radial topologies. Experiments are conducted to identify critical nodes within a communication network in response to a disturbance. The findings are incorporated into a constrained optimization problem to assess the impact of the disturbance on a specific node and its cascading effects on the overall network. Based on the solution of the optimization problem, a new hybrid network topology is also derived, combining the strengths of star and radial structures to improve network resilience. Furthermore, DESTinE is integrated with a virtual server and a hardware-in-the-loop (HIL) system using Raspberry Pi 5.","authors":["Khandaker Akramul Haque","Shining Sun","Xiang Huo","Ana E. Goulart","Katherine R. Davis"],"url":"https://arxiv.org/abs/2504.15198"}
{"created":"2025-04-22","title":"Zero-Shot, But at What Cost? Unveiling the Hidden Overhead of MILS's LLM-CLIP Framework for Image Captioning","abstract":"MILS (Multimodal Iterative LLM Solver) is a recently published framework that claims \"LLMs can see and hear without any training\" by leveraging an iterative, LLM-CLIP based approach for zero-shot image captioning. While this MILS approach demonstrates good performance, our investigation reveals that this success comes at a hidden, substantial computational cost due to its expensive multi-step refinement process. In contrast, alternative models such as BLIP-2 and GPT-4V achieve competitive results through a streamlined, single-pass approach. We hypothesize that the significant overhead inherent in MILS's iterative process may undermine its practical benefits, thereby challenging the narrative that zero-shot performance can be attained without incurring heavy resource demands. This work is the first to expose and quantify the trade-offs between output quality and computational cost in MILS, providing critical insights for the design of more efficient multimodal models.","authors":["Yassir Benhammou","Alessandro Tiberio","Gabriel Trautmann","Suman Kalyan"],"url":"https://arxiv.org/abs/2504.15199"}
{"created":"2025-04-22","title":"Phase-separated lipid vesicles: continuum modeling, simulation, and validation","abstract":"The paper presents a complete research cycle comprising continuum-based modeling, computational framework development, and validation setup to predict phase separation and surface hydrodynamics in lipid bilayer membranes. We starting with an overview of the key physical characteristics of lipid bilayers, including their composition, mechanical properties, and thermodynamics, and then discuss continuum models of multi-component bilayers. The most complex model is a Navier--Stokes--Cahn--Hilliard (NSCH) type system, describing the coupling of incompressible surface fluid dynamics with phase-field dynamics on arbitrarily curved geometries. It is discretized using trace finite element methods, which offer geometric flexibility and stability in representing surface PDEs. Numerical studies are conducted to examine physical features such as coarsening rates and interfacial dynamics. The computational results obtained from the NSCH model are compared against experimental data for membrane compositions with distinct phase behaviors, demonstrating that including both phase-field models and surface hydrodynamics is essential to accurately reproduce domain evolution observed in epi-fluorescence microscopy. Lastly, we extend the model to incorporate external forces that enable the simulation of vesicles containing cationic lipids, used to enhance membrane fusion.","authors":["Maxim Olshanskii","Annalisa Quaini"],"url":"https://arxiv.org/abs/2504.15201"}
{"created":"2025-04-22","title":"Extending the ElGamal Cryptosystem to the Third Group of Units of $\\Z_{n}$","abstract":"In this paper, we extend the ElGamal cryptosystem to the third group of units of the ring $\\Z_{n}$, which we prove to be more secure than the previous extensions. We describe the arithmetic needed in the new setting. We also provide some numerical simulations that shows the security and efficiency of our proposed cryptosystem.","authors":["Jana Hamza","Mohammad EL Hindi","Seifeddine Kadri","Therrar Kadri","Yahya Awad"],"url":"https://arxiv.org/abs/2504.15202"}
{"created":"2025-04-22","title":"Soft-Output from Covered Space Decoding of Product Codes","abstract":"In this work, we propose a new soft-in soft-out decoder called soft-output from covered space (SOCS) decoder. It estimates the a posteriori reliability based on the space explored by a list decoder, i.e., the set of vectors for which the list decoder knows whether they are codewords. This approach enables a more accurate calculation of the a posteriori reliability and results in gains of up to 0.25$\\,$dB for turbo product decoding with SOCS decoding compared to Chase-Pyndiah decoding.","authors":["Tim Janz","Simon Oberm\\\"uller","Andreas Zunker","Stephan ten Brink"],"url":"https://arxiv.org/abs/2504.15204"}
{"created":"2025-04-22","title":"Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus LLM Judges","abstract":"Retrieval-augmented generation (RAG) enables large language models (LLMs) to generate answers with citations from source documents containing \"ground truth\", thereby reducing system hallucinations. A crucial factor in RAG evaluation is \"support\", whether the information in the cited documents supports the answer. To this end, we conducted a large-scale comparative study of 45 participant submissions on 36 topics to the TREC 2024 RAG Track, comparing an automatic LLM judge (GPT-4o) against human judges for support assessment. We considered two conditions: (1) fully manual assessments from scratch and (2) manual assessments with post-editing of LLM predictions. Our results indicate that for 56% of the manual from-scratch assessments, human and GPT-4o predictions match perfectly (on a three-level scale), increasing to 72% in the manual with post-editing condition. Furthermore, by carefully analyzing the disagreements in an unbiased study, we found that an independent human judge correlates better with GPT-4o than a human judge, suggesting that LLM judges can be a reliable alternative for support assessment. To conclude, we provide a qualitative analysis of human and GPT-4o errors to help guide future iterations of support assessment.","authors":["Nandan Thakur","Ronak Pradeep","Shivani Upadhyay","Daniel Campos","Nick Craswell","Jimmy Lin"],"url":"https://arxiv.org/abs/2504.15205"}
{"created":"2025-04-22","title":"How Global Calibration Strengthens Multiaccuracy","abstract":"Multiaccuracy and multicalibration are multigroup fairness notions for prediction that have found numerous applications in learning and computational complexity. They can be achieved from a single learning primitive: weak agnostic learning. Here we investigate the power of multiaccuracy as a learning primitive, both with and without the additional assumption of calibration. We find that multiaccuracy in itself is rather weak, but that the addition of global calibration (this notion is called calibrated multiaccuracy) boosts its power substantially, enough to recover implications that were previously known only assuming the stronger notion of multicalibration.","authors":["S\\'ilvia Casacuberta","Parikshit Gopalan","Varun Kanade","Omer Reingold"],"url":"https://arxiv.org/abs/2504.15206"}
{"created":"2025-04-22","title":"Compute-Optimal LLMs Provably Generalize Better With Scale","abstract":"Why do larger language models generalize better? To investigate this question, we develop generalization bounds on the pretraining objective of large language models (LLMs) in the compute-optimal regime, as described by the Chinchilla scaling laws. We introduce a novel, fully empirical Freedman-type martingale concentration inequality that tightens existing bounds by accounting for the variance of the loss function. This generalization bound can be decomposed into three interpretable components: the number of parameters per token, the loss variance, and the quantization error at a fixed bitrate. As compute-optimal language models are scaled up, the number of parameters per data point remains constant; however, both the loss variance and the quantization error decrease, implying that larger models should have smaller generalization gaps. We examine why larger models tend to be more quantizable from an information theoretic perspective, showing that the rate at which they can integrate new information grows more slowly than their capacity on the compute-optimal frontier. From these findings we produce a scaling law for the generalization gap, with bounds that become predictably stronger with scale.","authors":["Marc Finzi","Sanyam Kapoor","Diego Granziol","Anming Gu","Christopher De Sa","J. Zico Kolter","Andrew Gordon Wilson"],"url":"https://arxiv.org/abs/2504.15208"}
{"created":"2025-04-22","title":"A Causal Convolutional Low-rank Representation Model for Imputation of Water Quality Data","abstract":"The monitoring of water quality is a crucial part of environmental protection, and a large number of monitors are widely deployed to monitor water quality. Due to unavoidable factors such as data acquisition breakdowns, sensors and communication failures, water quality monitoring data suffers from missing values over time, resulting in High-Dimensional and Sparse (HDS) Water Quality Data (WQD). The simple and rough filling of the missing values leads to inaccurate results and affects the implementation of relevant measures. Therefore, this paper proposes a Causal convolutional Low-rank Representation (CLR) model for imputing missing WQD to improve the completeness of the WQD, which employs a two-fold idea: a) applying causal convolutional operation to consider the temporal dependence of the low-rank representation, thus incorporating temporal information to improve the imputation accuracy; and b) implementing a hyperparameters adaptation scheme to automatically adjust the best hyperparameters during model training, thereby reducing the tedious manual adjustment of hyper-parameters. Experimental studies on three real-world water quality datasets demonstrate that the proposed CLR model is superior to some of the existing state-of-the-art imputation models in terms of imputation accuracy and time cost, as well as indicating that the proposed model provides more reliable decision support for environmental monitoring.","authors":["Xin Liao","Bing Yang","Tan Dongli","Cai Yu"],"url":"https://arxiv.org/abs/2504.15209"}
{"created":"2025-04-22","title":"Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs","abstract":"Code-generating Large Language Models (LLMs) have become essential tools in modern software development, enhancing productivity and accelerating development. This paper aims to investigate the fine-tuning of code-generating LLMs using Reinforcement Learning and Direct Preference Optimization, further improving their performance. To achieve this, we enhance the training data for the reward model with the help of symbolic execution techniques, ensuring more comprehensive and objective data. With symbolic execution, we create a custom dataset that better captures the nuances in code evaluation. Our reward models, fine-tuned on this dataset, demonstrate significant improvements over the baseline, CodeRL, in estimating the quality of generated code. Our code-generating LLMs, trained with the help of reward model feedback, achieve similar results compared to the CodeRL benchmark.","authors":["Marina Sakharova","Abhinav Anand","Mira Mezini"],"url":"https://arxiv.org/abs/2504.15210"}
{"created":"2025-04-22","title":"Position: Bayesian Statistics Facilitates Stakeholder Participation in Evaluation of Generative AI","abstract":"The evaluation of Generative AI (GenAI) systems plays a critical role in public policy and decision-making, yet existing methods are often limited by reliance on benchmark-driven, point-estimate comparisons that fail to capture uncertainty and broader societal impacts. This paper argues for the use of Bayesian statistics as a principled framework to address these challenges. Bayesian methods enable the integration of domain expertise through prior elicitation, allow for continuous learning from new data, and provide robust uncertainty quantification via posterior inference. We demonstrate how Bayesian inference can be applied to GenAI evaluation, particularly in incorporating stakeholder perspectives to enhance fairness, transparency, and reliability. Furthermore, we discuss Bayesian workflows as an iterative process for model validation and refinement, ensuring robust assessments of GenAI systems in dynamic, real-world contexts.","authors":["Yanan Long"],"url":"https://arxiv.org/abs/2504.15211"}
{"created":"2025-04-22","title":"Histogram-based Parameter-efficient Tuning for Passive Sonar Classification","abstract":"Parameter-efficient transfer learning (PETL) methods adapt large artificial neural networks to downstream tasks without fine-tuning the entire model. However, existing additive methods, such as adapters, sometimes struggle to capture distributional shifts in intermediate feature embeddings. We propose a novel histogram-based parameter-efficient tuning (HPT) technique that captures the statistics of the target domain and modulates the embeddings. Experimental results on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD) demonstrate that HPT outperforms conventional adapters. Notably, HPT achieves 91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yields feature representations closer to those of fully fine-tuned models. Overall, HPT balances parameter savings and performance, providing a distribution-aware alternative to existing adapters and shows a promising direction for scalable transfer learning in resource-constrained environments. The code is publicly available: https://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.","authors":["Amirmohammad Mohammadi","Davelle Carreiro","Alexandra Van Dine","Joshua Peeples"],"url":"https://arxiv.org/abs/2504.15214"}
{"created":"2025-04-22","title":"An experimental study of the influence of anonymous information on social media users","abstract":"Increasingly, people use social media for their day-to-day interactions and as a source of information, even though much of this information is practically anonymous. This raises the question: does anonymous information influence its recipients? We conducted an online, two-phase, preregistered experiment using a nationally representative sample of participants from the U.S. to find the answer. To avoid biases of opinions among participants, in the first phase, each participant examines ten Rorschach inkblots and chooses one of four opinions assigned to each inkblot. In the second phase, the participants are randomly assigned to one of four distinct information conditions and are asked to revisit their opinions for the same ten inkblots. Conditions ranged from repeating phase one to receiving anonymous comments about certain opinions. Results were consistent with the preregistration. Importantly, anonymous comments shown in phase two influence up to half of the participants' opinion selections. To better understand the role of anonymous comments in influencing the selections of opinions, we implemented agent-based modeling (ABM). ABM results suggest that a straightforward mechanism can explain the impact of such information. Overall, our results indicate that even anonymous information can have a significant impact on its recipients, potentially altering their popularity rankings. However, the strength of such influence weakens when recipients' confidence in their selections increases. Additionally, we found that participants' confidence in the first phase is inversely related to the number of change opinions.","authors":["Boleslaw K. Szymanski","Brendan Cross","John Hulton","James Flamino","Chris Gaiteri","Jonathan Z. Bakdash"],"url":"https://arxiv.org/abs/2504.15215"}
{"created":"2025-04-22","title":"DRAGON: Distributional Rewards Optimize Diffusion Generative Models","abstract":"We present Distributional RewArds for Generative OptimizatioN (DRAGON), a versatile framework for fine-tuning media generation models towards a desired outcome. Compared with traditional reinforcement learning with human feedback (RLHF) or pairwise preference approaches such as direct preference optimization (DPO), DRAGON is more flexible. It can optimize reward functions that evaluate either individual examples or distributions of them, making it compatible with a broad spectrum of instance-wise, instance-to-distribution, and distribution-to-distribution rewards. Leveraging this versatility, we construct novel reward functions by selecting an encoder and a set of reference examples to create an exemplar distribution. When cross-modality encoders such as CLAP are used, the reference examples may be of a different modality (e.g., text versus audio). Then, DRAGON gathers online and on-policy generations, scores them to construct a positive demonstration set and a negative set, and leverages the contrast between the two sets to maximize the reward. For evaluation, we fine-tune an audio-domain text-to-music diffusion model with 20 different reward functions, including a custom music aesthetics model, CLAP score, Vendi diversity, and Frechet audio distance (FAD). We further compare instance-wise (per-song) and full-dataset FAD settings while ablating multiple FAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an 81.45% average win rate. Moreover, reward functions based on exemplar sets indeed enhance generations and are comparable to model-based rewards. With an appropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality win rate without training on human preference annotations. As such, DRAGON exhibits a new approach to designing and optimizing reward functions for improving human-perceived quality. Sound examples at https://ml-dragon.github.io/web.","authors":["Yatong Bai","Jonah Casebeer","Somayeh Sojoudi","Nicholas J. Bryan"],"url":"https://arxiv.org/abs/2504.15217"}
{"created":"2025-04-22","title":"EvalAgent: Discovering Implicit Evaluation Criteria from the Web","abstract":"Evaluation of language model outputs on structured writing tasks is typically conducted with a number of desirable criteria presented to human evaluators or large language models (LLMs). For instance, on a prompt like \"Help me draft an academic talk on coffee intake vs research productivity\", a model response may be evaluated for criteria like accuracy and coherence. However, high-quality responses should do more than just satisfy basic task requirements. An effective response to this query should include quintessential features of an academic talk, such as a compelling opening, clear research questions, and a takeaway. To help identify these implicit criteria, we introduce EvalAgent, a novel framework designed to automatically uncover nuanced and task-specific criteria. EvalAgent first mines expert-authored online guidance. It then uses this evidence to propose diverse, long-tail evaluation criteria that are grounded in reliable external sources. Our experiments demonstrate that the grounded criteria produced by EvalAgent are often implicit (not directly stated in the user's prompt), yet specific (high degree of lexical precision). Further, EvalAgent criteria are often not satisfied by initial responses but they are actionable, such that responses can be refined to satisfy them. Finally, we show that combining LLM-generated and EvalAgent criteria uncovers more human-valued criteria than using LLMs alone.","authors":["Manya Wadhwa","Zayne Sprague","Chaitanya Malaviya","Philippe Laban","Junyi Jessy Li","Greg Durrett"],"url":"https://arxiv.org/abs/2504.15219"}
{"created":"2025-04-22","title":"Fully Bayesian Approaches to Topics over Time","abstract":"The Topics over Time (ToT) model captures thematic changes in timestamped datasets by explicitly modeling publication dates jointly with word co-occurrence patterns. However, ToT was not approached in a fully Bayesian fashion, a flaw that makes it susceptible to stability problems. To address this issue, we propose a fully Bayesian Topics over Time (BToT) model via the introduction of a conjugate prior to the Beta distribution. This prior acts as a regularization that prevents the online version of the algorithm from unstable updates when a topic is poorly represented in a mini-batch. The characteristics of this prior to the Beta distribution are studied here for the first time. Still, this model suffers from a difference in scale between the single-time observations and the multiplicity of words per document. A variation of BToT, Weighted Bayesian Topics over Time (WBToT), is proposed as a solution. In WBToT, publication dates are repeated a certain number of times per document, which balances the relative influence of words and timestamps along the inference process. We have tested our models on two datasets: a collection of over 200 years of US state-of-the-union (SOTU) addresses and a large-scale COVID-19 Twitter corpus of 10 million tweets. The results show that WBToT captures events better than Latent Dirichlet Allocation and other SOTA topic models like BERTopic: the median absolute deviation of the topic presence over time is reduced by $51\\%$ and $34\\%$, respectively. Our experiments also demonstrate the superior coherence of WBToT over BToT, which highlights the importance of balancing the time and word modalities. Finally, we illustrate the stability of the online optimization algorithm in WBToT, which allows the application of WBToT to problems that are intractable for standard ToT.","authors":["Juli\\'an Cendrero","Julio Gonzalo","Ivar Zapata"],"url":"https://arxiv.org/abs/2504.15220"}
{"created":"2025-04-22","title":"A Deep Learning Framework for Sequence Mining with Bidirectional LSTM and Multi-Scale Attention","abstract":"This paper addresses the challenges of mining latent patterns and modeling contextual dependencies in complex sequence data. A sequence pattern mining algorithm is proposed by integrating Bidirectional Long Short-Term Memory (BiLSTM) with a multi-scale attention mechanism. The BiLSTM captures both forward and backward dependencies in sequences, enhancing the model's ability to perceive global contextual structures. At the same time, the multi-scale attention module assigns adaptive weights to key feature regions under different window sizes. This improves the model's responsiveness to both local and global important information. Extensive experiments are conducted on a publicly available multivariate time series dataset. The proposed model is compared with several mainstream sequence modeling methods. Results show that it outperforms existing models in terms of accuracy, precision, and recall. This confirms the effectiveness and robustness of the proposed architecture in complex pattern recognition tasks. Further ablation studies and sensitivity analyses are carried out to investigate the effects of attention scale and input sequence length on model performance. These results provide empirical support for structural optimization of the model.","authors":["Tao Yang","Yu Cheng","Yaokun Ren","Yujia Lou","Minggu Wei","Honghui Xin"],"url":"https://arxiv.org/abs/2504.15223"}
{"created":"2025-04-22","title":"M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global Scoring and Calibrated Thresholding","abstract":"With the widespread availability of sensor data across industrial and operational systems, we frequently encounter heterogeneous time series from multiple systems. Anomaly detection is crucial for such systems to facilitate predictive maintenance. However, most existing anomaly detection methods are designed for either univariate or single-system multivariate data, making them insufficient for these complex scenarios. To address this, we introduce M$^2$AD, a framework for unsupervised anomaly detection in multivariate time series data from multiple systems. M$^2$AD employs deep models to capture expected behavior under normal conditions, using the residuals as indicators of potential anomalies. These residuals are then aggregated into a global anomaly score through a Gaussian Mixture Model and Gamma calibration. We theoretically demonstrate that this framework can effectively address heterogeneity and dependencies across sensors and systems. Empirically, M$^2$AD outperforms existing methods in extensive evaluations by 21% on average, and its effectiveness is demonstrated on a large-scale real-world case study on 130 assets in Amazon Fulfillment Centers. Our code and results are available at https://github.com/sarahmish/M2AD.","authors":["Sarah Alnegheimish","Zelin He","Matthew Reimherr","Akash Chandrayan","Abhinav Pradhan","Luca D'Angelo"],"url":"https://arxiv.org/abs/2504.15225"}
{"created":"2025-04-22","title":"A Genetic Fuzzy-Enabled Framework on Robotic Manipulation for In-Space Servicing","abstract":"Automation of robotic systems for servicing in cislunar space is becoming extremely important as the number of satellites in orbit increases. Safety is critical in performing satellite maintenance, so the control techniques utilized must be trusted in addition to being highly efficient. In this work, Genetic Fuzzy Trees are combined with the widely used LQR control scheme via Thales' TrUE AI Toolkit to create a trusted and efficient controller for a two-degree-of-freedom planar robotic manipulator that would theoretically be used to perform satellite maintenance. It was found that Genetic Fuzzy-LQR is 18.5% more performant than optimal LQR on average, and that it is incredibly robust to uncertainty.","authors":["Nathan Steffen","Wilhelm Louw","Nicholas Ernest","Timothy Arnett","Kelly Cohen"],"url":"https://arxiv.org/abs/2504.15226"}
{"created":"2025-04-22","title":"A Self-Improving Coding Agent","abstract":"We demonstrate that an LLM coding agent, equipped with basic coding tools, can autonomously edit itself, and thereby improve its performance on benchmark tasks. We find performance gains from 17% to 53% on a random subset of SWE Bench Verified, with additional performance gains on LiveCodeBench, as well as synthetically generated agent benchmarks. Our work represents an advancement in the automated and open-ended design of agentic systems, and provides a reference agent framework for those seeking to post-train LLMs on tool use and other agentic tasks.","authors":["Maxime Robeyns","Martin Szummer","Laurence Aitchison"],"url":"https://arxiv.org/abs/2504.15228"}
{"created":"2025-04-22","title":"Immersive Teleoperation Framework for Locomanipulation Tasks","abstract":"Recent advancements in robotic loco-manipulation have leveraged Virtual Reality (VR) to enhance the precision and immersiveness of teleoperation systems, significantly outperforming traditional methods reliant on 2D camera feeds and joystick controls. Despite these advancements, challenges remain, particularly concerning user experience across different setups. This paper introduces a novel VR-based teleoperation framework designed for a robotic manipulator integrated onto a mobile platform. Central to our approach is the application of Gaussian splatting, a technique that abstracts the manipulable scene into a VR environment, thereby enabling more intuitive and immersive interactions. Users can navigate and manipulate within the virtual scene as if interacting with a real robot, enhancing both the engagement and efficacy of teleoperation tasks. An extensive user study validates our approach, demonstrating significant usability and efficiency improvements. Two-thirds (66%) of participants completed tasks faster, achieving an average time reduction of 43%. Additionally, 93% preferred the Gaussian Splat interface overall, with unanimous (100%) recommendations for future use, highlighting improvements in precision, responsiveness, and situational awareness. Finally, we demonstrate the effectiveness of our framework through real-world experiments in two distinct application scenarios, showcasing the practical capabilities and versatility of the Splat-based VR interface.","authors":["Takuya Boehringer","Jonathan Embley-Riches","Karim Hammoud","Valerio Modugno","Dimitrios Kanoulas"],"url":"https://arxiv.org/abs/2504.15229"}
{"created":"2025-04-22","title":"Linear Complementary Pairs of Quasi-Cyclic and Quasi-Twisted Codes","abstract":"In this paper, we provide a polynomial characterization of linear complementary pairs of quasi-cyclic and quasi-twisted codes of index 2. We also give several examples of linear complementary pairs of quasi-cyclic and quasi-twisted codes with (almost) optimal security parameters.","authors":["Kanat Abdukhalikov","Duy Ho","San Ling","Gyanendra K. Verma"],"url":"https://arxiv.org/abs/2504.15231"}
{"created":"2025-04-22","title":"Shape-Guided Clothing Warping for Virtual Try-On","abstract":"Image-based virtual try-on aims to seamlessly fit in-shop clothing to a person image while maintaining pose consistency. Existing methods commonly employ the thin plate spline (TPS) transformation or appearance flow to deform in-shop clothing for aligning with the person's body. Despite their promising performance, these methods often lack precise control over fine details, leading to inconsistencies in shape between clothing and the person's body as well as distortions in exposed limb regions. To tackle these challenges, we propose a novel shape-guided clothing warping method for virtual try-on, dubbed SCW-VTON, which incorporates global shape constraints and additional limb textures to enhance the realism and consistency of the warped clothing and try-on results. To integrate global shape constraints for clothing warping, we devise a dual-path clothing warping module comprising a shape path and a flow path. The former path captures the clothing shape aligned with the person's body, while the latter path leverages the mapping between the pre- and post-deformation of the clothing shape to guide the estimation of appearance flow. Furthermore, to alleviate distortions in limb regions of try-on results, we integrate detailed limb guidance by developing a limb reconstruction network based on masked image modeling. Through the utilization of SCW-VTON, we are able to generate try-on results with enhanced clothing shape consistency and precise control over details. Extensive experiments demonstrate the superiority of our approach over state-of-the-art methods both qualitatively and quantitatively. The code is available at https://github.com/xyhanHIT/SCW-VTON.","authors":["Xiaoyu Han","Shunyuan Zheng","Zonglin Li","Chenyang Wang","Xin Sun","Quanling Meng"],"url":"https://arxiv.org/abs/2504.15232"}
{"created":"2025-04-22","title":"A Review on Privacy in DAG-Based DLTs","abstract":"Directed Acyclic Graph (DAG)-based Distributed Ledger Technologies (DLTs) have emerged as a promising solution to the scalability issues inherent in traditional blockchains. However, amidst the focus on scalability, the crucial aspect of privacy within DAG-based DLTs has been largely overlooked. This paper seeks to address this gap by providing a comprehensive examination of privacy notions and challenges within DAG-based DLTs. We delve into potential methodologies to enhance privacy within these systems, while also analyzing the associated hurdles and real-world implementations within state-of-the-art DAG-based DLTs. By exploring these methodologies, we not only illuminate the current landscape of privacy in DAG-based DLTs but also outline future research directions in this evolving field.","authors":["Mayank Raikwar"],"url":"https://arxiv.org/abs/2504.15233"}
{"created":"2025-04-22","title":"Cascade IPG Observer for Underwater Robot State Estimation","abstract":"This paper presents a novel cascade nonlinear observer framework for inertial state estimation. It tackles the problem of intermediate state estimation when external localization is unavailable or in the event of a sensor outage. The proposed observer comprises two nonlinear observers based on a recently developed iteratively preconditioned gradient descent (IPG) algorithm. It takes the inputs via an IMU preintegration model where the first observer is a quaternion-based IPG. The output for the first observer is the input for the second observer, estimating the velocity and, consequently, the position. The proposed observer is validated on a public underwater dataset and a real-world experiment using our robot platform. The estimation is compared with an extended Kalman filter (EKF) and an invariant extended Kalman filter (InEKF). Results demonstrate that our method outperforms these methods regarding better positional accuracy and lower variance.","authors":["Kaustubh Joshi","Tianchen Liu","Nikhil Chopra"],"url":"https://arxiv.org/abs/2504.15235"}
{"created":"2025-04-22","title":"Values in the Wild: Discovering and Analyzing Values in Real-World Language Model Interactions","abstract":"AI assistants can impart value judgments that shape people's decisions and worldviews, yet little is known empirically about what values these systems rely on in practice. To address this, we develop a bottom-up, privacy-preserving method to extract the values (normative considerations stated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit in hundreds of thousands of real-world interactions. We empirically discover and taxonomize 3,307 AI values and study how they vary by context. We find that Claude expresses many practical and epistemic values, and typically supports prosocial human values while resisting values like \"moral nihilism\". While some values appear consistently across contexts (e.g. \"transparency\"), many are more specialized and context-dependent, reflecting the diversity of human interlocutors and their varied contexts. For example, \"harm prevention\" emerges when Claude resists users, \"historical accuracy\" when responding to queries about controversial events, \"healthy boundaries\" when asked for relationship advice, and \"human agency\" in technology ethics discussions. By providing the first large-scale empirical mapping of AI values in deployment, our work creates a foundation for more grounded evaluation and design of values in AI systems.","authors":["Saffron Huang","Esin Durmus","Miles McCain","Kunal Handa","Alex Tamkin","Jerry Hong","Michael Stern","Arushi Somani","Xiuruo Zhang","Deep Ganguli"],"url":"https://arxiv.org/abs/2504.15236"}
{"created":"2025-04-22","title":"Conformalized-KANs: Uncertainty Quantification with Coverage Guarantees for Kolmogorov-Arnold Networks (KANs) in Scientific Machine Learning","abstract":"This paper explores uncertainty quantification (UQ) methods in the context of Kolmogorov-Arnold Networks (KANs). We apply an ensemble approach to KANs to obtain a heuristic measure of UQ, enhancing interpretability and robustness in modeling complex functions. Building on this, we introduce Conformalized-KANs, which integrate conformal prediction, a distribution-free UQ technique, with KAN ensembles to generate calibrated prediction intervals with guaranteed coverage. Extensive numerical experiments are conducted to evaluate the effectiveness of these methods, focusing particularly on the robustness and accuracy of the prediction intervals under various hyperparameter settings. We show that the conformal KAN predictions can be applied to recent extensions of KANs, including Finite Basis KANs (FBKANs) and multifideilty KANs (MFKANs). The results demonstrate the potential of our approaches to improve the reliability and applicability of KANs in scientific machine learning.","authors":["Amirhossein Mollaali","Christian Bolivar Moya","Amanda A. Howard","Alexander Heinlein","Panos Stinis","Guang Lin"],"url":"https://arxiv.org/abs/2504.15240"}
{"created":"2025-04-22","title":"MR. Guard: Multilingual Reasoning Guardrail using Curriculum Learning","abstract":"Large Language Models (LLMs) are susceptible to adversarial attacks such as jailbreaking, which can elicit harmful or unsafe behaviors. This vulnerability is exacerbated in multilingual setting, where multilingual safety-aligned data are often limited. Thus, developing a guardrail capable of detecting and filtering unsafe content across diverse languages is critical for deploying LLMs in real-world applications. In this work, we propose an approach to build a multilingual guardrail with reasoning. Our method consists of: (1) synthetic multilingual data generation incorporating culturally and linguistically nuanced variants, (2) supervised fine-tuning, and (3) a curriculum-guided Group Relative Policy Optimization (GRPO) framework that further improves performance. Experimental results demonstrate that our multilingual guardrail consistently outperforms recent baselines across both in-domain and out-of-domain languages. The multilingual reasoning capability of our guardrail enables it to generate multilingual explanations, which are particularly useful for understanding language-specific risks and ambiguities in multilingual content moderation.","authors":["Yahan Yang","Soham Dan","Shuo Li","Dan Roth","Insup Lee"],"url":"https://arxiv.org/abs/2504.15241"}
{"created":"2025-04-22","title":"Single-loop Algorithms for Stochastic Non-convex Optimization with Weakly-Convex Constraints","abstract":"Constrained optimization with multiple functional inequality constraints has significant applications in machine learning. This paper examines a crucial subset of such problems where both the objective and constraint functions are weakly convex. Existing methods often face limitations, including slow convergence rates or reliance on double-loop algorithmic designs. To overcome these challenges, we introduce a novel single-loop penalty-based stochastic algorithm. Following the classical exact penalty method, our approach employs a {\\bf hinge-based penalty}, which permits the use of a constant penalty parameter, enabling us to achieve a {\\bf state-of-the-art complexity} for finding an approximate Karush-Kuhn-Tucker (KKT) solution. We further extend our algorithm to address finite-sum coupled compositional objectives, which are prevalent in artificial intelligence applications, establishing improved complexity over existing approaches. Finally, we validate our method through experiments on fair learning with receiver operating characteristic (ROC) fairness constraints and continual learning with non-forgetting constraints.","authors":["Ming Yang","Gang Li","Quanqi Hu","Qihang Lin","Tianbao Yang"],"url":"https://arxiv.org/abs/2504.15243"}
{"created":"2025-04-22","title":"Faster Algorithms for Agnostically Learning Disjunctions and their Implications","abstract":"We study the algorithmic task of learning Boolean disjunctions in the distribution-free agnostic PAC model. The best known agnostic learner for the class of disjunctions over $\\{0, 1\\}^n$ is the $L_1$-polynomial regression algorithm, achieving complexity $2^{\\tilde{O}(n^{1/2})}$. This complexity bound is known to be nearly best possible within the class of Correlational Statistical Query (CSQ) algorithms. In this work, we develop an agnostic learner for this concept class with complexity $2^{\\tilde{O}(n^{1/3})}$. Our algorithm can be implemented in the Statistical Query (SQ) model, providing the first separation between the SQ and CSQ models in distribution-free agnostic learning.","authors":["Ilias Diakonikolas","Daniel M. Kane","Lisheng Ren"],"url":"https://arxiv.org/abs/2504.15244"}
{"created":"2025-04-22","title":"A Refreshment Stirred, Not Shaken (III): Can Swapping Be Differentially Private?","abstract":"The quest for a precise and contextually grounded answer to the question in the present paper's title resulted in this stirred-not-shaken triptych, a phrase that reflects our desire to deepen the theoretical basis, broaden the practical applicability, and reduce the misperception of differential privacy (DP)$\\unicode{x2014}$all without shaking its core foundations. Indeed, given the existence of more than 200 formulations of DP (and counting), before even attempting to answer the titular question one must first precisely specify what it actually means to be DP. Motivated by this observation, a theoretical investigation into DP's fundamental essence resulted in Part I of this trio, which introduces a five-building-block system explicating the who, where, what, how and how much aspects of DP. Instantiating this system in the context of the United States Decennial Census, Part II then demonstrates the broader applicability and relevance of DP by comparing a swapping strategy like that used in 2010 with the TopDown Algorithm$\\unicode{x2014}$a DP method adopted in the 2020 Census. This paper provides nontechnical summaries of the preceding two parts as well as new discussion$\\unicode{x2014}$for example, on how greater awareness of the five building blocks can thwart privacy theatrics; how our results bridging traditional SDC and DP allow a data custodian to reap the benefits of both these fields; how invariants impact disclosure risk; and how removing the implicit reliance on aleatoric uncertainty could lead to new generalizations of DP.","authors":["James Bailie","Ruobin Gong","Xiao-Li Meng"],"url":"https://arxiv.org/abs/2504.15246"}
{"created":"2025-04-22","title":"Lance: Efficient Random Access in Columnar Storage through Adaptive Structural Encodings","abstract":"The growing interest in artificial intelligence has created workloads that require both sequential and random access. At the same time, NVMe-backed storage solutions have emerged, providing caching capability for large columnar datasets in cloud storage. Current columnar storage libraries fall short of effectively utilizing an NVMe device's capabilities, especially when it comes to random access. Historically, this has been assumed an implicit weakness in columnar storage formats, but this has not been sufficiently explored. In this paper, we examine the effectiveness of popular columnar formats such as Apache Arrow, Apache Parquet, and Lance in both random access and full scan tasks against NVMe storage.","authors":["Weston Pace","Chang She","Lei Xu","Will Jones","Albert Lockett","Jun Wang","Raunak Shah"],"url":"https://arxiv.org/abs/2504.15247"}
{"created":"2025-04-22","title":"On Learning Parallel Pancakes with Mostly Uniform Weights","abstract":"We study the complexity of learning $k$-mixtures of Gaussians ($k$-GMMs) on $\\mathbb{R}^d$. This task is known to have complexity $d^{\\Omega(k)}$ in full generality. To circumvent this exponential lower bound on the number of components, research has focused on learning families of GMMs satisfying additional structural properties. A natural assumption posits that the component weights are not exponentially small and that the components have the same unknown covariance. Recent work gave a $d^{O(\\log(1/w_{\\min}))}$-time algorithm for this class of GMMs, where $w_{\\min}$ is the minimum weight. Our first main result is a Statistical Query (SQ) lower bound showing that this quasi-polynomial upper bound is essentially best possible, even for the special case of uniform weights. Specifically, we show that it is SQ-hard to distinguish between such a mixture and the standard Gaussian. We further explore how the distribution of weights affects the complexity of this task. Our second main result is a quasi-polynomial upper bound for the aforementioned testing task when most of the weights are uniform while a small fraction of the weights are potentially arbitrary.","authors":["Ilias Diakonikolas","Daniel M. Kane","Sushrut Karmalkar","Jasper C. H. Lee","Thanasis Pittas"],"url":"https://arxiv.org/abs/2504.15251"}
{"created":"2025-04-22","title":"SuoiAI: Building a Dataset for Aquatic Invertebrates in Vietnam","abstract":"Understanding and monitoring aquatic biodiversity is critical for ecological health and conservation efforts. This paper proposes SuoiAI, an end-to-end pipeline for building a dataset of aquatic invertebrates in Vietnam and employing machine learning (ML) techniques for species classification. We outline the methods for data collection, annotation, and model training, focusing on reducing annotation effort through semi-supervised learning and leveraging state-of-the-art object detection and classification models. Our approach aims to overcome challenges such as data scarcity, fine-grained classification, and deployment in diverse environmental conditions.","authors":["Tue Vo","Lakshay Sharma","Tuan Dinh","Khuong Dinh","Trang Nguyen","Trung Phan","Minh Do","Duong Vu"],"url":"https://arxiv.org/abs/2504.15252"}
{"created":"2025-04-22","title":"Evaluating Judges as Evaluators: The JETTS Benchmark of LLM-as-Judges as Test-Time Scaling Evaluators","abstract":"Scaling test-time computation, or affording a generator large language model (LLM) extra compute during inference, typically employs the help of external non-generative evaluators (i.e., reward models). Concurrently, LLM-judges, models trained to generate evaluations and critiques (explanations) in natural language, are becoming increasingly popular in automatic evaluation. Despite judge empirical successes, their effectiveness as evaluators in test-time scaling settings is largely unknown. In this paper, we introduce the Judge Evaluation for Test-Time Scaling (JETTS) benchmark, which evaluates judge performance in three domains (math reasoning, code generation, and instruction following) under three task settings: response reranking, step-level beam search, and critique-based response refinement. We evaluate 10 different judge models (7B-70B parameters) for 8 different base generator models (6.7B-72B parameters). Our benchmark shows that while judges are competitive with outcome reward models in reranking, they are consistently worse than process reward models in beam search procedures. Furthermore, though unique to LLM-judges, their natural language critiques are currently ineffective in guiding the generator towards better responses.","authors":["Yilun Zhou","Austin Xu","Peifeng Wang","Caiming Xiong","Shafiq Joty"],"url":"https://arxiv.org/abs/2504.15253"}
{"created":"2025-04-22","title":"CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation","abstract":"C-to-Rust transpilation is essential for modernizing legacy C code while enhancing safety and interoperability with modern Rust ecosystems. However, no dataset currently exists for evaluating whether a system can transpile C into safe Rust that passes a set of test cases. We introduce CRUST-Bench, a dataset of 100 C repositories, each paired with manually-written interfaces in safe Rust as well as test cases that can be used to validate correctness of the transpilation. By considering entire repositories rather than isolated functions, CRUST-Bench captures the challenges of translating complex projects with dependencies across multiple files. The provided Rust interfaces provide explicit specifications that ensure adherence to idiomatic, memory-safe Rust patterns, while the accompanying test cases enforce functional correctness. We evaluate state-of-the-art large language models (LLMs) on this task and find that safe and idiomatic Rust generation is still a challenging problem for various state-of-the-art methods and techniques. We also provide insights into the errors LLMs usually make in transpiling code from C to safe Rust. The best performing model, OpenAI o1, is able to solve only 15 tasks in a single-shot setting. Improvements on CRUST-Bench would lead to improved transpilation systems that can reason about complex scenarios and help in migrating legacy codebases from C into languages like Rust that ensure memory safety. You can find the dataset and code at https://github.com/anirudhkhatry/CRUST-bench.","authors":["Anirudh Khatry","Robert Zhang","Jia Pan","Ziteng Wang","Qiaochu Chen","Greg Durrett","Isil Dillig"],"url":"https://arxiv.org/abs/2504.15254"}
{"created":"2025-04-22","title":"FlowReasoner: Reinforcing Query-Level Meta-Agents","abstract":"This paper proposes a query-level meta-agent named FlowReasoner to automate the design of query-level multi-agent systems, i.e., one system per user query. Our core idea is to incentivize a reasoning-based meta-agent via external execution feedback. Concretely, by distilling DeepSeek R1, we first endow the basic reasoning ability regarding the generation of multi-agent systems to FlowReasoner. Then, we further enhance it via reinforcement learning (RL) with external execution feedback. A multi-purpose reward is designed to guide the RL training from aspects of performance, complexity, and efficiency. In this manner, FlowReasoner is enabled to generate a personalized multi-agent system for each user query via deliberative reasoning. Experiments on both engineering and competition code benchmarks demonstrate the superiority of FlowReasoner. Remarkably, it surpasses o1-mini by 10.52% accuracy across three benchmarks. The code is available at https://github.com/sail-sg/FlowReasoner.","authors":["Hongcheng Gao","Yue Liu","Yufei He","Longxu Dou","Chao Du","Zhijie Deng","Bryan Hooi","Min Lin","Tianyu Pang"],"url":"https://arxiv.org/abs/2504.15257"}
{"created":"2025-04-22","title":"Bringing Diversity from Diffusion Models to Semantic-Guided Face Asset Generation","abstract":"Digital modeling and reconstruction of human faces serve various applications. However, its availability is often hindered by the requirements of data capturing devices, manual labor, and suitable actors. This situation restricts the diversity, expressiveness, and control over the resulting models. This work aims to demonstrate that a semantically controllable generative network can provide enhanced control over the digital face modeling process. To enhance diversity beyond the limited human faces scanned in a controlled setting, we introduce a novel data generation pipeline that creates a high-quality 3D face database using a pre-trained diffusion model. Our proposed normalization module converts synthesized data from the diffusion model into high-quality scanned data. Using the 44,000 face models we obtained, we further developed an efficient GAN-based generator. This generator accepts semantic attributes as input, and generates geometry and albedo. It also allows continuous post-editing of attributes in the latent space. Our asset refinement component subsequently creates physically-based facial assets. We introduce a comprehensive system designed for creating and editing high-quality face assets. Our proposed model has undergone extensive experiment, comparison and evaluation. We also integrate everything into a web-based interactive tool. We aim to make this tool publicly available with the release of the paper.","authors":["Yunxuan Cai","Sitao Xiang","Zongjian Li","Haiwei Chen","Yajie Zhao"],"url":"https://arxiv.org/abs/2504.15259"}
{"created":"2025-04-22","title":"Leveraging Language Models for Automated Patient Record Linkage","abstract":"Objective: Healthcare data fragmentation presents a major challenge for linking patient data, necessitating robust record linkage to integrate patient records from diverse sources. This study investigates the feasibility of leveraging language models for automated patient record linkage, focusing on two key tasks: blocking and matching. Materials and Methods: We utilized real-world healthcare data from the Missouri Cancer Registry and Research Center, linking patient records from two independent sources using probabilistic linkage as a baseline. A transformer-based model, RoBERTa, was fine-tuned for blocking using sentence embeddings. For matching, several language models were experimented under fine-tuned and zero-shot settings, assessing their performance against ground truth labels. Results: The fine-tuned blocking model achieved a 92% reduction in the number of candidate pairs while maintaining near-perfect recall. In the matching task, fine-tuned Mistral-7B achieved the best performance with only 6 incorrect predictions. Among zero-shot models, Mistral-Small-24B performed best, with a total of 55 incorrect predictions. Discussion: Fine-tuned language models achieved strong performance in patient record blocking and matching with minimal errors. However, they remain less accurate and efficient than a hybrid rule-based and probabilistic approach for blocking. Additionally, reasoning models like DeepSeek-R1 are impractical for large-scale record linkage due to high computational costs. Conclusion: This study highlights the potential of language models for automating patient record linkage, offering improved efficiency by eliminating the manual efforts required to perform patient record linkage. Overall, language models offer a scalable solution that can enhance data integration, reduce manual effort, and support disease surveillance and research.","authors":["Mohammad Beheshti","Lovedeep Gondara","Iris Zachary"],"url":"https://arxiv.org/abs/2504.15261"}
{"created":"2025-04-22","title":"Interpretable Locomotion Prediction in Construction Using a Memory-Driven LLM Agent With Chain-of-Thought Reasoning","abstract":"Construction tasks are inherently unpredictable, with dynamic environments and safety-critical demands posing significant risks to workers. Exoskeletons offer potential assistance but falter without accurate intent recognition across diverse locomotion modes. This paper presents a locomotion prediction agent leveraging Large Language Models (LLMs) augmented with memory systems, aimed at improving exoskeleton assistance in such settings. Using multimodal inputs - spoken commands and visual data from smart glasses - the agent integrates a Perception Module, Short-Term Memory (STM), Long-Term Memory (LTM), and Refinement Module to predict locomotion modes effectively. Evaluation reveals a baseline weighted F1-score of 0.73 without memory, rising to 0.81 with STM, and reaching 0.90 with both STM and LTM, excelling with vague and safety-critical commands. Calibration metrics, including a Brier Score drop from 0.244 to 0.090 and ECE from 0.222 to 0.044, affirm improved reliability. This framework supports safer, high-level human-exoskeleton collaboration, with promise for adaptive assistive systems in dynamic industries.","authors":["Ehsan Ahmadi","Chao Wang"],"url":"https://arxiv.org/abs/2504.15263"}
{"created":"2025-04-22","title":"Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction","abstract":"We design a suite of minimal algorithmic tasks that are a loose abstraction of open-ended real-world tasks. This allows us to cleanly and controllably quantify the creative limits of the present-day language model. Much like real-world tasks that require a creative, far-sighted leap of thought, our tasks require an implicit, open-ended stochastic planning step that either (a) discovers new connections in an abstract knowledge graph (like in wordplay, drawing analogies, or research) or (b) constructs new patterns (like in designing math problems or new proteins). In these tasks, we empirically and conceptually argue how next-token learning is myopic and memorizes excessively; comparatively, multi-token approaches, namely teacherless training and diffusion models, excel in producing diverse and original output. Secondly, in our tasks, we find that to elicit randomness from the Transformer without hurting coherence, it is better to inject noise right at the input layer (via a method we dub hash-conditioning) rather than defer to temperature sampling from the output layer. Thus, our work offers a principled, minimal test-bed for analyzing open-ended creative skills, and offers new arguments for going beyond next-token learning and softmax-based sampling. We make part of the code available under https://github.com/chenwu98/algorithmic-creativity","authors":["Vaishnavh Nagarajan","Chen Henry Wu","Charles Ding","Aditi Raghunathan"],"url":"https://arxiv.org/abs/2504.15266"}
{"created":"2025-04-22","title":"Diffusion Bridge Models for 3D Medical Image Translation","abstract":"Diffusion tensor imaging (DTI) provides crucial insights into the microstructure of the human brain, but it can be time-consuming to acquire compared to more readily available T1-weighted (T1w) magnetic resonance imaging (MRI). To address this challenge, we propose a diffusion bridge model for 3D brain image translation between T1w MRI and DTI modalities. Our model learns to generate high-quality DTI fractional anisotropy (FA) images from T1w images and vice versa, enabling cross-modality data augmentation and reducing the need for extensive DTI acquisition. We evaluate our approach using perceptual similarity, pixel-level agreement, and distributional consistency metrics, demonstrating strong performance in capturing anatomical structures and preserving information on white matter integrity. The practical utility of the synthetic data is validated through sex classification and Alzheimer's disease classification tasks, where the generated images achieve comparable performance to real data. Our diffusion bridge model offers a promising solution for improving neuroimaging datasets and supporting clinical decision-making, with the potential to significantly impact neuroimaging research and clinical practice.","authors":["Shaorong Zhang","Tamoghna Chattopadhyay","Sophia I. Thomopoulos","Jose-Luis Ambite","Paul M. Thompson","Greg Ver Steeg"],"url":"https://arxiv.org/abs/2504.15267"}
{"created":"2025-04-22","title":"An LMM for Efficient Video Understanding via Reinforced Compression of Video Cubes","abstract":"Large Multimodal Models (LMMs) uniformly perceive video frames, creating computational inefficiency for videos with inherently varying temporal information density. This paper present \\textbf{Quicksviewer}, an LMM with new perceiving paradigm that partitions a video of nonuniform density into varying cubes using Gumbel Softmax, followed by a unified resampling for each cube to achieve efficient video understanding. This simple and intuitive approach dynamically compress video online based on its temporal density, significantly reducing spatiotemporal redundancy (overall 45$\\times$ compression rate), while enabling efficient training with large receptive field. We train the model from a language backbone through three progressive stages, each incorporating lengthy videos on average of 420s/1fps thanks to the perceiving efficiency. With only 0.8M total video-text samples for training, our model outperforms the direct baseline employing a fixed partitioning strategy by a maximum of 8.72 in accuracy, demonstrating the effectiveness in performance. On Video-MME, Quicksviewer achieves SOTA under modest sequence lengths using just up to 5\\% of tokens per frame required by baselines. With this paradigm, scaling up the number of input frames reveals a clear power law of the model capabilities. It is also empirically verified that the segments generated by the cubing network can help for analyzing continuous events in videos.","authors":["Ji Qi","Yuan Yao","Yushi Bai","Bin Xu","Juanzi Li","Zhiyuan Liu","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2504.15270"}
{"created":"2025-04-22","title":"Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models","abstract":"We introduce Eagle 2.5, a family of frontier vision-language models (VLMs) for long-context multimodal learning. Our work addresses the challenges in long video comprehension and high-resolution image understanding, introducing a generalist framework for both tasks. The proposed training framework incorporates Automatic Degrade Sampling and Image Area Preservation, two techniques that preserve contextual integrity and visual details. The framework also includes numerous efficiency optimizations in the pipeline for long-context data training. Finally, we propose Eagle-Video-110K, a novel dataset that integrates both story-level and clip-level annotations, facilitating long-video understanding. Eagle 2.5 demonstrates substantial improvements on long-context multimodal benchmarks, providing a robust solution to the limitations of existing VLMs. Notably, our best model Eagle 2.5-8B achieves 72.4% on Video-MME with 512 input frames, matching the results of top-tier commercial model such as GPT-4o and large-scale open-source models like Qwen2.5-VL-72B and InternVL2.5-78B.","authors":["Guo Chen","Zhiqi Li","Shihao Wang","Jindong Jiang","Yicheng Liu","Lidong Lu","De-An Huang","Wonmin Byeon","Matthieu Le","Tuomas Rintamaki","Tyler Poon","Max Ehrlich","Tuomas Rintamaki","Tyler Poon","Tong Lu","Limin Wang","Bryan Catanzaro","Jan Kautz","Andrew Tao","Zhiding Yu","Guilin Liu"],"url":"https://arxiv.org/abs/2504.15271"}
{"created":"2025-04-22","title":"Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning","abstract":"Process reward models (PRMs) have proven effective for test-time scaling of Large Language Models (LLMs) on challenging reasoning tasks. However, reward hacking issues with PRMs limit their successful application in reinforcement fine-tuning. In this paper, we identify the main cause of PRM-induced reward hacking: the canonical summation-form credit assignment in reinforcement learning (RL), which defines the value as cumulative gamma-decayed future rewards, easily induces LLMs to hack steps with high rewards. To address this, we propose PURE: Process sUpervised Reinforcement lEarning. The key innovation of PURE is a min-form credit assignment that formulates the value function as the minimum of future rewards. This method significantly alleviates reward hacking by limiting the value function range and distributing advantages more reasonably. Through extensive experiments on 3 base models, we show that PRM-based approaches enabling min-form credit assignment achieve comparable reasoning performance to verifiable reward-based methods within only 30% steps. In contrast, the canonical sum-form credit assignment collapses training even at the beginning! Additionally, when we supplement PRM-based fine-tuning with just 10% verifiable rewards, we further alleviate reward hacking and produce the best fine-tuned model based on Qwen2.5-Math-7B in our experiments, achieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5 benchmarks. Moreover, we summarize the observed reward hacking cases and analyze the causes of training collapse. Code and models are available at https://github.com/CJReinforce/PURE.","authors":["Jie Cheng","Ruixi Qiao","Lijun Li","Chao Guo","Junle Wang","Gang Xiong","Yisheng Lv","Fei-Yue Wang"],"url":"https://arxiv.org/abs/2504.15275"}
{"created":"2025-04-22","title":"DRAWER: Digital Reconstruction and Articulation With Environment Realism","abstract":"Creating virtual digital replicas from real-world data unlocks significant potential across domains like gaming and robotics. In this paper, we present DRAWER, a novel framework that converts a video of a static indoor scene into a photorealistic and interactive digital environment. Our approach centers on two main contributions: (i) a reconstruction module based on a dual scene representation that reconstructs the scene with fine-grained geometric details, and (ii) an articulation module that identifies articulation types and hinge positions, reconstructs simulatable shapes and appearances and integrates them into the scene. The resulting virtual environment is photorealistic, interactive, and runs in real time, with compatibility for game engines and robotic simulation platforms. We demonstrate the potential of DRAWER by using it to automatically create an interactive game in Unreal Engine and to enable real-to-sim-to-real transfer for robotics applications.","authors":["Hongchi Xia","Entong Su","Marius Memmel","Arhan Jain","Raymond Yu","Numfor Mbiziwo-Tiapo","Ali Farhadi","Abhishek Gupta","Shenlong Wang","Wei-Chiu Ma"],"url":"https://arxiv.org/abs/2504.15278"}
{"created":"2025-04-22","title":"VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models","abstract":"Visual reasoning is a core component of human intelligence and a critical capability for advanced multimodal models. Yet current reasoning evaluations of multimodal large language models (MLLMs) often rely on text descriptions and allow language-based reasoning shortcuts, failing to measure genuine vision-centric reasoning. To address this, we introduce VisuLogic: a benchmark of 1,000 human-verified problems across six categories (e.g., quantitative shifts, spatial relations, attribute comparisons). These various types of questions can be evaluated to assess the visual reasoning capabilities of MLLMs from multiple perspectives. We evaluate leading MLLMs on this benchmark and analyze their results to identify common failure modes. Most models score below 30% accuracy-only slightly above the 25% random baseline and far below the 51.4% achieved by humans-revealing significant gaps in visual reasoning. Furthermore, we provide a supplementary training dataset and a reinforcement-learning baseline to support further progress.","authors":["Weiye Xu","Jiahao Wang","Weiyun Wang","Zhe Chen","Wengang Zhou","Aijun Yang","Lewei Lu","Houqiang Li","Xiaohua Wang","Xizhou Zhu","Wenhai Wang","Jifeng Dai","Jinguo Zhu"],"url":"https://arxiv.org/abs/2504.15279"}
{"created":"2025-04-22","title":"Seeing from Another Perspective: Evaluating Multi-View Understanding in MLLMs","abstract":"Multi-view understanding, the ability to reconcile visual information across diverse viewpoints for effective navigation, manipulation, and 3D scene comprehension, is a fundamental challenge in Multi-Modal Large Language Models (MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive advances in high-level reasoning and planning, they frequently fall short when confronted with multi-view geometric consistency and cross-view correspondence. To comprehensively evaluate the challenges of MLLMs in multi-view scene reasoning, we propose All-Angles Bench, a benchmark of over 2,100 human carefully annotated multi-view question-answer pairs across 90 diverse real-world scenes. Our six tasks (counting, attribute identification, relative distance, relative direction, object manipulation, and camera pose estimation) specifically test model's geometric correspondence and the capacity to align information consistently across views. Our extensive experiments, benchmark on 27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and GPT-4o against human evaluators reveals a substantial performance gap, indicating that current MLLMs remain far from human-level proficiency. Through in-depth analysis, we show that MLLMs are particularly underperforming under two aspects: (1) cross-view correspondence for partially occluded views and (2) establishing the coarse camera poses. These findings highlight the necessity of domain-specific refinements or modules that embed stronger multi-view awareness. We believe that our All-Angles Bench offers valuable insights and contribute to bridging the gap between MLLMs and human-level multi-view understanding. The project and benchmark are publicly available at https://danielchyeh.github.io/All-Angles-Bench/.","authors":["Chun-Hsiao Yeh","Chenyu Wang","Shengbang Tong","Ta-Ying Cheng","Rouyu Wang","Tianzhe Chu","Yuexiang Zhai","Yubei Chen","Shenghua Gao","Yi Ma"],"url":"https://arxiv.org/abs/2504.15280"}
{"created":"2025-04-22","title":"StyleMe3D: Stylization with Disentangled Priors by Multiple Encoders on 3D Gaussians","abstract":"3D Gaussian Splatting (3DGS) excels in photorealistic scene reconstruction but struggles with stylized scenarios (e.g., cartoons, games) due to fragmented textures, semantic misalignment, and limited adaptability to abstract aesthetics. We propose StyleMe3D, a holistic framework for 3D GS style transfer that integrates multi-modal style conditioning, multi-level semantic alignment, and perceptual quality enhancement. Our key insights include: (1) optimizing only RGB attributes preserves geometric integrity during stylization; (2) disentangling low-, medium-, and high-level semantics is critical for coherent style transfer; (3) scalability across isolated objects and complex scenes is essential for practical deployment. StyleMe3D introduces four novel components: Dynamic Style Score Distillation (DSSD), leveraging Stable Diffusion's latent space for semantic alignment; Contrastive Style Descriptor (CSD) for localized, content-aware texture transfer; Simultaneously Optimized Scale (SOS) to decouple style details and structural coherence; and 3D Gaussian Quality Assessment (3DG-QA), a differentiable aesthetic prior trained on human-rated data to suppress artifacts and enhance visual harmony. Evaluated on NeRF synthetic dataset (objects) and tandt db (scenes) datasets, StyleMe3D outperforms state-of-the-art methods in preserving geometric details (e.g., carvings on sculptures) and ensuring stylistic consistency across scenes (e.g., coherent lighting in landscapes), while maintaining real-time rendering. This work bridges photorealistic 3D GS and artistic stylization, unlocking applications in gaming, virtual worlds, and digital art.","authors":["Cailin Zhuang","Yaoqi Hu","Xuanyang Zhang","Wei Cheng","Jiacheng Bao","Shengqi Liu","Yiying Yang","Xianfang Zeng","Gang Yu","Ming Li"],"url":"https://arxiv.org/abs/2504.15281"}
{"created":"2025-04-22","title":"A Practical Protocol for Quantum Oblivious Transfer from One-Way Functions","abstract":"We present a new simulation-secure quantum oblivious transfer (QOT) protocol based on one-way functions in the plain model. With a focus on practical implementation, our protocol surpasses prior works in efficiency, promising feasible experimental realization. We address potential experimental errors and their correction, offering analytical expressions to facilitate the analysis of the required quantum resources. Technically, we achieve simulation security for QOT through an equivocal and relaxed-extractable quantum bit commitment.","authors":["Eleni Diamanti","Alex B. Grilo","Adriano Innocenzi","Pascal Lefebvre","Verena Yacoub","\\'Alvaro Y\\'ang\\\"uez"],"url":"https://arxiv.org/abs/2406.09110"}
{"created":"2025-04-22","title":"GenShin:geometry-enhanced structural graph embodies binding pose can better predicting compound-protein interaction affinity","abstract":"AI-powered drug discovery typically relies on the successful prediction of compound-protein interactions, which are pivotal for the evaluation of designed compound molecules in structure-based drug design and represent a core challenge in the field.","authors":["Pingfei Zhu","Chenyang Zhao","Haishi Zhao","Bo Yang"],"url":"https://arxiv.org/abs/2504.13853"}
{"created":"2025-04-22","title":"A Graph Theoretic Approach for Exploring the Relationship between EV Adoption and Charging Infrastructure Growth","abstract":"The increasing global demand for conventional energy has led to significant challenges, particularly due to rising CO2 emissions and the depletion of natural resources. In the U.S., light-duty vehicles contribute significantly to transportation sector emissions, prompting a global shift toward electrified vehicles (EVs). Among the challenges that thwart the widespread adoption of EVs is the insufficient charging infrastructure (CI). This study focuses on exploring the complex relationship between EV adoption and CI growth. Employing a graph theoretic approach, we propose a graph model to analyze correlations between EV adoption and CI growth across 137 counties in six states. We examine how different time granularities impact these correlations in two distinct scenarios: Early Adoption and Late Adoption. Further, we conduct causality tests to assess the directional relationship between EV adoption and CI growth in both scenarios. Our main findings reveal that analysis using lower levels of time granularity result in more homogeneous clusters, with notable differences between clusters in EV adoption and those in CI growth. Additionally, we identify causal relationships between EV adoption and CI growth in 137 counties, and show that causality is observed more frequently in Early Adoption scenarios than in Late Adoption ones. However, the causal effects in Early Adoption are slower than those in Late Adoption.","authors":["Fahad S. Alrasheedi","Hesham H. Ali"],"url":"https://arxiv.org/abs/2504.13902"}
{"created":"2025-04-22","title":"How competitive are pay-as-bid auction games?","abstract":"Motivated by the current structure of ancillary services markets, we study the pay-as-bid auction game, a supply function model with discriminatory pricing and asymmetric firms. In this game, strategies are non-decreasing supply functions relating price to quantity and the exact choice of the strategy space turns out to be a crucial issue: when it includes all non-decreasing continuous functions, pure-strategy Nash equilibria often fail to exist. To overcome this, we restrict the strategy space to the set of Lipschitz-continuous functions and we prove that Nash equilibria always exist (under standard concavity assumptions) and consist of functions that are affine on their own support and have slope equal to the maximum allowed Lipschitz constant. We further show that the Nash equilibrium is unique up to the market-clearing price when the demand is affine and the asymmetric marginal production costs are homogeneous in zero. For quadratic production costs, we derive a closed-form expression and we compute the limit as the allowed Lipschitz constant grows to infinity. Our results show that in the limit the pay-as-bid auction game achieves perfect competition with efficient allocation and induces a lower market-clearing price compared to supply function models based on uniform price auctions.","authors":["Martina Vanelli","Giacomo Como","Fabio Fagnani"],"url":"https://arxiv.org/abs/2504.13920"}
{"created":"2025-04-22","title":"Compendium of Advances in Game Theory: Classical, Differential, Algorithmic, Non-Archimedean and Quantum Game","abstract":"This compendium features advances in Game Theory, to include:","authors":["Bourama Toni"],"url":"https://arxiv.org/abs/2504.13939"}
{"created":"2025-04-22","title":"Association between nutritional factors, inflammatory biomarkers and cancer types: an analysis of NHANES data using machine learning","abstract":"Background. Diet and inflammation are critical factors influencing cancer risk. However, the combined impact of nutritional status and inflammatory biomarkers on cancer status and type, using machine learning (ML), remains underexplored.","authors":["Yuqing Liu","Meng Zhao","Guanlan Hu","Yuchen Zhang"],"url":"https://arxiv.org/abs/2504.13978"}
{"created":"2025-04-22","title":"Predicting fermionic densities using a Projected Quantum Kernel method","abstract":"We use a support vector regressor based on a projected quantum kernel method to predict the density structure of 1D fermionic systems of interest in quantum chemistry and quantum matter. The kernel is built on with the observables of a quantum reservoir implementable with interacting Rydberg atoms. Training and test data of the fermionic system are generated using a Density Functional Theory approach. We test the performance of the method for several Hamiltonian parameters, finding a general common behavior of the error as a function of measurement time. At sufficiently large measurement times, we find that the method outperforms the classical linear kernel method and can be competitive with the radial basis function method.","authors":["Francesco Perciavalle","Francesco Plastina","Michele Pisarra","Nicola Lo Gullo"],"url":"https://arxiv.org/abs/2504.14002"}
{"created":"2025-04-22","title":"Towards Optimal Orders for Entanglement Swapping in Path Graphs: A Greedy Approach","abstract":"This paper considers the problem of finding an optimal order for entanglement swapping in a heterogeneous path of quantum repeaters so as to maximize the path throughput defined as the delivery rate of end-to-end entanglements. The primary difficulty in addressing this problem lies in the vast array of possible swapping orders for large paths and the complexity of the expected throughput, which depends on the attributes of each node and edge along the path, as well as the order of swapping. To cope with these issues, we first propose simple approximations in estimating the swapping outcome between two entanglement distributions that can run in constant time, thereby providing an efficient approach for evaluating and comparing different swapping orders, allowing us to solve the problem exactly for small paths. Second, as the number of possible orders grows exponentially with the number of repeaters in the path, we develop an efficient heuristic based on the greedy selection of nodes to sequentially perform swaps according to their swapping scores, defined as the expected number of entanglements resulting from their swaps. The scores are local but dynamic in the sense that they depend not just on the entanglement distributions available on the path but also on prior swapping decisions. Finally, we illustrate the efficiency and effectiveness of our proposed model and approach through extensive experimentation conducted using a general quantum network simulator.","authors":["Van Sy Mai","Abderrahim Amlou","Amar Abane","Abdella Battou"],"url":"https://arxiv.org/abs/2504.14040"}
{"created":"2025-04-22","title":"6G WavesFM: A Foundation Model for Sensing, Communication, and Localization","abstract":"This paper introduces WavesFM, a novel Wireless Foundation Model (WFM) framework, capable of supporting a wide array of communication, sensing, and localization tasks. Our proposed architecture combines a shared Vision Transformer (ViT) backbone with task-specific multi-layer perceptron (MLP) heads and incorporates Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning. This design promotes full parameter sharing across tasks, significantly reducing the computational and memory footprint without sacrificing performance. The model processes both image-like wireless modalities, such as spectrograms and channel state information (CSI), and in-phase and quadrature (IQ) signals arranged as orthogonal frequency-division multiplexing (OFDM) resource grids. We demonstrate the strong generalization capabilities of WavesFM through extensive experiments on four downstream tasks: Fifth Generation New Radio (5G NR) positioning; multiple-input multiple-output OFDM (MIMO-OFDM) channel estimation; human activity sensing; and radio-frequency (RF) signal classification. Compared to supervised baselines trained individually, our approach achieves superior performance while sharing 80% of its parameters across tasks. Furthermore, we show that pretraining on domain-relevant data not only boosts performance but also accelerates convergence, reducing training time by up to 5x. These results demonstrate that our unified WFM can support diverse tasks and deliver significant gains in both performance and efficiency, highlighting the transformative potential of foundation models to drive AI-native paradigms in future sixth-generation (6G) networks.","authors":["Ahmed Aboulfotouh","Elsayed Mohammed","Hatem Abou-Zeid"],"url":"https://arxiv.org/abs/2504.14100"}
{"created":"2025-04-22","title":"System of Agentic AI for the Discovery of Metal-Organic Frameworks","abstract":"Generative models and machine learning promise accelerated material discovery in MOFs for CO2 capture and water harvesting but face significant challenges navigating vast chemical spaces while ensuring synthetizability. Here, we present MOFGen, a system of Agentic AI comprising interconnected agents: a large language model that proposes novel MOF compositions, a diffusion model that generates crystal structures, quantum mechanical agents that optimize and filter candidates, and synthetic-feasibility agents guided by expert rules and machine learning. Trained on all experimentally reported MOFs and computational databases, MOFGen generated hundreds of thousands of novel MOF structures and synthesizable organic linkers. Our methodology was validated through high-throughput experiments and the successful synthesis of five \"AI-dreamt\" MOFs, representing a major step toward automated synthesizable material discovery.","authors":["Theo Jaffrelot Inizan","Sherry Yang","Aaron Kaplan","Yen-hsu Lin","Jian Yin","Saber Mirzaei","Mona Abdelgaid","Ali H. Alawadhi","KwangHwan Cho","Zhiling Zheng","Ekin Dogus Cubuk","Christian Borgs","Jennifer T. Chayes","Kristin A. Persson","Omar M. Yaghi"],"url":"https://arxiv.org/abs/2504.14110"}
{"created":"2025-04-22","title":"Breaking the Diffraction Barrier for Passive Sources: Parameter-Decoupled Superresolution Assisted by Physics-Informed Machine Learning","abstract":"We present a parameter-decoupled superresolution framework for estimating sub-wavelength separations of passive two-point sources without requiring prior knowledge or control of the source. Our theoretical foundation circumvents the need to estimate multiple challenging parameters such as partial coherence, brightness imbalance, random relative phase, and photon statistics. A physics-informed machine learning (ML) model (trained with a standard desktop workstation), synergistically integrating this theory, further addresses practical imperfections including background noise, photon loss, and centroid/orientation misalignment. The integrated parameter-decoupling superresolution method achieves resolution 14 and more times below the diffraction limit (corresponding to ~ 13.5 nm in optical microscopy) on experimentally generated realistic images with >82% fidelity, performance rivaling state-of-the-art techniques for actively controllable sources. Critically, our method's robustness against source parameter variability and source-independent noises enables potential applications in realistic scenarios where source control is infeasible, such as astrophysical imaging, live-cell microscopy, and quantum metrology. This work bridges a critical gap between theoretical superresolution limits and practical implementations for passive systems.","authors":["Abdelali Sajia","Bilal Benzimoun","Pawan Khatiwada","Guogan Zhao","Xiao-Feng Qian"],"url":"https://arxiv.org/abs/2504.14156"}
{"created":"2025-04-22","title":"DeepPD: Joint Phase and Object Estimation from Phase Diversity with Neural Calibration of a Deformable Mirror","abstract":"Sample-induced aberrations and optical imperfections limit the resolution of fluorescence microscopy. Phase diversity is a powerful technique that leverages complementary phase information in sequentially acquired images with deliberately introduced aberrations--the phase diversities--to enable phase and object reconstruction and restore diffraction-limited resolution. These phase diversities are typically introduced into the optical path via a deformable mirror. Existing phase-diversity-based methods are limited to Zernike modes, require large numbers of diversity images, or depend on accurate mirror calibration--which are all suboptimal. We present DeepPD, a deep learning-based framework that combines neural representations of the object and wavefront with a learned model of the deformable mirror to jointly estimate both object and phase from only five images. DeepPD improves robustness and reconstruction quality over previous approaches, even under severe aberrations. We demonstrate its performance on calibration targets and biological samples, including immunolabeled myosin in fixed PtK2 cells.","authors":["Magdalena C. Schneider","Courtney Johnson","Cedric Allier","Larissa Heinrich","Diane Adjavon","Joren Husic","Patrick La Rivi\\`ere","Stephan Saalfeld","Hari Shroff"],"url":"https://arxiv.org/abs/2504.14157"}
{"created":"2025-04-22","title":"Learning over von Mises-Fisher Distributions via a Wasserstein-like Geometry","abstract":"We introduce a novel, geometry-aware distance metric for the family of von Mises-Fisher (vMF) distributions, which are fundamental models for directional data on the unit hypersphere. Although the vMF distribution is widely employed in a variety of probabilistic learning tasks involving spherical data, principled tools for comparing vMF distributions remain limited, primarily due to the intractability of normalization constants and the absence of suitable geometric metrics. Motivated by the theory of optimal transport, we propose a Wasserstein-like distance that decomposes the discrepancy between two vMF distributions into two interpretable components: a geodesic term capturing the angular separation between mean directions, and a variance-like term quantifying differences in concentration parameters. The derivation leverages a Gaussian approximation in the high-concentration regime to yield a tractable, closed-form expression that respects the intrinsic spherical geometry. We show that the proposed distance exhibits desirable theoretical properties and induces a latent geometric structure on the space of non-degenerate vMF distributions. As a primary application, we develop the efficient algorithms for vMF mixture reduction, enabling structure-preserving compression of mixture models in high-dimensional settings. Empirical results on synthetic datasets and real-world high-dimensional embeddings, including biomedical sentence representations and deep visual features, demonstrate the effectiveness of the proposed geometry in distinguishing distributions and supporting interpretable inference. This work expands the statistical toolbox for directional data analysis by introducing a tractable, transport-inspired distance tailored to the geometry of the hypersphere.","authors":["Kisung You","Dennis Shung","Mauro Giuffr\\`e"],"url":"https://arxiv.org/abs/2504.14164"}
{"created":"2025-04-22","title":"The First VoicePrivacy Attacker Challenge","abstract":"The First VoicePrivacy Attacker Challenge is an ICASSP 2025 SP Grand Challenge which focuses on evaluating attacker systems against a set of voice anonymization systems submitted to the VoicePrivacy 2024 Challenge. Training, development, and evaluation datasets were provided along with a baseline attacker. Participants developed their attacker systems in the form of automatic speaker verification systems and submitted their scores on the development and evaluation data. The best attacker systems reduced the equal error rate (EER) by 25-44% relative w.r.t. the baseline.","authors":["Natalia Tomashenko","Xiaoxiao Miao","Emmanuel Vincent","Junichi Yamagishi"],"url":"https://arxiv.org/abs/2504.14183"}
{"created":"2025-04-22","title":"Leibniz rule for wedge product in discrete exterior calculus on general polygonal meshes","abstract":"Discrete exterior calculus offers a coordinate-free discretization of exterior calculus especially suited for computations on curved spaces. In this work, we present a wedge product on 2-dimensional pseudomanifolds, whose faces are any polygons. We prove that this polygonal wedge product is compatible with the discrete exterior derivative in the sense that it satisfies the Leibniz product rule. We thus extend previously studied discretizations of wedge products from simplicial or quadrilateral meshes to general polygonal surface meshes. We also prove that our discrete wedge product corresponds to a cup product of cochains on 2-pseudomanifolds.","authors":["Lenka Ptackova"],"url":"https://arxiv.org/abs/2504.14275"}
{"created":"2025-04-22","title":"Numerical analysis of a particle system for the calibrated Heston-type local stochastic volatility model","abstract":"We analyse a Monte Carlo particle method for the simulation of the calibrated Heston-type local stochastic volatility (H-LSV) model. The common application of a kernel estimator for a conditional expectation in the calibration condition results in a McKean-Vlasov (MV) stochastic differential equation (SDE) with non-standard coefficients. The primary challenges lie in certain mean-field terms in the drift and diffusion coefficients and the $1/2$-H\\\"{o}lder regularity of the diffusion coefficient. We establish the well-posedness of this equation for a fixed but arbitrarily small bandwidth of the kernel estimator. Moreover, we prove a strong propagation of chaos result, ensuring convergence of the particle system under a condition on the Feller ratio and up to a critical time. For the numerical simulation, we employ an Euler-Maruyama scheme for the log-spot process and a full truncation Euler scheme for the CIR volatility process. Under certain conditions on the inputs and the Feller ratio, we prove strong convergence of the Euler-Maruyama scheme with rate $1/2$ in time, up to a logarithmic factor. Numerical experiments illustrate the convergence of the discretisation scheme and validate the propagation of chaos in practice.","authors":["Christoph Reisinger","Maria Olympia Tsianni"],"url":"https://arxiv.org/abs/2504.14343"}
{"created":"2025-04-22","title":"Integrating LLM-Generated Views into Mean-Variance Optimization Using the Black-Litterman Model","abstract":"Portfolio optimization faces challenges due to the sensitivity in traditional mean-variance models. The Black-Litterman model mitigates this by integrating investor views, but defining these views remains difficult. This study explores the integration of large language models (LLMs) generated views into portfolio optimization using the Black-Litterman framework. Our method leverages LLMs to estimate expected stock returns from historical prices and company metadata, incorporating uncertainty through the variance in predictions. We conduct a backtest of the LLM-optimized portfolios from June 2024 to February 2025, rebalancing biweekly using the previous two weeks of price data. As baselines, we compare against the S&amp;P 500, an equal-weighted portfolio, and a traditional mean-variance optimized portfolio constructed using the same set of stocks. Empirical results suggest that different LLMs exhibit varying levels of predictive optimism and confidence stability, which impact portfolio performance. The source code and data are available at https://github.com/youngandbin/LLM-MVO-BLM.","authors":["Youngbin Lee","Yejin Kim","Suin Kim","Yongjae Lee"],"url":"https://arxiv.org/abs/2504.14345"}
{"created":"2025-04-22","title":"Density Measures for Language Generation","abstract":"The recent successes of large language models (LLMs) have led to a surge of theoretical research into language generation. A recent line of work proposes an abstract view, called language generation in the limit, where generation is seen as a game between an adversary and an algorithm: the adversary generates strings from an unknown language $K$, chosen from a countable collection of candidate languages, and after seeing a finite set of these strings, the algorithm must generate new strings from $K$ that it has not seen before. This formalism highlights a key tension: the trade-off between validity (the algorithm should only produce strings from the language) and breadth (it should be able to produce many strings from the language). This trade-off is central in applied language generation as well, where it appears as a balance between hallucination (generating invalid utterances) and mode collapse (generating only a restricted set of outputs). Despite its importance, this trade-off has been challenging to study quantitatively. We develop ways to quantify this trade-off by formalizing breadth using measures of density. Existing algorithms for language generation in the limit produce output sets that can have zero density in the true language, and this important failure of breadth might seem unavoidable. We show, however, that such a failure is not necessary: we provide an algorithm for language generation in the limit whose outputs have strictly positive density in $K$. We also study the internal representations built by these algorithms, specifically the sequence of hypothesized candidate languages they consider, and show that achieving the strongest form of breadth may require oscillating indefinitely between high- and low-density representations. Our analysis introduces a novel topology on language families, with notions of convergence and limit points playing a key role.","authors":["Jon Kleinberg","Fan Wei"],"url":"https://arxiv.org/abs/2504.14370"}
{"created":"2025-04-22","title":"Machine learning enhanced atom probe tomography analysis: a snapshot review","abstract":"Atom probe tomography (APT) is a burgeoning characterization technique that provides compositional mapping of materials in three-dimensions at near-atomic scale. Since its significant expansion in the past 30 years, we estimate that one million APT datasets have been collected, each containing millions to billions of individual ions. Their analysis and the extraction of microstructural information has largely relied upon individual users whose varied level of expertise causes clear and documented bias. Current practices hinder efficient data processing, and make challenging standardization and the deployment of data analysis workflows that would be compliant with FAIR data principles. Over the past decade, building upon the long-standing expertise of the APT community in the development of advanced data processing or data mining techniques, there has been a surge of novel machine learning (ML) approaches aiming for user-independence, and that are efficient, reproducible, and robust from a statistics perspective. Here, we provide a snapshot review of this rapidly evolving field. We begin with a brief introduction to APT and the nature of the APT data. This is followed by an overview of relevant ML algorithms and a comprehensive review of their applications to APT. We also discuss how ML can enable discoveries beyond human capability, offering new insights into the mechanisms within materials. Finally, we provide guidance for future directions in this domain.","authors":["Yue Li","Ye Wei","Alaukik Saxena","Markus K\\\"uhbach","Christoph Freysoldt","Baptiste Gault"],"url":"https://arxiv.org/abs/2504.14378"}
{"created":"2025-04-22","title":"Data Augmentation Using Neural Acoustic Fields With Retrieval-Augmented Pre-training","abstract":"This report details MERL's system for room impulse response (RIR) estimation submitted to the Generative Data Augmentation Workshop at ICASSP 2025 for Augmenting RIR Data (Task 1) and Improving Speaker Distance Estimation (Task 2). We first pre-train a neural acoustic field conditioned by room geometry on an external large-scale dataset in which pairs of RIRs and the geometries are provided. The neural acoustic field is then adapted to each target room by using the enrollment data, where we leverage either the provided room geometries or geometries retrieved from the external dataset, depending on availability. Lastly, we predict the RIRs for each pair of source and receiver locations specified by Task 1, and use these RIRs to train the speaker distance estimation model in Task 2.","authors":["Christopher Ick","Gordon Wichern","Yoshiki Masuyama","Fran\\c{c}ois G. Germain","Jonathan Le Roux"],"url":"https://arxiv.org/abs/2504.14409"}
{"created":"2025-04-22","title":"Optimal Lattice Boltzmann Closures through Multi-Agent Reinforcement Learning","abstract":"The Lattice Boltzmann method (LBM) offers a powerful and versatile approach to simulating diverse hydrodynamic phenomena, spanning microfluidics to aerodynamics. The vast range of spatiotemporal scales inherent in these systems currently renders full resolution impractical, necessitating the development of effective closure models for under-resolved simulations. Under-resolved LBMs are unstable, and while there is a number of important efforts to stabilize them, they often face limitations in generalizing across scales and physical systems. We present a novel, data-driven, multiagent reinforcement learning (MARL) approach that drastically improves stability and accuracy of coarse-grained LBM simulations. The proposed method uses a convolutional neural network to dynamically control the local relaxation parameter for the LB across the simulation grid. The LB-MARL framework is showcased in turbulent Kolmogorov flows. We find that the MARL closures stabilize the simulations and recover the energy spectra of significantly more expensive fully resolved simulations while maintaining computational efficiency. The learned closure model can be transferred to flow scenarios unseen during training and has improved robustness and spectral accuracy compared to traditional LBM models. We believe that MARL closures open new frontiers for efficient and accurate simulations of a multitude of complex problems not accessible to present-day LB methods alone.","authors":["Paul Fischer","Sebastian Kaltenbach","Sergey Litvinov","Sauro Succi","Petros Koumoutsakos"],"url":"https://arxiv.org/abs/2504.14422"}
{"created":"2025-04-22","title":"Optimal Scheduling of Dynamic Transport","abstract":"Flow-based methods for sampling and generative modeling use continuous-time dynamical systems to represent a {transport map} that pushes forward a source measure to a target measure. The introduction of a time axis provides considerable design freedom, and a central question is how to exploit this freedom. Though many popular methods seek straight line (i.e., zero acceleration) trajectories, we show here that a specific class of ``curved'' trajectories can significantly improve approximation and learning. In particular, we consider the unit-time interpolation of any given transport map $T$ and seek the schedule $\\tau: [0,1] \\to [0,1]$ that minimizes the spatial Lipschitz constant of the corresponding velocity field over all times $t \\in [0,1]$. This quantity is crucial as it allows for control of the approximation error when the velocity field is learned from data. We show that, for a broad class of source/target measures and transport maps $T$, the \\emph{optimal schedule} can be computed in closed form, and that the resulting optimal Lipschitz constant is \\emph{exponentially smaller} than that induced by an identity schedule (corresponding to, for instance, the Wasserstein geodesic). Our proof technique relies on the calculus of variations and $\\Gamma$-convergence, allowing us to approximate the aforementioned degenerate objective by a family of smooth, tractable problems.","authors":["Panos Tsimpos","Zhi Ren","Jakob Zech","Youssef Marzouk"],"url":"https://arxiv.org/abs/2504.14425"}
{"created":"2025-04-22","title":"Guess, SWAP, Repeat : Capturing Quantum Snapshots in Classical Memory","abstract":"We introduce a novel technique that enables observation of quantum states without direct measurement, preserving them for reuse. Our method allows multiple quantum states to be observed at different points within a single circuit, one at a time, and saved into classical memory without destruction. These saved states can be accessed on demand by downstream applications, introducing a dynamic and programmable notion of quantum memory that supports modular, non-destructive quantum workflows. We propose a hardware-agnostic, machine learning-driven framework to capture non-destructive estimates, or \"snapshots,\" of quantum states at arbitrary points within a circuit, enabling classical storage and later reconstruction, similar to memory operations in classical computing. This capability is essential for debugging, introspection, and persistent memory in quantum systems, yet remains difficult due to the no-cloning theorem and destructive measurements. Our guess-and-check approach uses fidelity estimation via the SWAP test to guide state reconstruction. We explore both gradient-based deep neural networks and gradient-free evolutionary strategies to estimate quantum states using only fidelity as the learning signal. We demonstrate a key component of our framework on IBM quantum hardware, achieving high-fidelity (approximately 1.0) reconstructions for Hadamard and other known states. In simulation, our models achieve an average fidelity of 0.999 across 100 random quantum states. This provides a pathway toward non-volatile quantum memory, enabling long-term storage and reuse of quantum information, and laying groundwork for future quantum memory architectures.","authors":["Debarshi Kundu","Avimita Chatterjee","Swaroop Ghosh"],"url":"https://arxiv.org/abs/2504.14459"}
{"created":"2025-04-22","title":"LBM-GNN: Graph Neural Network Enhanced Lattice Boltzmann Method","abstract":"In this paper, we present LBM-GNN, a novel approach that enhances the traditional Lattice Boltzmann Method (LBM) with Graph Neural Networks (GNNs). We apply this method to fluid dynamics simulations, demonstrating improved stability and accuracy compared to standard LBM implementations. The method is validated using benchmark problems such as the Taylor-Green vortex, focusing on accuracy, conservation properties, and performance across different Reynolds numbers and grid resolutions. Our results indicate that GNN-enhanced LBM can maintain better conservation properties while improving numerical stability at higher Reynolds numbers.","authors":["Yue Li"],"url":"https://arxiv.org/abs/2504.14494"}
{"created":"2025-04-22","title":"Enhancing LLM-based Quantum Code Generation with Multi-Agent Optimization and Quantum Error Correction","abstract":"Multi-agent frameworks with Large Language Models (LLMs) have become promising tools for generating general-purpose programming languages using test-driven development, allowing developers to create more accurate and robust code. However, their potential has not been fully unleashed for domain-specific programming languages, where specific domain exhibits unique optimization opportunities for customized improvement. In this paper, we take the first step in exploring multi-agent code generation for quantum programs. By identifying the unique optimizations in quantum designs such as quantum error correction, we introduce a novel multi-agent framework tailored to generating accurate, fault-tolerant quantum code. Each agent in the framework focuses on distinct optimizations, iteratively refining the code using a semantic analyzer with multi-pass inference, alongside an error correction code decoder. We also examine the effectiveness of inference-time techniques, like Chain-of-Thought (CoT) and Retrieval-Augmented Generation (RAG) in the context of quantum programming, uncovering observations that are different from general-purpose code generation. To evaluate our approach, we develop a test suite to measure the impact each optimization has on the accuracy of the generated code. Our findings indicate that techniques such as structured CoT significantly improve the generation of quantum algorithms by up to 50%. In contrast, we have also found that certain techniques such as RAG show limited improvement, yielding an accuracy increase of only 4%. Moreover, we showcase examples of AI-assisted quantum error prediction and correction, demonstrating the effectiveness of our multi-agent framework in reducing the quantum errors of generated quantum programs.","authors":["Charlie Campbell","Hao Mark Chen","Wayne Luk","Hongxiang Fan"],"url":"https://arxiv.org/abs/2504.14557"}
{"created":"2025-04-22","title":"Quantum-Enhanced Weight Optimization for Neural Networks Using Grover's Algorithm","abstract":"The main approach to hybrid quantum-classical neural networks (QNN) is employing quantum computing to build a neural network (NN) that has quantum features, which is then optimized classically. Here, we propose a different strategy: to use quantum computing in order to optimize the weights of a classical NN. As such, we design an instance of Grover's quantum search algorithm to accelerate the search for the optimal parameters of an NN during the training process, a task traditionally performed using the backpropagation algorithm with the gradient descent method. Indeed, gradient descent has issues such as exploding gradient, vanishing gradient, or convexity problem. Other methods tried to address such issues with strategies like genetic searches, but they carry additional problems like convergence consistency. Our original method avoids these issues -- because it does not calculate gradients -- and capitalizes on classical architectures' robustness and Grover's quadratic speedup in high-dimensional search spaces to significantly reduce test loss (58.75%) and improve test accuracy (35.25%), compared to classical NN weight optimization, on small datasets. Unlike most QNNs that are trained on small datasets only, our method is also scalable, as it allows the optimization of deep networks; for an NN with 3 hidden layers, trained on the Digits dataset from scikit-learn, we obtained a mean accuracy of 97.7%. Moreover, our method requires a much smaller number of qubits compared to other QNN approaches, making it very practical for near-future quantum computers that will still deliver a limited number of logical qubits.","authors":["Stefan-Alexandru Jura","Mihai Udrescu"],"url":"https://arxiv.org/abs/2504.14568"}
{"created":"2025-04-22","title":"Markovian Continuity of the MMSE","abstract":"Minimum mean square error (MMSE) estimation is widely used in signal processing and related fields. While it is known to be non-continuous with respect to all standard notions of stochastic convergence, it remains robust in practical applications. In this work, we review the known counterexamples to the continuity of the MMSE. We observe that, in these counterexamples, the discontinuity arises from an element in the converging measurement sequence providing more information about the estimand than the limit of the measurement sequence. We argue that this behavior is uncharacteristic of real-world applications and introduce a new stochastic convergence notion, termed Markovian convergence, to address this issue. We prove that the MMSE is, in fact, continuous under this new notion. We supplement this result with semi-continuity and continuity guarantees of the MMSE in other settings and prove the continuity of the MMSE under linear estimation.","authors":["Elad Domanovitz","Anatoly Khina"],"url":"https://arxiv.org/abs/2504.14659"}
{"created":"2025-04-22","title":"Additive energy, uncertainty principle and signal recovery mechanisms","abstract":"Given a signal $f:G\\to\\mathbb{C}$, where $G$ is a finite abelian group, under what reasonable assumptions can we guarantee the exact recovery of $f$ from a proper subset of its Fourier coefficients? In 1989, Donoho and Stark established a result \\cite{DS89} using the classical uncertainty principle, which states that $|\\text{supp}(f)|\\cdot|\\text{supp}(\\hat{f})|\\geq |G|$ for any nonzero signal $f$. Another result, first proven by Santose and Symes \\cite{SS86}, was based on the Logan phenomenon \\cite{L65}. In particular, the result showcases how the $L^1$ and $L^2$ minimizing signals with matching Fourier frequencies often recovers the original signal.","authors":["K. Aldahleh","A. Iosevich","J. Iosevich","J. Jaimangal","A. Mayeli","S. Pack"],"url":"https://arxiv.org/abs/2504.14702"}
{"created":"2025-04-22","title":"On the Tunability of Random Survival Forests Model for Predictive Maintenance","abstract":"This paper investigates the tunability of the Random Survival Forest (RSF) model in predictive maintenance, where accurate time-to-failure estimation is crucial. Although RSF is widely used due to its flexibility and ability to handle censored data, its performance is sensitive to hyperparameter configurations. However, systematic evaluations of RSF tunability remain limited, especially in predictive maintenance contexts. We introduce a three-level framework to quantify tunability: (1) a model-level metric measuring overall performance gain from tuning, (2) a hyperparameter-level metric assessing individual contributions, and (3) identification of optimal tuning ranges. These metrics are evaluated across multiple datasets using survival-specific criteria: the C-index for discrimination and the Brier score for calibration. Experiments on four CMAPSS dataset subsets, simulating aircraft engine degradation, reveal that hyperparameter tuning consistently improves model performance. On average, the C-index increased by 0.0547, while the Brier score decreased by 0.0199. These gains were consistent across all subsets. Moreover, ntree and mtry showed the highest average tunability, while nodesize offered stable improvements within the range of 10 to 30. In contrast, splitrule demonstrated negative tunability on average, indicating that improper tuning may reduce model performance. Our findings emphasize the practical importance of hyperparameter tuning in survival models and provide actionable insights for optimizing RSF in real-world predictive maintenance applications.","authors":["Yigitcan Yard{\\i}mc{\\i}","Mustafa Cavus"],"url":"https://arxiv.org/abs/2504.14744"}
{"created":"2025-04-22","title":"Segmentation with Noisy Labels via Spatially Correlated Distributions","abstract":"In semantic segmentation, the accuracy of models heavily depends on the high-quality annotations. However, in many practical scenarios such as medical imaging and remote sensing, obtaining true annotations is not straightforward and usually requires significant human labor. Relying on human labor often introduces annotation errors, including mislabeling, omissions, and inconsistency between annotators. In the case of remote sensing, differences in procurement time can lead to misaligned ground truth annotations. These label errors are not independently distributed, and instead usually appear in spatially connected regions where adjacent pixels are more likely to share the same errors. To address these issues, we propose an approximate Bayesian estimation based on a probabilistic model that assumes training data includes label errors, incorporating the tendency for these errors to occur with spatial correlations between adjacent pixels. Bayesian inference requires computing the posterior distribution of label errors, which becomes intractable when spatial correlations are present. We represent the correlation of label errors between adjacent pixels through a Gaussian distribution whose covariance is structured by a Kac-Murdock-Szeg\\\"{o} (KMS) matrix, solving the computational challenges. Through experiments on multiple segmentation tasks, we confirm that leveraging the spatial correlation of label errors significantly improves performance. Notably, in specific tasks such as lung segmentation, the proposed method achieves performance comparable to training with clean labels under moderate noise levels. Code is available at https://github.com/pfnet-research/Bayesian_SpatialCorr.","authors":["Ryu Tadokoro","Tsukasa Takagi","Shin-ichi Maeda"],"url":"https://arxiv.org/abs/2504.14795"}
{"created":"2025-04-22","title":"(Sub)Exponential Quantum Speedup for Optimization","abstract":"We demonstrate provable (sub)exponential quantum speedups in both discrete and continuous optimization, achieved through simple and natural quantum optimization algorithms, namely the quantum adiabatic algorithm for discrete optimization and quantum Hamiltonian descent for continuous optimization. Our result builds on the Gily\\'en--Hastings--Vazirani (sub)exponential oracle separation for adiabatic quantum computing. With a sequence of perturbative reductions, we compile their construction into two standalone objective functions, whose oracles can be directly leveraged by the plain adiabatic evolution and Schr\\\"odinger operator evolution for discrete and continuous optimization, respectively.","authors":["Jiaqi Leng","Kewen Wu","Xiaodi Wu","Yufan Zheng"],"url":"https://arxiv.org/abs/2504.14841"}
{"created":"2025-04-22","title":"Expected Free Energy-based Planning as Variational Inference","abstract":"We address the problem of planning under uncertainty, where an agent must choose actions that not only achieve desired outcomes but also reduce uncertainty. Traditional methods often treat exploration and exploitation as separate objectives, lacking a unified inferential foundation. Active inference, grounded in the Free Energy Principle, offers such a foundation by minimizing Expected Free Energy (EFE), a cost function that combines utility with epistemic drives like ambiguity resolution and novelty seeking. However, the computational burden of EFE minimization has remained a major obstacle to its scalability. In this paper, we show that EFE-based planning arises naturally from minimizing a variational free energy functional on a generative model augmented with preference and epistemic priors. This result reinforces theoretical consistency with the Free Energy Principle, by casting planning itself as variational inference. Our formulation yields optimal policies that jointly support goal achievement and information gain, while incorporating a complexity term that accounts for bounded computational resources. This unifying framework connects and extends existing methods, enabling scalable, resource-aware implementations of active inference agents.","authors":["Bert de Vries","Wouter Nuijten","Thijs van de Laar","Wouter Kouw","Sepideh Adamiat","Tim Nisslbeck","Mykola Lukashchuk","Hoang Minh Huu Nguyen","Marco Hidalgo Araya","Raphael Tresor","Thijs Jenneskens","Ivana Nikoloska","Raaja Subramanian","Bart van Erp","Dmitry Bagaev","Albert Podusenko"],"url":"https://arxiv.org/abs/2504.14898"}
{"created":"2025-04-22","title":"OmniAudio: Generating Spatial Audio from 360-Degree Video","abstract":"Traditional video-to-audio generation techniques primarily focus on field-of-view (FoV) video and non-spatial audio, often missing the spatial cues necessary for accurately representing sound sources in 3D environments. To address this limitation, we introduce a novel task, 360V2SA, to generate spatial audio from 360-degree videos, specifically producing First-order Ambisonics (FOA) audio - a standard format for representing 3D spatial audio that captures sound directionality and enables realistic 3D audio reproduction. We first create Sphere360, a novel dataset tailored for this task that is curated from real-world data. We also design an efficient semi-automated pipeline for collecting and cleaning paired video-audio data. To generate spatial audio from 360-degree video, we propose a novel framework OmniAudio, which leverages self-supervised pre-training using both spatial audio data (in FOA format) and large-scale non-spatial data. Furthermore, OmniAudio features a dual-branch framework that utilizes both panoramic and FoV video inputs to capture comprehensive local and global information from 360-degree videos. Experimental results demonstrate that OmniAudio achieves state-of-the-art performance across both objective and subjective metrics on Sphere360. Code and datasets will be released at https://github.com/liuhuadai/OmniAudio. The demo page is available at https://OmniAudio-360V2SA.github.io.","authors":["Huadai Liu","Tianyi Luo","Qikai Jiang","Kaicheng Luo","Peiwen Sun","Jialei Wan","Rongjie Huang","Qian Chen","Wen Wang","Xiangtai Li","Shiliang Zhang","Zhijie Yan","Zhou Zhao","Wei Xue"],"url":"https://arxiv.org/abs/2504.14906"}
{"created":"2025-04-22","title":"StableQuant: Layer Adaptive Post-Training Quantization for Speech Foundation Models","abstract":"In this paper, we propose StableQuant, a novel adaptive post-training quantization (PTQ) algorithm for widely used speech foundation models (SFMs). While PTQ has been successfully employed for compressing large language models (LLMs) due to its ability to bypass additional fine-tuning, directly applying these techniques to SFMs may not yield optimal results, as SFMs utilize distinct network architecture for feature extraction. StableQuant demonstrates optimal quantization performance regardless of the network architecture type, as it adaptively determines the quantization range for each layer by analyzing both the scale distributions and overall performance. We evaluate our algorithm on two SFMs, HuBERT and wav2vec2.0, for an automatic speech recognition (ASR) task, and achieve superior performance compared to traditional PTQ methods. StableQuant successfully reduces the sizes of SFM models to a quarter and doubles the inference speed while limiting the word error rate (WER) performance drop to less than 0.3% with 8-bit quantization.","authors":["Yeona Hong","Hyewon Han","Woo-jin Chung","Hong-Goo Kang"],"url":"https://arxiv.org/abs/2504.14915"}
{"created":"2025-04-22","title":"Integrating Response Time and Attention Duration in Bayesian Preference Learning for Multiple Criteria Decision Aiding","abstract":"We introduce a multiple criteria Bayesian preference learning framework incorporating behavioral cues for decision aiding. The framework integrates pairwise comparisons, response time, and attention duration to deepen insights into decision-making processes. The approach employs an additive value function model and utilizes a Bayesian framework to derive the posterior distribution of potential ranking models by defining the likelihood of observed preference data and specifying a prior on the preference structure. This distribution highlights each model's ability to reconstruct Decision-Makers' holistic pairwise comparisons. By leveraging both response time as a proxy for cognitive effort and alternative discriminability as well as attention duration as an indicator of criterion importance, the proposed model surpasses traditional methods by uncovering richer behavioral patterns. We report the results of a laboratory experiment on mobile phone contract selection involving 30 real subjects using a dedicated application with time-, eye-, and mouse-tracking components. We validate the novel method's ability to reconstruct complete preferences. The detailed ablation studies reveal time- and attention-related behavioral patterns, confirming that integrating comprehensive data leads to developing models that better align with the DM's actual preferences.","authors":["Jiaxuan Jiang","Jiapeng Liu","Mi{\\l}osz Kadzi\\'nski","Xiuwu Liao","Jingyu Dong"],"url":"https://arxiv.org/abs/2504.14938"}
{"created":"2025-04-22","title":"Parallel Kac's Walk Generates PRU","abstract":"Ma and Huang recently proved that the PFC construction, introduced by Metger, Poremba, Sinha and Yuen [MPSY24], gives an adaptive-secure pseudorandom unitary family PRU. Their proof developed a new path recording technique [MH24].","authors":["Chuhan Lu","Minglong Qin","Fang Song","Penghui Yao","Mingnan Zhao"],"url":"https://arxiv.org/abs/2504.14957"}
{"created":"2025-04-22","title":"Trainable Quantum Neural Network for Multiclass Image Classification with the Power of Pre-trained Tree Tensor Networks","abstract":"Tree tensor networks (TTNs) offer powerful models for image classification. While these TTN image classifiers already show excellent performance on classical hardware, embedding them into quantum neural networks (QNNs) may further improve the performance by leveraging quantum resources. However, embedding TTN classifiers into QNNs for multiclass classification remains challenging. Key obstacles are the highorder gate operations required for large bond dimensions and the mid-circuit postselection with exponentially low success rates necessary for the exact embedding. In this work, to address these challenges, we propose forest tensor network (FTN)-classifiers, which aggregate multiple small-bond-dimension TTNs. This allows us to handle multiclass classification without requiring large gates in the embedded circuits. We then remove the overhead of mid-circuit postselection by extending the adiabatic encoding framework to our setting and smoothly encode the FTN-classifiers into a quantum forest tensor network (qFTN)- classifiers. Numerical experiments on MNIST and CIFAR-10 demonstrate that we can successfully train FTN-classifiers and encode them into qFTN-classifiers, while maintaining or even improving the performance of the pre-trained FTN-classifiers. These results suggest that synergy between TTN classification models and QNNs can provide a robust and scalable framework for multiclass quantum-enhanced image classification.","authors":["Keisuke Murota","Takumi Kobori"],"url":"https://arxiv.org/abs/2504.14995"}
{"created":"2025-04-22","title":"Feedback Stackelberg-Nash equilibria in difference games with quasi-hierarchical interactions and inequality constraints","abstract":"In this paper, we study a class of two-player deterministic finite-horizon difference games with coupled inequality constraints, where each player has two types of decision variables: one involving sequential interactions and the other simultaneous interactions. We refer to these as quasi-hierarchical dynamic games and define a solution concept called the feedback Stackelberg-Nash (FSN) equilibrium. Under a separability assumption on cost functions, we formulate FSN solutions recursively using a dynamic programming-like approach. We further show that the FSN solution for these constrained games can be derived from the parametric feedback Stackelberg solution of an associated unconstrained game with only sequential interactions, given parameter choices that satisfy implicit complementarity conditions. For the linear-quadratic case, we show that the FSN solutions are obtained by reformulating these complementarity conditions as a single large-scale linear complementarity problem. Finally, we illustrate our results with a dynamic duopoly game with production constraints.","authors":["Partha Sarathi Mohapatra","Puduru Viswanadha Reddy","Georges Zaccour"],"url":"https://arxiv.org/abs/2504.15019"}
{"created":"2025-04-22","title":"Quantum pseudoresources imply cryptography","abstract":"While one-way functions (OWFs) serve as the minimal assumption for computational cryptography in the classical setting, in quantum cryptography, we have even weaker cryptographic assumptions such as pseudo-random states, and EFI pairs, among others. Moreover, the minimal assumption for computational quantum cryptography remains an open question. Recently, it has been shown that pseudoentanglement is necessary for the existence of quantum cryptography (Goul\\~ao and Elkouss 2024), but no cryptographic construction has been built from it.","authors":["Alex B. Grilo","\\'Alvaro Y\\'ang\\\"uez"],"url":"https://arxiv.org/abs/2504.15025"}
{"created":"2025-04-22","title":"Beyond Terabit/s Integrated Neuromorphic Photonic Processor for DSP-Free Optical Interconnects","abstract":"The rapid expansion of generative AI drives unprecedented demands for high-performance computing. Training large-scale AI models now requires vast interconnected GPU clusters across multiple data centers. Multi-scale AI training and inference demand uniform, ultra-low latency, and energy-efficient links to enable massive GPUs to function as a single cohesive unit. However, traditional electrical and optical interconnects, relying on conventional digital signal processors (DSPs) for signal distortion compensation, increasingly fail to meet these stringent requirements. To overcome these limitations, we present an integrated neuromorphic optical signal processor (OSP) that leverages deep reservoir computing and achieves DSP-free, all-optical, real-time processing. Experimentally, our OSP achieves a 100 Gbaud PAM4 per lane, 1.6 Tbit/s data center interconnect over a 5 km optical fiber in the C-band (equivalent to over 80 km in the O-band), far exceeding the reach of state-of-the-art DSP solutions, which are fundamentally constrained by chromatic dispersion in IMDD systems. Simultaneously, it reduces processing latency by four orders of magnitude and energy consumption by three orders of magnitude. Unlike DSPs, which introduce increased latency at high data rates, our OSP maintains consistent, ultra-low latency regardless of data rate scaling, making it ideal for future optical interconnects. Moreover, the OSP retains full optical field information for better impairment compensation and adapts to various modulation formats, data rates, and wavelengths. Fabricated using a mature silicon photonic process, the OSP can be monolithically integrated with silicon photonic transceivers, enhancing the compactness and reliability of all-optical interconnects. This research provides a highly scalable, energy-efficient, and high-speed solution, paving the way for next-generation AI infrastructure.","authors":["Benshan Wang","Qiarong Xiao","Tengji Xu","Li Fan","Shaojie Liu","Jianji Dong","Junwen Zhang","Chaoran Huang"],"url":"https://arxiv.org/abs/2504.15044"}
{"created":"2025-04-22","title":"OPO: Making Decision-Focused Data Acquisition Decisions","abstract":"We propose a model for making data acquisition decisions for variables in contextual stochastic optimisation problems. Data acquisition decisions are typically treated as separate and fixed. We explore problem settings in which the acquisition of contextual variables is costly and consequently constrained. The data acquisition problem is often solved heuristically for proxy objectives such as coverage. The more intuitive objective is the downstream decision quality as a result of data acquisition decisions. The whole pipeline can be characterised as an optimise-then-predict-then-optimise (OPO) problem. Analogously, much recent research has focused on how to integrate prediction and optimisation (PO) in the form of decision-focused learning. We propose leveraging differentiable optimisation to extend the integration to data acquisition. We solve the data acquisition problem with well-defined constraints by learning a surrogate linear objective function. We demonstrate an application of this model on a shortest path problem for which we first have to set a drone reconnaissance strategy to capture image segments serving as inputs to a model that predicts travel costs. We ablate the problem with a number of training modalities and demonstrate that the differentiable optimisation approach outperforms random search strategies.","authors":["Egon Per\\v{s}ak","Miguel F. Anjos"],"url":"https://arxiv.org/abs/2504.15062"}
{"created":"2025-04-22","title":"Explicit Lossless Vertex Expanders","abstract":"We give the first construction of explicit constant-degree lossless vertex expanders. Specifically, for any $\\varepsilon > 0$ and sufficiently large $d$, we give an explicit construction of an infinite family of $d$-regular graphs where every small set $S$ of vertices has $(1-\\varepsilon)d|S|$ neighbors (which implies $(1-2\\varepsilon)d|S|$ unique-neighbors). Our results also extend naturally to construct biregular bipartite graphs of any constant imbalance, where small sets on each side have strong expansion guarantees. The graphs we construct admit a free group action, and hence realize new families of quantum LDPC codes of Lin and M. Hsieh with a linear time decoding algorithm.","authors":["Jun-Ting Hsieh","Alexander Lubotzky","Sidhanth Mohanty","Assaf Reiner","Rachel Yun Zhang"],"url":"https://arxiv.org/abs/2504.15087"}
{"created":"2025-04-22","title":"Breaking Down Quantum Compilation: Profiling and Identifying Costly Passes","abstract":"With the increasing capabilities of quantum systems, the efficient, practical execution of quantum programs is becoming more critical. Each execution includes compilation time, which accounts for substantial overhead of the overall program runtime. To address this challenge, proposals that leverage precompilation techniques have emerged, whereby entire circuits or select components are precompiled to mitigate the compilation time spent during execution. Considering the impact of compilation time on quantum program execution, identifying the contribution of each individual compilation task to the execution time is necessary in directing the community's research efforts towards the development of an efficient compilation and execution pipeline. In this work, we perform a preliminary analysis of the quantum circuit compilation process in Qiskit, examining the cumulative runtime of each individual compilation task and identifying the tasks that most strongly impact the overall compilation time. Our results indicate that, as the desired level of optimization increases, circuit optimization and gate synthesis passes become the dominant tasks in compiling a Quantum Fourier Transform, with individual passes consuming up to 87% of the total compilation time. Mapping passes require the most compilation time for a GHZ state preparation circuit, accounting for over 99% of total compilation time.","authors":["Felix Zilk","Alessandro Tundo","Vincenzo De Maio","Ivona Brandic"],"url":"https://arxiv.org/abs/2504.15141"}
{"created":"2025-04-22","title":"Advanced posterior analyses of hidden Markov models: finite Markov chain imbedding and hybrid decoding","abstract":"Two major tasks in applications of hidden Markov models are to (i) compute distributions of summary statistics of the hidden state sequence, and (ii) decode the hidden state sequence. We describe finite Markov chain imbedding (FMCI) and hybrid decoding to solve each of these two tasks. In the first part of our paper we use FMCI to compute posterior distributions of summary statistics such as the number of visits to a hidden state, the total time spent in a hidden state, the dwell time in a hidden state, and the longest run length. We use simulations from the hidden state sequence, conditional on the observed sequence, to establish the FMCI framework. In the second part of our paper we apply hybrid segmentation for improved decoding of a HMM. We demonstrate that hybrid decoding shows increased performance compared to Viterbi or Posterior decoding (often also referred to as global or local decoding), and we introduce a novel procedure for choosing the tuning parameter in the hybrid procedure. Furthermore, we provide an alternative derivation of the hybrid loss function based on weighted geometric means. We demonstrate and apply FMCI and hybrid decoding on various classical data sets, and supply accompanying code for reproducibility.","authors":["Zenia Elise Damgaard B{\\ae}k","Mois\\`es Coll Maci\\`a","Laurits Skov","Asger Hobolth"],"url":"https://arxiv.org/abs/2504.15156"}
{"created":"2025-04-22","title":"Fully Adaptive Stepsizes: Which System Benefit More -- Centralized or Decentralized?","abstract":"In decentralized optimization, the choice of stepsize plays a critical role in algorithm performance. A common approach is to use a shared stepsize across all agents to ensure convergence. However, selecting an optimal stepsize often requires careful tuning, which can be time-consuming and may lead to slow convergence, especially when there is significant variation in the smoothness (L-smoothness) of local objective functions across agents. Individually tuning stepsizes per agent is also impractical, particularly in large-scale networks. To address these limitations, we propose AdGT, an adaptive gradient tracking method that enables each agent to adjust its stepsize based on the smoothness of its local objective. We prove that AdGT generates a sequence of iterates that converges to the optimal consensus solution. Through numerical experiments, we compare AdGT with fixed-stepsize gradient tracking methods and demonstrate its superior performance. Additionally, we compare AdGT with adaptive gradient descent (AdGD) in a centralized setting and observe that fully adaptive stepsizes offer greater benefits in decentralized networks than in centralized ones.","authors":["Diyako Ghaderyan","Stefan Werner"],"url":"https://arxiv.org/abs/2504.15196"}
{"created":"2025-04-22","title":"Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields","abstract":"Weak gravitational lensing is the slight distortion of galaxy shapes caused primarily by the gravitational effects of dark matter in the universe. In our work, we seek to invert the weak lensing signal from 2D telescope images to reconstruct a 3D map of the universe's dark matter field. While inversion typically yields a 2D projection of the dark matter field, accurate 3D maps of the dark matter distribution are essential for localizing structures of interest and testing theories of our universe. However, 3D inversion poses significant challenges. First, unlike standard 3D reconstruction that relies on multiple viewpoints, in this case, images are only observed from a single viewpoint. This challenge can be partially addressed by observing how galaxy emitters throughout the volume are lensed. However, this leads to the second challenge: the shapes and exact locations of unlensed galaxies are unknown, and can only be estimated with a very large degree of uncertainty. This introduces an overwhelming amount of noise which nearly drowns out the lensing signal completely. Previous approaches tackle this by imposing strong assumptions about the structures in the volume. We instead propose a methodology using a gravitationally-constrained neural field to flexibly model the continuous matter distribution. We take an analysis-by-synthesis approach, optimizing the weights of the neural network through a fully differentiable physical forward model to reproduce the lensing signal present in image measurements. We showcase our method on simulations, including realistic simulated measurements of dark matter distributions that mimic data from upcoming telescope surveys. Our results show that our method can not only outperform previous methods, but importantly is also able to recover potentially surprising dark matter structures.","authors":["Brandon Zhao","Aviad Levis","Liam Connor","Pratul P. Srinivasan","Katherine L. Bouman"],"url":"https://arxiv.org/abs/2504.15262"}
{"created":"2025-04-22","title":"Sunflowers and Ramsey problems for restricted intersections","abstract":"Extremal problems on set systems with restricted intersections have been an important part of combinatorics in the last 70 year. In this paper, we study the following Ramsey version of these problems. Given a set $L\\subseteq \\{0,\\dots,k-1\\}$ and a family $\\mathcal{F}$ of $k$-element sets which does not contain a sunflower with $m$ petals whose kernel size is in $L$, how large a subfamily of $\\mathcal{F}$ can we find in which no pair has intersection size in $L$? We give matching upper and lower bounds, determining the dependence on $m$ for all $k$ and $L$. This problem also finds applications in quantum computing.","authors":["Barnab\\'as Janzer","Zhihan Jin","Benny Sudakov","Kewen Wu"],"url":"https://arxiv.org/abs/2504.15264"}
{"created":"2025-04-22","title":"Universal time-series forecasting with mixture predictors","abstract":"This book is devoted to the problem of sequential probability forecasting, that is, predicting the probabilities of the next outcome of a growing sequence of observations given the past. This problem is considered in a very general setting that unifies commonly used probabilistic and non-probabilistic settings, trying to make as few as possible assumptions on the mechanism generating the observations. A common form that arises in various formulations of this problem is that of mixture predictors, which are formed as a combination of a finite or infinite set of other predictors attempting to combine their predictive powers. The main subject of this book are such mixture predictors, and the main results demonstrate the universality of this method in a very general probabilistic setting, but also show some of its limitations. While the problems considered are motivated by practical applications, involving, for example, financial, biological or behavioural data, this motivation is left implicit and all the results exposed are theoretical.","authors":["Daniil Ryabko"],"url":"https://arxiv.org/abs/2010.00297"}
{"created":"2025-04-22","title":"Game-Theoretic Multiagent Reinforcement Learning","abstract":"Following the remarkable success of the AlphaGo series, significant advances in multi-agent reinforcement learning (MARL) techniques have been witnessed. MARL corresponds to the learning problem in a multi-agent system in which multiple agents learn simultaneously. It is an interdisciplinary domain with a long history that includes game theory, machine learning, stochastic control, psychology, and optimisation. Although MARL has achieved considerable empirical success in solving real-world games, there is a lack of a self-contained overview in the literature that elaborates the game theoretical foundations of modern MARL methods and summarises the recent advances. In fact, the majority of existing surveys are outdated and do not fully cover the recent developments since 2010. In this work, we provide a monograph on MARL that covers both the fundamentals and the latest developments in the research frontier. The goal of our monograph is to provide a self-contained assessment of the current state-of-the-art MARL techniques from a game theoretical perspective. We expect this work to serve as a stepping stone for both new researchers who are about to enter this fast-growing domain and existing domain experts who want to obtain a panoramic view and identify new directions based on recent advances.","authors":["Yaodong Yang","Chengdong Ma","Zihan Ding","Stephen McAleer","Chi Jin","Jun Wang"],"url":"https://arxiv.org/abs/2011.00583"}
{"created":"2025-04-22","title":"Representation Learning by Ranking across multiple tasks","abstract":"In recent years, representation learning has become the research focus of the machine learning community. Large-scale neural networks are a crucial step toward achieving general intelligence, with their success largely attributed to their ability to learn abstract representations of data. Several learning fields are actively discussing how to learn representations, yet there is a lack of a unified perspective. We convert the representation learning problem under different tasks into a ranking problem. By adopting the ranking problem as a unified perspective, representation learning tasks can be solved in a unified manner by optimizing the ranking loss. Experiments under various learning tasks, such as classification, retrieval, multi-label learning, and regression, prove the superiority of the representation learning by ranking framework. Furthermore, experiments under self-supervised learning tasks demonstrate the significant advantage of the ranking framework in processing unsupervised training data, with data augmentation techniques further enhancing its performance.","authors":["Lifeng Gu"],"url":"https://arxiv.org/abs/2103.15093"}
{"created":"2025-04-22","title":"Explaining Representation by Mutual Information","abstract":"As interpretability gains attention in machine learning, there is a growing need for reliable models that fully explain representation content. We propose a mutual information (MI)-based method that decomposes neural network representations into three exhaustive components: total mutual information, decision-related information, and redundant information. This theoretically complete framework captures the entire input-representation relationship, surpassing partial explanations like those from Grad-CAM. Using two lightweight modules integrated into architectures such as CNNs and Transformers,we estimate these components and demonstrate their interpretive power through visualizations on ResNet and prototype network applied to image classification and few-shot learning tasks. Our approach is distinguished by three key features: 1. Rooted in mutual information theory, it delivers a thorough and theoretically grounded interpretation, surpassing the scope of existing interpretability methods. 2. Unlike conventional methods that focus on explaining decisions, our approach centers on interpreting representations. 3. It seamlessly integrates into pre-existing network architectures, requiring only fine-tuning of the inserted modules.","authors":["Lifeng Gu"],"url":"https://arxiv.org/abs/2103.15114"}
{"created":"2025-04-22","title":"Simple Worst-Case Optimal Adaptive Prefix-Free Coding","abstract":"We give a new and simple worst-case optimal algorithm for adaptive prefix-free coding that matches Gagie and Nekrich's bounds except for lower-order terms, and uses no data structures more complicated than a lookup table. Moreover, when Gagie and Nekrich's algorithm is modified for adaptive alphabetic prefix-free coding its decoding time slows down to $O (\\log \\log n)$ per character, but ours can be modified for this problem with no asymptotic slowdown. As far as we know, this gives the first algorithm for this alphabetic problem that is simultaneously worst-case optimal in terms of encoding and decoding time and of encoding length.","authors":["Travis Gagie"],"url":"https://arxiv.org/abs/2109.02997"}
{"created":"2025-04-22","title":"Persian Abstract Meaning Representation: Annotation Guidelines and Gold Standard Dataset","abstract":"This paper introduces the Persian Abstract Meaning Representation (AMR) guidelines, a detailed guide for annotating Persian sentences with AMR, focusing on the necessary adaptations to fit Persian's unique syntactic structures. We discuss the development process of a Persian AMR gold standard dataset consisting of 1,562 sentences created following the guidelines. By examining the language specifications and nuances that distinguish AMR annotations of a low-resource language like Persian, we shed light on the challenges and limitations of developing a universal meaning representation framework. The guidelines and the dataset introduced in this study highlight such challenges, aiming to advance the field.","authors":["Reza Takhshid","Tara Azin","Razieh Shojaei","Mohammad Bahrani"],"url":"https://arxiv.org/abs/2205.07712"}
{"created":"2025-04-22","title":"Traffic Congestion Prediction Using Machine Learning Techniques","abstract":"The prediction of traffic congestion can serve a crucial role in making future decisions. Although many studies have been conducted regarding congestion, most of these could not cover all the important factors (e.g., weather conditions). We proposed a prediction model for traffic congestion that can predict congestion based on day, time and several weather data (e.g., temperature, humidity). To evaluate our model, it has been tested against the traffic data of New Delhi. With this model, congestion of a road can be predicted one week ahead with an average RMSE of 1.12. Therefore, this model can be used to take preventive measure beforehand.","authors":["Rafed Muhammad Yasir","Moumita Asad","Naushin Nower","Mohammad Shoyaib"],"url":"https://arxiv.org/abs/2206.10983"}
{"created":"2025-04-22","title":"Semantic Image Synthesis via Diffusion Models","abstract":"Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable success in various image generation tasks compared with Generative Adversarial Nets (GANs). Recent work on semantic image synthesis mainly follows the de facto GAN-based approaches, which may lead to unsatisfactory quality or diversity of generated images. In this paper, we propose a novel framework based on DDPM for semantic image synthesis. Unlike previous conditional diffusion model directly feeds the semantic layout and noisy image as input to a U-Net structure, which may not fully leverage the information in the input semantic mask, our framework processes semantic layout and noisy image differently. It feeds noisy image to the encoder of the U-Net structure while the semantic layout to the decoder by multi-layer spatially-adaptive normalization operators. To further improve the generation quality and semantic interpretability in semantic image synthesis, we introduce the classifier-free guidance sampling strategy, which acknowledge the scores of an unconditional model for sampling process. Extensive experiments on four benchmark datasets demonstrate the effectiveness of our proposed method, achieving state-of-the-art performance in terms of fidelity (FID) and diversity (LPIPS). Our code and pretrained models are available at https://github.com/WeilunWang/semantic-diffusion-model.","authors":["Wengang Zhou","Weilun Wang","Wengang Zhou","Dongdong Chen","Dong Chen","Lu Yuan","Houqiang Li"],"url":"https://arxiv.org/abs/2207.00050"}
{"created":"2025-04-22","title":"MeritRank: Sybil Tolerant Reputation for Merit-based Tokenomics","abstract":"Decentralized reputation systems are emerging as promising mechanisms to enhance the effectiveness of token-based economies. Unlike traditional monetary incentives, these systems reward participants based on the actual value of their contributions to the network. However, the advantages and challenges associated with such systems remain largely unexplored. In this work, we investigate the inherent trade-offs in designing a decentralized reputation system that is simultaneously generalizable, trustless, and Sybil-resistant. Specifically, `generalizable' means that the system can assess various types of contributions across different contexts, `trustless' indicates that it functions without the need for a central authority to oversee reputations, and `Sybil-resistant' refers to its ability to withstand manipulations by fake identities, i.e., Sybil attacks.","authors":["Bulat Nasrulin","Georgy Ishmaev","Johan Pouwelse"],"url":"https://arxiv.org/abs/2207.09950"}
{"created":"2025-04-22","title":"PA-Boot: A Formally Verified Authentication Protocol for Multiprocessor Secure Boot","abstract":"Hardware supply-chain attacks are raising significant security threats to the boot process of multiprocessor systems. This paper identifies a new, prevalent hardware supply-chain attack surface that can bypass multiprocessor secure boot due to the absence of processor-authentication mechanisms. To defend against such attacks, we present PA-Boot, the first formally verified processor-authentication protocol for secure boot in multiprocessor systems. PA-Boot is proved functionally correct and is guaranteed to detect multiple adversarial behaviors, e.g., processor replacements, man-in-the-middle attacks, and tampering with certificates. The fine-grained formalization of PA-Boot and its fully mechanized security proofs are carried out in the Isabelle/HOL theorem prover with 306 lemmas/theorems and ~7,100 LoC. Experiments on a proof-of-concept implementation indicate that PA-Boot can effectively identify boot-process attacks with a considerably minor overhead and thereby improve the security of multiprocessor systems.","authors":["Zhuoruo Zhang","Rui Chang","Mingshuai Chen","Wenbo Shen","Chenyang Yu","He Huang","Qinming Dai","Yongwang Zhao"],"url":"https://arxiv.org/abs/2209.07936"}
{"created":"2025-04-22","title":"Exploring Self-Attention for Crop-type Classification Explainability","abstract":"Transformer models have become a promising approach for crop-type classification. Although their attention weights can be used to understand the relevant time points for crop disambiguation, the validity of these insights depends on how closely the attention weights approximate the actual workings of these black-box models, which is not always clear. In this paper, we introduce a novel explainability framework that systematically evaluates the explanatory power of the attention weights of a standard transformer encoder for crop-type classification. Our results show that attention patterns strongly relate to key dates, which are often associated with critical phenological events for crop-type classification. Further, the sensitivity analysis reveals the limited capability of the attention weights to characterize crop phenology as the identified phenological events depend on the other crops considered during training. This limitation highlights the relevance of future work towards the development of deep learning approaches capable of automatically learning the temporal vegetation dynamics for accurate crop disambiguation","authors":["Ivica Obadic","Ribana Roscher","Dario Augusto Borges Oliveira","Xiao Xiang Zhu"],"url":"https://arxiv.org/abs/2210.13167"}
{"created":"2025-04-22","title":"Enhancing Efficiency in Multidevice Federated Learning through Data Selection","abstract":"Ubiquitous wearable and mobile devices provide access to a diverse set of data. However, the mobility demand for our devices naturally imposes constraints on their computational and communication capabilities. A solution is to locally learn knowledge from data captured by ubiquitous devices, rather than to store and transmit the data in its original form. In this paper, we develop a federated learning framework, called Centaur, to incorporate on-device data selection at the edge, which allows partition-based training of a deep neural nets through collaboration between constrained and resourceful devices within the multidevice ecosystem of the same user. We benchmark on five neural net architecture and six datasets that include image data and wearable sensor time series. On average, Centaur achieves ~19% higher classification accuracy and ~58% lower federated training latency, compared to the baseline. We also evaluate Centaur when dealing with imbalanced non-iid data, client participation heterogeneity, and different mobility patterns. To encourage further research in this area, we release our code at https://github.com/nokia-bell-labs/data-centric-federated-learning","authors":["Fan Mo","Mohammad Malekzadeh","Soumyajit Chatterjee","Fahim Kawsar","Akhil Mathur"],"url":"https://arxiv.org/abs/2211.04175"}
{"created":"2025-04-22","title":"Tight Complexity Bounds for Counting Generalized Dominating Sets in Bounded-Treewidth Graphs Part I: Algorithmic Results","abstract":"We investigate how efficiently a well-studied family of domination-type problems can be solved on bounded-treewidth graphs. For sets $\\sigma,\\rho$ of non-negative integers, a $(\\sigma,\\rho)$-set of a graph $G$ is a set $S$ of vertices such that $|N(u)\\cap S|\\in \\sigma$ for every $u\\in S$, and $|N(v)\\cap S|\\in \\rho$ for every $v\\not\\in S$. The problem of finding a $(\\sigma,\\rho)$-set (of a certain size) unifies standard problems such as Independent Set, Dominating Set, Independent Dominating Set, and many others.","authors":["Jacob Focke","D\\'aniel Marx","Fionn Mc Inerney","Daniel Neuen","Govind S. Sankar","Philipp Schepper","Philip Wellnitz"],"url":"https://arxiv.org/abs/2211.04278"}
{"created":"2025-04-22","title":"GPU Optimizations for the Hierarchical Poincar\\'e-Steklov Scheme","abstract":"This manuscript presents GPU optimizations for the 2D Hierarchical Poincar\\'e-Steklov (HPS) discretization scheme. HPS is a multi-domain spectral collocation method that combines high-order discretizations with direct solvers to accurately resolve highly oscillatory solutions. The domain decomposition approach of HPS connects domains directly via a sparse direct solver. The proposed optimizations exploit batched linear algebra on modern hybrid architectures, are straightforward to implement, and improve the solver's practical speed. The manuscript demonstrates that GPU optimizations can significantly reduce the traditionally high cost of performing local static condensation for discretizations with very high local order $p$. Numerical experiments for the Helmholtz equation with high wavenumbers on curved and rectangular domains confirm the high accuracy achieved by the HPS discretization and the significant reduction in computation time achieved with GPU optimizations.","authors":["Anna Yesypenko","Per-Gunnar Martinsson"],"url":"https://arxiv.org/abs/2211.14969"}
{"created":"2025-04-22","title":"ApproxABFT: Approximate Algorithm-Based Fault Tolerance for Neural Network Processing","abstract":"With the increasing deployment of deep neural networks (DNNs) in terrestrial and aerospace safety-critical applications, system reliability has emerged as a co-equal design metric alongside computational efficiency. Algorithm-based fault tolerance (ABFT) mechanisms, characterized by architecture-agnostic and cost-effectiveness, have become a promising solution for reliability enhancement. However, conventional ABFT approaches rely on rigorous verification mechanisms where even minor computational deviations trigger error recovery processes, which not only disregards the intrinsic fault tolerance characteristics of DNN models but also incurs redundant fault tolerance processing overhead. To address these limitations, we propose an Approximate ABFT framework (ApproxABFT) that innovatively introduces adaptive error tolerance thresholds to enable selective fault recovery, activating error correction modules exclusively when computational deviations exceed predefined thresholds. This approach effectively mitigating overreaction to non-critical computational errors. Furthermore, a dynamic block granularity optimization algorithm is implemented to achieve inter-layer error sensitivity balancing. Experimental evaluations demonstrate that the proposed ApproxABFT achieves a 43.39% average reduction in redundant computing overhead compared to previous accurate ABFT, while simultaneously enhancing the tolerable soft error rate by an order of magnitude.","authors":["Xinghua Xue","Cheng Liu","Feng Min","Tao Luo","Yinhe Han"],"url":"https://arxiv.org/abs/2302.10469"}
{"created":"2025-04-22","title":"Three iterations of $(d-1)$-WL test distinguish non isometric clouds of $d$-dimensional points","abstract":"The Weisfeiler--Lehman (WL) test is a fundamental iterative algorithm for checking isomorphism of graphs. It has also been observed that it underlies the design of several graph neural network architectures, whose capabilities and performance can be understood in terms of the expressive power of this test. Motivated by recent developments in machine learning applications to datasets involving three-dimensional objects, we study when the WL test is {\\em complete} for clouds of euclidean points represented by complete distance graphs, i.e., when it can distinguish, up to isometry, any arbitrary such cloud. %arbitrary clouds of euclidean points represented by complete distance graphs. % How many dimensions of the Weisfeiler--Lehman test is enough to distinguish any two non-isometric point clouds in $d$-dimensional Euclidean space, assuming that these point clouds are given as complete graphs labeled by distances between the points? This question is important for understanding, which architectures of graph neural networks are capable of fully exploiting the spacial structure of a point cloud.","authors":["Valentino Delle Rose","Alexander Kozachinskiy","Crist\\'obal Rojas","Mircea Petrache","Pablo Barcel\\'o"],"url":"https://arxiv.org/abs/2303.12853"}
{"created":"2025-04-22","title":"Decidability of Querying First-Order Theories via Countermodels of Finite Width","abstract":"We propose a generic framework for establishing the decidability of a wide range of logical entailment problems (briefly called querying), based on the existence of countermodels that are structurally simple, gauged by certain types of width measures (with treewidth and cliquewidth as popular examples). As an important special case of our framework, we identify logics exhibiting width-finite finitely universal model sets, warranting decidable entailment for a wide range of homomorphism-closed queries, subsuming a diverse set of practically relevant query languages. As a particularly powerful width measure, we propose to employ Blumensath's partitionwidth, which subsumes various other commonly considered width measures and exhibits highly favorable computational and structural properties. Focusing on the formalism of existential rules as a popular showcase, we explain how finite partitionwidth sets of rules subsume other known abstract decidable classes but - leveraging existing notions of stratification - also cover a wide range of new rulesets. We expose natural limitations for fitting the class of finite unification sets into our picture and suggest several options for remedy.","authors":["Thomas Feller","Tim S. Lyon","Piotr Ostropolski-Nalewaja","Sebastian Rudolph"],"url":"https://arxiv.org/abs/2304.06348"}
{"created":"2025-04-22","title":"A Survey on Multi-Resident Activity Recognition in Smart Environments","abstract":"Human activity recognition (HAR) is a rapidly growing field that utilizes smart devices, sensors, and algorithms to automatically classify and identify the actions of individuals within a given environment. These systems have a wide range of applications, including assisting with caring tasks, increasing security, and improving energy efficiency. However, there are several challenges that must be addressed in order to effectively utilize HAR systems in multi-resident environments. One of the key challenges is accurately associating sensor observations with the identities of the individuals involved, which can be particularly difficult when residents are engaging in complex and collaborative activities. This paper provides a brief overview of the design and implementation of HAR systems, including a summary of the various data collection devices and approaches used for human activity identification. It also reviews previous research on the use of these systems in multi-resident environments and offers conclusions on the current state of the art in the field.","authors":["Farhad MortezaPour Shiri","Thinagaran Perumal","Norwati Mustapha","Raihani Mohamed","Mohd Anuaruddin Bin Ahmadon","Shingo Yamaguchi"],"url":"https://arxiv.org/abs/2304.12304"}
{"created":"2025-04-22","title":"Clustering What Matters in Constrained Settings","abstract":"Constrained clustering problems generalize classical clustering formulations, e.g., $k$-median, $k$-means, by imposing additional constraints on the feasibility of clustering. There has been significant recent progress in obtaining approximation algorithms for these problems, both in the metric and the Euclidean settings. However, the outlier version of these problems, where the solution is allowed to leave out $m$ points from the clustering, is not well understood. In this work, we give a general framework for reducing the outlier version of a constrained $k$-median or $k$-means problem to the corresponding outlier-free version with only $(1+\\varepsilon)$-loss in the approximation ratio. The reduction is obtained by mapping the original instance of the problem to $f(k,m, \\varepsilon)$ instances of the outlier-free version, where $f(k, m, \\varepsilon) = \\left( \\frac{k+m}{\\varepsilon}\\right)^{O(m)}$. As specific applications, we get the following results:","authors":["Ragesh Jaiswal","Amit Kumar"],"url":"https://arxiv.org/abs/2305.00175"}
{"created":"2025-04-22","title":"Multiscale analysis via pseudo-reversing and applications to manifold-valued sequences","abstract":"Modeling data using manifold values is a powerful concept with numerous advantages, particularly in addressing nonlinear phenomena. This approach captures the intrinsic geometric structure of the data, leading to more accurate descriptors and more efficient computational processes. However, even fundamental tasks like compression and data enhancement present meaningful challenges in the manifold setting. This paper introduces a multiscale transform that aims to represent manifold-valued sequences at different scales, enabling novel data processing tools for various applications. Similar to traditional methods, our construction is based on a refinement operator that acts as an upsampling operator and a corresponding downsampling operator. Inspired by Wiener's lemma, we term the latter as the reverse of the former. It turns out that some upsampling operators, for example, least-squares-based refinement, do not have a practical reverse. Therefore, we introduce the notion of pseudo-reversing and explore its analytical properties and asymptotic behavior. We derive analytical properties of the induced multiscale transform and conclude the paper with numerical illustrations showcasing different aspects of the pseudo-reversing and two data processing applications involving manifolds.","authors":["Wael Mattar","Nir Sharon"],"url":"https://arxiv.org/abs/2305.06261"}
{"created":"2025-04-22","title":"Evaluating the Impact of Community Oversight for Managing Mobile Privacy and Security","abstract":"Mobile privacy and security can be a collaborative process where individuals seek advice and help from their trusted communities. To support such collective privacy and security management, we developed a mobile app for Community Oversight of Privacy and Security (\"CO-oPS\") that allows community members to review one another's apps installed and permissions granted to provide feedback. We conducted a four-week-long field study with 22 communities (101 participants) of friends, families, or co-workers who installed the CO-oPS app on their phones. Measures of transparency, trust, and awareness of one another's mobile privacy and security behaviors, along with individual and community participation in mobile privacy and security co-management, increased from pre- to post-study. Interview findings confirmed that the app features supported collective considerations of apps and permissions. However, participants expressed a range of concerns regarding having community members with different levels of technical expertise and knowledge regarding mobile privacy and security that can impact motivation to participate and perform oversight. Our study demonstrates the potential and challenges of community oversight mechanisms to support communities to co-manage mobile privacy and security.","authors":["Mamtaj Akter","Madiha Tabassum","Nazmus Sakib Miazi","Leena Alghamdi","Jess Kropczynski","Pamela Wisniewski","Heather Lipford"],"url":"https://arxiv.org/abs/2306.02289"}
{"created":"2025-04-22","title":"A Simple $(1-\\epsilon)$-Approximation Semi-Streaming Algorithm for Maximum (Weighted) Matching","abstract":"We present a simple semi-streaming algorithm for $(1-\\epsilon)$-approximation of bipartite matching in $O(\\log{\\!(n)}/\\epsilon)$ passes. This matches the performance of state-of-the-art \"$\\epsilon$-efficient\" algorithms -- the ones with much better dependence on $\\epsilon$ albeit with some mild dependence on $n$ -- while being considerably simpler.","authors":["Sepehr Assadi"],"url":"https://arxiv.org/abs/2307.02968"}
{"created":"2025-04-22","title":"TVPR: Text-to-Video Person Retrieval and a New Benchmark","abstract":"Most existing methods for text-based person retrieval focus on text-to-image person retrieval. Nevertheless, due to the lack of dynamic information provided by isolated frames, the performance is hampered when the person is obscured or variable motion details are missed in isolated frames. To overcome this, we propose a novel Text-to-Video Person Retrieval (TVPR) task. Since there is no dataset or benchmark that describes person videos with natural language, we construct a large-scale cross-modal person video dataset containing detailed natural language annotations, termed as Text-to-Video Person Re-identification (TVPReid) dataset. In this paper, we introduce a Multielement Feature Guided Fragments Learning (MFGF) strategy, which leverages the cross-modal text-video representations to provide strong text-visual and text-motion matching information to tackle uncertain occlusion conflicting and variable motion details. Specifically, we establish two potential cross-modal spaces for text and video feature collaborative learning to progressively reduce the semantic difference between text and video. To evaluate the effectiveness of the proposed MFGF, extensive experiments have been conducted on TVPReid dataset. To the best of our knowledge, MFGF is the first successful attempt to use video for text-based person retrieval task and has achieved state-of-the-art performance on TVPReid dataset. The TVPReid dataset will be publicly available to benefit future research.","authors":["Xu Zhang","Fan Ni","Guan-Nan Dong","Aichun Zhu","Jianhui Wu","Mingcheng Ni","Hui Liu"],"url":"https://arxiv.org/abs/2307.07184"}
{"created":"2025-04-22","title":"Optimal Clustering with Dependent Costs in Bayesian Networks","abstract":"Clustering of nodes in Bayesian Networks (BNs) and related graphical models such as Dynamic BNs (DBNs) has been demonstrated to enhance computational efficiency and improve model learning. Typically, it involves the partitioning of the underlying Directed Acyclic Graph (DAG) into cliques, or optimising for some cost or criteria. Computational cost is important since BN and DBN inference, such as estimating marginal distributions given evidence or updating model parameters, is NP-hard. The challenge is exacerbated by cost dependency, where inference outcomes and hence clustering cost depends on both nodes within a cluster and the mapping of clusters that are connected by at least one arc. We propose an algorithm called Dependent Cluster MAPping (DCMAP) which is shown analytically, given an arbitrarily defined, positive cost function, to find all optimal cluster mappings, and do so with no more iterations than an equally informed algorithm. DCMAP is demonstrated on a complex systems seagrass DBN, which has 25 nodes per time-slice, and captures biological, ecological and environmental dynamics and their interactions to predict the impact of dredging stressors on resilience and their cumulative effects over time. The algorithm is employed to find clusters to optimise the computational efficiency of inferring marginal distributions given evidence. For the 25 (one time-slice) and 50-node (two time-slices) DBN, the search space size was $9.91\\times10^9$ and $1.51\\times10^{21}$ possible cluster mappings, respectively, but the first optimal solution was found at iteration number 856 (95\\% CI 852,866), and 1569 (1566,1581) with a cost that was 4\\% and 0.2\\% of the naive heuristic cost, respectively. Through optimal clustering, DCMAP opens up opportunities for further research beyond improving computational efficiency, such as using clustering to minimise entropy in BN learning.","authors":["Paul Pao-Yen Wu","Fabrizio Ruggeri","Kerrie Mengersen"],"url":"https://arxiv.org/abs/2308.03970"}
{"created":"2025-04-22","title":"Fairness Notions in DAG-based DLTs","abstract":"This paper investigates the issue of fairness in Distributed Ledger Technology (DLT), specifically focusing on the shortcomings observed in current blockchain systems due to Miner Extractable Value (MEV) phenomena and systemic centralization. We explore the potential of Directed Acyclic Graphs (DAGs) as a solution to address or mitigate these fairness concerns. Our objective is to gain a comprehensive understanding of fairness in DAG-based DLTs by examining its different aspects and measurement metrics. We aim to establish a shared knowledge base that facilitates accurate fairness assessment and allows for an evaluation of whether DAG-based DLTs offer a more equitable design. We describe the various dimensions of fairness and conduct a comparative analysis to examine how they relate to different components of DLTs. This analysis serves as a catalyst for further research, encouraging the development of cryptographic systems that promote fairness.","authors":["Mayank Raikwar","Nikita Polyanskii","Sebastian M\\\"uller"],"url":"https://arxiv.org/abs/2308.04831"}
{"created":"2025-04-22","title":"Improving Clinical Decision Support through Interpretable Machine Learning and Error Handling in Electronic Health Records","abstract":"The objective of this work is to develop an Electronic Medical Record (EMR) data processing tool that confers clinical context to Machine Learning (ML) algorithms for error handling, bias mitigation and interpretability. We present Trust-MAPS, an algorithm that translates clinical domain knowledge into high-dimensional, mixed-integer programming models that capture physiological and biological constraints on clinical measurements. EMR data is projected onto this constrained space, effectively bringing outliers to fall within a physiologically feasible range. We then compute the distance of each data point from the constrained space modeling healthy physiology to quantify deviation from the norm. These distances, termed \"trust-scores,\" are integrated into the feature space for downstream ML applications. We demonstrate the utility of Trust-MAPS by training a binary classifier for early sepsis prediction on data from the 2019 PhysioNet Computing in Cardiology Challenge, using the XGBoost algorithm and applying SMOTE for overcoming class-imbalance. The Trust-MAPS framework shows desirable behavior in handling potential errors and boosting predictive performance. We achieve an AUROC of 0.91 (0.89, 0.92 : 95% CI) for predicting sepsis 6 hours before onset - a marked 15% improvement over a baseline model trained without Trust-MAPS. Trust-scores emerge as clinically meaningful features that not only boost predictive performance for clinical decision support tasks, but also lend interpretability to ML models. This work is the first to translate clinical domain knowledge into mathematical constraints, model cross-vital dependencies, and identify aberrations in high-dimensional medical data. Our method allows for error handling in EMR, and confers interpretability and superior predictive power to models trained for clinical decision support.","authors":["Mehak Arora","Hassan Mortagy","Nathan Dwarshuis","Jeffrey Wang","Philip Yang","Andre L Holder","Swati Gupta","Rishikesan Kamaleswaran"],"url":"https://arxiv.org/abs/2308.10781"}
{"created":"2025-04-22","title":"AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling","abstract":"Business optimisation refers to the process of finding and implementing efficient and cost-effective means of operation to bring a competitive advantage for businesses. Synthesizing problem formulations is an integral part of business optimisation, which relies on human expertise to construct problem formulations using optimisation languages. Interestingly, with advancements in Large Language Models (LLMs), the human expertise needed in problem formulation can be minimized. However, developing an LLM for problem formulation is challenging, due to training data, token limitations, and lack of appropriate performance metrics. For the requirement of training data, recent attention has been directed towards fine-tuning pre-trained LLMs for downstream tasks rather than training an LLM from scratch for a specific task. In this paper, we adopt an LLM fine-tuning approach and propose an AI-Copilot for business optimisation problem formulation. For token limitations, we introduce modularization and prompt engineering techniques to synthesize complex problem formulations as modules that fit into the token limits of LLMs. Additionally, we design performance evaluation metrics that are better suited for assessing the accuracy and quality of problem formulations. The experiment results demonstrate that with this approach we can synthesize complex and large problem formulations for a typical business optimisation problem in production scheduling.","authors":["Pivithuru Thejan Amarasinghe","Su Nguyen","Yuan Sun","Damminda Alahakoon"],"url":"https://arxiv.org/abs/2309.13218"}
{"created":"2025-04-22","title":"Efficient Vectorized Backpropagation Algorithms for Training Feedforward Networks Composed of Quadratic Neurons","abstract":"Higher order artificial neurons whose outputs are computed by applying an activation function to a higher order multinomial function of the inputs have been considered in the past, but did not gain acceptance due to the extra parameters and computational cost. However, higher order neurons have significantly greater learning capabilities since the decision boundaries of higher order neurons can be complex surfaces instead of just hyperplanes. The boundary of a single quadratic neuron can be a general hyper-quadric surface allowing it to learn many nonlinearly separable datasets. Since quadratic forms can be represented by symmetric matrices, only $\\frac{n(n+1)}{2}$ additional parameters are needed instead of $n^2$. A quadratic Logistic regression model is first presented. Solutions to the XOR problem with a single quadratic neuron are considered. The complete vectorized equations for both forward and backward propagation in feedforward networks composed of quadratic neurons are derived. A reduced parameter quadratic neural network model with just $ n $ additional parameters per neuron that provides a compromise between learning ability and computational cost is presented. Comparison on benchmark classification datasets are used to demonstrate that a final layer of quadratic neurons enables networks to achieve higher accuracy with significantly fewer hidden layer neurons. In particular this paper shows that any dataset composed of $\\mathcal{C}$ bounded clusters can be separated with only a single layer of $\\mathcal{C}$ quadratic neurons.","authors":["Mathew Mithra Noel","Venkataraman Muthiah-Nakarajan","Yug D Oswal"],"url":"https://arxiv.org/abs/2310.02901"}
{"created":"2025-04-22","title":"A Holistic Evaluation of Piano Sound Quality","abstract":"This paper aims to develop a holistic evaluation method for piano sound quality to assist in purchasing decisions. Unlike previous studies that focused on the effect of piano performance techniques on sound quality, this study evaluates the inherent sound quality of different pianos. To derive quality evaluation systems, the study uses subjective questionnaires based on a piano sound quality dataset. The method selects the optimal piano classification models by comparing the fine-tuning results of different pre-training models of Convolutional Neural Networks (CNN). To improve the interpretability of the models, the study applies Equivalent Rectangular Bandwidth (ERB) analysis. The results reveal that musically trained individuals are better able to distinguish between the sound quality differences of different pianos. The best fine-tuned CNN pre-trained backbone achieves a high accuracy of 98.3% as the piano classifier. However, the dataset is limited, and the audio is sliced to increase its quantity, resulting in a lack of diversity and balance, so we use focal loss to reduce the impact of data imbalance. To optimize the method, the dataset will be expanded, or few-shot learning techniques will be employed in future research.","authors":["Monan Zhou","Shangda Wu","Shaohua Ji","Zijin Li","Wei Li"],"url":"https://arxiv.org/abs/2310.04722"}
{"created":"2025-04-22","title":"Energy-Aware Routing Algorithm for Mobile Ground-to-Air Charging","abstract":"We investigate the problem of energy-constrained planning for a cooperative system of an Unmanned Ground Vehicles (UGV) and an Unmanned Aerial Vehicle (UAV). In scenarios where the UGV serves as a mobile base to ferry the UAV and as a charging station to recharge the UAV, we formulate a novel energy-constrained routing problem. To tackle this problem, we design an energy-aware routing algorithm, aiming to minimize the overall mission duration under the energy limitations of both vehicles. The algorithm first solves a Traveling Salesman Problem (TSP) to generate a guided tour. Then, it employs the Monte-Carlo Tree Search (MCTS) algorithm to refine the tour and generate paths for the two vehicles. We evaluate the performance of our algorithm through extensive simulations and a proof-of-concept experiment. The results show that our algorithm consistently achieves near-optimal mission time and maintains fast running time across a wide range of problem instances.","authors":["Bill Cai","Fei Lu","Lifeng Zhou"],"url":"https://arxiv.org/abs/2310.07729"}
{"created":"2025-04-22","title":"Language-Guided Reinforcement Learning for Hard Attention in Few-Shot Learning","abstract":"Attention mechanisms have demonstrated significant potential in enhancing learning models by identifying key portions of input data, particularly in scenarios with limited training samples. Inspired by human perception, we propose that focusing on essential data segments, rather than the entire dataset, can improve the accuracy and reliability of the learning models. However, identifying these critical data segments, or \"hard attention finding,\" is challenging, especially in few-shot learning, due to the scarcity of training data and the complexity of model parameters. To address this, we introduce LaHA, a novel framework that leverages language-guided deep reinforcement learning to identify and utilize informative data regions, thereby improving both interpretability and performance. Extensive experiments on benchmark datasets validate the effectiveness of LaHA.","authors":["Bahareh Nikpour","Narges Armanfard"],"url":"https://arxiv.org/abs/2310.07800"}
{"created":"2025-04-22","title":"GLoRE: Evaluating Logical Reasoning of Large Language Models","abstract":"Large language models (LLMs) have shown significant general language understanding abilities. However, there has been a scarcity of attempts to assess the logical reasoning capacities of these LLMs, an essential facet of natural language understanding. To encourage further investigation in this area, we introduce GLoRE, a General Logical Reasoning Evaluation platform that not only consolidates diverse datasets but also standardizes them into a unified format suitable for evaluating large language models across zero-shot and few-shot scenarios. Our experimental results show that compared to the performance of humans and supervised fine-tuning models, the logical reasoning capabilities of large reasoning models, such as OpenAI's o1 mini, DeepSeek R1 and QwQ-32B, have seen remarkable improvements, with QwQ-32B achieving the highest benchmark performance to date. GLoRE is designed as a living project that continuously integrates new datasets and models, facilitating robust and comparative assessments of model performance in both commercial and Huggingface communities.","authors":["Hanmeng liu","Zhiyang Teng","Ruoxi Ning","Yiran Ding","Xiulai Li","Xiaozhang Liu","Yue Zhang"],"url":"https://arxiv.org/abs/2310.09107"}
{"created":"2025-04-22","title":"Representing Sugihara monoids via weakening relations","abstract":"We show that all Sugihara monoids can be represented as algebras of binary relations, with the monoid operation given by relational composition. Moreover, the binary relations are weakening relations. The first step is to obtain an explicit relational representation of all finite odd Sugihara chains. Our construction mimics that of Maddux (2010), where a relational representation of the finite even Sugihara chains is given. We define the class of representable Sugihara monoids as those which can be represented as reducts of distributive involutive FL-algebras of binary relations. We then show that the class of representable distributive involutive FL-algebras is closed under ultraproducts. This fact is used to demonstrate that the two infinite Sugihara monoids that generate the quasivariety are also representable. From this it follows that all Sugihara monoids are representable.","authors":["Andrew Craig","Claudette Robinson"],"url":"https://arxiv.org/abs/2310.12935"}
{"created":"2025-04-22","title":"Last Truck Scheduling for Middle-mile Next-day Delivery Coverage","abstract":"We consider an e-commerce retailer operating a supply chain that consists of middle- and last-mile transportation, and study its ability to deliver products stored in warehouses within a day from customer's order time. Successful next-day delivery requires inventory availability and timely truck schedules in the middle-mile and in this paper we assume a fixed inventory position and focus on optimizing the middle-mile last truck schedule. We formulate a novel optimization problem which decides the departure of the last truck at each (potential) network connection in order to maximize the number of customer orders that are served with next-day promise. We show that the respective next-day delivery optimization is a combinatorial problem that is NP-hard to approximate within $(1-1/e)opt\\approx 0.632opt$, hence every retailer that offers one-day deliveries has to deal with this complexity barrier. We study three variants of the problem motivated by operational constraints that different retailers encounter, and propose solutions schemes tailored to each problem's properties. To that end, we rely on greedy submodular maximization, pipage rounding techniques, and Lagrangian heuristics. The algorithms are scalable, offer worst-case optimality gap guarantees, and evaluated in realistic datasets and network scenarios were found to achieve even near-optimal results.","authors":["Konstantinos Benidis","Georgios Paschos","Martin Gross","George Iosifidis"],"url":"https://arxiv.org/abs/2310.18388"}
{"created":"2025-04-22","title":"Recognize Any Regions","abstract":"Understanding the semantics of individual regions or patches of unconstrained images, such as open-world object detection, remains a critical yet challenging task in computer vision. Building on the success of powerful image-level vision-language (ViL) foundation models like CLIP, recent efforts have sought to harness their capabilities by either training a contrastive model from scratch with an extensive collection of region-label pairs or aligning the outputs of a detection model with image-level representations of region proposals. Despite notable progress, these approaches are plagued by computationally intensive training requirements, susceptibility to data noise, and deficiency in contextual information. To address these limitations, we explore the synergistic potential of off-the-shelf foundation models, leveraging their respective strengths in localization and semantics. We introduce a novel, generic, and efficient architecture, named RegionSpot, designed to integrate position-aware localization knowledge from a localization foundation model (e.g., SAM) with semantic information from a ViL model (e.g., CLIP). To fully exploit pretrained knowledge while minimizing training overhead, we keep both foundation models frozen, focusing optimization efforts solely on a lightweight attention-based knowledge integration module. Extensive experiments in open-world object recognition show that our RegionSpot achieves significant performance gain over prior alternatives, along with substantial computational savings (e.g., training our model with 3 million data in a single day using 8 V100 GPUs). RegionSpot outperforms GLIP-L by 2.9 in mAP on LVIS val set, with an even larger margin of 13.1 AP for more challenging and rare categories, and a 2.5 AP increase on ODinW. Furthermore, it exceeds GroundingDINO-L by 11.0 AP for rare categories on the LVIS minival set.","authors":["Haosen Yang","Chuofan Ma","Bin Wen","Yi Jiang","Zehuan Yuan","Xiatian Zhu"],"url":"https://arxiv.org/abs/2311.01373"}
{"created":"2025-04-22","title":"An Information-theoretic Security Analysis of Honeyword","abstract":"Honeyword is a representative \"honey\" technique that employs decoy objects to mislead adversaries and protect the real ones. To assess the security of a Honeyword system, two metrics--flatness and success-number--have been proposed and evaluated using various simulated attackers. Existing evaluations typically apply statistical learning methods to distinguish real passwords from decoys on real-world datasets. However, such evaluations may overestimate the system's security, as more effective distinguishing attacks could potentially exist.","authors":["Pengcheng Su","Haibo Cheng","Wenting Li","Ping Wang"],"url":"https://arxiv.org/abs/2311.10960"}
{"created":"2025-04-22","title":"Inspecting Explainability of Transformer Models with Additional Statistical Information","abstract":"Transformer becomes more popular in the vision domain in recent years so there is a need for finding an effective way to interpret the Transformer model by visualizing it. In recent work, Chefer et al. can visualize the Transformer on vision and multi-modal tasks effectively by combining attention layers to show the importance of each image patch. However, when applying to other variants of Transformer such as the Swin Transformer, this method can not focus on the predicted object. Our method, by considering the statistics of tokens in layer normalization layers, shows a great ability to interpret the explainability of Swin Transformer and ViT.","authors":["Hoang C. Nguyen","Haeil Lee","Junmo Kim"],"url":"https://arxiv.org/abs/2311.11378"}
{"created":"2025-04-22","title":"Potential Societal Biases of ChatGPT in Higher Education: A Scoping Review","abstract":"Purpose:Generative Artificial Intelligence (GAI) models, such as ChatGPT, may inherit or amplify societal biases due to their training on extensive datasets. With the increasing usage of GAI by students, faculty, and staff in higher education institutions (HEIs), it is urgent to examine the ethical issues and potential biases associated with these technologies. Design/Approach/Methods:This scoping review aims to elucidate how biases related to GAI in HEIs have been researched and discussed in recent academic publications. We categorized the potential societal biases that GAI might cause in the field of higher education. Our review includes articles written in English, Chinese, and Japanese across four main databases, focusing on GAI usage in higher education and bias. Findings:Our findings reveal that while there is meaningful scholarly discussion around bias and discrimination concerning LLMs in the AI field, most articles addressing higher education approach the issue superficially. Few articles identify specific types of bias under different circumstances, and there is a notable lack of empirical research. Most papers in our review focus primarily on educational and research fields related to medicine and engineering, with some addressing English education. However, there is almost no discussion regarding the humanities and social sciences. Additionally, a significant portion of the current discourse is in English and primarily addresses English-speaking contexts. Originality/Value:To the best of our knowledge, our study is the first to summarize the potential societal biases in higher education. This review highlights the need for more in-depth studies and empirical work to understand the specific biases that GAI might introduce or amplify in educational settings, guiding the development of more ethical AI applications in higher education.","authors":["Ming Li","Ariunaa Enkhtur","Beverley Anne Yamamoto","Fei Cheng","Lilan Chen"],"url":"https://arxiv.org/abs/2311.14381"}
{"created":"2025-04-22","title":"Recursive lattice reduction -- A framework for finding short lattice vectors","abstract":"We propose a recursive lattice reduction framework for finding short non-zero vectors or dense sublattices of a lattice. The framework works by recursively searching for dense sublattices of dense sublattices (or their duals) with progressively lower rank. When the procedure encounters a recursive call on a lattice $L$ with relatively low rank, we simply use a known algorithm to find a shortest non-zero vector in $L$.","authors":["Divesh Aggarwal","Thomas Espitau","Spencer Peters","Noah Stephens-Davidowitz"],"url":"https://arxiv.org/abs/2311.15064"}
{"created":"2025-04-22","title":"LongStory: Coherent, Complete and Length Controlled Long story Generation","abstract":"A human author can write any length of story without losing coherence. Also, they always bring the story to a proper ending, an ability that current language models lack. In this work, we present the LongStory for coherent, complete, and length-controlled long story generation. LongStory introduces two novel methodologies: (1) the long and short-term contexts weight calibrator (CWC) and (2) long story structural positions (LSP). The CWC adjusts weights for long-term context Memory and short-term context Cheating, acknowledging their distinct roles. The LSP employs discourse tokens to convey the structural positions of a long story. Trained on three datasets with varied average story lengths, LongStory outperforms other baselines, including the strong story generator Plotmachine, in coherence, completeness, relevance, and repetitiveness. We also perform zero-shot tests on each dataset to assess the model's ability to predict outcomes beyond its training data and validate our methodology by comparing its performance with variants of our model.","authors":["Kyeongman Park","Nakyeong Yang","Kyomin Jung"],"url":"https://arxiv.org/abs/2311.15208"}
{"created":"2025-04-22","title":"LiteQSign: Lightweight and Quantum-Safe Signatures for Heterogeneous IoT Applications","abstract":"The rapid proliferation of resource-constrained IoT devices across sectors like healthcare, industrial automation, and finance introduces major security challenges. Traditional digital signatures, though foundational for authentication, are often infeasible for low-end devices with limited computational, memory, and energy resources. Also, the rise of quantum computing necessitates post-quantum (PQ) secure alternatives. However, NIST-standardized PQ signatures impose substantial overhead, limiting their practicality in energy-sensitive applications such as wearables, where signer-side efficiency is critical. To address these challenges, we present LightQSign (LightQS), a novel lightweight PQ signature that achieves near-optimal signature generation efficiency with only a small, constant number of hash operations per signing. Its core innovation enables verifiers to obtain one-time hash-based public keys without interacting with signers or third parties through secure computation. We formally prove the security of LightQSign in the random oracle model and evaluate its performance on commodity hardware and a resource-constrained 8-bit AtMega128A1 microcontroller. Experimental results show that LightQSign outperforms NIST PQC standards with lower computational overhead, minimal memory usage, and compact signatures. On an 8-bit microcontroller, it achieves up to 1.5-24x higher energy efficiency and 1.7-22x shorter signatures than PQ counterparts, and 56-76x better energy efficiency than conventional standards-enabling longer device lifespans and scalable, quantum-resilient authentication.","authors":["Attila A. Yavuz","Saleh Darzi","Saif E. Nouma"],"url":"https://arxiv.org/abs/2311.18674"}
{"created":"2025-04-22","title":"Exploring Radar Data Representations in Autonomous Driving: A Comprehensive Review","abstract":"With the rapid advancements of sensor technology and deep learning, autonomous driving systems are providing safe and efficient access to intelligent vehicles as well as intelligent transportation. Among these equipped sensors, the radar sensor plays a crucial role in providing robust perception information in diverse environmental conditions. This review focuses on exploring different radar data representations utilized in autonomous driving systems. Firstly, we introduce the capabilities and limitations of the radar sensor by examining the working principles of radar perception and signal processing of radar measurements. Then, we delve into the generation process of five radar representations, including the ADC signal, radar tensor, point cloud, grid map, and micro-Doppler signature. For each radar representation, we examine the related datasets, methods, advantages and limitations. Furthermore, we discuss the challenges faced in these data representations and propose potential research directions. Above all, this comprehensive review offers an in-depth insight into how these representations enhance autonomous system capabilities, providing guidance for radar perception researchers. To facilitate retrieval and comparison of different data representations, datasets and methods, we provide an interactive website at https://radar-camera-fusion.github.io/radar.","authors":["Shanliang Yao","Runwei Guan","Zitian Peng","Chenhang Xu","Yilu Shi","Weiping Ding","Eng Gee Lim","Yong Yue","Hyungjoon Seo","Ka Lok Man","Jieming Ma","Xiaohui Zhu","Yutao Yue"],"url":"https://arxiv.org/abs/2312.04861"}
{"created":"2025-04-22","title":"Agile-Quant: Activation-Guided Quantization for Faster Inference of LLMs on the Edge","abstract":"Large Language Models (LLMs) stand out for their impressive performance in intricate language modeling tasks. However, their demanding computational and memory needs pose obstacles for broad use on edge devices. Quantization is then introduced to boost LLMs' on-device efficiency. Recent works show that 8-bit or lower weight quantization is feasible with minimal impact on end-to-end task performance, while the activation is still not quantized. On the other hand, mainstream commodity edge devices still struggle to execute these sub-8-bit quantized networks effectively. In this paper, we propose Agile-Quant, an activation-guided quantization framework for popular Large Language Models (LLMs), and implement an end-to-end accelerator on multiple edge devices for faster inference. Considering the hardware profiling and activation analysis, we first introduce a basic activation quantization strategy to balance the trade-off of task performance and real inference speed. Then we leverage the activation-aware token pruning technique to reduce the outliers and the adverse impact on attentivity. Ultimately, we utilize the SIMD-based 4-bit multiplier and our efficient TRIP matrix multiplication to implement the accelerator for LLMs on the edge. We apply our framework on different scales of LLMs including LLaMA, OPT, and BLOOM with 4-bit or 8-bit for the activation and 4-bit for the weight quantization. Experiments show that Agile-Quant achieves simultaneous quantization of model weights and activations while maintaining task performance comparable to existing weight-only quantization methods. Moreover, in the 8- and 4-bit scenario, Agile-Quant achieves an on-device speedup of up to 2.55x compared to its FP16 counterparts across multiple edge devices, marking a pioneering advancement in this domain. Code: https://github.com/shawnricecake/agile-quant","authors":["Xuan Shen","Peiyan Dong","Lei Lu","Zhenglun Kong","Zhengang Li","Ming Lin","Chao Wu","Yanzhi Wang"],"url":"https://arxiv.org/abs/2312.05693"}
{"created":"2025-04-22","title":"DreamDistribution: Learning Prompt Distribution for Diverse In-distribution Generation","abstract":"The popularization of Text-to-Image (T2I) diffusion models enables the generation of high-quality images from text descriptions. However, generating diverse customized images with reference visual attributes remains challenging. This work focuses on personalizing T2I diffusion models at a more abstract concept or category level, adapting commonalities from a set of reference images while creating new instances with sufficient variations. We introduce a solution that allows a pretrained T2I diffusion model to learn a set of soft prompts, enabling the generation of novel images by sampling prompts from the learned distribution. These prompts offer text-guided editing capabilities and additional flexibility in controlling variation and mixing between multiple distributions. We also show the adaptability of the learned prompt distribution to other tasks, such as text-to-3D. Finally we demonstrate effectiveness of our approach through quantitative analysis including automatic evaluation and human assessment. Project website: https://briannlongzhao.github.io/DreamDistribution","authors":["Brian Nlong Zhao","Yuhang Xiao","Jiashu Xu","Xinyang Jiang","Yifan Yang","Dongsheng Li","Laurent Itti","Vibhav Vineet","Yunhao Ge"],"url":"https://arxiv.org/abs/2312.14216"}
{"created":"2025-04-22","title":"Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review","abstract":"This paper explores the frontiers of large language models (LLMs) in psychology applications. Psychology has undergone several theoretical changes, and the current use of Artificial Intelligence (AI) and Machine Learning, particularly LLMs, promises to open up new research directions. We provide a detailed exploration of how LLMs like ChatGPT are transforming psychological research. It discusses the impact of LLMs across various branches of psychology, including cognitive and behavioral, clinical and counseling, educational and developmental, and social and cultural psychology, highlighting their potential to simulate aspects of human cognition and behavior. The paper delves into the capabilities of these models to emulate human-like text generation, offering innovative tools for literature review, hypothesis generation, experimental design, experimental subjects, data analysis, academic writing, and peer review in psychology. While LLMs are essential in advancing research methodologies in psychology, the paper also cautions about their technical and ethical challenges. There are issues like data privacy, the ethical implications of using LLMs in psychological research, and the need for a deeper understanding of these models' limitations. Researchers should responsibly use LLMs in psychological studies, adhering to ethical standards and considering the potential consequences of deploying these technologies in sensitive areas. Overall, the article provides a comprehensive overview of the current state of LLMs in psychology, exploring potential benefits and challenges. It serves as a call to action for researchers to leverage LLMs' advantages responsibly while addressing associated risks.","authors":["Luoma Ke (Department of Psychological and Cognitive Sciences","Tsinghua University)","Song Tong (Department of Psychological and Cognitive Sciences","Tsinghua University)","Peng Cheng (School of Social Science","Tsinghua University)","Kaiping Peng (Department of Psychological and Cognitive Sciences","Tsinghua University)"],"url":"https://arxiv.org/abs/2401.01519"}
{"created":"2025-04-22","title":"Extended Stone Duality via Monoidal Adjunctions","abstract":"Extensions of Stone-type dualities have a long history in algebraic logic and have also been instrumental in proving results in algebraic language theory. We show how to extend abstract categorical dualities via monoidal adjunctions, subsuming various incarnations of classical extended Stone and Priestley duality as special cases, and providing the foundation for two new concrete dualities: First, we investigate residuation algebras, which are lattices with additional residual operators modeling language derivatives algebraically. We show that the subcategory of derivation algebras is dually equivalent to the category of profinite ordered monoids, restricting to a duality between Boolean residuation algebras and profinite monoids. We further refine this duality to capture relational morphisms of profinite ordered monoids, which dualize to natural morphisms of residuation algebras. Second, we apply the categorical extended duality to the discrete setting of sets and complete atomic Boolean algebras to obtain a concrete description for the dual of the category of all small categories.","authors":["Fabian Lenke","Henning Urbat","Stefan Milius"],"url":"https://arxiv.org/abs/2401.08219"}
{"created":"2025-04-22","title":"DirDist: A Metric for Comparing 3D Shapes Using Directional Distance Fields","abstract":"Qualifying the discrepancy between 3D geometric models, which could be represented with either point clouds or triangle meshes, is a pivotal issue with board applications. Existing methods mainly focus on directly establishing the correspondence between two models and then aggregating point-wise distance between corresponding points, resulting in them being either inefficient or ineffective. In this paper, we propose DirDist, an efficient, effective, robust, and differentiable distance metric for 3D geometry data. Specifically, we construct DirDist based on the proposed implicit representation of 3D models, namely directional distance field (DDF), which defines the directional distances of 3D points to a model to capture its local surface geometry. We then transfer the discrepancy between two 3D geometric models as the discrepancy between their DDFs defined on an identical domain, naturally establishing model correspondence. To demonstrate the advantage of our DirDist, we explore various distance metric-driven 3D geometric modeling tasks, including template surface fitting, rigid registration, non-rigid registration, scene flow estimation and human pose optimization. Extensive experiments show that our DirDist achieves significantly higher accuracy under all tasks. As a generic distance metric, DirDist has the potential to advance the field of 3D geometric modeling. The source code is available at https://github.com/rsy6318/DirDist.","authors":["Siyu Ren","Junhui Hou","Xiaodong Chen","Hongkai Xiong","Wenping Wang"],"url":"https://arxiv.org/abs/2401.09736"}
{"created":"2025-04-22","title":"Foundation Models in Federated Learning: Assessing Backdoor Vulnerabilities","abstract":"Federated Learning (FL), a privacy-preserving machine learning framework, faces significant data-related challenges. For example, the lack of suitable public datasets leads to ineffective information exchange, especially in heterogeneous environments with uneven data distribution. Foundation Models (FMs) offer a promising solution by generating synthetic datasets that mimic client data distributions, aiding model initialization and knowledge sharing among clients. However, the interaction between FMs and FL introduces new attack vectors that remain largely unexplored. This work therefore assesses the backdoor vulnerabilities exploiting FMs, where attackers exploit safety issues in FMs and poison synthetic datasets to compromise the entire system. Unlike traditional attacks, these new threats are characterized by their one-time, external nature, requiring minimal involvement in FL training. Given these uniqueness, current FL defense strategies provide limited robustness against this novel attack approach. Extensive experiments across image and text domains reveal the high susceptibility of FL to these novel threats, emphasizing the urgent need for enhanced security measures in FL in the era of FMs.","authors":["Xi Li","Chen Wu","Jiaqi Wang"],"url":"https://arxiv.org/abs/2401.10375"}
{"created":"2025-04-22","title":"Precision Robotic Spot-Spraying: Reducing Herbicide Use and Enhancing Environmental Outcomes in Sugarcane","abstract":"Precise robotic weed control plays an essential role in precision agriculture. It can help significantly reduce the environmental impact of herbicides while reducing weed management costs for farmers. In this paper, we demonstrate that a custom-designed robotic spot spraying tool based on computer vision and deep learning can significantly reduce herbicide usage on sugarcane farms. We present results from field trials that compare robotic spot spraying against industry-standard broadcast spraying, by measuring the weed control efficacy, the reduction in herbicide usage, and the water quality improvements in irrigation runoff. The average results across 25 hectares of field trials show that spot spraying on sugarcane farms is 97\\% as effective as broadcast spraying and reduces herbicide usage by 35\\%, proportionally to the weed density. For specific trial strips with lower weed pressure, spot spraying reduced herbicide usage by up to 65\\%. Water quality measurements of irrigation-induced runoff, three to six days after spraying, showed reductions in the mean concentration and mean load of herbicides of 39\\% and 54\\%, respectively, compared to broadcast spraying. These promising results reveal the capability of spot spraying technology to reduce herbicide usage on sugarcane farms without impacting weed control and potentially providing sustained water quality benefits.","authors":["Mostafa Rahimi Azghadi","Alex Olsen","Jake Wood","Alzayat Saleh","Brendan Calvert","Terry Granshaw","Emilie Fillols","Bronson Philippa"],"url":"https://arxiv.org/abs/2401.13931"}
{"created":"2025-04-22","title":"Embedding Ontologies via Incorporating Extensional and Intensional Knowledge","abstract":"Ontologies contain rich knowledge within domain, which can be divided into two categories, namely extensional knowledge and intensional knowledge. Extensional knowledge provides information about the concrete instances that belong to specific concepts in the ontology, while intensional knowledge details inherent properties, characteristics, and semantic associations among concepts. However, existing ontology embedding approaches fail to take both extensional knowledge and intensional knowledge into fine consideration simultaneously. In this paper, we propose a novel ontology embedding approach named EIKE (Extensional and Intensional Knowledge Embedding) by representing ontologies in two spaces, called extensional space and intensional space. EIKE presents a unified framework for embedding instances, concepts and their relations in an ontology, applying a geometry-based method to model extensional knowledge and a pretrained language model to model intensional knowledge, which can capture both structure information and textual information. Experimental results show that EIKE significantly outperforms state-of-the-art methods in three datasets for both triple classification and link prediction, indicating that EIKE provides a more comprehensive and representative perspective of the domain.","authors":["Keyu Wang","Guilin Qi","Jiaoyan Chen","Yi Huang","Tianxing Wu"],"url":"https://arxiv.org/abs/2402.01677"}
{"created":"2025-04-22","title":"SHIELD : An Evaluation Benchmark for Face Spoofing and Forgery Detection with Multimodal Large Language Models","abstract":"Multimodal large language models (MLLMs) have demonstrated strong capabilities in vision-related tasks, capitalizing on their visual semantic comprehension and reasoning capabilities. However, their ability to detect subtle visual spoofing and forgery clues in face attack detection tasks remains underexplored. In this paper, we introduce a benchmark, SHIELD, to evaluate MLLMs for face spoofing and forgery detection. Specifically, we design true/false and multiple-choice questions to assess MLLM performance on multimodal face data across two tasks. For the face anti-spoofing task, we evaluate three modalities (i.e., RGB, infrared, and depth) under six attack types. For the face forgery detection task, we evaluate GAN-based and diffusion-based data, incorporating visual and acoustic modalities. We conduct zero-shot and few-shot evaluations in standard and chain of thought (COT) settings. Additionally, we propose a novel multi-attribute chain of thought (MA-COT) paradigm for describing and judging various task-specific and task-irrelevant attributes of face images. The findings of this study demonstrate that MLLMs exhibit strong potential for addressing the challenges associated with the security of facial recognition technology applications.","authors":["Yichen Shi","Yuhao Gao","Yingxin Lai","Hongyang Wang","Jun Feng","Lei He","Jun Wan","Changsheng Chen","Zitong Yu","Xiaochun Cao"],"url":"https://arxiv.org/abs/2402.04178"}
{"created":"2025-04-22","title":"Symmetry-Breaking Augmentations for Ad Hoc Teamwork","abstract":"In dynamic collaborative settings, for artificial intelligence (AI) agents to better align with humans, they must adapt to novel teammates who utilise unforeseen strategies. While adaptation is often simple for humans, it can be challenging for AI agents. Our work introduces symmetry-breaking augmentations (SBA) as a novel approach to this challenge. By applying a symmetry-flipping operation to increase behavioural diversity among training teammates, SBA encourages agents to learn robust responses to unknown strategies, highlighting how social conventions impact human-AI alignment. We demonstrate this experimentally in two settings, showing that our approach outperforms previous ad hoc teamwork results in the challenging card game Hanabi. In addition, we propose a general metric for estimating symmetry dependency amongst a given set of policies. Our findings provide insights into how AI systems can better adapt to diverse human conventions and the core mechanics of alignment.","authors":["Ravi Hammond","Dustin Craggs","Mingyu Guo","Jakob Foerster","Ian Reid"],"url":"https://arxiv.org/abs/2402.09984"}
{"created":"2025-04-22","title":"Trading off Consistency and Dimensionality of Convex Surrogates for the Mode","abstract":"In multiclass classification over $n$ outcomes, the outcomes must be embedded into the reals with dimension at least $n-1$ in order to design a consistent surrogate loss that leads to the \"correct\" classification, regardless of the data distribution. For large $n$, such as in information retrieval and structured prediction tasks, optimizing a surrogate in $n-1$ dimensions is often intractable. We investigate ways to trade off surrogate loss dimension, the number of problem instances, and restricting the region of consistency in the simplex for multiclass classification. Following past work, we examine an intuitive embedding procedure that maps outcomes into the vertices of convex polytopes in a low-dimensional surrogate space. We show that full-dimensional subsets of the simplex exist around each point mass distribution for which consistency holds, but also, with less than $n-1$ dimensions, there exist distributions for which a phenomenon called hallucination occurs, which is when the optimal report under the surrogate loss is an outcome with zero probability. Looking towards application, we derive a result to check if consistency holds under a given polytope embedding and low-noise assumption, providing insight into when to use a particular embedding. We provide examples of embedding $n = 2^{d}$ outcomes into the $d$-dimensional unit cube and $n = d!$ outcomes into the $d$-dimensional permutahedron under low-noise assumptions. Finally, we demonstrate that with multiple problem instances, we can learn the mode with $\\frac{n}{2}$ dimensions over the whole simplex.","authors":["Enrique Nueve","Bo Waggoner","Dhamma Kimpara","Jessie Finocchiaro"],"url":"https://arxiv.org/abs/2402.10818"}
{"created":"2025-04-22","title":"PISA: An Adversarial Approach To Comparing Task Graph Scheduling Algorithms","abstract":"Scheduling a task graph representing an application over a heterogeneous network of computers is a fundamental problem in distributed computing. It is known to be not only NP-hard but also not polynomial-time approximable within a constant factor. As a result, many heuristic algorithms have been proposed over the past few decades. Yet it remains largely unclear how these algorithms compare to each other in terms of the quality of schedules they produce. We identify gaps in the traditional benchmarking approach to comparing task scheduling algorithms and propose a simulated annealing-based adversarial analysis approach called PISA to help address them. We also introduce SAGA, a new open-source library for comparing task scheduling algorithms. We use SAGA to benchmark 15 algorithms on 16 datasets and PISA to compare the algorithms in a pairwise manner. Algorithms that appear to perform similarly on benchmarking datasets are shown to perform very differently on adversarially chosen problem instances. Interestingly, the results indicate that this is true even when the adversarial search is constrained to selecting among well-structured, application-specific problem instances. This work represents an important step towards a more general understanding of the performance boundaries between task scheduling algorithms on different families of problem instances.","authors":["Jared Coleman","Bhaskar Krishnamachari"],"url":"https://arxiv.org/abs/2403.07120"}
{"created":"2025-04-22","title":"On Tractable $\\Phi$-Equilibria in Non-Concave Games","abstract":"While Online Gradient Descent and other no-regret learning procedures are known to efficiently converge to a coarse correlated equilibrium in games where each agent's utility is concave in their own strategy, this is not the case when utilities are non-concave -- a common scenario in machine learning applications involving strategies parameterized by deep neural networks, or when agents' utilities are computed by neural networks, or both. Non-concave games introduce significant game-theoretic and optimization challenges: (i) Nash equilibria may not exist; (ii) local Nash equilibria, though they exist, are intractable; and (iii) mixed Nash, correlated, and coarse correlated equilibria generally have infinite support and are intractable. To sidestep these challenges, we revisit the classical solution concept of $\\Phi$-equilibria introduced by Greenwald and Jafari [2003], which is guaranteed to exist for an arbitrary set of strategy modifications $\\Phi$ even in non-concave games [Stolz and Lugosi, 2007]. However, the tractability of $\\Phi$-equilibria in such games remains elusive.","authors":["Yang Cai","Constantinos Daskalakis","Haipeng Luo","Chen-Yu Wei","Weiqiang Zheng"],"url":"https://arxiv.org/abs/2403.08171"}
{"created":"2025-04-22","title":"Interpolatory model reduction of dynamical systems with root mean squared error","abstract":"The root mean squared error is an important measure used in a variety of applications such as structural dynamics and acoustics to model averaged deviations from standard behavior. For large-scale systems, simulations of this quantity quickly become computationally prohibitive. Classical model order reduction techniques attempt to resolve this issue via the construction of surrogate models that emulate the root mean squared error measure using an intermediate linear system. However, this approach requires a potentially large number of linear outputs, which can be disadvantageous in the design of reduced-order models. In this work, we consider directly the root mean squared error as the quantity of interest using the concept of quadratic-output models and propose several new model reduction techniques for the construction of appropriate surrogates. We test the proposed methods on a model for the vibrational response of a plate with tuned vibration absorbers.","authors":["Sean Reiter","Steffen W. R. Werner"],"url":"https://arxiv.org/abs/2403.08894"}
{"created":"2025-04-22","title":"Contract Design for Sequential Actions","abstract":"We introduce a novel model of contracts with combinatorial actions that accounts for sequential and adaptive agent behavior. As in the standard model, a principal delegates the execution of a costly project to an agent. There are $n$ actions, each one incurring a cost to the agent and inducing a probability distribution over $m$ outcomes; each outcome generates some reward for the principal. The principal incentivizes the agent through a contract that specifies a payment for each potential outcome. Unlike the standard model, the agent chooses actions sequentially. Following each action, the agent observes the realized outcome, and decides whether to stop or continue with another action. Upon halting, the agent chooses one of the realized outcomes, which determines both his payment and the principal's reward. This model captures common scenarios where the agent can make multiple attempts in the course of executing a project.","authors":["Tomer Ezra","Michal Feldman","Maya Schlesinger"],"url":"https://arxiv.org/abs/2403.09545"}
{"created":"2025-04-22","title":"Is Translation All You Need? A Study on Solving Multilingual Tasks with Large Language Models","abstract":"Large language models (LLMs) have demonstrated multilingual capabilities, yet they are mostly English-centric due to the imbalanced training corpora. While prior works have leveraged this bias to enhance multilingual performance through translation, they have been largely limited to natural language processing (NLP) tasks. In this work, we extend the evaluation to real-world user queries and non-English-centric LLMs, offering a broader examination of multilingual performance. Our key contribution lies in demonstrating that while translation into English can boost the performance of English-centric LLMs on NLP tasks, it is not universally optimal. For culture-related tasks that need deep language understanding, prompting in the native language proves more effective as it better captures the nuances of culture and language. Our experiments expose varied behaviors across LLMs and tasks in the multilingual context, underscoring the need for a more comprehensive approach to multilingual evaluation. Therefore, we call for greater efforts in developing and evaluating LLMs that go beyond English-centric paradigms.","authors":["Chaoqun Liu","Wenxuan Zhang","Yiran Zhao","Anh Tuan Luu","Lidong Bing"],"url":"https://arxiv.org/abs/2403.10258"}
{"created":"2025-04-22","title":"Federated Transfer Learning with Differential Privacy","abstract":"Federated learning has emerged as a powerful framework for analysing distributed data, yet two challenges remain pivotal: heterogeneity across sites and privacy of local data. In this paper, we address both challenges within a federated transfer learning framework, aiming to enhance learning on a target data set by leveraging information from multiple heterogeneous source data sets while adhering to privacy constraints. We rigorously formulate the notion of federated differential privacy, which offers privacy guarantees for each data set without assuming a trusted central server. Under this privacy model, we study three classical statistical problems: univariate mean estimation, low-dimensional linear regression, and high-dimensional linear regression. By investigating the minimax rates and quantifying the cost of privacy in each problem, we show that federated differential privacy is an intermediate privacy model between the well-established local and central models of differential privacy. Our analyses account for data heterogeneity and privacy, highlighting the fundamental costs associated with each factor and the benefits of knowledge transfer in federated learning.","authors":["Mengchu Li","Ye Tian","Yang Feng","Yi Yu"],"url":"https://arxiv.org/abs/2403.11343"}
{"created":"2025-04-22","title":"Relational Representation Learning Network for Cross-Spectral Image Patch Matching","abstract":"Recently, feature relation learning has drawn widespread attention in cross-spectral image patch matching. However, existing related research focuses on extracting diverse relations between image patch features and ignores sufficient intrinsic feature representations of individual image patches. Therefore, we propose an innovative relational representation learning idea that simultaneously focuses on sufficiently mining the intrinsic features of individual image patches and the relations between image patch features. Based on this, we construct a Relational Representation Learning Network (RRL-Net). Specifically, we innovatively construct an autoencoder to fully characterize the individual intrinsic features, and introduce a feature interaction learning (FIL) module to extract deep-level feature relations. To further fully mine individual intrinsic features, a lightweight multi-dimensional global-to-local attention (MGLA) module is constructed to enhance the global feature extraction of individual image patches and capture local dependencies within global features. By combining the MGLA module, we further explore the feature extraction network and construct an attention-based lightweight feature extraction (ALFE) network. In addition, we propose a multi-loss post-pruning (MLPP) optimization strategy, which greatly promotes network optimization while avoiding increases in parameters and inference time. Extensive experiments demonstrate that our RRL-Net achieves state-of-the-art (SOTA) performance on multiple public datasets. Our code are available at https://github.com/YuChuang1205/RRL-Net.","authors":["Chuang Yu","Yunpeng Liu","Jinmiao Zhao","Dou Quan","Zelin Shi","Xiangyu Yue"],"url":"https://arxiv.org/abs/2403.11751"}
{"created":"2025-04-22","title":"Safety Implications of Explainable Artificial Intelligence in End-to-End Autonomous Driving","abstract":"The end-to-end learning pipeline is gradually creating a paradigm shift in the ongoing development of highly autonomous vehicles (AVs), largely due to advances in deep learning, the availability of large-scale training datasets, and improvements in integrated sensor devices. However, a lack of explainability in real-time decisions with contemporary learning methods impedes user trust and attenuates the widespread deployment and commercialization of such vehicles. Moreover, the issue is exacerbated when these cars are involved in or cause traffic accidents. Consequently, explainability in end-to-end autonomous driving is essential to build trust in vehicular automation. With that said, automotive researchers have not yet rigorously explored safety benefits and consequences of explanations in end-to-end autonomous driving. This paper aims to bridge the gaps between these topics and seeks to answer the following research question: What are safety implications of explanations in end-to-end autonomous driving? In this regard, we first revisit established safety and explainability concepts in end-to-end driving. Furthermore, we present critical case studies and show the pivotal role of explanations in enhancing driving safety. Finally, we describe insights from empirical studies and reveal potential value, limitations, and caveats of practical explainable AI methods with respect to their potential impacts on safety of end-to-end driving.","authors":["Shahin Atakishiyev","Mohammad Salameh","Randy Goebel"],"url":"https://arxiv.org/abs/2403.12176"}
{"created":"2025-04-22","title":"HyperFusion: A Hypernetwork Approach to Multimodal Integration of Tabular and Medical Imaging Data for Predictive Modeling","abstract":"The integration of diverse clinical modalities such as medical imaging and the tabular data extracted from patients' Electronic Health Records (EHRs) is a crucial aspect of modern healthcare. Integrative analysis of multiple sources can provide a comprehensive understanding of the clinical condition of a patient, improving diagnosis and treatment decision. Deep Neural Networks (DNNs) consistently demonstrate outstanding performance in a wide range of multimodal tasks in the medical domain. However, the complex endeavor of effectively merging medical imaging with clinical, demographic and genetic information represented as numerical tabular data remains a highly active and ongoing research pursuit.","authors":["Daniel Duenias","Brennan Nichyporuk","Tal Arbel","Tammy Riklin Raviv"],"url":"https://arxiv.org/abs/2403.13319"}
{"created":"2025-04-22","title":"Realizing temporal transportation trees","abstract":"In this paper, we study the complexity of the periodic temporal graph realization problem with respect to upper bounds on the fastest path durations among its vertices. This constraint with respect to upper bounds appears naturally in transportation network design applications where, for example, a road network is given, and the goal is to appropriately schedule periodic travel routes, while not exceeding some desired upper bounds on the travel times. In our work, we focus only on underlying tree topologies, which are fundamental in many transportation network applications.","authors":["George B. Mertzios","Hendrik Molter","Nils Morawietz","Paul G. Spirakis"],"url":"https://arxiv.org/abs/2403.18513"}
{"created":"2025-04-22","title":"Prophet Inequalities with Cancellation Costs","abstract":"Most of the literature on online algorithms in revenue management focuses on settings with irrevocable decisions, where once a decision is made upon the arrival of a new input, it cannot be canceled later. Motivated by modern applications -- such as cloud spot markets, selling banner ads, or online hotel booking -- we introduce and study \"prophet inequalities with cancellations\" under linear cancellation costs (known as the buyback model). In the classic prophet inequality problem, a sequence of independent random variables $X_1, X_2, \\ldots$ with known distributions is revealed one by one, and a decision maker must decide when to stop and accept the current variable in order to maximize the expected value of their choice. In our model, after accepting $X_j$, one may later discard $X_j$ and accept another $X_i$ at a cost of $f \\times X_j$, where $f\\geq 0$ is a parameter. The goal is to maximize the expected net reward: the value of the final accepted variable minus the total cancellation cost. We aim to design online policies that are competitive against the optimal offline benchmark.","authors":["Farbod Ekbatani","Rad Niazadeh","Pranav Nuti","Jan Vondrak"],"url":"https://arxiv.org/abs/2404.00527"}
{"created":"2025-04-22","title":"O2V-Mapping: Online Open-Vocabulary Mapping with Neural Implicit Representation","abstract":"Online construction of open-ended language scenes is crucial for robotic applications, where open-vocabulary interactive scene understanding is required. Recently, neural implicit representation has provided a promising direction for online interactive mapping. However, implementing open-vocabulary scene understanding capability into online neural implicit mapping still faces three challenges: lack of local scene updating ability, blurry spatial hierarchical semantic segmentation and difficulty in maintaining multi-view consistency. To this end, we proposed O2V-mapping, which utilizes voxel-based language and geometric features to create an open-vocabulary field, thus allowing for local updates during online training process. Additionally, we leverage a foundational model for image segmentation to extract language features on object-level entities, achieving clear segmentation boundaries and hierarchical semantic features. For the purpose of preserving consistency in 3D object properties across different viewpoints, we propose a spatial adaptive voxel adjustment mechanism and a multi-view weight selection method. Extensive experiments on open-vocabulary object localization and semantic segmentation demonstrate that O2V-mapping achieves online construction of language scenes while enhancing accuracy, outperforming the previous SOTA method.","authors":["Muer Tie","Julong Wei","Zhengjun Wang","Ke Wu","Shansuai Yuan","Kaizhao Zhang","Jie Jia","Jieru Zhao","Zhongxue Gan","Wenchao Ding"],"url":"https://arxiv.org/abs/2404.06836"}
{"created":"2025-04-22","title":"Achieving Tight $O(4^k)$ Runtime Bounds on Jump$_k$ by Proving that Genetic Algorithms Evolve Near-Maximal Population Diversity","abstract":"The JUMP$_k$ benchmark was the first problem for which crossover was proven to give a speed-up over mutation-only evolutionary algorithms. Jansen and Wegener (2002) proved an upper bound of $O(\\text{poly}(n) + 4^k/p_c)$ for the ($\\mu$+1) Genetic Algorithm ($(\\mu+1)$ GA), but only for unrealistically small crossover probabilities $p_c$. To this date, it remains an open problem to prove similar upper bounds for realistic $p_c$; the best known runtime bound, in terms of function evaluations, for $p_c = \\Omega(1)$ is $O((n/\\chi)^{k-1})$, $\\chi$ a positive constant. We provide a novel approach and analyse the evolution of the population diversity, measured as sum of pairwise Hamming distances, for a variant of the $(\\mu+1)$ GA on JUMP$_k$. The $(\\mu+1)$-$\\lambda_c$-GA creates one offspring in each generation either by applying mutation to one parent or by applying crossover $\\lambda_c$ times to the same two parents (followed by mutation), to amplify the probability of creating an accepted offspring in generations with crossover. We show that population diversity in the $(\\mu+1)$-$\\lambda_c$-GA converges to an equilibrium of near-perfect diversity. This yields an improved time bound of $O(\\mu n \\log(\\mu) + 4^k)$ function evaluations for a range of $k$ under the mild assumptions $p_c = O(1/k)$ and $\\mu \\in \\Omega(kn)$. For all constant $k$, the restriction is satisfied for some $p_c = \\Omega(1)$ and it implies that the expected runtime for all constant $k$ and an appropriate $\\mu = \\Theta(kn)$ is bounded by $O(n^2 \\log n)$, irrespective of $k$. For larger $k$, the expected time of the $(\\mu+1)$-$\\lambda_c$-GA is $\\Theta(4^k)$, which is tight for a large class of unbiased black-box algorithms and faster than the original $(\\mu+1)$ GA by a factor of $\\Omega(1/p_c)$. We also show that our analysis can be extended to other unitation functions such as JUMP$_{k, \\delta}$ and HURDLE.","authors":["Andre Opris","Johannes Lengler","Dirk Sudholt"],"url":"https://arxiv.org/abs/2404.07061"}
{"created":"2025-04-22","title":"The complexity of convexity number and percolation time in the cycle convexity","abstract":"The subject of graph convexity is well explored in the literature, the so-called interval convexities above all. In this work, we explore the cycle convexity, an interval convexity whose interval function is $I(S) = S \\cup \\{u \\mid G[S \\cup \\{u\\}]$ has a cycle containing $u\\}$. In this convexity, we prove that determine whether the convexity number of a graph $G$ is at least $k$ is \\NP-complete and \\W[1]-hard when parameterized by the size of the solution when $G$ is a thick spider, but polynomial when $G$ is an extended $P_4$-laden graph. We also prove that determining whether the percolation time of a graph is at least $k$ is \\NP-complete even for fixed $k \\geq 9$, but polynomial for cacti or for fixed $k\\leq2$.","authors":["Carlos V. G. C. Lima","Thiago Marcilon","Pedro Paulo de Medeiros"],"url":"https://arxiv.org/abs/2404.09236"}
{"created":"2025-04-22","title":"Learning Self-Growth Maps for Fast and Accurate Imbalanced Streaming Data Clustering","abstract":"Streaming data clustering is a popular research topic in data mining and machine learning. Since streaming data is usually analyzed in data chunks, it is more susceptible to encounter the dynamic cluster imbalance issue. That is, the imbalance ratio of clusters changes over time, which can easily lead to fluctuations in either the accuracy or the efficiency of streaming data clustering. Therefore, we propose an accurate and efficient streaming data clustering approach to adapt the drifting and imbalanced cluster distributions. We first design a Self-Growth Map (SGM) that can automatically arrange neurons on demand according to local distribution, and thus achieve fast and incremental adaptation to the streaming distributions. Since SGM allocates an excess number of density-sensitive neurons to describe the global distribution, it can avoid missing small clusters among imbalanced distributions. We also propose a fast hierarchical merging strategy to combine the neurons that break up the relatively large clusters. It exploits the maintained SGM to quickly retrieve the intra-cluster distribution pairs for merging, which circumvents the most laborious global searching. It turns out that the proposed SGM can incrementally adapt to the distributions of new chunks, and the Self-grOwth map-guided Hierarchical merging for Imbalanced data clustering (SOHI) approach can quickly explore a true number of imbalanced clusters. Extensive experiments demonstrate that SOHI can efficiently and accurately explore cluster distributions for streaming data.","authors":["Yiqun Zhang","Sen Feng","Pengkai Wang","Zexi Tan","Xiaopeng Luo","Yuzhu Ji","Rong Zou","Yiu-ming Cheung"],"url":"https://arxiv.org/abs/2404.09243"}
{"created":"2025-04-22","title":"Convergence Analysis of Probability Flow ODE for Score-based Generative Models","abstract":"Score-based generative models have emerged as a powerful approach for sampling high-dimensional probability distributions. Despite their effectiveness, their theoretical underpinnings remain relatively underdeveloped. In this work, we study the convergence properties of deterministic samplers based on probability flow ODEs from both theoretical and numerical perspectives. Assuming access to $L^2$-accurate estimates of the score function, we prove the total variation between the target and the generated data distributions can be bounded above by $\\mathcal{O}(d^{3/4}\\delta^{1/2})$ in the continuous time level, where $d$ denotes the data dimension and $\\delta$ represents the $L^2$-score matching error. For practical implementations using a $p$-th order Runge-Kutta integrator with step size $h$, we establish error bounds of $\\mathcal{O}(d^{3/4}\\delta^{1/2} + d\\cdot(dh)^p)$ at the discrete level. Finally, we present numerical studies on problems up to 128 dimensions to verify our theory.","authors":["Daniel Zhengyu Huang","Jiaoyang Huang","Zhengjiang Lin"],"url":"https://arxiv.org/abs/2404.09730"}
{"created":"2025-04-22","title":"FedEGG: Federated Learning with Explicit Global Guidance","abstract":"Federated Learning (FL) holds great potential for diverse applications owing to its privacy-preserving nature. However, its convergence is often challenged by non-IID data distributions, limiting its effectiveness in real-world deployments. Existing methods help address these challenges via optimization-based client constraints, adaptive client selection, or the use of pre-trained models or synthetic data. In this work, we reinterpret these approaches as all introducing an \\emph{implicit guiding task} to regularize and steer client learning. Following this insight, we propose to introduce an \\emph{explicit global guiding task} into the current FL framework to improve convergence and performance. To this end, we present \\textbf{FedEGG}, a new FL algorithm that constructs a global guiding task using a well-defined, easy-to-converge learning task based on a public dataset and Large Language Models (LLMs). This approach effectively combines the strengths of federated (the original FL task) and centralized (the global guiding task) learning. We provide a theoretical analysis of FedEGG's convergence, examining the impact of data heterogeneity between the guiding and FL tasks and the guiding strength. Our analysis derives an upper bound for the optimal guiding strength, offering practical insights for implementation. Empirically, FedEGG demonstrates superior performance over state-of-the-art FL methods under both IID and non-IID settings, and further improves their performances when combined.","authors":["Kun Zhai","Yifeng Gao","Difan Zou","Guangnan Ye","Siheng Chen","Xingjun Ma","Yu-Gang Jiang"],"url":"https://arxiv.org/abs/2404.11888"}
{"created":"2025-04-22","title":"The Emerging Generative Artificial Intelligence Divide in the United States","abstract":"The digital divide refers to disparities in access to and use of digital tooling across social and economic groups. This divide can reinforce marginalization both at the individual level and at the level of places, because persistent economic advantages accrue to places where new technologies are adopted early. To what extent are emerging generative artificial intelligence (AI) tools subject to these social and spatial divides? We leverage a large-scale search query database to characterize U.S. residents' knowledge of a novel generative AI tool, ChatGPT, during its first six months of release. We identify hotspots of higher-than-expected search volumes for ChatGPT in coastal metropolitan areas, while coldspots are evident in the American South, Appalachia, and the Midwest. Nationwide, counties with the highest rates of search have proportionally more educated and more economically advantaged populations, as well as proportionally more technology and finance-sector jobs in comparison with other counties or with the national average. Observed associations with race/ethnicity and urbanicity are attenuated in fully adjusted hierarchical models, but education emerges as the strongest positive predictor of generative AI awareness. In the absence of intervention, early differences in uptake show a potential to reinforce existing spatial and socioeconomic divides.","authors":["Madeleine I. G. Daepp","Scott Counts"],"url":"https://arxiv.org/abs/2404.11988"}
{"created":"2025-04-22","title":"Airlift Challenge: A Competition for Optimizing Cargo Delivery","abstract":"Airlift operations require the timely distribution of various cargo, much of which is time sensitive and valuable. These operations, however, have to contend with sudden disruptions from weather and malfunctions, requiring immediate rescheduling. The Airlift Challenge competition seeks possible solutions via a simulator that provides a simplified abstraction of the airlift problem. The simulator uses an OpenAI gym interface that allows participants to create an algorithm for planning agent actions. The algorithm is scored using a remote evaluator against scenarios of ever-increasing difficulty. The second iteration of the competition was underway from November 2023 to April 2024. This paper describes the competition, simulation environment, and results. As a step towards applying generalized planning techniques to the problem, a temporal PDDL domain is presented for the Pickup and Delivery Problem, a model which lies at the core of the Airlift Challenge.","authors":["Adis Delanovic","Carmen Chiu","John F. Kolen","Marvin G\\\"ulhan","Jonathan Cawalla","Andre Beckus"],"url":"https://arxiv.org/abs/2404.17716"}
{"created":"2025-04-22","title":"Unified Dynamic Scanpath Predictors Outperform Individually Trained Neural Models","abstract":"Previous research on scanpath prediction has mainly focused on group models, disregarding the fact that the scanpaths and attentional behaviors of individuals are diverse. The disregard of these differences is especially detrimental to social human-robot interaction, whereby robots commonly emulate human gaze based on heuristics or predefined patterns. However, human gaze patterns are heterogeneous and varying behaviors can significantly affect the outcomes of such human-robot interactions. To fill this gap, we developed a deep learning-based social cue integration model for saliency prediction to instead predict scanpaths in videos. Our model learned scanpaths by recursively integrating fixation history and social cues through a gating mechanism and sequential attention. We evaluated our approach on gaze datasets of dynamic social scenes, observed under the free-viewing condition. The introduction of fixation history into our models makes it possible to train a single unified model rather than the resource-intensive approach of training individual models for each set of scanpaths. We observed that the late neural integration approach surpasses early fusion when training models on a large dataset, in comparison to a smaller dataset with a similar distribution. Results also indicate that a single unified model, trained on all the observers' scanpaths, performs on par or better than individually trained models. We hypothesize that this outcome is a result of the group saliency representations instilling universal attention in the model, while the supervisory signal and fixation history guide it to learn personalized attentional behaviors, providing the unified model a benefit over individual models due to its implicit representation of universal attention.","authors":["Fares Abawi","Di Fu","Stefan Wermter"],"url":"https://arxiv.org/abs/2405.02929"}
{"created":"2025-04-22","title":"Risks of Practicing Large Language Models in Smart Grid: Threat Modeling and Validation","abstract":"Large language models (LLMs) represent significant breakthroughs in artificial intelligence and hold potential for applications within smart grids. However, as demonstrated in previous literature, AI technologies are susceptible to various types of attacks. It is crucial to investigate and evaluate the risks associated with LLMs before deploying them in critical infrastructure like smart grids. In this paper, we systematically evaluated the risks of LLMs and identified two major types of attacks relevant to potential smart grid LLM applications, presenting the corresponding threat models. We validated these attacks using popular LLMs and real smart grid data. Our validation demonstrates that attackers are capable of injecting bad data and retrieving domain knowledge from LLMs employed in different smart grid applications.","authors":["Jiangnan Li","Yingyuan Yang","Jinyuan Sun"],"url":"https://arxiv.org/abs/2405.06237"}
{"created":"2025-04-22","title":"Direct Learning of Mesh and Appearance via 3D Gaussian Splatting","abstract":"Accurately reconstructing a 3D scene including explicit geometry information is both attractive and challenging. Geometry reconstruction can benefit from incorporating differentiable appearance models, such as Neural Radiance Fields and 3D Gaussian Splatting (3DGS). However, existing methods encounter efficiency issues due to indirect geometry learning and the paradigm of separately modeling geometry and surface appearance. In this work, we propose a learnable scene model that incorporates 3DGS with an explicit geometry representation, namely a mesh. Our model learns the mesh and appearance in an end-to-end manner, where we bind 3D Gaussians to the mesh faces and perform differentiable rendering of 3DGS to obtain photometric supervision. The model creates an effective information pathway to supervise the learning of both 3DGS and mesh. Experimental results demonstrate that the learned scene model not only improves efficiency and rendering quality but also enables manipulation via the explicit mesh. In addition, our model has a unique advantage in adapting to scene updates, thanks to the end-to-end learning of both mesh and appearance.","authors":["Ancheng Lin","Yusheng Xiang","Paul Kennedy","Jun Li"],"url":"https://arxiv.org/abs/2405.06945"}
{"created":"2025-04-22","title":"Industrial Metaverse: Enabling Technologies, Open Problems, and Future Trends","abstract":"As an emerging technology that enables seamless integration between the physical and virtual worlds, the Metaverse has great potential to be deployed in the industrial production field with the development of extended reality (XR) and next-generation communication networks. This deployment, called the Industrial Metaverse, is used for product design, production operations, industrial quality inspection, and product testing. However, there lacks of in-depth understanding of the enabling technologies associated with the Industrial Metaverse. This encompasses both the precise industrial scenarios targeted by each technology and the potential migration of technologies developed in other domains to the industrial sector. Driven by this issue, in this article, we conduct a comprehensive survey of the state-of-the-art literature on the Industrial Metaverse. Specifically, we first analyze the advantages of the Metaverse for industrial production. Then, we review a collection of key enabling technologies of the Industrial Metaverse, including blockchain (BC), digital twin (DT), 6G, XR, and artificial intelligence (AI), and analyze how these technologies can support different aspects of industrial production. Subsequently, we present numerous formidable challenges encountered within the Industrial Metaverse, including confidentiality and security concerns, resource limitations, and interoperability constraints. Furthermore, we investigate the extant solutions devised to address them. Finally, we briefly outline several open issues and future research directions of the Industrial Metaverse.","authors":["Shiying Zhang","Jun Li","Long Shi","Ming Ding","Dinh C. Nguyen","Wen Chen","Zhu Han"],"url":"https://arxiv.org/abs/2405.08542"}
{"created":"2025-04-22","title":"Low-Degree Polynomials Are Good Extractors","abstract":"We prove that random low-degree polynomials (over $\\mathbb{F}_2$) are unbiased, in an extremely general sense. That is, we show that random low-degree polynomials are good randomness extractors for a wide class of distributions. Prior to our work, such results were only known for the small families of (1) uniform sources, (2) affine sources, and (3) local sources. We significantly generalize these results, and prove the following.","authors":["Omar Alrabiah","Jesse Goodman","Jonathan Mosheiff","Jo\\~ao Ribeiro"],"url":"https://arxiv.org/abs/2405.10297"}
{"created":"2025-04-22","title":"Uncertainty-Aware PPG-2-ECG for Enhanced Cardiovascular Diagnosis using Diffusion Models","abstract":"Analyzing the cardiovascular system condition via Electrocardiography (ECG) is a common and highly effective approach, and it has been practiced and perfected over many decades. ECG sensing is non-invasive and relatively easy to acquire, and yet it is still cumbersome for holter monitoring tests that may span over hours and even days. A possible alternative in this context is Photoplethysmography (PPG): An optically-based signal that measures blood volume fluctuations, as typically sensed by conventional ``wearable devices''. While PPG presents clear advantages in acquisition, convenience, and cost-effectiveness, ECG provides more comprehensive information, allowing for a more precise detection of heart conditions. This implies that a conversion from PPG to ECG, as recently discussed in the literature, inherently involves an unavoidable level of uncertainty. In this paper we introduce a novel methodology for addressing the PPG-2-ECG conversion, and offer an enhanced classification of cardiovascular conditions using the given PPG, all while taking into account the uncertainties arising from the conversion process. We provide a mathematical justification for our proposed computational approach, and present empirical studies demonstrating its superior performance compared to state-of-the-art baseline methods.","authors":["Omer Belhasin","Idan Kligvasser","George Leifman","Regev Cohen","Erin Rainaldi","Li-Fang Cheng","Nishant Verma","Paul Varghese","Ehud Rivlin","Michael Elad"],"url":"https://arxiv.org/abs/2405.11566"}
{"created":"2025-04-22","title":"Fair Set Cover","abstract":"The potential harms of algorithmic decisions have ignited algorithmic fairness as a central topic in computer science. One of the fundamental problems in computer science is Set Cover, which has numerous applications with societal impacts, such as assembling a small team of individuals that collectively satisfy a range of expertise requirements. However, despite its broad application spectrum and significant potential impact, set cover has yet to be studied through the lens of fairness. Therefore, in this paper, we introduce Fair Set Cover, which aims not only to cover with a minimum-size set but also to satisfy demographic parity in its selection of sets. To this end, we develop multiple versions of fair set cover, study their hardness, and devise efficient approximation algorithms for each variant. Notably, under certain assumptions, our algorithms always guarantee zero-unfairness, with only a small increase in the approximation ratio compared to regular set cover. Furthermore, our experiments on various data sets and across different settings confirm the negligible price of fairness, as (a) the output size increases only slightly (if any) and (b) the time to compute the output does not significantly increase.","authors":["Mohsen Dehghankar","Rahul Raychaudhury","Stavros Sintos","Abolfazl Asudeh"],"url":"https://arxiv.org/abs/2405.11639"}
{"created":"2025-04-22","title":"Exploring Commonalities in Explanation Frameworks: A Multi-Domain Survey Analysis","abstract":"This study presents insights gathered from surveys and discussions with specialists in three domains, aiming to find essential elements for a universal explanation framework that could be applied to these and other similar use cases. The insights are incorporated into a software tool that utilizes GP algorithms, known for their interpretability. The applications analyzed include a medical scenario (involving predictive ML), a retail use case (involving prescriptive ML), and an energy use case (also involving predictive ML). We interviewed professionals from each sector, transcribing their conversations for further analysis. Additionally, experts and non-experts in these fields filled out questionnaires designed to probe various dimensions of explanatory methods. The findings indicate a universal preference for sacrificing a degree of accuracy in favor of greater explainability. Additionally, we highlight the significance of feature importance and counterfactual explanations as critical components of such a framework. Our questionnaires are publicly available to facilitate the dissemination of knowledge in the field of XAI.","authors":["Eduard Barbu","Marharyta Domnich","Raul Vicente","Nikos Sakkas","Andr\\'e Morim"],"url":"https://arxiv.org/abs/2405.11958"}
{"created":"2025-04-22","title":"A direct proof of a unified law of robustness for Bregman divergence losses","abstract":"In contemporary deep learning practice, models are often trained to near zero loss i.e. to nearly interpolate the training data. However, the number of parameters in the model is usually far more than the number of data points n, the theoretical minimum needed for interpolation: a phenomenon referred to as overparameterization. In an interesting piece of work, Bubeck and Sellke considered a natural notion of interpolation: the model is said to interpolate when the model's training loss goes below the loss of the conditional expectation of the response given the covariate. For this notion of interpolation and for a broad class of covariate distributions (specifically those satisfying a natural notion of concentration of measure), they showed that overparameterization is necessary for robust interpolation i.e. if the interpolating function is required to be Lipschitz. Their main proof technique applies to regression with square loss against a scalar response, but they remark that via a connection to Rademacher complexity and using tools such as the Ledoux-Talagrand contraction inequality, their result can be extended to more general losses, at least in the case of scalar response variables. In this work, we recast the original proof technique of Bubeck and Sellke in terms of a bias-variance type decomposition, and show that this view directly unlocks a generalization to Bregman divergence losses (even for vector-valued responses), without the use of tools such as Rademacher complexity or the Ledoux-Talagrand contraction principle. Bregman divergences are a natural class of losses since for these, the best estimator is the conditional expectation of the response given the covariate, and include other practical losses such as the cross entropy loss. Our work thus gives a more general understanding of the main proof technique of Bubeck and Sellke and demonstrates its broad utility.","authors":["Santanu Das","Jatin Batra","Piyush Srivastava"],"url":"https://arxiv.org/abs/2405.16639"}
{"created":"2025-04-22","title":"SLMRec: Distilling Large Language Models into Small for Sequential Recommendation","abstract":"Sequential Recommendation (SR) task involves predicting the next item a user is likely to interact with, given their past interactions. The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics. Recent research demonstrates the great impact of LLMs on sequential recommendation systems, either viewing sequential recommendation as language modeling or serving as the backbone for user representation. Although these methods deliver outstanding performance, there is scant evidence of the necessity of a large language model and how large the language model is needed, especially in the sequential recommendation scene. Meanwhile, due to the huge size of LLMs, it is inefficient and impractical to apply a LLM-based model in real-world platforms that often need to process billions of traffic logs daily. In this paper, we explore the influence of LLMs' depth by conducting extensive experiments on large-scale industry datasets. Surprisingly, our motivational experiments reveal that most intermediate layers of LLMs are redundant, indicating that pruning the remaining layers can still maintain strong performance. Motivated by this insight, we empower small language models for SR, namely SLMRec, which adopt a simple yet effective knowledge distillation method. Moreover, SLMRec is orthogonal to other post-training efficiency techniques, such as quantization and pruning, so that they can be leveraged in combination. Comprehensive experimental results illustrate that the proposed SLMRec model attains the best performance using only 13% of the parameters found in LLM-based recommendation models while simultaneously achieving up to 6.6x and 8.0x speedups in training and inference time costs, respectively. Besides, we provide a theoretical justification for why small language models can perform comparably to large language models in SR.","authors":["Wujiang Xu","Qitian Wu","Zujie Liang","Jiaojiao Han","Xuying Ning","Yunxiao Shi","Wenfang Lin","Yongfeng Zhang"],"url":"https://arxiv.org/abs/2405.17890"}
{"created":"2025-04-22","title":"Potential Field Based Deep Metric Learning","abstract":"Deep metric learning (DML) involves training a network to learn a semantically meaningful representation space. Many current approaches mine n-tuples of examples and model interactions within each tuplets. We present a novel, compositional DML model that instead of in tuples, represents the influence of each example (embedding) by a continuous potential field, and superposes the fields to obtain their combined global potential field. We use attractive/repulsive potential fields to represent interactions among embeddings from images of the same/different classes. Contrary to typical learning methods, where mutual influence of samples is proportional to their distance, we enforce reduction in such influence with distance, leading to a decaying field. We show that such decay helps improve performance on real world datasets with large intra-class variations and label noise. Like other proxy-based methods, we also use proxies to succinctly represent sub-populations of examples. We evaluate our method on three standard DML benchmarks- Cars-196, CUB-200-2011, and SOP datasets where it outperforms state-of-the-art baselines.","authors":["Shubhang Bhatnagar","Narendra Ahuja"],"url":"https://arxiv.org/abs/2405.18560"}
{"created":"2025-04-22","title":"SSFF: Investigating LLM Predictive Capabilities for Startup Success through a Multi-Agent Framework with Enhanced Explainability and Performance","abstract":"LLM based agents have recently demonstrated strong potential in automating complex tasks, yet accurately predicting startup success remains an open challenge with few benchmarks and tailored frameworks. To address these limitations, we propose the Startup Success Forecasting Framework, an autonomous system that emulates the reasoning of venture capital analysts through a multi agent collaboration model. Our framework integrates traditional machine learning methods such as random forests and neural networks within a retrieval augmented generation framework composed of three interconnected modules: a prediction block, an analysis block, and an external knowledge block. We evaluate our framework and identify three main findings. First, by leveraging founder segmentation, startups led by L5 founders are 3.79 times more likely to succeed than those led by L1 founders. Second, baseline large language models consistently overpredict startup success and struggle under realistic class imbalances largely due to overreliance on founder claims. Third, our framework significantly enhances prediction accuracy, yielding a 108.3 percent relative improvement over GPT 4o mini and a 30.8 percent relative improvement over GPT 4o. These results demonstrate the value of a multi agent approach combined with discriminative machine learning in mitigating the limitations of standard large language model based prediction methods.","authors":["Xisen Wang","Yigit Ihlamur","Fuat Alican"],"url":"https://arxiv.org/abs/2405.19456"}
{"created":"2025-04-22","title":"HOPE: A Reinforcement Learning-based Hybrid Policy Path Planner for Diverse Parking Scenarios","abstract":"Automated parking stands as a highly anticipated application of autonomous driving technology. However, existing path planning methodologies fall short of addressing this need due to their incapability to handle the diverse and complex parking scenarios in reality. While non-learning methods provide reliable planning results, they are vulnerable to intricate occasions, whereas learning-based ones are good at exploration but unstable in converging to feasible solutions. To leverage the strengths of both approaches, we introduce Hybrid pOlicy Path plannEr (HOPE). This novel solution integrates a reinforcement learning agent with Reeds-Shepp curves, enabling effective planning across diverse scenarios. HOPE guides the exploration of the reinforcement learning agent by applying an action mask mechanism and employs a transformer to integrate the perceived environmental information with the mask. To facilitate the training and evaluation of the proposed planner, we propose a criterion for categorizing the difficulty level of parking scenarios based on space and obstacle distribution. Experimental results demonstrate that our approach outperforms typical rule-based algorithms and traditional reinforcement learning methods, showing higher planning success rates and generalization across various scenarios. We also conduct real-world experiments to verify the practicability of HOPE. The code for our solution is openly available on https://github.com/jiamiya/HOPE.","authors":["Mingyang Jiang","Yueyuan Li","Songan Zhang","Siyuan Chen","Chunxiang Wang","Ming Yang"],"url":"https://arxiv.org/abs/2405.20579"}
{"created":"2025-04-22","title":"Aligning Language Models with Demonstrated Feedback","abstract":"Language models are aligned to emulate the collective voice of many, resulting in outputs that align with no one in particular. Steering LLMs away from generic output is possible through supervised finetuning or RLHF, but requires prohibitively large datasets for new ad-hoc tasks. We argue that it is instead possible to align an LLM to a specific setting by leveraging a very small number (< 10) of demonstrations as feedback. Our method, Demonstration ITerated Task Optimization (DITTO), directly aligns language model outputs to a user's demonstrated behaviors. Derived using ideas from online imitation learning, DITTO cheaply generates online comparison data by treating users' demonstrations as preferred over output from the LLM and its intermediate checkpoints. Concretely, DITTO operates by having an LLM generate examples that are presumed to be inferior to expert demonstrations. The method iteratively constructs pairwise preference relationships between these LLM-generated samples and expert demonstrations, potentially including comparisons between different training checkpoints. These constructed preference pairs are then used to train the model using a preference optimization algorithm (e.g. DPO). We evaluate DITTO's ability to learn fine-grained style and task alignment across domains such as news articles, emails, and blog posts. Additionally, we conduct a user study soliciting a range of demonstrations from participants (N = 16). Across our benchmarks and user study, we find that win-rates for DITTO outperform few-shot prompting, supervised fine-tuning, and other self-play methods by an avg. of 19% points. By using demonstrations as feedback directly, DITTO offers a novel method for effective customization of LLMs.","authors":["Omar Shaikh","Michelle S. Lam","Joey Hejna","Yijia Shao","Hyundong Cho","Michael S. Bernstein","Diyi Yang"],"url":"https://arxiv.org/abs/2406.00888"}
{"created":"2025-04-22","title":"FIRM: Flexible Interactive Reflection reMoval","abstract":"Removing reflection from a single image is challenging due to the absence of general reflection priors. Although existing methods incorporate extensive user guidance for satisfactory performance, they often lack the flexibility to adapt user guidance in different modalities, and dense user interactions further limit their practicality. To alleviate these problems, this paper presents FIRM, a novel framework for Flexible Interactive image Reflection reMoval with various forms of guidance, where users can provide sparse visual guidance (e.g., points, boxes, or strokes) or text descriptions for better reflection removal. Firstly, we design a novel user guidance conversion module (UGC) to transform different forms of guidance into unified contrastive masks. The contrastive masks provide explicit cues for identifying reflection and transmission layers in blended images. Secondly, we devise a contrastive mask-guided reflection removal network that comprises a newly proposed contrastive guidance interaction block (CGIB). This block leverages a unique cross-attention mechanism that merges contrastive masks with image features, allowing for precise layer separation. The proposed framework requires only 10\\% of the guidance time needed by previous interactive methods, which makes a step-change in flexibility. Extensive results on public real-world reflection removal datasets validate that our method demonstrates state-of-the-art reflection removal performance. Code is avaliable at https://github.com/ShawnChenn/FlexibleReflectionRemoval.","authors":["Xiao Chen","Xudong Jiang","Yunkang Tao","Zhen Lei","Qing Li","Chenyang Lei","Zhaoxiang Zhang"],"url":"https://arxiv.org/abs/2406.01555"}
{"created":"2025-04-22","title":"Improving Gaussian Splatting with Localized Points Management","abstract":"Point management is critical for optimizing 3D Gaussian Splatting models, as point initiation (e.g., via structure from motion) is often distributionally inappropriate. Typically, Adaptive Density Control (ADC) algorithm is adopted, leveraging view-averaged gradient magnitude thresholding for point densification, opacity thresholding for pruning, and regular all-points opacity reset. We reveal that this strategy is limited in tackling intricate/special image regions (e.g., transparent) due to inability of identifying all 3D zones requiring point densification, and lacking an appropriate mechanism to handle ill-conditioned points with negative impacts (e.g., occlusion due to false high opacity). To address these limitations, we propose a Localized Point Management (LPM) strategy, capable of identifying those error-contributing zones in greatest need for both point addition and geometry calibration. Zone identification is achieved by leveraging the underlying multiview geometry constraints, subject to image rendering errors. We apply point densification in the identified zones and then reset the opacity of the points in front of these regions, creating a new opportunity to correct poorly conditioned points. Serving as a versatile plugin, LPM can be seamlessly integrated into existing static 3D and dynamic 4D Gaussian Splatting models with minimal additional cost. Experimental evaluations validate the efficacy of our LPM in boosting a variety of existing 3D/4D models both quantitatively and qualitatively. Notably, LPM improves both static 3DGS and dynamic SpaceTimeGS to achieve state-of-the-art rendering quality while retaining real-time speeds, excelling on challenging datasets such as Tanks & Temples and the Neural 3D Video dataset.","authors":["Haosen Yang","Chenhao Zhang","Wenqing Wang","Marco Volino","Adrian Hilton","Li Zhang","Xiatian Zhu"],"url":"https://arxiv.org/abs/2406.04251"}
{"created":"2025-04-22","title":"A DeNoising FPN With Transformer R-CNN for Tiny Object Detection","abstract":"Despite notable advancements in the field of computer vision, the precise detection of tiny objects continues to pose a significant challenge, largely owing to the minuscule pixel representation allocated to these objects in imagery data. This challenge resonates profoundly in the domain of geoscience and remote sensing, where high-fidelity detection of tiny objects can facilitate a myriad of applications ranging from urban planning to environmental monitoring. In this paper, we propose a new framework, namely, DeNoising FPN with Trans R-CNN (DNTR), to improve the performance of tiny object detection. DNTR consists of an easy plug-in design, DeNoising FPN (DN-FPN), and an effective Transformer-based detector, Trans R-CNN. Specifically, feature fusion in the feature pyramid network is important for detecting multiscale objects. However, noisy features may be produced during the fusion process since there is no regularization between the features of different scales. Therefore, we introduce a DN-FPN module that utilizes contrastive learning to suppress noise in each level's features in the top-down path of FPN. Second, based on the two-stage framework, we replace the obsolete R-CNN detector with a novel Trans R-CNN detector to focus on the representation of tiny objects with self-attention. Experimental results manifest that our DNTR outperforms the baselines by at least 17.4% in terms of APvt on the AI-TOD dataset and 9.6% in terms of AP on the VisDrone dataset, respectively. Our code will be available at https://github.com/hoiliu-0801/DNTR.","authors":["Hou-I Liu","Yu-Wen Tseng","Kai-Cheng Chang","Pin-Jyun Wang","Hong-Han Shuai","Wen-Huang Cheng"],"url":"https://arxiv.org/abs/2406.05755"}
{"created":"2025-04-22","title":"Generalizable Human Gaussians from Single-View Image","abstract":"In this work, we tackle the task of learning 3D human Gaussians from a single image, focusing on recovering detailed appearance and geometry including unobserved regions. We introduce a single-view generalizable Human Gaussian Model (HGM), which employs a novel generate-then-refine pipeline with the guidance from human body prior and diffusion prior. Our approach uses a ControlNet to refine rendered back-view images from coarse predicted human Gaussians, then uses the refined image along with the input image to reconstruct refined human Gaussians. To mitigate the potential generation of unrealistic human poses and shapes, we incorporate human priors from the SMPL-X model as a dual branch, propagating image features from the SMPL-X volume to the image Gaussians using sparse convolution and attention mechanisms. Given that the initial SMPL-X estimation might be inaccurate, we gradually refine it with our HGM model. We validate our approach on several publicly available datasets. Our method surpasses previous methods in both novel view synthesis and surface reconstruction. Our approach also exhibits strong generalization for cross-dataset evaluation and in-the-wild images.","authors":["Jinnan Chen","Chen Li","Jianfeng Zhang","Lingting Zhu","Buzhen Huang","Hanlin Chen","Gim Hee Lee"],"url":"https://arxiv.org/abs/2406.06050"}
{"created":"2025-04-22","title":"Inverse Constitutional AI: Compressing Preferences into Principles","abstract":"Feedback data is widely used for fine-tuning and evaluating state-of-the-art AI models. Pairwise text preferences, where human or AI annotators select the \"better\" of two options, are particularly common. Such preferences are used to train (reward) models or to rank models with aggregate statistics. For many applications it is desirable to understand annotator preferences in addition to modelling them - not least because extensive prior work has shown various unintended biases in preference datasets. Yet, preference datasets remain challenging to interpret. Neither black-box reward models nor statistics can answer why one text is preferred over another. Manual interpretation of the numerous (long) response pairs is usually equally infeasible. In this paper, we introduce the Inverse Constitutional AI (ICAI) problem, formulating the interpretation of pairwise text preference data as a compression task. In constitutional AI, a set of principles (a constitution) is used to provide feedback and fine-tune AI models. ICAI inverts this process: given a feedback dataset, we aim to extract a constitution that best enables a large language model (LLM) to reconstruct the original annotations. We propose a corresponding ICAI algorithm and validate its generated constitutions quantitatively based on annotation reconstruction accuracy on several datasets: (a) synthetic feedback data with known principles; (b) AlpacaEval cross-annotated human feedback data; (c) crowdsourced Chatbot Arena data; and (d) PRISM data from diverse demographic groups. As a short and interpretable representation of the original dataset, generated constitutions have many potential use cases: help identify undesirable annotator biases, understand model performance better, scale feedback to unseen data, or adapt models to individual user or group preferences. We release the source code at https://github.com/rdnfn/icai.","authors":["Arduin Findeis","Timo Kaufmann","Eyke H\\\"ullermeier","Samuel Albanie","Robert Mullins"],"url":"https://arxiv.org/abs/2406.06560"}
{"created":"2025-04-22","title":"RILe: Reinforced Imitation Learning","abstract":"Acquiring complex behaviors is essential for artificially intelligent agents, yet learning these behaviors in high-dimensional settings poses a significant challenge due to the vast search space. Traditional reinforcement learning (RL) requires extensive manual effort for reward function engineering. Inverse reinforcement learning (IRL) uncovers reward functions from expert demonstrations but relies on an iterative process that is often computationally expensive. Imitation learning (IL) provides a more efficient alternative by directly comparing an agent's actions to expert demonstrations; however, in high-dimensional environments, such direct comparisons often offer insufficient feedback for effective learning. We introduce RILe (Reinforced Imitation Learning), a framework that combines the strengths of imitation learning and inverse reinforcement learning to learn a dense reward function efficiently and achieve strong performance in high-dimensional tasks. RILe employs a novel trainer-student framework: the trainer learns an adaptive reward function, and the student uses this reward signal to imitate expert behaviors. By dynamically adjusting its guidance as the student evolves, the trainer provides nuanced feedback across different phases of learning. Our framework produces high-performing policies in high-dimensional tasks where direct imitation fails to replicate complex behaviors. We validate RILe in challenging robotic locomotion tasks, demonstrating that it significantly outperforms existing methods and achieves near-expert performance across multiple settings.","authors":["Mert Albaba","Sammy Christen","Thomas Langarek","Christoph Gebhardt","Otmar Hilliges","Michael J. Black"],"url":"https://arxiv.org/abs/2406.08472"}
{"created":"2025-04-22","title":"Beyond Boundaries: Learning a Universal Entity Taxonomy across Datasets and Languages for Open Named Entity Recognition","abstract":"Open Named Entity Recognition (NER), which involves identifying arbitrary types of entities from arbitrary domains, remains challenging for Large Language Models (LLMs). Recent studies suggest that fine-tuning LLMs on extensive NER data can boost their performance. However, training directly on existing datasets neglects their inconsistent entity definitions and redundant data, limiting LLMs to dataset-specific learning and hindering out-of-domain adaptation. To address this, we present B2NERD, a compact dataset designed to guide LLMs' generalization in Open NER under a universal entity taxonomy. B2NERD is refined from 54 existing English and Chinese datasets using a two-step process. First, we detect inconsistent entity definitions across datasets and clarify them by distinguishable label names to construct a universal taxonomy of 400+ entity types. Second, we address redundancy using a data pruning strategy that selects fewer samples with greater category and semantic diversity. Comprehensive evaluation shows that B2NERD significantly enhances LLMs' Open NER capabilities. Our B2NER models, trained on B2NERD, outperform GPT-4 by 6.8-12.0 F1 points and surpass previous methods in 3 out-of-domain benchmarks across 15 datasets and 6 languages. The data, models, and code are publicly available at https://github.com/UmeanNever/B2NER.","authors":["Yuming Yang","Wantong Zhao","Caishuang Huang","Junjie Ye","Xiao Wang","Huiyuan Zheng","Yang Nan","Yuran Wang","Xueying Xu","Kaixin Huang","Yunke Zhang","Tao Gui","Qi Zhang","Xuanjing Huang"],"url":"https://arxiv.org/abs/2406.11192"}
{"created":"2025-04-22","title":"DataComp-LM: In search of the next generation of training sets for language models","abstract":"We introduce DataComp for Language Models (DCLM), a testbed for controlled dataset experiments with the goal of improving language models. As part of DCLM, we provide a standardized corpus of 240T tokens extracted from Common Crawl, effective pretraining recipes based on the OpenLM framework, and a broad suite of 53 downstream evaluations. Participants in the DCLM benchmark can experiment with data curation strategies such as deduplication, filtering, and data mixing at model scales ranging from 412M to 7B parameters. As a baseline for DCLM, we conduct extensive experiments and find that model-based filtering is key to assembling a high-quality training set. The resulting dataset, DCLM-Baseline enables training a 7B parameter language model from scratch to 64% 5-shot accuracy on MMLU with 2.6T training tokens. Compared to MAP-Neo, the previous state-of-the-art in open-data language models, DCLM-Baseline represents a 6.6 percentage point improvement on MMLU while being trained with 40% less compute. Our baseline model is also comparable to Mistral-7B-v0.3 and Llama 3 8B on MMLU (63% & 66%), and performs similarly on an average of 53 natural language understanding tasks while being trained with 6.6x less compute than Llama 3 8B. Our results highlight the importance of dataset design for training language models and offer a starting point for further research on data curation.","authors":["Jeffrey Li","Alex Fang","Georgios Smyrnis","Maor Ivgi","Matt Jordan","Samir Gadre","Hritik Bansal","Etash Guha","Sedrick Keh","Kushal Arora","Saurabh Garg","Rui Xin","Niklas Muennighoff","Reinhard Heckel","Jean Mercat","Mayee Chen","Suchin Gururangan","Mitchell Wortsman","Alon Albalak","Yonatan Bitton","Marianna Nezhurina","Amro Abbas","Cheng-Yu Hsieh","Dhruba Ghosh","Josh Gardner","Maciej Kilian","Hanlin Zhang","Rulin Shao","Sarah Pratt","Sunny Sanyal","Gabriel Ilharco","Giannis Daras","Kalyani Marathe","Aaron Gokaslan","Jieyu Zhang","Khyathi Chandu","Thao Nguyen","Igor Vasiljevic","Sham Kakade","Shuran Song","Sujay Sanghavi","Fartash Faghri","Sewoong Oh","Luke Zettlemoyer","Kyle Lo","Alaaeldin El-Nouby","Hadi Pouransari","Alexander Toshev","Stephanie Wang","Dirk Groeneveld","Luca Soldaini","Pang Wei Koh","Jenia Jitsev","Thomas Kollar","Alexandros G. Dimakis","Yair Carmon","Achal Dave","Ludwig Schmidt","Vaishaal Shankar"],"url":"https://arxiv.org/abs/2406.11794"}
{"created":"2025-04-22","title":"A-OctoMap: An Adaptive OctoMap for Online Path Planning","abstract":"Downsampling and path planning are essential in robotics and autonomous systems, as they enhance computational efficiency and enable effective navigation in complex environments. However, current downsampling methods often fail to preserve crucial geometric information while maintaining computational efficiency, leading to challenges such as information loss during map reconstruction and the need to balance precision with computational demands. Similarly, current graph-based search algorithms for path planning struggle with fixed resolutions in complex environments, resulting in inaccurate obstacle detection and suboptimal or failed pathfinding. To address these issues, we introduce an adaptive OctoMap that utilizes a hierarchical data structure. This innovative approach preserves key geometric information during downsampling and offers a more flexible representation for pathfinding within fixed-resolution maps, all while maintaining high computational efficiency. Simulations validate our method, showing significant improvements in reducing information loss, enhancing precision, and boosting the computational efficiency of map reconstruction compared to state-of-the-art methods. For path planning, our approach enhances Jump Point Search (JPS) by increasing the success rate of pathfinding and reducing path lengths, enabling more reliable navigation in complex scenes.","authors":["Yihui Mao","Shuo Liu"],"url":"https://arxiv.org/abs/2406.13910"}
{"created":"2025-04-22","title":"Temporal Knowledge Graph Question Answering: A Survey","abstract":"Knowledge Base Question Answering (KBQA) has been a long-standing field to answer questions based on knowledge bases. Recently, the evolving dynamics of knowledge have attracted a growing interest in Temporal Knowledge Graph Question Answering (TKGQA), an emerging task to answer temporal questions. However, this field grapples with ambiguities in defining temporal questions and lacks a systematic categorization of existing methods for TKGQA. In response, this paper provides a thorough survey from two perspectives: the taxonomy of temporal questions and the methodological categorization for TKGQA. Specifically, we first establish a detailed taxonomy of temporal questions engaged in prior studies. Subsequently, we provide a comprehensive review of TKGQA techniques of two categories: semantic parsing-based and TKG embedding-based. Building on this review, the paper outlines potential research directions aimed at advancing the field of TKGQA. This work aims to serve as a comprehensive reference for TKGQA and to stimulate further research.","authors":["Miao Su","Zixuan Li","Zhuo Chen","Long Bai","Xiaolong Jin","Jiafeng Guo"],"url":"https://arxiv.org/abs/2406.14191"}
{"created":"2025-04-22","title":"Jailbreaking as a Reward Misspecification Problem","abstract":"The widespread adoption of large language models (LLMs) has raised concerns about their safety and reliability, particularly regarding their vulnerability to adversarial attacks. In this paper, we propose a novel perspective that attributes this vulnerability to reward misspecification during the alignment process. This misspecification occurs when the reward function fails to accurately capture the intended behavior, leading to misaligned model outputs. We introduce a metric ReGap to quantify the extent of reward misspecification and demonstrate its effectiveness and robustness in detecting harmful backdoor prompts. Building upon these insights, we present ReMiss, a system for automated red teaming that generates adversarial prompts in a reward-misspecified space. ReMiss achieves state-of-the-art attack success rates on the AdvBench benchmark against various target aligned LLMs while preserving the human readability of the generated prompts. Furthermore, these attacks on open-source models demonstrate high transferability to closed-source models like GPT-4o and out-of-distribution tasks from HarmBench. Detailed analysis highlights the unique advantages of the proposed reward misspecification objective compared to previous methods, offering new insights for improving LLM safety and robustness.","authors":["Zhihui Xie","Jiahui Gao","Lei Li","Zhenguo Li","Qi Liu","Lingpeng Kong"],"url":"https://arxiv.org/abs/2406.14393"}
{"created":"2025-04-22","title":"Large-Scale Contextual Market Equilibrium Computation through Deep Learning","abstract":"Market equilibrium is one of the most fundamental solution concepts in economics and social optimization analysis. Existing works on market equilibrium computation primarily focus on settings with relatively few buyers. Motivated by this, our paper investigates the computation of market equilibrium in scenarios with a large-scale buyer population, where buyers and goods are represented by their contexts. Building on this realistic and generalized contextual market model, we introduce MarketFCNet, a deep learning-based method for approximating market equilibrium. We start by parameterizing the allocation of each good to each buyer using a neural network, which depends solely on the context of the buyer and the good. Next, we propose an efficient method to unbiasedly estimate the loss function of the training algorithm, enabling us to optimize the network parameters through gradient. To evaluate the approximated solution, we propose a metric called Nash Gap, which quantifies the deviation of the given allocation and price pair from the market equilibrium. Experimental results indicate that MarketFCNet delivers competitive performance and significantly lower running times compared to existing methods as the market scale expands, demonstrating the potential of deep learning-based methods to accelerate the approximation of large-scale contextual market equilibrium.","authors":["Yunxuan Ma","Yide Bian","Hao Xu","Weitao Yang","Jingshu Zhao","Zhijian Duan","Feng Wang","Xiaotie Deng"],"url":"https://arxiv.org/abs/2406.15459"}
{"created":"2025-04-22","title":"Simple Cracking of (Noise-Based) Dynamic Watermarking in Smart Grids","abstract":"Previous research employing a conceptual approach with a digital twin has demonstrated that (noise-based) dynamic watermarking is incapable of providing unconditional security in smart electrical grid systems. However, the implementation of digital twins can be prohibitively costly or infeasible due to limited available data on critical infrastructure. In this study, we first analyze the spectral properties of dynamic watermarking and its associated protocol. Subsequently, we present a straightforward attack inspired by the digital twin method, which extracts and utilizes the grid noises and completely breaches the security of dynamic watermarking without requiring knowledge of the private watermarking signal. The attacker can fully expose the grid while evading detection by the controller. Our findings indicate that in the absence of secure and authenticated communications, dynamic watermarking offers neither conditional nor unconditional security. Conversely, when communication lines, sensors, and communicators are equipped with tamper-resistant and secure/authenticated links, dynamic watermarking becomes redundant for grid security.","authors":["Mehmet Yildirim","Nasir Kenarangui","Robert Balog","Laszlo B. Kish","Chanan Singh"],"url":"https://arxiv.org/abs/2406.15494"}
{"created":"2025-04-22","title":"A Dual-Channel Particle Swarm Optimization Algorithm Based on Adaptive Balance Search","abstract":"The balance between exploration (Er) and exploitation (Ei) determines the generalization performance of the particle swarm optimization (PSO) algorithm on different problems. Although the insufficient balance caused by global best being located near a local minimum has been widely researched, few scholars have systematically paid attention to two behaviors about personal best position (P) and global best position (G) existing in PSO. 1) P's uncontrollable-exploitation and involuntary-exploration guidance behavior. 2) G's full-time and global guidance behavior, each of which negatively affects the balance of Er and Ei. With regards to this, we firstly discuss the two behaviors, unveiling the mechanisms by which they affect the balance, and further pinpoint three key points for better balancing Er and Ei: eliminating the coupling between P and G, empowering P with controllable-exploitation and voluntary-exploration guidance behavior, controlling G's full-time and global guidance behavior. Then, we present a dual-channel PSO algorithm based on adaptive balance search (DCPSO-ABS). This algorithm entails a dual-channel framework to mitigate the interaction of P and G, aiding in regulating the behaviors of P and G, and meanwhile an adaptive balance search strategy for empowering P with voluntary-exploration and controllable-exploitation guidance behavior as well as adaptively controlling G's full-time and global guidance behavior. Finally, three kinds of experiments on 57 benchmark functions are designed to demonstrate that our proposed algorithm has stronger generalization performance than selected state-of-the-art algorithms.","authors":["Zhenxing Zhang","Tianxian Zhang"],"url":"https://arxiv.org/abs/2406.16500"}
{"created":"2025-04-22","title":"LiveBench: A Challenging, Contamination-Limited LLM Benchmark","abstract":"Test set contamination, wherein test data from a benchmark ends up in a newer model's training set, is a well-documented obstacle for fair LLM evaluation and can quickly render benchmarks obsolete. To mitigate this, many recent benchmarks crowdsource new prompts and evaluations from human or LLM judges; however, these can introduce significant biases, and break down when scoring hard questions. In this work, we introduce a new benchmark for LLMs designed to be resistant to both test set contamination and the pitfalls of LLM judging and human crowdsourcing. We release LiveBench, the first benchmark that (1) contains frequently-updated questions from recent information sources, (2) scores answers automatically according to objective ground-truth values, and (3) contains a wide variety of challenging tasks, spanning math, coding, reasoning, language, instruction following, and data analysis. To achieve this, LiveBench contains questions that are based on recently-released math competitions, arXiv papers, news articles, and datasets, and it contains harder, contamination-limited versions of tasks from previous benchmarks such as Big-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source models, as well as dozens of open-source models ranging from 0.5B to 405B in size. LiveBench is difficult, with top models achieving below 70% accuracy. We release all questions, code, and model answers. Questions are added and updated on a monthly basis, and we release new tasks and harder versions of tasks over time so that LiveBench can distinguish between the capabilities of LLMs as they improve in the future. We welcome community engagement and collaboration for expanding the benchmark tasks and models.","authors":["Colin White","Samuel Dooley","Manley Roberts","Arka Pal","Ben Feuer","Siddhartha Jain","Ravid Shwartz-Ziv","Neel Jain","Khalid Saifullah","Sreemanti Dey","Shubh-Agrawal","Sandeep Singh Sandha","Siddartha Naidu","Chinmay Hegde","Yann LeCun","Tom Goldstein","Willie Neiswanger","Micah Goldblum"],"url":"https://arxiv.org/abs/2406.19314"}
{"created":"2025-04-22","title":"Multiple-Resolution Tokenization for Time Series Forecasting with an Application to Pricing","abstract":"We propose a transformer architecture for time series forecasting with a focus on time series tokenisation and apply it to a real-world prediction problem from the pricing domain. Our architecture aims to learn effective representations at many scales across all available data simultaneously. The model contains a number of novel modules: a differentiated form of time series patching which employs multiple resolutions, a multiple-resolution module for time-varying known variables, a mixer-based module for capturing cross-series information, and a novel output head with favourable scaling to account for the increased number of tokens. We present an application of this model to a real world prediction problem faced by the markdown team at a very large retailer. On the experiments conducted our model outperforms in-house models and the selected existing deep learning architectures.","authors":["Egon Per\\v{s}ak","Miguel F. Anjos","Sebastian Lautz","Aleksandar Kolev"],"url":"https://arxiv.org/abs/2407.03185"}
{"created":"2025-04-22","title":"Sparse-DeRF: Deblurred Neural Radiance Fields from Sparse View","abstract":"Recent studies construct deblurred neural radiance fields~(DeRF) using dozens of blurry images, which are not practical scenarios if only a limited number of blurry images are available. This paper focuses on constructing DeRF from sparse-view for more pragmatic real-world scenarios. As observed in our experiments, establishing DeRF from sparse views proves to be a more challenging problem due to the inherent complexity arising from the simultaneous optimization of blur kernels and NeRF from sparse view. Sparse-DeRF successfully regularizes the complicated joint optimization, presenting alleviated overfitting artifacts and enhanced quality on radiance fields. The regularization consists of three key components: Surface smoothness, helps the model accurately predict the scene structure utilizing unseen and additional hidden rays derived from the blur kernel based on statistical tendencies of real-world; Modulated gradient scaling, helps the model adjust the amount of the backpropagated gradient according to the arrangements of scene objects; Perceptual distillation improves the perceptual quality by overcoming the ill-posed multi-view inconsistency of image deblurring and distilling the pre-deblurred information, compensating for the lack of clean information in blurry images. We demonstrate the effectiveness of the Sparse-DeRF with extensive quantitative and qualitative experimental results by training DeRF from 2-view, 4-view, and 6-view blurry images.","authors":["Dogyoon Lee","Donghyeong Kim","Jungho Lee","Minhyeok Lee","Seunghoon Lee","Sangyoun Lee"],"url":"https://arxiv.org/abs/2407.06613"}
{"created":"2025-04-22","title":"Controlling Space and Time with Diffusion Models","abstract":"We present 4DiM, a cascaded diffusion model for 4D novel view synthesis (NVS), supporting generation with arbitrary camera trajectories and timestamps, in natural scenes, conditioned on one or more images. With a novel architecture and sampling procedure, we enable training on a mixture of 3D (with camera pose), 4D (pose+time) and video (time but no pose) data, which greatly improves generalization to unseen images and camera pose trajectories over prior works that focus on limited domains (e.g., object centric). 4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of image fidelity and pose alignment, while also enabling the generation of scene dynamics. 4DiM provides a general framework for a variety of tasks including single-image-to-3D, two-image-to-video (interpolation and extrapolation), and pose-conditioned video-to-video translation, which we illustrate qualitatively on a variety of scenes. For an overview see https://4d-diffusion.github.io","authors":["Daniel Watson","Saurabh Saxena","Lala Li","Andrea Tagliasacchi","David J. Fleet"],"url":"https://arxiv.org/abs/2407.07860"}
{"created":"2025-04-22","title":"Training on the Test Task Confounds Evaluation and Emergence","abstract":"We study a fundamental problem in the evaluation of large language models that we call training on the test task. Unlike wrongful practices like training on the test data, leakage, or data contamination, training on the test task is not a malpractice. Rather, the term describes a growing set of practices that utilize knowledge about evaluation tasks at training time. We demonstrate that training on the test task confounds both relative model evaluations and claims about emergent capabilities. We argue that the seeming superiority of one model family over another may be explained by a different degree of training on the test task. To this end, we propose an effective method to adjust for the effect of training on the test task on benchmark evaluations. Put simply, to fine-tune each model under comparison on the same task-relevant data prior to evaluation. We then show that instances of emergent behavior disappear gradually as models train on the test task. Our work promotes a new perspective on the evaluation of large language models, with broad implications for benchmarking and the study of emergent capabilities.","authors":["Ricardo Dominguez-Olmedo","Florian E. Dorner","Moritz Hardt"],"url":"https://arxiv.org/abs/2407.07890"}
{"created":"2025-04-22","title":"Mon CH\\'ERI: Mitigating Uninitialized Memory Access with Conditional Capabilities","abstract":"Up to 10% of memory-safety vulnerabilities in languages like C and C++ stem from uninitialized variables. This work addresses the prevalence and lack of adequate software mitigations for uninitialized memory issues, proposing architectural protections in hardware. Capability-based addressing, such as the University of Cambridge's CHERI, mitigates many memory defects, including spatial and temporal safety violations at an architectural level. CHERI, however, does not handle undefined behavior from uninitialized variables. We extend the CHERI capability model to include \"conditional capabilities\", enabling memory-access policies based on prior operations. This allows enforcement of policies that satisfy memory-safety objectives such as \"no reads to memory without at least one prior write\" (Write-before-Read). We present our architecture extension, compiler support, and detailed evaluation of our approach on the QEMU full-system simulator and a modified FPGA-based CHERI-RISCV softcore. Our evaluation shows conditional capabilities are practical, with high detection accuracy while adding a small (~3.5%) overhead which is comparable to the cost of baseline CHERI capabilities.","authors":["Merve G\\\"ulmez","H{\\aa}kan Englund","Jan Tobias M\\\"uhlberg","Thomas Nyman"],"url":"https://arxiv.org/abs/2407.08663"}
{"created":"2025-04-22","title":"Distributed computing for physics-based data-driven reduced modeling at scale: Application to a rotating detonation rocket engine","abstract":"High-performance computing (HPC) has revolutionized our ability to perform detailed simulations of complex real-world processes. A prominent contemporary example is from aerospace propulsion, where HPC is used for rotating detonation rocket engine (RDRE) simulations in support of the design of next-generation rocket engines; however, these simulations take millions of core hours even on powerful supercomputers, which makes them impractical for engineering tasks like design exploration and risk assessment. Data-driven reduced-order models (ROMs) aim to address this limitation by constructing computationally cheap yet sufficiently accurate approximations that serve as surrogates for the high-fidelity model. This paper contributes a distributed memory algorithm that achieves fast and scalable construction of predictive physics-based ROMs trained from sparse datasets of extremely large state dimension. The algorithm learns structured physics-based ROMs that approximate the dynamical systems underlying those datasets.This enables model reduction for problems at a scale and complexity that exceeds the capabilities of standard, serial approaches. We demonstrate our algorithm's scalability using up to $2,048$ cores on the Frontera supercomputer at the Texas Advanced Computing Center. We focus on a real-world three-dimensional RDRE for which one millisecond of simulated physical time requires one million core hours on a supercomputer. Using a training dataset of $2,536$ snapshots each of state dimension $76$ million, our distributed algorithm enables the construction of a predictive data-driven reduced model in just $13$ seconds on $2,048$ cores on Frontera.","authors":["Ionut-Gabriel Farcas","Rayomand P. Gundevia","Ramakanth Munipalli","Karen E. Willcox"],"url":"https://arxiv.org/abs/2407.09994"}
{"created":"2025-04-22","title":"Private Estimation when Data and Privacy Demands are Correlated","abstract":"Differential Privacy (DP) is the current gold-standard for ensuring privacy for statistical queries. Estimation problems under DP constraints appearing in the literature have largely focused on providing equal privacy to all users. We consider the problems of empirical mean estimation for univariate data and frequency estimation for categorical data, both subject to heterogeneous privacy constraints. Each user, contributing a sample to the dataset, is allowed to have a different privacy demand. The dataset itself is assumed to be worst-case and we study both problems under two different formulations -- first, where privacy demands and data may be correlated, and second, where correlations are weakened by random permutation of the dataset. We establish theoretical performance guarantees for our proposed algorithms, under both PAC error and mean-squared error. These performance guarantees translate to minimax optimality in several instances, and experiments confirm superior performance of our algorithms over other baseline techniques.","authors":["Syomantak Chaudhuri","Thomas A. Courtade"],"url":"https://arxiv.org/abs/2407.11274"}
{"created":"2025-04-22","title":"Many Perception Tasks are Highly Redundant Functions of their Input Data","abstract":"We show that many perception tasks, from visual recognition, semantic segmentation, optical flow, depth estimation to vocalization discrimination, are highly redundant functions of their input data. Images or spectrograms, projected into different subspaces, formed by orthogonal bases in pixel, Fourier or wavelet domains, can be used to solve these tasks remarkably well regardless of whether it is the top subspace where data varies the most, some intermediate subspace with moderate variability--or the bottom subspace where data varies the least. This phenomenon occurs because different subspaces have a large degree of redundant information relevant to the task.","authors":["Rahul Ramesh","Anthony Bisulco","Ronald W. DiTullio","Linran Wei","Vijay Balasubramanian","Kostas Daniilidis","Pratik Chaudhari"],"url":"https://arxiv.org/abs/2407.13841"}
{"created":"2025-04-22","title":"Prompt Adaptation as a Dynamic Complement in Generative AI Systems","abstract":"As generative AI systems rapidly improve, a key question emerges: How do users keep up-and what happens if they fail to do so. Drawing on theories of dynamic capabilities and IT complements, we examine prompt adaptation-the adjustments users make to their inputs in response to evolving model behavior-as a mechanism that helps determine whether technical advances translate into realized economic value. In a preregistered online experiment with 1,893 participants, who submitted over 18,000 prompts and generated more than 300,000 images, users attempted to replicate a target image in 10 tries using one of three randomly assigned models: DALL-E 2, DALL-E 3, or DALL-E 3 with automated prompt rewriting. We find that users with access to DALL-E 3 achieved higher image similarity than those with DALL-E 2-but only about half of this gain (51%) came from the model itself. The other half (49%) resulted from users adapting their prompts in response to the model's capabilities. This adaptation emerged across the skill distribution, was driven by trial-and-error, and could not be replicated by automated prompt rewriting, which erased 58% of the performance improvement associated with DALL-E 3. Our findings position prompt adaptation as a dynamic complement to generative AI-and suggest that without it, a substantial share of the economic value created when models advance may go unrealized.","authors":["Eaman Jahani","Benjamin S. Manning","Joe Zhang","Hong-Yi TuYe","Mohammed Alsobay","Christos Nicolaides","Siddharth Suri","David Holtz"],"url":"https://arxiv.org/abs/2407.14333"}
{"created":"2025-04-22","title":"Uniqueness of the inverse source problem for fractional diffusion-wave equations","abstract":"This study addresses the inverse source problem for the fractional diffusion-wave equation, characterized by a source comprising spatial and temporal components. The investigation is primarily concerned with practical scenarios where data is collected subsequent to an incident. We establish the uniqueness of either the spatial or the temporal component of the source, provided that the temporal component exhibits an asymptotic expansion at infinity. Taking anomalous diffusion as a typical example, we gather the asymptotic behavior of one of the following quantities: the concentration on partial interior region or at a point inside the region, or the flux on partial boundary or at a point on the boundary. The proof is based on the asymptotic expansion of the solution to the fractional diffusion-wave equation. Notably, our approach does not rely on the conventional vanishing conditions for the source components. We also observe that the extent of uniqueness is dependent on the fractional order.","authors":["Lingyun Qiu","Jiwoon Sim"],"url":"https://arxiv.org/abs/2407.14413"}
{"created":"2025-04-22","title":"OpenHands: An Open Platform for AI Software Developers as Generalist Agents","abstract":"Software is one of the most powerful tools that we humans have at our disposal; it allows a skilled programmer to interact with the world in complex and profound ways. At the same time, thanks to improvements in large language models (LLMs), there has also been a rapid development in AI agents that interact with and affect change in their surrounding environments. In this paper, we introduce OpenHands (f.k.a. OpenDevin), a platform for the development of powerful and flexible AI agents that interact with the world in similar ways to those of a human developer: by writing code, interacting with a command line, and browsing the web. We describe how the platform allows for the implementation of new agents, safe interaction with sandboxed environments for code execution, coordination between multiple agents, and incorporation of evaluation benchmarks. Based on our currently incorporated benchmarks, we perform an evaluation of agents over 15 challenging tasks, including software engineering (e.g., SWE-BENCH) and web browsing (e.g., WEBARENA), among others. Released under the permissive MIT license, OpenHands is a community project spanning academia and industry with more than 2.1K contributions from over 188 contributors.","authors":["Xingyao Wang","Boxuan Li","Yufan Song","Frank F. Xu","Xiangru Tang","Mingchen Zhuge","Jiayi Pan","Yueqi Song","Bowen Li","Jaskirat Singh","Hoang H. Tran","Fuqiang Li","Ren Ma","Mingzhang Zheng","Bill Qian","Yanjun Shao","Niklas Muennighoff","Yizhe Zhang","Binyuan Hui","Junyang Lin","Robert Brennan","Hao Peng","Heng Ji","Graham Neubig"],"url":"https://arxiv.org/abs/2407.16741"}
{"created":"2025-04-22","title":"Large Language Model for Verilog Generation with Code-Structure-Guided Reinforcement Learning","abstract":"Recent advancements in large language models (LLMs) have sparked significant interest in the automatic generation of Register Transfer Level (RTL) designs, particularly using Verilog. Current research on this topic primarily focuses on pre-training and instruction tuning, but the effectiveness of these methods is constrained by the limited availability of training data, as public Verilog code is far less abundant than software code. In particular, these methods struggle to effectively capture Verilog parallel code structures, which fundamentally differ from the imperative, sequential control flow typical in most software programming languages. This paper introduces VeriSeek, an LLM enhanced by reinforcement learning using a limited amount of high-quality training data to achieve high Verilog code generation performance. Our reinforcement learning approach employs code structure information as feedback signals to refine the pre-trained model, enabling it to effectively learn important patterns from Verilog code with parallel structures. Experiments show that VeriSeek outperforms state-of-the-art methods across multiple benchmarks.","authors":["Ning Wang","Bingkun Yao","Jie Zhou","Xi Wang","Zhe Jiang","Nan Guan"],"url":"https://arxiv.org/abs/2407.18271"}
{"created":"2025-04-22","title":"Adaptive Mix for Semi-Supervised Medical Image Segmentation","abstract":"Mix-up is a key technique for consistency regularization-based semi-supervised learning methods, blending two or more images to generate strong-perturbed samples for strong-weak pseudo supervision. Existing mix-up operations are performed either randomly or with predefined fixed rules, such as replacing low-confidence patches with high-confidence ones. The former lacks control over the perturbation degree, leading to overfitting on randomly perturbed samples, while the latter tends to generate images with trivial perturbations, both of which limit the effectiveness of consistency regularization. This paper aims to answer the following question: How can image mix-up perturbation be adaptively performed during training? To this end, we propose an Adaptive Mix algorithm (AdaMix) for image mix-up in a self-paced learning manner. Given that, in general, a model's performance gradually improves during training, AdaMix is equipped with a self-paced curriculum that, in the initial training stage, provides relatively simple perturbed samples and then gradually increases the difficulty of perturbed images by adaptively controlling the perturbation degree based on the model's learning state estimated by a self-paced regularize. We develop three frameworks with our AdaMix, i.e., AdaMix-ST, AdaMix-MT, and AdaMix-CT, for semi-supervised medical image segmentation. Extensive experiments on three public datasets show that the proposed frameworks can achieve superior performance. For example, compared with the state-of-the-art, AdaMix-CT achieves relative improvements of 2.62% in Dice similarity coefficient and 48.25% in average surface distance on the ACDC dataset with 10% labeled data. The results demonstrate that mix-up operations with dynamically adjusted perturbation strength based on the segmentation model's state can significantly enhance the effectiveness of consistency regularization.","authors":["Zhiqiang Shen","Peng Cao","Junming Su","Jinzhu Yang","Osmar R. Zaiane"],"url":"https://arxiv.org/abs/2407.21586"}
{"created":"2025-04-22","title":"Stop-and-go wave super-resolution reconstruction via iterative refinement","abstract":"Stop-and-go waves are a fundamental phenomenon in freeway traffic flow, contributing to inefficiencies, crashes, and emissions. Recent advancements in high-fidelity sensor technologies have improved the ability to capture detailed traffic dynamics, yet such systems remain scarce and costly. In contrast, conventional traffic sensors are widely deployed but suffer from relatively coarse-grain data resolution, potentially impeding accurate analysis of stop-and-go waves. This article explores whether generative AI models can enhance the resolution of conventional traffic sensor to approximate the quality of high-fidelity observations. We present a novel approach using a conditional diffusion denoising model, designed to reconstruct fine-grained traffic speed field from radar-based conventional sensors via iterative refinement. We introduce a new dataset, I24-WaveX, comprising 132 hours of data from both low and high-fidelity sensor systems, totaling over 2 million vehicle miles traveled. Our approach leverages this dataset to formulate the traffic measurement enhancement problem as a spatio-temporal super-resolution task. We demonstrate that our model can effectively reproduce the patterns of stop-and-go waves, achieving high accuracy in capturing these critical traffic dynamics. Our results show promising advancements in traffic data enhancement, offering a cost-effective way to leverage existing low spatio-temporal resolution sensor networks for improved traffic analysis and management. We also open-sourced our trained model and code to facilitate further research and applications.","authors":["Junyi Ji","Alex Richardson","Derek Gloudemans","Gergely Zach\\'ar","Matthew Nice","William Barbour","Jonathan Sprinkle","Benedetto Piccoli","Daniel B. Work"],"url":"https://arxiv.org/abs/2408.00941"}
{"created":"2025-04-22","title":"DNSSEC+: An Enhanced DNS Scheme Motivated by Benefits and Pitfalls of DNSSEC","abstract":"The absence of security and privacy measures between DNS recursive resolvers and authoritative nameservers has been exploited by both on-path and off-path attackers. While many security proposals have been made in practice and in previous literature, they typically face deployability barriers and/or lack a compelling set of security and privacy properties, resulting in limited adoption. We introduce DNSSEC+, a novel DNS scheme designed to mitigate the security and privacy vulnerabilities of the DNS resolution process between resolvers and name servers, while preserving the efficiency of the resolution process by maintaining a single round-trip. DNSSEC+ takes advantage of a hierarchical trust model that does not rely on external entities to DNS zones, but delegates nameserver replicas within a zone to serve zone data securely for short but renewable time intervals, facilitating real-time security properties for DNS messages without requiring long-term private keys to be duplicated (thus exposing to risk) on such replicas. We implement a proof of concept of DNSSEC+ for evaluation and show that for server-side processing latency, resolution time, and CPU usage, DNSSEC+ is comparable to less-secure schemes but significantly outperforms DNS-over-TLS.","authors":["Ali Sadeghi Jahromi","AbdelRahman Abdou","Paul C. van Oorschot"],"url":"https://arxiv.org/abs/2408.00968"}
{"created":"2025-04-22","title":"MCGMark: An Encodable and Robust Online Watermark for Tracing LLM-Generated Malicious Code","abstract":"With the advent of large language models (LLMs), numerous software service providers (SSPs) are dedicated to developing LLMs customized for code generation tasks, such as CodeLlama and Copilot. However, these LLMs can be leveraged by attackers to create malicious software, which may pose potential threats to the software ecosystem. For example, they can automate the creation of advanced phishing malware. To address this issue, we first conduct an empirical study and design a prompt dataset, MCGTest, which involves approximately 400 person-hours of work and consists of 406 malicious code generation tasks. Utilizing this dataset, we propose MCGMark, the first robust, code structure-aware, and encodable watermarking approach to trace LLM-generated code. We embed encodable information by controlling the token selection and ensuring the output quality based on probabilistic outliers. Additionally, we enhance the robustness of the watermark by considering the structural features of malicious code, preventing the embedding of the watermark in easily modified positions, such as comments. We validate the effectiveness and robustness of MCGMark on the DeepSeek-Coder. MCGMark achieves an embedding success rate of 88.9% within a maximum output limit of 400 tokens. Furthermore, it also demonstrates strong robustness and has minimal impact on the quality of the output code. Our approach assists SSPs in tracing and holding responsible parties accountable for malicious code generated by LLMs.","authors":["Kaiwen Ning","Jiachi Chen","Qingyuan Zhong","Tao Zhang","Yanlin Wang","Wei Li","Jingwen Zhang","Jianxing Yu","Yuming Feng","Weizhe Zhang","Zibin Zheng"],"url":"https://arxiv.org/abs/2408.01354"}
{"created":"2025-04-22","title":"Data-Driven Stochastic Closure Modeling via Conditional Diffusion Model and Neural Operator","abstract":"Closure models are widely used in simulating complex multiscale dynamical systems such as turbulence and the earth system, for which direct numerical simulation that resolves all scales is often too expensive. For those systems without a clear scale separation, deterministic and local closure models often lack enough generalization capability, which limits their performance in many real-world applications. In this work, we propose a data-driven modeling framework for constructing stochastic and non-local closure models via conditional diffusion model and neural operator. Specifically, the Fourier neural operator is incorporated into a score-based diffusion model, which serves as a data-driven stochastic closure model for complex dynamical systems governed by partial differential equations (PDEs). We also demonstrate how accelerated sampling methods can improve the efficiency of the data-driven stochastic closure model. The results show that the proposed methodology provides a systematic approach via generative machine learning techniques to construct data-driven stochastic closure models for multiscale dynamical systems with continuous spatiotemporal fields.","authors":["Xinghao Dong","Chuanqi Chen","Jin-Long Wu"],"url":"https://arxiv.org/abs/2408.02965"}
{"created":"2025-04-22","title":"COARA will not save science from the tyranny of administrative evaluation","abstract":"The Coalition for Advancing Research Assessment (CoARA) agreement is a cornerstone in the ongoing efforts to reform research evaluation. CoARA advocates for administrative evaluations of research that rely on peer review, supported by responsible metrics, as beneficial for both science and society. Its principles can be critically examined through the lens of Philip Kitcher's concept of well-ordered science in a democratic society. From Kitcher's perspective, CoARA's approach faces two significant challenges: definitions of quality and impact are determined by governments or evaluation institutions rather than emerging from broad public deliberation, and a select group of scientists is empowered to assess research based on these predefined criteria. This creates susceptibility to both the ''tyranny of expertise'' and the ''tyranny of ignorance'' that Kitcher cautions against. Achieving Kitcher's ideal would require limiting administrative evaluations to essential tasks, such as researcher recruitment and project funding, while establishing procedures grounded in principles of fairness.","authors":["Alberto Baccini"],"url":"https://arxiv.org/abs/2408.05587"}
{"created":"2025-04-22","title":"IFShip: Interpretable Fine-grained Ship Classification with Domain Knowledge-Enhanced Vision-Language Models","abstract":"End-to-end interpretation currently dominates the remote sensing fine-grained ship classification (RS-FGSC) task. However, the inference process remains uninterpretable, leading to criticisms of these models as \"black box\" systems. To address this issue, we propose a domain knowledge-enhanced Chain-of-Thought (CoT) prompt generation mechanism, which is used to semi-automatically construct a task-specific instruction-following dataset, TITANIC-FGS. By training on TITANIC-FGS, we adapt general-domain vision-language models (VLMs) to the FGSC task, resulting in a model named IFShip. Building upon IFShip, we develop an FGSC visual chatbot that redefines the FGSC problem as a step-by-step reasoning task and conveys the reasoning process in natural language. Experimental results show that IFShip outperforms state-of-the-art FGSC algorithms in both interpretability and classification accuracy. Furthermore, compared to VLMs such as LLaVA and MiniGPT-4, IFShip demonstrates superior performance on the FGSC task. It provides an accurate chain of reasoning when fine-grained ship types are recognizable to the human eye and offers interpretable explanations when they are not. Our dataset is publicly available at: https://github.com/lostwolves/IFShip.","authors":["Mingning Guo","Mengwei Wu","Yuxiang Shen","Haifeng Li","Chao Tao"],"url":"https://arxiv.org/abs/2408.06631"}
{"created":"2025-04-22","title":"Joint Graph Rewiring and Feature Denoising via Spectral Resonance","abstract":"When learning from graph data, the graph and the node features both give noisy information about the node labels. In this paper we propose an algorithm to jointly denoise the features and rewire the graph (JDR), which improves the performance of downstream node classification graph neural nets (GNNs). JDR works by aligning the leading spectral spaces of graph and feature matrices. It approximately solves the associated non-convex optimization problem in a way that handles graphs with multiple classes and different levels of homophily or heterophily. We theoretically justify JDR in a stylized setting and show that it consistently outperforms existing rewiring methods on a wide range of synthetic and real-world node classification tasks.","authors":["Jonas Linkerh\\\"agner","Cheng Shi","Ivan Dokmani\\'c"],"url":"https://arxiv.org/abs/2408.07191"}
{"created":"2025-04-22","title":"$\\mathcal{H}_2$-optimal Model Reduction of Linear Quadratic Output Systems in Finite Frequency Range","abstract":"In frequency-limited model order reduction, the objective is to maintain the frequency response of the original system within a specified frequency range in the reduced-order model. In this paper, a mathematical expression for the frequency-limited $\\mathcal{H}_2$ norm is derived, which quantifies the error within the desired frequency interval. Subsequently, the necessary conditions for a local optimum of the frequency-limited $\\mathcal{H}_2$ norm of the error are derived. The inherent difficulty in satisfying these conditions within a Petrov-Galerkin projection framework is also discussed. Using the optimality conditions and the Petrov-Galerkin projection, a stationary point iteration algorithm is proposed, which approximately satisfies these optimality conditions upon convergence. The main computational effort in the proposed algorithm involves solving sparse-dense Sylvester equations. These equations are frequently encountered in $\\mathcal{H}_2$ model order reduction algorithms and can be solved efficiently. Moreover, the algorithm bypasses the requirement of matrix logarithm computation, which is typically necessary for most frequency-limited reduction methods and can be computationally demanding for high-order systems. An illustrative example is provided to numerically validate the developed theory. The proposed algorithm's effectiveness in accurately approximating the original high-order model within the specified frequency range is demonstrated through the reduction of an advection-diffusion equation-based model, commonly used in model reduction literature for testing algorithms. Additionally, the algorithm's computational efficiency is highlighted by successfully reducing a flexible space structure model of order one million.","authors":["Umair Zulfiqar","Zhi-Hua Xiao","Qiu-Yan Song","Mohammad Monir Uddin","Victor Sreeram"],"url":"https://arxiv.org/abs/2408.07939"}
{"created":"2025-04-22","title":"Enhancing Audio-Language Models through Self-Supervised Post-Training with Text-Audio Pairs","abstract":"Research on multi-modal contrastive learning strategies for audio and text has rapidly gained interest. Contrastively trained Audio-Language Models (ALMs), such as CLAP, which establish a unified representation across audio and language modalities, have enhanced the efficacy in various subsequent tasks by providing good text aligned audio encoders and vice versa. These improvements are evident in areas like zero-shot audio classification and audio retrieval, among others. However, the ability of these models to understand natural language and temporal relations is still a largely unexplored and open field for research. In this paper, we propose to equip the multi-modal ALMs with temporal understanding without loosing their inherent prior capabilities of audio-language tasks with a temporal instillation method TeminAL. We implement a two-stage training scheme TeminAL A $\\&$ B, where the model first learns to differentiate between multiple sounds in TeminAL A, followed by a phase that instills a sense of time, thereby enhancing its temporal understanding in TeminAL B. This approach results in an average performance gain of $5.28\\%$ in temporal understanding on the ESC-50 dataset, while the model remains competitive in zero-shot retrieval and classification tasks on the AudioCap/Clotho datasets. We also note the lack of proper evaluation techniques for contrastive ALMs and propose a strategy for evaluating ALMs in zero-shot settings. The general-purpose zero-shot model evaluation strategy ZSTE, is used to evaluate various prior models. ZSTE demonstrates a general strategy to evaluate all ZS contrastive models. The model trained with TeminAL successfully outperforms current models on most downstream tasks.","authors":["Anshuman Sinha","Camille Migozzi","Aubin Rey","Chao Zhang"],"url":"https://arxiv.org/abs/2408.09269"}
{"created":"2025-04-22","title":"Accelerating Goal-Conditioned RL Algorithms and Research","abstract":"Self-supervision has the potential to transform reinforcement learning (RL), paralleling the breakthroughs it has enabled in other areas of machine learning. While self-supervised learning in other domains aims to find patterns in a fixed dataset, self-supervised goal-conditioned reinforcement learning (GCRL) agents discover new behaviors by learning from the goals achieved during unstructured interaction with the environment. However, these methods have failed to see similar success, both due to a lack of data from slow environment simulations as well as a lack of stable algorithms. We take a step toward addressing both of these issues by releasing a high-performance codebase and benchmark (JaxGCRL) for self-supervised GCRL, enabling researchers to train agents for millions of environment steps in minutes on a single GPU. By utilizing GPU-accelerated replay buffers, environments, and a stable contrastive RL algorithm, we reduce training time by up to $22\\times$. Additionally, we assess key design choices in contrastive RL, identifying those that most effectively stabilize and enhance training performance. With this approach, we provide a foundation for future research in self-supervised GCRL, enabling researchers to quickly iterate on new ideas and evaluate them in diverse and challenging environments. Website + Code: https://github.com/MichalBortkiewicz/JaxGCRL","authors":["Micha{\\l} Bortkiewicz","W{\\l}adys{\\l}aw Pa{\\l}ucki","Vivek Myers","Tadeusz Dziarmaga","Tomasz Arczewski","{\\L}ukasz Kuci\\'nski","Benjamin Eysenbach"],"url":"https://arxiv.org/abs/2408.11052"}
{"created":"2025-04-22","title":"PooDLe: Pooled and dense self-supervised learning from naturalistic videos","abstract":"Self-supervised learning has driven significant progress in learning from single-subject, iconic images. However, there are still unanswered questions about the use of minimally-curated, naturalistic video data, which contain dense scenes with many independent objects, imbalanced class distributions, and varying object sizes. In this paper, we propose PooDLe, a self-supervised learning method that combines an invariance-based objective on pooled representations with a dense SSL objective that enforces equivariance to optical flow warping. Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos. We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset, demonstrating its ability to capture spatial understanding from a dense objective and semantic understanding via a pooled representation objective.","authors":["Alex N. Wang","Christopher Hoang","Yuwen Xiong","Yann LeCun","Mengye Ren"],"url":"https://arxiv.org/abs/2408.11208"}
{"created":"2025-04-22","title":"Real-Time Rendering of Glints in the Presence of Area Lights","abstract":"Many real-world materials are characterized by a glittery appearance. Reproducing this effect in physically based renderings is a challenging problem due to its discrete nature, especially in real-time applications which require a consistently low runtime. Recent work focuses on glittery appearance illuminated by infinitesimally small light sources only. For light sources like the sun this approximation is a reasonable choice. In the real world however, all light sources are fundamentally area light sources. In this paper, we derive an efficient method for rendering glints illuminated by spatially constant diffuse area lights in real time. To this end, we require an adequate estimate for the probability of a single microfacet to be correctly oriented for reflection from the source to the observer. A good estimate is achieved either using linearly transformed cosines (LTC) for large light sources, or a locally constant approximation of the normal distribution for small spherical caps of light directions. To compute the resulting number of reflecting microfacets, we employ a counting model based on the binomial distribution. In the evaluation, we demonstrate the visual accuracy of our approach, which is easily integrated into existing real-time rendering frameworks, especially if they already implement shading for area lights using LTCs and a counting model for glint shading under point and directional illumination. Besides the overhead of the preexisting constituents, our method adds little to no additional overhead.","authors":["Tom Kneiphof","Reinhard Klein"],"url":"https://arxiv.org/abs/2408.13611"}
{"created":"2025-04-22","title":"An optimization-based coupling of reduced order models with efficient reduced adjoint basis generation approach","abstract":"Optimization-based coupling (OBC) is an attractive alternative to traditional Lagrange multiplier approaches in multiple modeling and simulation contexts. However, application of OBC to time-dependent problems has been hindered by the computational cost of finding the stationary points of the associated Lagrangian, which requires primal and adjoint solves. This issue can be mitigated by using OBC in conjunction with computationally efficient reduced order models (ROM). To demonstrate the potential of this combination, in this paper we develop an optimization-based ROM-ROM coupling for a transient advection-diffusion transmission problem. We pursue the ``optimize-then-reduce'' path towards solving the minimization problem at each timestep and solve reduced-space adjoint system of equations, where the main challenge in this formulation is the generation of adjoint snapshots and reduced bases for the adjoint systems required by the optimizer. One of the main contributions of the paper is a new technique for efficient adjoint snapshot collection for gradient-based optimizers in the context of optimization-based ROM-ROM couplings. We present numerical studies demonstrating the accuracy of the approach along with comparison between various approaches for selecting a reduced order basis for the adjoint systems, including decay of snapshot energy, average iteration counts, and timings.","authors":["Elizabeth Hawkins","Paul Kuberry","Pavel Bochev"],"url":"https://arxiv.org/abs/2408.14450"}
{"created":"2025-04-22","title":"DualKanbaFormer: An Efficient Selective Sparse Framework for Multimodal Aspect-based Sentiment Analysis","abstract":"Multimodal Aspect-based Sentiment Analysis (MABSA) enhances sentiment detection by integrating textual data with complementary modalities, such as images, to provide a more refined and comprehensive understanding of sentiment. However, conventional attention mechanisms, despite notable benchmarks, are hindered by quadratic complexity, limiting their ability to fully capture global contextual dependencies and rich semantic information in both modalities. To address this limitation, we introduce DualKanbaFormer, a novel framework that leverages parallel Textual and Visual KanbaFormer modules for robust multimodal analysis. Our approach incorporates Aspect-Driven Sparse Attention (ADSA) to dynamically balance coarse-grained aggregation and fine-grained selection for aspect-focused precision, ensuring the preservation of both global context awareness and local precision in textual and visual representations. Additionally, we utilize the Selective State Space Model (Mamba) to capture extensive global semantic information across both modalities. Furthermore, We replace traditional feed-forward networks and normalization with Kolmogorov-Arnold Networks (KANs) and Dynamic Tanh (DyT) to enhance non-linear expressivity and inference stability. To facilitate the effective integration of textual and visual features, we design a multimodal gated fusion layer that dynamically optimizes inter-modality interactions, significantly enhancing the models efficacy in MABSA tasks. Comprehensive experiments on two publicly available datasets reveal that DualKanbaFormer consistently outperforms several state-of-the-art (SOTA) models.","authors":["Adamu Lawan","Juhua Pu","Haruna Yunusa","Muhammad Lawan","Aliyu Umar","Adamu Sani Yahya","Mahmoud Basi"],"url":"https://arxiv.org/abs/2408.15379"}
{"created":"2025-04-22","title":"OmniRe: Omni Urban Scene Reconstruction","abstract":"We introduce OmniRe, a comprehensive system for efficiently creating high-fidelity digital twins of dynamic real-world scenes from on-device logs. Recent methods using neural fields or Gaussian Splatting primarily focus on vehicles, hindering a holistic framework for all dynamic foregrounds demanded by downstream applications, e.g., the simulation of human behavior. OmniRe extends beyond vehicle modeling to enable accurate, full-length reconstruction of diverse dynamic objects in urban scenes. Our approach builds scene graphs on 3DGS and constructs multiple Gaussian representations in canonical spaces that model various dynamic actors, including vehicles, pedestrians, cyclists, and others. OmniRe allows holistically reconstructing any dynamic object in the scene, enabling advanced simulations (~60Hz) that include human-participated scenarios, such as pedestrian behavior simulation and human-vehicle interaction. This comprehensive simulation capability is unmatched by existing methods. Extensive evaluations on the Waymo dataset show that our approach outperforms prior state-of-the-art methods quantitatively and qualitatively by a large margin. We further extend our results to 5 additional popular driving datasets to demonstrate its generalizability on common urban scenes.","authors":["Ziyu Chen","Jiawei Yang","Jiahui Huang","Riccardo de Lutio","Janick Martinez Esturo","Boris Ivanovic","Or Litany","Zan Gojcic","Sanja Fidler","Marco Pavone","Li Song","Yue Wang"],"url":"https://arxiv.org/abs/2408.16760"}
{"created":"2025-04-22","title":"Language-guided Scale-aware MedSegmentor for Lesion Segmentation in Medical Imaging","abstract":"In clinical practice, segmenting specific lesions based on the needs of physicians can significantly enhance diagnostic accuracy and treatment efficiency. However, conventional lesion segmentation models lack the flexibility to distinguish lesions according to specific requirements. Given the practical advantages of using text as guidance, we propose a novel model, Language-guided Scale-aware MedSegmentor (LSMS), which segments target lesions in medical images based on given textual expressions. We define this as a new task termed Referring Lesion Segmentation (RLS). To address the lack of suitable benchmarks for RLS, we construct a vision-language medical dataset named Reference Hepatic Lesion Segmentation (RefHL-Seg). LSMS incorporates two key designs: (i) Scale-Aware Vision-Language attention module, which performs visual feature extraction and vision-language alignment in parallel. By leveraging diverse convolutional kernels, this module acquires rich visual representations and interacts closely with linguistic features, thereby enhancing the model's capacity for precise object localization. (ii) Full-Scale Decoder, which globally models multi-modal features across multiple scales and captures complementary information between them to accurately delineate lesion boundaries. Additionally, we design a specialized loss function comprising both segmentation loss and vision-language contrastive loss to better optimize cross-modal learning. We validate the performance of LSMS on RLS as well as on conventional lesion segmentation tasks across multiple datasets. Our LSMS consistently achieves superior performance with significantly lower computational cost. Code and datasets will be released.","authors":["Shuyi Ouyang","Jinyang Zhang","Xiangye Lin","Xilai Wang","Qingqing Chen","Yen-Wei Chen","Lanfen Lin"],"url":"https://arxiv.org/abs/2408.17347"}
{"created":"2025-04-22","title":"Self-evolving Agents with reflective and memory-augmented abilities","abstract":"Large language models (LLMs) have made significant advances in the field of natural language processing, but they still face challenges such as continuous decision-making. In this research, we propose a novel framework by integrating iterative feedback, reflective mechanisms, and a memory optimization mechanism based on the Ebbinghaus forgetting curve, it significantly enhances the agents' capabilities in handling multi-tasking and long-span information.","authors":["Xuechen Liang","Yangfan He","Yinghui Xia","Xinyuan Song","Jianhui Wang","Meiling Tao","Li Sun","Xinhang Yuan","Jiayi Su","Keqin Li","Jiaqi Chen","Jinsong Yang","Siyuan Chen","Tianyu Shi"],"url":"https://arxiv.org/abs/2409.00872"}
{"created":"2025-04-22","title":"Task-Specific Directions: Definition, Exploration, and Utilization in Parameter Efficient Fine-Tuning","abstract":"Large language models demonstrate impressive performance on downstream tasks, yet they require extensive resource consumption when fully fine-tuning all parameters. To mitigate this, Parameter Efficient Fine-Tuning (PEFT) strategies, such as LoRA, have been developed. In this paper, we delve into the concept of task-specific directions (TSDs), which are critical for transitioning large models from pretrained states to task-specific enhancements in PEFT. We propose a framework to clearly define these directions and explore their properties and practical utilization challenges. We then introduce a novel approach, LoRA-Dash, which aims to maximize the impact of TSDs during the fine-tuning process, thereby enhancing model performance on targeted tasks. Additionally, based on our exploration of TSD, we focus on an important issue in PEFT: the initialization of LoRA. While some works have pointed out the significance of initialization for LoRA's performance and proposed various strategies, these methods are often empirical and not task-specific. To address this issue, we propose LoRA-Init. Starting from TSD, we identify the directions that require the most adjustment during fine-tuning for downstream tasks. By initializing the matrices in LoRA with these directions, LoRA-Init significantly enhances LoRA's performance. Moreover, we can combine LoRA-Dash and LoRA-Init to create the final version of LoRA based on TSDs, which we refer to as LoRA-TSD. Extensive experiments have conclusively demonstrated the effectiveness of these methods, and in-depth analyses further reveal the underlying mechanisms behind their success.","authors":["Chongjie Si","Zhiyi Shi","Shifan Zhang","Xiaokang Yang","Hanspeter Pfister","Wei Shen"],"url":"https://arxiv.org/abs/2409.01035"}
{"created":"2025-04-22","title":"Teen Talk: The Good, the Bad, and the Neutral of Adolescent Social Media Use","abstract":"The debate on whether social media has a net positive or negative effect on youth is ongoing. Therefore, we conducted a thematic analysis on 2,061 posts made by 1,038 adolescents aged 15-17 on an online peer-support platform to investigate the ways in which these teens discussed popular social media platforms in their posts and to identify differences in their experiences across platforms. Our findings revealed four main emergent themes for the ways in which social media was discussed: 1) Sharing negative experiences or outcomes of social media use (58%, n = 1,095), 2) Attempts to connect with others (45%, n = 922), 3) Highlighting the positive side of social media use (20%, n = 409), and 4) Seeking information (20%, n = 491). Overall, while sharing about negative experiences was more prominent, teens also discussed balanced perspectives of connection-seeking, positive experiences, and information support on social media that should not be discounted. Moreover, we found statistical significance for how these experiences differed across social media platforms. For instance, teens were most likely to seek romantic relationships on Snapchat and self-promote on YouTube. Meanwhile, Instagram was mentioned most frequently for body shaming, and Facebook was the most commonly discussed platform for privacy violations (mostly from parents). The key takeaway from our study is that the benefits and drawbacks of teens' social media usage can co-exist and net effects (positive or negative) can vary across different teens across various contexts. As such, we advocate for mitigating the negative experiences and outcomes of social media use as voiced by teens, to improve, rather than limit or restrict, their overall social media experience. We do this by taking an affordance perspective that aims to promote the digital well-being and online safety of youth \"by design.\"","authors":["Abdulmalik Alluhidan","Mamtaj Akter","Ashwaq Alsoubai","Jinkyung Park","Pamela Wisniewski"],"url":"https://arxiv.org/abs/2409.02358"}
{"created":"2025-04-22","title":"Examining Caregiving Roles to Differentiate the Effects of Using a Mobile App for Community Oversight for Privacy and Security","abstract":"We conducted a 4-week field study with 101 smartphone users who self-organized into 22 small groups of family, friends, and neighbors to use ``CO-oPS,'' a mobile app for co-managing mobile privacy and security. We differentiated between those who provided oversight (i.e., caregivers) and those who did not (i.e., caregivees) to examine differential effects on their experiences and behaviors while using CO-oPS. Caregivers reported higher power use, community trust, belonging, collective efficacy, and self-efficacy than caregivees. Both groups' self-efficacy and collective efficacy for mobile privacy and security increased after using CO-oPS. However, this increase was significantly stronger for caregivees. Our research demonstrates how community-based approaches can benefit people who need additional help managing their digital privacy and security. We provide recommendations to support community-based oversight for managing privacy and security within communities of different roles and skills.","authors":["Mamtaj Akter","Jess Kropczynski","Heather Lipford","Pamela Wisniewski"],"url":"https://arxiv.org/abs/2409.02364"}
{"created":"2025-04-22","title":"Hybrid Imitation-Learning Motion Planner for Urban Driving","abstract":"With the release of open source datasets such as nuPlan and Argoverse, the research around learning-based planners has spread a lot in the last years. Existing systems have shown excellent capabilities in imitating the human driver behaviour, but they struggle to guarantee safe closed-loop driving. Conversely, optimization-based planners offer greater security in short-term planning scenarios. To confront this challenge, in this paper we propose a novel hybrid motion planner that integrates both learning-based and optimization-based techniques. Initially, a multilayer perceptron (MLP) generates a human-like trajectory, which is then refined by an optimization-based component. This component not only minimizes tracking errors but also computes a trajectory that is both kinematically feasible and collision-free with obstacles and road boundaries. Our model effectively balances safety and human-likeness, mitigating the trade-off inherent in these objectives. We validate our approach through simulation experiments and further demonstrate its efficacy by deploying it in real-world self-driving vehicles.","authors":["Cristian Gariboldi","Matteo Corno","Beng Jin"],"url":"https://arxiv.org/abs/2409.02871"}
{"created":"2025-04-22","title":"Minimization of the Pseudospectral Abscissa of a Quadratic Matrix Polynomial","abstract":"For a quadratic matrix polynomial dependent on parameters and a given tolerance $\\epsilon > 0$, the minimization of the $\\epsilon$-pseudospectral abscissa over the set of permissible parameter values is discussed, with applications in damping optimization and brake squeal reductions in mind. An approach is introduced that is based on nonsmooth and global optimization (or smooth optimization techniques such as BFGS if there are many parameters) equipped with a globally convergent criss-cross algorithm to compute the $\\epsilon$-pseudospectral abscissa objective when the matrix polynomial is of small size. For the setting when the matrix polynomial is large, a subspace framework is introduced, and it is argued formally that it solves the minimization problem globally. The subspace framework restricts the parameter-dependent matrix polynomial to small subspaces, and thus solves the minimization problem for such restricted small matrix polynomials. It then expands the subspaces using the minimizers for the restricted polynomials. The proposed approach makes the global minimization of the $\\epsilon$-pseudospectral abscissa possible for a quadratic matrix polynomial dependent on a few parameters and for sizes up to at least a few hundreds. This is illustrated on several examples originating from damping optimization.","authors":["Volker Mehrmann","Emre Mengi"],"url":"https://arxiv.org/abs/2409.04297"}
{"created":"2025-04-22","title":"Seek and Solve Reasoning for Table Question Answering","abstract":"The complexities of table structures and question logic make table-based question answering (TQA) tasks challenging for Large Language Models (LLMs), often requiring task simplification before solving. This paper reveals that the reasoning process during task simplification may be more valuable than the simplified tasks themselves and aims to improve TQA performance by leveraging LLMs' reasoning capabilities. We propose a Seek-and-Solve pipeline that instructs the LLM to first seek relevant information and then answer questions, integrating these two stages at the reasoning level into a coherent Seek-and-Solve Chain of Thought (SS-CoT). Additionally, we distill a single-step TQA-solving prompt from this pipeline, using demonstrations with SS-CoT paths to guide the LLM in solving complex TQA tasks under In-Context Learning settings. Our experiments show that our approaches result in improved performance and reliability while being efficient. Our findings emphasize the importance of eliciting LLMs' reasoning capabilities to handle complex TQA tasks effectively.","authors":["Ruya Jiang","Chun Wang","Weihong Deng"],"url":"https://arxiv.org/abs/2409.05286"}
{"created":"2025-04-22","title":"MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders","abstract":"The rapid advancements in large language models (LLMs) have significantly enhanced natural language processing capabilities, facilitating the development of AudioLLMs that process and understand speech and audio inputs alongside text. Existing AudioLLMs typically combine a pre-trained audio encoder with a pre-trained LLM, which are subsequently finetuned on specific audio tasks. However, the pre-trained audio encoder has constrained capacity to capture features for new tasks and datasets. To address this, we propose to incorporate mixtures of `weak' encoders (MoWE) into the AudioLLM framework. MoWE supplements a base encoder with a pool of relatively light weight encoders, selectively activated based on the audio input to enhance feature extraction without significantly increasing model size. Our empirical results demonstrate that MoWE effectively improves multi-task performance, broadening the applicability of AudioLLMs to more diverse audio tasks.","authors":["Wenyu Zhang","Shuo Sun","Bin Wang","Xunlong Zou","Zhuohan Liu","Yingxu He","Geyu Lin","Nancy F. Chen","Ai Ti Aw"],"url":"https://arxiv.org/abs/2409.06635"}
{"created":"2025-04-22","title":"Bio-Eng-LMM AI Assist chatbot: A Comprehensive Tool for Research and Education","abstract":"This article introduces Bio-Eng-LMM AI chatbot, a versatile platform designed to enhance user interaction for educational and research purposes. Leveraging cutting-edge open-source Large Language Models (LLMs), Bio-Eng-LMM operates as a sophisticated AI assistant, exploiting the capabilities of traditional models like ChatGPT. Central to Bio-Eng-LMM is its implementation of Retrieval Augmented Generation (RAG) through three primary methods: integration of preprocessed documents, real-time processing of user-uploaded files, and information retrieval from any specified website. Additionally, the chatbot incorporates image generation via a Stable Diffusion Model (SDM), image understanding and response generation through LLAVA, and search functionality on the internet powered by secure search engine such as DuckDuckGo. To provide comprehensive support, Bio-Eng-LMM offers text summarization, website content summarization, and both text and voice interaction. The chatbot maintains session memory to ensure contextually relevant and coherent responses. This integrated platform builds upon the strengths of RAG-GPT and Web-Based RAG Query (WBRQ) where the system fetches relevant information directly from the web to enhance the LLMs response generation.","authors":["Ali Forootani","Danial Esmaeili Aliabadi","Daniela Thraen"],"url":"https://arxiv.org/abs/2409.07110"}
{"created":"2025-04-22","title":"SwinGS: Sliding Window Gaussian Splatting for Volumetric Video Streaming with Arbitrary Length","abstract":"Recent advances in 3D Gaussian Splatting (3DGS) have garnered significant attention in computer vision and computer graphics due to its high rendering speed and remarkable quality. While extant research has endeavored to extend the application of 3DGS from static to dynamic scenes, such efforts have been consistently impeded by excessive model sizes, constraints on video duration, and content deviation. These limitations significantly compromise the streamability of dynamic 3D Gaussian models, thereby restricting their utility in downstream applications, including volumetric video, autonomous vehicle, and immersive technologies such as virtual, augmented, and mixed reality.","authors":["Bangya Liu","Suman Banerjee"],"url":"https://arxiv.org/abs/2409.07759"}
{"created":"2025-04-22","title":"Detecting underdiagnosed medical conditions with opportunistic imaging","abstract":"Abdominal computed tomography (CT) scans are frequently performed in clinical settings. Opportunistic CT involves repurposing routine CT images to extract diagnostic information and is an emerging tool for detecting underdiagnosed conditions such as sarcopenia, hepatic steatosis, and ascites. This study utilizes deep learning methods to promote accurate diagnosis and clinical documentation. We analyze 2,674 inpatient CT scans to identify discrepancies between imaging phenotypes (characteristics derived from opportunistic CT scans) and their corresponding documentation in radiology reports and ICD coding. Through our analysis, we find that only 0.5%, 3.2%, and 30.7% of scans diagnosed with sarcopenia, hepatic steatosis, and ascites (respectively) through either opportunistic imaging or radiology reports were ICD-coded. Our findings demonstrate opportunistic CT's potential to enhance diagnostic precision and accuracy of risk adjustment models, offering advancements in precision medicine.","authors":["Asad Aali","Andrew Johnston","Louis Blankemeier","Dave Van Veen","Laura T Derry","David Svec","Jason Hom","Robert D. Boutin","Akshay S. Chaudhari"],"url":"https://arxiv.org/abs/2409.11686"}
{"created":"2025-04-22","title":"Relevance-driven Decision Making for Safer and More Efficient Human Robot Collaboration","abstract":"Human brain possesses the ability to effectively focus on important environmental components, which enhances perception, learning, reasoning, and decision-making. Inspired by this cognitive mechanism, we introduced a novel concept termed relevance for Human-Robot Collaboration (HRC). Relevance is a dimensionality reduction process that incorporates a continuously operating perception module, evaluates cue sufficiency within the scene, and applies a flexible formulation and computation framework. In this paper, we present an enhanced two-loop framework that integrates real-time and asynchronous processing to quantify relevance and leverage it for safer and more efficient human-robot collaboration (HRC). The two-loop framework integrates an asynchronous loop, which leverages LLM world knowledge to quantify relevance, and a real-time loop, which performs scene understanding, human intent prediction, and decision-making based on relevance. HRC decision-making is enhanced by a relevance-based task allocation method, as well as a motion generation and collision avoidance approach that incorporates human trajectory prediction. Simulations and experiments show that our methodology for relevance quantification can accurately and robustly predict the human objective and relevance, with an average accuracy of up to 0.90 for objective prediction and up to 0.96 for relevance prediction. Moreover, our motion generation methodology reduces collision cases by 63.76% and collision frames by 44.74% when compared with a state-of-the-art (SOTA) collision avoidance method. Our framework and methodologies, with relevance, guide the robot on how to best assist humans and generate safer and more efficient actions for HRC.","authors":["Xiaotong Zhang","Dingcheng Huang","Kamal Youcef-Toumi"],"url":"https://arxiv.org/abs/2409.13998"}
{"created":"2025-04-22","title":"On the Complexity of Neural Computation in Superposition","abstract":"Superposition, the ability of neural networks to represent more features than neurons, is increasingly seen as key to the efficiency of large models. This paper investigates the theoretical foundations of computing in superposition, establishing complexity bounds for explicit, provably correct algorithms.","authors":["Micah Adler","Nir Shavit"],"url":"https://arxiv.org/abs/2409.15318"}
{"created":"2025-04-22","title":"$L_2$-approximation using randomized lattice algorithms","abstract":"We propose a randomized lattice algorithm for approximating multivariate periodic functions over the $d$-dimensional unit cube from the weighted Korobov space with mixed smoothness $\\alpha > 1/2$ and product weights $\\gamma_1,\\gamma_2,\\ldots\\in [0,1]$. Building upon the deterministic lattice algorithm by Kuo, Sloan, and Wo\\'{z}niakowski (2006), we incorporate a randomized quadrature rule by Dick, Goda, and Suzuki (2022) to accelerate the convergence rate. This randomization involves drawing the number of points for function evaluations randomly, and selecting a good generating vector for rank-1 lattice points using the randomized component-by-component algorithm. We prove that our randomized algorithm achieves a worst-case root mean squared $L_2$-approximation error of order $M^{-\\alpha/2 - 1/8 + \\varepsilon}$ for an arbitrarily small $\\varepsilon > 0$, where $M$ denotes the maximum number of function evaluations, and that the error bound is independent of the dimension $d$ if the weights satisfy $\\sum_{j=1}^\\infty \\gamma_j^{1/\\alpha} < \\infty$. Our upper bound converges faster than a lower bound on the worst-case $L_2$-approximation error for deterministic rank-1 lattice-based approximation proved by Byrenheid, K\\\"{a}mmerer, Ullrich, and Volkmer (2017). We also show a lower error bound of order $M^{-\\alpha/2-1/2}$ for our randomized algorithm, leaving a slight gap between the upper and lower bounds open for future research.","authors":["Mou Cai","Takashi Goda","Yoshihito Kazashi"],"url":"https://arxiv.org/abs/2409.18757"}
{"created":"2025-04-22","title":"Edge-preserving noise for diffusion models","abstract":"Classical generative diffusion models learn an isotropic Gaussian denoising process, treating all spatial regions uniformly, thus neglecting potentially valuable structural information in the data. Inspired by the long-established work on anisotropic diffusion in image processing, we present a novel edge-preserving diffusion model that generalizes over existing isotropic models by considering a hybrid noise scheme. In particular, we introduce an edge-aware noise scheduler that varies between edge-preserving and isotropic Gaussian noise. We show that our model's generative process converges faster to results that more closely match the target distribution. We demonstrate its capability to better learn the low-to-mid frequencies within the dataset, which plays a crucial role in representing shapes and structural information. Our edge-preserving diffusion process consistently outperforms state-of-the-art baselines in unconditional image generation. It is also particularly more robust for generative tasks guided by a shape-based prior, such as stroke-to-image generation. We present qualitative and quantitative results (FID and CLIP score) showing consistent improvements of up to 30% for both tasks.","authors":["Jente Vandersanden","Sascha Holl","Xingchang Huang","Gurprit Singh"],"url":"https://arxiv.org/abs/2410.01540"}
{"created":"2025-04-22","title":"Depth Pro: Sharp Monocular Metric Depth in Less Than a Second","abstract":"We present a foundation model for zero-shot metric monocular depth estimation. Our model, Depth Pro, synthesizes high-resolution depth maps with unparalleled sharpness and high-frequency details. The predictions are metric, with absolute scale, without relying on the availability of metadata such as camera intrinsics. And the model is fast, producing a 2.25-megapixel depth map in 0.3 seconds on a standard GPU. These characteristics are enabled by a number of technical contributions, including an efficient multi-scale vision transformer for dense prediction, a training protocol that combines real and synthetic datasets to achieve high metric accuracy alongside fine boundary tracing, dedicated evaluation metrics for boundary accuracy in estimated depth maps, and state-of-the-art focal length estimation from a single image. Extensive experiments analyze specific design choices and demonstrate that Depth Pro outperforms prior work along multiple dimensions. We release code and weights at https://github.com/apple/ml-depth-pro","authors":["Aleksei Bochkovskii","Ama\\\"el Delaunoy","Hugo Germain","Marcel Santos","Yichao Zhou","Stephan R. Richter","Vladlen Koltun"],"url":"https://arxiv.org/abs/2410.02073"}
{"created":"2025-04-22","title":"From Imitation to Exploration: End-to-end Autonomous Driving based on World Model","abstract":"In recent years, end-to-end autonomous driving architectures have gained increasing attention due to their advantage in avoiding error accumulation. Most existing end-to-end autonomous driving methods are based on Imitation Learning (IL), which can quickly derive driving strategies by mimicking expert behaviors. However, IL often struggles to handle scenarios outside the training dataset, especially in high-dynamic and interaction-intensive traffic environments. In contrast, Reinforcement Learning (RL)-based driving models can optimize driving decisions through interaction with the environment, improving adaptability and robustness.","authors":["Yueyuan Li","Mingyang Jiang","Songan Zhang","Wei Yuan","Chunxiang Wang","Ming Yang"],"url":"https://arxiv.org/abs/2410.02253"}
{"created":"2025-04-22","title":"Learning Structured Representations by Embedding Class Hierarchy with Fast Optimal Transport","abstract":"To embed structured knowledge within labels into feature representations, prior work [Zeng et al., 2022] proposed to use the Cophenetic Correlation Coefficient (CPCC) as a regularizer during supervised learning. This regularizer calculates pairwise Euclidean distances of class means and aligns them with the corresponding shortest path distances derived from the label hierarchy tree. However, class means may not be good representatives of the class conditional distributions, especially when they are multi-mode in nature. To address this limitation, under the CPCC framework, we propose to use the Earth Mover's Distance (EMD) to measure the pairwise distances among classes in the feature space. We show that our exact EMD method generalizes previous work, and recovers the existing algorithm when class-conditional distributions are Gaussian. To further improve the computational efficiency of our method, we introduce the Optimal Transport-CPCC family by exploring four EMD approximation variants. Our most efficient OT-CPCC variant, the proposed Fast FlowTree algorithm, runs in linear time in the size of the dataset, while maintaining competitive performance across datasets and tasks. The code is available at https://github.com/uiuctml/OTCPCC.","authors":["Siqi Zeng","Sixian Du","Makoto Yamada","Han Zhao"],"url":"https://arxiv.org/abs/2410.03052"}
{"created":"2025-04-22","title":"Examining Racial Stereotypes in YouTube Autocomplete Suggestions","abstract":"Autocomplete is a popular search feature that predicts queries based on user input and guides users to a set of potentially relevant suggestions. In this study, we examine what YouTube autocompletes suggest to users seeking information about race on the platform. Specifically, we perform an algorithm output audit of autocomplete suggestions for input queries about four racial groups and examine the stereotypes they embody. Using critical discourse analysis, we identify five major sociocultural contexts in which racial information appears -Appearance, Ability, Culture, Social Equity, and Manner. We found that the participatory nature of YouTube produces a multifaceted representation of race-related content in its search outputs, characterized by enduring historical biases, aggregated discrimination, and interracial tensions, while simultaneously depicting minority resistance and aspirations of a post-racial society. We call for innovations in content moderation policy design and enforcement to address existing racial harms in YouTube search outputs.","authors":["Eunbin Ha","Haein Kong","Shagun Jhaver"],"url":"https://arxiv.org/abs/2410.03102"}
{"created":"2025-04-22","title":"A Retention-Centric Framework for Continual Learning with Guaranteed Model Developmental Safety","abstract":"In real-world applications, learning-enabled systems often undergo iterative model development to address challenging or emerging tasks, which involve collecting new data, training a new model and validating the model. This continual model development process raises a significant issue that acquiring new or improving existing capabilities may inadvertently lose good capabilities of the old model, also known as catastrophic forgetting. While existing continual learning aims to mitigate catastrophic forgetting by trading off performance on previous tasks and new tasks to ensure good average performance, it often falls short in cost-sensitive applications, where failing to preserve essential established capabilities introduces unforeseen costs and risks and substantial expenses for re-improving these capabilities. To address this issue, we impose a requirement on learning systems to ensure that a new model strictly retains important capabilities of the old model while improving target-task performance, which we term model developmental safety. To ensure model developmental safety, we propose a retention-centric framework with data-dependent constraints, and study how to continually develop a pretrained CLIP model for acquiring new or improving existing capabilities of image classification. We propose an efficient constrained optimization algorithm with theoretical guarantees and use its insights to finetune the CLIP model with task-dependent heads for promoting the model developmental safety. Experiments on autonomous driving and scene recognition datasets validate the efficacy of our method.","authors":["Gang Li","Wendi Yu","Yao Yao","Wei Tong","Yingbin Liang","Qihang Lin","Tianbao Yang"],"url":"https://arxiv.org/abs/2410.03955"}
{"created":"2025-04-22","title":"Overcoming False Illusions in Real-World Face Restoration with Multi-Modal Guided Diffusion Model","abstract":"We introduce a novel Multi-modal Guided Real-World Face Restoration (MGFR) technique designed to improve the quality of facial image restoration from low-quality inputs. Leveraging a blend of attribute text prompts, high-quality reference images, and identity information, MGFR can mitigate the generation of false facial attributes and identities often associated with generative face restoration methods. By incorporating a dual-control adapter and a two-stage training strategy, our method effectively utilizes multi-modal prior information for targeted restoration tasks. We also present the Reface-HQ dataset, comprising over 21,000 high-resolution facial images across 4800 identities, to address the need for reference face training images. Our approach achieves superior visual quality in restoring facial details under severe degradation and allows for controlled restoration processes, enhancing the accuracy of identity preservation and attribute correction. Including negative quality samples and attribute prompts in the training further refines the model's ability to generate detailed and perceptually accurate images.","authors":["Keda Tao","Jinjin Gu","Yulun Zhang","Xiucheng Wang","Nan Cheng"],"url":"https://arxiv.org/abs/2410.04161"}
{"created":"2025-04-22","title":"Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval","abstract":"Large language models (LLMs) have demonstrated significant potential in clinical decision support. Yet LLMs still suffer from hallucinations and lack fine-grained contextual medical knowledge, limiting their high-stake healthcare applications such as clinical diagnosis. Traditional retrieval-augmented generation (RAG) methods attempt to address these limitations but frequently retrieve sparse or irrelevant information, undermining prediction accuracy. We introduce KARE, a novel framework that integrates knowledge graph (KG) community-level retrieval with LLM reasoning to enhance healthcare predictions. KARE constructs a comprehensive multi-source KG by integrating biomedical databases, clinical literature, and LLM-generated insights, and organizes it using hierarchical graph community detection and summarization for precise and contextually relevant information retrieval. Our key innovations include: (1) a dense medical knowledge structuring approach enabling accurate retrieval of relevant information; (2) a dynamic knowledge retrieval mechanism that enriches patient contexts with focused, multi-faceted medical insights; and (3) a reasoning-enhanced prediction framework that leverages these enriched contexts to produce both accurate and interpretable clinical predictions. Extensive experiments demonstrate that KARE outperforms leading models by up to 10.8-15.0% on MIMIC-III and 12.6-12.7% on MIMIC-IV for mortality and readmission predictions. In addition to its impressive prediction accuracy, our framework leverages the reasoning capabilities of LLMs, enhancing the trustworthiness of clinical predictions.","authors":["Pengcheng Jiang","Cao Xiao","Minhao Jiang","Parminder Bhatia","Taha Kass-Hout","Jimeng Sun","Jiawei Han"],"url":"https://arxiv.org/abs/2410.04585"}
{"created":"2025-04-22","title":"How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension","abstract":"Benchmarking the capabilities and limitations of large language models (LLMs) in graph-related tasks is becoming an increasingly popular and crucial area of research. Recent studies have shown that LLMs exhibit a preliminary ability to understand graph structures and node features. However, the potential of LLMs in graph pattern mining remains largely unexplored. This is a key component in fields such as computational chemistry, biology, and social network analysis. To bridge this gap, this work introduces a comprehensive benchmark to assess LLMs' capabilities in graph pattern tasks. We have developed a benchmark that evaluates whether LLMs can understand graph patterns based on either terminological or topological descriptions. Additionally, our benchmark tests the LLMs' capacity to autonomously discover graph patterns from data. The benchmark encompasses both synthetic and real datasets, and a variety of models, with a total of 11 tasks and 7 models. Our experimental framework is designed for easy expansion to accommodate new models and datasets. Our findings reveal that: (1) LLMs have preliminary abilities to understand graph patterns, with O1-mini outperforming in the majority of tasks; (2) Formatting input data to align with the knowledge acquired during pretraining can enhance performance; (3) The strategies employed by LLMs may differ from those used in conventional algorithms.","authors":["Xinnan Dai","Haohao Qu","Yifen Shen","Bohang Zhang","Qihao Wen","Wenqi Fan","Dongsheng Li","Jiliang Tang","Caihua Shan"],"url":"https://arxiv.org/abs/2410.05298"}
{"created":"2025-04-22","title":"A Skewness-Based Criterion for Addressing Heteroscedastic Noise in Causal Discovery","abstract":"Real-world data often violates the equal-variance assumption (homoscedasticity), making it essential to account for heteroscedastic noise in causal discovery. In this work, we explore heteroscedastic symmetric noise models (HSNMs), where the effect $Y$ is modeled as $Y = f(X) + \\sigma(X)N$, with $X$ as the cause and $N$ as independent noise following a symmetric distribution. We introduce a novel criterion for identifying HSNMs based on the skewness of the score (i.e., the gradient of the log density) of the data distribution. This criterion establishes a computationally tractable measurement that is zero in the causal direction but nonzero in the anticausal direction, enabling the causal direction discovery. We extend this skewness-based criterion to the multivariate setting and propose SkewScore, an algorithm that handles heteroscedastic noise without requiring the extraction of exogenous noise. We also conduct a case study on the robustness of SkewScore in a bivariate model with a latent confounder, providing theoretical insights into its performance. Empirical studies further validate the effectiveness of the proposed method.","authors":["Yingyu Lin","Yuxing Huang","Wenqin Liu","Haoran Deng","Ignavier Ng","Kun Zhang","Mingming Gong","Yi-An Ma","Biwei Huang"],"url":"https://arxiv.org/abs/2410.06407"}
{"created":"2025-04-22","title":"Studying Practitioners' Expectations on Clear Code Review Comments","abstract":"The code review comment (CRC) is pivotal in the process of modern code review. It provides reviewers with the opportunity to identify potential bugs, offer constructive feedback, and suggest improvements. Clear and concise code review comments (CRCs) facilitate the communication between developers and is crucial to the correct understanding of the issues identified and proposed solutions. Despite the importance of CRCs' clarity, there is still a lack of guidelines on what constitutes a good clarity and how to evaluate it. In this paper, we conduct a comprehensive study on understanding and evaluating the clarity of CRCs. We first derive a set of attributes related to the clarity of CRCs, namely RIE attributes (i.e., Relevance, Informativeness, and Expression), as well as their corresponding evaluation criteria based on our literature review and survey with practitioners. We then investigate the clarity of CRCs in open-source projects written in nine programming languages and find that a large portion (i.e., 28.8%) of the CRCs lack the clarity in at least one of the attributes. Finally, we propose ClearCRC, an automated framework that evaluates the clarity of CRCs. Experimental results show that ClearCRC can effectively evaluate the clarity of CRCs and outperform the baselines.","authors":["Junkai Chen","Zhenhao Li","Qiheng Mao","Xing Hu","Kui Liu","Xin Xia"],"url":"https://arxiv.org/abs/2410.06515"}
{"created":"2025-04-22","title":"Detecting Training Data of Large Language Models via Expectation Maximization","abstract":"The advancement of large language models has grown parallel to the opacity of their training data. Membership inference attacks (MIAs) aim to determine whether specific data was used to train a model. They offer valuable insights into detecting data contamination and ensuring compliance with privacy and copyright standards. However, MIA for LLMs is challenging due to the massive scale of training data and the inherent ambiguity of membership in texts. Moreover, creating realistic MIA evaluation benchmarks is difficult as training and test data distributions are often unknown. We introduce EM-MIA, a novel membership inference method that iteratively refines membership scores and prefix scores via an expectation-maximization algorithm. Our approach leverages the observation that these scores can improve each other: membership scores help identify effective prefixes for detecting training data, while prefix scores help determine membership. As a result, EM-MIA achieves state-of-the-art results on WikiMIA. To enable comprehensive evaluation, we introduce OLMoMIA, a benchmark built from OLMo resources, which allows controlling task difficulty through varying degrees of overlap between training and test data distributions. Our experiments demonstrate EM-MIA is robust across different scenarios while also revealing fundamental limitations of current MIA approaches when member and non-member distributions are nearly identical.","authors":["Gyuwan Kim","Yang Li","Evangelia Spiliopoulou","Jie Ma","Miguel Ballesteros","William Yang Wang"],"url":"https://arxiv.org/abs/2410.07582"}
{"created":"2025-04-22","title":"When does additional information lead to longer travel time in multi-origin-destination networks?","abstract":"The Informational Braess' Paradox (IBP) illustrates a counterintuitive scenario where revelation of additional roadway segments to some self-interested travelers leads to increased travel times for these individuals. IBP extends the original Braess' paradox by relaxing the assumption that all travelers have identical and complete information about the network. In this paper, we study the conditions under which IBP does not occur in networks with non-atomic selfish travelers and multiple origin-destination pairs. Our results completely characterize the network topologies immune to IBP, thus resolving an open question proposed by Acemoglu et al.","authors":["Xujin Chen","Xiaodong Hu","Xinqi Jing","Zhongzheng Tang"],"url":"https://arxiv.org/abs/2410.08448"}
{"created":"2025-04-22","title":"Progressive Pruning: Analyzing the Impact of Intersection Attacks","abstract":"Stream-based communication dominates today's Internet, posing unique challenges for anonymous communication networks (ACNs). Traditionally designed for independent messages, ACNs struggle to account for the inherent vulnerabilities of streams, such as susceptibility to intersection attacks. In this work, we address this gap and introduce progressive pruning, a novel methodology for quantifying the susceptibility to intersection attacks. Progressive pruning quantifies and monitors anonymity sets over time, providing an assessment of an adversary's success in correlating senders and receivers. We leverage this methodology to analyze synthetic scenarios and large-scale simulations of the Tor network using our newly developed TorFS simulator. Our findings reveal that anonymity is significantly influenced by stream length, user population, and stream distribution across the network. These insights highlight critical design challenges for future ACNs seeking to safeguard stream-based communication against traffic analysis attacks.","authors":["Christoph D\\\"opmann","Maximilian Weisenseel","Florian Tschorsch"],"url":"https://arxiv.org/abs/2410.08700"}
{"created":"2025-04-22","title":"Decoding Secret Memorization in Code LLMs Through Token-Level Characterization","abstract":"Code Large Language Models (LLMs) have demonstrated remarkable capabilities in generating, understanding, and manipulating programming code. However, their training process inadvertently leads to the memorization of sensitive information, posing severe privacy risks. Existing studies on memorization in LLMs primarily rely on prompt engineering techniques, which suffer from limitations such as widespread hallucination and inefficient extraction of the target sensitive information. In this paper, we present a novel approach to characterize real and fake secrets generated by Code LLMs based on token probabilities. We identify four key characteristics that differentiate genuine secrets from hallucinated ones, providing insights into distinguishing real and fake secrets. To overcome the limitations of existing works, we propose DESEC, a two-stage method that leverages token-level features derived from the identified characteristics to guide the token decoding process. DESEC consists of constructing an offline token scoring model using a proxy Code LLM and employing the scoring model to guide the decoding process by reassigning token likelihoods. Through extensive experiments on four state-of-the-art Code LLMs using a diverse dataset, we demonstrate the superior performance of DESEC in achieving a higher plausible rate and extracting more real secrets compared to existing baselines. Our findings highlight the effectiveness of our token-level approach in enabling an extensive assessment of the privacy leakage risks associated with Code LLMs.","authors":["Yuqing Nie","Chong Wang","Kailong Wang","Guoai Xu","Guosheng Xu","Haoyu Wang"],"url":"https://arxiv.org/abs/2410.08858"}
{"created":"2025-04-22","title":"Nudging: Inference-time Alignment of LLMs via Guided Decoding","abstract":"Large language models (LLMs) require alignment to effectively and safely follow user instructions. This process necessitates training an aligned version for every base model, resulting in significant computational overhead. In this work, we propose nudging, a simple, plug-and-play, and training-free algorithm that aligns any base model at inference time using a small aligned model. Nudging is motivated by recent findings that alignment primarily alters the model's behavior on a small subset of stylistic tokens (e.g., discourse markers). We find that base models are significantly more uncertain when generating these tokens. Building on this insight, nudging employs a small aligned model to generate nudging tokens to guide the base model's output during decoding when the base model's uncertainty is high. We evaluate nudging across 3 model families on a diverse range of open-instruction tasks. Without any training, nudging a large base model with a 7x-14x smaller aligned model achieves zero-shot performance comparable to, and sometimes surpassing, that of large aligned models. By operating at the token level, nudging enables off-the-shelf collaboration between model families. For instance, nudging Gemma-2-27b with Llama-2-7b-chat outperforms Llama-2-70b-chat on various tasks. Overall, our work offers a modular and cost-efficient solution to LLM alignment. Our project website: https://fywalter.github.io/nudging/ .","authors":["Yu Fei","Yasaman Razeghi","Sameer Singh"],"url":"https://arxiv.org/abs/2410.09300"}
{"created":"2025-04-22","title":"DARE the Extreme: Revisiting Delta-Parameter Pruning For Fine-Tuned Models","abstract":"Storing open-source fine-tuned models separately introduces redundancy and increases response times in applications utilizing multiple models. Delta-parameter pruning (DPP), particularly the random drop and rescale (DARE) method proposed by Yu et al., addresses this by pruning the majority of delta parameters--the differences between fine-tuned and pre-trained model weights--while typically maintaining minimal performance loss. However, DARE fails when either the pruning rate or the magnitude of the delta parameters is large. We highlight two key reasons for this failure: (1) an excessively large rescaling factor as pruning rates increase, and (2) high mean and variance in the delta parameters. To push DARE's limits, we introduce DAREx (DARE the eXtreme), which features two algorithmic improvements: (1) DAREx-q, a rescaling factor modification that significantly boosts performance at high pruning rates (e.g., >30 % on COLA and SST2 for encoder models, with even greater gains in decoder models), and (2) DAREx-L2, which combines DARE with AdamR, an in-training method that applies appropriate delta regularization before DPP. We also demonstrate that DAREx-q can be seamlessly combined with vanilla parameter-efficient fine-tuning techniques like LoRA and can facilitate structural DPP. Additionally, we revisit the application of importance-based pruning techniques within DPP, demonstrating that they outperform random-based methods when delta parameters are large. Through this comprehensive study, we develop a pipeline for selecting the most appropriate DPP method under various practical scenarios.","authors":["Wenlong Deng","Yize Zhao","Vala Vakilian","Minghui Chen","Xiaoxiao Li","Christos Thrampoulidis"],"url":"https://arxiv.org/abs/2410.09344"}
{"created":"2025-04-22","title":"LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models","abstract":"With the rapid development of AI-generated content, the future internet may be inundated with synthetic data, making the discrimination of authentic and credible multimodal data increasingly challenging. Synthetic data detection has thus garnered widespread attention, and the performance of large multimodal models (LMMs) in this task has attracted significant interest. LMMs can provide natural language explanations for their authenticity judgments, enhancing the explainability of synthetic content detection. Simultaneously, the task of distinguishing between real and synthetic data effectively tests the perception, knowledge, and reasoning capabilities of LMMs. In response, we introduce LOKI, a novel benchmark designed to evaluate the ability of LMMs to detect synthetic data across multiple modalities. LOKI encompasses video, image, 3D, text, and audio modalities, comprising 18K carefully curated questions across 26 subcategories with clear difficulty levels. The benchmark includes coarse-grained judgment and multiple-choice questions, as well as fine-grained anomaly selection and explanation tasks, allowing for a comprehensive analysis of LMMs. We evaluated 22 open-source LMMs and 6 closed-source models on LOKI, highlighting their potential as synthetic data detectors and also revealing some limitations in the development of LMM capabilities. More information about LOKI can be found at https://opendatalab.github.io/LOKI/","authors":["Junyan Ye","Baichuan Zhou","Zilong Huang","Junan Zhang","Tianyi Bai","Hengrui Kang","Jun He","Honglin Lin","Zihao Wang","Tong Wu","Zhizheng Wu","Yiping Chen","Dahua Lin","Conghui He","Weijia Li"],"url":"https://arxiv.org/abs/2410.09732"}
{"created":"2025-04-22","title":"AI-based particle track identification in scintillating fibres read out with imaging sensors","abstract":"This paper presents the development and application of an AI-based method for particle track identification using scintillating fibres read out with imaging sensors. We propose a variational autoencoder (VAE) to efficiently filter and identify frames containing signal from the substantial data generated by SPAD array sensors. Our VAE model, trained on purely background frames, demonstrated a high capability to distinguish frames containing particle tracks from background noise. The performance of the VAE-based anomaly detection was validated with experimental data, demonstrating the method's ability to efficiently identify relevant events with rapid processing time, suggesting a solid prospect for deployment as a fast inference tool on hardware for real-time anomaly detection. This work highlights the potential of combining advanced sensor technology with machine learning techniques to enhance particle detection and tracking.","authors":["Noemi B\\\"uhrer","Sa\\'ul Alonso-Monsalve","Matthew Franks","Till Dieminger","Davide Sgalaberna"],"url":"https://arxiv.org/abs/2410.10519"}
{"created":"2025-04-22","title":"Context-Parametric Inversion: Why Instruction Finetuning Can Worsen Context Reliance","abstract":"A standard practice when using large language models is for users to supplement their instruction with an input context containing new information for the model to process. However, models struggle to reliably follow the input context, especially when it conflicts with their parametric knowledge from pretraining. In-principle, one would expect models to adapt to the user context better after instruction finetuning, particularly when handling knowledge conflicts. However, we observe a surprising failure mode: during instruction tuning, the context reliance under knowledge conflicts initially increases as expected, but then gradually decreases as instruction finetuning progresses. This happens while the performance on standard benchmarks keeps on increasing far after this drop. We call this phenomenon context-parametric inversion and observe it across multiple general purpose instruction tuning datasets such as TULU, Alpaca and Ultrachat, across different model families like Llama, Mistral, and Pythia. We perform various controlled studies and theoretical analysis to show that context-parametric inversion occurs due to examples in the instruction finetuning data where the input context provides information that aligns with model's parametric knowledge. Our analysis suggests some natural mitigation strategies with limited but insightful gains, and serves as a useful starting point in addressing this deficiency in instruction finetuning.","authors":["Sachin Goyal","Christina Baek","J. Zico Kolter","Aditi Raghunathan"],"url":"https://arxiv.org/abs/2410.10796"}
{"created":"2025-04-22","title":"Tree of Attributes Prompt Learning for Vision-Language Models","abstract":"Prompt learning has proven effective in adapting vision language models for downstream tasks. However, existing methods usually append learnable prompt tokens solely with the category names to obtain textual features, which fails to fully leverage the rich context indicated in the category name. To address this issue, we propose the Tree of Attributes Prompt learning (TAP), which first instructs LLMs to generate a tree of attributes with a \"concept - attribute - description\" structure for each category, and then learn the hierarchy with vision and text prompt tokens. Unlike existing methods that merely augment category names with a set of unstructured descriptions, our approach essentially distills structured knowledge graphs associated with class names from LLMs. Furthermore, our approach introduces text and vision prompts designed to explicitly learn the corresponding visual attributes, effectively serving as domain experts. Additionally, the general and diverse descriptions generated based on the class names may be wrong or absent in the specific given images. To address this misalignment, we further introduce a vision-conditional pooling module to extract instance-specific text features. Extensive experimental results demonstrate that our approach outperforms state-of-the-art methods on the zero-shot base-to-novel generalization, cross-dataset transfer, as well as few-shot classification across 11 diverse datasets. Code is available at https://github.com/HHenryD/TAP.","authors":["Tong Ding","Wanhua Li","Zhongqi Miao","Hanspeter Pfister"],"url":"https://arxiv.org/abs/2410.11201"}
{"created":"2025-04-22","title":"INR-Based Generative Steganography by Point Cloud Representation","abstract":"Generative steganography (GS) directly generates stego-media through secret message-driven generation. It makes the hiding capacity of GS higher than that of traditional steganography, as well as more resistant to classical steganalysis. However, the generators and extractors of existing GS methods can only target specific formats and types of data and lack of universality. Besides, the model size is usually related to the underlying grid resolution, and the transmission behavior of the extractor is susceptible to suspicion of steganalysis. Implicit neural representation(INR) is a technique for representing data in a continuous manner. Inspired by this, we propose an INR-based generative steganography by point cloud representation (INR-GSPC). By using the function generator, the problem of the generator model size growing exponentially with the increase of gridded data has been solved. That is able to generate a wide range of data types and break through the limitation of resolution. In order to unify the data formats of the generator and message extractor, the data is converted to point cloud representation. We designed and fixed a point cloud message extractor. By iterating over the point cloud with adding small perturbations to generate stego-media. This method can avoid the training and transmission process of the message extractor. To the best of our knowledge, this is the first method to apply point cloud to generative steganography. Experiments demonstrate that the stego-images generated by the scheme have an average PSNR value of more than 65, and the accuracy of message extraction reaches more than 99%.","authors":["Zhong Yangjie","Liu Jia","Luo Peng","Ke Yan","Cai Shen"],"url":"https://arxiv.org/abs/2410.11673"}
{"created":"2025-04-22","title":"BlendRL: A Framework for Merging Symbolic and Neural Policy Learning","abstract":"Humans can leverage both symbolic reasoning and intuitive reactions. In contrast, reinforcement learning policies are typically encoded in either opaque systems like neural networks or symbolic systems that rely on predefined symbols and rules. This disjointed approach severely limits the agents' capabilities, as they often lack either the flexible low-level reaction characteristic of neural agents or the interpretable reasoning of symbolic agents. To overcome this challenge, we introduce BlendRL, a neuro-symbolic RL framework that harmoniously integrates both paradigms within RL agents that use mixtures of both logic and neural policies. We empirically demonstrate that BlendRL agents outperform both neural and symbolic baselines in standard Atari environments, and showcase their robustness to environmental changes. Additionally, we analyze the interaction between neural and symbolic policies, illustrating how their hybrid use helps agents overcome each other's limitations.","authors":["Hikaru Shindo","Quentin Delfosse","Devendra Singh Dhami","Kristian Kersting"],"url":"https://arxiv.org/abs/2410.11689"}
{"created":"2025-04-22","title":"Reconstruction of Differentially Private Text Sanitization via Large Language Models","abstract":"Differential privacy (DP) is the de facto privacy standard against privacy leakage attacks, including many recently discovered ones against large language models (LLMs). However, we discovered that LLMs could reconstruct the altered/removed privacy from given DP-sanitized prompts. We propose two attacks (black-box and white-box) based on the accessibility to LLMs and show that LLMs could connect the pair of DP-sanitized text and the corresponding private training data of LLMs by giving sample text pairs as instructions (in the black-box attacks) or fine-tuning data (in the white-box attacks). To illustrate our findings, we conduct comprehensive experiments on modern LLMs (e.g., LLaMA-2, LLaMA-3, ChatGPT-3.5, ChatGPT-4, ChatGPT-4o, Claude-3, Claude-3.5, OPT, GPT-Neo, GPT-J, Gemma-2, and Pythia) using commonly used datasets (such as WikiMIA, Pile-CC, and Pile-Wiki) against both word-level and sentence-level DP. The experimental results show promising recovery rates, e.g., the black-box attacks against the word-level DP over WikiMIA dataset gave 72.18% on LLaMA-2 (70B), 82.39% on LLaMA-3 (70B), 75.35% on Gemma-2, 91.2% on ChatGPT-4o, and 94.01% on Claude-3.5 (Sonnet). More urgently, this study indicates that these well-known LLMs have emerged as a new security risk for existing DP text sanitization approaches in the current environment.","authors":["Shuchao Pang","Zhigang Lu","Haichen Wang","Peng Fu","Yongbin Zhou","Minhui Xue"],"url":"https://arxiv.org/abs/2410.12443"}
{"created":"2025-04-22","title":"Preference Diffusion for Recommendation","abstract":"Recommender systems predict personalized item rankings based on user preference distributions derived from historical behavior data. Recently, diffusion models (DMs) have gained attention in recommendation for their ability to model complex distributions, yet current DM-based recommenders often rely on traditional objectives like mean squared error (MSE) or recommendation objectives, which are not optimized for personalized ranking tasks or fail to fully leverage DM's generative potential. To address this, we propose PreferDiff, a tailored optimization objective for DM-based recommenders. PreferDiff transforms BPR into a log-likelihood ranking objective and integrates multiple negative samples to better capture user preferences. Specifically, we employ variational inference to handle the intractability through minimizing the variational upper bound and replaces MSE with cosine error to improve alignment with recommendation tasks. Finally, we balance learning generation and preference to enhance the training stability of DMs. PreferDiff offers three key benefits: it is the first personalized ranking loss designed specifically for DM-based recommenders and it improves ranking and faster convergence by addressing hard negatives. We also prove that it is theoretically connected to Direct Preference Optimization which indicates that it has the potential to align user preferences in DM-based recommenders via generative modeling. Extensive experiments across three benchmarks validate its superior recommendation performance and commendable general sequential recommendation capabilities. Our codes are available at https://github.com/lswhim/PreferDiff.","authors":["Shuo Liu","An Zhang","Guoqing Hu","Hong Qian","Tat-seng Chua"],"url":"https://arxiv.org/abs/2410.13117"}
{"created":"2025-04-22","title":"Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in Vision-Language Alignment","abstract":"The recent advancements in large language models (LLMs) and pre-trained vision models have accelerated the development of vision-language large models (VLLMs), enhancing the interaction between visual and linguistic modalities. Despite their notable success across various domains, VLLMs face challenges in modality alignment, which can lead to issues like hallucinations and unsafe content generation. Current alignment techniques often rely on coarse feedback and external datasets, limiting scalability and performance. In this paper, we propose FiSAO (Fine-Grained Self-Alignment Optimization), a novel self-alignment method that utilizes the model's own visual encoder as a fine-grained verifier to improve vision-language alignment without the need for additional data. By leveraging token-level feedback from the vision encoder, FiSAO significantly improves vision-language alignment, even surpassing traditional preference tuning methods that require additional data. Through both theoretical analysis and experimental validation, we demonstrate that FiSAO effectively addresses the misalignment problem in VLLMs, marking the first instance of token-level rewards being applied to such models.","authors":["Chenhang Cui","An Zhang","Yiyang Zhou","Zhaorun Chen","Gelei Deng","Huaxiu Yao","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2410.14148"}
{"created":"2025-04-22","title":"Adapting Multilingual LLMs to Low-Resource Languages using Continued Pre-training and Synthetic Corpus","abstract":"Multilingual LLMs support a variety of languages; however, their performance is suboptimal for low-resource languages. In this work, we emphasize the importance of continued pre-training of multilingual LLMs and the use of translation-based synthetic pre-training corpora for improving LLMs in low-resource languages. We conduct our study in the context of the low-resource Indic language Hindi. We introduce Nemotron-Mini-Hindi 4B, a bilingual SLM supporting both Hindi and English, based on Nemotron-Mini 4B. The model is trained using a mix of real and synthetic Hindi + English tokens, with continuous pre-training performed on 400B tokens. We demonstrate that both the base and instruct models achieve state-of-the-art results on Hindi benchmarks while remaining competitive on English tasks. Additionally, we observe that the continued pre-training approach enhances the model's overall factual accuracy. We perform an ablation study to highlight the impact of Hindi pre-training, showing significant improvements in Hindi chat capabilities and factual accuracy, which cannot be achieved through Hindi alignment alone.","authors":["Raviraj Joshi","Kanishk Singla","Anusha Kamath","Raunak Kalani","Rakesh Paul","Utkarsh Vaidya","Sanjay Singh Chauhan","Niranjan Wartikar","Eileen Long"],"url":"https://arxiv.org/abs/2410.14815"}
{"created":"2025-04-22","title":"Federated Communication-Efficient Multi-Objective Optimization","abstract":"We study a federated version of multi-objective optimization (MOO), where a single model is trained to optimize multiple objective functions. MOO has been extensively studied in the centralized setting but is less explored in federated or distributed settings. We propose FedCMOO, a novel communication-efficient federated multi-objective optimization (FMOO) algorithm that improves the error convergence performance of the model compared to existing approaches. Unlike prior works, the communication cost of FedCMOO does not scale with the number of objectives, as each client sends a single aggregated gradient to the central server. We provide a convergence analysis of the proposed method for smooth and non-convex objective functions under milder assumptions than in prior work. In addition, we introduce a variant of FedCMOO that allows users to specify a preference over the objectives in terms of a desired ratio of the final objective values. Through extensive experiments, we demonstrate the superiority of our proposed method over baseline approaches.","authors":["Baris Askin","Pranay Sharma","Gauri Joshi","Carlee Joe-Wong"],"url":"https://arxiv.org/abs/2410.16398"}
{"created":"2025-04-22","title":"How the Internet Facilitates Adverse Childhood Experiences for Youth Who Self-Identify as in Need of Services","abstract":"Youth implicated in the child welfare and juvenile justice systems, as well as those with an incarcerated parent, are considered the most vulnerable Children in Need of Services (CHINS). We identified 1,160 of these at-risk youth (ages 13-17) who sought support via an online peer support platform to understand their adverse childhood experiences and explore how the internet played a role in providing an outlet for support, as well as potentially facilitating risks. We first analyzed posts from 1,160 youth who self-identified as CHINS while sharing about their adverse experiences. Then, we retrieved all 239,929 posts by these users to identify salient topics within their support-seeking posts: 1) Urges to self-harm due to social drama, 2) desire for social connection, 3) struggles with family, and 4) substance use and sexual risks. We found that the internet often helped facilitate these problems; for example, the desperation for social connection often led to meeting unsafe people online, causing additional trauma. Family members and other unsafe people used the internet to perpetrate cyberabuse, while CHINS themselves leveraged online channels to engage in illegal and risky behavior. Our study calls for tailored support systems that address the unique needs of CHINS to promote safe online spaces and foster resilience to break the cycle of adversity. Empowering CHINS requires amplifying their voices and acknowledging the challenges they face as a result of their adverse childhood experiences.","authors":["Ozioma C. Oguine","Jinkyung Katie Park","Mamtaj Akter","Johanna Olesk","Abdulmalik Alluhidan","Pamela Wisniewski","Karla Badillo-Urquiola"],"url":"https://arxiv.org/abs/2410.16507"}
{"created":"2025-04-22","title":"Magnetic Preference Optimization: Achieving Last-iterate Convergence for Language Model Alignment","abstract":"Self-play methods have demonstrated remarkable success in enhancing model capabilities across various domains. In the context of Reinforcement Learning from Human Feedback (RLHF), self-play not only boosts Large Language Model (LLM) performance but also overcomes the limitations of traditional Bradley-Terry (BT) model assumptions by finding the Nash equilibrium (NE) of a preference-based, two-player constant-sum game. However, existing methods either guarantee only average-iterate convergence, incurring high storage and inference costs, or converge to the NE of a regularized game, failing to accurately reflect true human preferences. In this paper, we introduce Magnetic Preference Optimization (MPO), a novel approach capable of achieving last-iterate convergence to the NE of the original game, effectively overcoming the limitations of existing methods. Building upon Magnetic Mirror Descent (MMD), MPO attains a linear convergence rate, making it particularly suitable for fine-tuning LLMs. To ensure our algorithm is both theoretically sound and practically viable, we present a simple yet effective implementation that adapts the theoretical insights to the RLHF setting. Empirical results demonstrate that MPO can significantly enhance the performance of LLMs, highlighting the potential of self-play methods in alignment.","authors":["Mingzhi Wang","Chengdong Ma","Qizhi Chen","Linjian Meng","Yang Han","Jiancong Xiao","Zhaowei Zhang","Jing Huo","Weijie J. Su","Yaodong Yang"],"url":"https://arxiv.org/abs/2410.16714"}
{"created":"2025-04-22","title":"Preserving Privacy in Cloud-based Data-Driven Stabilization","abstract":"In the recent years, we have observed three significant trends in control systems: a renewed interest in data-driven control design, the abundance of cloud computational services and the importance of preserving privacy for the system under control. Motivated by these factors, this work investigates privacy-preserving outsourcing for the design of a stabilizing controller for unknown linear time-invariant systems.The main objective of this research is to preserve the privacy for the system dynamics by designing an outsourcing mechanism. To achieve this goal, we propose a scheme that combines transformation-based techniques and robust data-driven control design methods. The scheme preserves the privacy of both the open-loop and closed-loop system matrices while stabilizing the system under control.The scheme is applicable to both data with and without disturbance and is lightweight in terms of computational overhead. Numerical investigations for a case study demonstrate the impacts of our mechanism and its role in hindering malicious adversaries from achieving their goals.","authors":["Teimour Hosseinalizadeh","Nima Monshizadeh"],"url":"https://arxiv.org/abs/2410.17353"}
{"created":"2025-04-22","title":"LEO-based Positioning: Foundations, Signal Design, and Receiver Enhancements for 6G NTN","abstract":"The integration of non-terrestrial networks (NTN) into 5G new radio (NR) has opened up the possibility of developing a new positioning infrastructure using NR signals from Low-Earth Orbit (LEO) satellites. Compared to existing Global Navigation Satellite Systems (GNSS), LEO-based cellular positioning offers several advantages, such as a superior link budget, higher operating bandwidth, and large forthcoming constellations. Due to these factors, LEO-based positioning, navigation, and timing (PNT) is a potential enhancement for NTN in 6G cellular networks. However, extending the existing terrestrial cellular positioning methods to LEO-based NTN positioning requires key fundamental enhancements. These include creating broad positioning beams orthogonal to conventional communication beams, time-domain processing at the user equipment (UE) to resolve large delay and Doppler uncertainties, and efficiently accommodating positioning reference signals (PRS) from multiple satellites within the communication resource grid. In this paper, we present the first set of design insights by incorporating these enhancements and thoroughly evaluating LEO-based positioning, considering the constraints and capabilities of the NR-NTN physical layer. To evaluate the performance of LEO-based NTN positioning, we develop a comprehensive NR-compliant simulation framework, including LEO orbit simulation, transmission (Tx) and receiver (Rx) architectures, and a positioning engine incorporating the necessary enhancements. Our findings suggest that LEO-based NTN positioning could serve as a complementary infrastructure to GNSS and, with appropriate enhancements, may also offer a viable alternative.","authors":["Harish K. Dureppagari","Chiranjib Saha","Harikumar Krishnamurthy","Xiao Feng Wang","Alberto Rico-Alvari\\~no","R. Michael Buehrer","Harpreet S. Dhillon"],"url":"https://arxiv.org/abs/2410.18301"}
{"created":"2025-04-22","title":"Deterministic $(2/3-\\varepsilon)$-Approximation of Matroid Intersection Using Nearly-Linear Independence-Oracle Queries","abstract":"In the matroid intersection problem, we are given two matroids $\\mathcal{M}_1 = (V, \\mathcal{I}_1)$ and $\\mathcal{M}_2 = (V, \\mathcal{I}_2)$ defined on the same ground set $V$ of $n$ elements, and the objective is to find a common independent set $S \\in \\mathcal{I}_1 \\cap \\mathcal{I}_2$ of largest possible cardinality, denoted by $r$. In this paper, we consider a deterministic matroid intersection algorithm with only a nearly linear number of independence oracle queries. Our contribution is to present a deterministic $O(\\frac{n}{\\varepsilon} + r \\log r)$-independence-query $(2/3-\\varepsilon)$-approximation algorithm for any $\\varepsilon > 0$. Our idea is very simple: we apply a recent $\\tilde{O}(n \\sqrt{r}/\\varepsilon)$-independence-query $(1 - \\varepsilon)$-approximation algorithm of Blikstad [ICALP 2021], but terminate it before completion. Moreover, we also present a semi-streaming algorithm for $(2/3 -\\varepsilon)$-approximation of matroid intersection in $O(1/\\varepsilon)$ passes.","authors":["Tatsuya Terao"],"url":"https://arxiv.org/abs/2410.18820"}
{"created":"2025-04-22","title":"MaCTG: Multi-Agent Collaborative Thought Graph for Automatic Programming","abstract":"With the rapid advancement of Large Language Models (LLMs), LLM-based approaches have demonstrated strong problem-solving capabilities across various domains. However, in automatic programming, a single LLM is typically limited to function-level code generation, while multi-agent systems composed of multiple LLMs often suffer from inefficient task planning. This lack of structured coordination can lead to cascading hallucinations, where accumulated errors across agents result in suboptimal workflows and excessive computational costs. To overcome these challenges, we introduce MaCTG (Multi-Agent Collaborative Thought Graph), a novel multi-agent framework that employs a dynamic graph structure to facilitate precise task allocation and controlled collaboration among LLM agents. MaCTG autonomously assigns agent roles based on programming requirements, dynamically refines task distribution through context-aware adjustments, and systematically verifies and integrates project-level code, effectively reducing hallucination errors and improving overall accuracy. MaCTG enhances cost-effectiveness by implementing a hybrid LLM deployment, where proprietary models handle complex reasoning, while open-source models are used for routine coding and validation tasks. To evaluate MaCTG's effectiveness, we applied it to traditional image processing auto-programming tasks, achieving a state-of-the-art accuracy of 83.33%. Additionally, by leveraging its hybrid LLM configuration, MaCTG significantly reduced operational costs by 89.09% compared to existing multi-agent frameworks, demonstrating its efficiency, scalability, and real-world applicability.","authors":["Zixiao Zhao","Jing Sun","Zhe Hou","Zhiyuan Wei","Cheng-Hao Cai","Miao Qiao","Jin Song Dong"],"url":"https://arxiv.org/abs/2410.19245"}
{"created":"2025-04-22","title":"Transferable Adversarial Attacks on SAM and Its Downstream Models","abstract":"The utilization of large foundational models has a dilemma: while fine-tuning downstream tasks from them holds promise for making use of the well-generalized knowledge in practical applications, their open accessibility also poses threats of adverse usage. This paper, for the first time, explores the feasibility of adversarial attacking various downstream models fine-tuned from the segment anything model (SAM), by solely utilizing the information from the open-sourced SAM. In contrast to prevailing transfer-based adversarial attacks, we demonstrate the existence of adversarial dangers even without accessing the downstream task and dataset to train a similar surrogate model. To enhance the effectiveness of the adversarial attack towards models fine-tuned on unknown datasets, we propose a universal meta-initialization (UMI) algorithm to extract the intrinsic vulnerability inherent in the foundation model, which is then utilized as the prior knowledge to guide the generation of adversarial perturbations. Moreover, by formulating the gradient difference in the attacking process between the open-sourced SAM and its fine-tuned downstream models, we theoretically demonstrate that a deviation occurs in the adversarial update direction by directly maximizing the distance of encoded feature embeddings in the open-sourced SAM. Consequently, we propose a gradient robust loss that simulates the associated uncertainty with gradient-based noise augmentation to enhance the robustness of generated adversarial examples (AEs) towards this deviation, thus improving the transferability. Extensive experiments demonstrate the effectiveness of the proposed universal meta-initialized and gradient robust adversarial attack (UMI-GRAT) toward SAMs and their downstream models. Code is available at https://github.com/xiasong0501/GRAT.","authors":["Song Xia","Wenhan Yang","Yi Yu","Xun Lin","Henghui Ding","Ling-Yu Duan","Xudong Jiang"],"url":"https://arxiv.org/abs/2410.20197"}
{"created":"2025-04-22","title":"Fine-Grained and Multi-Dimensional Metrics for Document-Level Machine Translation","abstract":"Large language models (LLMs) have excelled in various NLP tasks, including machine translation (MT), yet most studies focus on sentence-level translation. This work investigates the inherent capability of instruction-tuned LLMs for document-level translation (docMT). Unlike prior approaches that require specialized techniques, we evaluate LLMs by directly prompting them to translate entire documents in a single pass. Our results show that this method improves translation quality compared to translating sentences separately, even without document-level fine-tuning. However, this advantage is not reflected in BLEU scores, which often favor sentence-based translations. We propose using the LLM-as-a-judge paradigm for evaluation, where GPT-4 is used to assess document coherence, accuracy, and fluency in a more nuanced way than n-gram-based metrics. Overall, our work demonstrates that instruction-tuned LLMs can effectively leverage document context for translation. However, we caution against using BLEU scores for evaluating docMT, as they often provide misleading outcomes, failing to capture the quality of document-level translation. Code and the outputs from GPT4-as-a-judge are available at https://github.com/EIT-NLP/BLEUless_DocMT","authors":["Yirong Sun","Dawei Zhu","Yanjun Chen","Erjia Xiao","Xinghao Chen","Xiaoyu Shen"],"url":"https://arxiv.org/abs/2410.20941"}
{"created":"2025-04-22","title":"CTINexus: Automatic Cyber Threat Intelligence Knowledge Graph Construction Using Large Language Models","abstract":"Textual descriptions in cyber threat intelligence (CTI) reports, such as security articles and news, are rich sources of knowledge about cyber threats, crucial for organizations to stay informed about the rapidly evolving threat landscape. However, current CTI knowledge extraction methods lack flexibility and generalizability, often resulting in inaccurate and incomplete knowledge extraction. Syntax parsing relies on fixed rules and dictionaries, while model fine-tuning requires large annotated datasets, making both paradigms challenging to adapt to new threats and ontologies. To bridge the gap, we propose CTINexus, a novel framework leveraging optimized in-context learning (ICL) of large language models (LLMs) for data-efficient CTI knowledge extraction and high-quality cybersecurity knowledge graph (CSKG) construction. Unlike existing methods, CTINexus requires neither extensive data nor parameter tuning and can adapt to various ontologies with minimal annotated examples. This is achieved through: (1) a carefully designed automatic prompt construction strategy with optimal demonstration retrieval for extracting a wide range of cybersecurity entities and relations; (2) a hierarchical entity alignment technique that canonicalizes the extracted knowledge and removes redundancy; (3) an long-distance relation prediction technique to further complete the CSKG with missing links. Our extensive evaluations using 150 real-world CTI reports collected from 10 platforms demonstrate that CTINexus significantly outperforms existing methods in constructing accurate and complete CSKG, highlighting its potential to transform CTI analysis with an efficient and adaptable solution for the dynamic threat landscape.","authors":["Yutong Cheng","Osama Bajaber","Saimon Amanuel Tsegai","Dawn Song","Peng Gao"],"url":"https://arxiv.org/abs/2410.21060"}
{"created":"2025-04-22","title":"How Does Critical Batch Size Scale in Pre-training?","abstract":"Training large-scale models under given resources requires careful design of parallelism strategies. In particular, the efficiency notion of critical batch size (CBS), concerning the compromise between time and compute, marks the threshold beyond which greater data parallelism leads to diminishing returns. To operationalize it, we propose a measure of CBS and pre-train a series of auto-regressive language models, ranging from 85 million to 1.2 billion parameters, on the C4 dataset. Through extensive hyper-parameter sweeps and careful control of factors such as batch size, momentum, and learning rate along with its scheduling, we systematically investigate the impact of scale on CBS. Then we fit scaling laws with respect to model and data sizes to decouple their effects. Overall, our results demonstrate that CBS scales primarily with data size rather than model size, a finding we justify theoretically through the analysis of infinite-width limits of neural networks and infinite-dimensional least squares regression. Of independent interest, we highlight the importance of common hyper-parameter choices and strategies for studying large-scale pre-training beyond fixed training durations.","authors":["Hanlin Zhang","Depen Morwani","Nikhil Vyas","Jingfeng Wu","Difan Zou","Udaya Ghai","Dean Foster","Sham Kakade"],"url":"https://arxiv.org/abs/2410.21676"}
{"created":"2025-04-22","title":"PK-YOLO: Pretrained Knowledge Guided YOLO for Brain Tumor Detection in Multiplanar MRI Slices","abstract":"Brain tumor detection in multiplane Magnetic Resonance Imaging (MRI) slices is a challenging task due to the various appearances and relationships in the structure of the multiplane images. In this paper, we propose a new You Only Look Once (YOLO)-based detection model that incorporates Pretrained Knowledge (PK), called PK-YOLO, to improve the performance for brain tumor detection in multiplane MRI slices. To our best knowledge, PK-YOLO is the first pretrained knowledge guided YOLO-based object detector. The main components of the new method are a pretrained pure lightweight convolutional neural network-based backbone via sparse masked modeling, a YOLO architecture with the pretrained backbone, and a regression loss function for improving small object detection. The pretrained backbone allows for feature transferability of object queries on individual plane MRI slices into the model encoders, and the learned domain knowledge base can improve in-domain detection. The improved loss function can further boost detection performance on small-size brain tumors in multiplanar two-dimensional MRI slices. Experimental results show that the proposed PK-YOLO achieves competitive performance on the multiplanar MRI brain tumor detection datasets compared to state-of-the-art YOLO-like and DETR-like object detectors. The code is available at https://github.com/mkang315/PK-YOLO.","authors":["Ming Kang","Fung Fung Ting","Rapha\\\"el C. -W. Phan","Chee-Ming Ting"],"url":"https://arxiv.org/abs/2410.21822"}
{"created":"2025-04-22","title":"Fast and scalable Wasserstein-1 neural optimal transport solver for single-cell perturbation prediction","abstract":"\\textbf{Motivation:} Predicting single-cell perturbation responses requires mapping between two unpaired single-cell data distributions. Optimal transport (OT) theory provides a principled framework for constructing such mappings by minimizing transport cost. Recently, Wasserstein-2 ($W_2$) neural optimal transport solvers (\\textit{e.g.}, CellOT) have been employed for this prediction task. However, $W_2$ OT relies on the general Kantorovich dual formulation, which involves optimizing over two conjugate functions, leading to a complex min-max optimization problem that converges slowly. \\\\ \\textbf{Results:} To address these challenges, we propose a novel solver based on the Wasserstein-1 ($W_1$) dual formulation. Unlike $W_2$, the $W_1$ dual simplifies the optimization to a maximization problem over a single 1-Lipschitz function, thus eliminating the need for time-consuming min-max optimization. While solving the $W_1$ dual only reveals the transport direction and does not directly provide a unique optimal transport map, we incorporate an additional step using adversarial training to determine an appropriate transport step size, effectively recovering the transport map. Our experiments demonstrate that the proposed $W_1$ neural optimal transport solver can mimic the $W_2$ OT solvers in finding a unique and ``monotonic\" map on 2D datasets. Moreover, the $W_1$ OT solver achieves performance on par with or surpasses $W_2$ OT solvers on real single-cell perturbation datasets. Furthermore, we show that $W_1$ OT solver achieves $25 \\sim 45\\times$ speedup, scales better on high dimensional transportation task, and can be directly applied on single-cell RNA-seq dataset with highly variable genes. \\\\ \\textbf{Availability and Implementation:} Our implementation and experiments are open-sourced at https://github.com/poseidonchan/w1ot.","authors":["Yanshuo Chen","Zhengmian Hu","Wei Chen","Heng Huang"],"url":"https://arxiv.org/abs/2411.00614"}
{"created":"2025-04-22","title":"ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building Large Language Model-Based Conversational AI Agents","abstract":"Large language model (LLM)-based agents are increasingly employed to interact with external environments (e.g., games, APIs, world models) to solve user-provided tasks. However, current frameworks often lack the ability to collaborate effectively with users in fully conversational settings. Conversations are essential for aligning on task details, achieving user-defined goals, and satisfying preferences. While existing agents address ambiguity through clarification questions, they underutilize the broader potential of an LLM's conversational capabilities. In this work, we introduce ReSpAct, an LLM-based agent designed to seamlessly integrate reasoning, decision-making, and dynamic dialogue for task-solving. Expanding on reasoning-first approaches like ReAct, ReSpAct employs active, free-flowing dialogues to interpret instructions, clarify goals, provide status updates, resolve subtask failures, and refine plans based on user inputs without any explicit dialogue schema. By alternating between task-solving actions and interactive conversations, ReSpAct demonstrates improved performance across diverse environments. We evaluate ReSpAct in user-interactive settings, including task-oriented dialogue systems (MultiWOZ) and decision-making tasks (ALFWorld, WebShop). ReSpAct outperforms ReAct with absolute success rate improvements of 6% and 4% in ALFWorld and WebShop, respectively, and achieves a 5.5% gain in Inform and a 3% gain in Success scores in MultiWOZ. These results highlight the value of integrating dynamic user-agent collaboration for more effective task resolution.","authors":["Vardhan Dongre","Xiaocheng Yang","Emre Can Acikgoz","Suvodip Dey","Gokhan Tur","Dilek Hakkani-T\\\"ur"],"url":"https://arxiv.org/abs/2411.00927"}
{"created":"2025-04-22","title":"Context Parallelism for Scalable Million-Token Inference","abstract":"We present context parallelism for long-context large language model inference, which achieves near-linear scaling for long-context prefill latency with up to 128 H100 GPUs across 16 nodes. Particularly, our method achieves 1M context prefill with Llama3 405B model in 77s (93% parallelization efficiency, 63% FLOPS utilization) and 128K context prefill in 3.8s. We develop two lossless exact ring attention variants: pass-KV and pass-Q to cover a wide range of use cases with the state-of-the-art performance: full prefill, persistent KV prefill and decode. Benchmarks on H100 GPU hosts inter-connected with RDMA and TCP both show similar scalability for long-context prefill, demonstrating that our method scales well using common commercial data center with medium-to-low inter-host bandwidth.","authors":["Amy Yang","Jingyi Yang","Aya Ibrahim","Xinfeng Xie","Bangsheng Tang","Grigory Sizov","Jeremy Reizenstein","Jongsoo Park","Jianyu Huang"],"url":"https://arxiv.org/abs/2411.01783"}
{"created":"2025-04-22","title":"Communication and Energy-Aware Multi-UAV Coverage Path Planning for Networked Operations","abstract":"This paper presents a communication and energy-aware multi-UAV Coverage Path Planning (mCPP) method for scenarios requiring continuous inter-UAV communication, such as cooperative search and rescue and surveillance missions. Unlike existing mCPP solutions that focus on energy, time, or coverage efficiency, the proposed method generates coverage paths that minimize a specified combination of energy and inter-UAV connectivity radius. Key features of the proposed algorithm include a simplified and validated energy consumption model, an efficient connectivity radius estimator, and an optimization framework that enables us to search for the optimal paths over irregular and obstacle-rich regions. The effectiveness and utility of the proposed algorithm is validated through simulations on various test regions with and without no-fly-zones. Real-world experiments on a three-UAV system demonstrate the remarkably high 99% match between the estimated and actual communication range requirement.","authors":["Mohamed Samshad","Ketan Rajawat"],"url":"https://arxiv.org/abs/2411.02772"}
{"created":"2025-04-22","title":"Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters","abstract":"Vision Language Models (VLMs) have demonstrated strong capabilities across various visual understanding and reasoning tasks, driven by incorporating image representations into the token inputs of Large Language Models (LLMs). However, their real-world deployment is often constrained by high latency during inference due to the substantial compute required by the LLM to process the large number of input tokens, predominantly arising from the image. To reduce inference costs, one can either downsize the LLM or reduce the number of input tokens needed to represent the image, the latter of which has been the focus of many recent efforts around token compression. However, it is unclear what the optimal trade-off is given a fixed inference budget. We first characterize this optimal trade-off between the number of visual tokens and LLM parameters by establishing scaling laws that capture variations in performance with these two factors. Our results reveal a surprising trend: for visual reasoning tasks, the inference-optimal behavior in VLMs is achieved by using the largest LLM that fits within the inference budget while minimizing visual token count - often to a single token. While the token reduction literature has mainly focused on maintaining base model performance by modestly reducing the token count (e.g., $5-10\\times$), our results indicate that the compute-optimal inference regime requires operating under even higher token compression ratios. Based on these insights, we take the first steps toward designing token compression algorithms tailored for high-compression settings, utilizing prompt-based compression of tokens. Our work underscores the performance and efficiency benefits of operating in low visual token regimes and the importance of developing tailored token reduction algorithms for such conditions. Code is available at https://github.com/locuslab/llava-token-compression.","authors":["Kevin Y. Li","Sachin Goyal","Joao D. Semedo","J. Zico Kolter"],"url":"https://arxiv.org/abs/2411.03312"}
{"created":"2025-04-22","title":"CrowdGenUI: Aligning LLM-Based UI Generation with Crowdsourced User Preferences","abstract":"Large Language Models (LLMs) have demonstrated remarkable potential across various design domains, including user interface (UI) generation. However, current LLMs for UI generation tend to offer generic solutions that lack a nuanced understanding of task context and user preferences. We present CrowdGenUI, a framework that enhances LLM-based UI generation with crowdsourced user preferences. This framework addresses the limitations by guiding LLM reasoning with real user preferences, enabling the generation of UI widgets that reflect user needs and task-specific requirements. We evaluate our framework in the image editing domain by collecting a library of 720 user preferences from 50 participants, covering preferences such as predictability, efficiency, and explorability of various UI widgets. A user study (N=78) demonstrates that UIs generated with our preference-guided framework can better match user intentions compared to those generated by LLMs alone, highlighting the effectiveness of our proposed framework. We further discuss the study findings and present insights for future research on LLM-based user-centered UI generation.","authors":["Yimeng Liu","Misha Sra","Chang Xiao"],"url":"https://arxiv.org/abs/2411.03477"}
{"created":"2025-04-22","title":"Constrained Multi-objective Bayesian Optimization through Optimistic Constraints Estimation","abstract":"Multi-objective Bayesian optimization has been widely adopted in scientific experiment design, including drug discovery and hyperparameter optimization. In practice, regulatory or safety concerns often impose additional thresholds on certain attributes of the experimental outcomes. Previous work has primarily focused on constrained single-objective optimization tasks or active search under constraints. The existing constrained multi-objective algorithms address the issue with heuristics and approximations, posing challenges to the analysis of the sample efficiency. We propose a novel constrained multi-objective Bayesian optimization algorithm COMBOO that balances active learning of the level-set defined on multiple unknowns with multi-objective optimization within the feasible region. We provide both theoretical analysis and empirical evidence, demonstrating the efficacy of our approach on various synthetic benchmarks and real-world applications.","authors":["Diantong Li","Fengxue Zhang","Chong Liu","Yuxin Chen"],"url":"https://arxiv.org/abs/2411.03641"}
{"created":"2025-04-22","title":"Seeing Through Pixel Motion: Learning Obstacle Avoidance from Optical Flow with One Camera","abstract":"Optical flow captures the motion of pixels in an image sequence over time, providing information about movement, depth, and environmental structure. Flying insects utilize this information to navigate and avoid obstacles, allowing them to execute highly agile maneuvers even in complex environments. Despite its potential, autonomous flying robots have yet to fully leverage this motion information to achieve comparable levels of agility and robustness. Challenges of control from optical flow include extracting accurate optical flow at high speeds, handling noisy estimation, and ensuring robust performance in complex environments. To address these challenges, we propose a novel end-to-end system for quadrotor obstacle avoidance using monocular optical flow. We develop an efficient differentiable simulator coupled with a simplified quadrotor model, allowing our policy to be trained directly through first-order gradient optimization. Additionally, we introduce a central flow attention mechanism and an action-guided active sensing strategy that enhances the policy's focus on task-relevant optical flow observations to enable more responsive decision-making during flight. Our system is validated both in simulation and the real world using an FPV racing drone. Despite being trained in a simple environment in simulation, our system is validated both in simulation and the real world using an FPV racing drone. Despite being trained in a simple environment in simulation, our system demonstrates agile and robust flight in various unknown, cluttered environments in the real world at speeds of up to 6m/s.","authors":["Yu Hu","Yuang Zhang","Yunlong Song","Yang Deng","Feng Yu","Linzuo Zhang","Weiyao Lin","Danping Zou","Wenxian Yu"],"url":"https://arxiv.org/abs/2411.04413"}
{"created":"2025-04-22","title":"Mining the Minoria: Unknown, Under-represented, and Under-performing Minority Groups","abstract":"Due to a variety of reasons, such as privacy, data in the wild often misses the grouping information required for identifying minorities. On the other hand, it is known that machine learning models are only as good as the data they are trained on and, hence, may underperform for the under-represented minority groups. The missing grouping information presents a dilemma for responsible data scientists who find themselves in an unknown-unknown situation, where not only do they not have access to the grouping attributes but do not also know what groups to consider.","authors":["Mohsen Dehghankar","Abolfazl Asudeh"],"url":"https://arxiv.org/abs/2411.04761"}
{"created":"2025-04-22","title":"CHATTER: A Character Attribution Dataset for Narrative Understanding","abstract":"Computational narrative understanding studies the identification, description, and interaction of the elements of a narrative: characters, attributes, events, and relations. Narrative research has given considerable attention to defining and classifying character types. However, these character-type taxonomies do not generalize well because they are small, too simple, or specific to a domain. We require robust and reliable benchmarks to test whether narrative models truly understand the nuances of the character's development in the story. Our work addresses this by curating the CHATTER dataset that labels whether a character portrays some attribute for 88124 character-attribute pairs, encompassing 2998 characters, 12967 attributes and 660 movies. We validate a subset of CHATTER, called CHATTEREVAL, using human annotations to serve as a benchmark to evaluate the character attribution task in movie scripts. \\evaldataset{} also assesses narrative understanding and the long-context modeling capacity of language models.","authors":["Sabyasachee Baruah","Shrikanth Narayanan"],"url":"https://arxiv.org/abs/2411.05227"}
{"created":"2025-04-22","title":"Aioli: A Unified Optimization Framework for Language Model Data Mixing","abstract":"Language model performance depends on identifying the optimal mixture of data groups to train on (e.g., law, code, math). Prior work has proposed a diverse set of methods to efficiently learn mixture proportions, ranging from fitting regression models over training runs to dynamically updating proportions throughout training. Surprisingly, we find that no existing method consistently outperforms a simple stratified sampling baseline in terms of average test perplexity. To understand this inconsistency, we unify existing methods into a standard framework, showing they are equivalent to solving a common optimization problem: minimize average loss subject to a method-specific mixing law -- an implicit assumption on the relationship between loss and mixture proportions. This framework suggests that measuring the fidelity of a method's mixing law can offer insights into its performance. Empirically, we find that existing methods set their mixing law parameters inaccurately, resulting in the inconsistent mixing performance we observe. Using this insight, we derive a new online method named Aioli, which directly estimates the mixing law parameters throughout training and uses them to dynamically adjust proportions. Aioli outperforms stratified sampling on 6 out of 6 datasets by an average of 0.27 test perplexity points, whereas existing methods fail to consistently beat stratified sampling, doing up to 6.9 points worse. Moreover, in a practical setting where proportions are learned on shorter runs due to computational constraints, Aioli can dynamically adjust these proportions over the full training run, consistently improving performance over existing methods by up to 12.012 test perplexity points.","authors":["Mayee F. Chen","Michael Y. Hu","Nicholas Lourie","Kyunghyun Cho","Christopher R\\'e"],"url":"https://arxiv.org/abs/2411.05735"}
{"created":"2025-04-22","title":"FactLens: Benchmarking Fine-Grained Fact Verification","abstract":"Large Language Models (LLMs) have shown impressive capability in language generation and understanding, but their tendency to hallucinate and produce factually incorrect information remains a key limitation. To verify LLM-generated contents and claims from other sources, traditional verification approaches often rely on holistic models that assign a single factuality label to complex claims, potentially obscuring nuanced errors. In this paper, we advocate for a shift toward fine-grained verification, where complex claims are broken down into smaller sub-claims for individual verification, allowing for more precise identification of inaccuracies, improved transparency, and reduced ambiguity in evidence retrieval. However, generating sub-claims poses challenges, such as maintaining context and ensuring semantic equivalence with respect to the original claim. We introduce FactLens, a benchmark for evaluating fine-grained fact verification, with metrics and automated evaluators of sub-claim quality. The benchmark data is manually curated to ensure high-quality ground truth. Our results show alignment between automated FactLens evaluators and human judgments, and we discuss the impact of sub-claim characteristics on the overall verification performance.","authors":["Kushan Mitra","Dan Zhang","Sajjadur Rahman","Estevam Hruschka"],"url":"https://arxiv.org/abs/2411.05980"}
{"created":"2025-04-22","title":"TinyML NLP Scheme for Semantic Wireless Sentiment Classification with Privacy Preservation","abstract":"Natural Language Processing (NLP) operations, such as semantic sentiment analysis and text synthesis, often raise privacy concerns and demand significant on-device computational resources. Centralized learning (CL) on the edge provides an energy-efficient alternative but requires collecting raw data, compromising user privacy. While federated learning (FL) enhances privacy, it imposes high computational energy demands on resource-constrained devices. This study provides insights into deploying privacy-preserving, energy-efficient NLP models on edge devices. We introduce semantic split learning (SL) as an energy-efficient, privacy-preserving tiny machine learning (TinyML) framework and compare it to FL and CL in the presence of Rayleigh fading and additive noise. Our results show that SL significantly reduces computational power and CO2 emissions while enhancing privacy, as evidenced by a fourfold increase in reconstruction error compared to FL and nearly eighteen times that of CL. In contrast, FL offers a balanced trade-off between privacy and efficiency. Our code is available for replication at our GitHub repository: https://github.com/AhmedRadwan02/TinyEco2AI-NLP.","authors":["Ahmed Y. Radwan","Mohammad Shehab","Mohamed-Slim Alouini"],"url":"https://arxiv.org/abs/2411.06291"}
{"created":"2025-04-22","title":"Deep Active Learning in the Open World","abstract":"Machine learning models deployed in open-world scenarios often encounter unfamiliar conditions and perform poorly in unanticipated situations. As AI systems advance and find application in safety-critical domains, effectively handling out-of-distribution (OOD) data is crucial to building open-world learning systems. In this work, we introduce ALOE, a novel active learning algorithm for open-world environments designed to enhance model adaptation by incorporating new OOD classes via a two-stage approach. First, diversity sampling selects a representative set of examples, followed by energy-based OOD detection to prioritize likely unknown classes for annotation. This strategy accelerates class discovery and learning, even under constrained annotation budgets. Evaluations on three long-tailed image classification benchmarks demonstrate that ALOE outperforms traditional active learning baselines, effectively expanding known categories while balancing annotation cost. Our findings reveal a crucial tradeoff between enhancing known-class performance and discovering new classes, setting the stage for future advancements in open-world machine learning.","authors":["Tian Xie","Jifan Zhang","Haoyue Bai","Robert Nowak"],"url":"https://arxiv.org/abs/2411.06353"}
{"created":"2025-04-22","title":"A Theoretical Analysis of Recommendation Loss Functions under Negative Sampling","abstract":"Loss functions like Categorical Cross Entropy (CCE), Binary Cross Entropy (BCE), and Bayesian Personalized Ranking (BPR) are commonly used in training Recommender Systems (RSs) to differentiate positive items - those interacted with by users - and negative items. While prior works empirically showed that CCE outperforms BCE and BPR when using the full set of negative items, we provide a theoretical explanation for this by proving that CCE offers the tightest lower bound on ranking metrics like Normalized Discounted Cumulative Gain (NDCG) and Mean Reciprocal Rank (MRR), followed by BPR and BCE. However, using the full set of negative items is computationally infeasible for large-scale RSs, prompting the use of negative sampling techniques. Under negative sampling, we reveal that BPR and CCE are equivalent when a single negative sample is drawn, and all three losses converge to the same global minimum. We further demonstrate that the sampled losses remain lower bounds for NDCG (MRR), albeit in a probabilistic sense. Our worst-case analysis shows that BCE offers the strongest bound on NDCG (MRR). Experiments on five datasets and four models empirically support these theoretical findings. Our code and supplementary material are available at https://github.com/federicosiciliano/recsys_losses.git.","authors":["Giulia Di Teodoro","Federico Siciliano","Nicola Tonellotto","Fabrizio Silvestri"],"url":"https://arxiv.org/abs/2411.07770"}
{"created":"2025-04-22","title":"LUDO: Low-Latency Understanding of Deformable Objects using Point Cloud Occupancy Functions","abstract":"Accurately determining the shape of objects and the location of their internal structures within deformable objects is crucial for medical tasks that require precise targeting, such as robotic biopsies. We introduce LUDO, a method for accurate low-latency understanding of deformable objects. LUDO reconstructs objects in their deformed state, including their internal structures, from a single-view point cloud observation in under 30 ms using occupancy networks. LUDO provides uncertainty estimates for its predictions. Additionally, it provides explainability by highlighting key features in its input observations. Both uncertainty and explainability are important for safety-critical applications such as surgical interventions. We demonstrate LUDO's abilities for autonomous targeting of internal regions of interest (ROIs) in deformable objects. %Additionally, LUDO provides uncertainty estimates and explainability for its predictions, both of which are important in safety-critical applications such as surgical interventions. We evaluate LUDO in real-world robotic experiments, achieving a success rate of 98.9% for puncturing various ROIs inside deformable objects. LUDO demonstrates the potential to interact with deformable objects without the need for deformable registration methods.","authors":["Pit Henrich","Franziska Mathis-Ullrich","Paul Maria Scheikl"],"url":"https://arxiv.org/abs/2411.08777"}
{"created":"2025-04-22","title":"Large Language Models as Robust Data Generators in Software Analytics: Are We There Yet?","abstract":"Large Language Model (LLM)-generated data is increasingly used in software analytics, but it is unclear how this data compares to human-written data, particularly when models are exposed to adversarial scenarios. Adversarial attacks can compromise the reliability and security of software systems, so understanding how LLM-generated data performs under these conditions, compared to human-written data, which serves as the benchmark for model performance, can provide valuable insights into whether LLM-generated data offers similar robustness and effectiveness. To address this gap, we systematically evaluate and compare the quality of human-written and LLM-generated data for fine-tuning robust pre-trained models (PTMs) in the context of adversarial attacks. We evaluate the robustness of six widely used PTMs, fine-tuned on human-written and LLM-generated data, before and after adversarial attacks. This evaluation employs nine state-of-the-art (SOTA) adversarial attack techniques across three popular software analytics tasks: clone detection, code summarization, and sentiment analysis in code review discussions. Additionally, we analyze the quality of the generated adversarial examples using eleven similarity metrics. Our findings reveal that while PTMs fine-tuned on LLM-generated data perform competitively with those fine-tuned on human-written data, they exhibit less robustness against adversarial attacks in software analytics tasks. Our study underscores the need for further exploration into enhancing the quality of LLM-generated training data to develop models that are both high-performing and capable of withstanding adversarial attacks in software analytics.","authors":["Md. Abdul Awal","Mrigank Rochan","Chanchal K. Roy"],"url":"https://arxiv.org/abs/2411.10565"}
{"created":"2025-04-22","title":"Spineless Traversal for Layout Invalidation","abstract":"Latency is a major concern for web rendering engines like those in Chrome, Safari, and Firefox. These engines reduce latency by using an incremental layout algorithm to redraw the page when the user interacts with it. In such an algorithm, elements that change frame-to-frame are marked dirty; only the dirty elements need be processed to draw the next frame, dramatically reducing latency. However, the standard incremental layout algorithm must search the page for dirty elements, accessing a number of auxiliary elements in the process. These auxiliary elements add cache misses and stalled cycles, and are responsible for a sizable fraction of all layout latency. We introduce a new, faster incremental layout algorithm called Spineless Traversal. Spineless Traversal uses a more computationally demanding priority queue algorithm to avoid the need to access auxiliary nodes and thus reduces cache traffic and stalls. This leads to dramatic speedups on the most latency-critical interactions such as hovering, typing, or animations. Moreover, thanks to numerous low-level optimizations, we are able to make Spineless Traversal competitive across the whole spectrum of incremental layout workloads. As a result, across 2216 benchmarks, Spineless Traversal is faster on 78.2% of the benchmark, with a mean speedup of 3.23x concentrated in the most latency-critical interactions such as hovering, typing, and animations.","authors":["Marisa Kirisame","Tiezhi Wang","Pavel Panchekha"],"url":"https://arxiv.org/abs/2411.10659"}
{"created":"2025-04-22","title":"Provable unlearning in topic modeling and downstream tasks","abstract":"Machine unlearning algorithms are increasingly important as legal concerns arise around the provenance of training data, but verifying the success of unlearning is often difficult. Provable guarantees for unlearning are often limited to supervised learning settings. In this paper, we provide the first theoretical guarantees for unlearning in the pre-training and fine-tuning paradigm by studying topic models, simple bag-of-words language models that can be adapted to solve downstream tasks like retrieval and classification. First, we design a provably effective unlearning algorithm for topic models that incurs a computational overhead independent of the size of the original dataset. Our analysis additionally quantifies the deletion capacity of the model -- i.e., the number of examples that can be unlearned without incurring a significant cost in model performance. Finally, we formally extend our analyses to account for adaptation to a given downstream task. In particular, we design an efficient algorithm to perform unlearning after fine-tuning the topic model via a linear head. Notably, we show that it is easier to unlearn pre-training data from models that have been fine-tuned to a particular task, and one can unlearn this data without modifying the base model.","authors":["Stanley Wei","Sadhika Malladi","Sanjeev Arora","Amartya Sanyal"],"url":"https://arxiv.org/abs/2411.12600"}
{"created":"2025-04-22","title":"Run-Length-Limited ISI-Mitigation (RLIM) Coding for Molecular Communication","abstract":"Inter-symbol interference (ISI) is a significant challenge in diffusion-based communication channels, where residual molecules from previous transmissions interfere with the current signal interval, leading to detection errors. We introduce a new infinite family of coding schemes, which we name RLIM, that require each 1-bit to be followed by at least i consecutive 0-bits, where i is any chosen positive integer. This enhances ISI mitigation and improves error correction capabilities compared to existing ISI-mitigating channel codes. Through extensive simulations, we demonstrate that the codebooks derived from the proposed RLIM scheme significantly reduce bit error rate compared to prominent coding methods. Simulation results also reveal that an important constraint in RLIM codes is redundant under zero-drift conditions, removal of which makes them equivalent to run-length-limited (RLL) codes. Notably, despite this equivalence, the proposed family of RLIM coding schemes retains a distinct power optimization constraint and employs a specialized error correction algorithm, preserving its unique character and advantages. Furthermore, in diffusion-based channels with time-varying drift, the previously redundant constraint becomes critical for ensuring robust detection, thus demonstrating the enhanced applicability of proposed RLIM codes for such channels as well.","authors":["Melih \\c{S}ahin","Ozgur B. Akan"],"url":"https://arxiv.org/abs/2411.15955"}
{"created":"2025-04-22","title":"Unraveling Arithmetic in Large Language Models: The Role of Algebraic Structures","abstract":"Large language models (LLMs) have demonstrated remarkable mathematical capabilities, largely driven by chain-of-thought (CoT) prompting, which decomposes complex reasoning into step-by-step solutions. This approach has enabled significant advancements, as evidenced by performance on benchmarks like GSM8K and MATH. However, the mechanisms underlying LLMs' ability to perform arithmetic in a single step of CoT remain poorly understood. Existing studies debate whether LLMs encode numerical values or rely on symbolic reasoning, while others explore attention and multi-layered processing in arithmetic tasks. In this work, we propose that LLMs learn arithmetic by capturing algebraic structures, such as commutativity and identity properties. Since these structures are observable through input-output relationships, they can generalize to unseen data. We empirically demonstrate that LLMs can learn algebraic structures using a custom dataset of arithmetic problems, as well as providing theoretical evidence showing that, under specific configurations of weights and biases, the transformer-based LLMs can generate embeddings that remain invariant to both permutations of input tokens and the presence of identity elements. Our findings indicate that leveraging algebraic structures can enhance the LLMs' arithmetic capabilities, offering insights into improving their arithmetic performance.","authors":["Fu-Chieh Chang","You-Chen Lin","Pei-Yuan Wu"],"url":"https://arxiv.org/abs/2411.16260"}
{"created":"2025-04-22","title":"Star Attention: Efficient LLM Inference over Long Sequences","abstract":"Inference with Transformer-based Large Language Models (LLMs) on long sequences is both costly and slow due to the quadratic complexity of the self-attention mechanism. We introduce Star Attention, a two-phase block-sparse approximation that improves computational efficiency by sharding attention across multiple hosts while minimizing communication overhead. In the first phase, the context is processed using blockwise-local attention across hosts, in parallel. In the second phase, query and response tokens attend to all prior cached tokens through sequence-global attention. Star Attention integrates seamlessly with most Transformer-based LLMs trained with global attention, reducing memory requirements and inference time by up to 11x while preserving 97-100% of accuracy.","authors":["Shantanu Acharya","Fei Jia","Boris Ginsburg"],"url":"https://arxiv.org/abs/2411.17116"}
{"created":"2025-04-22","title":"Automated Test Transfer Across Android Apps Using Large Language Models","abstract":"The pervasiveness of mobile apps in everyday life necessitates robust testing strategies to ensure quality and efficiency, especially through end-to-end usage-based tests for mobile apps' user interfaces (UIs). However, manually creating and maintaining such tests can be costly for developers. Since many apps share similar functionalities beneath diverse UIs, previous works have shown the possibility of transferring UI tests across different apps within the same domain, thereby eliminating the need for writing the tests manually. However, these methods have struggled to accommodate real-world variations, often facing limitations in scenarios where source and target apps are not very similar or fail to accurately transfer test oracles. This paper introduces an innovative technique, LLMigrate, which leverages Large Language Models (LLMs) to efficiently transfer usage-based UI tests across mobile apps. Our experimental evaluation shows LLMigrate can achieve a 97.5% success rate in automated test transfer, reducing the manual effort required to write tests from scratch by 91.1%. This represents an improvement of 9.1% in success rate and 38.2% in effort reduction compared to the best-performing prior technique, setting a new benchmark for automated test transfer.","authors":["Benyamin Beyzaei","Saghar Talebipour","Ghazal Rafiei","Nenad Medvidovic","Sam Malek"],"url":"https://arxiv.org/abs/2411.17933"}
{"created":"2025-04-22","title":"Decoding convolutional codes over finite rings. A linear dynamical systems approach","abstract":"Observable convolutional codes defined over Zpr with the Predictable Degree Property admits minimal input state output representations that behaves well under restriction of scalars. We make use of this fact to present Rosenthal's decoding algorithm for these convolutional codes. When combined with the Greferath-Vellbinger algorithm and a modified version of the Torrecillas-Lobillo-Navarro algorithm, the decoding problem reduces to selecting two decoding algorithms for linear block codes over a field. Finally, we analyze both the theoretical and practical error-correction capabilities of the combined algorithm,","authors":["\\'Angel Luis Mu\\~noz Casta\\~neda","Noem\\'i Decastro-Garc\\'ia","Miguel V. Carriegos"],"url":"https://arxiv.org/abs/2411.18316"}
{"created":"2025-04-22","title":"T2SG: Traffic Topology Scene Graph for Topology Reasoning in Autonomous Driving","abstract":"Understanding the traffic scenes and then generating high-definition (HD) maps present significant challenges in autonomous driving. In this paper, we defined a novel Traffic Topology Scene Graph, a unified scene graph explicitly modeling the lane, controlled and guided by different road signals (e.g., right turn), and topology relationships among them, which is always ignored by previous high-definition (HD) mapping methods. For the generation of T2SG, we propose TopoFormer, a novel one-stage Topology Scene Graph TransFormer with two newly designed layers. Specifically, TopoFormer incorporates a Lane Aggregation Layer (LAL) that leverages the geometric distance among the centerline of lanes to guide the aggregation of global information. Furthermore, we proposed a Counterfactual Intervention Layer (CIL) to model the reasonable road structure ( e.g., intersection, straight) among lanes under counterfactual intervention. Then the generated T2SG can provide a more accurate and explainable description of the topological structure in traffic scenes. Experimental results demonstrate that TopoFormer outperforms existing methods on the T2SG generation task, and the generated T2SG significantly enhances traffic topology reasoning in downstream tasks, achieving a state-of-the-art performance of 46.3 OLS on the OpenLane-V2 benchmark. We will release our source code and model.","authors":["Changsheng Lv","Mengshi Qi","Liang Liu","Huadong Ma"],"url":"https://arxiv.org/abs/2411.18894"}
{"created":"2025-04-22","title":"EF2X Exists For Four Agents","abstract":"We study the fair allocation of indivisible goods among a group of agents, aiming to limit the envy between any two agents. The central open problem in this literature, which has proven to be extremely challenging, is regarding the existence of an EFX allocation, i.e., an allocation such that any envy from some agent i toward another agent j would vanish if we were to remove any single good from the bundle allocated to j. When the agents' valuations are additive, which has been the main focus of prior works, Chaudhury et al. [2024] showed that an EFX allocation is guaranteed to exist for all instances involving up to three agents. Subsequently, Berger et al. [2022] extended this guarantee to nice-cancelable valuations and Akrami et al. [2023] to MMS-feasible valuations. However, the existence of EFX allocations for instances involving four agents remains open, even for additive valuations. We contribute to this literature by focusing on EF2X, a relaxation of EFX which requires that any envy toward some agent vanishes if any two of the goods allocated to that agent were to be removed. Our main result shows that EF2X allocations are guaranteed to exist for any instance with four agents, even for the class of cancelable valuations, which is more general than additive. Our proof is constructive, proposing an algorithm that computes such an allocation in pseudopolynomial time. Furthermore, for instances involving three agents we provide an algorithm that computes an EF2X allocation in polynomial time, in contrast to EFX, for which the fastest known algorithm for three agents is only pseudopolynomial.","authors":["Arash Ashuri","Vasilis Gkatzelis","Alkmini Sgouritsa"],"url":"https://arxiv.org/abs/2412.00254"}
{"created":"2025-04-22","title":"Simultaneously Satisfying MXS and EFL","abstract":"The two standard fairness notions in the resource allocation literature are proportionality and envy-freeness. If there are n agents competing for the available resources, then proportionality requires that each agent receives at least a 1/n fraction of their total value for the set of resources. On the other hand, envy-freeness requires that each agent weakly prefers the resources allocated to them over those allocated to any other agent. Each of these notions has its own benefits, but it is well known that neither one of the two is always achievable when the resources being allocated are indivisible. As a result, a lot of work has focused on satisfying fairness notions that relax either proportionality or envy-freeness. In this paper, we focus on MXS (a relaxation of proportionality) and EFL (a relaxation of envy-freeness). Each of these notions was previously shown to be achievable on its own [Barman et al.,2018, Caragiannis et al., 2023], and our main result is an algorithm that computes allocations that simultaneously satisfy both, combining the benefits of approximate proportionality and approximate envy-freeness. In fact, we prove this for any instance involving agents with valuation functions that are restricted MMS-feasible, which are more general than additive valuations. Also, since every EFL allocation directly satisfies other well-studied fairness notions like EF1, 1/2-EFX, 1/2-GMMS, and 2/3-PMMS, and every MXS allocation satisfies 4/7-MMS, the allocations returned by our algorithm simultaneously satisfy a wide variety of fairness notions and are, therefore, universally fair [Amanatidis et al., 2020].","authors":["Arash Ashuri","Vasilis Gkatzelis"],"url":"https://arxiv.org/abs/2412.00358"}
{"created":"2025-04-22","title":"Paint Outside the Box: Synthesizing and Selecting Training Data for Visual Grounding","abstract":"Visual grounding aims to localize the image regions based on a textual query. Given the difficulty of large-scale data curation, we investigate how to effectively learn visual grounding under data-scarce settings in this paper. To address the data scarcity, we propose a novel framework, POBF (Paint Outside the Box and Filter). POBF synthesizes images by inpainting outside the box, tackling a label misalignment issue encountered in previous works. Furthermore, POBF leverages an innovative filtering scheme to select the most effective training data. This scheme combines a hardness score and an overfitting score, balanced by a penalty term. Extensive experiments across four benchmark datasets demonstrate that POBF consistently improves performance, achieving an average gain of 5.83\\% over the real-data-only method and outperforming leading baselines by 2.29\\%-3.85\\% in accuracy. Additionally, we validate the robustness and generalizability of POBF across various generative models, training data sizes, and model architectures.","authors":["Zilin Du","Haoxin Li","Jianfei Yu","Boyang Li"],"url":"https://arxiv.org/abs/2412.00684"}
{"created":"2025-04-22","title":"ULSR-GS: Ultra Large-scale Surface Reconstruction Gaussian Splatting with Multi-View Geometric Consistency","abstract":"While Gaussian Splatting (GS) demonstrates efficient and high-quality scene rendering and small area surface extraction ability, it falls short in handling large-scale aerial image surface extraction tasks. To overcome this, we present ULSR-GS, a framework dedicated to high-fidelity surface extraction in ultra-large-scale scenes, addressing the limitations of existing GS-based mesh extraction methods. Specifically, we propose a point-to-photo partitioning approach combined with a multi-view optimal view matching principle to select the best training images for each sub-region. Additionally, during training, ULSR-GS employs a densification strategy based on multi-view geometric consistency to enhance surface extraction details. Experimental results demonstrate that ULSR-GS outperforms other state-of-the-art GS-based works on large-scale aerial photogrammetry benchmark datasets, significantly improving surface extraction accuracy in complex urban environments. Project page: https://ulsrgs.github.io.","authors":["Zhuoxiao Li","Shanliang Yao","Yong Yue","Wufan Zhao","Rongjun Qin","Angel F. Garcia-Fernandez","Andrew Levers","Xiaohui Zhu"],"url":"https://arxiv.org/abs/2412.01402"}
{"created":"2025-04-22","title":"GFreeDet: Exploiting Gaussian Splatting and Foundation Models for Model-free Unseen Object Detection in the BOP Challenge 2024","abstract":"We present GFreeDet, an unseen object detection approach that leverages Gaussian splatting and vision Foundation models under model-free setting. Unlike existing methods that rely on predefined CAD templates, GFreeDet reconstructs objects directly from reference videos using Gaussian splatting, enabling robust detection of novel objects without prior 3D models. Evaluated on the BOP-H3 benchmark, GFreeDet achieves comparable performance to CAD-based methods, demonstrating the viability of model-free detection for mixed reality (MR) applications. Notably, GFreeDet won the best overall method and the best fast method awards in the model-free 2D detection track at BOP Challenge 2024.","authors":["Xingyu Liu","Gu Wang","Chengxi Li","Yingyue Li","Chenyangguang Zhang","Ziqin Huang","Xiangyang Ji"],"url":"https://arxiv.org/abs/2412.01552"}
{"created":"2025-04-22","title":"WikiHint: A Human-Annotated Dataset for Hint Ranking and Generation","abstract":"The use of Large Language Models (LLMs) has increased significantly with users frequently asking questions to chatbots. In the time when information is readily accessible, it is crucial to stimulate and preserve human cognitive abilities and maintain strong reasoning skills. This paper addresses such challenges by promoting the use of hints as an alternative or a supplement to direct answers. We first introduce a manually constructed hint dataset, WikiHint, which is based on Wikipedia and includes 5,000 hints created for 1,000 questions. We then finetune open-source LLMs for hint generation in answer-aware and answer-agnostic contexts. We assess the effectiveness of the hints with human participants who answer questions with and without the aid of hints. Additionally, we introduce a lightweight evaluation method, HintRank, to evaluate and rank hints in both answer-aware and answer-agnostic settings. Our findings show that (a) the dataset helps generate more effective hints, (b) including answer information along with questions generally improves the quality of generated hints, and (c) encoder-based models perform better than decoder-based models in hint ranking.","authors":["Jamshid Mozafari","Florian Gerhold","Adam Jatowt"],"url":"https://arxiv.org/abs/2412.01626"}
{"created":"2025-04-22","title":"Linearly Homomorphic Signature with Tight Security on Lattice","abstract":"At present, in lattice-based linearly homomorphic signature schemes, especially under the standard model, there are very few schemes with tight security. This paper constructs the first lattice-based linearly homomorphic signature scheme that achieves tight security against existential unforgeability under chosen-message attacks (EUF-CMA) in the standard model. Furthermore, among existing schemes, the scheme proposed in this paper also offers certain advantages in terms of public key size, signature length, and computational cost.","authors":["Heng Guo","Kun Tian","Fengxia Liu","Zhiyong Zheng"],"url":"https://arxiv.org/abs/2412.01641"}
{"created":"2025-04-22","title":"EvRT-DETR: Latent Space Adaptation of Image Detectors for Event-based Vision","abstract":"Event-based cameras (EBCs) have emerged as a bio-inspired alternative to traditional cameras, offering advantages in power efficiency, temporal resolution, and high dynamic range. However, the development of image analysis methods for EBCs is challenging due to the sparse and asynchronous nature of the data. This work addresses the problem of object detection for EBC cameras. The current approaches to EBC object detection focus on constructing complex data representations and rely on specialized architectures. We introduce I2EvDet (Image-to-Event Detection), a novel adaptation framework that bridges mainstream object detection with temporal event data processing. First, we demonstrate that a Real-Time DEtection TRansformer, or RT-DETR, a state-of-the-art natural image detector, trained on a simple image-like representation of the EBC data achieves performance comparable to specialized EBC methods. Next, as part of our framework, we develop an efficient adaptation technique that transforms image-based detectors into event-based detection models by modifying their frozen latent representation space through minimal architectural additions. The resulting EvRT-DETR model reaches state-of-the-art performance on the standard benchmark datasets Gen1 (mAP $+2.3$) and 1Mpx/Gen4 (mAP $+1.4$). These results demonstrate a fundamentally new approach to EBC object detection through principled adaptation of mainstream architectures, offering an efficient alternative with potential applications to other temporal visual domains. The code is available at: https://github.com/realtime-intelligence/evrt-detr","authors":["Dmitrii Torbunov","Yihui Ren","Animesh Ghose","Odera Dim","Yonggang Cui"],"url":"https://arxiv.org/abs/2412.02890"}
{"created":"2025-04-22","title":"Assessing and Learning Alignment of Unimodal Vision and Language Models","abstract":"How well are unimodal vision and language models aligned? Although prior work have approached answering this question, their assessment methods do not directly translate to how these models are used in practical vision-language tasks. In this paper, we propose a direct assessment method, inspired by linear probing, to assess vision-language alignment. We identify that the degree of alignment of the SSL vision models depends on their SSL training objective, and we find that the clustering quality of SSL representations has a stronger impact on alignment performance than their linear separability. Next, we introduce Swift Alignment of Image and Language (SAIL), a efficient transfer learning framework that aligns pretrained unimodal vision and language models for downstream vision-language tasks. Since SAIL leverages the strengths of pretrained unimodal models, it requires significantly fewer (6%) paired image-text data for the multimodal alignment compared to models like CLIP which are trained from scratch. SAIL training only requires a single A100 GPU, 5 hours of training and can accommodate a batch size up to 32,768. SAIL achieves 73.4% zero-shot accuracy on ImageNet (vs. CLIP's 72.7%) and excels in zero-shot retrieval, complex reasoning, and semantic segmentation. Additionally, SAIL improves the language-compatibility of vision encoders that in turn enhance the performance of multimodal large language models. The entire codebase and model weights are open-source: https://lezhang7.github.io/sail.github.io/","authors":["Le Zhang","Qian Yang","Aishwarya Agrawal"],"url":"https://arxiv.org/abs/2412.04616"}
{"created":"2025-04-22","title":"A Unified Approach for Multi-granularity Search over Spatial Datasets","abstract":"There has been increased interest in data search as a means to find relevant datasets or data points in data lakes and repositories. Although approaches have been proposed to support spatial dataset search and data point search, they consider the two types of searches independently. To enable search operations ranging from the coarse-grained dataset level to the fine-grained data point level, we provide an integrated one that supports diverse query types and distance metrics. In this paper, we focus on designing a multi-granularity spatial data search system, called Spadas, that supports both dataset and data point search operations. To address the challenges of the high cost of indexing and susceptibility to outliers, we propose a unified index that can drastically improve query efficiency in various scenarios by organizing data reasonably and removing outliers in datasets. Moreover, to accelerate all data search operations, we propose a set of pruning mechanisms based on the unified index, including fast bound estimation, approximation technique with error bound, and pruning in batch techniques, to effectively filter out non-relevant datasets and points. Finally, we report the results of a detailed experimental evaluation using six spatial data repositories, achieving orders of magnitude faster than the state-of-the-art algorithms and demonstrating the effectiveness by case study. An online spatial data search system of Spadas is also implemented and made accessible to users.","authors":["Wenzhe Yang","Sheng Wang","Shixun Huang","Yuyang Liao","Yuan Sun","Juliana Freire","Zhiyong Peng"],"url":"https://arxiv.org/abs/2412.04805"}
{"created":"2025-04-22","title":"Training neural networks without backpropagation using particles","abstract":"Neural networks are a group of neurons stacked together in multiple layers to mimic the biological neurons in a human brain. Neural networks have been trained using the backpropagation algorithm based on gradient descent strategy for several decades. Several variants have been developed to improve the backpropagation algorithm. The loss function for the neural network is optimized through backpropagation, but several local minima exist in the manifold of the constructed neural network. We obtain several solutions matching the minima. The gradient descent strategy cannot avoid the problem of local minima and gets stuck in the minima due to the initialization. Particle swarm optimization (PSO) was proposed to select the best local minima among the search space of the loss function. The search space is limited to the instantiated particles in the PSO algorithm, and sometimes it cannot select the best solution. In the proposed approach, we overcome the problem of gradient descent and the limitation of the PSO algorithm by training individual neurons separately, capable of collectively solving the problem as a group of neurons forming a network. Our code and data are available at https://github.com/dipkmr/train-nn-wobp/","authors":["Deepak Kumar"],"url":"https://arxiv.org/abs/2412.05667"}
{"created":"2025-04-22","title":"Hierarchical Split Federated Learning: Convergence Analysis and System Optimization","abstract":"As AI models expand in size, it has become increasingly challenging to deploy federated learning (FL) on resource-constrained edge devices. To tackle this issue, split federated learning (SFL) has emerged as an FL framework with reduced workload on edge devices via model splitting; it has received extensive attention from the research community in recent years. Nevertheless, most prior works on SFL focus only on a two-tier architecture without harnessing multi-tier cloudedge computing resources. In this paper, we intend to analyze and optimize the learning performance of SFL under multi-tier systems. Specifically, we propose the hierarchical SFL (HSFL) framework and derive its convergence bound. Based on the theoretical results, we formulate a joint optimization problem for model splitting (MS) and model aggregation (MA). To solve this rather hard problem, we then decompose it into MS and MA subproblems that can be solved via an iterative descending algorithm. Simulation results demonstrate that the tailored algorithm can effectively optimize MS and MA for SFL within virtually any multi-tier system.","authors":["Zheng Lin","Wei Wei","Zhe Chen","Chan-Tong Lam","Xianhao Chen","Yue Gao","Jun Luo"],"url":"https://arxiv.org/abs/2412.07197"}
{"created":"2025-04-22","title":"3DSRBench: A Comprehensive 3D Spatial Reasoning Benchmark","abstract":"3D spatial reasoning is the ability to analyze and interpret the positions, orientations, and spatial relationships of objects within the 3D space. This allows models to develop a comprehensive understanding of the 3D scene, enabling their applicability to a broader range of areas, such as autonomous navigation, robotics, and AR/VR. While large multi-modal models (LMMs) have achieved remarkable progress in a wide range of image and video understanding tasks, their capabilities to perform 3D spatial reasoning on diverse natural images are less studied. In this work we present the first comprehensive 3D spatial reasoning benchmark, 3DSRBench, with 2,772 manually annotated visual question-answer pairs across 12 question types. We conduct robust and thorough evaluation of 3D spatial reasoning capabilities by balancing the data distribution and adopting a novel FlipEval strategy. To further study the robustness of 3D spatial reasoning w.r.t. camera 3D viewpoints, our 3DSRBench includes two subsets with 3D spatial reasoning questions on paired images with common and uncommon viewpoints. We benchmark a wide range of open-sourced and proprietary LMMs, uncovering their limitations in various aspects of 3D awareness, such as height, orientation, location, and multi-object reasoning, as well as their degraded performance on images with uncommon camera viewpoints. Our 3DSRBench provide valuable findings and insights about the future development of LMMs with strong 3D reasoning capabilities. Our project page and dataset is available https://3dsrbench.github.io.","authors":["Wufei Ma","Haoyu Chen","Guofeng Zhang","Celso M de Melo","Jieneng Chen","Alan Yuille"],"url":"https://arxiv.org/abs/2412.07825"}
{"created":"2025-04-22","title":"Steganography in Game Actions","abstract":"The exchange of messages has always carried with it the timeless challenge of secrecy. From whispers in shadows to the enigmatic notes written in the margins of history, humanity has long sought ways to convey thoughts that remain imperceptible to all but the chosen few. The challenge of subliminal communication has been addressed in various forms of steganography. However, the field faces a fundamental paradox: as the art of concealment advances, so too does the science of revelation, leading to an ongoing evolutionary interplay. This study seeks to extend the boundaries of what is considered a viable steganographic medium. We explore a steganographic paradigm, in which hidden information is communicated through the episodes of multiple agents interacting with an environment. Each agent, acting as an encoder, learns a policy to disguise the very existence of hidden messages within actions seemingly directed toward innocent objectives. Meanwhile, an observer, serving as a decoder, learns to associate behavioural patterns with their respective agents despite their dynamic nature, thereby unveiling the hidden messages. The interactions of agents are governed by the framework of multi-agent reinforcement learning and shaped by feedback from the observer. This framework encapsulates a game-theoretic dilemma, wherein agents face decisions between cooperating to create distinguishable behavioural patterns or defecting to pursue individually optimal yet potentially overlapping episodic actions. As a proof of concept, we exemplify action steganography through the game of labyrinth, a navigation task where subliminal communication is concealed within the act of steering toward a destination, and systematically validate the stego-system in terms of distortion, capacity, secrecy and robustness when subjected to simulated passive and active adversaries.","authors":["Ching-Chun Chang","Isao Echizen"],"url":"https://arxiv.org/abs/2412.10442"}
{"created":"2025-04-22","title":"Soft and Constrained Hypertree Width","abstract":"Hypertree decompositions provide a way to evaluate Conjunctive Queries (CQs) in polynomial time, where the exponent of this polynomial is determined by the width of the decomposition. In theory, the goal of efficient CQ evaluation therefore has to be a minimisation of the width. However, in practical settings, it turns out that there are also other properties of a decomposition that influence the performance of query evaluation. It is therefore of interest to restrict the computation of decompositions by constraints and to guide this computation by preferences. To this end, we propose a novel framework based on candidate tree decompositions, which allows us to introduce soft hypertree width (shw). This width measure is a relaxation of hypertree width (hw); it is never greater than hw and, in some cases, shw may actually be lower than hw. Most importantly, shw preserves the tractability of deciding if a given CQ is below some fixed bound, while offering more algorithmic flexibility. In particular, it provides a natural way to incorporate preferences and constraints into the computation of decompositions. A prototype implementation and preliminary experiments confirm that this novel framework can indeed have a practical impact on query evaluation.","authors":["Matthias Lanzinger","Cem Okulmus","Reinhard Pichler","Alexander Selzer","Georg Gottlob"],"url":"https://arxiv.org/abs/2412.11669"}
{"created":"2025-04-22","title":"Unanswerability Evaluation for Retrieval Augmented Generation","abstract":"Existing evaluation frameworks for retrieval-augmented generation (RAG) systems focus on answerable queries, but they overlook the importance of appropriately rejecting unanswerable requests. In this paper, we introduce UAEval4RAG, a framework designed to evaluate whether RAG systems can handle unanswerable queries effectively. We define a taxonomy with six unanswerable categories, and UAEval4RAG automatically synthesizes diverse and challenging queries for any given knowledge base with unanswered ratio and acceptable ratio metrics. We conduct experiments with various RAG components, including retrieval models, rewriting methods, rerankers, language models, and prompting strategies, and reveal hidden trade-offs in performance of RAG systems. Our findings highlight the critical role of component selection and prompt design in optimizing RAG systems to balance the accuracy of answerable queries with high rejection rates of unanswerable ones. UAEval4RAG provides valuable insights and tools for developing more robust and reliable RAG systems.","authors":["Xiangyu Peng","Prafulla Kumar Choubey","Caiming Xiong","Chien-Sheng Wu"],"url":"https://arxiv.org/abs/2412.12300"}
{"created":"2025-04-22","title":"An Adaptive Balance Search Based Complementary Heterogeneous Particle Swarm Optimization Architecture","abstract":"A series of modified cognitive-only particle swarm optimization (PSO) algorithms effectively mitigate premature convergence by constructing distinct vectors for different particles. However, the underutilization of these constructed vectors hampers convergence accuracy. In this paper, an adaptive balance search based complementary heterogeneous PSO architecture is proposed, which consists of a complementary heterogeneous PSO (CHxPSO) framework and an adaptive balance search (ABS) strategy. The CHxPSO framework mainly includes two update channels and two subswarms. Two channels exhibit nearly heterogeneous properties while sharing a common constructed vector. This ensures that one constructed vector is utilized across both heterogeneous update mechanisms. The two subswarms work within their respective channels during the evolutionary process, preventing interference between the two channels. The ABS strategy precisely controls the proportion of particles involved in the evolution in the two channels, and thereby guarantees the flexible utilization of the constructed vectors, based on the evolutionary process and the interactions with the problem's fitness landscape. Together, our architecture ensures the effective utilization of the constructed vectors by emphasizing exploration in the early evolutionary process while exploitation in the later, enhancing the performance of a series of modified cognitive-only PSOs. Extensive experimental results demonstrate the generalization performance of our architecture.","authors":["Zhenxing Zhang","Tianxian Zhang","Xiangliang Xu"],"url":"https://arxiv.org/abs/2412.12694"}
{"created":"2025-04-22","title":"SAUGE: Taming SAM for Uncertainty-Aligned Multi-Granularity Edge Detection","abstract":"Edge labels are typically at various granularity levels owing to the varying preferences of annotators, thus handling the subjectivity of per-pixel labels has been a focal point for edge detection. Previous methods often employ a simple voting strategy to diminish such label uncertainty or impose a strong assumption of labels with a pre-defined distribution, e.g., Gaussian. In this work, we unveil that the segment anything model (SAM) provides strong prior knowledge to model the uncertainty in edge labels. Our key insight is that the intermediate SAM features inherently correspond to object edges at various granularities, which reflects different edge options due to uncertainty. Therefore, we attempt to align uncertainty with granularity by regressing intermediate SAM features from different layers to object edges at multi-granularity levels. In doing so, the model can fully and explicitly explore diverse ``uncertainties'' in a data-driven fashion. Specifically, we inject a lightweight module (~ 1.5% additional parameters) into the frozen SAM to progressively fuse and adapt its intermediate features to estimate edges from coarse to fine. It is crucial to normalize the granularity level of human edge labels to match their innate uncertainty. For this, we simply perform linear blending to the real edge labels at hand to create pseudo labels with varying granularities. Consequently, our uncertainty-aligned edge detector can flexibly produce edges at any desired granularity (including an optimal one). Thanks to SAM, our model uniquely demonstrates strong generalizability for cross-dataset edge detection. Extensive experimental results on BSDS500, Muticue and NYUDv2 validate our model's superiority.","authors":["Xing Liufu","Chaolei Tan","Xiaotong Lin","Yonggang Qi","Jinxuan Li","Jian-Fang Hu"],"url":"https://arxiv.org/abs/2412.12892"}
{"created":"2025-04-22","title":"System-Level Experimental Evaluation of Reconfigurable Intelligent Surfaces for NextG Communication Systems","abstract":"Reconfigurable Intelligent Surfaces (RISs) are a promising technique for enhancing the performance of Next Generation (NextG) wireless communication systems in terms of both spectral and energy efficiency, as well as resource utilization. However, current RIS research has primarily focused on theoretical modeling and Physical (PHY) layer considerations only. Full protocol stack emulation and accurate modeling of the propagation characteristics of the wireless channel are necessary for studying the benefits introduced by RIS technology across various spectrum bands and use-cases. In this paper, we propose, for the first time: (i) accurate PHY layer RIS-enabled channel modeling through Geometry-Based Stochastic Models (GBSMs), leveraging the QUAsi Deterministic RadIo channel GenerAtor (QuaDRiGa) open-source statistical ray-tracer; (ii) optimized resource allocation with RISs by comprehensively studying energy efficiency and power control on different portions of the spectrum through a single-leader multiple-followers Stackelberg game theoretical approach; (iii) full-stack emulation and performance evaluation of RIS-assisted channels with SCOPE/srsRAN for Enhanced Mobile Broadband (eMBB) and Ultra Reliable and Low Latency Communications (URLLC) applications in the worlds largest emulator of wireless systems with hardware-in-the-loop, namely Colosseum. Our findings indicate (i) the significant power savings in terms of energy efficiency achieved with RIS-assisted topologies, especially in the millimeter wave (mmWave) band; and (ii) the benefits introduced for Sub-6 GHz band User Equipments (UEs), where the deployment of a relatively small RIS (e.g., in the order of 100 RIS elements) can result in decreased levels of latency for URLLC services in resource-constrained environments.","authors":["Maria Tsampazi","Tommaso Melodia"],"url":"https://arxiv.org/abs/2412.12969"}
{"created":"2025-04-22","title":"StreetCrafter: Street View Synthesis with Controllable Video Diffusion Models","abstract":"This paper aims to tackle the problem of photorealistic view synthesis from vehicle sensor data. Recent advancements in neural scene representation have achieved notable success in rendering high-quality autonomous driving scenes, but the performance significantly degrades as the viewpoint deviates from the training trajectory. To mitigate this problem, we introduce StreetCrafter, a novel controllable video diffusion model that utilizes LiDAR point cloud renderings as pixel-level conditions, which fully exploits the generative prior for novel view synthesis, while preserving precise camera control. Moreover, the utilization of pixel-level LiDAR conditions allows us to make accurate pixel-level edits to target scenes. In addition, the generative prior of StreetCrafter can be effectively incorporated into dynamic scene representations to achieve real-time rendering. Experiments on Waymo Open Dataset and PandaSet demonstrate that our model enables flexible control over viewpoint changes, enlarging the view synthesis regions for satisfying rendering, which outperforms existing methods.","authors":["Yunzhi Yan","Zhen Xu","Haotong Lin","Haian Jin","Haoyu Guo","Yida Wang","Kun Zhan","Xianpeng Lang","Hujun Bao","Xiaowei Zhou","Sida Peng"],"url":"https://arxiv.org/abs/2412.13188"}
{"created":"2025-04-22","title":"Driving Innovation in 6G Wireless Technologies: The OpenAirInterface Approach","abstract":"The development of 6G wireless technologies is rapidly advancing, with the 3rd Generation Partnership Project (3GPP) entering the pre-standardization phase and aiming to deliver the first specifications by 2028. This paper explores the OpenAirInterface (OAI) project, an open-source initiative that plays a crucial role in the evolution of 5G and future 6G networks. OAI provides a comprehensive implementation of 3GPP and O-RAN compliant networks, including Radio Access Network (RAN), Core Network (CN), and software-defined User Equipment (UE) components. This paper details the history and evolution of OAI, its licensing model, and the various projects under its umbrella, such as RAN, the CN, and the Operations, Administration and Maintenance (OAM) projects. It also highlights the development methodology, Continuous Integration/Continuous Delivery (CI/CD) processes, and end-to-end systems powered by OAI. Furthermore, the paper discusses the potential of OAI for 6G research, focusing on spectrum, reflective intelligent surfaces, and Artificial Intelligence (AI)/Machine Learning (ML) integration. The open-source approach of OAI is emphasized as essential for tackling the challenges of 6G, fostering community collaboration, and driving innovation in next-generation wireless technologies.","authors":["Florian Kaltenberger","Tommaso Melodia","Irfan Ghauri","Michele Polese","Raymond Knopp","Tien Thinh Nguyen","Sakthivel Velumani","Davide Villa","Leonardo Bonati","Robert Schmidt","Sagar Arora","Mikel Irazabal","Navid Nikaein"],"url":"https://arxiv.org/abs/2412.13295"}
{"created":"2025-04-22","title":"Quantum Codes from Group Ring Codes","abstract":"This article examines group ring codes over finite fields and finite groups. We also present a section on two-dimensional cyclic codes in the quotient ring $\\mathbb{F}_q[x, y] / \\langle x^{l} - 1, y^{m} - 1 \\rangle$. These two-dimensional cyclic codes can be analyzed using the group ring $\\mathbb{F}_q(C_{l} \\times C_{m})$, where $C_{l}$ and $C_{m}$ represent cyclic groups of orders $l$ and $m$, respectively. The aim is to show that studying group ring codes provides a more compact approach compared to the quotient ring method. We further extend this group ring framework to study codes over other group structures, such as the dihedral group, direct products of cyclic and dihedral groups, direct products of two cyclic groups, and semidirect products of two groups. Additionally, we explore necessary and sufficient conditions for such group ring codes to be self-orthogonal under Euclidean, Hermitian, and symplectic inner products and propose a construction for quantum codes.","authors":["Kanat Abdukhalikov (UAEU)","Tushar Bag (LIP","QINFO)","Daniel Panario"],"url":"https://arxiv.org/abs/2412.13616"}
{"created":"2025-04-22","title":"State Space Models are Strong Text Rerankers","abstract":"Transformers dominate NLP and IR; but their inference inefficiencies and challenges in extrapolating to longer contexts have sparked interest in alternative model architectures. Among these, state space models (SSMs) like Mamba offer promising advantages, particularly $O(1)$ time complexity in inference. Despite their potential, SSMs' effectiveness at text reranking\\, -- \\,a task requiring fine-grained query-document interaction and long-context understanding\\, -- \\,remains underexplored. This study benchmarks SSM-based architectures (specifically, Mamba-1 and Mamba-2) against transformer-based models across various scales, architectures, and pre-training objectives, focusing on performance and efficiency in text reranking tasks. We find that (1) Mamba architectures achieve competitive text ranking performance, comparable to transformer-based models of similar size; (2) they are less efficient in training and inference compared to transformers with flash attention; and (3) Mamba-2 outperforms Mamba-1 in both performance and efficiency. These results underscore the potential of state space models as a transformer alternative and highlight areas for improvement in future IR applications.","authors":["Zhichao Xu","Jinghua Yan","Ashim Gupta","Vivek Srikumar"],"url":"https://arxiv.org/abs/2412.14354"}
{"created":"2025-04-22","title":"Affordance-Aware Object Insertion via Mask-Aware Dual Diffusion","abstract":"As a common image editing operation, image composition involves integrating foreground objects into background scenes. In this paper, we expand the application of the concept of Affordance from human-centered image composition tasks to a more general object-scene composition framework, addressing the complex interplay between foreground objects and background scenes. Following the principle of Affordance, we define the affordance-aware object insertion task, which aims to seamlessly insert any object into any scene with various position prompts. To address the limited data issue and incorporate this task, we constructed the SAM-FB dataset, which contains over 3 million examples across more than 3,000 object categories. Furthermore, we propose the Mask-Aware Dual Diffusion (MADD) model, which utilizes a dual-stream architecture to simultaneously denoise the RGB image and the insertion mask. By explicitly modeling the insertion mask in the diffusion process, MADD effectively facilitates the notion of affordance. Extensive experimental results show that our method outperforms the state-of-the-art methods and exhibits strong generalization performance on in-the-wild images. Please refer to our code on https://github.com/KaKituken/affordance-aware-any.","authors":["Jixuan He","Wanhua Li","Ye Liu","Junsik Kim","Donglai Wei","Hanspeter Pfister"],"url":"https://arxiv.org/abs/2412.14462"}
{"created":"2025-04-22","title":"Offline Safe Reinforcement Learning Using Trajectory Classification","abstract":"Offline safe reinforcement learning (RL) has emerged as a promising approach for learning safe behaviors without engaging in risky online interactions with the environment. Most existing methods in offline safe RL rely on cost constraints at each time step (derived from global cost constraints) and this can result in either overly conservative policies or violation of safety constraints. In this paper, we propose to learn a policy that generates desirable trajectories and avoids undesirable trajectories. To be specific, we first partition the pre-collected dataset of state-action trajectories into desirable and undesirable subsets. Intuitively, the desirable set contains high reward and safe trajectories, and undesirable set contains unsafe trajectories and low-reward safe trajectories. Second, we learn a policy that generates desirable trajectories and avoids undesirable trajectories, where (un)desirability scores are provided by a classifier learnt from the dataset of desirable and undesirable trajectories. This approach bypasses the computational complexity and stability issues of a min-max objective that is employed in existing methods. Theoretically, we also show our approach's strong connections to existing learning paradigms involving human feedback. Finally, we extensively evaluate our method using the DSRL benchmark for offline safe RL. Empirically, our method outperforms competitive baselines, achieving higher rewards and better constraint satisfaction across a wide variety of benchmark tasks.","authors":["Ze Gong","Akshat Kumar","Pradeep Varakantham"],"url":"https://arxiv.org/abs/2412.15429"}
{"created":"2025-04-22","title":"Hybrid Beamforming Design for RSMA-enabled Near-Field Integrated Sensing and Communications","abstract":"Integrated sensing and communication (ISAC) networks leverage extremely large antenna arrays and high frequencies. This inevitably extends the Rayleigh distance, making near-field (NF) spherical wave propagation dominant. This unlocks numerous spatial degrees of freedom, raising the challenge of optimizing them for communication and sensing tradeoffs. To this end, we propose a rate-splitting multiple access (RSMA)-based NF-ISAC transmit scheme utilizing hybrid analog-digital antennas. RSMA enhances interference management, while a variable number of dedicated sensing beams adds beamforming flexibility. The objective is to maximize the minimum communication rate while ensuring multi-target sensing performance by jointly optimizing receive filters, analog and digital beamformers, common rate allocation, and the sensing beam count. To address uncertainty in sensing beam allocation, a rank-zero solution reconstruction method demonstrates that dedicated sensing beams are unnecessary for NF multi-target detection. A penalty dual decomposition (PDD)-based double-loop algorithm is introduced, employing weighted minimum mean-squared error (WMMSE) and quadratic transforms to reformulate communication and sensing rates. Simulations reveal that the proposed scheme: 1) achieves performance comparable to fully digital beamforming with fewer RF chains, (2) maintains NF multi-target detection without compromising communication rates, and 3) significantly outperforms conventional multiple access schemes and far-field ISAC systems.","authors":["Jiasi Zhou","Chintha Tellambura","Geoffrey Ye Li"],"url":"https://arxiv.org/abs/2412.17062"}
{"created":"2025-04-22","title":"Parallel Contraction Hierarchies Can Be Efficient and Scalable","abstract":"Contraction Hierarchies (CH) (Geisberger et al., 2008) is one of the most widely used algorithms for shortest-path queries on road networks. Compared to Dijkstra's algorithm, CH enables orders of magnitude faster query performance through a preprocessing phase, which iteratively categorizes vertices into hierarchies and adds shortcuts. However, constructing a CH is an expensive task. Existing solutions, including parallel ones, may suffer from long construction time. Especially in our experiments, we observe that existing parallel solutions demonstrate unsatisfactory scalability and have close performance to sequential algorithms.","authors":["Zijin Wan","Xiaojun Dong","Letong Wang","Enzuo Zhu","Yan Gu","Yihan Sun"],"url":"https://arxiv.org/abs/2412.18008"}
{"created":"2025-04-22","title":"The EnvDesign Model: A Method to Solve the Environment Design Problem","abstract":"Today, several people and organizations rely on cloud platforms. The reliability of cloud platforms depends heavily on the performance of their internal programs (agents). To better prevent regressions in cloud platforms, the design of pre-production testing environments (that test new agents, new hardwares, and other changes) must take into account the diversity of server/node properties (hardware model, virtual machine type, etc.) across the fleet and dynamically emphasize or de-emphasize the prevalence of certain node properties based on current testing priorities. This paper formulates this task as the ``environment design\" problem and presents the EnvDesign model, a method that uses graph theory and optimization algorithms to solve the environment design problem. The EnvDesign model was built on context and techniques that apply to combinatorial testing in general, so it can support combinatorial testing in other domains. An earlier version of this paper was peer-reviewed and published internally at Microsoft.","authors":["Akshay Sathiya","Rohit Pandey"],"url":"https://arxiv.org/abs/2412.18109"}
{"created":"2025-04-22","title":"TSceneJAL: Joint Active Learning of Traffic Scenes for 3D Object Detection","abstract":"Most autonomous driving (AD) datasets incur substantial costs for collection and labeling, inevitably yielding a plethora of low-quality and redundant data instances, thereby compromising performance and efficiency. Many applications in AD systems necessitate high-quality training datasets using both existing datasets and newly collected data. In this paper, we propose a traffic scene joint active learning (TSceneJAL) framework that can efficiently sample the balanced, diverse, and complex traffic scenes from both labeled and unlabeled data. The novelty of this framework is threefold: 1) a scene sampling scheme based on a category entropy, to identify scenes containing multiple object classes, thus mitigating class imbalance for the active learner; 2) a similarity sampling scheme, estimated through the directed graph representation and a marginalize kernel algorithm, to pick sparse and diverse scenes; 3) an uncertainty sampling scheme, predicted by a mixture density network, to select instances with the most unclear or complex regression outcomes for the learner. Finally, the integration of these three schemes in a joint selection strategy yields an optimal and valuable subdataset. Experiments on the KITTI, Lyft, nuScenes and SUScape datasets demonstrate that our approach outperforms existing state-of-the-art methods on 3D object detection tasks with up to 12% improvements.","authors":["Chenyang Lei","Weiyuan Peng","Guang Zhou","Meiying Zhang","Qi Hao","Chunlin Ji","Chengzhong Xu"],"url":"https://arxiv.org/abs/2412.18870"}
{"created":"2025-04-22","title":"SeaMo: A Season-Aware Multimodal Foundation Model for Remote Sensing","abstract":"Remote Sensing (RS) data encapsulates rich multi-dimensional information essential for Earth observation. Its vast volume, diverse sources, and temporal continuity make it particularly well-suited for developing large Visual Foundation Models (VFMs). These models serve as powerful feature extractors, leveraging extensive RS data for pretraining and subsequent fine-tuning in various geoscientific applications. However, existing VFMs in the RS domain often concentrate on specific image characteristics, neglecting the full season-aware potential of RS data. To bridge this gap, we introduce SeaMo, a novel VFM that effectively integrates multimodal and multi-seasonal RS information. SeaMo leverages a masked image modeling framework to fully exploit the spatial, spectral, and seasonal dimensions of RS data. Specifically, we employ unaligned spatial region selection to capture spatial heterogeneity, incorporate multi-source inputs for enhanced multimodal integration, and introduce temporal-multimodal fusion blocks to assimilate seasonal variations effectively. By explicitly modeling the complex, season-dependent attributes of RS data, SeaMo enhances generalization, robustness, and adaptability across geoscientific tasks. Extensive experiments and ablation studies demonstrate its superior performance, underscoring its potential as a foundational model for Earth observation.","authors":["Xuyang Li","Chenyu Li","Gemine Vivone","Danfeng Hong"],"url":"https://arxiv.org/abs/2412.19237"}
{"created":"2025-04-22","title":"Telegram as a Battlefield: Kremlin-related Communications during the Russia-Ukraine Conflict","abstract":"Telegram emerged as a crucial platform for both parties during the conflict between Russia and Ukraine. Per its minimal policies for content moderation, Pro-Kremlin narratives and potential misinformation were spread on Telegram, while anti-Kremlin narratives with related content were also propagated, such as war footage, troop movements, maps of bomb shelters, and air raid warnings. This paper presents a dataset of posts from both pro-Kremlin and anti-Kremlin Telegram channels, collected over a period spanning a year before and a year after the Russian invasion. The dataset comprises 404 pro-Kremlin channels with 4,109,645 posts and 114 anti-Kremlin channels with 1,117,768 posts. We provide details on the data collection process, processing methods, and dataset characterization. Lastly, we discuss the potential research opportunities this dataset may enable researchers across various disciplines.","authors":["Apaar Bawa","Ugur Kursuncu","Dilshod Achilov","Valerie L. Shalin","Nitin Agarwal","Esra Akbas"],"url":"https://arxiv.org/abs/2501.01884"}
{"created":"2025-04-22","title":"Humanoid Locomotion and Manipulation: Current Progress and Challenges in Control, Planning, and Learning","abstract":"Humanoid robots hold great potential to perform various human-level skills, involving unified locomotion and manipulation in real-world settings. Driven by advances in machine learning and the strength of existing model-based approaches, these capabilities have progressed rapidly, but often separately. This survey offers a comprehensive overview of the state-of-the-art in humanoid locomotion and manipulation (HLM), with a focus on control, planning, and learning methods. We first review the model-based methods that have been the backbone of humanoid robotics for the past three decades. We discuss contact planning, motion planning, and whole-body control, highlighting the trade-offs between model fidelity and computational efficiency. Then the focus is shifted to examine emerging learning-based methods, with an emphasis on reinforcement and imitation learning that enhance the robustness and versatility of loco-manipulation skills. Furthermore, we assess the potential of integrating foundation models with humanoid embodiments to enable the development of generalist humanoid agents. This survey also highlights the emerging role of tactile sensing, particularly whole-body tactile feedback, as a crucial modality for handling contact-rich interactions. Finally, we compare the strengths and limitations of model-based and learning-based paradigms from multiple perspectives, such as robustness, computational efficiency, versatility, and generalizability, and suggest potential solutions to existing challenges.","authors":["Zhaoyuan Gu","Junheng Li","Wenlan Shen","Wenhao Yu","Zhaoming Xie","Stephen McCrory","Xianyi Cheng","Abdulaziz Shamsah","Robert Griffin","C. Karen Liu","Abderrahmane Kheddar","Xue Bin Peng","Yuke Zhu","Guanya Shi","Quan Nguyen","Gordon Cheng","Huijun Gao","Ye Zhao"],"url":"https://arxiv.org/abs/2501.02116"}
{"created":"2025-04-22","title":"On Achievable Rates Over Noisy Nanopore Channels","abstract":"In this paper, we consider a recent channel model of a nanopore sequencer proposed by McBain, Viterbo, and Saunderson (2024), termed the \\emph{noisy nanopore channel} (NNC). In essence, an NNC is a duplication channel with structured, Markov inputs, that is corrupted by memoryless noise. We first discuss a (tight) lower bound on the capacity of the NNC in the absence of random noise. Next, we present bounds on the channel capacity of general noisy nanopore channels, via simple information-theoretic inequalities. We then consider two interesting regimes of operation of an NNC: first, where the memory of the input process is large and the random noise introduces erasures, and second, where the rate of measurements of the electric current (also called the sampling rate) is high. For these regimes, we show that it is possible to achieve information rates close to the noise-free capacity, using simple encoding and decoding schemes. In particular, our decoder for the regime of high sampling rates makes use of a change-point detection procedure -- a subroutine of immediate relevance for practitioners.","authors":["V. Arvind Rameshwar","Nir Weinberger"],"url":"https://arxiv.org/abs/2501.02917"}
{"created":"2025-04-22","title":"Proxy Discrimination After Students for Fair Admissions","abstract":"Today, there is no clear legal test for regulating the use of variables that proxy for race and other protected classes and classifications. This Article develops such a test. Decision tools that use proxies are narrowly tailored when they exhibit the weakest total proxy power. The test is necessarily comparative. Thus, if two algorithms predict loan repayment or university academic performance with identical accuracy rates, but one uses zip code and the other does not, then the second algorithm can be said to have deployed a more equitable means for achieving the same result as the first algorithm. Scenarios in which two algorithms produce comparable and non-identical results present a greater challenge. This Article suggests that lawmakers can develop caps to permissible proxy power over time, as courts and algorithm builders learn more about the power of variables. Finally, the Article considers who should bear the burden of producing less discriminatory alternatives and suggests plaintiffs remain in the best position to keep defendants honest - so long as testing data is made available.","authors":["Frank Fagan"],"url":"https://arxiv.org/abs/2501.03946"}
{"created":"2025-04-22","title":"Enhancing Low-Cost Video Editing with Lightweight Adaptors and Temporal-Aware Inversion","abstract":"Recent advancements in text-to-image (T2I) generation using diffusion models have enabled cost-effective video-editing applications by leveraging pre-trained models, eliminating the need for resource-intensive training. However, the frame-independence of T2I generation often results in poor temporal consistency. Existing methods address this issue through temporal layer fine-tuning or inference-based temporal propagation, but these approaches suffer from high training costs or limited temporal coherence. To address these challenges, we propose a General and Efficient Adapter (GE-Adapter) that integrates temporal-spatial and semantic consistency with Baliteral DDIM inversion. This framework introduces three key components: (1) Frame-based Temporal Consistency Blocks (FTC Blocks) to capture frame-specific features and enforce smooth inter-frame transitions via temporally-aware loss functions; (2) Channel-dependent Spatial Consistency Blocks (SCD Blocks) employing bilateral filters to enhance spatial coherence by reducing noise and artifacts; and (3) Token-based Semantic Consistency Module (TSC Module) to maintain semantic alignment using shared prompt tokens and frame-specific tokens. Our method significantly improves perceptual quality, text-image alignment, and temporal coherence, as demonstrated on the MSR-VTT dataset. Additionally, it achieves enhanced fidelity and frame-to-frame coherence, offering a practical solution for T2V editing.","authors":["Yangfan He","Sida Li","Kun Li","Xinyuan Song","Xinhang Yuan","Keqin Li","Kuan Lu","Menghao Huo","Jiaqi Chen","Miao Zhang","Xueqian Wang"],"url":"https://arxiv.org/abs/2501.04606"}
{"created":"2025-04-22","title":"Blockchain-Based Secure Vehicle Auction System with Smart Contracts","abstract":"The problem of a single point of failure in centralized systems poses a great challenge to the stability of such systems. Meanwhile, the tamperability of data within centralized systems makes users reluctant to trust and use centralized applications in many scenarios, including the financial and business sectors.","authors":["Ka Wai Wu"],"url":"https://arxiv.org/abs/2501.04841"}
{"created":"2025-04-22","title":"LongProc: Benchmarking Long-Context Language Models on Long Procedural Generation","abstract":"Existing benchmarks for evaluating long-context language models (LCLMs) primarily focus on long-context recall, requiring models to produce short responses based on a few critical snippets while processing thousands of irrelevant tokens. We introduce LongProc (Long Procedural Generation), a new benchmark that requires both the integration of highly dispersed information and long-form generation. LongProc consists of six diverse procedural generation tasks, such as extracting structured information from HTML pages into a TSV format and executing complex search procedures to create travel plans. These tasks challenge LCLMs by testing their ability to follow detailed procedural instructions, synthesize and reason over dispersed information, and generate structured, long-form outputs (up to 8K tokens). Furthermore, as these tasks adhere to deterministic procedures and yield structured outputs, they enable reliable rule-based evaluation. We evaluated 23 LCLMs, including instruction-tuned models and recent reasoning models, on LongProc at three difficulty levels, with the maximum number of output tokens set at 500, 2K, and 8K. Notably, while all tested models claim a context window size above 32K tokens, open-weight models typically falter on 2K-token tasks, and closed-source models like GPT-4o show significant degradation on 8K-token tasks. Reasoning models achieve stronger overall performance in long-form generation, benefiting from long CoT training. Further analysis reveals that LCLMs struggle to maintain long-range coherence in long-form generations. These findings highlight critical limitations in current LCLMs and suggest substantial room for improvement. Data and code available at: https://princeton-pli.github.io/LongProc.","authors":["Xi Ye","Fangcong Yin","Yinghui He","Joie Zhang","Howard Yen","Tianyu Gao","Greg Durrett","Danqi Chen"],"url":"https://arxiv.org/abs/2501.05414"}
{"created":"2025-04-22","title":"A Bring-Your-Own-Model Approach for ML-Driven Storage Placement in Warehouse-Scale Computers","abstract":"Storage systems account for a major portion of the total cost of ownership (TCO) of warehouse-scale computers, and thus have a major impact on the overall system's efficiency. Machine learning (ML)-based methods for solving key problems in storage system efficiency, such as data placement, have shown significant promise. However, there are few known practical deployments of such methods. Studying this problem in the context of real-world hyperscale data centers at Google, we identify a number of challenges that we believe cause this lack of practical adoption. Specifically, prior work assumes a monolithic model that resides entirely within the storage layer, an unrealistic assumption in real-world deployments with frequently changing workloads. To address this problem, we introduce a cross-layer approach where workloads instead ''bring their own model''. This strategy moves ML out of the storage system and instead allows each workload to train its own lightweight model at the application layer, capturing the workload's specific characteristics. These small, interpretable models generate predictions that guide a co-designed scheduling heuristic at the storage layer, enabling adaptation to diverse online environments. We build a proof-of-concept of this approach in a production distributed computation framework at Google. Evaluations in a test deployment and large-scale simulation studies using production traces show improvements of as much as 3.47$\\times$ in TCO savings compared to state-of-the-art baselines.","authors":["Chenxi Yang","Yan Li","Martin Maas","Mustafa Uysal","Ubaid Ullah Hafeez","Arif Merchant","Richard McDougall"],"url":"https://arxiv.org/abs/2501.05651"}
{"created":"2025-04-22","title":"How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond","abstract":"With the advancement of large language models (LLMs), intelligent models have evolved from mere tools to autonomous agents with their own goals and strategies for cooperating with humans. This evolution has birthed a novel paradigm in NLP, i.e., human-model cooperation, that has yielded remarkable progress in numerous NLP tasks in recent years. In this paper, we take the first step to present a thorough review of human-model cooperation, exploring its principles, formalizations, and open challenges. In particular, we introduce a new taxonomy that provides a unified perspective to summarize existing approaches. Also, we discuss potential frontier areas and their corresponding challenges. We regard our work as an entry point, paving the way for more breakthrough research in this regard.","authors":["Chen Huang","Yang Deng","Wenqiang Lei","Jiancheng Lv","Tat-Seng Chua","Jimmy Xiangji Huang"],"url":"https://arxiv.org/abs/2501.05714"}
{"created":"2025-04-22","title":"A Brain Age Residual Biomarker (BARB): Leveraging MRI-Based Models to Detect Latent Health Conditions in U.S. Veterans","abstract":"Age prediction using brain imaging, such as MRIs, has achieved promising results, with several studies identifying the model's residual as a potential biomarker for chronic disease states. In this study, we developed a brain age predictive model using a dataset of 1,220 U.S. veterans (18--80 years) and convolutional neural networks (CNNs) trained on two-dimensional slices of axial T2-weighted fast spin-echo and T2-weighted fluid attenuated inversion recovery MRI images. The model, incorporating a degree-3 polynomial ensemble, achieved an $R^{2}$ of 0.816 on the testing set. Images were acquired at the level of the anterior commissure and the frontal horns of the lateral ventricles. Residual analysis was performed to assess its potential as a biomarker for five ICD-coded conditions: hypertension (HTN), diabetes mellitus (DM), mild traumatic brain injury (mTBI), illicit substance abuse/dependence (SAD), and alcohol abuse/dependence (AAD). Residuals grouped by the number of ICD-coded conditions demonstrated different trends that were statistically significant ($p = 0.002$), suggesting a relationship between disease states and predicted brain age. This association was particularly pronounced in patients over 49 years, where negative residuals (indicating advanced brain aging) correlated with the presence of multiple ICD codes. These findings support the potential of residuals as biomarkers for detecting latent health conditions.","authors":["Shahrzad Jamshidi","Arthur Bousquet","Sugata Banerji","Mark F. Conneely","Bita Aslrousta"],"url":"https://arxiv.org/abs/2501.05970"}
{"created":"2025-04-22","title":"Optimizing Sequencing Coverage Depth in DNA Storage: Insights From DNA Storage Data","abstract":"DNA storage is now being considered as a new archival storage method for its durability and high information density, but still facing some challenges like high costs and low throughput. By reducing sequencing sample size for decoding digital data, minimizing DNA coverage depth helps lower both costs and system latency. Previous studies have mainly focused on minimizing coverage depth in uniform distribution channels under theoretical assumptions. In contrast, our work uses real DNA storage experimental data to extend this problem to log-normal distribution channels, a conclusion derived from our PCR and sequencing data analysis. In this framework, we investigate both noiseless and noisy channels. We first demonstrate a detailed positive correlation between MDS code rate and the expected minimum sequencing coverage depth. Moreover, we observe that the probability of successfully decoding all information in a single sequencing run decreases and then increases as code rate rises, when the sample size is optimized for complete decoding. Then we extend the lower bounds of the DNA coverage depth from uniform to log-normal noisy channels. The findings of this study provide valuable insights for the efficient execution of DNA storage experiments.","authors":["Ruiying Cao","Xin Chen"],"url":"https://arxiv.org/abs/2501.06801"}
{"created":"2025-04-22","title":"AlphaNet: Scaling Up Local-frame-based Atomistic Interatomic Potential","abstract":"Molecular dynamics simulations demand an unprecedented combination of accuracy and scalability to tackle grand challenges in catalysis and materials design. To bridge this gap, we present AlphaNet, a local-frame-based equivariant model that simultaneously improves computational efficiency and predictive precision for interatomic interactions. By constructing equivariant local frames with learnable geometric transitions, AlphaNet encodes atomic environments with enhanced representational capacity, achieving state-of-the-art accuracy in energy and force predictions. Extensive benchmarks on large-scale datasets spanning molecular reactions, crystal stability, and surface catalysis (Matbench Discovery and OC2M) demonstrate its superior performance over existing neural network interatomic potentials while ensuring scalability across diverse system sizes with varying types of interatomic interactions. The synergy of accuracy, efficiency, and transferability positions AlphaNet as a transformative tool for modeling multiscale phenomena, decoding dynamics in catalysis and functional interfaces, with direct implications for accelerating the discovery of complex molecular systems and functional materials.","authors":["Bangchen Yin","Jiaao Wang","Weitao Du","Pengbo Wang","Penghua Ying","Haojun Jia","Zisheng Zhang","Yuanqi Du","Carla P. Gomes","Chenru Duan","Graeme Henkelman","Hai Xiao"],"url":"https://arxiv.org/abs/2501.07155"}
{"created":"2025-04-22","title":"Automating Credit Card Limit Adjustments Using Machine Learning","abstract":"Venezuelan banks have historically made credit card limit adjustment decisions manually through committees. However, since the number of credit card holders in Venezuela is expected to increase in the upcoming months due to economic improvements, manual decisions are starting to become unfeasible. In this project, a machine learning model that uses cost-sensitive learning is proposed to automate the task of handing out credit card limit increases. To accomplish this, several neural network and XGBoost models are trained and compared, leveraging Venezolano de Credito's data and using grid search with 10-fold cross-validation. The proposed model is ultimately chosen due to its superior balance of accuracy, cost-effectiveness, and interpretability. The model's performance is evaluated against the committee's decisions using Cohen's kappa coefficient, showing an almost perfect agreement.","authors":["Diego Pestana","Enrique Areyan Viqueira"],"url":"https://arxiv.org/abs/2501.10451"}
{"created":"2025-04-22","title":"Generative Physical AI in Vision: A Survey","abstract":"Generative Artificial Intelligence (AI) has rapidly advanced the field of computer vision by enabling machines to create and interpret visual data with unprecedented sophistication. This transformation builds upon a foundation of generative models to produce realistic images, videos, and 3D/4D content. Conventional generative models primarily focus on visual fidelity while often neglecting the physical plausibility of the generated content. This gap limits their effectiveness in applications that require adherence to real-world physical laws, such as robotics, autonomous systems, and scientific simulations. As generative models evolve to increasingly integrate physical realism and dynamic simulation, their potential to function as \"world simulators\" expands. Therefore, the field of physics-aware generation in computer vision is rapidly growing, calling for a comprehensive survey to provide a structured analysis of current efforts. To serve this purpose, the survey presents a systematic review, categorizing methods based on how they incorporate physical knowledge, either through explicit simulation or implicit learning. It also analyzes key paradigms, discusses evaluation protocols, and identifies future research directions. By offering a comprehensive overview, this survey aims to help future developments in physically grounded generation for computer vision. The reviewed papers are summarized at https://tinyurl.com/Physics-Aware-Generation.","authors":["Daochang Liu","Junyu Zhang","Anh-Dung Dinh","Eunbyung Park","Shichao Zhang","Ajmal Mian","Mubarak Shah","Chang Xu"],"url":"https://arxiv.org/abs/2501.10928"}
{"created":"2025-04-22","title":"Efficient Frame Extraction: A Novel Approach Through Frame Similarity and Surgical Tool Tracking for Video Segmentation","abstract":"The interest in leveraging Artificial Intelligence (AI) for surgical procedures to automate analysis has witnessed a significant surge in recent years. One of the primary tools for recording surgical procedures and conducting subsequent analyses, such as performance assessment, is through videos. However, these operative videos tend to be notably lengthy compared to other fields, spanning from thirty minutes to several hours, which poses a challenge for AI models to effectively learn from them. Despite this challenge, the foreseeable increase in the volume of such videos in the near future necessitates the development and implementation of innovative techniques to tackle this issue effectively. In this article, we propose a novel technique called Kinematics Adaptive Frame Recognition (KAFR) that can efficiently eliminate redundant frames to reduce dataset size and computation time while retaining useful frames to improve accuracy. Specifically, we compute the similarity between consecutive frames by tracking the movement of surgical tools. Our approach follows these steps: $i)$ Tracking phase: a YOLOv8 model is utilized to detect tools presented in the scene, $ii)$ Similarity phase: Similarities between consecutive frames are computed by estimating variation in the spatial positions and velocities of the tools, $iii$) Classification phase: An X3D CNN is trained to classify segmentation. We evaluate the effectiveness of our approach by analyzing datasets obtained through retrospective reviews of cases at two referral centers. The newly annotated Gastrojejunostomy (GJ) dataset covers procedures performed between 2017 and 2021, while the previously annotated Pancreaticojejunostomy (PJ) dataset spans from 2011 to 2022 at the same centers.","authors":["Huu Phong Nguyen","Shekhar Madhav Khairnar","Sofia Garces Palacios","Amr Al-Abbas","Francisco Antunes","Bernardete Ribeiro","Melissa E. Hogg","Amer H. Zureikat","Patricio M. Polanco","Herbert Zeh III","Ganesh Sankaranarayanan"],"url":"https://arxiv.org/abs/2501.11153"}
{"created":"2025-04-22","title":"Complexity of approximate conflict-free, linearly-ordered, and nonmonochromatic hypergraph colourings","abstract":"Using the algebraic approach to promise constraint satisfaction problems, we establish complexity classifications of three natural variants of hypergraph colourings: standard nonmonochromatic colourings, conflict-free colourings, and linearly-ordered colourings.","authors":["Tamio-Vesa Nakajima","Zephyr Verwimp","Marcin Wrochna","Stanislav \\v{Z}ivn\\'y"],"url":"https://arxiv.org/abs/2501.12062"}
{"created":"2025-04-22","title":"Checkification: A Practical Approach for Testing Static Analysis Truths","abstract":"Static analysis is an essential component of many modern software development tools. Unfortunately, the ever-increasing complexity of static analyzers makes their coding error-prone. Even analysis tools based on rigorous mathematical techniques, such as abstract interpretation, are not immune to bugs. Ensuring the correctness and reliability of software analyzers is critical if they are to be inserted in production compilers and development environments. While compiler validation has seen notable success, formal validation of static analysis tools remains relatively unexplored. In this paper, we propose a method for testing abstract interpretation-based static analyzers. Broadly, it consists in checking, over a suite of benchmarks, that the properties inferred statically are satisfied dynamically. The main advantage of our approach lies in its simplicity, which stems directly from framing it within the Ciao assertion-based validation framework, and its blended static/dynamic assertion checking approach. We demonstrate that in this setting, the analysis can be tested with little effort by combining the following components already present in the framework: 1) the static analyzer, which outputs its results as the original program source with assertions interspersed; 2) the assertion run-time checking mechanism, which instruments a program to ensure that no assertion is violated at run time; 3) the random test case generator, which generates random test cases satisfying the properties present in assertion preconditions; and 4) the unit-test framework, which executes those test cases. We have applied our approach to the CiaoPP static analyzer, resulting in the identification of many bugs with reasonable overhead. Most of these bugs have been either fixed or confirmed, helping us detect a range of errors not only related to analysis soundness but also within other aspects of the framework.","authors":["Daniela Ferreiro","Ignacio Casso","Jose F. Morales","Pedro L\\'opez-Garc\\'ia","Manuel V. Hermenegildo"],"url":"https://arxiv.org/abs/2501.12093"}
{"created":"2025-04-22","title":"Exploring Temporally-Aware Features for Point Tracking","abstract":"Point tracking in videos is a fundamental task with applications in robotics, video editing, and more. While many vision tasks benefit from pre-trained feature backbones to improve generalizability, point tracking has primarily relied on simpler backbones trained from scratch on synthetic data, which may limit robustness in real-world scenarios. Additionally, point tracking requires temporal awareness to ensure coherence across frames, but using temporally-aware features is still underexplored. Most current methods often employ a two-stage process: an initial coarse prediction followed by a refinement stage to inject temporal information and correct errors from the coarse stage. These approach, however, is computationally expensive and potentially redundant if the feature backbone itself captures sufficient temporal information.","authors":["In\\`es Hyeonsu Kim","Seokju Cho","Jiahui Huang","Jung Yi","Joon-Young Lee","Seungryong Kim"],"url":"https://arxiv.org/abs/2501.12218"}
{"created":"2025-04-22","title":"DLEN: Dual Branch of Transformer for Low-Light Image Enhancement in Dual Domains","abstract":"Low-light image enhancement (LLE) aims to improve the visual quality of images captured in poorly lit conditions, which often suffer from low brightness, low contrast, noise, and color distortions. These issues hinder the performance of computer vision tasks such as object detection, facial recognition, and autonomous driving.Traditional enhancement techniques, such as multi-scale fusion and histogram equalization, fail to preserve fine details and often struggle with maintaining the natural appearance of enhanced images under complex lighting conditions. Although the Retinex theory provides a foundation for image decomposition, it often amplifies noise, leading to suboptimal image quality. In this paper, we propose the Dual Light Enhance Network (DLEN), a novel architecture that incorporates two distinct attention mechanisms, considering both spatial and frequency domains. Our model introduces a learnable wavelet transform module in the illumination estimation phase, preserving high- and low-frequency components to enhance edge and texture details. Additionally, we design a dual-branch structure that leverages the power of the Transformer architecture to enhance both the illumination and structural components of the image.Through extensive experiments, our model outperforms state-of-the-art methods on standard benchmarks.Code is available here: https://github.com/LaLaLoXX/DLEN","authors":["Junyu Xia","Jiesong Bai","Yihang Dong"],"url":"https://arxiv.org/abs/2501.12235"}
{"created":"2025-04-22","title":"Efficient Algorithm for Sparse Fourier Transform of Generalized $q$-ary Functions","abstract":"Computing the Fourier transform of a $q$-ary function $f:\\mathbb{Z}_{q}^n\\rightarrow \\mathbb{R}$, which maps $q$-ary sequences to real numbers, is an important problem in mathematics with wide-ranging applications in biology, signal processing, and machine learning. Previous studies have shown that, under the sparsity assumption, the Fourier transform can be computed efficiently using fast and sample-efficient algorithms. However, in most practical settings, the function is defined over a more general space -- the space of generalized $q$-ary sequences $\\mathbb{Z}_{q_1} \\times \\mathbb{Z}_{q_2} \\times \\cdots \\times \\mathbb{Z}_{q_n}$ -- where each $\\mathbb{Z}_{q_i}$ corresponds to integers modulo $q_i$. Herein, we develop GFast, a coding theoretic algorithm that computes the $S$-sparse Fourier transform of $f$ with a sample complexity of $O(Sn)$, computational complexity of $O(Sn \\log N)$, and a failure probability that approaches zero as $N=\\prod_{i=1}^n q_i \\rightarrow \\infty$ with $S = N^\\delta$ for some $0 \\leq \\delta < 1$. We show that a noise-robust version of GFast computes the transform with a sample complexity of $O(Sn^2)$ and computational complexity of $O(Sn^2 \\log N)$ under the same high probability guarantees. Additionally, we demonstrate that GFast computes the sparse Fourier transform of generalized $q$-ary functions $8\\times$ faster using $16\\times$ fewer samples on synthetic experiments, and enables explaining real-world heart disease diagnosis and protein fitness models using up to $13\\times$ fewer samples compared to existing Fourier algorithms applied to the most efficient parameterization of the models as $q$-ary functions.","authors":["Darin Tsui","Kunal Talreja","Amirali Aghazadeh"],"url":"https://arxiv.org/abs/2501.12365"}
{"created":"2025-04-22","title":"DARB-Splatting: Generalizing Splatting with Decaying Anisotropic Radial Basis Functions","abstract":"Splatting-based 3D reconstruction methods have gained popularity with the advent of 3D Gaussian Splatting, efficiently synthesizing high-quality novel views. These methods commonly resort to using exponential family functions, such as the Gaussian function, as reconstruction kernels due to their anisotropic nature, ease of projection, and differentiability in rasterization. However, the field remains restricted to variations within the exponential family, leaving generalized reconstruction kernels largely underexplored, partly due to the lack of easy integrability in 3D to 2D projections. In this light, we show that a class of decaying anisotropic radial basis functions (DARBFs), which are non-negative functions of the Mahalanobis distance, supports splatting by approximating the Gaussian function's closed-form integration advantage. With this fresh perspective, we demonstrate up to 34% faster convergence during training and a 45% reduction in memory consumption across various DARB reconstruction kernels, while maintaining comparable PSNR, SSIM, and LPIPS results. We will make the code available.","authors":["Vishagar Arunan (University of Moratuwa)","Saeedha Nazar (University of Moratuwa)","Hashiru Pramuditha (University of Moratuwa)","Vinasirajan Viruthshaan (University of Moratuwa)","Sameera Ramasinghe (University of Adelaide)","Simon Lucey (University of Adelaide)","Ranga Rodrigo (University of Moratuwa)"],"url":"https://arxiv.org/abs/2501.12369"}
{"created":"2025-04-22","title":"Modality Unified Attack for Omni-Modality Person Re-Identification","abstract":"Deep learning based person re-identification (re-id) models have been widely employed in surveillance systems. Recent studies have demonstrated that black-box single-modality and cross-modality re-id models are vulnerable to adversarial examples (AEs), leaving the robustness of multi-modality re-id models unexplored. Due to the lack of knowledge about the specific type of model deployed in the target black-box surveillance system, we aim to generate modality unified AEs for omni-modality (single-, cross- and multi-modality) re-id models. Specifically, we propose a novel Modality Unified Attack method to train modality-specific adversarial generators to generate AEs that effectively attack different omni-modality models. A multi-modality model is adopted as the surrogate model, wherein the features of each modality are perturbed by metric disruption loss before fusion. To collapse the common features of omni-modality models, Cross Modality Simulated Disruption approach is introduced to mimic the cross-modality feature embeddings by intentionally feeding images to non-corresponding modality-specific subnetworks of the surrogate model. Moreover, Multi Modality Collaborative Disruption strategy is devised to facilitate the attacker to comprehensively corrupt the informative content of person images by leveraging a multi modality feature collaborative metric disruption loss. Extensive experiments show that our MUA method can effectively attack the omni-modality re-id models, achieving 55.9%, 24.4%, 49.0% and 62.7% mean mAP Drop Rate, respectively.","authors":["Yuan Bian","Min Liu","Yunqi Yi","Xueping Wang","Yunfeng Ma","Yaonan Wang"],"url":"https://arxiv.org/abs/2501.12761"}
{"created":"2025-04-22","title":"A Cognitive Paradigm Approach to Probe the Perception-Reasoning Interface in VLMs","abstract":"A fundamental challenge in artificial intelligence involves understanding the cognitive processes underlying visual reasoning in sophisticated models like Vision-Language Models (VLMs). How do these models integrate visual perception with abstract thought, especially when reasoning across multiple images? Drawing inspiration from cognitive science, this paper introduces a structured evaluation framework using Bongard Problems (BPs) - a classic test of visual abstraction to dissect the perception-reasoning interface in VLMs. We propose three distinct evaluation paradigms, mirroring human problem-solving strategies: Direct Visual Rule Learning (DVRL; holistic processing), Deductive Rule Learning (DRL; rule extraction and application), and Componential Analysis (CA; analytical decomposition via textual descriptions). These paradigms allow us to systematically vary the cognitive load and probe specific processing stages. Notably, the CA paradigm enables the evaluation of multi-image reasoning even in VLMs architecturally limited to single images and facilitates the isolation of reasoning capabilities from perceptual limitations by controlling the descriptive input. Ablation studies further confirm that reasoning abilities improve significantly when perceptual challenges are mitigated. Our framework provides a valuable diagnostic tool, highlighting the need to enhance visual processing fidelity for achieving more robust and human-like visual intelligence in AI.","authors":["Mohit Vaishnav","Tanel Tammet"],"url":"https://arxiv.org/abs/2501.13620"}
{"created":"2025-04-22","title":"Active Learning for Continual Learning: Keeping the Past Alive in the Present","abstract":"Continual learning (CL) enables deep neural networks to adapt to ever-changing data distributions. In practice, there may be scenarios where annotation is costly, leading to active continual learning (ACL), which performs active learning (AL) for the CL scenarios when reducing the labeling cost by selecting the most informative subset is preferable. However, conventional AL strategies are not suitable for ACL, as they focus solely on learning the new knowledge, leading to catastrophic forgetting of previously learned tasks. Therefore, ACL requires a new AL strategy that can balance the prevention of catastrophic forgetting and the ability to quickly learn new tasks. In this paper, we propose AccuACL, Accumulated informativeness-based Active Continual Learning, by the novel use of the Fisher information matrix as a criterion for sample selection, derived from a theoretical analysis of the Fisher-optimality preservation properties within the framework of ACL, while also addressing the scalability issue of Fisher information-based AL. Extensive experiments demonstrate that AccuACL significantly outperforms AL baselines across various CL algorithms, increasing the average accuracy and forgetting by 23.8% and 17.0%, respectively, on average.","authors":["Jaehyun Park","Dongmin Park","Jae-Gil Lee"],"url":"https://arxiv.org/abs/2501.14278"}
{"created":"2025-04-22","title":"Idiom Detection in Sorani Kurdish Texts","abstract":"Idiom detection using Natural Language Processing (NLP) is the computerized process of recognizing figurative expressions within a text that convey meanings beyond the literal interpretation of the words. While idiom detection has seen significant progress across various languages, the Kurdish language faces a considerable research gap in this area despite the importance of idioms in tasks like machine translation and sentiment analysis. This study addresses idiom detection in Sorani Kurdish by approaching it as a text classification task using deep learning techniques. To tackle this, we developed a dataset containing 10,580 sentences embedding 101 Sorani Kurdish idioms across diverse contexts. Using this dataset, we developed and evaluated three deep learning models: KuBERT-based transformer sequence classification, a Recurrent Convolutional Neural Network (RCNN), and a BiLSTM model with an attention mechanism. The evaluations revealed that the transformer model, the fine-tuned BERT, consistently outperformed the others, achieving nearly 99% accuracy while the RCNN achieved 96.5% and the BiLSTM 80%. These results highlight the effectiveness of Transformer-based architectures in low-resource languages like Kurdish. This research provides a dataset, three optimized models, and insights into idiom detection, laying a foundation for advancing Kurdish NLP.","authors":["Skala Kamaran Omer","Hossein Hassani"],"url":"https://arxiv.org/abs/2501.14528"}
{"created":"2025-04-22","title":"Enhancing Intent Understanding for Ambiguous prompt: A Human-Machine Co-Adaption Strategy","abstract":"Today's image generation systems are capable of producing realistic and high-quality images. However, user prompts often contain ambiguities, making it difficult for these systems to interpret users' actual intentions. Consequently, many users must modify their prompts several times to ensure the generated images meet their expectations. While some methods focus on enhancing prompts to make the generated images fit user needs, the model is still hard to understand users' real needs, especially for non-expert users. In this research, we aim to enhance the visual parameter-tuning process, making the model user-friendly for individuals without specialized knowledge and better understand user needs. We propose a human-machine co-adaption strategy using mutual information between the user's prompts and the pictures under modification as the optimizing target to make the system better adapt to user needs. We find that an improved model can reduce the necessity for multiple rounds of adjustments. We also collect multi-round dialogue datasets with prompts and images pairs and user intent. Various experiments demonstrate the effectiveness of the proposed method in our proposed dataset. Our annotation tools and several examples of our dataset are available at https://zenodo.org/records/14876029 for easier review. We will make open source our full dataset and code.","authors":["Yangfan He","Jianhui Wang","Yijin Wang","Kun Li","Yan Zhong","Xinyuan Song","Li Sun","Jingyuan Lu","Miao Zhang","Tianyu Shi","Xinhang Yuan","Kuan Lu","Menghao Huo","Keqin Li","Jiaqi Chen"],"url":"https://arxiv.org/abs/2501.15167"}
{"created":"2025-04-22","title":"Deep Learning in Early Alzheimer's disease's Detection: A Comprehensive Survey of Classification, Segmentation, and Feature Extraction Methods","abstract":"Alzheimers disease is a deadly neurological condition, impairing important memory and brain functions. Alzheimers disease promotes brain shrinkage, ultimately leading to dementia. Dementia diagnosis typically takes 2.8 to 4.4 years after the first clinical indication. Advancements in computing and information technology have led to many techniques of studying Alzheimers disease. Early identification and therapy are crucial for preventing Alzheimers disease, as early-onset dementia hits people before the age of 65, while late-onset dementia occurs after this age. According to the 2015 World Alzheimers disease Report, there are 46.8 million individuals worldwide suffering from dementia, with an anticipated 74.7 million more by 2030 and 131.5 million by 2050. Deep Learning has outperformed conventional Machine Learning techniques by identifying intricate structures in high-dimensional data. Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN), have achieved an accuracy of up to 96.0% for Alzheimers disease classification, and 84.2% for mild cognitive impairment (MCI) conversion prediction. There have been few literature surveys available on applying ML to predict dementia, lacking in congenital observations. However, this survey has focused on a specific data channel for dementia detection. This study evaluated Deep Learning algorithms for early Alzheimers disease detection, using openly accessible datasets, feature segmentation, and classification methods. This article also has identified research gaps and limits in detecting Alzheimers disease, which can inform future research.","authors":["Rubab Hafeez","Sadia Waheed","Syeda Aleena Naqvi","Fahad Maqbool","Amna Sarwar","Sajjad Saleem","Muhammad Imran Sharif","Kamran Siddique","Zahid Akhtar"],"url":"https://arxiv.org/abs/2501.15293"}
{"created":"2025-04-22","title":"Advancing Generative Artificial Intelligence and Large Language Models for Demand Side Management with Internet of Electric Vehicles","abstract":"Generative artificial intelligence, particularly through large language models (LLMs), is poised to transform energy optimization and demand side management (DSM) within microgrids. This paper explores the integration of LLMs into energy management, emphasizing their roles in automating the optimization of DSM strategies with Internet of electric vehicles. We investigate challenges and solutions associated with DSM and explore the new opportunities presented by leveraging LLMs. Then, we propose an innovative solution that enhances LLMs with retrieval-augmented generation for automatic problem formulation, code generation, and customizing optimization. We present a case study to demonstrate the effectiveness of our proposed solution in charging scheduling and optimization for electric vehicles, highlighting our solution's significant advancements in energy efficiency and user adaptability. This work underscores the potential of LLMs for energy optimization and fosters a new era of intelligent DSM solutions.","authors":["Hanwen Zhang","Ruichen Zhang","Wei Zhang","Dusit Niyato","Yonggang Wen"],"url":"https://arxiv.org/abs/2501.15544"}
{"created":"2025-04-22","title":"Visual Theory of Mind Enables the Invention of Proto-Writing","abstract":"Symbolic writing systems are graphical semiotic codes that are ubiquitous in modern society but are otherwise absent in the animal kingdom. Anthropological evidence suggests that the earliest forms of some writing systems originally consisted of iconic pictographs, which signify their referent via visual resemblance. While previous studies have examined the emergence and, separately, the evolution of pictographic systems through a computational lens, most employ non-naturalistic methodologies that make it difficult to draw clear analogies to human and animal cognition. We develop a multi-agent reinforcement learning testbed for emergent communication called a Signification Game, and formulate a model of inferential communication that enables agents to leverage visual theory of mind to communicate actions using pictographs. Our model, which is situated within a broader formalism for animal communication, sheds light on the cognitive and cultural processes underlying the emergence of proto-writing.","authors":["Benjamin A. Spiegel","Lucas Gelfond","George Konidaris"],"url":"https://arxiv.org/abs/2502.01568"}
{"created":"2025-04-22","title":"Deep Learning-Based Approach for Identification of Potato Leaf Diseases Using Wrapper Feature Selection and Feature Concatenation","abstract":"The potato is a widely grown crop in many regions of the world. In recent decades, potato farming has gained incredible traction in the world. Potatoes are susceptible to several illnesses that stunt their development. This plant seems to have significant leaf disease. Early Blight and Late Blight are two prevalent leaf diseases that affect potato plants. The early detection of these diseases would be beneficial for enhancing the yield of this crop. The ideal solution is to use image processing to identify and analyze these disorders. Here, we present an autonomous method based on image processing and machine learning to detect late blight disease affecting potato leaves. The proposed method comprises four different phases: (1) Histogram Equalization is used to improve the quality of the input image; (2) feature extraction is performed using a Deep CNN model, then these extracted features are concatenated; (3) feature selection is performed using wrapper-based feature selection; (4) classification is performed using an SVM classifier and its variants. This proposed method achieves the highest accuracy of 99% using SVM by selecting 550 features.","authors":["Muhammad Ahtsam Naeem","Muhammad Asim Saleem","Muhammad Imran Sharif","Shahzad Akber","Sajjad Saleem","Zahid Akhtar","Kamran Siddique"],"url":"https://arxiv.org/abs/2502.03370"}
{"created":"2025-04-22","title":"Replacing K-infinity Function with Leaky ReLU in Barrier Function Design: A Union of Invariant Sets Approach for ReLU-Based Dynamical Systems","abstract":"In this paper, a systematic framework is presented for determining piecewise affine PWA barrier functions and their corresponding invariant sets for dynamical systems identified via Rectified Linear Unit (ReLU) neural networks or their equivalent PWA representations. A common approach to determining the invariant set is to use Nagumo's condition, or to utilize the barrier function with a class K-infinity function. It may be challenging to find a suitable class K-infinity function in some cases. We propose leaky ReLU as an efficient substitute for the complex nonlinear K-infinity function in our formulation. Moreover, we propose the Union of Invariant Sets (UIS) method, which combines information from multiple invariant sets in order to compute the largest possible PWA invariant set. The proposed framework is validated through multiple examples, showcasing its potential to enhance the analysis of invariant sets in ReLU-based dynamical systems. Our code is available at: https://github.com/PouyaSamanipour/UIS.git.","authors":["Pouya Samanipour","Hasan Poonawala"],"url":"https://arxiv.org/abs/2502.03765"}
{"created":"2025-04-22","title":"MRAMG-Bench: A Comprehensive Benchmark for Advancing Multimodal Retrieval-Augmented Multimodal Generation","abstract":"Recent advances in Retrieval-Augmented Generation (RAG) have significantly improved response accuracy and relevance by incorporating external knowledge into Large Language Models (LLMs). However, existing RAG methods primarily focus on generating text-only answers, even in Multimodal Retrieval-Augmented Generation (MRAG) scenarios, where multimodal elements are retrieved to assist in generating text answers. To address this, we introduce the Multimodal Retrieval-Augmented Multimodal Generation (MRAMG) task, in which we aim to generate multimodal answers that combine both text and images, fully leveraging the multimodal data within a corpus. Despite growing attention to this challenging task, a notable lack of a comprehensive benchmark persists for effectively evaluating its performance. To bridge this gap, we provide MRAMG-Bench, a meticulously curated, human-annotated benchmark comprising 4,346 documents, 14,190 images, and 4,800 QA pairs, distributed across six distinct datasets and spanning three domains: Web, Academia, and Lifestyle. The datasets incorporate diverse difficulty levels and complex multi-image scenarios, providing a robust foundation for evaluating the MRAMG task. To facilitate rigorous evaluation, MRAMG-Bench incorporates a comprehensive suite of both statistical and LLM-based metrics, enabling a thorough analysis of the performance of generative models in the MRAMG task. Additionally, we propose an efficient and flexible multimodal answer generation framework that can leverage LLMs/MLLMs to generate multimodal responses. Our datasets and complete evaluation results for 11 popular generative models are available at https://github.com/MRAMG-Bench/MRAMG.","authors":["Qinhan Yu","Zhiyou Xiao","Binghui Li","Zhengren Wang","Chong Chen","Wentao Zhang"],"url":"https://arxiv.org/abs/2502.04176"}
{"created":"2025-04-22","title":"Fast Adaptive Anti-Jamming Channel Access via Deep Q Learning and Coarse-Grained Spectrum Prediction","abstract":"This paper investigates the anti-jamming channel access problem in complex and unknown jamming environments, where the jammer could dynamically adjust its strategies to target different channels. Traditional channel hopping anti-jamming approaches using fixed patterns are ineffective against such dynamic jamming attacks. Although the emerging deep reinforcement learning (DRL) based dynamic channel access approach could achieve the Nash equilibrium under fast-changing jamming attacks, it requires extensive training episodes. To address this issue, we propose a fast adaptive anti-jamming channel access approach guided by the intuition of ``learning faster than the jammer\", where a synchronously updated coarse-grained spectrum prediction serves as an auxiliary task for the deep Q learning (DQN) based anti-jamming model. This helps the model identify a superior Q-function compared to standard DRL while significantly reducing the number of training episodes. Numerical results indicate that the proposed approach significantly accelerates the rate of convergence in model training, reducing the required training episodes by up to 70% compared to standard DRL. Additionally, it also achieves a 10% improvement in throughput over NE strategies, owing to the effective use of coarse-grained spectrum prediction.","authors":["Jianshu Zhang","Xiaofu Wu","Junquan Hu"],"url":"https://arxiv.org/abs/2502.04963"}
{"created":"2025-04-22","title":"AuraFusion360: Augmented Unseen Region Alignment for Reference-based 360{\\deg} Unbounded Scene Inpainting","abstract":"Three-dimensional scene inpainting is crucial for applications from virtual reality to architectural visualization, yet existing methods struggle with view consistency and geometric accuracy in 360{\\deg} unbounded scenes. We present AuraFusion360, a novel reference-based method that enables high-quality object removal and hole filling in 3D scenes represented by Gaussian Splatting. Our approach introduces (1) depth-aware unseen mask generation for accurate occlusion identification, (2) Adaptive Guided Depth Diffusion, a zero-shot method for accurate initial point placement without requiring additional training, and (3) SDEdit-based detail enhancement for multi-view coherence. We also introduce 360-USID, the first comprehensive dataset for 360{\\deg} unbounded scene inpainting with ground truth. Extensive experiments demonstrate that AuraFusion360 significantly outperforms existing methods, achieving superior perceptual quality while maintaining geometric accuracy across dramatic viewpoint changes.","authors":["Chung-Ho Wu","Yang-Jung Chen","Ying-Huan Chen","Jie-Ying Lee","Bo-Hsu Ke","Chun-Wei Tuan Mu","Yi-Chuan Huang","Chin-Yang Lin","Min-Hung Chen","Yen-Yu Lin","Yu-Lun Liu"],"url":"https://arxiv.org/abs/2502.05176"}
{"created":"2025-04-22","title":"Principles and Components of Federated Learning Architectures","abstract":"Federated Learning (FL) is a machine learning framework where multiple clients, from mobiles to enterprises, collaboratively construct a model under the orchestration of a central server but still retain the decentralized nature of the training data. This decentralized training of models offers numerous advantages, including cost savings, enhanced privacy, improved security, and compliance with legal requirements. However, for all its apparent advantages, FL is not immune to the limitations of conventional machine learning methodologies. This article provides an elaborate explanation of the inherent concepts and features found within federated learning architecture, addressing five key domains: system heterogeneity, data partitioning, machine learning models, communication protocols, and privacy techniques. This article also highlights the limitations in this domain and proposes avenues for future work. Besides, we provide a set of architectural patterns for federated learning systems, which are derived from the systematic survey of the literature. The main elements of FL, the fundamentals of Federated Learning, and a few architectural specifics will all be better understood with the aid of this research.","authors":["MD Abdullah Al Nasim","Fatema Tuj Johura Soshi","Parag Biswas","A. S. M Anas Ferdous","Abdur Rashid","Angona Biswas","Kishor Datta Gupta"],"url":"https://arxiv.org/abs/2502.05273"}
{"created":"2025-04-22","title":"Can LLMs Rank the Harmfulness of Smaller LLMs? We are Not There Yet","abstract":"Large language models (LLMs) have become ubiquitous, thus it is important to understand their risks and limitations. Smaller LLMs can be deployed where compute resources are constrained, such as edge devices, but with different propensity to generate harmful output. Mitigation of LLM harm typically depends on annotating the harmfulness of LLM output, which is expensive to collect from humans. This work studies two questions: How do smaller LLMs rank regarding generation of harmful content? How well can larger LLMs annotate harmfulness? We prompt three small LLMs to elicit harmful content of various types, such as discriminatory language, offensive content, privacy invasion, or negative influence, and collect human rankings of their outputs. Then, we evaluate three state-of-the-art large LLMs on their ability to annotate the harmfulness of these responses. We find that the smaller models differ with respect to harmfulness. We also find that large LLMs show low to moderate agreement with humans. These findings underline the need for further work on harm mitigation in LLMs.","authors":["Berk Atil","Vipul Gupta","Sarkar Snigdha Sarathi Das","Rebecca J. Passonneau"],"url":"https://arxiv.org/abs/2502.05291"}
{"created":"2025-04-22","title":"Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual Descriptions Using Gaussian Splatting, ChatGPT/Deepseek, and Google Maps Platform","abstract":"Urban digital twins are virtual replicas of cities that use multi-source data and data analytics to optimize urban planning, infrastructure management, and decision-making. Towards this, we propose a framework focused on the single-building scale. By connecting to cloud mapping platforms such as Google Map Platforms APIs, by leveraging state-of-the-art multi-agent Large Language Models data analysis using ChatGPT(4o) and Deepseek-V3/R1, and by using our Gaussian Splatting-based mesh extraction pipeline, our Digital Twin Buildings framework can retrieve a building's 3D model, visual descriptions, and achieve cloud-based mapping integration with large language model-based data analytics using a building's address, postal code, or geographic coordinates.","authors":["Kyle Gao","Dening Lu","Liangzhi Li","Nan Chen","Hongjie He","Linlin Xu","Jonathan Li"],"url":"https://arxiv.org/abs/2502.05769"}
{"created":"2025-04-22","title":"ClinKD: Cross-Modal Clinical Knowledge Distiller For Multi-Task Medical Images","abstract":"Medical Visual Question Answering (Med-VQA) represents a critical and challenging subtask within the general VQA domain. Despite significant advancements in general Visual Question Answering (VQA), multimodal large language models (MLLMs) still exhibit substantial limitations when handling multi-task VQA scenarios. These limitations manifest through erroneous spatial localization and misinterpretation of medical images, which primarily arise from two fundamental issues: inadequate image-text alignment and insufficient medical knowledge in general-purpose MLLMs for specialized medical applications. To address these issues, we introduce the Cross-Modal Clinical Knowledge Distiller (ClinKD), an innovative framework designed to enhance image-text alignment and establish more effective medical knowledge adaptation mechanisms, which enables MLLMs to adapt to medical knowledge. Our extensive experimental evaluations demonstrate that the ClinKD achieves state-of-the-art performance on the Med-GRIT-270k dataset, a challenging medical benchmark containing fine-grained multi-task QA pairs. The results indicate that our approach not only significantly improves image-text alignment but also effectively enables MLLMs to adapt to the medical knowledge. The source code for ClinKD is available at: https://github.com/overloadedHenry/ClinKD.","authors":["Hongyu Ge","Longkun Hao","Zihui Xu","Zhenxin Lin","Bin Li","Shoujun Zhou","Hongjin Zhao","Yihang Liu"],"url":"https://arxiv.org/abs/2502.05928"}
{"created":"2025-04-22","title":"Can LLMs Replace Human Evaluators? An Empirical Study of LLM-as-a-Judge in Software Engineering","abstract":"Recently, large language models (LLMs) have been deployed to tackle various software engineering (SE) tasks like code generation, significantly advancing the automation of SE tasks. However, assessing the quality of these LLM-generated code and text remains challenging. The commonly used Pass@k metric necessitates extensive unit tests and configured environments, demands a high labor cost, and is not suitable for evaluating LLM-generated text. Conventional metrics like BLEU, which measure only lexical rather than semantic similarity, have also come under scrutiny. In response, a new trend has emerged to employ LLMs for automated evaluation, known as LLM-as-a-judge. These LLM-as-a-judge methods are claimed to better mimic human assessment than conventional metrics without relying on high-quality reference answers. Nevertheless, their exact human alignment in SE tasks remains unexplored.","authors":["Ruiqi Wang","Jiyu Guo","Cuiyun Gao","Guodong Fan","Chun Yong Chong","Xin Xia"],"url":"https://arxiv.org/abs/2502.06193"}
{"created":"2025-04-22","title":"Conditioning and AGM-like belief change in the Desirability-Indifference framework","abstract":"We show how the AGM framework for belief change (expansion, revision, contraction) can be extended to deal with conditioning in the so-called Desirability-Indifference framework, based on abstract notions of accepting and rejecting options, as well as on abstract notions of events. This level of abstraction allows us to deal simultaneously with classical and quantum probability theory.","authors":["Kathelijne Coussement","Gert de Cooman","Keano De Vos"],"url":"https://arxiv.org/abs/2502.06235"}
{"created":"2025-04-22","title":"Meta-Computing Enhanced Federated Learning in IIoT: Satisfaction-Aware Incentive Scheme via DRL-Based Stackelberg Game","abstract":"The Industrial Internet of Things (IIoT) leverages Federated Learning (FL) for distributed model training while preserving data privacy, and meta-computing enhances FL by optimizing and integrating distributed computing resources, improving efficiency and scalability. Efficient IIoT operations require a trade-off between model quality and training latency. Consequently, a primary challenge of FL in IIoT is to optimize overall system performance by balancing model quality and training latency. This paper designs a satisfaction function that accounts for data size, Age of Information (AoI), and training latency for meta-computing. Additionally, the satisfaction function is incorporated into the utility functions to incentivize nodes in IIoT participation in model training. We model the utility functions of servers and nodes as a two-stage Stackelberg game and employ a deep reinforcement learning approach to learn the Stackelberg equilibrium. This approach ensures balanced rewards and enhances the applicability of the incentive scheme for IIoT. Simulation results demonstrate that, under the same budget constraints, the proposed incentive scheme improves utility by at least 23.7% compared to existing FL schemes without compromising model accuracy.","authors":["Xiaohuan Li","Shaowen Qin","Xin Tang","Jiawen Kang","Jin Ye","Zhonghua Zhao","Yusi Zheng","Dusit Niyato"],"url":"https://arxiv.org/abs/2502.06909"}
{"created":"2025-04-22","title":"Machine Learning Fleet Efficiency: Analyzing and Optimizing Large-Scale Google TPU Systems with ML Productivity Goodput","abstract":"Recent years have seen the emergence of machine learning (ML) workloads deployed in warehouse-scale computing (WSC) settings, also known as ML fleets. As the computational demands placed on ML fleets have increased due to the rise of large models and growing demand for ML applications, it has become increasingly critical to measure and improve the efficiency of such systems. However, there is not yet an established methodology to characterize ML fleet performance and identify potential performance optimizations accordingly. This paper presents a large-scale analysis of an ML fleet based on Google's TPUs, introducing a framework to capture fleet-wide efficiency, systematically evaluate performance characteristics, and identify optimization strategies for the fleet. We begin by defining an ML fleet, outlining its components, and analyzing an example Google ML fleet in production comprising thousands of accelerators running diverse workloads. Our study reveals several critical insights: first, ML fleets extend beyond the hardware layer, with model, data, framework, compiler, and scheduling layers significantly impacting performance; second, the heterogeneous nature of ML fleets poses challenges in characterizing individual workload performance; and third, traditional utilization-based metrics prove insufficient for ML fleet characterization. To address these challenges, we present the \"ML Productivity Goodput\" (MPG) metric to measure ML fleet efficiency. We show how to leverage this metric to characterize the fleet across the ML system stack. We also present methods to identify and optimize performance bottlenecks using MPG, providing strategies for managing warehouse-scale ML systems in general. Lastly, we demonstrate quantitative evaluations from applying these methods to a real ML fleet for internal-facing Google TPU workloads, where we observed tangible improvements.","authors":["Arissa Wongpanich","Tayo Oguntebi","Jose Baiocchi Paredes","Yu Emma Wang","Phitchaya Mangpo Phothilimthana","Ritwika Mitra","Zongwei Zhou","Naveen Kumar","Vijay Janapa Reddi"],"url":"https://arxiv.org/abs/2502.06982"}
{"created":"2025-04-22","title":"BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models","abstract":"Previous multilingual benchmarks focus primarily on simple understanding tasks, but for large language models(LLMs), we emphasize proficiency in instruction following, reasoning, long context understanding, code generation, and so on. However, measuring these advanced capabilities across languages is underexplored. To address the disparity, we introduce BenchMAX, a multi-way multilingual evaluation benchmark that allows for fair comparisons of these important abilities across languages. To maintain high quality, three distinct native-speaking annotators independently annotate each sample within all tasks after the data was machine-translated from English into 16 other languages. Additionally, we present a novel translation challenge stemming from dataset construction. Extensive experiments on BenchMAX reveal varying effectiveness of core capabilities across languages, highlighting performance gaps that cannot be bridged by simply scaling up model size. BenchMAX serves as a comprehensive multilingual evaluation platform, providing a promising test bed to promote the development of multilingual language models. The dataset and code are publicly accessible.","authors":["Xu Huang","Wenhao Zhu","Hanxu Hu","Conghui He","Lei Li","Shujian Huang","Fei Yuan"],"url":"https://arxiv.org/abs/2502.07346"}
{"created":"2025-04-22","title":"Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving","abstract":"We introduce Goedel-Prover, an open-source language model that achieves state-of-the-art (as of April 5 2025) performance in automated formal proof generation for mathematical problems. A key challenge in this field is the scarcity of formalized mathematical statements and proofs, which we address through the following approaches. First, we train LLMs to convert natural language math problems from the Numina dataset to equivalent formal statements in Lean 4. This process creates the dataset Goedel-Pset-v1, which includes 1.64 million formal statements. Next, we develop a large dataset of formal proofs by training a series of provers. Each new prover can prove many statements that previous ones could not, and these new proofs are added to the training set for the next prover. Finally, we obtain the dataset Goedel-Pset-v1-solved, which contains proofs for over 800K statements from Goedel-Pset-v1. Supervised fine-tuning (SFT) of DeepSeek-Prover-V1.5-Base on Goedel-Pset-v1-solved (i.e., no RL) yields a Goedel-Prover-SFT that achieves a success rate of 57.6% (Pass@32) on miniF2F, surpassing the previous leader DeepSeek-Prover-V1.5-RL (trained using SFT + RL on a proprietary dataset) by 7.6%. On PutnamBench, Goedel-Prover-SFT successfully solves 7 problems (Pass@512), ranking first on the leaderboard. We provide extensive discussion of our training methodology, highlighting the key design choices that contribute to Goedel-Prover's strong performance. Further RL training (including DPO) improves Goedel-Prover-SFT's success rate to over 60% (Pass@32) on miniF2F.","authors":["Yong Lin","Shange Tang","Bohan Lyu","Jiayun Wu","Hongzhou Lin","Kaiyu Yang","Jia Li","Mengzhou Xia","Danqi Chen","Sanjeev Arora","Chi Jin"],"url":"https://arxiv.org/abs/2502.07640"}
{"created":"2025-04-22","title":"A combined Lax-Wendroff/interpolation approach with finite element method for a three-dimensional system of tectonic deformation model: application to landslides in Cameroon","abstract":"This paper develops an efficient computational technique to assess the landslide responses to tectonic deformation and to predict the implications of large bedrocks landslides on the short and long-term development of the disasters. The considered equations represent a three-dimensional system of geological structure deformation subject to suitable initial and boundary conditions. The space derivatives are approximated using the finite element procedure while the approximation in time derivative is obtained using the Lax-Wendroff and interpolation techniques. The new approach is so called a combined Lax-Wendroff/interpolation method with finite element method. The modified Lax-Wendroff/interpolation scheme is employed to efficiently treat the time derivative term and to provide a suitable time step restriction for stability. Under this time step requirement, both stability and error estimates of the new algorithm are deeply analyzed using a constructed strong norm. The theory suggests that the developed computational technique is second-order accurate in time and spatial convergent with order O(h^{p}), where $h$ denotes the space size and p is a positive integer. A wide set of numerical examples are carried out to confirm the theoretical results and to demonstrate the utility and validity of the proposed numerical scheme. An application to landslides observed in west and center regions in Cameroon from October 2019 to November 2024, are discussed.","authors":["Eric Ngondiep"],"url":"https://arxiv.org/abs/2502.07797"}
{"created":"2025-04-22","title":"Learning Humanoid Standing-up Control across Diverse Postures","abstract":"Standing-up control is crucial for humanoid robots, with the potential for integration into current locomotion and loco-manipulation systems, such as fall recovery. Existing approaches are either limited to simulations that overlook hardware constraints or rely on predefined ground-specific motion trajectories, failing to enable standing up across postures in real-world scenes. To bridge this gap, we present HoST (Humanoid Standing-up Control), a reinforcement learning framework that learns standing-up control from scratch, enabling robust sim-to-real transfer across diverse postures. HoST effectively learns posture-adaptive motions by leveraging a multi-critic architecture and curriculum-based training on diverse simulated terrains. To ensure successful real-world deployment, we constrain the motion with smoothness regularization and implicit motion speed bound to alleviate oscillatory and violent motions on physical hardware, respectively. After simulation-based training, the learned control policies are directly deployed on the Unitree G1 humanoid robot. Our experimental results demonstrate that the controllers achieve smooth, stable, and robust standing-up motions across a wide range of laboratory and outdoor environments. Videos and code are available at https://taohuang13.github.io/humanoid-standingup.github.io/.","authors":["Tao Huang","Junli Ren","Huayi Wang","Zirui Wang","Qingwei Ben","Muning Wen","Xiao Chen","Jianan Li","Jiangmiao Pang"],"url":"https://arxiv.org/abs/2502.08378"}
{"created":"2025-04-22","title":"SparQLe: Speech Queries to Text Translation Through LLMs","abstract":"With the growing influence of Large Language Models (LLMs), there is increasing interest in integrating speech representations with them to enable more seamless multi-modal processing and speech understanding. This study introduces a novel approach that leverages self-supervised speech representations in combination with instruction-tuned LLMs for speech-to-text translation. The proposed approach leverages a modality adapter to align extracted speech features with instruction-tuned LLMs using English-language data. Our experiments demonstrate that this method effectively preserves the semantic content of the input speech and serves as an effective bridge between self-supervised speech models and instruction-tuned LLMs, offering a promising solution for various speech understanding applications.","authors":["Amirbek Djanibekov","Hanan Aldarmaki"],"url":"https://arxiv.org/abs/2502.09284"}
{"created":"2025-04-22","title":"Grassroots Platforms with Atomic Transactions: Social Networks, Cryptocurrencies, and Democratic Federations","abstract":"Grassroots platforms aim to offer an egalitarian alternative to global platforms. Whereas global platforms can have only a single instance, grassroots platforms can have multiple instances that emerge and operate independently of each other and of any global resource except the network, and can interoperate and coalesce into ever-larger instances once interconnected. Key grassroots platforms include grassroots social networks, grassroots cryptocurrencies, and grassroots democratic federations. Previously, grassroots platforms were defined formally and proven grassroots using unary distributed transition systems, in which each transition is carried out by a single agent. However, grassroots platforms cater for a more abstract specification using transactions carried out atomically by multiple agents, something that cannot be expressed by unary transition systems. As a result, their original specifications and proofs were unnecessarily cumbersome and opaque.","authors":["Ehud Shapiro"],"url":"https://arxiv.org/abs/2502.11299"}
{"created":"2025-04-22","title":"TechSinger: Technique Controllable Multilingual Singing Voice Synthesis via Flow Matching","abstract":"Singing voice synthesis has made remarkable progress in generating natural and high-quality voices. However, existing methods rarely provide precise control over vocal techniques such as intensity, mixed voice, falsetto, bubble, and breathy tones, thus limiting the expressive potential of synthetic voices. We introduce TechSinger, an advanced system for controllable singing voice synthesis that supports five languages and seven vocal techniques. TechSinger leverages a flow-matching-based generative model to produce singing voices with enhanced expressive control over various techniques. To enhance the diversity of training data, we develop a technique detection model that automatically annotates datasets with phoneme-level technique labels. Additionally, our prompt-based technique prediction model enables users to specify desired vocal attributes through natural language, offering fine-grained control over the synthesized singing. Experimental results demonstrate that TechSinger significantly enhances the expressiveness and realism of synthetic singing voices, outperforming existing methods in terms of audio quality and technique-specific control. Audio samples can be found at https://gwx314.github.io/tech-singer/.","authors":["Wenxiang Guo","Yu Zhang","Changhao Pan","Rongjie Huang","Li Tang","Ruiqi Li","Zhiqing Hong","Yongqi Wang","Zhou Zhao"],"url":"https://arxiv.org/abs/2502.12572"}
{"created":"2025-04-22","title":"Activation-wise Propagation: A Universal Strategy to Break Timestep Constraints in Spiking Neural Networks for 3D Data Processing","abstract":"Due to their event-driven and parameter-efficient effect, spiking neural networks (SNNs) show potential in tasks requiring real-time multi-sensor perception, such as autonomous driving. The spiking mechanism facilitates sparse encoding, enabling spatial and temporal data to be represented in a discrete manner. However, SNNs still lag behind artificial neural networks (ANNs) in terms of performance and computational efficiency. One major challenge in SNNs is the timestep-wise iterative update of neuronal states, which makes it difficult to achieve an optimal trade-off among accuracy, latency, and training cost. Although some methods perform well with shorter timesteps, few propose strategies to overcome such constraint effectively. Moreover, many recent SNN advancements rely on either optimizations tailored to specific architectures or a collection of specialized neuron-level strategies. While these approaches can enhance performance, they often lead to increased computational expense and restrict their application to particular architectures or modalities. This leaves room for further exploration of simple, universal, and structure-agnostic strategies that could offer broader applicability and efficiency. In this paper, we introduce Activation-wise Membrane Potential Propagation (AMP2), a novel state update mechanism for spiking neurons. Inspired by skip connections in deep networks, AMP2 incorporates the membrane potential of neurons into network, eliminating the need for iterative updates. Our method achieves significant improvements across various 3D modalities, including 3D point clouds and event streams, boosting Spiking PointNet's accuracy on ModelNet40 from 87.36% to 89.74% and surpassing ANN PointNet in recognition accuracy on the DVS128 Gesture dataset.","authors":["Jian Song","Xiangfei Yang","Donglin Wang"],"url":"https://arxiv.org/abs/2502.12791"}
{"created":"2025-04-22","title":"HiddenDetect: Detecting Jailbreak Attacks against Large Vision-Language Models via Monitoring Hidden States","abstract":"The integration of additional modalities increases the susceptibility of large vision-language models (LVLMs) to safety risks, such as jailbreak attacks, compared to their language-only counterparts. While existing research primarily focuses on post-hoc alignment techniques, the underlying safety mechanisms within LVLMs remain largely unexplored. In this work , we investigate whether LVLMs inherently encode safety-relevant signals within their internal activations during inference. Our findings reveal that LVLMs exhibit distinct activation patterns when processing unsafe prompts, which can be leveraged to detect and mitigate adversarial inputs without requiring extensive fine-tuning. Building on this insight, we introduce HiddenDetect, a novel tuning-free framework that harnesses internal model activations to enhance safety. Experimental results show that {HiddenDetect} surpasses state-of-the-art methods in detecting jailbreak attacks against LVLMs. By utilizing intrinsic safety-aware patterns, our method provides an efficient and scalable solution for strengthening LVLM robustness against multimodal threats. Our code will be released publicly at https://github.com/leigest519/HiddenDetect.","authors":["Yilei Jiang","Xinyan Gao","Tianshuo Peng","Yingshui Tan","Xiaoyong Zhu","Bo Zheng","Xiangyu Yue"],"url":"https://arxiv.org/abs/2502.14744"}
{"created":"2025-04-22","title":"LServe: Efficient Long-sequence LLM Serving with Unified Sparse Attention","abstract":"Large language models (LLMs) have shown remarkable potential in processing long sequences and complex reasoning tasks, yet efficiently serving these models remains challenging due to the quadratic computational complexity of attention in the prefilling stage and the large memory footprint of the KV cache in the decoding stage. To address these issues, we introduce LServe, an efficient system that accelerates long-sequence LLM serving via hybrid sparse attention. This method unifies different hardware-friendly, structured sparsity patterns for both prefilling and decoding attention into a single framework, where computations on less important tokens are skipped block-wise. LServe demonstrates the compatibility of static and dynamic sparsity in long-context LLM attention. This design enables multiplicative speedups by combining these optimizations. Specifically, we convert half of the attention heads to nearly free streaming heads in both the prefilling and decoding stages. Additionally, we find that only a constant number of KV pages is required to preserve long-context and reasoning capabilities, irrespective of context length. We then design a hierarchical KV page selection policy that dynamically prunes KV pages based on query-centric similarity. On average, LServe accelerates LLM prefilling by up to 2.9x and decoding by 1.3-2.1x over vLLM, maintaining long-context accuracy. Code is released at https://github.com/mit-han-lab/omniserve.","authors":["Shang Yang","Junxian Guo","Haotian Tang","Qinghao Hu","Guangxuan Xiao","Jiaming Tang","Yujun Lin","Zhijian Liu","Yao Lu","Song Han"],"url":"https://arxiv.org/abs/2502.14866"}
{"created":"2025-04-22","title":"Human-AI Collaboration in Cloud Security: Cognitive Hierarchy-Driven Deep Reinforcement Learning","abstract":"Given the complexity of multi-tenant cloud environments and the growing need for real-time threat mitigation, Security Operations Centers (SOCs) must adopt AI-driven adaptive defense mechanisms to counter Advanced Persistent Threats (APTs). However, SOC analysts face challenges in handling adaptive adversarial tactics, requiring intelligent decision-support frameworks. We propose a Cognitive Hierarchy Theory-driven Deep Q-Network (CHT-DQN) framework that models interactive decision-making between SOC analysts and AI-driven APT bots. The SOC analyst (defender) operates at cognitive level-1, anticipating attacker strategies, while the APT bot (attacker) follows a level-0 policy. By incorporating CHT into DQN, our framework enhances adaptive SOC defense using Attack Graph (AG)-based reinforcement learning. Simulation experiments across varying AG complexities show that CHT-DQN consistently achieves higher data protection and lower action discrepancies compared to standard DQN. A theoretical lower bound further confirms its superiority as AG complexity increases. A human-in-the-loop (HITL) evaluation on Amazon Mechanical Turk (MTurk) reveals that SOC analysts using CHT-DQN-derived transition probabilities align more closely with adaptive attackers, leading to better defense outcomes. Moreover, human behavior aligns with Prospect Theory (PT) and Cumulative Prospect Theory (CPT): participants are less likely to reselect failed actions and more likely to persist with successful ones. This asymmetry reflects amplified loss sensitivity and biased probability weighting -- underestimating gains after failure and overestimating continued success. Our findings highlight the potential of integrating cognitive models into deep reinforcement learning to improve real-time SOC decision-making for cloud security.","authors":["Zahra Aref","Sheng Wei","Narayan B. Mandayam"],"url":"https://arxiv.org/abs/2502.16054"}
{"created":"2025-04-22","title":"The Design Space of Recent AI-assisted Research Tools for Ideation, Sensemaking, and Scientific Creativity","abstract":"Generative AI (GenAI) tools are radically expanding the scope and capability of automation in knowledge work such as academic research. While promising for augmenting cognition and streamlining processes, AI-assisted research tools may also increase automation bias and hinder critical thinking. To examine recent developments, we surveyed publications from leading HCI venues over the past three years, closely analyzing thirteen tools to better understand the novel capabilities of these AI-assisted systems and the design spaces they enable: seven employing traditional AI or customized transformer-based approaches, and six integrating open-access large language models (LLMs). Our analysis characterizes the emerging design space, distinguishes between tools focused on workflow mimicry versus generative exploration, and yields four critical design recommendations to guide the development of future systems that foster meaningful cognitive engagement: providing user agency and control, differentiating divergent/convergent thinking support, ensuring adaptability, and prioritizing transparency/accuracy. This work discusses how these insights signal a shift from mere workflow replication towards generative co-creation, presenting new opportunities for the community to craft intuitive, AI-driven research interfaces and interactions.","authors":["Runlong Ye (University of Toronto)","Matthew Varona (University of Toronto)","Oliver Huang (University of Toronto)","Patrick Yung Kang Lee (University of Toronto)","Michael Liut (University of Toronto)","Carolina Nobre (University of Toronto)"],"url":"https://arxiv.org/abs/2502.16291"}
{"created":"2025-04-22","title":"Wrong Answers Can Also Be Useful: PlausibleQA -- A Large-Scale QA Dataset with Answer Plausibility Scores","abstract":"Large Language Models (LLMs) are revolutionizing information retrieval, with chatbots becoming an important source for answering user queries. As by their design, LLMs prioritize generating correct answers, the value of highly plausible yet incorrect answers (candidate answers) tends to be overlooked. However, such answers can still prove useful, for example, they can play a crucial role in tasks like Multiple-Choice Question Answering (MCQA) and QA Robustness Assessment (QARA). Existing QA datasets primarily focus on correct answers without explicit consideration of the plausibility of other candidate answers, limiting opportunity for more nuanced evaluations of models. To address this gap, we introduce PlausibleQA, a large-scale dataset comprising 10,000 questions and 100,000 candidate answers, each annotated with plausibility scores and justifications for their selection. Additionally, the dataset includes 900,000 justifications for pairwise comparisons between candidate answers, further refining plausibility assessments. We evaluate PlausibleQA through human assessments and empirical experiments, demonstrating its utility in MCQA and QARA analysis. Our findings show that plausibility-aware approaches are effective for MCQA distractor generation and QARA. We release PlausibleQA as a resource for advancing QA research and enhancing LLM performance in distinguishing plausible distractors from correct answers.","authors":["Jamshid Mozafari","Abdelrahman Abdallah","Bhawna Piryani","Adam Jatowt"],"url":"https://arxiv.org/abs/2502.16358"}
{"created":"2025-04-22","title":"Potential-Based Greedy Matching for Dynamic Delivery Pooling","abstract":"We study the pooling of multiple orders into a single trip, a strategy widely adopted by online delivery platforms. When an order has to be dispatched, the platform must determine which (if any) of the other available orders to pool it with, weighing the immediate efficiency gains against the uncertain, differential benefits of holding each order for future pooling opportunities. In this paper, we demonstrate the effectiveness of using the length of each job as its opportunity cost, via a potential-based greedy algorithm (PB). The algorithm is very simple, pooling each departing job with the available job that maximizes the savings in travel distance minus a half of its distance (i.e. the potential). On the theoretical front, we show that PB significantly improves upon a naive greedy algorithm in terms of worst-case performance: as the density of the market increases, the regret per job vanishes under PB but remains constant under naive greedy. In addition, we show that the potential approximates the marginal cost of dispatching each job in a stochastic setting with sufficient density. Moreover, we conduct extensive numerical experiments and show that despite its simplicity, PB consistently outperforms a number of benchmark algorithms, including (i) batching-based heuristics that are widely used in practice, and (ii) forecast-aware heuristics that estimate the marginal costs of dispatching different jobs using historical data.","authors":["Hongyao Ma","Will Ma","Matias Romero"],"url":"https://arxiv.org/abs/2502.16862"}
{"created":"2025-04-22","title":"A Novel Retinal Image Contrast Enhancement -- Fuzzy-Based Method","abstract":"The vascular structure in retinal images plays a crucial role in ophthalmic diagnostics, and its accuracies are directly influenced by the quality of the retinal image. Contrast enhancement is one of the crucial steps in any segmentation algorithm - the more so since the retinal images are related to medical diagnosis. Contrast enhancement is a vital step that not only intensifies the darkness of the blood vessels but also prevents minor capillaries from being disregarded during the process. This paper proposes a novel model that utilizes the linear blending of Fuzzy Contrast Enhancement (FCE) and Contrast Limited Adaptive Histogram Equalization (CLAHE) to enhance the retinal image for retinal vascular structure segmentation. The scheme is tested using the Digital Retinal Images for Vessel Extraction (DRIVE) dataset. The assertion was then evaluated through performance comparison among other methodologies which are Gray-scaling, Histogram Equalization (HE), FCE, and CLAHE. It was evident in this paper that the combination of FCE and CLAHE methods showed major improvement. Both FCE and CLAHE methods dominating with 88% as better enhancement methods proved that preprocessing through fuzzy logic is effective.","authors":["Adnan Shaout","Jiho Han"],"url":"https://arxiv.org/abs/2502.17850"}
{"created":"2025-04-22","title":"Harnessing Multiple Large Language Models: A Survey on LLM Ensemble","abstract":"LLM Ensemble -- which involves the comprehensive use of multiple large language models (LLMs), each aimed at handling user queries during downstream inference, to benefit from their individual strengths -- has gained substantial attention recently. The widespread availability of LLMs, coupled with their varying strengths and out-of-the-box usability, has profoundly advanced the field of LLM Ensemble. This paper presents the first systematic review of recent developments in LLM Ensemble. First, we introduce our taxonomy of LLM Ensemble and discuss several related research problems. Then, we provide a more in-depth classification of the methods under the broad categories of \"ensemble-before-inference, ensemble-during-inference, ensemble-after-inference'', and review all relevant methods. Finally, we introduce related benchmarks and applications, summarize existing studies, and suggest several future research directions. A curated list of papers on LLM Ensemble is available at https://github.com/junchenzhi/Awesome-LLM-Ensemble.","authors":["Zhijun Chen","Jingzheng Li","Pengpeng Chen","Zhuoran Li","Kai Sun","Yuankai Luo","Qianren Mao","Dingqi Yang","Hailong Sun","Philip S. Yu"],"url":"https://arxiv.org/abs/2502.18036"}
{"created":"2025-04-22","title":"Steganography Beyond Space-Time with Chain of Multimodal AI","abstract":"Steganography is the art and science of covert writing, with a broad range of applications interwoven within the realm of cybersecurity. As artificial intelligence continues to evolve, its ability to synthesise realistic content emerges as a threat in the hands of cybercriminals who seek to manipulate and misrepresent the truth. Such synthetic content introduces a non-trivial risk of overwriting the subtle changes made for the purpose of steganography. When the signals in both the spatial and temporal domains are vulnerable to unforeseen overwriting, it calls for reflection on what, if any, remains invariant. This study proposes a paradigm in steganography for audiovisual media, where messages are concealed beyond both spatial and temporal domains. A chain of multimodal artificial intelligence is developed to deconstruct audiovisual content into a cover text, embed a message within the linguistic domain, and then reconstruct the audiovisual content through synchronising both auditory and visual modalities with the resultant stego text. The message is encoded by biasing the word sampling process of a language generation model and decoded by analysing the probability distribution of word choices. The accuracy of message transmission is evaluated under both zero-bit and multi-bit capacity settings. Fidelity is assessed through both biometric and semantic similarities, capturing the identities of the recorded face and voice, as well as the core ideas conveyed through the media. Secrecy is examined through statistical comparisons between cover and stego texts. Robustness is tested across various scenarios, including audiovisual resampling, face-swapping, voice-cloning and their combinations.","authors":["Ching-Chun Chang","Isao Echizen"],"url":"https://arxiv.org/abs/2502.18547"}
{"created":"2025-04-22","title":"Distill Any Depth: Distillation Creates a Stronger Monocular Depth Estimator","abstract":"Recent advances in zero-shot monocular depth estimation(MDE) have significantly improved generalization by unifying depth distributions through normalized depth representations and by leveraging large-scale unlabeled data via pseudo-label distillation. However, existing methods that rely on global depth normalization treat all depth values equally, which can amplify noise in pseudo-labels and reduce distillation effectiveness. In this paper, we present a systematic analysis of depth normalization strategies in the context of pseudo-label distillation. Our study shows that, under recent distillation paradigms (e.g., shared-context distillation), normalization is not always necessary, as omitting it can help mitigate the impact of noisy supervision. Furthermore, rather than focusing solely on how depth information is represented, we propose Cross-Context Distillation, which integrates both global and local depth cues to enhance pseudo-label quality. We also introduce an assistant-guided distillation strategy that incorporates complementary depth priors from a diffusion-based teacher model, enhancing supervision diversity and robustness. Extensive experiments on benchmark datasets demonstrate that our approach significantly outperforms state-of-the-art methods, both quantitatively and qualitatively.","authors":["Xiankang He","Dongyan Guo","Hongji Li","Ruibo Li","Ying Cui","Chi Zhang"],"url":"https://arxiv.org/abs/2502.19204"}
{"created":"2025-04-22","title":"Revealing Treatment Non-Adherence Bias in Clinical Machine Learning Using Large Language Models","abstract":"Machine learning systems trained on electronic health records (EHRs) increasingly guide treatment decisions, but their reliability depends on the critical assumption that patients follow the prescribed treatments recorded in EHRs. Using EHR data from 3,623 hypertension patients, we investigate how treatment non-adherence introduces implicit bias that can fundamentally distort both causal inference and predictive modeling. By extracting patient adherence information from clinical notes using a large language model (LLM), we identify 786 patients (21.7%) with medication non-adherence. We further uncover key demographic and clinical factors associated with non-adherence, as well as patient-reported reasons including side effects and difficulties obtaining refills. Our findings demonstrate that this implicit bias can not only reverse estimated treatment effects, but also degrade model performance by up to 5% while disproportionately affecting vulnerable populations by exacerbating disparities in decision outcomes and model error rates. This highlights the importance of accounting for treatment non-adherence in developing responsible and equitable clinical machine learning systems.","authors":["Zhongyuan Liang","Arvind Suresh","Irene Y. Chen"],"url":"https://arxiv.org/abs/2502.19625"}
{"created":"2025-04-22","title":"MedUnifier: Unifying Vision-and-Language Pre-training on Medical Data with Vision Generation Task using Discrete Visual Representations","abstract":"Despite significant progress in Vision-Language Pre-training (VLP), current approaches predominantly emphasize feature extraction and cross-modal comprehension, with limited attention to generating or transforming visual content. This gap hinders the model's ability to synthesize coherent and novel visual representations from textual prompts, thereby reducing the effectiveness of multi-modal learning. In this work, we propose MedUnifier, a unified VLP framework tailored for medical data. MedUnifier seamlessly integrates text-grounded image generation capabilities with multi-modal learning strategies, including image-text contrastive alignment, image-text matching and image-grounded text generation. Unlike traditional methods that reply on continuous visual representations, our approach employs visual vector quantization, which not only facilitates a more cohesive learning strategy for cross-modal understanding but also enhances multi-modal generation quality by effectively leveraging discrete representations. Our framework's effectiveness is evidenced by the experiments on established benchmarks, including uni-modal tasks (supervised fine-tuning), cross-modal tasks (image-text retrieval and zero-shot image classification), and multi-modal tasks (medical report generation, image synthesis), where it achieves state-of-the-art performance across various tasks. MedUnifier also offers a highly adaptable tool for a wide range of language and vision tasks in healthcare, marking advancement toward the development of a generalizable AI model for medical applications.","authors":["Ziyang Zhang","Yang Yu","Yucheng Chen","Xulei Yang","Si Yong Yeo"],"url":"https://arxiv.org/abs/2503.01019"}
{"created":"2025-04-22","title":"HeterRec: Heterogeneous Information Transformer for Scalable Sequential Recommendation","abstract":"Transformer-based sequential recommendation (TSR) models have shown superior performance in recommendation systems, where the quality of item representations plays a crucial role. Classical representation methods integrate item features using concatenation or neural networks to generate homogeneous representation sequences. While straightforward, these methods overlook the heterogeneity of item features, limiting the transformer's ability to capture fine-grained patterns and restricting scalability. Recent studies have attempted to integrate user-side heterogeneous features into item representation sequences, but item-side heterogeneous features, which are vital for performance, remain excluded. To address these challenges, we propose a Heterogeneous Information Transformer model for Sequential Recommendation (HeterRec), which incorporates Heterogeneous Token Flatten Layer (HTFL) and Hierarchical Causal Transformer Layer (HCT). Our HTFL is a novel item tokenization method that converts items into a heterogeneous token set and organizes these tokens into heterogeneous sequences, effectively enhancing performance gains when scaling up the model. Moreover, HCT introduces token-level and item-level causal transformers to extract fine-grained patterns from the heterogeneous sequences. Additionally, we design a Listwise Multi-step Prediction (LMP) Loss function to further improve performance. Extensive experiments on both offline and online datasets show that the HeterRec model achieves superior performance.","authors":["Hao Deng","Haibo Xing","Kanefumi Matsuyama","Yulei Huang","Jinxin Hu","Hong Wen","Jia Xu","Zulong Chen","Yu Zhang","Xiaoyi Zeng","Jing Zhang"],"url":"https://arxiv.org/abs/2503.01469"}
{"created":"2025-04-22","title":"Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation","abstract":"Many large-scale systems rely on high-quality deep representations (embeddings) to facilitate tasks like retrieval, search, and generative modeling. Matryoshka Representation Learning (MRL) recently emerged as a solution for adaptive embedding lengths, but it requires full model retraining and suffers from noticeable performance degradations at short lengths. In this paper, we show that sparse coding offers a compelling alternative for achieving adaptive representation with minimal overhead and higher fidelity. We propose Contrastive Sparse Representation (CSR), a method that sparsifies pre-trained embeddings into a high-dimensional but selectively activated feature space. By leveraging lightweight autoencoding and task-aware contrastive objectives, CSR preserves semantic quality while allowing flexible, cost-effective inference at different sparsity levels. Extensive experiments on image, text, and multimodal benchmarks demonstrate that CSR consistently outperforms MRL in terms of both accuracy and retrieval speed-often by large margins-while also cutting training time to a fraction of that required by MRL. Our results establish sparse coding as a powerful paradigm for adaptive representation learning in real-world applications where efficiency and fidelity are both paramount. Code is available at https://github.com/neilwen987/CSR_Adaptive_Rep","authors":["Tiansheng Wen","Yifei Wang","Zequn Zeng","Zhong Peng","Yudi Su","Xinyang Liu","Bo Chen","Hongwei Liu","Stefanie Jegelka","Chenyu You"],"url":"https://arxiv.org/abs/2503.01776"}
{"created":"2025-04-22","title":"Proof-Producing Translation of Functional Programs into a Time \\& Space Reasonable Model","abstract":"We present a semi-automated framework to construct and reason about programs in a deeply-embedded while-language. The while-language we consider is a simple computation model that can simulate (and be simulated by) Turing Machines with a quadratic time and constant space blow-up. Our framework derives while-programs from functional programs written in a subset of Isabelle/HOL, namely tail-recursive functions with first-order arguments and algebraic datatypes. As far as we are aware, it is the first framework targeting a computation model that is reasonable in time and space from a complexity-theoretic perspective.","authors":["Kevin Kappelmann","Fabian Huch","Lukas Stevens","Mohammad Abdulaziz"],"url":"https://arxiv.org/abs/2503.02975"}
{"created":"2025-04-22","title":"Generative Learning of Densities on Manifolds","abstract":"A generative modeling framework is proposed that combines diffusion models and manifold learning to efficiently sample data densities on manifolds. The approach utilizes Diffusion Maps to uncover possible low-dimensional underlying (latent) spaces in the high-dimensional data (ambient) space. Two approaches for sampling from the latent data density are described. The first is a score-based diffusion model, which is trained to map a standard normal distribution to the latent data distribution using a neural network. The second one involves solving an It\\^o stochastic differential equation in the latent space. Additional realizations of the data are generated by lifting the samples back to the ambient space using Double Diffusion Maps, a recently introduced technique typically employed in studying dynamical system reduction; here the focus lies in sampling densities rather than system dynamics. The proposed approaches enable sampling high dimensional data densities restricted to low-dimensional, a priori unknown manifolds. The efficacy of the proposed framework is demonstrated through a benchmark problem and a material with multiscale structure.","authors":["Dimitris G. Giovanis","Ellis Crabtree","Roger G. Ghanem","Ioannis G. Kevrekidis"],"url":"https://arxiv.org/abs/2503.03963"}
{"created":"2025-04-22","title":"Urban Metaverse: The Smart City in the Industrial Metaverse. Opportunities of the metaverse for real-time, interactive, and inclusive infrastructure applications in urban areas","abstract":"The Urban Metaverse describes an immersive 3D environment that connects the physical world of the city and its citizens with its digital data and systems. Physical and digital realities merge, opening up new possibilities for the design and use of the city. This trend study serves as a source of inspiration and guidance for city and community leaders, urban planners, IT professionals, and anyone interested in the future of urban spaces. It helps to understand the opportunities and challenges of the urban metaverse as an evolution of the Smart City and to set the course for sustainable and innovative urban development. To this end, the study analyzes the opportunities that the urban metaverse offers for urban administration and the everyday life of citizens, presents key technologies, and highlights the socio-economic challenges of implementation. The focus is on the potential of the urban metaverse to optimize the planning and operation of urban infrastructures, to promote inclusion and civic participation, and to enhance the innovative capacity of cities and municipalities. The study develops four recommendations for the implementation of metaverse applications in an urban context: 1. user-centered design, 2. ubiquitous accessibility, 3. proactive design of the regulatory framework, and 4. development of viable business models.","authors":["Christina Dienhart","Luis Kaufhold","Frank Piller"],"url":"https://arxiv.org/abs/2503.04729"}
{"created":"2025-04-22","title":"AILuminate: Introducing v1.0 of the AI Risk and Reliability Benchmark from MLCommons","abstract":"The rapid advancement and deployment of AI systems have created an urgent need for standard safety-evaluation frameworks. This paper introduces AILuminate v1.0, the first comprehensive industry-standard benchmark for assessing AI-product risk and reliability. Its development employed an open process that included participants from multiple fields. The benchmark evaluates an AI system's resistance to prompts designed to elicit dangerous, illegal, or undesirable behavior in 12 hazard categories, including violent crimes, nonviolent crimes, sex-related crimes, child sexual exploitation, indiscriminate weapons, suicide and self-harm, intellectual property, privacy, defamation, hate, sexual content, and specialized advice (election, financial, health, legal). Our method incorporates a complete assessment standard, extensive prompt datasets, a novel evaluation framework, a grading and reporting system, and the technical as well as organizational infrastructure for long-term support and evolution. In particular, the benchmark employs an understandable five-tier grading scale (Poor to Excellent) and incorporates an innovative entropy-based system-response evaluation.","authors":["Shaona Ghosh","Heather Frase","Adina Williams","Sarah Luger","Paul R\\\"ottger","Fazl Barez","Sean McGregor","Kenneth Fricklas","Mala Kumar","Quentin Feuillade--Montixi","Kurt Bollacker","Felix Friedrich","Ryan Tsang","Bertie Vidgen","Alicia Parrish","Chris Knotz","Eleonora Presani","Jonathan Bennion","Marisa Ferrara Boston","Mike Kuniavsky","Wiebke Hutiri","James Ezick","Malek Ben Salem","Rajat Sahay","Sujata Goswami","Usman Gohar","Ben Huang","Supheakmungkol Sarin","Elie Alhajjar","Canyu Chen","Roman Eng","Kashyap Ramanandula Manjusha","Virendra Mehta","Eileen Long","Murali Emani","Natan Vidra","Benjamin Rukundo","Abolfazl Shahbazi","Kongtao Chen","Rajat Ghosh","Vithursan Thangarasa","Pierre Peign\\'e","Abhinav Singh","Max Bartolo","Satyapriya Krishna","Mubashara Akhtar","Rafael Gold","Cody Coleman","Luis Oala","Vassil Tashev","Joseph Marvin Imperial","Amy Russ","Sasidhar Kunapuli","Nicolas Miailhe","Julien Delaunay","Bhaktipriya Radharapu","Rajat Shinde","Tuesday","Debojyoti Dutta","Declan Grabb","Ananya Gangavarapu","Saurav Sahay","Agasthya Gangavarapu","Patrick Schramowski","Stephen Singam","Tom David","Xudong Han","Priyanka Mary Mammen","Tarunima Prabhakar","Venelin Kovatchev","Rebecca Weiss","Ahmed Ahmed","Kelvin N. Manyeki","Sandeep Madireddy","Foutse Khomh","Fedor Zhdanov","Joachim Baumann","Nina Vasan","Xianjun Yang","Carlos Mougn","Jibin Rajan Varghese","Hussain Chinoy","Seshakrishna Jitendar","Manil Maskey","Claire V. Hardgrove","Tianhao Li","Aakash Gupta","Emil Joswin","Yifan Mai","Shachi H Kumar","Cigdem Patlak","Kevin Lu","Vincent Alessi","Sree Bhargavi Balija","Chenhe Gu","Robert Sullivan","James Gealy","Matt Lavrisa","James Goel","Peter Mattson","Percy Liang","Joaquin Vanschoren"],"url":"https://arxiv.org/abs/2503.05731"}
{"created":"2025-04-22","title":"Multi-agent Auto-Bidding with Latent Graph Diffusion Models","abstract":"This paper proposes a diffusion-based auto-bidding framework that leverages graph representations to model large-scale auction environments. In such settings, agents must dynamically optimize bidding strategies under constraints defined by key performance indicator (KPI) metrics, all while operating in competitive environments characterized by uncertain, sparse, and stochastic variables. To address these challenges, we introduce a novel approach combining learnable graph-based embeddings with a planning-based latent diffusion model (LDM). By capturing patterns and nuances underlying the interdependence of impression opportunities and the multi-agent dynamics of the auction environment, the graph representation enable expressive computations regarding auto-bidding outcomes. With reward alignment techniques, the LDM's posterior is fine-tuned to generate auto-bidding trajectories that maximize KPI metrics while satisfying constraint thresholds. Empirical evaluations on both real-world and synthetic auction environments demonstrate significant improvements in auto-bidding performance across multiple common KPI metrics, as well as accuracy in forecasting auction outcomes.","authors":["Dom Huh","Prasant Mohapatra"],"url":"https://arxiv.org/abs/2503.05805"}
{"created":"2025-04-22","title":"VACT: A Video Automatic Causal Testing System and a Benchmark","abstract":"With the rapid advancement of text-conditioned Video Generation Models (VGMs), the quality of generated videos has significantly improved, bringing these models closer to functioning as ``*world simulators*'' and making real-world-level video generation more accessible and cost-effective. However, the generated videos often contain factual inaccuracies and lack understanding of fundamental physical laws. While some previous studies have highlighted this issue in limited domains through manual analysis, a comprehensive solution has not yet been established, primarily due to the absence of a generalized, automated approach for modeling and assessing the causal reasoning of these models across diverse scenarios. To address this gap, we propose VACT: an **automated** framework for modeling, evaluating, and measuring the causal understanding of VGMs in real-world scenarios. By combining causal analysis techniques with a carefully designed large language model assistant, our system can assess the causal behavior of models in various contexts without human annotation, which offers strong generalization and scalability. Additionally, we introduce multi-level causal evaluation metrics to provide a detailed analysis of the causal performance of VGMs. As a demonstration, we use our framework to benchmark several prevailing VGMs, offering insight into their causal reasoning capabilities. Our work lays the foundation for systematically addressing the causal understanding deficiencies in VGMs and contributes to advancing their reliability and real-world applicability.","authors":["Haotong Yang","Qingyuan Zheng","Yunjian Gao","Yongkun Yang","Yangbo He","Zhouchen Lin","Muhan Zhang"],"url":"https://arxiv.org/abs/2503.06163"}
{"created":"2025-04-22","title":"From Idea to Implementation: Evaluating the Influence of Large Language Models in Software Development -- An Opinion Paper","abstract":"The introduction of transformer architecture was a turning point in Natural Language Processing (NLP). Models based on the transformer architecture such as Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-Trained Transformer (GPT) have gained widespread popularity in various applications such as software development and education. The availability of Large Language Models (LLMs) such as ChatGPT and Bard to the general public has showcased the tremendous potential of these models and encouraged their integration into various domains such as software development for tasks such as code generation, debugging, and documentation generation. In this study, opinions from 11 experts regarding their experience with LLMs for software development have been gathered and analysed to draw insights that can guide successful and responsible integration. The overall opinion of the experts is positive, with the experts identifying advantages such as increase in productivity and reduced coding time. Potential concerns and challenges such as risk of over-dependence and ethical considerations have also been highlighted.","authors":["Sargam Yadav (School of Informatics and Creative Arts","Dundalk Institute of Technology","Dundalk","Ireland)","Asifa Mehmood Qureshi (School of Informatics and Creative Arts","Dundalk Institute of Technology","Dundalk","Ireland)","Abhishek Kaushik (School of Informatics and Creative Arts","Dundalk Institute of Technology","Dundalk","Ireland)","Shubham Sharma (The Centre for Research in Engineering Surface Technology)","Roisin Loughran (School of Informatics and Creative Arts","Dundalk Institute of Technology","Dundalk","Ireland)","Subramaniam Kazhuparambil (Zendesk","Dublin","Ireland)","Andrew Shaw (School of Informatics and Creative Arts","Dundalk Institute of Technology","Dundalk","Ireland)","Mohammed Sabry (ADAPT Centre Dublin","Ireland)","Niamh St John Lynch (School of Informatics and Creative Arts","Dundalk Institute of Technology","Dundalk","Ireland)",". Nikhil Singh (National College of Ireland","Dublin","Ireland)","Padraic O'Hara (School of Informatics and Creative Arts","Dundalk Institute of Technology","Dundalk","Ireland)","Pranay Jaiswal (School of Informatics and Creative Arts","Dundalk Institute of Technology","Dundalk","Ireland)","Roshan Chandru (School of Informatics and Creative Arts","Dundalk Institute of Technology","Dundalk","Ireland)","David Lillis (School of Computer Science","University College Dublin)"],"url":"https://arxiv.org/abs/2503.07450"}
{"created":"2025-04-22","title":"HRAvatar: High-Quality and Relightable Gaussian Head Avatar","abstract":"Reconstructing animatable and high-quality 3D head avatars from monocular videos, especially with realistic relighting, is a valuable task. However, the limited information from single-view input, combined with the complex head poses and facial movements, makes this challenging. Previous methods achieve real-time performance by combining 3D Gaussian Splatting with a parametric head model, but the resulting head quality suffers from inaccurate face tracking and limited expressiveness of the deformation model. These methods also fail to produce realistic effects under novel lighting conditions. To address these issues, we propose HRAvatar, a 3DGS-based method that reconstructs high-fidelity, relightable 3D head avatars. HRAvatar reduces tracking errors through end-to-end optimization and better captures individual facial deformations using learnable blendshapes and learnable linear blend skinning. Additionally, it decomposes head appearance into several physical properties and incorporates physically-based shading to account for environmental lighting. Extensive experiments demonstrate that HRAvatar not only reconstructs superior-quality heads but also achieves realistic visual effects under varying lighting conditions.","authors":["Dongbin Zhang","Yunfei Liu","Lijian Lin","Ye Zhu","Kangjie Chen","Minghan Qin","Yu Li","Haoqian Wang"],"url":"https://arxiv.org/abs/2503.08224"}
{"created":"2025-04-22","title":"Improved Approximation Algorithms for Three-Dimensional Bin Packing","abstract":"We study three fundamental three-dimensional (3D) geometric packing problems: 3D (Geometric) Bin Packing (3D-BP), 3D Strip Packing (3D-SP), and Minimum Volume Bounding Box (3D-MVBB), where given a set of 3D (rectangular) cuboids, the goal is to find an axis-aligned nonoverlapping packing of all cuboids. In 3D-BP, we need to pack the given cuboids into the minimum number of unit cube bins. In 3D-SP, we need to pack them into a 3D cuboid with a unit square base and minimum height. Finally, in 3D-MVBB, the goal is to pack into a cuboid box of minimum volume.","authors":["Debajyoti Kar","Arindam Khan","Malin Rau"],"url":"https://arxiv.org/abs/2503.08863"}
{"created":"2025-04-22","title":"KNighter: Transforming Static Analysis with LLM-Synthesized Checkers","abstract":"Static analysis is a powerful technique for bug detection in critical systems like operating system kernels. However, designing and implementing static analyzers is challenging, time-consuming, and typically limited to predefined bug patterns. While large language models (LLMs) have shown promise for static analysis, directly applying them to scan large systems remains impractical due to computational constraints and contextual limitations.","authors":["Chenyuan Yang","Zijie Zhao","Zichen Xie","Haoyu Li","Lingming Zhang"],"url":"https://arxiv.org/abs/2503.09002"}
{"created":"2025-04-22","title":"ASIDE: Architectural Separation of Instructions and Data in Language Models","abstract":"Despite their remarkable performance, large language models lack elementary safety features, and this makes them susceptible to numerous malicious attacks. In particular, previous work has identified the absence of an intrinsic separation between instructions and data as a root cause for the success of prompt injection attacks. In this work, we propose a method, ASIDE, that allows the model to clearly separate between instructions and data on the level of embeddings. ASIDE applies a fixed orthogonal rotation to the embeddings of data tokens, thus creating distinct representations of instructions and data tokens without introducing any additional parameters. We demonstrate the effectiveness of our method by instruct-tuning LLMs with ASIDE and showing (1) highly increased instruction-data separation scores without a loss in model capabilities and (2) competitive results on prompt injection benchmarks, even without dedicated safety training. Additionally, we study the working mechanism behind our method through an analysis of model representations.","authors":["Egor Zverev","Evgenii Kortukov","Alexander Panfilov","Alexandra Volkova","Soroush Tabesh","Sebastian Lapuschkin","Wojciech Samek","Christoph H. Lampert"],"url":"https://arxiv.org/abs/2503.10566"}
{"created":"2025-04-22","title":"GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding","abstract":"Pixel grounding, encompassing tasks such as Referring Expression Segmentation (RES), has garnered considerable attention due to its immense potential for bridging the gap between vision and language modalities. However, advancements in this domain are currently constrained by limitations inherent in existing datasets, including limited object categories, insufficient textual diversity, and a scarcity of high-quality annotations. To mitigate these limitations, we introduce GroundingSuite, which comprises: (1) an automated data annotation framework leveraging multiple Vision-Language Model (VLM) agents; (2) a large-scale training dataset encompassing 9.56 million diverse referring expressions and their corresponding segmentations; and (3) a meticulously curated evaluation benchmark consisting of 3,800 images. The GroundingSuite training dataset facilitates substantial performance improvements, enabling models trained on it to achieve state-of-the-art results. Specifically, a cIoU of 68.9 on gRefCOCO and a gIoU of 55.3 on RefCOCOm. Moreover, the GroundingSuite annotation framework demonstrates superior efficiency compared to the current leading data annotation method, i.e., $4.5 \\times$ faster than the GLaMM.","authors":["Rui Hu","Lianghui Zhu","Yuxuan Zhang","Tianheng Cheng","Lei Liu","Heng Liu","Longjin Ran","Xiaoxin Chen","Wenyu Liu","Xinggang Wang"],"url":"https://arxiv.org/abs/2503.10596"}
{"created":"2025-04-22","title":"Semantic Wave Functions: Exploring Meaning in Large Language Models Through Quantum Formalism","abstract":"Large Language Models (LLMs) encode semantic relationships in high-dimensional vector embeddings. This paper explores the analogy between LLM embedding spaces and quantum mechanics, positing that LLMs operate within a quantized semantic space where words and phrases behave as quantum states. To capture nuanced semantic interference effects, we extend the standard real-valued embedding space to the complex domain, drawing parallels to the double-slit experiment. We introduce a \"semantic wave function\" to formalize this quantum-derived representation and utilize potential landscapes, such as the double-well potential, to model semantic ambiguity. Furthermore, we propose a complex-valued similarity measure that incorporates both magnitude and phase information, enabling a more sensitive comparison of semantic representations. We develop a path integral formalism, based on a nonlinear Schr\\\"odinger equation with a gauge field and Mexican hat potential, to model the dynamic evolution of LLM behavior. This interdisciplinary approach offers a new theoretical framework for understanding and potentially manipulating LLMs, with the goal of advancing both artificial and natural language understanding.","authors":["Timo Aukusti Laine"],"url":"https://arxiv.org/abs/2503.10664"}
{"created":"2025-04-22","title":"OCPM$^2$: Extending the Process Mining Methodology for Object-Centric Event Data Extraction","abstract":"Object-Centric Process Mining (OCPM) enables business process analysis from multiple perspectives. For example, an educational path can be examined from the viewpoints of students, teachers, and groups. This analysis depends on Object-Centric Event Data (OCED), which captures relationships between events and object types, representing different perspectives. Unlike traditional process mining techniques, extracting OCED minimizes the need for repeated log extractions when shifting the analytical focus. However, recording these complex relationships increases the complexity of the log extraction process. To address this challenge, this paper proposes a methodology for extracting OCED based on PM\\inst{2}, a well-established process mining framework. Our approach introduces a structured framework that guides data analysts and engineers in extracting OCED for process analysis. We validate this framework by applying it in a real-world educational setting, demonstrating its effectiveness in extracting an Object-Centric Event Log (OCEL), which serves as the standard format for recording OCED, from a learning management system and an administrative grading system.","authors":["Najmeh Miri","Shahrzad Khayatbashi","Jelena Zdravkovic","Amin Jalali"],"url":"https://arxiv.org/abs/2503.10735"}
{"created":"2025-04-22","title":"TLAC: Two-stage LMM Augmented CLIP for Zero-Shot Classification","abstract":"Contrastive Language-Image Pretraining (CLIP) has shown impressive zero-shot performance on image classification. However, state-of-the-art methods often rely on fine-tuning techniques like prompt learning and adapter-based tuning to optimize CLIP's performance. The necessity for fine-tuning significantly limits CLIP's adaptability to novel datasets and domains. This requirement mandates substantial time and computational resources for each new dataset. To overcome this limitation, we introduce simple yet effective training-free approaches, Single-stage LMM Augmented CLIP (SLAC) and Two-stage LMM Augmented CLIP (TLAC), that leverages powerful Large Multimodal Models (LMMs), such as Gemini, for image classification. The proposed methods leverages the capabilities of pre-trained LMMs, allowing for seamless adaptation to diverse datasets and domains without the need for additional training. Our approaches involve prompting the LMM to identify objects within an image. Subsequently, the CLIP text encoder determines the image class by identifying the dataset class with the highest semantic similarity to the LLM predicted object. Our models achieved superior accuracy on 9 of 11 base-to-novel datasets, including ImageNet, SUN397, and Caltech101, while maintaining a strictly training-free paradigm. Our TLAC model achieved an overall accuracy of 83.44%, surpassing the previous state-of-the-art few-shot methods by a margin of 6.75%. Compared to other training-free approaches, our TLAC method achieved 83.6% average accuracy across 13 datasets, a 9.7% improvement over the previous methods. Our Code is available at https://github.com/ans92/TLAC","authors":["Ans Munir","Faisal Z. Qureshi","Muhammad Haris Khan","Mohsen Ali"],"url":"https://arxiv.org/abs/2503.12206"}
{"created":"2025-04-22","title":"SynLlama: Generating Synthesizable Molecules and Their Analogs with Large Language Models","abstract":"Generative machine learning models for small molecule drug discovery have shown immense promise, but many molecules they generate are too difficult to synthesize, making them impractical for further investigation or development. In this work, we present a novel approach by fine-tuning Meta's Llama3 Large Language Models (LLMs) to create SynLlama, which generates full synthetic pathways made of commonly accessible building blocks and robust organic reaction templates. SynLlama explores a large synthesizable space using significantly less data compared to other state-of-the-art methods, and offers strong performance in bottom-up synthesis, synthesizable analog generation, and hit expansion, offering medicinal chemists a valuable tool for drug discovery developments. We find that SynLlama, even without training on external building blocks, can effectively generalize to unseen yet purchasable building blocks, meaning that its reconstruction capabilities extend to a broader synthesizable chemical space than the training data. We also demonstrate the use of SynLlama in a pharmaceutical context for synthesis planning of analog molecules and hit expansion leads for proposed inhibitors of target proteins.","authors":["Kunyang Sun","Dorian Bagni","Joseph M. Cavanagh","Yingze Wang","Jacob M. Sawyer","Andrew Gritsevskiy","Oufan Zhang","Teresa Head-Gordon"],"url":"https://arxiv.org/abs/2503.12602"}
{"created":"2025-04-22","title":"Halving transcription time: A fast, user-friendly and GDPR-compliant workflow to create AI-assisted transcripts for content analysis","abstract":"In qualitative research, data transcription is often labor-intensive and time-consuming. To expedite this process, a workflow utilizing artificial intelligence (AI) was developed. This workflow not only enhances transcription speed but also addresses the issue of AI-generated transcripts often lacking compatibility with standard content analysis software. Within this workflow, automatic speech recognition is employed to create initial transcripts from audio recordings, which are then formatted to be compatible with content analysis software such as ATLAS or MAXQDA. Empirical data from a study of 12 interviews suggests that this workflow can reduce transcription time by up to 76.4%. Furthermore, by using widely used standard software, this process is suitable for both students and researchers while also being adaptable to a variety of learning, teaching, and research environments. It is also particularly beneficial for non-native speakers. In addition, the workflow is GDPR-compliant and facilitates local, offline transcript generation, which is crucial when dealing with sensitive data.","authors":["Jakob Sponholz","Andreas Weilinghoff","Juliane Schopf"],"url":"https://arxiv.org/abs/2503.13031"}
{"created":"2025-04-22","title":"Causal Emergence 2.0: Quantifying emergent complexity","abstract":"Complex systems can be described at myriad different scales, and their causal workings often have multiscale structure (e.g., a computer can be described at the microscale of its hardware circuitry, the mesoscale of its machine code, and the macroscale of its operating system). While scientists study and model systems across the full hierarchy of their scales, from microphysics to macroeconomics, there is debate about what the macroscales of systems can possibly add beyond mere compression. To resolve this longstanding issue, here a new theory of emergence is introduced wherein the different scales of a system are treated like slices of a higher-dimensional object. The theory can distinguish which of these scales possess unique causal contributions, and which are not causally relevant. Constructed from an axiomatic notion of causation, the theory's application is demonstrated in coarse-grains of Markov chains. It identifies all cases of macroscale causation: instances where reduction to a microscale is possible, yet lossy about causation. Furthermore, the theory posits a causal apportioning schema that calculates the causal contribution of each scale, showing what each uniquely adds. Finally, it reveals a novel measure of emergent complexity: how widely distributed a system's causal workings are across its hierarchy of scales.","authors":["Erik Hoel"],"url":"https://arxiv.org/abs/2503.13395"}
{"created":"2025-04-22","title":"Concat-ID: Towards Universal Identity-Preserving Video Synthesis","abstract":"We present Concat-ID, a unified framework for identity-preserving video generation. Concat-ID employs Variational Autoencoders to extract image features, which are concatenated with video latents along the sequence dimension, leveraging solely 3D self-attention mechanisms without the need for additional modules. A novel cross-video pairing strategy and a multi-stage training regimen are introduced to balance identity consistency and facial editability while enhancing video naturalness. Extensive experiments demonstrate Concat-ID's superiority over existing methods in both single and multi-identity generation, as well as its seamless scalability to multi-subject scenarios, including virtual try-on and background-controllable generation. Concat-ID establishes a new benchmark for identity-preserving video synthesis, providing a versatile and scalable solution for a wide range of applications.","authors":["Yong Zhong","Zhuoyi Yang","Jiayan Teng","Xiaotao Gu","Chongxuan Li"],"url":"https://arxiv.org/abs/2503.14151"}
{"created":"2025-04-22","title":"Prompt Flow Integrity to Prevent Privilege Escalation in LLM Agents","abstract":"Large Language Models (LLMs) are combined with tools to create powerful LLM agents that provide a wide range of services. Unlike traditional software, LLM agent's behavior is determined at runtime by natural language prompts from either user or tool's data. This flexibility enables a new computing paradigm with unlimited capabilities and programmability, but also introduces new security risks, vulnerable to privilege escalation attacks. Moreover, user prompts are prone to be interpreted in an insecure way by LLM agents, creating non-deterministic behaviors that can be exploited by attackers. To address these security risks, we propose Prompt Flow Integrity (PFI), a system security-oriented solution to prevent privilege escalation in LLM agents. Analyzing the architectural characteristics of LLM agents, PFI features three mitigation techniques -- i.e., agent isolation, secure untrusted data processing, and privilege escalation guardrails. Our evaluation result shows that PFI effectively mitigates privilege escalation attacks while successfully preserving the utility of LLM agents.","authors":["Juhee Kim","Woohyuk Choi","Byoungyoung Lee"],"url":"https://arxiv.org/abs/2503.15547"}
{"created":"2025-04-22","title":"A Unified Framework for Quantitative Cache Analysis","abstract":"In this work we unify two existing lines of work towards cache analysis for non-LRU policies. To this end, we extend the notion of competitiveness to block competitiveness and systematically analyze the competitiveness and block competitiveness of FIFO and MRU relative to LRU for arbitrary associativities. We show how competitiveness and block competitiveness can be exploited in state-of-the-art WCET analysis based on the results of existing persistence analyses for LRU. Unlike prior work, our approach is applicable to microarchitectures that exhibit timing anomalies. We experimentally evaluate the precision and cost of our approach on benchmarks from TACLeBench. The experiments demonstrate that quantitative cache analysis for FIFO and MRU comes close to the precision of LRU.","authors":["Sophie Kahlen","Jan Reineke"],"url":"https://arxiv.org/abs/2503.16588"}
{"created":"2025-04-22","title":"\"The Diagram is like Guardrails\": Structuring GenAI-assisted Hypotheses Exploration with an Interactive Shared Representation","abstract":"Data analysis encompasses a spectrum of tasks, from high-level conceptual reasoning to lower-level execution. While AI-powered tools increasingly support execution tasks, there remains a need for intelligent assistance in conceptual tasks. This paper investigates the design of an ordered node-link tree interface augmented with AI-generated information hints and visualizations, as a potential shared representation for hypothesis exploration. Through a design probe (n=22), participants generated diagrams averaging 21.82 hypotheses. Our findings showed that the node-link diagram acts as \"guardrails\" for hypothesis exploration, facilitating structured workflows, providing comprehensive overviews, and enabling efficient backtracking. The AI-generated information hints, particularly visualizations, aided users in transforming abstract ideas into data-backed concepts while reducing cognitive load. We further discuss how node-link diagrams can support both parallel exploration and iterative refinement in hypothesis formulation, potentially enhancing the breadth and depth of human-AI collaborative data analysis.","authors":["Zijian Ding","Michelle Brachman","Joel Chan","Werner Geyer"],"url":"https://arxiv.org/abs/2503.16791"}
{"created":"2025-04-22","title":"PH2ST:ST-Prompt Guided Histological Hypergraph Learning for Spatial Gene Expression Prediction","abstract":"Spatial Transcriptomics (ST) reveals the spatial distribution of gene expression in tissues, offering critical insights into biological processes and disease mechanisms. However, the high cost, limited coverage, and technical complexity of current ST technologies restrict their widespread use in clinical and research settings, making obtaining high-resolution transcriptomic profiles across large tissue areas challenging. Predicting ST from H\\&amp;E-stained histology images has emerged as a promising alternative to address these limitations but remains challenging due to the heterogeneous relationship between histomorphology and gene expression, which is affected by substantial variability across patients and tissue sections. In response, we propose PH2ST, a prompt-guided hypergraph learning framework, which leverages limited ST signals to guide multi-scale histological representation learning for accurate and robust spatial gene expression prediction. Extensive evaluations on two public ST datasets and multiple prompt sampling strategies simulating real-world scenarios demonstrate that PH2ST not only outperforms existing state-of-the-art methods, but also shows strong potential for practical applications such as imputing missing spots, ST super-resolution, and local-to-global prediction, highlighting its value for scalable and cost-effective spatial gene expression mapping in biomedical contexts.","authors":["Yi Niu","Jiashuai Liu","Yingkang Zhan","Jiangbo Shi","Di Zhang","Marika Reinius","Ines Machado","Mireia Crispin-Ortuzar","Jialun Wu","Chen Li","Zeyu Gao"],"url":"https://arxiv.org/abs/2503.16816"}
{"created":"2025-04-22","title":"A Language Anchor-Guided Method for Robust Noisy Domain Generalization","abstract":"Real-world machine learning applications often struggle with two major challenges: distribution shift and label noise. Models tend to overfit by focusing on redundant and uninformative features in the training data, which makes it hard for them to generalize to the target domain. Noisy data worsens this problem by causing further overfitting to the noise, meaning that existing methods often fail to tell the difference between true, invariant features and misleading, spurious ones. To tackle these issues, we introduce Anchor Alignment and Adaptive Weighting (A3W). This new algorithm uses sample reweighting guided by natural language processing (NLP) anchors to extract more representative features. In simple terms, A3W leverages semantic representations from natural language models as a source of domain-invariant prior knowledge. Additionally, it employs a weighted loss function that adjusts each sample's contribution based on its similarity to the corresponding NLP anchor. This adjustment makes the model more robust to noisy labels. Extensive experiments on standard benchmark datasets show that A3W consistently outperforms state-of-the-art domain generalization methods, offering significant improvements in both accuracy and robustness across different datasets and noise levels.","authors":["Zilin Dai","Lehong Wang","Fangzhou Lin","Yidong Wang","Zhigang Li","Kazunori D Yamada","Ziming Zhang","Wang Lu"],"url":"https://arxiv.org/abs/2503.17211"}
{"created":"2025-04-22","title":"AIJIM: A Scalable Model for Real-Time AI in Environmental Journalism","abstract":"Environmental journalism is vital for raising awareness of ecological crises and supporting evidence-based policy, yet traditional methods suffer from delays, limited scalability, and lack of coverage in under-monitored regions. This paper introduces the Artificial Intelligence Journalism Integration Model (AIJIM), a conceptual and transferable theoretical model that structures real-time, AI-supported environmental journalism workflows. AIJIM combines citizen-sourced image data, automated hazard detection, dual-level validation (visual and textual), and AI-generated reporting. Validated through a pilot study in Mallorca, AIJIM achieved significant improvements in reporting speed and accuracy, while maintaining transparency and ethical oversight through Explainable AI (XAI), GDPR compliance, and community review. The model demonstrates high transferability and offers a new benchmark for scalable, responsible, and participatory journalism at the intersection of environmental communication and artificial intelligence.","authors":["Torsten Tiltack"],"url":"https://arxiv.org/abs/2503.17401"}
{"created":"2025-04-22","title":"A Predictive Services Architecture for Efficient Airspace Operations","abstract":"Predicting air traffic congestion and flow management is essential for airlines and Air Navigation Service Providers (ANSP) to enhance operational efficiency. Accurate estimates of future airport capacity and airspace density are vital for better airspace management, reducing air traffic controller workload and fuel consumption, ultimately promoting sustainable aviation. While existing literature has addressed these challenges, data management and query processing remain complex due to the vast volume of high-rate air traffic data. Many analytics use cases require a common pre-processing infrastructure, as ad-hoc approaches are insufficient. Additionally, linear prediction models often fall short, necessitating more advanced techniques.","authors":["\\'Italo Romani de Oliveira","Samet Ayhan","Glaucia Balvedi","Michael Biglin","Pablo Costas","Euclides C. Pinto Neto","Alexandre Leite","Felipe C. F. de Azevedo"],"url":"https://arxiv.org/abs/2503.17515"}
{"created":"2025-04-22","title":"Reason2Attack: Jailbreaking Text-to-Image Models via LLM Reasoning","abstract":"Text-to-Image(T2I) models typically deploy safety filters to prevent the generation of sensitive images. Unfortunately, recent jailbreaking attack methods manually design prompts for the LLM to generate adversarial prompts, which effectively bypass safety filters while producing sensitive images, exposing safety vulnerabilities of T2I models. However, due to the LLM's limited understanding of the T2I model and its safety filters, existing methods require numerous queries to achieve a successful attack, limiting their practical applicability. To address this issue, we propose Reason2Attack(R2A), which aims to enhance the LLM's reasoning capabilities in generating adversarial prompts by incorporating the jailbreaking attack into the post-training process of the LLM. Specifically, we first propose a CoT example synthesis pipeline based on Frame Semantics, which generates adversarial prompts by identifying related terms and corresponding context illustrations. Using CoT examples generated by the pipeline, we fine-tune the LLM to understand the reasoning path and format the output structure. Subsequently, we incorporate the jailbreaking attack task into the reinforcement learning process of the LLM and design an attack process reward that considers prompt length, prompt stealthiness, and prompt effectiveness, aiming to further enhance reasoning accuracy. Extensive experiments on various T2I models show that R2A achieves a better attack success ratio while requiring fewer queries than baselines. Moreover, our adversarial prompts demonstrate strong attack transferability across both open-source and commercial T2I models.","authors":["Chenyu Zhang","Lanjun Wang","Yiwen Ma","Wenhui Li","An-An Liu"],"url":"https://arxiv.org/abs/2503.17987"}
{"created":"2025-04-22","title":"Flow to Learn: Flow Matching on Neural Network Parameters","abstract":"Foundational language models show a remarkable ability to learn new concepts during inference via context data. However, similar work for images lag behind. To address this challenge, we introduce FLoWN, a flow matching model that learns to generate neural network parameters for different tasks. Our approach models the flow on latent space, while conditioning the process on context data. Experiments verify that FLoWN attains various desiderata for a meta-learning model. In addition, it matches or exceeds baselines on in-distribution tasks, provides better initializations for classifier training, and is performant on out-of-distribution few-shot tasks while having a fine-tuning mechanism to improve performance.","authors":["Daniel Saragih","Deyu Cao","Tejas Balaji","Ashwin Santhosh"],"url":"https://arxiv.org/abs/2503.19371"}
{"created":"2025-04-22","title":"ICE: Intrinsic Concept Extraction from a Single Image via Diffusion Models","abstract":"The inherent ambiguity in defining visual concepts poses significant challenges for modern generative models, such as the diffusion-based Text-to-Image (T2I) models, in accurately learning concepts from a single image. Existing methods lack a systematic way to reliably extract the interpretable underlying intrinsic concepts. To address this challenge, we present ICE, short for Intrinsic Concept Extraction, a novel framework that exclusively utilises a T2I model to automatically and systematically extract intrinsic concepts from a single image. ICE consists of two pivotal stages. In the first stage, ICE devises an automatic concept localization module to pinpoint relevant text-based concepts and their corresponding masks within the image. This critical stage streamlines concept initialization and provides precise guidance for subsequent analysis. The second stage delves deeper into each identified mask, decomposing the object-level concepts into intrinsic concepts and general concepts. This decomposition allows for a more granular and interpretable breakdown of visual elements. Our framework demonstrates superior performance on intrinsic concept extraction from a single image in an unsupervised manner. Project page: https://visual-ai.github.io/ice","authors":["Fernando Julio Cendra","Kai Han"],"url":"https://arxiv.org/abs/2503.19902"}
{"created":"2025-04-22","title":"Wan: Open and Advanced Large-Scale Video Generative Models","abstract":"This report presents Wan, a comprehensive and open suite of video foundation models designed to push the boundaries of video generation. Built upon the mainstream diffusion transformer paradigm, Wan achieves significant advancements in generative capabilities through a series of innovations, including our novel VAE, scalable pre-training strategies, large-scale data curation, and automated evaluation metrics. These contributions collectively enhance the model's performance and versatility. Specifically, Wan is characterized by four key features: Leading Performance: The 14B model of Wan, trained on a vast dataset comprising billions of images and videos, demonstrates the scaling laws of video generation with respect to both data and model size. It consistently outperforms the existing open-source models as well as state-of-the-art commercial solutions across multiple internal and external benchmarks, demonstrating a clear and significant performance superiority. Comprehensiveness: Wan offers two capable models, i.e., 1.3B and 14B parameters, for efficiency and effectiveness respectively. It also covers multiple downstream applications, including image-to-video, instruction-guided video editing, and personal video generation, encompassing up to eight tasks. Consumer-Grade Efficiency: The 1.3B model demonstrates exceptional resource efficiency, requiring only 8.19 GB VRAM, making it compatible with a wide range of consumer-grade GPUs. Openness: We open-source the entire series of Wan, including source code and all models, with the goal of fostering the growth of the video generation community. This openness seeks to significantly expand the creative possibilities of video production in the industry and provide academia with high-quality video foundation models. All the code and models are available at https://github.com/Wan-Video/Wan2.1.","authors":["Team Wan","Ang Wang","Baole Ai","Bin Wen","Chaojie Mao","Chen-Wei Xie","Di Chen","Feiwu Yu","Haiming Zhao","Jianxiao Yang","Jianyuan Zeng","Jiayu Wang","Jingfeng Zhang","Jingren Zhou","Jinkai Wang","Jixuan Chen","Kai Zhu","Kang Zhao","Keyu Yan","Lianghua Huang","Mengyang Feng","Ningyi Zhang","Pandeng Li","Pingyu Wu","Ruihang Chu","Ruili Feng","Shiwei Zhang","Siyang Sun","Tao Fang","Tianxing Wang","Tianyi Gui","Tingyu Weng","Tong Shen","Wei Lin","Wei Wang","Wei Wang","Wenmeng Zhou","Wente Wang","Wenting Shen","Wenyuan Yu","Xianzhong Shi","Xiaoming Huang","Xin Xu","Yan Kou","Yangyu Lv","Yifei Li","Yijing Liu","Yiming Wang","Yingya Zhang","Yitong Huang","Yong Li","You Wu","Yu Liu","Yulin Pan","Yun Zheng","Yuntao Hong","Yupeng Shi","Yutong Feng","Zeyinzi Jiang","Zhen Han","Zhi-Fan Wu","Ziyu Liu"],"url":"https://arxiv.org/abs/2503.20314"}
{"created":"2025-04-22","title":"MAR-3D: Progressive Masked Auto-regressor for High-Resolution 3D Generation","abstract":"Recent advances in auto-regressive transformers have revolutionized generative modeling across different domains, from language processing to visual generation, demonstrating remarkable capabilities. However, applying these advances to 3D generation presents three key challenges: the unordered nature of 3D data conflicts with sequential next-token prediction paradigm, conventional vector quantization approaches incur substantial compression loss when applied to 3D meshes, and the lack of efficient scaling strategies for higher resolution latent prediction. To address these challenges, we introduce MAR-3D, which integrates a pyramid variational autoencoder with a cascaded masked auto-regressive transformer (Cascaded MAR) for progressive latent upscaling in the continuous space. Our architecture employs random masking during training and auto-regressive denoising in random order during inference, naturally accommodating the unordered property of 3D latent tokens. Additionally, we propose a cascaded training strategy with condition augmentation that enables efficiently up-scale the latent token resolution with fast convergence. Extensive experiments demonstrate that MAR-3D not only achieves superior performance and generalization capabilities compared to existing methods but also exhibits enhanced scaling capabilities compared to joint distribution modeling approaches (e.g., diffusion transformers).","authors":["Jinnan Chen","Lingting Zhu","Zeyu Hu","Shengju Qian","Yugang Chen","Xin Wang","Gim Hee Lee"],"url":"https://arxiv.org/abs/2503.20519"}
{"created":"2025-04-22","title":"LLM Agents That Act Like Us: Accurate Human Behavior Simulation with Real-World Data","abstract":"Recent research shows that LLMs can simulate ``believable'' human behaviors to power LLM agents via prompt-only methods. In this work, we focus on evaluating and improving LLM's objective ``accuracy'' rather than the subjective ``believability'' in the web action generation task, leveraging a large-scale, real-world dataset collected from online shopping human actions. We present the first comprehensive quantitative evaluation of state-of-the-art LLMs (e.g., DeepSeek-R1, Llama, and Claude) on the task of web action generation. Our results show that fine-tuning LLMs on real-world behavioral data substantially improves their ability to generate actions compared to prompt-only methods. Furthermore, incorporating synthesized reasoning traces into model training leads to additional performance gains, demonstrating the value of explicit rationale in behavior modeling. This work establishes a new benchmark for evaluating LLMs in behavior simulation and offers actionable insights into how real-world action data and reasoning augmentation can enhance the fidelity of LLM agents.","authors":["Yuxuan Lu","Jing Huang","Yan Han","Bennet Bei","Yaochen Xie","Dakuo Wang","Jessie Wang","Qi He"],"url":"https://arxiv.org/abs/2503.20749"}
{"created":"2025-04-22","title":"Rerouting Connection: Hybrid Computer Vision Analysis Reveals Visual Similarity Between Indus and Tibetan-Yi Corridor Writing Systems","abstract":"This thesis employs a hybrid CNN-Transformer architecture, alongside a detailed anthropological framework, to investigate potential historical connections between the visual morphology of the Indus Valley script and pictographic systems of the Tibetan-Yi Corridor. Through an ensemble methodology of three target scripts across 15 independently trained models, we demonstrate that Tibetan-Yi Corridor scripts exhibit approximately six-fold higher visual similarity to the Indus script (0.635) than to the Bronze Age Proto-Cuneiform (0.102) or Proto-Elamite (0.078).","authors":["Ooha Lakkadi Reddy"],"url":"https://arxiv.org/abs/2503.21074"}
{"created":"2025-04-22","title":"ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging","abstract":"This paper presents the ZJUKLAB team's submission for SemEval-2025 Task 4: Unlearning Sensitive Content from Large Language Models. This task aims to selectively erase sensitive knowledge from large language models, avoiding both over-forgetting and under-forgetting issues. We propose an unlearning system that leverages Model Merging (specifically TIES-Merging), combining two specialized models into a more balanced unlearned model. Our system achieves competitive results, ranking second among 26 teams, with an online score of 0.944 for Task Aggregate and 0.487 for overall Aggregate. In this paper, we also conduct local experiments and perform a comprehensive analysis of the unlearning process, examining performance trajectories, loss dynamics, and weight perspectives, along with several supplementary experiments, to understand the effectiveness of our method. Furthermore, we analyze the shortcomings of our method and evaluation metrics, emphasizing that MIA scores and ROUGE-based metrics alone are insufficient to fully evaluate successful unlearning. Finally, we emphasize the need for more comprehensive evaluation methodologies and rethinking of unlearning objectives in future research. Code is available at https://github.com/zjunlp/unlearn/tree/main/semeval25.","authors":["Haoming Xu","Shuxun Wang","Yanqiu Zhao","Yi Zhong","Ziyan Jiang","Ningyuan Zhao","Shumin Deng","Huajun Chen","Ningyu Zhang"],"url":"https://arxiv.org/abs/2503.21088"}
{"created":"2025-04-22","title":"A Computational Theory for Efficient Model Evaluation with Causal Guarantees","abstract":"In order to reduce the cost of experimental evaluation for models, we introduce a computational theory of evaluation for prediction and decision models: build evaluation model to accelerate the evaluation procedures. We prove upper bounds of generalized error and generalized causal effect error of given evaluation models. We also prove efficiency, and consistency to estimated causal effect from deployed subject to evaluation metric by prediction. To learn evaluation models, we propose a meta-learner to handle heterogeneous evaluation subjects space problem. Comparing with existed evaluation approaches, our (conditional) evaluation model reduced 24.1\\%-99.0\\% evaluation errors across 12 scenes, including individual medicine, scientific simulation, social experiment, business activity, and quantum trade. The evaluation time is reduced 3-7 order of magnitude comparing with experiments or simulations.","authors":["Hedong Yan"],"url":"https://arxiv.org/abs/2503.21138"}
{"created":"2025-04-22","title":"Moving Beyond Parental Control toward Community-based Approaches to Adolescent Online Safety","abstract":"In this position paper, we discuss the paradigm shift that moves away from parental mediation approaches toward collaborative approaches to promote adolescents' online safety. We present empirical studies that highlight the limitations of traditional parental control models and advocate for collaborative, community-driven solutions that prioritize teen empowerment. Specifically, we explore how extending oversight beyond the immediate family to include trusted community members can provide crucial support for teens in managing their online lives. We discuss the potential benefits and challenges of this expanded approach, emphasizing the importance of granular privacy controls and reciprocal support within these networks. Finally, we pose open questions for the research community to consider during the workshop, focusing on the design of \"teen-centered\" online safety solutions that foster autonomy, awareness, and self-regulation.","authors":["Mamtaj Akter","Jinkyung Katie Park","Pamela J. Wisniewski"],"url":"https://arxiv.org/abs/2503.22995"}
{"created":"2025-04-22","title":"SCORE: Story Coherence and Retrieval Enhancement for AI Narratives","abstract":"Large Language Models (LLMs) can generate creative and engaging narratives from user-specified input, but maintaining coherence and emotional depth throughout these AI-generated stories remains a challenge. In this work, we propose SCORE, a framework for Story Coherence and Retrieval Enhancement, designed to detect and resolve narrative inconsistencies. By tracking key item statuses and generating episode summaries, SCORE uses a Retrieval-Augmented Generation (RAG) approach, incorporating TF-IDF and cosine similarity to identify related episodes and enhance the overall story structure. Results from testing multiple LLM-generated stories demonstrate that SCORE significantly improves the consistency and stability of narrative coherence compared to baseline GPT models, providing a more robust method for evaluating and refining AI-generated narratives.","authors":["Qiang Yi","Yangfan He","Jianhui Wang","Xinyuan Song","Shiyao Qian","Xinhang Yuan","Miao Zhang","Li Sun","Keqin Li","Kuan Lu","Menghao Huo","Jiaqi Chen","Tianyu Shi"],"url":"https://arxiv.org/abs/2503.23512"}
{"created":"2025-04-22","title":"My CXL Pool Obviates Your PCIe Switch","abstract":"Pooling PCIe devices across multiple hosts offers a promising solution to mitigate stranded I/O resources, enhance device utilization, address device failures, and reduce total cost of ownership. The only viable option today are PCIe switches, which decouple PCIe devices from hosts by connecting them through a hardware switch. However, the high cost and limited flexibility of PCIe switches hinder their widespread adoption beyond specialized datacenter use cases.","authors":["Yuhong Zhong","Daniel S. Berger","Pantea Zardoshti","Enrique Saurez","Jacob Nelson","Antonis Psistakis","Joshua Fried","Asaf Cidon"],"url":"https://arxiv.org/abs/2503.23611"}
{"created":"2025-04-22","title":"STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?","abstract":"The use of Multimodal Large Language Models (MLLMs) as an end-to-end solution for Embodied AI and Autonomous Driving has become a prevailing trend. While MLLMs have been extensively studied for visual semantic understanding tasks, their ability to perform precise and quantitative spatial-temporal understanding in real-world applications remains largely unexamined, leading to uncertain prospects. To evaluate models' Spatial-Temporal Intelligence, we introduce STI-Bench, a benchmark designed to evaluate MLLMs' spatial-temporal understanding through challenging tasks such as estimating and predicting the appearance, pose, displacement, and motion of objects. Our benchmark encompasses a wide range of robot and vehicle operations across desktop, indoor, and outdoor scenarios. The extensive experiments reveals that the state-of-the-art MLLMs still struggle in real-world spatial-temporal understanding, especially in tasks requiring precise distance estimation and motion analysis.","authors":["Yun Li","Yiming Zhang","Tao Lin","XiangRui Liu","Wenxiao Cai","Zheng Liu","Bo Zhao"],"url":"https://arxiv.org/abs/2503.23765"}
{"created":"2025-04-22","title":"Communication-Efficient and Personalized Federated Foundation Model Fine-Tuning via Tri-Matrix Adaptation","abstract":"In federated learning, fine-tuning pre-trained foundation models poses significant challenges, particularly regarding high communication cost and suboptimal model performance due to data heterogeneity between the clients. To address these issues, this paper introduces communication-efficient federated LoRA adaption (CE-LoRA), a method that employs a tri-factorization low-rank adaptation approach with personalized model parameter aggregation. We first presents a novel LoRA parameter factorization by introducing a small-size dense matrix, which can significantly reduce the communication cost and achieve comparable empirical performance than transferring the low-rank parameter matrix used by existing methods. Without violating data privacy, the server considers the client similarity in both training dataset and model parameter space, and learns personalized weights for model aggregation. Our experiments on various LLM and VLM fine-tuning tasks demonstrate that CE-LoRA not only significantly reduces communication overhead but also improves performance under not independently and identically distributed data conditions. In addition, CE-LoRA improves data privacy protection, effectively mitigating gradient-based data reconstruction attacks.","authors":["Yongle Li","Bo Liu","Sheng Huang","ZHeng ZHang","Xiaotong Yuan","Richang Hong"],"url":"https://arxiv.org/abs/2503.23869"}
{"created":"2025-04-22","title":"Lorentzian Graph Isomorphic Network","abstract":"We introduce the Lorentzian Graph Isomorphic Network (LGIN), a novel graph neural network (GNN) designed to operate in hyperbolic spaces, leveraging the Lorentzian model to enhance graph representation learning. Existing GNNs primarily operate in Euclidean spaces, which can limit their ability to capture hierarchical and multi-relational structures inherent to complex graphs. LGIN addresses this by incorporating curvature-aware aggregation functions that preserve the Lorentzian metric tensor, ensuring embeddings remain constrained within the hyperbolic space by proposing a new update rule that effectively captures both local neighborhood interactions and global structural properties, enabling LGIN to distinguish non-isomorphic graphs with expressiveness at least as powerful as the Weisfeiler-Lehman test. Through extensive evaluation across nine benchmark datasets, including molecular and protein structures, LGIN consistently outperforms or matches state-of-the-art GNNs, demonstrating its robustness and efficacy in modeling complex graph structures. To the best of our knowledge, this is the first study to extend the concept of a powerful graph neural network to Riemannian manifolds, paving the way for future advancements in hyperbolic graph learning. The code for our paper can be found at https://github.com/Deceptrax123/LGIN.","authors":["Srinitish Srinivasan","Omkumar CU"],"url":"https://arxiv.org/abs/2504.00142"}
{"created":"2025-04-22","title":"Control Barrier Functions via Minkowski Operations for Safe Navigation among Polytopic Sets","abstract":"Safely navigating around obstacles while respecting the dynamics, control, and geometry of the underlying system is a key challenge in robotics. Control Barrier Functions (CBFs) generate safe control policies by considering system dynamics and geometry when calculating safe forward-invariant sets. Existing CBF-based methods often rely on conservative shape approximations, like spheres or ellipsoids, which have explicit and differentiable distance functions. In this paper, we propose an optimization-defined CBF that directly considers the exact Signed Distance Function (SDF) between a polytopic robot and polytopic obstacles. Inspired by the Gilbert-Johnson-Keerthi (GJK) algorithm, we formulate both (i) minimum distance and (ii) penetration depth between polytopic sets as convex optimization problems in the space of Minkowski difference operations (the MD-space). Convenient geometric properties of the MD-space enable the derivatives of implicit SDF between two polytopes to be computed via differentiable optimization. We demonstrate the proposed framework in three scenarios including pure translation, initialization inside an unsafe set, and multi-obstacle avoidance. These three scenarios highlight the generation of a non-conservative maneuver, a recovery after starting in collision, and the consideration of multiple obstacles via pairwise CBF constraint, respectively.","authors":["Yi-Hsuan Chen","Shuo Liu","Wei Xiao","Calin Belta","Michael Otte"],"url":"https://arxiv.org/abs/2504.00364"}
{"created":"2025-04-22","title":"Scene4U: Hierarchical Layered 3D Scene Reconstruction from Single Panoramic Image for Your Immerse Exploration","abstract":"The reconstruction of immersive and realistic 3D scenes holds significant practical importance in various fields of computer vision and computer graphics. Typically, immersive and realistic scenes should be free from obstructions by dynamic objects, maintain global texture consistency, and allow for unrestricted exploration. The current mainstream methods for image-driven scene construction involves iteratively refining the initial image using a moving virtual camera to generate the scene. However, previous methods struggle with visual discontinuities due to global texture inconsistencies under varying camera poses, and they frequently exhibit scene voids caused by foreground-background occlusions. To this end, we propose a novel layered 3D scene reconstruction framework from panoramic image, named Scene4U. Specifically, Scene4U integrates an open-vocabulary segmentation model with a large language model to decompose a real panorama into multiple layers. Then, we employs a layered repair module based on diffusion model to restore occluded regions using visual cues and depth information, generating a hierarchical representation of the scene. The multi-layer panorama is then initialized as a 3D Gaussian Splatting representation, followed by layered optimization, which ultimately produces an immersive 3D scene with semantic and structural consistency that supports free exploration. Scene4U outperforms state-of-the-art method, improving by 24.24% in LPIPS and 24.40% in BRISQUE, while also achieving the fastest training speed. Additionally, to demonstrate the robustness of Scene4U and allow users to experience immersive scenes from various landmarks, we build WorldVista3D dataset for 3D scene reconstruction, which contains panoramic images of globally renowned sites. The implementation code and dataset will be released at https://github.com/LongHZ140516/Scene4U .","authors":["Zilong Huang","Jun He","Junyan Ye","Lihan Jiang","Weijia Li","Yiping Chen","Ting Han"],"url":"https://arxiv.org/abs/2504.00387"}
{"created":"2025-04-22","title":"ToReMi: Topic-Aware Data Reweighting for Dynamic Pre-Training Data Selection","abstract":"Pre-training large language models (LLMs) necessitates enormous diverse textual corpora, making effective data selection a key challenge for balancing computational resources and model performance. Current methodologies primarily emphasize data quality metrics and mixing proportions, yet they fail to adequately capture the underlying semantic connections between training samples and quality disparities within individual domains. We introduce ToReMi (Topic-based Reweighting for Model improvement), a novel two-stage framework that dynamically adjusts training sample weights according to their topical associations and observed learning patterns. Our comprehensive experiments reveal that ToReMi variants consistently achieve superior performance over conventional pre-training approaches, demonstrating accelerated perplexity reduction across multiple domains and enhanced capabilities on downstream evaluation tasks. Code is available at https://github.com/zxx000728/ToReMi.","authors":["Xiaoxuan Zhu","Zhouhong Gu","Baiqian Wu","Suhang Zheng","Tao Wang","Tianyu Li","Hongwei Feng","Yanghua Xiao"],"url":"https://arxiv.org/abs/2504.00695"}
{"created":"2025-04-22","title":"Detection of Disease on Nasal Breath Sound by New Lightweight Architecture: Using COVID-19 as An Example","abstract":"Background. Infectious diseases, particularly COVID-19, continue to be a significant global health issue. Although many countries have reduced or stopped large-scale testing measures, the detection of such diseases remains a propriety. Objective. This study aims to develop a novel, lightweight deep neural network for efficient, accurate, and cost-effective detection of COVID-19 using a nasal breathing audio data collected via smartphones. Methodology. Nasal breathing audio from 128 patients diagnosed with the Omicron variant was collected. Mel-Frequency Cepstral Coefficients (MFCCs), a widely used feature in speech and sound analysis, were employed for extracting important characteristics from the audio signals. Additional feature selection was performed using Random Forest (RF) and Principal Component Analysis (PCA) for dimensionality reduction. A Dense-ReLU-Dropout model was trained with K-fold cross-validation (K=3), and performance metrics like accuracy, precision, recall, and F1-score were used to evaluate the model. Results. The proposed model achieved 97% accuracy in detecting COVID-19 from nasal breathing sounds, outperforming state-of-the-art methods such as those by [23] and [13]. Our Dense-ReLU-Dropout model, using RF and PCA for feature selection, achieves high accuracy with greater computational efficiency compared to existing methods that require more complex models or larger datasets. Conclusion. The findings suggest that the proposed method holds significant potential for clinical implementation, advancing smartphone-based diagnostics in infectious diseases. The Dense-ReLU-Dropout model, combined with innovative feature processing techniques, offers a promising approach for efficient and accurate COVID-19 detection, showcasing the capabilities of mobile device-based diagnostics","authors":["Jiayuan She","Lin Shi","Peiqi Li","Ziling Dong","Renxing Li","Shengkai Li","Liping Gu","Zhao Tong","Zhuochang Yang","Yajie Ji","Liang Feng","Jiangang Chen"],"url":"https://arxiv.org/abs/2504.00730"}
{"created":"2025-04-22","title":"A Survey on Music Generation from Single-Modal, Cross-Modal, and Multi-Modal Perspectives","abstract":"Multi-modal music generation, using multiple modalities like text, images, and video alongside musical scores and audio as guidance, is an emerging research area with broad applications. This paper reviews this field, categorizing music generation systems from the perspective of modalities. The review covers modality representation, multi-modal data alignment, and their utilization to guide music generation. Current datasets and evaluation methods are also discussed. Key challenges in this area include effective multi-modal integration, large-scale comprehensive datasets, and systematic evaluation methods. Finally, an outlook on future research directions is provided, focusing on creativity, efficiency, multi-modal alignment, and evaluation.","authors":["Shuyu Li","Shulei Ji","Zihao Wang","Songruoyao Wu","Jiaxing Yu","Kejun Zhang"],"url":"https://arxiv.org/abs/2504.00837"}
{"created":"2025-04-22","title":"Explorable INR: An Implicit Neural Representation for Ensemble Simulation Enabling Efficient Spatial and Parameter Exploration","abstract":"With the growing computational power available for high-resolution ensemble simulations in scientific fields such as cosmology and oceanology, storage and computational demands present significant challenges. Current surrogate models fall short in the flexibility of point- or region-based predictions as the entire field reconstruction is required for each parameter setting, hence hindering the efficiency of parameter space exploration. Limitations exist in capturing physical attribute distributions and pinpointing optimal parameter configurations. In this work, we propose Explorable INR, a novel implicit neural representation-based surrogate model, designed to facilitate exploration and allow point-based spatial queries without computing full-scale field data. In addition, to further address computational bottlenecks of spatial exploration, we utilize probabilistic affine forms (PAFs) for uncertainty propagation through Explorable INR to obtain statistical summaries, facilitating various ensemble analysis and visualization tasks that are expensive with existing models. Furthermore, we reformulate the parameter exploration problem as optimization tasks using gradient descent and KL divergence minimization that ensures scalability. We demonstrate that the Explorable INR with the proposed approach for spatial and parameter exploration can significantly reduce computation and memory costs while providing effective ensemble analysis.","authors":["Yi-Tang Chen","Haoyu Li","Neng Shi","Xihaier Luo","Wei Xu","Han-Wei Shen"],"url":"https://arxiv.org/abs/2504.00904"}
{"created":"2025-04-22","title":"Enabling Efficient Processing of Spiking Neural Networks with On-Chip Learning on Commodity Neuromorphic Processors for Edge AI Systems","abstract":"The rising demand for energy-efficient edge AI systems (e.g., mobile agents/robots) has increased the interest in neuromorphic computing, since it offers ultra-low power/energy AI computation through spiking neural network (SNN) algorithms on neuromorphic processors. However, their efficient implementation strategy has not been comprehensively studied, hence limiting SNN deployments for edge AI systems. Toward this, we propose a design methodology to enable efficient SNN processing on commodity neuromorphic processors. To do this, we first study the key characteristics of targeted neuromorphic hardware (e.g., memory and compute budgets), and leverage this information to perform compatibility analysis for network selection. Afterward, we employ a mapping strategy for efficient SNN implementation on the targeted processor. Furthermore, we incorporate an efficient on-chip learning mechanism to update the systems' knowledge for adapting to new input classes and dynamic environments. The experimental results show that the proposed methodology leads the system to achieve low latency of inference (i.e., less than 50ms for image classification, less than 200ms for real-time object detection in video streaming, and less than 1ms in keyword recognition) and low latency of on-chip learning (i.e., less than 2ms for keyword recognition), while incurring less than 250mW of processing power and less than 15mJ of energy consumption across the respective different applications and scenarios. These results show the potential of the proposed methodology in enabling efficient edge AI systems for diverse application use-cases.","authors":["Rachmad Vidya Wicaksana Putra","Pasindu Wickramasinghe","Muhammad Shafique"],"url":"https://arxiv.org/abs/2504.00957"}
{"created":"2025-04-22","title":"Advancing MoE Efficiency: A Collaboration-Constrained Routing (C2R) Strategy for Better Expert Parallelism Design","abstract":"Mixture-of-Experts (MoE) has successfully scaled up models while maintaining nearly constant computing costs. By employing a gating network to route input tokens, it selectively activates a subset of expert networks to process the corresponding token embeddings. However, in practice, the efficiency of MoE is challenging to achieve due to two key reasons: imbalanced expert activation, which leads to substantial idle time during model or expert parallelism, and insufficient capacity utilization; massive communication overhead, induced by numerous expert routing combinations in expert parallelism at the system level. Previous works typically formulate it as the load imbalance issue characterized by the gating network favoring certain experts over others or attribute it to static execution which fails to adapt to the dynamic expert workload at runtime. In this paper, we exploit it from a brand new perspective, a higher-order view and analysis of MoE routing policies: expert collaboration and specialization where some experts tend to activate broadly with others (collaborative), while others are more likely to activate only with a specific subset of experts (specialized). Our experiments reveal that most experts tend to be overly collaborative, leading to increased communication overhead from repeatedly sending tokens to different accelerators. To this end, we propose a novel collaboration-constrained routing (C2R) strategy to encourage more specialized expert groups, as well as to improve expert utilization, and present an efficient implementation of MoE that further leverages expert specialization. We achieve an average performance improvement of 0.51% and 0.33% on LLaMA-MoE and Qwen-MoE respectively across ten downstream NLP benchmarks, and reduce the all2all communication costs between GPUs, bringing an extra 20%-30% total running time savings on top of the existing SoTA, i.e. MegaBlocks.","authors":["Mohan Zhang","Pingzhi Li","Jie Peng","Mufan Qiu","Tianlong Chen"],"url":"https://arxiv.org/abs/2504.01337"}
{"created":"2025-04-22","title":"FlowMotion: Target-Predictive Conditional Flow Matching for Jitter-Reduced Text-Driven Human Motion Generation","abstract":"Achieving high-fidelity and temporally smooth 3D human motion generation remains a challenge, particularly within resource-constrained environments. We introduce FlowMotion, a novel method leveraging Conditional Flow Matching (CFM). FlowMotion incorporates a training objective within CFM that focuses on more accurately predicting target motion in 3D human motion generation, resulting in enhanced generation fidelity and temporal smoothness while maintaining the fast synthesis times characteristic of flow-matching-based methods. FlowMotion achieves state-of-the-art jitter performance, achieving the best jitter in the KIT dataset and the second-best jitter in the HumanML3D dataset, and a competitive FID value in both datasets. This combination provides robust and natural motion sequences, offering a promising equilibrium between generation quality and temporal naturalness.","authors":["Manolo Canales Cuba","Vin\\'icius do Carmo Mel\\'icio","Jo\\~ao Paulo Gois"],"url":"https://arxiv.org/abs/2504.01338"}
{"created":"2025-04-22","title":"DreamActor-M1: Holistic, Expressive and Robust Human Image Animation with Hybrid Guidance","abstract":"While recent image-based human animation methods achieve realistic body and facial motion synthesis, critical gaps remain in fine-grained holistic controllability, multi-scale adaptability, and long-term temporal coherence, which leads to their lower expressiveness and robustness. We propose a diffusion transformer (DiT) based framework, DreamActor-M1, with hybrid guidance to overcome these limitations. For motion guidance, our hybrid control signals that integrate implicit facial representations, 3D head spheres, and 3D body skeletons achieve robust control of facial expressions and body movements, while producing expressive and identity-preserving animations. For scale adaptation, to handle various body poses and image scales ranging from portraits to full-body views, we employ a progressive training strategy using data with varying resolutions and scales. For appearance guidance, we integrate motion patterns from sequential frames with complementary visual references, ensuring long-term temporal coherence for unseen regions during complex movements. Experiments demonstrate that our method outperforms the state-of-the-art works, delivering expressive results for portraits, upper-body, and full-body generation with robust long-term consistency. Project Page: https://grisoon.github.io/DreamActor-M1/.","authors":["Yuxuan Luo","Zhengkun Rong","Lizhen Wang","Longhao Zhang","Tianshu Hu","Yongming Zhu"],"url":"https://arxiv.org/abs/2504.01724"}
{"created":"2025-04-22","title":"Information Gain Is Not All You Need","abstract":"Autonomous exploration in mobile robotics often involves a trade-off between two objectives: maximizing environmental coverage and minimizing the total path length. In the widely used information gain paradigm, exploration is guided by the expected value of observations. While this approach is effective under budget-constrained settings--where only a limited number of observations can be made--it fails to align with quality-constrained scenarios, in which the robot must fully explore the environment to a desired level of certainty or quality. In such cases, total information gain is effectively fixed, and maximizing it per step can lead to inefficient, greedy behavior and unnecessary backtracking. This paper argues that information gain should not serve as an optimization objective in quality-constrained exploration. Instead, it should be used to filter viable candidate actions. We propose a novel heuristic, distance advantage, which selects candidate frontiers based on a trade-off between proximity to the robot and remoteness from other frontiers. This heuristic aims to reduce future detours by prioritizing exploration of isolated regions before the robot's opportunity to visit them efficiently has passed. We evaluate our method in simulated environments against classical frontier-based exploration and gain-maximizing approaches. Results show that distance advantage significantly reduces total path length across a variety of environments, both with and without access to prior map predictions. Our findings challenge the assumption that more accurate gain estimation improves performance and offer a more suitable alternative for the quality-constrained exploration paradigm.","authors":["Ludvig Ericson","Jos\\'e Pedro","Patric Jensfelt"],"url":"https://arxiv.org/abs/2504.01980"}
{"created":"2025-04-22","title":"Self-Resource Allocation in Multi-Agent LLM Systems","abstract":"With the development of LLMs as agents, there is a growing interest in connecting multiple agents into multi-agent systems to solve tasks concurrently, focusing on their role in task assignment and coordination. This paper explores how LLMs can effectively allocate computational tasks among multiple agents, considering factors such as cost, efficiency, and performance. In this work, we address key questions, including the effectiveness of LLMs as orchestrators and planners, comparing their effectiveness in task assignment and coordination. Our experiments demonstrate that LLMs can achieve high validity and accuracy in resource allocation tasks. We find that the planner method outperforms the orchestrator method in handling concurrent actions, resulting in improved efficiency and better utilization of agents. Additionally, we show that providing explicit information about worker capabilities enhances the allocation strategies of planners, particularly when dealing with suboptimal workers.","authors":["Alfonso Amayuelas","Jingbo Yang","Saaket Agashe","Ashwin Nagarajan","Antonis Antoniades","Xin Eric Wang","William Wang"],"url":"https://arxiv.org/abs/2504.02051"}
{"created":"2025-04-22","title":"MultiSensor-Home: A Wide-area Multi-modal Multi-view Dataset for Action Recognition and Transformer-based Sensor Fusion","abstract":"Multi-modal multi-view action recognition is a rapidly growing field in computer vision, offering significant potential for applications in surveillance. However, current datasets often fail to address real-world challenges such as wide-area distributed settings, asynchronous data streams, and the lack of frame-level annotations. Furthermore, existing methods face difficulties in effectively modeling inter-view relationships and enhancing spatial feature learning. In this paper, we introduce the MultiSensor-Home dataset, a novel benchmark designed for comprehensive action recognition in home environments, and also propose the Multi-modal Multi-view Transformer-based Sensor Fusion (MultiTSF) method. The proposed MultiSensor-Home dataset features untrimmed videos captured by distributed sensors, providing high-resolution RGB and audio data along with detailed multi-view frame-level action labels. The proposed MultiTSF method leverages a Transformer-based fusion mechanism to dynamically model inter-view relationships. Furthermore, the proposed method integrates a human detection module to enhance spatial feature learning, guiding the model to prioritize frames with human activity to enhance action the recognition accuracy. Experiments on the proposed MultiSensor-Home and the existing MM-Office datasets demonstrate the superiority of MultiTSF over the state-of-the-art methods. Quantitative and qualitative results highlight the effectiveness of the proposed method in advancing real-world multi-modal multi-view action recognition.","authors":["Trung Thanh Nguyen","Yasutomo Kawanishi","Vijay John","Takahiro Komamizu","Ichiro Ide"],"url":"https://arxiv.org/abs/2504.02287"}
{"created":"2025-04-22","title":"Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation","abstract":"Long-form video processing fundamentally challenges vision-language models (VLMs) due to the high computational costs of handling extended temporal sequences. Existing token pruning and feature merging methods often sacrifice critical temporal dependencies or dilute semantic information. We introduce differential distillation, a principled approach that systematically preserves task-relevant information while suppressing redundancy. Based on this principle, we develop ViLaMP, a hierarchical video-language model that processes hour-long videos at ``mixed precision'' through two key mechanisms: (1) differential keyframe selection that maximizes query relevance while maintaining temporal distinctiveness at the frame level and (2) differential feature merging that preserves query-salient features in non-keyframes at the patch level. Hence, ViLaMP retains full information in keyframes while reducing non-keyframes to their most salient features, resembling mixed-precision training. Extensive experiments demonstrate ViLaMP's superior performance across four video understanding benchmarks, particularly on long-form content. Notably, ViLaMP can process ultra-long videos (up to 10K frames) on a single NVIDIA A100 GPU, achieving substantial computational efficiency while maintaining state-of-the-art performance.","authors":["Chuanqi Cheng","Jian Guan","Wei Wu","Rui Yan"],"url":"https://arxiv.org/abs/2504.02438"}
{"created":"2025-04-22","title":"CHARMS: A Cognitive Hierarchical Agent for Reasoning and Motion Stylization in Autonomous Driving","abstract":"To address the challenges of limited behavioral intelligence and overly simplified vehicle behavior modeling in autonomous driving simulations, this paper proposes the Cognitive Hierarchical Agent for Reasoning and Motion Stylization (CHARMS). Leveraging Level-k game theory, we model human driver decision-making using reinforcement learning pretraining and supervised fine-tuning. This enables the resulting models to exhibit diverse behaviors, improving the intelligence and realism of surrounding vehicles in simulation. Building upon this capability, we further develop a scenario generation framework that utilizes the Poisson cognitive hierarchy theory to control the distribution of vehicles with different driving styles through Poisson and binomial sampling. Experimental results demonstrate that CHARMS is capable of both making intelligent decisions as an ego vehicle and generating diverse, realistic driving scenarios as surrounding vehicles. The code for CHARMS will be released at https://github.com/WUTAD-Wjy/CHARMS.","authors":["Jingyi Wang","Duanfeng Chu","Zejian Deng","Liping Lu","Pan Zhou"],"url":"https://arxiv.org/abs/2504.02450"}
{"created":"2025-04-22","title":"Learning Human Perspective in Line Drawings from Single Sketches","abstract":"Artist-drawn sketches only loosely conform to analytical models of perspective projection. This deviation of human-drawn perspective from analytical perspective models is persistent and well known, but has yet to be algorithmically replicated or even well understood. Capturing human perspective can benefit many computer graphics applications, including sketch-based modeling and non-photorealistic rendering. We propose the first dedicated method for learning and replicating human perspective. A core challenge in learning this perspective is the lack of suitable large-scale data, as well as the heterogeneity of human drawing choices. We overcome the data paucity by learning, in a one-shot setup, from a single artist sketch of a given 3D shape and a best matching analytical camera view of the same shape. We match the contours of the depicted shape in this view to corresponding artist strokes. We then learn a spatially continuous local perspective deviation function that modifies the camera perspective projecting the contours to their corresponding strokes while retaining key geometric properties that artists strive to preserve when depicting 3D content. We leverage the observation that artists employ similar perspectives when depicting shapes from slightly different view angles to algorithmically augment our training data. First, we use the perspective function learned from the single example to generate more human-like contour renders from nearby views; then, we pair these renders with the analytical camera contours from these views and use these pairs as additional training data. The resulting learned perspective functions are well aligned with the training sketch perspectives and are consistent across views. We compare our results to potential alternatives, demonstrating the superiority of the proposed approach, and showcasing applications that benefit from learned human perspective.","authors":["Jinfan Yang","Leo Foord-Kelcey","Suzuran Takikawa","Nicholas Vining","Niloy Mitra","Alla Sheffer"],"url":"https://arxiv.org/abs/2504.03099"}
{"created":"2025-04-22","title":"Extending the SAREF4ENER Ontology with Flexibility Based on FlexOffers","abstract":"A key element to support the increased amounts of renewable energy in the energy system is flexibility, i.e., the possibility of changing energy loads in time and amount. Many flexibility models have been designed; however, exact models fail to scale for long time horizons or many devices. Because of this, the FlexOffer (FOs) model has been designed, to provide device-independent approximations of flexibility with good accuracy, and much better scaling for long time horizons and many devices. An important aspect of the real-life implementation of energy flexibility is enabling flexible data exchange with many types of smart energy appliances and market systems, e.g., in smart buildings. For this, ontologies standardizing data formats are required. However, the current industry standard ontology for integrating smart devices for energy purposes, SAREF for Energy Flexibility (SAREF4ENER) only has limited support for flexibility and thus cannot support important use cases. In this paper we propose an extension of SAREF4ENER that integrates full support for the complete FlexOffer model, including advanced use cases, while maintaining backward compatibility. This novel ontology module can accurately describe flexibility for advanced devices such as electric vehicles, batteries, and heat pumps. It can also capture the inherent uncertainty associated with many flexible load types.","authors":["Fabio Lilliu (University of Cagliari)","Amir Laadhar (PANTOPIX GmbH & Co. KG)","Christian Thomsen (Aalborg University)","Diego Reforgiato Recupero (University of Cagliari)","Torben Bach Pedersen (Aalborg University)"],"url":"https://arxiv.org/abs/2504.03595"}
{"created":"2025-04-22","title":"NAACL2025 Tutorial: Adaptation of Large Language Models","abstract":"This tutorial on adaptation of LLMs is designed to address the growing demand for models that go beyond the static capabilities of generic LLMs by providing an overview of dynamic, domain-specific, and task-adaptive LLM adaptation techniques. While general LLMs have demonstrated strong generalization across a variety of tasks, they often struggle to perform well in specialized domains such as finance, healthcare, and code generation for underrepresented languages. Additionally, their static nature limits their ability to evolve with the changing world, and they are often extremely large in size, making them impractical and costly to deploy at scale. As a result, the adaptation of LLMs has drawn much attention since the birth of LLMs and is of core importance, both for industry, which focuses on serving its targeted users, and academia, which can greatly benefit from small but powerful LLMs. To address this gap, this tutorial aims to provide an overview of the LLM adaptation techniques. We start with an introduction to LLM adaptation, from both the data perspective and the model perspective. We then emphasize how the evaluation metrics and benchmarks are different from other techniques. After establishing the problems, we explore various adaptation techniques. We categorize adaptation techniques into two main families. The first is parametric knowledge adaptation, which focuses on updating the parametric knowledge within LLMs. Additionally, we will discuss real-time adaptation techniques, including model editing, which allows LLMs to be updated dynamically in production environments. The second kind of adaptation is semi-parametric knowledge adaptation, where the goal is to update LLM parameters to better leverage external knowledge or tools through techniques like retrieval-augmented generation (RAG) and agent-based systems.","authors":["Zixuan Ke","Yifei Ming","Shafiq Joty"],"url":"https://arxiv.org/abs/2504.03931"}
{"created":"2025-04-22","title":"Intrinsic Verification of Parsers and Formal Grammar Theory in Dependent Lambek Calculus (Extended Version)","abstract":"We present Dependent Lambek Calculus, a domain-specific dependent type theory for verified parsing and formal grammar theory. In Dependent Lambek Calculus, linear types are used as a syntax for formal grammars, and parsers can be written as linear terms. The linear typing restriction provides a form of intrinsic verification that a parser yields only valid parse trees for the input string. We demonstrate the expressivity of this system by showing that the combination of inductive linear types and dependency on non-linear data can be used to encode commonly used grammar formalisms such as regular and context-free grammars as well as traces of various types of automata. Using these encodings, we define parsers for regular expressions using deterministic automata, as well as examples of verified parsers of context-free grammars.","authors":["Steven Schaefer","Nathan Varner","Pedro H. Azevedo de Amorim","Max S. New"],"url":"https://arxiv.org/abs/2504.03995"}
{"created":"2025-04-22","title":"MedM-VL: What Makes a Good Medical LVLM?","abstract":"Medical image analysis is essential in modern healthcare. Deep learning has redirected research focus toward complex medical multimodal tasks, including report generation and visual question answering. Traditional task-specific models often fall short in handling these challenges. Large vision-language models (LVLMs) offer new solutions for solving such tasks. In this study, we build on the popular LLaVA framework to systematically explore model architectures and training strategies for both 2D and 3D medical LVLMs. We present extensive empirical findings and practical guidance. To support reproducibility and future research, we release a modular codebase, MedM-VL, and two pre-trained models: MedM-VL-2D for 2D medical image analysis and MedM-VL-CT-Chest for 3D CT-based applications. The code and models are available at: https://github.com/MSIIP/MedM-VL","authors":["Yiming Shi","Shaoshuai Yang","Xun Zhu","Haoyu Wang","Miao Li","Ji Wu"],"url":"https://arxiv.org/abs/2504.04323"}
{"created":"2025-04-22","title":"WeiDetect: Weibull Distribution-Based Defense against Poisoning Attacks in Federated Learning for Network Intrusion Detection Systems","abstract":"In the era of data expansion, ensuring data privacy has become increasingly critical, posing significant challenges to traditional AI-based applications. In addition, the increasing adoption of IoT devices has introduced significant cybersecurity challenges, making traditional Network Intrusion Detection Systems (NIDS) less effective against evolving threats, and privacy concerns and regulatory restrictions limit their deployment. Federated Learning (FL) has emerged as a promising solution, allowing decentralized model training while maintaining data privacy to solve these issues. However, despite implementing privacy-preserving technologies, FL systems remain vulnerable to adversarial attacks. Furthermore, data distribution among clients is not heterogeneous in the FL scenario. We propose WeiDetect, a two-phase, server-side defense mechanism for FL-based NIDS that detects malicious participants to address these challenges. In the first phase, local models are evaluated using a validation dataset to generate validation scores. These scores are then analyzed using a Weibull distribution, identifying and removing malicious models. We conducted experiments to evaluate the effectiveness of our approach in diverse attack settings. Our evaluation included two popular datasets, CIC-Darknet2020 and CSE-CIC-IDS2018, tested under non-IID data distributions. Our findings highlight that WeiDetect outperforms state-of-the-art defense approaches, improving higher target class recall up to 70% and enhancing the global model's F1 score by 1% to 14%.","authors":["Sameera K. M.","Vinod P.","Anderson Rocha","Rafidha Rehiman K. A.","Mauro Conti"],"url":"https://arxiv.org/abs/2504.04367"}
{"created":"2025-04-22","title":"Deliberate Planning of 3D Bin Packing on Packing Configuration Trees","abstract":"Online 3D Bin Packing Problem (3D-BPP) has widespread applications in industrial automation. Existing methods usually solve the problem with limited resolution of spatial discretization, and/or cannot deal with complex practical constraints well. We propose to enhance the practical applicability of online 3D-BPP via learning on a novel hierarchical representation, packing configuration tree (PCT). PCT is a full-fledged description of the state and action space of bin packing which can support packing policy learning based on deep reinforcement learning (DRL). The size of the packing action space is proportional to the number of leaf nodes, making the DRL model easy to train and well-performing even with continuous solution space. We further discover the potential of PCT as tree-based planners in deliberately solving packing problems of industrial significance, including large-scale packing and different variations of BPP setting. A recursive packing method is proposed to decompose large-scale packing into smaller sub-trees while a spatial ensemble mechanism integrates local solutions into global. For different BPP variations with additional decision variables, such as lookahead, buffering, and offline packing, we propose a unified planning framework enabling out-of-the-box problem solving. Extensive evaluations demonstrate that our method outperforms existing online BPP baselines and is versatile in incorporating various practical constraints. The planning process excels across large-scale problems and diverse problem variations. We develop a real-world packing robot for industrial warehousing, with careful designs accounting for constrained placement and transportation stability. Our packing robot operates reliably and efficiently on unprotected pallets at 10 seconds per box. It achieves averagely 19 boxes per pallet with 57.4% space utilization for relatively large-size boxes.","authors":["Hang Zhao","Juzhan Xu","Kexiong Yu","Ruizhen Hu","Chenyang Zhu","Kai Xu"],"url":"https://arxiv.org/abs/2504.04421"}
{"created":"2025-04-22","title":"Continuous Locomotive Crowd Behavior Generation","abstract":"Modeling and reproducing crowd behaviors are important in various domains including psychology, robotics, transport engineering and virtual environments. Conventional methods have focused on synthesizing momentary scenes, which have difficulty in replicating the continuous nature of real-world crowds. In this paper, we introduce a novel method for automatically generating continuous, realistic crowd trajectories with heterogeneous behaviors and interactions among individuals. We first design a crowd emitter model. To do this, we obtain spatial layouts from single input images, including a segmentation map, appearance map, population density map and population probability, prior to crowd generation. The emitter then continually places individuals on the timeline by assigning independent behavior characteristics such as agents' type, pace, and start/end positions using diffusion models. Next, our crowd simulator produces their long-term locomotions. To simulate diverse actions, it can augment their behaviors based on a Markov chain. As a result, our overall framework populates the scenes with heterogeneous crowd behaviors by alternating between the proposed emitter and simulator. Note that all the components in the proposed framework are user-controllable. Lastly, we propose a benchmark protocol to evaluate the realism and quality of the generated crowds in terms of the scene-level population dynamics and the individual-level trajectory accuracy. We demonstrate that our approach effectively models diverse crowd behavior patterns and generalizes well across different geographical environments. Code is publicly available at https://github.com/InhwanBae/CrowdES .","authors":["Inhwan Bae","Junoh Lee","Hae-Gon Jeon"],"url":"https://arxiv.org/abs/2504.04756"}
{"created":"2025-04-22","title":"Anisotropic space-time goal-oriented error control and mesh adaptivity for convection-diffusion-reaction equations","abstract":"We present an anisotropic goal-oriented error estimator based on the Dual Weighted Residual (DWR) method for time-dependent convection-diffusion-reaction (CDR) equations. Using anisotropic interpolation operators the estimator is elementwise separated with respect to the single directions in space and time leading to adaptive, anisotropic mesh refinement in a natural way. To prevent spurious oscillations the streamline upwind Petrov-Galerkin (SUPG) method is applied to stabilize the underlying system in the case of high P\\'eclet numbers. Efficiency and robustness of the underlying algorithm are demonstrated for different goal functionals. The directional error indicators quantify anisotropy of the solution with respect to the goal, and produce meshes that efficiently capture sharp layers. Numerical examples show the superiority of the proposed approach over isotropic adaptive and global mesh refinement using established benchmarks for convection-dominated transport.","authors":["M. Bause","M. Bruchh\\\"auser","B. Endtmayer","N. Margenberg","I. Toulopoulos","T. Wick"],"url":"https://arxiv.org/abs/2504.04951"}
{"created":"2025-04-22","title":"Following the Whispers of Values: Unraveling Neural Mechanisms Behind Value-Oriented Behaviors in LLMs","abstract":"Despite the impressive performance of large language models (LLMs), they can present unintended biases and harmful behaviors driven by encoded values, emphasizing the urgent need to understand the value mechanisms behind them. However, current research primarily evaluates these values through external responses with a focus on AI safety, lacking interpretability and failing to assess social values in real-world contexts. In this paper, we propose a novel framework called ValueExploration, which aims to explore the behavior-driven mechanisms of National Social Values within LLMs at the neuron level. As a case study, we focus on Chinese Social Values and first construct C-voice, a large-scale bilingual benchmark for identifying and evaluating Chinese Social Values in LLMs. By leveraging C-voice, we then identify and locate the neurons responsible for encoding these values according to activation difference. Finally, by deactivating these neurons, we analyze shifts in model behavior, uncovering the internal mechanism by which values influence LLM decision-making. Extensive experiments on four representative LLMs validate the efficacy of our framework. The benchmark and code will be available.","authors":["Ling Hu","Yuemei Xu","Xiaoyang Gu","Letao Han"],"url":"https://arxiv.org/abs/2504.04994"}
{"created":"2025-04-22","title":"Unleashing the Power of LLMs in Dense Retrieval with Query Likelihood Modeling","abstract":"Dense retrieval is a crucial task in Information Retrieval (IR) and is the foundation for downstream tasks such as re-ranking. Recently, large language models (LLMs) have shown compelling semantic understanding capabilities and are appealing to researchers studying dense retrieval. LLMs, as decoder-style generative models, are competent at language generation while falling short on modeling global information due to the lack of attention to tokens afterward. Inspired by the classical word-based language modeling approach for IR, i.e., the query likelihood (QL) model, we seek to sufficiently utilize LLMs' generative ability by QL maximization. However, instead of ranking documents with QL estimation, we introduce an auxiliary task of QL maximization to yield a better backbone for contrastively learning a discriminative retriever. We name our model as LLM-QL. To condense global document semantics to a single vector during QL modeling, LLM-QL has two major components, Attention Stop (AS) and Input Corruption (IC). AS stops the attention of predictive tokens to previous tokens until the ending token of the document. IC masks a portion of tokens in the input documents during prediction. Experiments on MSMARCO show that LLM-QL can achieve significantly better performance than other LLM-based retrievers and using QL estimated by LLM-QL for ranking outperforms word-based QL by a large margin.","authors":["Hengran Zhang","Keping Bi","Jiafeng Guo","Xiaojie Sun","Shihao Liu","Daiting Shi","Dawei Yin","Xueqi Cheng"],"url":"https://arxiv.org/abs/2504.05216"}
{"created":"2025-04-22","title":"Structuring Multiple Simple Cycle Reservoirs with Particle Swarm Optimization","abstract":"Reservoir Computing (RC) is a time-efficient computational paradigm derived from Recurrent Neural Networks (RNNs). The Simple Cycle Reservoir (SCR) is an RC model that stands out for its minimalistic design, offering extremely low construction complexity and proven capability of universally approximating time-invariant causal fading memory filters, even in the linear dynamics regime. This paper introduces Multiple Simple Cycle Reservoirs (MSCRs), a multi-reservoir framework that extends Echo State Networks (ESNs) by replacing a single large reservoir with multiple interconnected SCRs. We demonstrate that optimizing MSCR using Particle Swarm Optimization (PSO) outperforms existing multi-reservoir models, achieving competitive predictive performance with a lower-dimensional state space. By modeling interconnections as a weighted Directed Acyclic Graph (DAG), our approach enables flexible, task-specific network topology adaptation. Numerical simulations on three benchmark time-series prediction tasks confirm these advantages over rival algorithms. These findings highlight the potential of MSCR-PSO as a promising framework for optimizing multi-reservoir systems, providing a foundation for further advancements and applications of interconnected SCRs for developing efficient AI devices.","authors":["Ziqiang Li","Robert Simon Fong","Kantaro Fujiwara","Kazuyuki Aihara","Gouhei Tanaka"],"url":"https://arxiv.org/abs/2504.05347"}
{"created":"2025-04-22","title":"SPARK-Remote: A Cost-Effective System for Remote Bimanual Robot Teleoperation","abstract":"Robot teleoperation enables human control over robotic systems in environments where full autonomy is challenging. Recent advancements in low-cost teleoperation devices and VR/AR technologies have expanded accessibility, particularly for bimanual robot manipulators. However, transitioning from in-person to remote teleoperation presents challenges in task performance. We introduce SPARK, a kinematically scaled, low-cost teleoperation system for operating bimanual robots. Its effectiveness is compared to existing technologies like the 3D SpaceMouse and VR/AR controllers. We further extend SPARK to SPARK-Remote, integrating sensor-based force feedback using haptic gloves and a force controller for remote teleoperation. We evaluate SPARK and SPARK-Remote variants on 5 bimanual manipulation tasks which feature operational properties - positional precision, rotational precision, large movements in the workspace, and bimanual collaboration - to test the effective teleoperation modes. Our findings offer insights into improving low-cost teleoperation interfaces for real-world applications. For supplementary materials, additional experiments, and qualitative results, visit the project webpage: https://bit.ly/41EfcJa","authors":["Adam Imdieke","Karthik Desingh"],"url":"https://arxiv.org/abs/2504.05488"}
{"created":"2025-04-22","title":"BoolE: Exact Symbolic Reasoning via Boolean Equality Saturation","abstract":"Boolean symbolic reasoning for gate-level netlists is a critical step in verification, logic and datapath synthesis, and hardware security. Specifically, reasoning datapath and adder tree in bit-blasted Boolean networks is particularly crucial for verification and synthesis, and challenging. Conventional approaches either fail to accurately (exactly) identify the function blocks of the designs in gate-level netlist with structural hashing and symbolic propagation, or their reasoning performance is highly sensitive to structure modifications caused by technology mapping or logic optimization. This paper introduces BoolE, an exact symbolic reasoning framework for Boolean netlists using equality saturation. BoolE optimizes scalability and performance by integrating domain-specific Boolean ruleset for term rewriting. We incorporate a novel extraction algorithm into BoolE to enhance its structural insight and computational efficiency, which adeptly identifies and captures multi-input, multi-output high-level structures (e.g., full adder) in the reconstructed e-graph.","authors":["Jiaqi Yin","Zhan Song","Chen Chen","Qihao Hu","Cunxi Yu"],"url":"https://arxiv.org/abs/2504.05577"}
{"created":"2025-04-22","title":"Large Language Models Enhanced Hyperbolic Space Recommender Systems","abstract":"Large Language Models (LLMs) have attracted significant attention in recommender systems for their excellent world knowledge capabilities. However, existing methods that rely on Euclidean space struggle to capture the rich hierarchical information inherent in textual and semantic data, which is essential for capturing user preferences. The geometric properties of hyperbolic space offer a promising solution to address this issue. Nevertheless, integrating LLMs-based methods with hyperbolic space to effectively extract and incorporate diverse hierarchical information is non-trivial. To this end, we propose a model-agnostic framework, named HyperLLM, which extracts and integrates hierarchical information from both structural and semantic perspectives. Structurally, HyperLLM uses LLMs to generate multi-level classification tags with hierarchical parent-child relationships for each item. Then, tag-item and user-item interactions are jointly learned and aligned through contrastive learning, thereby providing the model with clear hierarchical information. Semantically, HyperLLM introduces a novel meta-optimized strategy to extract hierarchical information from semantic embeddings and bridge the gap between the semantic and collaborative spaces for seamless integration. Extensive experiments show that HyperLLM significantly outperforms recommender systems based on hyperbolic space and LLMs, achieving performance improvements of over 40%. Furthermore, HyperLLM not only improves recommender performance but also enhances training stability, highlighting the critical role of hierarchical information in recommender systems.","authors":["Wentao Cheng","Zhida Qin","Zexue Wu","Pengzhan Zhou","Tianyu Huang"],"url":"https://arxiv.org/abs/2504.05694"}
{"created":"2025-04-22","title":"Persona Dynamics: Unveiling the Impact of Personality Traits on Agents in Text-Based Games","abstract":"Artificial agents are increasingly central to complex interactions and decision-making tasks, yet aligning their behaviors with desired human values remains an open challenge. In this work, we investigate how human-like personality traits influence agent behavior and performance within text-based interactive environments. We introduce PANDA: Personality Adapted Neural Decision Agents, a novel method for projecting human personality traits onto agents to guide their behavior. To induce personality in a text-based game agent, (i) we train a personality classifier to identify what personality type the agent's actions exhibit, and (ii) we integrate the personality profiles directly into the agent's policy-learning pipeline. By deploying agents embodying 16 distinct personality types across 25 text-based games and analyzing their trajectories, we demonstrate that an agent's action decisions can be guided toward specific personality profiles. Moreover, certain personality types, such as those characterized by higher levels of Openness, display marked advantages in performance. These findings underscore the promise of personality-adapted agents for fostering more aligned, effective, and human-centric decision-making in interactive environments.","authors":["Seungwon Lim","Seungbeen Lee","Dongjun Min","Youngjae Yu"],"url":"https://arxiv.org/abs/2504.06868"}
{"created":"2025-04-22","title":"S-EO: A Large-Scale Dataset for Geometry-Aware Shadow Detection in Remote Sensing Applications","abstract":"We introduce the S-EO dataset: a large-scale, high-resolution dataset, designed to advance geometry-aware shadow detection. Collected from diverse public-domain sources, including challenge datasets and government providers such as USGS, our dataset comprises 702 georeferenced tiles across the USA, each covering 500x500 m. Each tile includes multi-date, multi-angle WorldView-3 pansharpened RGB images, panchromatic images, and a ground-truth DSM of the area obtained from LiDAR scans. For each image, we provide a shadow mask derived from geometry and sun position, a vegetation mask based on the NDVI index, and a bundle-adjusted RPC model. With approximately 20,000 images, the S-EO dataset establishes a new public resource for shadow detection in remote sensing imagery and its applications to 3D reconstruction. To demonstrate the dataset's impact, we train and evaluate a shadow detector, showcasing its ability to generalize, even to aerial images. Finally, we extend EO-NeRF - a state-of-the-art NeRF approach for satellite imagery - to leverage our shadow predictions for improved 3D reconstructions.","authors":["El\\'ias Masquil","Roger Mar\\'i","Thibaud Ehret","Enric Meinhardt-Llopis","Pablo Mus\\'e","Gabriele Facciolo"],"url":"https://arxiv.org/abs/2504.06920"}
{"created":"2025-04-22","title":"ID-Booth: Identity-consistent Face Generation with Diffusion Models","abstract":"Recent advances in generative modeling have enabled the generation of high-quality synthetic data that is applicable in a variety of domains, including face recognition. Here, state-of-the-art generative models typically rely on conditioning and fine-tuning of powerful pretrained diffusion models to facilitate the synthesis of realistic images of a desired identity. Yet, these models often do not consider the identity of subjects during training, leading to poor consistency between generated and intended identities. In contrast, methods that employ identity-based training objectives tend to overfit on various aspects of the identity, and in turn, lower the diversity of images that can be generated. To address these issues, we present in this paper a novel generative diffusion-based framework, called ID-Booth. ID-Booth consists of a denoising network responsible for data generation, a variational auto-encoder for mapping images to and from a lower-dimensional latent space and a text encoder that allows for prompt-based control over the generation procedure. The framework utilizes a novel triplet identity training objective and enables identity-consistent image generation while retaining the synthesis capabilities of pretrained diffusion models. Experiments with a state-of-the-art latent diffusion model and diverse prompts reveal that our method facilitates better intra-identity consistency and inter-identity separability than competing methods, while achieving higher image diversity. In turn, the produced data allows for effective augmentation of small-scale datasets and training of better-performing recognition models in a privacy-preserving manner. The source code for the ID-Booth framework is publicly available at https://github.com/dariant/ID-Booth.","authors":["Darian Toma\\v{s}evi\\'c","Fadi Boutros","Chenhao Lin","Naser Damer","Vitomir \\v{S}truc","Peter Peer"],"url":"https://arxiv.org/abs/2504.07392"}
{"created":"2025-04-22","title":"AI-Slop to AI-Polish? Aligning Language Models through Edit-Based Writing Rewards and Test-time Computation","abstract":"AI-generated text is proliferating across domains, from creative writing and journalism to marketing content and scientific articles. Models can follow user-provided instructions to generate coherent and grammatically correct outputs but in this work, we study a more fundamental question: how do we evaluate and improve the writing quality of AI-generated text? Writing quality assessment has received less attention from the community, in part because it is fundamentally subjective and requires expertise. We first introduce the Writing Quality Benchmark (WQ) by consolidating five writing-preference datasets into 4,729 writing quality judgments. Our experiments show that most of the competitive baselines, including state-of-the-art LLMs that excel at reasoning tasks, barely outperform random baselines on WQ. We then train specialized Writing Quality Reward Models (WQRM) of various sizes for writing quality assessment that demonstrate strong generalization on four out-of-distribution test sets and 74% accuracy on the WQ benchmark. To further show WQRM's practical benefits during inference, we leverage additional test-time compute to generate and rank multiple candidate revisions, allowing us to select higher-quality outputs from an initial draft. Human evaluation with 9 experienced writers confirm that WQRM-based selection produces writing samples preferred by experts 66% overall, and 72.2% when the reward gap is larger than 1 point. We release our datasets and models to encourage community engagement with writing quality assessment and development of AI writing systems better aligned with human preferences.","authors":["Tuhin Chakrabarty","Philippe Laban","Chien-Sheng Wu"],"url":"https://arxiv.org/abs/2504.07532"}
{"created":"2025-04-22","title":"Relaxing the Markov Requirements on Reinforcement Learning Under Weak Relative Ignorability","abstract":"Incomplete data, confounding effects, and violations of the Markov property are interrelated problems which are ubiquitous in Reinforcement Learning applications. We introduce the concept of ``relative ignorabilty\" and leverage it to establish a novel convergence theorem for adaptive Reinforcement Learning. This theoretical result relaxes the Markov assumption on the stochastic process underlying conventional $Q$-learning, deploying a generalized form of the Robbins-Monro stochastic approximation theorem to establish optimality. This result has clear downstream implications for most active subfields of Reinforcement Learning, with clear paths for extension to the field of Causal Inference.","authors":["MaryLena Bleile"],"url":"https://arxiv.org/abs/2504.07722"}
{"created":"2025-04-22","title":"Pychop: Emulating Low-Precision Arithmetic in Numerical Methods and Neural Networks","abstract":"Motivated by the growing demand for low-precision arithmetic in computational science, we exploit lower-precision emulation in Python -- widely regarded as the dominant programming language for numerical analysis and machine learning. Low-precision training has revolutionized deep learning by enabling more efficient computation and reduced memory and energy consumption while maintaining model fidelity. To better enable numerical experimentation with and exploration of low precision computation, we developed the Pychop library, which supports customizable floating-point formats and a comprehensive set of rounding modes in Python, allowing users to benefit from fast, low-precision emulation in numerous applications. Pychop also introduces interfaces for both PyTorch and JAX, enabling efficient low-precision emulation on GPUs for neural network training and inference with unparalleled flexibility.","authors":["Erin Carson","Xinye Chen"],"url":"https://arxiv.org/abs/2504.07835"}
{"created":"2025-04-22","title":"2D-Curri-DPO: Two-Dimensional Curriculum Learning for Direct Preference Optimization","abstract":"Aligning large language models with human preferences is crucial for their safe deployment. While Direct Preference Optimization (DPO) offers an efficient alternative to reinforcement learning from human feedback, traditional DPO methods are limited by their reliance on single preference pairs. Recent work like Curriculum-DPO integrates multiple pairs using a one-dimensional difficulty curriculum based on pairwise distinguishability (PD), but overlooks the complexity of the input prompt itself. To address this, we propose 2D-Curri-DPO, a novel framework employing a two-dimensional curriculum that jointly models Prompt Complexity (PC) and Pairwise Distinguishability. This framework introduces dual difficulty metrics to quantify prompt semantic complexity and response preference clarity, defines a curriculum strategy space encompassing multiple selectable strategies for task adaptation, and incorporates a KL-divergence-based adaptive mechanism for dynamic reference model updates to enhance training stability. Comprehensive experiments demonstrate that 2D-Curri-DPO significantly outperforms standard DPO and prior curriculum methods across multiple benchmarks, including MT-Bench, Vicuna Bench, and WizardLM. Our approach achieves state-of-the-art performance on challenging test sets like UltraFeedback. Ablation studies confirm the benefits of the 2D structure and adaptive mechanisms, while analysis provides guidance for strategy selection. These findings demonstrate that effective alignment requires modeling both prompt complexity and pairwise distinguishability, establishing adaptive, multi-dimensional curriculum learning as a powerful and interpretable new paradigm for preference-based language model optimization.","authors":["Mengyang Li","Zhong Zhang"],"url":"https://arxiv.org/abs/2504.07856"}
{"created":"2025-04-22","title":"On the Practice of Deep Hierarchical Ensemble Network for Ad Conversion Rate Prediction","abstract":"The predictions of click through rate (CTR) and conversion rate (CVR) play a crucial role in the success of ad-recommendation systems. A Deep Hierarchical Ensemble Network (DHEN) has been proposed to integrate multiple feature crossing modules and has achieved great success in CTR prediction. However, its performance for CVR prediction is unclear in the conversion ads setting, where an ad bids for the probability of a user's off-site actions on a third party website or app, including purchase, add to cart, sign up, etc. A few challenges in DHEN: 1) What feature-crossing modules (MLP, DCN, Transformer, to name a few) should be included in DHEN? 2) How deep and wide should DHEN be to achieve the best trade-off between efficiency and efficacy? 3) What hyper-parameters to choose in each feature-crossing module? Orthogonal to the model architecture, the input personalization features also significantly impact model performance with a high degree of freedom. In this paper, we attack this problem and present our contributions biased to the applied data science side, including:","authors":["Jinfeng Zhuang","Yinrui Li","Runze Su","Ke Xu","Zhixuan Shao","Kungang Li","Ling Leng","Han Sun","Meng Qi","Yixiong Meng","Yang Tang","Zhifang Liu","Qifei Shen","Aayush Mudgal"],"url":"https://arxiv.org/abs/2504.08169"}
{"created":"2025-04-22","title":"Evaluating Pedestrian Risks in Shared Spaces Through Autonomous Vehicle Experiments on a Fixed Track","abstract":"The majority of research on safety in autonomous vehicles has been conducted in structured and controlled environments. However, there is a scarcity of research on safety in unregulated pedestrian areas, especially when interacting with public transport vehicles like trams. This study investigates pedestrian responses to an alert system in this context by replicating this real-world scenario in an environment using an autonomous vehicle. The results show that safety measures from other contexts can be adapted to shared spaces with trams, where fixed tracks heighten risks in unregulated crossings.","authors":["Enrico Del Re","Novel Certad","Joshua Varughese","Cristina Olaverri-Monreal"],"url":"https://arxiv.org/abs/2504.08316"}
{"created":"2025-04-22","title":"Tactile sensing enables vertical obstacle negotiation for elongate many-legged robots","abstract":"Many-legged elongated robots show promise for reliable mobility on rugged landscapes. However, most studies on these systems focus on planar motion planning without addressing rapid vertical motion. Despite their success on mild rugged terrains, recent field tests reveal a critical need for 3D behaviors (e.g., climbing or traversing tall obstacles). The challenges of 3D motion planning partially lie in designing sensing and control for a complex high-degree-of-freedom system, typically with over 25 degrees of freedom. To address the first challenge regarding sensing, we propose a tactile antenna system that enables the robot to probe obstacles to gather information about their structure. Building on this sensory input, we develop a control framework that integrates data from the antenna and foot contact sensors to dynamically adjust the robot's vertical body undulation for effective climbing. With the addition of simple, low-bandwidth tactile sensors, a robot with high static stability and redundancy exhibits predictable climbing performance in complex environments using a simple feedback controller. Laboratory and outdoor experiments demonstrate the robot's ability to climb obstacles up to five times its height. Moreover, the robot exhibits robust climbing capabilities on obstacles covered with shifting, robot-sized random items and those characterized by rapidly changing curvatures. These findings demonstrate an alternative solution to perceive the environment and facilitate effective response for legged robots, paving ways towards future highly capable, low-profile many-legged robots.","authors":["Juntao He","Baxi Chong","Massimiliano Iaschi","Vincent R. Nienhusser","Sehoon Ha","Daniel I. Goldman"],"url":"https://arxiv.org/abs/2504.08615"}
{"created":"2025-04-22","title":"MSCCL++: Rethinking GPU Communication Abstractions for Cutting-edge AI Applications","abstract":"Modern cutting-edge AI applications are being developed over fast-evolving, heterogeneous, nascent hardware devices. This requires frequent reworking of the AI software stack to adopt bottom-up changes from new hardware, which takes time for general-purpose software libraries. Consequently, real applications often develop custom software stacks optimized for their specific workloads and hardware. Custom stacks help in quick development and optimization, but incur a lot of redundant efforts across applications in writing non-portable code. This paper discusses an alternative communication library interface for AI applications that offers both portability and performance by reducing redundant efforts while maintaining flexibility for customization. We present MSCCL++, a novel abstraction of GPU communication based on separation of concerns: (1) a primitive interface provides a minimal hardware abstraction as a common ground for software and hardware developers to write custom communication, and (2) higher-level portable interfaces and specialized implementations enable optimization for different workloads and hardware environments. This approach makes the primitive interface reusable across applications while enabling highly flexible optimization. Compared to state-of-the-art baselines (NCCL, RCCL, and MSCCL), MSCCL++ achieves speedups of up to 5.4$\\times$ for collective communication and up to 15% for real-world AI inference workloads. MSCCL++ is in production of multiple AI services provided by Microsoft Azure, and is also adopted by RCCL, the GPU collective communication library maintained by AMD. MSCCL++ is open-source and available at https://github.com/microsoft/mscclpp.","authors":["Aashaka Shah","Abhinav Jangda","Binyang Li","Caio Rocha","Changho Hwang","Jithin Jose","Madan Musuvathi","Olli Saarikivi","Peng Cheng","Qinghua Zhou","Roshan Dathathri","Saeed Maleki","Ziyue Yang"],"url":"https://arxiv.org/abs/2504.09014"}
{"created":"2025-04-22","title":"An Enhanced Iterative Deepening Search Algorithm for the Unrestricted Container Rehandling Problem","abstract":"In container terminal yards, the Container Rehandling Problem (CRP) involves rearranging containers between stacks under specific operational rules, and it is a pivotal optimization challenge in intelligent container scheduling systems. Existing CRP studies primarily focus on minimizing reallocation costs using two-dimensional bay structures, considering factors such as container size, weight, arrival sequences, and retrieval priorities. This paper introduces an enhanced deepening search algorithm integrated with improved lower bounds to boost search efficiency. To further reduce the search space, we design mutually consistent pruning rules to avoid excessive computational overhead. The proposed algorithm is validated on three widely used benchmark datasets for the Unrestricted Container Rehandling Problem (UCRP). Experimental results demonstrate that our approach outperforms state-of-the-art exact algorithms in solving the more general UCRP variant, particularly exhibiting superior efficiency when handling containers within the same priority group under strict time constraints.","authors":["Ruoqi Wang","Jiawei Li"],"url":"https://arxiv.org/abs/2504.09046"}
{"created":"2025-04-22","title":"VibWalk: Mapping Lower-limb Haptic Experiences of Everyday Walking","abstract":"Walking is among the most common human activities where the feet can gather rich tactile information from the ground. The dynamic contact between the feet and the ground generates vibration signals that can be sensed by the foot skin. While existing research focuses on foot pressure sensing and lower-limb interactions, methods of decoding tactile information from foot vibrations remain underexplored. Here, we propose a foot-equipped wearable system capable of recording wideband vibration signals during walking activities. By enabling location-based recording, our system generates maps of haptic data that encode information on ground materials, lower-limb activities, and road conditions. Its efficacy was demonstrated through studies involving 31 users walking over 18 different ground textures, achieving an overall identification accuracy exceeding 95\\% (cross-user accuracy of 87\\%). Our system allows pedestrians to map haptic information through their daily walking activities, which has potential applications in creating digitalized walking experiences and monitoring road conditions.","authors":["Shih Ying-Lei","Dongxu Tang","Weiming Hu","Sang Ho Yoon","Yitian Shao"],"url":"https://arxiv.org/abs/2504.09089"}
{"created":"2025-04-22","title":"Can Large Language Models Become Policy Refinement Partners? Evidence from China's Social Security Studies","abstract":"The rapid development of large language models (LLMs) is reshaping operational paradigms across multidisciplinary domains. LLMs' emergent capability to synthesize policy-relevant insights across disciplinary boundaries suggests potential as decision-support tools. However, their actual performance and suitability as policy refinement partners still require verification through rigorous and systematic evaluations. Our study employs the context-embedded generation-adaptation framework to conduct a tripartite comparison among the American GPT-4o, the Chinese DeepSeek-R1 and human researchers, investigating the capability boundaries and performance characteristics of LLMs in generating policy recommendations for China's social security issues. This study demonstrates that while LLMs exhibit distinct advantages in systematic policy design, they face significant limitations in addressing complex social dynamics, balancing stakeholder interests, and controlling fiscal risks within the social security domain. Furthermore, DeepSeek-R1 demonstrates superior performance to GPT-4o across all evaluation dimensions in policy recommendation generation, illustrating the potential of localized training to improve contextual alignment. These findings suggest that regionally-adapted LLMs can function as supplementary tools for generating diverse policy alternatives informed by domain-specific social insights. Nevertheless, the formulation of policy refinement requires integration with human researchers' expertise, which remains critical for interpreting institutional frameworks, cultural norms, and value systems.","authors":["Jinghan Ke","Zheng Zhou","Yuxuan Zhao"],"url":"https://arxiv.org/abs/2504.09137"}
{"created":"2025-04-22","title":"Probabilistic Strategies: Definability and the Tensor Completeness Problem","abstract":"Programs that combine I/O and countable probabilistic choice, modulo either bisimilarity or trace equivalence, can be seen as describing a probabilistic strategy. For well-founded programs, we might expect to axiomatize bisimilarity via a sum of equational theories and trace equivalence via a tensor of such theories. This is by analogy with similar results for nondeterminism, established previously.","authors":["Nathan Bowler","Sergey Goncharov","Paul Blain Levy"],"url":"https://arxiv.org/abs/2504.09392"}
{"created":"2025-04-22","title":"UXAgent: A System for Simulating Usability Testing of Web Design with LLM Agents","abstract":"Usability testing is a fundamental research method that user experience (UX) researchers use to evaluate and iterate a web design, but\\textbf{ how to evaluate and iterate the usability testing study design } itself? Recent advances in Large Language Model-simulated Agent (\\textbf{LLM Agent}) research inspired us to design \\textbf{UXAgent} to support UX researchers in evaluating and reiterating their usability testing study design before they conduct the real human-subject study. Our system features a Persona Generator module, an LLM Agent module, and a Universal Browser Connector module to automatically generate thousands of simulated users to interactively test the target website. The system also provides an Agent Interview Interface and a Video Replay Interface so that the UX researchers can easily review and analyze the generated qualitative and quantitative log data. Through a heuristic evaluation, five UX researcher participants praised the innovation of our system but also expressed concerns about the future of LLM Agent usage in UX studies.","authors":["Yuxuan Lu","Bingsheng Yao","Hansu Gu","Jing Huang","Jessie Wang","Yang Li","Jiri Gesi","Qi He","Toby Jia-Jun Li","Dakuo Wang"],"url":"https://arxiv.org/abs/2504.09407"}
{"created":"2025-04-22","title":"FROG: Effective Friend Recommendation in Online Games via Modality-aware User Preferences","abstract":"Due to the convenience of mobile devices, the online games have become an important part for user entertainments in reality, creating a demand for friend recommendation in online games. However, none of existing approaches can effectively incorporate the multi-modal user features (e.g., images and texts) with the structural information in the friendship graph, due to the following limitations: (1) some of them ignore the high-order structural proximity between users, (2) some fail to learn the pairwise relevance between users at modality-specific level, and (3) some cannot capture both the local and global user preferences on different modalities. By addressing these issues, in this paper, we propose an end-to-end model FROG that better models the user preferences on potential friends. Comprehensive experiments on both offline evaluation and online deployment at Tencent have demonstrated the superiority of FROG over existing approaches.","authors":["Qiwei Wang","Dandan Lin","Wenqing Lin","Ziming Wu"],"url":"https://arxiv.org/abs/2504.09428"}
{"created":"2025-04-22","title":"Bounds and Optimal Constructions of Generalized Merge-Convertible Codes for Code Conversion into LRCs","abstract":"Error-correcting codes are essential for ensuring fault tolerance in modern distributed data storage systems. However, in practice, factors such as the failure rates of storage devices can vary significantly over time, resulting in changes to the optimal code parameters. To reduce storage cost while maintaining efficiency, Maturana and Rashmi introduced a theoretical framework known as code conversion, which enables dynamic adjustment of code parameters according to device performance. In this paper, we focus exclusively on the bounds and constructions of generalized merge-convertible codes. First, we establish a new lower bound on the access cost when the final code is an $(r,\\delta)$-LRC. This bound unifies and generalizes all previously known bounds for merge conversion, where the initial and final codes are either LRCs or MDS codes. We then construct a family of access-optimal MDS convertible codes by leveraging subgroups of the automorphism group of a rational function field. It is worth noting that our construction is also per-symbol read access-optimal. Next, we further extend our MDS-based construction to design access-optimal convertible codes for the conversion between $(r,\\delta)$-LRCs with parameters that have not been previously reported. Finally, using the parity-check matrix approach, we present a construction of access-optimal convertible codes that enable merge conversion from MDS codes to an $(r,\\delta)$-LRC. To the best of our knowledge, this is the first explicit optimal construction of code conversion between MDS codes and LRCs. All of our constructions are performed over finite fields whose sizes grow linearly with the code length.","authors":["Haoming Shi","Weijun Fang","Yuan Gao"],"url":"https://arxiv.org/abs/2504.09580"}
{"created":"2025-04-22","title":"GeoNav: Empowering MLLMs with Explicit Geospatial Reasoning Abilities for Language-Goal Aerial Navigation","abstract":"Language-goal aerial navigation is a critical challenge in embodied AI, requiring UAVs to localize targets in complex environments such as urban blocks based on textual specification. Existing methods, often adapted from indoor navigation, struggle to scale due to limited field of view, semantic ambiguity among objects, and lack of structured spatial reasoning. In this work, we propose GeoNav, a geospatially aware multimodal agent to enable long-range navigation. GeoNav operates in three phases-landmark navigation, target search, and precise localization-mimicking human coarse-to-fine spatial strategies. To support such reasoning, it dynamically builds two different types of spatial memory. The first is a global but schematic cognitive map, which fuses prior textual geographic knowledge and embodied visual cues into a top-down, annotated form for fast navigation to the landmark region. The second is a local but delicate scene graph representing hierarchical spatial relationships between blocks, landmarks, and objects, which is used for definite target localization. On top of this structured representation, GeoNav employs a spatially aware, multimodal chain-of-thought prompting mechanism to enable multimodal large language models with efficient and interpretable decision-making across stages. On the CityNav urban navigation benchmark, GeoNav surpasses the current state-of-the-art by up to 12.53% in success rate and significantly improves navigation efficiency, even in hard-level tasks. Ablation studies highlight the importance of each module, showcasing how geospatial representations and coarse-to-fine reasoning enhance UAV navigation.","authors":["Haotian Xu","Yue Hu","Chen Gao","Zhengqiu Zhu","Yong Zhao","Yong Li","Quanjun Yin"],"url":"https://arxiv.org/abs/2504.09587"}
{"created":"2025-04-22","title":"Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws","abstract":"Large Language Models (LLMs) have demonstrated remarkable capabilities across numerous tasks, yet principled explanations for their underlying mechanisms and several phenomena, such as scaling laws, hallucinations, and related behaviors, remain elusive. In this work, we revisit the classical relationship between compression and prediction, grounded in Kolmogorov complexity and Shannon information theory, to provide deeper insights into LLM behaviors. By leveraging the Kolmogorov Structure Function and interpreting LLM compression as a two-part coding process, we offer a detailed view of how LLMs acquire and store information across increasing model and data scales -- from pervasive syntactic patterns to progressively rarer knowledge elements. Motivated by this theoretical perspective and natural assumptions inspired by Heap's and Zipf's laws, we introduce a simplified yet representative hierarchical data-generation framework called the Syntax-Knowledge model. Under the Bayesian setting, we show that prediction and compression within this model naturally lead to diverse learning and scaling behaviors of LLMs. In particular, our theoretical analysis offers intuitive and principled explanations for both data and model scaling laws, the dynamics of knowledge acquisition during training and fine-tuning, factual knowledge hallucinations in LLMs. The experimental results validate our theoretical predictions.","authors":["Zhixuan Pan","Shaowen Wang","Jian Li"],"url":"https://arxiv.org/abs/2504.09597"}
{"created":"2025-04-22","title":"EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety","abstract":"The rise of LLM-driven AI characters raises safety concerns, particularly for vulnerable human users with psychological disorders. To address these risks, we propose EmoAgent, a multi-agent AI framework designed to evaluate and mitigate mental health hazards in human-AI interactions. EmoAgent comprises two components: EmoEval simulates virtual users, including those portraying mentally vulnerable individuals, to assess mental health changes before and after interactions with AI characters. It uses clinically proven psychological and psychiatric assessment tools (PHQ-9, PDI, PANSS) to evaluate mental risks induced by LLM. EmoGuard serves as an intermediary, monitoring users' mental status, predicting potential harm, and providing corrective feedback to mitigate risks. Experiments conducted in popular character-based chatbots show that emotionally engaging dialogues can lead to psychological deterioration in vulnerable users, with mental state deterioration in more than 34.4% of the simulations. EmoGuard significantly reduces these deterioration rates, underscoring its role in ensuring safer AI-human interactions. Our code is available at: https://github.com/1akaman/EmoAgent","authors":["Jiahao Qiu","Yinghui He","Xinzhe Juan","Yiming Wang","Yuhan Liu","Zixin Yao","Yue Wu","Xun Jiang","Ling Yang","Mengdi Wang"],"url":"https://arxiv.org/abs/2504.09689"}
{"created":"2025-04-22","title":"SegOTA: Accelerating Over-the-Air Federated Learning with Segmented Transmission","abstract":"Federated learning (FL) with over-the-air computation efficiently utilizes the communication resources, but it can still experience significant latency when each device transmits a large number of model parameters to the server. This paper proposes the Segmented Over-The-Air (SegOTA) method for FL, which reduces latency by partitioning devices into groups and letting each group transmit only one segment of the model parameters in each communication round. Considering a multi-antenna server, we model the SegOTA transmission and reception process to establish an upper bound on the expected model learning optimality gap. We minimize this upper bound, by formulating the per-round online optimization of device grouping and joint transmit-receive beamforming, for which we derive efficient closed-form solutions. Simulation results show that our proposed SegOTA substantially outperforms the conventional full-model OTA approach and other common alternatives.","authors":["Chong Zhang","Min Dong","Ben Liang","Ali Afana","Yahia Ahmed"],"url":"https://arxiv.org/abs/2504.09745"}
{"created":"2025-04-22","title":"Understanding and Optimizing Multi-Stage AI Inference Pipelines","abstract":"The rapid evolution of Large Language Models (LLMs) has driven the need for increasingly sophisticated inference pipelines and hardware platforms. Modern LLM serving extends beyond traditional prefill-decode workflows, incorporating multi-stage processes such as Retrieval Augmented Generation (RAG), key-value (KV) cache retrieval, dynamic model routing, and multi step reasoning. These stages exhibit diverse computational demands, requiring distributed systems that integrate GPUs, ASICs, CPUs, and memory-centric architectures. However, existing simulators lack the fidelity to model these heterogeneous, multi-engine workflows, limiting their ability to inform architectural decisions.","authors":["Abhimanyu Rajeshkumar Bambhaniya","Hanjiang Wu","Suvinay Subramanian","Sudarshan Srinivasan","Souvik Kundu","Amir Yazdanbakhsh","Midhilesh Elavazhagan","Madhu Kumar","Tushar Krishna"],"url":"https://arxiv.org/abs/2504.09775"}
{"created":"2025-04-22","title":"FUSION: Fully Integration of Vision-Language Representations for Deep Cross-Modal Understanding","abstract":"We introduce FUSION, a family of multimodal large language models (MLLMs) with a fully vision-language alignment and integration paradigm. Unlike existing methods that primarily rely on late-stage modality interaction during LLM decoding, our approach achieves deep, dynamic integration throughout the entire processing pipeline. To this end, we propose Text-Guided Unified Vision Encoding, incorporating textual information in vision encoding to achieve pixel-level integration. We further design Context-Aware Recursive Alignment Decoding that recursively aggregates visual features conditioned on textual context during decoding, enabling fine-grained, question-level semantic integration. To guide feature mapping and mitigate modality discrepancies, we develop Dual-Supervised Semantic Mapping Loss. Additionally, we construct a Synthesized Language-Driven Question-Answer (QA) dataset through a new data synthesis method, prioritizing high-quality QA pairs to optimize text-guided feature integration. Building on these foundations, we train FUSION at two scales-3B, 8B-and demonstrate that our full-modality integration approach significantly outperforms existing methods with only 630 vision tokens. Notably, FUSION 3B surpasses Cambrian-1 8B and Florence-VL 8B on most benchmarks. FUSION 3B continues to outperform Cambrian-1 8B even when limited to 300 vision tokens. Our ablation studies show that FUSION outperforms LLaVA-NeXT on over half of the benchmarks under same configuration without dynamic resolution, highlighting the effectiveness of our approach. We release our code, model weights, and dataset. https://github.com/starriver030515/FUSION","authors":["Zheng Liu","Mengjie Liu","Jingzhou Chen","Jingwei Xu","Bin Cui","Conghui He","Wentao Zhang"],"url":"https://arxiv.org/abs/2504.09925"}
{"created":"2025-04-22","title":"TianQuan-Climate: A Subseasonal-to-Seasonal Global Weather Model via Incorporate Climatology State","abstract":"Subseasonal forecasting serves as an important support for Sustainable Development Goals (SDGs), such as climate challenges, agricultural yield and sustainable energy production. However, subseasonal forecasting is a complex task in meteorology due to dissipating initial conditions and delayed external forces. Although AI models are increasingly pushing the boundaries of this forecasting limit, they face two major challenges: error accumulation and Smoothness. To address these two challenges, we propose Climate Furnace Subseasonal-to-Seasonal (TianQuan-Climate), a novel machine learning model designed to provide global daily mean forecasts up to 45 days, covering five upper-air atmospheric variables at 13 pressure levels and two surface variables. Our proposed TianQuan-Climate has two advantages: 1) it utilizes a multi-model prediction strategy to reduce system error impacts in long-term subseasonal forecasts; 2) it incorporates a Content Fusion Module for climatological integration and extends ViT with uncertainty blocks (UD-ViT) to improve generalization by learning from uncertainty. We demonstrate the effectiveness of TianQuan-Climate on benchmarks for weather forecasting and climate projections within the 15 to 45-day range, where TianQuan-Climate outperforms existing numerical and AI methods.","authors":["Guowen Li","Xintong Liu","Shilei Cao","Haoyuan Liang","Mengxuan Chen","Lixian Zhang","Jinxiao Zhang","Jiuke Wang","Meng Jin","Juepeng Zheng"],"url":"https://arxiv.org/abs/2504.09940"}
{"created":"2025-04-22","title":"Proofs of Useful Work from Arbitrary Matrix Multiplication","abstract":"We revisit the longstanding open problem of implementing Nakamoto's proof-of-work (PoW) consensus based on a real-world computational task $T(x)$ (as opposed to artificial random hashing), in a truly permissionless setting where the miner itself chooses the input $x$. The challenge in designing such a Proof-of-Useful-Work (PoUW) protocol, is using the native computation of $T(x)$ to produce a PoW certificate with prescribed hardness and with negligible computational overhead over the worst-case complexity of $T(\\cdot)$ -- This ensures malicious miners cannot ``game the system\" by fooling the verifier to accept with higher probability compared to honest miners (while using similar computational resources). Indeed, obtaining a PoUW with $O(1)$-factor overhead is trivial for any task $T$, but also useless.","authors":["Ilan Komargodski","Itamar Schen","Omri Weinstein"],"url":"https://arxiv.org/abs/2504.09971"}
{"created":"2025-04-22","title":"Emotional Strain and Frustration in LLM Interactions in Software Engineering","abstract":"Large Language Models (LLMs) are increasingly integrated into various daily tasks in Software Engineering such as coding and requirement elicitation. Despite their various capabilities and constant use, some interactions can lead to unexpected challenges (e.g. hallucinations or verbose answers) and, in turn, cause emotions that develop into frustration. Frustration can negatively impact engineers' productivity and well-being if they escalate into stress and burnout. In this paper, we assess the impact of LLM interactions on software engineers' emotional responses, specifically strains, and identify common causes of frustration when interacting with LLMs at work. Based on 62 survey responses from software engineers in industry and academia across various companies and universities, we found that a majority of our respondents experience frustrations or other related emotions regardless of the nature of their work. Additionally, our results showed that frustration mainly stemmed from issues with correctness and less critical issues such as adaptability to context or specific format. While such issues may not cause frustration in general, artefacts that do not follow certain preferences, standards, or best practices can make the output unusable without extensive modification, causing frustration over time. In addition to the frustration triggers, our study offers guidelines to improve the software engineers' experience, aiming to minimise long-term consequences on mental health.","authors":["Cristina Martinez Montes","Ranim Khojah"],"url":"https://arxiv.org/abs/2504.10050"}
{"created":"2025-04-22","title":"MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation Framework","abstract":"Recent advancements in large language models (LLMs) and multi-modal LLMs have been remarkable. However, these models still rely solely on their parametric knowledge, which limits their ability to generate up-to-date information and increases the risk of producing erroneous content. Retrieval-Augmented Generation (RAG) partially mitigates these challenges by incorporating external data sources, yet the reliance on databases and retrieval systems can introduce irrelevant or inaccurate documents, ultimately undermining both performance and reasoning quality. In this paper, we propose Multi-Modal Knowledge-Based Retrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework that leverages the inherent knowledge boundaries of models to dynamically generate semantic tags for the retrieval process. This strategy enables the joint filtering of retrieved documents, retaining only the most relevant and accurate references. Extensive experiments on knowledge-based visual question-answering tasks demonstrate the efficacy of our approach: on the E-VQA dataset, our method improves performance by +4.2% on the Single-Hop subset and +0.4% on the full dataset, while on the InfoSeek dataset, it achieves gains of +7.8% on the Unseen-Q subset, +8.2% on the Unseen-E subset, and +8.1% on the full dataset. These results highlight significant enhancements in both accuracy and robustness over the current state-of-the-art MLLM and RAG frameworks.","authors":["Zihan Ling","Zhiyao Guo","Yixuan Huang","Yi An","Shuai Xiao","Jinsong Lan","Xiaoyong Zhu","Bo Zheng"],"url":"https://arxiv.org/abs/2504.10074"}
{"created":"2025-04-22","title":"Hierarchical and Step-Layer-Wise Tuning of Attention Specialty for Multi-Instance Synthesis in Diffusion Transformers","abstract":"Text-to-image (T2I) generation models often struggle with multi-instance synthesis (MIS), where they must accurately depict multiple distinct instances in a single image based on complex prompts detailing individual features. Traditional MIS control methods for UNet architectures like SD v1.5/SDXL fail to adapt to DiT-based models like FLUX and SD v3.5, which rely on integrated attention between image and text tokens rather than text-image cross-attention. To enhance MIS in DiT, we first analyze the mixed attention mechanism in DiT. Our token-wise and layer-wise analysis of attention maps reveals a hierarchical response structure: instance tokens dominate early layers, background tokens in middle layers, and attribute tokens in later layers. Building on this observation, we propose a training-free approach for enhancing MIS in DiT-based models with hierarchical and step-layer-wise attention specialty tuning (AST). AST amplifies key regions while suppressing irrelevant areas in distinct attention maps across layers and steps, guided by the hierarchical structure. This optimizes multimodal interactions by hierarchically decoupling the complex prompts with instance-based sketches. We evaluate our approach using upgraded sketch-based layouts for the T2I-CompBench and customized complex scenes. Both quantitative and qualitative results confirm our method enhances complex layout generation, ensuring precise instance placement and attribute representation in MIS.","authors":["Chunyang Zhang","Zhenhong Sun","Zhicheng Zhang","Junyan Wang","Yu Zhang","Dong Gong","Huadong Mo","Daoyi Dong"],"url":"https://arxiv.org/abs/2504.10148"}
{"created":"2025-04-22","title":"InstructEngine: Instruction-driven Text-to-Image Alignment","abstract":"Reinforcement Learning from Human/AI Feedback (RLHF/RLAIF) has been extensively utilized for preference alignment of text-to-image models. Existing methods face certain limitations in terms of both data and algorithm. For training data, most approaches rely on manual annotated preference data, either by directly fine-tuning the generators or by training reward models to provide training signals. However, the high annotation cost makes them difficult to scale up, the reward model consumes extra computation and cannot guarantee accuracy. From an algorithmic perspective, most methods neglect the value of text and only take the image feedback as a comparative signal, which is inefficient and sparse. To alleviate these drawbacks, we propose the InstructEngine framework. Regarding annotation cost, we first construct a taxonomy for text-to-image generation, then develop an automated data construction pipeline based on it. Leveraging advanced large multimodal models and human-defined rules, we generate 25K text-image preference pairs. Finally, we introduce cross-validation alignment method, which refines data efficiency by organizing semantically analogous samples into mutually comparable pairs. Evaluations on DrawBench demonstrate that InstructEngine improves SD v1.5 and SDXL's performance by 10.53% and 5.30%, outperforming state-of-the-art baselines, with ablation study confirming the benefits of InstructEngine's all components. A win rate of over 50% in human reviews also proves that InstructEngine better aligns with human preferences.","authors":["Xingyu Lu","Yuhang Hu","YiFan Zhang","Kaiyu Jiang","Changyi Liu","Tianke Zhang","Jinpeng Wang","Chun Yuan","Bin Wen","Fan Yang","Tingting Gao","Di Zhang"],"url":"https://arxiv.org/abs/2504.10329"}
{"created":"2025-04-22","title":"LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian Splatting for Novel View Synthesis","abstract":"Novel view synthesis (NVS) in low-light scenes remains a significant challenge due to degraded inputs characterized by severe noise, low dynamic range (LDR) and unreliable initialization. While recent NeRF-based approaches have shown promising results, most suffer from high computational costs, and some rely on carefully captured or pre-processed data--such as RAW sensor inputs or multi-exposure sequences--which severely limits their practicality. In contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering with competitive visual fidelity; however, existing 3DGS-based methods struggle with low-light sRGB inputs, resulting in unstable Gaussian initialization and ineffective noise suppression. To address these challenges, we propose LL-Gaussian, a novel framework for 3D reconstruction and enhancement from low-light sRGB images, enabling pseudo normal-light novel view synthesis. Our method introduces three key innovations: 1) an end-to-end Low-Light Gaussian Initialization Module (LLGIM) that leverages dense priors from learning-based MVS approach to generate high-quality initial point clouds; 2) a dual-branch Gaussian decomposition model that disentangles intrinsic scene properties (reflectance and illumination) from transient interference, enabling stable and interpretable optimization; 3) an unsupervised optimization strategy guided by both physical constrains and diffusion prior to jointly steer decomposition and enhancement. Additionally, we contribute a challenging dataset collected in extreme low-light environments and demonstrate the effectiveness of LL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussian achieves up to 2,000 times faster inference and reduces training time to just 2%, while delivering superior reconstruction and rendering quality.","authors":["Hao Sun","Fenggen Yu","Huiyao Xu","Tao Zhang","Changqing Zou"],"url":"https://arxiv.org/abs/2504.10331"}
{"created":"2025-04-22","title":"Forecasting from Clinical Textual Time Series: Adaptations of the Encoder and Decoder Language Model Families","abstract":"Clinical case reports encode rich, temporal patient trajectories that are often underexploited by traditional machine learning methods relying on structured data. In this work, we introduce the forecasting problem from textual time series, where timestamped clinical findings -- extracted via an LLM-assisted annotation pipeline -- serve as the primary input for prediction. We systematically evaluate a diverse suite of models, including fine-tuned decoder-based large language models and encoder-based transformers, on tasks of event occurrence prediction, temporal ordering, and survival analysis. Our experiments reveal that encoder-based models consistently achieve higher F1 scores and superior temporal concordance for short- and long-horizon event forecasting, while fine-tuned masking approaches enhance ranking performance. In contrast, instruction-tuned decoder models demonstrate a relative advantage in survival analysis, especially in early prognosis settings. Our sensitivity analyses further demonstrate the importance of time ordering, which requires clinical time series construction, as compared to text ordering, the format of the text inputs that LLMs are classically trained on. This highlights the additional benefit that can be ascertained from time-ordered corpora, with implications for temporal tasks in the era of widespread LLM use.","authors":["Shahriar Noroozizadeh","Sayantan Kumar","Jeremy C. Weiss"],"url":"https://arxiv.org/abs/2504.10340"}
{"created":"2025-04-22","title":"Satellite Federated Fine-Tuning for Foundation Models in Space Computing Power Networks","abstract":"Advancements in artificial intelligence (AI) and low-earth orbit (LEO) satellites have promoted the application of large remote sensing foundation models for various downstream tasks. However, direct downloading of these models for fine-tuning on the ground is impeded by privacy concerns and limited bandwidth. Satellite federated learning (FL) offers a solution by enabling model fine-tuning directly on-board satellites and aggregating model updates without data downloading. Nevertheless, for large foundation models, the computational capacity of satellites is insufficient to support effective on-board fine-tuning in traditional satellite FL frameworks. To address these challenges, we propose a satellite-ground collaborative federated fine-tuning framework. The key of the framework lies in how to reasonably decompose and allocate model components to alleviate insufficient on-board computation capabilities. During fine-tuning, satellites exchange intermediate results with ground stations or other satellites for forward propagation and back propagation, which brings communication challenges due to the special communication topology of space transmission networks, such as intermittent satellite-ground communication, short duration of satellite-ground communication windows, and unstable inter-orbit inter-satellite links (ISLs). To reduce transmission delays, we further introduce tailored communication strategies that integrate both communication and computing resources. Specifically, we propose a parallel intra-orbit communication strategy, a topology-aware satellite-ground communication strategy, and a latency-minimalization inter-orbit communication strategy to reduce space communication costs. Simulation results demonstrate significant reductions in training time with improvements of approximately 33%.","authors":["Yan Zhu","Jingyang Zhu","Ting Wang","Yuanming Shi","Chunxiao Jiang","Khaled Ben Letaief"],"url":"https://arxiv.org/abs/2504.10403"}
{"created":"2025-04-22","title":"InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models","abstract":"We introduce InternVL3, a significant advancement in the InternVL series featuring a native multimodal pre-training paradigm. Rather than adapting a text-only large language model (LLM) into a multimodal large language model (MLLM) that supports visual inputs, InternVL3 jointly acquires multimodal and linguistic capabilities from both diverse multimodal data and pure-text corpora during a single pre-training stage. This unified training paradigm effectively addresses the complexities and alignment challenges commonly encountered in conventional post-hoc training pipelines for MLLMs. To further improve performance and scalability, InternVL3 incorporates variable visual position encoding (V2PE) to support extended multimodal contexts, employs advanced post-training techniques such as supervised fine-tuning (SFT) and mixed preference optimization (MPO), and adopts test-time scaling strategies alongside an optimized training infrastructure. Extensive empirical evaluations demonstrate that InternVL3 delivers superior performance across a wide range of multi-modal tasks. In particular, InternVL3-78B achieves a score of 72.2 on the MMMU benchmark, setting a new state-of-the-art among open-source MLLMs. Its capabilities remain highly competitive with leading proprietary models, including ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro, while also maintaining strong pure-language proficiency. In pursuit of open-science principles, we will publicly release both the training data and model weights to foster further research and development in next-generation MLLMs.","authors":["Jinguo Zhu","Weiyun Wang","Zhe Chen","Zhaoyang Liu","Shenglong Ye","Lixin Gu","Hao Tian","Yuchen Duan","Weijie Su","Jie Shao","Zhangwei Gao","Erfei Cui","Xuehui Wang","Yue Cao","Yangzhou Liu","Xingguang Wei","Hongjie Zhang","Haomin Wang","Weiye Xu","Hao Li","Jiahao Wang","Nianchen Deng","Songze Li","Yinan He","Tan Jiang","Jiapeng Luo","Yi Wang","Conghui He","Botian Shi","Xingcheng Zhang","Wenqi Shao","Junjun He","Yingtong Xiong","Wenwen Qu","Peng Sun","Penglong Jiao","Han Lv","Lijun Wu","Kaipeng Zhang","Huipeng Deng","Jiaye Ge","Kai Chen","Limin Wang","Min Dou","Lewei Lu","Xizhou Zhu","Tong Lu","Dahua Lin","Yu Qiao","Jifeng Dai","Wenhai Wang"],"url":"https://arxiv.org/abs/2504.10479"}
{"created":"2025-04-22","title":"TrustMap: Mapping Truthfulness Stance of Social Media Posts on Factual Claims for Geographical Analysis","abstract":"Factual claims and misinformation circulate widely on social media and affect how people form opinions and make decisions. This paper presents a truthfulness stance map (TrustMap), an application that identifies and maps public stances toward factual claims across U.S. regions. Each social media post is classified as positive, negative, or neutral/no stance, based on whether it believes a factual claim is true or false, expresses uncertainty about the truthfulness, or does not explicitly take a position on the claim's truthfulness. The tool uses a retrieval-augmented model with fine-tuned language models for automatic stance classification. The stance classification results and social media posts are grouped by location to show how stance patterns vary geographically. TrustMap allows users to explore these patterns by claim and region and connects stance detection with geographical analysis to better understand public engagement with factual claims.","authors":["Zhengyuan Zhu","Haiqi Zhang","Zeyu Zhang","Chengkai Li"],"url":"https://arxiv.org/abs/2504.10511"}
{"created":"2025-04-22","title":"Emotion Alignment: Discovering the Gap Between Social Media and Real-World Sentiments in Persian Tweets and Images","abstract":"In contemporary society, widespread social media usage is evident in people's daily lives. Nevertheless, disparities in emotional expressions between the real world and online platforms can manifest. We comprehensively analyzed Persian community on X to explore this phenomenon. An innovative pipeline was designed to measure the similarity between emotions in the real world compared to social media. Accordingly, recent tweets and images of participants were gathered and analyzed using Transformers-based text and image sentiment analysis modules. Each participant's friends also provided insights into the their real-world emotions. A distance criterion was used to compare real-world feelings with virtual experiences. Our study encompassed N=105 participants, 393 friends who contributed their perspectives, over 8,300 collected tweets, and 2,000 media images. Results indicated a 28.67% similarity between images and real-world emotions, while tweets exhibited a 75.88% alignment with real-world feelings. Additionally, the statistical significance confirmed that the observed disparities in sentiment proportions.","authors":["Sina Elahimanesh","Mohammadali Mohammadkhani","Shohreh Kasaei"],"url":"https://arxiv.org/abs/2504.10662"}
{"created":"2025-04-22","title":"Characterizing Knowledge Manipulation in a Russian Wikipedia Fork","abstract":"Wikipedia is powered by MediaWiki, a free and open-source software that is also the infrastructure for many other wiki-based online encyclopedias. These include the recently launched website Ruwiki, which has copied and modified the original Russian Wikipedia content to conform to Russian law. To identify practices and narratives that could be associated with different forms of knowledge manipulation, this article presents an in-depth analysis of this Russian Wikipedia fork. We propose a methodology to characterize the main changes with respect to the original version. The foundation of this study is a comprehensive comparative analysis of more than 1.9M articles from Russian Wikipedia and its fork. Using meta-information and geographical, temporal, categorical, and textual features, we explore the changes made by Ruwiki editors. Furthermore, we present a classification of the main topics of knowledge manipulation in this fork, including a numerical estimation of their scope. This research not only sheds light on significant changes within Ruwiki, but also provides a methodology that could be applied to analyze other Wikipedia forks and similar collaborative projects.","authors":["Mykola Trokhymovych","Oleksandr Kosovan","Nathan Forrester","Pablo Arag\\'on","Diego Saez-Trumper","Ricardo Baeza-Yates"],"url":"https://arxiv.org/abs/2504.10663"}
{"created":"2025-04-22","title":"Power-scaled Bayesian Inference with Score-based Generative Models","abstract":"We propose a score-based generative algorithm for sampling from power-scaled priors and likelihoods within the Bayesian inference framework. Our algorithm enables flexible control over prior-likelihood influence without requiring retraining for different power-scaling configurations. Specifically, we focus on synthesizing seismic velocity models conditioned on imaged seismic. Our method enables sensitivity analysis by sampling from intermediate power posteriors, allowing us to assess the relative influence of the prior and likelihood on samples of the posterior distribution. Through a comprehensive set of experiments, we evaluate the effects of varying the power parameter in different settings: applying it solely to the prior, to the likelihood of a Bayesian formulation, and to both simultaneously. The results show that increasing the power of the likelihood up to a certain threshold improves the fidelity of posterior samples to the conditioning data (e.g., seismic images), while decreasing the prior power promotes greater structural diversity among samples. Moreover, we find that moderate scaling of the likelihood leads to a reduced shot data residual, confirming its utility in posterior refinement.","authors":["Huseyin Tuna Erdinc","Yunlin Zeng","Abhinav Prakash Gahlot","Felix J. Herrmann"],"url":"https://arxiv.org/abs/2504.10807"}
{"created":"2025-04-22","title":"A comprehensive review of remote sensing in wetland classification and mapping","abstract":"Wetlands constitute critical ecosystems that support both biodiversity and human well-being; however, they have experienced a significant decline since the 20th century. Back in the 1970s, researchers began to employ remote sensing technologies for wetland classification and mapping to elucidate the extent and variations of wetlands. Although some review articles summarized the development of this field, there is a lack of a thorough and in-depth understanding of wetland classification and mapping: (1) the scientific importance of wetlands, (2) major data, methods used in wetland classification and mapping, (3) driving factors of wetland changes, (4) current research paradigm and limitations, (5) challenges and opportunities in wetland classification and mapping under the context of technological innovation and global environmental change. In this review, we aim to provide a comprehensive perspective and new insights into wetland classification and mapping for readers to answer these questions. First, we conduct a meta-analysis of over 1,200 papers, encompassing wetland types, methods, sensor types, and study sites, examining prevailing trends in wetland classification and mapping. Next, we review and synthesize the wetland features and existing data and methods in wetland classification and mapping. We also summarize typical wetland mapping products and explore the intrinsic driving factors of wetland changes across multiple spatial and temporal scales. Finally, we discuss current limitations and propose future directions in response to global environmental change and technological innovation. This review consolidates our understanding of wetland remote sensing and offers scientific recommendations that foster transformative progress in wetland science.","authors":["Shuai Yuan","Xiangan Liang","Tianwu Lin","Shuang Chen","Rui Liu","Jie Wang","Hongsheng Zhang","Peng Gong"],"url":"https://arxiv.org/abs/2504.10842"}
{"created":"2025-04-22","title":"A Pseudorandom Generator for Functions of Low-Degree Polynomial Threshold Functions","abstract":"Developing explicit pseudorandom generators (PRGs) for prominent categories of Boolean functions is a key focus in computational complexity theory. In this paper, we investigate the PRGs against the functions of degree-$d$ polynomial threshold functions (PTFs) over Gaussian space. Our main result is an explicit construction of PRG with seed length $\\mathrm{poly}(k,d,1/\\epsilon)\\cdot\\log n$ that can fool any function of $k$ degree-$d$ PTFs with probability at least $1-\\varepsilon$. More specifically, we show that the summation of $L$ independent $R$-moment-matching Gaussian vectors $\\epsilon$-fools functions of $k$ degree-$d$ PTFs, where $L=\\mathrm{poly}( k, d, \\frac{1}{\\epsilon})$ and $R = O({\\log \\frac{kd}{\\epsilon}})$. The PRG is then obtained by applying an appropriate discretization to Gaussian vectors with bounded independence.","authors":["Penghui Yao","Mingnan Zhao"],"url":"https://arxiv.org/abs/2504.10904"}
{"created":"2025-04-22","title":"An Efficient and Mixed Heterogeneous Model for Image Restoration","abstract":"Image restoration~(IR), as a fundamental multimedia data processing task, has a significant impact on downstream visual applications. In recent years, researchers have focused on developing general-purpose IR models capable of handling diverse degradation types, thereby reducing the cost and complexity of model development. Current mainstream approaches are based on three architectural paradigms: CNNs, Transformers, and Mambas. CNNs excel in efficient inference, whereas Transformers and Mamba excel at capturing long-range dependencies and modeling global contexts. While each architecture has demonstrated success in specialized, single-task settings, limited efforts have been made to effectively integrate heterogeneous architectures to jointly address diverse IR challenges. To bridge this gap, we propose RestorMixer, an efficient and general-purpose IR model based on mixed-architecture fusion. RestorMixer adopts a three-stage encoder-decoder structure, where each stage is tailored to the resolution and feature characteristics of the input. In the initial high-resolution stage, CNN-based blocks are employed to rapidly extract shallow local features. In the subsequent stages, we integrate a refined multi-directional scanning Mamba module with a multi-scale window-based self-attention mechanism. This hierarchical and adaptive design enables the model to leverage the strengths of CNNs in local feature extraction, Mamba in global context modeling, and attention mechanisms in dynamic feature refinement. Extensive experimental results demonstrate that RestorMixer achieves leading performance across multiple IR tasks while maintaining high inference efficiency. The official code can be accessed at https://github.com/ClimBin/RestorMixer.","authors":["Yubin Gu","Yuan Meng","Kaihang Zheng","Xiaoshuai Sun","Jiayi Ji","Weijian Ruan","Liujuan Cao","Rongrong Ji"],"url":"https://arxiv.org/abs/2504.10967"}
{"created":"2025-04-22","title":"GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*","abstract":"The emerging trend in computer vision emphasizes developing universal models capable of simultaneously addressing multiple diverse tasks. Such universality typically requires joint training across multi-domain datasets to ensure effective generalization. However, monocular 3D object detection presents unique challenges in multi-domain training due to the scarcity of datasets annotated with accurate 3D ground-truth labels, especially beyond typical road-based autonomous driving contexts. To address this challenge, we introduce a novel weakly supervised framework leveraging pseudo-labels. Current pretrained models often struggle to accurately detect pedestrians in non-road environments due to inherent dataset biases. Unlike generalized image-based 2D object detection models, achieving similar generalization in monocular 3D detection remains largely unexplored. In this paper, we propose GATE3D, a novel framework designed specifically for generalized monocular 3D object detection via weak supervision. GATE3D effectively bridges domain gaps by employing consistency losses between 2D and 3D predictions. Remarkably, our model achieves competitive performance on the KITTI benchmark as well as on an indoor-office dataset collected by us to evaluate the generalization capabilities of our framework. Our results demonstrate that GATE3D significantly accelerates learning from limited annotated data through effective pre-training strategies, highlighting substantial potential for broader impacts in robotics, augmented reality, and virtual reality applications. Project page: https://ies0411.github.io/GATE3D/","authors":["Eunsoo Im","Changhyun Jee","Jung Kwon Lee"],"url":"https://arxiv.org/abs/2504.11014"}
{"created":"2025-04-22","title":"Slice+Slice Baby: Generating Last-Level Cache Eviction Sets in the Blink of an Eye","abstract":"An essential step for mounting cache attacks is finding eviction sets, collections of memory locations that contend on cache space. On Intel processors, one of the main challenges for identifying contending addresses is the sliced cache design, where the processor hashes the physical address to determine where in the cache a memory location is stored. While past works have demonstrated that the hash function can be reversed, they also showed that it depends on physical address bits that the adversary does not know.","authors":["Bradley Morgan","Gal Horowitz","Sioli O'Connell","Stephan van Schaik","Chitchanok Chuengsatiansup","Daniel Genkin","Olaf Maennel","Paul Montague","Eyal Ronen","Yuval Yarom"],"url":"https://arxiv.org/abs/2504.11208"}
{"created":"2025-04-22","title":"PVUW 2025 Challenge Report: Advances in Pixel-level Understanding of Complex Videos in the Wild","abstract":"This report provides a comprehensive overview of the 4th Pixel-level Video Understanding in the Wild (PVUW) Challenge, held in conjunction with CVPR 2025. It summarizes the challenge outcomes, participating methodologies, and future research directions. The challenge features two tracks: MOSE, which focuses on complex scene video object segmentation, and MeViS, which targets motion-guided, language-based video segmentation. Both tracks introduce new, more challenging datasets designed to better reflect real-world scenarios. Through detailed evaluation and analysis, the challenge offers valuable insights into the current state-of-the-art and emerging trends in complex video segmentation. More information can be found on the workshop website: https://pvuw.github.io/.","authors":["Henghui Ding","Chang Liu","Nikhila Ravi","Shuting He","Yunchao Wei","Song Bai","Philip Torr","Kehuan Song","Xinglin Xie","Kexin Zhang","Licheng Jiao","Lingling Li","Shuyuan Yang","Xuqiang Cao","Linnan Zhao","Jiaxuan Zhao","Fang Liu","Mengjiao Wang","Junpei Zhang","Xu Liu","Yuting Yang","Mengru Ma","Hao Fang","Runmin Cong","Xiankai Lu","Zhiyang Chen","Wei Zhang","Tianming Liang","Haichao Jiang","Wei-Shi Zheng","Jian-Fang Hu","Haobo Yuan","Xiangtai Li","Tao Zhang","Lu Qi","Ming-Hsuan Yang"],"url":"https://arxiv.org/abs/2504.11326"}
{"created":"2025-04-22","title":"A Mathematical Framework of Semantic Communication based on Category Theory","abstract":"While semantic communication (SemCom) has recently demonstrated great potential to enhance transmission efficiency and reliability by leveraging machine learning (ML) and knowledge base (KB), there is a lack of mathematical modeling to rigorously characterize SemCom system and quantify the performance gain obtained from ML and KB. In this paper, we develop a mathematical framework for SemCom based on category theory, rigorously modeling the concepts of semantic entities and semantic probability space. Within this framework, we introduce the semantic entropy to quantify the uncertainty of semantic entities. We theoretically prove that semantic entropy can be effectively reduced by exploiting KBs, which capture semantic dependencies. Within the formulated semantic space, semantic entities can be combined according to the required semantic ambiguity, and the combined entities can be encoded based on semantic dependencies obtained from KB. Then, we derive semantic channel capacity modeling, which incorporates the mutual information obtained in KB to accurately measure the transmission efficiency of SemCom. Numerical simulations validate the effectiveness of the proposed framework, showing that SemCom with KB integration outperforms traditional communication in both entropy reduction and coding efficiency.","authors":["Shuheng Hua","Yao Sun","Kairong Ma","Dusit Niyato","Muhammad Ali Imran"],"url":"https://arxiv.org/abs/2504.11334"}
{"created":"2025-04-22","title":"Interpretable Hybrid-Rule Temporal Point Processes","abstract":"Temporal Point Processes (TPPs) are widely used for modeling event sequences in various medical domains, such as disease onset prediction, progression analysis, and clinical decision support. Although TPPs effectively capture temporal dynamics, their lack of interpretability remains a critical challenge. Recent advancements have introduced interpretable TPPs. However, these methods fail to incorporate numerical features, thereby limiting their ability to generate precise predictions. To address this issue, we propose Hybrid-Rule Temporal Point Processes (HRTPP), a novel framework that integrates temporal logic rules with numerical features, improving both interpretability and predictive accuracy in event modeling. HRTPP comprises three key components: basic intensity for intrinsic event likelihood, rule-based intensity for structured temporal dependencies, and numerical feature intensity for dynamic probability modulation. To effectively discover valid rules, we introduce a two-phase rule mining strategy with Bayesian optimization. To evaluate our method, we establish a multi-criteria assessment framework, incorporating rule validity, model fitting, and temporal predictive accuracy. Experimental results on real-world medical datasets demonstrate that HRTPP outperforms state-of-the-art interpretable TPPs in terms of predictive performance and clinical interpretability. In case studies, the rules extracted by HRTPP explain the disease progression, offering valuable contributions to medical diagnosis.","authors":["Yunyang Cao","Juekai Lin","Hongye Wang","Wenhao Li","Bo Jin"],"url":"https://arxiv.org/abs/2504.11344"}
{"created":"2025-04-22","title":"MultiCore+TPU Accelerated Multi-Modal TinyML for Livestock Behaviour Recognition","abstract":"The advancement of technology has revolutionised the agricultural industry, transitioning it from labour-intensive farming practices to automated, AI-powered management systems. In recent years, more intelligent livestock monitoring solutions have been proposed to enhance farming efficiency and productivity. This work presents a novel approach to animal activity recognition and movement tracking, leveraging tiny machine learning (TinyML) techniques, wireless communication framework, and microcontroller platforms to develop an efficient, cost-effective livestock sensing system. It collects and fuses accelerometer data and vision inputs to build a multi-modal network for three tasks: image classification, object detection, and behaviour recognition. The system is deployed and evaluated on commercial microcontrollers for real-time inference using embedded applications, demonstrating up to 270$\\times$ model size reduction, less than 80ms response latency, and on-par performance comparable to existing methods. The incorporation of the TinyML technique allows for seamless data transmission between devices, benefiting use cases in remote locations with poor Internet connectivity. This work delivers a robust, scalable IoT-edge livestock monitoring solution adaptable to diverse farming needs, offering flexibility for future extensions.","authors":["Qianxue Zhang","Eiman Kanjo"],"url":"https://arxiv.org/abs/2504.11467"}
{"created":"2025-04-22","title":"Flux Already Knows -- Activating Subject-Driven Image Generation without Training","abstract":"We propose a simple yet effective zero-shot framework for subject-driven image generation using a vanilla Flux model. By framing the task as grid-based image completion and simply replicating the subject image(s) in a mosaic layout, we activate strong identity-preserving capabilities without any additional data, training, or inference-time fine-tuning. This \"free lunch\" approach is further strengthened by a novel cascade attention design and meta prompting technique, boosting fidelity and versatility. Experimental results show that our method outperforms baselines across multiple key metrics in benchmarks and human preference studies, with trade-offs in certain aspects. Additionally, it supports diverse edits, including logo insertion, virtual try-on, and subject replacement or insertion. These results demonstrate that a pre-trained foundational text-to-image model can enable high-quality, resource-efficient subject-driven generation, opening new possibilities for lightweight customization in downstream applications.","authors":["Hao Kang","Stathi Fotiadis","Liming Jiang","Qing Yan","Yumin Jia","Zichuan Liu","Min Jin Chong","Xin Lu"],"url":"https://arxiv.org/abs/2504.11478"}
{"created":"2025-04-22","title":"Counterfactual Fairness Evaluation of Machine Learning Models on Educational Datasets","abstract":"As machine learning models are increasingly used in educational settings, from detecting at-risk students to predicting student performance, algorithmic bias and its potential impacts on students raise critical concerns about algorithmic fairness. Although group fairness is widely explored in education, works on individual fairness in a causal context are understudied, especially on counterfactual fairness. This paper explores the notion of counterfactual fairness for educational data by conducting counterfactual fairness analysis of machine learning models on benchmark educational datasets. We demonstrate that counterfactual fairness provides meaningful insight into the causality of sensitive attributes and causal-based individual fairness in education.","authors":["Woojin Kim","Hyeoncheol Kim"],"url":"https://arxiv.org/abs/2504.11504"}
{"created":"2025-04-22","title":"E-morphic: Scalable Equality Saturation for Structural Exploration in Logic Synthesis","abstract":"In technology mapping, the quality of the final implementation heavily relies on the circuit structure after technology-independent optimization. Recent studies have introduced equality saturation as a novel optimization approach. However, its efficiency remains a hurdle against its wide adoption in logic synthesis. This paper proposes a highly scalable and efficient framework named E-morphic. It is the first work that employs equality saturation for resynthesis after conventional technology-independent logic optimizations, enabling structure exploration before technology mapping. Powered by several key enhancements to the equality saturation framework, such as direct e-graph-circuit conversion, solution-space pruning, and simulated annealing for e-graph extraction, this approach not only improves the scalability and extraction efficiency of e-graph rewriting but also addresses the structural bias issue present in conventional logic synthesis flows through parallel structural exploration and resynthesis. Experiments show that, compared to the state-of-the-art delay optimization flow in ABC, E-morphic on average achieves 12.54% area saving and 7.29% delay reduction on the large-scale circuits in the EPFL benchmark.","authors":["Chen Chen","Guangyu HU","Cunxi Yu","Yuzhe Ma","Hongce Zhang"],"url":"https://arxiv.org/abs/2504.11574"}
{"created":"2025-04-22","title":"DVLTA-VQA: Decoupled Vision-Language Modeling with Text-Guided Adaptation for Blind Video Quality Assessment","abstract":"Inspired by the dual-stream theory of the human visual system (HVS) - where the ventral stream is responsible for object recognition and detail analysis, while the dorsal stream focuses on spatial relationships and motion perception - an increasing number of video quality assessment (VQA) works built upon this framework are proposed. Recent advancements in large multi-modal models, notably Contrastive Language-Image Pretraining (CLIP), have motivated researchers to incorporate CLIP into dual-stream-based VQA methods. This integration aims to harness the model's superior semantic understanding capabilities to replicate the object recognition and detail analysis in ventral stream, as well as spatial relationship analysis in dorsal stream. However, CLIP is originally designed for images and lacks the ability to capture temporal and motion information inherent in videos. To address the limitation, this paper propose a Decoupled Vision-Language Modeling with Text-Guided Adaptation for Blind Video Quality Assessment (DVLTA-VQA), which decouples CLIP's visual and textual components, and integrates them into different stages of the NR-VQA pipeline. Specifically, a Video-Based Temporal CLIP module is proposed to explicitly model temporal dynamics and enhance motion perception, aligning with the dorsal stream. Additionally, a Temporal Context Module is developed to refine inter-frame dependencies, further improving motion modeling. On the ventral stream side, a Basic Visual Feature Extraction Module is employed to strengthen detail analysis. Finally, a text-guided adaptive fusion strategy is proposed to enable dynamic weighting of features, facilitating more effective integration of spatial and temporal information.","authors":["Li Yu","Situo Wang","Wei Zhou","Moncef Gabbouj"],"url":"https://arxiv.org/abs/2504.11733"}
{"created":"2025-04-22","title":"Selective Attention Federated Learning: Improving Privacy and Efficiency for Clinical Text Classification","abstract":"Federated Learning (FL) faces major challenges regarding communication overhead and model privacy when training large language models (LLMs), especially in healthcare applications. To address these, we introduce Selective Attention Federated Learning (SAFL), a novel approach that dynamically fine-tunes only those transformer layers identified as attention-critical. By employing attention patterns to determine layer importance, SAFL significantly reduces communication bandwidth and enhances differential privacy resilience. Evaluations on clinical NLP benchmarks (i2b2 Clinical Concept Extraction and MIMIC-III discharge summaries) demonstrate that SAFL achieves competitive performance with centralized models while substantially improving communication efficiency and privacy preservation.","authors":["Yue Li","Lihong Zhang"],"url":"https://arxiv.org/abs/2504.11793"}
{"created":"2025-04-22","title":"Zooming In on Fakes: A Novel Dataset for Localized AI-Generated Image Detection with Forgery Amplification Approach","abstract":"The rise of AI-generated image editing tools has made localized forgeries increasingly realistic, posing challenges for visual content integrity. Although recent efforts have explored localized AIGC detection, existing datasets predominantly focus on object-level forgeries while overlooking broader scene edits in regions such as sky or ground. To address these limitations, we introduce \\textbf{BR-Gen}, a large-scale dataset of 150,000 locally forged images with diverse scene-aware annotations, which are based on semantic calibration to ensure high-quality samples. BR-Gen is constructed through a fully automated Perception-Creation-Evaluation pipeline to ensure semantic coherence and visual realism. In addition, we further propose \\textbf{NFA-ViT}, a Noise-guided Forgery Amplification Vision Transformer that enhances the detection of localized forgeries by amplifying forgery-related features across the entire image. NFA-ViT mines heterogeneous regions in images, \\emph{i.e.}, potential edited areas, by noise fingerprints. Subsequently, attention mechanism is introduced to compel the interaction between normal and abnormal features, thereby propagating the generalization traces throughout the entire image, allowing subtle forgeries to influence a broader context and improving overall detection robustness. Extensive experiments demonstrate that BR-Gen constructs entirely new scenarios that are not covered by existing methods. Take a step further, NFA-ViT outperforms existing methods on BR-Gen and generalizes well across current benchmarks. All data and codes are available at https://github.com/clpbc/BR-Gen.","authors":["Lvpan Cai","Haowei Wang","Jiayi Ji","YanShu ZhouMen","Yiwei Ma","Xiaoshuai Sun","Liujuan Cao","Rongrong Ji"],"url":"https://arxiv.org/abs/2504.11922"}
{"created":"2025-04-22","title":"Large Language Models as Quasi-crystals: Coherence Without Repetition in Generative Text","abstract":"This essay proposes an interpretive analogy between large language models (LLMs) and quasicrystals, systems that exhibit global coherence without periodic repetition, generated through local constraints. While LLMs are typically evaluated in terms of predictive accuracy, factuality, or alignment, this structural perspective suggests that one of their most characteristic behaviors is the production of internally resonant linguistic patterns. Drawing on the history of quasicrystals, which forced a redefinition of structural order in physical systems, the analogy highlights an alternative mode of coherence in generative language: constraint-based organization without repetition or symbolic intent. Rather than viewing LLMs as imperfect agents or stochastic approximators, we suggest understanding them as generators of quasi-structured outputs. This framing complements existing evaluation paradigms by foregrounding formal coherence and pattern as interpretable features of model behavior. While the analogy has limits, it offers a conceptual tool for exploring how coherence might arise and be assessed in systems where meaning is emergent, partial, or inaccessible. In support of this perspective, we draw on philosophy of science and language, including model-based accounts of scientific representation, structural realism, and inferentialist views of meaning. We further propose the notion of structural evaluation: a mode of assessment that examines how well outputs propagate constraint, variation, and order across spans of generated text. This essay aims to reframe the current discussion around large language models, not by rejecting existing methods, but by suggesting an additional axis of interpretation grounded in structure rather than semantics.","authors":["Jose Manuel Guevara-Vela"],"url":"https://arxiv.org/abs/2504.11986"}
{"created":"2025-04-22","title":"Communication Optimization for Decentralized Learning atop Bandwidth-limited Edge Networks","abstract":"Decentralized federated learning (DFL) is a promising machine learning paradigm for bringing artificial intelligence (AI) capabilities to the network edge. Running DFL on top of edge networks, however, faces severe performance challenges due to the extensive parameter exchanges between agents. Most existing solutions for these challenges were based on simplistic communication models, which cannot capture the case of learning over a multi-hop bandwidth-limited network. In this work, we address this problem by jointly designing the communication scheme for the overlay network formed by the agents and the mixing matrix that controls the communication demands between the agents. By carefully analyzing the properties of our problem, we cast each design problem into a tractable optimization and develop an efficient algorithm with guaranteed performance. Our evaluations based on real topology and data show that the proposed algorithm can reduce the total training time by over $80\\%$ compared to the baseline without sacrificing accuracy, while significantly improving the computational efficiency over the state of the art.","authors":["Tingyang Sun","Tuan Nguyen","Ting He"],"url":"https://arxiv.org/abs/2504.12210"}
{"created":"2025-04-22","title":"Advancing Arabic Speech Recognition Through Large-Scale Weakly Supervised Learning","abstract":"Automatic speech recognition (ASR) is crucial for human-machine interaction in diverse applications like conversational agents, industrial robotics, call center automation, and automated subtitling. However, developing high-performance ASR models remains challenging, particularly for low-resource languages like Arabic, due to the scarcity of large, labeled speech datasets, which are costly and labor-intensive to produce. In this work, we employ weakly supervised learning to train an Arabic ASR model using the Conformer architecture. Our model is trained from scratch on 15,000 hours of weakly annotated speech data covering both Modern Standard Arabic (MSA) and Dialectal Arabic (DA), eliminating the need for costly manual transcriptions. Despite the absence of human-verified labels, our approach achieves state-of-the-art (SOTA) results in Arabic ASR, surpassing both open and closed-source models on standard benchmarks. By demonstrating the effectiveness of weak supervision as a scalable, cost-efficient alternative to traditional supervised approaches, paving the way for improved ASR systems in low resource settings.","authors":["Mahmoud Salhab","Marwan Elghitany","Shameed Sait","Syed Sibghat Ullah","Mohammad Abusheikh","Hasan Abusheikh"],"url":"https://arxiv.org/abs/2504.12254"}
{"created":"2025-04-22","title":"A Strategic Coordination Framework of Small LLMs Matches Large LLMs in Data Synthesis","abstract":"While data synthesis and distillation are promising strategies to enhance small language models, current approaches heavily rely on Large Language Models (LLMs), which suffer from high computational costs, environmental inefficiency, and potential biases inherited from monolithic architectures. In contrast, smaller LLMs are more accessible and sustainable, but their individual capabilities often fall short in generating high-quality, diverse, and reliable data. Inspired by collaborative human processes (e.g., peer review), we propose a multiple small LLMs involved framework, GRA, that aggregates specialized roles across small LLMs to iterative refinement and quality control typically achieved by a single large LLM. In this collaborative framework, multiple small LLMs assume distinct roles-Generator, Reviewer, and Adjudicator-to simulate a peer-review-inspired data synthesis pipeline. The Generator proposes initial data samples, the Reviewer critiques their quality and diversity, and the Adjudicator resolves conflicts to finalize the output. By decomposing the synthesis process into specialized sub-tasks, collaborative small LLMs can achieve data-level parity with large LLM-based distillation. Through experiments across multiple benchmarks, we demonstrate that GRA-produced data matches or exceeds the quality of single large LLM outputs, e.g., Qwen-2.5-72B-Instruct. Our results challenge the necessity of monolithic large models for high-quality data synthesis, advocating instead for strategic coordination of smaller agents. Our datasets, models, and code are publicly available at https://github.com/GX-XinGao/GRA.","authors":["Xin Gao","Qizhi Pei","Zinan Tang","Yu Li","Honglin Lin","Jiang Wu","Lijun Wu","Conghui He"],"url":"https://arxiv.org/abs/2504.12322"}
{"created":"2025-04-22","title":"The Other Side of the Coin: Exploring Fairness in Retrieval-Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by retrieving relevant document from external knowledge sources. By referencing this external knowledge, RAG effectively reduces the generation of factually incorrect content and addresses hallucination issues within LLMs. Recently, there has been growing attention to improving the performance and efficiency of RAG systems from various perspectives. While these advancements have yielded significant results, the application of RAG in domains with considerable societal implications raises a critical question about fairness: What impact does the introduction of the RAG paradigm have on the fairness of LLMs? To address this question, we conduct extensive experiments by varying the LLMs, retrievers, and retrieval sources. Our experimental analysis reveals that the scale of the LLMs plays a significant role in influencing fairness outcomes within the RAG framework. When the model scale is smaller than 8B, the integration of retrieval mechanisms often exacerbates unfairness in small-scale LLMs (e.g., LLaMA3.2-1B, Mistral-7B, and LLaMA3-8B). To mitigate the fairness issues introduced by RAG for small-scale LLMs, we propose two approaches, FairFT and FairFilter. Specifically, in FairFT, we align the retriever with the LLM in terms of fairness, enabling it to retrieve documents that facilitate fairer model outputs. In FairFilter, we propose a fairness filtering mechanism to filter out biased content after retrieval. Finally, we validate our proposed approaches on real-world datasets, demonstrating their effectiveness in improving fairness while maintaining performance.","authors":["Zheng Zhang","Ning Li","Qi Liu","Rui Li","Weibo Gao","Qingyang Mao","Zhenya Huang","Baosheng Yu","Dacheng Tao"],"url":"https://arxiv.org/abs/2504.12323"}
{"created":"2025-04-22","title":"Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex","abstract":"Text-attributed graphs (TAGs) present unique challenges in representation learning by requiring models to capture both the semantic richness of node-associated texts and the structural dependencies of the graph. While graph neural networks (GNNs) excel at modeling topological information, they lack the capacity to process unstructured text. Conversely, large language models (LLMs) are proficient in text understanding but are typically unaware of graph structure. In this work, we propose BiGTex (Bidirectional Graph Text), a novel architecture that tightly integrates GNNs and LLMs through stacked Graph-Text Fusion Units. Each unit allows for mutual attention between textual and structural representations, enabling information to flow in both directions, text influencing structure and structure guiding textual interpretation. The proposed architecture is trained using parameter-efficient fine-tuning (LoRA), keeping the LLM frozen while adapting to task-specific signals. Extensive experiments on five benchmark datasets demonstrate that BiGTex achieves state-of-the-art performance in node classification and generalizes effectively to link prediction. An ablation study further highlights the importance of soft prompting and bi-directional attention in the model's success.","authors":["Azadeh Beiranvand","Seyed Mehdi Vahidipour"],"url":"https://arxiv.org/abs/2504.12474"}
{"created":"2025-04-22","title":"Event Quality Score (EQS): Assessing the Realism of Simulated Event Camera Streams via Distances in Latent Space","abstract":"Event cameras promise a paradigm shift in vision sensing with their low latency, high dynamic range, and asynchronous nature of events. Unfortunately, the scarcity of high-quality labeled datasets hinders their widespread adoption in deep learning-driven computer vision. To mitigate this, several simulators have been proposed to generate synthetic event data for training models for detection and estimation tasks. However, the fundamentally different sensor design of event cameras compared to traditional frame-based cameras poses a challenge for accurate simulation. As a result, most simulated data fail to mimic data captured by real event cameras. Inspired by existing work on using deep features for image comparison, we introduce event quality score (EQS), a quality metric that utilizes activations of the RVT architecture. Through sim-to-real experiments on the DSEC driving dataset, it is shown that a higher EQS implies improved generalization to real-world data after training on simulated events. Thus, optimizing for EQS can lead to developing more realistic event camera simulators, effectively reducing the simulation gap. EQS is available at https://github.com/eventbasedvision/EQS.","authors":["Kaustav Chanda","Aayush Atul Verma","Arpitsinh Vaghela","Yezhou Yang","Bharatesh Chakravarthi"],"url":"https://arxiv.org/abs/2504.12515"}
{"created":"2025-04-22","title":"Post-Hurricane Debris Segmentation Using Fine-Tuned Foundational Vision Models","abstract":"Timely and accurate detection of hurricane debris is critical for effective disaster response and community resilience. While post-disaster aerial imagery is readily available, robust debris segmentation solutions applicable across multiple disaster regions remain limited. Developing a generalized solution is challenging due to varying environmental and imaging conditions that alter debris' visual signatures across different regions, further compounded by the scarcity of training data. This study addresses these challenges by fine-tuning pre-trained foundational vision models, achieving robust performance with a relatively small, high-quality dataset. Specifically, this work introduces an open-source dataset comprising approximately 1,200 manually annotated aerial RGB images from Hurricanes Ian, Ida, and Ike. To mitigate human biases and enhance data quality, labels from multiple annotators are strategically aggregated and visual prompt engineering is employed. The resulting fine-tuned model, named fCLIPSeg, achieves a Dice score of 0.70 on data from Hurricane Ida -- a disaster event entirely excluded during training -- with virtually no false positives in debris-free areas. This work presents the first event-agnostic debris segmentation model requiring only standard RGB imagery during deployment, making it well-suited for rapid, large-scale post-disaster impact assessments and recovery planning.","authors":["Kooshan Amini","Yuhao Liu","Jamie Ellen Padgett","Guha Balakrishnan","Ashok Veeraraghavan"],"url":"https://arxiv.org/abs/2504.12542"}
{"created":"2025-04-22","title":"Anonymous Public Announcements","abstract":"We formalise the notion of an anonymous public announcement in the tradition of public announcement logic. Such announcements can be seen as in-between a public announcement from ``the outside\" (an announcement of $\\phi$) and a public announcement by one of the agents (an announcement of $K_a\\phi$): we get more information than just $\\phi$, but not (necessarily) about exactly who made it. Even if such an announcement is prima facie anonymous, depending on the background knowledge of the agents it might reveal the identity of the announcer: if I post something on a message board, the information might reveal who I am even if I don't sign my name. Furthermore, like in the Russian Cards puzzle, if we assume that the announcer's intention was to stay anonymous, that in fact might reveal more information. In this paper we first look at the case when no assumption about intentions are made, in which case the logic with an anonymous public announcement operator is reducible to epistemic logic. We then look at the case when we assume common knowledge of the intention to stay anonymous, which is both more complex and more interesting: in several ways it boils down to the notion of a ``safe\" announcement (again, similarly to Russian Cards). Main results include formal expressivity results and axiomatic completeness for key logical languages.","authors":["Thomas {\\AA}gotnes","Rustam Galimullin","Ken Satoh","Satoshi Tojo"],"url":"https://arxiv.org/abs/2504.12546"}
{"created":"2025-04-22","title":"From Regulation to Support: Centering Humans in Technology-Mediated Emotion Intervention in Care Contexts","abstract":"Enhancing emotional well-being has become a significant focus in HCI and CSCW, with technologies increasingly designed to track, visualize, and manage emotions. However, these approaches have faced criticism for potentially suppressing certain emotional experiences. Through a scoping review of 53 empirical studies from ACM proceedings implementing Technology-Mediated Emotion Intervention (TMEI), we critically examine current practices through lenses drawn from HCI critical theories. Our analysis reveals emotion intervention mechanisms that extend beyond traditional emotion regulation paradigms, identifying care-centered goals that prioritize non-judgmental emotional support and preserve users' identities. The findings demonstrate how researchers design technologies for generating artificial care, intervening in power dynamics, and nudging behavioral changes. We contribute the concept of \"emotion support\" as an alternative approach to \"emotion regulation,\" emphasizing human-centered approaches to emotional well-being. This work advances the understanding of diverse human emotional needs beyond individual and cognitive perspectives, offering design implications that critically reimagine how technologies can honor emotional complexity, preserve human agency, and transform power dynamics in care contexts.","authors":["Jiaying \"Lizzy\" Liu","Shuer Zhuo","Xingyu Li","Andrew Dillon","Noura Howell","Angela D. R. Smith","Yan Zhang"],"url":"https://arxiv.org/abs/2504.12614"}
{"created":"2025-04-22","title":"Packing Input Frame Context in Next-Frame Prediction Models for Video Generation","abstract":"We present a neural network structure, FramePack, to train next-frame (or next-frame-section) prediction models for video generation. The FramePack compresses input frames to make the transformer context length a fixed number regardless of the video length. As a result, we are able to process a large number of frames using video diffusion with computation bottleneck similar to image diffusion. This also makes the training video batch sizes significantly higher (batch sizes become comparable to image diffusion training). We also propose an anti-drifting sampling method that generates frames in inverted temporal order with early-established endpoints to avoid exposure bias (error accumulation over iterations). Finally, we show that existing video diffusion models can be finetuned with FramePack, and their visual quality may be improved because the next-frame prediction supports more balanced diffusion schedulers with less extreme flow shift timesteps.","authors":["Lvmin Zhang","Maneesh Agrawala"],"url":"https://arxiv.org/abs/2504.12626"}
{"created":"2025-04-22","title":"A0: An Affordance-Aware Hierarchical Model for General Robotic Manipulation","abstract":"Robotic manipulation faces critical challenges in understanding spatial affordances--the \"where\" and \"how\" of object interactions--essential for complex manipulation tasks like wiping a board or stacking objects. Existing methods, including modular-based and end-to-end approaches, often lack robust spatial reasoning capabilities. Unlike recent point-based and flow-based affordance methods that focus on dense spatial representations or trajectory modeling, we propose A0, a hierarchical affordance-aware diffusion model that decomposes manipulation tasks into high-level spatial affordance understanding and low-level action execution. A0 leverages the Embodiment-Agnostic Affordance Representation, which captures object-centric spatial affordances by predicting contact points and post-contact trajectories. A0 is pre-trained on 1 million contact points data and fine-tuned on annotated trajectories, enabling generalization across platforms. Key components include Position Offset Attention for motion-aware feature extraction and a Spatial Information Aggregation Layer for precise coordinate mapping. The model's output is executed by the action execution module. Experiments on multiple robotic systems (Franka, Kinova, Realman, and Dobot) demonstrate A0's superior performance in complex tasks, showcasing its efficiency, flexibility, and real-world applicability.","authors":["Rongtao Xu","Jian Zhang","Minghao Guo","Youpeng Wen","Haoting Yang","Min Lin","Jianzheng Huang","Zhe Li","Kaidong Zhang","Liqiong Wang","Yuxuan Kuang","Meng Cao","Feng Zheng","Xiaodan Liang"],"url":"https://arxiv.org/abs/2504.12636"}
{"created":"2025-04-22","title":"NTIRE 2025 Challenge on Day and Night Raindrop Removal for Dual-Focused Images: Methods and Results","abstract":"This paper reviews the NTIRE 2025 Challenge on Day and Night Raindrop Removal for Dual-Focused Images. This challenge received a wide range of impressive solutions, which are developed and evaluated using our collected real-world Raindrop Clarity dataset. Unlike existing deraining datasets, our Raindrop Clarity dataset is more diverse and challenging in degradation types and contents, which includes day raindrop-focused, day background-focused, night raindrop-focused, and night background-focused degradations. This dataset is divided into three subsets for competition: 14,139 images for training, 240 images for validation, and 731 images for testing. The primary objective of this challenge is to establish a new and powerful benchmark for the task of removing raindrops under varying lighting and focus conditions. There are a total of 361 participants in the competition, and 32 teams submitting valid solutions and fact sheets for the final testing phase. These submissions achieved state-of-the-art (SOTA) performance on the Raindrop Clarity dataset. The project can be found at https://lixinustc.github.io/CVPR-NTIRE2025-RainDrop-Competition.github.io/.","authors":["Xin Li","Yeying Jin","Xin Jin","Zongwei Wu","Bingchen Li","Yufei Wang","Wenhan Yang","Yu Li","Zhibo Chen","Bihan Wen","Robby T. Tan","Radu Timofte","Qiyu Rong","Hongyuan Jing","Mengmeng Zhang","Jinglong Li","Xiangyu Lu","Yi Ren","Yuting Liu","Meng Zhang","Xiang Chen","Qiyuan Guan","Jiangxin Dong","Jinshan Pan","Conglin Gou","Qirui Yang","Fangpu Zhang","Yunlong Lin","Sixiang Chen","Guoxi Huang","Ruirui Lin","Yan Zhang","Jingyu Yang","Huanjing Yue","Jiyuan Chen","Qiaosi Yi","Hongjun Wang","Chenxi Xie","Shuai Li","Yuhui Wu","Kaiyi Ma","Jiakui Hu","Juncheng Li","Liwen Pan","Guangwei Gao","Wenjie Li","Zhenyu Jin","Heng Guo","Zhanyu Ma","Yubo Wang","Jinghua Wang","Wangzhi Xing","Anjusree Karnavar","Diqi Chen","Mohammad Aminul Islam","Hao Yang","Ruikun Zhang","Liyuan Pan","Qianhao Luo","XinCao","Han Zhou","Yan Min","Wei Dong","Jun Chen","Taoyi Wu","Weijia Dou","Yu Wang","Shengjie Zhao","Yongcheng Huang","Xingyu Han","Anyan Huang","Hongtao Wu","Hong Wang","Yefeng Zheng","Abhijeet Kumar","Aman Kumar","Marcos V. Conde","Paula Garrido","Daniel Feijoo","Juan C. Benito","Guanglu Dong","Xin Lin","Siyuan Liu","Tianheng Zheng","Jiayu Zhong","Shouyi Wang","Xiangtai Li","Lanqing Guo","Lu Qi","Chao Ren","Shuaibo Wang","Shilong Zhang","Wanyu Zhou","Yunze Wu","Qinzhong Tan","Jieyuan Pei","Zhuoxuan Li","Jiayu Wang","Haoyu Bian","Haoran Sun","Subhajit Paul","Ni Tang","Junhao Huang","Zihan Cheng","Hongyun Zhu","Yuehan Wu","Kaixin Deng","Hang Ouyang","Tianxin Xiao","Fan Yang","Zhizun Luo","Zeyu Xiao","Zhuoyuan Li","Nguyen Pham Hoang Le","An Dinh Thien","Son T. Luu","Kiet Van Nguyen","Ronghua Xu","Xianmin Tian","Weijian Zhou","Jiacheng Zhang","Yuqian Chen","Yihang Duan","Yujie Wu","Suresh Raikwar","Arsh Garg","Kritika","Jianhua Zheng","Xiaoshan Ma","Ruolin Zhao","Yongyu Yang","Yongsheng Liang","Guiming Huang","Qiang Li","Hongbin Zhang","Xiangyu Zheng","A. N. Rajagopalan"],"url":"https://arxiv.org/abs/2504.12711"}
{"created":"2025-04-22","title":"Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination","abstract":"Zero-shot coordination (ZSC), the ability to adapt to a new partner in a cooperative task, is a critical component of human-compatible AI. While prior work has focused on training agents to cooperate on a single task, these specialized models do not generalize to new tasks, even if they are highly similar. Here, we study how reinforcement learning on a distribution of environments with a single partner enables learning general cooperative skills that support ZSC with many new partners on many new problems. We introduce two Jax-based, procedural generators that create billions of solvable coordination challenges. We develop a new paradigm called Cross-Environment Cooperation (CEC), and show that it outperforms competitive baselines quantitatively and qualitatively when collaborating with real people. Our findings suggest that learning to collaborate across many unique scenarios encourages agents to develop general norms, which prove effective for collaboration with different partners. Together, our results suggest a new route toward designing generalist cooperative agents capable of interacting with humans without requiring human data.","authors":["Kunal Jha","Wilka Carvalho","Yancheng Liang","Simon S. Du","Max Kleiman-Weiner","Natasha Jaques"],"url":"https://arxiv.org/abs/2504.12714"}
{"created":"2025-04-22","title":"FedX: Adaptive Model Decomposition and Quantization for IoT Federated Learning","abstract":"Federated Learning (FL) allows collaborative training among multiple devices without data sharing, thus enabling privacy-sensitive applications on mobile or Internet of Things (IoT) devices, such as mobile health and asset tracking. However, designing an FL system with good model utility that works with low computation/communication overhead on heterogeneous, resource-constrained mobile/IoT devices is challenging. To address this problem, this paper proposes FedX, a novel adaptive model decomposition and quantization FL system for IoT. To balance utility with resource constraints on IoT devices, FedX decomposes a global FL model into different sub-networks with adaptive numbers of quantized bits for different devices. The key idea is that a device with fewer resources receives a smaller sub-network for lower overhead but utilizes a larger number of quantized bits for higher model utility, and vice versa. The quantization operations in FedX are done at the server to reduce the computational load on devices. FedX iteratively minimizes the losses in the devices' local data and in the server's public data using quantized sub-networks under a regularization term, and thus it maximizes the benefits of combining FL with model quantization through knowledge sharing among the server and devices in a cost-effective training process. Extensive experiments show that FedX significantly improves quantization times by up to 8.43X, on-device computation time by 1.5X, and total end-to-end training time by 1.36X, compared with baseline FL systems. We guarantee the global model convergence theoretically and validate local model convergence empirically, highlighting FedX's optimization efficiency.","authors":["Phung Lai","Xiaopeng Jiang","Hai Phan","Cristian Borcea","Khang Tran","An Chen","Vijaya Datta Mayyuri","Ruoming Jin"],"url":"https://arxiv.org/abs/2504.12849"}
{"created":"2025-04-22","title":"Benchmarking Multi-National Value Alignment for Large Language Models","abstract":"Do Large Language Models (LLMs) hold positions that conflict with your country's values? Occasionally they do! However, existing works primarily focus on ethical reviews, failing to capture the diversity of national values, which encompass broader policy, legal, and moral considerations. Furthermore, current benchmarks that rely on spectrum tests using manually designed questionnaires are not easily scalable.","authors":["Weijie Shi","Chengyi Ju","Chengzhong Liu","Jiaming Ji","Jipeng Zhang","Ruiyuan Zhang","Jia Zhu","Jiajie Xu","Yaodong Yang","Sirui Han","Yike Guo"],"url":"https://arxiv.org/abs/2504.12911"}
{"created":"2025-04-22","title":"SkyReels-V2: Infinite-length Film Generative Model","abstract":"Recent advances in video generation have been driven by diffusion models and autoregressive frameworks, yet critical challenges persist in harmonizing prompt adherence, visual quality, motion dynamics, and duration: compromises in motion dynamics to enhance temporal visual quality, constrained video duration (5-10 seconds) to prioritize resolution, and inadequate shot-aware generation stemming from general-purpose MLLMs' inability to interpret cinematic grammar, such as shot composition, actor expressions, and camera motions. These intertwined limitations hinder realistic long-form synthesis and professional film-style generation. To address these limitations, we propose SkyReels-V2, an Infinite-length Film Generative Model, that synergizes Multi-modal Large Language Model (MLLM), Multi-stage Pretraining, Reinforcement Learning, and Diffusion Forcing Framework. Firstly, we design a comprehensive structural representation of video that combines the general descriptions by the Multi-modal LLM and the detailed shot language by sub-expert models. Aided with human annotation, we then train a unified Video Captioner, named SkyCaptioner-V1, to efficiently label the video data. Secondly, we establish progressive-resolution pretraining for the fundamental video generation, followed by a four-stage post-training enhancement: Initial concept-balanced Supervised Fine-Tuning (SFT) improves baseline quality; Motion-specific Reinforcement Learning (RL) training with human-annotated and synthetic distortion data addresses dynamic artifacts; Our diffusion forcing framework with non-decreasing noise schedules enables long-video synthesis in an efficient search space; Final high-quality SFT refines visual fidelity. All the code and models are available at https://github.com/SkyworkAI/SkyReels-V2.","authors":["Guibin Chen","Dixuan Lin","Jiangping Yang","Chunze Lin","Junchen Zhu","Mingyuan Fan","Hao Zhang","Sheng Chen","Zheng Chen","Chengcheng Ma","Weiming Xiong","Wei Wang","Nuo Pang","Kang Kang","Zhiheng Xu","Yuzhe Jin","Yupeng Liang","Yubing Song","Peng Zhao","Boyuan Xu","Di Qiu","Debang Li","Zhengcong Fei","Yang Li","Yahui Zhou"],"url":"https://arxiv.org/abs/2504.13074"}
{"created":"2025-04-22","title":"Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo","abstract":"A wide range of LM applications require generating text that conforms to syntactic or semantic constraints. Imposing such constraints can be naturally framed as probabilistic conditioning, but exact generation from the resulting distribution -- which can differ substantially from the LM's base distribution -- is generally intractable. In this work, we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time, and efficiently reallocate computational resources in light of new information during the course of generation. By comparing to a number of alternatives and ablations on four challenging domains -- Python code generation for data science, text-to-SQL, goal inference, and molecule synthesis -- we demonstrate that, with little overhead, our approach allows small open-source language models to outperform models over 8x larger, as well as closed-source, fine-tuned ones. In support of the probabilistic perspective, we show that these performance improvements are driven by better approximation to the posterior distribution. Our system builds on the framework of Lew et al. (2023) and integrates with its language model probabilistic programming language, giving users a simple, programmable way to apply SMC to a broad variety of controlled generation problems.","authors":["Jo\\~ao Loula","Benjamin LeBrun","Li Du","Ben Lipkin","Clemente Pasti","Gabriel Grand","Tianyu Liu","Yahya Emara","Marjorie Freedman","Jason Eisner","Ryan Cotterell","Vikash Mansinghka","Alexander K. Lew","Tim Vieira","Timothy J. O'Donnell"],"url":"https://arxiv.org/abs/2504.13139"}
{"created":"2025-04-22","title":"Exploring Expert Failures Improves LLM Agent Tuning","abstract":"Large Language Models (LLMs) have shown tremendous potential as agents, excelling at tasks that require multiple rounds of reasoning and interactions. Rejection Sampling Fine-Tuning (RFT) has emerged as an effective method for finetuning LLMs as agents: it first imitates expert-generated successful trajectories and further improves agentic skills through iterative fine-tuning on successful, self-generated trajectories. However, since the expert (e.g., GPT-4) succeeds primarily on simpler subtasks and RFT inherently favors simpler scenarios, many complex subtasks remain unsolved and persistently out-of-distribution (OOD). Upon investigating these challenging subtasks, we discovered that previously failed expert trajectories can often provide valuable guidance, e.g., plans and key actions, that can significantly improve agent exploration efficiency and acquisition of critical skills. Motivated by these observations, we propose Exploring Expert Failures (EEF), which identifies beneficial actions from failed expert trajectories and integrates them into the training dataset. Potentially harmful actions are meticulously excluded to prevent contamination of the model learning process. By leveraging the beneficial actions in expert failures, EEF successfully solves some previously unsolvable subtasks and improves agent tuning performance. Remarkably, our approach achieved a 62\\% win rate in WebShop, outperforming RFT (53. 6\\%) and GPT-4 (35. 6\\%), and to the best of our knowledge, setting a new state-of-the-art as the first method to surpass a score of 0.81 in WebShop and exceed 81 in SciWorld.","authors":["Li-Cheng Lan","Andrew Bai","Minhao Cheng","Cho-Jui Hsieh","Tianyi Zhou"],"url":"https://arxiv.org/abs/2504.13145"}
{"created":"2025-04-22","title":"Ramsey expansions of metrically homogeneous graphs","abstract":"We investigate Ramsey expansions, the coherent extension property for partial isometries (EPPA), and the existence of a stationary independence relation for all classes of metrically homogeneous graphs from Cherlin's catalogue. We show that, with the exception of tree-like graphs, all metric spaces in the catalogue have precompact Ramsey expansions (or lifts) with the expansion property. With two exceptions we can also characterise the existence of a stationary independence relation and coherent EPPA.","authors":["Andr\\'es Aranda","David Bradley-Williams","Jan Hubi\\v{c}ka","Miltiadis Karamanlis","Michael Kompatscher","Mat\\v{e}j Kone\\v{c}n\\'y","Micheal Pawliuk"],"url":"https://arxiv.org/abs/1707.02612"}
{"created":"2025-04-22","title":"Degrees of incomputability, realizability and constructive reverse mathematics","abstract":"There is a way of assigning a realizability notion to each degree of incomputability. In our setting, we make use of Weihrauch degrees (degrees of incomputability/discontinuity of partial multi-valued functions) to obtain Lifschitz-like relative realizability predicates. In this note, we present sample examples on how to lift some separation results on Weihrauch degrees to those over intuitionistic Zermelo-Fraenkel set theory ${\\bf IZF}$.","authors":["Takayuki Kihara"],"url":"https://arxiv.org/abs/2002.10712"}
{"created":"2025-04-22","title":"Composite Goodness-of-fit Tests with Kernels","abstract":"Model misspecification can create significant challenges for the implementation of probabilistic models, and this has led to development of a range of robust methods which directly account for this issue. However, whether these more involved methods are required will depend on whether the model is really misspecified, and there is a lack of generally applicable methods to answer this question. In this paper, we propose one such method. More precisely, we propose kernel-based hypothesis tests for the challenging composite testing problem, where we are interested in whether the data comes from any distribution in some parametric family. Our tests make use of minimum distance estimators based on the maximum mean discrepancy and the kernel Stein discrepancy. They are widely applicable, including whenever the density of the parametric model is known up to normalisation constant, or if the model takes the form of a simulator. As our main result, we show that we are able to estimate the parameter and conduct our test on the same data (without data splitting), while maintaining a correct test level. Our approach is illustrated on a range of problems, including testing for goodness-of-fit of an unnormalised non-parametric density model, and an intractable generative model of a biological cellular network.","authors":["Oscar Key","Arthur Gretton","Fran\\c{c}ois-Xavier Briol","Tamara Fernandez"],"url":"https://arxiv.org/abs/2111.10275"}
{"created":"2025-04-22","title":"Preconditioned Gradient Descent for Overparameterized Nonconvex Burer--Monteiro Factorization with Global Optimality Certification","abstract":"We consider using gradient descent to minimize the nonconvex function $f(X)=\\phi(XX^{T})$ over an $n\\times r$ factor matrix $X$, in which $\\phi$ is an underlying smooth convex cost function defined over $n\\times n$ matrices. While only a second-order stationary point $X$ can be provably found in reasonable time, if $X$ is additionally rank deficient, then its rank deficiency certifies it as being globally optimal. This way of certifying global optimality necessarily requires the search rank $r$ of the current iterate $X$ to be overparameterized with respect to the rank $r^{\\star}$ of the global minimizer $X^{\\star}$. Unfortunately, overparameterization significantly slows down the convergence of gradient descent, from a linear rate with $r=r^{\\star}$ to a sublinear rate when $r>r^{\\star}$, even when $\\phi$ is strongly convex. In this paper, we propose an inexpensive preconditioner that restores the convergence rate of gradient descent back to linear in the overparameterized case, while also making it agnostic to possible ill-conditioning in the global minimizer $X^{\\star}$.","authors":["Gavin Zhang","Salar Fattahi","Richard Y. Zhang"],"url":"https://arxiv.org/abs/2206.03345"}
{"created":"2025-04-22","title":"Strong Converse Bounds for Compression of Mixed States","abstract":"In this paper, we study strong converse properties for both visible and blind compression of mixed states. The optimal rate of a visible compression scheme is obtained in terms of the entanglement of purification, whose additivity remains unknown so far. For a variation of extendible states, we prove that the entanglement of purification is additive and apply this to obtain a \"pretty strong\" converse bound for the blind and visible compression of such states. Namely, when the rate decreases below the optimal rate, the error exhibits a discontinuous jump from 0 to at least $\\frac{1}{3\\sqrt{2}}$.","authors":["Zahra Baghali Khanian"],"url":"https://arxiv.org/abs/2206.09415"}
{"created":"2025-04-22","title":"Online Statistical Inference in Decision-Making with Matrix Context","abstract":"The study of online decision-making problems that leverage contextual information has drawn notable attention due to their significant applications in fields ranging from healthcare to autonomous systems. In modern applications, contextual information can be rich and is often represented as a matrix. Moreover, while existing online decision algorithms mainly focus on reward maximization, less attention has been devoted to statistical inference. To address these gaps, in this work, we consider an online decision-making problem with a matrix context where the true model parameters have a low-rank structure. We propose a fully online procedure to conduct statistical inference with adaptively collected data. The low-rank structure of the model parameter and the adaptive nature of the data collection process make this difficult: standard low-rank estimators are biased and cannot be obtained in a sequential manner while existing inference approaches in sequential decision-making algorithms fail to account for the low-rankness and are also biased. To overcome these challenges, we introduce a new online debiasing procedure to simultaneously handle both sources of bias. Our inference framework encompasses both parameter inference and optimal policy value inference. In theory, we establish the asymptotic normality of the proposed online debiased estimators and prove the validity of the constructed confidence intervals for both inference tasks. Our inference results are built upon a newly developed low-rank stochastic gradient descent estimator and its convergence result, which are also of independent interest.","authors":["Qiyu Han","Will Wei Sun","Yichen Zhang"],"url":"https://arxiv.org/abs/2212.11385"}
{"created":"2025-04-22","title":"Auctions with Tokens: Monetary Policy as a Mechanism Design Choice","abstract":"I study a repeated auction in which payments are made with a blockchain token created and initially owned by the auction designer. Unlike the ``virtual money'' previously examined in mechanism design, such tokens can be saved and traded outside the mechanism. I show that the present-discounted value of expected revenues equals that of a conventional dollar auction, but revenues accrue earlier and are less volatile. The optimal monetary policy burns the tokens used for payment, a practice common in blockchain-based protocols. I also show that the same outcome can be reproduced in a dollar auction if the auctioneer issues a suitable dollar-denominated security. This equivalence breaks down with moral hazard and contracting frictions: with severe contracting frictions the token auction dominates, whereas with mild contracting frictions the dollar auction combined with a dollar-denominated financial instrument is preferred.","authors":["Andrea Canidio"],"url":"https://arxiv.org/abs/2301.13794"}
{"created":"2025-04-22","title":"Enhanced Adaptive Gradient Algorithms for Nonconvex-PL Minimax Optimization","abstract":"Minimax optimization recently is widely applied in many machine learning tasks such as generative adversarial networks, robust learning and reinforcement learning. In the paper, we study a class of nonconvex-nonconcave minimax optimization with nonsmooth regularization, where the objective function is possibly nonconvex on primal variable $x$, and it is nonconcave and satisfies the Polyak-Lojasiewicz (PL) condition on dual variable $y$. Moreover, we propose a class of enhanced momentum-based gradient descent ascent methods (i.e., MSGDA and AdaMSGDA) to solve these stochastic nonconvex-PL minimax problems. In particular, our AdaMSGDA algorithm can use various adaptive learning rates in updating the variables $x$ and $y$ without relying on any specifical types. Theoretically, we prove that our methods have the best known sample complexity of $\\tilde{O}(\\epsilon^{-3})$ only requiring one sample at each loop in finding an $\\epsilon$-stationary solution. Some numerical experiments on PL-game and Wasserstein-GAN demonstrate the efficiency of our proposed methods.","authors":["Feihu Huang","Chunyu Xuan","Xinrui Wang","Siqi Zhang","Songcan Chen"],"url":"https://arxiv.org/abs/2303.03984"}
{"created":"2025-04-22","title":"Large Banks and Systemic Risk: Insights from a Mean-Field Game Model","abstract":"This paper presents a dynamic game framework to analyze the role of large banks in interbank markets. By extending existing models, we incorporate a large bank as a dynamic decision-maker interacting with multiple small banks. Using the mean-field game methodology and convex analysis, best-response trading strategies are derived, leading to an approximate equilibrium for the interbank market. We investigate the influence of the large bank on the market stability by examining individual default probabilities and systemic risk, through the use of Monte Carlo simulations. Our findings reveal that, when the size of the major bank is not excessively large, it can positively contribute to market stability. However, there is also the potential for negative spillover effects in the event of default, leading to an increase in systemic risk. The magnitude of this impact is further influenced by the size and trading rate of the major bank. Overall, this study provides valuable insights into the management of systemic risk in interbank markets.","authors":["Yuanyuan Chang","Dena Firoozi","David Benatia"],"url":"https://arxiv.org/abs/2305.17830"}
{"created":"2025-04-22","title":"Training Neural Networks on RAW and HDR Images for Restoration Tasks","abstract":"The vast majority of standard image and video content available online is represented in display-encoded color spaces, in which pixel values are conveniently scaled to a limited range (0-1) and the color distribution is approximately perceptually uniform. In contrast, both camera RAW and high dynamic range (HDR) images are often represented in linear color spaces, in which color values are linearly related to colorimetric quantities of light. While training on commonly available display-encoded images is a well-established practice, there is no consensus on how neural networks should be trained for tasks on RAW and HDR images in linear color spaces. In this work, we test several approaches on three popular image restoration applications: denoising, deblurring, and single-image super-resolution. We examine whether HDR/RAW images need to be display-encoded using popular transfer functions (PQ, PU21, and mu-law), or whether it is better to train in linear color spaces, but use loss functions that correct for perceptual non-uniformity. Our results indicate that neural networks train significantly better on HDR and RAW images represented in display-encoded color spaces, which offer better perceptual uniformity than linear spaces. This small change to the training strategy can bring a very substantial gain in performance, between 2 and 9 dB.","authors":["Andrew Yanzhe Ke","Lei Luo","Xiaoyu Xiang","Yuchen Fan","Rakesh Ranjan","Alexandre Chapiro","Rafa{\\l} K. Mantiuk"],"url":"https://arxiv.org/abs/2312.03640"}
{"created":"2025-04-22","title":"QRCC: Evaluating Large Quantum Circuits on Small Quantum Computers through Integrated Qubit Reuse and Circuit Cutting","abstract":"Quantum computing has recently emerged as a promising computing paradigm for many application domains. However, the size of quantum circuits that can be run with high fidelity is constrained by the limited quantity and quality of physical qubits. Recently proposed schemes, such as wire cutting and qubit reuse, mitigate the problem but produce sub-optimal results as they address the problem individually. In addition, gate cutting, an alternative circuit-cutting strategy that is suitable for circuits computing expectation values, has not been fully explored in the field.","authors":["Aditya Pawar","Yingheng Li","Zewei Mo","Yanan Guo","Youtao Zhang","Xulong Tang","Jun Yang"],"url":"https://arxiv.org/abs/2312.10298"}
{"created":"2025-04-22","title":"CAP: A General Algorithm for Online Selective Conformal Prediction with FCR Control","abstract":"We study the problem of post-selection predictive inference in an online fashion. To avoid devoting resources to unimportant units, a preliminary selection of the current individual before reporting its prediction interval is common and meaningful in online predictive tasks. Since the online selection causes a temporal multiplicity in the selected prediction intervals, it is important to control the real-time false coverage-statement rate (FCR) which measures the overall miscoverage level. We develop a general framework named CAP (Calibration after Adaptive Pick) that performs an adaptive pick rule on historical data to construct a calibration set if the current individual is selected and then outputs a conformal prediction interval for the unobserved label. We provide tractable procedures for constructing the calibration set for popular online selection rules. We proved that CAP can achieve an exact selection-conditional coverage guarantee in the finite-sample and distribution-free regimes. To account for the distribution shift in online data, we also embed CAP into some recent dynamic conformal prediction algorithms and show that the proposed method can deliver long-run FCR control. Numerical results on both synthetic and real data corroborate that CAP can effectively control FCR around the target level and yield more narrowed prediction intervals over existing baselines across various settings.","authors":["Yajie Bao","Yuyang Huo","Haojie Ren","Changliang Zou"],"url":"https://arxiv.org/abs/2403.07728"}
{"created":"2025-04-22","title":"Barren plateaus are amplified by the dimension of qudits","abstract":"Variational Quantum Algorithms (VQAs) have emerged as pivotal strategies for attaining quantum advantage in diverse scientific and technological domains, notably within Quantum Neural Networks. However, despite their potential, VQAs encounter significant obstacles, chief among them being the vanishing gradient problem, commonly referred to as barren plateaus. In this article, through meticulous analysis, we demonstrate that existing literature implicitly suggests the intrinsic influence of qudit dimensionality on barren plateaus. To instantiate these findings, we present numerical results that exemplify the impact of qudit dimensionality on barren plateaus. Therefore, despite the proposition of various error mitigation techniques, our results call for further scrutiny about their efficacy in the context of VQAs with qudits.","authors":["Lucas Friedrich","Tiago de Souza Farias","Jonas Maziero"],"url":"https://arxiv.org/abs/2405.08190"}
{"created":"2025-04-22","title":"4+3 Phases of Compute-Optimal Neural Scaling Laws","abstract":"We consider the solvable neural scaling model with three parameters: data complexity, target complexity, and model-parameter-count. We use this neural scaling model to derive new predictions about the compute-limited, infinite-data scaling law regime. To train the neural scaling model, we run one-pass stochastic gradient descent on a mean-squared loss. We derive a representation of the loss curves which holds over all iteration counts and improves in accuracy as the model parameter count grows. We then analyze the compute-optimal model-parameter-count, and identify 4 phases (+3 subphases) in the data-complexity/target-complexity phase-plane. The phase boundaries are determined by the relative importance of model capacity, optimizer noise, and embedding of the features. We furthermore derive, with mathematical proof and extensive numerical evidence, the scaling-law exponents in all of these phases, in particular computing the optimal model-parameter-count as a function of floating point operation budget.","authors":["Elliot Paquette","Courtney Paquette","Lechao Xiao","Jeffrey Pennington"],"url":"https://arxiv.org/abs/2405.15074"}
{"created":"2025-04-22","title":"Multilevel Facility Location Optimization: A Novel Integer Programming Formulation and Approaches to Heuristic Solutions","abstract":"We attack the 4-level facility location problem (4L-FLP), a critical component in supply chains. Foundational tasks here involve selecting markets, plants, warehouses, and distribution centers to maximize profits while considering related constraints. Based on a variation of the quadratic assignment problem, we propose a novel integer programming formula that significantly reduces the variables. Our model incorporates several realistic features, including transportation costs and upper bounds on facilities at each level. It accounts for one-time fixed costs associated with selecting each facility. To solve this complex problem, we develop and experimentally test two solution procedures: a multi-start greedy heuristic and a multi-start tabu search. We conduct extensive sensitivity analyses on the results to assess the reliability of proposed algorithms. This study contributes to improved solution methods for large-scale 4L-FLPs, providing a valuable tool for supply chain maturity.","authors":["Bahram Alidaee","Haibo Wang"],"url":"https://arxiv.org/abs/2406.07382"}
{"created":"2025-04-22","title":"Enhancing Diagnostic Accuracy in Rare and Common Fundus Diseases with a Knowledge-Rich Vision-Language Model","abstract":"Previous foundation models for fundus images were pre-trained with limited disease categories and knowledge base. Here we introduce a knowledge-rich vision-language model (RetiZero) that leverages knowledge from more than 400 fundus diseases. For RetiZero's pretraining, we compiled 341,896 fundus images paired with texts, sourced from public datasets, ophthalmic literature, and online resources, encompassing a diverse range of diseases across multiple ethnicities and countries. RetiZero exhibits remarkable performance in several downstream tasks, including zero-shot disease recognition, image-to-image retrieval, AI-assisted clinical diagnosis,few-shot fine-tuning, and internal- and cross-domain disease identification. In zero-shot scenarios, RetiZero achieves Top-5 accuracies of 0.843 for 15 diseases and 0.756 for 52 diseases. For image retrieval, it achieves Top-5 scores of 0.950 and 0.886 for the same sets, respectively. AI-assisted clinical diagnosis results show that RetiZero's Top-3 zero-shot performance surpasses the average of 19 ophthalmologists from Singapore, China, and the United States. RetiZero substantially enhances clinicians' accuracy in diagnosing fundus diseases, in particularly rare ones. These findings underscore the value of integrating the RetiZero into clinical settings, where various fundus diseases are encountered.","authors":["Meng Wang","Tian Lin","Aidi Lin","Kai Yu","Yuanyuan Peng","Lianyu Wang","Cheng Chen","Ke Zou","Huiyu Liang","Man Chen","Xue Yao","Meiqin Zhang","Binwei Huang","Chaoxin Zheng","Peixin Zhang","Wei Chen","Yilong Luo","Yifan Chen","Honghe Xia","Tingkun Shi","Qi Zhang","Jinming Guo","Xiaolin Chen","Jingcheng Wang","Yih Chung Tham","Dianbo Liu","Wendy Wong","Sahil Thakur","Beau Fenner","Danqi Fang","Siying Liu","Qingyun Liu","Yuqiang Huang","Hongqiang Zeng","Yanda Meng","Yukun Zhou","Zehua Jiang","Minghui Qiu","Changqing Zhang","Xinjian Chen","Sophia Y. Wang","Cecilia S. Lee","Lucia Sobrin","Carol Y Cheung","Chi Pui Pang","Pearse A. Keane","Ching-Yu Cheng","Haoyu Chen","Huazhu Fu"],"url":"https://arxiv.org/abs/2406.09317"}
{"created":"2025-04-22","title":"First-Order Methods for Linearly Constrained Bilevel Optimization","abstract":"Algorithms for bilevel optimization often encounter Hessian computations, which are prohibitive in high dimensions. While recent works offer first-order methods for unconstrained bilevel problems, the constrained setting remains relatively underexplored. We present first-order linearly constrained optimization methods with finite-time hypergradient stationarity guarantees. For linear equality constraints, we attain $\\epsilon$-stationarity in $\\widetilde{O}(\\epsilon^{-2})$ gradient oracle calls, which is nearly-optimal. For linear inequality constraints, we attain $(\\delta,\\epsilon)$-Goldstein stationarity in $\\widetilde{O}(d{\\delta^{-1} \\epsilon^{-3}})$ gradient oracle calls, where $d$ is the upper-level dimension. Finally, we obtain for the linear inequality setting dimension-free rates of $\\widetilde{O}({\\delta^{-1} \\epsilon^{-4}})$ oracle complexity under the additional assumption of oracle access to the optimal dual variable. Along the way, we develop new nonsmooth nonconvex optimization methods with inexact oracles. We verify these guarantees with preliminary numerical experiments.","authors":["Guy Kornowski","Swati Padmanabhan","Kai Wang","Zhe Zhang","Suvrit Sra"],"url":"https://arxiv.org/abs/2406.12771"}
{"created":"2025-04-22","title":"Enhancing OOD Detection Using Latent Diffusion","abstract":"Numerous Out-of-Distribution (OOD) detection algorithms have been developed to identify unknown samples or objects in real-world deployments. One line of work related to OOD detection propose utilizing auxiliary datasets to train OOD detectors, thereby enhancing the performance of OOD detection. Recently, researchers propose to leverage Stable Diffusion (SD) to generate outliers in the pixel space, which may complicate network training. To mitigate this issue, we propose an Outlier Aware Learning (OAL) framework, which synthesizes OOD training data in the latent space. This improvement enables us to train the network with only a few synthesized outliers. Besides, to regularize the model's decision boundary, we develop a mutual information-based contrastive learning module (MICL) that amplifies the distinction between In-Distribution (ID) and collected OOD features. Moreover, we develop a knowledge distillation module to prevent the degradation of ID classification accuracy when training with OOD data. Extensive experiments on CIFAR-10/100 benchmarks demonstrate the superior performance of our method.","authors":["Heng Gao","Zhuolin He","Jian Pu"],"url":"https://arxiv.org/abs/2406.16525"}
{"created":"2025-04-22","title":"Interior Point Methods for Structured Quantum Relative Entropy Optimization Problems","abstract":"Quantum relative entropy optimization refers to a class of convex problems in which a linear functional is minimized over an affine section of the epigraph of the quantum relative entropy function. Recently, the self-concordance of a natural barrier function was proved for this set, and various implementations of interior-point methods have been made available to solve this class of optimization problems. In this paper, we show how common structures arising from applications in quantum information theory can be exploited to improve the efficiency of solving quantum relative entropy optimization problems using interior-point methods. First, we show that the natural barrier function for the epigraph of the quantum relative entropy composed with positive linear operators is self-concordant, even when these linear operators map to singular matrices. Compared to modelling problems using the full quantum relative entropy cone, this allows us to remove redundant log-determinant expressions from the barrier function and reduce the overall barrier parameter. Second, we show how certain slices of the quantum relative entropy cone exhibit useful properties which should be exploited whenever possible to perform certain key steps of interior-point methods more efficiently. We demonstrate how these methods can be applied to applications in quantum information theory, including quantifying quantum key rates, quantum rate-distortion functions, quantum channel capacities, and the ground state energy of Hamiltonians. Our numerical results show that these techniques improve computation times by up to several orders of magnitude, and allow previously intractable problems to be solved.","authors":["Kerry He","James Saunderson","Hamza Fawzi"],"url":"https://arxiv.org/abs/2407.00241"}
{"created":"2025-04-22","title":"$A^*$ for Graphs of Convex Sets","abstract":"We present a novel algorithm that fuses the existing convex-programming based approach with heuristic information to find optimality guarantees and near-optimal paths for the Shortest Path Problem in the Graph of Convex Sets (SPP-GCS). Our method, inspired by $A^*$, initiates a best-first-like procedure from a designated subset of vertices and iteratively expands it until further growth is neither possible nor beneficial. Traditionally, obtaining solutions with bounds for an optimization problem involves solving a relaxation, modifying the relaxed solution to a feasible one, and then comparing the two solutions to establish bounds. However, for SPP-GCS, we demonstrate that reversing this process can be more advantageous, especially with Euclidean travel costs. In other words, we initially employ $A^*$ to find a feasible solution for SPP-GCS, then solve a convex relaxation restricted to the vertices explored by $A^*$ to obtain a relaxed solution, and finally, compare the solutions to derive bounds. We present numerical results to highlight the advantages of our algorithm over the existing approach in terms of the sizes of the convex programs solved and computation time.","authors":["Kaarthik Sundar","Sivakumar Rathinam"],"url":"https://arxiv.org/abs/2407.17413"}
{"created":"2025-04-22","title":"Conditional Brownian Bridge Diffusion Model for VHR SAR to Optical Image Translation","abstract":"Synthetic Aperture Radar (SAR) imaging technology provides the unique advantage of being able to collect data regardless of weather conditions and time. However, SAR images exhibit complex backscatter patterns and speckle noise, which necessitate expertise for interpretation. Research on translating SAR images into optical-like representations has been conducted to aid the interpretation of SAR data. Nevertheless, existing studies have predominantly utilized low-resolution satellite imagery datasets and have largely been based on Generative Adversarial Network (GAN) which are known for their training instability and low fidelity. To overcome these limitations of low-resolution data usage and GAN-based approaches, this letter introduces a conditional image-to-image translation approach based on Brownian Bridge Diffusion Model (BBDM). We conducted comprehensive experiments on the MSAW dataset, a paired SAR and optical images collection of 0.5m Very-High-Resolution (VHR). The experimental results indicate that our method surpasses both the Conditional Diffusion Models (CDMs) and the GAN-based models in diverse perceptual quality metrics.","authors":["Seon-Hoon Kim","Dae-Won Chung"],"url":"https://arxiv.org/abs/2408.07947"}
{"created":"2025-04-22","title":"MANGO: Learning Disentangled Image Transformation Manifolds with Grouped Operators","abstract":"Learning semantically meaningful image transformations (i.e. rotation, thickness, blur) directly from examples can be a challenging task. Recently, the Manifold Autoencoder (MAE) proposed using a set of Lie group operators to learn image transformations directly from examples. However, this approach has limitations, as the learned operators are not guaranteed to be disentangled and the training routine is prohibitively expensive when scaling up the model. To address these limitations, we propose MANGO (transformation Manifolds with Grouped Operators) for learning disentangled operators that describe image transformations in distinct latent subspaces. Moreover, our approach allows practitioners the ability to define which transformations they aim to model, thus improving the semantic meaning of the learned operators. Through our experiments, we demonstrate that MANGO enables composition of image transformations and introduces a one-phase training routine that leads to a 100x speedup over prior works.","authors":["Brighton Ancelin","Yenho Chen","Peimeng Guan","Chiraag Kaushik","Belen Martin-Urcelay","Alex Saad-Falcon","Nakul Singh"],"url":"https://arxiv.org/abs/2409.09542"}
{"created":"2025-04-22","title":"Triangulated spheres with holes in triangulated surfaces","abstract":"Let $\\mathbb{S}_h$ denote a sphere with $h$ holes. Given a triangulation $G$ of a surface $\\mathbb{M}$, we consider the question of when $G$ contains a spanning subgraph $H$ such that $H$ is a triangulated $\\mathbb{S}_h$. We give a new short proof of a theorem of Nevo and Tarabykin that every triangulation $G$ of the torus contains a spanning subgraph which is a triangulated cylinder. For arbitrary surfaces, we prove that every high facewidth triangulation of a surface with $h$ handles contains a spanning subgraph which is a triangulated $\\mathbb{S}_{2h}$. We also prove that for every $0 \\leq g' < g$ and $w \\in \\mathbb{N}$, there exists a triangulation of facewidth at least $w$ of a surface of Euler genus $g$ that does not have a spanning subgraph which is a triangulated $\\mathbb{S}_{g'}$. Our results are motivated by, and have applications for, rigidity questions in the plane.","authors":["Katie Clinch","Sean Dewar","Niloufar Fuladi","Maximilian Gorsky","Tony Huynh","Eleftherios Kastis","Atsuhiro Nakamoto","Anthony Nixon","Brigitte Servatius"],"url":"https://arxiv.org/abs/2410.04450"}
{"created":"2025-04-22","title":"Beyond Sequence: Impact of Geometric Context for RNA Property Prediction","abstract":"Accurate prediction of RNA properties, such as stability and interactions, is crucial for advancing our understanding of biological processes and developing RNA-based therapeutics. RNA structures can be represented as 1D sequences, 2D topological graphs, or 3D all-atom models, each offering different insights into its function. Existing works predominantly focus on 1D sequence-based models, which overlook the geometric context provided by 2D and 3D geometries. This study presents the first systematic evaluation of incorporating explicit 2D and 3D geometric information into RNA property prediction, considering not only performance but also real-world challenges such as limited data availability, partial labeling, sequencing noise, and computational efficiency. To this end, we introduce a newly curated set of RNA datasets with enhanced 2D and 3D structural annotations, providing a resource for model evaluation on RNA data. Our findings reveal that models with explicit geometry encoding generally outperform sequence-based models, with an average prediction RMSE reduction of around 12% across all various RNA tasks and excelling in low-data and partial labeling regimes, underscoring the value of explicitly incorporating geometric context. On the other hand, geometry-unaware sequence-based models are more robust under sequencing noise but often require around $2-5\\times$ training data to match the performance of geometry-aware models. Our study offers further insights into the trade-offs between different RNA representations in practical applications and addresses a significant gap in evaluating deep learning models for RNA tasks.","authors":["Junjie Xu","Artem Moskalev","Tommaso Mansi","Mangal Prakash","Rui Liao"],"url":"https://arxiv.org/abs/2410.11933"}
{"created":"2025-04-22","title":"Contractivity and linear convergence in bilinear saddle-point problems: An operator-theoretic approach","abstract":"We study the convex-concave bilinear saddle-point problem $\\min_x \\max_y f(x) + y^\\top Ax - g(y)$, where both, only one, or none of the functions $f$ and $g$ are strongly convex, and suitable rank conditions on the matrix $A$ hold. The solution of this problem is at the core of many machine learning tasks. By employing tools from monotone operator theory, we systematically prove the contractivity (in turn, the linear convergence) of several first-order primal-dual algorithms, including the Chambolle-Pock method. Our approach results in concise proofs, and it yields new convergence guarantees and tighter bounds compared to known results.","authors":["Colin Dirren","Mattia Bianchi","Panagiotis D. Grontas","John Lygeros","Florian D\\\"orfler"],"url":"https://arxiv.org/abs/2410.14592"}
{"created":"2025-04-22","title":"Metamizer: a versatile neural optimizer for fast and accurate physics simulations","abstract":"Efficient physics simulations are essential for numerous applications, ranging from realistic cloth animations or smoke effects in video games, to analyzing pollutant dispersion in environmental sciences, to calculating vehicle drag coefficients in engineering applications. Unfortunately, analytical solutions to the underlying physical equations are rarely available, and numerical solutions require high computational resources. Latest developments in the field of physics-based Deep Learning have led to promising efficiency improvements but still suffer from limited generalization capabilities and low accuracy compared to numerical solvers.","authors":["Nils Wandel","Stefan Schulz","Reinhard Klein"],"url":"https://arxiv.org/abs/2410.19746"}
{"created":"2025-04-22","title":"Robust multi-coil MRI reconstruction via self-supervised denoising","abstract":"To examine the effect of incorporating self-supervised denoising as a pre-processing step for training deep learning (DL) based reconstruction methods on data corrupted by Gaussian noise. K-space data employed for training are typically multi-coil and inherently noisy. Although DL-based reconstruction methods trained on fully sampled data can enable high reconstruction quality, obtaining large, noise-free datasets is impractical. We leverage Generalized Stein's Unbiased Risk Estimate (GSURE) for denoising. We evaluate two DL-based reconstruction methods: Diffusion Probabilistic Models (DPMs) and Model-Based Deep Learning (MoDL). We evaluate the impact of denoising on the performance of these DL-based methods in solving accelerated multi-coil magnetic resonance imaging (MRI) reconstruction. The experiments were carried out on T2-weighted brain and fat-suppressed proton-density knee scans. We observed that self-supervised denoising enhances the quality and efficiency of MRI reconstructions across various scenarios. Specifically, employing denoised images rather than noisy counterparts when training DL networks results in lower normalized root mean squared error (NRMSE), higher structural similarity index measure (SSIM) and peak signal-to-noise ratio (PSNR) across different SNR levels, including 32dB, 22dB, and 12dB for T2-weighted brain data, and 24dB, 14dB, and 4dB for fat-suppressed knee data. Overall, we showed that denoising is an essential pre-processing technique capable of improving the efficacy of DL-based MRI reconstruction methods under diverse conditions. By refining the quality of input data, denoising enables training more effective DL networks, potentially bypassing the need for noise-free reference MRI scans.","authors":["Asad Aali","Marius Arvinte","Sidharth Kumar","Yamin I. Arefeen","Jonathan I. Tamir"],"url":"https://arxiv.org/abs/2411.12919"}
{"created":"2025-04-22","title":"Hyperspectral image fusion, Unsupervised hyperspectral super-resolution, Modality decoupling, Self-supervised learning","abstract":"Hyperspectral and Multispectral Image Fusion (HMIF) aims to fuse low-resolution hyperspectral images (LR-HSIs) and high-resolution multispectral images (HR-MSIs) to reconstruct high spatial and high spectral resolution images. Current methods typically apply direct fusion from the two modalities without effective supervision, leading to an incomplete perception of deep modality-complementary information and a limited understanding of inter-modality correlations. To address these issues, we propose a simple yet effective solution for unsupervised HMIF, revealing that modality decoupling is key to improving fusion performance. Specifically, we propose an end-to-end self-supervised \\textbf{Mo}dality-Decoupled \\textbf{S}patial-\\textbf{S}pectral Fusion (\\textbf{MossFuse}) framework that decouples shared and complementary information across modalities and aggregates a concise representation of both LR-HSIs and HR-MSIs to reduce modality redundancy. Also, we introduce the subspace clustering loss as a clear guide to decouple modality-shared features from modality-complementary ones. Systematic experiments over multiple datasets demonstrate that our simple and effective approach consistently outperforms the existing HMIF methods while requiring considerably fewer parameters with reduced inference time. The anonymous source code is in \\href{https://github.com/dusongcheng/MossFuse}{MossFuse}.","authors":["Songcheng Du","Yang Zou","Zixu Wang","Xingyuan Li","Ying Li","Changjing Shang","Qiang Shen"],"url":"https://arxiv.org/abs/2412.04802"}
{"created":"2025-04-22","title":"The emergence of chaos in population game dynamics induced by comparisons","abstract":"Precise description of population game dynamics introduced by revision protocols - an economic model describing the agent's propensity to switch to a better-performing strategy - is of importance in economics and social sciences in general. In this setting innovation or imitation of others is the force which drives the evolution of the economic system. As the continuous-time game dynamics is relatively well understood, the same cannot be said about revision driven dynamics in the discrete time. We investigate the behavior of agents in a $2\\times 2$ anti-coordination game with symmetric random matching and a unique mixed Nash equilibrium. In continuous time the Nash equilibrium is attracting and induces a global evolutionary stable state. We show that in the discrete time one can construct (either innovative or imitative) revision protocol and choose a level of the time step, under which the game dynamics is Li-Yorke chaotic, inducing complex and unpredictable behavior of the system, precluding stable predictions of equilibrium. Moreover, we reveal that this unpredictability is encoded into any imitative revision protocol. Furthermore, we show that for any such game there exists a perturbed pairwise proportional imitation protocol introducing chaotic behavior of the agents for sufficiently large time step.","authors":["Jakub Bielawski","{\\L}ukasz Cholewa","Fryderyk Falniowski"],"url":"https://arxiv.org/abs/2412.06037"}
{"created":"2025-04-22","title":"Adaptive Control of Positive Systems with Application to Learning SSP","abstract":"An adaptive controller is proposed and analyzed for the class of infinite-horizon optimal control problems in positive linear systems presented in (Ohlin et al., 2024b). This controller is derived from the solution of a \"data-driven algebraic equation\" constructed using the model-free Bellman equation from Q-learning. The equation is driven by data correlation matrices that do not scale with the number of data points, enabling efficient online implementation. Consequently, a sufficient condition guaranteeing stability and robustness to unmodeled dynamics is established. The derived results also provide a quantitative characterization of the interplay between excitation level and robustness to unmodeled dynamics. The class of optimal control problems considered here is equivalent to Stochastic Shortest Path (SSP) problems, allowing for a performance comparison between the proposed adaptive policy and model-free algorithms for learning the stochastic shortest path, as demonstrated in the numerical experiment.","authors":["Fethi Bencherki","Anders Rantzer"],"url":"https://arxiv.org/abs/2412.17012"}
{"created":"2025-04-22","title":"Toward Sufficient Statistical Power in Algorithmic Bias Assessment: A Test for ABROCA","abstract":"Algorithmic bias is a pressing concern in educational data mining (EDM), as it risks amplifying inequities in learning outcomes. The Area Between ROC Curves (ABROCA) metric is frequently used to measure discrepancies in model performance across demographic groups to quantify overall model fairness. However, its skewed distribution--especially when class or group imbalances exist--makes significance testing challenging. This study investigates ABROCA's distributional properties and contributes robust methods for its significance testing. Specifically, we address (1) whether ABROCA follows any known distribution, (2) how to reliably test for algorithmic bias using ABROCA, and (3) the statistical power achievable with ABROCA-based bias assessments under typical EDM sample specifications. Simulation results confirm that ABROCA does not match standard distributions, including those suited to accommodate skewness. We propose nonparametric randomization tests for ABROCA and demonstrate that reliably detecting bias with ABROCA requires large sample sizes or substantial effect sizes, particularly in imbalanced settings. Findings suggest that ABROCA-based bias evaluations based on sample sizes common in EDM tend to be underpowered, undermining the reliability of conclusions about model fairness. By offering open-source code to simulate power and statistically test ABROCA, this paper aims to foster more reliable statistical testing in EDM research. It supports broader efforts toward replicability and equity in educational modeling.","authors":["Conrad Borchers"],"url":"https://arxiv.org/abs/2501.04683"}
{"created":"2025-04-22","title":"Engineering-Oriented Design of Drift-Resilient MTJ Random Number Generator via Hybrid Control Strategies","abstract":"Magnetic Tunnel Junctions (MTJs) have shown great promise as hardware sources for true random number generation (TRNG) due to their intrinsic stochastic switching behavior. However, practical deployment remains challenged by drift in switching probability caused by thermal fluctuations, device aging, and environmental instability. This work presents an engineering-oriented, drift-resilient MTJ-based TRNG architecture, enabled by a hybrid control strategy that combines self-stabilizing feedback with pulse width modulation. A key component is the Downcalibration-2 scheme, which updates the control parameter every two steps using only integer-resolution timing, ensuring excellent statistical quality without requiring bit discarding, pre-characterization, or external calibration. Extensive experimental measurements and numerical simulations demonstrate that this approach maintains stable randomness under dynamic temperature drift, using only simple digital logic. The proposed architecture offers high throughput, robustness, and scalability, making it well-suited for secure hardware applications, embedded systems, and edge computing environments.","authors":["Ran Zhang","Caihua Wan","Yingqian Xu","Xiaohan Li","Raik Hoffmann","Meike Hindenberg","Shiqiang Liu","Dehao Kong","Shilong Xiong","Shikun He","Alptekin Vardar","Qiang Dai","Junlu Gong","Yihui Sun","Zejie Zheng","Thomas K\\\"ampfe","Guoqiang Yu","Xiufeng Han"],"url":"https://arxiv.org/abs/2501.15206"}
{"created":"2025-04-22","title":"Comparative clinical evaluation of \"memory-efficient\" synthetic 3d generative adversarial networks (gan) head-to-head to state of art: results on computed tomography of the chest","abstract":"Generative Adversarial Networks (GANs) are increasingly used to generate synthetic medical images, addressing the critical shortage of annotated data for training Artificial Intelligence systems. This study introduces CRF-GAN, a novel memory-efficient GAN architecture that enhances structural consistency in 3D medical image synthesis. Integrating Conditional Random Fields within a two-step generation process allows CRF-GAN improving spatial coherence while maintaining high-resolution image quality. The model's performance is evaluated against the state-of-the-art hierarchical (HA)-GAN model. Materials and Methods: We evaluate the performance of CRF-GAN against the HA-GAN model. The comparison between the two models was made through a quantitative evaluation, using FID and MMD metrics, and a qualitative evaluation, through a two-alternative forced choice (2AFC) test completed by a pool of 12 resident radiologists, to assess the realism of the generated images. Results: CRF-GAN outperformed HA-GAN with lower FID and MMD scores, indicating better image fidelity. The 2AFC test showed a significant preference for images generated by CRF-Gan over those generated by HA-GAN. Additionally, CRF-GAN demonstrated 9.34% lower memory usage and achieved up to 14.6% faster training speeds, offering substantial computational savings. Discussion: CRF-GAN model successfully generates high-resolution 3D medical images with non-inferior quality to conventional models, while being more memory-efficient and faster. The key objective was not only to lower the computational cost but also to reallocate the freed-up resources towards the creation of higher-resolution 3D imaging, which is still a critical factor limiting their direct clinical applicability. Moreover, unlike many previous studies, we combined qualitative and quantitative assessments to obtain a more holistic feedback on the model's performance.","authors":["Mahshid Shiri","Chandra Bortolotto","Alessandro Bruno","Alessio Consonni","Daniela Maria Grasso","Leonardo Brizzi","Daniele Loiacono","Lorenzo Preda"],"url":"https://arxiv.org/abs/2501.15572"}
{"created":"2025-04-22","title":"Shifting Attention to You: Personalized Brain-Inspired AI Models","abstract":"The integration of human and artificial intelligence offers a powerful avenue for advancing our understanding of information processing, as each system provides unique computational insights. However, despite the promise of human-AI integration, current AI models are largely trained on massive datasets, optimized for population-level performance, lacking mechanisms to align their computations with individual users' perceptual semantics and neural dynamics. Here we show that integrating human behavioral insights and millisecond scale neural data within a fine tuned CLIP based model not only captures generalized and individualized aspects of perception but also over doubles behavioral performance compared to the unmodified CLIP baseline. By embedding human inductive biases and mirroring dynamic neural processes during training, personalized neural fine tuning improves predictions of human similarity judgments and tracks the temporal evolution of individual neural responses. Our work establishes a novel, interpretable framework for designing adaptive AI systems, with broad implications for neuroscience, personalized medicine, and human-computer interaction.","authors":["Stephen Chong Zhao","Yang Hu","Jason Lee","Andrew Bender","Trisha Mazumdar","Mark Wallace","David A. Tovar"],"url":"https://arxiv.org/abs/2502.04658"}
{"created":"2025-04-22","title":"First-Order Intuitionistic Linear Logic and Hypergraph Languages","abstract":"The Lambek calculus is a substructural logic known to be closely related to the formal language theory: on the one hand, it is used for generating formal languages by means of categorial grammars and, on the other hand, it has formal language semantics, with respect to which it is sound and complete. This paper studies a similar relation between first-order intuitionistic linear logic ILL1 along with its multiplicative fragment MILL1 on the one hand and the hypergraph grammar theory on the other. In the first part, we introduce a novel concept of hypergraph first-order logic categorial grammar, which is a generalisation of string MILL1 grammars studied e.g. in Richard Moot's 2014 works. We prove that hypergraph ILL1 grammars generate all recursively enumerable hypergraph languages and that hypergraph MILL1 grammars are as powerful as linear-time hypergraph transformation systems. In addition, we show that the class of languages generated by string MILL1 grammars is closed under intersection and that it includes a non-semilinear language as well as an NP-complete one. This shows how much more powerful string MILL1 grammars are as compared to Lambek categorial grammars.","authors":["Tikhon Pshenitsyn"],"url":"https://arxiv.org/abs/2502.05816"}
{"created":"2025-04-22","title":"Conditioning through indifference in quantum mechanics","abstract":"We can learn (more) about the state a quantum system is in through measurements. We look at how to describe the uncertainty about a quantum system's state conditional on executing such measurements. We show that by exploiting the interplay between desirability, coherence and indifference, a general rule for conditioning can be derived. We then apply this rule to conditioning on measurement outcomes, and show how it generalises to conditioning on a set of measurement outcomes.","authors":["Keano De Vos","Gert de Cooman"],"url":"https://arxiv.org/abs/2502.06249"}
{"created":"2025-04-22","title":"Three Fundamental Questions in Modern Infinite-Domain Constraint Satisfaction","abstract":"The Feder-Vardi dichotomy conjecture for Constraint Satisfaction Problems (CSPs) with finite templates, confirmed independently by Bulatov and Zhuk, has an extension to certain well-behaved infinite templates due to Bodirsky and Pinsker which remains wide open. We provide answers to three fundamental questions on the scope of the Bodirsky-Pinsker conjecture. Our first two main results provide two simplifications of this scope, one of structural, and the other one of algebraic nature. The former simplification implies that the conjecture is equivalent to its restriction to templates without algebraicity, a crucial assumption in the most powerful classification methods. The latter yields that the higher-arity invariants of any template within its scope can be assumed to be essentially injective, and any algebraic condition characterizing any complexity class within the conjecture closed under Datalog reductions must be satisfiable by injections, thus lifting the mystery of the better applicability of certain conditions over others. Our third main result uses the first one to show that any non-trivially tractable template within the scope serves, up to a Datalog-computable modification of it, as the witness of the tractability of a non-finitely tractable finite-domain Promise Constraint Satisfaction Problem (PCSP) by the so-called sandwich method. This generalizes a recent result of Mottet and provides a strong hitherto unknown connection between the Bodirsky-Pinsker conjecture and finite-domain PCSPs.","authors":["Michael Pinsker","Jakub Rydval","Moritz Sch\\\"obi","Christoph Spiess"],"url":"https://arxiv.org/abs/2502.06621"}
{"created":"2025-04-22","title":"Algorithmic contiguity from low-degree conjecture and applications in correlated random graphs","abstract":"In this paper, assuming a natural strengthening of the low-degree conjecture, we provide evidence of computational hardness for two problems: (1) the (partial) matching recovery problem in the sparse correlated Erd\\H{o}s-R\\'enyi graphs $\\mathcal G(n,q;\\rho)$ when the edge-density $q=n^{-1+o(1)}$ and the correlation $\\rho<\\sqrt{\\alpha}$ lies below the Otter's threshold, solving a remaining problem in \\cite{DDL23+}; (2) the detection problem between the correlated sparse stochastic block model $\\mathcal S(n,\\tfrac{\\lambda}{n};k,\\epsilon;s)$ and a pair of independent stochastic block models $\\mathcal S(n,\\tfrac{\\lambda s}{n};k,\\epsilon)$ when $\\epsilon^2 \\lambda s<1$ lies below the Kesten-Stigum (KS) threshold and $s<\\sqrt{\\alpha}$ lies below the Otter's threshold, solving a remaining problem in \\cite{CDGL24+}.","authors":["Zhangsong Li"],"url":"https://arxiv.org/abs/2502.09832"}
{"created":"2025-04-22","title":"Generalized De Bruijn Words, Invertible Necklaces, and the Burrows-Wheeler Transform","abstract":"We define generalized de Bruijn words as those words having a Burrows-Wheeler transform that is a concatenation of permutations of the alphabet. We show that generalized de Bruijn words are in 1-to-1 correspondence with Hamiltonian cycles in the generalized de Bruijn graphs introduced in the early '80s in the context of network design. When the size of the alphabet is a prime $p$, we define invertible necklaces as those whose BWT-matrix is non-singular. We show that invertible necklaces of length $n$ correspond to normal bases of the finite field $F_{p^n}$, and that they form an Abelian group isomorphic to the Reutenauer group $RG_p^n$. Using known results in abstract algebra, we can make a bridge between generalized de Bruijn words and invertible necklaces. In particular, we highlight a correspondence between binary de Bruijn words of order $d+1$, binary necklaces of length $2^{d}$ having an odd number of $1$'s, invertible BWT matrices of size $2^{d}\\times 2^{d}$, and normal bases of the finite field $F_{2^{2^{d}}}$.","authors":["Gabriele Fici","Est\\'eban Gabory"],"url":"https://arxiv.org/abs/2502.12844"}
{"created":"2025-04-22","title":"A Bayesian Interpretation of the Internal Model Principle","abstract":"The internal model principle, originally proposed in the theory of control of linear systems, nowadays represents a more general class of results in control theory and cybernetics. The central claim of these results is that, under suitable assumptions, if a system (a controller) can regulate against a class of external inputs (from the environment), it is because the system contains a model of the system causing these inputs, which can be used to generate signals counteracting them. Similar claims on the role of internal models appear also in cognitive science, especially in modern Bayesian treatments of cognitive agents, often suggesting that a system (a human subject, or some other agent) models its environment to adapt against disturbances and perform goal-directed behaviour. It is however unclear whether the Bayesian internal models discussed in cognitive science bear any formal relation to the internal models invoked in standard treatments of control theory. Here, we first review the internal model principle and present a precise formulation of it using concepts inspired by categorical systems theory. This leads to a formal definition of ``model'' generalising its use in the internal model principle. Although this notion of model is not a priori related to the notion of Bayesian reasoning, we show that it can be seen as a special case of possibilistic Bayesian filtering. This result is based on a recent line of work formalising, using Markov categories, a notion of ``interpretation'', describing when a system can be interpreted as performing Bayesian filtering on an outside world in a consistent way.","authors":["Manuel Baltieri","Martin Biehl","Matteo Capucci","Nathaniel Virgo"],"url":"https://arxiv.org/abs/2503.00511"}
{"created":"2025-04-22","title":"Unsupervised Learning for AoD Estimation in MISO Downlink LoS Transmissions","abstract":"With the emergence of simultaneous localization and communication (SLAC), it becomes more and more attractive to perform angle of departure (AoD) estimation at the receiving Internet of Thing (IoT) user end for improved positioning accuracy, flexibility and enhanced user privacy. To address challenges like a large number of real-time measurements required for latency-critical applications and enormous data collection for training deep learning models in conventional AoD estimation methods, we propose in this letter an unsupervised learning framework, which unifies training for both deterministic maximum likelihood (DML) and stochastic maximum likelihood (SML) based AoD estimation in multiple-input single-output (MISO) downlink (DL) wireless transmissions. Specifically, under the line-of-sight (LoS) assumption, we incorporate both the received signals and pilot-sequence information, as per its availability at the DL user, into the input of the deep learning model, and adopt a common neural network architecture compatible with input data in both DML and SML cases. Extensive numerical results validate that the proposed unsupervised learning based AoD estimation not only improves estimation accuracy, but also significantly reduces required number of observations, thereby reducing both estimation overhead and latency compared to various benchmarks.","authors":["Jiaying Li","Yuanwei Liu","Hong Xing"],"url":"https://arxiv.org/abs/2503.12033"}
{"created":"2025-04-22","title":"Online Conformal Probabilistic Numerics via Adaptive Edge-Cloud Offloading","abstract":"Consider an edge computing setting in which a user submits queries for the solution of a linear system to an edge processor, which is subject to time-varying computing availability. The edge processor applies a probabilistic linear solver (PLS) so as to be able to respond to the user's query within the allotted time and computing budget. Feedback to the user is in the form of a set of plausible solutions. Due to model misspecification, the highest-probability-density (HPD) set obtained via a direct application of PLS does not come with coverage guarantees with respect to the true solution of the linear system. This work introduces a new method to calibrate the HPD sets produced by PLS with the aim of guaranteeing long-term coverage requirements. The proposed method, referred to as online conformal prediction-PLS (OCP-PLS), assumes sporadic feedback from cloud to edge. This enables the online calibration of uncertainty thresholds via online conformal prediction (OCP), an online optimization method previously studied in the context of prediction models. The validity of OCP-PLS is verified via experiments that bring insights into trade-offs between coverage, prediction set size, and cloud usage.","authors":["Qiushuo Hou","Sangwoo Park","Matteo Zecchin","Yunlong Cai","Guanding Yu","Osvaldo Simeone"],"url":"https://arxiv.org/abs/2503.14453"}
{"created":"2025-04-22","title":"Resource Allocation for RIS-Assisted CoMP-NOMA Networks using Reinforcement Learning","abstract":"This thesis delves into the forefront of wireless communication by exploring the synergistic integration of three transformative technologies: STAR-RIS, CoMP, and NOMA. Driven by the ever-increasing demand for higher data rates, improved spectral efficiency, and expanded coverage in the evolving landscape of 6G development, this research investigates the potential of these technologies to revolutionize future wireless networks.","authors":["Muhammad Umer","Muhammad Ahmed Mohsin","Huma Ghafoor","Syed Ali Hassan"],"url":"https://arxiv.org/abs/2504.00975"}
{"created":"2025-04-22","title":"Neural Encoding and Decoding at Scale","abstract":"Recent work has demonstrated that large-scale, multi-animal models are powerful tools for characterizing the relationship between neural activity and behavior. Current large-scale approaches, however, focus exclusively on either predicting neural activity from behavior (encoding) or predicting behavior from neural activity (decoding), limiting their ability to capture the bidirectional relationship between neural activity and behavior. To bridge this gap, we introduce a multimodal, multi-task model that enables simultaneous Neural Encoding and Decoding at Scale (NEDS). Central to our approach is a novel multi-task-masking strategy, which alternates between neural, behavioral, within-modality, and cross-modality masking. We pretrain our method on the International Brain Laboratory (IBL) repeated site dataset, which includes recordings from 83 animals performing the same visual decision-making task. In comparison to other large-scale models, we demonstrate that NEDS achieves state-of-the-art performance for both encoding and decoding when pretrained on multi-animal data and then fine-tuned on new animals. Surprisingly, NEDS's learned embeddings exhibit emergent properties: even without explicit training, they are highly predictive of the brain regions in each recording. Altogether, our approach is a step towards a foundation model of the brain that enables seamless translation between neural activity and behavior.","authors":["Yizi Zhang","Yanchen Wang","Mehdi Azabou","Alexandre Andre","Zixuan Wang","Hanrui Lyu","The International Brain Laboratory","Eva Dyer","Liam Paninski","Cole Hurwitz"],"url":"https://arxiv.org/abs/2504.08201"}
{"created":"2025-04-22","title":"Stochastic momentum ADMM for nonconvex and nonsmooth optimization with application to PnP algorithm","abstract":"This paper proposes SMADMM, a single-loop Stochastic Momentum Alternating Direction Method of Multipliers for solving a class of nonconvex and nonsmooth composite optimization problems. SMADMM achieves the optimal oracle complexity of $\\mathcal{O}(\\epsilon^{-3/2})$ in the online setting. Unlike previous stochastic ADMM algorithms that require large mini-batches or a double-loop structure, SMADMM uses only $\\mathcal{O}(1)$ stochastic gradient evaluations per iteration and avoids costly restarts. To further improve practicality, we incorporate dynamic step sizes and penalty parameters, proving that SMADMM maintains its optimal complexity without the need for large initial batches. We also develop PnP-SMADMM by integrating plug-and-play priors, and establish its theoretical convergence under mild assumptions. Extensive experiments on classification, CT image reconstruction, and phase retrieval tasks demonstrate that our approach outperforms existing stochastic ADMM methods both in accuracy and efficiency, validating our theoretical results.","authors":["Kangkang Deng","Shuchang Zhang","Boyu Wang","Jiachen Jin","Juan Zhou","Hongxia Wang"],"url":"https://arxiv.org/abs/2504.08223"}
{"created":"2025-04-22","title":"Graph-Based Prediction Models for Data Debiasing","abstract":"Bias in data collection, arising from both under-reporting and over-reporting, poses significant challenges in critical applications such as healthcare and public safety. In this work, we introduce Graph-based Over- and Under-reporting Debiasing (GROUD), a novel graph-based optimization framework that debiases reported data by jointly estimating the true incident counts and the associated reporting bias probabilities. By modeling the bias as a smooth signal over a graph constructed from geophysical or feature-based similarities, our convex formulation not only ensures a unique solution but also comes with theoretical recovery guarantees under certain assumptions. We validate GROUD on both challenging simulated experiments and real-world datasets -- including Atlanta emergency calls and COVID-19 vaccine adverse event reports -- demonstrating its robustness and superior performance in accurately recovering debiased counts. This approach paves the way for more reliable downstream decision-making in systems affected by reporting irregularities.","authors":["Dongze Wu","Hanyang Jiang","Yao Xie"],"url":"https://arxiv.org/abs/2504.09348"}
{"created":"2025-04-22","title":"Fine-tuning a Large Language Model for Automating Computational Fluid Dynamics Simulations","abstract":"Configuring computational fluid dynamics (CFD) simulations typically demands extensive domain expertise, limiting broader access. Although large language models (LLMs) have advanced scientific computing, their use in automating CFD workflows is underdeveloped. We introduce a novel approach centered on domain-specific LLM adaptation. By fine-tuning Qwen2.5-7B-Instruct on NL2FOAM, our custom dataset of 28716 natural language-to-OpenFOAM configuration pairs with chain-of-thought (CoT) annotations, we enable direct translation from natural language descriptions to executable CFD setups. A multi-agent framework orchestrates the process, autonomously verifying inputs, generating configurations, running simulations, and correcting errors. Evaluation on a benchmark of 21 diverse flow cases demonstrates state-of-the-art performance, achieving 88.7% solution accuracy and 82.6% first-attempt success rate. This significantly outperforms larger general-purpose models like Qwen2.5-72B-Instruct, DeepSeek-R1, and Llama3.3-70B-Instruct, while also requiring fewer correction iterations and maintaining high computational efficiency. The results highlight the critical role of domain-specific adaptation in deploying LLM assistants for complex engineering workflows. Our code and fine-tuned model have been deposited at https://github.com/YYgroup/AutoCFD.","authors":["Zhehao Dong","Zhen Lu","Yue Yang"],"url":"https://arxiv.org/abs/2504.09602"}
{"created":"2025-04-22","title":"Physics-Informed Neural Networks for Enhanced Interface Preservation in Lattice Boltzmann Multiphase Simulations","abstract":"This paper presents an improved approach for preserving sharp interfaces in multiphase Lattice Boltzmann Method (LBM) simulations using Physics-Informed Neural Networks (PINNs). Interface diffusion is a common challenge in multiphase LBM, leading to reduced accuracy in simulating phenomena where interfacial dynamics are critical. We propose a coupled PINN-LBM framework that maintains interface sharpness while preserving the physical accuracy of the simulation. Our approach is validated through droplet simulations, with quantitative metrics measuring interface width, maximum gradient, phase separation, effective interface width, and interface energy. The enhanced visualization techniques employed in this work clearly demonstrate the superior performance of PINN-LBM over standard LBM for multiphase simulations, particularly in maintaining well-defined interfaces throughout the simulation. We provide a comprehensive analysis of the results, showcasing how the neural network integration effectively counteracts numerical diffusion, while maintaining physical consistency with the underlying fluid dynamics.","authors":["Yue Li","Lihong Zhang"],"url":"https://arxiv.org/abs/2504.10539"}
{"created":"2025-04-22","title":"Wasserstein Distributionally Robust Regret Optimization","abstract":"Distributionally Robust Optimization (DRO) is a popular framework for decision-making under uncertainty, but its adversarial nature can lead to overly conservative solutions. To address this, we study ex-ante Distributionally Robust Regret Optimization (DRRO), focusing on Wasserstein-based ambiguity sets which are popular due to their links to regularization and machine learning. We provide a systematic analysis of Wasserstein DRRO, paralleling known results for Wasserstein DRO. Under smoothness and regularity conditions, we show that Wasserstein DRRO coincides with Empirical Risk Minimization (ERM) up to first-order terms, and exactly so in convex quadratic settings. We revisit the Wasserstein DRRO newsvendor problem, where the loss is the maximum of two linear functions of demand and decision. Extending [25], we show that the regret can be computed by maximizing two one-dimensional concave functions. For more general loss functions involving the maximum of multiple linear terms in multivariate random variables and decision vectors, we prove that computing the regret and thus also the DRRO policy is NP-hard. We then propose a convex relaxation for these more general Wasserstein DRRO problems and demonstrate its strong empirical performance. Finally, we provide an upper bound on the optimality gap of our relaxation and show it improves over recent alternatives.","authors":["Lukas-Benedikt Fiechtner","Jose Blanchet"],"url":"https://arxiv.org/abs/2504.10796"}
{"created":"2025-04-22","title":"Traffic Adaptive Moving-window Service Patrolling for Real-time Incident Management during High-impact Events","abstract":"This paper presents the Traffic Adaptive Moving-window Patrolling Algorithm (TAMPA), designed to improve real-time incident management during major events like sports tournaments and concerts. Such events significantly stress transportation networks, requiring efficient and adaptive patrol solutions. TAMPA integrates predictive traffic modeling and real-time complaint estimation, dynamically optimizing patrol deployment. Using dynamic programming, the algorithm continuously adjusts patrol strategies within short planning windows, effectively balancing immediate response and efficient routing. Leveraging the Dvoretzky-Kiefer-Wolfowitz inequality, TAMPA detects significant shifts in complaint patterns, triggering proactive adjustments in patrol routes. Theoretical analyses ensure performance remains closely aligned with optimal solutions. Simulation results from an urban traffic network demonstrate TAMPA's superior performance, showing improvements of approximately 87.5\\% over stationary methods and 114.2\\% over random strategies. Future work includes enhancing adaptability and incorporating digital twin technology for improved predictive accuracy, particularly relevant for events like the 2026 FIFA World Cup at MetLife Stadium.","authors":["Haozhe Lei","Ya-Ting Yang","Tao Li","Zilin Bian","Fan Zuo","Sundeep Rangan","Kaan Ozbay"],"url":"https://arxiv.org/abs/2504.11570"}
